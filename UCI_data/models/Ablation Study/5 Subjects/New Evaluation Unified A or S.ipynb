{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '58 tGravityAcc-energy()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '90 tBodyAccJerk-max()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '203 tBodyAccMag-mad()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '216 tGravityAccMag-mad()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Activity_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Activity_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "class Subject_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Subject_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 5)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def get_act_matrix(batch_size, a_dim):\n",
    "    indexes = np.random.randint(a_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((len(indexes), indexes.max()+1))\n",
    "    one_hot[np.arange(len(indexes)),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "    \n",
    "def get_usr_matrix(batch_size, u_dim):\n",
    "    indexes = np.random.randint(u_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((indexes.size, indexes.max()+1))\n",
    "    one_hot[np.arange(indexes.size),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7, 8]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Activity_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.2604368925094604, Final Batch Loss: 1.0923066139221191\n",
      "Epoch 2, Loss: 3.247307777404785, Final Batch Loss: 1.0743658542633057\n",
      "Epoch 3, Loss: 3.244359254837036, Final Batch Loss: 1.0873245000839233\n",
      "Epoch 4, Loss: 3.244392156600952, Final Batch Loss: 1.0947113037109375\n",
      "Epoch 5, Loss: 3.231306314468384, Final Batch Loss: 1.079217791557312\n",
      "Epoch 6, Loss: 3.224176526069641, Final Batch Loss: 1.0788626670837402\n",
      "Epoch 7, Loss: 3.212392568588257, Final Batch Loss: 1.075840950012207\n",
      "Epoch 8, Loss: 3.1904834508895874, Final Batch Loss: 1.048733115196228\n",
      "Epoch 9, Loss: 3.1881483793258667, Final Batch Loss: 1.0706324577331543\n",
      "Epoch 10, Loss: 3.1638439893722534, Final Batch Loss: 1.0475085973739624\n",
      "Epoch 11, Loss: 3.1571143865585327, Final Batch Loss: 1.0665897130966187\n",
      "Epoch 12, Loss: 3.119445562362671, Final Batch Loss: 1.039324164390564\n",
      "Epoch 13, Loss: 3.0842329263687134, Final Batch Loss: 1.0190354585647583\n",
      "Epoch 14, Loss: 3.0516557693481445, Final Batch Loss: 1.015592336654663\n",
      "Epoch 15, Loss: 3.0023139119148254, Final Batch Loss: 0.9949137568473816\n",
      "Epoch 16, Loss: 2.9496070742607117, Final Batch Loss: 0.9842869639396667\n",
      "Epoch 17, Loss: 2.87856525182724, Final Batch Loss: 0.9512726664543152\n",
      "Epoch 18, Loss: 2.8293068408966064, Final Batch Loss: 0.9305863976478577\n",
      "Epoch 19, Loss: 2.7417696714401245, Final Batch Loss: 0.9082787036895752\n",
      "Epoch 20, Loss: 2.6471421122550964, Final Batch Loss: 0.8818858861923218\n",
      "Epoch 21, Loss: 2.5413323044776917, Final Batch Loss: 0.8551588654518127\n",
      "Epoch 22, Loss: 2.3499033451080322, Final Batch Loss: 0.73246169090271\n",
      "Epoch 23, Loss: 2.2707438468933105, Final Batch Loss: 0.7499188780784607\n",
      "Epoch 24, Loss: 2.0810739398002625, Final Batch Loss: 0.6877457499504089\n",
      "Epoch 25, Loss: 1.946934163570404, Final Batch Loss: 0.6308414340019226\n",
      "Epoch 26, Loss: 1.8313607573509216, Final Batch Loss: 0.5889766216278076\n",
      "Epoch 27, Loss: 1.7017680406570435, Final Batch Loss: 0.5514640212059021\n",
      "Epoch 28, Loss: 1.6285793781280518, Final Batch Loss: 0.5256755352020264\n",
      "Epoch 29, Loss: 1.504746675491333, Final Batch Loss: 0.4570435881614685\n",
      "Epoch 30, Loss: 1.4598879516124725, Final Batch Loss: 0.46054255962371826\n",
      "Epoch 31, Loss: 1.448612242937088, Final Batch Loss: 0.4915132522583008\n",
      "Epoch 32, Loss: 1.3770503103733063, Final Batch Loss: 0.4783516526222229\n",
      "Epoch 33, Loss: 1.3350881338119507, Final Batch Loss: 0.4564710557460785\n",
      "Epoch 34, Loss: 1.2135781645774841, Final Batch Loss: 0.40580832958221436\n",
      "Epoch 35, Loss: 1.1761963069438934, Final Batch Loss: 0.3701143264770508\n",
      "Epoch 36, Loss: 1.0866841971874237, Final Batch Loss: 0.36376968026161194\n",
      "Epoch 37, Loss: 1.043293982744217, Final Batch Loss: 0.3278809189796448\n",
      "Epoch 38, Loss: 0.9927924871444702, Final Batch Loss: 0.3155425786972046\n",
      "Epoch 39, Loss: 0.9548542499542236, Final Batch Loss: 0.30468466877937317\n",
      "Epoch 40, Loss: 0.8756161630153656, Final Batch Loss: 0.27966582775115967\n",
      "Epoch 41, Loss: 0.8639023303985596, Final Batch Loss: 0.28271806240081787\n",
      "Epoch 42, Loss: 0.8132726401090622, Final Batch Loss: 0.26386716961860657\n",
      "Epoch 43, Loss: 0.8036204874515533, Final Batch Loss: 0.27745118737220764\n",
      "Epoch 44, Loss: 0.6473435610532761, Final Batch Loss: 0.18116876482963562\n",
      "Epoch 45, Loss: 0.7171773165464401, Final Batch Loss: 0.2574860751628876\n",
      "Epoch 46, Loss: 0.6967354714870453, Final Batch Loss: 0.23641043901443481\n",
      "Epoch 47, Loss: 0.5423297137022018, Final Batch Loss: 0.1429319679737091\n",
      "Epoch 48, Loss: 0.6977723687887192, Final Batch Loss: 0.25665101408958435\n",
      "Epoch 49, Loss: 0.6063874810934067, Final Batch Loss: 0.20577837526798248\n",
      "Epoch 50, Loss: 0.5398916304111481, Final Batch Loss: 0.19594784080982208\n",
      "Epoch 51, Loss: 0.5130590200424194, Final Batch Loss: 0.2027805745601654\n",
      "Epoch 52, Loss: 0.5436184406280518, Final Batch Loss: 0.16949224472045898\n",
      "Epoch 53, Loss: 0.5297371447086334, Final Batch Loss: 0.1876993030309677\n",
      "Epoch 54, Loss: 0.4957582652568817, Final Batch Loss: 0.1884555071592331\n",
      "Epoch 55, Loss: 0.46980805695056915, Final Batch Loss: 0.14406335353851318\n",
      "Epoch 56, Loss: 0.4752535969018936, Final Batch Loss: 0.1694696992635727\n",
      "Epoch 57, Loss: 0.4498906433582306, Final Batch Loss: 0.12760058045387268\n",
      "Epoch 58, Loss: 0.48492996394634247, Final Batch Loss: 0.18336336314678192\n",
      "Epoch 59, Loss: 0.4316660091280937, Final Batch Loss: 0.10840954631567001\n",
      "Epoch 60, Loss: 0.3922648951411247, Final Batch Loss: 0.11272227019071579\n",
      "Epoch 61, Loss: 0.4824671819806099, Final Batch Loss: 0.1889820545911789\n",
      "Epoch 62, Loss: 0.44557371735572815, Final Batch Loss: 0.12646305561065674\n",
      "Epoch 63, Loss: 0.49107229709625244, Final Batch Loss: 0.19033659994602203\n",
      "Epoch 64, Loss: 0.42464614659547806, Final Batch Loss: 0.11660406738519669\n",
      "Epoch 65, Loss: 0.4149007946252823, Final Batch Loss: 0.1471479833126068\n",
      "Epoch 66, Loss: 0.43164295703172684, Final Batch Loss: 0.16467227041721344\n",
      "Epoch 67, Loss: 0.3595135733485222, Final Batch Loss: 0.10567566752433777\n",
      "Epoch 68, Loss: 0.3834098353981972, Final Batch Loss: 0.1239762082695961\n",
      "Epoch 69, Loss: 0.43709493428468704, Final Batch Loss: 0.18110547959804535\n",
      "Epoch 70, Loss: 0.37887896597385406, Final Batch Loss: 0.09882965683937073\n",
      "Epoch 71, Loss: 0.3807917535305023, Final Batch Loss: 0.13687939941883087\n",
      "Epoch 72, Loss: 0.38842054456472397, Final Batch Loss: 0.11018850654363632\n",
      "Epoch 73, Loss: 0.38047101348638535, Final Batch Loss: 0.13407526910305023\n",
      "Epoch 74, Loss: 0.36079417169094086, Final Batch Loss: 0.15746456384658813\n",
      "Epoch 75, Loss: 0.34611625224351883, Final Batch Loss: 0.13603049516677856\n",
      "Epoch 76, Loss: 0.304369293153286, Final Batch Loss: 0.08962543308734894\n",
      "Epoch 77, Loss: 0.3373209238052368, Final Batch Loss: 0.0898338332772255\n",
      "Epoch 78, Loss: 0.38930943608283997, Final Batch Loss: 0.12415530532598495\n",
      "Epoch 79, Loss: 0.35453105717897415, Final Batch Loss: 0.10636422038078308\n",
      "Epoch 80, Loss: 0.3190208226442337, Final Batch Loss: 0.12247258424758911\n",
      "Epoch 81, Loss: 0.29759080708026886, Final Batch Loss: 0.0811343565583229\n",
      "Epoch 82, Loss: 0.337263748049736, Final Batch Loss: 0.09436389803886414\n",
      "Epoch 83, Loss: 0.28067538514733315, Final Batch Loss: 0.06064501777291298\n",
      "Epoch 84, Loss: 0.2739958390593529, Final Batch Loss: 0.10011272877454758\n",
      "Epoch 85, Loss: 0.3245539963245392, Final Batch Loss: 0.10257097333669662\n",
      "Epoch 86, Loss: 0.3182617500424385, Final Batch Loss: 0.12653295695781708\n",
      "Epoch 87, Loss: 0.2889937534928322, Final Batch Loss: 0.12135549634695053\n",
      "Epoch 88, Loss: 0.3051977679133415, Final Batch Loss: 0.10842105001211166\n",
      "Epoch 89, Loss: 0.25827474147081375, Final Batch Loss: 0.0809796154499054\n",
      "Epoch 90, Loss: 0.3103492259979248, Final Batch Loss: 0.1410001814365387\n",
      "Epoch 91, Loss: 0.2918897196650505, Final Batch Loss: 0.07669991254806519\n",
      "Epoch 92, Loss: 0.31067361682653427, Final Batch Loss: 0.1318087875843048\n",
      "Epoch 93, Loss: 0.27587809041142464, Final Batch Loss: 0.09399374574422836\n",
      "Epoch 94, Loss: 0.26352744549512863, Final Batch Loss: 0.09877213835716248\n",
      "Epoch 95, Loss: 0.24736660718917847, Final Batch Loss: 0.06703515350818634\n",
      "Epoch 96, Loss: 0.3017524965107441, Final Batch Loss: 0.1494264155626297\n",
      "Epoch 97, Loss: 0.25714995339512825, Final Batch Loss: 0.1360548883676529\n",
      "Epoch 98, Loss: 0.28554344177246094, Final Batch Loss: 0.13812099397182465\n",
      "Epoch 99, Loss: 0.2637404687702656, Final Batch Loss: 0.04197053238749504\n",
      "Epoch 100, Loss: 0.3087204545736313, Final Batch Loss: 0.08604883402585983\n",
      "Epoch 101, Loss: 0.2762925364077091, Final Batch Loss: 0.04977768287062645\n",
      "Epoch 102, Loss: 0.2891998589038849, Final Batch Loss: 0.07435642927885056\n",
      "Epoch 103, Loss: 0.33044975250959396, Final Batch Loss: 0.13485071063041687\n",
      "Epoch 104, Loss: 0.3111090809106827, Final Batch Loss: 0.12404372543096542\n",
      "Epoch 105, Loss: 0.25702960789203644, Final Batch Loss: 0.09529513120651245\n",
      "Epoch 106, Loss: 0.24036618322134018, Final Batch Loss: 0.06625594198703766\n",
      "Epoch 107, Loss: 0.21521390601992607, Final Batch Loss: 0.05284782126545906\n",
      "Epoch 108, Loss: 0.2962027043104172, Final Batch Loss: 0.07353553920984268\n",
      "Epoch 109, Loss: 0.24678698182106018, Final Batch Loss: 0.07583807408809662\n",
      "Epoch 110, Loss: 0.27660348266363144, Final Batch Loss: 0.1306135356426239\n",
      "Epoch 111, Loss: 0.21792250871658325, Final Batch Loss: 0.08152972906827927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112, Loss: 0.3059864416718483, Final Batch Loss: 0.09663908183574677\n",
      "Epoch 113, Loss: 0.25133049860596657, Final Batch Loss: 0.07476981729269028\n",
      "Epoch 114, Loss: 0.22448139637708664, Final Batch Loss: 0.09522062540054321\n",
      "Epoch 115, Loss: 0.21518034860491753, Final Batch Loss: 0.03550456091761589\n",
      "Epoch 116, Loss: 0.1985253021121025, Final Batch Loss: 0.030714109539985657\n",
      "Epoch 117, Loss: 0.25120290368795395, Final Batch Loss: 0.05948729068040848\n",
      "Epoch 118, Loss: 0.20078280195593834, Final Batch Loss: 0.0382009781897068\n",
      "Epoch 119, Loss: 0.274280846118927, Final Batch Loss: 0.1045471578836441\n",
      "Epoch 120, Loss: 0.24227990582585335, Final Batch Loss: 0.10553690791130066\n",
      "Epoch 121, Loss: 0.2517029158771038, Final Batch Loss: 0.05814242735505104\n",
      "Epoch 122, Loss: 0.21462027728557587, Final Batch Loss: 0.06380203366279602\n",
      "Epoch 123, Loss: 0.2476310357451439, Final Batch Loss: 0.11554593592882156\n",
      "Epoch 124, Loss: 0.22515712678432465, Final Batch Loss: 0.06796742975711823\n",
      "Epoch 125, Loss: 0.26470310240983963, Final Batch Loss: 0.1121068149805069\n",
      "Epoch 126, Loss: 0.27988171577453613, Final Batch Loss: 0.10331684350967407\n",
      "Epoch 127, Loss: 0.18164745345711708, Final Batch Loss: 0.09301338344812393\n",
      "Epoch 128, Loss: 0.2701593041419983, Final Batch Loss: 0.12921097874641418\n",
      "Epoch 129, Loss: 0.18653148040175438, Final Batch Loss: 0.052142877131700516\n",
      "Epoch 130, Loss: 0.23335742577910423, Final Batch Loss: 0.08466336131095886\n",
      "Epoch 131, Loss: 0.19868573173880577, Final Batch Loss: 0.04309457167983055\n",
      "Epoch 132, Loss: 0.23963376134634018, Final Batch Loss: 0.06897743791341782\n",
      "Epoch 133, Loss: 0.17661835625767708, Final Batch Loss: 0.0833585187792778\n",
      "Epoch 134, Loss: 0.1995634250342846, Final Batch Loss: 0.03666933998465538\n",
      "Epoch 135, Loss: 0.1829528994858265, Final Batch Loss: 0.04497595503926277\n",
      "Epoch 136, Loss: 0.17744747176766396, Final Batch Loss: 0.04746057465672493\n",
      "Epoch 137, Loss: 0.193119078874588, Final Batch Loss: 0.035709187388420105\n",
      "Epoch 138, Loss: 0.23454129695892334, Final Batch Loss: 0.08858289569616318\n",
      "Epoch 139, Loss: 0.302812859416008, Final Batch Loss: 0.14111538231372833\n",
      "Epoch 140, Loss: 0.27516620978713036, Final Batch Loss: 0.1148640364408493\n",
      "Epoch 141, Loss: 0.2399340607225895, Final Batch Loss: 0.09189806878566742\n",
      "Epoch 142, Loss: 0.244515061378479, Final Batch Loss: 0.07528287917375565\n",
      "Epoch 143, Loss: 0.2642896920442581, Final Batch Loss: 0.06802456825971603\n",
      "Epoch 144, Loss: 0.17676061391830444, Final Batch Loss: 0.04787249490618706\n",
      "Epoch 145, Loss: 0.236020777374506, Final Batch Loss: 0.10807821154594421\n",
      "Epoch 146, Loss: 0.2224011942744255, Final Batch Loss: 0.09211727231740952\n",
      "Epoch 147, Loss: 0.15422789007425308, Final Batch Loss: 0.06074151769280434\n",
      "Epoch 148, Loss: 0.17093459889292717, Final Batch Loss: 0.050701647996902466\n",
      "Epoch 149, Loss: 0.2320556491613388, Final Batch Loss: 0.054434165358543396\n",
      "Epoch 150, Loss: 0.20974188670516014, Final Batch Loss: 0.09119047969579697\n",
      "Epoch 151, Loss: 0.20061152428388596, Final Batch Loss: 0.05426971614360809\n",
      "Epoch 152, Loss: 0.19888202846050262, Final Batch Loss: 0.08204525709152222\n",
      "Epoch 153, Loss: 0.20529355853796005, Final Batch Loss: 0.07434846460819244\n",
      "Epoch 154, Loss: 0.2128652259707451, Final Batch Loss: 0.0837668776512146\n",
      "Epoch 155, Loss: 0.20021069422364235, Final Batch Loss: 0.08207949995994568\n",
      "Epoch 156, Loss: 0.15189003571867943, Final Batch Loss: 0.04609604924917221\n",
      "Epoch 157, Loss: 0.22202376648783684, Final Batch Loss: 0.09530133008956909\n",
      "Epoch 158, Loss: 0.2035149596631527, Final Batch Loss: 0.038458872586488724\n",
      "Epoch 159, Loss: 0.24260956794023514, Final Batch Loss: 0.15233109891414642\n",
      "Epoch 160, Loss: 0.15280993655323982, Final Batch Loss: 0.03641703352332115\n",
      "Epoch 161, Loss: 0.18218382820487022, Final Batch Loss: 0.023698929697275162\n",
      "Epoch 162, Loss: 0.2091851830482483, Final Batch Loss: 0.07407736033201218\n",
      "Epoch 163, Loss: 0.19108256325125694, Final Batch Loss: 0.0450018085539341\n",
      "Epoch 164, Loss: 0.13650638610124588, Final Batch Loss: 0.02294563129544258\n",
      "Epoch 165, Loss: 0.16863427683711052, Final Batch Loss: 0.06446660310029984\n",
      "Epoch 166, Loss: 0.18238992616534233, Final Batch Loss: 0.10144799947738647\n",
      "Epoch 167, Loss: 0.20476090162992477, Final Batch Loss: 0.10224612802267075\n",
      "Epoch 168, Loss: 0.18169845268130302, Final Batch Loss: 0.08077911287546158\n",
      "Epoch 169, Loss: 0.26585852168500423, Final Batch Loss: 0.1393493115901947\n",
      "Epoch 170, Loss: 0.13474196195602417, Final Batch Loss: 0.040322985500097275\n",
      "Epoch 171, Loss: 0.15750621259212494, Final Batch Loss: 0.06746543943881989\n",
      "Epoch 172, Loss: 0.1774175874888897, Final Batch Loss: 0.05926527455449104\n",
      "Epoch 173, Loss: 0.16319138556718826, Final Batch Loss: 0.02762831747531891\n",
      "Epoch 174, Loss: 0.1814703457057476, Final Batch Loss: 0.04007889702916145\n",
      "Epoch 175, Loss: 0.12997793033719063, Final Batch Loss: 0.021372638642787933\n",
      "Epoch 176, Loss: 0.1829410344362259, Final Batch Loss: 0.08701114356517792\n",
      "Epoch 177, Loss: 0.16623927652835846, Final Batch Loss: 0.04157167300581932\n",
      "Epoch 178, Loss: 0.19571590796113014, Final Batch Loss: 0.1019502580165863\n",
      "Epoch 179, Loss: 0.18318473175168037, Final Batch Loss: 0.07177937775850296\n",
      "Epoch 180, Loss: 0.13755390793085098, Final Batch Loss: 0.018944447860121727\n",
      "Epoch 181, Loss: 0.1885935217142105, Final Batch Loss: 0.11224225908517838\n",
      "Epoch 182, Loss: 0.17006364837288857, Final Batch Loss: 0.05729648098349571\n",
      "Epoch 183, Loss: 0.20198391377925873, Final Batch Loss: 0.10964075475931168\n",
      "Epoch 184, Loss: 0.17520444840192795, Final Batch Loss: 0.04241977632045746\n",
      "Epoch 185, Loss: 0.17829124256968498, Final Batch Loss: 0.043695997446775436\n",
      "Epoch 186, Loss: 0.16122575290501118, Final Batch Loss: 0.02403232268989086\n",
      "Epoch 187, Loss: 0.12217164132744074, Final Batch Loss: 0.015553628094494343\n",
      "Epoch 188, Loss: 0.19090097025036812, Final Batch Loss: 0.057478535920381546\n",
      "Epoch 189, Loss: 0.14645111933350563, Final Batch Loss: 0.03366002440452576\n",
      "Epoch 190, Loss: 0.17117192968726158, Final Batch Loss: 0.034316424280405045\n",
      "Epoch 191, Loss: 0.15869377180933952, Final Batch Loss: 0.028233863413333893\n",
      "Epoch 192, Loss: 0.1387923713773489, Final Batch Loss: 0.027921048924326897\n",
      "Epoch 193, Loss: 0.14312091283500195, Final Batch Loss: 0.042382534593343735\n",
      "Epoch 194, Loss: 0.1546257734298706, Final Batch Loss: 0.011074215173721313\n",
      "Epoch 195, Loss: 0.16224094852805138, Final Batch Loss: 0.03422900289297104\n",
      "Epoch 196, Loss: 0.15539966896176338, Final Batch Loss: 0.07295673340559006\n",
      "Epoch 197, Loss: 0.17298897355794907, Final Batch Loss: 0.08434048295021057\n",
      "Epoch 198, Loss: 0.15904206410050392, Final Batch Loss: 0.06783287972211838\n",
      "Epoch 199, Loss: 0.17935705557465553, Final Batch Loss: 0.03433315083384514\n",
      "Epoch 200, Loss: 0.15687615796923637, Final Batch Loss: 0.018106896430253983\n",
      "Epoch 201, Loss: 0.1950143352150917, Final Batch Loss: 0.0832856148481369\n",
      "Epoch 202, Loss: 0.12387415021657944, Final Batch Loss: 0.04024377837777138\n",
      "Epoch 203, Loss: 0.1302625872194767, Final Batch Loss: 0.05170129984617233\n",
      "Epoch 204, Loss: 0.1336863450706005, Final Batch Loss: 0.03668998181819916\n",
      "Epoch 205, Loss: 0.12822610884904861, Final Batch Loss: 0.03284535929560661\n",
      "Epoch 206, Loss: 0.1377620603889227, Final Batch Loss: 0.019998999312520027\n",
      "Epoch 207, Loss: 0.19371915608644485, Final Batch Loss: 0.054065726697444916\n",
      "Epoch 208, Loss: 0.14890296384692192, Final Batch Loss: 0.03890662267804146\n",
      "Epoch 209, Loss: 0.184280414134264, Final Batch Loss: 0.0838434174656868\n",
      "Epoch 210, Loss: 0.13063209131360054, Final Batch Loss: 0.05042213574051857\n",
      "Epoch 211, Loss: 0.14995237067341805, Final Batch Loss: 0.05498708039522171\n",
      "Epoch 212, Loss: 0.16157704964280128, Final Batch Loss: 0.0791064202785492\n",
      "Epoch 213, Loss: 0.14260659366846085, Final Batch Loss: 0.07099846005439758\n",
      "Epoch 214, Loss: 0.1711438000202179, Final Batch Loss: 0.03162520006299019\n",
      "Epoch 215, Loss: 0.14025388285517693, Final Batch Loss: 0.04140900447964668\n",
      "Epoch 216, Loss: 0.11891826055943966, Final Batch Loss: 0.022322801873087883\n",
      "Epoch 217, Loss: 0.14194229617714882, Final Batch Loss: 0.026179347187280655\n",
      "Epoch 218, Loss: 0.17986154928803444, Final Batch Loss: 0.08504197001457214\n",
      "Epoch 219, Loss: 0.13418391533195972, Final Batch Loss: 0.028461148962378502\n",
      "Epoch 220, Loss: 0.11512086540460587, Final Batch Loss: 0.0419500358402729\n",
      "Epoch 221, Loss: 0.12751332856714725, Final Batch Loss: 0.03501056134700775\n",
      "Epoch 222, Loss: 0.151011161506176, Final Batch Loss: 0.018729452043771744\n",
      "Epoch 223, Loss: 0.13908720668405294, Final Batch Loss: 0.015249478630721569\n",
      "Epoch 224, Loss: 0.1691325455904007, Final Batch Loss: 0.07487146556377411\n",
      "Epoch 225, Loss: 0.12544343806803226, Final Batch Loss: 0.024326851591467857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226, Loss: 0.16384362615644932, Final Batch Loss: 0.060432318598032\n",
      "Epoch 227, Loss: 0.1456424668431282, Final Batch Loss: 0.043471530079841614\n",
      "Epoch 228, Loss: 0.12595934979617596, Final Batch Loss: 0.0276006031781435\n",
      "Epoch 229, Loss: 0.1649528332054615, Final Batch Loss: 0.07057897746562958\n",
      "Epoch 230, Loss: 0.170269887894392, Final Batch Loss: 0.05601052939891815\n",
      "Epoch 231, Loss: 0.13846344873309135, Final Batch Loss: 0.03289224952459335\n",
      "Epoch 232, Loss: 0.15925528667867184, Final Batch Loss: 0.06524311006069183\n",
      "Epoch 233, Loss: 0.17631692253053188, Final Batch Loss: 0.09764669835567474\n",
      "Epoch 234, Loss: 0.12454153224825859, Final Batch Loss: 0.014943383634090424\n",
      "Epoch 235, Loss: 0.15399792417883873, Final Batch Loss: 0.036055441945791245\n",
      "Epoch 236, Loss: 0.10579955019056797, Final Batch Loss: 0.04582373425364494\n",
      "Epoch 237, Loss: 0.11644266545772552, Final Batch Loss: 0.027970753610134125\n",
      "Epoch 238, Loss: 0.16486212238669395, Final Batch Loss: 0.08295343816280365\n",
      "Epoch 239, Loss: 0.1675122044980526, Final Batch Loss: 0.05886850133538246\n",
      "Epoch 240, Loss: 0.15375184267759323, Final Batch Loss: 0.06977075338363647\n",
      "Epoch 241, Loss: 0.13601494207978249, Final Batch Loss: 0.04812660068273544\n",
      "Epoch 242, Loss: 0.12656112853437662, Final Batch Loss: 0.015238379128277302\n",
      "Epoch 243, Loss: 0.1175044346600771, Final Batch Loss: 0.022553985938429832\n",
      "Epoch 244, Loss: 0.11660240963101387, Final Batch Loss: 0.01686527207493782\n",
      "Epoch 245, Loss: 0.12261463701725006, Final Batch Loss: 0.030330626294016838\n",
      "Epoch 246, Loss: 0.18252488039433956, Final Batch Loss: 0.09363812208175659\n",
      "Epoch 247, Loss: 0.1609698012471199, Final Batch Loss: 0.03902100771665573\n",
      "Epoch 248, Loss: 0.18704995140433311, Final Batch Loss: 0.10263792425394058\n",
      "Epoch 249, Loss: 0.15622422099113464, Final Batch Loss: 0.03823733702301979\n",
      "Epoch 250, Loss: 0.13296335749328136, Final Batch Loss: 0.025086035951972008\n",
      "Epoch 251, Loss: 0.11451026238501072, Final Batch Loss: 0.01636926643550396\n",
      "Epoch 252, Loss: 0.16926190815865993, Final Batch Loss: 0.04376235231757164\n",
      "Epoch 253, Loss: 0.12883073091506958, Final Batch Loss: 0.036092206835746765\n",
      "Epoch 254, Loss: 0.1651410236954689, Final Batch Loss: 0.05965901538729668\n",
      "Epoch 255, Loss: 0.12215455807745457, Final Batch Loss: 0.02467534877359867\n",
      "Epoch 256, Loss: 0.11088564246892929, Final Batch Loss: 0.014787295833230019\n",
      "Epoch 257, Loss: 0.17888880893588066, Final Batch Loss: 0.08871588110923767\n",
      "Epoch 258, Loss: 0.13343342021107674, Final Batch Loss: 0.03130410984158516\n",
      "Epoch 259, Loss: 0.09388613514602184, Final Batch Loss: 0.02301131747663021\n",
      "Epoch 260, Loss: 0.09508977644145489, Final Batch Loss: 0.020270679146051407\n",
      "Epoch 261, Loss: 0.1866980753839016, Final Batch Loss: 0.10653495043516159\n",
      "Epoch 262, Loss: 0.19037069752812386, Final Batch Loss: 0.0801098644733429\n",
      "Epoch 263, Loss: 0.1247759498655796, Final Batch Loss: 0.02858399972319603\n",
      "Epoch 264, Loss: 0.1546575203537941, Final Batch Loss: 0.051720403134822845\n",
      "Epoch 265, Loss: 0.1296462081372738, Final Batch Loss: 0.036466989666223526\n",
      "Epoch 266, Loss: 0.13715720735490322, Final Batch Loss: 0.05912928655743599\n",
      "Epoch 267, Loss: 0.15533430874347687, Final Batch Loss: 0.023537423461675644\n",
      "Epoch 268, Loss: 0.12803173437714577, Final Batch Loss: 0.029872428625822067\n",
      "Epoch 269, Loss: 0.11100972630083561, Final Batch Loss: 0.018977856263518333\n",
      "Epoch 270, Loss: 0.15823913924396038, Final Batch Loss: 0.08525394648313522\n",
      "Epoch 271, Loss: 0.1388224083930254, Final Batch Loss: 0.020431505516171455\n",
      "Epoch 272, Loss: 0.16815130785107613, Final Batch Loss: 0.09360311925411224\n",
      "Epoch 273, Loss: 0.11733845435082912, Final Batch Loss: 0.016789132729172707\n",
      "Epoch 274, Loss: 0.13933341018855572, Final Batch Loss: 0.02505728416144848\n",
      "Epoch 275, Loss: 0.12220981903374195, Final Batch Loss: 0.05256802216172218\n",
      "Epoch 276, Loss: 0.09210399724543095, Final Batch Loss: 0.020383644849061966\n",
      "Epoch 277, Loss: 0.09557807631790638, Final Batch Loss: 0.018508633598685265\n",
      "Epoch 278, Loss: 0.1011544931679964, Final Batch Loss: 0.015625154599547386\n",
      "Epoch 279, Loss: 0.15075512044131756, Final Batch Loss: 0.08238931000232697\n",
      "Epoch 280, Loss: 0.14041188545525074, Final Batch Loss: 0.024793891236186028\n",
      "Epoch 281, Loss: 0.11503258720040321, Final Batch Loss: 0.03172225132584572\n",
      "Epoch 282, Loss: 0.1072014831006527, Final Batch Loss: 0.007912367582321167\n",
      "Epoch 283, Loss: 0.1314915046095848, Final Batch Loss: 0.05691047012805939\n",
      "Epoch 284, Loss: 0.14624283835291862, Final Batch Loss: 0.05225181579589844\n",
      "Epoch 285, Loss: 0.1475924402475357, Final Batch Loss: 0.03598495572805405\n",
      "Epoch 286, Loss: 0.14220881089568138, Final Batch Loss: 0.043108779937028885\n",
      "Epoch 287, Loss: 0.12754718214273453, Final Batch Loss: 0.05051873251795769\n",
      "Epoch 288, Loss: 0.11556367948651314, Final Batch Loss: 0.05234904587268829\n",
      "Epoch 289, Loss: 0.15323523804545403, Final Batch Loss: 0.06246533989906311\n",
      "Epoch 290, Loss: 0.13127945736050606, Final Batch Loss: 0.04259847104549408\n",
      "Epoch 291, Loss: 0.12647641077637672, Final Batch Loss: 0.06358368694782257\n",
      "Epoch 292, Loss: 0.10115356091409922, Final Batch Loss: 0.014171225018799305\n",
      "Epoch 293, Loss: 0.1058011632412672, Final Batch Loss: 0.033892083913087845\n",
      "Epoch 294, Loss: 0.10210826434195042, Final Batch Loss: 0.01835567317903042\n",
      "Epoch 295, Loss: 0.1031403373926878, Final Batch Loss: 0.041864458471536636\n",
      "Epoch 296, Loss: 0.15336255356669426, Final Batch Loss: 0.0765690803527832\n",
      "Epoch 297, Loss: 0.10635389760136604, Final Batch Loss: 0.042643219232559204\n",
      "Epoch 298, Loss: 0.12007385306060314, Final Batch Loss: 0.040925558656454086\n",
      "Epoch 299, Loss: 0.12409995496273041, Final Batch Loss: 0.04961303621530533\n",
      "Epoch 300, Loss: 0.11261861026287079, Final Batch Loss: 0.052318669855594635\n",
      "Epoch 301, Loss: 0.11125760432332754, Final Batch Loss: 0.05222732573747635\n",
      "Epoch 302, Loss: 0.10257587395608425, Final Batch Loss: 0.027509275823831558\n",
      "Epoch 303, Loss: 0.12869595177471638, Final Batch Loss: 0.034768685698509216\n",
      "Epoch 304, Loss: 0.11418046057224274, Final Batch Loss: 0.04139605537056923\n",
      "Epoch 305, Loss: 0.15686878375709057, Final Batch Loss: 0.07823240011930466\n",
      "Epoch 306, Loss: 0.12718558683991432, Final Batch Loss: 0.027072723954916\n",
      "Epoch 307, Loss: 0.10538104921579361, Final Batch Loss: 0.03249229118227959\n",
      "Epoch 308, Loss: 0.12362202443182468, Final Batch Loss: 0.05776248499751091\n",
      "Epoch 309, Loss: 0.12006830796599388, Final Batch Loss: 0.016868777573108673\n",
      "Epoch 310, Loss: 0.10731565579771996, Final Batch Loss: 0.02831452339887619\n",
      "Epoch 311, Loss: 0.11109565384685993, Final Batch Loss: 0.053930945694446564\n",
      "Epoch 312, Loss: 0.09655416198074818, Final Batch Loss: 0.012678420171141624\n",
      "Epoch 313, Loss: 0.12691965885460377, Final Batch Loss: 0.008738895878195763\n",
      "Epoch 314, Loss: 0.08382219634950161, Final Batch Loss: 0.017193183302879333\n",
      "Epoch 315, Loss: 0.10680165514349937, Final Batch Loss: 0.01727781817317009\n",
      "Epoch 316, Loss: 0.12898273393511772, Final Batch Loss: 0.04288923740386963\n",
      "Epoch 317, Loss: 0.10586686432361603, Final Batch Loss: 0.030244622379541397\n",
      "Epoch 318, Loss: 0.12935101240873337, Final Batch Loss: 0.05918262526392937\n",
      "Epoch 319, Loss: 0.192884037271142, Final Batch Loss: 0.11962634325027466\n",
      "Epoch 320, Loss: 0.1435885988175869, Final Batch Loss: 0.06632448732852936\n",
      "Epoch 321, Loss: 0.11486600525677204, Final Batch Loss: 0.04006347432732582\n",
      "Epoch 322, Loss: 0.13498836383223534, Final Batch Loss: 0.0491880364716053\n",
      "Epoch 323, Loss: 0.10881639458239079, Final Batch Loss: 0.021240418776869774\n",
      "Epoch 324, Loss: 0.1523618884384632, Final Batch Loss: 0.07922965288162231\n",
      "Epoch 325, Loss: 0.15739991515874863, Final Batch Loss: 0.0740613043308258\n",
      "Epoch 326, Loss: 0.08832539804279804, Final Batch Loss: 0.010603593662381172\n",
      "Epoch 327, Loss: 0.10735983960330486, Final Batch Loss: 0.016419997438788414\n",
      "Epoch 328, Loss: 0.11999455094337463, Final Batch Loss: 0.04964284598827362\n",
      "Epoch 329, Loss: 0.12090463936328888, Final Batch Loss: 0.03372956067323685\n",
      "Epoch 330, Loss: 0.07126106321811676, Final Batch Loss: 0.023914938792586327\n",
      "Epoch 331, Loss: 0.1367662362754345, Final Batch Loss: 0.04879237338900566\n",
      "Epoch 332, Loss: 0.12733976542949677, Final Batch Loss: 0.05876144394278526\n",
      "Epoch 333, Loss: 0.10648093186318874, Final Batch Loss: 0.030597729608416557\n",
      "Epoch 334, Loss: 0.07796098291873932, Final Batch Loss: 0.01272634044289589\n",
      "Epoch 335, Loss: 0.1130580510944128, Final Batch Loss: 0.04375740885734558\n",
      "Epoch 336, Loss: 0.10258934274315834, Final Batch Loss: 0.02002544142305851\n",
      "Epoch 337, Loss: 0.1122315376996994, Final Batch Loss: 0.06098457798361778\n",
      "Epoch 338, Loss: 0.10286413878202438, Final Batch Loss: 0.021772298961877823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339, Loss: 0.12507102638483047, Final Batch Loss: 0.019910115748643875\n",
      "Epoch 340, Loss: 0.07847681641578674, Final Batch Loss: 0.013336708769202232\n",
      "Epoch 341, Loss: 0.10658838972449303, Final Batch Loss: 0.014708191156387329\n",
      "Epoch 342, Loss: 0.15185553207993507, Final Batch Loss: 0.08283641934394836\n",
      "Epoch 343, Loss: 0.08011816069483757, Final Batch Loss: 0.019245581701397896\n",
      "Epoch 344, Loss: 0.12524322140961885, Final Batch Loss: 0.040476951748132706\n",
      "Epoch 345, Loss: 0.14335806854069233, Final Batch Loss: 0.07770899683237076\n",
      "Epoch 346, Loss: 0.1516022626310587, Final Batch Loss: 0.1064026728272438\n",
      "Epoch 347, Loss: 0.14036710560321808, Final Batch Loss: 0.05265795812010765\n",
      "Epoch 348, Loss: 0.1244139987975359, Final Batch Loss: 0.05804908275604248\n",
      "Epoch 349, Loss: 0.1442355653271079, Final Batch Loss: 0.0797082856297493\n",
      "Epoch 350, Loss: 0.09420447424054146, Final Batch Loss: 0.03353453055024147\n",
      "Epoch 351, Loss: 0.12120024673640728, Final Batch Loss: 0.06677079945802689\n",
      "Epoch 352, Loss: 0.10998903959989548, Final Batch Loss: 0.036831002682447433\n",
      "Epoch 353, Loss: 0.11952393874526024, Final Batch Loss: 0.02928617224097252\n",
      "Epoch 354, Loss: 0.08704390563070774, Final Batch Loss: 0.01861817203462124\n",
      "Epoch 355, Loss: 0.09770967811346054, Final Batch Loss: 0.017658134922385216\n",
      "Epoch 356, Loss: 0.09673344902694225, Final Batch Loss: 0.042657870799303055\n",
      "Epoch 357, Loss: 0.11808576714247465, Final Batch Loss: 0.011152113787829876\n",
      "Epoch 358, Loss: 0.10762212797999382, Final Batch Loss: 0.04190758243203163\n",
      "Epoch 359, Loss: 0.10263574868440628, Final Batch Loss: 0.02517978474497795\n",
      "Epoch 360, Loss: 0.14145968481898308, Final Batch Loss: 0.020608041435480118\n",
      "Epoch 361, Loss: 0.11686697974801064, Final Batch Loss: 0.016184721142053604\n",
      "Epoch 362, Loss: 0.1271904855966568, Final Batch Loss: 0.02040001004934311\n",
      "Epoch 363, Loss: 0.1050176490098238, Final Batch Loss: 0.039974864572286606\n",
      "Epoch 364, Loss: 0.10253820661455393, Final Batch Loss: 0.014338289387524128\n",
      "Epoch 365, Loss: 0.0978638781234622, Final Batch Loss: 0.011587151326239109\n",
      "Epoch 366, Loss: 0.0820889356546104, Final Batch Loss: 0.007246015127748251\n",
      "Epoch 367, Loss: 0.10185644868761301, Final Batch Loss: 0.01113958191126585\n",
      "Epoch 368, Loss: 0.12662560492753983, Final Batch Loss: 0.049407944083213806\n",
      "Epoch 369, Loss: 0.11008785851299763, Final Batch Loss: 0.06873124837875366\n",
      "Epoch 370, Loss: 0.12163959443569183, Final Batch Loss: 0.07543370872735977\n",
      "Epoch 371, Loss: 0.10553795471787453, Final Batch Loss: 0.03388281911611557\n",
      "Epoch 372, Loss: 0.08970889449119568, Final Batch Loss: 0.031201645731925964\n",
      "Epoch 373, Loss: 0.0836822111159563, Final Batch Loss: 0.018828772008419037\n",
      "Epoch 374, Loss: 0.10972877591848373, Final Batch Loss: 0.0168222077190876\n",
      "Epoch 375, Loss: 0.08934782445430756, Final Batch Loss: 0.03776128590106964\n",
      "Epoch 376, Loss: 0.1030811257660389, Final Batch Loss: 0.03163677081465721\n",
      "Epoch 377, Loss: 0.0845712386071682, Final Batch Loss: 0.02356697991490364\n",
      "Epoch 378, Loss: 0.08138988725841045, Final Batch Loss: 0.02087073028087616\n",
      "Epoch 379, Loss: 0.0872612688690424, Final Batch Loss: 0.007236184552311897\n",
      "Epoch 380, Loss: 0.11725742183625698, Final Batch Loss: 0.06180966645479202\n",
      "Epoch 381, Loss: 0.10796521604061127, Final Batch Loss: 0.03385535627603531\n",
      "Epoch 382, Loss: 0.13910932280123234, Final Batch Loss: 0.06661610305309296\n",
      "Epoch 383, Loss: 0.10187260992825031, Final Batch Loss: 0.05307637155056\n",
      "Epoch 384, Loss: 0.07848775619640946, Final Batch Loss: 0.0060144164599478245\n",
      "Epoch 385, Loss: 0.10255669988691807, Final Batch Loss: 0.06670945137739182\n",
      "Epoch 386, Loss: 0.09107587486505508, Final Batch Loss: 0.041172903031110764\n",
      "Epoch 387, Loss: 0.07654587551951408, Final Batch Loss: 0.022812452167272568\n",
      "Epoch 388, Loss: 0.09571480564773083, Final Batch Loss: 0.013600671663880348\n",
      "Epoch 389, Loss: 0.10889483988285065, Final Batch Loss: 0.040759120136499405\n",
      "Epoch 390, Loss: 0.08741739112883806, Final Batch Loss: 0.011092244647443295\n",
      "Epoch 391, Loss: 0.13976304605603218, Final Batch Loss: 0.07292477041482925\n",
      "Epoch 392, Loss: 0.11718795076012611, Final Batch Loss: 0.04368537291884422\n",
      "Epoch 393, Loss: 0.11630973219871521, Final Batch Loss: 0.0552937276661396\n",
      "Epoch 394, Loss: 0.0843255827203393, Final Batch Loss: 0.013261937536299229\n",
      "Epoch 395, Loss: 0.0791600588709116, Final Batch Loss: 0.032804083079099655\n",
      "Epoch 396, Loss: 0.09274462424218655, Final Batch Loss: 0.023067481815814972\n",
      "Epoch 397, Loss: 0.10738526657223701, Final Batch Loss: 0.028193138539791107\n",
      "Epoch 398, Loss: 0.07655997388064861, Final Batch Loss: 0.025606399402022362\n",
      "Epoch 399, Loss: 0.1439638677984476, Final Batch Loss: 0.06445480138063431\n",
      "Epoch 400, Loss: 0.09899029415100813, Final Batch Loss: 0.05701481178402901\n",
      "Epoch 401, Loss: 0.09423433151096106, Final Batch Loss: 0.012667554430663586\n",
      "Epoch 402, Loss: 0.07135680504143238, Final Batch Loss: 0.0122488122433424\n",
      "Epoch 403, Loss: 0.09455135092139244, Final Batch Loss: 0.014592286199331284\n",
      "Epoch 404, Loss: 0.1132415309548378, Final Batch Loss: 0.06539251655340195\n",
      "Epoch 405, Loss: 0.11218660976737738, Final Batch Loss: 0.05403123423457146\n",
      "Epoch 406, Loss: 0.10335712879896164, Final Batch Loss: 0.0349542573094368\n",
      "Epoch 407, Loss: 0.09390502888709307, Final Batch Loss: 0.016905387863516808\n",
      "Epoch 408, Loss: 0.08133198507130146, Final Batch Loss: 0.025506043806672096\n",
      "Epoch 409, Loss: 0.07017464749515057, Final Batch Loss: 0.017454233020544052\n",
      "Epoch 410, Loss: 0.06218850612640381, Final Batch Loss: 0.01586022600531578\n",
      "Epoch 411, Loss: 0.12310830317437649, Final Batch Loss: 0.05982902646064758\n",
      "Epoch 412, Loss: 0.11794195603579283, Final Batch Loss: 0.012867159210145473\n",
      "Epoch 413, Loss: 0.08239245414733887, Final Batch Loss: 0.011948222294449806\n",
      "Epoch 414, Loss: 0.0981218945235014, Final Batch Loss: 0.016317322850227356\n",
      "Epoch 415, Loss: 0.08088088687509298, Final Batch Loss: 0.008980614133179188\n",
      "Epoch 416, Loss: 0.08359817508608103, Final Batch Loss: 0.009364907629787922\n",
      "Epoch 417, Loss: 0.07091318164020777, Final Batch Loss: 0.006290012039244175\n",
      "Epoch 418, Loss: 0.08597164414823055, Final Batch Loss: 0.023286616429686546\n",
      "Epoch 419, Loss: 0.09126907028257847, Final Batch Loss: 0.030735915526747704\n",
      "Epoch 420, Loss: 0.08394875936210155, Final Batch Loss: 0.016621846705675125\n",
      "Epoch 421, Loss: 0.09702856466174126, Final Batch Loss: 0.042643219232559204\n",
      "Epoch 422, Loss: 0.06501384172588587, Final Batch Loss: 0.0367511510848999\n",
      "Epoch 423, Loss: 0.06713778711855412, Final Batch Loss: 0.006805235520005226\n",
      "Epoch 424, Loss: 0.0676051415503025, Final Batch Loss: 0.018299825489521027\n",
      "Epoch 425, Loss: 0.10203165095299482, Final Batch Loss: 0.07745181769132614\n",
      "Epoch 426, Loss: 0.09149034321308136, Final Batch Loss: 0.030203236266970634\n",
      "Epoch 427, Loss: 0.09108699485659599, Final Batch Loss: 0.027798255905508995\n",
      "Epoch 428, Loss: 0.11216084472835064, Final Batch Loss: 0.05271965637803078\n",
      "Epoch 429, Loss: 0.08263717498630285, Final Batch Loss: 0.015696166083216667\n",
      "Epoch 430, Loss: 0.10565837658941746, Final Batch Loss: 0.037105292081832886\n",
      "Epoch 431, Loss: 0.08643694408237934, Final Batch Loss: 0.04857143387198448\n",
      "Epoch 432, Loss: 0.0671379491686821, Final Batch Loss: 0.030304940417408943\n",
      "Epoch 433, Loss: 0.119778111577034, Final Batch Loss: 0.054744232445955276\n",
      "Epoch 434, Loss: 0.10327290184795856, Final Batch Loss: 0.046720363199710846\n",
      "Epoch 435, Loss: 0.0848852638155222, Final Batch Loss: 0.01597774028778076\n",
      "Epoch 436, Loss: 0.12341330759227276, Final Batch Loss: 0.06898792833089828\n",
      "Epoch 437, Loss: 0.10756893642246723, Final Batch Loss: 0.04295692592859268\n",
      "Epoch 438, Loss: 0.11791460402309895, Final Batch Loss: 0.05779104679822922\n",
      "Epoch 439, Loss: 0.09924995247274637, Final Batch Loss: 0.07050975412130356\n",
      "Epoch 440, Loss: 0.07397021166980267, Final Batch Loss: 0.019358118996024132\n",
      "Epoch 441, Loss: 0.08956688269972801, Final Batch Loss: 0.011683322489261627\n",
      "Epoch 442, Loss: 0.07682785950601101, Final Batch Loss: 0.009768730029463768\n",
      "Epoch 443, Loss: 0.06735708424821496, Final Batch Loss: 0.0058084880001842976\n",
      "Epoch 444, Loss: 0.08148010354489088, Final Batch Loss: 0.02885785885155201\n",
      "Epoch 445, Loss: 0.05946745723485947, Final Batch Loss: 0.014179149642586708\n",
      "Epoch 446, Loss: 0.07650650851428509, Final Batch Loss: 0.013439061120152473\n",
      "Epoch 447, Loss: 0.07075095362961292, Final Batch Loss: 0.021420057862997055\n",
      "Epoch 448, Loss: 0.0653158463537693, Final Batch Loss: 0.012140540406107903\n",
      "Epoch 449, Loss: 0.050319031812250614, Final Batch Loss: 0.005267477594316006\n",
      "Epoch 450, Loss: 0.11363221053034067, Final Batch Loss: 0.06280321627855301\n",
      "Epoch 451, Loss: 0.059577688574790955, Final Batch Loss: 0.02423957735300064\n",
      "Epoch 452, Loss: 0.06458587944507599, Final Batch Loss: 0.008178804069757462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 453, Loss: 0.09411703236401081, Final Batch Loss: 0.02697077952325344\n",
      "Epoch 454, Loss: 0.07861884776502848, Final Batch Loss: 0.009278235025703907\n",
      "Epoch 455, Loss: 0.0821051336824894, Final Batch Loss: 0.015054140239953995\n",
      "Epoch 456, Loss: 0.08794862870126963, Final Batch Loss: 0.009803486056625843\n",
      "Epoch 457, Loss: 0.07733837235718966, Final Batch Loss: 0.030808182433247566\n",
      "Epoch 458, Loss: 0.0805782787501812, Final Batch Loss: 0.027099916711449623\n",
      "Epoch 459, Loss: 0.06489600567147136, Final Batch Loss: 0.004706739913672209\n",
      "Epoch 460, Loss: 0.08211303502321243, Final Batch Loss: 0.04224906116724014\n",
      "Epoch 461, Loss: 0.08703353255987167, Final Batch Loss: 0.034636929631233215\n",
      "Epoch 462, Loss: 0.07503071054816246, Final Batch Loss: 0.016214150935411453\n",
      "Epoch 463, Loss: 0.0987707618623972, Final Batch Loss: 0.04480660706758499\n",
      "Epoch 464, Loss: 0.07401635404676199, Final Batch Loss: 0.012677990831434727\n",
      "Epoch 465, Loss: 0.04896857123821974, Final Batch Loss: 0.00889732874929905\n",
      "Epoch 466, Loss: 0.08242645114660263, Final Batch Loss: 0.021147552877664566\n",
      "Epoch 467, Loss: 0.07376749254763126, Final Batch Loss: 0.019343923777341843\n",
      "Epoch 468, Loss: 0.07841306459158659, Final Batch Loss: 0.02033294551074505\n",
      "Epoch 469, Loss: 0.09884923696517944, Final Batch Loss: 0.04056467115879059\n",
      "Epoch 470, Loss: 0.07812669686973095, Final Batch Loss: 0.05154848098754883\n",
      "Epoch 471, Loss: 0.05158999375998974, Final Batch Loss: 0.013968057930469513\n",
      "Epoch 472, Loss: 0.08811808563768864, Final Batch Loss: 0.037461090832948685\n",
      "Epoch 473, Loss: 0.09783936897292733, Final Batch Loss: 0.06439650803804398\n",
      "Epoch 474, Loss: 0.07740402035415173, Final Batch Loss: 0.009661903604865074\n",
      "Epoch 475, Loss: 0.07871914352290332, Final Batch Loss: 0.003755164099857211\n",
      "Epoch 476, Loss: 0.052891118451952934, Final Batch Loss: 0.008915024809539318\n",
      "Epoch 477, Loss: 0.053413691464811563, Final Batch Loss: 0.007543093059211969\n",
      "Epoch 478, Loss: 0.07764745596796274, Final Batch Loss: 0.04268359765410423\n",
      "Epoch 479, Loss: 0.07760902680456638, Final Batch Loss: 0.04226420074701309\n",
      "Epoch 480, Loss: 0.07563558500260115, Final Batch Loss: 0.014707027934491634\n",
      "Epoch 481, Loss: 0.0712419031187892, Final Batch Loss: 0.004321041516959667\n",
      "Epoch 482, Loss: 0.09978371858596802, Final Batch Loss: 0.06607134640216827\n",
      "Epoch 483, Loss: 0.08231157530099154, Final Batch Loss: 0.029347741976380348\n",
      "Epoch 484, Loss: 0.08339244406670332, Final Batch Loss: 0.006410445086658001\n",
      "Epoch 485, Loss: 0.09231345634907484, Final Batch Loss: 0.0542578250169754\n",
      "Epoch 486, Loss: 0.08785432809963822, Final Batch Loss: 0.060785580426454544\n",
      "Epoch 487, Loss: 0.05817302456125617, Final Batch Loss: 0.004441922064870596\n",
      "Epoch 488, Loss: 0.07253086799755692, Final Batch Loss: 0.007227076683193445\n",
      "Epoch 489, Loss: 0.0786907197907567, Final Batch Loss: 0.05115451663732529\n",
      "Epoch 490, Loss: 0.05627726390957832, Final Batch Loss: 0.01714499294757843\n",
      "Epoch 491, Loss: 0.08615260757505894, Final Batch Loss: 0.03708513453602791\n",
      "Epoch 492, Loss: 0.09739472717046738, Final Batch Loss: 0.047541987150907516\n",
      "Epoch 493, Loss: 0.08862063102424145, Final Batch Loss: 0.016288960352540016\n",
      "Epoch 494, Loss: 0.06605435721576214, Final Batch Loss: 0.02363704703748226\n",
      "Epoch 495, Loss: 0.08550153439864516, Final Batch Loss: 0.005501918029040098\n",
      "Epoch 496, Loss: 0.11743481457233429, Final Batch Loss: 0.04379921779036522\n",
      "Epoch 497, Loss: 0.11709070764482021, Final Batch Loss: 0.05283245071768761\n",
      "Epoch 498, Loss: 0.06746722105890512, Final Batch Loss: 0.021264025941491127\n",
      "Epoch 499, Loss: 0.05766591336578131, Final Batch Loss: 0.012111726216971874\n",
      "Epoch 500, Loss: 0.09020138904452324, Final Batch Loss: 0.024222197011113167\n",
      "Epoch 501, Loss: 0.06748383026570082, Final Batch Loss: 0.029493704438209534\n",
      "Epoch 502, Loss: 0.07123368605971336, Final Batch Loss: 0.013115992769598961\n",
      "Epoch 503, Loss: 0.0719099105335772, Final Batch Loss: 0.03725147992372513\n",
      "Epoch 504, Loss: 0.07353034242987633, Final Batch Loss: 0.0187947116792202\n",
      "Epoch 505, Loss: 0.048545013880357146, Final Batch Loss: 0.003741114167496562\n",
      "Epoch 506, Loss: 0.1082259863615036, Final Batch Loss: 0.07155678421258926\n",
      "Epoch 507, Loss: 0.058938962407410145, Final Batch Loss: 0.015141496434807777\n",
      "Epoch 508, Loss: 0.06608797609806061, Final Batch Loss: 0.015986043959856033\n",
      "Epoch 509, Loss: 0.07515096291899681, Final Batch Loss: 0.014186384156346321\n",
      "Epoch 510, Loss: 0.067783884704113, Final Batch Loss: 0.019749479368329048\n",
      "Epoch 511, Loss: 0.0954264048486948, Final Batch Loss: 0.06560684740543365\n",
      "Epoch 512, Loss: 0.05833536805585027, Final Batch Loss: 0.0058301291428506374\n",
      "Epoch 513, Loss: 0.07183114159852266, Final Batch Loss: 0.011695516295731068\n",
      "Epoch 514, Loss: 0.06197954714298248, Final Batch Loss: 0.01492021419107914\n",
      "Epoch 515, Loss: 0.09227416105568409, Final Batch Loss: 0.02801012434065342\n",
      "Epoch 516, Loss: 0.052020969334989786, Final Batch Loss: 0.0053242589347064495\n",
      "Epoch 517, Loss: 0.06757239624857903, Final Batch Loss: 0.013686686754226685\n",
      "Epoch 518, Loss: 0.0887131686322391, Final Batch Loss: 0.006228627171367407\n",
      "Epoch 519, Loss: 0.10396051965653896, Final Batch Loss: 0.052958156913518906\n",
      "Epoch 520, Loss: 0.06686298735439777, Final Batch Loss: 0.020723050460219383\n",
      "Epoch 521, Loss: 0.0454530012793839, Final Batch Loss: 0.004682423546910286\n",
      "Epoch 522, Loss: 0.06826148089021444, Final Batch Loss: 0.013528379611670971\n",
      "Epoch 523, Loss: 0.0947764590382576, Final Batch Loss: 0.029035938903689384\n",
      "Epoch 524, Loss: 0.08151168935000896, Final Batch Loss: 0.042757488787174225\n",
      "Epoch 525, Loss: 0.08798295725136995, Final Batch Loss: 0.03416546434164047\n",
      "Epoch 526, Loss: 0.0931508606299758, Final Batch Loss: 0.04235026240348816\n",
      "Epoch 527, Loss: 0.09584812261164188, Final Batch Loss: 0.04269789159297943\n",
      "Epoch 528, Loss: 0.07214777357876301, Final Batch Loss: 0.023831019178032875\n",
      "Epoch 529, Loss: 0.056492774514481425, Final Batch Loss: 0.012517577037215233\n",
      "Epoch 530, Loss: 0.07865907158702612, Final Batch Loss: 0.041637443006038666\n",
      "Epoch 531, Loss: 0.0508084436878562, Final Batch Loss: 0.020624659955501556\n",
      "Epoch 532, Loss: 0.055559152737259865, Final Batch Loss: 0.005866670981049538\n",
      "Epoch 533, Loss: 0.08159972541034222, Final Batch Loss: 0.013460475020110607\n",
      "Epoch 534, Loss: 0.0447208690457046, Final Batch Loss: 0.006792552303522825\n",
      "Epoch 535, Loss: 0.057658023200929165, Final Batch Loss: 0.029947619885206223\n",
      "Epoch 536, Loss: 0.048350170254707336, Final Batch Loss: 0.010473744943737984\n",
      "Epoch 537, Loss: 0.05230897665023804, Final Batch Loss: 0.004479535855352879\n",
      "Epoch 538, Loss: 0.05656405072659254, Final Batch Loss: 0.026002252474427223\n",
      "Epoch 539, Loss: 0.04839027766138315, Final Batch Loss: 0.013750775717198849\n",
      "Epoch 540, Loss: 0.05823930399492383, Final Batch Loss: 0.007628952618688345\n",
      "Epoch 541, Loss: 0.0787707595154643, Final Batch Loss: 0.04274613782763481\n",
      "Epoch 542, Loss: 0.08359778672456741, Final Batch Loss: 0.013136660680174828\n",
      "Epoch 543, Loss: 0.0916148703545332, Final Batch Loss: 0.0734160915017128\n",
      "Epoch 544, Loss: 0.08780370466411114, Final Batch Loss: 0.04572166129946709\n",
      "Epoch 545, Loss: 0.07376994006335735, Final Batch Loss: 0.008061656728386879\n",
      "Epoch 546, Loss: 0.06849347613751888, Final Batch Loss: 0.0069206636399030685\n",
      "Epoch 547, Loss: 0.047310223802924156, Final Batch Loss: 0.00852807518094778\n",
      "Epoch 548, Loss: 0.09285865258425474, Final Batch Loss: 0.05809341371059418\n",
      "Epoch 549, Loss: 0.06074260734021664, Final Batch Loss: 0.019647130742669106\n",
      "Epoch 550, Loss: 0.07350805308669806, Final Batch Loss: 0.046488065272569656\n",
      "Epoch 551, Loss: 0.05083560384809971, Final Batch Loss: 0.008448539301753044\n",
      "Epoch 552, Loss: 0.06836441764608026, Final Batch Loss: 0.003661717753857374\n",
      "Epoch 553, Loss: 0.04514368809759617, Final Batch Loss: 0.008968575857579708\n",
      "Epoch 554, Loss: 0.06553738657385111, Final Batch Loss: 0.04120201617479324\n",
      "Epoch 555, Loss: 0.07161126146093011, Final Batch Loss: 0.005594963673502207\n",
      "Epoch 556, Loss: 0.0633118711411953, Final Batch Loss: 0.010450674220919609\n",
      "Epoch 557, Loss: 0.07413177378475666, Final Batch Loss: 0.023346003144979477\n",
      "Epoch 558, Loss: 0.09299260564148426, Final Batch Loss: 0.030810948461294174\n",
      "Epoch 559, Loss: 0.05672483053058386, Final Batch Loss: 0.018324168398976326\n",
      "Epoch 560, Loss: 0.05837402516044676, Final Batch Loss: 0.0032292271498590708\n",
      "Epoch 561, Loss: 0.06921630166471004, Final Batch Loss: 0.04362286254763603\n",
      "Epoch 562, Loss: 0.0637809089384973, Final Batch Loss: 0.005841923411935568\n",
      "Epoch 563, Loss: 0.04621705738827586, Final Batch Loss: 0.00627437187358737\n",
      "Epoch 564, Loss: 0.04192626662552357, Final Batch Loss: 0.012286239303648472\n",
      "Epoch 565, Loss: 0.05492310877889395, Final Batch Loss: 0.027514522895216942\n",
      "Epoch 566, Loss: 0.046666841953992844, Final Batch Loss: 0.005828181281685829\n",
      "Epoch 567, Loss: 0.05048098601400852, Final Batch Loss: 0.010525880381464958\n",
      "Epoch 568, Loss: 0.06334554217755795, Final Batch Loss: 0.00520587433129549\n",
      "Epoch 569, Loss: 0.06341734761372209, Final Batch Loss: 0.007667677942663431\n",
      "Epoch 570, Loss: 0.052598314825445414, Final Batch Loss: 0.006334871985018253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571, Loss: 0.06205115630291402, Final Batch Loss: 0.003509437432512641\n",
      "Epoch 572, Loss: 0.057165298610925674, Final Batch Loss: 0.012721666134893894\n",
      "Epoch 573, Loss: 0.04725164407864213, Final Batch Loss: 0.004663120489567518\n",
      "Epoch 574, Loss: 0.04966484010219574, Final Batch Loss: 0.02153162844479084\n",
      "Epoch 575, Loss: 0.07787551544606686, Final Batch Loss: 0.040095005184412\n",
      "Epoch 576, Loss: 0.050972756929695606, Final Batch Loss: 0.022674420848488808\n",
      "Epoch 577, Loss: 0.06692821905016899, Final Batch Loss: 0.02130342833697796\n",
      "Epoch 578, Loss: 0.05786796938627958, Final Batch Loss: 0.010273781605064869\n",
      "Epoch 579, Loss: 0.0756622264161706, Final Batch Loss: 0.040968749672174454\n",
      "Epoch 580, Loss: 0.04614747874438763, Final Batch Loss: 0.009165025316178799\n",
      "Epoch 581, Loss: 0.0608173287473619, Final Batch Loss: 0.009088996797800064\n",
      "Epoch 582, Loss: 0.06866852007806301, Final Batch Loss: 0.009521761909127235\n",
      "Epoch 583, Loss: 0.05049962364137173, Final Batch Loss: 0.009638570249080658\n",
      "Epoch 584, Loss: 0.0512512531131506, Final Batch Loss: 0.02783624641597271\n",
      "Epoch 585, Loss: 0.06501985155045986, Final Batch Loss: 0.01780209131538868\n",
      "Epoch 586, Loss: 0.05614810902625322, Final Batch Loss: 0.00226689875125885\n",
      "Epoch 587, Loss: 0.03790597664192319, Final Batch Loss: 0.0037157083861529827\n",
      "Epoch 588, Loss: 0.06813331274315715, Final Batch Loss: 0.04313578084111214\n",
      "Epoch 589, Loss: 0.055538018234074116, Final Batch Loss: 0.005902644246816635\n",
      "Epoch 590, Loss: 0.0625638673081994, Final Batch Loss: 0.012940676882863045\n",
      "Epoch 591, Loss: 0.055980585515499115, Final Batch Loss: 0.008650500327348709\n",
      "Epoch 592, Loss: 0.04674911452457309, Final Batch Loss: 0.0054715718142688274\n",
      "Epoch 593, Loss: 0.04992882860824466, Final Batch Loss: 0.005162752699106932\n",
      "Epoch 594, Loss: 0.06803121417760849, Final Batch Loss: 0.03928448259830475\n",
      "Epoch 595, Loss: 0.05609551165252924, Final Batch Loss: 0.013798961415886879\n",
      "Epoch 596, Loss: 0.07379474956542253, Final Batch Loss: 0.04878547415137291\n",
      "Epoch 597, Loss: 0.043988543562591076, Final Batch Loss: 0.008820736780762672\n",
      "Epoch 598, Loss: 0.09028826467692852, Final Batch Loss: 0.0645185112953186\n",
      "Epoch 599, Loss: 0.0714585604146123, Final Batch Loss: 0.039337001740932465\n",
      "Epoch 600, Loss: 0.09706232603639364, Final Batch Loss: 0.05768412724137306\n",
      "Epoch 601, Loss: 0.07838331395760179, Final Batch Loss: 0.054128248244524\n",
      "Epoch 602, Loss: 0.037623350508511066, Final Batch Loss: 0.005589665845036507\n",
      "Epoch 603, Loss: 0.04853296699002385, Final Batch Loss: 0.010743626393377781\n",
      "Epoch 604, Loss: 0.0497616003267467, Final Batch Loss: 0.0058175246231257915\n",
      "Epoch 605, Loss: 0.053573259618133307, Final Batch Loss: 0.012110098265111446\n",
      "Epoch 606, Loss: 0.05595872877165675, Final Batch Loss: 0.004882378038018942\n",
      "Epoch 607, Loss: 0.08526923786848783, Final Batch Loss: 0.03902582451701164\n",
      "Epoch 608, Loss: 0.04201105609536171, Final Batch Loss: 0.013362955302000046\n",
      "Epoch 609, Loss: 0.04866952495649457, Final Batch Loss: 0.0065187872387468815\n",
      "Epoch 610, Loss: 0.06495012808591127, Final Batch Loss: 0.008907741867005825\n",
      "Epoch 611, Loss: 0.06408684700727463, Final Batch Loss: 0.025898072868585587\n",
      "Epoch 612, Loss: 0.04146952461451292, Final Batch Loss: 0.02642856538295746\n",
      "Epoch 613, Loss: 0.07930706068873405, Final Batch Loss: 0.04127892851829529\n",
      "Epoch 614, Loss: 0.05997222475707531, Final Batch Loss: 0.03859388083219528\n",
      "Epoch 615, Loss: 0.043556518852710724, Final Batch Loss: 0.007689367048442364\n",
      "Epoch 616, Loss: 0.12386122904717922, Final Batch Loss: 0.06725937873125076\n",
      "Epoch 617, Loss: 0.061657716520130634, Final Batch Loss: 0.026567569002509117\n",
      "Epoch 618, Loss: 0.06934494525194168, Final Batch Loss: 0.033562369644641876\n",
      "Epoch 619, Loss: 0.059669921174645424, Final Batch Loss: 0.009669525548815727\n",
      "Epoch 620, Loss: 0.06010994268581271, Final Batch Loss: 0.016161037608981133\n",
      "Epoch 621, Loss: 0.039249269757419825, Final Batch Loss: 0.002463501412421465\n",
      "Epoch 622, Loss: 0.04754986148327589, Final Batch Loss: 0.010975481010973454\n",
      "Epoch 623, Loss: 0.04111618269234896, Final Batch Loss: 0.0050254641100764275\n",
      "Epoch 624, Loss: 0.046764493919909, Final Batch Loss: 0.008366690017282963\n",
      "Epoch 625, Loss: 0.06278619263321161, Final Batch Loss: 0.01131614949554205\n",
      "Epoch 626, Loss: 0.04115057643502951, Final Batch Loss: 0.009220433421432972\n",
      "Epoch 627, Loss: 0.07498056953772902, Final Batch Loss: 0.006737345363944769\n",
      "Epoch 628, Loss: 0.07920186873525381, Final Batch Loss: 0.010417294688522816\n",
      "Epoch 629, Loss: 0.06444074120372534, Final Batch Loss: 0.018503138795495033\n",
      "Epoch 630, Loss: 0.07642038725316525, Final Batch Loss: 0.04388917610049248\n",
      "Epoch 631, Loss: 0.04519937187433243, Final Batch Loss: 0.014890146441757679\n",
      "Epoch 632, Loss: 0.10269282897934318, Final Batch Loss: 0.0723399966955185\n",
      "Epoch 633, Loss: 0.0773708550259471, Final Batch Loss: 0.043041396886110306\n",
      "Epoch 634, Loss: 0.04885474080219865, Final Batch Loss: 0.025588123127818108\n",
      "Epoch 635, Loss: 0.05867250356823206, Final Batch Loss: 0.036153703927993774\n",
      "Epoch 636, Loss: 0.067512771114707, Final Batch Loss: 0.015017509460449219\n",
      "Epoch 637, Loss: 0.05233971867710352, Final Batch Loss: 0.00560001190751791\n",
      "Epoch 638, Loss: 0.05374212865717709, Final Batch Loss: 0.003486579516902566\n",
      "Epoch 639, Loss: 0.044383778935298324, Final Batch Loss: 0.002198734087869525\n",
      "Epoch 640, Loss: 0.05877093132585287, Final Batch Loss: 0.03325241431593895\n",
      "Epoch 641, Loss: 0.06571809388697147, Final Batch Loss: 0.02194119431078434\n",
      "Epoch 642, Loss: 0.056481510400772095, Final Batch Loss: 0.027494851499795914\n",
      "Epoch 643, Loss: 0.043867044150829315, Final Batch Loss: 0.005159470252692699\n",
      "Epoch 644, Loss: 0.043922778218984604, Final Batch Loss: 0.008203532546758652\n",
      "Epoch 645, Loss: 0.06337339663878083, Final Batch Loss: 0.04134175926446915\n",
      "Epoch 646, Loss: 0.04296597512438893, Final Batch Loss: 0.002905594650655985\n",
      "Epoch 647, Loss: 0.045964684803038836, Final Batch Loss: 0.009102324023842812\n",
      "Epoch 648, Loss: 0.03697448829188943, Final Batch Loss: 0.0059999944642186165\n",
      "Epoch 649, Loss: 0.049481953494250774, Final Batch Loss: 0.005455498583614826\n",
      "Epoch 650, Loss: 0.04616365907713771, Final Batch Loss: 0.005347564350813627\n",
      "Epoch 651, Loss: 0.03872504085302353, Final Batch Loss: 0.003778293263167143\n",
      "Epoch 652, Loss: 0.05593587039038539, Final Batch Loss: 0.004772366490215063\n",
      "Epoch 653, Loss: 0.051282865926623344, Final Batch Loss: 0.010748665779829025\n",
      "Epoch 654, Loss: 0.06990047544240952, Final Batch Loss: 0.04251471161842346\n",
      "Epoch 655, Loss: 0.035509096924215555, Final Batch Loss: 0.006177982781082392\n",
      "Epoch 656, Loss: 0.0775979533791542, Final Batch Loss: 0.047906484454870224\n",
      "Epoch 657, Loss: 0.042149052023887634, Final Batch Loss: 0.006681729108095169\n",
      "Epoch 658, Loss: 0.05554297333583236, Final Batch Loss: 0.03582264110445976\n",
      "Epoch 659, Loss: 0.05525601655244827, Final Batch Loss: 0.012703932821750641\n",
      "Epoch 660, Loss: 0.05453781969845295, Final Batch Loss: 0.006767144426703453\n",
      "Epoch 661, Loss: 0.046924637630581856, Final Batch Loss: 0.004280764609575272\n",
      "Epoch 662, Loss: 0.07764388574287295, Final Batch Loss: 0.059486743062734604\n",
      "Epoch 663, Loss: 0.04558543115854263, Final Batch Loss: 0.015209626406431198\n",
      "Epoch 664, Loss: 0.041399345733225346, Final Batch Loss: 0.006430973764508963\n",
      "Epoch 665, Loss: 0.040677571669220924, Final Batch Loss: 0.006111683323979378\n",
      "Epoch 666, Loss: 0.05475393030792475, Final Batch Loss: 0.011531956493854523\n",
      "Epoch 667, Loss: 0.057646621484309435, Final Batch Loss: 0.006518720183521509\n",
      "Epoch 668, Loss: 0.046236167661845684, Final Batch Loss: 0.007834935560822487\n",
      "Epoch 669, Loss: 0.038944236701354384, Final Batch Loss: 0.0023858898784965277\n",
      "Epoch 670, Loss: 0.06639639288187027, Final Batch Loss: 0.03157023340463638\n",
      "Epoch 671, Loss: 0.043800441548228264, Final Batch Loss: 0.007000179961323738\n",
      "Epoch 672, Loss: 0.04790903604589403, Final Batch Loss: 0.0038772367406636477\n",
      "Epoch 673, Loss: 0.038860238157212734, Final Batch Loss: 0.007833410985767841\n",
      "Epoch 674, Loss: 0.0698383953422308, Final Batch Loss: 0.02049286663532257\n",
      "Epoch 675, Loss: 0.0599205915350467, Final Batch Loss: 0.0034386564511805773\n",
      "Epoch 676, Loss: 0.0418759360909462, Final Batch Loss: 0.014581386931240559\n",
      "Epoch 677, Loss: 0.04488829057663679, Final Batch Loss: 0.008315431885421276\n",
      "Epoch 678, Loss: 0.05336803989484906, Final Batch Loss: 0.005414730403572321\n",
      "Epoch 679, Loss: 0.040971721056848764, Final Batch Loss: 0.0021921885199844837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 680, Loss: 0.041676882887259126, Final Batch Loss: 0.005447307601571083\n",
      "Epoch 681, Loss: 0.060150884091854095, Final Batch Loss: 0.027557676658034325\n",
      "Epoch 682, Loss: 0.05432946467772126, Final Batch Loss: 0.0074066524393856525\n",
      "Epoch 683, Loss: 0.07684389688074589, Final Batch Loss: 0.0459766648709774\n",
      "Epoch 684, Loss: 0.04783196607604623, Final Batch Loss: 0.008486419916152954\n",
      "Epoch 685, Loss: 0.05903622321784496, Final Batch Loss: 0.022016778588294983\n",
      "Epoch 686, Loss: 0.03585340455174446, Final Batch Loss: 0.011479261331260204\n",
      "Epoch 687, Loss: 0.053640601225197315, Final Batch Loss: 0.010728666558861732\n",
      "Epoch 688, Loss: 0.05716672074049711, Final Batch Loss: 0.02665119059383869\n",
      "Epoch 689, Loss: 0.08217423874884844, Final Batch Loss: 0.04441709816455841\n",
      "Epoch 690, Loss: 0.042983639519661665, Final Batch Loss: 0.009599744342267513\n",
      "Epoch 691, Loss: 0.0439073396846652, Final Batch Loss: 0.0067818015813827515\n",
      "Epoch 692, Loss: 0.061690579168498516, Final Batch Loss: 0.0233493372797966\n",
      "Epoch 693, Loss: 0.042370199924334884, Final Batch Loss: 0.002625931752845645\n",
      "Epoch 694, Loss: 0.055096556432545185, Final Batch Loss: 0.02126295492053032\n",
      "Epoch 695, Loss: 0.0751774050295353, Final Batch Loss: 0.05050066486001015\n",
      "Epoch 696, Loss: 0.05459811957553029, Final Batch Loss: 0.018320633098483086\n",
      "Epoch 697, Loss: 0.033107145922258496, Final Batch Loss: 0.003215891309082508\n",
      "Epoch 698, Loss: 0.06974733155220747, Final Batch Loss: 0.036212388426065445\n",
      "Epoch 699, Loss: 0.058950318954885006, Final Batch Loss: 0.013641933910548687\n",
      "Epoch 700, Loss: 0.047629840206354856, Final Batch Loss: 0.005526173394173384\n",
      "Epoch 701, Loss: 0.07660732138901949, Final Batch Loss: 0.05296877399086952\n",
      "Epoch 702, Loss: 0.08118629455566406, Final Batch Loss: 0.017940513789653778\n",
      "Epoch 703, Loss: 0.04562899377197027, Final Batch Loss: 0.01798713020980358\n",
      "Epoch 704, Loss: 0.042405500542372465, Final Batch Loss: 0.022604798898100853\n",
      "Epoch 705, Loss: 0.06731971353292465, Final Batch Loss: 0.0147317536175251\n",
      "Epoch 706, Loss: 0.05870698764920235, Final Batch Loss: 0.039467643946409225\n",
      "Epoch 707, Loss: 0.055125710321590304, Final Batch Loss: 0.003209706163033843\n",
      "Epoch 708, Loss: 0.06704485882073641, Final Batch Loss: 0.03573235496878624\n",
      "Epoch 709, Loss: 0.06901740841567516, Final Batch Loss: 0.05542938783764839\n",
      "Epoch 710, Loss: 0.0339296106249094, Final Batch Loss: 0.007499772123992443\n",
      "Epoch 711, Loss: 0.0339227938093245, Final Batch Loss: 0.00427983095869422\n",
      "Epoch 712, Loss: 0.05082107614725828, Final Batch Loss: 0.020491356030106544\n",
      "Epoch 713, Loss: 0.06660649320110679, Final Batch Loss: 0.04072555899620056\n",
      "Epoch 714, Loss: 0.03610249096527696, Final Batch Loss: 0.0028699864633381367\n",
      "Epoch 715, Loss: 0.042268795892596245, Final Batch Loss: 0.012091130018234253\n",
      "Epoch 716, Loss: 0.035037760622799397, Final Batch Loss: 0.013974560424685478\n",
      "Epoch 717, Loss: 0.0764902220107615, Final Batch Loss: 0.05538802221417427\n",
      "Epoch 718, Loss: 0.049655233044177294, Final Batch Loss: 0.026078904047608376\n",
      "Epoch 719, Loss: 0.07485739886760712, Final Batch Loss: 0.025986388325691223\n",
      "Epoch 720, Loss: 0.05914757028222084, Final Batch Loss: 0.014565253630280495\n",
      "Epoch 721, Loss: 0.039342548698186874, Final Batch Loss: 0.011441160924732685\n",
      "Epoch 722, Loss: 0.05284636374562979, Final Batch Loss: 0.026396015658974648\n",
      "Epoch 723, Loss: 0.03539960738271475, Final Batch Loss: 0.00507998326793313\n",
      "Epoch 724, Loss: 0.050954241305589676, Final Batch Loss: 0.025972651317715645\n",
      "Epoch 725, Loss: 0.04180281236767769, Final Batch Loss: 0.0143100181594491\n",
      "Epoch 726, Loss: 0.0548387598246336, Final Batch Loss: 0.009060712531208992\n",
      "Epoch 727, Loss: 0.047163688112050295, Final Batch Loss: 0.004339521285146475\n",
      "Epoch 728, Loss: 0.02600744878873229, Final Batch Loss: 0.006106203887611628\n",
      "Epoch 729, Loss: 0.09305344521999359, Final Batch Loss: 0.01923980750143528\n",
      "Epoch 730, Loss: 0.06531186029314995, Final Batch Loss: 0.03097582794725895\n",
      "Epoch 731, Loss: 0.04952573636546731, Final Batch Loss: 0.007434500847011805\n",
      "Epoch 732, Loss: 0.03492617257870734, Final Batch Loss: 0.0030819422099739313\n",
      "Epoch 733, Loss: 0.05544678866863251, Final Batch Loss: 0.02240031585097313\n",
      "Epoch 734, Loss: 0.04292679764330387, Final Batch Loss: 0.005993351340293884\n",
      "Epoch 735, Loss: 0.029357049614191055, Final Batch Loss: 0.008145937696099281\n",
      "Epoch 736, Loss: 0.04673111019656062, Final Batch Loss: 0.005788545589894056\n",
      "Epoch 737, Loss: 0.03647270426154137, Final Batch Loss: 0.005827427841722965\n",
      "Epoch 738, Loss: 0.059909635223448277, Final Batch Loss: 0.027943404391407967\n",
      "Epoch 739, Loss: 0.05338379601016641, Final Batch Loss: 0.006050860974937677\n",
      "Epoch 740, Loss: 0.04402713803574443, Final Batch Loss: 0.008713793009519577\n",
      "Epoch 741, Loss: 0.034603023901581764, Final Batch Loss: 0.008057541213929653\n",
      "Epoch 742, Loss: 0.03615137655287981, Final Batch Loss: 0.0076434011571109295\n",
      "Epoch 743, Loss: 0.03627754305489361, Final Batch Loss: 0.0020637388806790113\n",
      "Epoch 744, Loss: 0.057183653116226196, Final Batch Loss: 0.02289523370563984\n",
      "Epoch 745, Loss: 0.03948468342423439, Final Batch Loss: 0.003972270525991917\n",
      "Epoch 746, Loss: 0.026642026845365763, Final Batch Loss: 0.005948623176664114\n",
      "Epoch 747, Loss: 0.03470863029360771, Final Batch Loss: 0.008081533946096897\n",
      "Epoch 748, Loss: 0.049928073305636644, Final Batch Loss: 0.006294033024460077\n",
      "Epoch 749, Loss: 0.05196119053289294, Final Batch Loss: 0.03008667193353176\n",
      "Epoch 750, Loss: 0.03537682956084609, Final Batch Loss: 0.0068487017415463924\n",
      "Epoch 751, Loss: 0.07200463581830263, Final Batch Loss: 0.006991705857217312\n",
      "Epoch 752, Loss: 0.04297164361923933, Final Batch Loss: 0.004322753753513098\n",
      "Epoch 753, Loss: 0.03385614790022373, Final Batch Loss: 0.0033512902446091175\n",
      "Epoch 754, Loss: 0.063050129218027, Final Batch Loss: 0.05098962038755417\n",
      "Epoch 755, Loss: 0.044127019587904215, Final Batch Loss: 0.006731285247951746\n",
      "Epoch 756, Loss: 0.04587547900155187, Final Batch Loss: 0.0076061938889324665\n",
      "Epoch 757, Loss: 0.03819719050079584, Final Batch Loss: 0.005367750767618418\n",
      "Epoch 758, Loss: 0.034338067285716534, Final Batch Loss: 0.008962678723037243\n",
      "Epoch 759, Loss: 0.06339696468785405, Final Batch Loss: 0.051881782710552216\n",
      "Epoch 760, Loss: 0.05233899224549532, Final Batch Loss: 0.03043377213180065\n",
      "Epoch 761, Loss: 0.04505388950929046, Final Batch Loss: 0.026732537895441055\n",
      "Epoch 762, Loss: 0.042891099117696285, Final Batch Loss: 0.0015383707359433174\n",
      "Epoch 763, Loss: 0.05127602256834507, Final Batch Loss: 0.007850784808397293\n",
      "Epoch 764, Loss: 0.038029735907912254, Final Batch Loss: 0.007052483968436718\n",
      "Epoch 765, Loss: 0.04519618162885308, Final Batch Loss: 0.003981307614594698\n",
      "Epoch 766, Loss: 0.03686093911528587, Final Batch Loss: 0.011791552416980267\n",
      "Epoch 767, Loss: 0.0392405167222023, Final Batch Loss: 0.005606880411505699\n",
      "Epoch 768, Loss: 0.039120602421462536, Final Batch Loss: 0.007914965972304344\n",
      "Epoch 769, Loss: 0.05160782067105174, Final Batch Loss: 0.029878655448555946\n",
      "Epoch 770, Loss: 0.04784490307793021, Final Batch Loss: 0.03183295577764511\n",
      "Epoch 771, Loss: 0.0308256761636585, Final Batch Loss: 0.0025670023169368505\n",
      "Epoch 772, Loss: 0.052097891457378864, Final Batch Loss: 0.024421213194727898\n",
      "Epoch 773, Loss: 0.028341794502921402, Final Batch Loss: 0.0015391624765470624\n",
      "Epoch 774, Loss: 0.05450332071632147, Final Batch Loss: 0.03915632516145706\n",
      "Epoch 775, Loss: 0.1119781790766865, Final Batch Loss: 0.07480921596288681\n",
      "Epoch 776, Loss: 0.11335105076432228, Final Batch Loss: 0.07857563346624374\n",
      "Epoch 777, Loss: 0.053753938525915146, Final Batch Loss: 0.026396751403808594\n",
      "Epoch 778, Loss: 0.058076564222574234, Final Batch Loss: 0.015899015590548515\n",
      "Epoch 779, Loss: 0.04225424071773887, Final Batch Loss: 0.007348834071308374\n",
      "Epoch 780, Loss: 0.029625747352838516, Final Batch Loss: 0.0030212122946977615\n",
      "Epoch 781, Loss: 0.057397112250328064, Final Batch Loss: 0.028544340282678604\n",
      "Epoch 782, Loss: 0.039816200733184814, Final Batch Loss: 0.018514614552259445\n",
      "Epoch 783, Loss: 0.04734681220725179, Final Batch Loss: 0.005922209937125444\n",
      "Epoch 784, Loss: 0.058848896995186806, Final Batch Loss: 0.016121601685881615\n",
      "Epoch 785, Loss: 0.04770777840167284, Final Batch Loss: 0.007178450934588909\n",
      "Epoch 786, Loss: 0.0380914406850934, Final Batch Loss: 0.00788163486868143\n",
      "Epoch 787, Loss: 0.07397858193144202, Final Batch Loss: 0.049769021570682526\n",
      "Epoch 788, Loss: 0.03343916544690728, Final Batch Loss: 0.005271037574857473\n",
      "Epoch 789, Loss: 0.04949687235057354, Final Batch Loss: 0.011496910825371742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 790, Loss: 0.056135928723961115, Final Batch Loss: 0.027016334235668182\n",
      "Epoch 791, Loss: 0.037148776929825544, Final Batch Loss: 0.007028766442090273\n",
      "Epoch 792, Loss: 0.04941973788663745, Final Batch Loss: 0.037907715886831284\n",
      "Epoch 793, Loss: 0.03934152889996767, Final Batch Loss: 0.009203378111124039\n",
      "Epoch 794, Loss: 0.035156446509063244, Final Batch Loss: 0.007451192941516638\n",
      "Epoch 795, Loss: 0.039370373357087374, Final Batch Loss: 0.005023144651204348\n",
      "Epoch 796, Loss: 0.031175096286460757, Final Batch Loss: 0.0027064948808401823\n",
      "Epoch 797, Loss: 0.07927225017920136, Final Batch Loss: 0.03315015509724617\n",
      "Epoch 798, Loss: 0.03635220695286989, Final Batch Loss: 0.004920239560306072\n",
      "Epoch 799, Loss: 0.05971898138523102, Final Batch Loss: 0.03586842119693756\n",
      "Epoch 800, Loss: 0.04521173099055886, Final Batch Loss: 0.0051842802204191685\n",
      "Epoch 801, Loss: 0.048478849697858095, Final Batch Loss: 0.0049514141865074635\n",
      "Epoch 802, Loss: 0.05191411729902029, Final Batch Loss: 0.02141983062028885\n",
      "Epoch 803, Loss: 0.08111586607992649, Final Batch Loss: 0.061646051704883575\n",
      "Epoch 804, Loss: 0.06015934003517032, Final Batch Loss: 0.03821184113621712\n",
      "Epoch 805, Loss: 0.03676503337919712, Final Batch Loss: 0.016613906249403954\n",
      "Epoch 806, Loss: 0.038989125518128276, Final Batch Loss: 0.005674948450177908\n",
      "Epoch 807, Loss: 0.04920387174934149, Final Batch Loss: 0.01916533336043358\n",
      "Epoch 808, Loss: 0.0340802064165473, Final Batch Loss: 0.01454426534473896\n",
      "Epoch 809, Loss: 0.03562627057544887, Final Batch Loss: 0.0035982041154056787\n",
      "Epoch 810, Loss: 0.03221803903579712, Final Batch Loss: 0.00875707995146513\n",
      "Epoch 811, Loss: 0.038827970158308744, Final Batch Loss: 0.027640722692012787\n",
      "Epoch 812, Loss: 0.04469250421971083, Final Batch Loss: 0.020190313458442688\n",
      "Epoch 813, Loss: 0.045621189288794994, Final Batch Loss: 0.026422040536999702\n",
      "Epoch 814, Loss: 0.042336718644946814, Final Batch Loss: 0.0065255179069936275\n",
      "Epoch 815, Loss: 0.024171022698283195, Final Batch Loss: 0.007455974817276001\n",
      "Epoch 816, Loss: 0.0409126803278923, Final Batch Loss: 0.008094092831015587\n",
      "Epoch 817, Loss: 0.05468885134905577, Final Batch Loss: 0.026122955605387688\n",
      "Epoch 818, Loss: 0.05161690339446068, Final Batch Loss: 0.024583391845226288\n",
      "Epoch 819, Loss: 0.025833467952907085, Final Batch Loss: 0.009035333059728146\n",
      "Epoch 820, Loss: 0.037853218615055084, Final Batch Loss: 0.006219957023859024\n",
      "Epoch 821, Loss: 0.03704824158921838, Final Batch Loss: 0.015393547713756561\n",
      "Epoch 822, Loss: 0.04537091497331858, Final Batch Loss: 0.00608026422560215\n",
      "Epoch 823, Loss: 0.032631937647238374, Final Batch Loss: 0.00235141278244555\n",
      "Epoch 824, Loss: 0.03906385833397508, Final Batch Loss: 0.024723220616579056\n",
      "Epoch 825, Loss: 0.04343369556590915, Final Batch Loss: 0.005648850928992033\n",
      "Epoch 826, Loss: 0.028744535986334085, Final Batch Loss: 0.0056503512896597385\n",
      "Epoch 827, Loss: 0.02865626523271203, Final Batch Loss: 0.0025085662491619587\n",
      "Epoch 828, Loss: 0.0700336480513215, Final Batch Loss: 0.011601435951888561\n",
      "Epoch 829, Loss: 0.04787620739080012, Final Batch Loss: 0.025555560365319252\n",
      "Epoch 830, Loss: 0.04908206406980753, Final Batch Loss: 0.0056813983246684074\n",
      "Epoch 831, Loss: 0.03752678772434592, Final Batch Loss: 0.007712567690759897\n",
      "Epoch 832, Loss: 0.04008374293334782, Final Batch Loss: 0.010452439077198505\n",
      "Epoch 833, Loss: 0.03422213392332196, Final Batch Loss: 0.004730415064841509\n",
      "Epoch 834, Loss: 0.0325101928319782, Final Batch Loss: 0.0018375569488853216\n",
      "Epoch 835, Loss: 0.04777963925153017, Final Batch Loss: 0.015522195026278496\n",
      "Epoch 836, Loss: 0.03780786332208663, Final Batch Loss: 0.0013351786183193326\n",
      "Epoch 837, Loss: 0.022017646115273237, Final Batch Loss: 0.0014140796847641468\n",
      "Epoch 838, Loss: 0.05386159010231495, Final Batch Loss: 0.026142382994294167\n",
      "Epoch 839, Loss: 0.05939714144915342, Final Batch Loss: 0.047251589596271515\n",
      "Epoch 840, Loss: 0.03410317609086633, Final Batch Loss: 0.01827349327504635\n",
      "Epoch 841, Loss: 0.04327287897467613, Final Batch Loss: 0.017543641850352287\n",
      "Epoch 842, Loss: 0.05438361503183842, Final Batch Loss: 0.00978967547416687\n",
      "Epoch 843, Loss: 0.028780484572052956, Final Batch Loss: 0.001972599420696497\n",
      "Epoch 844, Loss: 0.04118186701089144, Final Batch Loss: 0.0011184224858880043\n",
      "Epoch 845, Loss: 0.04996679676696658, Final Batch Loss: 0.02221810817718506\n",
      "Epoch 846, Loss: 0.03853895142674446, Final Batch Loss: 0.010855200700461864\n",
      "Epoch 847, Loss: 0.02313506370410323, Final Batch Loss: 0.005432691890746355\n",
      "Epoch 848, Loss: 0.026382928364910185, Final Batch Loss: 0.00134689558763057\n",
      "Epoch 849, Loss: 0.034614276606589556, Final Batch Loss: 0.00754356337711215\n",
      "Epoch 850, Loss: 0.03125952556729317, Final Batch Loss: 0.014810067601501942\n",
      "Epoch 851, Loss: 0.04306196141988039, Final Batch Loss: 0.019343217834830284\n",
      "Epoch 852, Loss: 0.03284912067465484, Final Batch Loss: 0.005285629071295261\n",
      "Epoch 853, Loss: 0.044373602606356144, Final Batch Loss: 0.006656424142420292\n",
      "Epoch 854, Loss: 0.04036495462059975, Final Batch Loss: 0.007282281760126352\n",
      "Epoch 855, Loss: 0.044118390418589115, Final Batch Loss: 0.008612045086920261\n",
      "Epoch 856, Loss: 0.04456751514226198, Final Batch Loss: 0.009924654848873615\n",
      "Epoch 857, Loss: 0.03204041882418096, Final Batch Loss: 0.0038205774035304785\n",
      "Epoch 858, Loss: 0.04682642547413707, Final Batch Loss: 0.01255421619862318\n",
      "Epoch 859, Loss: 0.024240276543423533, Final Batch Loss: 0.001408618874847889\n",
      "Epoch 860, Loss: 0.043836365919560194, Final Batch Loss: 0.016535963863134384\n",
      "Epoch 861, Loss: 0.02635305980220437, Final Batch Loss: 0.004501353017985821\n",
      "Epoch 862, Loss: 0.04115104954689741, Final Batch Loss: 0.01842113584280014\n",
      "Epoch 863, Loss: 0.045735932886600494, Final Batch Loss: 0.033443693071603775\n",
      "Epoch 864, Loss: 0.07791100651957095, Final Batch Loss: 0.06928062438964844\n",
      "Epoch 865, Loss: 0.03750761318951845, Final Batch Loss: 0.01421425212174654\n",
      "Epoch 866, Loss: 0.05290094576776028, Final Batch Loss: 0.03588951751589775\n",
      "Epoch 867, Loss: 0.03193395212292671, Final Batch Loss: 0.010047698393464088\n",
      "Epoch 868, Loss: 0.03193258959800005, Final Batch Loss: 0.002928336150944233\n",
      "Epoch 869, Loss: 0.035510586109012365, Final Batch Loss: 0.018999246880412102\n",
      "Epoch 870, Loss: 0.03026983980089426, Final Batch Loss: 0.015062465332448483\n",
      "Epoch 871, Loss: 0.0350360325537622, Final Batch Loss: 0.002427802886813879\n",
      "Epoch 872, Loss: 0.03770436882041395, Final Batch Loss: 0.009218953549861908\n",
      "Epoch 873, Loss: 0.04854905977845192, Final Batch Loss: 0.020091049373149872\n",
      "Epoch 874, Loss: 0.05161274038255215, Final Batch Loss: 0.04098526015877724\n",
      "Epoch 875, Loss: 0.040594700956717134, Final Batch Loss: 0.0032173132058233023\n",
      "Epoch 876, Loss: 0.04047649493440986, Final Batch Loss: 0.019652843475341797\n",
      "Epoch 877, Loss: 0.07998035755008459, Final Batch Loss: 0.05273670703172684\n",
      "Epoch 878, Loss: 0.0295891254208982, Final Batch Loss: 0.00453164940699935\n",
      "Epoch 879, Loss: 0.03441111650317907, Final Batch Loss: 0.005326711572706699\n",
      "Epoch 880, Loss: 0.027333782520145178, Final Batch Loss: 0.011975022964179516\n",
      "Epoch 881, Loss: 0.050058797001838684, Final Batch Loss: 0.011270763352513313\n",
      "Epoch 882, Loss: 0.03306631720624864, Final Batch Loss: 0.011040099896490574\n",
      "Epoch 883, Loss: 0.04007390467450023, Final Batch Loss: 0.021687354892492294\n",
      "Epoch 884, Loss: 0.027537522837519646, Final Batch Loss: 0.008850308135151863\n",
      "Epoch 885, Loss: 0.023260285379365087, Final Batch Loss: 0.0023104234132915735\n",
      "Epoch 886, Loss: 0.026309218956157565, Final Batch Loss: 0.002430301858112216\n",
      "Epoch 887, Loss: 0.026899666991084814, Final Batch Loss: 0.004107409156858921\n",
      "Epoch 888, Loss: 0.055847514886409044, Final Batch Loss: 0.034216027706861496\n",
      "Epoch 889, Loss: 0.04761027172207832, Final Batch Loss: 0.032663363963365555\n",
      "Epoch 890, Loss: 0.038291752338409424, Final Batch Loss: 0.0030805806163698435\n",
      "Epoch 891, Loss: 0.027469178196042776, Final Batch Loss: 0.004365245811641216\n",
      "Epoch 892, Loss: 0.04491929989308119, Final Batch Loss: 0.0278452280908823\n",
      "Epoch 893, Loss: 0.03557999851182103, Final Batch Loss: 0.022751668468117714\n",
      "Epoch 894, Loss: 0.02550553425680846, Final Batch Loss: 0.0018288110150024295\n",
      "Epoch 895, Loss: 0.048148931469768286, Final Batch Loss: 0.03240437060594559\n",
      "Epoch 896, Loss: 0.030832186806946993, Final Batch Loss: 0.019696401432156563\n",
      "Epoch 897, Loss: 0.038421450881287456, Final Batch Loss: 0.01748649962246418\n",
      "Epoch 898, Loss: 0.02477957191877067, Final Batch Loss: 0.0062248799949884415\n",
      "Epoch 899, Loss: 0.05035095755010843, Final Batch Loss: 0.03228745982050896\n",
      "Epoch 900, Loss: 0.0331578878685832, Final Batch Loss: 0.009114257991313934\n",
      "Epoch 901, Loss: 0.046531648840755224, Final Batch Loss: 0.005734555888921022\n",
      "Epoch 902, Loss: 0.030930031556636095, Final Batch Loss: 0.006144279148429632\n",
      "Epoch 903, Loss: 0.02276337845250964, Final Batch Loss: 0.003892496693879366\n",
      "Epoch 904, Loss: 0.02658443886321038, Final Batch Loss: 0.00472277170047164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 905, Loss: 0.02533346286509186, Final Batch Loss: 0.00179449247661978\n",
      "Epoch 906, Loss: 0.03180993814021349, Final Batch Loss: 0.01576361432671547\n",
      "Epoch 907, Loss: 0.02769830951001495, Final Batch Loss: 0.01080361008644104\n",
      "Epoch 908, Loss: 0.027808393817394972, Final Batch Loss: 0.011378679424524307\n",
      "Epoch 909, Loss: 0.029005393502302468, Final Batch Loss: 0.01942848041653633\n",
      "Epoch 910, Loss: 0.03540905611589551, Final Batch Loss: 0.01962900720536709\n",
      "Epoch 911, Loss: 0.030485147144645452, Final Batch Loss: 0.0014623613096773624\n",
      "Epoch 912, Loss: 0.023107113898731768, Final Batch Loss: 0.0016748668858781457\n",
      "Epoch 913, Loss: 0.021851631812751293, Final Batch Loss: 0.008670599199831486\n",
      "Epoch 914, Loss: 0.05597346927970648, Final Batch Loss: 0.024044344201683998\n",
      "Epoch 915, Loss: 0.02683293237350881, Final Batch Loss: 0.0023410662543028593\n",
      "Epoch 916, Loss: 0.034164504148066044, Final Batch Loss: 0.025734610855579376\n",
      "Epoch 917, Loss: 0.03371845651417971, Final Batch Loss: 0.008743167854845524\n",
      "Epoch 918, Loss: 0.03126805182546377, Final Batch Loss: 0.006012429017573595\n",
      "Epoch 919, Loss: 0.0340377944521606, Final Batch Loss: 0.01688103750348091\n",
      "Epoch 920, Loss: 0.01919683488085866, Final Batch Loss: 0.0032239053398370743\n",
      "Epoch 921, Loss: 0.022646332858130336, Final Batch Loss: 0.0031146917026489973\n",
      "Epoch 922, Loss: 0.035817356780171394, Final Batch Loss: 0.013722503557801247\n",
      "Epoch 923, Loss: 0.025808546226471663, Final Batch Loss: 0.006374973338097334\n",
      "Epoch 924, Loss: 0.017962346057174727, Final Batch Loss: 0.00046649269643239677\n",
      "Epoch 925, Loss: 0.017915149335749447, Final Batch Loss: 0.0011030967580154538\n",
      "Epoch 926, Loss: 0.013951317756436765, Final Batch Loss: 0.006359390448778868\n",
      "Epoch 927, Loss: 0.040259476052597165, Final Batch Loss: 0.01483176089823246\n",
      "Epoch 928, Loss: 0.04149209661409259, Final Batch Loss: 0.028830666095018387\n",
      "Epoch 929, Loss: 0.04306969977915287, Final Batch Loss: 0.01545178983360529\n",
      "Epoch 930, Loss: 0.017022889107465744, Final Batch Loss: 0.006899524014443159\n",
      "Epoch 931, Loss: 0.04998241178691387, Final Batch Loss: 0.026094146072864532\n",
      "Epoch 932, Loss: 0.029916161205619574, Final Batch Loss: 0.020240185782313347\n",
      "Epoch 933, Loss: 0.024439168395474553, Final Batch Loss: 0.013290232047438622\n",
      "Epoch 934, Loss: 0.02791678113862872, Final Batch Loss: 0.005937266629189253\n",
      "Epoch 935, Loss: 0.024773293174803257, Final Batch Loss: 0.006366286426782608\n",
      "Epoch 936, Loss: 0.02117252629250288, Final Batch Loss: 0.0073471409268677235\n",
      "Epoch 937, Loss: 0.05527139641344547, Final Batch Loss: 0.03281351923942566\n",
      "Epoch 938, Loss: 0.022531484719365835, Final Batch Loss: 0.009195075370371342\n",
      "Epoch 939, Loss: 0.02738024853169918, Final Batch Loss: 0.002232082188129425\n",
      "Epoch 940, Loss: 0.02655948046594858, Final Batch Loss: 0.004141760058701038\n",
      "Epoch 941, Loss: 0.026361478259786963, Final Batch Loss: 0.004041879903525114\n",
      "Epoch 942, Loss: 0.020299366209656, Final Batch Loss: 0.001159917563199997\n",
      "Epoch 943, Loss: 0.027187349274754524, Final Batch Loss: 0.0025006430223584175\n",
      "Epoch 944, Loss: 0.017124763457104564, Final Batch Loss: 0.00139764160849154\n",
      "Epoch 945, Loss: 0.04550901986658573, Final Batch Loss: 0.005540379323065281\n",
      "Epoch 946, Loss: 0.03687399532645941, Final Batch Loss: 0.00747188413515687\n",
      "Epoch 947, Loss: 0.03183944150805473, Final Batch Loss: 0.014846449717879295\n",
      "Epoch 948, Loss: 0.035519985016435385, Final Batch Loss: 0.006161459255963564\n",
      "Epoch 949, Loss: 0.014915496809408069, Final Batch Loss: 0.0037437404971569777\n",
      "Epoch 950, Loss: 0.02435501106083393, Final Batch Loss: 0.0072151776403188705\n",
      "Epoch 951, Loss: 0.019965290324762464, Final Batch Loss: 0.0009533704724162817\n",
      "Epoch 952, Loss: 0.037058004178106785, Final Batch Loss: 0.02818952687084675\n",
      "Epoch 953, Loss: 0.025235523004084826, Final Batch Loss: 0.00578837376087904\n",
      "Epoch 954, Loss: 0.052608050405979156, Final Batch Loss: 0.02256774716079235\n",
      "Epoch 955, Loss: 0.0161511872720439, Final Batch Loss: 0.0004616603546310216\n",
      "Epoch 956, Loss: 0.037034603068605065, Final Batch Loss: 0.02047351561486721\n",
      "Epoch 957, Loss: 0.01960446545854211, Final Batch Loss: 0.004392043687403202\n",
      "Epoch 958, Loss: 0.032952690962702036, Final Batch Loss: 0.0027776407077908516\n",
      "Epoch 959, Loss: 0.020631450810469687, Final Batch Loss: 0.0017000621883198619\n",
      "Epoch 960, Loss: 0.016138689941726625, Final Batch Loss: 0.00740297744050622\n",
      "Epoch 961, Loss: 0.03733167890459299, Final Batch Loss: 0.014325682073831558\n",
      "Epoch 962, Loss: 0.020367685705423355, Final Batch Loss: 0.00743950204923749\n",
      "Epoch 963, Loss: 0.016675719525665045, Final Batch Loss: 0.008851256221532822\n",
      "Epoch 964, Loss: 0.020554193761199713, Final Batch Loss: 0.004029959440231323\n",
      "Epoch 965, Loss: 0.015686069848015904, Final Batch Loss: 0.0019984778482466936\n",
      "Epoch 966, Loss: 0.02623435214627534, Final Batch Loss: 0.015330438502132893\n",
      "Epoch 967, Loss: 0.034709676168859005, Final Batch Loss: 0.014364211820065975\n",
      "Epoch 968, Loss: 0.019727970473468304, Final Batch Loss: 0.001796375960111618\n",
      "Epoch 969, Loss: 0.030543426983058453, Final Batch Loss: 0.002195080742239952\n",
      "Epoch 970, Loss: 0.01331345597282052, Final Batch Loss: 0.006972412578761578\n",
      "Epoch 971, Loss: 0.020232532173395157, Final Batch Loss: 0.008147337473928928\n",
      "Epoch 972, Loss: 0.04047874640673399, Final Batch Loss: 0.027732254937291145\n",
      "Epoch 973, Loss: 0.014891112223267555, Final Batch Loss: 0.004969878122210503\n",
      "Epoch 974, Loss: 0.01956498925574124, Final Batch Loss: 0.003554236376658082\n",
      "Epoch 975, Loss: 0.01658478449098766, Final Batch Loss: 0.007763680070638657\n",
      "Epoch 976, Loss: 0.032052568858489394, Final Batch Loss: 0.02611337974667549\n",
      "Epoch 977, Loss: 0.012406752211973071, Final Batch Loss: 0.0029435628093779087\n",
      "Epoch 978, Loss: 0.03522838884964585, Final Batch Loss: 0.002418720629066229\n",
      "Epoch 979, Loss: 0.014964898815378547, Final Batch Loss: 0.006652886979281902\n",
      "Epoch 980, Loss: 0.02784363436512649, Final Batch Loss: 0.002075872151181102\n",
      "Epoch 981, Loss: 0.038572131190449, Final Batch Loss: 0.02644438110291958\n",
      "Epoch 982, Loss: 0.01712061103899032, Final Batch Loss: 0.0017934871139004827\n",
      "Epoch 983, Loss: 0.11398320505395532, Final Batch Loss: 0.1016388013958931\n",
      "Epoch 984, Loss: 0.015363537590019405, Final Batch Loss: 0.000560563406907022\n",
      "Epoch 985, Loss: 0.02210875926539302, Final Batch Loss: 0.0046264659613370895\n",
      "Epoch 986, Loss: 0.025038094841875136, Final Batch Loss: 0.001422567875124514\n",
      "Epoch 987, Loss: 0.06491173384711146, Final Batch Loss: 0.02397644892334938\n",
      "Epoch 988, Loss: 0.021154702175408602, Final Batch Loss: 0.001098940847441554\n",
      "Epoch 989, Loss: 0.015592953423038125, Final Batch Loss: 0.0024707340635359287\n",
      "Epoch 990, Loss: 0.03103746986016631, Final Batch Loss: 0.0010729064233601093\n",
      "Epoch 991, Loss: 0.019249282544478774, Final Batch Loss: 0.011391432024538517\n",
      "Epoch 992, Loss: 0.022387034725397825, Final Batch Loss: 0.0056965649127960205\n",
      "Epoch 993, Loss: 0.026866392232477665, Final Batch Loss: 0.015437121503055096\n",
      "Epoch 994, Loss: 0.026567547116428614, Final Batch Loss: 0.0051160226576030254\n",
      "Epoch 995, Loss: 0.02210997650399804, Final Batch Loss: 0.012344097718596458\n",
      "Epoch 996, Loss: 0.012530185747891665, Final Batch Loss: 0.0015913230599835515\n",
      "Epoch 997, Loss: 0.03001850377768278, Final Batch Loss: 0.013159730471670628\n",
      "Epoch 998, Loss: 0.01455902960151434, Final Batch Loss: 0.0072989193722605705\n",
      "Epoch 999, Loss: 0.026898814481683075, Final Batch Loss: 0.009030063636600971\n",
      "Epoch 1000, Loss: 0.01318771461956203, Final Batch Loss: 0.0027080338913947344\n",
      "Epoch 1001, Loss: 0.024481148197082803, Final Batch Loss: 0.0004096596676390618\n",
      "Epoch 1002, Loss: 0.012478683842346072, Final Batch Loss: 0.001088630873709917\n",
      "Epoch 1003, Loss: 0.02211827621795237, Final Batch Loss: 0.014140013605356216\n",
      "Epoch 1004, Loss: 0.036863554269075394, Final Batch Loss: 0.03263123333454132\n",
      "Epoch 1005, Loss: 0.043332253117114305, Final Batch Loss: 0.034394994378089905\n",
      "Epoch 1006, Loss: 0.01653772301506251, Final Batch Loss: 0.0009299473604187369\n",
      "Epoch 1007, Loss: 0.025161907076835632, Final Batch Loss: 0.0049895355477929115\n",
      "Epoch 1008, Loss: 0.03150520188501105, Final Batch Loss: 0.0008439015946350992\n",
      "Epoch 1009, Loss: 0.05231677042320371, Final Batch Loss: 0.0006814789958298206\n",
      "Epoch 1010, Loss: 0.013184328330680728, Final Batch Loss: 0.002715202048420906\n",
      "Epoch 1011, Loss: 0.015605277381837368, Final Batch Loss: 0.003812492126598954\n",
      "Epoch 1012, Loss: 0.014685078407637775, Final Batch Loss: 0.001271729706786573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1013, Loss: 0.02523139724507928, Final Batch Loss: 0.013526600785553455\n",
      "Epoch 1014, Loss: 0.025347725371830165, Final Batch Loss: 0.009546734392642975\n",
      "Epoch 1015, Loss: 0.03126635996159166, Final Batch Loss: 0.0016987085109576583\n",
      "Epoch 1016, Loss: 0.029627894051373005, Final Batch Loss: 0.008341562002897263\n",
      "Epoch 1017, Loss: 0.008835970424115658, Final Batch Loss: 0.0017610450740903616\n",
      "Epoch 1018, Loss: 0.009003738639876246, Final Batch Loss: 0.0024750027805566788\n",
      "Epoch 1019, Loss: 0.019985494203865528, Final Batch Loss: 0.013195188716053963\n",
      "Epoch 1020, Loss: 0.012129928218200803, Final Batch Loss: 0.0006921605672687292\n",
      "Epoch 1021, Loss: 0.011855823220685124, Final Batch Loss: 0.0005258452147245407\n",
      "Epoch 1022, Loss: 0.044928114977665246, Final Batch Loss: 0.03662882372736931\n",
      "Epoch 1023, Loss: 0.02341413393151015, Final Batch Loss: 0.018655940890312195\n",
      "Epoch 1024, Loss: 0.023454492329619825, Final Batch Loss: 0.015339555218815804\n",
      "Epoch 1025, Loss: 0.01831730268895626, Final Batch Loss: 0.00460605276748538\n",
      "Epoch 1026, Loss: 0.06118347332812846, Final Batch Loss: 0.0020618881098926067\n",
      "Epoch 1027, Loss: 0.017732064705342054, Final Batch Loss: 0.007685796823352575\n",
      "Epoch 1028, Loss: 0.013688585546333343, Final Batch Loss: 0.0007578768418170512\n",
      "Epoch 1029, Loss: 0.01698138061328791, Final Batch Loss: 0.005064711440354586\n",
      "Epoch 1030, Loss: 0.015565031673759222, Final Batch Loss: 0.009388958103954792\n",
      "Epoch 1031, Loss: 0.010393118835054338, Final Batch Loss: 0.003566176164895296\n",
      "Epoch 1032, Loss: 0.011941701639443636, Final Batch Loss: 0.005919868592172861\n",
      "Epoch 1033, Loss: 0.02228985307738185, Final Batch Loss: 0.002781062852591276\n",
      "Epoch 1034, Loss: 0.007031837711110711, Final Batch Loss: 0.0030096671544015408\n",
      "Epoch 1035, Loss: 0.014227064559236169, Final Batch Loss: 0.00184856285341084\n",
      "Epoch 1036, Loss: 0.010246562538668513, Final Batch Loss: 0.002011028351262212\n",
      "Epoch 1037, Loss: 0.007087970618158579, Final Batch Loss: 0.000646126689389348\n",
      "Epoch 1038, Loss: 0.015606559696607292, Final Batch Loss: 0.007942897267639637\n",
      "Epoch 1039, Loss: 0.020686016650870442, Final Batch Loss: 0.013721170835196972\n",
      "Epoch 1040, Loss: 0.012551440391689539, Final Batch Loss: 0.002976570976898074\n",
      "Epoch 1041, Loss: 0.012374535901471972, Final Batch Loss: 0.00305424677208066\n",
      "Epoch 1042, Loss: 0.01196983433328569, Final Batch Loss: 0.0010955099714919925\n",
      "Epoch 1043, Loss: 0.0057562318397685885, Final Batch Loss: 0.002349237911403179\n",
      "Epoch 1044, Loss: 0.009119334863498807, Final Batch Loss: 0.001719167921692133\n",
      "Epoch 1045, Loss: 0.013388119172304869, Final Batch Loss: 0.0046664513647556305\n",
      "Epoch 1046, Loss: 0.01803381205536425, Final Batch Loss: 0.0038923141546547413\n",
      "Epoch 1047, Loss: 0.019469060585834086, Final Batch Loss: 0.005023791920393705\n",
      "Epoch 1048, Loss: 0.025786389829590917, Final Batch Loss: 0.01646072417497635\n",
      "Epoch 1049, Loss: 0.01818601170089096, Final Batch Loss: 0.009031062014400959\n",
      "Epoch 1050, Loss: 0.01795211574062705, Final Batch Loss: 0.005124921444803476\n",
      "Epoch 1051, Loss: 0.01705896225757897, Final Batch Loss: 0.008565753698348999\n",
      "Epoch 1052, Loss: 0.0567927029915154, Final Batch Loss: 0.004794370848685503\n",
      "Epoch 1053, Loss: 0.013409421226242557, Final Batch Loss: 0.0004087075649295002\n",
      "Epoch 1054, Loss: 0.010311992140486836, Final Batch Loss: 0.002108354587107897\n",
      "Epoch 1055, Loss: 0.011958452174440026, Final Batch Loss: 0.002656672615557909\n",
      "Epoch 1056, Loss: 0.012193626491352916, Final Batch Loss: 0.0034791147336363792\n",
      "Epoch 1057, Loss: 0.030733930761925876, Final Batch Loss: 0.0011710774851962924\n",
      "Epoch 1058, Loss: 0.016078609274700284, Final Batch Loss: 0.0014010516460984945\n",
      "Epoch 1059, Loss: 0.014442346524447203, Final Batch Loss: 0.008196134120225906\n",
      "Epoch 1060, Loss: 0.03496508888201788, Final Batch Loss: 0.0004348611109890044\n",
      "Epoch 1061, Loss: 0.017293589655309916, Final Batch Loss: 0.008282111026346684\n",
      "Epoch 1062, Loss: 0.016192555893212557, Final Batch Loss: 0.0021519616711884737\n",
      "Epoch 1063, Loss: 0.012448895489796996, Final Batch Loss: 0.0025361841544508934\n",
      "Epoch 1064, Loss: 0.034250712022185326, Final Batch Loss: 0.003923975396901369\n",
      "Epoch 1065, Loss: 0.0243511984590441, Final Batch Loss: 0.013768099248409271\n",
      "Epoch 1066, Loss: 0.021402593702077866, Final Batch Loss: 0.005740392487496138\n",
      "Epoch 1067, Loss: 0.005370050203055143, Final Batch Loss: 0.001207782537676394\n",
      "Epoch 1068, Loss: 0.026205197791568935, Final Batch Loss: 0.012942124158143997\n",
      "Epoch 1069, Loss: 0.012100232997909188, Final Batch Loss: 0.001244239741936326\n",
      "Epoch 1070, Loss: 0.11616567499004304, Final Batch Loss: 0.11078378558158875\n",
      "Epoch 1071, Loss: 0.018267974257469177, Final Batch Loss: 0.0026162024587392807\n",
      "Epoch 1072, Loss: 0.02087177149951458, Final Batch Loss: 0.000510187353938818\n",
      "Epoch 1073, Loss: 0.01850545994238928, Final Batch Loss: 0.0005761663778685033\n",
      "Epoch 1074, Loss: 0.009843495732638985, Final Batch Loss: 0.0007628792081959546\n",
      "Epoch 1075, Loss: 0.016632759710773826, Final Batch Loss: 0.008337374776601791\n",
      "Epoch 1076, Loss: 0.0810369597747922, Final Batch Loss: 0.0707247331738472\n",
      "Epoch 1077, Loss: 0.005840398604050279, Final Batch Loss: 0.0017091765766963363\n",
      "Epoch 1078, Loss: 0.008113220450468361, Final Batch Loss: 0.0017139514675363898\n",
      "Epoch 1079, Loss: 0.006403447361662984, Final Batch Loss: 0.0027905891183763742\n",
      "Epoch 1080, Loss: 0.01648672655574046, Final Batch Loss: 0.00037110349512659013\n",
      "Epoch 1081, Loss: 0.021878445288166404, Final Batch Loss: 0.0032054136972874403\n",
      "Epoch 1082, Loss: 0.030777886393480003, Final Batch Loss: 0.001240198384039104\n",
      "Epoch 1083, Loss: 0.01648518070578575, Final Batch Loss: 0.005528629291802645\n",
      "Epoch 1084, Loss: 0.012264808639883995, Final Batch Loss: 0.0014685954665765166\n",
      "Epoch 1085, Loss: 0.03392207541037351, Final Batch Loss: 0.0010473342845216393\n",
      "Epoch 1086, Loss: 0.01732392911799252, Final Batch Loss: 0.001530263340100646\n",
      "Epoch 1087, Loss: 0.028613437083549798, Final Batch Loss: 0.000592700089327991\n",
      "Epoch 1088, Loss: 0.01400203735101968, Final Batch Loss: 0.0009773984784260392\n",
      "Epoch 1089, Loss: 0.020048115868121386, Final Batch Loss: 0.007061258424073458\n",
      "Epoch 1090, Loss: 0.008947061374783516, Final Batch Loss: 0.0012874475214630365\n",
      "Epoch 1091, Loss: 0.010307980119250715, Final Batch Loss: 0.001903245341964066\n",
      "Epoch 1092, Loss: 0.015525936672929674, Final Batch Loss: 0.0008894797065295279\n",
      "Epoch 1093, Loss: 0.03865264682099223, Final Batch Loss: 0.001958770677447319\n",
      "Epoch 1094, Loss: 0.014543629251420498, Final Batch Loss: 0.0088182482868433\n",
      "Epoch 1095, Loss: 0.0111113958992064, Final Batch Loss: 0.0023916373029351234\n",
      "Epoch 1096, Loss: 0.003040285431779921, Final Batch Loss: 0.0007203066488727927\n",
      "Epoch 1097, Loss: 0.018646796699613333, Final Batch Loss: 0.007778611499816179\n",
      "Epoch 1098, Loss: 0.01477105263620615, Final Batch Loss: 0.0013647382147610188\n",
      "Epoch 1099, Loss: 0.014189749723300338, Final Batch Loss: 0.0021546438802033663\n",
      "Epoch 1100, Loss: 0.026594474678859115, Final Batch Loss: 0.0027006843592971563\n",
      "Epoch 1101, Loss: 0.010646723443642259, Final Batch Loss: 0.004011691082268953\n",
      "Epoch 1102, Loss: 0.007400581962428987, Final Batch Loss: 0.0008883413393050432\n",
      "Epoch 1103, Loss: 0.005601080600172281, Final Batch Loss: 0.0006356878438964486\n",
      "Epoch 1104, Loss: 0.008268157951533794, Final Batch Loss: 0.0009791599586606026\n",
      "Epoch 1105, Loss: 0.009943575714714825, Final Batch Loss: 0.001334508997388184\n",
      "Epoch 1106, Loss: 0.0149458417436108, Final Batch Loss: 0.001261568977497518\n",
      "Epoch 1107, Loss: 0.017585687106475234, Final Batch Loss: 0.003499095095321536\n",
      "Epoch 1108, Loss: 0.022720647044479847, Final Batch Loss: 0.015205963514745235\n",
      "Epoch 1109, Loss: 0.04071915929671377, Final Batch Loss: 0.03559648245573044\n",
      "Epoch 1110, Loss: 0.019721367862075567, Final Batch Loss: 0.006147067528218031\n",
      "Epoch 1111, Loss: 0.01837770501151681, Final Batch Loss: 0.0011188483331352472\n",
      "Epoch 1112, Loss: 0.010781711083836854, Final Batch Loss: 0.0017365849344059825\n",
      "Epoch 1113, Loss: 0.007033668807707727, Final Batch Loss: 0.0038686757907271385\n",
      "Epoch 1114, Loss: 0.010398638201877475, Final Batch Loss: 0.004627191927284002\n",
      "Epoch 1115, Loss: 0.012479670578613877, Final Batch Loss: 0.0022979017812758684\n",
      "Epoch 1116, Loss: 0.007955914596095681, Final Batch Loss: 0.0011700954055413604\n",
      "Epoch 1117, Loss: 0.014587180805392563, Final Batch Loss: 0.01063384860754013\n",
      "Epoch 1118, Loss: 0.0044131772592663765, Final Batch Loss: 0.0011264360509812832\n",
      "Epoch 1119, Loss: 0.012113248172681779, Final Batch Loss: 0.002960022771731019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1120, Loss: 0.022483534296043217, Final Batch Loss: 0.0010741312289610505\n",
      "Epoch 1121, Loss: 0.00906972005032003, Final Batch Loss: 0.004092862829566002\n",
      "Epoch 1122, Loss: 0.012760394718497992, Final Batch Loss: 0.0027924359310418367\n",
      "Epoch 1123, Loss: 0.007856671116314828, Final Batch Loss: 0.0023259359877556562\n",
      "Epoch 1124, Loss: 0.018434850499033928, Final Batch Loss: 0.002873930847272277\n",
      "Epoch 1125, Loss: 0.00987326237373054, Final Batch Loss: 0.0018376047955825925\n",
      "Epoch 1126, Loss: 0.008843560004606843, Final Batch Loss: 0.0027281465008854866\n",
      "Epoch 1127, Loss: 0.012454446929041296, Final Batch Loss: 0.0007035974995233119\n",
      "Epoch 1128, Loss: 0.010940194712020457, Final Batch Loss: 0.0013315017567947507\n",
      "Epoch 1129, Loss: 0.0032381085475208238, Final Batch Loss: 0.0001291351654799655\n",
      "Epoch 1130, Loss: 0.01358267612522468, Final Batch Loss: 0.0004645562148652971\n",
      "Epoch 1131, Loss: 0.009427534649148583, Final Batch Loss: 0.0010478467447683215\n",
      "Epoch 1132, Loss: 0.009108539670705795, Final Batch Loss: 0.0031776234973222017\n",
      "Epoch 1133, Loss: 0.003863650606945157, Final Batch Loss: 0.0018993811681866646\n",
      "Epoch 1134, Loss: 0.011856777011416852, Final Batch Loss: 0.003409859724342823\n",
      "Epoch 1135, Loss: 0.005711046513170004, Final Batch Loss: 0.0035899863578379154\n",
      "Epoch 1136, Loss: 0.0033781874226406217, Final Batch Loss: 0.0006189786945469677\n",
      "Epoch 1137, Loss: 0.008833113010041416, Final Batch Loss: 0.0017934011993929744\n",
      "Epoch 1138, Loss: 0.017121234792284667, Final Batch Loss: 0.011533859185874462\n",
      "Epoch 1139, Loss: 0.013773153768852353, Final Batch Loss: 0.004326201509684324\n",
      "Epoch 1140, Loss: 0.011342039797455072, Final Batch Loss: 0.007754593621939421\n",
      "Epoch 1141, Loss: 0.006007281306665391, Final Batch Loss: 0.0019268878968432546\n",
      "Epoch 1142, Loss: 0.0323693766258657, Final Batch Loss: 0.002841873560100794\n",
      "Epoch 1143, Loss: 0.026324150268919766, Final Batch Loss: 0.023321483284235\n",
      "Epoch 1144, Loss: 0.020247438456863165, Final Batch Loss: 0.004144603852182627\n",
      "Epoch 1145, Loss: 0.006686196255031973, Final Batch Loss: 0.0009060472366400063\n",
      "Epoch 1146, Loss: 0.03082664485555142, Final Batch Loss: 0.0013345242477953434\n",
      "Epoch 1147, Loss: 0.02640450478065759, Final Batch Loss: 0.0016862472984939814\n",
      "Epoch 1148, Loss: 0.0038344086497090757, Final Batch Loss: 0.0005881477845832705\n",
      "Epoch 1149, Loss: 0.029758930788375437, Final Batch Loss: 0.022811733186244965\n",
      "Epoch 1150, Loss: 0.026166477240622044, Final Batch Loss: 0.0006288136355578899\n",
      "Epoch 1151, Loss: 0.006854702776763588, Final Batch Loss: 0.00037653284380212426\n",
      "Epoch 1152, Loss: 0.010549406288191676, Final Batch Loss: 0.002204870106652379\n",
      "Epoch 1153, Loss: 0.00797269819304347, Final Batch Loss: 0.0026445549447089434\n",
      "Epoch 1154, Loss: 0.015742160845547915, Final Batch Loss: 0.0051735821180045605\n",
      "Epoch 1155, Loss: 0.008627853298094124, Final Batch Loss: 0.0009307688451372087\n",
      "Epoch 1156, Loss: 0.014541764743626118, Final Batch Loss: 0.004762614611536264\n",
      "Epoch 1157, Loss: 0.010353802354075015, Final Batch Loss: 0.0019712024368345737\n",
      "Epoch 1158, Loss: 0.011307884007692337, Final Batch Loss: 0.007320091128349304\n",
      "Epoch 1159, Loss: 0.03213274059817195, Final Batch Loss: 0.023355741053819656\n",
      "Epoch 1160, Loss: 0.02344003552570939, Final Batch Loss: 0.011633218266069889\n",
      "Epoch 1161, Loss: 0.013140514609403908, Final Batch Loss: 0.000596095691435039\n",
      "Epoch 1162, Loss: 0.003527484252117574, Final Batch Loss: 0.000754485372453928\n",
      "Epoch 1163, Loss: 0.0027052599762100726, Final Batch Loss: 0.0002543869486544281\n",
      "Epoch 1164, Loss: 0.018886145669966936, Final Batch Loss: 0.006826649885624647\n",
      "Epoch 1165, Loss: 0.06141700781881809, Final Batch Loss: 0.057644087821245193\n",
      "Epoch 1166, Loss: 0.020915098080877215, Final Batch Loss: 0.0005610273801721632\n",
      "Epoch 1167, Loss: 0.01891532214358449, Final Batch Loss: 0.0035820482298731804\n",
      "Epoch 1168, Loss: 0.01940598979126662, Final Batch Loss: 0.0005052386550232768\n",
      "Epoch 1169, Loss: 0.01589758927002549, Final Batch Loss: 0.009324238635599613\n",
      "Epoch 1170, Loss: 0.02563791477587074, Final Batch Loss: 0.022739233449101448\n",
      "Epoch 1171, Loss: 0.006709383800625801, Final Batch Loss: 0.001027794904075563\n",
      "Epoch 1172, Loss: 0.012102745240554214, Final Batch Loss: 0.007083066273480654\n",
      "Epoch 1173, Loss: 0.0123194286134094, Final Batch Loss: 0.0023365693632513285\n",
      "Epoch 1174, Loss: 0.008746279636397958, Final Batch Loss: 0.00036119413562119007\n",
      "Epoch 1175, Loss: 0.005311663146130741, Final Batch Loss: 0.0006409903289750218\n",
      "Epoch 1176, Loss: 0.009656759939389303, Final Batch Loss: 0.007780882064253092\n",
      "Epoch 1177, Loss: 0.008961349492892623, Final Batch Loss: 0.004597245715558529\n",
      "Epoch 1178, Loss: 0.008097379468381405, Final Batch Loss: 0.005242339335381985\n",
      "Epoch 1179, Loss: 0.01501538057345897, Final Batch Loss: 0.007100318092852831\n",
      "Epoch 1180, Loss: 0.011130748316645622, Final Batch Loss: 0.0038468928541988134\n",
      "Epoch 1181, Loss: 0.009423336130566895, Final Batch Loss: 0.006638718768954277\n",
      "Epoch 1182, Loss: 0.002751097927102819, Final Batch Loss: 0.00042383457184769213\n",
      "Epoch 1183, Loss: 0.0064314305782318115, Final Batch Loss: 0.0010702029103413224\n",
      "Epoch 1184, Loss: 0.0058505552879069, Final Batch Loss: 0.00025702864513732493\n",
      "Epoch 1185, Loss: 0.008183002704754472, Final Batch Loss: 0.003940341528505087\n",
      "Epoch 1186, Loss: 0.007984577328898013, Final Batch Loss: 0.0009158967295661569\n",
      "Epoch 1187, Loss: 0.029160285368561745, Final Batch Loss: 0.00933455303311348\n",
      "Epoch 1188, Loss: 0.007064197678118944, Final Batch Loss: 0.0017539303516969085\n",
      "Epoch 1189, Loss: 0.002619920182041824, Final Batch Loss: 0.0011693299748003483\n",
      "Epoch 1190, Loss: 0.006888620555400848, Final Batch Loss: 0.000784524017944932\n",
      "Epoch 1191, Loss: 0.011288808891549706, Final Batch Loss: 0.0017206778284162283\n",
      "Epoch 1192, Loss: 0.0032484413241036236, Final Batch Loss: 0.0004884513909928501\n",
      "Epoch 1193, Loss: 0.011659698560833931, Final Batch Loss: 0.010361261665821075\n",
      "Epoch 1194, Loss: 0.0053268325282260776, Final Batch Loss: 0.0020357000175863504\n",
      "Epoch 1195, Loss: 0.003607066988479346, Final Batch Loss: 0.00046240922529250383\n",
      "Epoch 1196, Loss: 0.006964808737393469, Final Batch Loss: 0.0026551506016403437\n",
      "Epoch 1197, Loss: 0.0016742431180318817, Final Batch Loss: 0.00020912040781695396\n",
      "Epoch 1198, Loss: 0.0035223487648181617, Final Batch Loss: 0.0006420277641154826\n",
      "Epoch 1199, Loss: 0.009822598891332746, Final Batch Loss: 0.003480719868093729\n",
      "Epoch 1200, Loss: 0.005619816773105413, Final Batch Loss: 0.000371749687474221\n",
      "Epoch 1201, Loss: 0.013809193740598857, Final Batch Loss: 0.011923548765480518\n",
      "Epoch 1202, Loss: 0.013190325815230608, Final Batch Loss: 0.0011162464506924152\n",
      "Epoch 1203, Loss: 0.004204079683404416, Final Batch Loss: 0.0005097264074720442\n",
      "Epoch 1204, Loss: 0.0056014383444562554, Final Batch Loss: 0.0006590367993339896\n",
      "Epoch 1205, Loss: 0.011387466685846448, Final Batch Loss: 0.0031969156116247177\n",
      "Epoch 1206, Loss: 0.005428838194347918, Final Batch Loss: 0.0005288475076667964\n",
      "Epoch 1207, Loss: 0.009359962190501392, Final Batch Loss: 0.0008386977715417743\n",
      "Epoch 1208, Loss: 0.016579904593527317, Final Batch Loss: 0.001599048264324665\n",
      "Epoch 1209, Loss: 0.007390274899080396, Final Batch Loss: 0.0037642528768628836\n",
      "Epoch 1210, Loss: 0.004180314426776022, Final Batch Loss: 0.0019056019373238087\n",
      "Epoch 1211, Loss: 0.02356322284322232, Final Batch Loss: 0.0012256669579073787\n",
      "Epoch 1212, Loss: 0.009122591000050306, Final Batch Loss: 0.0071840668097138405\n",
      "Epoch 1213, Loss: 0.0025931099080480635, Final Batch Loss: 0.0004656134406104684\n",
      "Epoch 1214, Loss: 0.010429058922454715, Final Batch Loss: 0.0006549046374857426\n",
      "Epoch 1215, Loss: 0.002698181793675758, Final Batch Loss: 0.0006228889687918127\n",
      "Epoch 1216, Loss: 0.018910760802100413, Final Batch Loss: 0.00017816996842157096\n",
      "Epoch 1217, Loss: 0.011767491232603788, Final Batch Loss: 0.0009289156878367066\n",
      "Epoch 1218, Loss: 0.013557950034737587, Final Batch Loss: 0.008174060843884945\n",
      "Epoch 1219, Loss: 0.010122815147042274, Final Batch Loss: 0.003058378119021654\n",
      "Epoch 1220, Loss: 0.005243251216597855, Final Batch Loss: 0.0029511749744415283\n",
      "Epoch 1221, Loss: 0.015462395560462028, Final Batch Loss: 0.00044914480531588197\n",
      "Epoch 1222, Loss: 0.013259325292892754, Final Batch Loss: 0.009942206554114819\n",
      "Epoch 1223, Loss: 0.002741142379818484, Final Batch Loss: 0.0004599814710672945\n",
      "Epoch 1224, Loss: 0.011070463544456288, Final Batch Loss: 0.006057867780327797\n",
      "Epoch 1225, Loss: 0.009910548804327846, Final Batch Loss: 0.0010557910427451134\n",
      "Epoch 1226, Loss: 0.0024445048184134066, Final Batch Loss: 0.0004354385891929269\n",
      "Epoch 1227, Loss: 0.0019632120383903384, Final Batch Loss: 0.0002655446878634393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1228, Loss: 0.005567969870753586, Final Batch Loss: 0.0010018349858000875\n",
      "Epoch 1229, Loss: 0.0033466697204858065, Final Batch Loss: 0.0005462317494675517\n",
      "Epoch 1230, Loss: 0.010075307276565582, Final Batch Loss: 0.0005934008513577282\n",
      "Epoch 1231, Loss: 0.0179231574293226, Final Batch Loss: 0.007295343093574047\n",
      "Epoch 1232, Loss: 0.0027595270657911897, Final Batch Loss: 0.0003359817201271653\n",
      "Epoch 1233, Loss: 0.0032079581287689507, Final Batch Loss: 0.001105407951399684\n",
      "Epoch 1234, Loss: 0.002010971657000482, Final Batch Loss: 0.00022000307217240334\n",
      "Epoch 1235, Loss: 0.007108157500624657, Final Batch Loss: 0.004020450636744499\n",
      "Epoch 1236, Loss: 0.001953379818587564, Final Batch Loss: 0.00013128806313034147\n",
      "Epoch 1237, Loss: 0.0064381815027445555, Final Batch Loss: 0.004799988120794296\n",
      "Epoch 1238, Loss: 0.0033452316420152783, Final Batch Loss: 0.0006881922017782927\n",
      "Epoch 1239, Loss: 0.007944649551063776, Final Batch Loss: 0.0015306919813156128\n",
      "Epoch 1240, Loss: 0.016528431908227503, Final Batch Loss: 0.0015796782681718469\n",
      "Epoch 1241, Loss: 0.003365935932379216, Final Batch Loss: 0.001779031939804554\n",
      "Epoch 1242, Loss: 0.0023513773339800537, Final Batch Loss: 0.00046587252290919423\n",
      "Epoch 1243, Loss: 0.006896353035699576, Final Batch Loss: 0.0026384557131677866\n",
      "Epoch 1244, Loss: 0.005432236095657572, Final Batch Loss: 0.00040840261499397457\n",
      "Epoch 1245, Loss: 0.004359062062576413, Final Batch Loss: 0.000790564576163888\n",
      "Epoch 1246, Loss: 0.0049184899689862505, Final Batch Loss: 0.0031832843087613583\n",
      "Epoch 1247, Loss: 0.007694825704675168, Final Batch Loss: 0.0008771326974965632\n",
      "Epoch 1248, Loss: 0.002835817460436374, Final Batch Loss: 0.0004377039731480181\n",
      "Epoch 1249, Loss: 0.005384165677241981, Final Batch Loss: 0.0008810246945358813\n",
      "Epoch 1250, Loss: 0.01106187904952094, Final Batch Loss: 0.0005124285235069692\n",
      "Epoch 1251, Loss: 0.008857249937136658, Final Batch Loss: 0.00016380725719500333\n",
      "Epoch 1252, Loss: 0.010025658733866294, Final Batch Loss: 2.546669747971464e-05\n",
      "Epoch 1253, Loss: 0.009240445564500988, Final Batch Loss: 0.0005975149106234312\n",
      "Epoch 1254, Loss: 0.008239678863901645, Final Batch Loss: 0.0009055545669980347\n",
      "Epoch 1255, Loss: 0.0030323966057039797, Final Batch Loss: 0.0002515777596272528\n",
      "Epoch 1256, Loss: 0.0029146420129109174, Final Batch Loss: 0.00038480592775158584\n",
      "Epoch 1257, Loss: 0.007842478109523654, Final Batch Loss: 0.0011460778769105673\n",
      "Epoch 1258, Loss: 0.004211325431242585, Final Batch Loss: 0.0006973035633563995\n",
      "Epoch 1259, Loss: 0.0042144901235587895, Final Batch Loss: 0.0009132456034421921\n",
      "Epoch 1260, Loss: 0.0037070123362354934, Final Batch Loss: 0.0008949009352363646\n",
      "Epoch 1261, Loss: 0.003030249150469899, Final Batch Loss: 0.00074772973312065\n",
      "Epoch 1262, Loss: 0.017687239625956863, Final Batch Loss: 0.0007103504030965269\n",
      "Epoch 1263, Loss: 0.0209948499687016, Final Batch Loss: 0.0013881109189242125\n",
      "Epoch 1264, Loss: 0.015127297258004546, Final Batch Loss: 0.0014072583289816976\n",
      "Epoch 1265, Loss: 0.005779689410701394, Final Batch Loss: 0.0012449623318389058\n",
      "Epoch 1266, Loss: 0.008610937744379044, Final Batch Loss: 0.0016281825955957174\n",
      "Epoch 1267, Loss: 0.005140853128978051, Final Batch Loss: 0.0002750250860117376\n",
      "Epoch 1268, Loss: 0.009045204846188426, Final Batch Loss: 0.0009716337081044912\n",
      "Epoch 1269, Loss: 0.002776175329927355, Final Batch Loss: 0.0006919623701833189\n",
      "Epoch 1270, Loss: 0.0038629810442216694, Final Batch Loss: 0.0003428037161938846\n",
      "Epoch 1271, Loss: 0.026846819935599342, Final Batch Loss: 0.00032295650453306735\n",
      "Epoch 1272, Loss: 0.004663618601625785, Final Batch Loss: 0.0022921606432646513\n",
      "Epoch 1273, Loss: 0.010416849225293845, Final Batch Loss: 0.0007110798615030944\n",
      "Epoch 1274, Loss: 0.013855464523658156, Final Batch Loss: 0.0025232909247279167\n",
      "Epoch 1275, Loss: 0.002811157319229096, Final Batch Loss: 0.0012289794394746423\n",
      "Epoch 1276, Loss: 0.004196024063276127, Final Batch Loss: 0.0018535921117290854\n",
      "Epoch 1277, Loss: 0.004428174266649876, Final Batch Loss: 9.46468862821348e-05\n",
      "Epoch 1278, Loss: 0.006790634914068505, Final Batch Loss: 0.00041282354504801333\n",
      "Epoch 1279, Loss: 0.004059644823428243, Final Batch Loss: 0.0011440555099397898\n",
      "Epoch 1280, Loss: 0.0030081723525654525, Final Batch Loss: 0.00030397981754504144\n",
      "Epoch 1281, Loss: 0.0031256107322406024, Final Batch Loss: 0.0003156246093567461\n",
      "Epoch 1282, Loss: 0.00951591250486672, Final Batch Loss: 0.006174995563924313\n",
      "Epoch 1283, Loss: 0.009737938002217561, Final Batch Loss: 0.0006186708924360573\n",
      "Epoch 1284, Loss: 0.003084097581449896, Final Batch Loss: 0.00014467997243627906\n",
      "Epoch 1285, Loss: 0.01323375350330025, Final Batch Loss: 0.0009580651530995965\n",
      "Epoch 1286, Loss: 0.0020284067431930453, Final Batch Loss: 0.0006032477249391377\n",
      "Epoch 1287, Loss: 0.004755839676363394, Final Batch Loss: 0.00014689119416289032\n",
      "Epoch 1288, Loss: 0.014199537690728903, Final Batch Loss: 0.0005292408168315887\n",
      "Epoch 1289, Loss: 0.0014711975818499923, Final Batch Loss: 0.0004886476090177894\n",
      "Epoch 1290, Loss: 0.007022952660918236, Final Batch Loss: 0.0007250462658703327\n",
      "Epoch 1291, Loss: 0.0515254121273756, Final Batch Loss: 0.0074119120836257935\n",
      "Epoch 1292, Loss: 0.006583783659152687, Final Batch Loss: 0.0016287565231323242\n",
      "Epoch 1293, Loss: 0.020102696551475674, Final Batch Loss: 0.0005473023629747331\n",
      "Epoch 1294, Loss: 0.0030291086877696216, Final Batch Loss: 0.0004271129728294909\n",
      "Epoch 1295, Loss: 0.005502933403477073, Final Batch Loss: 0.00010576131171546876\n",
      "Epoch 1296, Loss: 0.003866641956847161, Final Batch Loss: 0.0016143536195158958\n",
      "Epoch 1297, Loss: 0.03543203859589994, Final Batch Loss: 0.002009433461353183\n",
      "Epoch 1298, Loss: 0.0023373098811134696, Final Batch Loss: 0.0004989136359654367\n",
      "Epoch 1299, Loss: 0.0022868418018333614, Final Batch Loss: 0.0008971452480182052\n",
      "Epoch 1300, Loss: 0.013469072466250509, Final Batch Loss: 0.0006734474445693195\n",
      "Epoch 1301, Loss: 0.011059793119784445, Final Batch Loss: 8.190594962798059e-05\n",
      "Epoch 1302, Loss: 0.005130838413606398, Final Batch Loss: 0.000169757564435713\n",
      "Epoch 1303, Loss: 0.00291743288107682, Final Batch Loss: 0.00013046259118709713\n",
      "Epoch 1304, Loss: 0.006907170114573091, Final Batch Loss: 0.0006682166713289917\n",
      "Epoch 1305, Loss: 0.0033292873413302004, Final Batch Loss: 0.0011969705810770392\n",
      "Epoch 1306, Loss: 0.009469006734434515, Final Batch Loss: 0.002187197795137763\n",
      "Epoch 1307, Loss: 0.004313946126785595, Final Batch Loss: 8.102373249130324e-05\n",
      "Epoch 1308, Loss: 0.015615492244251072, Final Batch Loss: 0.000553279765881598\n",
      "Epoch 1309, Loss: 0.0013663601130247116, Final Batch Loss: 0.00038999354001134634\n",
      "Epoch 1310, Loss: 0.0021192377025727183, Final Batch Loss: 0.0002135272661689669\n",
      "Epoch 1311, Loss: 0.0020931944018229842, Final Batch Loss: 0.00029827153775841\n",
      "Epoch 1312, Loss: 0.0013203323178458959, Final Batch Loss: 0.00026670785155147314\n",
      "Epoch 1313, Loss: 0.0028769621276296675, Final Batch Loss: 0.0017343845684081316\n",
      "Epoch 1314, Loss: 0.0025172527821268886, Final Batch Loss: 0.0002786966215353459\n",
      "Epoch 1315, Loss: 0.007093254185747355, Final Batch Loss: 0.0017220309237018228\n",
      "Epoch 1316, Loss: 0.016252268105745316, Final Batch Loss: 0.004645009525120258\n",
      "Epoch 1317, Loss: 0.008897661929950118, Final Batch Loss: 0.000633475196082145\n",
      "Epoch 1318, Loss: 0.0039675656298641115, Final Batch Loss: 0.0012841492425650358\n",
      "Epoch 1319, Loss: 0.01679616770707071, Final Batch Loss: 0.0035328848753124475\n",
      "Epoch 1320, Loss: 0.0030699284106958658, Final Batch Loss: 0.0019728841725736856\n",
      "Epoch 1321, Loss: 0.0031000254311948083, Final Batch Loss: 0.000816117215435952\n",
      "Epoch 1322, Loss: 0.016503654813277535, Final Batch Loss: 0.00023810051789041609\n",
      "Epoch 1323, Loss: 0.004263430048013106, Final Batch Loss: 0.0004673688963521272\n",
      "Epoch 1324, Loss: 0.002137535804649815, Final Batch Loss: 0.0013238444225862622\n",
      "Epoch 1325, Loss: 0.06323041768337134, Final Batch Loss: 0.0001819790486479178\n",
      "Epoch 1326, Loss: 0.0032206259202212095, Final Batch Loss: 0.0013201091205701232\n",
      "Epoch 1327, Loss: 0.004580576729495078, Final Batch Loss: 0.00019975099712610245\n",
      "Epoch 1328, Loss: 0.010926881630439311, Final Batch Loss: 0.004725660663098097\n",
      "Epoch 1329, Loss: 0.012019953690469265, Final Batch Loss: 0.0013358283322304487\n",
      "Epoch 1330, Loss: 0.006128216569777578, Final Batch Loss: 0.0004325752961449325\n",
      "Epoch 1331, Loss: 0.005586414605204482, Final Batch Loss: 0.00011057049414375797\n",
      "Epoch 1332, Loss: 0.048497842508368194, Final Batch Loss: 0.04554269462823868\n",
      "Epoch 1333, Loss: 0.015224981936626136, Final Batch Loss: 0.0009706299169920385\n",
      "Epoch 1334, Loss: 0.005783644824987277, Final Batch Loss: 0.0014640898443758488\n",
      "Epoch 1335, Loss: 0.004851373611018062, Final Batch Loss: 0.00024354610650334507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1336, Loss: 0.009561262093484402, Final Batch Loss: 0.0006218759808689356\n",
      "Epoch 1337, Loss: 0.0024340313393622637, Final Batch Loss: 0.0005485594156198204\n",
      "Epoch 1338, Loss: 0.014435190125368536, Final Batch Loss: 0.0006618723273277283\n",
      "Epoch 1339, Loss: 0.009266440581995994, Final Batch Loss: 0.004465533420443535\n",
      "Epoch 1340, Loss: 0.00524954532738775, Final Batch Loss: 0.0017557578394189477\n",
      "Epoch 1341, Loss: 0.00853402481880039, Final Batch Loss: 0.0005232596304267645\n",
      "Epoch 1342, Loss: 0.0029373696888796985, Final Batch Loss: 0.0007260175771079957\n",
      "Epoch 1343, Loss: 0.002957625954877585, Final Batch Loss: 0.0014104734873399138\n",
      "Epoch 1344, Loss: 0.03869390836916864, Final Batch Loss: 0.031378794461488724\n",
      "Epoch 1345, Loss: 0.008891909674275666, Final Batch Loss: 0.0013583628460764885\n",
      "Epoch 1346, Loss: 0.06211959104984999, Final Batch Loss: 0.038131289184093475\n",
      "Epoch 1347, Loss: 0.025684432417619973, Final Batch Loss: 0.016961483284831047\n",
      "Epoch 1348, Loss: 0.0033624713541939855, Final Batch Loss: 0.0005919981049373746\n",
      "Epoch 1349, Loss: 0.039460860076360404, Final Batch Loss: 0.0017073916969820857\n",
      "Epoch 1350, Loss: 0.022487875656224787, Final Batch Loss: 0.014527715742588043\n",
      "Epoch 1351, Loss: 0.0058783744752872735, Final Batch Loss: 0.0013274118537083268\n",
      "Epoch 1352, Loss: 0.015798885142430663, Final Batch Loss: 0.0005106858443468809\n",
      "Epoch 1353, Loss: 0.03575958264991641, Final Batch Loss: 0.03143259137868881\n",
      "Epoch 1354, Loss: 0.001971893885638565, Final Batch Loss: 0.0005551018984988332\n",
      "Epoch 1355, Loss: 0.003996822517365217, Final Batch Loss: 0.0013980172807350755\n",
      "Epoch 1356, Loss: 0.0121254522819072, Final Batch Loss: 0.0013789375079795718\n",
      "Epoch 1357, Loss: 0.04548415879253298, Final Batch Loss: 0.04232573136687279\n",
      "Epoch 1358, Loss: 0.00809726765146479, Final Batch Loss: 0.000824547722004354\n",
      "Epoch 1359, Loss: 0.0028375235269777477, Final Batch Loss: 0.000933164672460407\n",
      "Epoch 1360, Loss: 0.019005581852979958, Final Batch Loss: 0.007951028645038605\n",
      "Epoch 1361, Loss: 0.03373389784246683, Final Batch Loss: 0.0010953922756016254\n",
      "Epoch 1362, Loss: 0.008906112634576857, Final Batch Loss: 0.0010286777978762984\n",
      "Epoch 1363, Loss: 0.017288880771957338, Final Batch Loss: 0.003162173554301262\n",
      "Epoch 1364, Loss: 0.021747094579041004, Final Batch Loss: 0.01611860655248165\n",
      "Epoch 1365, Loss: 0.015438727918080986, Final Batch Loss: 0.0019355727126821876\n",
      "Epoch 1366, Loss: 0.006831652746768668, Final Batch Loss: 0.0006153516587801278\n",
      "Epoch 1367, Loss: 0.01755512011004612, Final Batch Loss: 0.000671572401188314\n",
      "Epoch 1368, Loss: 0.007320735836401582, Final Batch Loss: 0.0024136498104780912\n",
      "Epoch 1369, Loss: 0.010991925140842795, Final Batch Loss: 0.0010824402561411262\n",
      "Epoch 1370, Loss: 0.0066401222720742226, Final Batch Loss: 0.002305163536220789\n",
      "Epoch 1371, Loss: 0.030561787309125066, Final Batch Loss: 0.023923218250274658\n",
      "Epoch 1372, Loss: 0.0062828336376696825, Final Batch Loss: 0.002856283448636532\n",
      "Epoch 1373, Loss: 0.025216789916157722, Final Batch Loss: 0.018628600984811783\n",
      "Epoch 1374, Loss: 0.005070374230854213, Final Batch Loss: 0.00020034232875332236\n",
      "Epoch 1375, Loss: 0.0036946701584383845, Final Batch Loss: 0.000892156851477921\n",
      "Epoch 1376, Loss: 0.02717974764527753, Final Batch Loss: 0.012403001077473164\n",
      "Epoch 1377, Loss: 0.006255587679333985, Final Batch Loss: 0.001297467271797359\n",
      "Epoch 1378, Loss: 0.0034058363526128232, Final Batch Loss: 0.0003467277274467051\n",
      "Epoch 1379, Loss: 0.004117550401133485, Final Batch Loss: 0.0001326844358118251\n",
      "Epoch 1380, Loss: 0.017750466882716864, Final Batch Loss: 0.00016660214168950915\n",
      "Epoch 1381, Loss: 0.0023092479386832565, Final Batch Loss: 0.0007010871195234358\n",
      "Epoch 1382, Loss: 0.002173019864130765, Final Batch Loss: 0.0005407029530033469\n",
      "Epoch 1383, Loss: 0.005012043111491948, Final Batch Loss: 0.0010869144462049007\n",
      "Epoch 1384, Loss: 0.0024385662109125406, Final Batch Loss: 9.498526924289763e-05\n",
      "Epoch 1385, Loss: 0.008079959778115153, Final Batch Loss: 0.0063994769006967545\n",
      "Epoch 1386, Loss: 0.0090869631676469, Final Batch Loss: 0.007737806532531977\n",
      "Epoch 1387, Loss: 0.0023512710467912257, Final Batch Loss: 0.0004205903096590191\n",
      "Epoch 1388, Loss: 0.0031800366123206913, Final Batch Loss: 0.0003336546360515058\n",
      "Epoch 1389, Loss: 0.0027577424625633284, Final Batch Loss: 0.00020996715466026217\n",
      "Epoch 1390, Loss: 0.019760882307309657, Final Batch Loss: 0.0009675365290604532\n",
      "Epoch 1391, Loss: 0.0016018129244912416, Final Batch Loss: 0.0006938427104614675\n",
      "Epoch 1392, Loss: 0.006199912299052812, Final Batch Loss: 0.0001737298589432612\n",
      "Epoch 1393, Loss: 0.008252154329966288, Final Batch Loss: 0.00010739254503278062\n",
      "Epoch 1394, Loss: 0.005694272986147553, Final Batch Loss: 0.0003537641023285687\n",
      "Epoch 1395, Loss: 0.0024814088246785104, Final Batch Loss: 0.0006984442588873208\n",
      "Epoch 1396, Loss: 0.002834657731000334, Final Batch Loss: 0.0005029918975196779\n",
      "Epoch 1397, Loss: 0.0017955922521650791, Final Batch Loss: 0.000660726276692003\n",
      "Epoch 1398, Loss: 0.025601920031476766, Final Batch Loss: 0.02370021492242813\n",
      "Epoch 1399, Loss: 0.009408967744093388, Final Batch Loss: 0.0068627577275037766\n",
      "Epoch 1400, Loss: 0.020915938817779534, Final Batch Loss: 0.013372865505516529\n",
      "Epoch 1401, Loss: 0.0028530540002975613, Final Batch Loss: 0.00020875970949418843\n",
      "Epoch 1402, Loss: 0.002159601339371875, Final Batch Loss: 0.001217721146531403\n",
      "Epoch 1403, Loss: 0.003948620054870844, Final Batch Loss: 0.0011175445979461074\n",
      "Epoch 1404, Loss: 0.005175723985303193, Final Batch Loss: 0.003466477617621422\n",
      "Epoch 1405, Loss: 0.012979528051801026, Final Batch Loss: 0.0010828428203240037\n",
      "Epoch 1406, Loss: 0.0020404664828674868, Final Batch Loss: 0.00022036484733689576\n",
      "Epoch 1407, Loss: 0.0062790115480311215, Final Batch Loss: 0.0008133028750307858\n",
      "Epoch 1408, Loss: 0.009020001394674182, Final Batch Loss: 0.005283325910568237\n",
      "Epoch 1409, Loss: 0.024007452884688973, Final Batch Loss: 0.01679583452641964\n",
      "Epoch 1410, Loss: 0.009200065862387419, Final Batch Loss: 0.0016877891030162573\n",
      "Epoch 1411, Loss: 0.007279624973307364, Final Batch Loss: 0.00020703002519439906\n",
      "Epoch 1412, Loss: 0.0025696079101180658, Final Batch Loss: 0.0013385532656684518\n",
      "Epoch 1413, Loss: 0.005486740679771174, Final Batch Loss: 0.00011368637933628634\n",
      "Epoch 1414, Loss: 0.010893843049416319, Final Batch Loss: 0.00045430686441250145\n",
      "Epoch 1415, Loss: 0.004419940407387912, Final Batch Loss: 0.0010714931413531303\n",
      "Epoch 1416, Loss: 0.002012453303905204, Final Batch Loss: 0.0006009929929859936\n",
      "Epoch 1417, Loss: 0.00424189874320291, Final Batch Loss: 0.00027403078274801373\n",
      "Epoch 1418, Loss: 0.001563357887789607, Final Batch Loss: 0.00017171187209896743\n",
      "Epoch 1419, Loss: 0.00817003328120336, Final Batch Loss: 0.0007122385432012379\n",
      "Epoch 1420, Loss: 0.0027145692729391158, Final Batch Loss: 0.0005195605917833745\n",
      "Epoch 1421, Loss: 0.015688173152739182, Final Batch Loss: 0.00040374681702814996\n",
      "Epoch 1422, Loss: 0.027874501887708902, Final Batch Loss: 0.020053919404745102\n",
      "Epoch 1423, Loss: 0.0032876708428375423, Final Batch Loss: 0.0019790998194366693\n",
      "Epoch 1424, Loss: 0.0008388439964619465, Final Batch Loss: 6.589058466488495e-05\n",
      "Epoch 1425, Loss: 0.0017573544173501432, Final Batch Loss: 0.000486331875436008\n",
      "Epoch 1426, Loss: 0.0030654939655505586, Final Batch Loss: 4.601538603310473e-05\n",
      "Epoch 1427, Loss: 0.014681495173135772, Final Batch Loss: 0.011822720989584923\n",
      "Epoch 1428, Loss: 0.0028003602637909353, Final Batch Loss: 0.0019250494660809636\n",
      "Epoch 1429, Loss: 0.008098072314169258, Final Batch Loss: 0.007428925484418869\n",
      "Epoch 1430, Loss: 0.008536921464838088, Final Batch Loss: 0.005858216434717178\n",
      "Epoch 1431, Loss: 0.006408075045328587, Final Batch Loss: 0.004100951831787825\n",
      "Epoch 1432, Loss: 0.010424362262710929, Final Batch Loss: 0.0015817421954125166\n",
      "Epoch 1433, Loss: 0.007024571707006544, Final Batch Loss: 0.0003892223467119038\n",
      "Epoch 1434, Loss: 0.0008764087542658672, Final Batch Loss: 0.00020907561702188104\n",
      "Epoch 1435, Loss: 0.0020277313888072968, Final Batch Loss: 0.00020044695702381432\n",
      "Epoch 1436, Loss: 0.0019420837343204767, Final Batch Loss: 0.0008579653804190457\n",
      "Epoch 1437, Loss: 0.0035689303185790777, Final Batch Loss: 0.00202894932590425\n",
      "Epoch 1438, Loss: 0.006964930420508608, Final Batch Loss: 0.00028171538724564016\n",
      "Epoch 1439, Loss: 0.018379326240392402, Final Batch Loss: 0.00118446652777493\n",
      "Epoch 1440, Loss: 0.03438265783188399, Final Batch Loss: 0.00014360730710905045\n",
      "Epoch 1441, Loss: 0.0043653725006151944, Final Batch Loss: 0.0016508842818439007\n",
      "Epoch 1442, Loss: 0.012300235335715115, Final Batch Loss: 0.010262085124850273\n",
      "Epoch 1443, Loss: 0.005728558753617108, Final Batch Loss: 0.001289411331526935\n",
      "Epoch 1444, Loss: 0.012174485338618979, Final Batch Loss: 0.00031626466079615057\n",
      "Epoch 1445, Loss: 0.01162189117167145, Final Batch Loss: 0.0003876447444781661\n",
      "Epoch 1446, Loss: 0.0023089853493729606, Final Batch Loss: 0.00021575480059254915\n",
      "Epoch 1447, Loss: 0.0019472191343083978, Final Batch Loss: 0.0006261852686293423\n",
      "Epoch 1448, Loss: 0.008465309627354145, Final Batch Loss: 0.004740195348858833\n",
      "Epoch 1449, Loss: 0.002389037108514458, Final Batch Loss: 0.001560130389407277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1450, Loss: 0.0033312983578071, Final Batch Loss: 0.0008280027541331947\n",
      "Epoch 1451, Loss: 0.0021940919759799726, Final Batch Loss: 3.442186425672844e-05\n",
      "Epoch 1452, Loss: 0.0014480247482424602, Final Batch Loss: 0.00019405623606871814\n",
      "Epoch 1453, Loss: 0.005711479112505913, Final Batch Loss: 0.0007500004721805453\n",
      "Epoch 1454, Loss: 0.0017917176592163742, Final Batch Loss: 0.0005080170230939984\n",
      "Epoch 1455, Loss: 0.009540830156765878, Final Batch Loss: 0.0014073426136747003\n",
      "Epoch 1456, Loss: 0.0020148030744167045, Final Batch Loss: 0.00012877870176453143\n",
      "Epoch 1457, Loss: 0.005972620579996146, Final Batch Loss: 0.00019500010239426047\n",
      "Epoch 1458, Loss: 0.0016341190312232357, Final Batch Loss: 4.389935565995984e-05\n",
      "Epoch 1459, Loss: 0.0037377004337031394, Final Batch Loss: 0.001553454203531146\n",
      "Epoch 1460, Loss: 0.006558527093147859, Final Batch Loss: 0.004391083959490061\n",
      "Epoch 1461, Loss: 0.005570507986703888, Final Batch Loss: 0.004444307181984186\n",
      "Epoch 1462, Loss: 0.002006328315474093, Final Batch Loss: 0.0004595371428877115\n",
      "Epoch 1463, Loss: 0.012425688793882728, Final Batch Loss: 0.0012322359252721071\n",
      "Epoch 1464, Loss: 0.022260313271544874, Final Batch Loss: 0.0044567822478711605\n",
      "Epoch 1465, Loss: 0.0013205233844928443, Final Batch Loss: 0.00034120824420824647\n",
      "Epoch 1466, Loss: 0.022397304128389806, Final Batch Loss: 0.0003631431027315557\n",
      "Epoch 1467, Loss: 0.002528005134081468, Final Batch Loss: 0.0014244342455640435\n",
      "Epoch 1468, Loss: 0.005695542262401432, Final Batch Loss: 0.001272919005714357\n",
      "Epoch 1469, Loss: 0.001645460637519136, Final Batch Loss: 0.00043509455281309783\n",
      "Epoch 1470, Loss: 0.006782592827221379, Final Batch Loss: 0.00020054422202520072\n",
      "Epoch 1471, Loss: 0.007483760244213045, Final Batch Loss: 0.0023123782593756914\n",
      "Epoch 1472, Loss: 0.0051457713125273585, Final Batch Loss: 0.003963919822126627\n",
      "Epoch 1473, Loss: 0.011813431279733777, Final Batch Loss: 0.002369079040363431\n",
      "Epoch 1474, Loss: 0.011830961157102138, Final Batch Loss: 0.0003449854557402432\n",
      "Epoch 1475, Loss: 0.02580000364105217, Final Batch Loss: 0.009861930273473263\n",
      "Epoch 1476, Loss: 0.0035292243119329214, Final Batch Loss: 0.001854306785389781\n",
      "Epoch 1477, Loss: 0.007732697995379567, Final Batch Loss: 0.002733035245910287\n",
      "Epoch 1478, Loss: 0.005873848800547421, Final Batch Loss: 0.0012955263955518603\n",
      "Epoch 1479, Loss: 0.00661909143673256, Final Batch Loss: 0.004022047854959965\n",
      "Epoch 1480, Loss: 0.004781531650223769, Final Batch Loss: 0.0014670422533527017\n",
      "Epoch 1481, Loss: 0.005330476036760956, Final Batch Loss: 0.0016102503286674619\n",
      "Epoch 1482, Loss: 0.01647011609748006, Final Batch Loss: 0.001346382312476635\n",
      "Epoch 1483, Loss: 0.0026460826920811087, Final Batch Loss: 0.0014049189630895853\n",
      "Epoch 1484, Loss: 0.006598681124160066, Final Batch Loss: 0.005812580231577158\n",
      "Epoch 1485, Loss: 0.0076456047827377915, Final Batch Loss: 0.0017839388456195593\n",
      "Epoch 1486, Loss: 0.0025570249708835036, Final Batch Loss: 0.0003137753519695252\n",
      "Epoch 1487, Loss: 0.008154119015671313, Final Batch Loss: 0.0005409113364294171\n",
      "Epoch 1488, Loss: 0.0016933454026002437, Final Batch Loss: 0.00033783548860810697\n",
      "Epoch 1489, Loss: 0.005387835379224271, Final Batch Loss: 0.001928828307427466\n",
      "Epoch 1490, Loss: 0.0009635942697059363, Final Batch Loss: 0.00029294268460944295\n",
      "Epoch 1491, Loss: 0.002921603911090642, Final Batch Loss: 0.001332261716015637\n",
      "Epoch 1492, Loss: 0.007118395471479744, Final Batch Loss: 0.0039484938606619835\n",
      "Epoch 1493, Loss: 0.005619075207505375, Final Batch Loss: 0.003719247179105878\n",
      "Epoch 1494, Loss: 0.0026105656288564205, Final Batch Loss: 0.0006361320847645402\n",
      "Epoch 1495, Loss: 0.012840024748584256, Final Batch Loss: 0.00039449482574127614\n",
      "Epoch 1496, Loss: 0.008307128911837935, Final Batch Loss: 0.0002618591533973813\n",
      "Epoch 1497, Loss: 0.0012905522453365847, Final Batch Loss: 0.000615679775364697\n",
      "Epoch 1498, Loss: 0.010382121981820092, Final Batch Loss: 0.00040296136285178363\n",
      "Epoch 1499, Loss: 0.002587062626844272, Final Batch Loss: 0.0002392771129962057\n",
      "Epoch 1500, Loss: 0.0061520334566012025, Final Batch Loss: 0.0006038587307557464\n",
      "Epoch 1501, Loss: 0.011123937438242137, Final Batch Loss: 0.003109653713181615\n",
      "Epoch 1502, Loss: 0.021982092526741326, Final Batch Loss: 0.012153418734669685\n",
      "Epoch 1503, Loss: 0.024196411133743823, Final Batch Loss: 0.0019056230084970593\n",
      "Epoch 1504, Loss: 0.005685799813363701, Final Batch Loss: 0.0006378015386871994\n",
      "Epoch 1505, Loss: 0.03780585102504119, Final Batch Loss: 0.0017098489915952086\n",
      "Epoch 1506, Loss: 0.026535407232586294, Final Batch Loss: 0.0007961183437146246\n",
      "Epoch 1507, Loss: 0.01510934077668935, Final Batch Loss: 0.0001853819703683257\n",
      "Epoch 1508, Loss: 0.010256789129925892, Final Batch Loss: 0.0003449296054895967\n",
      "Epoch 1509, Loss: 0.021104628132889047, Final Batch Loss: 0.001544330851174891\n",
      "Epoch 1510, Loss: 0.01108506484888494, Final Batch Loss: 0.0006395506206899881\n",
      "Epoch 1511, Loss: 0.017368023400194943, Final Batch Loss: 0.001273049390874803\n",
      "Epoch 1512, Loss: 0.002836571788066067, Final Batch Loss: 0.0001598601375008002\n",
      "Epoch 1513, Loss: 0.005396959721110761, Final Batch Loss: 0.003422787645831704\n",
      "Epoch 1514, Loss: 0.033498512115329504, Final Batch Loss: 0.031245727092027664\n",
      "Epoch 1515, Loss: 0.004843478702241555, Final Batch Loss: 0.00047490012366324663\n",
      "Epoch 1516, Loss: 0.009280052385292947, Final Batch Loss: 0.000789464102126658\n",
      "Epoch 1517, Loss: 0.04528295039199293, Final Batch Loss: 0.01568642072379589\n",
      "Epoch 1518, Loss: 0.002718678559176624, Final Batch Loss: 0.001132286386564374\n",
      "Epoch 1519, Loss: 0.0019412016990827397, Final Batch Loss: 0.0002069625916192308\n",
      "Epoch 1520, Loss: 0.007765068265143782, Final Batch Loss: 0.000629569636657834\n",
      "Epoch 1521, Loss: 0.004758696799399331, Final Batch Loss: 0.0033615233842283487\n",
      "Epoch 1522, Loss: 0.0037033264234196395, Final Batch Loss: 0.0006950048264116049\n",
      "Epoch 1523, Loss: 0.0026908187137451023, Final Batch Loss: 0.00037676424835808575\n",
      "Epoch 1524, Loss: 0.004622068896424025, Final Batch Loss: 0.000972515030298382\n",
      "Epoch 1525, Loss: 0.0038922949752304703, Final Batch Loss: 0.00028381680021993816\n",
      "Epoch 1526, Loss: 0.005029532941989601, Final Batch Loss: 0.0030547822825610638\n",
      "Epoch 1527, Loss: 0.013016279437579215, Final Batch Loss: 0.0008165262406691909\n",
      "Epoch 1528, Loss: 0.005837332209921442, Final Batch Loss: 0.0007577535579912364\n",
      "Epoch 1529, Loss: 0.006031328579410911, Final Batch Loss: 0.0033150718081742525\n",
      "Epoch 1530, Loss: 0.010781216318719089, Final Batch Loss: 0.007478727493435144\n",
      "Epoch 1531, Loss: 0.0021838106331415474, Final Batch Loss: 0.0007098110509105027\n",
      "Epoch 1532, Loss: 0.008275309228338301, Final Batch Loss: 0.00025721712154336274\n",
      "Epoch 1533, Loss: 0.0031037522639962845, Final Batch Loss: 0.0006515897694043815\n",
      "Epoch 1534, Loss: 0.002458776638377458, Final Batch Loss: 0.0008668034570291638\n",
      "Epoch 1535, Loss: 0.016133717726916075, Final Batch Loss: 0.004868828691542149\n",
      "Epoch 1536, Loss: 0.004932054260279983, Final Batch Loss: 0.00039306882536038756\n",
      "Epoch 1537, Loss: 0.008273787490907125, Final Batch Loss: 0.00014612263476010412\n",
      "Epoch 1538, Loss: 0.0027353631157893687, Final Batch Loss: 0.000694513728376478\n",
      "Epoch 1539, Loss: 0.006820930109824985, Final Batch Loss: 0.004615635611116886\n",
      "Epoch 1540, Loss: 0.011539076396729797, Final Batch Loss: 0.0006368655594997108\n",
      "Epoch 1541, Loss: 0.00664109451463446, Final Batch Loss: 0.00089861179003492\n",
      "Epoch 1542, Loss: 0.0016459455655422062, Final Batch Loss: 0.00015390277258120477\n",
      "Epoch 1543, Loss: 0.0034243138652527705, Final Batch Loss: 0.0001454209123039618\n",
      "Epoch 1544, Loss: 0.02266931370832026, Final Batch Loss: 0.018145285546779633\n",
      "Epoch 1545, Loss: 0.003978608641773462, Final Batch Loss: 0.0006558120949193835\n",
      "Epoch 1546, Loss: 0.0038613356300629675, Final Batch Loss: 0.0006117987795732915\n",
      "Epoch 1547, Loss: 0.003504079068079591, Final Batch Loss: 0.0003400872810743749\n",
      "Epoch 1548, Loss: 0.001506184518802911, Final Batch Loss: 0.00018610787810757756\n",
      "Epoch 1549, Loss: 0.01190047338604927, Final Batch Loss: 0.005335393827408552\n",
      "Epoch 1550, Loss: 0.005644061486236751, Final Batch Loss: 0.0038050273433327675\n",
      "Epoch 1551, Loss: 0.005563497776165605, Final Batch Loss: 0.00011938856914639473\n",
      "Epoch 1552, Loss: 0.003580569406040013, Final Batch Loss: 0.00026874919421970844\n",
      "Epoch 1553, Loss: 0.004130386339966208, Final Batch Loss: 0.0007652139174751937\n",
      "Epoch 1554, Loss: 0.004320300940889865, Final Batch Loss: 0.0007430160767398775\n",
      "Epoch 1555, Loss: 0.03493222678662278, Final Batch Loss: 0.01153051108121872\n",
      "Epoch 1556, Loss: 0.0012293666659388691, Final Batch Loss: 0.000541945977602154\n",
      "Epoch 1557, Loss: 0.008702294951945078, Final Batch Loss: 0.001211531925946474\n",
      "Epoch 1558, Loss: 0.0020513974013738334, Final Batch Loss: 0.0006517528090626001\n",
      "Epoch 1559, Loss: 0.001849409454734996, Final Batch Loss: 0.0005889393505640328\n",
      "Epoch 1560, Loss: 0.0014404893736355007, Final Batch Loss: 0.0001260017161257565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1561, Loss: 0.0022227462468435988, Final Batch Loss: 0.0005569198401644826\n",
      "Epoch 1562, Loss: 0.0043980878763250075, Final Batch Loss: 8.713281567906961e-05\n",
      "Epoch 1563, Loss: 0.005156686238478869, Final Batch Loss: 0.0007847885717637837\n",
      "Epoch 1564, Loss: 0.001311453990638256, Final Batch Loss: 0.0005130346980877221\n",
      "Epoch 1565, Loss: 0.0047348811640404165, Final Batch Loss: 0.0007020503981038928\n",
      "Epoch 1566, Loss: 0.0029185675375629216, Final Batch Loss: 0.0012104903580620885\n",
      "Epoch 1567, Loss: 0.0021279614229570143, Final Batch Loss: 0.0014227981446310878\n",
      "Epoch 1568, Loss: 0.008850839745718986, Final Batch Loss: 0.00028925976948812604\n",
      "Epoch 1569, Loss: 0.00258298814878799, Final Batch Loss: 0.000920889142435044\n",
      "Epoch 1570, Loss: 0.00582369326002663, Final Batch Loss: 0.00011444198753451928\n",
      "Epoch 1571, Loss: 0.003904665936715901, Final Batch Loss: 0.0007023481884971261\n",
      "Epoch 1572, Loss: 0.006308502837782726, Final Batch Loss: 0.0009422276052646339\n",
      "Epoch 1573, Loss: 0.006216767622390762, Final Batch Loss: 0.00027817735099233687\n",
      "Epoch 1574, Loss: 0.0016240711556747556, Final Batch Loss: 0.0005952182109467685\n",
      "Epoch 1575, Loss: 0.003635826811660081, Final Batch Loss: 0.0011449774028733373\n",
      "Epoch 1576, Loss: 0.0074344639433547854, Final Batch Loss: 0.005246541928499937\n",
      "Epoch 1577, Loss: 0.0423961552005494, Final Batch Loss: 0.00013802693865727633\n",
      "Epoch 1578, Loss: 0.002335599587240722, Final Batch Loss: 9.944091289071366e-05\n",
      "Epoch 1579, Loss: 0.004296664439607412, Final Batch Loss: 0.00012125825742259622\n",
      "Epoch 1580, Loss: 0.004574214806780219, Final Batch Loss: 0.0032382486388087273\n",
      "Epoch 1581, Loss: 0.004919190221698955, Final Batch Loss: 0.004411653149873018\n",
      "Epoch 1582, Loss: 0.007075457077007741, Final Batch Loss: 0.00041226757457479835\n",
      "Epoch 1583, Loss: 0.0017472865292802453, Final Batch Loss: 0.00043162619112990797\n",
      "Epoch 1584, Loss: 0.005258331977529451, Final Batch Loss: 0.0001482938532717526\n",
      "Epoch 1585, Loss: 0.004674260970205069, Final Batch Loss: 0.000897727208212018\n",
      "Epoch 1586, Loss: 0.001612445295904763, Final Batch Loss: 0.0002070641057798639\n",
      "Epoch 1587, Loss: 0.0015221206413116306, Final Batch Loss: 0.0005696731386706233\n",
      "Epoch 1588, Loss: 0.004312962191761471, Final Batch Loss: 0.0009114168351516128\n",
      "Epoch 1589, Loss: 0.003654932777862996, Final Batch Loss: 0.001370027894154191\n",
      "Epoch 1590, Loss: 0.007036882336251438, Final Batch Loss: 0.0005210036179050803\n",
      "Epoch 1591, Loss: 0.0020832545415032655, Final Batch Loss: 0.00035726019996218383\n",
      "Epoch 1592, Loss: 0.004577143961796537, Final Batch Loss: 0.0003533231501933187\n",
      "Epoch 1593, Loss: 0.013920390221755952, Final Batch Loss: 0.0005019001546315849\n",
      "Epoch 1594, Loss: 0.0032490933954250067, Final Batch Loss: 0.0003797764366026968\n",
      "Epoch 1595, Loss: 0.004766473895870149, Final Batch Loss: 0.00036984056350775063\n",
      "Epoch 1596, Loss: 0.00609191256808117, Final Batch Loss: 0.0008905947906896472\n",
      "Epoch 1597, Loss: 0.0029032620368525386, Final Batch Loss: 0.0015735157066956162\n",
      "Epoch 1598, Loss: 0.005848658009199426, Final Batch Loss: 0.0005336372414603829\n",
      "Epoch 1599, Loss: 0.0032018974306993186, Final Batch Loss: 0.0011401409283280373\n",
      "Epoch 1600, Loss: 0.009034713075379841, Final Batch Loss: 0.001826991094276309\n",
      "Epoch 1601, Loss: 0.00840172020252794, Final Batch Loss: 0.0018028051126748323\n",
      "Epoch 1602, Loss: 0.001281862161704339, Final Batch Loss: 0.0005012903711758554\n",
      "Epoch 1603, Loss: 0.0019789143989328295, Final Batch Loss: 0.0013246954185888171\n",
      "Epoch 1604, Loss: 0.0043360256240703166, Final Batch Loss: 0.0006659466307610273\n",
      "Epoch 1605, Loss: 0.016946883872151375, Final Batch Loss: 0.014466394670307636\n",
      "Epoch 1606, Loss: 0.012279037677217275, Final Batch Loss: 0.006451135966926813\n",
      "Epoch 1607, Loss: 0.0017659128061495721, Final Batch Loss: 0.0007891664863564074\n",
      "Epoch 1608, Loss: 0.002201494004111737, Final Batch Loss: 0.0010279297130182385\n",
      "Epoch 1609, Loss: 0.009708572586532682, Final Batch Loss: 0.0006388008478097618\n",
      "Epoch 1610, Loss: 0.03889779336168431, Final Batch Loss: 0.03623780235648155\n",
      "Epoch 1611, Loss: 0.012106989801395684, Final Batch Loss: 0.0006926506175659597\n",
      "Epoch 1612, Loss: 0.011741192196495831, Final Batch Loss: 0.0011911094188690186\n",
      "Epoch 1613, Loss: 0.007783972949255258, Final Batch Loss: 0.00559441652148962\n",
      "Epoch 1614, Loss: 0.00971813993237447, Final Batch Loss: 0.001940810470841825\n",
      "Epoch 1615, Loss: 0.004571688419673592, Final Batch Loss: 0.00038297666469588876\n",
      "Epoch 1616, Loss: 0.026366762107500108, Final Batch Loss: 5.328805491444655e-05\n",
      "Epoch 1617, Loss: 0.0020038593793287873, Final Batch Loss: 0.0014930885517969728\n",
      "Epoch 1618, Loss: 0.01366460217104759, Final Batch Loss: 0.00015572177653666586\n",
      "Epoch 1619, Loss: 0.010495809852727689, Final Batch Loss: 0.005962429568171501\n",
      "Epoch 1620, Loss: 0.0029834111483069137, Final Batch Loss: 9.980455797631294e-05\n",
      "Epoch 1621, Loss: 0.005492615862749517, Final Batch Loss: 0.0037902493495494127\n",
      "Epoch 1622, Loss: 0.003867699299007654, Final Batch Loss: 0.00100969267077744\n",
      "Epoch 1623, Loss: 0.0041581199038773775, Final Batch Loss: 0.00026276172138750553\n",
      "Epoch 1624, Loss: 0.006588258373085409, Final Batch Loss: 0.0020924978889524937\n",
      "Epoch 1625, Loss: 0.007607467676280066, Final Batch Loss: 0.0008914450882002711\n",
      "Epoch 1626, Loss: 0.0015781391521159094, Final Batch Loss: 2.763840529951267e-05\n",
      "Epoch 1627, Loss: 0.0036519161076284945, Final Batch Loss: 0.0005538248806260526\n",
      "Epoch 1628, Loss: 0.0038232260703807697, Final Batch Loss: 0.00017086895240936428\n",
      "Epoch 1629, Loss: 0.008742533216718584, Final Batch Loss: 0.0009314058697782457\n",
      "Epoch 1630, Loss: 0.010953872464597225, Final Batch Loss: 0.00204778672195971\n",
      "Epoch 1631, Loss: 0.004317939252359793, Final Batch Loss: 0.00047168866149149835\n",
      "Epoch 1632, Loss: 0.013833027158398181, Final Batch Loss: 0.012351058423519135\n",
      "Epoch 1633, Loss: 0.003782771647820482, Final Batch Loss: 4.426087616593577e-05\n",
      "Epoch 1634, Loss: 0.010144198109628633, Final Batch Loss: 0.0007730093784630299\n",
      "Epoch 1635, Loss: 0.004124060389585793, Final Batch Loss: 0.0005559400888159871\n",
      "Epoch 1636, Loss: 0.0023022706154733896, Final Batch Loss: 0.0012519600568339229\n",
      "Epoch 1637, Loss: 0.00628081476315856, Final Batch Loss: 0.0005765469977632165\n",
      "Epoch 1638, Loss: 0.004889891468337737, Final Batch Loss: 0.000799408764578402\n",
      "Epoch 1639, Loss: 0.0015192500577541068, Final Batch Loss: 0.0005471835029311478\n",
      "Epoch 1640, Loss: 0.01587699718947988, Final Batch Loss: 0.0002396682248217985\n",
      "Epoch 1641, Loss: 0.0045777614577673376, Final Batch Loss: 0.00037226983113214374\n",
      "Epoch 1642, Loss: 0.009153828170383349, Final Batch Loss: 0.006797274574637413\n",
      "Epoch 1643, Loss: 0.005542751227039844, Final Batch Loss: 0.0002821498201228678\n",
      "Epoch 1644, Loss: 0.0017130256455857307, Final Batch Loss: 0.0008713211282156408\n",
      "Epoch 1645, Loss: 0.0024284280370920897, Final Batch Loss: 0.00100565399043262\n",
      "Epoch 1646, Loss: 0.002353484509512782, Final Batch Loss: 0.0003464178298600018\n",
      "Epoch 1647, Loss: 0.0015800580440554768, Final Batch Loss: 0.0005794104072265327\n",
      "Epoch 1648, Loss: 0.0030618243908975273, Final Batch Loss: 0.002504935022443533\n",
      "Epoch 1649, Loss: 0.00269017496611923, Final Batch Loss: 0.0011078575626015663\n",
      "Epoch 1650, Loss: 0.011193273618118837, Final Batch Loss: 0.0002989711065310985\n",
      "Epoch 1651, Loss: 0.01352511637378484, Final Batch Loss: 0.0012266123667359352\n",
      "Epoch 1652, Loss: 0.01204188953852281, Final Batch Loss: 0.007001470308750868\n",
      "Epoch 1653, Loss: 0.0015780553658260033, Final Batch Loss: 0.0006493536639027297\n",
      "Epoch 1654, Loss: 0.002324011133168824, Final Batch Loss: 0.0001629880425753072\n",
      "Epoch 1655, Loss: 0.01635653362609446, Final Batch Loss: 0.0010149769950658083\n",
      "Epoch 1656, Loss: 0.006914581346791238, Final Batch Loss: 0.005185318179428577\n",
      "Epoch 1657, Loss: 0.0024053685483522713, Final Batch Loss: 0.00017937301890924573\n",
      "Epoch 1658, Loss: 0.0026576432719593868, Final Batch Loss: 4.19068819610402e-05\n",
      "Epoch 1659, Loss: 0.0028460666944738477, Final Batch Loss: 0.00033195261494256556\n",
      "Epoch 1660, Loss: 0.039275239876587875, Final Batch Loss: 0.00021205162920523435\n",
      "Epoch 1661, Loss: 0.0017592543590581045, Final Batch Loss: 0.00020836862677242607\n",
      "Epoch 1662, Loss: 0.007162400346715003, Final Batch Loss: 0.0007050352287478745\n",
      "Epoch 1663, Loss: 0.0026325944054406136, Final Batch Loss: 0.0002605058834888041\n",
      "Epoch 1664, Loss: 0.006716541014611721, Final Batch Loss: 0.0020194470416754484\n",
      "Epoch 1665, Loss: 0.0035087414435110986, Final Batch Loss: 0.00042807444697245955\n",
      "Epoch 1666, Loss: 0.00671872089151293, Final Batch Loss: 0.0015818894607946277\n",
      "Epoch 1667, Loss: 0.0029343590140342712, Final Batch Loss: 0.0006667932029813528\n",
      "Epoch 1668, Loss: 0.009599044919013977, Final Batch Loss: 0.0021691482979804277\n",
      "Epoch 1669, Loss: 0.0014456244534812868, Final Batch Loss: 0.00012438505655154586\n",
      "Epoch 1670, Loss: 0.003077206951275002, Final Batch Loss: 4.406953667057678e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1671, Loss: 0.0037981002824380994, Final Batch Loss: 0.000980858807452023\n",
      "Epoch 1672, Loss: 0.001476723118685186, Final Batch Loss: 0.00013408165250439197\n",
      "Epoch 1673, Loss: 0.0024434212828055024, Final Batch Loss: 0.00042861996917054057\n",
      "Epoch 1674, Loss: 0.0013347119383979589, Final Batch Loss: 0.00033241321216337383\n",
      "Epoch 1675, Loss: 0.0018125178175978363, Final Batch Loss: 0.0003892152744811028\n",
      "Epoch 1676, Loss: 0.001464992790715769, Final Batch Loss: 0.00010304039460606873\n",
      "Epoch 1677, Loss: 0.0022238282836042345, Final Batch Loss: 0.00039771024603396654\n",
      "Epoch 1678, Loss: 0.007508964248700067, Final Batch Loss: 0.0001627730089239776\n",
      "Epoch 1679, Loss: 0.005457403254695237, Final Batch Loss: 0.0005989441415295005\n",
      "Epoch 1680, Loss: 0.0017156565954792313, Final Batch Loss: 0.0009969250531867146\n",
      "Epoch 1681, Loss: 0.001573291840031743, Final Batch Loss: 0.0005065436125732958\n",
      "Epoch 1682, Loss: 0.0018844466540031135, Final Batch Loss: 4.0322309359908104e-05\n",
      "Epoch 1683, Loss: 0.003369508049217984, Final Batch Loss: 0.0015685500111430883\n",
      "Epoch 1684, Loss: 0.0020124512229813263, Final Batch Loss: 0.00023856181360315531\n",
      "Epoch 1685, Loss: 0.0009450506258872338, Final Batch Loss: 0.00048226615763269365\n",
      "Epoch 1686, Loss: 0.0016075618914328516, Final Batch Loss: 0.0006522145122289658\n",
      "Epoch 1687, Loss: 0.004134329908993095, Final Batch Loss: 0.00027833759668283165\n",
      "Epoch 1688, Loss: 0.002812994731357321, Final Batch Loss: 0.0004476156609598547\n",
      "Epoch 1689, Loss: 0.0013030878908466548, Final Batch Loss: 0.00030095333931967616\n",
      "Epoch 1690, Loss: 0.0010375532037869561, Final Batch Loss: 3.867423583869822e-05\n",
      "Epoch 1691, Loss: 0.0035722182219615206, Final Batch Loss: 0.000577985483687371\n",
      "Epoch 1692, Loss: 0.01602843611181015, Final Batch Loss: 0.00010013420978793874\n",
      "Epoch 1693, Loss: 0.013738629291765392, Final Batch Loss: 0.0009732910548336804\n",
      "Epoch 1694, Loss: 0.004864252347033471, Final Batch Loss: 0.0002317923936061561\n",
      "Epoch 1695, Loss: 0.009755460196174681, Final Batch Loss: 0.00940666999667883\n",
      "Epoch 1696, Loss: 0.0013247510069049895, Final Batch Loss: 0.00039697650936432183\n",
      "Epoch 1697, Loss: 0.004592060504364781, Final Batch Loss: 0.0037937043234705925\n",
      "Epoch 1698, Loss: 0.006190258794958936, Final Batch Loss: 3.901894160662778e-05\n",
      "Epoch 1699, Loss: 0.0008795327321422519, Final Batch Loss: 2.609913826745469e-05\n",
      "Epoch 1700, Loss: 0.0024505542824044824, Final Batch Loss: 0.000347101129591465\n",
      "Epoch 1701, Loss: 0.009223380431649275, Final Batch Loss: 0.0004581937100738287\n",
      "Epoch 1702, Loss: 0.003948889789171517, Final Batch Loss: 0.0007671677158214152\n",
      "Epoch 1703, Loss: 0.0014431670279009268, Final Batch Loss: 0.0008281070622615516\n",
      "Epoch 1704, Loss: 0.0025492407439742237, Final Batch Loss: 0.0002593814569991082\n",
      "Epoch 1705, Loss: 0.0007844132924219593, Final Batch Loss: 0.00020857766503468156\n",
      "Epoch 1706, Loss: 0.0014266123544075526, Final Batch Loss: 5.053095082985237e-05\n",
      "Epoch 1707, Loss: 0.003389138844795525, Final Batch Loss: 0.0006461968878284097\n",
      "Epoch 1708, Loss: 0.0018656306638149545, Final Batch Loss: 0.0005951013299636543\n",
      "Epoch 1709, Loss: 0.0009912080422509462, Final Batch Loss: 0.00017227699572686106\n",
      "Epoch 1710, Loss: 0.012118003047362436, Final Batch Loss: 5.885098653379828e-05\n",
      "Epoch 1711, Loss: 0.0013576512938016094, Final Batch Loss: 2.92911208816804e-05\n",
      "Epoch 1712, Loss: 0.0015868633927311748, Final Batch Loss: 0.00017974904039874673\n",
      "Epoch 1713, Loss: 0.005612658453173935, Final Batch Loss: 0.0011239700252190232\n",
      "Epoch 1714, Loss: 0.004712449313956313, Final Batch Loss: 0.0002854490012396127\n",
      "Epoch 1715, Loss: 0.0026960869145113975, Final Batch Loss: 0.00029271087259985507\n",
      "Epoch 1716, Loss: 0.009731213562190533, Final Batch Loss: 0.0028744805604219437\n",
      "Epoch 1717, Loss: 0.009736346633872017, Final Batch Loss: 0.009221783839166164\n",
      "Epoch 1718, Loss: 0.02004032675176859, Final Batch Loss: 0.01896263100206852\n",
      "Epoch 1719, Loss: 0.021176938826101832, Final Batch Loss: 0.004706642124801874\n",
      "Epoch 1720, Loss: 0.001860186122939922, Final Batch Loss: 0.0004901669453829527\n",
      "Epoch 1721, Loss: 0.0013169493759050965, Final Batch Loss: 0.0003928229562006891\n",
      "Epoch 1722, Loss: 0.0014095549995545298, Final Batch Loss: 0.0004382453626021743\n",
      "Epoch 1723, Loss: 0.0008576110558351502, Final Batch Loss: 9.556213626638055e-05\n",
      "Epoch 1724, Loss: 0.0012249323190189898, Final Batch Loss: 0.00015914769028313458\n",
      "Epoch 1725, Loss: 0.033495919284177944, Final Batch Loss: 0.0017884053522720933\n",
      "Epoch 1726, Loss: 0.009714283456560224, Final Batch Loss: 0.0007153450860641897\n",
      "Epoch 1727, Loss: 0.019154312016326003, Final Batch Loss: 7.982288661878556e-05\n",
      "Epoch 1728, Loss: 0.00111883576028049, Final Batch Loss: 0.0003282766556367278\n",
      "Epoch 1729, Loss: 0.0011843225511256605, Final Batch Loss: 0.00033004698343575\n",
      "Epoch 1730, Loss: 0.03058216642239131, Final Batch Loss: 0.0003853524394799024\n",
      "Epoch 1731, Loss: 0.004256578758941032, Final Batch Loss: 0.0006649037241004407\n",
      "Epoch 1732, Loss: 0.02053462585899979, Final Batch Loss: 0.0195805411785841\n",
      "Epoch 1733, Loss: 0.009008218941744417, Final Batch Loss: 0.005933713633567095\n",
      "Epoch 1734, Loss: 0.0015953004185575992, Final Batch Loss: 0.0004026282695122063\n",
      "Epoch 1735, Loss: 0.004962329578120261, Final Batch Loss: 0.002139734337106347\n",
      "Epoch 1736, Loss: 0.006511099694762379, Final Batch Loss: 0.0004865592927671969\n",
      "Epoch 1737, Loss: 0.002835868683177978, Final Batch Loss: 0.0020632119849324226\n",
      "Epoch 1738, Loss: 0.012108298717066646, Final Batch Loss: 0.009434514679014683\n",
      "Epoch 1739, Loss: 0.04277731878391933, Final Batch Loss: 7.72453349782154e-05\n",
      "Epoch 1740, Loss: 0.00680821540299803, Final Batch Loss: 0.004271321929991245\n",
      "Epoch 1741, Loss: 0.0022150554577820003, Final Batch Loss: 0.00023832934675738215\n",
      "Epoch 1742, Loss: 0.0023737371375318617, Final Batch Loss: 0.0010718033881857991\n",
      "Epoch 1743, Loss: 0.056134749873308465, Final Batch Loss: 0.00030006581800989807\n",
      "Epoch 1744, Loss: 0.0038028997951187193, Final Batch Loss: 0.0006955710123293102\n",
      "Epoch 1745, Loss: 0.013422178504697513, Final Batch Loss: 0.0012800974072888494\n",
      "Epoch 1746, Loss: 0.0021443151053972542, Final Batch Loss: 0.0006631619762629271\n",
      "Epoch 1747, Loss: 0.003782349464017898, Final Batch Loss: 0.0010029817931354046\n",
      "Epoch 1748, Loss: 0.004499150498304516, Final Batch Loss: 0.003368319943547249\n",
      "Epoch 1749, Loss: 0.002617888145323377, Final Batch Loss: 0.0005613997927866876\n",
      "Epoch 1750, Loss: 0.003457581187831238, Final Batch Loss: 0.0003099973837379366\n",
      "Epoch 1751, Loss: 0.002722710953094065, Final Batch Loss: 0.000853376230224967\n",
      "Epoch 1752, Loss: 0.007191108772531152, Final Batch Loss: 0.003329657018184662\n",
      "Epoch 1753, Loss: 0.003635614411905408, Final Batch Loss: 0.0009662611992098391\n",
      "Epoch 1754, Loss: 0.0019667255401145667, Final Batch Loss: 0.0013272512005642056\n",
      "Epoch 1755, Loss: 0.006910099065862596, Final Batch Loss: 0.005264367442578077\n",
      "Epoch 1756, Loss: 0.0004878243380517233, Final Batch Loss: 5.8096822613151744e-05\n",
      "Epoch 1757, Loss: 0.0029232929227873683, Final Batch Loss: 0.0005241273320280015\n",
      "Epoch 1758, Loss: 0.003440990694798529, Final Batch Loss: 0.0004553749458864331\n",
      "Epoch 1759, Loss: 0.022089438745751977, Final Batch Loss: 0.000727804028429091\n",
      "Epoch 1760, Loss: 0.001360935901175253, Final Batch Loss: 0.00021751124586444348\n",
      "Epoch 1761, Loss: 0.003068530568270944, Final Batch Loss: 0.0004379708843771368\n",
      "Epoch 1762, Loss: 0.001334449763817247, Final Batch Loss: 2.5616689526941627e-05\n",
      "Epoch 1763, Loss: 0.0039421055116690695, Final Batch Loss: 0.002582389395684004\n",
      "Epoch 1764, Loss: 0.02928399726806674, Final Batch Loss: 6.605139060411602e-05\n",
      "Epoch 1765, Loss: 0.0025961936626117676, Final Batch Loss: 0.00032582934363745153\n",
      "Epoch 1766, Loss: 0.0030172163096722215, Final Batch Loss: 0.0012370377080515027\n",
      "Epoch 1767, Loss: 0.007353347726166248, Final Batch Loss: 0.005438519641757011\n",
      "Epoch 1768, Loss: 0.004023353649245109, Final Batch Loss: 9.845531167229638e-05\n",
      "Epoch 1769, Loss: 0.0024686593242222443, Final Batch Loss: 0.0005480396212078631\n",
      "Epoch 1770, Loss: 0.00892107916297391, Final Batch Loss: 0.0004318228457123041\n",
      "Epoch 1771, Loss: 0.0016424960922449827, Final Batch Loss: 0.0005635268171317875\n",
      "Epoch 1772, Loss: 0.0029876895423512906, Final Batch Loss: 0.0010682997526600957\n",
      "Epoch 1773, Loss: 0.003906227444531396, Final Batch Loss: 0.0005502479034475982\n",
      "Epoch 1774, Loss: 0.012731331516988575, Final Batch Loss: 0.0007348493672907352\n",
      "Epoch 1775, Loss: 0.0012580674228956923, Final Batch Loss: 0.0001884507219074294\n",
      "Epoch 1776, Loss: 0.0007623966957908124, Final Batch Loss: 7.754444959573448e-05\n",
      "Epoch 1777, Loss: 0.0008043408015510067, Final Batch Loss: 0.0003500895982142538\n",
      "Epoch 1778, Loss: 0.0056286120088770986, Final Batch Loss: 0.004373075906187296\n",
      "Epoch 1779, Loss: 0.0009091435422305949, Final Batch Loss: 7.665559678571299e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1780, Loss: 0.006791347113903612, Final Batch Loss: 0.0046644387766718864\n",
      "Epoch 1781, Loss: 0.001545335428090766, Final Batch Loss: 0.0004153722838964313\n",
      "Epoch 1782, Loss: 0.013284692744491622, Final Batch Loss: 0.00027104897890239954\n",
      "Epoch 1783, Loss: 0.006011802644934505, Final Batch Loss: 0.0008081154664978385\n",
      "Epoch 1784, Loss: 0.003929170197807252, Final Batch Loss: 0.00049092888366431\n",
      "Epoch 1785, Loss: 0.008419732446782291, Final Batch Loss: 0.0012575178407132626\n",
      "Epoch 1786, Loss: 0.0029309595411177725, Final Batch Loss: 0.000526878226082772\n",
      "Epoch 1787, Loss: 0.004093405150342733, Final Batch Loss: 0.0011199910659343004\n",
      "Epoch 1788, Loss: 0.005690090300049633, Final Batch Loss: 0.0046159359626472\n",
      "Epoch 1789, Loss: 0.004420149401994422, Final Batch Loss: 0.0004256544925738126\n",
      "Epoch 1790, Loss: 0.0009752085352374706, Final Batch Loss: 3.186596222803928e-05\n",
      "Epoch 1791, Loss: 0.007050243497360498, Final Batch Loss: 0.0006721718818880618\n",
      "Epoch 1792, Loss: 0.005092358565889299, Final Batch Loss: 0.004762384109199047\n",
      "Epoch 1793, Loss: 0.005305576501996256, Final Batch Loss: 0.00010653595381882042\n",
      "Epoch 1794, Loss: 0.020670651807449758, Final Batch Loss: 0.01685291714966297\n",
      "Epoch 1795, Loss: 0.004217536261421628, Final Batch Loss: 0.0036943776067346334\n",
      "Epoch 1796, Loss: 0.016158520462340675, Final Batch Loss: 0.00012353922647889704\n",
      "Epoch 1797, Loss: 0.07646371610462666, Final Batch Loss: 0.036126501858234406\n",
      "Epoch 1798, Loss: 0.0008803284581517801, Final Batch Loss: 0.0002749442937783897\n",
      "Epoch 1799, Loss: 0.01762562800286105, Final Batch Loss: 0.013102918863296509\n",
      "Epoch 1800, Loss: 0.006379323021974415, Final Batch Loss: 0.0019269440090283751\n",
      "Epoch 1801, Loss: 0.01634877611650154, Final Batch Loss: 0.008526505902409554\n",
      "Epoch 1802, Loss: 0.004942674026096938, Final Batch Loss: 5.3292209486244246e-05\n",
      "Epoch 1803, Loss: 0.01692843291675672, Final Batch Loss: 0.0002643835614435375\n",
      "Epoch 1804, Loss: 0.007146231015212834, Final Batch Loss: 0.001892959582619369\n",
      "Epoch 1805, Loss: 0.012102070031687617, Final Batch Loss: 0.0009244338143616915\n",
      "Epoch 1806, Loss: 0.0016948239936027676, Final Batch Loss: 0.0004165460413787514\n",
      "Epoch 1807, Loss: 0.014809614513069391, Final Batch Loss: 0.0053279465064406395\n",
      "Epoch 1808, Loss: 0.002359465026529506, Final Batch Loss: 0.0013540317304432392\n",
      "Epoch 1809, Loss: 0.052114518999587744, Final Batch Loss: 0.04965241998434067\n",
      "Epoch 1810, Loss: 0.004060514911543578, Final Batch Loss: 0.0009329782333225012\n",
      "Epoch 1811, Loss: 0.001442415508790873, Final Batch Loss: 0.0004413392161950469\n",
      "Epoch 1812, Loss: 0.005770128802396357, Final Batch Loss: 0.000256227096542716\n",
      "Epoch 1813, Loss: 0.0016918738256208599, Final Batch Loss: 0.0007406608201563358\n",
      "Epoch 1814, Loss: 0.005925965844653547, Final Batch Loss: 0.0017546056769788265\n",
      "Epoch 1815, Loss: 0.0011901403486263007, Final Batch Loss: 5.4261909099295735e-05\n",
      "Epoch 1816, Loss: 0.017926292959600687, Final Batch Loss: 0.0013694984372705221\n",
      "Epoch 1817, Loss: 0.0020207709167152643, Final Batch Loss: 0.0004427731328178197\n",
      "Epoch 1818, Loss: 0.0111961493275885, Final Batch Loss: 5.1240484026493505e-05\n",
      "Epoch 1819, Loss: 0.001948415330844, Final Batch Loss: 0.0002355918986722827\n",
      "Epoch 1820, Loss: 0.001449625677196309, Final Batch Loss: 0.0002645833301357925\n",
      "Epoch 1821, Loss: 0.020386633288580924, Final Batch Loss: 0.0005249003297649324\n",
      "Epoch 1822, Loss: 0.0015192222781479359, Final Batch Loss: 0.0004561991663649678\n",
      "Epoch 1823, Loss: 0.0025048160750884563, Final Batch Loss: 0.0003167099494021386\n",
      "Epoch 1824, Loss: 0.0025296733947470784, Final Batch Loss: 0.00045411998871713877\n",
      "Epoch 1825, Loss: 0.001153809716925025, Final Batch Loss: 0.00028479070169851184\n",
      "Epoch 1826, Loss: 0.007680210081161931, Final Batch Loss: 0.00048744844389148057\n",
      "Epoch 1827, Loss: 0.002803441500873305, Final Batch Loss: 9.106677316594869e-05\n",
      "Epoch 1828, Loss: 0.003647239413112402, Final Batch Loss: 0.002094302559271455\n",
      "Epoch 1829, Loss: 0.001491136004915461, Final Batch Loss: 0.00035328546073287725\n",
      "Epoch 1830, Loss: 0.0018180016850237735, Final Batch Loss: 6.94476839271374e-05\n",
      "Epoch 1831, Loss: 0.002489867474650964, Final Batch Loss: 0.0004583658592309803\n",
      "Epoch 1832, Loss: 0.0016554612666368484, Final Batch Loss: 0.0007270791102200747\n",
      "Epoch 1833, Loss: 0.0019219783061998896, Final Batch Loss: 9.060790034709498e-05\n",
      "Epoch 1834, Loss: 0.001093679791665636, Final Batch Loss: 0.0005511029739864171\n",
      "Epoch 1835, Loss: 0.0057943006249843165, Final Batch Loss: 0.0001764736807672307\n",
      "Epoch 1836, Loss: 0.0029588378965854645, Final Batch Loss: 0.0013840609462931752\n",
      "Epoch 1837, Loss: 0.001311154235736467, Final Batch Loss: 0.0001510621077613905\n",
      "Epoch 1838, Loss: 0.0012930025986861438, Final Batch Loss: 0.00023733635316602886\n",
      "Epoch 1839, Loss: 0.0033499980927444994, Final Batch Loss: 0.00040354131488129497\n",
      "Epoch 1840, Loss: 0.0012994343269383535, Final Batch Loss: 0.0002874858910217881\n",
      "Epoch 1841, Loss: 0.003604738099966198, Final Batch Loss: 0.0008308922406286001\n",
      "Epoch 1842, Loss: 0.0011473371196188964, Final Batch Loss: 6.585784285562113e-05\n",
      "Epoch 1843, Loss: 0.01673486444633454, Final Batch Loss: 0.0015159555478021502\n",
      "Epoch 1844, Loss: 0.0027725405525416136, Final Batch Loss: 0.002454417524859309\n",
      "Epoch 1845, Loss: 0.00037965735100442544, Final Batch Loss: 0.00017763454525265843\n",
      "Epoch 1846, Loss: 0.0007136484346119687, Final Batch Loss: 7.325902697630227e-05\n",
      "Epoch 1847, Loss: 0.0026502022628847044, Final Batch Loss: 0.0003432772937230766\n",
      "Epoch 1848, Loss: 0.0011309131077723578, Final Batch Loss: 9.830770432017744e-05\n",
      "Epoch 1849, Loss: 0.003041663789190352, Final Batch Loss: 0.0010660028783604503\n",
      "Epoch 1850, Loss: 0.0026899531949311495, Final Batch Loss: 0.0019511242862790823\n",
      "Epoch 1851, Loss: 0.00585401666467078, Final Batch Loss: 0.00046185165410861373\n",
      "Epoch 1852, Loss: 0.0026084856799570844, Final Batch Loss: 0.00015277473721653223\n",
      "Epoch 1853, Loss: 0.0010142363316845149, Final Batch Loss: 0.0003223100211471319\n",
      "Epoch 1854, Loss: 0.0019328133930684999, Final Batch Loss: 0.0001301208249060437\n",
      "Epoch 1855, Loss: 0.0020318290044087917, Final Batch Loss: 0.0003532553091645241\n",
      "Epoch 1856, Loss: 0.005768961611465784, Final Batch Loss: 5.3243176807882264e-05\n",
      "Epoch 1857, Loss: 0.0049144895892823115, Final Batch Loss: 0.00011899486707989126\n",
      "Epoch 1858, Loss: 0.0030322367092594504, Final Batch Loss: 0.00013415125431492925\n",
      "Epoch 1859, Loss: 0.006777016329579055, Final Batch Loss: 0.00105897372122854\n",
      "Epoch 1860, Loss: 0.0014881787647027522, Final Batch Loss: 0.0002899177197832614\n",
      "Epoch 1861, Loss: 0.00208935124828713, Final Batch Loss: 4.329079092713073e-05\n",
      "Epoch 1862, Loss: 0.004953310541168321, Final Batch Loss: 0.004636191762983799\n",
      "Epoch 1863, Loss: 0.005982400587527081, Final Batch Loss: 0.005195586010813713\n",
      "Epoch 1864, Loss: 0.00418869437999092, Final Batch Loss: 0.0012301465030759573\n",
      "Epoch 1865, Loss: 0.00259464155533351, Final Batch Loss: 0.00025029698736034334\n",
      "Epoch 1866, Loss: 0.02296339930035174, Final Batch Loss: 0.020651381462812424\n",
      "Epoch 1867, Loss: 0.002426320188533282, Final Batch Loss: 5.379339199862443e-05\n",
      "Epoch 1868, Loss: 0.007701254915446043, Final Batch Loss: 0.0033298961352556944\n",
      "Epoch 1869, Loss: 0.0010098420243593864, Final Batch Loss: 0.0005001601530238986\n",
      "Epoch 1870, Loss: 0.011233781813643873, Final Batch Loss: 0.006364026572555304\n",
      "Epoch 1871, Loss: 0.02866234749672003, Final Batch Loss: 0.00027487732586450875\n",
      "Epoch 1872, Loss: 0.002403067672275938, Final Batch Loss: 0.00011746957898139954\n",
      "Epoch 1873, Loss: 0.0162277469644323, Final Batch Loss: 0.015204072929918766\n",
      "Epoch 1874, Loss: 0.008670522598549724, Final Batch Loss: 0.0006503603653982282\n",
      "Epoch 1875, Loss: 0.0008262415867648087, Final Batch Loss: 0.00022093365259934217\n",
      "Epoch 1876, Loss: 0.0012389642652124166, Final Batch Loss: 0.00042344979010522366\n",
      "Epoch 1877, Loss: 0.022762854743632488, Final Batch Loss: 0.0001595946232555434\n",
      "Epoch 1878, Loss: 0.032398393228504574, Final Batch Loss: 4.5247343223309144e-05\n",
      "Epoch 1879, Loss: 0.0015128634549910203, Final Batch Loss: 0.0011200373992323875\n",
      "Epoch 1880, Loss: 0.004901049847831018, Final Batch Loss: 0.004495385568588972\n",
      "Epoch 1881, Loss: 0.005525236694666091, Final Batch Loss: 0.0012639386113733053\n",
      "Epoch 1882, Loss: 0.0004107723507331684, Final Batch Loss: 4.5948661863803864e-05\n",
      "Epoch 1883, Loss: 0.009220741914759856, Final Batch Loss: 4.768440703628585e-05\n",
      "Epoch 1884, Loss: 0.0011035485804313794, Final Batch Loss: 0.000310895120492205\n",
      "Epoch 1885, Loss: 0.01418733160244301, Final Batch Loss: 0.000915209820959717\n",
      "Epoch 1886, Loss: 0.0014770460838917643, Final Batch Loss: 0.0005189591902308166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1887, Loss: 0.00041490056173643097, Final Batch Loss: 6.832375220255926e-05\n",
      "Epoch 1888, Loss: 0.002815059939166531, Final Batch Loss: 0.0021313088946044445\n",
      "Epoch 1889, Loss: 0.006039666972355917, Final Batch Loss: 0.0007294427487067878\n",
      "Epoch 1890, Loss: 0.004746699676616117, Final Batch Loss: 0.0030378177762031555\n",
      "Epoch 1891, Loss: 0.0005157873820280656, Final Batch Loss: 0.00022363790776580572\n",
      "Epoch 1892, Loss: 0.0024247915716841817, Final Batch Loss: 0.00029154986259527504\n",
      "Epoch 1893, Loss: 0.003478195343632251, Final Batch Loss: 0.002218453912064433\n",
      "Epoch 1894, Loss: 0.003339388596941717, Final Batch Loss: 0.00272490200586617\n",
      "Epoch 1895, Loss: 0.0022916396483196877, Final Batch Loss: 0.0020372439175844193\n",
      "Epoch 1896, Loss: 0.0013479595654644072, Final Batch Loss: 0.00031274298089556396\n",
      "Epoch 1897, Loss: 0.0033032575738616288, Final Batch Loss: 0.0005820714286528528\n",
      "Epoch 1898, Loss: 0.005210461065871641, Final Batch Loss: 0.0003121480986010283\n",
      "Epoch 1899, Loss: 0.0318731285224203, Final Batch Loss: 0.007466951385140419\n",
      "Epoch 1900, Loss: 0.003349567428813316, Final Batch Loss: 0.002545425435528159\n",
      "Epoch 1901, Loss: 0.0017412391462130472, Final Batch Loss: 0.00020753723219968379\n",
      "Epoch 1902, Loss: 0.0029000962676946074, Final Batch Loss: 0.00035034422762691975\n",
      "Epoch 1903, Loss: 0.0011034007402486168, Final Batch Loss: 0.00041452786535955966\n",
      "Epoch 1904, Loss: 0.00031560721254209056, Final Batch Loss: 6.062839020160027e-05\n",
      "Epoch 1905, Loss: 0.01759312441572547, Final Batch Loss: 0.00519615039229393\n",
      "Epoch 1906, Loss: 0.00401512230746448, Final Batch Loss: 0.0004363183106761426\n",
      "Epoch 1907, Loss: 0.001295005582505837, Final Batch Loss: 0.0004374747513793409\n",
      "Epoch 1908, Loss: 0.002263278525788337, Final Batch Loss: 0.0010503308149054646\n",
      "Epoch 1909, Loss: 0.004564630231470801, Final Batch Loss: 0.00011643495236057788\n",
      "Epoch 1910, Loss: 0.0011582629158510827, Final Batch Loss: 0.0010343152098357677\n",
      "Epoch 1911, Loss: 0.0011458124499768019, Final Batch Loss: 0.0001555943163111806\n",
      "Epoch 1912, Loss: 0.0028313149232417345, Final Batch Loss: 7.99068802734837e-05\n",
      "Epoch 1913, Loss: 0.002257382991956547, Final Batch Loss: 0.0013713338412344456\n",
      "Epoch 1914, Loss: 0.002341008061193861, Final Batch Loss: 0.0018860193667933345\n",
      "Epoch 1915, Loss: 0.0028729358709824737, Final Batch Loss: 5.196737402002327e-05\n",
      "Epoch 1916, Loss: 0.0010685225570341572, Final Batch Loss: 0.0002506960881873965\n",
      "Epoch 1917, Loss: 0.0021176238951738924, Final Batch Loss: 0.000627119792625308\n",
      "Epoch 1918, Loss: 0.0005800904909847304, Final Batch Loss: 8.26243485789746e-05\n",
      "Epoch 1919, Loss: 0.0008533721083949786, Final Batch Loss: 5.5646607506787404e-05\n",
      "Epoch 1920, Loss: 0.0312916872499045, Final Batch Loss: 0.00016657295054756105\n",
      "Epoch 1921, Loss: 0.0044666503163171, Final Batch Loss: 0.001132846693508327\n",
      "Epoch 1922, Loss: 0.002957616830826737, Final Batch Loss: 0.0002049051836365834\n",
      "Epoch 1923, Loss: 0.0020385897951200604, Final Batch Loss: 0.0005255602882243693\n",
      "Epoch 1924, Loss: 0.003210107381164562, Final Batch Loss: 7.98150067566894e-05\n",
      "Epoch 1925, Loss: 0.0015888605266809464, Final Batch Loss: 0.0006609330303035676\n",
      "Epoch 1926, Loss: 0.0009998829091273365, Final Batch Loss: 1.4132591786619741e-05\n",
      "Epoch 1927, Loss: 0.028017167562211398, Final Batch Loss: 0.021157370880246162\n",
      "Epoch 1928, Loss: 0.011592225753702223, Final Batch Loss: 0.008627303875982761\n",
      "Epoch 1929, Loss: 0.003458735045569483, Final Batch Loss: 0.00010251565981889144\n",
      "Epoch 1930, Loss: 0.009756984742125496, Final Batch Loss: 0.0002720011107157916\n",
      "Epoch 1931, Loss: 0.0033440164697822183, Final Batch Loss: 0.000675333954859525\n",
      "Epoch 1932, Loss: 0.002143593861546833, Final Batch Loss: 0.00016289840277750045\n",
      "Epoch 1933, Loss: 0.005582002442679368, Final Batch Loss: 0.000225527081056498\n",
      "Epoch 1934, Loss: 0.015627784829121083, Final Batch Loss: 6.258528446778655e-05\n",
      "Epoch 1935, Loss: 0.000871379699674435, Final Batch Loss: 0.0001275800896110013\n",
      "Epoch 1936, Loss: 0.002612684853374958, Final Batch Loss: 0.0006435568793676794\n",
      "Epoch 1937, Loss: 0.005728615331463516, Final Batch Loss: 0.0017601912841200829\n",
      "Epoch 1938, Loss: 0.017481049639172852, Final Batch Loss: 0.006486201658844948\n",
      "Epoch 1939, Loss: 0.005242126586381346, Final Batch Loss: 0.0029169381596148014\n",
      "Epoch 1940, Loss: 0.0017290602263528854, Final Batch Loss: 0.0004992559552192688\n",
      "Epoch 1941, Loss: 0.0029220175347290933, Final Batch Loss: 0.00017313208081759512\n",
      "Epoch 1942, Loss: 0.0034845656191464514, Final Batch Loss: 0.000188106409041211\n",
      "Epoch 1943, Loss: 0.004213127293041907, Final Batch Loss: 0.00021918384300079197\n",
      "Epoch 1944, Loss: 0.0037657526991097257, Final Batch Loss: 0.0006998592289164662\n",
      "Epoch 1945, Loss: 0.028831569346948527, Final Batch Loss: 0.028231756761670113\n",
      "Epoch 1946, Loss: 0.0009572068011038937, Final Batch Loss: 9.697103087091818e-05\n",
      "Epoch 1947, Loss: 0.002405010221991688, Final Batch Loss: 0.00037078626337461174\n",
      "Epoch 1948, Loss: 0.030861145392918843, Final Batch Loss: 1.9107987100142054e-05\n",
      "Epoch 1949, Loss: 0.0009005820174934343, Final Batch Loss: 0.00028908971580676734\n",
      "Epoch 1950, Loss: 0.005230600669165142, Final Batch Loss: 0.0023957251105457544\n",
      "Epoch 1951, Loss: 0.003049119928618893, Final Batch Loss: 0.0004536817141342908\n",
      "Epoch 1952, Loss: 0.0004079215577803552, Final Batch Loss: 0.0002718745090533048\n",
      "Epoch 1953, Loss: 0.05714887619251385, Final Batch Loss: 0.04037242755293846\n",
      "Epoch 1954, Loss: 0.015241491542838048, Final Batch Loss: 0.00011926801380468532\n",
      "Epoch 1955, Loss: 0.012052743055392057, Final Batch Loss: 0.00027006311574950814\n",
      "Epoch 1956, Loss: 0.0024543292383896187, Final Batch Loss: 0.000148307197378017\n",
      "Epoch 1957, Loss: 0.0014144968299660832, Final Batch Loss: 0.00011244603956583887\n",
      "Epoch 1958, Loss: 0.0015197669708868489, Final Batch Loss: 0.0004722727171611041\n",
      "Epoch 1959, Loss: 0.0018255134345963597, Final Batch Loss: 0.0009611928253434598\n",
      "Epoch 1960, Loss: 0.002424390142550692, Final Batch Loss: 9.13403055164963e-05\n",
      "Epoch 1961, Loss: 0.0012755634852510411, Final Batch Loss: 4.1077688365476206e-05\n",
      "Epoch 1962, Loss: 0.00895476748701185, Final Batch Loss: 0.006867586635053158\n",
      "Epoch 1963, Loss: 0.003820533398538828, Final Batch Loss: 0.0018574760761111975\n",
      "Epoch 1964, Loss: 0.011178684246260673, Final Batch Loss: 0.0036896690726280212\n",
      "Epoch 1965, Loss: 0.001430477568646893, Final Batch Loss: 0.0007026079692877829\n",
      "Epoch 1966, Loss: 0.006520249444292858, Final Batch Loss: 0.00017462423420511186\n",
      "Epoch 1967, Loss: 0.005346476740669459, Final Batch Loss: 0.0038360506296157837\n",
      "Epoch 1968, Loss: 0.004504221375100315, Final Batch Loss: 0.0038630871567875147\n",
      "Epoch 1969, Loss: 0.003309205138066318, Final Batch Loss: 6.645189569098875e-05\n",
      "Epoch 1970, Loss: 0.006377811194397509, Final Batch Loss: 0.000864763162098825\n",
      "Epoch 1971, Loss: 0.002340465667657554, Final Batch Loss: 0.0004955421900376678\n",
      "Epoch 1972, Loss: 0.005084320087917149, Final Batch Loss: 0.0012491099769249558\n",
      "Epoch 1973, Loss: 0.0030775221530348063, Final Batch Loss: 0.0009076095884665847\n",
      "Epoch 1974, Loss: 0.0037671072350349277, Final Batch Loss: 0.0005687896045856178\n",
      "Epoch 1975, Loss: 0.00499954164843075, Final Batch Loss: 0.00016219003009609878\n",
      "Epoch 1976, Loss: 0.010690952825825661, Final Batch Loss: 0.0007679085829295218\n",
      "Epoch 1977, Loss: 0.010035304992925376, Final Batch Loss: 0.0007073308224789798\n",
      "Epoch 1978, Loss: 0.0027878200344275683, Final Batch Loss: 0.00035415482125245035\n",
      "Epoch 1979, Loss: 0.025715107505675405, Final Batch Loss: 0.00011283723870292306\n",
      "Epoch 1980, Loss: 0.0014198190910974517, Final Batch Loss: 0.00017317057063337415\n",
      "Epoch 1981, Loss: 0.003663394869363401, Final Batch Loss: 8.571139915147796e-05\n",
      "Epoch 1982, Loss: 0.0021640682534780353, Final Batch Loss: 0.00025335600366815925\n",
      "Epoch 1983, Loss: 0.0009455618856009096, Final Batch Loss: 0.00020181651052553207\n",
      "Epoch 1984, Loss: 0.006418598466552794, Final Batch Loss: 0.004993021488189697\n",
      "Epoch 1985, Loss: 0.0021127106592757627, Final Batch Loss: 7.602809637319297e-05\n",
      "Epoch 1986, Loss: 0.004696193631389178, Final Batch Loss: 0.00018484263273421675\n",
      "Epoch 1987, Loss: 0.0017237542488146573, Final Batch Loss: 0.000327922694850713\n",
      "Epoch 1988, Loss: 0.0016775751719251275, Final Batch Loss: 0.0008256460423581302\n",
      "Epoch 1989, Loss: 0.001796899692635634, Final Batch Loss: 2.0563000362017192e-05\n",
      "Epoch 1990, Loss: 0.0032553730270592496, Final Batch Loss: 0.00015413608343806118\n",
      "Epoch 1991, Loss: 0.001611506988410838, Final Batch Loss: 0.0006392149371095002\n",
      "Epoch 1992, Loss: 0.0024231349234469235, Final Batch Loss: 0.0012886014301329851\n",
      "Epoch 1993, Loss: 0.0030152203689794987, Final Batch Loss: 0.000355924159521237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1994, Loss: 0.002747600548900664, Final Batch Loss: 3.7012185202911496e-05\n",
      "Epoch 1995, Loss: 0.0016432706615887582, Final Batch Loss: 0.00032422394724562764\n",
      "Epoch 1996, Loss: 0.03667955528362654, Final Batch Loss: 4.1503546526655555e-05\n",
      "Epoch 1997, Loss: 0.002285294816829264, Final Batch Loss: 0.0004771361709572375\n",
      "Epoch 1998, Loss: 0.006208966413396411, Final Batch Loss: 0.00018868948973249644\n",
      "Epoch 1999, Loss: 0.02170651371125132, Final Batch Loss: 0.00019680231343954802\n",
      "Epoch 2000, Loss: 0.00827351193584036, Final Batch Loss: 2.4236083845607936e-05\n",
      "Epoch 2001, Loss: 0.007255490723764524, Final Batch Loss: 0.0039017214439809322\n",
      "Epoch 2002, Loss: 0.00186083086009603, Final Batch Loss: 3.156145612592809e-05\n",
      "Epoch 2003, Loss: 0.0023113812203519046, Final Batch Loss: 0.0005438849912025034\n",
      "Epoch 2004, Loss: 0.0004177258088020608, Final Batch Loss: 6.962803308852017e-05\n",
      "Epoch 2005, Loss: 0.002685642393771559, Final Batch Loss: 0.0017082510748878121\n",
      "Epoch 2006, Loss: 0.004052468721056357, Final Batch Loss: 0.0001558759540785104\n",
      "Epoch 2007, Loss: 0.0010561794115346856, Final Batch Loss: 0.00010926355753326789\n",
      "Epoch 2008, Loss: 0.004536343847576063, Final Batch Loss: 8.068410534178838e-05\n",
      "Epoch 2009, Loss: 0.00868904049275443, Final Batch Loss: 0.00639288080856204\n",
      "Epoch 2010, Loss: 0.005732041812734678, Final Batch Loss: 0.004704452119767666\n",
      "Epoch 2011, Loss: 0.002784420699754264, Final Batch Loss: 9.27637520362623e-05\n",
      "Epoch 2012, Loss: 0.0016374432889278978, Final Batch Loss: 0.0007073252345435321\n",
      "Epoch 2013, Loss: 0.0007345811754930764, Final Batch Loss: 0.00023541580594610423\n",
      "Epoch 2014, Loss: 0.00170229678042233, Final Batch Loss: 0.0009119543246924877\n",
      "Epoch 2015, Loss: 0.0006649161769018974, Final Batch Loss: 0.0004375717544462532\n",
      "Epoch 2016, Loss: 0.000534007944224868, Final Batch Loss: 5.348695412976667e-05\n",
      "Epoch 2017, Loss: 0.0015964088961482048, Final Batch Loss: 0.0005541483988054097\n",
      "Epoch 2018, Loss: 0.0014303397620096803, Final Batch Loss: 0.0005999984568916261\n",
      "Epoch 2019, Loss: 0.0026022344100056216, Final Batch Loss: 0.0001586416328791529\n",
      "Epoch 2020, Loss: 0.00037124006848898716, Final Batch Loss: 0.00012076253187842667\n",
      "Epoch 2021, Loss: 0.004074536700500175, Final Batch Loss: 0.0003148454416077584\n",
      "Epoch 2022, Loss: 0.0020483589614741504, Final Batch Loss: 0.0010609058663249016\n",
      "Epoch 2023, Loss: 0.002378908742684871, Final Batch Loss: 0.0005024769925512373\n",
      "Epoch 2024, Loss: 0.007486194255761802, Final Batch Loss: 0.004184050019830465\n",
      "Epoch 2025, Loss: 0.011895002964593004, Final Batch Loss: 0.011650134809315205\n",
      "Epoch 2026, Loss: 0.00030574301490560174, Final Batch Loss: 6.327942537609488e-05\n",
      "Epoch 2027, Loss: 0.004647512461815495, Final Batch Loss: 0.0005827893037348986\n",
      "Epoch 2028, Loss: 0.0010725888860179111, Final Batch Loss: 0.00021913919772487134\n",
      "Epoch 2029, Loss: 0.0052519168821163476, Final Batch Loss: 0.0013963938690721989\n",
      "Epoch 2030, Loss: 0.004193341883365065, Final Batch Loss: 0.0004615231300704181\n",
      "Epoch 2031, Loss: 0.0033973305035033263, Final Batch Loss: 8.163224993040785e-05\n",
      "Epoch 2032, Loss: 0.00393602266558446, Final Batch Loss: 0.0014416280901059508\n",
      "Epoch 2033, Loss: 0.004383085608424153, Final Batch Loss: 0.003977437969297171\n",
      "Epoch 2034, Loss: 0.0008301218986161985, Final Batch Loss: 6.547568045789376e-05\n",
      "Epoch 2035, Loss: 0.006252470280742273, Final Batch Loss: 0.0004380218160804361\n",
      "Epoch 2036, Loss: 0.002508023419068195, Final Batch Loss: 0.002029363764449954\n",
      "Epoch 2037, Loss: 0.005215437966398895, Final Batch Loss: 0.00145956058986485\n",
      "Epoch 2038, Loss: 0.0010742800659500062, Final Batch Loss: 0.00039081161958165467\n",
      "Epoch 2039, Loss: 0.0026043482357636094, Final Batch Loss: 0.00011586403707042336\n",
      "Epoch 2040, Loss: 0.002853935060556978, Final Batch Loss: 7.293156522791833e-05\n",
      "Epoch 2041, Loss: 0.004386973902001046, Final Batch Loss: 0.0001637137174839154\n",
      "Epoch 2042, Loss: 0.007003388716839254, Final Batch Loss: 0.0003247804706916213\n",
      "Epoch 2043, Loss: 0.0011020729652955197, Final Batch Loss: 7.801496394677088e-05\n",
      "Epoch 2044, Loss: 0.018768347945297137, Final Batch Loss: 0.0003987845848314464\n",
      "Epoch 2045, Loss: 0.0025990115391323343, Final Batch Loss: 0.0008096051751635969\n",
      "Epoch 2046, Loss: 0.02021943047293462, Final Batch Loss: 0.00032691494561731815\n",
      "Epoch 2047, Loss: 0.0010164036793867126, Final Batch Loss: 0.0002760629286058247\n",
      "Epoch 2048, Loss: 0.0013355350602068938, Final Batch Loss: 0.0007296320400200784\n",
      "Epoch 2049, Loss: 0.002843085036147386, Final Batch Loss: 0.00015930537483654916\n",
      "Epoch 2050, Loss: 0.0039718495681881905, Final Batch Loss: 0.00025631964672356844\n",
      "Epoch 2051, Loss: 0.006550747115397826, Final Batch Loss: 0.00012304753181524575\n",
      "Epoch 2052, Loss: 0.0016641895454085898, Final Batch Loss: 5.433433034340851e-05\n",
      "Epoch 2053, Loss: 0.0032179438712773845, Final Batch Loss: 0.0013036428717896342\n",
      "Epoch 2054, Loss: 0.0019154602196067572, Final Batch Loss: 0.001396326464600861\n",
      "Epoch 2055, Loss: 0.002567446877947077, Final Batch Loss: 0.0007214908255264163\n",
      "Epoch 2056, Loss: 0.0007184219793998636, Final Batch Loss: 7.064262172207236e-05\n",
      "Epoch 2057, Loss: 0.002899783263274003, Final Batch Loss: 0.0025872685946524143\n",
      "Epoch 2058, Loss: 0.0006233468157006428, Final Batch Loss: 0.00024752478930167854\n",
      "Epoch 2059, Loss: 0.0034363226732239127, Final Batch Loss: 0.0027421703562140465\n",
      "Epoch 2060, Loss: 0.023965879547176883, Final Batch Loss: 0.022007906809449196\n",
      "Epoch 2061, Loss: 0.0008175114198820665, Final Batch Loss: 0.000393760041333735\n",
      "Epoch 2062, Loss: 0.000781323280534707, Final Batch Loss: 0.0001338231231784448\n",
      "Epoch 2063, Loss: 0.003705361217726022, Final Batch Loss: 0.0010980876395478845\n",
      "Epoch 2064, Loss: 0.0024466639370075427, Final Batch Loss: 5.350566789275035e-05\n",
      "Epoch 2065, Loss: 0.025638182531110942, Final Batch Loss: 0.022342858836054802\n",
      "Epoch 2066, Loss: 0.01097383617889136, Final Batch Loss: 0.0004378306330181658\n",
      "Epoch 2067, Loss: 0.0028206130082253367, Final Batch Loss: 0.0001448720577172935\n",
      "Epoch 2068, Loss: 0.0021524916373891756, Final Batch Loss: 0.0009509410010650754\n",
      "Epoch 2069, Loss: 0.011615539551712573, Final Batch Loss: 0.00973312184214592\n",
      "Epoch 2070, Loss: 0.001233004906680435, Final Batch Loss: 0.0005222035688348114\n",
      "Epoch 2071, Loss: 0.002153721696231514, Final Batch Loss: 0.0008271355764009058\n",
      "Epoch 2072, Loss: 0.003201511804945767, Final Batch Loss: 0.0005808017449453473\n",
      "Epoch 2073, Loss: 0.0017200160073116422, Final Batch Loss: 0.0002365531981922686\n",
      "Epoch 2074, Loss: 0.003429718519328162, Final Batch Loss: 0.0004573218466248363\n",
      "Epoch 2075, Loss: 0.003821570106083527, Final Batch Loss: 0.0002669543318916112\n",
      "Epoch 2076, Loss: 0.0018512359820306301, Final Batch Loss: 0.0008248153608292341\n",
      "Epoch 2077, Loss: 0.0007754603939247318, Final Batch Loss: 6.042680615792051e-05\n",
      "Epoch 2078, Loss: 0.011825611829408444, Final Batch Loss: 0.009462221525609493\n",
      "Epoch 2079, Loss: 0.0017657681310083717, Final Batch Loss: 0.00018497591372579336\n",
      "Epoch 2080, Loss: 0.0011446056014392525, Final Batch Loss: 0.0003676078049466014\n",
      "Epoch 2081, Loss: 0.002610879309941083, Final Batch Loss: 0.000605893146712333\n",
      "Epoch 2082, Loss: 0.012403776250721421, Final Batch Loss: 0.011891430243849754\n",
      "Epoch 2083, Loss: 0.0010050820710603148, Final Batch Loss: 0.0001524458493804559\n",
      "Epoch 2084, Loss: 0.0045442019909387454, Final Batch Loss: 0.0002280148764839396\n",
      "Epoch 2085, Loss: 0.0021533324324991554, Final Batch Loss: 0.0002944197040051222\n",
      "Epoch 2086, Loss: 0.0009572515409672633, Final Batch Loss: 0.00031599312205798924\n",
      "Epoch 2087, Loss: 0.003547803033143282, Final Batch Loss: 0.0004057198530063033\n",
      "Epoch 2088, Loss: 0.001409473130479455, Final Batch Loss: 0.0003951490216422826\n",
      "Epoch 2089, Loss: 0.001564278583828127, Final Batch Loss: 2.2025717044016346e-05\n",
      "Epoch 2090, Loss: 0.0006467745988629758, Final Batch Loss: 0.00012754475756082684\n",
      "Epoch 2091, Loss: 0.000982508499873802, Final Batch Loss: 0.0002049915783572942\n",
      "Epoch 2092, Loss: 0.003089660225668922, Final Batch Loss: 0.000654586881864816\n",
      "Epoch 2093, Loss: 0.0008503177850798238, Final Batch Loss: 3.1246472644852474e-05\n",
      "Epoch 2094, Loss: 0.0011897744043380953, Final Batch Loss: 5.7487231970299035e-05\n",
      "Epoch 2095, Loss: 0.023421282443450764, Final Batch Loss: 0.00029089837335050106\n",
      "Epoch 2096, Loss: 0.001511430451500928, Final Batch Loss: 1.7817361367633566e-05\n",
      "Epoch 2097, Loss: 0.0011685492208926007, Final Batch Loss: 0.000383686856366694\n",
      "Epoch 2098, Loss: 0.008979499514680356, Final Batch Loss: 0.00042643555207177997\n",
      "Epoch 2099, Loss: 0.010096644691657275, Final Batch Loss: 8.472945773974061e-05\n",
      "Epoch 2100, Loss: 0.0010159633529838175, Final Batch Loss: 0.00030146754579618573\n",
      "Epoch 2101, Loss: 0.0011442981631262228, Final Batch Loss: 0.00020022950775455683\n",
      "Epoch 2102, Loss: 0.003495277662295848, Final Batch Loss: 0.00029450521105900407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2103, Loss: 0.024669447331689298, Final Batch Loss: 0.0008411208400502801\n",
      "Epoch 2104, Loss: 0.004345690715126693, Final Batch Loss: 0.0010600235546007752\n",
      "Epoch 2105, Loss: 0.0007884108636062592, Final Batch Loss: 0.0001686517207417637\n",
      "Epoch 2106, Loss: 0.0023011814046185464, Final Batch Loss: 0.00036227746750228107\n",
      "Epoch 2107, Loss: 0.001775396136508789, Final Batch Loss: 8.468297164654359e-05\n",
      "Epoch 2108, Loss: 0.004554829039989272, Final Batch Loss: 0.004296293016523123\n",
      "Epoch 2109, Loss: 0.003531091468175873, Final Batch Loss: 0.000581654894631356\n",
      "Epoch 2110, Loss: 0.00210306318331277, Final Batch Loss: 8.841233648126945e-05\n",
      "Epoch 2111, Loss: 0.03311528917402029, Final Batch Loss: 0.0025151411537081003\n",
      "Epoch 2112, Loss: 0.0009949170307663735, Final Batch Loss: 4.42344717157539e-05\n",
      "Epoch 2113, Loss: 0.0021538079890888184, Final Batch Loss: 0.00035346619552001357\n",
      "Epoch 2114, Loss: 0.0009252917661797255, Final Batch Loss: 0.00022945963428355753\n",
      "Epoch 2115, Loss: 0.002359711754252203, Final Batch Loss: 0.001495886710472405\n",
      "Epoch 2116, Loss: 0.0003480568193481304, Final Batch Loss: 1.7730861145537347e-05\n",
      "Epoch 2117, Loss: 0.0036031065974384546, Final Batch Loss: 0.0007841730839572847\n",
      "Epoch 2118, Loss: 0.001194472519273404, Final Batch Loss: 9.556121221976355e-05\n",
      "Epoch 2119, Loss: 0.0027790581807494164, Final Batch Loss: 0.0005590785876847804\n",
      "Epoch 2120, Loss: 0.0029542082047555596, Final Batch Loss: 0.0023711123503744602\n",
      "Epoch 2121, Loss: 0.0498748323880136, Final Batch Loss: 0.047636207193136215\n",
      "Epoch 2122, Loss: 0.0029497899231500924, Final Batch Loss: 0.0002688156091608107\n",
      "Epoch 2123, Loss: 0.0014355416351463646, Final Batch Loss: 0.0004765540361404419\n",
      "Epoch 2124, Loss: 0.021816630083776545, Final Batch Loss: 1.7061531252693385e-05\n",
      "Epoch 2125, Loss: 0.0026934494417218957, Final Batch Loss: 2.732979555730708e-05\n",
      "Epoch 2126, Loss: 0.0039147217612480745, Final Batch Loss: 0.0001830856635933742\n",
      "Epoch 2127, Loss: 0.0031710956391179934, Final Batch Loss: 0.0012184290681034327\n",
      "Epoch 2128, Loss: 0.0009763407579157501, Final Batch Loss: 0.0001497585908509791\n",
      "Epoch 2129, Loss: 0.011181352805579081, Final Batch Loss: 0.00037183696986176074\n",
      "Epoch 2130, Loss: 0.0015071711968630552, Final Batch Loss: 0.0009363369317725301\n",
      "Epoch 2131, Loss: 0.0009322347905253991, Final Batch Loss: 0.0002739539777394384\n",
      "Epoch 2132, Loss: 0.00799605117936153, Final Batch Loss: 0.007440729532390833\n",
      "Epoch 2133, Loss: 0.0014173496747389436, Final Batch Loss: 0.00013953560846857727\n",
      "Epoch 2134, Loss: 0.004494141991017386, Final Batch Loss: 0.000340345868607983\n",
      "Epoch 2135, Loss: 0.0019967847038060427, Final Batch Loss: 0.0002863714180421084\n",
      "Epoch 2136, Loss: 0.0010186730469285976, Final Batch Loss: 4.3912306864513084e-05\n",
      "Epoch 2137, Loss: 0.002546485629864037, Final Batch Loss: 0.0006823088624514639\n",
      "Epoch 2138, Loss: 0.002486865341779776, Final Batch Loss: 0.000169700724654831\n",
      "Epoch 2139, Loss: 0.0016005055367713794, Final Batch Loss: 0.0006501192692667246\n",
      "Epoch 2140, Loss: 0.0008811563820927404, Final Batch Loss: 0.0001153345438069664\n",
      "Epoch 2141, Loss: 0.028442108421586454, Final Batch Loss: 0.0006469387444667518\n",
      "Epoch 2142, Loss: 0.0010827755759237334, Final Batch Loss: 0.00012806009908672422\n",
      "Epoch 2143, Loss: 0.003384166629984975, Final Batch Loss: 0.001896094181574881\n",
      "Epoch 2144, Loss: 0.0006713476323056966, Final Batch Loss: 0.0003353503125254065\n",
      "Epoch 2145, Loss: 0.0010129875263373833, Final Batch Loss: 3.2752355764387175e-05\n",
      "Epoch 2146, Loss: 0.020708052252302878, Final Batch Loss: 0.020261382684111595\n",
      "Epoch 2147, Loss: 0.005978858047456015, Final Batch Loss: 0.0003493317635729909\n",
      "Epoch 2148, Loss: 0.0014610329817514867, Final Batch Loss: 0.0003948881640098989\n",
      "Epoch 2149, Loss: 0.002195639826823026, Final Batch Loss: 0.0006698216893710196\n",
      "Epoch 2150, Loss: 0.006908942537847906, Final Batch Loss: 0.000255786522757262\n",
      "Epoch 2151, Loss: 0.050821667289710604, Final Batch Loss: 0.00022732627985533327\n",
      "Epoch 2152, Loss: 0.005173929268494248, Final Batch Loss: 0.0007267466862685978\n",
      "Epoch 2153, Loss: 0.007833632407709956, Final Batch Loss: 0.000751590239815414\n",
      "Epoch 2154, Loss: 0.00111674521031091, Final Batch Loss: 6.284891424002126e-05\n",
      "Epoch 2155, Loss: 0.010459987053764053, Final Batch Loss: 0.00021301775996107608\n",
      "Epoch 2156, Loss: 0.002946606051409617, Final Batch Loss: 0.0019057068275287747\n",
      "Epoch 2157, Loss: 0.0029237327253213152, Final Batch Loss: 8.24375165393576e-05\n",
      "Epoch 2158, Loss: 0.0020553540816763416, Final Batch Loss: 0.0009937772992998362\n",
      "Epoch 2159, Loss: 0.010240809438982978, Final Batch Loss: 0.00819840095937252\n",
      "Epoch 2160, Loss: 0.00043895861017517745, Final Batch Loss: 0.0002179771545343101\n",
      "Epoch 2161, Loss: 0.0015482812304981053, Final Batch Loss: 0.0005345414974726737\n",
      "Epoch 2162, Loss: 0.0004992645117454231, Final Batch Loss: 0.0002330102724954486\n",
      "Epoch 2163, Loss: 0.008394473319640383, Final Batch Loss: 0.007929145358502865\n",
      "Epoch 2164, Loss: 0.0010168859153054655, Final Batch Loss: 0.0002835004997905344\n",
      "Epoch 2165, Loss: 0.004064919397933409, Final Batch Loss: 0.0012949217343702912\n",
      "Epoch 2166, Loss: 0.0010665291047189385, Final Batch Loss: 0.0005206911009736359\n",
      "Epoch 2167, Loss: 0.00444941341993399, Final Batch Loss: 0.004083711188286543\n",
      "Epoch 2168, Loss: 0.0009439824352739379, Final Batch Loss: 0.000176941481186077\n",
      "Epoch 2169, Loss: 0.0014216527051758021, Final Batch Loss: 0.0007340225274674594\n",
      "Epoch 2170, Loss: 0.0027219067706028, Final Batch Loss: 0.00014494058268610388\n",
      "Epoch 2171, Loss: 0.007731397170573473, Final Batch Loss: 0.00323970103636384\n",
      "Epoch 2172, Loss: 0.0021484111712197773, Final Batch Loss: 0.00010441178892506287\n",
      "Epoch 2173, Loss: 0.002662816201336682, Final Batch Loss: 0.0004541754606179893\n",
      "Epoch 2174, Loss: 0.0027048371848650277, Final Batch Loss: 0.0005319949123077095\n",
      "Epoch 2175, Loss: 0.0016423025517724454, Final Batch Loss: 0.0006970823742449284\n",
      "Epoch 2176, Loss: 0.01740435668034479, Final Batch Loss: 0.0005302265635691583\n",
      "Epoch 2177, Loss: 0.0004749673535116017, Final Batch Loss: 0.00014195691619534045\n",
      "Epoch 2178, Loss: 0.0005127658732817508, Final Batch Loss: 0.0002422743127681315\n",
      "Epoch 2179, Loss: 0.019828637901809998, Final Batch Loss: 0.017112089321017265\n",
      "Epoch 2180, Loss: 0.0010024198418250307, Final Batch Loss: 0.00010144853149540722\n",
      "Epoch 2181, Loss: 0.008268478857644368, Final Batch Loss: 6.590698467334732e-05\n",
      "Epoch 2182, Loss: 0.000792281141912099, Final Batch Loss: 0.00033849800820462406\n",
      "Epoch 2183, Loss: 0.0006976609729463235, Final Batch Loss: 0.00048608871293254197\n",
      "Epoch 2184, Loss: 0.011780041852034628, Final Batch Loss: 0.0006184029625728726\n",
      "Epoch 2185, Loss: 0.03352103239740245, Final Batch Loss: 0.03272894769906998\n",
      "Epoch 2186, Loss: 0.002180873678298667, Final Batch Loss: 0.00036925848689861596\n",
      "Epoch 2187, Loss: 0.004758897499414161, Final Batch Loss: 0.0002497444220352918\n",
      "Epoch 2188, Loss: 0.0011411760497139767, Final Batch Loss: 0.00022425373026635498\n",
      "Epoch 2189, Loss: 0.0261643041158095, Final Batch Loss: 0.0007152689504437149\n",
      "Epoch 2190, Loss: 0.0008781191718298942, Final Batch Loss: 0.00024485605536028743\n",
      "Epoch 2191, Loss: 0.003047572448849678, Final Batch Loss: 0.002425422426313162\n",
      "Epoch 2192, Loss: 0.014016060027643107, Final Batch Loss: 0.00023199417046271265\n",
      "Epoch 2193, Loss: 0.0016583022224949673, Final Batch Loss: 0.0001683894806774333\n",
      "Epoch 2194, Loss: 0.006440008452045731, Final Batch Loss: 0.00013139673683326691\n",
      "Epoch 2195, Loss: 0.0004731850858661346, Final Batch Loss: 6.423544982681051e-05\n",
      "Epoch 2196, Loss: 0.0021688476554118097, Final Batch Loss: 0.00024692583247087896\n",
      "Epoch 2197, Loss: 0.003460328502114862, Final Batch Loss: 0.0012077382998540998\n",
      "Epoch 2198, Loss: 0.005211765877902508, Final Batch Loss: 0.0038568442687392235\n",
      "Epoch 2199, Loss: 0.002570780910900794, Final Batch Loss: 0.002220454625785351\n",
      "Epoch 2200, Loss: 0.0012117710575694218, Final Batch Loss: 0.00023121254344005138\n",
      "Epoch 2201, Loss: 0.0035770385729847476, Final Batch Loss: 0.00043146725511178374\n",
      "Epoch 2202, Loss: 0.0020429795840755105, Final Batch Loss: 0.00024718052009120584\n",
      "Epoch 2203, Loss: 0.004236936612869613, Final Batch Loss: 0.0006558552267961204\n",
      "Epoch 2204, Loss: 0.0006257457862375304, Final Batch Loss: 0.00020494732598308474\n",
      "Epoch 2205, Loss: 0.00591444454039447, Final Batch Loss: 0.0028234233614057302\n",
      "Epoch 2206, Loss: 0.0008228488441091031, Final Batch Loss: 0.0002382649399805814\n",
      "Epoch 2207, Loss: 0.0064937762363115326, Final Batch Loss: 0.003921749535948038\n",
      "Epoch 2208, Loss: 0.0010520849173190072, Final Batch Loss: 0.00012477936979848891\n",
      "Epoch 2209, Loss: 0.012517572322394699, Final Batch Loss: 0.00015624793013557792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2210, Loss: 0.0016321427974617109, Final Batch Loss: 0.00019685516599565744\n",
      "Epoch 2211, Loss: 0.03572749183513224, Final Batch Loss: 0.01173663791269064\n",
      "Epoch 2212, Loss: 0.001081633847206831, Final Batch Loss: 0.0005616759299300611\n",
      "Epoch 2213, Loss: 0.0009940709242073353, Final Batch Loss: 0.0003301323449704796\n",
      "Epoch 2214, Loss: 0.0015985964855644852, Final Batch Loss: 0.0003504249616526067\n",
      "Epoch 2215, Loss: 0.0037257867952575907, Final Batch Loss: 0.0007671442581340671\n",
      "Epoch 2216, Loss: 0.0011838429054478183, Final Batch Loss: 0.00020092750492040068\n",
      "Epoch 2217, Loss: 0.0018070916703436524, Final Batch Loss: 0.0003902044554706663\n",
      "Epoch 2218, Loss: 0.0008791381114860997, Final Batch Loss: 0.0003057541907764971\n",
      "Epoch 2219, Loss: 0.0008168360800482333, Final Batch Loss: 3.638309135567397e-05\n",
      "Epoch 2220, Loss: 0.007991599821252748, Final Batch Loss: 0.0009602554491721094\n",
      "Epoch 2221, Loss: 0.0008051371114561334, Final Batch Loss: 0.0001317394053330645\n",
      "Epoch 2222, Loss: 0.004277602245565504, Final Batch Loss: 0.003355184569954872\n",
      "Epoch 2223, Loss: 0.009795796795515344, Final Batch Loss: 0.008822210133075714\n",
      "Epoch 2224, Loss: 0.0030199628236005083, Final Batch Loss: 0.0009817631216719747\n",
      "Epoch 2225, Loss: 0.007635810165083967, Final Batch Loss: 0.0002152785746147856\n",
      "Epoch 2226, Loss: 0.0012683711538556963, Final Batch Loss: 0.0007315024267882109\n",
      "Epoch 2227, Loss: 0.030603554216213524, Final Batch Loss: 0.0006181568605825305\n",
      "Epoch 2228, Loss: 0.009048628970049322, Final Batch Loss: 0.005441421642899513\n",
      "Epoch 2229, Loss: 0.005725522329157684, Final Batch Loss: 0.0005149524076841772\n",
      "Epoch 2230, Loss: 0.023162580764619634, Final Batch Loss: 0.0002664476342033595\n",
      "Epoch 2231, Loss: 0.0038852308189234463, Final Batch Loss: 2.5480139811406843e-05\n",
      "Epoch 2232, Loss: 0.001165258785476908, Final Batch Loss: 0.0004915018798783422\n",
      "Epoch 2233, Loss: 0.013477150863764109, Final Batch Loss: 4.330007141106762e-05\n",
      "Epoch 2234, Loss: 0.01208656180097023, Final Batch Loss: 8.080420229816809e-05\n",
      "Epoch 2235, Loss: 0.000897514633834362, Final Batch Loss: 0.00016620114911347628\n",
      "Epoch 2236, Loss: 0.0006040582084096968, Final Batch Loss: 6.445471080951393e-05\n",
      "Epoch 2237, Loss: 0.004829293848160887, Final Batch Loss: 3.7817317206645384e-05\n",
      "Epoch 2238, Loss: 0.0021750157611677423, Final Batch Loss: 0.00020835701434407383\n",
      "Epoch 2239, Loss: 0.0009806824527913705, Final Batch Loss: 0.0004982341779395938\n",
      "Epoch 2240, Loss: 0.0014891453320160508, Final Batch Loss: 0.000276045233476907\n",
      "Epoch 2241, Loss: 0.0006844889430794865, Final Batch Loss: 6.636156467720866e-05\n",
      "Epoch 2242, Loss: 0.0008017811924219131, Final Batch Loss: 0.00013134221080690622\n",
      "Epoch 2243, Loss: 0.004519921087194234, Final Batch Loss: 0.003699783468618989\n",
      "Epoch 2244, Loss: 0.0010967760172206908, Final Batch Loss: 0.00031275616493076086\n",
      "Epoch 2245, Loss: 0.0009083825279958546, Final Batch Loss: 6.674023461528122e-05\n",
      "Epoch 2246, Loss: 0.004347627080278471, Final Batch Loss: 0.0035983179695904255\n",
      "Epoch 2247, Loss: 0.0007762865425320342, Final Batch Loss: 0.00015680563228670508\n",
      "Epoch 2248, Loss: 0.0009488167779636569, Final Batch Loss: 0.00015201824135147035\n",
      "Epoch 2249, Loss: 0.002354394702706486, Final Batch Loss: 0.0005102981813251972\n",
      "Epoch 2250, Loss: 0.00048275487279170193, Final Batch Loss: 3.814157753367908e-05\n",
      "Epoch 2251, Loss: 0.022157200932269916, Final Batch Loss: 0.004657130688428879\n",
      "Epoch 2252, Loss: 0.00230059731984511, Final Batch Loss: 0.0013674197252839804\n",
      "Epoch 2253, Loss: 0.012179434212157503, Final Batch Loss: 0.0015686079859733582\n",
      "Epoch 2254, Loss: 0.001345677621429786, Final Batch Loss: 0.0004573156184051186\n",
      "Epoch 2255, Loss: 0.0020587830076692626, Final Batch Loss: 0.00030061666620895267\n",
      "Epoch 2256, Loss: 0.001976679253857583, Final Batch Loss: 0.001010615611448884\n",
      "Epoch 2257, Loss: 0.0016993674871628173, Final Batch Loss: 0.0010794802801683545\n",
      "Epoch 2258, Loss: 0.006641896801738767, Final Batch Loss: 6.084901906433515e-05\n",
      "Epoch 2259, Loss: 0.000560283828235697, Final Batch Loss: 7.617648952873424e-05\n",
      "Epoch 2260, Loss: 0.002020189847826259, Final Batch Loss: 3.486306013655849e-05\n",
      "Epoch 2261, Loss: 0.0029053489706711844, Final Batch Loss: 0.000227822209126316\n",
      "Epoch 2262, Loss: 0.0011218699655728415, Final Batch Loss: 0.0001762853207765147\n",
      "Epoch 2263, Loss: 0.04891935718478635, Final Batch Loss: 0.005178858991712332\n",
      "Epoch 2264, Loss: 0.0022729604024789296, Final Batch Loss: 9.627622057450935e-05\n",
      "Epoch 2265, Loss: 0.0019494665320962667, Final Batch Loss: 0.00023905369744170457\n",
      "Epoch 2266, Loss: 0.001204777327075135, Final Batch Loss: 0.000877451675478369\n",
      "Epoch 2267, Loss: 0.000712028777343221, Final Batch Loss: 0.00025208244915120304\n",
      "Epoch 2268, Loss: 0.00044028628144587856, Final Batch Loss: 0.0002543121518101543\n",
      "Epoch 2269, Loss: 0.005053163149568718, Final Batch Loss: 0.0024647158570587635\n",
      "Epoch 2270, Loss: 0.0011323320941301063, Final Batch Loss: 0.0002573837118688971\n",
      "Epoch 2271, Loss: 0.03841721338540083, Final Batch Loss: 0.0003202789812348783\n",
      "Epoch 2272, Loss: 0.0007031543282209896, Final Batch Loss: 0.00028885528445243835\n",
      "Epoch 2273, Loss: 0.0003417880288907327, Final Batch Loss: 2.3363980290014297e-05\n",
      "Epoch 2274, Loss: 0.0010021408161264844, Final Batch Loss: 7.090689177857712e-05\n",
      "Epoch 2275, Loss: 0.0008474631686112843, Final Batch Loss: 0.0005664697964675725\n",
      "Epoch 2276, Loss: 0.0005394021864049137, Final Batch Loss: 0.0004543003742583096\n",
      "Epoch 2277, Loss: 0.01224475388880819, Final Batch Loss: 0.005687412340193987\n",
      "Epoch 2278, Loss: 0.02416114787774859, Final Batch Loss: 0.023697685450315475\n",
      "Epoch 2279, Loss: 0.04072936163356644, Final Batch Loss: 0.01888306811451912\n",
      "Epoch 2280, Loss: 0.0022466853260993958, Final Batch Loss: 0.0010134554468095303\n",
      "Epoch 2281, Loss: 0.05657036437332863, Final Batch Loss: 0.00011893941700691357\n",
      "Epoch 2282, Loss: 0.010952797638310585, Final Batch Loss: 3.1207782740239054e-05\n",
      "Epoch 2283, Loss: 0.0011195084516657516, Final Batch Loss: 0.0005649053491652012\n",
      "Epoch 2284, Loss: 0.0022053873108234257, Final Batch Loss: 0.0011907443404197693\n",
      "Epoch 2285, Loss: 0.0037526422820519656, Final Batch Loss: 0.0003462070308160037\n",
      "Epoch 2286, Loss: 0.028867813656688668, Final Batch Loss: 0.0001878618058981374\n",
      "Epoch 2287, Loss: 0.0019170935192960314, Final Batch Loss: 5.1746312237810344e-05\n",
      "Epoch 2288, Loss: 0.0037696937506552786, Final Batch Loss: 0.0020595903042703867\n",
      "Epoch 2289, Loss: 0.004573530808556825, Final Batch Loss: 0.00020387204131111503\n",
      "Epoch 2290, Loss: 0.00740183622110635, Final Batch Loss: 0.00048271677223965526\n",
      "Epoch 2291, Loss: 0.0019160805604769848, Final Batch Loss: 3.1678318919148296e-05\n",
      "Epoch 2292, Loss: 0.0014116509264567867, Final Batch Loss: 6.951685645617545e-05\n",
      "Epoch 2293, Loss: 0.0021684790181097924, Final Batch Loss: 7.143279617594089e-06\n",
      "Epoch 2294, Loss: 0.0023367175890598446, Final Batch Loss: 0.0002537367690820247\n",
      "Epoch 2295, Loss: 0.0010098876664415002, Final Batch Loss: 0.00024092450621537864\n",
      "Epoch 2296, Loss: 0.0016931011050473899, Final Batch Loss: 0.00037383133894763887\n",
      "Epoch 2297, Loss: 0.0038388817847589962, Final Batch Loss: 0.00011628033098531887\n",
      "Epoch 2298, Loss: 0.010809621890075505, Final Batch Loss: 0.006813724525272846\n",
      "Epoch 2299, Loss: 0.006498104514321312, Final Batch Loss: 0.00018341853865422308\n",
      "Epoch 2300, Loss: 0.00038419404882006347, Final Batch Loss: 0.00013530442083720118\n",
      "Epoch 2301, Loss: 0.003639275993919, Final Batch Loss: 0.00010572638711892068\n",
      "Epoch 2302, Loss: 0.002545213275880087, Final Batch Loss: 0.00023649400100111961\n",
      "Epoch 2303, Loss: 0.0031791648507351056, Final Batch Loss: 0.0001815287978388369\n",
      "Epoch 2304, Loss: 0.0007456797829945572, Final Batch Loss: 9.179570042761043e-05\n",
      "Epoch 2305, Loss: 0.000679870368912816, Final Batch Loss: 0.00013410171959549189\n",
      "Epoch 2306, Loss: 0.0034212265845781076, Final Batch Loss: 1.2036743100907188e-05\n",
      "Epoch 2307, Loss: 0.0005397703971539158, Final Batch Loss: 5.0268197810510173e-05\n",
      "Epoch 2308, Loss: 0.002328327391296625, Final Batch Loss: 6.732632755301893e-05\n",
      "Epoch 2309, Loss: 0.005963948118733242, Final Batch Loss: 0.0013166143326088786\n",
      "Epoch 2310, Loss: 0.006270127269090153, Final Batch Loss: 0.00457695173099637\n",
      "Epoch 2311, Loss: 0.0006626644753850996, Final Batch Loss: 0.0001497530611231923\n",
      "Epoch 2312, Loss: 0.003021876276761759, Final Batch Loss: 0.00010598051449051127\n",
      "Epoch 2313, Loss: 0.0021919460050412454, Final Batch Loss: 4.496398469200358e-05\n",
      "Epoch 2314, Loss: 0.0006023211681167595, Final Batch Loss: 3.98471238440834e-05\n",
      "Epoch 2315, Loss: 0.0003985767107224092, Final Batch Loss: 0.00011257444566581398\n",
      "Epoch 2316, Loss: 0.021655495424056426, Final Batch Loss: 1.5006778994575143e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2317, Loss: 0.0005307743413140997, Final Batch Loss: 0.00011152485967613757\n",
      "Epoch 2318, Loss: 0.002124596052453853, Final Batch Loss: 0.0012602804927155375\n",
      "Epoch 2319, Loss: 0.000986022685538046, Final Batch Loss: 0.0003493386029731482\n",
      "Epoch 2320, Loss: 0.001283529563806951, Final Batch Loss: 0.0004009607946500182\n",
      "Epoch 2321, Loss: 0.004009040392702445, Final Batch Loss: 0.00192182045429945\n",
      "Epoch 2322, Loss: 0.005680080532329157, Final Batch Loss: 0.0004908645059913397\n",
      "Epoch 2323, Loss: 0.002945097425254062, Final Batch Loss: 0.00035272733657620847\n",
      "Epoch 2324, Loss: 0.0009616070019546896, Final Batch Loss: 0.0003501279279589653\n",
      "Epoch 2325, Loss: 0.015382307392428629, Final Batch Loss: 0.00033362233079969883\n",
      "Epoch 2326, Loss: 0.0011853953619720414, Final Batch Loss: 0.00020487314031925052\n",
      "Epoch 2327, Loss: 0.001577705261297524, Final Batch Loss: 0.00021997798467054963\n",
      "Epoch 2328, Loss: 0.0049358661635778844, Final Batch Loss: 0.000523747003171593\n",
      "Epoch 2329, Loss: 0.0006632340227952227, Final Batch Loss: 0.0002124152088072151\n",
      "Epoch 2330, Loss: 0.0005042611956014298, Final Batch Loss: 0.0001254280359717086\n",
      "Epoch 2331, Loss: 0.005944661592366174, Final Batch Loss: 0.004570693243294954\n",
      "Epoch 2332, Loss: 0.002701149642234668, Final Batch Loss: 0.0005539901903830469\n",
      "Epoch 2333, Loss: 0.0012859851121902466, Final Batch Loss: 0.000978383352048695\n",
      "Epoch 2334, Loss: 0.006489325343864039, Final Batch Loss: 0.00023733792477287352\n",
      "Epoch 2335, Loss: 0.00037035891000414267, Final Batch Loss: 0.00014411105075851083\n",
      "Epoch 2336, Loss: 0.00308482744731009, Final Batch Loss: 0.0016450653783977032\n",
      "Epoch 2337, Loss: 0.0011888658336829394, Final Batch Loss: 0.0004417609015945345\n",
      "Epoch 2338, Loss: 0.000423059580498375, Final Batch Loss: 0.00012255401816219091\n",
      "Epoch 2339, Loss: 0.0028594676332431845, Final Batch Loss: 0.00010641973494784907\n",
      "Epoch 2340, Loss: 0.0015509001386817545, Final Batch Loss: 0.0001223752915393561\n",
      "Epoch 2341, Loss: 0.0023275130224647, Final Batch Loss: 0.000991491018794477\n",
      "Epoch 2342, Loss: 0.004004380461992696, Final Batch Loss: 0.00017056374053936452\n",
      "Epoch 2343, Loss: 0.002285711670992896, Final Batch Loss: 0.0008466030121780932\n",
      "Epoch 2344, Loss: 0.0008974354714155197, Final Batch Loss: 0.0001626469602342695\n",
      "Epoch 2345, Loss: 0.0012714378244709224, Final Batch Loss: 0.00046668879804201424\n",
      "Epoch 2346, Loss: 0.0027044744638260454, Final Batch Loss: 0.002160120289772749\n",
      "Epoch 2347, Loss: 0.002656148179084994, Final Batch Loss: 0.0008403226383961737\n",
      "Epoch 2348, Loss: 0.04580046655610204, Final Batch Loss: 0.04187563806772232\n",
      "Epoch 2349, Loss: 0.0028126852339482866, Final Batch Loss: 0.0008781481883488595\n",
      "Epoch 2350, Loss: 0.013811857235850766, Final Batch Loss: 0.01324633602052927\n",
      "Epoch 2351, Loss: 0.0005749297997681424, Final Batch Loss: 2.4177759769372642e-05\n",
      "Epoch 2352, Loss: 0.0033147149079013616, Final Batch Loss: 0.0004251220088917762\n",
      "Epoch 2353, Loss: 0.0010542624804656953, Final Batch Loss: 0.0007704636664129794\n",
      "Epoch 2354, Loss: 0.0009594404036761262, Final Batch Loss: 0.000604579399805516\n",
      "Epoch 2355, Loss: 0.0015929786604829133, Final Batch Loss: 0.00031816610135138035\n",
      "Epoch 2356, Loss: 0.004039158062369097, Final Batch Loss: 0.0036064465530216694\n",
      "Epoch 2357, Loss: 0.013735937711317092, Final Batch Loss: 0.0002474500215612352\n",
      "Epoch 2358, Loss: 0.0005250798858469352, Final Batch Loss: 0.00018037711561191827\n",
      "Epoch 2359, Loss: 0.0034162319352617487, Final Batch Loss: 0.00014071362966205925\n",
      "Epoch 2360, Loss: 0.0006814466905780137, Final Batch Loss: 8.292436541523784e-05\n",
      "Epoch 2361, Loss: 0.0008684987988090143, Final Batch Loss: 0.0004790806269738823\n",
      "Epoch 2362, Loss: 0.0020902504329569638, Final Batch Loss: 0.0008207125938497484\n",
      "Epoch 2363, Loss: 0.004270617791917175, Final Batch Loss: 0.0034170562867075205\n",
      "Epoch 2364, Loss: 0.0006173458386911079, Final Batch Loss: 1.969508593901992e-05\n",
      "Epoch 2365, Loss: 0.0009417317669431213, Final Batch Loss: 7.822065526852384e-06\n",
      "Epoch 2366, Loss: 0.0003177347425662447, Final Batch Loss: 1.555597918923013e-05\n",
      "Epoch 2367, Loss: 0.0019090560672339052, Final Batch Loss: 0.0005666972137987614\n",
      "Epoch 2368, Loss: 0.0011196229024790227, Final Batch Loss: 0.0007888718391768634\n",
      "Epoch 2369, Loss: 0.0009712900209706277, Final Batch Loss: 0.00029506185092031956\n",
      "Epoch 2370, Loss: 0.009317646297859028, Final Batch Loss: 0.008608805947005749\n",
      "Epoch 2371, Loss: 0.006759516385500319, Final Batch Loss: 7.774696859996766e-05\n",
      "Epoch 2372, Loss: 0.0027695234966813587, Final Batch Loss: 0.00020315550500527024\n",
      "Epoch 2373, Loss: 0.0011926738879992627, Final Batch Loss: 0.0001361114118481055\n",
      "Epoch 2374, Loss: 0.0007998782002687221, Final Batch Loss: 2.3464037440135144e-05\n",
      "Epoch 2375, Loss: 0.00035530463355826214, Final Batch Loss: 4.4127998990006745e-05\n",
      "Epoch 2376, Loss: 0.004142195801250637, Final Batch Loss: 0.0005379902431741357\n",
      "Epoch 2377, Loss: 0.0041550091991666704, Final Batch Loss: 0.002147249411791563\n",
      "Epoch 2378, Loss: 0.0005467327500809915, Final Batch Loss: 0.00011865715350722894\n",
      "Epoch 2379, Loss: 0.001312762025918346, Final Batch Loss: 7.768968498567119e-05\n",
      "Epoch 2380, Loss: 0.01870162578416057, Final Batch Loss: 0.017932388931512833\n",
      "Epoch 2381, Loss: 0.000653256596706342, Final Batch Loss: 7.414787978632376e-05\n",
      "Epoch 2382, Loss: 0.0009414071319042705, Final Batch Loss: 7.972011371748522e-05\n",
      "Epoch 2383, Loss: 0.030816830229014158, Final Batch Loss: 0.027114614844322205\n",
      "Epoch 2384, Loss: 0.012645041133509949, Final Batch Loss: 0.00020280820899643004\n",
      "Epoch 2385, Loss: 0.0184518713504076, Final Batch Loss: 0.0004057119367644191\n",
      "Epoch 2386, Loss: 0.007306668674573302, Final Batch Loss: 0.00021663575898855925\n",
      "Epoch 2387, Loss: 0.019960011151852086, Final Batch Loss: 0.00041090164449997246\n",
      "Epoch 2388, Loss: 0.0006441128061851487, Final Batch Loss: 0.00021605499205179513\n",
      "Epoch 2389, Loss: 0.0028489776886999607, Final Batch Loss: 0.0008939856779761612\n",
      "Epoch 2390, Loss: 0.005352798878448084, Final Batch Loss: 0.0009215803584083915\n",
      "Epoch 2391, Loss: 0.0021124698978383094, Final Batch Loss: 0.0001800524623831734\n",
      "Epoch 2392, Loss: 0.003953195962822065, Final Batch Loss: 0.00039395465864799917\n",
      "Epoch 2393, Loss: 0.012081374195986427, Final Batch Loss: 0.0006225960678420961\n",
      "Epoch 2394, Loss: 0.001964953276910819, Final Batch Loss: 0.0010950581636279821\n",
      "Epoch 2395, Loss: 0.0017736582667566836, Final Batch Loss: 0.00015494757099077106\n",
      "Epoch 2396, Loss: 0.0057343496882822365, Final Batch Loss: 0.0037211694288998842\n",
      "Epoch 2397, Loss: 0.007372153326286934, Final Batch Loss: 0.00014185412146616727\n",
      "Epoch 2398, Loss: 0.022949407109990716, Final Batch Loss: 0.02142564207315445\n",
      "Epoch 2399, Loss: 0.0022599524236284196, Final Batch Loss: 0.0009181242785416543\n",
      "Epoch 2400, Loss: 0.000875118697877042, Final Batch Loss: 0.00015158865426201373\n",
      "Epoch 2401, Loss: 0.01344657460867893, Final Batch Loss: 0.009077372960746288\n",
      "Epoch 2402, Loss: 0.014762067497940734, Final Batch Loss: 0.00016282725846394897\n",
      "Epoch 2403, Loss: 0.001959014916792512, Final Batch Loss: 0.0014903444098308682\n",
      "Epoch 2404, Loss: 0.001933974024723284, Final Batch Loss: 0.00019961381622124463\n",
      "Epoch 2405, Loss: 0.0028116315515944734, Final Batch Loss: 0.0004214306827634573\n",
      "Epoch 2406, Loss: 0.0014748504327144474, Final Batch Loss: 0.0003178698825649917\n",
      "Epoch 2407, Loss: 0.029664661691640504, Final Batch Loss: 0.028464794158935547\n",
      "Epoch 2408, Loss: 0.002015622827457264, Final Batch Loss: 0.00018244815873913467\n",
      "Epoch 2409, Loss: 0.003789412949117832, Final Batch Loss: 0.0007176729268394411\n",
      "Epoch 2410, Loss: 0.0012609010009327903, Final Batch Loss: 0.00010155084601137787\n",
      "Epoch 2411, Loss: 0.009062275566975586, Final Batch Loss: 0.0001416900340700522\n",
      "Epoch 2412, Loss: 0.0007070835235936102, Final Batch Loss: 4.940604776493274e-05\n",
      "Epoch 2413, Loss: 0.0013957765258965082, Final Batch Loss: 0.000909256050363183\n",
      "Epoch 2414, Loss: 0.0006969019887037575, Final Batch Loss: 0.00039618401206098497\n",
      "Epoch 2415, Loss: 0.0008754342052270658, Final Batch Loss: 8.238566078944132e-05\n",
      "Epoch 2416, Loss: 0.003622310236096382, Final Batch Loss: 0.0006529017118737102\n",
      "Epoch 2417, Loss: 0.004464886937057599, Final Batch Loss: 0.0004578196967486292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2418, Loss: 0.0008343549852725118, Final Batch Loss: 0.00034001292078755796\n",
      "Epoch 2419, Loss: 0.0005537188008020166, Final Batch Loss: 5.261142723611556e-05\n",
      "Epoch 2420, Loss: 0.001164261131634703, Final Batch Loss: 0.00021798411034978926\n",
      "Epoch 2421, Loss: 0.001386750111123547, Final Batch Loss: 0.00026051836903207004\n",
      "Epoch 2422, Loss: 0.0005448949086712673, Final Batch Loss: 0.000321606028592214\n",
      "Epoch 2423, Loss: 0.0010806329155457206, Final Batch Loss: 0.0005876155337318778\n",
      "Epoch 2424, Loss: 0.015870927563810255, Final Batch Loss: 2.9792914574500173e-05\n",
      "Epoch 2425, Loss: 0.0010740661818999797, Final Batch Loss: 0.0005188897484913468\n",
      "Epoch 2426, Loss: 0.002500792696082499, Final Batch Loss: 6.406104512279853e-05\n",
      "Epoch 2427, Loss: 0.0010145182604901493, Final Batch Loss: 0.0006881830049678683\n",
      "Epoch 2428, Loss: 0.0009283233302994631, Final Batch Loss: 0.00011108497710665688\n",
      "Epoch 2429, Loss: 0.0005655576023855247, Final Batch Loss: 0.0003531993424985558\n",
      "Epoch 2430, Loss: 0.0074747728067450225, Final Batch Loss: 6.465514888986945e-05\n",
      "Epoch 2431, Loss: 0.0015203186321741669, Final Batch Loss: 9.17173565539997e-06\n",
      "Epoch 2432, Loss: 0.002567806077422574, Final Batch Loss: 0.0004146885476075113\n",
      "Epoch 2433, Loss: 0.0008919235842768103, Final Batch Loss: 0.00017946433217730373\n",
      "Epoch 2434, Loss: 0.0006850943682366051, Final Batch Loss: 0.0004123569233343005\n",
      "Epoch 2435, Loss: 0.0005309135740390047, Final Batch Loss: 0.0001832072011893615\n",
      "Epoch 2436, Loss: 0.0012358455132925883, Final Batch Loss: 0.00044833397259935737\n",
      "Epoch 2437, Loss: 0.001608117323485203, Final Batch Loss: 0.0005754478625021875\n",
      "Epoch 2438, Loss: 0.009878746361209778, Final Batch Loss: 4.0010094380704686e-05\n",
      "Epoch 2439, Loss: 0.0028232735949131893, Final Batch Loss: 8.866702046361752e-06\n",
      "Epoch 2440, Loss: 0.010397666919743642, Final Batch Loss: 0.009364438243210316\n",
      "Epoch 2441, Loss: 0.00627991883084178, Final Batch Loss: 0.003710799617692828\n",
      "Epoch 2442, Loss: 0.0016651618279865943, Final Batch Loss: 0.0006853039376437664\n",
      "Epoch 2443, Loss: 0.0014012238243594766, Final Batch Loss: 0.0007496741600334644\n",
      "Epoch 2444, Loss: 0.0029074840613247943, Final Batch Loss: 9.504231456958223e-06\n",
      "Epoch 2445, Loss: 0.002886944857891649, Final Batch Loss: 0.00012096283899154514\n",
      "Epoch 2446, Loss: 0.00044586258445633575, Final Batch Loss: 0.00010600183304632083\n",
      "Epoch 2447, Loss: 0.000938663084525615, Final Batch Loss: 0.0002510174526832998\n",
      "Epoch 2448, Loss: 0.0008752774592721835, Final Batch Loss: 5.81452768528834e-05\n",
      "Epoch 2449, Loss: 0.0005779461862402968, Final Batch Loss: 0.0003947125806007534\n",
      "Epoch 2450, Loss: 0.0010448717657709494, Final Batch Loss: 0.0002142485318472609\n",
      "Epoch 2451, Loss: 0.0005193586694076657, Final Batch Loss: 0.00011200927110621706\n",
      "Epoch 2452, Loss: 0.0006335228536045179, Final Batch Loss: 0.00027400930412113667\n",
      "Epoch 2453, Loss: 0.0008689332516951254, Final Batch Loss: 0.00015493930550292134\n",
      "Epoch 2454, Loss: 0.0017845868460426573, Final Batch Loss: 1.2587381206685677e-05\n",
      "Epoch 2455, Loss: 0.0026064164776471443, Final Batch Loss: 9.06402783584781e-05\n",
      "Epoch 2456, Loss: 0.0006699860896333121, Final Batch Loss: 0.00047713698586449027\n",
      "Epoch 2457, Loss: 0.0007114825421012938, Final Batch Loss: 0.0002235334977740422\n",
      "Epoch 2458, Loss: 0.0003455700589256594, Final Batch Loss: 2.115200368280057e-05\n",
      "Epoch 2459, Loss: 0.00018432661545375595, Final Batch Loss: 1.234236788150156e-05\n",
      "Epoch 2460, Loss: 0.0012855416935053654, Final Batch Loss: 0.0001957086642505601\n",
      "Epoch 2461, Loss: 0.006890456439577974, Final Batch Loss: 0.0063705104403197765\n",
      "Epoch 2462, Loss: 0.004887780174612999, Final Batch Loss: 0.0034658547956496477\n",
      "Epoch 2463, Loss: 0.001090634919819422, Final Batch Loss: 0.00037823524326086044\n",
      "Epoch 2464, Loss: 0.0007375962741207331, Final Batch Loss: 0.0004063015803694725\n",
      "Epoch 2465, Loss: 0.0008692684059496969, Final Batch Loss: 0.00017718070012051612\n",
      "Epoch 2466, Loss: 0.0006309280288405716, Final Batch Loss: 0.0003228957939427346\n",
      "Epoch 2467, Loss: 0.0013506977484212257, Final Batch Loss: 0.000742293952498585\n",
      "Epoch 2468, Loss: 0.0003934874512196984, Final Batch Loss: 3.428586569498293e-05\n",
      "Epoch 2469, Loss: 0.0010839172173291445, Final Batch Loss: 0.0003016926348209381\n",
      "Epoch 2470, Loss: 0.0016241693010670133, Final Batch Loss: 4.116772106499411e-05\n",
      "Epoch 2471, Loss: 0.0006348377246467862, Final Batch Loss: 3.535050564096309e-05\n",
      "Epoch 2472, Loss: 0.0076346020214259624, Final Batch Loss: 0.001442761393263936\n",
      "Epoch 2473, Loss: 0.00044866431926493533, Final Batch Loss: 5.824654726893641e-05\n",
      "Epoch 2474, Loss: 0.0006016640763846226, Final Batch Loss: 0.00011202323366887867\n",
      "Epoch 2475, Loss: 0.0007338012474065181, Final Batch Loss: 4.033237564726733e-05\n",
      "Epoch 2476, Loss: 0.0005890013380849268, Final Batch Loss: 0.0003806386957876384\n",
      "Epoch 2477, Loss: 0.0009768627569428645, Final Batch Loss: 0.0003822830331046134\n",
      "Epoch 2478, Loss: 0.0036159373266855255, Final Batch Loss: 1.5619283658452332e-05\n",
      "Epoch 2479, Loss: 0.0008461518082185648, Final Batch Loss: 0.0004927488625980914\n",
      "Epoch 2480, Loss: 0.0004713215930678416, Final Batch Loss: 4.7171339247142896e-05\n",
      "Epoch 2481, Loss: 0.0007796346289978828, Final Batch Loss: 4.309248106437735e-05\n",
      "Epoch 2482, Loss: 0.0029747130247415043, Final Batch Loss: 0.0007537528872489929\n",
      "Epoch 2483, Loss: 0.013873245217837393, Final Batch Loss: 0.00028046645456925035\n",
      "Epoch 2484, Loss: 0.006401402028131997, Final Batch Loss: 0.006327981129288673\n",
      "Epoch 2485, Loss: 0.0004962212860846194, Final Batch Loss: 1.2314909326960333e-05\n",
      "Epoch 2486, Loss: 0.0011977930626017042, Final Batch Loss: 7.557836215710267e-05\n",
      "Epoch 2487, Loss: 0.0016953429876593873, Final Batch Loss: 3.429733624216169e-05\n",
      "Epoch 2488, Loss: 0.00041504172986606136, Final Batch Loss: 0.00010925003880402073\n",
      "Epoch 2489, Loss: 0.011026389360267785, Final Batch Loss: 2.419481643300969e-05\n",
      "Epoch 2490, Loss: 0.0011680337356665405, Final Batch Loss: 2.23797596845543e-05\n",
      "Epoch 2491, Loss: 0.00024347745056729764, Final Batch Loss: 4.400433681439608e-05\n",
      "Epoch 2492, Loss: 0.0059306947368895635, Final Batch Loss: 0.0004084940592292696\n",
      "Epoch 2493, Loss: 0.0002984821185236797, Final Batch Loss: 8.756538591114804e-05\n",
      "Epoch 2494, Loss: 0.001208182075060904, Final Batch Loss: 0.0002490739861968905\n",
      "Epoch 2495, Loss: 0.00553037506142573, Final Batch Loss: 1.3285089153214358e-05\n",
      "Epoch 2496, Loss: 0.0040730327054916415, Final Batch Loss: 0.0006638120394200087\n",
      "Epoch 2497, Loss: 0.0006505032069981098, Final Batch Loss: 7.501502113882452e-05\n",
      "Epoch 2498, Loss: 0.0037507469969568774, Final Batch Loss: 0.0003403369919396937\n",
      "Epoch 2499, Loss: 0.00038136971397761954, Final Batch Loss: 1.1530823940120172e-05\n",
      "Epoch 2500, Loss: 0.013446085642499384, Final Batch Loss: 0.010079115629196167\n",
      "Epoch 2501, Loss: 0.0018281922384630889, Final Batch Loss: 0.0006644835812039673\n",
      "Epoch 2502, Loss: 0.0006378090838552453, Final Batch Loss: 0.0005251247202977538\n",
      "Epoch 2503, Loss: 0.0007960746079334058, Final Batch Loss: 7.731928053544834e-05\n",
      "Epoch 2504, Loss: 0.0010795839625643566, Final Batch Loss: 0.0003514242998789996\n",
      "Epoch 2505, Loss: 0.0013493921724148095, Final Batch Loss: 0.00017551719793118536\n",
      "Epoch 2506, Loss: 0.00045423684059642255, Final Batch Loss: 8.303471258841455e-05\n",
      "Epoch 2507, Loss: 0.00047394894500030205, Final Batch Loss: 3.446367190917954e-05\n",
      "Epoch 2508, Loss: 0.004472851054742932, Final Batch Loss: 0.0010875847656279802\n",
      "Epoch 2509, Loss: 0.0061147311607783195, Final Batch Loss: 4.8533282097196206e-05\n",
      "Epoch 2510, Loss: 0.007431879217620008, Final Batch Loss: 0.0005187226925045252\n",
      "Epoch 2511, Loss: 0.000749537801311817, Final Batch Loss: 0.00010910713899647817\n",
      "Epoch 2512, Loss: 0.002816364540194627, Final Batch Loss: 0.0019775312393903732\n",
      "Epoch 2513, Loss: 0.05355699844403716, Final Batch Loss: 2.9066761271678843e-05\n",
      "Epoch 2514, Loss: 0.0008517638998455368, Final Batch Loss: 0.0006168645340949297\n",
      "Epoch 2515, Loss: 0.0009440109424758703, Final Batch Loss: 0.0003597513714339584\n",
      "Epoch 2516, Loss: 0.001223493272846099, Final Batch Loss: 0.0003006643382832408\n",
      "Epoch 2517, Loss: 0.0004223211744829314, Final Batch Loss: 1.4595791071769781e-05\n",
      "Epoch 2518, Loss: 0.004536102642305195, Final Batch Loss: 0.0020728346426039934\n",
      "Epoch 2519, Loss: 0.0020713627454824746, Final Batch Loss: 0.00037748736212961376\n",
      "Epoch 2520, Loss: 0.006070503457522136, Final Batch Loss: 2.371073242102284e-05\n",
      "Epoch 2521, Loss: 0.003241454076487571, Final Batch Loss: 0.0018921440932899714\n",
      "Epoch 2522, Loss: 0.0022140057844808325, Final Batch Loss: 0.00024237700563389808\n",
      "Epoch 2523, Loss: 0.00048249788233079016, Final Batch Loss: 0.00012604615767486393\n",
      "Epoch 2524, Loss: 0.001966162191820331, Final Batch Loss: 0.0017852659802883863\n",
      "Epoch 2525, Loss: 0.0012703635002253577, Final Batch Loss: 8.361782238353044e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2526, Loss: 0.0007100343427737243, Final Batch Loss: 0.0003039755392819643\n",
      "Epoch 2527, Loss: 0.0010716397810028866, Final Batch Loss: 0.0005301781347952783\n",
      "Epoch 2528, Loss: 0.0019893335229426157, Final Batch Loss: 0.0017255634302273393\n",
      "Epoch 2529, Loss: 0.0011413967004045844, Final Batch Loss: 0.00039317552000284195\n",
      "Epoch 2530, Loss: 0.0011750179110094905, Final Batch Loss: 0.0006674470496363938\n",
      "Epoch 2531, Loss: 0.0008360338833881542, Final Batch Loss: 0.0005503536085598171\n",
      "Epoch 2532, Loss: 0.00038715562914148904, Final Batch Loss: 4.694820017903112e-05\n",
      "Epoch 2533, Loss: 0.000957735872361809, Final Batch Loss: 0.0003006816259585321\n",
      "Epoch 2534, Loss: 0.0017559962579980493, Final Batch Loss: 0.0001931694569066167\n",
      "Epoch 2535, Loss: 0.0010796022761496715, Final Batch Loss: 0.0007468467811122537\n",
      "Epoch 2536, Loss: 0.002658086406881921, Final Batch Loss: 0.00018551218090578914\n",
      "Epoch 2537, Loss: 0.0038286276321741752, Final Batch Loss: 3.9144935726653785e-05\n",
      "Epoch 2538, Loss: 0.00032058890792541206, Final Batch Loss: 8.021145913517103e-05\n",
      "Epoch 2539, Loss: 0.0004880440483248094, Final Batch Loss: 1.6355692423530854e-05\n",
      "Epoch 2540, Loss: 0.0006221693402039818, Final Batch Loss: 3.943012416129932e-05\n",
      "Epoch 2541, Loss: 0.0015120828757062554, Final Batch Loss: 0.0004613808123394847\n",
      "Epoch 2542, Loss: 0.0005425110284704715, Final Batch Loss: 0.00023417797638103366\n",
      "Epoch 2543, Loss: 0.0007938648996059783, Final Batch Loss: 0.0005218819133006036\n",
      "Epoch 2544, Loss: 0.0038741164607927203, Final Batch Loss: 0.0006501603638753295\n",
      "Epoch 2545, Loss: 0.004597467326675542, Final Batch Loss: 0.004122717306017876\n",
      "Epoch 2546, Loss: 0.0017161443684017286, Final Batch Loss: 4.9095600843429565e-05\n",
      "Epoch 2547, Loss: 0.0018717347011261154, Final Batch Loss: 0.00012248997518327087\n",
      "Epoch 2548, Loss: 0.003417396394070238, Final Batch Loss: 0.0002931477501988411\n",
      "Epoch 2549, Loss: 0.0006309905584203079, Final Batch Loss: 0.00023059827799443156\n",
      "Epoch 2550, Loss: 0.007739654160104692, Final Batch Loss: 0.0003391280770301819\n",
      "Epoch 2551, Loss: 0.00159857448306866, Final Batch Loss: 0.000491150189191103\n",
      "Epoch 2552, Loss: 0.060177144419867545, Final Batch Loss: 0.05805264040827751\n",
      "Epoch 2553, Loss: 0.003998459869762883, Final Batch Loss: 0.00011278245801804587\n",
      "Epoch 2554, Loss: 0.005228821071796119, Final Batch Loss: 0.0022878730669617653\n",
      "Epoch 2555, Loss: 0.0029354942380450666, Final Batch Loss: 0.00150652218144387\n",
      "Epoch 2556, Loss: 0.004539470639429055, Final Batch Loss: 9.887768828775734e-05\n",
      "Epoch 2557, Loss: 0.03433134446822805, Final Batch Loss: 0.005934193264693022\n",
      "Epoch 2558, Loss: 0.012764996499754488, Final Batch Loss: 0.010347449220716953\n",
      "Epoch 2559, Loss: 0.0008911437471397221, Final Batch Loss: 0.00030265250825323164\n",
      "Epoch 2560, Loss: 0.005521595856407657, Final Batch Loss: 0.0004421441408339888\n",
      "Epoch 2561, Loss: 0.0037708627060055733, Final Batch Loss: 0.0028342099394649267\n",
      "Epoch 2562, Loss: 0.0729151233099401, Final Batch Loss: 0.06959816813468933\n",
      "Epoch 2563, Loss: 0.00041493455501040444, Final Batch Loss: 0.00023439231154043227\n",
      "Epoch 2564, Loss: 0.00041275138210039586, Final Batch Loss: 0.00012779304233845323\n",
      "Epoch 2565, Loss: 0.0012829922488890588, Final Batch Loss: 0.0006462514284066856\n",
      "Epoch 2566, Loss: 0.0010511236177990213, Final Batch Loss: 0.0006507952930405736\n",
      "Epoch 2567, Loss: 0.0004919145940220915, Final Batch Loss: 0.00020425612456165254\n",
      "Epoch 2568, Loss: 0.010411852985271253, Final Batch Loss: 0.0003501075552776456\n",
      "Epoch 2569, Loss: 0.005340077914297581, Final Batch Loss: 0.0024436635430902243\n",
      "Epoch 2570, Loss: 0.005326482467353344, Final Batch Loss: 0.0030949425417929888\n",
      "Epoch 2571, Loss: 0.03414676000829786, Final Batch Loss: 0.0020517713855952024\n",
      "Epoch 2572, Loss: 0.001921736606163904, Final Batch Loss: 0.00027940611471422017\n",
      "Epoch 2573, Loss: 0.0018898062990047038, Final Batch Loss: 0.00034697557566687465\n",
      "Epoch 2574, Loss: 0.010432966271764599, Final Batch Loss: 0.010078622959554195\n",
      "Epoch 2575, Loss: 0.0028271855553612113, Final Batch Loss: 0.00026566843735054135\n",
      "Epoch 2576, Loss: 0.004879496060311794, Final Batch Loss: 0.0017841026419773698\n",
      "Epoch 2577, Loss: 0.004230465128784999, Final Batch Loss: 0.00014691377873532474\n",
      "Epoch 2578, Loss: 0.0016341380833182484, Final Batch Loss: 0.00057978491531685\n",
      "Epoch 2579, Loss: 0.006115789641626179, Final Batch Loss: 0.0004290355136618018\n",
      "Epoch 2580, Loss: 0.02802124692243524, Final Batch Loss: 0.011534033343195915\n",
      "Epoch 2581, Loss: 0.002769411454210058, Final Batch Loss: 0.00026528185117058456\n",
      "Epoch 2582, Loss: 0.0007582056423416361, Final Batch Loss: 0.00015869068738538772\n",
      "Epoch 2583, Loss: 0.005062729644123465, Final Batch Loss: 0.0020505478605628014\n",
      "Epoch 2584, Loss: 0.011863989668199793, Final Batch Loss: 0.0004476441827137023\n",
      "Epoch 2585, Loss: 0.002049196140433196, Final Batch Loss: 0.001735283643938601\n",
      "Epoch 2586, Loss: 0.0021041675463493448, Final Batch Loss: 3.474634650046937e-05\n",
      "Epoch 2587, Loss: 0.003839105716906488, Final Batch Loss: 0.0016788216307759285\n",
      "Epoch 2588, Loss: 0.0037276688526617363, Final Batch Loss: 0.00022698678367305547\n",
      "Epoch 2589, Loss: 0.0027559676964301616, Final Batch Loss: 0.0005365428514778614\n",
      "Epoch 2590, Loss: 0.0019399058510316536, Final Batch Loss: 0.0015203498769551516\n",
      "Epoch 2591, Loss: 0.0021065822584205307, Final Batch Loss: 0.0015954171540215611\n",
      "Epoch 2592, Loss: 0.0013203225207689684, Final Batch Loss: 2.7441285055829212e-05\n",
      "Epoch 2593, Loss: 0.0008148959896061569, Final Batch Loss: 0.00014770860434509814\n",
      "Epoch 2594, Loss: 0.0010081789077958092, Final Batch Loss: 0.00017309629765804857\n",
      "Epoch 2595, Loss: 0.0033883590513141826, Final Batch Loss: 8.543090370949358e-05\n",
      "Epoch 2596, Loss: 0.0017270131793338805, Final Batch Loss: 0.0005259488243609667\n",
      "Epoch 2597, Loss: 0.0027462544676382095, Final Batch Loss: 0.0007892384892329574\n",
      "Epoch 2598, Loss: 0.0013347542080737185, Final Batch Loss: 2.064939690171741e-05\n",
      "Epoch 2599, Loss: 0.0008708222740096971, Final Batch Loss: 0.0004359418817330152\n",
      "Epoch 2600, Loss: 0.00422246024118067, Final Batch Loss: 1.119994431064697e-05\n",
      "Epoch 2601, Loss: 0.0020712145924335346, Final Batch Loss: 0.00012527818034868687\n",
      "Epoch 2602, Loss: 0.0009108623780775815, Final Batch Loss: 0.00035314899287186563\n",
      "Epoch 2603, Loss: 0.00037038758091512136, Final Batch Loss: 0.0001332925312453881\n",
      "Epoch 2604, Loss: 0.0017741843475960195, Final Batch Loss: 0.0013092583976686\n",
      "Epoch 2605, Loss: 0.0005969984704279341, Final Batch Loss: 0.00036309866118244827\n",
      "Epoch 2606, Loss: 0.0021289055275701685, Final Batch Loss: 2.9249551516841166e-05\n",
      "Epoch 2607, Loss: 0.0007290418361662887, Final Batch Loss: 9.389529441250488e-05\n",
      "Epoch 2608, Loss: 0.002058882761048153, Final Batch Loss: 0.0006555929430760443\n",
      "Epoch 2609, Loss: 0.002995153441588627, Final Batch Loss: 0.0003208091948181391\n",
      "Epoch 2610, Loss: 0.014569859617040493, Final Batch Loss: 0.0003002551675308496\n",
      "Epoch 2611, Loss: 0.0020389341516420245, Final Batch Loss: 0.00024780823150649667\n",
      "Epoch 2612, Loss: 0.0011195570732525084, Final Batch Loss: 9.133051935350522e-05\n",
      "Epoch 2613, Loss: 0.004156874550972134, Final Batch Loss: 0.0006790850893594325\n",
      "Epoch 2614, Loss: 0.008059341969783418, Final Batch Loss: 0.0003771454794332385\n",
      "Epoch 2615, Loss: 0.009124705451540649, Final Batch Loss: 0.0008432482136413455\n",
      "Epoch 2616, Loss: 0.0007342943208641373, Final Batch Loss: 0.0001350939564872533\n",
      "Epoch 2617, Loss: 0.001017532282276079, Final Batch Loss: 0.0004369312373455614\n",
      "Epoch 2618, Loss: 0.001024870725814253, Final Batch Loss: 0.000271512457402423\n",
      "Epoch 2619, Loss: 0.004410513793118298, Final Batch Loss: 0.00036008708411827683\n",
      "Epoch 2620, Loss: 0.007682848779950291, Final Batch Loss: 0.00018366987933404744\n",
      "Epoch 2621, Loss: 0.011040523881092668, Final Batch Loss: 0.005441451910883188\n",
      "Epoch 2622, Loss: 0.0003345307050039992, Final Batch Loss: 5.173468525754288e-05\n",
      "Epoch 2623, Loss: 0.002936788441729732, Final Batch Loss: 8.931891352403909e-05\n",
      "Epoch 2624, Loss: 0.0008840886075631715, Final Batch Loss: 0.0005549166235141456\n",
      "Epoch 2625, Loss: 0.0007103007228579372, Final Batch Loss: 0.0004380539758130908\n",
      "Epoch 2626, Loss: 0.0033844523095467594, Final Batch Loss: 4.411014015204273e-05\n",
      "Epoch 2627, Loss: 0.0026609388733049855, Final Batch Loss: 0.00019650961621664464\n",
      "Epoch 2628, Loss: 0.0006401138671208173, Final Batch Loss: 0.0001272291992790997\n",
      "Epoch 2629, Loss: 0.0017683885198493954, Final Batch Loss: 4.1065180994337425e-05\n",
      "Epoch 2630, Loss: 0.0007776506245136261, Final Batch Loss: 0.0001270528882741928\n",
      "Epoch 2631, Loss: 0.002018654515268281, Final Batch Loss: 0.0002766956458799541\n",
      "Epoch 2632, Loss: 0.0008419485675403848, Final Batch Loss: 0.00036952251684851944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2633, Loss: 0.0009100263378059026, Final Batch Loss: 0.0005313644651323557\n",
      "Epoch 2634, Loss: 0.0018586087535368279, Final Batch Loss: 0.0004998181248083711\n",
      "Epoch 2635, Loss: 0.0010098118109453935, Final Batch Loss: 4.436316157807596e-05\n",
      "Epoch 2636, Loss: 0.0012291945531615056, Final Batch Loss: 0.00011815335165010765\n",
      "Epoch 2637, Loss: 0.012424494470906211, Final Batch Loss: 5.603870886261575e-05\n",
      "Epoch 2638, Loss: 0.0017164135351777077, Final Batch Loss: 0.0004488855192903429\n",
      "Epoch 2639, Loss: 0.0013298275880515575, Final Batch Loss: 0.00030961018637754023\n",
      "Epoch 2640, Loss: 0.0025709576293593273, Final Batch Loss: 0.0022694224026054144\n",
      "Epoch 2641, Loss: 0.0033946012990782037, Final Batch Loss: 0.0001454820594517514\n",
      "Epoch 2642, Loss: 0.0024544594962208066, Final Batch Loss: 0.00021078504505567253\n",
      "Epoch 2643, Loss: 0.00724794453708455, Final Batch Loss: 0.001278710667975247\n",
      "Epoch 2644, Loss: 0.003465208752459148, Final Batch Loss: 3.18697166221682e-05\n",
      "Epoch 2645, Loss: 0.0038312636606860906, Final Batch Loss: 0.0017922238912433386\n",
      "Epoch 2646, Loss: 0.0006866846815682948, Final Batch Loss: 0.0002150052023353055\n",
      "Epoch 2647, Loss: 0.0002744737703324063, Final Batch Loss: 1.7104595826822333e-05\n",
      "Epoch 2648, Loss: 0.0005787424088339321, Final Batch Loss: 0.00019516193424351513\n",
      "Epoch 2649, Loss: 0.00038548958309547743, Final Batch Loss: 1.4606272998207714e-05\n",
      "Epoch 2650, Loss: 0.004722496232716367, Final Batch Loss: 0.0008242072071880102\n",
      "Epoch 2651, Loss: 0.0019965858409705106, Final Batch Loss: 3.74617193301674e-05\n",
      "Epoch 2652, Loss: 0.02240368475759169, Final Batch Loss: 4.460472700884566e-05\n",
      "Epoch 2653, Loss: 0.0035310170496813953, Final Batch Loss: 0.00045232538832351565\n",
      "Epoch 2654, Loss: 0.0044786723592551425, Final Batch Loss: 0.003018416929990053\n",
      "Epoch 2655, Loss: 0.0031624647599528544, Final Batch Loss: 0.00011480267130536959\n",
      "Epoch 2656, Loss: 0.008627932213130407, Final Batch Loss: 0.0003751630720216781\n",
      "Epoch 2657, Loss: 0.0026860454963753, Final Batch Loss: 0.00019406445790082216\n",
      "Epoch 2658, Loss: 0.001260637101950124, Final Batch Loss: 0.00027600303292274475\n",
      "Epoch 2659, Loss: 0.001832405527238734, Final Batch Loss: 0.0002943879517260939\n",
      "Epoch 2660, Loss: 0.0007719857057963964, Final Batch Loss: 0.0006079528830014169\n",
      "Epoch 2661, Loss: 0.002418310526991263, Final Batch Loss: 0.002080013742670417\n",
      "Epoch 2662, Loss: 0.002462102347635664, Final Batch Loss: 0.000774949905462563\n",
      "Epoch 2663, Loss: 0.0005681740585714579, Final Batch Loss: 0.0003869697102345526\n",
      "Epoch 2664, Loss: 0.005562202772125602, Final Batch Loss: 0.0001426681556040421\n",
      "Epoch 2665, Loss: 0.0009281231177737936, Final Batch Loss: 0.0005282482597976923\n",
      "Epoch 2666, Loss: 0.0018753465847112238, Final Batch Loss: 0.0011745314113795757\n",
      "Epoch 2667, Loss: 0.0006440219804062508, Final Batch Loss: 0.00010443318024044856\n",
      "Epoch 2668, Loss: 0.013513000187231228, Final Batch Loss: 0.0003395778767298907\n",
      "Epoch 2669, Loss: 0.0006323852503555827, Final Batch Loss: 0.00010076881881104782\n",
      "Epoch 2670, Loss: 0.0025038600142579526, Final Batch Loss: 0.00033217002055607736\n",
      "Epoch 2671, Loss: 0.03394672154536238, Final Batch Loss: 0.02650083228945732\n",
      "Epoch 2672, Loss: 0.0048273858410539106, Final Batch Loss: 0.0002296969323651865\n",
      "Epoch 2673, Loss: 0.0020363265939522535, Final Batch Loss: 7.128584547899663e-05\n",
      "Epoch 2674, Loss: 0.019015594793017954, Final Batch Loss: 8.255368447862566e-05\n",
      "Epoch 2675, Loss: 0.0035156123813067097, Final Batch Loss: 0.0016070205019786954\n",
      "Epoch 2676, Loss: 0.001548649317555828, Final Batch Loss: 0.00036505350726656616\n",
      "Epoch 2677, Loss: 0.006665069056907669, Final Batch Loss: 0.00025655809440650046\n",
      "Epoch 2678, Loss: 0.0018477889825589955, Final Batch Loss: 0.001196698984131217\n",
      "Epoch 2679, Loss: 0.0012736626958940178, Final Batch Loss: 0.0007750368095003068\n",
      "Epoch 2680, Loss: 0.0015229028358589858, Final Batch Loss: 0.0002969852357637137\n",
      "Epoch 2681, Loss: 0.001709737201963435, Final Batch Loss: 1.6425356079707853e-05\n",
      "Epoch 2682, Loss: 0.00110183164360933, Final Batch Loss: 0.00014380690117832273\n",
      "Epoch 2683, Loss: 0.0005083581490907818, Final Batch Loss: 0.00018137488223146647\n",
      "Epoch 2684, Loss: 0.0028724307339871302, Final Batch Loss: 0.0022459032479673624\n",
      "Epoch 2685, Loss: 0.004741864177049138, Final Batch Loss: 8.543654985260218e-05\n",
      "Epoch 2686, Loss: 0.0023918240221973974, Final Batch Loss: 4.3962343625025824e-05\n",
      "Epoch 2687, Loss: 0.0020158221159363165, Final Batch Loss: 0.0001278704294236377\n",
      "Epoch 2688, Loss: 0.00140986024052836, Final Batch Loss: 0.0002449583844281733\n",
      "Epoch 2689, Loss: 0.000901994870218914, Final Batch Loss: 0.00012072343815816566\n",
      "Epoch 2690, Loss: 0.0003778633472393267, Final Batch Loss: 5.459130625240505e-05\n",
      "Epoch 2691, Loss: 0.0009722952891024761, Final Batch Loss: 0.00010836670844582841\n",
      "Epoch 2692, Loss: 0.0007881205092417076, Final Batch Loss: 0.0004990905872546136\n",
      "Epoch 2693, Loss: 0.001973636739421636, Final Batch Loss: 0.00016380081069655716\n",
      "Epoch 2694, Loss: 0.0008090560586424544, Final Batch Loss: 0.00013452082930598408\n",
      "Epoch 2695, Loss: 0.0010015916923293844, Final Batch Loss: 0.00021002932044211775\n",
      "Epoch 2696, Loss: 0.000631726230494678, Final Batch Loss: 0.00016722583677619696\n",
      "Epoch 2697, Loss: 0.0006143309092294658, Final Batch Loss: 2.6112067644135095e-05\n",
      "Epoch 2698, Loss: 0.0006779013783670962, Final Batch Loss: 0.0002941757265944034\n",
      "Epoch 2699, Loss: 0.0016123402238008566, Final Batch Loss: 0.0003940376336686313\n",
      "Epoch 2700, Loss: 0.0012114695928175934, Final Batch Loss: 4.250353231327608e-05\n",
      "Epoch 2701, Loss: 0.0011699833266902715, Final Batch Loss: 0.000507187214680016\n",
      "Epoch 2702, Loss: 0.0018737462814897299, Final Batch Loss: 0.00014427595306187868\n",
      "Epoch 2703, Loss: 0.0006351705815177411, Final Batch Loss: 0.00013053606380708516\n",
      "Epoch 2704, Loss: 0.0005970755883026868, Final Batch Loss: 0.0002939131809398532\n",
      "Epoch 2705, Loss: 0.00028906745865242556, Final Batch Loss: 0.00012964945926796645\n",
      "Epoch 2706, Loss: 0.0006722556136082858, Final Batch Loss: 0.00020996545208618045\n",
      "Epoch 2707, Loss: 0.0016752914089011028, Final Batch Loss: 0.0011511141201481223\n",
      "Epoch 2708, Loss: 0.0006825975142419338, Final Batch Loss: 0.0003050039813388139\n",
      "Epoch 2709, Loss: 0.0013213749843998812, Final Batch Loss: 8.189313666662201e-05\n",
      "Epoch 2710, Loss: 0.01255897109513171, Final Batch Loss: 0.00946708582341671\n",
      "Epoch 2711, Loss: 0.0002482691706973128, Final Batch Loss: 3.9838647353462875e-05\n",
      "Epoch 2712, Loss: 0.002896646299632266, Final Batch Loss: 0.0001452298747608438\n",
      "Epoch 2713, Loss: 0.0007143585389712825, Final Batch Loss: 0.00022768627968616784\n",
      "Epoch 2714, Loss: 0.00031279936229111627, Final Batch Loss: 0.00012617850734386593\n",
      "Epoch 2715, Loss: 0.0006390545531758107, Final Batch Loss: 3.800006379606202e-05\n",
      "Epoch 2716, Loss: 0.0010289738711435348, Final Batch Loss: 0.00020984429283998907\n",
      "Epoch 2717, Loss: 0.0016726581452530809, Final Batch Loss: 0.0006202031509019434\n",
      "Epoch 2718, Loss: 0.0007443429858540185, Final Batch Loss: 2.3971959308255464e-05\n",
      "Epoch 2719, Loss: 0.0010538436981732957, Final Batch Loss: 4.0987324609886855e-05\n",
      "Epoch 2720, Loss: 0.0014159274433040991, Final Batch Loss: 3.258531796745956e-05\n",
      "Epoch 2721, Loss: 0.006326486145553645, Final Batch Loss: 9.688741556601599e-05\n",
      "Epoch 2722, Loss: 0.001370468206005171, Final Batch Loss: 0.0007508996059186757\n",
      "Epoch 2723, Loss: 0.0006131703721621307, Final Batch Loss: 1.2455495379981585e-05\n",
      "Epoch 2724, Loss: 0.0013338437711354345, Final Batch Loss: 0.0006712748436257243\n",
      "Epoch 2725, Loss: 0.0013227768904471304, Final Batch Loss: 4.7463076043641195e-05\n",
      "Epoch 2726, Loss: 0.0023203804157674313, Final Batch Loss: 6.588059477508068e-05\n",
      "Epoch 2727, Loss: 0.0005232889852777589, Final Batch Loss: 0.00026608436019159853\n",
      "Epoch 2728, Loss: 0.0008830377482809126, Final Batch Loss: 0.00023734165006317198\n",
      "Epoch 2729, Loss: 0.0025412763498025015, Final Batch Loss: 0.0022482709027826786\n",
      "Epoch 2730, Loss: 0.0008041321925702505, Final Batch Loss: 1.425746813765727e-05\n",
      "Epoch 2731, Loss: 0.0004946146509610116, Final Batch Loss: 6.212861626408994e-05\n",
      "Epoch 2732, Loss: 0.0001968286233022809, Final Batch Loss: 4.6492190449498594e-05\n",
      "Epoch 2733, Loss: 0.0028159940557088703, Final Batch Loss: 8.652314136270434e-05\n",
      "Epoch 2734, Loss: 0.002200564387749182, Final Batch Loss: 6.525566277559847e-05\n",
      "Epoch 2735, Loss: 0.000805064146334189, Final Batch Loss: 8.002038157428615e-06\n",
      "Epoch 2736, Loss: 0.0021433942747535184, Final Batch Loss: 0.0006774542271159589\n",
      "Epoch 2737, Loss: 0.0005201683488849085, Final Batch Loss: 0.00013862595369573683\n",
      "Epoch 2738, Loss: 0.0004214655564283021, Final Batch Loss: 0.00022782449377700686\n",
      "Epoch 2739, Loss: 0.0015241451365000103, Final Batch Loss: 1.1157466360600665e-05\n",
      "Epoch 2740, Loss: 0.0002932599491032306, Final Batch Loss: 1.144192719948478e-05\n",
      "Epoch 2741, Loss: 0.0028786382754333317, Final Batch Loss: 9.054553811438382e-05\n",
      "Epoch 2742, Loss: 0.000716176800779067, Final Batch Loss: 6.354482320602983e-05\n",
      "Epoch 2743, Loss: 0.00031338663393398747, Final Batch Loss: 3.0107497877907008e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2744, Loss: 0.0012372511118883267, Final Batch Loss: 0.00020415792823769152\n",
      "Epoch 2745, Loss: 0.0011689658167597372, Final Batch Loss: 3.3795182389440015e-05\n",
      "Epoch 2746, Loss: 0.0010163136757910252, Final Batch Loss: 7.871152774896473e-05\n",
      "Epoch 2747, Loss: 0.00018380280744167976, Final Batch Loss: 3.21898733091075e-05\n",
      "Epoch 2748, Loss: 0.00016142316326295258, Final Batch Loss: 1.4826341612206306e-05\n",
      "Epoch 2749, Loss: 0.0036635611031670123, Final Batch Loss: 0.00046439297148026526\n",
      "Epoch 2750, Loss: 0.0034114467416657135, Final Batch Loss: 0.003262735204771161\n",
      "Epoch 2751, Loss: 0.0008538656729797367, Final Batch Loss: 5.6438326282659546e-05\n",
      "Epoch 2752, Loss: 0.0021648659276252147, Final Batch Loss: 1.8037968402495608e-05\n",
      "Epoch 2753, Loss: 0.0005425853523775004, Final Batch Loss: 0.00011470601748442277\n",
      "Epoch 2754, Loss: 0.006752247896656627, Final Batch Loss: 1.1716711014742032e-05\n",
      "Epoch 2755, Loss: 0.002548987278714776, Final Batch Loss: 0.001695754355750978\n",
      "Epoch 2756, Loss: 0.001599877476110123, Final Batch Loss: 8.194726251531392e-05\n",
      "Epoch 2757, Loss: 0.0008751064888201654, Final Batch Loss: 0.00024929296341724694\n",
      "Epoch 2758, Loss: 0.0017836731567513198, Final Batch Loss: 0.00024342005781363696\n",
      "Epoch 2759, Loss: 0.0015107768758753082, Final Batch Loss: 2.0911835235892795e-05\n",
      "Epoch 2760, Loss: 0.0005452091809274862, Final Batch Loss: 2.4583869162597694e-05\n",
      "Epoch 2761, Loss: 0.028764038172084838, Final Batch Loss: 0.028361910954117775\n",
      "Epoch 2762, Loss: 0.000672272450174205, Final Batch Loss: 0.00024737557396292686\n",
      "Epoch 2763, Loss: 0.0011256621219217777, Final Batch Loss: 0.00033291225554421544\n",
      "Epoch 2764, Loss: 0.001962711097803549, Final Batch Loss: 1.855397022154648e-05\n",
      "Epoch 2765, Loss: 0.00049476875574328, Final Batch Loss: 0.0002124114107573405\n",
      "Epoch 2766, Loss: 0.0035383029135118704, Final Batch Loss: 0.0034258535597473383\n",
      "Epoch 2767, Loss: 0.0020338638278190047, Final Batch Loss: 0.00013475216110236943\n",
      "Epoch 2768, Loss: 0.0012368204043013975, Final Batch Loss: 0.0004159353266004473\n",
      "Epoch 2769, Loss: 0.0022681964983348735, Final Batch Loss: 0.0010112423915416002\n",
      "Epoch 2770, Loss: 0.0013324193496373482, Final Batch Loss: 0.00011047282896470279\n",
      "Epoch 2771, Loss: 0.0010959829960484058, Final Batch Loss: 0.00036620465107262135\n",
      "Epoch 2772, Loss: 0.0008277685119537637, Final Batch Loss: 0.0002204611082561314\n",
      "Epoch 2773, Loss: 0.0038522329414263368, Final Batch Loss: 0.000202229741262272\n",
      "Epoch 2774, Loss: 0.0028457112348405644, Final Batch Loss: 7.988749712239951e-05\n",
      "Epoch 2775, Loss: 0.0005515308876056224, Final Batch Loss: 0.00013376549759414047\n",
      "Epoch 2776, Loss: 0.009573705960065126, Final Batch Loss: 0.00011013905168510973\n",
      "Epoch 2777, Loss: 0.0007090491926646791, Final Batch Loss: 0.00011315855226712301\n",
      "Epoch 2778, Loss: 0.0034840713487938046, Final Batch Loss: 0.0005201472085900605\n",
      "Epoch 2779, Loss: 0.0007901526332716458, Final Batch Loss: 4.252910002833232e-05\n",
      "Epoch 2780, Loss: 0.003511828341288492, Final Batch Loss: 0.0002587503695394844\n",
      "Epoch 2781, Loss: 0.00646132191104698, Final Batch Loss: 0.0023876538034528494\n",
      "Epoch 2782, Loss: 0.0004062828029418597, Final Batch Loss: 1.3885732187191024e-05\n",
      "Epoch 2783, Loss: 0.0006327913943096064, Final Batch Loss: 0.0003860325668938458\n",
      "Epoch 2784, Loss: 0.0024473247467540205, Final Batch Loss: 0.0003355584340170026\n",
      "Epoch 2785, Loss: 0.00030401418916881084, Final Batch Loss: 8.328099647769704e-05\n",
      "Epoch 2786, Loss: 0.0005174426059966208, Final Batch Loss: 2.973804839712102e-05\n",
      "Epoch 2787, Loss: 0.014087428731727414, Final Batch Loss: 0.00023088515445124358\n",
      "Epoch 2788, Loss: 0.0020826294567086734, Final Batch Loss: 0.00011506520240800455\n",
      "Epoch 2789, Loss: 0.000594448167248629, Final Batch Loss: 0.0004082487430423498\n",
      "Epoch 2790, Loss: 0.0005509751399586094, Final Batch Loss: 1.0814274901349563e-05\n",
      "Epoch 2791, Loss: 0.0015907179063106014, Final Batch Loss: 7.245197139127413e-06\n",
      "Epoch 2792, Loss: 0.0065105621397378854, Final Batch Loss: 0.00013898612814955413\n",
      "Epoch 2793, Loss: 0.0005941318122495431, Final Batch Loss: 2.5941630156012252e-05\n",
      "Epoch 2794, Loss: 0.01424519862030138, Final Batch Loss: 6.259043402678799e-06\n",
      "Epoch 2795, Loss: 0.00157072716683615, Final Batch Loss: 9.115143620874733e-05\n",
      "Epoch 2796, Loss: 0.002352858107769862, Final Batch Loss: 0.0005219080485403538\n",
      "Epoch 2797, Loss: 0.00046857070265104994, Final Batch Loss: 3.14343415084295e-05\n",
      "Epoch 2798, Loss: 0.0030811239521426614, Final Batch Loss: 2.2887015802552924e-05\n",
      "Epoch 2799, Loss: 0.000772129264078103, Final Batch Loss: 5.142502050148323e-05\n",
      "Epoch 2800, Loss: 0.0002575897324277321, Final Batch Loss: 5.5553675338160247e-05\n",
      "Epoch 2801, Loss: 0.0015191257243714062, Final Batch Loss: 2.1043741071480326e-05\n",
      "Epoch 2802, Loss: 0.0001880761446955148, Final Batch Loss: 3.340345938340761e-05\n",
      "Epoch 2803, Loss: 0.0005983643932268023, Final Batch Loss: 0.00030756351770833135\n",
      "Epoch 2804, Loss: 0.020782125895493664, Final Batch Loss: 3.599866613512859e-05\n",
      "Epoch 2805, Loss: 0.0025863032051347545, Final Batch Loss: 1.0522969205339905e-05\n",
      "Epoch 2806, Loss: 0.0001827631976993871, Final Batch Loss: 2.5706414817250334e-05\n",
      "Epoch 2807, Loss: 0.003231757815228775, Final Batch Loss: 0.00014461579849012196\n",
      "Epoch 2808, Loss: 0.0022997152263997123, Final Batch Loss: 0.0003279319789726287\n",
      "Epoch 2809, Loss: 0.0036432144115678966, Final Batch Loss: 0.0004847341915592551\n",
      "Epoch 2810, Loss: 0.0013354460679693148, Final Batch Loss: 0.0001791341055650264\n",
      "Epoch 2811, Loss: 0.006890467251650989, Final Batch Loss: 0.0048634810373187065\n",
      "Epoch 2812, Loss: 0.0011872573086293414, Final Batch Loss: 0.0003595963353291154\n",
      "Epoch 2813, Loss: 0.003419858490815386, Final Batch Loss: 0.0014557987451553345\n",
      "Epoch 2814, Loss: 0.0011147791956318542, Final Batch Loss: 0.0004429345717653632\n",
      "Epoch 2815, Loss: 0.015019003505585715, Final Batch Loss: 0.014165753498673439\n",
      "Epoch 2816, Loss: 0.023284471448278055, Final Batch Loss: 0.00023875696933828294\n",
      "Epoch 2817, Loss: 0.0006126928492449224, Final Batch Loss: 0.00021650909911841154\n",
      "Epoch 2818, Loss: 0.001161586322268704, Final Batch Loss: 6.088472218834795e-05\n",
      "Epoch 2819, Loss: 0.0025407820194232045, Final Batch Loss: 0.00014321506023406982\n",
      "Epoch 2820, Loss: 0.0022223370760912076, Final Batch Loss: 0.000300856598187238\n",
      "Epoch 2821, Loss: 0.010065928683616221, Final Batch Loss: 0.0002671077090781182\n",
      "Epoch 2822, Loss: 0.000577641163545195, Final Batch Loss: 7.436534360749647e-05\n",
      "Epoch 2823, Loss: 0.0012688419374171644, Final Batch Loss: 0.00037979811895638704\n",
      "Epoch 2824, Loss: 0.0022695341031067073, Final Batch Loss: 7.980651571415365e-05\n",
      "Epoch 2825, Loss: 0.009342990473669488, Final Batch Loss: 7.991010352270678e-05\n",
      "Epoch 2826, Loss: 0.00014192348135111388, Final Batch Loss: 3.561630001058802e-05\n",
      "Epoch 2827, Loss: 0.05783778498880565, Final Batch Loss: 0.042375318706035614\n",
      "Epoch 2828, Loss: 0.0009368654573336244, Final Batch Loss: 0.00047655569505877793\n",
      "Epoch 2829, Loss: 0.0009096628346014768, Final Batch Loss: 0.00015120813623070717\n",
      "Epoch 2830, Loss: 0.0009476982959313318, Final Batch Loss: 9.360323019791394e-05\n",
      "Epoch 2831, Loss: 0.017503927861980628, Final Batch Loss: 0.00010125721746589988\n",
      "Epoch 2832, Loss: 0.001308932769461535, Final Batch Loss: 0.0008805825491435826\n",
      "Epoch 2833, Loss: 0.0011861261191370431, Final Batch Loss: 4.388869638205506e-05\n",
      "Epoch 2834, Loss: 0.00898445671191439, Final Batch Loss: 0.006616044323891401\n",
      "Epoch 2835, Loss: 0.0005032292247051373, Final Batch Loss: 2.5123437808360904e-05\n",
      "Epoch 2836, Loss: 0.0036189877428114414, Final Batch Loss: 0.0004308907373342663\n",
      "Epoch 2837, Loss: 0.0018142577828257345, Final Batch Loss: 0.00014468493463937193\n",
      "Epoch 2838, Loss: 0.0014791181311011314, Final Batch Loss: 8.254838758148253e-05\n",
      "Epoch 2839, Loss: 0.002629021182656288, Final Batch Loss: 0.00026532099582254887\n",
      "Epoch 2840, Loss: 0.012575454609759618, Final Batch Loss: 9.452366066398099e-05\n",
      "Epoch 2841, Loss: 0.0015879309066804126, Final Batch Loss: 0.00017503388517070562\n",
      "Epoch 2842, Loss: 0.010322234476916492, Final Batch Loss: 0.00039764094981364906\n",
      "Epoch 2843, Loss: 0.0007722613663645461, Final Batch Loss: 0.0004158609372097999\n",
      "Epoch 2844, Loss: 0.0034800831781467423, Final Batch Loss: 0.0011466656578704715\n",
      "Epoch 2845, Loss: 0.0006584944203495979, Final Batch Loss: 0.0003577216702979058\n",
      "Epoch 2846, Loss: 0.004036370399262523, Final Batch Loss: 0.0024927209597080946\n",
      "Epoch 2847, Loss: 0.0008746689272811636, Final Batch Loss: 0.00028625098639167845\n",
      "Epoch 2848, Loss: 0.0014606048935092986, Final Batch Loss: 0.001193334232084453\n",
      "Epoch 2849, Loss: 0.0021286914015945513, Final Batch Loss: 0.0017056543147191405\n",
      "Epoch 2850, Loss: 0.06299018565914594, Final Batch Loss: 0.06197080761194229\n",
      "Epoch 2851, Loss: 0.0024545848173147533, Final Batch Loss: 0.0022347867488861084\n",
      "Epoch 2852, Loss: 0.0011211252058274113, Final Batch Loss: 0.0002936079690698534\n",
      "Epoch 2853, Loss: 0.005536248645512387, Final Batch Loss: 0.0010662222048267722\n",
      "Epoch 2854, Loss: 0.0036243527429178357, Final Batch Loss: 0.0009377940441481769\n",
      "Epoch 2855, Loss: 0.011628675420070067, Final Batch Loss: 0.008924209512770176\n",
      "Epoch 2856, Loss: 0.0028125325916334987, Final Batch Loss: 0.0006172445719130337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2857, Loss: 0.024617667819256894, Final Batch Loss: 0.00014304927026387304\n",
      "Epoch 2858, Loss: 0.004218898287945194, Final Batch Loss: 8.503682329319417e-05\n",
      "Epoch 2859, Loss: 0.000464334976641112, Final Batch Loss: 2.9756842195638455e-05\n",
      "Epoch 2860, Loss: 0.0009891596346278675, Final Batch Loss: 8.127540786517784e-05\n",
      "Epoch 2861, Loss: 0.0008851415332173929, Final Batch Loss: 0.00018468663620296866\n",
      "Epoch 2862, Loss: 0.0017186062323162332, Final Batch Loss: 0.00023383584630209953\n",
      "Epoch 2863, Loss: 0.00014286209625424817, Final Batch Loss: 4.095778422197327e-05\n",
      "Epoch 2864, Loss: 0.002199532071244903, Final Batch Loss: 2.4953202228061855e-05\n",
      "Epoch 2865, Loss: 0.0009691858140286058, Final Batch Loss: 9.648516424931586e-05\n",
      "Epoch 2866, Loss: 0.0003035733143406105, Final Batch Loss: 1.2143403182562906e-05\n",
      "Epoch 2867, Loss: 0.0004927686532028019, Final Batch Loss: 0.00012459397839847952\n",
      "Epoch 2868, Loss: 0.00045819050501449965, Final Batch Loss: 5.7453569752397016e-05\n",
      "Epoch 2869, Loss: 0.001145340720540844, Final Batch Loss: 0.00024093319370876998\n",
      "Epoch 2870, Loss: 0.006729537431965582, Final Batch Loss: 0.0001597632362972945\n",
      "Epoch 2871, Loss: 0.0011832282216346357, Final Batch Loss: 4.997605356038548e-05\n",
      "Epoch 2872, Loss: 0.0007983669420355, Final Batch Loss: 0.0004868950927630067\n",
      "Epoch 2873, Loss: 0.008790027583017945, Final Batch Loss: 0.003668366000056267\n",
      "Epoch 2874, Loss: 0.0008492476190440357, Final Batch Loss: 0.00045552599476650357\n",
      "Epoch 2875, Loss: 0.0007207328235381283, Final Batch Loss: 0.00011881505633937195\n",
      "Epoch 2876, Loss: 0.0030111223022686318, Final Batch Loss: 0.0018947911448776722\n",
      "Epoch 2877, Loss: 0.0008982532017398626, Final Batch Loss: 0.0005876843933947384\n",
      "Epoch 2878, Loss: 0.00031812717315915506, Final Batch Loss: 2.1390331312431954e-05\n",
      "Epoch 2879, Loss: 0.0006300919412751682, Final Batch Loss: 0.00010206213482888415\n",
      "Epoch 2880, Loss: 0.0006957452860660851, Final Batch Loss: 0.0002888682938646525\n",
      "Epoch 2881, Loss: 0.0002498371359251905, Final Batch Loss: 2.2589378204429522e-05\n",
      "Epoch 2882, Loss: 0.0008317696047015488, Final Batch Loss: 0.00041684863390401006\n",
      "Epoch 2883, Loss: 0.0006523584015667439, Final Batch Loss: 0.0001567134604556486\n",
      "Epoch 2884, Loss: 0.0006850065983599052, Final Batch Loss: 0.00017369915440212935\n",
      "Epoch 2885, Loss: 0.002080760350509081, Final Batch Loss: 8.445302228210494e-05\n",
      "Epoch 2886, Loss: 0.00040621608786750585, Final Batch Loss: 0.00011413858010200784\n",
      "Epoch 2887, Loss: 0.003923060238776088, Final Batch Loss: 1.1555818673514295e-05\n",
      "Epoch 2888, Loss: 0.00038455363392131403, Final Batch Loss: 0.0002202421019319445\n",
      "Epoch 2889, Loss: 0.0006884654721943662, Final Batch Loss: 0.00018682399240788072\n",
      "Epoch 2890, Loss: 0.0007919730705907568, Final Batch Loss: 0.00012171972775831819\n",
      "Epoch 2891, Loss: 0.0006968689849600196, Final Batch Loss: 0.0003117197775281966\n",
      "Epoch 2892, Loss: 0.001905760324007133, Final Batch Loss: 3.360865594004281e-05\n",
      "Epoch 2893, Loss: 0.001975287712411955, Final Batch Loss: 0.0002315566671313718\n",
      "Epoch 2894, Loss: 0.0018865984457079321, Final Batch Loss: 0.00018535813433118165\n",
      "Epoch 2895, Loss: 0.00030336802228703164, Final Batch Loss: 0.00014476497017312795\n",
      "Epoch 2896, Loss: 0.0008577536355005577, Final Batch Loss: 0.00025358484708704054\n",
      "Epoch 2897, Loss: 0.0028931088017998263, Final Batch Loss: 4.888026160188019e-05\n",
      "Epoch 2898, Loss: 0.00044639614861807786, Final Batch Loss: 5.663836418534629e-05\n",
      "Epoch 2899, Loss: 0.0005354696477297693, Final Batch Loss: 0.00015110291133169085\n",
      "Epoch 2900, Loss: 0.003998922686150763, Final Batch Loss: 0.0037730729673057795\n",
      "Epoch 2901, Loss: 0.000652533199172467, Final Batch Loss: 0.0003181959327775985\n",
      "Epoch 2902, Loss: 0.0005646851859637536, Final Batch Loss: 0.0003325445286463946\n",
      "Epoch 2903, Loss: 0.0002713773210416548, Final Batch Loss: 0.00018307390564586967\n",
      "Epoch 2904, Loss: 0.0014386057300725952, Final Batch Loss: 0.0003235063632018864\n",
      "Epoch 2905, Loss: 0.00031847584614297375, Final Batch Loss: 9.440678695682436e-05\n",
      "Epoch 2906, Loss: 0.001194421281979885, Final Batch Loss: 0.0002947670000139624\n",
      "Epoch 2907, Loss: 0.0004937990415783133, Final Batch Loss: 0.00015594273281749338\n",
      "Epoch 2908, Loss: 0.00038931276503717527, Final Batch Loss: 7.58854512241669e-05\n",
      "Epoch 2909, Loss: 0.0022276833769865334, Final Batch Loss: 0.0015405304729938507\n",
      "Epoch 2910, Loss: 0.001192302772324183, Final Batch Loss: 7.659678885829635e-06\n",
      "Epoch 2911, Loss: 0.0015469062418560497, Final Batch Loss: 5.844826955581084e-05\n",
      "Epoch 2912, Loss: 0.0019473694410407916, Final Batch Loss: 3.729196760104969e-05\n",
      "Epoch 2913, Loss: 0.007017081894446164, Final Batch Loss: 0.00040741090197116137\n",
      "Epoch 2914, Loss: 0.0009268936701118946, Final Batch Loss: 0.000494783220347017\n",
      "Epoch 2915, Loss: 0.0021217852336121723, Final Batch Loss: 0.00031538098119199276\n",
      "Epoch 2916, Loss: 0.0012150382026447915, Final Batch Loss: 0.0007012701244093478\n",
      "Epoch 2917, Loss: 0.0019482740462990478, Final Batch Loss: 0.00043533401913009584\n",
      "Epoch 2918, Loss: 0.0005334533270797692, Final Batch Loss: 6.34242533124052e-05\n",
      "Epoch 2919, Loss: 0.004134191520279273, Final Batch Loss: 0.0002912035852205008\n",
      "Epoch 2920, Loss: 0.0028656904250965454, Final Batch Loss: 0.002810709411278367\n",
      "Epoch 2921, Loss: 0.00033179733509314246, Final Batch Loss: 1.63068798428867e-05\n",
      "Epoch 2922, Loss: 0.0002957301403512247, Final Batch Loss: 4.903338776784949e-05\n",
      "Epoch 2923, Loss: 0.0004979253571946174, Final Batch Loss: 0.00020076367945875973\n",
      "Epoch 2924, Loss: 0.00019790854094026145, Final Batch Loss: 0.00013938138727098703\n",
      "Epoch 2925, Loss: 0.0016397448198404163, Final Batch Loss: 0.001175018958747387\n",
      "Epoch 2926, Loss: 0.0006193369190441445, Final Batch Loss: 0.00020142001449130476\n",
      "Epoch 2927, Loss: 0.00020757809033966623, Final Batch Loss: 1.4426597772398964e-05\n",
      "Epoch 2928, Loss: 0.00045888698514318094, Final Batch Loss: 0.0001675848034210503\n",
      "Epoch 2929, Loss: 0.0012408157635945827, Final Batch Loss: 4.40856019849889e-05\n",
      "Epoch 2930, Loss: 0.0004507149351411499, Final Batch Loss: 0.00020102399867027998\n",
      "Epoch 2931, Loss: 0.0005524394000531174, Final Batch Loss: 6.294552440522239e-05\n",
      "Epoch 2932, Loss: 0.0004532587990979664, Final Batch Loss: 0.0002764692180790007\n",
      "Epoch 2933, Loss: 0.00414946669661731, Final Batch Loss: 0.003949705511331558\n",
      "Epoch 2934, Loss: 0.0018669662313186564, Final Batch Loss: 5.3999719966668636e-05\n",
      "Epoch 2935, Loss: 0.002246751777420286, Final Batch Loss: 0.0020638771820813417\n",
      "Epoch 2936, Loss: 0.0004087409943167586, Final Batch Loss: 0.0002879204985219985\n",
      "Epoch 2937, Loss: 0.00042391454553580843, Final Batch Loss: 0.0001992482430068776\n",
      "Epoch 2938, Loss: 0.0020583182194968686, Final Batch Loss: 0.0001858576142694801\n",
      "Epoch 2939, Loss: 0.0005988145203446038, Final Batch Loss: 6.600231427000836e-05\n",
      "Epoch 2940, Loss: 0.0011385135585442185, Final Batch Loss: 0.00028189108707010746\n",
      "Epoch 2941, Loss: 0.0006920215091668069, Final Batch Loss: 0.0003354308137204498\n",
      "Epoch 2942, Loss: 0.00047462404472753406, Final Batch Loss: 0.00033146358327940106\n",
      "Epoch 2943, Loss: 0.0013377143477555364, Final Batch Loss: 0.00035280504380352795\n",
      "Epoch 2944, Loss: 0.0008910123942769133, Final Batch Loss: 1.2874788808403537e-05\n",
      "Epoch 2945, Loss: 0.002669843379408121, Final Batch Loss: 0.00026214297395199537\n",
      "Epoch 2946, Loss: 0.0021617665352096083, Final Batch Loss: 0.0020409440621733665\n",
      "Epoch 2947, Loss: 0.0011162182904627116, Final Batch Loss: 6.0618272073043045e-06\n",
      "Epoch 2948, Loss: 0.0002941232560260687, Final Batch Loss: 0.0001900587376439944\n",
      "Epoch 2949, Loss: 0.002786570301395841, Final Batch Loss: 0.00017838338681031018\n",
      "Epoch 2950, Loss: 0.001802687140298076, Final Batch Loss: 9.420259448233992e-05\n",
      "Epoch 2951, Loss: 0.0005676155451510567, Final Batch Loss: 3.238013232476078e-05\n",
      "Epoch 2952, Loss: 0.00017132118136942154, Final Batch Loss: 0.00012214032176416367\n",
      "Epoch 2953, Loss: 0.000402917114115553, Final Batch Loss: 2.08716701308731e-05\n",
      "Epoch 2954, Loss: 0.00037326308665797114, Final Batch Loss: 0.0001613895146874711\n",
      "Epoch 2955, Loss: 0.0003731899123522453, Final Batch Loss: 0.0001544304977869615\n",
      "Epoch 2956, Loss: 0.0017482445109635592, Final Batch Loss: 0.0015673035522922873\n",
      "Epoch 2957, Loss: 0.005993982704239897, Final Batch Loss: 0.00010993068281095475\n",
      "Epoch 2958, Loss: 0.00015876135239523137, Final Batch Loss: 1.1065557373513002e-05\n",
      "Epoch 2959, Loss: 0.00029324775641725864, Final Batch Loss: 2.5669285605545156e-05\n",
      "Epoch 2960, Loss: 0.00048815446280059405, Final Batch Loss: 3.039578950847499e-05\n",
      "Epoch 2961, Loss: 0.0012162176208221354, Final Batch Loss: 9.196926112053916e-05\n",
      "Epoch 2962, Loss: 0.001612494386790786, Final Batch Loss: 6.594588921871036e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2963, Loss: 0.000191179779903905, Final Batch Loss: 6.343371933326125e-05\n",
      "Epoch 2964, Loss: 0.005559186669415794, Final Batch Loss: 0.004664687439799309\n",
      "Epoch 2965, Loss: 0.024869212589692324, Final Batch Loss: 6.295921048149467e-05\n",
      "Epoch 2966, Loss: 0.022359747352311388, Final Batch Loss: 0.0003709559387061745\n",
      "Epoch 2967, Loss: 0.0012942538742208853, Final Batch Loss: 0.00012633630831260234\n",
      "Epoch 2968, Loss: 0.0017617800913285464, Final Batch Loss: 0.001409183256328106\n",
      "Epoch 2969, Loss: 0.0003417600346438121, Final Batch Loss: 2.6549623726168647e-05\n",
      "Epoch 2970, Loss: 0.00036794929110328667, Final Batch Loss: 5.9075038734590635e-05\n",
      "Epoch 2971, Loss: 0.0019174660010321531, Final Batch Loss: 0.0015303080435842276\n",
      "Epoch 2972, Loss: 0.0006470847656601109, Final Batch Loss: 6.43784151179716e-05\n",
      "Epoch 2973, Loss: 0.0002702047331695212, Final Batch Loss: 6.03619082539808e-06\n",
      "Epoch 2974, Loss: 0.0015871959913056344, Final Batch Loss: 0.001156280399300158\n",
      "Epoch 2975, Loss: 0.0007176296567195095, Final Batch Loss: 5.05037751281634e-05\n",
      "Epoch 2976, Loss: 0.0008883447517291643, Final Batch Loss: 8.674451964907348e-05\n",
      "Epoch 2977, Loss: 0.002309202463948168, Final Batch Loss: 0.0019342148443683982\n",
      "Epoch 2978, Loss: 0.0005549686525228026, Final Batch Loss: 0.00021711221779696643\n",
      "Epoch 2979, Loss: 0.00015745113159937318, Final Batch Loss: 2.660898280737456e-05\n",
      "Epoch 2980, Loss: 0.004861848428845406, Final Batch Loss: 0.00022463717323262244\n",
      "Epoch 2981, Loss: 0.00044890015851706266, Final Batch Loss: 0.0002942730498034507\n",
      "Epoch 2982, Loss: 0.0008725927000341471, Final Batch Loss: 3.150247721350752e-05\n",
      "Epoch 2983, Loss: 0.005834853451233357, Final Batch Loss: 0.0016601028619334102\n",
      "Epoch 2984, Loss: 0.0017495663541922113, Final Batch Loss: 1.8696036931942217e-05\n",
      "Epoch 2985, Loss: 0.0003582154677133076, Final Batch Loss: 0.0001399778702761978\n",
      "Epoch 2986, Loss: 0.0011843043175758794, Final Batch Loss: 3.1438034056918696e-05\n",
      "Epoch 2987, Loss: 0.005698763416148722, Final Batch Loss: 0.003994539380073547\n",
      "Epoch 2988, Loss: 0.001443625344109023, Final Batch Loss: 1.5142741176532581e-05\n",
      "Epoch 2989, Loss: 0.0015392879190585518, Final Batch Loss: 3.5722819120564964e-06\n",
      "Epoch 2990, Loss: 0.00018299187104275916, Final Batch Loss: 1.0075289537780918e-05\n",
      "Epoch 2991, Loss: 0.0004207702586427331, Final Batch Loss: 0.00029403530061244965\n",
      "Epoch 2992, Loss: 0.0002263685964862816, Final Batch Loss: 7.988935249159113e-05\n",
      "Epoch 2993, Loss: 0.00016141006381076295, Final Batch Loss: 3.5982731787953526e-05\n",
      "Epoch 2994, Loss: 0.00026793425058713183, Final Batch Loss: 1.814939605537802e-05\n",
      "Epoch 2995, Loss: 0.001294740432058461, Final Batch Loss: 0.0009641604265198112\n",
      "Epoch 2996, Loss: 0.005898875664570369, Final Batch Loss: 0.003380504436790943\n",
      "Epoch 2997, Loss: 0.00039423752241418697, Final Batch Loss: 0.00024997821310535073\n",
      "Epoch 2998, Loss: 0.0010987008572556078, Final Batch Loss: 0.00018200470367446542\n",
      "Epoch 2999, Loss: 0.001295331254368648, Final Batch Loss: 0.0010692632058635354\n",
      "Epoch 3000, Loss: 0.00019458328642940614, Final Batch Loss: 4.267472104402259e-05\n",
      "Epoch 3001, Loss: 0.0012598405737662688, Final Batch Loss: 0.00030222241184674203\n",
      "Epoch 3002, Loss: 8.753154452278977e-05, Final Batch Loss: 3.954737985623069e-05\n",
      "Epoch 3003, Loss: 0.00019705655995494453, Final Batch Loss: 0.00016743867308832705\n",
      "Epoch 3004, Loss: 0.0015418149487231858, Final Batch Loss: 0.0014176415279507637\n",
      "Epoch 3005, Loss: 0.0014152877338347025, Final Batch Loss: 0.00011226521019125357\n",
      "Epoch 3006, Loss: 0.00037433496299854596, Final Batch Loss: 0.00032651275978423655\n",
      "Epoch 3007, Loss: 0.0001688929260126315, Final Batch Loss: 5.7088032917818055e-05\n",
      "Epoch 3008, Loss: 0.006980938378546853, Final Batch Loss: 0.006146105471998453\n",
      "Epoch 3009, Loss: 0.000280332395050209, Final Batch Loss: 4.097519922652282e-05\n",
      "Epoch 3010, Loss: 0.00035681435838341713, Final Batch Loss: 0.00018594233551993966\n",
      "Epoch 3011, Loss: 0.0010700762031774502, Final Batch Loss: 0.00047850809642113745\n",
      "Epoch 3012, Loss: 0.001034084132697899, Final Batch Loss: 0.0003206179535482079\n",
      "Epoch 3013, Loss: 0.0009050087674040697, Final Batch Loss: 1.2329262062849011e-05\n",
      "Epoch 3014, Loss: 0.0004518940768321045, Final Batch Loss: 0.00010916670726146549\n",
      "Epoch 3015, Loss: 0.0012087293289368972, Final Batch Loss: 0.0008417387725785375\n",
      "Epoch 3016, Loss: 0.0003131931516691111, Final Batch Loss: 0.00012638731277547777\n",
      "Epoch 3017, Loss: 0.0036010003968840465, Final Batch Loss: 0.0029312772676348686\n",
      "Epoch 3018, Loss: 0.00033427271773689426, Final Batch Loss: 3.158787512802519e-05\n",
      "Epoch 3019, Loss: 0.005660874619934475, Final Batch Loss: 0.005447729956358671\n",
      "Epoch 3020, Loss: 8.72492582857376e-05, Final Batch Loss: 2.4760034648352303e-05\n",
      "Epoch 3021, Loss: 0.006652127425695653, Final Batch Loss: 1.1643480320344679e-05\n",
      "Epoch 3022, Loss: 0.008558300180084188, Final Batch Loss: 0.008455968461930752\n",
      "Epoch 3023, Loss: 0.00036260915112507064, Final Batch Loss: 0.0002625152701511979\n",
      "Epoch 3024, Loss: 0.00046545865188818425, Final Batch Loss: 0.00023803567455615848\n",
      "Epoch 3025, Loss: 0.0006057748960301979, Final Batch Loss: 0.00012945615162607282\n",
      "Epoch 3026, Loss: 0.0004486838552111294, Final Batch Loss: 6.0066926380386576e-05\n",
      "Epoch 3027, Loss: 0.0020761594951181905, Final Batch Loss: 0.000484637072077021\n",
      "Epoch 3028, Loss: 0.00027221946220379323, Final Batch Loss: 0.00016844755737110972\n",
      "Epoch 3029, Loss: 0.0027233730843363446, Final Batch Loss: 7.788850780343637e-05\n",
      "Epoch 3030, Loss: 0.004447770144906826, Final Batch Loss: 0.004239547997713089\n",
      "Epoch 3031, Loss: 0.028035366121912375, Final Batch Loss: 0.004424379672855139\n",
      "Epoch 3032, Loss: 0.00028460382600314915, Final Batch Loss: 7.498993363697082e-05\n",
      "Epoch 3033, Loss: 0.00048068953128677094, Final Batch Loss: 0.00011928527237614617\n",
      "Epoch 3034, Loss: 0.00033278442424489185, Final Batch Loss: 9.767724986886606e-05\n",
      "Epoch 3035, Loss: 0.0022894095454830676, Final Batch Loss: 0.0015237184707075357\n",
      "Epoch 3036, Loss: 0.00028861643659183756, Final Batch Loss: 0.00018451536016073078\n",
      "Epoch 3037, Loss: 0.000905311550013721, Final Batch Loss: 4.6851084334775805e-05\n",
      "Epoch 3038, Loss: 0.00019204403724870645, Final Batch Loss: 4.503712261794135e-06\n",
      "Epoch 3039, Loss: 0.0022744414054614026, Final Batch Loss: 0.00021040889259893447\n",
      "Epoch 3040, Loss: 0.000687729141645832, Final Batch Loss: 4.186176010989584e-05\n",
      "Epoch 3041, Loss: 0.0015887512340668763, Final Batch Loss: 5.4099577937449794e-06\n",
      "Epoch 3042, Loss: 0.00036630443719332106, Final Batch Loss: 2.4471239157719538e-05\n",
      "Epoch 3043, Loss: 0.0012687239614024293, Final Batch Loss: 0.0011923684505745769\n",
      "Epoch 3044, Loss: 0.0002502923052816186, Final Batch Loss: 2.814245453919284e-05\n",
      "Epoch 3045, Loss: 0.0009443767339689657, Final Batch Loss: 5.0383314373902977e-05\n",
      "Epoch 3046, Loss: 0.007160790744819678, Final Batch Loss: 0.00640067970380187\n",
      "Epoch 3047, Loss: 0.0002708596766751725, Final Batch Loss: 0.00012465591134969145\n",
      "Epoch 3048, Loss: 0.003611814208852593, Final Batch Loss: 9.520535968476906e-05\n",
      "Epoch 3049, Loss: 0.00312983151525259, Final Batch Loss: 0.0028547439724206924\n",
      "Epoch 3050, Loss: 0.0007734056089248043, Final Batch Loss: 0.0002500085101928562\n",
      "Epoch 3051, Loss: 0.00043577874384936877, Final Batch Loss: 2.1879113774048164e-05\n",
      "Epoch 3052, Loss: 0.00011431565690145362, Final Batch Loss: 1.826493644330185e-05\n",
      "Epoch 3053, Loss: 0.0027393357049732003, Final Batch Loss: 0.00027824201970361173\n",
      "Epoch 3054, Loss: 0.001902591422549449, Final Batch Loss: 0.00012371579941827804\n",
      "Epoch 3055, Loss: 0.00023086399232852273, Final Batch Loss: 8.612458623247221e-05\n",
      "Epoch 3056, Loss: 0.001349388672679197, Final Batch Loss: 0.00025357023696415126\n",
      "Epoch 3057, Loss: 0.00024731235498620663, Final Batch Loss: 0.0001690550852799788\n",
      "Epoch 3058, Loss: 0.0003435371436353307, Final Batch Loss: 0.00021181585907470435\n",
      "Epoch 3059, Loss: 0.0004539902802207507, Final Batch Loss: 8.664318738738075e-05\n",
      "Epoch 3060, Loss: 0.0009262507883249782, Final Batch Loss: 0.0003669270081445575\n",
      "Epoch 3061, Loss: 0.0011916654111701064, Final Batch Loss: 0.0009476313134655356\n",
      "Epoch 3062, Loss: 0.004227417492074892, Final Batch Loss: 0.0020372066646814346\n",
      "Epoch 3063, Loss: 0.0018284653051523492, Final Batch Loss: 3.828054468613118e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3064, Loss: 0.0003339408413012279, Final Batch Loss: 3.887964703608304e-05\n",
      "Epoch 3065, Loss: 0.0002106048632413149, Final Batch Loss: 0.00011376425391063094\n",
      "Epoch 3066, Loss: 0.0018424913396302145, Final Batch Loss: 7.724245369900018e-05\n",
      "Epoch 3067, Loss: 0.006752667406317414, Final Batch Loss: 3.110824536634027e-06\n",
      "Epoch 3068, Loss: 0.0008698618003109004, Final Batch Loss: 0.0006651458679698408\n",
      "Epoch 3069, Loss: 0.0002832774625858292, Final Batch Loss: 0.00019921887724194676\n",
      "Epoch 3070, Loss: 0.0017349911177007016, Final Batch Loss: 0.0014694913988932967\n",
      "Epoch 3071, Loss: 0.00822363406769, Final Batch Loss: 0.007769622839987278\n",
      "Epoch 3072, Loss: 0.0002713801823119866, Final Batch Loss: 1.549674379930366e-05\n",
      "Epoch 3073, Loss: 0.002444463400024688, Final Batch Loss: 3.930687307729386e-05\n",
      "Epoch 3074, Loss: 0.01562195700716984, Final Batch Loss: 1.526707455923315e-05\n",
      "Epoch 3075, Loss: 0.0002478795031493064, Final Batch Loss: 7.832657865947112e-05\n",
      "Epoch 3076, Loss: 0.044306185798632214, Final Batch Loss: 5.224366395850666e-05\n",
      "Epoch 3077, Loss: 0.00043131407619512174, Final Batch Loss: 2.2575399270863272e-05\n",
      "Epoch 3078, Loss: 0.0009069613297469914, Final Batch Loss: 0.0006214990862645209\n",
      "Epoch 3079, Loss: 0.0007500375431845896, Final Batch Loss: 0.0005324177909642458\n",
      "Epoch 3080, Loss: 0.0012985794528503902, Final Batch Loss: 4.403631464811042e-05\n",
      "Epoch 3081, Loss: 0.000414252466725884, Final Batch Loss: 5.1639170123962685e-05\n",
      "Epoch 3082, Loss: 0.013889931802623323, Final Batch Loss: 1.7995005691773258e-05\n",
      "Epoch 3083, Loss: 0.0005055819656263338, Final Batch Loss: 1.1808244380517863e-05\n",
      "Epoch 3084, Loss: 0.004933362557494547, Final Batch Loss: 0.00017375808965880424\n",
      "Epoch 3085, Loss: 0.0009436034597456455, Final Batch Loss: 0.00012356710794847459\n",
      "Epoch 3086, Loss: 0.0004126711210119538, Final Batch Loss: 0.0002510848280508071\n",
      "Epoch 3087, Loss: 0.00035355966156203067, Final Batch Loss: 0.0001801144244382158\n",
      "Epoch 3088, Loss: 0.005549067158426624, Final Batch Loss: 0.005357018206268549\n",
      "Epoch 3089, Loss: 0.00039453099452657625, Final Batch Loss: 1.9299804989714175e-05\n",
      "Epoch 3090, Loss: 0.00022972023361944593, Final Batch Loss: 4.261077629053034e-05\n",
      "Epoch 3091, Loss: 0.00041113064798992127, Final Batch Loss: 0.0002777503104880452\n",
      "Epoch 3092, Loss: 0.00041774097189772874, Final Batch Loss: 0.0002541565045248717\n",
      "Epoch 3093, Loss: 0.0013524434107239358, Final Batch Loss: 0.00035596403176896274\n",
      "Epoch 3094, Loss: 0.00042686343658715487, Final Batch Loss: 5.856237839907408e-05\n",
      "Epoch 3095, Loss: 0.00014340248026201152, Final Batch Loss: 5.863794285687618e-05\n",
      "Epoch 3096, Loss: 0.00467193516305997, Final Batch Loss: 4.2093408410437405e-05\n",
      "Epoch 3097, Loss: 0.0004903249191556824, Final Batch Loss: 0.00022719541448168457\n",
      "Epoch 3098, Loss: 0.0002641718519953429, Final Batch Loss: 1.0362577995692845e-05\n",
      "Epoch 3099, Loss: 0.0009332243862445466, Final Batch Loss: 0.0006252218736335635\n",
      "Epoch 3100, Loss: 0.00037449364026542753, Final Batch Loss: 7.369964441750199e-05\n",
      "Epoch 3101, Loss: 0.001236612704815343, Final Batch Loss: 4.511515726335347e-05\n",
      "Epoch 3102, Loss: 0.0009919266049109865, Final Batch Loss: 0.0007176318904384971\n",
      "Epoch 3103, Loss: 0.0006762754710507579, Final Batch Loss: 6.26571782049723e-05\n",
      "Epoch 3104, Loss: 0.000283293458778644, Final Batch Loss: 0.0001448965776944533\n",
      "Epoch 3105, Loss: 0.0019716388633241877, Final Batch Loss: 8.174912363756448e-05\n",
      "Epoch 3106, Loss: 0.0003992026249761693, Final Batch Loss: 7.433453720295802e-05\n",
      "Epoch 3107, Loss: 0.0023842634254833683, Final Batch Loss: 0.0015886323526501656\n",
      "Epoch 3108, Loss: 0.0001645829306653468, Final Batch Loss: 2.200761082349345e-05\n",
      "Epoch 3109, Loss: 0.0014161242470436264, Final Batch Loss: 1.882137803477235e-05\n",
      "Epoch 3110, Loss: 0.004935512348311022, Final Batch Loss: 0.00313098868355155\n",
      "Epoch 3111, Loss: 0.003607052560255397, Final Batch Loss: 3.850424400297925e-05\n",
      "Epoch 3112, Loss: 0.0001598178760104929, Final Batch Loss: 4.437312782101799e-06\n",
      "Epoch 3113, Loss: 0.0028154010656180617, Final Batch Loss: 3.3935070860025007e-06\n",
      "Epoch 3114, Loss: 0.005665635901095811, Final Batch Loss: 8.212262036977336e-05\n",
      "Epoch 3115, Loss: 0.0008919841002352769, Final Batch Loss: 0.00047678849659860134\n",
      "Epoch 3116, Loss: 0.019660888996440917, Final Batch Loss: 8.953461656346917e-05\n",
      "Epoch 3117, Loss: 0.0012685169494943693, Final Batch Loss: 0.0010409675305709243\n",
      "Epoch 3118, Loss: 0.0035014469831367023, Final Batch Loss: 0.0030100003350526094\n",
      "Epoch 3119, Loss: 0.014770880021387711, Final Batch Loss: 0.00017507115262560546\n",
      "Epoch 3120, Loss: 0.010610981273202924, Final Batch Loss: 0.00033134969999082386\n",
      "Epoch 3121, Loss: 0.0005885619611945003, Final Batch Loss: 0.00017755354929249734\n",
      "Epoch 3122, Loss: 0.000604234155616723, Final Batch Loss: 0.0003303746343590319\n",
      "Epoch 3123, Loss: 0.0009937772119883448, Final Batch Loss: 7.451183046214283e-05\n",
      "Epoch 3124, Loss: 0.001673693472184823, Final Batch Loss: 0.0006136972224339843\n",
      "Epoch 3125, Loss: 0.002934491632913705, Final Batch Loss: 7.727956835879013e-05\n",
      "Epoch 3126, Loss: 0.0004435184418980498, Final Batch Loss: 5.3561554523184896e-05\n",
      "Epoch 3127, Loss: 0.0008739628392504528, Final Batch Loss: 0.0005198982544243336\n",
      "Epoch 3128, Loss: 0.0014633436549047474, Final Batch Loss: 0.0011627606581896544\n",
      "Epoch 3129, Loss: 0.0016080756140581798, Final Batch Loss: 0.0012587275123223662\n",
      "Epoch 3130, Loss: 0.00018331670435145497, Final Batch Loss: 3.936115535907447e-05\n",
      "Epoch 3131, Loss: 0.00056682679860387, Final Batch Loss: 0.00020522500562947243\n",
      "Epoch 3132, Loss: 0.0006890749937156215, Final Batch Loss: 0.0002429859305266291\n",
      "Epoch 3133, Loss: 0.00038683142338413745, Final Batch Loss: 8.368354610865936e-05\n",
      "Epoch 3134, Loss: 0.0024905493337428197, Final Batch Loss: 2.0733641576953232e-05\n",
      "Epoch 3135, Loss: 0.0010416652221465483, Final Batch Loss: 0.0003985655202995986\n",
      "Epoch 3136, Loss: 0.0008333877667610068, Final Batch Loss: 4.51613450422883e-05\n",
      "Epoch 3137, Loss: 0.002167954491596902, Final Batch Loss: 5.447166404337622e-05\n",
      "Epoch 3138, Loss: 0.0001642739034650731, Final Batch Loss: 5.317292743711732e-05\n",
      "Epoch 3139, Loss: 0.004785820961842546, Final Batch Loss: 0.004690882284194231\n",
      "Epoch 3140, Loss: 0.0013945042592240497, Final Batch Loss: 0.00014919822569936514\n",
      "Epoch 3141, Loss: 0.0002669140204716314, Final Batch Loss: 1.7842550050772843e-06\n",
      "Epoch 3142, Loss: 0.0018961817113449797, Final Batch Loss: 0.0004017690662294626\n",
      "Epoch 3143, Loss: 0.00284014614589978, Final Batch Loss: 0.002149066422134638\n",
      "Epoch 3144, Loss: 0.00014703490342071746, Final Batch Loss: 1.8446382455294952e-05\n",
      "Epoch 3145, Loss: 0.0002766153520497028, Final Batch Loss: 0.00010405922512290999\n",
      "Epoch 3146, Loss: 0.00028426495191524737, Final Batch Loss: 3.247601125622168e-05\n",
      "Epoch 3147, Loss: 0.00016481468446727376, Final Batch Loss: 1.928273013618309e-05\n",
      "Epoch 3148, Loss: 0.0018455674799042754, Final Batch Loss: 1.9845094357151538e-05\n",
      "Epoch 3149, Loss: 0.0009560392682033125, Final Batch Loss: 3.130038021481596e-05\n",
      "Epoch 3150, Loss: 0.0030118629365460947, Final Batch Loss: 0.0029104144778102636\n",
      "Epoch 3151, Loss: 0.00024043575103860348, Final Batch Loss: 7.432328129652888e-05\n",
      "Epoch 3152, Loss: 0.001061914434103528, Final Batch Loss: 3.890652806148864e-05\n",
      "Epoch 3153, Loss: 0.0025129394580289954, Final Batch Loss: 0.0013293590163812041\n",
      "Epoch 3154, Loss: 0.0005864240920345765, Final Batch Loss: 0.00035712134558707476\n",
      "Epoch 3155, Loss: 0.0002639717895362992, Final Batch Loss: 1.610036997590214e-05\n",
      "Epoch 3156, Loss: 0.004342377481407311, Final Batch Loss: 0.004280495457351208\n",
      "Epoch 3157, Loss: 0.0004231268849252956, Final Batch Loss: 4.83459843962919e-05\n",
      "Epoch 3158, Loss: 0.0003540614343364723, Final Batch Loss: 9.388029866386205e-05\n",
      "Epoch 3159, Loss: 0.0004602814224199392, Final Batch Loss: 0.00011855443881358951\n",
      "Epoch 3160, Loss: 0.0005142294976394624, Final Batch Loss: 3.375559754204005e-05\n",
      "Epoch 3161, Loss: 0.0011340735727571882, Final Batch Loss: 0.00012612182763405144\n",
      "Epoch 3162, Loss: 0.00017642087004787754, Final Batch Loss: 1.9620896637206897e-05\n",
      "Epoch 3163, Loss: 0.004357290833922889, Final Batch Loss: 0.003995354752987623\n",
      "Epoch 3164, Loss: 0.0007335757927648956, Final Batch Loss: 2.9927594368928112e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3165, Loss: 0.000757192825403763, Final Batch Loss: 3.8714188121957704e-05\n",
      "Epoch 3166, Loss: 0.0023603466106578708, Final Batch Loss: 9.82885030680336e-05\n",
      "Epoch 3167, Loss: 0.0029379166262515355, Final Batch Loss: 3.338519672979601e-05\n",
      "Epoch 3168, Loss: 0.00036933404408046044, Final Batch Loss: 1.7390393622918054e-05\n",
      "Epoch 3169, Loss: 0.0013675617228727788, Final Batch Loss: 0.0008020566892810166\n",
      "Epoch 3170, Loss: 0.0002405898558208719, Final Batch Loss: 1.7698061128612608e-05\n",
      "Epoch 3171, Loss: 0.0027198777315788902, Final Batch Loss: 2.027955633820966e-05\n",
      "Epoch 3172, Loss: 0.000239297691223328, Final Batch Loss: 1.3755639884038828e-05\n",
      "Epoch 3173, Loss: 0.0016700660271453671, Final Batch Loss: 6.302855763351545e-05\n",
      "Epoch 3174, Loss: 0.0002861342491087271, Final Batch Loss: 2.2812433599028736e-05\n",
      "Epoch 3175, Loss: 0.0007822905658940726, Final Batch Loss: 6.468316769314697e-06\n",
      "Epoch 3176, Loss: 0.0011381793665350415, Final Batch Loss: 0.0005049890605732799\n",
      "Epoch 3177, Loss: 0.00027806483558379114, Final Batch Loss: 3.085553180426359e-05\n",
      "Epoch 3178, Loss: 0.000375255807512076, Final Batch Loss: 9.882749054668238e-07\n",
      "Epoch 3179, Loss: 0.000263465027728671, Final Batch Loss: 7.465937869710615e-06\n",
      "Epoch 3180, Loss: 0.0003158340186928399, Final Batch Loss: 1.648757461225614e-05\n",
      "Epoch 3181, Loss: 0.0006110734248068184, Final Batch Loss: 0.0003551877452991903\n",
      "Epoch 3182, Loss: 0.0015343352060881443, Final Batch Loss: 7.281365105882287e-05\n",
      "Epoch 3183, Loss: 0.00015249864372890443, Final Batch Loss: 3.1123316148296e-05\n",
      "Epoch 3184, Loss: 0.0004901337524643168, Final Batch Loss: 0.00021781472605653107\n",
      "Epoch 3185, Loss: 0.002414729548036121, Final Batch Loss: 5.4556083341594785e-05\n",
      "Epoch 3186, Loss: 0.0007896419556345791, Final Batch Loss: 5.655782297253609e-05\n",
      "Epoch 3187, Loss: 0.0001672657708695624, Final Batch Loss: 1.4176799595588818e-05\n",
      "Epoch 3188, Loss: 0.0004895731981378049, Final Batch Loss: 6.482162280008197e-05\n",
      "Epoch 3189, Loss: 0.0005288972315611318, Final Batch Loss: 0.0002541939029470086\n",
      "Epoch 3190, Loss: 0.0002135041404471849, Final Batch Loss: 0.00012664817040786147\n",
      "Epoch 3191, Loss: 0.0013549881405197084, Final Batch Loss: 0.00016794903785921633\n",
      "Epoch 3192, Loss: 0.0008336122409673408, Final Batch Loss: 0.00013381967437453568\n",
      "Epoch 3193, Loss: 0.013672069588210434, Final Batch Loss: 0.002416917821392417\n",
      "Epoch 3194, Loss: 0.004716399162134621, Final Batch Loss: 0.004588047042489052\n",
      "Epoch 3195, Loss: 0.00019070443522650748, Final Batch Loss: 0.00012651520955841988\n",
      "Epoch 3196, Loss: 0.0020428835232451092, Final Batch Loss: 4.442548015504144e-05\n",
      "Epoch 3197, Loss: 5.29622320755152e-05, Final Batch Loss: 7.048054612823762e-06\n",
      "Epoch 3198, Loss: 0.0027623049431895197, Final Batch Loss: 5.161990429769503e-06\n",
      "Epoch 3199, Loss: 0.0003121894387732027, Final Batch Loss: 2.3608261471963488e-05\n",
      "Epoch 3200, Loss: 0.0023981401300261496, Final Batch Loss: 0.002206425881013274\n",
      "Epoch 3201, Loss: 0.003003091216669418, Final Batch Loss: 0.0002800869115162641\n",
      "Epoch 3202, Loss: 7.766800445097033e-05, Final Batch Loss: 1.5460436770808883e-05\n",
      "Epoch 3203, Loss: 0.00104969602489291, Final Batch Loss: 9.832708201429341e-06\n",
      "Epoch 3204, Loss: 7.960343555168947e-05, Final Batch Loss: 3.258632204961032e-05\n",
      "Epoch 3205, Loss: 0.00029956445359857753, Final Batch Loss: 0.0001436427846783772\n",
      "Epoch 3206, Loss: 0.056655228883755626, Final Batch Loss: 0.05642721429467201\n",
      "Epoch 3207, Loss: 0.00039038700197124854, Final Batch Loss: 0.0001161387117463164\n",
      "Epoch 3208, Loss: 0.0002888433518819511, Final Batch Loss: 0.0001483428932260722\n",
      "Epoch 3209, Loss: 0.0004953097377438098, Final Batch Loss: 0.00010710748028941453\n",
      "Epoch 3210, Loss: 0.0022713826037943363, Final Batch Loss: 0.00021822606504429132\n",
      "Epoch 3211, Loss: 0.001022301450575469, Final Batch Loss: 0.00014208124775905162\n",
      "Epoch 3212, Loss: 0.0026649553910829127, Final Batch Loss: 0.00015728973085060716\n",
      "Epoch 3213, Loss: 0.018743811556305445, Final Batch Loss: 1.2966341273568105e-05\n",
      "Epoch 3214, Loss: 0.003774114607949741, Final Batch Loss: 0.0033469204790890217\n",
      "Epoch 3215, Loss: 0.00029633930353156757, Final Batch Loss: 0.000212142665986903\n",
      "Epoch 3216, Loss: 0.000651198458399449, Final Batch Loss: 6.34410298516741e-06\n",
      "Epoch 3217, Loss: 0.002113724171067588, Final Batch Loss: 0.00021130398090463132\n",
      "Epoch 3218, Loss: 0.0018604463657538872, Final Batch Loss: 0.00013547236449085176\n",
      "Epoch 3219, Loss: 0.0010197882729698904, Final Batch Loss: 0.00019208170124329627\n",
      "Epoch 3220, Loss: 0.002093959457852179, Final Batch Loss: 4.875696322415024e-05\n",
      "Epoch 3221, Loss: 0.0009712145420053275, Final Batch Loss: 8.523509677615948e-06\n",
      "Epoch 3222, Loss: 0.0007280847785295919, Final Batch Loss: 0.0005717150052078068\n",
      "Epoch 3223, Loss: 0.0015961712051648647, Final Batch Loss: 3.3509015338495374e-05\n",
      "Epoch 3224, Loss: 0.0004325305690144887, Final Batch Loss: 0.00014848208229523152\n",
      "Epoch 3225, Loss: 0.0029375093508861028, Final Batch Loss: 9.465317998547107e-05\n",
      "Epoch 3226, Loss: 0.016583092462497007, Final Batch Loss: 9.30561054701684e-06\n",
      "Epoch 3227, Loss: 0.00025890179858834017, Final Batch Loss: 2.825298906827811e-05\n",
      "Epoch 3228, Loss: 0.0005555514362640679, Final Batch Loss: 1.6542835510335863e-05\n",
      "Epoch 3229, Loss: 0.000321467116009444, Final Batch Loss: 8.227063517551869e-05\n",
      "Epoch 3230, Loss: 0.0014807826082687825, Final Batch Loss: 0.0005195054691284895\n",
      "Epoch 3231, Loss: 0.000912978415726684, Final Batch Loss: 0.00012856011744588614\n",
      "Epoch 3232, Loss: 0.00038408036925829947, Final Batch Loss: 0.00013658744865097106\n",
      "Epoch 3233, Loss: 0.0001846713239501696, Final Batch Loss: 1.8287875718669966e-05\n",
      "Epoch 3234, Loss: 0.0013011214359721635, Final Batch Loss: 0.0012429042253643274\n",
      "Epoch 3235, Loss: 0.000698162907610822, Final Batch Loss: 4.500837349041831e-06\n",
      "Epoch 3236, Loss: 0.00042528439371380955, Final Batch Loss: 7.055400783428922e-05\n",
      "Epoch 3237, Loss: 0.0008388598216697574, Final Batch Loss: 7.047783583402634e-05\n",
      "Epoch 3238, Loss: 0.00013686994896033866, Final Batch Loss: 1.780332581802213e-06\n",
      "Epoch 3239, Loss: 0.0035250305591034703, Final Batch Loss: 0.0015237507177516818\n",
      "Epoch 3240, Loss: 0.00035694405960384756, Final Batch Loss: 8.936512313084677e-05\n",
      "Epoch 3241, Loss: 0.00020855124967056327, Final Batch Loss: 4.4677130063064396e-05\n",
      "Epoch 3242, Loss: 0.0009511098905932158, Final Batch Loss: 0.0001170906180050224\n",
      "Epoch 3243, Loss: 0.00031146982564678183, Final Batch Loss: 5.3408939493237995e-06\n",
      "Epoch 3244, Loss: 0.004355231823865324, Final Batch Loss: 0.003146249335259199\n",
      "Epoch 3245, Loss: 0.013385426391323563, Final Batch Loss: 0.00010284131712978706\n",
      "Epoch 3246, Loss: 0.0001965349929378135, Final Batch Loss: 9.433958621229976e-05\n",
      "Epoch 3247, Loss: 0.0005367112385101791, Final Batch Loss: 5.188221257412806e-05\n",
      "Epoch 3248, Loss: 0.003741486281796824, Final Batch Loss: 0.0034580319188535213\n",
      "Epoch 3249, Loss: 0.0009244602169928839, Final Batch Loss: 0.0008499674149788916\n",
      "Epoch 3250, Loss: 0.00028707438650599215, Final Batch Loss: 1.8056425687973388e-05\n",
      "Epoch 3251, Loss: 0.00011478361739136744, Final Batch Loss: 2.5298742912127636e-05\n",
      "Epoch 3252, Loss: 0.001083481460227631, Final Batch Loss: 0.00013264102744869888\n",
      "Epoch 3253, Loss: 0.003232166840462014, Final Batch Loss: 0.0004187279555480927\n",
      "Epoch 3254, Loss: 0.0006082183808757691, Final Batch Loss: 9.483981557423249e-05\n",
      "Epoch 3255, Loss: 0.0012221454380778596, Final Batch Loss: 0.0005322282086126506\n",
      "Epoch 3256, Loss: 0.004544350522337481, Final Batch Loss: 0.0002723388315644115\n",
      "Epoch 3257, Loss: 0.0001438455110474024, Final Batch Loss: 3.057182038901374e-05\n",
      "Epoch 3258, Loss: 0.0026802509055414703, Final Batch Loss: 0.0026275641284883022\n",
      "Epoch 3259, Loss: 0.022824170151579892, Final Batch Loss: 0.02044314704835415\n",
      "Epoch 3260, Loss: 0.003877842922520358, Final Batch Loss: 7.707940676482394e-05\n",
      "Epoch 3261, Loss: 0.08796311193145812, Final Batch Loss: 0.05129748955368996\n",
      "Epoch 3262, Loss: 0.0032774523133412004, Final Batch Loss: 0.00041148217860609293\n",
      "Epoch 3263, Loss: 7.795389319653623e-05, Final Batch Loss: 1.5627379980287515e-05\n",
      "Epoch 3264, Loss: 0.0003554016711859731, Final Batch Loss: 1.475358112656977e-05\n",
      "Epoch 3265, Loss: 0.010485530736332294, Final Batch Loss: 0.009852699004113674\n",
      "Epoch 3266, Loss: 0.0008590158977312967, Final Batch Loss: 0.0002638904261402786\n",
      "Epoch 3267, Loss: 0.031116799531446304, Final Batch Loss: 0.029434941709041595\n",
      "Epoch 3268, Loss: 0.0006537898552778643, Final Batch Loss: 4.9028552894014865e-05\n",
      "Epoch 3269, Loss: 0.0034922058694064617, Final Batch Loss: 0.0010152991162613034\n",
      "Epoch 3270, Loss: 0.0003412844816921279, Final Batch Loss: 0.00012037356646033004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3271, Loss: 0.0041469818679615855, Final Batch Loss: 0.0003285259008407593\n",
      "Epoch 3272, Loss: 0.001475706674682442, Final Batch Loss: 0.0007533858879469335\n",
      "Epoch 3273, Loss: 0.020232375856721774, Final Batch Loss: 0.0004928458365611732\n",
      "Epoch 3274, Loss: 0.0011517460879986174, Final Batch Loss: 0.0008822918171063066\n",
      "Epoch 3275, Loss: 0.0007478975603589788, Final Batch Loss: 0.0005252180271781981\n",
      "Epoch 3276, Loss: 0.0004193777576801949, Final Batch Loss: 6.827206561865751e-06\n",
      "Epoch 3277, Loss: 0.004852930243941955, Final Batch Loss: 0.00022386728960555047\n",
      "Epoch 3278, Loss: 0.0005417694701463915, Final Batch Loss: 5.9263060393277556e-05\n",
      "Epoch 3279, Loss: 0.00037530546615016647, Final Batch Loss: 9.813423093874007e-05\n",
      "Epoch 3280, Loss: 0.0004074914031662047, Final Batch Loss: 3.984686190960929e-05\n",
      "Epoch 3281, Loss: 0.042949430586304516, Final Batch Loss: 0.04211283102631569\n",
      "Epoch 3282, Loss: 0.003706446790602058, Final Batch Loss: 0.00021278875647112727\n",
      "Epoch 3283, Loss: 0.0013237975363153964, Final Batch Loss: 0.0006558357272297144\n",
      "Epoch 3284, Loss: 0.0006995680450927466, Final Batch Loss: 0.00018943159375339746\n",
      "Epoch 3285, Loss: 0.0008970013586804271, Final Batch Loss: 0.00031536255846731365\n",
      "Epoch 3286, Loss: 0.0012285039701964706, Final Batch Loss: 0.0004652884672395885\n",
      "Epoch 3287, Loss: 0.01590617284819018, Final Batch Loss: 0.00023206215701065958\n",
      "Epoch 3288, Loss: 0.007163329879404046, Final Batch Loss: 0.005707648117095232\n",
      "Epoch 3289, Loss: 0.0018725591653492302, Final Batch Loss: 0.0002891044714488089\n",
      "Epoch 3290, Loss: 0.0008633566249045543, Final Batch Loss: 0.00019007740775123239\n",
      "Epoch 3291, Loss: 0.0036150526721030474, Final Batch Loss: 0.002666813787072897\n",
      "Epoch 3292, Loss: 0.0017231464735232294, Final Batch Loss: 0.0001856904709711671\n",
      "Epoch 3293, Loss: 0.0021985235216561705, Final Batch Loss: 0.0001875765301520005\n",
      "Epoch 3294, Loss: 0.0005133672384545207, Final Batch Loss: 0.00040388666093349457\n",
      "Epoch 3295, Loss: 0.00045336326002143323, Final Batch Loss: 0.00015608717512805015\n",
      "Epoch 3296, Loss: 0.0008179006836144254, Final Batch Loss: 0.00013709781342186034\n",
      "Epoch 3297, Loss: 0.0003154734513373114, Final Batch Loss: 8.192694076569751e-05\n",
      "Epoch 3298, Loss: 0.0014014782645972446, Final Batch Loss: 0.00023266834614332765\n",
      "Epoch 3299, Loss: 0.0005873707414139062, Final Batch Loss: 0.0003605665697250515\n",
      "Epoch 3300, Loss: 0.0002987059961014893, Final Batch Loss: 8.355810132343322e-05\n",
      "Epoch 3301, Loss: 0.0014001716817801935, Final Batch Loss: 1.2974361197848339e-05\n",
      "Epoch 3302, Loss: 0.004057813404870103, Final Batch Loss: 0.002370179630815983\n",
      "Epoch 3303, Loss: 0.00016490962298121303, Final Batch Loss: 7.084647222654894e-05\n",
      "Epoch 3304, Loss: 0.00021754338376922533, Final Batch Loss: 3.539790486684069e-05\n",
      "Epoch 3305, Loss: 0.00025843219191301614, Final Batch Loss: 3.830237255897373e-05\n",
      "Epoch 3306, Loss: 0.0005045833495387342, Final Batch Loss: 3.4486492950236425e-05\n",
      "Epoch 3307, Loss: 0.00037040491406514775, Final Batch Loss: 1.5252777302521281e-05\n",
      "Epoch 3308, Loss: 0.0022659999958705157, Final Batch Loss: 0.0002294538717251271\n",
      "Epoch 3309, Loss: 0.00028936438320670277, Final Batch Loss: 0.00011072748020524159\n",
      "Epoch 3310, Loss: 0.0013418833841569722, Final Batch Loss: 3.400341665837914e-05\n",
      "Epoch 3311, Loss: 0.0011659206356853247, Final Batch Loss: 0.0007039945921860635\n",
      "Epoch 3312, Loss: 0.0033772884926293045, Final Batch Loss: 0.002753980690613389\n",
      "Epoch 3313, Loss: 0.0009321644720330369, Final Batch Loss: 0.0007115904008969665\n",
      "Epoch 3314, Loss: 0.0013703998934033734, Final Batch Loss: 4.288850959710544e-06\n",
      "Epoch 3315, Loss: 0.0010091072945215274, Final Batch Loss: 7.658109097974375e-05\n",
      "Epoch 3316, Loss: 0.000447136684670113, Final Batch Loss: 8.45316972117871e-05\n",
      "Epoch 3317, Loss: 0.00026115164928341983, Final Batch Loss: 0.00023082162078935653\n",
      "Epoch 3318, Loss: 0.00028063906756869983, Final Batch Loss: 0.00013140054943505675\n",
      "Epoch 3319, Loss: 0.00808523160594632, Final Batch Loss: 0.007952424697577953\n",
      "Epoch 3320, Loss: 0.00046553426363971084, Final Batch Loss: 0.00023597101971972734\n",
      "Epoch 3321, Loss: 0.0007309470438485732, Final Batch Loss: 2.0775978555320762e-05\n",
      "Epoch 3322, Loss: 0.00022443258058046922, Final Batch Loss: 8.29917989904061e-05\n",
      "Epoch 3323, Loss: 0.0010660347033990547, Final Batch Loss: 0.0006628863629885018\n",
      "Epoch 3324, Loss: 0.00015256587539624888, Final Batch Loss: 6.334485806291923e-05\n",
      "Epoch 3325, Loss: 0.000878778773767408, Final Batch Loss: 3.2053554605226964e-05\n",
      "Epoch 3326, Loss: 0.0036351674134493805, Final Batch Loss: 8.971039642347023e-05\n",
      "Epoch 3327, Loss: 0.0001956263749889331, Final Batch Loss: 2.5492694476270117e-05\n",
      "Epoch 3328, Loss: 0.0001807933695090469, Final Batch Loss: 8.589824574301019e-05\n",
      "Epoch 3329, Loss: 0.00024553326329623815, Final Batch Loss: 0.00017411267617717385\n",
      "Epoch 3330, Loss: 0.027713563753422932, Final Batch Loss: 2.1594440113403834e-05\n",
      "Epoch 3331, Loss: 0.0009966557117877528, Final Batch Loss: 0.00043399861897341907\n",
      "Epoch 3332, Loss: 0.00019398512813495472, Final Batch Loss: 5.2303275879239663e-05\n",
      "Epoch 3333, Loss: 0.00038854020385770127, Final Batch Loss: 3.076664143009111e-05\n",
      "Epoch 3334, Loss: 0.0006598092622880358, Final Batch Loss: 0.0004930380382575095\n",
      "Epoch 3335, Loss: 0.002121672110661166, Final Batch Loss: 0.00012112370313843712\n",
      "Epoch 3336, Loss: 0.00022903046919964254, Final Batch Loss: 0.00012536357098724693\n",
      "Epoch 3337, Loss: 0.0005671544240613002, Final Batch Loss: 0.0002592221717350185\n",
      "Epoch 3338, Loss: 0.0002064896125375526, Final Batch Loss: 0.00010799074516398832\n",
      "Epoch 3339, Loss: 0.03801477295928635, Final Batch Loss: 0.03692030906677246\n",
      "Epoch 3340, Loss: 0.00048028621040430153, Final Batch Loss: 1.2577752386278007e-05\n",
      "Epoch 3341, Loss: 0.0007949077553348616, Final Batch Loss: 0.00012428470654413104\n",
      "Epoch 3342, Loss: 0.007614596950588748, Final Batch Loss: 0.00026143365539610386\n",
      "Epoch 3343, Loss: 0.011189757678948808, Final Batch Loss: 6.861525616841391e-05\n",
      "Epoch 3344, Loss: 0.02888226894719992, Final Batch Loss: 7.007132808212191e-05\n",
      "Epoch 3345, Loss: 0.000735259338398464, Final Batch Loss: 7.871210982557386e-05\n",
      "Epoch 3346, Loss: 0.024517743055184837, Final Batch Loss: 9.751237666932866e-05\n",
      "Epoch 3347, Loss: 0.0004989640146959573, Final Batch Loss: 9.145547664957121e-05\n",
      "Epoch 3348, Loss: 0.0036548071147990413, Final Batch Loss: 0.00041868563857860863\n",
      "Epoch 3349, Loss: 0.0005008008447475731, Final Batch Loss: 0.00016154428885784\n",
      "Epoch 3350, Loss: 0.0008939335857576225, Final Batch Loss: 0.0007678179536014795\n",
      "Epoch 3351, Loss: 0.002073187210044125, Final Batch Loss: 0.0017729118699207902\n",
      "Epoch 3352, Loss: 0.0006966586297494359, Final Batch Loss: 0.00035286936326883733\n",
      "Epoch 3353, Loss: 0.0006016403131070547, Final Batch Loss: 2.2718413674738258e-05\n",
      "Epoch 3354, Loss: 0.0009231985604856163, Final Batch Loss: 0.0003534428251441568\n",
      "Epoch 3355, Loss: 0.014401309401364415, Final Batch Loss: 2.143366691598203e-05\n",
      "Epoch 3356, Loss: 0.0006191602915350813, Final Batch Loss: 6.747265433659777e-05\n",
      "Epoch 3357, Loss: 0.0012696277117356658, Final Batch Loss: 0.0009915411937981844\n",
      "Epoch 3358, Loss: 0.0005174553589313291, Final Batch Loss: 8.254879503510892e-05\n",
      "Epoch 3359, Loss: 0.006042447726940736, Final Batch Loss: 0.005169884767383337\n",
      "Epoch 3360, Loss: 0.0031608213466824964, Final Batch Loss: 0.002776375273242593\n",
      "Epoch 3361, Loss: 0.0004313873687351588, Final Batch Loss: 0.00018402253044769168\n",
      "Epoch 3362, Loss: 0.0006563290589838289, Final Batch Loss: 0.0001006974998745136\n",
      "Epoch 3363, Loss: 0.001529914647107944, Final Batch Loss: 0.0004287396150175482\n",
      "Epoch 3364, Loss: 0.0042577970889396966, Final Batch Loss: 0.0012384109431877732\n",
      "Epoch 3365, Loss: 0.0012340285538812168, Final Batch Loss: 0.0002844727714546025\n",
      "Epoch 3366, Loss: 0.0010835402499651536, Final Batch Loss: 0.00029527212609536946\n",
      "Epoch 3367, Loss: 0.0010977672063745558, Final Batch Loss: 0.0009368053870275617\n",
      "Epoch 3368, Loss: 0.0036944192688679323, Final Batch Loss: 0.00035376407322473824\n",
      "Epoch 3369, Loss: 0.002073756913887337, Final Batch Loss: 0.00024341398966498673\n",
      "Epoch 3370, Loss: 0.0007898623371147551, Final Batch Loss: 0.0005940968985669315\n",
      "Epoch 3371, Loss: 0.0005781806903542019, Final Batch Loss: 3.975891013396904e-05\n",
      "Epoch 3372, Loss: 0.0006725834318785928, Final Batch Loss: 0.00031490862602367997\n",
      "Epoch 3373, Loss: 0.0031646248535253108, Final Batch Loss: 0.0015506952768191695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3374, Loss: 0.01636638666241197, Final Batch Loss: 9.20048842090182e-05\n",
      "Epoch 3375, Loss: 0.00037068982965138275, Final Batch Loss: 2.498266076145228e-05\n",
      "Epoch 3376, Loss: 0.0003419228032726096, Final Batch Loss: 1.6747848349041305e-05\n",
      "Epoch 3377, Loss: 0.011182262838701718, Final Batch Loss: 4.14841779274866e-05\n",
      "Epoch 3378, Loss: 0.00037679437082260847, Final Batch Loss: 0.00010263120930176228\n",
      "Epoch 3379, Loss: 0.000185577566298889, Final Batch Loss: 2.8831340387114324e-05\n",
      "Epoch 3380, Loss: 0.0005690262478310615, Final Batch Loss: 0.00019273559155408293\n",
      "Epoch 3381, Loss: 0.0039061346906237304, Final Batch Loss: 0.003634357824921608\n",
      "Epoch 3382, Loss: 0.00048803201934788376, Final Batch Loss: 0.0001815368013922125\n",
      "Epoch 3383, Loss: 0.0012014033418381587, Final Batch Loss: 0.0011302335187792778\n",
      "Epoch 3384, Loss: 0.0008398051431868225, Final Batch Loss: 0.000509811332449317\n",
      "Epoch 3385, Loss: 0.00027147301443619654, Final Batch Loss: 0.00012521172175183892\n",
      "Epoch 3386, Loss: 0.0011306297456030734, Final Batch Loss: 7.949083374114707e-05\n",
      "Epoch 3387, Loss: 0.00024156215113180224, Final Batch Loss: 2.9320939574972726e-05\n",
      "Epoch 3388, Loss: 0.0004173487677689991, Final Batch Loss: 4.769753104483243e-06\n",
      "Epoch 3389, Loss: 0.0003932982544938568, Final Batch Loss: 1.0520223440835252e-05\n",
      "Epoch 3390, Loss: 0.0023485777564928867, Final Batch Loss: 7.710565841989592e-05\n",
      "Epoch 3391, Loss: 0.0008040996926865773, Final Batch Loss: 3.9687674870947376e-05\n",
      "Epoch 3392, Loss: 0.003345672637806274, Final Batch Loss: 3.824424493359402e-05\n",
      "Epoch 3393, Loss: 0.00039670059231866617, Final Batch Loss: 1.82548046723241e-05\n",
      "Epoch 3394, Loss: 0.0022660020767943934, Final Batch Loss: 0.000436674861703068\n",
      "Epoch 3395, Loss: 0.020354109170511947, Final Batch Loss: 8.795463145361282e-06\n",
      "Epoch 3396, Loss: 0.0020182851003482938, Final Batch Loss: 0.00030928265186958015\n",
      "Epoch 3397, Loss: 0.0014031518585397862, Final Batch Loss: 0.0010607190197333694\n",
      "Epoch 3398, Loss: 0.0006864905553811695, Final Batch Loss: 2.8159684006823227e-05\n",
      "Epoch 3399, Loss: 0.0017795573294279166, Final Batch Loss: 2.9728827939834446e-05\n",
      "Epoch 3400, Loss: 0.00034792111637216294, Final Batch Loss: 0.00018907953926827759\n",
      "Epoch 3401, Loss: 0.03656656848761486, Final Batch Loss: 0.032234832644462585\n",
      "Epoch 3402, Loss: 0.0005923760691075586, Final Batch Loss: 0.00039322045631706715\n",
      "Epoch 3403, Loss: 0.00022345637262333184, Final Batch Loss: 0.00012739081284962595\n",
      "Epoch 3404, Loss: 8.54297350088018e-05, Final Batch Loss: 6.769670108042192e-06\n",
      "Epoch 3405, Loss: 0.0013579513652075548, Final Batch Loss: 0.00010641533299349248\n",
      "Epoch 3406, Loss: 0.0033437110178056173, Final Batch Loss: 0.0018847744213417172\n",
      "Epoch 3407, Loss: 0.0017268812771362718, Final Batch Loss: 8.953993528848514e-06\n",
      "Epoch 3408, Loss: 0.002129914180841297, Final Batch Loss: 0.0013404363999143243\n",
      "Epoch 3409, Loss: 0.0002754975066636689, Final Batch Loss: 0.00010539080540183932\n",
      "Epoch 3410, Loss: 0.0008532285137334839, Final Batch Loss: 0.0003083778719883412\n",
      "Epoch 3411, Loss: 0.0008005370473256335, Final Batch Loss: 0.0003240705409552902\n",
      "Epoch 3412, Loss: 0.002731610700720921, Final Batch Loss: 0.002113544847816229\n",
      "Epoch 3413, Loss: 0.024528105287572544, Final Batch Loss: 1.1142666153318714e-05\n",
      "Epoch 3414, Loss: 0.0004109549554414116, Final Batch Loss: 0.00021894319797866046\n",
      "Epoch 3415, Loss: 0.0005198130456847139, Final Batch Loss: 0.00037827674532309175\n",
      "Epoch 3416, Loss: 0.002015750258578919, Final Batch Loss: 0.00023693435650784522\n",
      "Epoch 3417, Loss: 0.011459234781796113, Final Batch Loss: 0.00046506887883879244\n",
      "Epoch 3418, Loss: 0.0007890259548730683, Final Batch Loss: 6.183966615935788e-05\n",
      "Epoch 3419, Loss: 0.0027424450454418547, Final Batch Loss: 0.0024895882233977318\n",
      "Epoch 3420, Loss: 0.0005570803805312607, Final Batch Loss: 3.541431578923948e-05\n",
      "Epoch 3421, Loss: 0.00026404209347674623, Final Batch Loss: 8.064896246651188e-05\n",
      "Epoch 3422, Loss: 0.0002376054399064742, Final Batch Loss: 1.7382299120072275e-05\n",
      "Epoch 3423, Loss: 0.0009245893197658006, Final Batch Loss: 3.773946446017362e-05\n",
      "Epoch 3424, Loss: 0.0012856082612415776, Final Batch Loss: 0.00024659078917466104\n",
      "Epoch 3425, Loss: 0.000424167636083439, Final Batch Loss: 0.00011647869541775435\n",
      "Epoch 3426, Loss: 0.0022479929320979863, Final Batch Loss: 0.0009369712206535041\n",
      "Epoch 3427, Loss: 0.00047146869928837987, Final Batch Loss: 1.368831090076128e-05\n",
      "Epoch 3428, Loss: 0.0004129209337406792, Final Batch Loss: 0.00016449175018351525\n",
      "Epoch 3429, Loss: 0.0013915522504248656, Final Batch Loss: 3.773062417167239e-05\n",
      "Epoch 3430, Loss: 0.00014869699589326046, Final Batch Loss: 5.4911488405195996e-05\n",
      "Epoch 3431, Loss: 0.0025330860225949436, Final Batch Loss: 0.0013541872613132\n",
      "Epoch 3432, Loss: 0.0016188830486498773, Final Batch Loss: 9.362149285152555e-05\n",
      "Epoch 3433, Loss: 0.0012137491539760958, Final Batch Loss: 4.167458610027097e-05\n",
      "Epoch 3434, Loss: 0.0009514774465060327, Final Batch Loss: 2.0073613995919004e-05\n",
      "Epoch 3435, Loss: 0.009089308041438926, Final Batch Loss: 0.0007015746086835861\n",
      "Epoch 3436, Loss: 0.0017090270393964602, Final Batch Loss: 1.2824018995161168e-05\n",
      "Epoch 3437, Loss: 0.0015239183558151126, Final Batch Loss: 0.001094395061954856\n",
      "Epoch 3438, Loss: 0.0007924848505354021, Final Batch Loss: 0.000691944791469723\n",
      "Epoch 3439, Loss: 0.0002766676443570759, Final Batch Loss: 8.930724288802594e-05\n",
      "Epoch 3440, Loss: 0.0034673031914280728, Final Batch Loss: 0.0031398707069456577\n",
      "Epoch 3441, Loss: 0.00021674589515896514, Final Batch Loss: 6.926713831489906e-05\n",
      "Epoch 3442, Loss: 0.0027716888653230853, Final Batch Loss: 6.0864691477036104e-05\n",
      "Epoch 3443, Loss: 0.00014210157860361505, Final Batch Loss: 2.9690554583794437e-05\n",
      "Epoch 3444, Loss: 0.0002802762683131732, Final Batch Loss: 9.196900646202266e-05\n",
      "Epoch 3445, Loss: 0.0006886065202706959, Final Batch Loss: 3.095401552855037e-05\n",
      "Epoch 3446, Loss: 0.044415374693926424, Final Batch Loss: 0.0005174087709747255\n",
      "Epoch 3447, Loss: 0.0006534498825203627, Final Batch Loss: 0.00011950904445257038\n",
      "Epoch 3448, Loss: 0.002614354445540812, Final Batch Loss: 7.702368020545691e-05\n",
      "Epoch 3449, Loss: 0.003041426527488511, Final Batch Loss: 4.0115359297487885e-05\n",
      "Epoch 3450, Loss: 0.0006108591187512502, Final Batch Loss: 0.000453432381618768\n",
      "Epoch 3451, Loss: 0.008145980264089303, Final Batch Loss: 3.60661833838094e-05\n",
      "Epoch 3452, Loss: 0.0002160675976483617, Final Batch Loss: 3.487711364869028e-05\n",
      "Epoch 3453, Loss: 0.015915460895485012, Final Batch Loss: 0.002703707432374358\n",
      "Epoch 3454, Loss: 0.002356086504732957, Final Batch Loss: 0.001817594631575048\n",
      "Epoch 3455, Loss: 0.0015183419309323654, Final Batch Loss: 0.0002108483313350007\n",
      "Epoch 3456, Loss: 0.0005533998155442532, Final Batch Loss: 0.00011302340135443956\n",
      "Epoch 3457, Loss: 0.001967933145351708, Final Batch Loss: 0.0014131303178146482\n",
      "Epoch 3458, Loss: 0.02761849630769575, Final Batch Loss: 4.0534861909691244e-05\n",
      "Epoch 3459, Loss: 0.0005234490126895253, Final Batch Loss: 3.97795120079536e-05\n",
      "Epoch 3460, Loss: 0.0004682996732299216, Final Batch Loss: 0.00029610886122100055\n",
      "Epoch 3461, Loss: 0.0003726919640030246, Final Batch Loss: 0.0002914333890657872\n",
      "Epoch 3462, Loss: 0.00081223389133811, Final Batch Loss: 9.46895161177963e-05\n",
      "Epoch 3463, Loss: 0.0008819840586511418, Final Batch Loss: 0.0002827289863489568\n",
      "Epoch 3464, Loss: 0.006089029106078669, Final Batch Loss: 0.0048469374887645245\n",
      "Epoch 3465, Loss: 0.0017863036373455543, Final Batch Loss: 0.0016455043805763125\n",
      "Epoch 3466, Loss: 0.002516888183890842, Final Batch Loss: 0.0012058564461767673\n",
      "Epoch 3467, Loss: 0.0026536656223470345, Final Batch Loss: 0.0001384013012284413\n",
      "Epoch 3468, Loss: 0.024955584609415382, Final Batch Loss: 0.00037277297815307975\n",
      "Epoch 3469, Loss: 0.0006369465190800838, Final Batch Loss: 8.290184632642195e-05\n",
      "Epoch 3470, Loss: 0.0007926414982648566, Final Batch Loss: 0.0004624128923751414\n",
      "Epoch 3471, Loss: 0.0017660129815340042, Final Batch Loss: 0.00040336884558200836\n",
      "Epoch 3472, Loss: 0.00046515876238117926, Final Batch Loss: 2.4428863980574533e-05\n",
      "Epoch 3473, Loss: 0.021872819030249957, Final Batch Loss: 4.3519474274944514e-05\n",
      "Epoch 3474, Loss: 0.0005659799571731128, Final Batch Loss: 0.0003501534811221063\n",
      "Epoch 3475, Loss: 0.0013804542104480788, Final Batch Loss: 2.1907806512899697e-05\n",
      "Epoch 3476, Loss: 0.0021860456181457266, Final Batch Loss: 0.00021235986787360162\n",
      "Epoch 3477, Loss: 0.002527408127207309, Final Batch Loss: 0.0019280374981462955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3478, Loss: 0.007990419944690075, Final Batch Loss: 0.00015302373503800482\n",
      "Epoch 3479, Loss: 0.0011979203700320795, Final Batch Loss: 0.0001326511410297826\n",
      "Epoch 3480, Loss: 0.0003958861734645325, Final Batch Loss: 9.312711881648283e-06\n",
      "Epoch 3481, Loss: 0.00031547582329949364, Final Batch Loss: 0.00019156701455358416\n",
      "Epoch 3482, Loss: 0.0034738288013613783, Final Batch Loss: 7.560033554909751e-05\n",
      "Epoch 3483, Loss: 0.000565121321415063, Final Batch Loss: 3.862761514028534e-05\n",
      "Epoch 3484, Loss: 0.0005529148256755434, Final Batch Loss: 5.8149547840002924e-05\n",
      "Epoch 3485, Loss: 0.0008089766197372228, Final Batch Loss: 0.0002256599545944482\n",
      "Epoch 3486, Loss: 0.0003722555593412835, Final Batch Loss: 5.1379207434365526e-05\n",
      "Epoch 3487, Loss: 0.0120429109010729, Final Batch Loss: 0.00018921370792668313\n",
      "Epoch 3488, Loss: 0.0001715833504931652, Final Batch Loss: 1.0413860763947014e-05\n",
      "Epoch 3489, Loss: 0.0008512900603818707, Final Batch Loss: 3.198241029167548e-05\n",
      "Epoch 3490, Loss: 0.0033407190931029618, Final Batch Loss: 0.00017441280942875892\n",
      "Epoch 3491, Loss: 0.000349253008607775, Final Batch Loss: 0.00014934822684153914\n",
      "Epoch 3492, Loss: 0.00047638071919209324, Final Batch Loss: 3.395510066184215e-05\n",
      "Epoch 3493, Loss: 0.001163594262834522, Final Batch Loss: 1.622620584385004e-05\n",
      "Epoch 3494, Loss: 0.00033570821324246936, Final Batch Loss: 4.7837656893534586e-05\n",
      "Epoch 3495, Loss: 0.0010234810470137745, Final Batch Loss: 0.0004423985374160111\n",
      "Epoch 3496, Loss: 0.0035957105283159763, Final Batch Loss: 6.24266904196702e-05\n",
      "Epoch 3497, Loss: 0.001394155513480655, Final Batch Loss: 0.0009606598760001361\n",
      "Epoch 3498, Loss: 0.01354994774737861, Final Batch Loss: 9.207776747643948e-05\n",
      "Epoch 3499, Loss: 0.0017733478380250745, Final Batch Loss: 0.00022687282762490213\n",
      "Epoch 3500, Loss: 0.01475304578707437, Final Batch Loss: 3.123825808870606e-05\n",
      "Epoch 3501, Loss: 0.0030742073395231273, Final Batch Loss: 6.212326843524352e-05\n",
      "Epoch 3502, Loss: 0.0007017204043222591, Final Batch Loss: 0.0003570720728021115\n",
      "Epoch 3503, Loss: 0.0009417674591531977, Final Batch Loss: 0.0001720619184197858\n",
      "Epoch 3504, Loss: 0.0009050187873071991, Final Batch Loss: 9.17055003810674e-05\n",
      "Epoch 3505, Loss: 0.0015655241440981627, Final Batch Loss: 0.00016278433031402528\n",
      "Epoch 3506, Loss: 0.0003364780241099652, Final Batch Loss: 0.00025765341706573963\n",
      "Epoch 3507, Loss: 0.0004435430309968069, Final Batch Loss: 0.00027316337218508124\n",
      "Epoch 3508, Loss: 0.00029912785248598084, Final Batch Loss: 0.00017929129535332322\n",
      "Epoch 3509, Loss: 0.0007416548032779247, Final Batch Loss: 0.00020211961236782372\n",
      "Epoch 3510, Loss: 0.002017026548855938, Final Batch Loss: 3.188780101481825e-05\n",
      "Epoch 3511, Loss: 0.00036231972262612544, Final Batch Loss: 4.069151691510342e-05\n",
      "Epoch 3512, Loss: 0.0013730937025684398, Final Batch Loss: 0.0012735433410853148\n",
      "Epoch 3513, Loss: 0.02290056002766505, Final Batch Loss: 8.743797661736608e-05\n",
      "Epoch 3514, Loss: 0.0029022918170085177, Final Batch Loss: 0.0001579792588017881\n",
      "Epoch 3515, Loss: 0.001700768931186758, Final Batch Loss: 8.150951180141419e-05\n",
      "Epoch 3516, Loss: 0.0014214467768169925, Final Batch Loss: 1.4747014347449294e-06\n",
      "Epoch 3517, Loss: 0.0007537235360359773, Final Batch Loss: 7.937152258818969e-05\n",
      "Epoch 3518, Loss: 0.0003831324938801117, Final Batch Loss: 0.0002575209364295006\n",
      "Epoch 3519, Loss: 0.0005226458888500929, Final Batch Loss: 0.00031176680931821465\n",
      "Epoch 3520, Loss: 0.0012989824172109365, Final Batch Loss: 0.0005177922430448234\n",
      "Epoch 3521, Loss: 0.0006783316202927381, Final Batch Loss: 0.0001356195571133867\n",
      "Epoch 3522, Loss: 0.0007774532932671718, Final Batch Loss: 0.0005890222382731736\n",
      "Epoch 3523, Loss: 0.002153311501388089, Final Batch Loss: 0.0014406348345801234\n",
      "Epoch 3524, Loss: 0.0004987275024177507, Final Batch Loss: 6.521055911434814e-05\n",
      "Epoch 3525, Loss: 0.005450152726552915, Final Batch Loss: 0.00035132604534737766\n",
      "Epoch 3526, Loss: 0.0028444119161576964, Final Batch Loss: 2.485259756213054e-05\n",
      "Epoch 3527, Loss: 0.000919773658097256, Final Batch Loss: 6.175030284794047e-05\n",
      "Epoch 3528, Loss: 0.0003368205507285893, Final Batch Loss: 4.023526707896963e-05\n",
      "Epoch 3529, Loss: 0.0007099560607457533, Final Batch Loss: 0.0002102352154906839\n",
      "Epoch 3530, Loss: 0.00720568468386773, Final Batch Loss: 0.006284375675022602\n",
      "Epoch 3531, Loss: 0.0018110959008481586, Final Batch Loss: 1.9615124983829446e-05\n",
      "Epoch 3532, Loss: 0.004275225248420611, Final Batch Loss: 0.00045925742597319186\n",
      "Epoch 3533, Loss: 0.0038216999237192795, Final Batch Loss: 0.00013233210484031588\n",
      "Epoch 3534, Loss: 0.002285430888150586, Final Batch Loss: 0.002034720964729786\n",
      "Epoch 3535, Loss: 0.0011317255266476423, Final Batch Loss: 0.0006841743597760797\n",
      "Epoch 3536, Loss: 0.0006499050723505206, Final Batch Loss: 7.633434870513156e-05\n",
      "Epoch 3537, Loss: 0.0008474341593682766, Final Batch Loss: 0.00010509350977372378\n",
      "Epoch 3538, Loss: 0.0016491138958372176, Final Batch Loss: 0.0008268567617051303\n",
      "Epoch 3539, Loss: 0.003958942194003612, Final Batch Loss: 0.0004977139760740101\n",
      "Epoch 3540, Loss: 0.00023097050507203676, Final Batch Loss: 4.806443757843226e-05\n",
      "Epoch 3541, Loss: 0.00033277596230618656, Final Batch Loss: 0.00012188574328320101\n",
      "Epoch 3542, Loss: 0.0005117805158079136, Final Batch Loss: 0.00015024913591332734\n",
      "Epoch 3543, Loss: 0.0007951736697577871, Final Batch Loss: 0.0005981387803331017\n",
      "Epoch 3544, Loss: 0.00044258728757995414, Final Batch Loss: 1.2504756341513712e-05\n",
      "Epoch 3545, Loss: 0.011542108908543014, Final Batch Loss: 9.41073267313186e-06\n",
      "Epoch 3546, Loss: 0.00117797456914559, Final Batch Loss: 0.0002412058529444039\n",
      "Epoch 3547, Loss: 0.009129180434683803, Final Batch Loss: 0.008919843472540379\n",
      "Epoch 3548, Loss: 0.0010972127893182915, Final Batch Loss: 6.091954492148943e-05\n",
      "Epoch 3549, Loss: 0.0019684443686855957, Final Batch Loss: 0.00015200818597804755\n",
      "Epoch 3550, Loss: 0.0004932352967443876, Final Batch Loss: 8.194356632884592e-05\n",
      "Epoch 3551, Loss: 0.0006199323252076283, Final Batch Loss: 0.00030903841252438724\n",
      "Epoch 3552, Loss: 0.016524097649380565, Final Batch Loss: 0.0006497402209788561\n",
      "Epoch 3553, Loss: 0.0005525596279767342, Final Batch Loss: 3.287594154244289e-05\n",
      "Epoch 3554, Loss: 0.0008967348476289771, Final Batch Loss: 8.242671174230054e-05\n",
      "Epoch 3555, Loss: 0.0063841038281680085, Final Batch Loss: 6.57347627566196e-05\n",
      "Epoch 3556, Loss: 0.002197407535277307, Final Batch Loss: 0.0003811995848082006\n",
      "Epoch 3557, Loss: 0.0031518031682935543, Final Batch Loss: 0.00024955268600024283\n",
      "Epoch 3558, Loss: 0.002727365877944976, Final Batch Loss: 6.515978020615876e-05\n",
      "Epoch 3559, Loss: 0.001215736563608516, Final Batch Loss: 9.900629083858803e-05\n",
      "Epoch 3560, Loss: 0.0008879378819983685, Final Batch Loss: 2.7636300728772767e-05\n",
      "Epoch 3561, Loss: 0.0007795102792442776, Final Batch Loss: 7.785607158439234e-05\n",
      "Epoch 3562, Loss: 0.0005012778829041054, Final Batch Loss: 1.465051627747016e-05\n",
      "Epoch 3563, Loss: 0.0024225508022936992, Final Batch Loss: 0.0003686073760036379\n",
      "Epoch 3564, Loss: 0.0006725669445586391, Final Batch Loss: 3.940438909921795e-05\n",
      "Epoch 3565, Loss: 0.0016371259116567671, Final Batch Loss: 9.73162823356688e-05\n",
      "Epoch 3566, Loss: 0.001751802441503969, Final Batch Loss: 1.4194070899975486e-05\n",
      "Epoch 3567, Loss: 0.0006101423277868889, Final Batch Loss: 0.00041771159158088267\n",
      "Epoch 3568, Loss: 0.0026818070400622673, Final Batch Loss: 0.0002966929168906063\n",
      "Epoch 3569, Loss: 0.0003564873686627834, Final Batch Loss: 0.0002144289028365165\n",
      "Epoch 3570, Loss: 0.0005490831408678787, Final Batch Loss: 0.0003729832824319601\n",
      "Epoch 3571, Loss: 0.0018873289591283537, Final Batch Loss: 8.371449803235009e-05\n",
      "Epoch 3572, Loss: 0.002164197154343128, Final Batch Loss: 0.0016333041712641716\n",
      "Epoch 3573, Loss: 0.0005898389936191961, Final Batch Loss: 0.000415358052123338\n",
      "Epoch 3574, Loss: 0.00064947897408274, Final Batch Loss: 0.0005359300994314253\n",
      "Epoch 3575, Loss: 0.0014575132227037102, Final Batch Loss: 0.00021534369443543255\n",
      "Epoch 3576, Loss: 0.0025892252051562537, Final Batch Loss: 3.0611427064286545e-05\n",
      "Epoch 3577, Loss: 0.00037008880008215783, Final Batch Loss: 0.00013547738490160555\n",
      "Epoch 3578, Loss: 0.0009094574634218588, Final Batch Loss: 0.00015053073002491146\n",
      "Epoch 3579, Loss: 0.0003743711204151623, Final Batch Loss: 5.6395059800706804e-05\n",
      "Epoch 3580, Loss: 0.0010527197737246752, Final Batch Loss: 0.00023736985167488456\n",
      "Epoch 3581, Loss: 0.00020537700038403273, Final Batch Loss: 5.041221447754651e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3582, Loss: 0.00023011920302451472, Final Batch Loss: 1.3294039490574505e-05\n",
      "Epoch 3583, Loss: 0.0024928937491495162, Final Batch Loss: 0.00041179460822604597\n",
      "Epoch 3584, Loss: 0.0019642946863314137, Final Batch Loss: 0.00040729177999310195\n",
      "Epoch 3585, Loss: 0.0006989657194935717, Final Batch Loss: 3.2809133699629456e-05\n",
      "Epoch 3586, Loss: 0.00029530309029723867, Final Batch Loss: 6.5000690483429935e-06\n",
      "Epoch 3587, Loss: 0.0005842108657816425, Final Batch Loss: 0.0002578752755653113\n",
      "Epoch 3588, Loss: 0.0002963306906167418, Final Batch Loss: 0.00011562703002709895\n",
      "Epoch 3589, Loss: 0.0008906316688808147, Final Batch Loss: 3.3800712117226794e-05\n",
      "Epoch 3590, Loss: 0.00010791770728246775, Final Batch Loss: 3.938834197469987e-05\n",
      "Epoch 3591, Loss: 0.0020743766262967256, Final Batch Loss: 7.834366442693863e-06\n",
      "Epoch 3592, Loss: 0.0003290535605628975, Final Batch Loss: 0.00023317277373280376\n",
      "Epoch 3593, Loss: 0.0004808944613614585, Final Batch Loss: 4.057648402522318e-05\n",
      "Epoch 3594, Loss: 0.0002638070891407551, Final Batch Loss: 0.0002039629325736314\n",
      "Epoch 3595, Loss: 0.0011396339541533962, Final Batch Loss: 3.897552960552275e-05\n",
      "Epoch 3596, Loss: 0.0003854439637507312, Final Batch Loss: 0.0002609661314636469\n",
      "Epoch 3597, Loss: 0.0004878735780948773, Final Batch Loss: 6.290552846621722e-05\n",
      "Epoch 3598, Loss: 0.00024369373022636864, Final Batch Loss: 2.72193083219463e-05\n",
      "Epoch 3599, Loss: 0.0006204369710758328, Final Batch Loss: 0.0003410808276385069\n",
      "Epoch 3600, Loss: 0.0005821989598189248, Final Batch Loss: 0.00044332831748761237\n",
      "Epoch 3601, Loss: 0.00026848987545236014, Final Batch Loss: 3.34876895067282e-05\n",
      "Epoch 3602, Loss: 0.00019203125521016773, Final Batch Loss: 7.752516467007808e-06\n",
      "Epoch 3603, Loss: 9.512456745142117e-05, Final Batch Loss: 2.0651692466344684e-05\n",
      "Epoch 3604, Loss: 0.00021356125216698274, Final Batch Loss: 3.691851088660769e-05\n",
      "Epoch 3605, Loss: 0.002019300518441014, Final Batch Loss: 2.5907880626618862e-05\n",
      "Epoch 3606, Loss: 0.000653325900202617, Final Batch Loss: 0.0004566090938169509\n",
      "Epoch 3607, Loss: 0.0002190737177443225, Final Batch Loss: 8.091225026873872e-05\n",
      "Epoch 3608, Loss: 0.0014354757695400622, Final Batch Loss: 3.638704583863728e-05\n",
      "Epoch 3609, Loss: 0.00015813549816812156, Final Batch Loss: 8.04675346444128e-06\n",
      "Epoch 3610, Loss: 0.0006542731516674394, Final Batch Loss: 1.69973118318012e-05\n",
      "Epoch 3611, Loss: 0.000588418661209289, Final Batch Loss: 0.00041862751822918653\n",
      "Epoch 3612, Loss: 0.002362195991736371, Final Batch Loss: 2.7016627427656204e-05\n",
      "Epoch 3613, Loss: 0.000344872090863646, Final Batch Loss: 8.667898509884253e-05\n",
      "Epoch 3614, Loss: 0.007985853582795244, Final Batch Loss: 0.007581448648124933\n",
      "Epoch 3615, Loss: 0.0008423319995927159, Final Batch Loss: 0.00011999857088085264\n",
      "Epoch 3616, Loss: 0.00029740702302660793, Final Batch Loss: 0.0001306230406044051\n",
      "Epoch 3617, Loss: 0.0032696878915885463, Final Batch Loss: 0.002962979255244136\n",
      "Epoch 3618, Loss: 0.00019174316548742354, Final Batch Loss: 3.394795203348622e-05\n",
      "Epoch 3619, Loss: 0.0002063133943011053, Final Batch Loss: 0.00010294698586221784\n",
      "Epoch 3620, Loss: 0.0001403975984430872, Final Batch Loss: 6.976945587666705e-05\n",
      "Epoch 3621, Loss: 0.0008436552598141134, Final Batch Loss: 0.00022235514188650995\n",
      "Epoch 3622, Loss: 0.006007543546729721, Final Batch Loss: 0.0030583927873522043\n",
      "Epoch 3623, Loss: 0.0004790459279320203, Final Batch Loss: 0.0001629079197300598\n",
      "Epoch 3624, Loss: 0.0009788853858481161, Final Batch Loss: 0.000733072345610708\n",
      "Epoch 3625, Loss: 0.00015394077126984484, Final Batch Loss: 4.190995605313219e-05\n",
      "Epoch 3626, Loss: 0.0011912943664356135, Final Batch Loss: 2.1996900613885373e-05\n",
      "Epoch 3627, Loss: 6.892375313327648e-05, Final Batch Loss: 1.9816417989204638e-05\n",
      "Epoch 3628, Loss: 5.026917415307253e-05, Final Batch Loss: 7.446579274983378e-06\n",
      "Epoch 3629, Loss: 0.00207208052961505, Final Batch Loss: 0.0014524240978062153\n",
      "Epoch 3630, Loss: 0.0001982929497899022, Final Batch Loss: 3.668139470391907e-05\n",
      "Epoch 3631, Loss: 0.00017054728596122004, Final Batch Loss: 4.2597934225341305e-05\n",
      "Epoch 3632, Loss: 0.0012871971484855749, Final Batch Loss: 4.1760482417885214e-05\n",
      "Epoch 3633, Loss: 0.02643433947014273, Final Batch Loss: 1.7301532352576032e-05\n",
      "Epoch 3634, Loss: 0.0003790303053392563, Final Batch Loss: 4.387779699754901e-05\n",
      "Epoch 3635, Loss: 0.00019646149212348973, Final Batch Loss: 7.323425052163657e-06\n",
      "Epoch 3636, Loss: 0.00016882268209883478, Final Batch Loss: 1.7210642909049056e-05\n",
      "Epoch 3637, Loss: 0.0003601843441174424, Final Batch Loss: 7.51409470467479e-06\n",
      "Epoch 3638, Loss: 0.0009606509456716594, Final Batch Loss: 1.116705698223086e-05\n",
      "Epoch 3639, Loss: 0.0034655734125408344, Final Batch Loss: 0.0006610600394196808\n",
      "Epoch 3640, Loss: 0.0029880870606575627, Final Batch Loss: 0.002679765224456787\n",
      "Epoch 3641, Loss: 0.0005612462409771979, Final Batch Loss: 0.0001731501251924783\n",
      "Epoch 3642, Loss: 0.00016633753693895414, Final Batch Loss: 0.00010760816076071933\n",
      "Epoch 3643, Loss: 0.00017484754425822757, Final Batch Loss: 3.624975215643644e-05\n",
      "Epoch 3644, Loss: 0.00042798461072379723, Final Batch Loss: 0.00027144214254803956\n",
      "Epoch 3645, Loss: 0.0024828341338434257, Final Batch Loss: 0.0001184301363537088\n",
      "Epoch 3646, Loss: 0.003984812545240857, Final Batch Loss: 4.926581459585577e-05\n",
      "Epoch 3647, Loss: 0.00032961726901703514, Final Batch Loss: 3.62168975698296e-05\n",
      "Epoch 3648, Loss: 0.00015929592700558715, Final Batch Loss: 6.236791523406282e-05\n",
      "Epoch 3649, Loss: 0.0022329409657686483, Final Batch Loss: 4.731223452836275e-05\n",
      "Epoch 3650, Loss: 0.0004541425696515944, Final Batch Loss: 4.9594662414165214e-05\n",
      "Epoch 3651, Loss: 0.008936090911447536, Final Batch Loss: 0.00011213132529519498\n",
      "Epoch 3652, Loss: 0.00016296703324769624, Final Batch Loss: 8.784099918557331e-05\n",
      "Epoch 3653, Loss: 0.0002490451588528231, Final Batch Loss: 9.77411400526762e-06\n",
      "Epoch 3654, Loss: 0.0012472191847336944, Final Batch Loss: 2.5050347176147625e-05\n",
      "Epoch 3655, Loss: 0.0005356365873012692, Final Batch Loss: 0.0002949001209344715\n",
      "Epoch 3656, Loss: 0.0007137102038541343, Final Batch Loss: 0.0004512360319495201\n",
      "Epoch 3657, Loss: 0.003997798696218524, Final Batch Loss: 6.104735803091899e-05\n",
      "Epoch 3658, Loss: 0.007323996280319989, Final Batch Loss: 0.0005749567644670606\n",
      "Epoch 3659, Loss: 0.002245447089080699, Final Batch Loss: 7.948902202770114e-05\n",
      "Epoch 3660, Loss: 0.0010169136739932583, Final Batch Loss: 8.215801244659815e-06\n",
      "Epoch 3661, Loss: 0.00031145587672654074, Final Batch Loss: 2.698725256777834e-05\n",
      "Epoch 3662, Loss: 0.00026127989622182213, Final Batch Loss: 3.10561154037714e-05\n",
      "Epoch 3663, Loss: 0.00025199038464052137, Final Batch Loss: 9.638589835958555e-05\n",
      "Epoch 3664, Loss: 8.313285616168287e-05, Final Batch Loss: 2.090311136271339e-05\n",
      "Epoch 3665, Loss: 0.00013598089572042227, Final Batch Loss: 5.5376000091200694e-05\n",
      "Epoch 3666, Loss: 0.00022250581423577387, Final Batch Loss: 5.516442979569547e-05\n",
      "Epoch 3667, Loss: 0.0007193755591288209, Final Batch Loss: 0.0006395942764356732\n",
      "Epoch 3668, Loss: 0.01404247545360704, Final Batch Loss: 4.13616762671154e-05\n",
      "Epoch 3669, Loss: 0.00020898134789604228, Final Batch Loss: 3.0799899832345545e-05\n",
      "Epoch 3670, Loss: 0.00035339692476554774, Final Batch Loss: 1.775670170900412e-05\n",
      "Epoch 3671, Loss: 0.0006391709030140191, Final Batch Loss: 3.503059997456148e-05\n",
      "Epoch 3672, Loss: 0.00021257588741718791, Final Batch Loss: 3.68003238691017e-05\n",
      "Epoch 3673, Loss: 0.00939350604039646, Final Batch Loss: 5.482213055074681e-06\n",
      "Epoch 3674, Loss: 0.00015222144247672986, Final Batch Loss: 1.6016887457226403e-05\n",
      "Epoch 3675, Loss: 0.0005012612164136954, Final Batch Loss: 8.527618774678558e-05\n",
      "Epoch 3676, Loss: 0.0001764872777130222, Final Batch Loss: 5.762542787124403e-05\n",
      "Epoch 3677, Loss: 0.0005350896826712415, Final Batch Loss: 0.0001225611922563985\n",
      "Epoch 3678, Loss: 0.00026885405532084405, Final Batch Loss: 7.186792936408892e-05\n",
      "Epoch 3679, Loss: 0.0024105191259877756, Final Batch Loss: 0.0007133022299967706\n",
      "Epoch 3680, Loss: 0.00020347401368780993, Final Batch Loss: 0.00014593628293368965\n",
      "Epoch 3681, Loss: 0.00019966782974734087, Final Batch Loss: 6.561373538715998e-06\n",
      "Epoch 3682, Loss: 0.0030963888129917905, Final Batch Loss: 0.00285230646841228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3683, Loss: 0.0005547538585233269, Final Batch Loss: 0.00038272576057352126\n",
      "Epoch 3684, Loss: 0.010508150357054546, Final Batch Loss: 5.1967668696306646e-05\n",
      "Epoch 3685, Loss: 0.0010533455315453466, Final Batch Loss: 8.252938278019428e-05\n",
      "Epoch 3686, Loss: 0.00028082864491807413, Final Batch Loss: 5.1166357479814906e-06\n",
      "Epoch 3687, Loss: 0.0004062643492943607, Final Batch Loss: 0.00018604124488774687\n",
      "Epoch 3688, Loss: 0.00013789455442747567, Final Batch Loss: 2.3275848434423096e-05\n",
      "Epoch 3689, Loss: 0.0007364112625509733, Final Batch Loss: 1.8440239728079177e-05\n",
      "Epoch 3690, Loss: 0.00026464543043402955, Final Batch Loss: 0.0001213662326335907\n",
      "Epoch 3691, Loss: 0.0003120010151178576, Final Batch Loss: 0.00010074506280943751\n",
      "Epoch 3692, Loss: 0.0009381300042150542, Final Batch Loss: 0.0002033351775025949\n",
      "Epoch 3693, Loss: 0.0009417124711035285, Final Batch Loss: 0.00011193405225640163\n",
      "Epoch 3694, Loss: 0.019838976173559786, Final Batch Loss: 1.946975135069806e-05\n",
      "Epoch 3695, Loss: 0.0010049306729342788, Final Batch Loss: 0.00035321968607604504\n",
      "Epoch 3696, Loss: 0.00010276897228322923, Final Batch Loss: 1.69539653143147e-05\n",
      "Epoch 3697, Loss: 0.00013816161299473606, Final Batch Loss: 3.311031832708977e-05\n",
      "Epoch 3698, Loss: 0.0005288412248773966, Final Batch Loss: 4.3225500121479854e-05\n",
      "Epoch 3699, Loss: 0.0008570228055759799, Final Batch Loss: 1.9329989299876615e-05\n",
      "Epoch 3700, Loss: 0.00034687415245571174, Final Batch Loss: 4.541595990303904e-05\n",
      "Epoch 3701, Loss: 0.00022204831020644633, Final Batch Loss: 1.4386815564648714e-05\n",
      "Epoch 3702, Loss: 0.000362503771611955, Final Batch Loss: 1.943224560818635e-05\n",
      "Epoch 3703, Loss: 0.017466912111558486, Final Batch Loss: 0.017372649163007736\n",
      "Epoch 3704, Loss: 0.0008580253925174475, Final Batch Loss: 3.857228875858709e-05\n",
      "Epoch 3705, Loss: 0.00021876742903259583, Final Batch Loss: 3.793886935454793e-05\n",
      "Epoch 3706, Loss: 0.0018036455876426771, Final Batch Loss: 0.000131489330669865\n",
      "Epoch 3707, Loss: 0.04917686549742939, Final Batch Loss: 0.001000880030915141\n",
      "Epoch 3708, Loss: 0.003102230912190862, Final Batch Loss: 0.002665542997419834\n",
      "Epoch 3709, Loss: 0.0001376430036543752, Final Batch Loss: 7.333345820370596e-06\n",
      "Epoch 3710, Loss: 0.0020167398106423207, Final Batch Loss: 5.0625654694158584e-05\n",
      "Epoch 3711, Loss: 0.0011066845809182269, Final Batch Loss: 1.212902589031728e-05\n",
      "Epoch 3712, Loss: 0.0024786645590211265, Final Batch Loss: 8.732280548429117e-05\n",
      "Epoch 3713, Loss: 0.00010632992234604899, Final Batch Loss: 2.7670348572428338e-05\n",
      "Epoch 3714, Loss: 0.002437317929434357, Final Batch Loss: 3.4158318158006296e-05\n",
      "Epoch 3715, Loss: 0.0003106195326836314, Final Batch Loss: 0.0001368026132695377\n",
      "Epoch 3716, Loss: 0.003042610493139364, Final Batch Loss: 0.002969532273709774\n",
      "Epoch 3717, Loss: 0.0002234786188637372, Final Batch Loss: 3.453364843153395e-05\n",
      "Epoch 3718, Loss: 0.002782827301416546, Final Batch Loss: 0.0001768073416315019\n",
      "Epoch 3719, Loss: 0.00032413833105238155, Final Batch Loss: 7.808724330971017e-05\n",
      "Epoch 3720, Loss: 0.009276607866922859, Final Batch Loss: 0.000370051886420697\n",
      "Epoch 3721, Loss: 0.000816979183582589, Final Batch Loss: 3.603947698138654e-05\n",
      "Epoch 3722, Loss: 0.0016271404456347227, Final Batch Loss: 0.0005838480428792536\n",
      "Epoch 3723, Loss: 0.0005241657781880349, Final Batch Loss: 9.100577153731138e-05\n",
      "Epoch 3724, Loss: 0.0023428797503584065, Final Batch Loss: 6.349357136059552e-05\n",
      "Epoch 3725, Loss: 0.0014586952747777104, Final Batch Loss: 0.0010379815939813852\n",
      "Epoch 3726, Loss: 0.00038601233245572075, Final Batch Loss: 8.683480700710788e-05\n",
      "Epoch 3727, Loss: 0.0014429399016080424, Final Batch Loss: 0.001158864120952785\n",
      "Epoch 3728, Loss: 0.0003253455925005255, Final Batch Loss: 2.382403727096971e-05\n",
      "Epoch 3729, Loss: 0.000526678362803068, Final Batch Loss: 3.8053236494306475e-05\n",
      "Epoch 3730, Loss: 0.0009729030025482643, Final Batch Loss: 3.94391427107621e-05\n",
      "Epoch 3731, Loss: 0.0007677561025047908, Final Batch Loss: 9.060466982191429e-05\n",
      "Epoch 3732, Loss: 0.0009514010343991686, Final Batch Loss: 0.00018555184942670166\n",
      "Epoch 3733, Loss: 0.006736962524882983, Final Batch Loss: 0.00023255389533005655\n",
      "Epoch 3734, Loss: 0.0003496792069199728, Final Batch Loss: 3.008170642715413e-05\n",
      "Epoch 3735, Loss: 0.0040114410512614995, Final Batch Loss: 0.0015773206250742078\n",
      "Epoch 3736, Loss: 0.0009873766321106814, Final Batch Loss: 0.0008491378976032138\n",
      "Epoch 3737, Loss: 0.0015439866674569203, Final Batch Loss: 1.8088850993080996e-05\n",
      "Epoch 3738, Loss: 0.0005334996203600895, Final Batch Loss: 0.00011085189908044413\n",
      "Epoch 3739, Loss: 0.009193602192681283, Final Batch Loss: 7.869675027905032e-05\n",
      "Epoch 3740, Loss: 0.00045366438644123264, Final Batch Loss: 2.5370351067977026e-05\n",
      "Epoch 3741, Loss: 0.0014970072188589256, Final Batch Loss: 1.5978737792465836e-05\n",
      "Epoch 3742, Loss: 0.07136520968924742, Final Batch Loss: 0.03977670893073082\n",
      "Epoch 3743, Loss: 0.0001940214897331316, Final Batch Loss: 3.211218790966086e-05\n",
      "Epoch 3744, Loss: 0.005235964697931195, Final Batch Loss: 4.458861440070905e-05\n",
      "Epoch 3745, Loss: 0.0008289488032460213, Final Batch Loss: 0.00031970508280210197\n",
      "Epoch 3746, Loss: 0.0011944811831199331, Final Batch Loss: 1.155587779066991e-05\n",
      "Epoch 3747, Loss: 0.015057620617881184, Final Batch Loss: 0.0014708645176142454\n",
      "Epoch 3748, Loss: 0.0006977837001613807, Final Batch Loss: 0.00021473877131938934\n",
      "Epoch 3749, Loss: 0.0006446629931815551, Final Batch Loss: 0.0004919384373351932\n",
      "Epoch 3750, Loss: 0.00011213089965167455, Final Batch Loss: 1.148637784353923e-05\n",
      "Epoch 3751, Loss: 0.00028742326685460284, Final Batch Loss: 7.040706987027079e-05\n",
      "Epoch 3752, Loss: 0.037929576414171606, Final Batch Loss: 0.0004513889434747398\n",
      "Epoch 3753, Loss: 0.0013013199422857724, Final Batch Loss: 0.00010192603076575324\n",
      "Epoch 3754, Loss: 0.00024892904548323713, Final Batch Loss: 3.871082662953995e-05\n",
      "Epoch 3755, Loss: 0.01132568691537017, Final Batch Loss: 5.256638542050496e-05\n",
      "Epoch 3756, Loss: 5.8272680689697154e-05, Final Batch Loss: 9.182032954413444e-06\n",
      "Epoch 3757, Loss: 0.0018552200563135557, Final Batch Loss: 6.719375232933089e-05\n",
      "Epoch 3758, Loss: 0.0020919928938383237, Final Batch Loss: 0.0004764340410474688\n",
      "Epoch 3759, Loss: 0.00016921314636419993, Final Batch Loss: 6.683460014755838e-06\n",
      "Epoch 3760, Loss: 0.00023724503989797086, Final Batch Loss: 9.657695045461878e-05\n",
      "Epoch 3761, Loss: 0.0007303255515580531, Final Batch Loss: 7.1920090704225e-05\n",
      "Epoch 3762, Loss: 0.002522211492760107, Final Batch Loss: 0.00046566210221499205\n",
      "Epoch 3763, Loss: 0.0004434697657416109, Final Batch Loss: 0.0003322355914860964\n",
      "Epoch 3764, Loss: 0.00025311778153991327, Final Batch Loss: 3.536127042025328e-05\n",
      "Epoch 3765, Loss: 0.0011346714745741338, Final Batch Loss: 0.0004355362325441092\n",
      "Epoch 3766, Loss: 0.0003264147126174066, Final Batch Loss: 3.226012267987244e-05\n",
      "Epoch 3767, Loss: 0.003904006920492975, Final Batch Loss: 0.00266681844368577\n",
      "Epoch 3768, Loss: 0.001861979308159789, Final Batch Loss: 0.00042487442260608077\n",
      "Epoch 3769, Loss: 0.0003629343627835624, Final Batch Loss: 6.302903784671798e-06\n",
      "Epoch 3770, Loss: 0.0002488682803232223, Final Batch Loss: 3.30098882841412e-05\n",
      "Epoch 3771, Loss: 0.0005615394529741025, Final Batch Loss: 4.293143501854502e-05\n",
      "Epoch 3772, Loss: 0.0009216422295139637, Final Batch Loss: 0.0003870032378472388\n",
      "Epoch 3773, Loss: 0.003070395003305748, Final Batch Loss: 0.0005179558065719903\n",
      "Epoch 3774, Loss: 0.0002070925220323261, Final Batch Loss: 5.066219819127582e-05\n",
      "Epoch 3775, Loss: 0.0008169413295036065, Final Batch Loss: 1.0350030606787186e-05\n",
      "Epoch 3776, Loss: 0.001457549908082001, Final Batch Loss: 0.0010646060109138489\n",
      "Epoch 3777, Loss: 0.00014181764800014207, Final Batch Loss: 7.922964141471311e-05\n",
      "Epoch 3778, Loss: 0.002193847729358822, Final Batch Loss: 0.00020244286861270666\n",
      "Epoch 3779, Loss: 0.00016520710960321594, Final Batch Loss: 1.5709074432379566e-05\n",
      "Epoch 3780, Loss: 0.0013021926715737209, Final Batch Loss: 0.0004940109211020172\n",
      "Epoch 3781, Loss: 0.0007088964694048627, Final Batch Loss: 7.170977369241882e-06\n",
      "Epoch 3782, Loss: 0.0009981059556594118, Final Batch Loss: 0.0008012958569452167\n",
      "Epoch 3783, Loss: 0.001933921048475895, Final Batch Loss: 0.0012526785722002387\n",
      "Epoch 3784, Loss: 0.0004643586289603263, Final Batch Loss: 0.00020863572717644274\n",
      "Epoch 3785, Loss: 0.00010129973725270247, Final Batch Loss: 3.543429556884803e-06\n",
      "Epoch 3786, Loss: 0.0003872835368383676, Final Batch Loss: 0.00025192173779942095\n",
      "Epoch 3787, Loss: 0.0010204225982306525, Final Batch Loss: 7.160903624026105e-05\n",
      "Epoch 3788, Loss: 0.00032091634216158127, Final Batch Loss: 3.4896818306151545e-06\n",
      "Epoch 3789, Loss: 0.00038667674652970163, Final Batch Loss: 1.4266518519434612e-05\n",
      "Epoch 3790, Loss: 0.0008846754717524163, Final Batch Loss: 0.00018932884267996997\n",
      "Epoch 3791, Loss: 0.0005429976154118776, Final Batch Loss: 1.9496768800308928e-05\n",
      "Epoch 3792, Loss: 0.00017298280545219313, Final Batch Loss: 9.161303023574874e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3793, Loss: 0.00019857213465002133, Final Batch Loss: 2.8041309633408673e-05\n",
      "Epoch 3794, Loss: 0.00030257941398303956, Final Batch Loss: 4.449183325050399e-05\n",
      "Epoch 3795, Loss: 6.245351778488839e-05, Final Batch Loss: 2.9844864911865443e-05\n",
      "Epoch 3796, Loss: 0.0022884282643644838, Final Batch Loss: 0.0009586510714143515\n",
      "Epoch 3797, Loss: 0.0007950298422656488, Final Batch Loss: 7.141358946682885e-05\n",
      "Epoch 3798, Loss: 0.00015202407212200342, Final Batch Loss: 8.18811804492725e-06\n",
      "Epoch 3799, Loss: 0.0007932967855595052, Final Batch Loss: 0.0005510991904884577\n",
      "Epoch 3800, Loss: 8.217446884373203e-05, Final Batch Loss: 9.658022463554516e-06\n",
      "Epoch 3801, Loss: 0.000203720079298364, Final Batch Loss: 4.4930715375812724e-05\n",
      "Epoch 3802, Loss: 1.8313014493287483e-05, Final Batch Loss: 1.0901734412982478e-06\n",
      "Epoch 3803, Loss: 0.0009100331481022295, Final Batch Loss: 7.493399607483298e-05\n",
      "Epoch 3804, Loss: 0.0026191494307568064, Final Batch Loss: 2.98589493468171e-05\n",
      "Epoch 3805, Loss: 0.0010951390577247366, Final Batch Loss: 1.64757548191119e-05\n",
      "Epoch 3806, Loss: 0.0010497947041585576, Final Batch Loss: 0.0001361490722047165\n",
      "Epoch 3807, Loss: 0.0004301121152820997, Final Batch Loss: 2.3439853976015e-05\n",
      "Epoch 3808, Loss: 0.0012639568549275282, Final Batch Loss: 9.606369530956727e-06\n",
      "Epoch 3809, Loss: 0.0013094799360260367, Final Batch Loss: 0.000482884090160951\n",
      "Epoch 3810, Loss: 0.0008580520698160399, Final Batch Loss: 5.175917613087222e-05\n",
      "Epoch 3811, Loss: 0.0031746477507113013, Final Batch Loss: 4.3662152165779844e-05\n",
      "Epoch 3812, Loss: 0.00026110866383532993, Final Batch Loss: 1.790543319657445e-05\n",
      "Epoch 3813, Loss: 0.0011081771608587587, Final Batch Loss: 2.949198278656695e-05\n",
      "Epoch 3814, Loss: 0.0006870061629342672, Final Batch Loss: 0.0006744242273271084\n",
      "Epoch 3815, Loss: 0.0009067783830687404, Final Batch Loss: 0.00017355596355628222\n",
      "Epoch 3816, Loss: 0.00026142230490222573, Final Batch Loss: 6.68453867547214e-05\n",
      "Epoch 3817, Loss: 0.001094412655220367, Final Batch Loss: 0.00020412261073943228\n",
      "Epoch 3818, Loss: 0.00012049082033627201, Final Batch Loss: 1.795897878764663e-05\n",
      "Epoch 3819, Loss: 0.00044157671072753146, Final Batch Loss: 1.8040700524579734e-05\n",
      "Epoch 3820, Loss: 0.000436744836406433, Final Batch Loss: 2.599530307634268e-05\n",
      "Epoch 3821, Loss: 9.993791172746569e-05, Final Batch Loss: 1.3147149729775265e-05\n",
      "Epoch 3822, Loss: 0.004077365112607367, Final Batch Loss: 6.636310718022287e-05\n",
      "Epoch 3823, Loss: 0.001641245667997282, Final Batch Loss: 9.134807623922825e-05\n",
      "Epoch 3824, Loss: 0.02259674170636572, Final Batch Loss: 0.0001491187431383878\n",
      "Epoch 3825, Loss: 0.0061857895634602755, Final Batch Loss: 7.777666905894876e-05\n",
      "Epoch 3826, Loss: 0.013701438205316663, Final Batch Loss: 0.0022415139246731997\n",
      "Epoch 3827, Loss: 0.0007259923368110321, Final Batch Loss: 5.223305561230518e-05\n",
      "Epoch 3828, Loss: 0.0013871776318410411, Final Batch Loss: 0.00016250161570496857\n",
      "Epoch 3829, Loss: 0.0002646539232955547, Final Batch Loss: 0.00014244693738874048\n",
      "Epoch 3830, Loss: 0.0003574278198357206, Final Batch Loss: 0.0002375952317379415\n",
      "Epoch 3831, Loss: 9.894075992633589e-05, Final Batch Loss: 2.213433981523849e-05\n",
      "Epoch 3832, Loss: 0.0009075503012354602, Final Batch Loss: 5.285951374389697e-06\n",
      "Epoch 3833, Loss: 0.004100291047734572, Final Batch Loss: 3.714442073032842e-06\n",
      "Epoch 3834, Loss: 0.00021440039927256294, Final Batch Loss: 8.968001930043101e-05\n",
      "Epoch 3835, Loss: 0.0009495771337242331, Final Batch Loss: 4.133921174798161e-05\n",
      "Epoch 3836, Loss: 0.0020264023914933205, Final Batch Loss: 6.474315887317061e-05\n",
      "Epoch 3837, Loss: 0.0019103425147477537, Final Batch Loss: 0.0006106839864514768\n",
      "Epoch 3838, Loss: 0.0008212596949306317, Final Batch Loss: 0.0002737409377004951\n",
      "Epoch 3839, Loss: 0.0012455757168936543, Final Batch Loss: 7.681670103920624e-05\n",
      "Epoch 3840, Loss: 0.021125879786268342, Final Batch Loss: 0.00013374896661844105\n",
      "Epoch 3841, Loss: 0.00046349184049176984, Final Batch Loss: 0.0002729880216065794\n",
      "Epoch 3842, Loss: 0.00018472377269063145, Final Batch Loss: 7.490468124160543e-05\n",
      "Epoch 3843, Loss: 0.0005383308525779285, Final Batch Loss: 6.902524910401553e-05\n",
      "Epoch 3844, Loss: 0.0037195795084699057, Final Batch Loss: 0.0035799711477011442\n",
      "Epoch 3845, Loss: 0.001631310547963949, Final Batch Loss: 5.69682233617641e-05\n",
      "Epoch 3846, Loss: 0.00012751346093864413, Final Batch Loss: 5.995615538267884e-06\n",
      "Epoch 3847, Loss: 0.00013585441774921492, Final Batch Loss: 2.6380987037555315e-05\n",
      "Epoch 3848, Loss: 0.0006080839812057093, Final Batch Loss: 0.00013653507630806416\n",
      "Epoch 3849, Loss: 0.01048913802151219, Final Batch Loss: 4.343013642937876e-05\n",
      "Epoch 3850, Loss: 0.0005942814132140484, Final Batch Loss: 2.7630196200334467e-05\n",
      "Epoch 3851, Loss: 0.0002200489179813303, Final Batch Loss: 0.0001017611866700463\n",
      "Epoch 3852, Loss: 0.00041590410546632484, Final Batch Loss: 9.054723341250792e-05\n",
      "Epoch 3853, Loss: 0.00031544244120595977, Final Batch Loss: 8.779652853263542e-05\n",
      "Epoch 3854, Loss: 0.0029182375728851184, Final Batch Loss: 0.0023491408210247755\n",
      "Epoch 3855, Loss: 0.0003563619920896599, Final Batch Loss: 1.56767728185514e-05\n",
      "Epoch 3856, Loss: 0.0005297010284266435, Final Batch Loss: 3.8373829738702625e-05\n",
      "Epoch 3857, Loss: 0.005261241531115957, Final Batch Loss: 0.00463196262717247\n",
      "Epoch 3858, Loss: 0.0006667628513241652, Final Batch Loss: 0.0005329180276021361\n",
      "Epoch 3859, Loss: 0.0020654936670325696, Final Batch Loss: 6.545703217852861e-05\n",
      "Epoch 3860, Loss: 0.00026852685914491303, Final Batch Loss: 0.00010042522626463324\n",
      "Epoch 3861, Loss: 0.0018939579676953144, Final Batch Loss: 0.00010641398694133386\n",
      "Epoch 3862, Loss: 0.0010908582771662623, Final Batch Loss: 0.0001290649379370734\n",
      "Epoch 3863, Loss: 0.00031874064370640554, Final Batch Loss: 2.1670002752216533e-05\n",
      "Epoch 3864, Loss: 0.0012293243089516181, Final Batch Loss: 0.0002137249248335138\n",
      "Epoch 3865, Loss: 0.0016769378780736588, Final Batch Loss: 0.0008817606722004712\n",
      "Epoch 3866, Loss: 0.0001403955520800082, Final Batch Loss: 3.988074604421854e-05\n",
      "Epoch 3867, Loss: 0.0002031822659773752, Final Batch Loss: 5.1801223889924586e-05\n",
      "Epoch 3868, Loss: 0.0003506593457132112, Final Batch Loss: 2.89080708171241e-05\n",
      "Epoch 3869, Loss: 0.0001829994398576673, Final Batch Loss: 1.6934653103817254e-05\n",
      "Epoch 3870, Loss: 0.00023860449437052011, Final Batch Loss: 6.461380689870566e-05\n",
      "Epoch 3871, Loss: 0.0005331796419341117, Final Batch Loss: 8.541859278921038e-05\n",
      "Epoch 3872, Loss: 0.00040957412420539185, Final Batch Loss: 0.00015240263019222766\n",
      "Epoch 3873, Loss: 0.0011627955245785415, Final Batch Loss: 0.00010454385483171791\n",
      "Epoch 3874, Loss: 0.0008109196896839421, Final Batch Loss: 4.244532101438381e-05\n",
      "Epoch 3875, Loss: 0.0010398547310614958, Final Batch Loss: 0.0006375199882313609\n",
      "Epoch 3876, Loss: 0.0006940726743778214, Final Batch Loss: 6.399153789971024e-05\n",
      "Epoch 3877, Loss: 0.04368671158590587, Final Batch Loss: 4.9660920922178775e-05\n",
      "Epoch 3878, Loss: 0.004960729587764945, Final Batch Loss: 1.6943020455073565e-05\n",
      "Epoch 3879, Loss: 0.0005008900843677111, Final Batch Loss: 0.0001733840472297743\n",
      "Epoch 3880, Loss: 0.0004255739549989812, Final Batch Loss: 8.330870332429186e-05\n",
      "Epoch 3881, Loss: 0.0005473669771163259, Final Batch Loss: 3.751906115212478e-05\n",
      "Epoch 3882, Loss: 0.013567780595622025, Final Batch Loss: 0.00029028565040789545\n",
      "Epoch 3883, Loss: 0.00030814565980108455, Final Batch Loss: 9.818867692956701e-05\n",
      "Epoch 3884, Loss: 0.0008945470035541803, Final Batch Loss: 0.00046740277321077883\n",
      "Epoch 3885, Loss: 0.0010912435263890075, Final Batch Loss: 1.9460467228782363e-05\n",
      "Epoch 3886, Loss: 0.001027898193569854, Final Batch Loss: 7.233707583509386e-05\n",
      "Epoch 3887, Loss: 0.0012396662204992026, Final Batch Loss: 0.00034284876892343163\n",
      "Epoch 3888, Loss: 0.02087555195976165, Final Batch Loss: 0.0009308013250119984\n",
      "Epoch 3889, Loss: 0.021797170589707093, Final Batch Loss: 4.956350676366128e-05\n",
      "Epoch 3890, Loss: 0.0009598927972547244, Final Batch Loss: 3.3871263440232724e-05\n",
      "Epoch 3891, Loss: 0.0006310053831839468, Final Batch Loss: 3.8355992728611454e-05\n",
      "Epoch 3892, Loss: 0.0023002849593467545, Final Batch Loss: 0.00017644179752096534\n",
      "Epoch 3893, Loss: 0.002400675497483462, Final Batch Loss: 0.0004959425423294306\n",
      "Epoch 3894, Loss: 0.005042307278927183, Final Batch Loss: 0.000510789395775646\n",
      "Epoch 3895, Loss: 0.0012474178220145404, Final Batch Loss: 0.0004351470270194113\n",
      "Epoch 3896, Loss: 0.0026205487083643675, Final Batch Loss: 0.0011660800082609057\n",
      "Epoch 3897, Loss: 0.00034969386615557596, Final Batch Loss: 0.00016759563004598022\n",
      "Epoch 3898, Loss: 0.005389774567447603, Final Batch Loss: 0.004701567348092794\n",
      "Epoch 3899, Loss: 0.0008834539912641048, Final Batch Loss: 0.0004475533205550164\n",
      "Epoch 3900, Loss: 0.002427337318295031, Final Batch Loss: 0.00017387552361469716\n",
      "Epoch 3901, Loss: 0.000563507441256661, Final Batch Loss: 0.00040947753586806357\n",
      "Epoch 3902, Loss: 0.007855048392229946, Final Batch Loss: 5.832389069837518e-05\n",
      "Epoch 3903, Loss: 0.000492922066769097, Final Batch Loss: 4.907037509838119e-05\n",
      "Epoch 3904, Loss: 0.003915959161531646, Final Batch Loss: 0.0011658824514597654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3905, Loss: 0.0010100132058141753, Final Batch Loss: 0.00018134608399122953\n",
      "Epoch 3906, Loss: 0.00027542217503651045, Final Batch Loss: 5.539374615182169e-05\n",
      "Epoch 3907, Loss: 0.00022802400417276658, Final Batch Loss: 1.4243862096918747e-05\n",
      "Epoch 3908, Loss: 0.0003104704592260532, Final Batch Loss: 5.4639269364997745e-05\n",
      "Epoch 3909, Loss: 0.0007111051231731835, Final Batch Loss: 4.44496208729106e-06\n",
      "Epoch 3910, Loss: 0.00045013907947577536, Final Batch Loss: 0.00011168197670485824\n",
      "Epoch 3911, Loss: 0.000263732646999415, Final Batch Loss: 5.177448474569246e-05\n",
      "Epoch 3912, Loss: 0.000173193675436778, Final Batch Loss: 1.5054622053867206e-05\n",
      "Epoch 3913, Loss: 0.0010995725770044373, Final Batch Loss: 0.0010335096158087254\n",
      "Epoch 3914, Loss: 0.0001525451125417021, Final Batch Loss: 1.1753350008802954e-05\n",
      "Epoch 3915, Loss: 0.000804399945991463, Final Batch Loss: 1.8675715182325803e-05\n",
      "Epoch 3916, Loss: 0.0013279030681587756, Final Batch Loss: 4.562125832308084e-05\n",
      "Epoch 3917, Loss: 0.0006054234227121924, Final Batch Loss: 0.0004999656230211258\n",
      "Epoch 3918, Loss: 0.000460675806607469, Final Batch Loss: 1.3246744856587611e-05\n",
      "Epoch 3919, Loss: 0.00024096236484183464, Final Batch Loss: 2.7558200599742122e-05\n",
      "Epoch 3920, Loss: 0.00013131394734955393, Final Batch Loss: 4.307559720473364e-05\n",
      "Epoch 3921, Loss: 0.00024024773847486358, Final Batch Loss: 2.904658867919352e-05\n",
      "Epoch 3922, Loss: 0.002848067495506257, Final Batch Loss: 0.0022759628482162952\n",
      "Epoch 3923, Loss: 0.00019203659030608833, Final Batch Loss: 7.168761658249423e-05\n",
      "Epoch 3924, Loss: 0.0005969441735942382, Final Batch Loss: 1.6078873159131035e-05\n",
      "Epoch 3925, Loss: 0.016240040873526596, Final Batch Loss: 0.016111604869365692\n",
      "Epoch 3926, Loss: 0.00045540892097051255, Final Batch Loss: 8.06479511084035e-05\n",
      "Epoch 3927, Loss: 0.0017416454429621808, Final Batch Loss: 2.45293413172476e-05\n",
      "Epoch 3928, Loss: 0.00500513521137691, Final Batch Loss: 4.846031060878886e-06\n",
      "Epoch 3929, Loss: 0.0031343410846602637, Final Batch Loss: 0.0017163053853437304\n",
      "Epoch 3930, Loss: 0.00035125828071613796, Final Batch Loss: 0.0001370632235193625\n",
      "Epoch 3931, Loss: 0.005068884100182913, Final Batch Loss: 0.00014960647968109697\n",
      "Epoch 3932, Loss: 0.0012994335556868464, Final Batch Loss: 0.00013380743621382862\n",
      "Epoch 3933, Loss: 0.0005053508430137299, Final Batch Loss: 0.00014527965686284006\n",
      "Epoch 3934, Loss: 0.00021704511891584843, Final Batch Loss: 6.968854722799733e-05\n",
      "Epoch 3935, Loss: 0.0012881824659416452, Final Batch Loss: 0.00021304140682332218\n",
      "Epoch 3936, Loss: 0.0013252596472739242, Final Batch Loss: 3.1198687793221325e-05\n",
      "Epoch 3937, Loss: 0.0034042919432977214, Final Batch Loss: 2.4299442884512246e-05\n",
      "Epoch 3938, Loss: 0.000316464525894844, Final Batch Loss: 6.419378041755408e-05\n",
      "Epoch 3939, Loss: 7.03418468219752e-05, Final Batch Loss: 1.7930671674548648e-05\n",
      "Epoch 3940, Loss: 0.00025457788524363423, Final Batch Loss: 1.4836689842923079e-05\n",
      "Epoch 3941, Loss: 6.548794408445247e-05, Final Batch Loss: 9.364099241793156e-06\n",
      "Epoch 3942, Loss: 0.0003793411187871243, Final Batch Loss: 0.0002863970003090799\n",
      "Epoch 3943, Loss: 0.0002993929520016536, Final Batch Loss: 7.4561990913935e-05\n",
      "Epoch 3944, Loss: 8.933545359468553e-05, Final Batch Loss: 1.3798658983432688e-05\n",
      "Epoch 3945, Loss: 0.00018998135692527285, Final Batch Loss: 1.2916988453071099e-05\n",
      "Epoch 3946, Loss: 0.0001680035011304426, Final Batch Loss: 8.032234291022178e-06\n",
      "Epoch 3947, Loss: 0.00016003383871066035, Final Batch Loss: 8.781041287875269e-06\n",
      "Epoch 3948, Loss: 0.001372094040561933, Final Batch Loss: 4.4206281017977744e-05\n",
      "Epoch 3949, Loss: 0.0002829424865922192, Final Batch Loss: 0.0002257853775518015\n",
      "Epoch 3950, Loss: 0.0001753019678290002, Final Batch Loss: 6.067693175282329e-05\n",
      "Epoch 3951, Loss: 0.003302429879340707, Final Batch Loss: 0.0005605755723081529\n",
      "Epoch 3952, Loss: 0.000632558827419416, Final Batch Loss: 1.2851867722929455e-05\n",
      "Epoch 3953, Loss: 9.336465700471308e-05, Final Batch Loss: 4.611800977727398e-05\n",
      "Epoch 3954, Loss: 0.0003304423137251433, Final Batch Loss: 2.9080167678330326e-06\n",
      "Epoch 3955, Loss: 0.0005323756595316809, Final Batch Loss: 0.00044957734644412994\n",
      "Epoch 3956, Loss: 0.0037756665515189525, Final Batch Loss: 0.00011212114623049274\n",
      "Epoch 3957, Loss: 0.00014358459702634718, Final Batch Loss: 3.553926944732666e-06\n",
      "Epoch 3958, Loss: 7.093832391547039e-05, Final Batch Loss: 2.1452598957694136e-05\n",
      "Epoch 3959, Loss: 0.00046685321285622194, Final Batch Loss: 1.7996215319726616e-05\n",
      "Epoch 3960, Loss: 0.0005971564569335897, Final Batch Loss: 6.039475920260884e-05\n",
      "Epoch 3961, Loss: 0.0002034302851825487, Final Batch Loss: 0.00011350702698109671\n",
      "Epoch 3962, Loss: 0.0014357614709297195, Final Batch Loss: 0.0001723132882034406\n",
      "Epoch 3963, Loss: 0.0004115315168746747, Final Batch Loss: 0.00012644045636989176\n",
      "Epoch 3964, Loss: 0.0020071528269909322, Final Batch Loss: 6.63087994325906e-05\n",
      "Epoch 3965, Loss: 0.001607873935427051, Final Batch Loss: 2.1226278477115557e-05\n",
      "Epoch 3966, Loss: 0.0002777732952381484, Final Batch Loss: 0.00011227909999433905\n",
      "Epoch 3967, Loss: 0.00016619460438960232, Final Batch Loss: 5.797350968350656e-05\n",
      "Epoch 3968, Loss: 0.0008651290754642105, Final Batch Loss: 0.0005275718285702169\n",
      "Epoch 3969, Loss: 0.0005683518575096969, Final Batch Loss: 0.0004618557868525386\n",
      "Epoch 3970, Loss: 0.00018031506942861597, Final Batch Loss: 1.1526676644280087e-06\n",
      "Epoch 3971, Loss: 0.0024224978260463104, Final Batch Loss: 4.2874584323726594e-05\n",
      "Epoch 3972, Loss: 0.0003737006954906974, Final Batch Loss: 4.948967762175016e-05\n",
      "Epoch 3973, Loss: 0.0019024450557481032, Final Batch Loss: 0.0014569804770871997\n",
      "Epoch 3974, Loss: 0.0001373869108647341, Final Batch Loss: 2.7339909138390794e-05\n",
      "Epoch 3975, Loss: 0.00018524831466493197, Final Batch Loss: 3.787937748711556e-05\n",
      "Epoch 3976, Loss: 0.0002661374774106662, Final Batch Loss: 9.76111459749518e-06\n",
      "Epoch 3977, Loss: 0.0035752419662458124, Final Batch Loss: 2.0865541955572553e-05\n",
      "Epoch 3978, Loss: 0.001606621661267127, Final Batch Loss: 1.777845864125993e-05\n",
      "Epoch 3979, Loss: 0.00010475733233761275, Final Batch Loss: 2.7618343665380962e-06\n",
      "Epoch 3980, Loss: 0.002629019859341497, Final Batch Loss: 0.0025247226003557444\n",
      "Epoch 3981, Loss: 0.006733150621585082, Final Batch Loss: 0.006538239307701588\n",
      "Epoch 3982, Loss: 0.00011516571566971834, Final Batch Loss: 5.851472906215349e-06\n",
      "Epoch 3983, Loss: 0.0002950607449747622, Final Batch Loss: 9.894741378957406e-05\n",
      "Epoch 3984, Loss: 0.00028169623965368373, Final Batch Loss: 0.00024810220929794014\n",
      "Epoch 3985, Loss: 0.002511290736947558, Final Batch Loss: 0.0012819005642086267\n",
      "Epoch 3986, Loss: 0.00022331165018840693, Final Batch Loss: 0.000130060754599981\n",
      "Epoch 3987, Loss: 5.187283568375278e-05, Final Batch Loss: 6.18500416749157e-06\n",
      "Epoch 3988, Loss: 0.00013661441516887862, Final Batch Loss: 1.0841404218808748e-05\n",
      "Epoch 3989, Loss: 0.0011110524501418695, Final Batch Loss: 4.872819408774376e-05\n",
      "Epoch 3990, Loss: 0.0021979507291689515, Final Batch Loss: 0.001752075389958918\n",
      "Epoch 3991, Loss: 0.0004746373488160316, Final Batch Loss: 2.0228326320648193e-05\n",
      "Epoch 3992, Loss: 0.0003959126015615766, Final Batch Loss: 9.32468810788123e-06\n",
      "Epoch 3993, Loss: 0.0035700988719327142, Final Batch Loss: 1.9686436644406058e-05\n",
      "Epoch 3994, Loss: 0.005129300323460484, Final Batch Loss: 0.0003756885707844049\n",
      "Epoch 3995, Loss: 0.0001951694066519849, Final Batch Loss: 1.229261306434637e-05\n",
      "Epoch 3996, Loss: 0.02650205639656633, Final Batch Loss: 0.0003363194700796157\n",
      "Epoch 3997, Loss: 0.001292955108510796, Final Batch Loss: 0.0003202073567081243\n",
      "Epoch 3998, Loss: 7.96520816948032e-05, Final Batch Loss: 9.933071851264685e-06\n",
      "Epoch 3999, Loss: 6.576094438059954e-05, Final Batch Loss: 1.427864935976686e-05\n",
      "Epoch 4000, Loss: 0.002591705197119154, Final Batch Loss: 0.0006393040530383587\n",
      "Epoch 4001, Loss: 0.00017831600507633993, Final Batch Loss: 5.984898052702192e-06\n",
      "Epoch 4002, Loss: 0.00013781299276161008, Final Batch Loss: 4.5453041821019724e-05\n",
      "Epoch 4003, Loss: 0.06685556717457075, Final Batch Loss: 2.361181213927921e-05\n",
      "Epoch 4004, Loss: 0.00020537892305583227, Final Batch Loss: 3.0261757274274714e-05\n",
      "Epoch 4005, Loss: 0.0011120117851532996, Final Batch Loss: 0.0001824861392378807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4006, Loss: 0.0008984041487565264, Final Batch Loss: 4.1924948163796216e-05\n",
      "Epoch 4007, Loss: 0.00019704682927113026, Final Batch Loss: 2.8616617782972753e-05\n",
      "Epoch 4008, Loss: 0.005227350497079897, Final Batch Loss: 1.763969885359984e-05\n",
      "Epoch 4009, Loss: 0.0014392018201760948, Final Batch Loss: 0.000189333368325606\n",
      "Epoch 4010, Loss: 0.02373919460660545, Final Batch Loss: 0.00022761790023650974\n",
      "Epoch 4011, Loss: 0.04017163819662528, Final Batch Loss: 0.03996261954307556\n",
      "Epoch 4012, Loss: 0.0014787420295760967, Final Batch Loss: 1.595829235156998e-05\n",
      "Epoch 4013, Loss: 9.468302414461505e-05, Final Batch Loss: 2.3612989025423303e-05\n",
      "Epoch 4014, Loss: 0.00011593339331739116, Final Batch Loss: 3.4207743738079444e-05\n",
      "Epoch 4015, Loss: 0.004181939892077935, Final Batch Loss: 7.858738172217272e-06\n",
      "Epoch 4016, Loss: 0.0004959745347150601, Final Batch Loss: 0.00023336887534242123\n",
      "Epoch 4017, Loss: 0.00023319225510931574, Final Batch Loss: 4.805534263141453e-05\n",
      "Epoch 4018, Loss: 0.0003650614162324928, Final Batch Loss: 8.114860247587785e-05\n",
      "Epoch 4019, Loss: 0.00034639779187273234, Final Batch Loss: 8.361326035810634e-05\n",
      "Epoch 4020, Loss: 0.014016554621775867, Final Batch Loss: 6.055099220247939e-06\n",
      "Epoch 4021, Loss: 0.0005608810233752592, Final Batch Loss: 1.8874468878493644e-05\n",
      "Epoch 4022, Loss: 0.0010481921681275708, Final Batch Loss: 4.4219750634511e-06\n",
      "Epoch 4023, Loss: 0.00041285669067292474, Final Batch Loss: 2.7089801733382046e-05\n",
      "Epoch 4024, Loss: 0.00024169360222003888, Final Batch Loss: 2.9755632567685097e-05\n",
      "Epoch 4025, Loss: 0.012467847380321473, Final Batch Loss: 0.0005191453383304179\n",
      "Epoch 4026, Loss: 0.036948873254004866, Final Batch Loss: 0.0004571996396407485\n",
      "Epoch 4027, Loss: 0.001194945172755979, Final Batch Loss: 0.0003147468960378319\n",
      "Epoch 4028, Loss: 0.0031329490202551824, Final Batch Loss: 6.669190952379722e-06\n",
      "Epoch 4029, Loss: 0.0006665387045359239, Final Batch Loss: 8.24340240797028e-05\n",
      "Epoch 4030, Loss: 0.0011309279980196152, Final Batch Loss: 5.206565037951805e-05\n",
      "Epoch 4031, Loss: 0.0033335934567730874, Final Batch Loss: 7.595501665491611e-05\n",
      "Epoch 4032, Loss: 0.00025465370708843693, Final Batch Loss: 3.581250348361209e-05\n",
      "Epoch 4033, Loss: 0.000442057651525829, Final Batch Loss: 0.0001286018086830154\n",
      "Epoch 4034, Loss: 0.0012143630665377714, Final Batch Loss: 0.0009441149886697531\n",
      "Epoch 4035, Loss: 0.000884020708326716, Final Batch Loss: 0.00012031861842842773\n",
      "Epoch 4036, Loss: 0.0005064060023869388, Final Batch Loss: 0.00016399103333242238\n",
      "Epoch 4037, Loss: 0.0034082352503901348, Final Batch Loss: 0.0030790234450250864\n",
      "Epoch 4038, Loss: 0.0021471339277923107, Final Batch Loss: 0.0009059279691427946\n",
      "Epoch 4039, Loss: 0.00027266183315077797, Final Batch Loss: 9.074326953850687e-05\n",
      "Epoch 4040, Loss: 0.00022483194788947003, Final Batch Loss: 4.458815965335816e-05\n",
      "Epoch 4041, Loss: 0.0014435008270083927, Final Batch Loss: 0.00019737269030883908\n",
      "Epoch 4042, Loss: 0.0002794982065097429, Final Batch Loss: 7.536578777944669e-05\n",
      "Epoch 4043, Loss: 0.0007034245209069923, Final Batch Loss: 0.00013571525050792843\n",
      "Epoch 4044, Loss: 0.0003057761250602198, Final Batch Loss: 5.940933078818489e-06\n",
      "Epoch 4045, Loss: 0.016570804553339258, Final Batch Loss: 0.015888409689068794\n",
      "Epoch 4046, Loss: 0.000524575705640018, Final Batch Loss: 9.912997484207153e-05\n",
      "Epoch 4047, Loss: 0.0011353887821314856, Final Batch Loss: 0.0005628453800454736\n",
      "Epoch 4048, Loss: 0.001322657088167034, Final Batch Loss: 8.955378143582493e-05\n",
      "Epoch 4049, Loss: 0.01626654119172599, Final Batch Loss: 0.00022431631805375218\n",
      "Epoch 4050, Loss: 0.00094663466734346, Final Batch Loss: 8.362786320503801e-05\n",
      "Epoch 4051, Loss: 0.036093027330935, Final Batch Loss: 0.0001878690382000059\n",
      "Epoch 4052, Loss: 0.0015296977580874227, Final Batch Loss: 0.0012025578180328012\n",
      "Epoch 4053, Loss: 0.0007273208102560602, Final Batch Loss: 1.9977720512542874e-05\n",
      "Epoch 4054, Loss: 0.00026390277707832865, Final Batch Loss: 5.0368245865684e-05\n",
      "Epoch 4055, Loss: 0.0004610888354363851, Final Batch Loss: 0.00013724564632866532\n",
      "Epoch 4056, Loss: 0.00019059448823099956, Final Batch Loss: 7.874969014665112e-05\n",
      "Epoch 4057, Loss: 0.000575449230382219, Final Batch Loss: 6.271820166148245e-05\n",
      "Epoch 4058, Loss: 0.00013854276585334446, Final Batch Loss: 5.753954246756621e-05\n",
      "Epoch 4059, Loss: 0.00022458054081653245, Final Batch Loss: 2.0814968593185768e-05\n",
      "Epoch 4060, Loss: 0.0005242219049250707, Final Batch Loss: 8.645327761769295e-05\n",
      "Epoch 4061, Loss: 0.0006808115940657444, Final Batch Loss: 0.0004564490809570998\n",
      "Epoch 4062, Loss: 0.0004953661082254257, Final Batch Loss: 0.00031585601391270757\n",
      "Epoch 4063, Loss: 0.0004893630612059496, Final Batch Loss: 2.335861063329503e-05\n",
      "Epoch 4064, Loss: 0.0005321886274032295, Final Batch Loss: 0.00026994544896297157\n",
      "Epoch 4065, Loss: 0.009171549063466955, Final Batch Loss: 0.00019593453907873482\n",
      "Epoch 4066, Loss: 0.018989574960869504, Final Batch Loss: 1.6014801076380536e-05\n",
      "Epoch 4067, Loss: 0.00035069244040641934, Final Batch Loss: 6.894020043546334e-05\n",
      "Epoch 4068, Loss: 0.00322996883187443, Final Batch Loss: 6.782409036532044e-05\n",
      "Epoch 4069, Loss: 0.03530534790479578, Final Batch Loss: 0.03280861675739288\n",
      "Epoch 4070, Loss: 0.0007392249826807529, Final Batch Loss: 0.00015171107952482998\n",
      "Epoch 4071, Loss: 0.0009022688609547913, Final Batch Loss: 4.078683559782803e-05\n",
      "Epoch 4072, Loss: 0.008119330246699974, Final Batch Loss: 0.00026340255863033235\n",
      "Epoch 4073, Loss: 0.004337616715929471, Final Batch Loss: 0.0005831426824443042\n",
      "Epoch 4074, Loss: 0.0006092230287322309, Final Batch Loss: 0.0003492161340545863\n",
      "Epoch 4075, Loss: 0.001319014911132399, Final Batch Loss: 0.001180522027425468\n",
      "Epoch 4076, Loss: 0.0019056348064623307, Final Batch Loss: 0.0007947025005705655\n",
      "Epoch 4077, Loss: 0.0064859549747779965, Final Batch Loss: 0.0001646053569857031\n",
      "Epoch 4078, Loss: 0.0003298911251476966, Final Batch Loss: 9.075906564248726e-05\n",
      "Epoch 4079, Loss: 0.00020337957539595664, Final Batch Loss: 5.512238567462191e-05\n",
      "Epoch 4080, Loss: 0.0018822674428520259, Final Batch Loss: 3.143047433695756e-05\n",
      "Epoch 4081, Loss: 0.0016246110608335584, Final Batch Loss: 0.0007908380939625204\n",
      "Epoch 4082, Loss: 0.0002011366104852641, Final Batch Loss: 2.1107940483489074e-05\n",
      "Epoch 4083, Loss: 0.002716355083975941, Final Batch Loss: 0.002123574260622263\n",
      "Epoch 4084, Loss: 0.006119848971138708, Final Batch Loss: 0.00023315503494814038\n",
      "Epoch 4085, Loss: 0.0002864987727662083, Final Batch Loss: 0.0001305856421822682\n",
      "Epoch 4086, Loss: 0.00027203978243051097, Final Batch Loss: 5.87673821428325e-05\n",
      "Epoch 4087, Loss: 0.0004901944557786919, Final Batch Loss: 0.00015304012049455196\n",
      "Epoch 4088, Loss: 0.026766792994749267, Final Batch Loss: 0.026446346193552017\n",
      "Epoch 4089, Loss: 0.0005433599308162229, Final Batch Loss: 1.9958826669608243e-05\n",
      "Epoch 4090, Loss: 0.02470072875075857, Final Batch Loss: 0.02450147457420826\n",
      "Epoch 4091, Loss: 0.028780861328414176, Final Batch Loss: 5.368798883864656e-05\n",
      "Epoch 4092, Loss: 0.0011864743755722884, Final Batch Loss: 0.0009793615899980068\n",
      "Epoch 4093, Loss: 0.00026212279408355244, Final Batch Loss: 3.248652137699537e-05\n",
      "Epoch 4094, Loss: 0.0009099639501073398, Final Batch Loss: 3.994076178059913e-05\n",
      "Epoch 4095, Loss: 0.0004436281815287657, Final Batch Loss: 0.0001544727711006999\n",
      "Epoch 4096, Loss: 0.001656607520999387, Final Batch Loss: 0.0003283310797996819\n",
      "Epoch 4097, Loss: 0.0006877601808810141, Final Batch Loss: 3.9436581573681906e-05\n",
      "Epoch 4098, Loss: 0.0004690781715908088, Final Batch Loss: 0.00024265205138362944\n",
      "Epoch 4099, Loss: 0.0010877819568122504, Final Batch Loss: 2.0022942408104427e-05\n",
      "Epoch 4100, Loss: 0.0030749870056752115, Final Batch Loss: 0.0019020099425688386\n",
      "Epoch 4101, Loss: 0.00027626060727925505, Final Batch Loss: 2.351138937228825e-05\n",
      "Epoch 4102, Loss: 0.0014344542778417235, Final Batch Loss: 1.3176168067730032e-05\n",
      "Epoch 4103, Loss: 0.0006939801387488842, Final Batch Loss: 0.0002955155505333096\n",
      "Epoch 4104, Loss: 0.0011372044264135184, Final Batch Loss: 1.8633685613167472e-05\n",
      "Epoch 4105, Loss: 0.016455203731311485, Final Batch Loss: 3.517368531902321e-05\n",
      "Epoch 4106, Loss: 0.0003151063538098242, Final Batch Loss: 4.283560338080861e-05\n",
      "Epoch 4107, Loss: 0.0021705390317947604, Final Batch Loss: 2.5731271307449788e-05\n",
      "Epoch 4108, Loss: 0.0015976112845237367, Final Batch Loss: 0.000936475524213165\n",
      "Epoch 4109, Loss: 0.0006357402962748893, Final Batch Loss: 2.1466890757437795e-05\n",
      "Epoch 4110, Loss: 0.00041742200482985936, Final Batch Loss: 4.331460877438076e-05\n",
      "Epoch 4111, Loss: 0.000201184881007066, Final Batch Loss: 0.00010142008977709338\n",
      "Epoch 4112, Loss: 0.00041784875793382525, Final Batch Loss: 0.0001013535147649236\n",
      "Epoch 4113, Loss: 0.0006732308829668909, Final Batch Loss: 0.0001122899993788451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4114, Loss: 0.0012575890214066021, Final Batch Loss: 0.0004664748557843268\n",
      "Epoch 4115, Loss: 0.0002117512449331116, Final Batch Loss: 5.341014912119135e-05\n",
      "Epoch 4116, Loss: 0.0010075752798002213, Final Batch Loss: 0.0001868369581643492\n",
      "Epoch 4117, Loss: 0.0009563814819557592, Final Batch Loss: 0.00044922230881638825\n",
      "Epoch 4118, Loss: 0.00038101631071185693, Final Batch Loss: 0.00012103553308406845\n",
      "Epoch 4119, Loss: 0.0005964123338344507, Final Batch Loss: 0.00046598061453551054\n",
      "Epoch 4120, Loss: 0.00048161881022679154, Final Batch Loss: 1.7250635210075416e-05\n",
      "Epoch 4121, Loss: 0.002787454315694049, Final Batch Loss: 0.00028840734739787877\n",
      "Epoch 4122, Loss: 0.004296883002098184, Final Batch Loss: 0.00016783388855401427\n",
      "Epoch 4123, Loss: 0.0012110444076824933, Final Batch Loss: 0.00024734463659115136\n",
      "Epoch 4124, Loss: 0.0002668427332537249, Final Batch Loss: 7.370395178440958e-05\n",
      "Epoch 4125, Loss: 0.00019449253886705264, Final Batch Loss: 4.675613308791071e-05\n",
      "Epoch 4126, Loss: 0.0018821273552021012, Final Batch Loss: 0.0014154810924082994\n",
      "Epoch 4127, Loss: 0.0015597853671351913, Final Batch Loss: 0.0001096148116630502\n",
      "Epoch 4128, Loss: 0.0006350753756123595, Final Batch Loss: 0.0002153149398509413\n",
      "Epoch 4129, Loss: 0.005039496594690718, Final Batch Loss: 0.004837155807763338\n",
      "Epoch 4130, Loss: 0.016633854727842845, Final Batch Loss: 0.016438283026218414\n",
      "Epoch 4131, Loss: 0.00015804163012944628, Final Batch Loss: 3.0012599381734617e-05\n",
      "Epoch 4132, Loss: 0.0002653587580425665, Final Batch Loss: 4.122607788303867e-05\n",
      "Epoch 4133, Loss: 0.0013191994494263781, Final Batch Loss: 2.1630314222420566e-05\n",
      "Epoch 4134, Loss: 0.002166123133065412, Final Batch Loss: 0.00018909649224951863\n",
      "Epoch 4135, Loss: 0.0004637737583834678, Final Batch Loss: 0.00021054728131275624\n",
      "Epoch 4136, Loss: 0.0006179121701279655, Final Batch Loss: 0.00027146388310939074\n",
      "Epoch 4137, Loss: 0.0009977060162782436, Final Batch Loss: 0.0007766493945382535\n",
      "Epoch 4138, Loss: 0.0005567149050875742, Final Batch Loss: 6.117006250860868e-06\n",
      "Epoch 4139, Loss: 0.0004525170588749461, Final Batch Loss: 1.903169322758913e-05\n",
      "Epoch 4140, Loss: 0.001193958283693064, Final Batch Loss: 5.3998643124941736e-05\n",
      "Epoch 4141, Loss: 0.0007303227939701173, Final Batch Loss: 5.3130093874642625e-05\n",
      "Epoch 4142, Loss: 0.004165140722761862, Final Batch Loss: 0.003933979198336601\n",
      "Epoch 4143, Loss: 0.000418818999605719, Final Batch Loss: 6.939826562302187e-05\n",
      "Epoch 4144, Loss: 0.0013552971940953285, Final Batch Loss: 0.00037619879003614187\n",
      "Epoch 4145, Loss: 0.00015599184916936792, Final Batch Loss: 6.871502409921959e-05\n",
      "Epoch 4146, Loss: 0.0006793105312681291, Final Batch Loss: 0.0006100279279053211\n",
      "Epoch 4147, Loss: 0.0031600568581779953, Final Batch Loss: 0.0005898803356103599\n",
      "Epoch 4148, Loss: 0.0010905462950177025, Final Batch Loss: 2.1276482584653422e-05\n",
      "Epoch 4149, Loss: 0.0002905593173636589, Final Batch Loss: 1.8241855286760256e-05\n",
      "Epoch 4150, Loss: 0.0039390008969348855, Final Batch Loss: 0.0035682599991559982\n",
      "Epoch 4151, Loss: 0.00018231036574434256, Final Batch Loss: 9.253471034753602e-06\n",
      "Epoch 4152, Loss: 0.00042593630132614635, Final Batch Loss: 6.740389653714374e-05\n",
      "Epoch 4153, Loss: 0.0027768394866143353, Final Batch Loss: 3.7875797715969384e-05\n",
      "Epoch 4154, Loss: 0.0003305273512523854, Final Batch Loss: 7.100049697328359e-05\n",
      "Epoch 4155, Loss: 0.0002579040919954423, Final Batch Loss: 5.290562330628745e-05\n",
      "Epoch 4156, Loss: 0.0003769526883843355, Final Batch Loss: 8.130389323923737e-05\n",
      "Epoch 4157, Loss: 0.0033417905688111205, Final Batch Loss: 0.003174582729116082\n",
      "Epoch 4158, Loss: 0.0040736646587902214, Final Batch Loss: 0.003961671143770218\n",
      "Epoch 4159, Loss: 0.00021322177053662017, Final Batch Loss: 9.411264909431338e-05\n",
      "Epoch 4160, Loss: 0.002372179873418645, Final Batch Loss: 0.002281344961374998\n",
      "Epoch 4161, Loss: 0.00017741431838658173, Final Batch Loss: 2.4647046302561648e-05\n",
      "Epoch 4162, Loss: 0.0014281530529842712, Final Batch Loss: 5.6612778280396014e-05\n",
      "Epoch 4163, Loss: 0.0014282744232332334, Final Batch Loss: 7.609940075781196e-05\n",
      "Epoch 4164, Loss: 0.0008997609311336419, Final Batch Loss: 3.2634823583066463e-05\n",
      "Epoch 4165, Loss: 0.00038381110061891377, Final Batch Loss: 0.00012620633060578257\n",
      "Epoch 4166, Loss: 0.0006066327769076452, Final Batch Loss: 0.00010232869681203738\n",
      "Epoch 4167, Loss: 7.004260442045052e-05, Final Batch Loss: 1.7064921848941594e-05\n",
      "Epoch 4168, Loss: 0.001167783688288182, Final Batch Loss: 0.0003753383061848581\n",
      "Epoch 4169, Loss: 0.0023404797921102727, Final Batch Loss: 1.4871862731524743e-05\n",
      "Epoch 4170, Loss: 0.00013253836550575215, Final Batch Loss: 4.538348366622813e-05\n",
      "Epoch 4171, Loss: 0.0006165896920720115, Final Batch Loss: 0.0001505521358922124\n",
      "Epoch 4172, Loss: 0.0006939206748484139, Final Batch Loss: 1.9928581878048135e-06\n",
      "Epoch 4173, Loss: 0.014089442152908305, Final Batch Loss: 0.012921517714858055\n",
      "Epoch 4174, Loss: 0.00021614286197291221, Final Batch Loss: 3.630314677138813e-05\n",
      "Epoch 4175, Loss: 0.00019759084170800634, Final Batch Loss: 1.7125876183854416e-05\n",
      "Epoch 4176, Loss: 0.0003258591750636697, Final Batch Loss: 6.339441461022943e-05\n",
      "Epoch 4177, Loss: 0.00021489821301656775, Final Batch Loss: 9.782731649465859e-05\n",
      "Epoch 4178, Loss: 0.000440546087702387, Final Batch Loss: 2.3552283892058767e-05\n",
      "Epoch 4179, Loss: 0.00041867995241773315, Final Batch Loss: 2.958492041216232e-05\n",
      "Epoch 4180, Loss: 0.00023806122817404685, Final Batch Loss: 5.7581860346545e-06\n",
      "Epoch 4181, Loss: 0.00019789791622315533, Final Batch Loss: 2.1037292754044756e-05\n",
      "Epoch 4182, Loss: 0.00026705986965680495, Final Batch Loss: 0.0001797511795302853\n",
      "Epoch 4183, Loss: 0.0005360095228752471, Final Batch Loss: 0.00030110671650618315\n",
      "Epoch 4184, Loss: 0.00026652754058886785, Final Batch Loss: 1.2100927051506005e-05\n",
      "Epoch 4185, Loss: 4.781782854479388e-05, Final Batch Loss: 2.389836936345091e-06\n",
      "Epoch 4186, Loss: 0.00040452423854731023, Final Batch Loss: 0.00016717663675080985\n",
      "Epoch 4187, Loss: 0.00021235197527857963, Final Batch Loss: 2.1969610315863974e-05\n",
      "Epoch 4188, Loss: 0.00047534212717437185, Final Batch Loss: 0.00010449121327837929\n",
      "Epoch 4189, Loss: 0.00016838928058859892, Final Batch Loss: 4.388924935483374e-05\n",
      "Epoch 4190, Loss: 0.000206516695470782, Final Batch Loss: 0.0001481078506913036\n",
      "Epoch 4191, Loss: 0.00014203336877471884, Final Batch Loss: 5.0720286708383355e-06\n",
      "Epoch 4192, Loss: 0.0005704777540813666, Final Batch Loss: 0.00044617807725444436\n",
      "Epoch 4193, Loss: 0.001447428952815244, Final Batch Loss: 8.265207725344226e-06\n",
      "Epoch 4194, Loss: 0.00033795530725910794, Final Batch Loss: 0.00010315381223335862\n",
      "Epoch 4195, Loss: 0.00018058091882267036, Final Batch Loss: 4.497701229411177e-05\n",
      "Epoch 4196, Loss: 0.001102461974369362, Final Batch Loss: 3.365423617651686e-05\n",
      "Epoch 4197, Loss: 0.0001944868272403255, Final Batch Loss: 4.481576252146624e-05\n",
      "Epoch 4198, Loss: 8.795480084700102e-05, Final Batch Loss: 2.3110135316528613e-06\n",
      "Epoch 4199, Loss: 0.0007649265135114547, Final Batch Loss: 0.0006781935226172209\n",
      "Epoch 4200, Loss: 0.00031092600875126664, Final Batch Loss: 1.2443239029380493e-05\n",
      "Epoch 4201, Loss: 0.0003604249677664484, Final Batch Loss: 1.4079693755775224e-05\n",
      "Epoch 4202, Loss: 0.00015348493980127387, Final Batch Loss: 8.329111733473837e-05\n",
      "Epoch 4203, Loss: 0.00011412905405450147, Final Batch Loss: 1.7945852960110642e-05\n",
      "Epoch 4204, Loss: 0.0003275012595622684, Final Batch Loss: 2.5826071578194387e-05\n",
      "Epoch 4205, Loss: 0.025591172197891865, Final Batch Loss: 3.7970916309859604e-05\n",
      "Epoch 4206, Loss: 0.005013466616219375, Final Batch Loss: 0.00466884532943368\n",
      "Epoch 4207, Loss: 0.0015127245824260172, Final Batch Loss: 9.13422554731369e-05\n",
      "Epoch 4208, Loss: 0.0002247413376608165, Final Batch Loss: 1.881903335743118e-05\n",
      "Epoch 4209, Loss: 0.0023496682097174926, Final Batch Loss: 1.4588697013095953e-05\n",
      "Epoch 4210, Loss: 0.0016229762177317753, Final Batch Loss: 0.0015985070494934916\n",
      "Epoch 4211, Loss: 0.0003096420405199751, Final Batch Loss: 1.735870318952948e-05\n",
      "Epoch 4212, Loss: 0.00044217028334969655, Final Batch Loss: 0.00019863971101585776\n",
      "Epoch 4213, Loss: 0.0015647181498934515, Final Batch Loss: 1.6484242223668844e-05\n",
      "Epoch 4214, Loss: 0.0010968775213768822, Final Batch Loss: 6.849314559076447e-06\n",
      "Epoch 4215, Loss: 0.0003079426496697124, Final Batch Loss: 0.00014990892668720335\n",
      "Epoch 4216, Loss: 0.00022166409507917706, Final Batch Loss: 1.242381586052943e-05\n",
      "Epoch 4217, Loss: 0.0005331455067789648, Final Batch Loss: 2.9620412533404306e-05\n",
      "Epoch 4218, Loss: 0.00020787815446965396, Final Batch Loss: 5.656163557432592e-05\n",
      "Epoch 4219, Loss: 0.00025447745792916976, Final Batch Loss: 0.00017153088992927223\n",
      "Epoch 4220, Loss: 0.0007417186880047666, Final Batch Loss: 2.934531403298024e-05\n",
      "Epoch 4221, Loss: 0.00025914760772138834, Final Batch Loss: 4.862389323534444e-05\n",
      "Epoch 4222, Loss: 0.00019220111062168144, Final Batch Loss: 4.652535790228285e-05\n",
      "Epoch 4223, Loss: 0.004622179348189093, Final Batch Loss: 1.24855641843169e-05\n",
      "Epoch 4224, Loss: 0.00038872803997946903, Final Batch Loss: 0.0003270770830567926\n",
      "Epoch 4225, Loss: 0.001914564458274981, Final Batch Loss: 0.0018009311752393842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4226, Loss: 0.0006716047646477818, Final Batch Loss: 0.00040166510734707117\n",
      "Epoch 4227, Loss: 0.005049423853051849, Final Batch Loss: 0.004796160850673914\n",
      "Epoch 4228, Loss: 0.0002886615911847912, Final Batch Loss: 6.554441642947495e-05\n",
      "Epoch 4229, Loss: 0.0002737367249210365, Final Batch Loss: 0.00014486999134533107\n",
      "Epoch 4230, Loss: 0.0002999768767040223, Final Batch Loss: 0.0001305898476857692\n",
      "Epoch 4231, Loss: 0.00017062997721950524, Final Batch Loss: 0.00010720640420913696\n",
      "Epoch 4232, Loss: 0.0003918440843335702, Final Batch Loss: 7.048357474559452e-06\n",
      "Epoch 4233, Loss: 0.002195741205014201, Final Batch Loss: 4.897762210021028e-06\n",
      "Epoch 4234, Loss: 0.0006081767205614597, Final Batch Loss: 0.00028012768598273396\n",
      "Epoch 4235, Loss: 0.00025173834910674486, Final Batch Loss: 0.00011254606943111867\n",
      "Epoch 4236, Loss: 0.0001954651988853584, Final Batch Loss: 4.4213960791239515e-05\n",
      "Epoch 4237, Loss: 0.0002594660381873837, Final Batch Loss: 1.9272207282483578e-05\n",
      "Epoch 4238, Loss: 4.945594810124021e-05, Final Batch Loss: 9.537631740386132e-06\n",
      "Epoch 4239, Loss: 0.00017754505461198278, Final Batch Loss: 1.552525645820424e-05\n",
      "Epoch 4240, Loss: 0.0001827148207667051, Final Batch Loss: 2.8613610993488692e-05\n",
      "Epoch 4241, Loss: 0.004095326039532665, Final Batch Loss: 0.0032115166541188955\n",
      "Epoch 4242, Loss: 0.0010970244557029218, Final Batch Loss: 1.4577221918443684e-05\n",
      "Epoch 4243, Loss: 0.0001673341466812417, Final Batch Loss: 4.082074519828893e-05\n",
      "Epoch 4244, Loss: 0.0007109521229722304, Final Batch Loss: 0.0005748819676227868\n",
      "Epoch 4245, Loss: 0.0017118787036451977, Final Batch Loss: 0.001632740255445242\n",
      "Epoch 4246, Loss: 0.00023968391178641468, Final Batch Loss: 0.00014679119340144098\n",
      "Epoch 4247, Loss: 0.0004563677721307613, Final Batch Loss: 0.00040462546166963875\n",
      "Epoch 4248, Loss: 0.00015310596836570767, Final Batch Loss: 6.712540653097676e-06\n",
      "Epoch 4249, Loss: 0.0002371426235185936, Final Batch Loss: 7.422081398544833e-05\n",
      "Epoch 4250, Loss: 0.002176300302380696, Final Batch Loss: 0.0014732718700543046\n",
      "Epoch 4251, Loss: 0.0005683479466824792, Final Batch Loss: 6.882935849716887e-05\n",
      "Epoch 4252, Loss: 0.01949487919046078, Final Batch Loss: 2.9602189897559583e-05\n",
      "Epoch 4253, Loss: 0.0002527629694668576, Final Batch Loss: 8.283834904432297e-05\n",
      "Epoch 4254, Loss: 0.00044642250577453524, Final Batch Loss: 0.00017744481738191098\n",
      "Epoch 4255, Loss: 0.0003978396052843891, Final Batch Loss: 9.503488399786875e-05\n",
      "Epoch 4256, Loss: 0.0008330029563694552, Final Batch Loss: 4.042355158162536e-06\n",
      "Epoch 4257, Loss: 0.00877471425337717, Final Batch Loss: 0.0004818779125344008\n",
      "Epoch 4258, Loss: 0.0009109522889048094, Final Batch Loss: 0.0006833361694589257\n",
      "Epoch 4259, Loss: 7.631325070178718e-05, Final Batch Loss: 6.891371867823182e-06\n",
      "Epoch 4260, Loss: 0.0006776284262741683, Final Batch Loss: 0.0001374486309941858\n",
      "Epoch 4261, Loss: 0.0014905472053214908, Final Batch Loss: 0.0003894257824867964\n",
      "Epoch 4262, Loss: 0.0019486677774693817, Final Batch Loss: 0.0003300857497379184\n",
      "Epoch 4263, Loss: 0.0002777526206045877, Final Batch Loss: 0.00013700593262910843\n",
      "Epoch 4264, Loss: 0.0006856356940261321, Final Batch Loss: 1.9426779545028694e-05\n",
      "Epoch 4265, Loss: 0.0018227969776489772, Final Batch Loss: 0.0016199995297938585\n",
      "Epoch 4266, Loss: 0.001498121848271694, Final Batch Loss: 6.273114559007809e-05\n",
      "Epoch 4267, Loss: 0.0003233824609196745, Final Batch Loss: 0.00011093672947026789\n",
      "Epoch 4268, Loss: 0.0009767957963049412, Final Batch Loss: 9.553259587846696e-05\n",
      "Epoch 4269, Loss: 0.0012932122335769236, Final Batch Loss: 0.0009582628845237195\n",
      "Epoch 4270, Loss: 0.00016733468510210514, Final Batch Loss: 4.355671626399271e-05\n",
      "Epoch 4271, Loss: 0.0015303542240872048, Final Batch Loss: 5.787450209027156e-05\n",
      "Epoch 4272, Loss: 0.0006051689360901946, Final Batch Loss: 6.460943041020073e-06\n",
      "Epoch 4273, Loss: 0.0005032871031289687, Final Batch Loss: 0.0001122049507102929\n",
      "Epoch 4274, Loss: 0.000172278246282076, Final Batch Loss: 3.2935231502051465e-06\n",
      "Epoch 4275, Loss: 0.0001318519625783665, Final Batch Loss: 4.718164200312458e-05\n",
      "Epoch 4276, Loss: 0.00022521092250826769, Final Batch Loss: 8.520641131326556e-05\n",
      "Epoch 4277, Loss: 0.00022246230582823046, Final Batch Loss: 0.00018536999414209276\n",
      "Epoch 4278, Loss: 0.0004292553785489872, Final Batch Loss: 6.408976332750171e-05\n",
      "Epoch 4279, Loss: 0.0009007075714180246, Final Batch Loss: 0.00011985698802163824\n",
      "Epoch 4280, Loss: 0.00045155061798141105, Final Batch Loss: 1.3442545423458796e-05\n",
      "Epoch 4281, Loss: 0.0005394473373598885, Final Batch Loss: 0.000175868917722255\n",
      "Epoch 4282, Loss: 0.0011622751480899751, Final Batch Loss: 0.00018332814215682447\n",
      "Epoch 4283, Loss: 0.0009956062012861366, Final Batch Loss: 1.4101638043939602e-05\n",
      "Epoch 4284, Loss: 0.0013461258222378092, Final Batch Loss: 0.0010073492303490639\n",
      "Epoch 4285, Loss: 0.0004801807663170621, Final Batch Loss: 0.00030695644090883434\n",
      "Epoch 4286, Loss: 0.00044908426025358494, Final Batch Loss: 2.398608012299519e-05\n",
      "Epoch 4287, Loss: 0.0008571566331738723, Final Batch Loss: 1.0556924280535895e-05\n",
      "Epoch 4288, Loss: 0.00018878039463743335, Final Batch Loss: 7.173758785938844e-05\n",
      "Epoch 4289, Loss: 0.0006725995272063301, Final Batch Loss: 7.001560334174428e-06\n",
      "Epoch 4290, Loss: 0.0014829219226157875, Final Batch Loss: 4.025745874969289e-05\n",
      "Epoch 4291, Loss: 0.029756217601971002, Final Batch Loss: 0.00013361868332140148\n",
      "Epoch 4292, Loss: 0.00047185584298858885, Final Batch Loss: 2.5627779905335046e-05\n",
      "Epoch 4293, Loss: 0.0001922394694702234, Final Batch Loss: 0.00011681220348691568\n",
      "Epoch 4294, Loss: 0.0004180985952189076, Final Batch Loss: 1.1510909644130152e-05\n",
      "Epoch 4295, Loss: 0.00011652286411845125, Final Batch Loss: 4.5197881263447925e-05\n",
      "Epoch 4296, Loss: 0.0001703824473224813, Final Batch Loss: 0.0001363727351417765\n",
      "Epoch 4297, Loss: 0.00020680364104919136, Final Batch Loss: 2.7081587177235633e-05\n",
      "Epoch 4298, Loss: 0.0019402091784286313, Final Batch Loss: 0.0007750241784378886\n",
      "Epoch 4299, Loss: 0.0007163026111811632, Final Batch Loss: 3.277223731856793e-05\n",
      "Epoch 4300, Loss: 0.00038071195558586624, Final Batch Loss: 5.844796760356985e-06\n",
      "Epoch 4301, Loss: 0.000509641642565839, Final Batch Loss: 0.0002784203097689897\n",
      "Epoch 4302, Loss: 0.01622669424978085, Final Batch Loss: 0.015922335907816887\n",
      "Epoch 4303, Loss: 0.002382233906246256, Final Batch Loss: 4.66604033135809e-05\n",
      "Epoch 4304, Loss: 0.003871091816108674, Final Batch Loss: 0.0002332394360564649\n",
      "Epoch 4305, Loss: 0.09900854796433123, Final Batch Loss: 0.0940939411520958\n",
      "Epoch 4306, Loss: 0.00852782197034685, Final Batch Loss: 1.9701015844475478e-05\n",
      "Epoch 4307, Loss: 0.00040113975410349667, Final Batch Loss: 8.615008118795231e-05\n",
      "Epoch 4308, Loss: 0.0007756455270282459, Final Batch Loss: 0.0006107335211709142\n",
      "Epoch 4309, Loss: 0.008221147843869403, Final Batch Loss: 6.253196625038981e-05\n",
      "Epoch 4310, Loss: 0.00032701406053092796, Final Batch Loss: 2.0479785234783776e-05\n",
      "Epoch 4311, Loss: 0.00039434652717318386, Final Batch Loss: 4.321704909671098e-05\n",
      "Epoch 4312, Loss: 0.006706550164381042, Final Batch Loss: 0.006380398757755756\n",
      "Epoch 4313, Loss: 0.0005030575739510823, Final Batch Loss: 0.0003623497032094747\n",
      "Epoch 4314, Loss: 0.0006147528474684805, Final Batch Loss: 0.0003328267193865031\n",
      "Epoch 4315, Loss: 0.00031457224395126104, Final Batch Loss: 8.540185081074014e-05\n",
      "Epoch 4316, Loss: 0.01940540873329155, Final Batch Loss: 7.778199505992234e-05\n",
      "Epoch 4317, Loss: 0.0006820437774877064, Final Batch Loss: 0.00012042088928865269\n",
      "Epoch 4318, Loss: 0.0016091899960883893, Final Batch Loss: 3.127117088297382e-05\n",
      "Epoch 4319, Loss: 0.0002526681128074415, Final Batch Loss: 5.72215358261019e-05\n",
      "Epoch 4320, Loss: 0.0020321942647569813, Final Batch Loss: 0.00010184117854805663\n",
      "Epoch 4321, Loss: 0.0003952331098844297, Final Batch Loss: 0.00013087564730085433\n",
      "Epoch 4322, Loss: 0.0012272535677766427, Final Batch Loss: 0.0007271891226992011\n",
      "Epoch 4323, Loss: 0.0018044349126284942, Final Batch Loss: 0.0008320707129314542\n",
      "Epoch 4324, Loss: 0.0003270129454904236, Final Batch Loss: 0.00013997383939567953\n",
      "Epoch 4325, Loss: 0.0012766497457050718, Final Batch Loss: 0.000911701179575175\n",
      "Epoch 4326, Loss: 0.024260989754111506, Final Batch Loss: 0.023993520066142082\n",
      "Epoch 4327, Loss: 0.001222616806444421, Final Batch Loss: 2.9557575544458814e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4328, Loss: 0.000261584757026867, Final Batch Loss: 0.00019135174807161093\n",
      "Epoch 4329, Loss: 0.03977532452699961, Final Batch Loss: 0.039610449224710464\n",
      "Epoch 4330, Loss: 0.0013796860293950886, Final Batch Loss: 0.00013334564573597163\n",
      "Epoch 4331, Loss: 0.00030289863934740424, Final Batch Loss: 0.00011141934373881668\n",
      "Epoch 4332, Loss: 0.00041067243728321046, Final Batch Loss: 0.0002968796470668167\n",
      "Epoch 4333, Loss: 0.008610240518464707, Final Batch Loss: 0.00012806915037799627\n",
      "Epoch 4334, Loss: 0.0071680027031106874, Final Batch Loss: 0.0001789135712897405\n",
      "Epoch 4335, Loss: 0.000872280819748994, Final Batch Loss: 0.00011104290751973167\n",
      "Epoch 4336, Loss: 0.001330036382569233, Final Batch Loss: 1.5034896932775155e-05\n",
      "Epoch 4337, Loss: 0.005333795677870512, Final Batch Loss: 0.0044706338085234165\n",
      "Epoch 4338, Loss: 0.009128270467044786, Final Batch Loss: 0.0002914358919952065\n",
      "Epoch 4339, Loss: 0.0008102573956421111, Final Batch Loss: 0.00038303210749290884\n",
      "Epoch 4340, Loss: 0.0002977542389999144, Final Batch Loss: 0.00011980689305346459\n",
      "Epoch 4341, Loss: 0.0038514881489390973, Final Batch Loss: 1.64157863764558e-05\n",
      "Epoch 4342, Loss: 0.00026375995730631985, Final Batch Loss: 9.012705413624644e-05\n",
      "Epoch 4343, Loss: 0.0003918870643246919, Final Batch Loss: 7.145261042751372e-05\n",
      "Epoch 4344, Loss: 0.00036016644298797473, Final Batch Loss: 0.00014474430645350367\n",
      "Epoch 4345, Loss: 0.0007859403049224056, Final Batch Loss: 7.464961527148262e-05\n",
      "Epoch 4346, Loss: 0.0010430058173369616, Final Batch Loss: 0.000489535799715668\n",
      "Epoch 4347, Loss: 0.0030802525870967656, Final Batch Loss: 9.290422894991934e-05\n",
      "Epoch 4348, Loss: 0.0013562262174673378, Final Batch Loss: 5.645975761581212e-05\n",
      "Epoch 4349, Loss: 0.0005754100493504666, Final Batch Loss: 0.00016068066179286689\n",
      "Epoch 4350, Loss: 0.0007315128605114296, Final Batch Loss: 6.315993960015476e-05\n",
      "Epoch 4351, Loss: 0.0002858713487512432, Final Batch Loss: 3.8468497223220766e-05\n",
      "Epoch 4352, Loss: 0.0008723750961507903, Final Batch Loss: 1.4073071724851616e-05\n",
      "Epoch 4353, Loss: 0.0005969144694972783, Final Batch Loss: 0.00010692673095036298\n",
      "Epoch 4354, Loss: 0.00020162746295682155, Final Batch Loss: 5.3373409173218533e-05\n",
      "Epoch 4355, Loss: 0.005162700661458075, Final Batch Loss: 0.00041596664232201874\n",
      "Epoch 4356, Loss: 0.0005015553178964183, Final Batch Loss: 0.00025070662377402186\n",
      "Epoch 4357, Loss: 0.00033829973108367994, Final Batch Loss: 0.00014699286839459091\n",
      "Epoch 4358, Loss: 0.0020146543211012613, Final Batch Loss: 0.0015010503120720387\n",
      "Epoch 4359, Loss: 0.0033846139594970737, Final Batch Loss: 0.002890706295147538\n",
      "Epoch 4360, Loss: 0.0010836215478775557, Final Batch Loss: 3.986365845776163e-05\n",
      "Epoch 4361, Loss: 0.00039609376108273864, Final Batch Loss: 0.00012666081602219492\n",
      "Epoch 4362, Loss: 0.0002515084015612956, Final Batch Loss: 7.124703552108258e-05\n",
      "Epoch 4363, Loss: 0.000495384112582542, Final Batch Loss: 0.0002620562445372343\n",
      "Epoch 4364, Loss: 0.001030074625305133, Final Batch Loss: 4.210257975501008e-05\n",
      "Epoch 4365, Loss: 0.0002672799600986764, Final Batch Loss: 5.560507997870445e-05\n",
      "Epoch 4366, Loss: 0.00034074321956722997, Final Batch Loss: 0.00013486116949934512\n",
      "Epoch 4367, Loss: 0.0002396408344793599, Final Batch Loss: 0.00010750912770163268\n",
      "Epoch 4368, Loss: 0.0019973195376223885, Final Batch Loss: 0.0018588799284771085\n",
      "Epoch 4369, Loss: 0.0005727565403503831, Final Batch Loss: 5.2678467909572646e-05\n",
      "Epoch 4370, Loss: 0.00017507979646325111, Final Batch Loss: 2.206631688750349e-05\n",
      "Epoch 4371, Loss: 0.0009352749184472486, Final Batch Loss: 0.00022988991986494511\n",
      "Epoch 4372, Loss: 0.0004418367134348955, Final Batch Loss: 4.588417868944816e-05\n",
      "Epoch 4373, Loss: 0.0008530831655662041, Final Batch Loss: 4.806303695659153e-05\n",
      "Epoch 4374, Loss: 0.000139110710733803, Final Batch Loss: 2.3614828023710288e-05\n",
      "Epoch 4375, Loss: 0.00035068311990471557, Final Batch Loss: 0.00020845398830715567\n",
      "Epoch 4376, Loss: 0.00022934528897167183, Final Batch Loss: 5.170228541828692e-05\n",
      "Epoch 4377, Loss: 0.00027926225448027253, Final Batch Loss: 8.011753379832953e-05\n",
      "Epoch 4378, Loss: 0.00045504212175728753, Final Batch Loss: 0.0001627808960620314\n",
      "Epoch 4379, Loss: 0.0006406862739822827, Final Batch Loss: 0.00027317978674545884\n",
      "Epoch 4380, Loss: 0.0007342090975726023, Final Batch Loss: 0.00017805362585932016\n",
      "Epoch 4381, Loss: 0.0019709176158357877, Final Batch Loss: 0.0018479271093383431\n",
      "Epoch 4382, Loss: 0.0003002375378855504, Final Batch Loss: 6.68431821395643e-05\n",
      "Epoch 4383, Loss: 0.00027141130703967065, Final Batch Loss: 0.00012818533286917955\n",
      "Epoch 4384, Loss: 0.00012822174721804913, Final Batch Loss: 1.9733661247300915e-05\n",
      "Epoch 4385, Loss: 0.00031387182207254227, Final Batch Loss: 1.6088537449832074e-05\n",
      "Epoch 4386, Loss: 0.0017919533129315823, Final Batch Loss: 0.00031242496334016323\n",
      "Epoch 4387, Loss: 0.00029868105048080906, Final Batch Loss: 0.00012690015137195587\n",
      "Epoch 4388, Loss: 0.0008008596960280556, Final Batch Loss: 5.990625868435018e-05\n",
      "Epoch 4389, Loss: 0.0003920110648323316, Final Batch Loss: 2.0147326722508296e-05\n",
      "Epoch 4390, Loss: 0.00031527422834187746, Final Batch Loss: 6.152498826850206e-05\n",
      "Epoch 4391, Loss: 0.00033579746741452254, Final Batch Loss: 0.0001436273887520656\n",
      "Epoch 4392, Loss: 0.0003202882617188152, Final Batch Loss: 2.7287631382932886e-05\n",
      "Epoch 4393, Loss: 0.00017956705596589018, Final Batch Loss: 1.0199955795542337e-05\n",
      "Epoch 4394, Loss: 0.0013387581730057718, Final Batch Loss: 2.1822876078658737e-05\n",
      "Epoch 4395, Loss: 0.0012070865923305973, Final Batch Loss: 0.0009215754107572138\n",
      "Epoch 4396, Loss: 0.002192120286053978, Final Batch Loss: 0.0001256104587810114\n",
      "Epoch 4397, Loss: 0.030160858452290995, Final Batch Loss: 0.00016199462697841227\n",
      "Epoch 4398, Loss: 0.0022154399266582914, Final Batch Loss: 0.002042085863649845\n",
      "Epoch 4399, Loss: 0.005091183251352049, Final Batch Loss: 0.0017908636946231127\n",
      "Epoch 4400, Loss: 0.0005653329935739748, Final Batch Loss: 0.00015999369497876614\n",
      "Epoch 4401, Loss: 0.0002888769449782558, Final Batch Loss: 9.511520329397172e-05\n",
      "Epoch 4402, Loss: 0.003438495255977614, Final Batch Loss: 4.5704695367021486e-05\n",
      "Epoch 4403, Loss: 0.0002761633550107945, Final Batch Loss: 4.3483811168698594e-05\n",
      "Epoch 4404, Loss: 0.002128195443219738, Final Batch Loss: 9.545475040795282e-05\n",
      "Epoch 4405, Loss: 0.0015236155304592103, Final Batch Loss: 0.0013861731858924031\n",
      "Epoch 4406, Loss: 0.0023216726767714135, Final Batch Loss: 0.00040197288035415113\n",
      "Epoch 4407, Loss: 0.0005252636547083966, Final Batch Loss: 0.00011949302279390395\n",
      "Epoch 4408, Loss: 0.00020100393339816947, Final Batch Loss: 8.346357208210975e-05\n",
      "Epoch 4409, Loss: 0.001423591451612083, Final Batch Loss: 2.8821179967053467e-06\n",
      "Epoch 4410, Loss: 0.00011858154903165996, Final Batch Loss: 5.067819802206941e-05\n",
      "Epoch 4411, Loss: 0.0004697920994658489, Final Batch Loss: 0.0002460622345097363\n",
      "Epoch 4412, Loss: 0.00043748185271397233, Final Batch Loss: 0.00016120132931973785\n",
      "Epoch 4413, Loss: 0.0009723074617795646, Final Batch Loss: 5.076208617538214e-05\n",
      "Epoch 4414, Loss: 0.0019088521075900644, Final Batch Loss: 0.0003432721714489162\n",
      "Epoch 4415, Loss: 0.0018067587006953545, Final Batch Loss: 8.583159797126427e-05\n",
      "Epoch 4416, Loss: 0.0004146893206780078, Final Batch Loss: 0.00011623610043898225\n",
      "Epoch 4417, Loss: 0.00031802765442989767, Final Batch Loss: 1.878642797237262e-05\n",
      "Epoch 4418, Loss: 0.0003203330998076126, Final Batch Loss: 3.722224209923297e-05\n",
      "Epoch 4419, Loss: 0.00011934236681554466, Final Batch Loss: 2.9832077416358516e-05\n",
      "Epoch 4420, Loss: 0.0002084932530124206, Final Batch Loss: 0.0001488129055360332\n",
      "Epoch 4421, Loss: 0.000576826416363474, Final Batch Loss: 5.972936196485534e-05\n",
      "Epoch 4422, Loss: 0.00033379896558471955, Final Batch Loss: 0.00021326944988686591\n",
      "Epoch 4423, Loss: 0.00013575569937529508, Final Batch Loss: 1.4601273505832069e-05\n",
      "Epoch 4424, Loss: 0.000460561886029609, Final Batch Loss: 3.8011030483176e-06\n",
      "Epoch 4425, Loss: 0.0002521043934393674, Final Batch Loss: 5.2985451475251466e-05\n",
      "Epoch 4426, Loss: 0.0013272079268062953, Final Batch Loss: 4.037731923745014e-05\n",
      "Epoch 4427, Loss: 0.0022178950675879605, Final Batch Loss: 6.191089778440073e-05\n",
      "Epoch 4428, Loss: 0.0005776434700237587, Final Batch Loss: 9.444859460927546e-05\n",
      "Epoch 4429, Loss: 0.00022417157288145972, Final Batch Loss: 1.0234870387648698e-05\n",
      "Epoch 4430, Loss: 0.00026115416767424904, Final Batch Loss: 3.593079964048229e-05\n",
      "Epoch 4431, Loss: 0.0002257206397189293, Final Batch Loss: 4.245373929734342e-05\n",
      "Epoch 4432, Loss: 0.006618901861656923, Final Batch Loss: 3.3156647987198085e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4433, Loss: 0.0005879457385162823, Final Batch Loss: 0.0001901085488498211\n",
      "Epoch 4434, Loss: 0.0007512731062888633, Final Batch Loss: 0.00020775791199412197\n",
      "Epoch 4435, Loss: 0.0023284060225705616, Final Batch Loss: 0.002106150845065713\n",
      "Epoch 4436, Loss: 0.0002919048856711015, Final Batch Loss: 0.00010047598334494978\n",
      "Epoch 4437, Loss: 0.0005466931552291499, Final Batch Loss: 9.863529157883022e-06\n",
      "Epoch 4438, Loss: 0.00019143480221828213, Final Batch Loss: 1.1838171303679701e-05\n",
      "Epoch 4439, Loss: 0.0011784474227169994, Final Batch Loss: 3.178336555720307e-05\n",
      "Epoch 4440, Loss: 0.00018520858429837972, Final Batch Loss: 5.2254825277486816e-05\n",
      "Epoch 4441, Loss: 0.0002234067433164455, Final Batch Loss: 0.00011527096648933366\n",
      "Epoch 4442, Loss: 0.0016865745819814038, Final Batch Loss: 3.556831143214367e-05\n",
      "Epoch 4443, Loss: 0.0025745706443558447, Final Batch Loss: 4.297577834222466e-05\n",
      "Epoch 4444, Loss: 0.005168775884158094, Final Batch Loss: 1.0284567906637676e-05\n",
      "Epoch 4445, Loss: 0.0002675980867934413, Final Batch Loss: 0.0001624668948352337\n",
      "Epoch 4446, Loss: 0.0004447569062904222, Final Batch Loss: 0.00019306350441183895\n",
      "Epoch 4447, Loss: 0.0010244310269627022, Final Batch Loss: 2.1784400814794935e-05\n",
      "Epoch 4448, Loss: 0.00348702713563398, Final Batch Loss: 2.3981849153642543e-05\n",
      "Epoch 4449, Loss: 0.0010713940901041497, Final Batch Loss: 0.00017540752014610916\n",
      "Epoch 4450, Loss: 0.0017837533214333234, Final Batch Loss: 0.0017501605907455087\n",
      "Epoch 4451, Loss: 0.004166894239460817, Final Batch Loss: 1.6958492778940126e-05\n",
      "Epoch 4452, Loss: 0.0003534742063493468, Final Batch Loss: 1.358074223389849e-05\n",
      "Epoch 4453, Loss: 0.0003136079667456215, Final Batch Loss: 2.827690877893474e-05\n",
      "Epoch 4454, Loss: 0.002122178368153982, Final Batch Loss: 0.000295251258648932\n",
      "Epoch 4455, Loss: 0.008082645857939497, Final Batch Loss: 0.004186023026704788\n",
      "Epoch 4456, Loss: 0.001755361323375837, Final Batch Loss: 2.267847776238341e-05\n",
      "Epoch 4457, Loss: 0.002403529701041407, Final Batch Loss: 8.321871064254083e-06\n",
      "Epoch 4458, Loss: 0.000989949619906838, Final Batch Loss: 1.9871351469191723e-05\n",
      "Epoch 4459, Loss: 0.0012746270822390215, Final Batch Loss: 6.0076621593907475e-05\n",
      "Epoch 4460, Loss: 0.0003796664532274008, Final Batch Loss: 8.748615073272958e-05\n",
      "Epoch 4461, Loss: 0.027690134706062963, Final Batch Loss: 2.2102427465142682e-05\n",
      "Epoch 4462, Loss: 0.0011093779576185625, Final Batch Loss: 3.321731855976395e-05\n",
      "Epoch 4463, Loss: 0.00029011333572270814, Final Batch Loss: 2.848082840500865e-05\n",
      "Epoch 4464, Loss: 0.0001545072955195792, Final Batch Loss: 6.540386675624177e-05\n",
      "Epoch 4465, Loss: 0.0010665495137800463, Final Batch Loss: 0.0009401090210303664\n",
      "Epoch 4466, Loss: 0.0002854881404346088, Final Batch Loss: 9.308203152613714e-05\n",
      "Epoch 4467, Loss: 0.002812664901284734, Final Batch Loss: 0.0018578681629151106\n",
      "Epoch 4468, Loss: 0.0009624161039027967, Final Batch Loss: 0.000254700833465904\n",
      "Epoch 4469, Loss: 0.00011320544854243053, Final Batch Loss: 4.730637556349393e-06\n",
      "Epoch 4470, Loss: 0.0013822091714246199, Final Batch Loss: 0.0009763563866727054\n",
      "Epoch 4471, Loss: 0.03818982075972599, Final Batch Loss: 0.037574730813503265\n",
      "Epoch 4472, Loss: 0.00038134771602926776, Final Batch Loss: 0.0001207226378028281\n",
      "Epoch 4473, Loss: 0.006002467041980708, Final Batch Loss: 0.005896363873034716\n",
      "Epoch 4474, Loss: 0.00045532231888500974, Final Batch Loss: 0.0002180146548198536\n",
      "Epoch 4475, Loss: 0.010899004046223126, Final Batch Loss: 0.00046103133354336023\n",
      "Epoch 4476, Loss: 0.0004275299361324869, Final Batch Loss: 0.00023043992405291647\n",
      "Epoch 4477, Loss: 0.001297342314501293, Final Batch Loss: 0.00011950301995966583\n",
      "Epoch 4478, Loss: 0.00039760473373462446, Final Batch Loss: 0.00012317074288148433\n",
      "Epoch 4479, Loss: 0.0002692480611585779, Final Batch Loss: 8.423494364251383e-06\n",
      "Epoch 4480, Loss: 0.00021030511925346218, Final Batch Loss: 4.9453508836450055e-05\n",
      "Epoch 4481, Loss: 0.00023968573259480763, Final Batch Loss: 1.8894594177254476e-05\n",
      "Epoch 4482, Loss: 6.578490865649655e-05, Final Batch Loss: 1.6532849258510396e-05\n",
      "Epoch 4483, Loss: 0.00038748906445107423, Final Batch Loss: 7.348701183218509e-05\n",
      "Epoch 4484, Loss: 0.0011101442487415625, Final Batch Loss: 1.620447619643528e-05\n",
      "Epoch 4485, Loss: 0.00510085545192851, Final Batch Loss: 1.3389938430918846e-05\n",
      "Epoch 4486, Loss: 0.001205357606522739, Final Batch Loss: 0.00014719337923452258\n",
      "Epoch 4487, Loss: 0.0011352907895343378, Final Batch Loss: 0.0010482260258868337\n",
      "Epoch 4488, Loss: 0.0003518469966365956, Final Batch Loss: 7.127129356376827e-05\n",
      "Epoch 4489, Loss: 0.00025254245338146575, Final Batch Loss: 1.921553848660551e-05\n",
      "Epoch 4490, Loss: 0.0010185495193582028, Final Batch Loss: 0.0002736049355007708\n",
      "Epoch 4491, Loss: 0.0004805048811249435, Final Batch Loss: 6.434669921873137e-05\n",
      "Epoch 4492, Loss: 0.00028616536292247474, Final Batch Loss: 2.4318074792972766e-05\n",
      "Epoch 4493, Loss: 0.0003485993584035896, Final Batch Loss: 4.0276288927998394e-05\n",
      "Epoch 4494, Loss: 0.0008250965911429375, Final Batch Loss: 0.00015377042291220278\n",
      "Epoch 4495, Loss: 0.0010876525702769868, Final Batch Loss: 0.00023692220565862954\n",
      "Epoch 4496, Loss: 0.0004759042885780218, Final Batch Loss: 6.568860953848343e-06\n",
      "Epoch 4497, Loss: 0.00012668015551753342, Final Batch Loss: 7.858670869609341e-05\n",
      "Epoch 4498, Loss: 0.0006728176376782358, Final Batch Loss: 1.5672179870307446e-05\n",
      "Epoch 4499, Loss: 0.000243332864556578, Final Batch Loss: 3.161698259646073e-05\n",
      "Epoch 4500, Loss: 0.001626905650482513, Final Batch Loss: 0.00013749786012340337\n",
      "Epoch 4501, Loss: 0.0007351185704465024, Final Batch Loss: 4.568791337078437e-05\n",
      "Epoch 4502, Loss: 0.004187803679087665, Final Batch Loss: 6.845566531410441e-05\n",
      "Epoch 4503, Loss: 0.0008866734788171016, Final Batch Loss: 8.104687003651634e-05\n",
      "Epoch 4504, Loss: 0.0012496183917392045, Final Batch Loss: 0.00014030374586582184\n",
      "Epoch 4505, Loss: 0.0036013084900332615, Final Batch Loss: 0.0017283330671489239\n",
      "Epoch 4506, Loss: 0.00019752672051254194, Final Batch Loss: 2.9282373361638747e-05\n",
      "Epoch 4507, Loss: 0.0005346812249626964, Final Batch Loss: 9.589691762812436e-05\n",
      "Epoch 4508, Loss: 0.00037529110340983607, Final Batch Loss: 2.4048928025877103e-05\n",
      "Epoch 4509, Loss: 0.00011252994772803504, Final Batch Loss: 1.4806377294007689e-05\n",
      "Epoch 4510, Loss: 0.00018300412648386555, Final Batch Loss: 1.4874724911351223e-05\n",
      "Epoch 4511, Loss: 0.000636884649793501, Final Batch Loss: 0.0002492989879101515\n",
      "Epoch 4512, Loss: 0.0004895597594440915, Final Batch Loss: 2.1297306375345215e-05\n",
      "Epoch 4513, Loss: 0.0014203439241100568, Final Batch Loss: 2.3649441573070362e-05\n",
      "Epoch 4514, Loss: 0.0006601961795240641, Final Batch Loss: 0.00019189695012755692\n",
      "Epoch 4515, Loss: 0.0005582763769780286, Final Batch Loss: 0.00016725037130527198\n",
      "Epoch 4516, Loss: 0.0012630869023269042, Final Batch Loss: 0.0009253646712750196\n",
      "Epoch 4517, Loss: 0.001566199538501678, Final Batch Loss: 0.0012306210119277239\n",
      "Epoch 4518, Loss: 0.00014423656784856576, Final Batch Loss: 2.8147874218120705e-06\n",
      "Epoch 4519, Loss: 0.0009773049750947393, Final Batch Loss: 0.0003576005401555449\n",
      "Epoch 4520, Loss: 0.0007051594520817162, Final Batch Loss: 1.0634693353495095e-05\n",
      "Epoch 4521, Loss: 0.010832610776560614, Final Batch Loss: 6.8320230639074e-05\n",
      "Epoch 4522, Loss: 3.957949229516089e-05, Final Batch Loss: 6.7857163230655715e-06\n",
      "Epoch 4523, Loss: 0.00022390504818758927, Final Batch Loss: 0.00010899656626861542\n",
      "Epoch 4524, Loss: 0.00016002743905119132, Final Batch Loss: 5.418746513896622e-05\n",
      "Epoch 4525, Loss: 0.0011982226133113727, Final Batch Loss: 0.00037713703932240605\n",
      "Epoch 4526, Loss: 0.00020147255418123677, Final Batch Loss: 0.00011193899263162166\n",
      "Epoch 4527, Loss: 0.00023641721054445952, Final Batch Loss: 8.516924572177231e-05\n",
      "Epoch 4528, Loss: 0.00029907199859735556, Final Batch Loss: 3.3674357837298885e-05\n",
      "Epoch 4529, Loss: 0.0011010416637873277, Final Batch Loss: 0.00022885118960402906\n",
      "Epoch 4530, Loss: 0.004474540054616227, Final Batch Loss: 2.9453733077389188e-05\n",
      "Epoch 4531, Loss: 0.0001158836021204479, Final Batch Loss: 6.498311267932877e-05\n",
      "Epoch 4532, Loss: 0.00039473932883993257, Final Batch Loss: 2.1195288354647346e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4533, Loss: 0.00022207465008250438, Final Batch Loss: 0.00010565969569142908\n",
      "Epoch 4534, Loss: 0.0007380193419521675, Final Batch Loss: 3.6708654079120606e-05\n",
      "Epoch 4535, Loss: 0.0004266225514584221, Final Batch Loss: 4.3440690205898136e-05\n",
      "Epoch 4536, Loss: 0.00031990319985197857, Final Batch Loss: 1.7906066204886883e-05\n",
      "Epoch 4537, Loss: 0.0009743516711750999, Final Batch Loss: 0.0007807968650013208\n",
      "Epoch 4538, Loss: 0.0004292314115446061, Final Batch Loss: 0.0002707074163481593\n",
      "Epoch 4539, Loss: 0.002564633196016075, Final Batch Loss: 0.0001405584189342335\n",
      "Epoch 4540, Loss: 0.00019903449992852984, Final Batch Loss: 9.660237083153334e-06\n",
      "Epoch 4541, Loss: 0.00010228564769931836, Final Batch Loss: 1.3521402252081316e-05\n",
      "Epoch 4542, Loss: 0.00012989104106964078, Final Batch Loss: 1.2911088560940698e-05\n",
      "Epoch 4543, Loss: 0.0004336184174462687, Final Batch Loss: 1.5605823136866093e-05\n",
      "Epoch 4544, Loss: 0.0002208787827839842, Final Batch Loss: 0.00014148687478154898\n",
      "Epoch 4545, Loss: 0.00040050061215879396, Final Batch Loss: 0.00018458608246874064\n",
      "Epoch 4546, Loss: 0.00029648519011971075, Final Batch Loss: 1.2359387255855836e-05\n",
      "Epoch 4547, Loss: 0.0009639505706218188, Final Batch Loss: 1.0166696483793203e-05\n",
      "Epoch 4548, Loss: 0.0003572473997337511, Final Batch Loss: 5.471997064887546e-05\n",
      "Epoch 4549, Loss: 0.0002739137526077684, Final Batch Loss: 3.667477358249016e-05\n",
      "Epoch 4550, Loss: 0.0003014216708834283, Final Batch Loss: 0.00010823823686223477\n",
      "Epoch 4551, Loss: 0.0005796161931357346, Final Batch Loss: 2.9834125598426908e-05\n",
      "Epoch 4552, Loss: 0.0007343616816797294, Final Batch Loss: 0.0005248388624750078\n",
      "Epoch 4553, Loss: 0.0006023897312843474, Final Batch Loss: 3.0451208658632822e-05\n",
      "Epoch 4554, Loss: 0.0008777371840551496, Final Batch Loss: 0.0008055108482949436\n",
      "Epoch 4555, Loss: 8.378844540857244e-05, Final Batch Loss: 1.051504114002455e-05\n",
      "Epoch 4556, Loss: 0.00019590471856645308, Final Batch Loss: 4.672300201491453e-05\n",
      "Epoch 4557, Loss: 0.00011265312309660658, Final Batch Loss: 2.6099903607246233e-06\n",
      "Epoch 4558, Loss: 0.0006052098215150181, Final Batch Loss: 2.3551021513412707e-05\n",
      "Epoch 4559, Loss: 0.002366747310588835, Final Batch Loss: 3.442722299951129e-05\n",
      "Epoch 4560, Loss: 8.820766151984571e-05, Final Batch Loss: 4.571007139020367e-06\n",
      "Epoch 4561, Loss: 0.0009347375889774412, Final Batch Loss: 4.697171243606135e-05\n",
      "Epoch 4562, Loss: 0.0002691118043003371, Final Batch Loss: 1.7241507521248423e-05\n",
      "Epoch 4563, Loss: 0.002082318373140879, Final Batch Loss: 0.00012627367686945945\n",
      "Epoch 4564, Loss: 0.00020266401406843215, Final Batch Loss: 0.00013436003064271063\n",
      "Epoch 4565, Loss: 0.002020293570240028, Final Batch Loss: 0.0002053326606983319\n",
      "Epoch 4566, Loss: 0.01371164128795499, Final Batch Loss: 0.0001119748703786172\n",
      "Epoch 4567, Loss: 0.018491712224204093, Final Batch Loss: 0.0031915633007884026\n",
      "Epoch 4568, Loss: 0.007324097874516156, Final Batch Loss: 4.117011121707037e-05\n",
      "Epoch 4569, Loss: 0.010569346421107184, Final Batch Loss: 0.000263961439486593\n",
      "Epoch 4570, Loss: 0.00027050978678744286, Final Batch Loss: 1.9030339899472892e-05\n",
      "Epoch 4571, Loss: 0.0035443653559923405, Final Batch Loss: 7.363452823483385e-06\n",
      "Epoch 4572, Loss: 0.0013195645151427016, Final Batch Loss: 0.0008315977174788713\n",
      "Epoch 4573, Loss: 0.002308182134584058, Final Batch Loss: 4.254376835888252e-05\n",
      "Epoch 4574, Loss: 0.0007069295315886848, Final Batch Loss: 6.360498809954152e-05\n",
      "Epoch 4575, Loss: 0.011183233684278093, Final Batch Loss: 0.00011955876834690571\n",
      "Epoch 4576, Loss: 0.00036954308598069474, Final Batch Loss: 8.932337368605658e-05\n",
      "Epoch 4577, Loss: 0.0005926249650656246, Final Batch Loss: 7.310529326787218e-05\n",
      "Epoch 4578, Loss: 0.0018398345091554802, Final Batch Loss: 3.5433648008620366e-05\n",
      "Epoch 4579, Loss: 0.0014441251987591386, Final Batch Loss: 8.000805974006653e-05\n",
      "Epoch 4580, Loss: 0.0018042713018076029, Final Batch Loss: 0.0005723254871554673\n",
      "Epoch 4581, Loss: 0.000256789846389438, Final Batch Loss: 8.044777496252209e-05\n",
      "Epoch 4582, Loss: 0.0048769227250886615, Final Batch Loss: 5.965076343272813e-05\n",
      "Epoch 4583, Loss: 0.00015019836610008497, Final Batch Loss: 7.5745556387119e-05\n",
      "Epoch 4584, Loss: 0.0005938818430877291, Final Batch Loss: 0.0004925850662402809\n",
      "Epoch 4585, Loss: 0.0001783003426680807, Final Batch Loss: 4.747735147248022e-05\n",
      "Epoch 4586, Loss: 0.00022425925271818414, Final Batch Loss: 6.354660581564531e-05\n",
      "Epoch 4587, Loss: 0.002187894648159272, Final Batch Loss: 0.00017814329476095736\n",
      "Epoch 4588, Loss: 0.0026502195396460593, Final Batch Loss: 0.0011600001016631722\n",
      "Epoch 4589, Loss: 0.00027169068926014006, Final Batch Loss: 0.00016265982412733138\n",
      "Epoch 4590, Loss: 0.00036695993912871927, Final Batch Loss: 0.00014888227451592684\n",
      "Epoch 4591, Loss: 0.00010214763460680842, Final Batch Loss: 4.3988296965835616e-05\n",
      "Epoch 4592, Loss: 0.00032905658372328617, Final Batch Loss: 0.00020750286057591438\n",
      "Epoch 4593, Loss: 6.701416805299232e-05, Final Batch Loss: 1.2604096809809562e-05\n",
      "Epoch 4594, Loss: 0.001394227336277254, Final Batch Loss: 0.0012699400540441275\n",
      "Epoch 4595, Loss: 0.0007731224759481847, Final Batch Loss: 0.0001568295556353405\n",
      "Epoch 4596, Loss: 0.00032871785879251547, Final Batch Loss: 0.00020048281294293702\n",
      "Epoch 4597, Loss: 0.0017247736013814574, Final Batch Loss: 0.0009211193537339568\n",
      "Epoch 4598, Loss: 0.012965641044502263, Final Batch Loss: 1.64012690220261e-05\n",
      "Epoch 4599, Loss: 0.00028350217417028034, Final Batch Loss: 6.52024846203858e-06\n",
      "Epoch 4600, Loss: 0.0022548075430677272, Final Batch Loss: 0.001958827953785658\n",
      "Epoch 4601, Loss: 0.00010383680637460202, Final Batch Loss: 2.758760456345044e-05\n",
      "Epoch 4602, Loss: 0.0001818303790059872, Final Batch Loss: 9.79755786829628e-05\n",
      "Epoch 4603, Loss: 0.0008721513113414403, Final Batch Loss: 4.718239142675884e-05\n",
      "Epoch 4604, Loss: 0.000303605425870046, Final Batch Loss: 0.00013055432646069676\n",
      "Epoch 4605, Loss: 0.0039339708018815145, Final Batch Loss: 0.0037560006603598595\n",
      "Epoch 4606, Loss: 0.0006073712975194212, Final Batch Loss: 1.7166012185043655e-05\n",
      "Epoch 4607, Loss: 0.00039244317304110155, Final Batch Loss: 0.00020575305097736418\n",
      "Epoch 4608, Loss: 0.002486993580532726, Final Batch Loss: 1.94214480870869e-05\n",
      "Epoch 4609, Loss: 0.0014641165762441233, Final Batch Loss: 0.0009440575377084315\n",
      "Epoch 4610, Loss: 0.0011649773955468845, Final Batch Loss: 4.260408331901999e-06\n",
      "Epoch 4611, Loss: 0.0006634901792494929, Final Batch Loss: 5.643668373522814e-06\n",
      "Epoch 4612, Loss: 0.00013866712106391788, Final Batch Loss: 3.138410465908237e-05\n",
      "Epoch 4613, Loss: 0.00042855861101998016, Final Batch Loss: 4.7041248762980103e-05\n",
      "Epoch 4614, Loss: 0.0010828455433511408, Final Batch Loss: 1.6445404980913736e-05\n",
      "Epoch 4615, Loss: 0.000173969518073136, Final Batch Loss: 0.0001069241261575371\n",
      "Epoch 4616, Loss: 0.00019629843518487178, Final Batch Loss: 3.876947084791027e-05\n",
      "Epoch 4617, Loss: 0.000617856716417009, Final Batch Loss: 5.723231879528612e-05\n",
      "Epoch 4618, Loss: 0.004393939236251754, Final Batch Loss: 0.002736882772296667\n",
      "Epoch 4619, Loss: 0.00040005625851335935, Final Batch Loss: 0.0002483772113919258\n",
      "Epoch 4620, Loss: 0.00021348031077650376, Final Batch Loss: 8.540113049093634e-05\n",
      "Epoch 4621, Loss: 0.00016111862146317435, Final Batch Loss: 3.701092055052868e-06\n",
      "Epoch 4622, Loss: 0.00012709932161669713, Final Batch Loss: 8.100600825855508e-05\n",
      "Epoch 4623, Loss: 9.881921596388565e-05, Final Batch Loss: 1.2648867595999036e-05\n",
      "Epoch 4624, Loss: 0.0007343296492763329, Final Batch Loss: 7.181164983194321e-05\n",
      "Epoch 4625, Loss: 0.00045664193748962134, Final Batch Loss: 0.0001267212355742231\n",
      "Epoch 4626, Loss: 0.0009097220045077847, Final Batch Loss: 2.11359110835474e-05\n",
      "Epoch 4627, Loss: 0.00026224494285997935, Final Batch Loss: 8.007822907529771e-05\n",
      "Epoch 4628, Loss: 0.0003688717793011165, Final Batch Loss: 6.672484687442193e-06\n",
      "Epoch 4629, Loss: 0.0003043157485080883, Final Batch Loss: 0.00010526520054554567\n",
      "Epoch 4630, Loss: 0.004732568599138176, Final Batch Loss: 0.003825751831755042\n",
      "Epoch 4631, Loss: 0.0007747819108772092, Final Batch Loss: 9.783682617126033e-05\n",
      "Epoch 4632, Loss: 0.0009408008636455634, Final Batch Loss: 0.0008794539025984704\n",
      "Epoch 4633, Loss: 0.0022305605380097404, Final Batch Loss: 8.1235273682978e-05\n",
      "Epoch 4634, Loss: 0.0003001568420586409, Final Batch Loss: 7.401415496133268e-05\n",
      "Epoch 4635, Loss: 0.0011056793009629473, Final Batch Loss: 0.00014561500574927777\n",
      "Epoch 4636, Loss: 0.0016257388160738628, Final Batch Loss: 1.2778084055753425e-05\n",
      "Epoch 4637, Loss: 0.0003088762232437148, Final Batch Loss: 0.0002445510181132704\n",
      "Epoch 4638, Loss: 0.0015838256331335288, Final Batch Loss: 3.5100511013297364e-05\n",
      "Epoch 4639, Loss: 7.531465416832361e-05, Final Batch Loss: 2.3246469936566427e-05\n",
      "Epoch 4640, Loss: 0.00012309758494666312, Final Batch Loss: 2.8347878469503485e-05\n",
      "Epoch 4641, Loss: 0.0018070971527777147, Final Batch Loss: 2.4957449568319134e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4642, Loss: 0.00023696569587627891, Final Batch Loss: 2.880813008232508e-05\n",
      "Epoch 4643, Loss: 0.0034969841926795198, Final Batch Loss: 2.5597631974960677e-05\n",
      "Epoch 4644, Loss: 0.00035782952545559965, Final Batch Loss: 9.796478843782097e-05\n",
      "Epoch 4645, Loss: 0.00023320420223171823, Final Batch Loss: 3.57900389644783e-05\n",
      "Epoch 4646, Loss: 0.00010815308905876009, Final Batch Loss: 4.80656890431419e-05\n",
      "Epoch 4647, Loss: 0.00012210959721414838, Final Batch Loss: 1.1572201401577331e-05\n",
      "Epoch 4648, Loss: 0.0003988535281678196, Final Batch Loss: 5.122009679325856e-05\n",
      "Epoch 4649, Loss: 0.00042849469537031837, Final Batch Loss: 4.04546590289101e-05\n",
      "Epoch 4650, Loss: 0.0011787027106038295, Final Batch Loss: 5.2784096624236554e-05\n",
      "Epoch 4651, Loss: 0.007796736008458538, Final Batch Loss: 2.3844866518629715e-05\n",
      "Epoch 4652, Loss: 0.0014070724428165704, Final Batch Loss: 0.0007505555404350162\n",
      "Epoch 4653, Loss: 0.00020239160176060977, Final Batch Loss: 0.00011282923514954746\n",
      "Epoch 4654, Loss: 0.00048492271889699623, Final Batch Loss: 0.00012399922707118094\n",
      "Epoch 4655, Loss: 0.0007813964912202209, Final Batch Loss: 0.00014000920054968446\n",
      "Epoch 4656, Loss: 0.008013234259124147, Final Batch Loss: 0.00045956613030284643\n",
      "Epoch 4657, Loss: 0.002530612055124948, Final Batch Loss: 4.02957339247223e-05\n",
      "Epoch 4658, Loss: 0.002264946302602766, Final Batch Loss: 5.603284080279991e-06\n",
      "Epoch 4659, Loss: 0.00014704516979691107, Final Batch Loss: 7.987683784449473e-05\n",
      "Epoch 4660, Loss: 0.0058545878723634814, Final Batch Loss: 5.705357125407318e-06\n",
      "Epoch 4661, Loss: 0.0011219689331483096, Final Batch Loss: 0.0009621945209801197\n",
      "Epoch 4662, Loss: 0.003097707322012866, Final Batch Loss: 3.001755067089107e-05\n",
      "Epoch 4663, Loss: 6.869368189654779e-05, Final Batch Loss: 2.9811204512952827e-05\n",
      "Epoch 4664, Loss: 0.00013529753414331935, Final Batch Loss: 2.481750925653614e-05\n",
      "Epoch 4665, Loss: 0.0003226698245271109, Final Batch Loss: 0.00011796201579272747\n",
      "Epoch 4666, Loss: 0.002588245115475729, Final Batch Loss: 0.0001146770955529064\n",
      "Epoch 4667, Loss: 0.0010611066791170742, Final Batch Loss: 1.9260736735304818e-05\n",
      "Epoch 4668, Loss: 0.0007872334381318069, Final Batch Loss: 9.95511709334096e-06\n",
      "Epoch 4669, Loss: 6.985909476497909e-05, Final Batch Loss: 1.0016444321081508e-05\n",
      "Epoch 4670, Loss: 0.00022125684517959598, Final Batch Loss: 0.00014812838344369084\n",
      "Epoch 4671, Loss: 4.646162869903492e-05, Final Batch Loss: 6.768999810446985e-06\n",
      "Epoch 4672, Loss: 0.00022657482986687683, Final Batch Loss: 9.844585292739794e-05\n",
      "Epoch 4673, Loss: 0.00015069550863699988, Final Batch Loss: 1.8878337868954986e-05\n",
      "Epoch 4674, Loss: 0.0003666594584501581, Final Batch Loss: 0.0003011277294717729\n",
      "Epoch 4675, Loss: 9.414968189958017e-05, Final Batch Loss: 1.5455307220690884e-05\n",
      "Epoch 4676, Loss: 0.02698011509346543, Final Batch Loss: 4.6789326006546617e-05\n",
      "Epoch 4677, Loss: 0.00015638671902706847, Final Batch Loss: 3.738418308785185e-05\n",
      "Epoch 4678, Loss: 0.0012059141445206478, Final Batch Loss: 0.00024071270308922976\n",
      "Epoch 4679, Loss: 0.0001520456535217818, Final Batch Loss: 1.1112275387858972e-05\n",
      "Epoch 4680, Loss: 0.0001678793632891029, Final Batch Loss: 2.357360062887892e-05\n",
      "Epoch 4681, Loss: 0.025220299256034195, Final Batch Loss: 4.196318332105875e-05\n",
      "Epoch 4682, Loss: 0.009479244596150238, Final Batch Loss: 1.7914229829329997e-05\n",
      "Epoch 4683, Loss: 0.00019565909678931348, Final Batch Loss: 7.71768536651507e-05\n",
      "Epoch 4684, Loss: 0.0005110688580316491, Final Batch Loss: 0.0003363541036378592\n",
      "Epoch 4685, Loss: 0.0005009525921195745, Final Batch Loss: 0.00010556230699876323\n",
      "Epoch 4686, Loss: 0.00019475005683489144, Final Batch Loss: 0.00010019591718446463\n",
      "Epoch 4687, Loss: 0.0007938919443404302, Final Batch Loss: 0.00014236684364732355\n",
      "Epoch 4688, Loss: 0.0005226165267231409, Final Batch Loss: 4.417699892655946e-05\n",
      "Epoch 4689, Loss: 0.00025012682363012573, Final Batch Loss: 1.1101094969490077e-05\n",
      "Epoch 4690, Loss: 0.0006746315411874093, Final Batch Loss: 7.503401866415516e-05\n",
      "Epoch 4691, Loss: 0.00032073079091787804, Final Batch Loss: 0.0002719179028645158\n",
      "Epoch 4692, Loss: 0.005505349223312805, Final Batch Loss: 0.00026398804038763046\n",
      "Epoch 4693, Loss: 0.0008781255728536053, Final Batch Loss: 1.6462965504615568e-05\n",
      "Epoch 4694, Loss: 0.00010984344044118188, Final Batch Loss: 1.1908432497875765e-05\n",
      "Epoch 4695, Loss: 0.0006715100244036876, Final Batch Loss: 8.082878775894642e-05\n",
      "Epoch 4696, Loss: 0.00029022050330240745, Final Batch Loss: 0.00014123672735877335\n",
      "Epoch 4697, Loss: 0.003666640532173915, Final Batch Loss: 8.020712994039059e-05\n",
      "Epoch 4698, Loss: 0.0006524620512209367, Final Batch Loss: 1.8292539607500657e-05\n",
      "Epoch 4699, Loss: 0.0007594404560222756, Final Batch Loss: 0.0006216426845639944\n",
      "Epoch 4700, Loss: 0.0002217508663306944, Final Batch Loss: 6.442799349315464e-05\n",
      "Epoch 4701, Loss: 0.00020677131578850094, Final Batch Loss: 6.892417877679691e-05\n",
      "Epoch 4702, Loss: 0.0001503224211774068, Final Batch Loss: 1.767644971550908e-05\n",
      "Epoch 4703, Loss: 0.00013224888607510366, Final Batch Loss: 5.81386593694333e-05\n",
      "Epoch 4704, Loss: 6.129237272034516e-05, Final Batch Loss: 7.510231171181658e-06\n",
      "Epoch 4705, Loss: 0.019140626031003194, Final Batch Loss: 0.0020887190476059914\n",
      "Epoch 4706, Loss: 0.015532501764027984, Final Batch Loss: 0.00010853139247046784\n",
      "Epoch 4707, Loss: 0.0018794554453052115, Final Batch Loss: 4.001244451501407e-05\n",
      "Epoch 4708, Loss: 0.00035832954381476156, Final Batch Loss: 4.308440475142561e-05\n",
      "Epoch 4709, Loss: 0.00011292500403214945, Final Batch Loss: 7.448397809639573e-05\n",
      "Epoch 4710, Loss: 0.026637563612894155, Final Batch Loss: 3.99202253902331e-05\n",
      "Epoch 4711, Loss: 0.0017595861918380251, Final Batch Loss: 1.5616073142155074e-05\n",
      "Epoch 4712, Loss: 0.00029946366703370586, Final Batch Loss: 2.0689869415946305e-05\n",
      "Epoch 4713, Loss: 0.016669437631207984, Final Batch Loss: 3.636354085756466e-05\n",
      "Epoch 4714, Loss: 0.006109542795456946, Final Batch Loss: 0.004829903598874807\n",
      "Epoch 4715, Loss: 0.002458571645547636, Final Batch Loss: 9.766775474417955e-05\n",
      "Epoch 4716, Loss: 0.000812987056633574, Final Batch Loss: 2.4317496354342438e-05\n",
      "Epoch 4717, Loss: 0.00046140955964801833, Final Batch Loss: 0.00029800974880345166\n",
      "Epoch 4718, Loss: 0.0013472425162035506, Final Batch Loss: 1.7945136278285645e-05\n",
      "Epoch 4719, Loss: 0.00017210154328495264, Final Batch Loss: 7.990304584382102e-05\n",
      "Epoch 4720, Loss: 0.003090199166763341, Final Batch Loss: 0.001374244224280119\n",
      "Epoch 4721, Loss: 0.0007957046473165974, Final Batch Loss: 0.00012811311171390116\n",
      "Epoch 4722, Loss: 0.0007248693509609438, Final Batch Loss: 0.0005869503365829587\n",
      "Epoch 4723, Loss: 0.011105072047939757, Final Batch Loss: 6.352268974296749e-05\n",
      "Epoch 4724, Loss: 0.0003670787009468768, Final Batch Loss: 6.77771822665818e-05\n",
      "Epoch 4725, Loss: 0.000202205112145748, Final Batch Loss: 7.117344648577273e-05\n",
      "Epoch 4726, Loss: 0.0005051772386650555, Final Batch Loss: 0.0002031332260230556\n",
      "Epoch 4727, Loss: 0.002936245068667631, Final Batch Loss: 0.002786839148029685\n",
      "Epoch 4728, Loss: 0.0025260381189582404, Final Batch Loss: 1.5208042896119878e-05\n",
      "Epoch 4729, Loss: 0.0010747624128271127, Final Batch Loss: 2.708294960029889e-05\n",
      "Epoch 4730, Loss: 0.00039536076656077057, Final Batch Loss: 0.0001818983000703156\n",
      "Epoch 4731, Loss: 0.0011900414829142392, Final Batch Loss: 0.00022781791631132364\n",
      "Epoch 4732, Loss: 0.0004980294233973837, Final Batch Loss: 7.546514098066837e-05\n",
      "Epoch 4733, Loss: 6.459664336944115e-05, Final Batch Loss: 5.420805337053025e-06\n",
      "Epoch 4734, Loss: 0.00018869499035645276, Final Batch Loss: 0.00010376374120824039\n",
      "Epoch 4735, Loss: 0.00019583548782975413, Final Batch Loss: 6.737466173944995e-05\n",
      "Epoch 4736, Loss: 0.0001606143887329381, Final Batch Loss: 9.588259126758203e-05\n",
      "Epoch 4737, Loss: 0.0008582585187468794, Final Batch Loss: 1.4577829460904468e-05\n",
      "Epoch 4738, Loss: 0.00023653840980841778, Final Batch Loss: 4.722278754343279e-05\n",
      "Epoch 4739, Loss: 0.00020101481459278148, Final Batch Loss: 7.969878424773924e-06\n",
      "Epoch 4740, Loss: 0.0007126064519979991, Final Batch Loss: 2.1566651412285864e-05\n",
      "Epoch 4741, Loss: 0.00023776480884407647, Final Batch Loss: 0.00015085714403539896\n",
      "Epoch 4742, Loss: 0.002480303119227756, Final Batch Loss: 9.09626905922778e-05\n",
      "Epoch 4743, Loss: 0.0005496890862559667, Final Batch Loss: 1.0697933248593472e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4744, Loss: 0.00043045712300227024, Final Batch Loss: 4.57569258287549e-05\n",
      "Epoch 4745, Loss: 0.023404930798278656, Final Batch Loss: 5.3671210480388254e-05\n",
      "Epoch 4746, Loss: 0.008756675277254544, Final Batch Loss: 6.188363477122039e-05\n",
      "Epoch 4747, Loss: 0.006645425237365998, Final Batch Loss: 0.00020253362890798599\n",
      "Epoch 4748, Loss: 0.0009662016746005975, Final Batch Loss: 0.0006979848258197308\n",
      "Epoch 4749, Loss: 0.003743929155461956, Final Batch Loss: 0.0030883417930454016\n",
      "Epoch 4750, Loss: 0.0033366773241141345, Final Batch Loss: 0.002771733794361353\n",
      "Epoch 4751, Loss: 0.000299456313769042, Final Batch Loss: 1.1256054676778149e-05\n",
      "Epoch 4752, Loss: 0.01601397826016182, Final Batch Loss: 0.00011944053403567523\n",
      "Epoch 4753, Loss: 0.00037432750468724407, Final Batch Loss: 8.266131044365466e-05\n",
      "Epoch 4754, Loss: 0.002611540963698644, Final Batch Loss: 8.61323278513737e-05\n",
      "Epoch 4755, Loss: 0.002502877761799027, Final Batch Loss: 1.625580080144573e-05\n",
      "Epoch 4756, Loss: 0.0002347759364056401, Final Batch Loss: 9.55469804466702e-05\n",
      "Epoch 4757, Loss: 0.0012353115598671138, Final Batch Loss: 0.00019392248941585422\n",
      "Epoch 4758, Loss: 0.000988919913652353, Final Batch Loss: 0.0007114802137948573\n",
      "Epoch 4759, Loss: 0.001350660950265592, Final Batch Loss: 2.5062992790481076e-05\n",
      "Epoch 4760, Loss: 0.0021720206023019273, Final Batch Loss: 0.001277815899811685\n",
      "Epoch 4761, Loss: 0.001207787157909479, Final Batch Loss: 0.0001164867207990028\n",
      "Epoch 4762, Loss: 0.00016544594564038562, Final Batch Loss: 4.175054527877364e-06\n",
      "Epoch 4763, Loss: 0.006995014919084497, Final Batch Loss: 0.0055583566427230835\n",
      "Epoch 4764, Loss: 0.0013112652668496594, Final Batch Loss: 0.0011248283553868532\n",
      "Epoch 4765, Loss: 0.00014850810657662805, Final Batch Loss: 2.67936284217285e-05\n",
      "Epoch 4766, Loss: 0.0013866896333638579, Final Batch Loss: 0.0012962031178176403\n",
      "Epoch 4767, Loss: 0.0001292516681132838, Final Batch Loss: 8.81779269548133e-05\n",
      "Epoch 4768, Loss: 0.0002991229048348032, Final Batch Loss: 0.00014397251652553678\n",
      "Epoch 4769, Loss: 0.0019253463706263574, Final Batch Loss: 2.9641429136972874e-05\n",
      "Epoch 4770, Loss: 0.0024072677042568102, Final Batch Loss: 0.0017541212728247046\n",
      "Epoch 4771, Loss: 0.0017533190439280588, Final Batch Loss: 3.840924546238966e-05\n",
      "Epoch 4772, Loss: 0.00022020124742994085, Final Batch Loss: 3.8173333450686187e-05\n",
      "Epoch 4773, Loss: 0.011023968340396095, Final Batch Loss: 8.283358329208568e-05\n",
      "Epoch 4774, Loss: 0.0009755275204952341, Final Batch Loss: 1.021600837702863e-05\n",
      "Epoch 4775, Loss: 8.961085586633999e-05, Final Batch Loss: 9.205014066537842e-06\n",
      "Epoch 4776, Loss: 0.0008730626368560479, Final Batch Loss: 4.320035259297583e-06\n",
      "Epoch 4777, Loss: 0.0005036718030169141, Final Batch Loss: 0.00010318979184376076\n",
      "Epoch 4778, Loss: 0.0015932915011944715, Final Batch Loss: 1.0167994332732633e-05\n",
      "Epoch 4779, Loss: 0.000252497631663573, Final Batch Loss: 4.391935362946242e-05\n",
      "Epoch 4780, Loss: 0.00012140240505686961, Final Batch Loss: 2.699472679523751e-05\n",
      "Epoch 4781, Loss: 0.0009992357445298694, Final Batch Loss: 1.2605589290615171e-05\n",
      "Epoch 4782, Loss: 0.0008387186971958727, Final Batch Loss: 2.4287332053063437e-05\n",
      "Epoch 4783, Loss: 0.006228895661479328, Final Batch Loss: 6.515047425637022e-05\n",
      "Epoch 4784, Loss: 0.001367955617752159, Final Batch Loss: 0.0012274935143068433\n",
      "Epoch 4785, Loss: 0.0005773406846856233, Final Batch Loss: 0.00017095715156756341\n",
      "Epoch 4786, Loss: 0.0013272833748487756, Final Batch Loss: 0.0006007439806126058\n",
      "Epoch 4787, Loss: 0.00019911893832613714, Final Batch Loss: 6.037316416040994e-05\n",
      "Epoch 4788, Loss: 0.00040433793037664145, Final Batch Loss: 0.0001104749389924109\n",
      "Epoch 4789, Loss: 0.008416400247369893, Final Batch Loss: 0.007135926745831966\n",
      "Epoch 4790, Loss: 0.0012496828130679205, Final Batch Loss: 0.00010743002349045128\n",
      "Epoch 4791, Loss: 0.00022680188885715324, Final Batch Loss: 1.329500628344249e-05\n",
      "Epoch 4792, Loss: 0.0005384352880355436, Final Batch Loss: 1.91858816833701e-05\n",
      "Epoch 4793, Loss: 0.0007932372391223907, Final Batch Loss: 0.00030515718390233815\n",
      "Epoch 4794, Loss: 0.0001891234060167335, Final Batch Loss: 3.007611485372763e-05\n",
      "Epoch 4795, Loss: 4.68365142296534e-05, Final Batch Loss: 8.12247071735328e-06\n",
      "Epoch 4796, Loss: 0.0009117618810705608, Final Batch Loss: 0.0008117224206216633\n",
      "Epoch 4797, Loss: 0.00014900012320140377, Final Batch Loss: 4.425123188411817e-05\n",
      "Epoch 4798, Loss: 0.00011322912496325443, Final Batch Loss: 1.3388353181653656e-05\n",
      "Epoch 4799, Loss: 8.980280108517036e-05, Final Batch Loss: 2.1733705580118112e-05\n",
      "Epoch 4800, Loss: 0.0003866838160320185, Final Batch Loss: 7.484447996830568e-05\n",
      "Epoch 4801, Loss: 0.0003051136172871338, Final Batch Loss: 2.1223446310614236e-05\n",
      "Epoch 4802, Loss: 0.001062636465576361, Final Batch Loss: 1.9157230781274848e-05\n",
      "Epoch 4803, Loss: 9.646714170230553e-05, Final Batch Loss: 2.381799822614994e-05\n",
      "Epoch 4804, Loss: 0.00014069658209336922, Final Batch Loss: 2.572217636043206e-05\n",
      "Epoch 4805, Loss: 0.0003682695205498021, Final Batch Loss: 4.246378011885099e-05\n",
      "Epoch 4806, Loss: 0.0001555784674565075, Final Batch Loss: 1.623871867195703e-05\n",
      "Epoch 4807, Loss: 0.00017497538101451937, Final Batch Loss: 1.608530328667257e-05\n",
      "Epoch 4808, Loss: 5.4426117458206136e-05, Final Batch Loss: 2.1254163584671915e-05\n",
      "Epoch 4809, Loss: 0.00013877807396056596, Final Batch Loss: 1.002271892502904e-05\n",
      "Epoch 4810, Loss: 0.00013937321102730493, Final Batch Loss: 1.091135459319048e-06\n",
      "Epoch 4811, Loss: 0.00012931919263792224, Final Batch Loss: 4.5651420805370435e-05\n",
      "Epoch 4812, Loss: 5.399696328822756e-05, Final Batch Loss: 1.4458712939813267e-05\n",
      "Epoch 4813, Loss: 8.224540579249151e-05, Final Batch Loss: 1.5500290828640573e-05\n",
      "Epoch 4814, Loss: 0.002406538357718091, Final Batch Loss: 4.8834339395398274e-05\n",
      "Epoch 4815, Loss: 0.0001663051739342336, Final Batch Loss: 5.7946604101744015e-06\n",
      "Epoch 4816, Loss: 0.0011808485196524998, Final Batch Loss: 0.0006625917158089578\n",
      "Epoch 4817, Loss: 0.00029625337083416525, Final Batch Loss: 0.00024147119256667793\n",
      "Epoch 4818, Loss: 0.00014420708976103924, Final Batch Loss: 3.266996645834297e-05\n",
      "Epoch 4819, Loss: 0.001405275064826128, Final Batch Loss: 0.00037020654417574406\n",
      "Epoch 4820, Loss: 3.6259756143408595e-05, Final Batch Loss: 4.878242634731578e-06\n",
      "Epoch 4821, Loss: 0.028901245392262354, Final Batch Loss: 0.028809260576963425\n",
      "Epoch 4822, Loss: 0.00029614029699587263, Final Batch Loss: 7.652270869584754e-05\n",
      "Epoch 4823, Loss: 0.0007039512329356512, Final Batch Loss: 6.356616722769104e-06\n",
      "Epoch 4824, Loss: 0.0020920192000630777, Final Batch Loss: 3.976808875449933e-05\n",
      "Epoch 4825, Loss: 0.0064272714662365615, Final Batch Loss: 0.0061866226606070995\n",
      "Epoch 4826, Loss: 0.0031635710984119214, Final Batch Loss: 2.821330417646095e-05\n",
      "Epoch 4827, Loss: 0.0008490678883390501, Final Batch Loss: 0.0001900534116430208\n",
      "Epoch 4828, Loss: 0.0007570659454358974, Final Batch Loss: 0.0006638179183937609\n",
      "Epoch 4829, Loss: 0.0001480949140386656, Final Batch Loss: 3.784377622650936e-05\n",
      "Epoch 4830, Loss: 0.0010773347530630417, Final Batch Loss: 4.009539770777337e-05\n",
      "Epoch 4831, Loss: 0.0008566316100768745, Final Batch Loss: 0.00011104508303105831\n",
      "Epoch 4832, Loss: 0.0010201487348240335, Final Batch Loss: 3.741166801773943e-05\n",
      "Epoch 4833, Loss: 0.009319701144704595, Final Batch Loss: 0.008956572972238064\n",
      "Epoch 4834, Loss: 0.002829515182384057, Final Batch Loss: 0.0006771120242774487\n",
      "Epoch 4835, Loss: 0.003110049914539559, Final Batch Loss: 0.0029181598220020533\n",
      "Epoch 4836, Loss: 0.00801419111667201, Final Batch Loss: 0.00013897576718591154\n",
      "Epoch 4837, Loss: 0.04307067205081694, Final Batch Loss: 0.00044891887228004634\n",
      "Epoch 4838, Loss: 0.0004941679071635008, Final Batch Loss: 6.287785799941048e-05\n",
      "Epoch 4839, Loss: 9.160009176412132e-05, Final Batch Loss: 2.8299087716732174e-05\n",
      "Epoch 4840, Loss: 0.0015312844298023265, Final Batch Loss: 6.087981091695838e-05\n",
      "Epoch 4841, Loss: 0.00020899375522276387, Final Batch Loss: 3.3997202990576625e-05\n",
      "Epoch 4842, Loss: 0.009157572963886196, Final Batch Loss: 5.66834096389357e-05\n",
      "Epoch 4843, Loss: 0.006655090550339082, Final Batch Loss: 3.491720781312324e-05\n",
      "Epoch 4844, Loss: 0.0028516258898889646, Final Batch Loss: 0.0026838413905352354\n",
      "Epoch 4845, Loss: 0.005942451713053742, Final Batch Loss: 1.3859189493814483e-05\n",
      "Epoch 4846, Loss: 0.0006770094478270039, Final Batch Loss: 0.00021113608090672642\n",
      "Epoch 4847, Loss: 0.0018577492501208326, Final Batch Loss: 2.0710502212750725e-05\n",
      "Epoch 4848, Loss: 0.07127566863709944, Final Batch Loss: 0.07108750939369202\n",
      "Epoch 4849, Loss: 0.005049852598858706, Final Batch Loss: 1.0572551218501758e-05\n",
      "Epoch 4850, Loss: 0.003024786739842966, Final Batch Loss: 0.0007359454757533967\n",
      "Epoch 4851, Loss: 0.000501350066770101, Final Batch Loss: 7.330486550927162e-05\n",
      "Epoch 4852, Loss: 0.00024487141126883216, Final Batch Loss: 2.0884584955638275e-05\n",
      "Epoch 4853, Loss: 0.0002124866186932195, Final Batch Loss: 4.3354881199775264e-05\n",
      "Epoch 4854, Loss: 0.0012132426345488057, Final Batch Loss: 0.0006134939612820745\n",
      "Epoch 4855, Loss: 0.003168346550410206, Final Batch Loss: 8.582065675000194e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4856, Loss: 0.0015400590928038582, Final Batch Loss: 5.422158574219793e-05\n",
      "Epoch 4857, Loss: 0.0025757667717698496, Final Batch Loss: 3.544432547641918e-05\n",
      "Epoch 4858, Loss: 0.0005081676268900992, Final Batch Loss: 1.7727276144796633e-06\n",
      "Epoch 4859, Loss: 0.0008765353450144175, Final Batch Loss: 5.552734000957571e-05\n",
      "Epoch 4860, Loss: 0.012802461102637608, Final Batch Loss: 6.158063570183003e-06\n",
      "Epoch 4861, Loss: 0.0003038084651052486, Final Batch Loss: 7.540686056017876e-05\n",
      "Epoch 4862, Loss: 0.0003865583385049831, Final Batch Loss: 0.0001513498864369467\n",
      "Epoch 4863, Loss: 0.005661087574480916, Final Batch Loss: 0.005254814401268959\n",
      "Epoch 4864, Loss: 0.0007890068518463522, Final Batch Loss: 3.524182830005884e-06\n",
      "Epoch 4865, Loss: 9.223125925927889e-05, Final Batch Loss: 1.4956456652726047e-05\n",
      "Epoch 4866, Loss: 0.00012334419625403825, Final Batch Loss: 3.430384094826877e-05\n",
      "Epoch 4867, Loss: 5.574834767685388e-05, Final Batch Loss: 6.431026577047305e-06\n",
      "Epoch 4868, Loss: 0.0003848000160360243, Final Batch Loss: 4.815457577933557e-05\n",
      "Epoch 4869, Loss: 0.00046664547517139, Final Batch Loss: 5.170847362023778e-05\n",
      "Epoch 4870, Loss: 0.00011100559913757024, Final Batch Loss: 4.3823354644700885e-05\n",
      "Epoch 4871, Loss: 0.00039754028875904623, Final Batch Loss: 1.2113161574234255e-05\n",
      "Epoch 4872, Loss: 0.00012665087706409395, Final Batch Loss: 1.9639021047623828e-05\n",
      "Epoch 4873, Loss: 0.0001607703852641862, Final Batch Loss: 4.960546357324347e-05\n",
      "Epoch 4874, Loss: 9.844485430221539e-05, Final Batch Loss: 3.2077219657367095e-05\n",
      "Epoch 4875, Loss: 0.0020537570017040707, Final Batch Loss: 0.0001323949109064415\n",
      "Epoch 4876, Loss: 0.000346767690643901, Final Batch Loss: 0.00010215822112513706\n",
      "Epoch 4877, Loss: 0.00036935514071956277, Final Batch Loss: 6.943258631508797e-05\n",
      "Epoch 4878, Loss: 0.0008998078337754123, Final Batch Loss: 0.00025473287678323686\n",
      "Epoch 4879, Loss: 0.0036526178882922977, Final Batch Loss: 9.498614235781133e-05\n",
      "Epoch 4880, Loss: 0.00017738261522026733, Final Batch Loss: 2.1240837668301538e-05\n",
      "Epoch 4881, Loss: 0.00010769200707727578, Final Batch Loss: 6.18363410467282e-05\n",
      "Epoch 4882, Loss: 0.0006519095704788924, Final Batch Loss: 0.0005260456237010658\n",
      "Epoch 4883, Loss: 0.00030073664311203174, Final Batch Loss: 1.8208618712378666e-05\n",
      "Epoch 4884, Loss: 0.0006155394876259379, Final Batch Loss: 7.516179903177544e-05\n",
      "Epoch 4885, Loss: 0.0002739398623816669, Final Batch Loss: 0.0001650868507567793\n",
      "Epoch 4886, Loss: 0.00016134854558913503, Final Batch Loss: 5.7618608479970135e-06\n",
      "Epoch 4887, Loss: 0.00010268175401506596, Final Batch Loss: 2.6481580789550208e-05\n",
      "Epoch 4888, Loss: 0.0010452086044097086, Final Batch Loss: 2.8952641514479183e-05\n",
      "Epoch 4889, Loss: 0.00028079871299269143, Final Batch Loss: 6.0199534345883876e-05\n",
      "Epoch 4890, Loss: 0.00021675576772395289, Final Batch Loss: 0.00017986544116865844\n",
      "Epoch 4891, Loss: 0.00030854749547870597, Final Batch Loss: 0.0002457273949403316\n",
      "Epoch 4892, Loss: 0.0018871503425543779, Final Batch Loss: 1.0671436939446721e-05\n",
      "Epoch 4893, Loss: 0.007528402024490788, Final Batch Loss: 2.292796580150025e-06\n",
      "Epoch 4894, Loss: 7.204422627182794e-05, Final Batch Loss: 4.750741209136322e-05\n",
      "Epoch 4895, Loss: 0.006374759881509817, Final Batch Loss: 6.615766324102879e-05\n",
      "Epoch 4896, Loss: 0.003863703010210884, Final Batch Loss: 2.054849210253451e-05\n",
      "Epoch 4897, Loss: 0.0011359386435287888, Final Batch Loss: 0.0010646629380062222\n",
      "Epoch 4898, Loss: 0.00023557013537356397, Final Batch Loss: 7.079281931510195e-05\n",
      "Epoch 4899, Loss: 0.000951949416048592, Final Batch Loss: 3.097510489169508e-05\n",
      "Epoch 4900, Loss: 0.003853763771985541, Final Batch Loss: 0.00019311910727992654\n",
      "Epoch 4901, Loss: 6.072024189052172e-05, Final Batch Loss: 2.7807320293504745e-05\n",
      "Epoch 4902, Loss: 0.00024025225138757378, Final Batch Loss: 6.0710866819135845e-05\n",
      "Epoch 4903, Loss: 0.001124342485127272, Final Batch Loss: 0.0010483337100595236\n",
      "Epoch 4904, Loss: 0.0009018075070343912, Final Batch Loss: 0.00020707435032818466\n",
      "Epoch 4905, Loss: 0.0011193840764462948, Final Batch Loss: 0.00023907380818855017\n",
      "Epoch 4906, Loss: 0.0011623790969679249, Final Batch Loss: 4.88901150674792e-06\n",
      "Epoch 4907, Loss: 0.00014513206315314164, Final Batch Loss: 1.310554853262147e-05\n",
      "Epoch 4908, Loss: 0.00043184251808270346, Final Batch Loss: 0.00018788993475027382\n",
      "Epoch 4909, Loss: 0.0019327302652527578, Final Batch Loss: 0.0017311936244368553\n",
      "Epoch 4910, Loss: 0.0001510717938799644, Final Batch Loss: 4.1000570490723476e-05\n",
      "Epoch 4911, Loss: 0.0006735871138516814, Final Batch Loss: 2.6669516955735162e-05\n",
      "Epoch 4912, Loss: 0.00545359673560597, Final Batch Loss: 7.476752216462046e-05\n",
      "Epoch 4913, Loss: 0.0004361909423096222, Final Batch Loss: 1.167200844065519e-05\n",
      "Epoch 4914, Loss: 0.00011779129999922588, Final Batch Loss: 2.046383815468289e-05\n",
      "Epoch 4915, Loss: 0.0029520102325477637, Final Batch Loss: 3.693552571348846e-05\n",
      "Epoch 4916, Loss: 0.0017901522776355705, Final Batch Loss: 1.5429598079208517e-06\n",
      "Epoch 4917, Loss: 0.0007535845143138431, Final Batch Loss: 0.00029852002626284957\n",
      "Epoch 4918, Loss: 0.0008369580546059296, Final Batch Loss: 4.669040208682418e-06\n",
      "Epoch 4919, Loss: 0.0001887609323603101, Final Batch Loss: 8.850720041664317e-05\n",
      "Epoch 4920, Loss: 5.6109119213942904e-05, Final Batch Loss: 1.7087797459680587e-05\n",
      "Epoch 4921, Loss: 0.00010881855632760562, Final Batch Loss: 1.403287114953855e-05\n",
      "Epoch 4922, Loss: 0.00011350135537213646, Final Batch Loss: 3.933335028705187e-05\n",
      "Epoch 4923, Loss: 0.00013858543934475165, Final Batch Loss: 6.347481394186616e-05\n",
      "Epoch 4924, Loss: 0.00012091972166672349, Final Batch Loss: 2.4686776669113897e-05\n",
      "Epoch 4925, Loss: 0.0006004335809848271, Final Batch Loss: 0.00034015768324024975\n",
      "Epoch 4926, Loss: 0.0008808436323306523, Final Batch Loss: 0.00037201092345640063\n",
      "Epoch 4927, Loss: 0.00023630038049304858, Final Batch Loss: 0.00010957909398712218\n",
      "Epoch 4928, Loss: 0.00045339307689573616, Final Batch Loss: 2.977888289024122e-05\n",
      "Epoch 4929, Loss: 0.0025755279530130792, Final Batch Loss: 1.739040089887567e-05\n",
      "Epoch 4930, Loss: 0.00011156149230373558, Final Batch Loss: 3.928854130208492e-05\n",
      "Epoch 4931, Loss: 0.00014217228090274148, Final Batch Loss: 2.248516830150038e-05\n",
      "Epoch 4932, Loss: 0.00034149053317378275, Final Batch Loss: 3.298883530078456e-05\n",
      "Epoch 4933, Loss: 0.001024009068714804, Final Batch Loss: 0.0008962727733887732\n",
      "Epoch 4934, Loss: 0.08934652990137693, Final Batch Loss: 0.08900332450866699\n",
      "Epoch 4935, Loss: 0.0022097516630310565, Final Batch Loss: 0.0020035484340041876\n",
      "Epoch 4936, Loss: 0.0009230895184373367, Final Batch Loss: 0.000830837176181376\n",
      "Epoch 4937, Loss: 0.0023731649916953756, Final Batch Loss: 0.0016866943333297968\n",
      "Epoch 4938, Loss: 0.00044947674177819863, Final Batch Loss: 8.450213499600068e-05\n",
      "Epoch 4939, Loss: 0.00017753368865669472, Final Batch Loss: 7.593697955599055e-05\n",
      "Epoch 4940, Loss: 0.0012175248557468876, Final Batch Loss: 7.031920540612191e-05\n",
      "Epoch 4941, Loss: 0.0005361585044738604, Final Batch Loss: 1.0347413990530185e-05\n",
      "Epoch 4942, Loss: 0.003663924249849515, Final Batch Loss: 2.387907079537399e-05\n",
      "Epoch 4943, Loss: 0.006204262870596722, Final Batch Loss: 0.00023853607126511633\n",
      "Epoch 4944, Loss: 0.0001771583729350823, Final Batch Loss: 3.659037611214444e-05\n",
      "Epoch 4945, Loss: 0.00044643933961197035, Final Batch Loss: 0.0003566619416233152\n",
      "Epoch 4946, Loss: 6.851315265521407e-05, Final Batch Loss: 2.5183784600812942e-05\n",
      "Epoch 4947, Loss: 0.0009899501892505214, Final Batch Loss: 5.928096652496606e-05\n",
      "Epoch 4948, Loss: 0.00020830161884077825, Final Batch Loss: 4.702523074229248e-05\n",
      "Epoch 4949, Loss: 0.0006140514742583036, Final Batch Loss: 4.5018663513474166e-05\n",
      "Epoch 4950, Loss: 0.00038179667171789333, Final Batch Loss: 5.489623436005786e-05\n",
      "Epoch 4951, Loss: 0.04610600267187692, Final Batch Loss: 0.015008730813860893\n",
      "Epoch 4952, Loss: 0.0004494315326155629, Final Batch Loss: 4.740393706015311e-05\n",
      "Epoch 4953, Loss: 0.001270914297492709, Final Batch Loss: 0.0001860865013441071\n",
      "Epoch 4954, Loss: 0.0007430907862726599, Final Batch Loss: 0.00013559451326727867\n",
      "Epoch 4955, Loss: 0.0019073836683674017, Final Batch Loss: 2.2434696802520193e-05\n",
      "Epoch 4956, Loss: 0.0010223506978945807, Final Batch Loss: 0.00014298762835096568\n",
      "Epoch 4957, Loss: 0.007413095809170045, Final Batch Loss: 6.180170021252707e-05\n",
      "Epoch 4958, Loss: 0.0004650199171010172, Final Batch Loss: 2.3015911210677586e-05\n",
      "Epoch 4959, Loss: 0.0012416647659847513, Final Batch Loss: 0.0003417205298319459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4960, Loss: 0.0055983132115215994, Final Batch Loss: 0.00533036794513464\n",
      "Epoch 4961, Loss: 0.0038635080763924634, Final Batch Loss: 1.5993389752111398e-05\n",
      "Epoch 4962, Loss: 0.0002254892278870102, Final Batch Loss: 5.8315392379881814e-05\n",
      "Epoch 4963, Loss: 0.000147668004501611, Final Batch Loss: 1.6057980246841908e-05\n",
      "Epoch 4964, Loss: 0.0002977113581437152, Final Batch Loss: 3.656770786619745e-05\n",
      "Epoch 4965, Loss: 0.009331422952527646, Final Batch Loss: 7.417795131914318e-05\n",
      "Epoch 4966, Loss: 0.0003868610365316272, Final Batch Loss: 0.000220410933252424\n",
      "Epoch 4967, Loss: 0.0012191456771688536, Final Batch Loss: 3.928559453925118e-05\n",
      "Epoch 4968, Loss: 0.0023845407649787376, Final Batch Loss: 0.0021098593715578318\n",
      "Epoch 4969, Loss: 0.0012921376765007153, Final Batch Loss: 4.878109029959887e-05\n",
      "Epoch 4970, Loss: 0.000511285272295936, Final Batch Loss: 1.741700543789193e-05\n",
      "Epoch 4971, Loss: 0.0010778749929158948, Final Batch Loss: 9.150857658823952e-05\n",
      "Epoch 4972, Loss: 0.0005089237965876237, Final Batch Loss: 0.00014100682165008038\n",
      "Epoch 4973, Loss: 0.00011987298785243183, Final Batch Loss: 8.155328396242112e-05\n",
      "Epoch 4974, Loss: 0.00023530918406322598, Final Batch Loss: 4.914959572488442e-05\n",
      "Epoch 4975, Loss: 0.00014391575859917793, Final Batch Loss: 6.799527182010934e-05\n",
      "Epoch 4976, Loss: 0.0005231920044934668, Final Batch Loss: 4.286510829842882e-06\n",
      "Epoch 4977, Loss: 0.0002585687216196675, Final Batch Loss: 7.232654752442613e-05\n",
      "Epoch 4978, Loss: 0.0007086884324962739, Final Batch Loss: 0.00012037278793286532\n",
      "Epoch 4979, Loss: 0.001664673838604358, Final Batch Loss: 0.001574389636516571\n",
      "Epoch 4980, Loss: 0.0010714606614783406, Final Batch Loss: 0.0007495934260077775\n",
      "Epoch 4981, Loss: 0.0003487501962808892, Final Batch Loss: 0.00016508852422703058\n",
      "Epoch 4982, Loss: 0.015191067337582354, Final Batch Loss: 7.624031422892585e-05\n",
      "Epoch 4983, Loss: 8.662860818731133e-05, Final Batch Loss: 1.8427510440233164e-05\n",
      "Epoch 4984, Loss: 0.00034021567307718215, Final Batch Loss: 7.206763712019892e-06\n",
      "Epoch 4985, Loss: 0.000759698057663627, Final Batch Loss: 0.0003214529133401811\n",
      "Epoch 4986, Loss: 0.003831210000498686, Final Batch Loss: 1.1938303941860795e-05\n",
      "Epoch 4987, Loss: 5.7511932027409784e-05, Final Batch Loss: 2.690701512619853e-05\n",
      "Epoch 4988, Loss: 0.0012680835388891865, Final Batch Loss: 0.00022721356071997434\n",
      "Epoch 4989, Loss: 0.0002129265030816896, Final Batch Loss: 8.095243174466304e-06\n",
      "Epoch 4990, Loss: 0.0024894745329220314, Final Batch Loss: 3.5321168979862705e-05\n",
      "Epoch 4991, Loss: 0.00014291184743342455, Final Batch Loss: 1.8364111383561976e-05\n",
      "Epoch 4992, Loss: 0.0018734944314928725, Final Batch Loss: 0.0015598379541188478\n",
      "Epoch 4993, Loss: 0.0008364171371795237, Final Batch Loss: 0.0007431168924085796\n",
      "Epoch 4994, Loss: 0.0030149864323902875, Final Batch Loss: 0.0006790561019442976\n",
      "Epoch 4995, Loss: 0.00019162317403242923, Final Batch Loss: 1.628703648748342e-05\n",
      "Epoch 4996, Loss: 0.0008232970212702639, Final Batch Loss: 6.0270685935392976e-05\n",
      "Epoch 4997, Loss: 0.001329623642959632, Final Batch Loss: 0.0001860164775280282\n",
      "Epoch 4998, Loss: 0.0001146348804468289, Final Batch Loss: 3.71881942555774e-05\n",
      "Epoch 4999, Loss: 0.00020118404790991917, Final Batch Loss: 6.321109685814008e-05\n",
      "Epoch 5000, Loss: 0.0005212669311731588, Final Batch Loss: 0.0001573573099449277\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55  0  0]\n",
      " [ 2 48  0]\n",
      " [ 0  0 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96491   1.00000   0.98214        55\n",
      "           1    1.00000   0.96000   0.97959        50\n",
      "           2    1.00000   1.00000   1.00000        52\n",
      "\n",
      "    accuracy                        0.98726       157\n",
      "   macro avg    0.98830   0.98667   0.98724       157\n",
      "weighted avg    0.98771   0.98726   0.98724       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (gen): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=108, out_features=80, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=80, out_features=60, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=60, out_features=50, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Linear(in_features=50, out_features=30, bias=True)\n",
       "    (4): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = Generator(z_dim = 108)\n",
    "load_model(gen, \"3 Label 5 Subject GAN Ablation_gen.param\")\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(X_test)\n",
    "latent_vectors = get_noise(size, 100)\n",
    "act_vectors = get_act_matrix(size, 3)\n",
    "usr_vectors = get_usr_matrix(size, 5)\n",
    "\n",
    "to_gen = torch.cat((latent_vectors, act_vectors[1], usr_vectors[1]), 1)\n",
    "fake_features = gen(to_gen).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  0  0]\n",
      " [ 0 50  0]\n",
      " [ 0  0 57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        50\n",
      "           1    1.00000   1.00000   1.00000        50\n",
      "           2    1.00000   1.00000   1.00000        57\n",
      "\n",
      "    accuracy                        1.00000       157\n",
      "   macro avg    1.00000   1.00000   1.00000       157\n",
      "weighted avg    1.00000   1.00000   1.00000       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(act_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(act_vectors[0], preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7, 8]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    elif y[k] == 5:\n",
    "        y[k] = 2\n",
    "    elif y[k] == 7:\n",
    "        y[k] = 3\n",
    "    else:\n",
    "        y[k] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Subject_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.839553952217102, Final Batch Loss: 1.6145284175872803\n",
      "Epoch 2, Loss: 4.837301015853882, Final Batch Loss: 1.6172398328781128\n",
      "Epoch 3, Loss: 4.832103848457336, Final Batch Loss: 1.6099274158477783\n",
      "Epoch 4, Loss: 4.832404971122742, Final Batch Loss: 1.614314317703247\n",
      "Epoch 5, Loss: 4.832371234893799, Final Batch Loss: 1.6175434589385986\n",
      "Epoch 6, Loss: 4.819251775741577, Final Batch Loss: 1.5992883443832397\n",
      "Epoch 7, Loss: 4.825602650642395, Final Batch Loss: 1.6082749366760254\n",
      "Epoch 8, Loss: 4.828278422355652, Final Batch Loss: 1.628514289855957\n",
      "Epoch 9, Loss: 4.817973256111145, Final Batch Loss: 1.6059249639511108\n",
      "Epoch 10, Loss: 4.798864006996155, Final Batch Loss: 1.5827860832214355\n",
      "Epoch 11, Loss: 4.808717608451843, Final Batch Loss: 1.6040841341018677\n",
      "Epoch 12, Loss: 4.804565191268921, Final Batch Loss: 1.6033741235733032\n",
      "Epoch 13, Loss: 4.799977779388428, Final Batch Loss: 1.590522050857544\n",
      "Epoch 14, Loss: 4.794031023979187, Final Batch Loss: 1.5898159742355347\n",
      "Epoch 15, Loss: 4.792007207870483, Final Batch Loss: 1.594910740852356\n",
      "Epoch 16, Loss: 4.7895708084106445, Final Batch Loss: 1.5983816385269165\n",
      "Epoch 17, Loss: 4.794375061988831, Final Batch Loss: 1.6015256643295288\n",
      "Epoch 18, Loss: 4.775912165641785, Final Batch Loss: 1.5960952043533325\n",
      "Epoch 19, Loss: 4.777903318405151, Final Batch Loss: 1.6052559614181519\n",
      "Epoch 20, Loss: 4.759353160858154, Final Batch Loss: 1.5776764154434204\n",
      "Epoch 21, Loss: 4.763030767440796, Final Batch Loss: 1.5903193950653076\n",
      "Epoch 22, Loss: 4.744906425476074, Final Batch Loss: 1.593794584274292\n",
      "Epoch 23, Loss: 4.747799038887024, Final Batch Loss: 1.6004365682601929\n",
      "Epoch 24, Loss: 4.736425042152405, Final Batch Loss: 1.5959948301315308\n",
      "Epoch 25, Loss: 4.704887390136719, Final Batch Loss: 1.5546979904174805\n",
      "Epoch 26, Loss: 4.6817498207092285, Final Batch Loss: 1.5449845790863037\n",
      "Epoch 27, Loss: 4.658017039299011, Final Batch Loss: 1.5454870462417603\n",
      "Epoch 28, Loss: 4.639687657356262, Final Batch Loss: 1.5394171476364136\n",
      "Epoch 29, Loss: 4.638298869132996, Final Batch Loss: 1.5352386236190796\n",
      "Epoch 30, Loss: 4.625043034553528, Final Batch Loss: 1.5458654165267944\n",
      "Epoch 31, Loss: 4.585016846656799, Final Batch Loss: 1.5128881931304932\n",
      "Epoch 32, Loss: 4.547756314277649, Final Batch Loss: 1.49891996383667\n",
      "Epoch 33, Loss: 4.53156304359436, Final Batch Loss: 1.4962327480316162\n",
      "Epoch 34, Loss: 4.497547388076782, Final Batch Loss: 1.4811738729476929\n",
      "Epoch 35, Loss: 4.506257176399231, Final Batch Loss: 1.5066863298416138\n",
      "Epoch 36, Loss: 4.425971150398254, Final Batch Loss: 1.4447132349014282\n",
      "Epoch 37, Loss: 4.456626772880554, Final Batch Loss: 1.5181341171264648\n",
      "Epoch 38, Loss: 4.3891681432724, Final Batch Loss: 1.4331090450286865\n",
      "Epoch 39, Loss: 4.401751756668091, Final Batch Loss: 1.4771196842193604\n",
      "Epoch 40, Loss: 4.37733268737793, Final Batch Loss: 1.4751863479614258\n",
      "Epoch 41, Loss: 4.289544343948364, Final Batch Loss: 1.4158991575241089\n",
      "Epoch 42, Loss: 4.242011547088623, Final Batch Loss: 1.3894858360290527\n",
      "Epoch 43, Loss: 4.304943680763245, Final Batch Loss: 1.4650874137878418\n",
      "Epoch 44, Loss: 4.229724645614624, Final Batch Loss: 1.4067965745925903\n",
      "Epoch 45, Loss: 4.2417685985565186, Final Batch Loss: 1.4490665197372437\n",
      "Epoch 46, Loss: 4.183635473251343, Final Batch Loss: 1.420520544052124\n",
      "Epoch 47, Loss: 4.095985293388367, Final Batch Loss: 1.344700574874878\n",
      "Epoch 48, Loss: 4.098132371902466, Final Batch Loss: 1.345901608467102\n",
      "Epoch 49, Loss: 3.977942943572998, Final Batch Loss: 1.2758891582489014\n",
      "Epoch 50, Loss: 3.9756243228912354, Final Batch Loss: 1.3166046142578125\n",
      "Epoch 51, Loss: 3.9597811698913574, Final Batch Loss: 1.3013603687286377\n",
      "Epoch 52, Loss: 3.917752504348755, Final Batch Loss: 1.3611876964569092\n",
      "Epoch 53, Loss: 3.8437881469726562, Final Batch Loss: 1.2638843059539795\n",
      "Epoch 54, Loss: 3.773187756538391, Final Batch Loss: 1.2370638847351074\n",
      "Epoch 55, Loss: 3.845175266265869, Final Batch Loss: 1.2739717960357666\n",
      "Epoch 56, Loss: 3.744466543197632, Final Batch Loss: 1.2130136489868164\n",
      "Epoch 57, Loss: 3.7752262353897095, Final Batch Loss: 1.250820517539978\n",
      "Epoch 58, Loss: 3.6546274423599243, Final Batch Loss: 1.1671204566955566\n",
      "Epoch 59, Loss: 3.720900297164917, Final Batch Loss: 1.285960078239441\n",
      "Epoch 60, Loss: 3.5700812339782715, Final Batch Loss: 1.1492353677749634\n",
      "Epoch 61, Loss: 3.6430788040161133, Final Batch Loss: 1.281205415725708\n",
      "Epoch 62, Loss: 3.5136581659317017, Final Batch Loss: 1.1112427711486816\n",
      "Epoch 63, Loss: 3.4746296405792236, Final Batch Loss: 1.1738137006759644\n",
      "Epoch 64, Loss: 3.4764223098754883, Final Batch Loss: 1.1486706733703613\n",
      "Epoch 65, Loss: 3.448356866836548, Final Batch Loss: 1.1594418287277222\n",
      "Epoch 66, Loss: 3.3790032863616943, Final Batch Loss: 1.1126160621643066\n",
      "Epoch 67, Loss: 3.2430925369262695, Final Batch Loss: 1.0279096364974976\n",
      "Epoch 68, Loss: 3.3807483911514282, Final Batch Loss: 1.1471102237701416\n",
      "Epoch 69, Loss: 3.3038488626480103, Final Batch Loss: 1.101149082183838\n",
      "Epoch 70, Loss: 3.2745752334594727, Final Batch Loss: 1.021820306777954\n",
      "Epoch 71, Loss: 3.2271944284439087, Final Batch Loss: 1.058152198791504\n",
      "Epoch 72, Loss: 3.2582528591156006, Final Batch Loss: 1.1494688987731934\n",
      "Epoch 73, Loss: 3.2161587476730347, Final Batch Loss: 1.0634875297546387\n",
      "Epoch 74, Loss: 3.1553694009780884, Final Batch Loss: 1.011765956878662\n",
      "Epoch 75, Loss: 3.183384418487549, Final Batch Loss: 1.0654008388519287\n",
      "Epoch 76, Loss: 3.0892257690429688, Final Batch Loss: 0.9888888597488403\n",
      "Epoch 77, Loss: 3.1225754022598267, Final Batch Loss: 1.0086301565170288\n",
      "Epoch 78, Loss: 3.163115620613098, Final Batch Loss: 1.0035663843154907\n",
      "Epoch 79, Loss: 3.2131611108779907, Final Batch Loss: 1.101697564125061\n",
      "Epoch 80, Loss: 3.038495659828186, Final Batch Loss: 0.9579504728317261\n",
      "Epoch 81, Loss: 3.0655601024627686, Final Batch Loss: 1.03323233127594\n",
      "Epoch 82, Loss: 3.0073591470718384, Final Batch Loss: 0.9744296073913574\n",
      "Epoch 83, Loss: 2.99910306930542, Final Batch Loss: 0.976776123046875\n",
      "Epoch 84, Loss: 3.0856754779815674, Final Batch Loss: 1.0618449449539185\n",
      "Epoch 85, Loss: 2.9511314630508423, Final Batch Loss: 0.9219748377799988\n",
      "Epoch 86, Loss: 3.0873149037361145, Final Batch Loss: 0.953118622303009\n",
      "Epoch 87, Loss: 3.072646141052246, Final Batch Loss: 1.0236834287643433\n",
      "Epoch 88, Loss: 3.049160599708557, Final Batch Loss: 1.0460838079452515\n",
      "Epoch 89, Loss: 3.0220256447792053, Final Batch Loss: 1.0272786617279053\n",
      "Epoch 90, Loss: 2.8992703557014465, Final Batch Loss: 0.972579836845398\n",
      "Epoch 91, Loss: 2.934581756591797, Final Batch Loss: 0.9304754734039307\n",
      "Epoch 92, Loss: 2.9323227405548096, Final Batch Loss: 0.9426291584968567\n",
      "Epoch 93, Loss: 2.9401974081993103, Final Batch Loss: 0.9503836035728455\n",
      "Epoch 94, Loss: 2.908437192440033, Final Batch Loss: 0.9706326127052307\n",
      "Epoch 95, Loss: 2.920829176902771, Final Batch Loss: 0.9285328984260559\n",
      "Epoch 96, Loss: 2.9129260182380676, Final Batch Loss: 0.9563065767288208\n",
      "Epoch 97, Loss: 2.9280781149864197, Final Batch Loss: 0.9802237153053284\n",
      "Epoch 98, Loss: 2.9208394289016724, Final Batch Loss: 1.0406941175460815\n",
      "Epoch 99, Loss: 2.8435567021369934, Final Batch Loss: 0.954796552658081\n",
      "Epoch 100, Loss: 2.837614417076111, Final Batch Loss: 0.9481174945831299\n",
      "Epoch 101, Loss: 2.8297824263572693, Final Batch Loss: 0.937312662601471\n",
      "Epoch 102, Loss: 2.873269200325012, Final Batch Loss: 0.8972710967063904\n",
      "Epoch 103, Loss: 2.8243346214294434, Final Batch Loss: 0.8914386630058289\n",
      "Epoch 104, Loss: 2.8674315214157104, Final Batch Loss: 0.942355215549469\n",
      "Epoch 105, Loss: 2.741881787776947, Final Batch Loss: 0.8871631026268005\n",
      "Epoch 106, Loss: 2.7133411169052124, Final Batch Loss: 0.8753669857978821\n",
      "Epoch 107, Loss: 2.7501361966133118, Final Batch Loss: 0.9394958019256592\n",
      "Epoch 108, Loss: 2.712162733078003, Final Batch Loss: 0.9605075120925903\n",
      "Epoch 109, Loss: 2.7569547295570374, Final Batch Loss: 0.9509262442588806\n",
      "Epoch 110, Loss: 2.702519178390503, Final Batch Loss: 0.8468594551086426\n",
      "Epoch 111, Loss: 2.834354817867279, Final Batch Loss: 1.0404947996139526\n",
      "Epoch 112, Loss: 2.7549537420272827, Final Batch Loss: 0.9501669406890869\n",
      "Epoch 113, Loss: 2.7021884322166443, Final Batch Loss: 0.8912096619606018\n",
      "Epoch 114, Loss: 2.6700987815856934, Final Batch Loss: 0.929309606552124\n",
      "Epoch 115, Loss: 2.8222014904022217, Final Batch Loss: 1.0997573137283325\n",
      "Epoch 116, Loss: 2.697328507900238, Final Batch Loss: 0.8148682117462158\n",
      "Epoch 117, Loss: 2.6333996653556824, Final Batch Loss: 0.8015125393867493\n",
      "Epoch 118, Loss: 2.6049658060073853, Final Batch Loss: 0.7532711029052734\n",
      "Epoch 119, Loss: 2.5880383253097534, Final Batch Loss: 0.8501688838005066\n",
      "Epoch 120, Loss: 2.641675889492035, Final Batch Loss: 0.8532836437225342\n",
      "Epoch 121, Loss: 2.635411024093628, Final Batch Loss: 0.8636631965637207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122, Loss: 2.857576608657837, Final Batch Loss: 1.0055596828460693\n",
      "Epoch 123, Loss: 2.638202488422394, Final Batch Loss: 0.8568491339683533\n",
      "Epoch 124, Loss: 2.6889217495918274, Final Batch Loss: 0.8775727152824402\n",
      "Epoch 125, Loss: 2.697430670261383, Final Batch Loss: 0.9317885637283325\n",
      "Epoch 126, Loss: 2.613822102546692, Final Batch Loss: 0.8672077655792236\n",
      "Epoch 127, Loss: 2.584209442138672, Final Batch Loss: 0.8406413793563843\n",
      "Epoch 128, Loss: 2.600424110889435, Final Batch Loss: 0.8953009247779846\n",
      "Epoch 129, Loss: 2.64409601688385, Final Batch Loss: 0.8530316948890686\n",
      "Epoch 130, Loss: 2.528627634048462, Final Batch Loss: 0.747594952583313\n",
      "Epoch 131, Loss: 2.6002153754234314, Final Batch Loss: 0.8706572651863098\n",
      "Epoch 132, Loss: 2.5497177243232727, Final Batch Loss: 0.866150438785553\n",
      "Epoch 133, Loss: 2.604208767414093, Final Batch Loss: 0.883480966091156\n",
      "Epoch 134, Loss: 2.439949929714203, Final Batch Loss: 0.8046993017196655\n",
      "Epoch 135, Loss: 2.5439692735671997, Final Batch Loss: 0.8776836395263672\n",
      "Epoch 136, Loss: 2.5779241919517517, Final Batch Loss: 0.8835719227790833\n",
      "Epoch 137, Loss: 2.5265806913375854, Final Batch Loss: 0.7870357036590576\n",
      "Epoch 138, Loss: 2.4599584341049194, Final Batch Loss: 0.832403302192688\n",
      "Epoch 139, Loss: 2.522391140460968, Final Batch Loss: 0.8428602814674377\n",
      "Epoch 140, Loss: 2.517613172531128, Final Batch Loss: 0.8307831883430481\n",
      "Epoch 141, Loss: 2.510065972805023, Final Batch Loss: 0.7696908712387085\n",
      "Epoch 142, Loss: 2.4365808367729187, Final Batch Loss: 0.7767648100852966\n",
      "Epoch 143, Loss: 2.527609169483185, Final Batch Loss: 0.8272138833999634\n",
      "Epoch 144, Loss: 2.374615788459778, Final Batch Loss: 0.7810933589935303\n",
      "Epoch 145, Loss: 2.4894453287124634, Final Batch Loss: 0.8349243402481079\n",
      "Epoch 146, Loss: 2.4475908279418945, Final Batch Loss: 0.8269332647323608\n",
      "Epoch 147, Loss: 2.3949695229530334, Final Batch Loss: 0.7772707343101501\n",
      "Epoch 148, Loss: 2.4259711503982544, Final Batch Loss: 0.8294078707695007\n",
      "Epoch 149, Loss: 2.495698571205139, Final Batch Loss: 0.7970866560935974\n",
      "Epoch 150, Loss: 2.5236124992370605, Final Batch Loss: 0.8738097548484802\n",
      "Epoch 151, Loss: 2.5109593272209167, Final Batch Loss: 0.8631996512413025\n",
      "Epoch 152, Loss: 2.4162681102752686, Final Batch Loss: 0.8222353458404541\n",
      "Epoch 153, Loss: 2.366898000240326, Final Batch Loss: 0.7332995533943176\n",
      "Epoch 154, Loss: 2.420703649520874, Final Batch Loss: 0.8367670774459839\n",
      "Epoch 155, Loss: 2.3966123461723328, Final Batch Loss: 0.6974755525588989\n",
      "Epoch 156, Loss: 2.3826202154159546, Final Batch Loss: 0.740827202796936\n",
      "Epoch 157, Loss: 2.466638147830963, Final Batch Loss: 0.8452974557876587\n",
      "Epoch 158, Loss: 2.481827437877655, Final Batch Loss: 0.8271484375\n",
      "Epoch 159, Loss: 2.3962432146072388, Final Batch Loss: 0.8107816576957703\n",
      "Epoch 160, Loss: 2.4399001598358154, Final Batch Loss: 0.8530992865562439\n",
      "Epoch 161, Loss: 2.411014974117279, Final Batch Loss: 0.8415006995201111\n",
      "Epoch 162, Loss: 2.452919363975525, Final Batch Loss: 0.8051706552505493\n",
      "Epoch 163, Loss: 2.4401513934135437, Final Batch Loss: 0.7560989856719971\n",
      "Epoch 164, Loss: 2.34859961271286, Final Batch Loss: 0.7645971179008484\n",
      "Epoch 165, Loss: 2.422541081905365, Final Batch Loss: 0.771446704864502\n",
      "Epoch 166, Loss: 2.411854565143585, Final Batch Loss: 0.8284562230110168\n",
      "Epoch 167, Loss: 2.4263455271720886, Final Batch Loss: 0.7820443511009216\n",
      "Epoch 168, Loss: 2.37956041097641, Final Batch Loss: 0.7464599013328552\n",
      "Epoch 169, Loss: 2.2982435822486877, Final Batch Loss: 0.697198212146759\n",
      "Epoch 170, Loss: 2.375536262989044, Final Batch Loss: 0.7588009238243103\n",
      "Epoch 171, Loss: 2.3225866556167603, Final Batch Loss: 0.6887272596359253\n",
      "Epoch 172, Loss: 2.4214577674865723, Final Batch Loss: 0.8628284931182861\n",
      "Epoch 173, Loss: 2.313046097755432, Final Batch Loss: 0.7518466711044312\n",
      "Epoch 174, Loss: 2.292162299156189, Final Batch Loss: 0.7984912395477295\n",
      "Epoch 175, Loss: 2.31872296333313, Final Batch Loss: 0.7506977915763855\n",
      "Epoch 176, Loss: 2.3353469371795654, Final Batch Loss: 0.6804856061935425\n",
      "Epoch 177, Loss: 2.459040880203247, Final Batch Loss: 0.7957653403282166\n",
      "Epoch 178, Loss: 2.350132703781128, Final Batch Loss: 0.7544266581535339\n",
      "Epoch 179, Loss: 2.4341045022010803, Final Batch Loss: 0.7925605773925781\n",
      "Epoch 180, Loss: 2.3229408264160156, Final Batch Loss: 0.8083345890045166\n",
      "Epoch 181, Loss: 2.3623489141464233, Final Batch Loss: 0.7741037607192993\n",
      "Epoch 182, Loss: 2.3509740829467773, Final Batch Loss: 0.8238653540611267\n",
      "Epoch 183, Loss: 2.415881335735321, Final Batch Loss: 0.841393768787384\n",
      "Epoch 184, Loss: 2.367206394672394, Final Batch Loss: 0.8450117707252502\n",
      "Epoch 185, Loss: 2.3581032156944275, Final Batch Loss: 0.8199979662895203\n",
      "Epoch 186, Loss: 2.3019428849220276, Final Batch Loss: 0.716144859790802\n",
      "Epoch 187, Loss: 2.208156108856201, Final Batch Loss: 0.708581268787384\n",
      "Epoch 188, Loss: 2.32195645570755, Final Batch Loss: 0.7295777201652527\n",
      "Epoch 189, Loss: 2.3184558749198914, Final Batch Loss: 0.7255420088768005\n",
      "Epoch 190, Loss: 2.225899577140808, Final Batch Loss: 0.7586456537246704\n",
      "Epoch 191, Loss: 2.37485671043396, Final Batch Loss: 0.8572257161140442\n",
      "Epoch 192, Loss: 2.303808033466339, Final Batch Loss: 0.7991416454315186\n",
      "Epoch 193, Loss: 2.3393282294273376, Final Batch Loss: 0.800922155380249\n",
      "Epoch 194, Loss: 2.3388847708702087, Final Batch Loss: 0.8454506993293762\n",
      "Epoch 195, Loss: 2.2666028141975403, Final Batch Loss: 0.783494234085083\n",
      "Epoch 196, Loss: 2.263045847415924, Final Batch Loss: 0.747631847858429\n",
      "Epoch 197, Loss: 2.28820538520813, Final Batch Loss: 0.694840133190155\n",
      "Epoch 198, Loss: 2.360141396522522, Final Batch Loss: 0.7947143316268921\n",
      "Epoch 199, Loss: 2.2928918600082397, Final Batch Loss: 0.7605271935462952\n",
      "Epoch 200, Loss: 2.353410243988037, Final Batch Loss: 0.8276461362838745\n",
      "Epoch 201, Loss: 2.2737197279930115, Final Batch Loss: 0.7354618310928345\n",
      "Epoch 202, Loss: 2.2402021884918213, Final Batch Loss: 0.7055965065956116\n",
      "Epoch 203, Loss: 2.3151872158050537, Final Batch Loss: 0.8073789477348328\n",
      "Epoch 204, Loss: 2.3846603631973267, Final Batch Loss: 0.890317440032959\n",
      "Epoch 205, Loss: 2.2652183771133423, Final Batch Loss: 0.7177442312240601\n",
      "Epoch 206, Loss: 2.2514830231666565, Final Batch Loss: 0.7791593670845032\n",
      "Epoch 207, Loss: 2.2876080870628357, Final Batch Loss: 0.8173631429672241\n",
      "Epoch 208, Loss: 2.246089458465576, Final Batch Loss: 0.7474222779273987\n",
      "Epoch 209, Loss: 2.301751732826233, Final Batch Loss: 0.7529839873313904\n",
      "Epoch 210, Loss: 2.247522473335266, Final Batch Loss: 0.7534119486808777\n",
      "Epoch 211, Loss: 2.2767025232315063, Final Batch Loss: 0.8227235674858093\n",
      "Epoch 212, Loss: 2.269317924976349, Final Batch Loss: 0.7011314630508423\n",
      "Epoch 213, Loss: 2.3106484413146973, Final Batch Loss: 0.8267672657966614\n",
      "Epoch 214, Loss: 2.318247675895691, Final Batch Loss: 0.8011143803596497\n",
      "Epoch 215, Loss: 2.265096664428711, Final Batch Loss: 0.7467384338378906\n",
      "Epoch 216, Loss: 2.244602918624878, Final Batch Loss: 0.7497841119766235\n",
      "Epoch 217, Loss: 2.2301231622695923, Final Batch Loss: 0.700920045375824\n",
      "Epoch 218, Loss: 2.144958794116974, Final Batch Loss: 0.6760748028755188\n",
      "Epoch 219, Loss: 2.2158426642417908, Final Batch Loss: 0.687109649181366\n",
      "Epoch 220, Loss: 2.2704561352729797, Final Batch Loss: 0.7843008637428284\n",
      "Epoch 221, Loss: 2.2660419940948486, Final Batch Loss: 0.7693243622779846\n",
      "Epoch 222, Loss: 2.200263738632202, Final Batch Loss: 0.6724485754966736\n",
      "Epoch 223, Loss: 2.2390283346176147, Final Batch Loss: 0.6598304510116577\n",
      "Epoch 224, Loss: 2.186939001083374, Final Batch Loss: 0.7119020819664001\n",
      "Epoch 225, Loss: 2.240401029586792, Final Batch Loss: 0.7516651749610901\n",
      "Epoch 226, Loss: 2.1420114040374756, Final Batch Loss: 0.7099345922470093\n",
      "Epoch 227, Loss: 2.2244457006454468, Final Batch Loss: 0.738745391368866\n",
      "Epoch 228, Loss: 2.2667372822761536, Final Batch Loss: 0.783094584941864\n",
      "Epoch 229, Loss: 2.2332367300987244, Final Batch Loss: 0.8094468712806702\n",
      "Epoch 230, Loss: 2.3250167965888977, Final Batch Loss: 0.820892333984375\n",
      "Epoch 231, Loss: 2.1636927723884583, Final Batch Loss: 0.7141718864440918\n",
      "Epoch 232, Loss: 2.2273597717285156, Final Batch Loss: 0.6934626698493958\n",
      "Epoch 233, Loss: 2.256154179573059, Final Batch Loss: 0.7799736261367798\n",
      "Epoch 234, Loss: 2.177459478378296, Final Batch Loss: 0.7316561937332153\n",
      "Epoch 235, Loss: 2.190794587135315, Final Batch Loss: 0.831150233745575\n",
      "Epoch 236, Loss: 2.2338943481445312, Final Batch Loss: 0.8437743782997131\n",
      "Epoch 237, Loss: 2.36184024810791, Final Batch Loss: 0.853667140007019\n",
      "Epoch 238, Loss: 2.16057026386261, Final Batch Loss: 0.8091162443161011\n",
      "Epoch 239, Loss: 2.2010398507118225, Final Batch Loss: 0.7691047787666321\n",
      "Epoch 240, Loss: 2.106172740459442, Final Batch Loss: 0.6531298756599426\n",
      "Epoch 241, Loss: 2.2108890414237976, Final Batch Loss: 0.6859904527664185\n",
      "Epoch 242, Loss: 2.085530459880829, Final Batch Loss: 0.6357457637786865\n",
      "Epoch 243, Loss: 2.1860307455062866, Final Batch Loss: 0.8387234807014465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244, Loss: 2.246470332145691, Final Batch Loss: 0.7294342517852783\n",
      "Epoch 245, Loss: 2.189693331718445, Final Batch Loss: 0.6972238421440125\n",
      "Epoch 246, Loss: 2.169723331928253, Final Batch Loss: 0.7296915650367737\n",
      "Epoch 247, Loss: 2.1256173253059387, Final Batch Loss: 0.7211810350418091\n",
      "Epoch 248, Loss: 2.11428165435791, Final Batch Loss: 0.7470353841781616\n",
      "Epoch 249, Loss: 2.1838529109954834, Final Batch Loss: 0.8089057207107544\n",
      "Epoch 250, Loss: 2.0742334723472595, Final Batch Loss: 0.6606023907661438\n",
      "Epoch 251, Loss: 2.2646254301071167, Final Batch Loss: 0.8225829005241394\n",
      "Epoch 252, Loss: 2.216134011745453, Final Batch Loss: 0.8121317028999329\n",
      "Epoch 253, Loss: 2.1799646615982056, Final Batch Loss: 0.7849014401435852\n",
      "Epoch 254, Loss: 2.169919013977051, Final Batch Loss: 0.7476747035980225\n",
      "Epoch 255, Loss: 2.2606475353240967, Final Batch Loss: 0.8081663846969604\n",
      "Epoch 256, Loss: 2.1458941102027893, Final Batch Loss: 0.6613348126411438\n",
      "Epoch 257, Loss: 2.1069856882095337, Final Batch Loss: 0.7289128303527832\n",
      "Epoch 258, Loss: 2.110513389110565, Final Batch Loss: 0.6663945317268372\n",
      "Epoch 259, Loss: 2.0905168652534485, Final Batch Loss: 0.7369081377983093\n",
      "Epoch 260, Loss: 2.2267098426818848, Final Batch Loss: 0.8629614114761353\n",
      "Epoch 261, Loss: 2.1719244718551636, Final Batch Loss: 0.7294139266014099\n",
      "Epoch 262, Loss: 2.1434115767478943, Final Batch Loss: 0.7438883185386658\n",
      "Epoch 263, Loss: 2.2344589233398438, Final Batch Loss: 0.8122269511222839\n",
      "Epoch 264, Loss: 2.2435616850852966, Final Batch Loss: 0.7624815702438354\n",
      "Epoch 265, Loss: 2.08525550365448, Final Batch Loss: 0.6875622868537903\n",
      "Epoch 266, Loss: 2.1317795515060425, Final Batch Loss: 0.7602326273918152\n",
      "Epoch 267, Loss: 2.1777431964874268, Final Batch Loss: 0.7132871747016907\n",
      "Epoch 268, Loss: 2.061775028705597, Final Batch Loss: 0.6408323645591736\n",
      "Epoch 269, Loss: 2.031979203224182, Final Batch Loss: 0.6753766536712646\n",
      "Epoch 270, Loss: 2.1625534892082214, Final Batch Loss: 0.7381525635719299\n",
      "Epoch 271, Loss: 2.099671959877014, Final Batch Loss: 0.7137491703033447\n",
      "Epoch 272, Loss: 2.059941291809082, Final Batch Loss: 0.6344477534294128\n",
      "Epoch 273, Loss: 2.049387216567993, Final Batch Loss: 0.6276278495788574\n",
      "Epoch 274, Loss: 2.0806214809417725, Final Batch Loss: 0.6835464835166931\n",
      "Epoch 275, Loss: 2.084095776081085, Final Batch Loss: 0.6781402230262756\n",
      "Epoch 276, Loss: 2.1769543886184692, Final Batch Loss: 0.8420577049255371\n",
      "Epoch 277, Loss: 2.023274302482605, Final Batch Loss: 0.6553995609283447\n",
      "Epoch 278, Loss: 2.0126630663871765, Final Batch Loss: 0.610784113407135\n",
      "Epoch 279, Loss: 2.088892340660095, Final Batch Loss: 0.7951339483261108\n",
      "Epoch 280, Loss: 1.9719963073730469, Final Batch Loss: 0.6190153360366821\n",
      "Epoch 281, Loss: 1.9875080585479736, Final Batch Loss: 0.6612880825996399\n",
      "Epoch 282, Loss: 2.1507416367530823, Final Batch Loss: 0.7381278276443481\n",
      "Epoch 283, Loss: 1.9386247992515564, Final Batch Loss: 0.6621473431587219\n",
      "Epoch 284, Loss: 2.0463646054267883, Final Batch Loss: 0.716697633266449\n",
      "Epoch 285, Loss: 2.0464083552360535, Final Batch Loss: 0.5760590434074402\n",
      "Epoch 286, Loss: 2.0436944365501404, Final Batch Loss: 0.6253153681755066\n",
      "Epoch 287, Loss: 2.0777206420898438, Final Batch Loss: 0.6186535954475403\n",
      "Epoch 288, Loss: 2.0432223081588745, Final Batch Loss: 0.5679700374603271\n",
      "Epoch 289, Loss: 2.0947155952453613, Final Batch Loss: 0.6817260980606079\n",
      "Epoch 290, Loss: 2.089626967906952, Final Batch Loss: 0.6843166351318359\n",
      "Epoch 291, Loss: 2.025430142879486, Final Batch Loss: 0.6893085837364197\n",
      "Epoch 292, Loss: 2.045437514781952, Final Batch Loss: 0.6464422345161438\n",
      "Epoch 293, Loss: 2.0094127655029297, Final Batch Loss: 0.6674725413322449\n",
      "Epoch 294, Loss: 2.1756160259246826, Final Batch Loss: 0.7314707636833191\n",
      "Epoch 295, Loss: 2.033272683620453, Final Batch Loss: 0.6909064650535583\n",
      "Epoch 296, Loss: 1.913731575012207, Final Batch Loss: 0.5823459029197693\n",
      "Epoch 297, Loss: 2.063730299472809, Final Batch Loss: 0.6356088519096375\n",
      "Epoch 298, Loss: 2.021951198577881, Final Batch Loss: 0.6797314286231995\n",
      "Epoch 299, Loss: 2.046701431274414, Final Batch Loss: 0.6667281985282898\n",
      "Epoch 300, Loss: 1.9897873401641846, Final Batch Loss: 0.6523028612136841\n",
      "Epoch 301, Loss: 2.1235817670822144, Final Batch Loss: 0.7412838339805603\n",
      "Epoch 302, Loss: 2.077618181705475, Final Batch Loss: 0.6743177175521851\n",
      "Epoch 303, Loss: 2.003120720386505, Final Batch Loss: 0.6400237679481506\n",
      "Epoch 304, Loss: 1.880401074886322, Final Batch Loss: 0.5377345681190491\n",
      "Epoch 305, Loss: 2.0150492191314697, Final Batch Loss: 0.6772273778915405\n",
      "Epoch 306, Loss: 2.0197998881340027, Final Batch Loss: 0.6868093013763428\n",
      "Epoch 307, Loss: 2.032410144805908, Final Batch Loss: 0.6488140225410461\n",
      "Epoch 308, Loss: 2.0942278504371643, Final Batch Loss: 0.6703956723213196\n",
      "Epoch 309, Loss: 2.073548436164856, Final Batch Loss: 0.6985790133476257\n",
      "Epoch 310, Loss: 1.9832791090011597, Final Batch Loss: 0.597375214099884\n",
      "Epoch 311, Loss: 1.9491808414459229, Final Batch Loss: 0.6589993238449097\n",
      "Epoch 312, Loss: 2.016973555088043, Final Batch Loss: 0.5955365300178528\n",
      "Epoch 313, Loss: 2.0649421215057373, Final Batch Loss: 0.7264609932899475\n",
      "Epoch 314, Loss: 1.9366256594657898, Final Batch Loss: 0.5905951857566833\n",
      "Epoch 315, Loss: 2.0219390988349915, Final Batch Loss: 0.6769413352012634\n",
      "Epoch 316, Loss: 1.9645480513572693, Final Batch Loss: 0.6466401219367981\n",
      "Epoch 317, Loss: 2.0648234486579895, Final Batch Loss: 0.6488513946533203\n",
      "Epoch 318, Loss: 2.103717565536499, Final Batch Loss: 0.7472283840179443\n",
      "Epoch 319, Loss: 1.971981704235077, Final Batch Loss: 0.6654793620109558\n",
      "Epoch 320, Loss: 1.9242296814918518, Final Batch Loss: 0.666820764541626\n",
      "Epoch 321, Loss: 2.0835044384002686, Final Batch Loss: 0.6594856381416321\n",
      "Epoch 322, Loss: 2.0188756585121155, Final Batch Loss: 0.6977382302284241\n",
      "Epoch 323, Loss: 2.0997071266174316, Final Batch Loss: 0.7285944223403931\n",
      "Epoch 324, Loss: 1.9110209345817566, Final Batch Loss: 0.6715425252914429\n",
      "Epoch 325, Loss: 1.9850731492042542, Final Batch Loss: 0.6588695049285889\n",
      "Epoch 326, Loss: 1.9291982054710388, Final Batch Loss: 0.6348769664764404\n",
      "Epoch 327, Loss: 2.009866714477539, Final Batch Loss: 0.6773515939712524\n",
      "Epoch 328, Loss: 1.9714300036430359, Final Batch Loss: 0.694735050201416\n",
      "Epoch 329, Loss: 1.955230176448822, Final Batch Loss: 0.6281001567840576\n",
      "Epoch 330, Loss: 1.9970169067382812, Final Batch Loss: 0.7178338170051575\n",
      "Epoch 331, Loss: 1.9408103823661804, Final Batch Loss: 0.5831535458564758\n",
      "Epoch 332, Loss: 1.9918019771575928, Final Batch Loss: 0.6825605034828186\n",
      "Epoch 333, Loss: 2.0702176690101624, Final Batch Loss: 0.6989688277244568\n",
      "Epoch 334, Loss: 2.1732949018478394, Final Batch Loss: 0.7902045249938965\n",
      "Epoch 335, Loss: 2.11456298828125, Final Batch Loss: 0.6899265050888062\n",
      "Epoch 336, Loss: 1.9790319204330444, Final Batch Loss: 0.6823232173919678\n",
      "Epoch 337, Loss: 2.027258574962616, Final Batch Loss: 0.7271918058395386\n",
      "Epoch 338, Loss: 2.0271087288856506, Final Batch Loss: 0.7047209739685059\n",
      "Epoch 339, Loss: 1.9845077991485596, Final Batch Loss: 0.691181480884552\n",
      "Epoch 340, Loss: 1.8792147636413574, Final Batch Loss: 0.5839157104492188\n",
      "Epoch 341, Loss: 1.8950121402740479, Final Batch Loss: 0.6312506794929504\n",
      "Epoch 342, Loss: 2.0409396290779114, Final Batch Loss: 0.6865024566650391\n",
      "Epoch 343, Loss: 1.923168420791626, Final Batch Loss: 0.5072322487831116\n",
      "Epoch 344, Loss: 1.939423143863678, Final Batch Loss: 0.6396149396896362\n",
      "Epoch 345, Loss: 1.9559144377708435, Final Batch Loss: 0.637667179107666\n",
      "Epoch 346, Loss: 1.9929792284965515, Final Batch Loss: 0.6950831413269043\n",
      "Epoch 347, Loss: 1.8648601770401, Final Batch Loss: 0.5996845960617065\n",
      "Epoch 348, Loss: 1.8417242765426636, Final Batch Loss: 0.5779526233673096\n",
      "Epoch 349, Loss: 1.920658528804779, Final Batch Loss: 0.6374990344047546\n",
      "Epoch 350, Loss: 1.865567922592163, Final Batch Loss: 0.5575734376907349\n",
      "Epoch 351, Loss: 1.9250769019126892, Final Batch Loss: 0.6416098475456238\n",
      "Epoch 352, Loss: 1.9344388246536255, Final Batch Loss: 0.6033018827438354\n",
      "Epoch 353, Loss: 1.7691866159439087, Final Batch Loss: 0.5536313652992249\n",
      "Epoch 354, Loss: 1.9169462323188782, Final Batch Loss: 0.616057276725769\n",
      "Epoch 355, Loss: 1.8867576122283936, Final Batch Loss: 0.626001238822937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356, Loss: 2.008184552192688, Final Batch Loss: 0.7065636515617371\n",
      "Epoch 357, Loss: 2.0276641249656677, Final Batch Loss: 0.6842998266220093\n",
      "Epoch 358, Loss: 1.9321308732032776, Final Batch Loss: 0.6797393560409546\n",
      "Epoch 359, Loss: 1.9239376783370972, Final Batch Loss: 0.6693888902664185\n",
      "Epoch 360, Loss: 1.9585251212120056, Final Batch Loss: 0.7179808616638184\n",
      "Epoch 361, Loss: 1.913045048713684, Final Batch Loss: 0.6566598415374756\n",
      "Epoch 362, Loss: 1.844868242740631, Final Batch Loss: 0.6293975710868835\n",
      "Epoch 363, Loss: 1.8440181612968445, Final Batch Loss: 0.5888350009918213\n",
      "Epoch 364, Loss: 1.9047794938087463, Final Batch Loss: 0.6366846561431885\n",
      "Epoch 365, Loss: 1.8104463815689087, Final Batch Loss: 0.5458212494850159\n",
      "Epoch 366, Loss: 1.9317023158073425, Final Batch Loss: 0.6350725889205933\n",
      "Epoch 367, Loss: 1.9010189175605774, Final Batch Loss: 0.6182428598403931\n",
      "Epoch 368, Loss: 1.913204550743103, Final Batch Loss: 0.5714969635009766\n",
      "Epoch 369, Loss: 1.919134497642517, Final Batch Loss: 0.6274283528327942\n",
      "Epoch 370, Loss: 1.8551966547966003, Final Batch Loss: 0.5848889946937561\n",
      "Epoch 371, Loss: 1.8960295915603638, Final Batch Loss: 0.676651120185852\n",
      "Epoch 372, Loss: 1.9918354153633118, Final Batch Loss: 0.7047974467277527\n",
      "Epoch 373, Loss: 1.915884554386139, Final Batch Loss: 0.6375049352645874\n",
      "Epoch 374, Loss: 1.7754679322242737, Final Batch Loss: 0.5938709378242493\n",
      "Epoch 375, Loss: 1.907945454120636, Final Batch Loss: 0.6566034555435181\n",
      "Epoch 376, Loss: 1.8516842722892761, Final Batch Loss: 0.6371457576751709\n",
      "Epoch 377, Loss: 1.8460408449172974, Final Batch Loss: 0.5512223243713379\n",
      "Epoch 378, Loss: 1.8656501770019531, Final Batch Loss: 0.6456111073493958\n",
      "Epoch 379, Loss: 1.9340131282806396, Final Batch Loss: 0.7188047170639038\n",
      "Epoch 380, Loss: 1.900660753250122, Final Batch Loss: 0.6238903403282166\n",
      "Epoch 381, Loss: 1.821847379207611, Final Batch Loss: 0.6109735369682312\n",
      "Epoch 382, Loss: 1.8581590056419373, Final Batch Loss: 0.6049844026565552\n",
      "Epoch 383, Loss: 1.850731372833252, Final Batch Loss: 0.6012779474258423\n",
      "Epoch 384, Loss: 1.8413543105125427, Final Batch Loss: 0.6293631792068481\n",
      "Epoch 385, Loss: 1.7423320412635803, Final Batch Loss: 0.5981047749519348\n",
      "Epoch 386, Loss: 1.8931178450584412, Final Batch Loss: 0.6229166984558105\n",
      "Epoch 387, Loss: 1.829864263534546, Final Batch Loss: 0.5942354798316956\n",
      "Epoch 388, Loss: 1.8421257734298706, Final Batch Loss: 0.5965631008148193\n",
      "Epoch 389, Loss: 2.045489490032196, Final Batch Loss: 0.7658413648605347\n",
      "Epoch 390, Loss: 1.877812683582306, Final Batch Loss: 0.7441259622573853\n",
      "Epoch 391, Loss: 1.8343983888626099, Final Batch Loss: 0.6611021161079407\n",
      "Epoch 392, Loss: 1.8538613319396973, Final Batch Loss: 0.589902937412262\n",
      "Epoch 393, Loss: 1.912921130657196, Final Batch Loss: 0.7073419690132141\n",
      "Epoch 394, Loss: 1.8682487607002258, Final Batch Loss: 0.6272807717323303\n",
      "Epoch 395, Loss: 1.7142724990844727, Final Batch Loss: 0.5839434266090393\n",
      "Epoch 396, Loss: 1.8582828640937805, Final Batch Loss: 0.6468493938446045\n",
      "Epoch 397, Loss: 1.7994217276573181, Final Batch Loss: 0.6012036204338074\n",
      "Epoch 398, Loss: 1.821704089641571, Final Batch Loss: 0.5882111191749573\n",
      "Epoch 399, Loss: 1.7572811245918274, Final Batch Loss: 0.5346142053604126\n",
      "Epoch 400, Loss: 1.7378259897232056, Final Batch Loss: 0.5813180804252625\n",
      "Epoch 401, Loss: 1.7838926911354065, Final Batch Loss: 0.6476551294326782\n",
      "Epoch 402, Loss: 1.7990403771400452, Final Batch Loss: 0.6035546660423279\n",
      "Epoch 403, Loss: 1.9008296728134155, Final Batch Loss: 0.6298671960830688\n",
      "Epoch 404, Loss: 1.7863041162490845, Final Batch Loss: 0.550330400466919\n",
      "Epoch 405, Loss: 1.7353883385658264, Final Batch Loss: 0.5087982416152954\n",
      "Epoch 406, Loss: 1.825452208518982, Final Batch Loss: 0.5782724618911743\n",
      "Epoch 407, Loss: 1.7568095326423645, Final Batch Loss: 0.5908909440040588\n",
      "Epoch 408, Loss: 1.9048559069633484, Final Batch Loss: 0.6156762838363647\n",
      "Epoch 409, Loss: 1.837492287158966, Final Batch Loss: 0.6320961713790894\n",
      "Epoch 410, Loss: 1.7595301866531372, Final Batch Loss: 0.610098123550415\n",
      "Epoch 411, Loss: 1.850819706916809, Final Batch Loss: 0.6545990109443665\n",
      "Epoch 412, Loss: 1.7992274761199951, Final Batch Loss: 0.6295409798622131\n",
      "Epoch 413, Loss: 1.8515838384628296, Final Batch Loss: 0.6124138236045837\n",
      "Epoch 414, Loss: 1.72517728805542, Final Batch Loss: 0.563766598701477\n",
      "Epoch 415, Loss: 1.7956998944282532, Final Batch Loss: 0.6321390271186829\n",
      "Epoch 416, Loss: 1.7584193348884583, Final Batch Loss: 0.6146063804626465\n",
      "Epoch 417, Loss: 1.8328064680099487, Final Batch Loss: 0.5987396240234375\n",
      "Epoch 418, Loss: 1.752644121646881, Final Batch Loss: 0.5982378721237183\n",
      "Epoch 419, Loss: 1.735599935054779, Final Batch Loss: 0.5756803154945374\n",
      "Epoch 420, Loss: 1.7063140869140625, Final Batch Loss: 0.5938063263893127\n",
      "Epoch 421, Loss: 1.7643170356750488, Final Batch Loss: 0.5847745537757874\n",
      "Epoch 422, Loss: 1.734531581401825, Final Batch Loss: 0.5650662183761597\n",
      "Epoch 423, Loss: 1.7794950604438782, Final Batch Loss: 0.6218671202659607\n",
      "Epoch 424, Loss: 1.8073036074638367, Final Batch Loss: 0.6264476776123047\n",
      "Epoch 425, Loss: 1.7593165636062622, Final Batch Loss: 0.5919238924980164\n",
      "Epoch 426, Loss: 1.7828317284584045, Final Batch Loss: 0.6132157444953918\n",
      "Epoch 427, Loss: 1.7159279882907867, Final Batch Loss: 0.48246118426322937\n",
      "Epoch 428, Loss: 1.8469637036323547, Final Batch Loss: 0.6292691230773926\n",
      "Epoch 429, Loss: 1.8401475548744202, Final Batch Loss: 0.6073337197303772\n",
      "Epoch 430, Loss: 1.788774013519287, Final Batch Loss: 0.626214861869812\n",
      "Epoch 431, Loss: 1.636123150587082, Final Batch Loss: 0.4546225368976593\n",
      "Epoch 432, Loss: 1.7540249228477478, Final Batch Loss: 0.5873109102249146\n",
      "Epoch 433, Loss: 1.727624237537384, Final Batch Loss: 0.5715622305870056\n",
      "Epoch 434, Loss: 1.734388530254364, Final Batch Loss: 0.5635966062545776\n",
      "Epoch 435, Loss: 1.7245216369628906, Final Batch Loss: 0.5785103440284729\n",
      "Epoch 436, Loss: 1.800391137599945, Final Batch Loss: 0.5460848212242126\n",
      "Epoch 437, Loss: 1.6533052325248718, Final Batch Loss: 0.5376670360565186\n",
      "Epoch 438, Loss: 1.8113839030265808, Final Batch Loss: 0.6085579991340637\n",
      "Epoch 439, Loss: 1.7669199109077454, Final Batch Loss: 0.608457088470459\n",
      "Epoch 440, Loss: 1.7660229206085205, Final Batch Loss: 0.5455819964408875\n",
      "Epoch 441, Loss: 1.7872000336647034, Final Batch Loss: 0.6586900353431702\n",
      "Epoch 442, Loss: 1.7802821397781372, Final Batch Loss: 0.5957467555999756\n",
      "Epoch 443, Loss: 1.7419938445091248, Final Batch Loss: 0.5925769209861755\n",
      "Epoch 444, Loss: 1.719020962715149, Final Batch Loss: 0.5851404666900635\n",
      "Epoch 445, Loss: 1.6951324939727783, Final Batch Loss: 0.5623775124549866\n",
      "Epoch 446, Loss: 1.7577481269836426, Final Batch Loss: 0.5827428698539734\n",
      "Epoch 447, Loss: 1.715390920639038, Final Batch Loss: 0.5629037618637085\n",
      "Epoch 448, Loss: 1.7906742691993713, Final Batch Loss: 0.6354221105575562\n",
      "Epoch 449, Loss: 1.7453734278678894, Final Batch Loss: 0.6171654462814331\n",
      "Epoch 450, Loss: 1.6742019653320312, Final Batch Loss: 0.5299898982048035\n",
      "Epoch 451, Loss: 1.7949846982955933, Final Batch Loss: 0.5750367045402527\n",
      "Epoch 452, Loss: 1.6708475649356842, Final Batch Loss: 0.46855512261390686\n",
      "Epoch 453, Loss: 1.7264602780342102, Final Batch Loss: 0.6167718172073364\n",
      "Epoch 454, Loss: 1.7597118616104126, Final Batch Loss: 0.6055640578269958\n",
      "Epoch 455, Loss: 1.7260580658912659, Final Batch Loss: 0.5566686987876892\n",
      "Epoch 456, Loss: 1.6699210405349731, Final Batch Loss: 0.5313066244125366\n",
      "Epoch 457, Loss: 1.6637358665466309, Final Batch Loss: 0.5066977143287659\n",
      "Epoch 458, Loss: 1.6487271785736084, Final Batch Loss: 0.5650740265846252\n",
      "Epoch 459, Loss: 1.6590021550655365, Final Batch Loss: 0.4773026406764984\n",
      "Epoch 460, Loss: 1.6406834721565247, Final Batch Loss: 0.5060613751411438\n",
      "Epoch 461, Loss: 1.7649640440940857, Final Batch Loss: 0.6276498436927795\n",
      "Epoch 462, Loss: 1.6777385473251343, Final Batch Loss: 0.5266293883323669\n",
      "Epoch 463, Loss: 1.7161786556243896, Final Batch Loss: 0.597449004650116\n",
      "Epoch 464, Loss: 1.7427054047584534, Final Batch Loss: 0.5857363939285278\n",
      "Epoch 465, Loss: 1.61300927400589, Final Batch Loss: 0.5040560364723206\n",
      "Epoch 466, Loss: 1.573545902967453, Final Batch Loss: 0.47959771752357483\n",
      "Epoch 467, Loss: 1.5665758848190308, Final Batch Loss: 0.4845678508281708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468, Loss: 1.7182719111442566, Final Batch Loss: 0.5587525367736816\n",
      "Epoch 469, Loss: 1.6893838047981262, Final Batch Loss: 0.5710378289222717\n",
      "Epoch 470, Loss: 1.6810516119003296, Final Batch Loss: 0.6180922389030457\n",
      "Epoch 471, Loss: 1.6723129749298096, Final Batch Loss: 0.5546655058860779\n",
      "Epoch 472, Loss: 1.6261698007583618, Final Batch Loss: 0.5382681488990784\n",
      "Epoch 473, Loss: 1.7262502312660217, Final Batch Loss: 0.5835670232772827\n",
      "Epoch 474, Loss: 1.7777738571166992, Final Batch Loss: 0.6432754993438721\n",
      "Epoch 475, Loss: 1.582400619983673, Final Batch Loss: 0.4735668897628784\n",
      "Epoch 476, Loss: 1.6934038400650024, Final Batch Loss: 0.5529405474662781\n",
      "Epoch 477, Loss: 1.6804919838905334, Final Batch Loss: 0.6366568803787231\n",
      "Epoch 478, Loss: 1.6948765516281128, Final Batch Loss: 0.5348029136657715\n",
      "Epoch 479, Loss: 1.7063970565795898, Final Batch Loss: 0.5912700891494751\n",
      "Epoch 480, Loss: 1.6820008754730225, Final Batch Loss: 0.60968416929245\n",
      "Epoch 481, Loss: 1.8350696563720703, Final Batch Loss: 0.7041046023368835\n",
      "Epoch 482, Loss: 1.6910439133644104, Final Batch Loss: 0.5674673914909363\n",
      "Epoch 483, Loss: 1.6438190937042236, Final Batch Loss: 0.5379937291145325\n",
      "Epoch 484, Loss: 1.6588395833969116, Final Batch Loss: 0.5103905200958252\n",
      "Epoch 485, Loss: 1.643202006816864, Final Batch Loss: 0.4846544861793518\n",
      "Epoch 486, Loss: 1.639419674873352, Final Batch Loss: 0.5227001905441284\n",
      "Epoch 487, Loss: 1.689024806022644, Final Batch Loss: 0.624951183795929\n",
      "Epoch 488, Loss: 1.715375006198883, Final Batch Loss: 0.5784329771995544\n",
      "Epoch 489, Loss: 1.6760931611061096, Final Batch Loss: 0.5618944764137268\n",
      "Epoch 490, Loss: 1.5923280715942383, Final Batch Loss: 0.5188033580780029\n",
      "Epoch 491, Loss: 1.6316888332366943, Final Batch Loss: 0.5263746380805969\n",
      "Epoch 492, Loss: 1.6521039605140686, Final Batch Loss: 0.5094135999679565\n",
      "Epoch 493, Loss: 1.5049998760223389, Final Batch Loss: 0.4557412266731262\n",
      "Epoch 494, Loss: 1.7129334211349487, Final Batch Loss: 0.5762292146682739\n",
      "Epoch 495, Loss: 1.7066158652305603, Final Batch Loss: 0.6383857727050781\n",
      "Epoch 496, Loss: 1.7003273367881775, Final Batch Loss: 0.6089144349098206\n",
      "Epoch 497, Loss: 1.5969942510128021, Final Batch Loss: 0.5515370965003967\n",
      "Epoch 498, Loss: 1.5765965282917023, Final Batch Loss: 0.49053266644477844\n",
      "Epoch 499, Loss: 1.6135995984077454, Final Batch Loss: 0.5604982972145081\n",
      "Epoch 500, Loss: 1.5706726908683777, Final Batch Loss: 0.4878843426704407\n",
      "Epoch 501, Loss: 1.558664083480835, Final Batch Loss: 0.5038777589797974\n",
      "Epoch 502, Loss: 1.7078424096107483, Final Batch Loss: 0.5565919280052185\n",
      "Epoch 503, Loss: 1.5854986906051636, Final Batch Loss: 0.47443926334381104\n",
      "Epoch 504, Loss: 1.6393752992153168, Final Batch Loss: 0.5686624646186829\n",
      "Epoch 505, Loss: 1.603200912475586, Final Batch Loss: 0.5652838945388794\n",
      "Epoch 506, Loss: 1.5914683938026428, Final Batch Loss: 0.5160267949104309\n",
      "Epoch 507, Loss: 1.5845153331756592, Final Batch Loss: 0.6376540660858154\n",
      "Epoch 508, Loss: 1.6182069182395935, Final Batch Loss: 0.5394741892814636\n",
      "Epoch 509, Loss: 1.5822663605213165, Final Batch Loss: 0.4705345332622528\n",
      "Epoch 510, Loss: 1.6997020840644836, Final Batch Loss: 0.5770182013511658\n",
      "Epoch 511, Loss: 1.6540105938911438, Final Batch Loss: 0.5659358501434326\n",
      "Epoch 512, Loss: 1.5361497402191162, Final Batch Loss: 0.45492756366729736\n",
      "Epoch 513, Loss: 1.6167889833450317, Final Batch Loss: 0.553312361240387\n",
      "Epoch 514, Loss: 1.5354661643505096, Final Batch Loss: 0.5047190189361572\n",
      "Epoch 515, Loss: 1.660302221775055, Final Batch Loss: 0.5509602427482605\n",
      "Epoch 516, Loss: 1.6101949214935303, Final Batch Loss: 0.5757463574409485\n",
      "Epoch 517, Loss: 1.5289885103702545, Final Batch Loss: 0.5067352056503296\n",
      "Epoch 518, Loss: 1.5430243611335754, Final Batch Loss: 0.48537278175354004\n",
      "Epoch 519, Loss: 1.6392017602920532, Final Batch Loss: 0.5307406783103943\n",
      "Epoch 520, Loss: 1.4774916470050812, Final Batch Loss: 0.45002540946006775\n",
      "Epoch 521, Loss: 1.631991446018219, Final Batch Loss: 0.5219709277153015\n",
      "Epoch 522, Loss: 1.6902239322662354, Final Batch Loss: 0.5715586543083191\n",
      "Epoch 523, Loss: 1.5580712258815765, Final Batch Loss: 0.5324070453643799\n",
      "Epoch 524, Loss: 1.5094446539878845, Final Batch Loss: 0.4603828191757202\n",
      "Epoch 525, Loss: 1.5361906588077545, Final Batch Loss: 0.5506269931793213\n",
      "Epoch 526, Loss: 1.6246004700660706, Final Batch Loss: 0.5591089725494385\n",
      "Epoch 527, Loss: 1.6309494376182556, Final Batch Loss: 0.5196018218994141\n",
      "Epoch 528, Loss: 1.5428180396556854, Final Batch Loss: 0.529242217540741\n",
      "Epoch 529, Loss: 1.5650764107704163, Final Batch Loss: 0.5374640226364136\n",
      "Epoch 530, Loss: 1.7151358723640442, Final Batch Loss: 0.6895186901092529\n",
      "Epoch 531, Loss: 1.6066678762435913, Final Batch Loss: 0.5199741721153259\n",
      "Epoch 532, Loss: 1.5800018012523651, Final Batch Loss: 0.5294852256774902\n",
      "Epoch 533, Loss: 1.5730109214782715, Final Batch Loss: 0.5613571405410767\n",
      "Epoch 534, Loss: 1.6185991764068604, Final Batch Loss: 0.5338987708091736\n",
      "Epoch 535, Loss: 1.5640121102333069, Final Batch Loss: 0.5709220767021179\n",
      "Epoch 536, Loss: 1.6096750497817993, Final Batch Loss: 0.4974123239517212\n",
      "Epoch 537, Loss: 1.6033210456371307, Final Batch Loss: 0.5720303058624268\n",
      "Epoch 538, Loss: 1.6356919407844543, Final Batch Loss: 0.6064010262489319\n",
      "Epoch 539, Loss: 1.4986104667186737, Final Batch Loss: 0.485772043466568\n",
      "Epoch 540, Loss: 1.5127469897270203, Final Batch Loss: 0.4811541736125946\n",
      "Epoch 541, Loss: 1.5858217477798462, Final Batch Loss: 0.5506032705307007\n",
      "Epoch 542, Loss: 1.5527384877204895, Final Batch Loss: 0.5111557245254517\n",
      "Epoch 543, Loss: 1.5805529356002808, Final Batch Loss: 0.5643753409385681\n",
      "Epoch 544, Loss: 1.5000613927841187, Final Batch Loss: 0.5272974371910095\n",
      "Epoch 545, Loss: 1.5753700733184814, Final Batch Loss: 0.5139374732971191\n",
      "Epoch 546, Loss: 1.486522614955902, Final Batch Loss: 0.5049164891242981\n",
      "Epoch 547, Loss: 1.667423278093338, Final Batch Loss: 0.6573585271835327\n",
      "Epoch 548, Loss: 1.5595164597034454, Final Batch Loss: 0.58559250831604\n",
      "Epoch 549, Loss: 1.554938554763794, Final Batch Loss: 0.520224392414093\n",
      "Epoch 550, Loss: 1.6226753890514374, Final Batch Loss: 0.6141417622566223\n",
      "Epoch 551, Loss: 1.6178129017353058, Final Batch Loss: 0.5352880358695984\n",
      "Epoch 552, Loss: 1.5587932765483856, Final Batch Loss: 0.5037782788276672\n",
      "Epoch 553, Loss: 1.5218207836151123, Final Batch Loss: 0.4796984791755676\n",
      "Epoch 554, Loss: 1.5800893306732178, Final Batch Loss: 0.4340192675590515\n",
      "Epoch 555, Loss: 1.5802108347415924, Final Batch Loss: 0.5680651068687439\n",
      "Epoch 556, Loss: 1.5981344282627106, Final Batch Loss: 0.5594176054000854\n",
      "Epoch 557, Loss: 1.565099060535431, Final Batch Loss: 0.5306797027587891\n",
      "Epoch 558, Loss: 1.5303435325622559, Final Batch Loss: 0.5405689477920532\n",
      "Epoch 559, Loss: 1.4905784130096436, Final Batch Loss: 0.5406762361526489\n",
      "Epoch 560, Loss: 1.5155583322048187, Final Batch Loss: 0.513732373714447\n",
      "Epoch 561, Loss: 1.5211504101753235, Final Batch Loss: 0.5132572650909424\n",
      "Epoch 562, Loss: 1.5095368325710297, Final Batch Loss: 0.4664917290210724\n",
      "Epoch 563, Loss: 1.5214718282222748, Final Batch Loss: 0.518460750579834\n",
      "Epoch 564, Loss: 1.5098397433757782, Final Batch Loss: 0.5213266611099243\n",
      "Epoch 565, Loss: 1.661906123161316, Final Batch Loss: 0.5087394118309021\n",
      "Epoch 566, Loss: 1.5736718773841858, Final Batch Loss: 0.5838350653648376\n",
      "Epoch 567, Loss: 1.4644106924533844, Final Batch Loss: 0.4776974022388458\n",
      "Epoch 568, Loss: 1.497977763414383, Final Batch Loss: 0.42152199149131775\n",
      "Epoch 569, Loss: 1.4920322895050049, Final Batch Loss: 0.5317482352256775\n",
      "Epoch 570, Loss: 1.494345784187317, Final Batch Loss: 0.4936220049858093\n",
      "Epoch 571, Loss: 1.4878462553024292, Final Batch Loss: 0.5239049792289734\n",
      "Epoch 572, Loss: 1.4854179322719574, Final Batch Loss: 0.4682893455028534\n",
      "Epoch 573, Loss: 1.3929583728313446, Final Batch Loss: 0.5051723718643188\n",
      "Epoch 574, Loss: 1.5622086822986603, Final Batch Loss: 0.5828238129615784\n",
      "Epoch 575, Loss: 1.5867001414299011, Final Batch Loss: 0.6290114521980286\n",
      "Epoch 576, Loss: 1.3757816553115845, Final Batch Loss: 0.4131307899951935\n",
      "Epoch 577, Loss: 1.4709160029888153, Final Batch Loss: 0.44128456711769104\n",
      "Epoch 578, Loss: 1.506220430135727, Final Batch Loss: 0.4935539662837982\n",
      "Epoch 579, Loss: 1.5611883997917175, Final Batch Loss: 0.5049125552177429\n",
      "Epoch 580, Loss: 1.398694783449173, Final Batch Loss: 0.41102686524391174\n",
      "Epoch 581, Loss: 1.473588764667511, Final Batch Loss: 0.45564666390419006\n",
      "Epoch 582, Loss: 1.5702194273471832, Final Batch Loss: 0.6127829551696777\n",
      "Epoch 583, Loss: 1.492354929447174, Final Batch Loss: 0.47944363951683044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 584, Loss: 1.5387628674507141, Final Batch Loss: 0.5560010075569153\n",
      "Epoch 585, Loss: 1.629539132118225, Final Batch Loss: 0.5784626603126526\n",
      "Epoch 586, Loss: 1.531347393989563, Final Batch Loss: 0.4489745497703552\n",
      "Epoch 587, Loss: 1.5107180178165436, Final Batch Loss: 0.6044085025787354\n",
      "Epoch 588, Loss: 1.5022199153900146, Final Batch Loss: 0.5488395094871521\n",
      "Epoch 589, Loss: 1.4865348637104034, Final Batch Loss: 0.4741832911968231\n",
      "Epoch 590, Loss: 1.470547080039978, Final Batch Loss: 0.4309541583061218\n",
      "Epoch 591, Loss: 1.4147456586360931, Final Batch Loss: 0.4520549178123474\n",
      "Epoch 592, Loss: 1.4862683713436127, Final Batch Loss: 0.46486160159111023\n",
      "Epoch 593, Loss: 1.5472756922245026, Final Batch Loss: 0.5244698524475098\n",
      "Epoch 594, Loss: 1.4260532855987549, Final Batch Loss: 0.44121357798576355\n",
      "Epoch 595, Loss: 1.4690822064876556, Final Batch Loss: 0.4481867849826813\n",
      "Epoch 596, Loss: 1.3687477707862854, Final Batch Loss: 0.44696611166000366\n",
      "Epoch 597, Loss: 1.3538885712623596, Final Batch Loss: 0.3930937349796295\n",
      "Epoch 598, Loss: 1.4750171899795532, Final Batch Loss: 0.6228340268135071\n",
      "Epoch 599, Loss: 1.430312156677246, Final Batch Loss: 0.4428785741329193\n",
      "Epoch 600, Loss: 1.3862201571464539, Final Batch Loss: 0.4827156662940979\n",
      "Epoch 601, Loss: 1.4584171175956726, Final Batch Loss: 0.4371839165687561\n",
      "Epoch 602, Loss: 1.4322013556957245, Final Batch Loss: 0.41085800528526306\n",
      "Epoch 603, Loss: 1.5104597210884094, Final Batch Loss: 0.5145860910415649\n",
      "Epoch 604, Loss: 1.524183601140976, Final Batch Loss: 0.5725911855697632\n",
      "Epoch 605, Loss: 1.367714673280716, Final Batch Loss: 0.4372771084308624\n",
      "Epoch 606, Loss: 1.378415822982788, Final Batch Loss: 0.4136353135108948\n",
      "Epoch 607, Loss: 1.5286118388175964, Final Batch Loss: 0.5383859872817993\n",
      "Epoch 608, Loss: 1.4478745758533478, Final Batch Loss: 0.44714978337287903\n",
      "Epoch 609, Loss: 1.4846971035003662, Final Batch Loss: 0.5183443427085876\n",
      "Epoch 610, Loss: 1.571800172328949, Final Batch Loss: 0.6171221137046814\n",
      "Epoch 611, Loss: 1.443008691072464, Final Batch Loss: 0.4945422410964966\n",
      "Epoch 612, Loss: 1.452301800251007, Final Batch Loss: 0.48356014490127563\n",
      "Epoch 613, Loss: 1.4209114015102386, Final Batch Loss: 0.43041786551475525\n",
      "Epoch 614, Loss: 1.4307760894298553, Final Batch Loss: 0.4209860861301422\n",
      "Epoch 615, Loss: 1.4622405767440796, Final Batch Loss: 0.5304046273231506\n",
      "Epoch 616, Loss: 1.4909400343894958, Final Batch Loss: 0.48975124955177307\n",
      "Epoch 617, Loss: 1.4456765949726105, Final Batch Loss: 0.4464690387248993\n",
      "Epoch 618, Loss: 1.3493449687957764, Final Batch Loss: 0.41441982984542847\n",
      "Epoch 619, Loss: 1.4457513689994812, Final Batch Loss: 0.4423290491104126\n",
      "Epoch 620, Loss: 1.547223150730133, Final Batch Loss: 0.5031028985977173\n",
      "Epoch 621, Loss: 1.4135373532772064, Final Batch Loss: 0.37422484159469604\n",
      "Epoch 622, Loss: 1.483158826828003, Final Batch Loss: 0.48362475633621216\n",
      "Epoch 623, Loss: 1.3183664977550507, Final Batch Loss: 0.3478904068470001\n",
      "Epoch 624, Loss: 1.3733395338058472, Final Batch Loss: 0.36441510915756226\n",
      "Epoch 625, Loss: 1.4052387177944183, Final Batch Loss: 0.4258071482181549\n",
      "Epoch 626, Loss: 1.4100372195243835, Final Batch Loss: 0.46136677265167236\n",
      "Epoch 627, Loss: 1.3498616814613342, Final Batch Loss: 0.39389222860336304\n",
      "Epoch 628, Loss: 1.545329213142395, Final Batch Loss: 0.5832069516181946\n",
      "Epoch 629, Loss: 1.5204180777072906, Final Batch Loss: 0.6325877904891968\n",
      "Epoch 630, Loss: 1.3984166085720062, Final Batch Loss: 0.4359988272190094\n",
      "Epoch 631, Loss: 1.4121560156345367, Final Batch Loss: 0.4786529839038849\n",
      "Epoch 632, Loss: 1.447592705488205, Final Batch Loss: 0.40994229912757874\n",
      "Epoch 633, Loss: 1.4061014354228973, Final Batch Loss: 0.44255053997039795\n",
      "Epoch 634, Loss: 1.4066134691238403, Final Batch Loss: 0.45072537660598755\n",
      "Epoch 635, Loss: 1.4470749199390411, Final Batch Loss: 0.4868432581424713\n",
      "Epoch 636, Loss: 1.3685880899429321, Final Batch Loss: 0.4462467133998871\n",
      "Epoch 637, Loss: 1.4491226375102997, Final Batch Loss: 0.45572006702423096\n",
      "Epoch 638, Loss: 1.4376406073570251, Final Batch Loss: 0.45938748121261597\n",
      "Epoch 639, Loss: 1.351347655057907, Final Batch Loss: 0.4339253306388855\n",
      "Epoch 640, Loss: 1.4241030812263489, Final Batch Loss: 0.5008320212364197\n",
      "Epoch 641, Loss: 1.4338366091251373, Final Batch Loss: 0.506432831287384\n",
      "Epoch 642, Loss: 1.385326862335205, Final Batch Loss: 0.4527706205844879\n",
      "Epoch 643, Loss: 1.3875084817409515, Final Batch Loss: 0.4493952691555023\n",
      "Epoch 644, Loss: 1.4147811830043793, Final Batch Loss: 0.4328298568725586\n",
      "Epoch 645, Loss: 1.38687863945961, Final Batch Loss: 0.4745570421218872\n",
      "Epoch 646, Loss: 1.3953256011009216, Final Batch Loss: 0.44283193349838257\n",
      "Epoch 647, Loss: 1.3770522475242615, Final Batch Loss: 0.4377537667751312\n",
      "Epoch 648, Loss: 1.4220331013202667, Final Batch Loss: 0.4812089502811432\n",
      "Epoch 649, Loss: 1.5277741253376007, Final Batch Loss: 0.5229681730270386\n",
      "Epoch 650, Loss: 1.3323971629142761, Final Batch Loss: 0.3943636417388916\n",
      "Epoch 651, Loss: 1.531583696603775, Final Batch Loss: 0.5560271739959717\n",
      "Epoch 652, Loss: 1.5124526023864746, Final Batch Loss: 0.5832616090774536\n",
      "Epoch 653, Loss: 1.4969171285629272, Final Batch Loss: 0.5648130774497986\n",
      "Epoch 654, Loss: 1.400047242641449, Final Batch Loss: 0.4713963568210602\n",
      "Epoch 655, Loss: 1.4099386930465698, Final Batch Loss: 0.44857457280158997\n",
      "Epoch 656, Loss: 1.4265602827072144, Final Batch Loss: 0.4814687967300415\n",
      "Epoch 657, Loss: 1.3291907012462616, Final Batch Loss: 0.38330498337745667\n",
      "Epoch 658, Loss: 1.369642972946167, Final Batch Loss: 0.38922119140625\n",
      "Epoch 659, Loss: 1.4111316800117493, Final Batch Loss: 0.44705280661582947\n",
      "Epoch 660, Loss: 1.3522339165210724, Final Batch Loss: 0.4765779674053192\n",
      "Epoch 661, Loss: 1.3111482560634613, Final Batch Loss: 0.42586103081703186\n",
      "Epoch 662, Loss: 1.4077375531196594, Final Batch Loss: 0.43441691994667053\n",
      "Epoch 663, Loss: 1.4229525327682495, Final Batch Loss: 0.4813198745250702\n",
      "Epoch 664, Loss: 1.4244426786899567, Final Batch Loss: 0.4954019784927368\n",
      "Epoch 665, Loss: 1.4152500331401825, Final Batch Loss: 0.4568338692188263\n",
      "Epoch 666, Loss: 1.33951136469841, Final Batch Loss: 0.46016713976860046\n",
      "Epoch 667, Loss: 1.4053420424461365, Final Batch Loss: 0.475776344537735\n",
      "Epoch 668, Loss: 1.4116759896278381, Final Batch Loss: 0.4134274423122406\n",
      "Epoch 669, Loss: 1.4416747093200684, Final Batch Loss: 0.5437988042831421\n",
      "Epoch 670, Loss: 1.3772509098052979, Final Batch Loss: 0.4302324652671814\n",
      "Epoch 671, Loss: 1.4453954696655273, Final Batch Loss: 0.517133355140686\n",
      "Epoch 672, Loss: 1.4055730700492859, Final Batch Loss: 0.4573422074317932\n",
      "Epoch 673, Loss: 1.3676258325576782, Final Batch Loss: 0.4030570089817047\n",
      "Epoch 674, Loss: 1.4204879403114319, Final Batch Loss: 0.4713601768016815\n",
      "Epoch 675, Loss: 1.293875902891159, Final Batch Loss: 0.45165055990219116\n",
      "Epoch 676, Loss: 1.3427797555923462, Final Batch Loss: 0.46771255135536194\n",
      "Epoch 677, Loss: 1.423327088356018, Final Batch Loss: 0.4827767610549927\n",
      "Epoch 678, Loss: 1.3966006934642792, Final Batch Loss: 0.5010607838630676\n",
      "Epoch 679, Loss: 1.3834092617034912, Final Batch Loss: 0.40274640917778015\n",
      "Epoch 680, Loss: 1.3847785592079163, Final Batch Loss: 0.4047500789165497\n",
      "Epoch 681, Loss: 1.3602145314216614, Final Batch Loss: 0.45899927616119385\n",
      "Epoch 682, Loss: 1.476192146539688, Final Batch Loss: 0.49344345927238464\n",
      "Epoch 683, Loss: 1.3808051645755768, Final Batch Loss: 0.4310370087623596\n",
      "Epoch 684, Loss: 1.3466259837150574, Final Batch Loss: 0.3880700170993805\n",
      "Epoch 685, Loss: 1.2891461849212646, Final Batch Loss: 0.3869613707065582\n",
      "Epoch 686, Loss: 1.3801566362380981, Final Batch Loss: 0.41253364086151123\n",
      "Epoch 687, Loss: 1.3828838467597961, Final Batch Loss: 0.495929092168808\n",
      "Epoch 688, Loss: 1.360106348991394, Final Batch Loss: 0.4310499131679535\n",
      "Epoch 689, Loss: 1.346368283033371, Final Batch Loss: 0.3971477448940277\n",
      "Epoch 690, Loss: 1.3886289596557617, Final Batch Loss: 0.3957364857196808\n",
      "Epoch 691, Loss: 1.3397753238677979, Final Batch Loss: 0.4165927469730377\n",
      "Epoch 692, Loss: 1.356618970632553, Final Batch Loss: 0.4576931893825531\n",
      "Epoch 693, Loss: 1.4752513468265533, Final Batch Loss: 0.6076490879058838\n",
      "Epoch 694, Loss: 1.3221673965454102, Final Batch Loss: 0.4000215530395508\n",
      "Epoch 695, Loss: 1.297858327627182, Final Batch Loss: 0.3865572214126587\n",
      "Epoch 696, Loss: 1.310076743364334, Final Batch Loss: 0.5163979530334473\n",
      "Epoch 697, Loss: 1.2938613891601562, Final Batch Loss: 0.44744640588760376\n",
      "Epoch 698, Loss: 1.4686911404132843, Final Batch Loss: 0.5232363343238831\n",
      "Epoch 699, Loss: 1.2553503811359406, Final Batch Loss: 0.42389991879463196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 700, Loss: 1.430153876543045, Final Batch Loss: 0.4422585368156433\n",
      "Epoch 701, Loss: 1.3652132451534271, Final Batch Loss: 0.47666695713996887\n",
      "Epoch 702, Loss: 1.344236820936203, Final Batch Loss: 0.49505048990249634\n",
      "Epoch 703, Loss: 1.2998444139957428, Final Batch Loss: 0.3795081079006195\n",
      "Epoch 704, Loss: 1.3318525850772858, Final Batch Loss: 0.4090394079685211\n",
      "Epoch 705, Loss: 1.3246943354606628, Final Batch Loss: 0.4013107419013977\n",
      "Epoch 706, Loss: 1.2925695776939392, Final Batch Loss: 0.40572163462638855\n",
      "Epoch 707, Loss: 1.1882216036319733, Final Batch Loss: 0.3257046043872833\n",
      "Epoch 708, Loss: 1.3344700038433075, Final Batch Loss: 0.35693231225013733\n",
      "Epoch 709, Loss: 1.3562683761119843, Final Batch Loss: 0.42119231820106506\n",
      "Epoch 710, Loss: 1.349608838558197, Final Batch Loss: 0.5204422473907471\n",
      "Epoch 711, Loss: 1.2732755839824677, Final Batch Loss: 0.4037211239337921\n",
      "Epoch 712, Loss: 1.3231378197669983, Final Batch Loss: 0.44435879588127136\n",
      "Epoch 713, Loss: 1.464600831270218, Final Batch Loss: 0.5523537397384644\n",
      "Epoch 714, Loss: 1.3592306971549988, Final Batch Loss: 0.42906463146209717\n",
      "Epoch 715, Loss: 1.3431062698364258, Final Batch Loss: 0.45137518644332886\n",
      "Epoch 716, Loss: 1.3774247467517853, Final Batch Loss: 0.4711626470088959\n",
      "Epoch 717, Loss: 1.3188430666923523, Final Batch Loss: 0.39069250226020813\n",
      "Epoch 718, Loss: 1.2626574039459229, Final Batch Loss: 0.39946144819259644\n",
      "Epoch 719, Loss: 1.2918432652950287, Final Batch Loss: 0.36520645022392273\n",
      "Epoch 720, Loss: 1.2581267952919006, Final Batch Loss: 0.4122265577316284\n",
      "Epoch 721, Loss: 1.2897765636444092, Final Batch Loss: 0.4193953573703766\n",
      "Epoch 722, Loss: 1.2931884229183197, Final Batch Loss: 0.4202615022659302\n",
      "Epoch 723, Loss: 1.2451961040496826, Final Batch Loss: 0.40005460381507874\n",
      "Epoch 724, Loss: 1.3754059374332428, Final Batch Loss: 0.4223812520503998\n",
      "Epoch 725, Loss: 1.3054889142513275, Final Batch Loss: 0.43734943866729736\n",
      "Epoch 726, Loss: 1.3528002202510834, Final Batch Loss: 0.45826777815818787\n",
      "Epoch 727, Loss: 1.2908839285373688, Final Batch Loss: 0.43729302287101746\n",
      "Epoch 728, Loss: 1.3097034692764282, Final Batch Loss: 0.34535881876945496\n",
      "Epoch 729, Loss: 1.3913198113441467, Final Batch Loss: 0.5101548433303833\n",
      "Epoch 730, Loss: 1.3936221599578857, Final Batch Loss: 0.5234412550926208\n",
      "Epoch 731, Loss: 1.369805932044983, Final Batch Loss: 0.49300315976142883\n",
      "Epoch 732, Loss: 1.3942418694496155, Final Batch Loss: 0.5218165516853333\n",
      "Epoch 733, Loss: 1.2168302237987518, Final Batch Loss: 0.39288529753685\n",
      "Epoch 734, Loss: 1.3274093270301819, Final Batch Loss: 0.4148274064064026\n",
      "Epoch 735, Loss: 1.287014663219452, Final Batch Loss: 0.422869473695755\n",
      "Epoch 736, Loss: 1.370838850736618, Final Batch Loss: 0.4715381860733032\n",
      "Epoch 737, Loss: 1.3049255311489105, Final Batch Loss: 0.4683932363986969\n",
      "Epoch 738, Loss: 1.265644758939743, Final Batch Loss: 0.3846137523651123\n",
      "Epoch 739, Loss: 1.2469382584095001, Final Batch Loss: 0.3989081084728241\n",
      "Epoch 740, Loss: 1.3045636713504791, Final Batch Loss: 0.37818431854248047\n",
      "Epoch 741, Loss: 1.266579955816269, Final Batch Loss: 0.49806299805641174\n",
      "Epoch 742, Loss: 1.3076291978359222, Final Batch Loss: 0.4302290081977844\n",
      "Epoch 743, Loss: 1.2223097085952759, Final Batch Loss: 0.4048592448234558\n",
      "Epoch 744, Loss: 1.2815354466438293, Final Batch Loss: 0.40497222542762756\n",
      "Epoch 745, Loss: 1.1973170042037964, Final Batch Loss: 0.3346564769744873\n",
      "Epoch 746, Loss: 1.212602436542511, Final Batch Loss: 0.37750011682510376\n",
      "Epoch 747, Loss: 1.3051505386829376, Final Batch Loss: 0.4225129187107086\n",
      "Epoch 748, Loss: 1.3322332799434662, Final Batch Loss: 0.48735663294792175\n",
      "Epoch 749, Loss: 1.3749034404754639, Final Batch Loss: 0.4770055115222931\n",
      "Epoch 750, Loss: 1.1755773723125458, Final Batch Loss: 0.35956814885139465\n",
      "Epoch 751, Loss: 1.216498464345932, Final Batch Loss: 0.33200669288635254\n",
      "Epoch 752, Loss: 1.2779659926891327, Final Batch Loss: 0.4405832588672638\n",
      "Epoch 753, Loss: 1.2501724064350128, Final Batch Loss: 0.3744722008705139\n",
      "Epoch 754, Loss: 1.3345511555671692, Final Batch Loss: 0.5122184753417969\n",
      "Epoch 755, Loss: 1.3869353532791138, Final Batch Loss: 0.46359017491340637\n",
      "Epoch 756, Loss: 1.306920349597931, Final Batch Loss: 0.35337257385253906\n",
      "Epoch 757, Loss: 1.2935502231121063, Final Batch Loss: 0.32472291588783264\n",
      "Epoch 758, Loss: 1.2362016141414642, Final Batch Loss: 0.41854819655418396\n",
      "Epoch 759, Loss: 1.3766589164733887, Final Batch Loss: 0.4209442436695099\n",
      "Epoch 760, Loss: 1.3318016827106476, Final Batch Loss: 0.4414815306663513\n",
      "Epoch 761, Loss: 1.3859191536903381, Final Batch Loss: 0.4539301097393036\n",
      "Epoch 762, Loss: 1.2266288995742798, Final Batch Loss: 0.3600878417491913\n",
      "Epoch 763, Loss: 1.2216497659683228, Final Batch Loss: 0.35760658979415894\n",
      "Epoch 764, Loss: 1.2467543482780457, Final Batch Loss: 0.4363582730293274\n",
      "Epoch 765, Loss: 1.2285118103027344, Final Batch Loss: 0.3498380184173584\n",
      "Epoch 766, Loss: 1.184386283159256, Final Batch Loss: 0.3699609935283661\n",
      "Epoch 767, Loss: 1.289553165435791, Final Batch Loss: 0.49412786960601807\n",
      "Epoch 768, Loss: 1.3212463855743408, Final Batch Loss: 0.43727120757102966\n",
      "Epoch 769, Loss: 1.2151378989219666, Final Batch Loss: 0.3555854856967926\n",
      "Epoch 770, Loss: 1.2460724115371704, Final Batch Loss: 0.3662078380584717\n",
      "Epoch 771, Loss: 1.2329192161560059, Final Batch Loss: 0.40646231174468994\n",
      "Epoch 772, Loss: 1.359555870294571, Final Batch Loss: 0.5184415578842163\n",
      "Epoch 773, Loss: 1.2599758505821228, Final Batch Loss: 0.44078755378723145\n",
      "Epoch 774, Loss: 1.292329579591751, Final Batch Loss: 0.5120143890380859\n",
      "Epoch 775, Loss: 1.3234898149967194, Final Batch Loss: 0.4879058599472046\n",
      "Epoch 776, Loss: 1.3542905151844025, Final Batch Loss: 0.535102128982544\n",
      "Epoch 777, Loss: 1.27271169424057, Final Batch Loss: 0.4438631236553192\n",
      "Epoch 778, Loss: 1.2387670278549194, Final Batch Loss: 0.44607141613960266\n",
      "Epoch 779, Loss: 1.2682266235351562, Final Batch Loss: 0.4614753723144531\n",
      "Epoch 780, Loss: 1.185536801815033, Final Batch Loss: 0.3934066593647003\n",
      "Epoch 781, Loss: 1.2918079197406769, Final Batch Loss: 0.4094586968421936\n",
      "Epoch 782, Loss: 1.2738326489925385, Final Batch Loss: 0.4193061888217926\n",
      "Epoch 783, Loss: 1.1736993193626404, Final Batch Loss: 0.3375627398490906\n",
      "Epoch 784, Loss: 1.2928142845630646, Final Batch Loss: 0.43423378467559814\n",
      "Epoch 785, Loss: 1.2198197841644287, Final Batch Loss: 0.33354923129081726\n",
      "Epoch 786, Loss: 1.250062346458435, Final Batch Loss: 0.4632760286331177\n",
      "Epoch 787, Loss: 1.257163792848587, Final Batch Loss: 0.36090391874313354\n",
      "Epoch 788, Loss: 1.1605535447597504, Final Batch Loss: 0.28309711813926697\n",
      "Epoch 789, Loss: 1.2857082784175873, Final Batch Loss: 0.4387058913707733\n",
      "Epoch 790, Loss: 1.234245479106903, Final Batch Loss: 0.4295763671398163\n",
      "Epoch 791, Loss: 1.231347918510437, Final Batch Loss: 0.40537524223327637\n",
      "Epoch 792, Loss: 1.204416036605835, Final Batch Loss: 0.4215725362300873\n",
      "Epoch 793, Loss: 1.1918907463550568, Final Batch Loss: 0.40624210238456726\n",
      "Epoch 794, Loss: 1.2980179488658905, Final Batch Loss: 0.5148608088493347\n",
      "Epoch 795, Loss: 1.2093849778175354, Final Batch Loss: 0.38952288031578064\n",
      "Epoch 796, Loss: 1.258973777294159, Final Batch Loss: 0.4066113829612732\n",
      "Epoch 797, Loss: 1.2707126438617706, Final Batch Loss: 0.39182552695274353\n",
      "Epoch 798, Loss: 1.2446706593036652, Final Batch Loss: 0.4720294773578644\n",
      "Epoch 799, Loss: 1.261909395456314, Final Batch Loss: 0.459695428609848\n",
      "Epoch 800, Loss: 1.151352882385254, Final Batch Loss: 0.37629392743110657\n",
      "Epoch 801, Loss: 1.1567309498786926, Final Batch Loss: 0.42170771956443787\n",
      "Epoch 802, Loss: 1.3131185472011566, Final Batch Loss: 0.521485447883606\n",
      "Epoch 803, Loss: 1.1897169947624207, Final Batch Loss: 0.37264779210090637\n",
      "Epoch 804, Loss: 1.3154606819152832, Final Batch Loss: 0.4887743294239044\n",
      "Epoch 805, Loss: 1.1344875693321228, Final Batch Loss: 0.3819109797477722\n",
      "Epoch 806, Loss: 1.328512191772461, Final Batch Loss: 0.5634472966194153\n",
      "Epoch 807, Loss: 1.2894335985183716, Final Batch Loss: 0.4273078441619873\n",
      "Epoch 808, Loss: 1.317118763923645, Final Batch Loss: 0.5295666456222534\n",
      "Epoch 809, Loss: 1.1829495131969452, Final Batch Loss: 0.39663925766944885\n",
      "Epoch 810, Loss: 1.2266489267349243, Final Batch Loss: 0.41446858644485474\n",
      "Epoch 811, Loss: 1.233246237039566, Final Batch Loss: 0.48306992650032043\n",
      "Epoch 812, Loss: 1.184459388256073, Final Batch Loss: 0.338896244764328\n",
      "Epoch 813, Loss: 1.3235763609409332, Final Batch Loss: 0.5154998302459717\n",
      "Epoch 814, Loss: 1.2187340557575226, Final Batch Loss: 0.3703414499759674\n",
      "Epoch 815, Loss: 1.2474546432495117, Final Batch Loss: 0.4400705099105835\n",
      "Epoch 816, Loss: 1.249237209558487, Final Batch Loss: 0.4441761076450348\n",
      "Epoch 817, Loss: 1.2171204090118408, Final Batch Loss: 0.4471043050289154\n",
      "Epoch 818, Loss: 1.191153109073639, Final Batch Loss: 0.3909112811088562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 819, Loss: 1.1671441197395325, Final Batch Loss: 0.3065258264541626\n",
      "Epoch 820, Loss: 1.168853521347046, Final Batch Loss: 0.3619665205478668\n",
      "Epoch 821, Loss: 1.2613551914691925, Final Batch Loss: 0.4389816224575043\n",
      "Epoch 822, Loss: 1.0817759335041046, Final Batch Loss: 0.29604485630989075\n",
      "Epoch 823, Loss: 1.1943969428539276, Final Batch Loss: 0.358942449092865\n",
      "Epoch 824, Loss: 1.2262492179870605, Final Batch Loss: 0.33887335658073425\n",
      "Epoch 825, Loss: 1.185712218284607, Final Batch Loss: 0.3550240397453308\n",
      "Epoch 826, Loss: 1.3176204562187195, Final Batch Loss: 0.4263975918292999\n",
      "Epoch 827, Loss: 1.1346126794815063, Final Batch Loss: 0.4246833920478821\n",
      "Epoch 828, Loss: 1.2045551538467407, Final Batch Loss: 0.4112703204154968\n",
      "Epoch 829, Loss: 1.1339117884635925, Final Batch Loss: 0.3663807511329651\n",
      "Epoch 830, Loss: 1.1490555703639984, Final Batch Loss: 0.39299193024635315\n",
      "Epoch 831, Loss: 1.2930131554603577, Final Batch Loss: 0.48877599835395813\n",
      "Epoch 832, Loss: 1.2568643987178802, Final Batch Loss: 0.4575871229171753\n",
      "Epoch 833, Loss: 1.1448467671871185, Final Batch Loss: 0.33863070607185364\n",
      "Epoch 834, Loss: 1.3393710851669312, Final Batch Loss: 0.43799149990081787\n",
      "Epoch 835, Loss: 1.3059868216514587, Final Batch Loss: 0.48359185457229614\n",
      "Epoch 836, Loss: 1.197155237197876, Final Batch Loss: 0.31246325373649597\n",
      "Epoch 837, Loss: 1.243456482887268, Final Batch Loss: 0.4111514687538147\n",
      "Epoch 838, Loss: 1.2682088613510132, Final Batch Loss: 0.41669589281082153\n",
      "Epoch 839, Loss: 1.2086161077022552, Final Batch Loss: 0.44679465889930725\n",
      "Epoch 840, Loss: 1.2654683887958527, Final Batch Loss: 0.4089968204498291\n",
      "Epoch 841, Loss: 1.187628149986267, Final Batch Loss: 0.37681838870048523\n",
      "Epoch 842, Loss: 1.1866064369678497, Final Batch Loss: 0.38620033860206604\n",
      "Epoch 843, Loss: 1.193846434354782, Final Batch Loss: 0.34022417664527893\n",
      "Epoch 844, Loss: 1.1378556489944458, Final Batch Loss: 0.257307767868042\n",
      "Epoch 845, Loss: 1.1889755129814148, Final Batch Loss: 0.4002915620803833\n",
      "Epoch 846, Loss: 1.1996031701564789, Final Batch Loss: 0.3959769308567047\n",
      "Epoch 847, Loss: 1.2046354711055756, Final Batch Loss: 0.44451406598091125\n",
      "Epoch 848, Loss: 1.2448464334011078, Final Batch Loss: 0.4307137429714203\n",
      "Epoch 849, Loss: 1.2195002734661102, Final Batch Loss: 0.36262887716293335\n",
      "Epoch 850, Loss: 1.3551797270774841, Final Batch Loss: 0.5343610644340515\n",
      "Epoch 851, Loss: 1.2478351593017578, Final Batch Loss: 0.4373800754547119\n",
      "Epoch 852, Loss: 1.1730656325817108, Final Batch Loss: 0.3937584161758423\n",
      "Epoch 853, Loss: 1.155577927827835, Final Batch Loss: 0.3894629180431366\n",
      "Epoch 854, Loss: 1.1740433275699615, Final Batch Loss: 0.38076573610305786\n",
      "Epoch 855, Loss: 1.2827599942684174, Final Batch Loss: 0.47108718752861023\n",
      "Epoch 856, Loss: 1.1995514929294586, Final Batch Loss: 0.3721441328525543\n",
      "Epoch 857, Loss: 1.1327138245105743, Final Batch Loss: 0.3458244204521179\n",
      "Epoch 858, Loss: 1.2155216932296753, Final Batch Loss: 0.4256516098976135\n",
      "Epoch 859, Loss: 1.1592091917991638, Final Batch Loss: 0.47078484296798706\n",
      "Epoch 860, Loss: 1.223152220249176, Final Batch Loss: 0.41679587960243225\n",
      "Epoch 861, Loss: 1.1044989824295044, Final Batch Loss: 0.3597542345523834\n",
      "Epoch 862, Loss: 1.1951154470443726, Final Batch Loss: 0.38848865032196045\n",
      "Epoch 863, Loss: 1.269780308008194, Final Batch Loss: 0.5081542730331421\n",
      "Epoch 864, Loss: 1.208533614873886, Final Batch Loss: 0.4146685302257538\n",
      "Epoch 865, Loss: 1.2428032457828522, Final Batch Loss: 0.4685060679912567\n",
      "Epoch 866, Loss: 1.233326494693756, Final Batch Loss: 0.3135148584842682\n",
      "Epoch 867, Loss: 1.1885682344436646, Final Batch Loss: 0.4458746612071991\n",
      "Epoch 868, Loss: 1.1472309231758118, Final Batch Loss: 0.35834139585494995\n",
      "Epoch 869, Loss: 1.1317585706710815, Final Batch Loss: 0.38268139958381653\n",
      "Epoch 870, Loss: 1.0925368666648865, Final Batch Loss: 0.3515697419643402\n",
      "Epoch 871, Loss: 1.1847727596759796, Final Batch Loss: 0.3631488084793091\n",
      "Epoch 872, Loss: 1.095637559890747, Final Batch Loss: 0.33678141236305237\n",
      "Epoch 873, Loss: 1.0971536040306091, Final Batch Loss: 0.3481742739677429\n",
      "Epoch 874, Loss: 1.2358382642269135, Final Batch Loss: 0.40688595175743103\n",
      "Epoch 875, Loss: 1.0514029264450073, Final Batch Loss: 0.3125405013561249\n",
      "Epoch 876, Loss: 1.1755904257297516, Final Batch Loss: 0.3921937346458435\n",
      "Epoch 877, Loss: 1.152924507856369, Final Batch Loss: 0.4520372152328491\n",
      "Epoch 878, Loss: 1.0972515046596527, Final Batch Loss: 0.3492557406425476\n",
      "Epoch 879, Loss: 1.0578011572360992, Final Batch Loss: 0.31469687819480896\n",
      "Epoch 880, Loss: 1.1543400287628174, Final Batch Loss: 0.3931732475757599\n",
      "Epoch 881, Loss: 1.0972674787044525, Final Batch Loss: 0.3480825126171112\n",
      "Epoch 882, Loss: 1.2992804944515228, Final Batch Loss: 0.46010634303092957\n",
      "Epoch 883, Loss: 1.1606549322605133, Final Batch Loss: 0.3678358495235443\n",
      "Epoch 884, Loss: 1.2452642321586609, Final Batch Loss: 0.3899633288383484\n",
      "Epoch 885, Loss: 1.1839757561683655, Final Batch Loss: 0.36305612325668335\n",
      "Epoch 886, Loss: 1.2037612795829773, Final Batch Loss: 0.4616524577140808\n",
      "Epoch 887, Loss: 1.1439453661441803, Final Batch Loss: 0.36532753705978394\n",
      "Epoch 888, Loss: 1.1869319379329681, Final Batch Loss: 0.42800015211105347\n",
      "Epoch 889, Loss: 1.2486176490783691, Final Batch Loss: 0.4220626950263977\n",
      "Epoch 890, Loss: 1.1958350241184235, Final Batch Loss: 0.4257393181324005\n",
      "Epoch 891, Loss: 1.198238343000412, Final Batch Loss: 0.4291321039199829\n",
      "Epoch 892, Loss: 1.1179652512073517, Final Batch Loss: 0.3233768343925476\n",
      "Epoch 893, Loss: 1.1608763337135315, Final Batch Loss: 0.410894513130188\n",
      "Epoch 894, Loss: 1.1532522141933441, Final Batch Loss: 0.3667527139186859\n",
      "Epoch 895, Loss: 1.1111558377742767, Final Batch Loss: 0.3689529597759247\n",
      "Epoch 896, Loss: 1.2012011110782623, Final Batch Loss: 0.427377313375473\n",
      "Epoch 897, Loss: 1.1293261349201202, Final Batch Loss: 0.3621150851249695\n",
      "Epoch 898, Loss: 1.0284178853034973, Final Batch Loss: 0.3095826506614685\n",
      "Epoch 899, Loss: 1.0471445322036743, Final Batch Loss: 0.29676833748817444\n",
      "Epoch 900, Loss: 1.1977747976779938, Final Batch Loss: 0.43480873107910156\n",
      "Epoch 901, Loss: 1.1059994995594025, Final Batch Loss: 0.3512614667415619\n",
      "Epoch 902, Loss: 1.1883538961410522, Final Batch Loss: 0.3813702166080475\n",
      "Epoch 903, Loss: 1.137761265039444, Final Batch Loss: 0.3758165240287781\n",
      "Epoch 904, Loss: 1.1038574576377869, Final Batch Loss: 0.4105522334575653\n",
      "Epoch 905, Loss: 1.195665329694748, Final Batch Loss: 0.4511268734931946\n",
      "Epoch 906, Loss: 1.1249828040599823, Final Batch Loss: 0.3504616618156433\n",
      "Epoch 907, Loss: 1.113457053899765, Final Batch Loss: 0.3657596707344055\n",
      "Epoch 908, Loss: 1.1426515579223633, Final Batch Loss: 0.3862553536891937\n",
      "Epoch 909, Loss: 1.1933721601963043, Final Batch Loss: 0.45501255989074707\n",
      "Epoch 910, Loss: 1.1313371658325195, Final Batch Loss: 0.43691471219062805\n",
      "Epoch 911, Loss: 1.2990511059761047, Final Batch Loss: 0.5044238567352295\n",
      "Epoch 912, Loss: 1.1455880403518677, Final Batch Loss: 0.41856423020362854\n",
      "Epoch 913, Loss: 1.1230396926403046, Final Batch Loss: 0.3687414526939392\n",
      "Epoch 914, Loss: 1.2069109082221985, Final Batch Loss: 0.37678590416908264\n",
      "Epoch 915, Loss: 1.129904955625534, Final Batch Loss: 0.3398197591304779\n",
      "Epoch 916, Loss: 1.163078248500824, Final Batch Loss: 0.394125372171402\n",
      "Epoch 917, Loss: 1.1375190317630768, Final Batch Loss: 0.395542711019516\n",
      "Epoch 918, Loss: 1.1358467638492584, Final Batch Loss: 0.3652275502681732\n",
      "Epoch 919, Loss: 1.115620732307434, Final Batch Loss: 0.35375991463661194\n",
      "Epoch 920, Loss: 1.0865508615970612, Final Batch Loss: 0.35831618309020996\n",
      "Epoch 921, Loss: 1.0986737608909607, Final Batch Loss: 0.33279889822006226\n",
      "Epoch 922, Loss: 1.1766459941864014, Final Batch Loss: 0.37166154384613037\n",
      "Epoch 923, Loss: 1.0981276333332062, Final Batch Loss: 0.3983621895313263\n",
      "Epoch 924, Loss: 1.114216387271881, Final Batch Loss: 0.35554274916648865\n",
      "Epoch 925, Loss: 1.0617334246635437, Final Batch Loss: 0.3184763193130493\n",
      "Epoch 926, Loss: 1.0916116833686829, Final Batch Loss: 0.36087721586227417\n",
      "Epoch 927, Loss: 1.0305356681346893, Final Batch Loss: 0.33825451135635376\n",
      "Epoch 928, Loss: 1.2232307493686676, Final Batch Loss: 0.4966045022010803\n",
      "Epoch 929, Loss: 1.1357402503490448, Final Batch Loss: 0.4199689030647278\n",
      "Epoch 930, Loss: 1.1284545958042145, Final Batch Loss: 0.31799256801605225\n",
      "Epoch 931, Loss: 1.1482318341732025, Final Batch Loss: 0.34940916299819946\n",
      "Epoch 932, Loss: 1.1201420426368713, Final Batch Loss: 0.29681313037872314\n",
      "Epoch 933, Loss: 1.1050000190734863, Final Batch Loss: 0.3653370440006256\n",
      "Epoch 934, Loss: 1.1051660776138306, Final Batch Loss: 0.3723355531692505\n",
      "Epoch 935, Loss: 1.0652894377708435, Final Batch Loss: 0.3941432535648346\n",
      "Epoch 936, Loss: 1.1357646882534027, Final Batch Loss: 0.36156708002090454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 937, Loss: 1.0738160610198975, Final Batch Loss: 0.3459298312664032\n",
      "Epoch 938, Loss: 1.067499816417694, Final Batch Loss: 0.3460705578327179\n",
      "Epoch 939, Loss: 1.0593774020671844, Final Batch Loss: 0.33531761169433594\n",
      "Epoch 940, Loss: 1.1528380811214447, Final Batch Loss: 0.35258200764656067\n",
      "Epoch 941, Loss: 1.0842549204826355, Final Batch Loss: 0.3564368486404419\n",
      "Epoch 942, Loss: 1.1828312277793884, Final Batch Loss: 0.4176693260669708\n",
      "Epoch 943, Loss: 0.9882672131061554, Final Batch Loss: 0.2510859966278076\n",
      "Epoch 944, Loss: 1.0037928819656372, Final Batch Loss: 0.3423548638820648\n",
      "Epoch 945, Loss: 0.9560599327087402, Final Batch Loss: 0.2698211371898651\n",
      "Epoch 946, Loss: 1.1667914986610413, Final Batch Loss: 0.3956696093082428\n",
      "Epoch 947, Loss: 1.0156012773513794, Final Batch Loss: 0.267119824886322\n",
      "Epoch 948, Loss: 0.9735515415668488, Final Batch Loss: 0.266754686832428\n",
      "Epoch 949, Loss: 1.0748791694641113, Final Batch Loss: 0.3089989423751831\n",
      "Epoch 950, Loss: 1.0692919790744781, Final Batch Loss: 0.35195183753967285\n",
      "Epoch 951, Loss: 1.1608467996120453, Final Batch Loss: 0.41140276193618774\n",
      "Epoch 952, Loss: 1.0755707025527954, Final Batch Loss: 0.35836061835289\n",
      "Epoch 953, Loss: 1.1798146069049835, Final Batch Loss: 0.4760110080242157\n",
      "Epoch 954, Loss: 1.0283560752868652, Final Batch Loss: 0.30827611684799194\n",
      "Epoch 955, Loss: 1.1729569733142853, Final Batch Loss: 0.39634501934051514\n",
      "Epoch 956, Loss: 1.0657728612422943, Final Batch Loss: 0.3430681824684143\n",
      "Epoch 957, Loss: 1.033978432416916, Final Batch Loss: 0.3322148025035858\n",
      "Epoch 958, Loss: 1.0902154743671417, Final Batch Loss: 0.3212422728538513\n",
      "Epoch 959, Loss: 1.017215222120285, Final Batch Loss: 0.27118581533432007\n",
      "Epoch 960, Loss: 1.173748642206192, Final Batch Loss: 0.40828821063041687\n",
      "Epoch 961, Loss: 1.1393178403377533, Final Batch Loss: 0.40599676966667175\n",
      "Epoch 962, Loss: 1.1102600991725922, Final Batch Loss: 0.34693729877471924\n",
      "Epoch 963, Loss: 1.1107462346553802, Final Batch Loss: 0.3282429575920105\n",
      "Epoch 964, Loss: 1.054707556962967, Final Batch Loss: 0.35765787959098816\n",
      "Epoch 965, Loss: 1.170042246580124, Final Batch Loss: 0.42409178614616394\n",
      "Epoch 966, Loss: 1.1053512692451477, Final Batch Loss: 0.3463173806667328\n",
      "Epoch 967, Loss: 1.1777960062026978, Final Batch Loss: 0.5149644613265991\n",
      "Epoch 968, Loss: 0.9868033230304718, Final Batch Loss: 0.26367321610450745\n",
      "Epoch 969, Loss: 1.1367714703083038, Final Batch Loss: 0.4198000431060791\n",
      "Epoch 970, Loss: 1.0599779784679413, Final Batch Loss: 0.3741339445114136\n",
      "Epoch 971, Loss: 1.0639601647853851, Final Batch Loss: 0.3572789430618286\n",
      "Epoch 972, Loss: 1.0673308074474335, Final Batch Loss: 0.32710614800453186\n",
      "Epoch 973, Loss: 1.141770839691162, Final Batch Loss: 0.45769649744033813\n",
      "Epoch 974, Loss: 1.1053776741027832, Final Batch Loss: 0.3441380262374878\n",
      "Epoch 975, Loss: 1.06174835562706, Final Batch Loss: 0.3768177330493927\n",
      "Epoch 976, Loss: 1.1037594377994537, Final Batch Loss: 0.40875980257987976\n",
      "Epoch 977, Loss: 1.1380223631858826, Final Batch Loss: 0.40955132246017456\n",
      "Epoch 978, Loss: 1.0848564207553864, Final Batch Loss: 0.40673622488975525\n",
      "Epoch 979, Loss: 1.1411207914352417, Final Batch Loss: 0.47824084758758545\n",
      "Epoch 980, Loss: 1.1350791454315186, Final Batch Loss: 0.38652196526527405\n",
      "Epoch 981, Loss: 0.9971314370632172, Final Batch Loss: 0.3104616701602936\n",
      "Epoch 982, Loss: 1.0769321918487549, Final Batch Loss: 0.3351547122001648\n",
      "Epoch 983, Loss: 1.1064861118793488, Final Batch Loss: 0.40931835770606995\n",
      "Epoch 984, Loss: 1.062245488166809, Final Batch Loss: 0.3779136836528778\n",
      "Epoch 985, Loss: 1.0352181196212769, Final Batch Loss: 0.3172839283943176\n",
      "Epoch 986, Loss: 1.077606588602066, Final Batch Loss: 0.3336782157421112\n",
      "Epoch 987, Loss: 1.0299602448940277, Final Batch Loss: 0.29026564955711365\n",
      "Epoch 988, Loss: 1.0059397518634796, Final Batch Loss: 0.29508331418037415\n",
      "Epoch 989, Loss: 1.1369404196739197, Final Batch Loss: 0.4421486258506775\n",
      "Epoch 990, Loss: 1.0585407614707947, Final Batch Loss: 0.4023662507534027\n",
      "Epoch 991, Loss: 1.068226158618927, Final Batch Loss: 0.28705066442489624\n",
      "Epoch 992, Loss: 1.1907274723052979, Final Batch Loss: 0.4225570261478424\n",
      "Epoch 993, Loss: 1.0174284875392914, Final Batch Loss: 0.2500121295452118\n",
      "Epoch 994, Loss: 1.055845469236374, Final Batch Loss: 0.33486372232437134\n",
      "Epoch 995, Loss: 1.0619038939476013, Final Batch Loss: 0.3593316972255707\n",
      "Epoch 996, Loss: 1.0380856096744537, Final Batch Loss: 0.2946965992450714\n",
      "Epoch 997, Loss: 1.0003477036952972, Final Batch Loss: 0.28808000683784485\n",
      "Epoch 998, Loss: 1.190682739019394, Final Batch Loss: 0.42615950107574463\n",
      "Epoch 999, Loss: 1.1210210621356964, Final Batch Loss: 0.4364861249923706\n",
      "Epoch 1000, Loss: 1.0631136000156403, Final Batch Loss: 0.38252073526382446\n",
      "Epoch 1001, Loss: 1.1954838037490845, Final Batch Loss: 0.3435211181640625\n",
      "Epoch 1002, Loss: 1.0910409688949585, Final Batch Loss: 0.3624589145183563\n",
      "Epoch 1003, Loss: 1.0927037298679352, Final Batch Loss: 0.33084043860435486\n",
      "Epoch 1004, Loss: 1.0197896361351013, Final Batch Loss: 0.3059488534927368\n",
      "Epoch 1005, Loss: 1.1039965450763702, Final Batch Loss: 0.3949417173862457\n",
      "Epoch 1006, Loss: 1.0314764976501465, Final Batch Loss: 0.31052127480506897\n",
      "Epoch 1007, Loss: 1.0391379296779633, Final Batch Loss: 0.2976580858230591\n",
      "Epoch 1008, Loss: 1.10205078125, Final Batch Loss: 0.4432600438594818\n",
      "Epoch 1009, Loss: 1.0204389989376068, Final Batch Loss: 0.2616212069988251\n",
      "Epoch 1010, Loss: 1.172810673713684, Final Batch Loss: 0.434468537569046\n",
      "Epoch 1011, Loss: 1.1236450672149658, Final Batch Loss: 0.4278404414653778\n",
      "Epoch 1012, Loss: 1.0470891296863556, Final Batch Loss: 0.35507407784461975\n",
      "Epoch 1013, Loss: 1.0476380288600922, Final Batch Loss: 0.3500296473503113\n",
      "Epoch 1014, Loss: 1.0978124141693115, Final Batch Loss: 0.31721410155296326\n",
      "Epoch 1015, Loss: 0.9799717962741852, Final Batch Loss: 0.3555445075035095\n",
      "Epoch 1016, Loss: 1.0990122258663177, Final Batch Loss: 0.3792122006416321\n",
      "Epoch 1017, Loss: 1.077923059463501, Final Batch Loss: 0.4119163751602173\n",
      "Epoch 1018, Loss: 1.1371340453624725, Final Batch Loss: 0.34357014298439026\n",
      "Epoch 1019, Loss: 1.205439180135727, Final Batch Loss: 0.37857791781425476\n",
      "Epoch 1020, Loss: 1.1563160717487335, Final Batch Loss: 0.35762298107147217\n",
      "Epoch 1021, Loss: 1.0768312811851501, Final Batch Loss: 0.39599156379699707\n",
      "Epoch 1022, Loss: 0.996730238199234, Final Batch Loss: 0.3119427263736725\n",
      "Epoch 1023, Loss: 1.0039913654327393, Final Batch Loss: 0.2766931354999542\n",
      "Epoch 1024, Loss: 1.0788980424404144, Final Batch Loss: 0.3876991868019104\n",
      "Epoch 1025, Loss: 1.179885596036911, Final Batch Loss: 0.4694063663482666\n",
      "Epoch 1026, Loss: 1.055735558271408, Final Batch Loss: 0.3102876842021942\n",
      "Epoch 1027, Loss: 1.166099101305008, Final Batch Loss: 0.4037768244743347\n",
      "Epoch 1028, Loss: 1.0096694231033325, Final Batch Loss: 0.28638961911201477\n",
      "Epoch 1029, Loss: 0.992725282907486, Final Batch Loss: 0.3403226137161255\n",
      "Epoch 1030, Loss: 1.0729643106460571, Final Batch Loss: 0.4246367812156677\n",
      "Epoch 1031, Loss: 1.0451188683509827, Final Batch Loss: 0.33194148540496826\n",
      "Epoch 1032, Loss: 1.0917643904685974, Final Batch Loss: 0.3688361644744873\n",
      "Epoch 1033, Loss: 1.0035635828971863, Final Batch Loss: 0.27394551038742065\n",
      "Epoch 1034, Loss: 0.9830884039402008, Final Batch Loss: 0.3346463143825531\n",
      "Epoch 1035, Loss: 1.0355732142925262, Final Batch Loss: 0.2580558657646179\n",
      "Epoch 1036, Loss: 1.1060208976268768, Final Batch Loss: 0.4128901958465576\n",
      "Epoch 1037, Loss: 0.99385204911232, Final Batch Loss: 0.32482147216796875\n",
      "Epoch 1038, Loss: 1.06911039352417, Final Batch Loss: 0.32953986525535583\n",
      "Epoch 1039, Loss: 0.9686974883079529, Final Batch Loss: 0.312583863735199\n",
      "Epoch 1040, Loss: 1.035223513841629, Final Batch Loss: 0.3735249638557434\n",
      "Epoch 1041, Loss: 0.9668315351009369, Final Batch Loss: 0.309474378824234\n",
      "Epoch 1042, Loss: 0.9941033124923706, Final Batch Loss: 0.2897454798221588\n",
      "Epoch 1043, Loss: 1.058342695236206, Final Batch Loss: 0.3417128324508667\n",
      "Epoch 1044, Loss: 0.9741475880146027, Final Batch Loss: 0.28419196605682373\n",
      "Epoch 1045, Loss: 1.071874588727951, Final Batch Loss: 0.390121191740036\n",
      "Epoch 1046, Loss: 0.9052986949682236, Final Batch Loss: 0.2379629760980606\n",
      "Epoch 1047, Loss: 1.0901505649089813, Final Batch Loss: 0.3693150579929352\n",
      "Epoch 1048, Loss: 1.046639323234558, Final Batch Loss: 0.3908729553222656\n",
      "Epoch 1049, Loss: 1.0614646077156067, Final Batch Loss: 0.3382924795150757\n",
      "Epoch 1050, Loss: 1.0975306928157806, Final Batch Loss: 0.3267576992511749\n",
      "Epoch 1051, Loss: 1.038501888513565, Final Batch Loss: 0.34682944416999817\n",
      "Epoch 1052, Loss: 1.0896689891815186, Final Batch Loss: 0.363881379365921\n",
      "Epoch 1053, Loss: 0.914177417755127, Final Batch Loss: 0.2647875249385834\n",
      "Epoch 1054, Loss: 1.019235610961914, Final Batch Loss: 0.36563897132873535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1055, Loss: 0.9314512014389038, Final Batch Loss: 0.2601239085197449\n",
      "Epoch 1056, Loss: 1.023193746805191, Final Batch Loss: 0.37965255975723267\n",
      "Epoch 1057, Loss: 0.9469174444675446, Final Batch Loss: 0.2809704542160034\n",
      "Epoch 1058, Loss: 1.1114473640918732, Final Batch Loss: 0.37221667170524597\n",
      "Epoch 1059, Loss: 0.992743730545044, Final Batch Loss: 0.2917327284812927\n",
      "Epoch 1060, Loss: 1.1114168763160706, Final Batch Loss: 0.39927056431770325\n",
      "Epoch 1061, Loss: 0.9326715469360352, Final Batch Loss: 0.32342034578323364\n",
      "Epoch 1062, Loss: 0.9351372122764587, Final Batch Loss: 0.25600600242614746\n",
      "Epoch 1063, Loss: 1.0086234211921692, Final Batch Loss: 0.34986642003059387\n",
      "Epoch 1064, Loss: 1.1100088059902191, Final Batch Loss: 0.43637099862098694\n",
      "Epoch 1065, Loss: 0.9851396679878235, Final Batch Loss: 0.3110521733760834\n",
      "Epoch 1066, Loss: 1.1735325157642365, Final Batch Loss: 0.4096061587333679\n",
      "Epoch 1067, Loss: 0.9814087450504303, Final Batch Loss: 0.37395957112312317\n",
      "Epoch 1068, Loss: 1.001008614897728, Final Batch Loss: 0.23653234541416168\n",
      "Epoch 1069, Loss: 0.9768087565898895, Final Batch Loss: 0.2951516807079315\n",
      "Epoch 1070, Loss: 1.0146160125732422, Final Batch Loss: 0.3096592426300049\n",
      "Epoch 1071, Loss: 1.0791065990924835, Final Batch Loss: 0.4156310260295868\n",
      "Epoch 1072, Loss: 1.0239414870738983, Final Batch Loss: 0.34525883197784424\n",
      "Epoch 1073, Loss: 1.1512078046798706, Final Batch Loss: 0.428813099861145\n",
      "Epoch 1074, Loss: 1.0427916646003723, Final Batch Loss: 0.36925846338272095\n",
      "Epoch 1075, Loss: 0.9494481086730957, Final Batch Loss: 0.25030726194381714\n",
      "Epoch 1076, Loss: 1.0398190915584564, Final Batch Loss: 0.32187703251838684\n",
      "Epoch 1077, Loss: 1.0562270283699036, Final Batch Loss: 0.3636043071746826\n",
      "Epoch 1078, Loss: 0.94417804479599, Final Batch Loss: 0.33256766200065613\n",
      "Epoch 1079, Loss: 1.0823999643325806, Final Batch Loss: 0.3748798072338104\n",
      "Epoch 1080, Loss: 1.0464935898780823, Final Batch Loss: 0.3563552796840668\n",
      "Epoch 1081, Loss: 1.0440137088298798, Final Batch Loss: 0.35963699221611023\n",
      "Epoch 1082, Loss: 0.9692349135875702, Final Batch Loss: 0.31602105498313904\n",
      "Epoch 1083, Loss: 0.9921550452709198, Final Batch Loss: 0.3279467821121216\n",
      "Epoch 1084, Loss: 0.9267428666353226, Final Batch Loss: 0.2240152806043625\n",
      "Epoch 1085, Loss: 0.961745411157608, Final Batch Loss: 0.3197331130504608\n",
      "Epoch 1086, Loss: 0.9795366525650024, Final Batch Loss: 0.2876685857772827\n",
      "Epoch 1087, Loss: 1.0653320848941803, Final Batch Loss: 0.3601152300834656\n",
      "Epoch 1088, Loss: 1.0302922129631042, Final Batch Loss: 0.3538229763507843\n",
      "Epoch 1089, Loss: 0.9704996645450592, Final Batch Loss: 0.2921464145183563\n",
      "Epoch 1090, Loss: 0.9799051880836487, Final Batch Loss: 0.3208112418651581\n",
      "Epoch 1091, Loss: 1.0283550918102264, Final Batch Loss: 0.3212917149066925\n",
      "Epoch 1092, Loss: 1.0609395802021027, Final Batch Loss: 0.2683860957622528\n",
      "Epoch 1093, Loss: 0.9773794710636139, Final Batch Loss: 0.3039206266403198\n",
      "Epoch 1094, Loss: 1.0534040331840515, Final Batch Loss: 0.3605469763278961\n",
      "Epoch 1095, Loss: 1.0287882685661316, Final Batch Loss: 0.3484511971473694\n",
      "Epoch 1096, Loss: 1.0342085361480713, Final Batch Loss: 0.3619641363620758\n",
      "Epoch 1097, Loss: 1.0298414528369904, Final Batch Loss: 0.4012226164340973\n",
      "Epoch 1098, Loss: 0.9174502491950989, Final Batch Loss: 0.25805866718292236\n",
      "Epoch 1099, Loss: 0.9363500773906708, Final Batch Loss: 0.2819107472896576\n",
      "Epoch 1100, Loss: 0.9821206033229828, Final Batch Loss: 0.3634130656719208\n",
      "Epoch 1101, Loss: 1.0710809230804443, Final Batch Loss: 0.4124422073364258\n",
      "Epoch 1102, Loss: 0.9688648581504822, Final Batch Loss: 0.2694748342037201\n",
      "Epoch 1103, Loss: 0.9030998945236206, Final Batch Loss: 0.27956506609916687\n",
      "Epoch 1104, Loss: 1.002961665391922, Final Batch Loss: 0.36150017380714417\n",
      "Epoch 1105, Loss: 1.0280850231647491, Final Batch Loss: 0.3612370789051056\n",
      "Epoch 1106, Loss: 1.003008246421814, Final Batch Loss: 0.31356701254844666\n",
      "Epoch 1107, Loss: 1.0010137557983398, Final Batch Loss: 0.3145489990711212\n",
      "Epoch 1108, Loss: 0.9731301516294479, Final Batch Loss: 0.24849657714366913\n",
      "Epoch 1109, Loss: 0.9898274838924408, Final Batch Loss: 0.36434078216552734\n",
      "Epoch 1110, Loss: 0.9206196069717407, Final Batch Loss: 0.25798970460891724\n",
      "Epoch 1111, Loss: 0.9151691794395447, Final Batch Loss: 0.2857550084590912\n",
      "Epoch 1112, Loss: 0.9635644853115082, Final Batch Loss: 0.3269929587841034\n",
      "Epoch 1113, Loss: 1.047762006521225, Final Batch Loss: 0.3589407503604889\n",
      "Epoch 1114, Loss: 0.9328155815601349, Final Batch Loss: 0.3090316653251648\n",
      "Epoch 1115, Loss: 1.0322099030017853, Final Batch Loss: 0.3757835030555725\n",
      "Epoch 1116, Loss: 0.9558990895748138, Final Batch Loss: 0.3103713095188141\n",
      "Epoch 1117, Loss: 1.046084463596344, Final Batch Loss: 0.40873387455940247\n",
      "Epoch 1118, Loss: 1.013355553150177, Final Batch Loss: 0.2952060401439667\n",
      "Epoch 1119, Loss: 1.0633911192417145, Final Batch Loss: 0.34047988057136536\n",
      "Epoch 1120, Loss: 0.9528101086616516, Final Batch Loss: 0.2878131866455078\n",
      "Epoch 1121, Loss: 1.0264273285865784, Final Batch Loss: 0.37678083777427673\n",
      "Epoch 1122, Loss: 0.9588124454021454, Final Batch Loss: 0.2910572588443756\n",
      "Epoch 1123, Loss: 0.9900138080120087, Final Batch Loss: 0.315315842628479\n",
      "Epoch 1124, Loss: 1.0494569838047028, Final Batch Loss: 0.3599361777305603\n",
      "Epoch 1125, Loss: 0.9748115539550781, Final Batch Loss: 0.34945806860923767\n",
      "Epoch 1126, Loss: 0.9862907230854034, Final Batch Loss: 0.3254113495349884\n",
      "Epoch 1127, Loss: 0.9167180359363556, Final Batch Loss: 0.26501187682151794\n",
      "Epoch 1128, Loss: 0.9723877012729645, Final Batch Loss: 0.32243791222572327\n",
      "Epoch 1129, Loss: 1.1861542165279388, Final Batch Loss: 0.4956132471561432\n",
      "Epoch 1130, Loss: 0.9468145966529846, Final Batch Loss: 0.2973896563053131\n",
      "Epoch 1131, Loss: 0.9032919108867645, Final Batch Loss: 0.24786022305488586\n",
      "Epoch 1132, Loss: 0.9208431094884872, Final Batch Loss: 0.2459365576505661\n",
      "Epoch 1133, Loss: 0.9730533063411713, Final Batch Loss: 0.33396556973457336\n",
      "Epoch 1134, Loss: 1.0571334064006805, Final Batch Loss: 0.36060184240341187\n",
      "Epoch 1135, Loss: 1.0016704499721527, Final Batch Loss: 0.3295876085758209\n",
      "Epoch 1136, Loss: 1.1219341158866882, Final Batch Loss: 0.3818499445915222\n",
      "Epoch 1137, Loss: 0.9506286680698395, Final Batch Loss: 0.21750497817993164\n",
      "Epoch 1138, Loss: 1.0783100128173828, Final Batch Loss: 0.3586239516735077\n",
      "Epoch 1139, Loss: 0.9696454405784607, Final Batch Loss: 0.3220187723636627\n",
      "Epoch 1140, Loss: 0.9584142714738846, Final Batch Loss: 0.24898461997509003\n",
      "Epoch 1141, Loss: 0.8973760008811951, Final Batch Loss: 0.2997204065322876\n",
      "Epoch 1142, Loss: 0.904617041349411, Final Batch Loss: 0.3016497492790222\n",
      "Epoch 1143, Loss: 0.9575367569923401, Final Batch Loss: 0.33093899488449097\n",
      "Epoch 1144, Loss: 1.025552898645401, Final Batch Loss: 0.3537617325782776\n",
      "Epoch 1145, Loss: 1.09418985247612, Final Batch Loss: 0.4098112881183624\n",
      "Epoch 1146, Loss: 0.8805055022239685, Final Batch Loss: 0.29567843675613403\n",
      "Epoch 1147, Loss: 0.9604138433933258, Final Batch Loss: 0.3023241460323334\n",
      "Epoch 1148, Loss: 0.8926113396883011, Final Batch Loss: 0.20757295191287994\n",
      "Epoch 1149, Loss: 0.940604567527771, Final Batch Loss: 0.3339405953884125\n",
      "Epoch 1150, Loss: 1.017453819513321, Final Batch Loss: 0.29308196902275085\n",
      "Epoch 1151, Loss: 0.990473747253418, Final Batch Loss: 0.3781503736972809\n",
      "Epoch 1152, Loss: 0.912918746471405, Final Batch Loss: 0.27231672406196594\n",
      "Epoch 1153, Loss: 0.9992387890815735, Final Batch Loss: 0.3788965940475464\n",
      "Epoch 1154, Loss: 1.1311006247997284, Final Batch Loss: 0.39849308133125305\n",
      "Epoch 1155, Loss: 1.0302000641822815, Final Batch Loss: 0.3324835002422333\n",
      "Epoch 1156, Loss: 0.9962234497070312, Final Batch Loss: 0.33563604950904846\n",
      "Epoch 1157, Loss: 1.0872606337070465, Final Batch Loss: 0.43400001525878906\n",
      "Epoch 1158, Loss: 1.010994166135788, Final Batch Loss: 0.36778271198272705\n",
      "Epoch 1159, Loss: 0.9395045042037964, Final Batch Loss: 0.37564152479171753\n",
      "Epoch 1160, Loss: 1.0656166970729828, Final Batch Loss: 0.28477197885513306\n",
      "Epoch 1161, Loss: 1.1141290962696075, Final Batch Loss: 0.3928014636039734\n",
      "Epoch 1162, Loss: 1.0378064513206482, Final Batch Loss: 0.30154767632484436\n",
      "Epoch 1163, Loss: 0.8823442757129669, Final Batch Loss: 0.30226653814315796\n",
      "Epoch 1164, Loss: 0.9501963555812836, Final Batch Loss: 0.29651111364364624\n",
      "Epoch 1165, Loss: 0.9456049799919128, Final Batch Loss: 0.306957483291626\n",
      "Epoch 1166, Loss: 1.0197413861751556, Final Batch Loss: 0.35281553864479065\n",
      "Epoch 1167, Loss: 0.8904157429933548, Final Batch Loss: 0.21102292835712433\n",
      "Epoch 1168, Loss: 1.2034742534160614, Final Batch Loss: 0.4570925831794739\n",
      "Epoch 1169, Loss: 0.9232105612754822, Final Batch Loss: 0.28716757893562317\n",
      "Epoch 1170, Loss: 0.9762473702430725, Final Batch Loss: 0.36721381545066833\n",
      "Epoch 1171, Loss: 0.9855038225650787, Final Batch Loss: 0.34533220529556274\n",
      "Epoch 1172, Loss: 0.979418158531189, Final Batch Loss: 0.28362101316452026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1173, Loss: 0.9794884920120239, Final Batch Loss: 0.2897375524044037\n",
      "Epoch 1174, Loss: 0.9293053448200226, Final Batch Loss: 0.33860403299331665\n",
      "Epoch 1175, Loss: 0.9586000740528107, Final Batch Loss: 0.3353237509727478\n",
      "Epoch 1176, Loss: 1.0073286294937134, Final Batch Loss: 0.38295868039131165\n",
      "Epoch 1177, Loss: 1.043731689453125, Final Batch Loss: 0.2871409058570862\n",
      "Epoch 1178, Loss: 0.9629430770874023, Final Batch Loss: 0.27388203144073486\n",
      "Epoch 1179, Loss: 0.9366088807582855, Final Batch Loss: 0.27063021063804626\n",
      "Epoch 1180, Loss: 0.8633194863796234, Final Batch Loss: 0.27061599493026733\n",
      "Epoch 1181, Loss: 1.0342730283737183, Final Batch Loss: 0.38813501596450806\n",
      "Epoch 1182, Loss: 0.9931042194366455, Final Batch Loss: 0.38780510425567627\n",
      "Epoch 1183, Loss: 0.8326592892408371, Final Batch Loss: 0.2758968472480774\n",
      "Epoch 1184, Loss: 0.9735236465930939, Final Batch Loss: 0.3718497157096863\n",
      "Epoch 1185, Loss: 1.0534497499465942, Final Batch Loss: 0.3172023296356201\n",
      "Epoch 1186, Loss: 0.9614994525909424, Final Batch Loss: 0.3433939516544342\n",
      "Epoch 1187, Loss: 0.9178487658500671, Final Batch Loss: 0.2668604254722595\n",
      "Epoch 1188, Loss: 0.9616745114326477, Final Batch Loss: 0.3459237813949585\n",
      "Epoch 1189, Loss: 0.8603158593177795, Final Batch Loss: 0.26026663184165955\n",
      "Epoch 1190, Loss: 0.8775257766246796, Final Batch Loss: 0.2714196443557739\n",
      "Epoch 1191, Loss: 1.0020450353622437, Final Batch Loss: 0.3071742355823517\n",
      "Epoch 1192, Loss: 0.9840786457061768, Final Batch Loss: 0.30971673130989075\n",
      "Epoch 1193, Loss: 0.9144144356250763, Final Batch Loss: 0.2544610798358917\n",
      "Epoch 1194, Loss: 0.894286185503006, Final Batch Loss: 0.30291447043418884\n",
      "Epoch 1195, Loss: 0.9665407538414001, Final Batch Loss: 0.3038049638271332\n",
      "Epoch 1196, Loss: 0.9725160151720047, Final Batch Loss: 0.24259720742702484\n",
      "Epoch 1197, Loss: 1.0646914541721344, Final Batch Loss: 0.31388968229293823\n",
      "Epoch 1198, Loss: 0.8755040764808655, Final Batch Loss: 0.24594241380691528\n",
      "Epoch 1199, Loss: 0.9859572649002075, Final Batch Loss: 0.329858660697937\n",
      "Epoch 1200, Loss: 1.066521316766739, Final Batch Loss: 0.4025544822216034\n",
      "Epoch 1201, Loss: 0.9612258076667786, Final Batch Loss: 0.29099053144454956\n",
      "Epoch 1202, Loss: 0.9549066722393036, Final Batch Loss: 0.3404785394668579\n",
      "Epoch 1203, Loss: 1.072021245956421, Final Batch Loss: 0.4151553213596344\n",
      "Epoch 1204, Loss: 0.9221782088279724, Final Batch Loss: 0.2867186367511749\n",
      "Epoch 1205, Loss: 0.9552183747291565, Final Batch Loss: 0.3932103216648102\n",
      "Epoch 1206, Loss: 0.9322834014892578, Final Batch Loss: 0.2962754964828491\n",
      "Epoch 1207, Loss: 0.8669769912958145, Final Batch Loss: 0.23050068318843842\n",
      "Epoch 1208, Loss: 0.9829789400100708, Final Batch Loss: 0.3399806320667267\n",
      "Epoch 1209, Loss: 0.9649128019809723, Final Batch Loss: 0.33972764015197754\n",
      "Epoch 1210, Loss: 0.8571511209011078, Final Batch Loss: 0.2542557418346405\n",
      "Epoch 1211, Loss: 0.9130031764507294, Final Batch Loss: 0.29075491428375244\n",
      "Epoch 1212, Loss: 1.0094368755817413, Final Batch Loss: 0.36043989658355713\n",
      "Epoch 1213, Loss: 0.898077055811882, Final Batch Loss: 0.3214145600795746\n",
      "Epoch 1214, Loss: 0.9938222467899323, Final Batch Loss: 0.33273881673812866\n",
      "Epoch 1215, Loss: 0.9537334144115448, Final Batch Loss: 0.33437004685401917\n",
      "Epoch 1216, Loss: 0.8549601435661316, Final Batch Loss: 0.2725701630115509\n",
      "Epoch 1217, Loss: 1.0864746272563934, Final Batch Loss: 0.3524651825428009\n",
      "Epoch 1218, Loss: 0.9302172511816025, Final Batch Loss: 0.23805062472820282\n",
      "Epoch 1219, Loss: 0.958448201417923, Final Batch Loss: 0.3837152123451233\n",
      "Epoch 1220, Loss: 1.0986511707305908, Final Batch Loss: 0.4573117196559906\n",
      "Epoch 1221, Loss: 0.9611052572727203, Final Batch Loss: 0.31632447242736816\n",
      "Epoch 1222, Loss: 0.9856860041618347, Final Batch Loss: 0.3904077410697937\n",
      "Epoch 1223, Loss: 0.8682342767715454, Final Batch Loss: 0.26742222905158997\n",
      "Epoch 1224, Loss: 1.0330324470996857, Final Batch Loss: 0.38016629219055176\n",
      "Epoch 1225, Loss: 0.9346251487731934, Final Batch Loss: 0.32858461141586304\n",
      "Epoch 1226, Loss: 0.9226402640342712, Final Batch Loss: 0.3013419508934021\n",
      "Epoch 1227, Loss: 0.9081746637821198, Final Batch Loss: 0.26057708263397217\n",
      "Epoch 1228, Loss: 0.9393249452114105, Final Batch Loss: 0.38768693804740906\n",
      "Epoch 1229, Loss: 0.9793220460414886, Final Batch Loss: 0.36137592792510986\n",
      "Epoch 1230, Loss: 0.9343865513801575, Final Batch Loss: 0.3503119647502899\n",
      "Epoch 1231, Loss: 0.9700764119625092, Final Batch Loss: 0.35586321353912354\n",
      "Epoch 1232, Loss: 0.8728455603122711, Final Batch Loss: 0.30548718571662903\n",
      "Epoch 1233, Loss: 0.9315599203109741, Final Batch Loss: 0.29713261127471924\n",
      "Epoch 1234, Loss: 1.0135069489479065, Final Batch Loss: 0.40472206473350525\n",
      "Epoch 1235, Loss: 0.9857706427574158, Final Batch Loss: 0.3461593687534332\n",
      "Epoch 1236, Loss: 0.9202474355697632, Final Batch Loss: 0.31927064061164856\n",
      "Epoch 1237, Loss: 0.9822361171245575, Final Batch Loss: 0.2854631543159485\n",
      "Epoch 1238, Loss: 0.9909310638904572, Final Batch Loss: 0.35487499833106995\n",
      "Epoch 1239, Loss: 0.9576360285282135, Final Batch Loss: 0.2655731737613678\n",
      "Epoch 1240, Loss: 0.9680183231830597, Final Batch Loss: 0.30827662348747253\n",
      "Epoch 1241, Loss: 0.9589610993862152, Final Batch Loss: 0.3074911832809448\n",
      "Epoch 1242, Loss: 0.9299783110618591, Final Batch Loss: 0.27438291907310486\n",
      "Epoch 1243, Loss: 0.8941062986850739, Final Batch Loss: 0.2902770936489105\n",
      "Epoch 1244, Loss: 0.9251648187637329, Final Batch Loss: 0.3405313491821289\n",
      "Epoch 1245, Loss: 0.9337888062000275, Final Batch Loss: 0.31480419635772705\n",
      "Epoch 1246, Loss: 0.853622168302536, Final Batch Loss: 0.280580073595047\n",
      "Epoch 1247, Loss: 0.9398529529571533, Final Batch Loss: 0.3923080861568451\n",
      "Epoch 1248, Loss: 0.9671510756015778, Final Batch Loss: 0.30377086997032166\n",
      "Epoch 1249, Loss: 0.8834770023822784, Final Batch Loss: 0.32149145007133484\n",
      "Epoch 1250, Loss: 0.9593542814254761, Final Batch Loss: 0.3604186475276947\n",
      "Epoch 1251, Loss: 0.982445240020752, Final Batch Loss: 0.3115020990371704\n",
      "Epoch 1252, Loss: 0.8172158300876617, Final Batch Loss: 0.2337837517261505\n",
      "Epoch 1253, Loss: 0.8960497677326202, Final Batch Loss: 0.3081605136394501\n",
      "Epoch 1254, Loss: 0.8920822441577911, Final Batch Loss: 0.24181118607521057\n",
      "Epoch 1255, Loss: 0.8323093950748444, Final Batch Loss: 0.2889809310436249\n",
      "Epoch 1256, Loss: 0.9564452469348907, Final Batch Loss: 0.2677423059940338\n",
      "Epoch 1257, Loss: 0.914930909872055, Final Batch Loss: 0.3355238437652588\n",
      "Epoch 1258, Loss: 0.8864439725875854, Final Batch Loss: 0.2768247127532959\n",
      "Epoch 1259, Loss: 0.957908421754837, Final Batch Loss: 0.34685948491096497\n",
      "Epoch 1260, Loss: 0.9190324544906616, Final Batch Loss: 0.36253657937049866\n",
      "Epoch 1261, Loss: 0.8664342761039734, Final Batch Loss: 0.28003832697868347\n",
      "Epoch 1262, Loss: 0.834154024720192, Final Batch Loss: 0.2319999784231186\n",
      "Epoch 1263, Loss: 0.9235458374023438, Final Batch Loss: 0.3095610737800598\n",
      "Epoch 1264, Loss: 1.0639693140983582, Final Batch Loss: 0.49563655257225037\n",
      "Epoch 1265, Loss: 0.850993275642395, Final Batch Loss: 0.2903253734111786\n",
      "Epoch 1266, Loss: 0.8319162726402283, Final Batch Loss: 0.2621126174926758\n",
      "Epoch 1267, Loss: 0.9605534076690674, Final Batch Loss: 0.278935968875885\n",
      "Epoch 1268, Loss: 0.9353858828544617, Final Batch Loss: 0.3132069706916809\n",
      "Epoch 1269, Loss: 0.8956862986087799, Final Batch Loss: 0.3228234052658081\n",
      "Epoch 1270, Loss: 0.9831465482711792, Final Batch Loss: 0.35194772481918335\n",
      "Epoch 1271, Loss: 0.9267528355121613, Final Batch Loss: 0.2892836034297943\n",
      "Epoch 1272, Loss: 0.9348432123661041, Final Batch Loss: 0.3311811089515686\n",
      "Epoch 1273, Loss: 0.8659573942422867, Final Batch Loss: 0.3250848948955536\n",
      "Epoch 1274, Loss: 0.9026908278465271, Final Batch Loss: 0.2914636433124542\n",
      "Epoch 1275, Loss: 0.9185892939567566, Final Batch Loss: 0.33791884779930115\n",
      "Epoch 1276, Loss: 0.9631386399269104, Final Batch Loss: 0.3188740015029907\n",
      "Epoch 1277, Loss: 0.9180623292922974, Final Batch Loss: 0.32102811336517334\n",
      "Epoch 1278, Loss: 0.9086318910121918, Final Batch Loss: 0.3266710638999939\n",
      "Epoch 1279, Loss: 0.8976683020591736, Final Batch Loss: 0.3039674758911133\n",
      "Epoch 1280, Loss: 0.8886842429637909, Final Batch Loss: 0.2653447091579437\n",
      "Epoch 1281, Loss: 0.9330871999263763, Final Batch Loss: 0.3202148973941803\n",
      "Epoch 1282, Loss: 0.9053966701030731, Final Batch Loss: 0.2954547107219696\n",
      "Epoch 1283, Loss: 0.9005612730979919, Final Batch Loss: 0.279094934463501\n",
      "Epoch 1284, Loss: 0.9381703734397888, Final Batch Loss: 0.32956016063690186\n",
      "Epoch 1285, Loss: 0.8695147186517715, Final Batch Loss: 0.23701836168766022\n",
      "Epoch 1286, Loss: 0.990897536277771, Final Batch Loss: 0.35186004638671875\n",
      "Epoch 1287, Loss: 0.8002072274684906, Final Batch Loss: 0.22881940007209778\n",
      "Epoch 1288, Loss: 0.8243351131677628, Final Batch Loss: 0.2256014496088028\n",
      "Epoch 1289, Loss: 0.8925615698099136, Final Batch Loss: 0.31891515851020813\n",
      "Epoch 1290, Loss: 0.8697514235973358, Final Batch Loss: 0.26206380128860474\n",
      "Epoch 1291, Loss: 0.918053925037384, Final Batch Loss: 0.3161975145339966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1292, Loss: 0.950292319059372, Final Batch Loss: 0.3488456904888153\n",
      "Epoch 1293, Loss: 0.8287989795207977, Final Batch Loss: 0.28954023122787476\n",
      "Epoch 1294, Loss: 0.9847959876060486, Final Batch Loss: 0.35395896434783936\n",
      "Epoch 1295, Loss: 0.8515881299972534, Final Batch Loss: 0.2740436792373657\n",
      "Epoch 1296, Loss: 0.9493905901908875, Final Batch Loss: 0.3775506615638733\n",
      "Epoch 1297, Loss: 0.8099472522735596, Final Batch Loss: 0.27945324778556824\n",
      "Epoch 1298, Loss: 0.850291833281517, Final Batch Loss: 0.22051943838596344\n",
      "Epoch 1299, Loss: 0.8390391767024994, Final Batch Loss: 0.319864422082901\n",
      "Epoch 1300, Loss: 1.0235962271690369, Final Batch Loss: 0.3747974932193756\n",
      "Epoch 1301, Loss: 0.9668340086936951, Final Batch Loss: 0.31858372688293457\n",
      "Epoch 1302, Loss: 1.0364291667938232, Final Batch Loss: 0.39968764781951904\n",
      "Epoch 1303, Loss: 0.9343944191932678, Final Batch Loss: 0.382588267326355\n",
      "Epoch 1304, Loss: 0.8186122924089432, Final Batch Loss: 0.24133990705013275\n",
      "Epoch 1305, Loss: 0.9240342974662781, Final Batch Loss: 0.32726165652275085\n",
      "Epoch 1306, Loss: 0.935663640499115, Final Batch Loss: 0.35166606307029724\n",
      "Epoch 1307, Loss: 0.8905070126056671, Final Batch Loss: 0.28563058376312256\n",
      "Epoch 1308, Loss: 1.0790191888809204, Final Batch Loss: 0.43314746022224426\n",
      "Epoch 1309, Loss: 0.9246824681758881, Final Batch Loss: 0.2742566764354706\n",
      "Epoch 1310, Loss: 0.9248471558094025, Final Batch Loss: 0.25276219844818115\n",
      "Epoch 1311, Loss: 0.8566916584968567, Final Batch Loss: 0.25846123695373535\n",
      "Epoch 1312, Loss: 0.9804086983203888, Final Batch Loss: 0.2947849929332733\n",
      "Epoch 1313, Loss: 0.8469477891921997, Final Batch Loss: 0.3139503300189972\n",
      "Epoch 1314, Loss: 0.9557878375053406, Final Batch Loss: 0.33823445439338684\n",
      "Epoch 1315, Loss: 0.8617293238639832, Final Batch Loss: 0.2824823558330536\n",
      "Epoch 1316, Loss: 0.8990155160427094, Final Batch Loss: 0.2650826573371887\n",
      "Epoch 1317, Loss: 0.9113547205924988, Final Batch Loss: 0.32859495282173157\n",
      "Epoch 1318, Loss: 1.0066349506378174, Final Batch Loss: 0.29864197969436646\n",
      "Epoch 1319, Loss: 0.9516558647155762, Final Batch Loss: 0.4065376818180084\n",
      "Epoch 1320, Loss: 0.9223172068595886, Final Batch Loss: 0.3576110303401947\n",
      "Epoch 1321, Loss: 0.9729142189025879, Final Batch Loss: 0.40766641497612\n",
      "Epoch 1322, Loss: 0.904175192117691, Final Batch Loss: 0.2655334770679474\n",
      "Epoch 1323, Loss: 0.9355166256427765, Final Batch Loss: 0.333439439535141\n",
      "Epoch 1324, Loss: 0.8255051672458649, Final Batch Loss: 0.2734728455543518\n",
      "Epoch 1325, Loss: 0.9269107282161713, Final Batch Loss: 0.4022866487503052\n",
      "Epoch 1326, Loss: 0.8933632522821426, Final Batch Loss: 0.3538714647293091\n",
      "Epoch 1327, Loss: 0.828214019536972, Final Batch Loss: 0.27822044491767883\n",
      "Epoch 1328, Loss: 0.799816831946373, Final Batch Loss: 0.24523192644119263\n",
      "Epoch 1329, Loss: 0.8974433243274689, Final Batch Loss: 0.34778448939323425\n",
      "Epoch 1330, Loss: 0.9186868071556091, Final Batch Loss: 0.2761169970035553\n",
      "Epoch 1331, Loss: 0.8784496188163757, Final Batch Loss: 0.28301653265953064\n",
      "Epoch 1332, Loss: 0.9306220710277557, Final Batch Loss: 0.3365970253944397\n",
      "Epoch 1333, Loss: 0.8490702956914902, Final Batch Loss: 0.248545840382576\n",
      "Epoch 1334, Loss: 0.8602963238954544, Final Batch Loss: 0.24477164447307587\n",
      "Epoch 1335, Loss: 0.9273715019226074, Final Batch Loss: 0.2676796615123749\n",
      "Epoch 1336, Loss: 0.7900963723659515, Final Batch Loss: 0.25237494707107544\n",
      "Epoch 1337, Loss: 0.9527195990085602, Final Batch Loss: 0.34691768884658813\n",
      "Epoch 1338, Loss: 0.8978974521160126, Final Batch Loss: 0.32784777879714966\n",
      "Epoch 1339, Loss: 0.9333794713020325, Final Batch Loss: 0.2767185866832733\n",
      "Epoch 1340, Loss: 0.8844121396541595, Final Batch Loss: 0.36466357111930847\n",
      "Epoch 1341, Loss: 0.9599301218986511, Final Batch Loss: 0.2878945469856262\n",
      "Epoch 1342, Loss: 0.8395189046859741, Final Batch Loss: 0.21723616123199463\n",
      "Epoch 1343, Loss: 0.7747646868228912, Final Batch Loss: 0.26733317971229553\n",
      "Epoch 1344, Loss: 0.9664115607738495, Final Batch Loss: 0.3362083435058594\n",
      "Epoch 1345, Loss: 0.8570351451635361, Final Batch Loss: 0.24142612516880035\n",
      "Epoch 1346, Loss: 0.9248144924640656, Final Batch Loss: 0.3149438798427582\n",
      "Epoch 1347, Loss: 0.9226136803627014, Final Batch Loss: 0.36670538783073425\n",
      "Epoch 1348, Loss: 0.9435441493988037, Final Batch Loss: 0.34112057089805603\n",
      "Epoch 1349, Loss: 0.9432744383811951, Final Batch Loss: 0.34915000200271606\n",
      "Epoch 1350, Loss: 0.9369071125984192, Final Batch Loss: 0.29748138785362244\n",
      "Epoch 1351, Loss: 0.8838392198085785, Final Batch Loss: 0.33182117342948914\n",
      "Epoch 1352, Loss: 1.0062400698661804, Final Batch Loss: 0.332622766494751\n",
      "Epoch 1353, Loss: 0.9105086624622345, Final Batch Loss: 0.3073537051677704\n",
      "Epoch 1354, Loss: 0.7523058950901031, Final Batch Loss: 0.2154417634010315\n",
      "Epoch 1355, Loss: 0.904982179403305, Final Batch Loss: 0.2263183891773224\n",
      "Epoch 1356, Loss: 0.9006607532501221, Final Batch Loss: 0.3436761200428009\n",
      "Epoch 1357, Loss: 0.8360308110713959, Final Batch Loss: 0.19279077649116516\n",
      "Epoch 1358, Loss: 0.8397912979125977, Final Batch Loss: 0.2876169681549072\n",
      "Epoch 1359, Loss: 0.8852032124996185, Final Batch Loss: 0.28224942088127136\n",
      "Epoch 1360, Loss: 0.8604749739170074, Final Batch Loss: 0.2961879372596741\n",
      "Epoch 1361, Loss: 0.8753388375043869, Final Batch Loss: 0.2922351360321045\n",
      "Epoch 1362, Loss: 0.806481271982193, Final Batch Loss: 0.2627184987068176\n",
      "Epoch 1363, Loss: 0.8812585771083832, Final Batch Loss: 0.3304406702518463\n",
      "Epoch 1364, Loss: 0.8836267590522766, Final Batch Loss: 0.3203180730342865\n",
      "Epoch 1365, Loss: 0.8234148025512695, Final Batch Loss: 0.2801102101802826\n",
      "Epoch 1366, Loss: 0.8549494743347168, Final Batch Loss: 0.23093760013580322\n",
      "Epoch 1367, Loss: 0.9229961782693863, Final Batch Loss: 0.32361409068107605\n",
      "Epoch 1368, Loss: 0.8117555677890778, Final Batch Loss: 0.2652808725833893\n",
      "Epoch 1369, Loss: 0.8294349163770676, Final Batch Loss: 0.2011236995458603\n",
      "Epoch 1370, Loss: 0.9439062476158142, Final Batch Loss: 0.3364390730857849\n",
      "Epoch 1371, Loss: 0.9140660464763641, Final Batch Loss: 0.3210659325122833\n",
      "Epoch 1372, Loss: 0.8469071686267853, Final Batch Loss: 0.3433877229690552\n",
      "Epoch 1373, Loss: 0.9785042107105255, Final Batch Loss: 0.28739723563194275\n",
      "Epoch 1374, Loss: 0.8194644600152969, Final Batch Loss: 0.23257334530353546\n",
      "Epoch 1375, Loss: 0.8119792193174362, Final Batch Loss: 0.23287995159626007\n",
      "Epoch 1376, Loss: 0.8015569150447845, Final Batch Loss: 0.2266974300146103\n",
      "Epoch 1377, Loss: 0.9416102170944214, Final Batch Loss: 0.3209797441959381\n",
      "Epoch 1378, Loss: 0.8413865119218826, Final Batch Loss: 0.21774832904338837\n",
      "Epoch 1379, Loss: 0.7199396193027496, Final Batch Loss: 0.19224274158477783\n",
      "Epoch 1380, Loss: 0.8349796235561371, Final Batch Loss: 0.22236120700836182\n",
      "Epoch 1381, Loss: 0.7455801516771317, Final Batch Loss: 0.22813387215137482\n",
      "Epoch 1382, Loss: 0.9520370960235596, Final Batch Loss: 0.3135288953781128\n",
      "Epoch 1383, Loss: 0.9380666315555573, Final Batch Loss: 0.34281888604164124\n",
      "Epoch 1384, Loss: 0.837093710899353, Final Batch Loss: 0.2687073349952698\n",
      "Epoch 1385, Loss: 0.8496461510658264, Final Batch Loss: 0.32226288318634033\n",
      "Epoch 1386, Loss: 0.8410229831933975, Final Batch Loss: 0.3178459703922272\n",
      "Epoch 1387, Loss: 0.8717164397239685, Final Batch Loss: 0.30839812755584717\n",
      "Epoch 1388, Loss: 0.9394969046115875, Final Batch Loss: 0.3240671753883362\n",
      "Epoch 1389, Loss: 0.8585699498653412, Final Batch Loss: 0.29484912753105164\n",
      "Epoch 1390, Loss: 0.8905355930328369, Final Batch Loss: 0.31132757663726807\n",
      "Epoch 1391, Loss: 0.7416191548109055, Final Batch Loss: 0.23401962220668793\n",
      "Epoch 1392, Loss: 0.7944732308387756, Final Batch Loss: 0.1737227439880371\n",
      "Epoch 1393, Loss: 0.806091234087944, Final Batch Loss: 0.24825097620487213\n",
      "Epoch 1394, Loss: 0.7542626559734344, Final Batch Loss: 0.2062254250049591\n",
      "Epoch 1395, Loss: 0.868240237236023, Final Batch Loss: 0.328791081905365\n",
      "Epoch 1396, Loss: 0.8085449635982513, Final Batch Loss: 0.223624587059021\n",
      "Epoch 1397, Loss: 0.8052681237459183, Final Batch Loss: 0.3105001747608185\n",
      "Epoch 1398, Loss: 0.8200034201145172, Final Batch Loss: 0.24363011121749878\n",
      "Epoch 1399, Loss: 0.8843480348587036, Final Batch Loss: 0.3393738269805908\n",
      "Epoch 1400, Loss: 0.8146393001079559, Final Batch Loss: 0.2538977265357971\n",
      "Epoch 1401, Loss: 0.7942705899477005, Final Batch Loss: 0.26538532972335815\n",
      "Epoch 1402, Loss: 0.8207886219024658, Final Batch Loss: 0.24061188101768494\n",
      "Epoch 1403, Loss: 0.9054430425167084, Final Batch Loss: 0.27159997820854187\n",
      "Epoch 1404, Loss: 0.8260151594877243, Final Batch Loss: 0.30527210235595703\n",
      "Epoch 1405, Loss: 0.7849336713552475, Final Batch Loss: 0.2490610033273697\n",
      "Epoch 1406, Loss: 0.8638448417186737, Final Batch Loss: 0.32536378502845764\n",
      "Epoch 1407, Loss: 0.9030159711837769, Final Batch Loss: 0.26431867480278015\n",
      "Epoch 1408, Loss: 0.8104845434427261, Final Batch Loss: 0.23234514892101288\n",
      "Epoch 1409, Loss: 0.7336656451225281, Final Batch Loss: 0.23128177225589752\n",
      "Epoch 1410, Loss: 0.8093754798173904, Final Batch Loss: 0.2975175380706787\n",
      "Epoch 1411, Loss: 0.7648380249738693, Final Batch Loss: 0.21902675926685333\n",
      "Epoch 1412, Loss: 0.9008792787790298, Final Batch Loss: 0.35843005776405334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1413, Loss: 0.7994113266468048, Final Batch Loss: 0.281213641166687\n",
      "Epoch 1414, Loss: 0.8518480509519577, Final Batch Loss: 0.35669806599617004\n",
      "Epoch 1415, Loss: 0.8269369751214981, Final Batch Loss: 0.1861291080713272\n",
      "Epoch 1416, Loss: 0.9733631014823914, Final Batch Loss: 0.30309998989105225\n",
      "Epoch 1417, Loss: 0.8478958606719971, Final Batch Loss: 0.27062633633613586\n",
      "Epoch 1418, Loss: 0.9594119787216187, Final Batch Loss: 0.32066768407821655\n",
      "Epoch 1419, Loss: 0.9436036646366119, Final Batch Loss: 0.28216856718063354\n",
      "Epoch 1420, Loss: 0.8903665244579315, Final Batch Loss: 0.293335497379303\n",
      "Epoch 1421, Loss: 0.8030880838632584, Final Batch Loss: 0.2038070112466812\n",
      "Epoch 1422, Loss: 0.8534954190254211, Final Batch Loss: 0.2502250671386719\n",
      "Epoch 1423, Loss: 0.847197949886322, Final Batch Loss: 0.3077738285064697\n",
      "Epoch 1424, Loss: 0.8602084666490555, Final Batch Loss: 0.26549580693244934\n",
      "Epoch 1425, Loss: 0.8999271541833878, Final Batch Loss: 0.3528425693511963\n",
      "Epoch 1426, Loss: 0.8339645266532898, Final Batch Loss: 0.2649763822555542\n",
      "Epoch 1427, Loss: 0.8340175747871399, Final Batch Loss: 0.2681227922439575\n",
      "Epoch 1428, Loss: 0.8597676455974579, Final Batch Loss: 0.3349323868751526\n",
      "Epoch 1429, Loss: 0.7698716521263123, Final Batch Loss: 0.2713784873485565\n",
      "Epoch 1430, Loss: 0.7717224955558777, Final Batch Loss: 0.2647850513458252\n",
      "Epoch 1431, Loss: 0.8089949786663055, Final Batch Loss: 0.2555527091026306\n",
      "Epoch 1432, Loss: 0.8591118305921555, Final Batch Loss: 0.3690069615840912\n",
      "Epoch 1433, Loss: 0.8185544610023499, Final Batch Loss: 0.3123258650302887\n",
      "Epoch 1434, Loss: 0.8252054750919342, Final Batch Loss: 0.1906822919845581\n",
      "Epoch 1435, Loss: 0.7286147922277451, Final Batch Loss: 0.18798419833183289\n",
      "Epoch 1436, Loss: 0.8885693401098251, Final Batch Loss: 0.24858064949512482\n",
      "Epoch 1437, Loss: 0.8124164938926697, Final Batch Loss: 0.2623668909072876\n",
      "Epoch 1438, Loss: 0.8389098346233368, Final Batch Loss: 0.26492664217948914\n",
      "Epoch 1439, Loss: 0.8240879476070404, Final Batch Loss: 0.25460776686668396\n",
      "Epoch 1440, Loss: 0.9869291484355927, Final Batch Loss: 0.3609882593154907\n",
      "Epoch 1441, Loss: 0.9055645167827606, Final Batch Loss: 0.3233168125152588\n",
      "Epoch 1442, Loss: 0.873051181435585, Final Batch Loss: 0.40036240220069885\n",
      "Epoch 1443, Loss: 0.7373282164335251, Final Batch Loss: 0.26953184604644775\n",
      "Epoch 1444, Loss: 0.7441297024488449, Final Batch Loss: 0.20647896826267242\n",
      "Epoch 1445, Loss: 0.8994456827640533, Final Batch Loss: 0.2698383927345276\n",
      "Epoch 1446, Loss: 0.8520414382219315, Final Batch Loss: 0.24229015409946442\n",
      "Epoch 1447, Loss: 0.9116371870040894, Final Batch Loss: 0.30765965580940247\n",
      "Epoch 1448, Loss: 0.889635905623436, Final Batch Loss: 0.3564821183681488\n",
      "Epoch 1449, Loss: 0.9685284197330475, Final Batch Loss: 0.354204386472702\n",
      "Epoch 1450, Loss: 0.738738939166069, Final Batch Loss: 0.21721120178699493\n",
      "Epoch 1451, Loss: 0.818534642457962, Final Batch Loss: 0.25101396441459656\n",
      "Epoch 1452, Loss: 0.8640348166227341, Final Batch Loss: 0.23826535046100616\n",
      "Epoch 1453, Loss: 1.0949189066886902, Final Batch Loss: 0.5165038108825684\n",
      "Epoch 1454, Loss: 0.9413763880729675, Final Batch Loss: 0.3709760308265686\n",
      "Epoch 1455, Loss: 0.8626737892627716, Final Batch Loss: 0.30522140860557556\n",
      "Epoch 1456, Loss: 0.8712386786937714, Final Batch Loss: 0.2378898710012436\n",
      "Epoch 1457, Loss: 0.8940834105014801, Final Batch Loss: 0.3627990186214447\n",
      "Epoch 1458, Loss: 0.8460231274366379, Final Batch Loss: 0.2072819024324417\n",
      "Epoch 1459, Loss: 0.8306022733449936, Final Batch Loss: 0.2778550386428833\n",
      "Epoch 1460, Loss: 0.7507973313331604, Final Batch Loss: 0.24189060926437378\n",
      "Epoch 1461, Loss: 0.8874512761831284, Final Batch Loss: 0.35161250829696655\n",
      "Epoch 1462, Loss: 0.8461669385433197, Final Batch Loss: 0.30227819085121155\n",
      "Epoch 1463, Loss: 0.8958478271961212, Final Batch Loss: 0.27938342094421387\n",
      "Epoch 1464, Loss: 0.9876952767372131, Final Batch Loss: 0.35125842690467834\n",
      "Epoch 1465, Loss: 0.7697754949331284, Final Batch Loss: 0.24553640186786652\n",
      "Epoch 1466, Loss: 0.9049726128578186, Final Batch Loss: 0.31834810972213745\n",
      "Epoch 1467, Loss: 0.7692624181509018, Final Batch Loss: 0.27714937925338745\n",
      "Epoch 1468, Loss: 0.7398457825183868, Final Batch Loss: 0.24455279111862183\n",
      "Epoch 1469, Loss: 0.7966499030590057, Final Batch Loss: 0.28996720910072327\n",
      "Epoch 1470, Loss: 0.7640362977981567, Final Batch Loss: 0.20653405785560608\n",
      "Epoch 1471, Loss: 0.8683137148618698, Final Batch Loss: 0.3258514106273651\n",
      "Epoch 1472, Loss: 0.8476575314998627, Final Batch Loss: 0.2825051546096802\n",
      "Epoch 1473, Loss: 0.8515555560588837, Final Batch Loss: 0.3196054995059967\n",
      "Epoch 1474, Loss: 0.8435216248035431, Final Batch Loss: 0.23771658539772034\n",
      "Epoch 1475, Loss: 0.7782551050186157, Final Batch Loss: 0.23938798904418945\n",
      "Epoch 1476, Loss: 0.8008613586425781, Final Batch Loss: 0.219178706407547\n",
      "Epoch 1477, Loss: 0.7892775535583496, Final Batch Loss: 0.2660074532032013\n",
      "Epoch 1478, Loss: 0.78028804063797, Final Batch Loss: 0.26465722918510437\n",
      "Epoch 1479, Loss: 0.8675526678562164, Final Batch Loss: 0.31826820969581604\n",
      "Epoch 1480, Loss: 0.8450733870267868, Final Batch Loss: 0.27552229166030884\n",
      "Epoch 1481, Loss: 0.8075371235609055, Final Batch Loss: 0.34887415170669556\n",
      "Epoch 1482, Loss: 0.9006377756595612, Final Batch Loss: 0.3334297239780426\n",
      "Epoch 1483, Loss: 0.857608437538147, Final Batch Loss: 0.2857280373573303\n",
      "Epoch 1484, Loss: 0.8032799959182739, Final Batch Loss: 0.2923279404640198\n",
      "Epoch 1485, Loss: 0.8719310760498047, Final Batch Loss: 0.27356961369514465\n",
      "Epoch 1486, Loss: 0.9244333207607269, Final Batch Loss: 0.3383483290672302\n",
      "Epoch 1487, Loss: 0.8171191513538361, Final Batch Loss: 0.24235469102859497\n",
      "Epoch 1488, Loss: 0.8916691243648529, Final Batch Loss: 0.28703367710113525\n",
      "Epoch 1489, Loss: 0.9129244983196259, Final Batch Loss: 0.35996562242507935\n",
      "Epoch 1490, Loss: 0.7955445796251297, Final Batch Loss: 0.2079250067472458\n",
      "Epoch 1491, Loss: 0.9434604346752167, Final Batch Loss: 0.28803953528404236\n",
      "Epoch 1492, Loss: 0.8529028296470642, Final Batch Loss: 0.22573229670524597\n",
      "Epoch 1493, Loss: 0.9261446595191956, Final Batch Loss: 0.3118307888507843\n",
      "Epoch 1494, Loss: 0.8923904597759247, Final Batch Loss: 0.33267125487327576\n",
      "Epoch 1495, Loss: 0.8698394596576691, Final Batch Loss: 0.2670881152153015\n",
      "Epoch 1496, Loss: 0.8473118543624878, Final Batch Loss: 0.2894380986690521\n",
      "Epoch 1497, Loss: 0.7612520307302475, Final Batch Loss: 0.2917217016220093\n",
      "Epoch 1498, Loss: 0.8688743859529495, Final Batch Loss: 0.2899591028690338\n",
      "Epoch 1499, Loss: 0.8230389505624771, Final Batch Loss: 0.22272299230098724\n",
      "Epoch 1500, Loss: 0.8730478882789612, Final Batch Loss: 0.2936028838157654\n",
      "Epoch 1501, Loss: 0.786688894033432, Final Batch Loss: 0.2688054144382477\n",
      "Epoch 1502, Loss: 0.9557265937328339, Final Batch Loss: 0.37834081053733826\n",
      "Epoch 1503, Loss: 0.9433560371398926, Final Batch Loss: 0.3531339466571808\n",
      "Epoch 1504, Loss: 0.7381785660982132, Final Batch Loss: 0.2315901666879654\n",
      "Epoch 1505, Loss: 0.7951492071151733, Final Batch Loss: 0.25144529342651367\n",
      "Epoch 1506, Loss: 0.8632525503635406, Final Batch Loss: 0.2844892144203186\n",
      "Epoch 1507, Loss: 0.9599466472864151, Final Batch Loss: 0.39061421155929565\n",
      "Epoch 1508, Loss: 0.8167239725589752, Final Batch Loss: 0.25297969579696655\n",
      "Epoch 1509, Loss: 0.7188681215047836, Final Batch Loss: 0.196904718875885\n",
      "Epoch 1510, Loss: 0.8950279057025909, Final Batch Loss: 0.2828117609024048\n",
      "Epoch 1511, Loss: 0.847647100687027, Final Batch Loss: 0.2507951855659485\n",
      "Epoch 1512, Loss: 0.8499888181686401, Final Batch Loss: 0.20327827334403992\n",
      "Epoch 1513, Loss: 0.817871481180191, Final Batch Loss: 0.29467105865478516\n",
      "Epoch 1514, Loss: 0.7575990408658981, Final Batch Loss: 0.23531471192836761\n",
      "Epoch 1515, Loss: 0.8670108914375305, Final Batch Loss: 0.28929638862609863\n",
      "Epoch 1516, Loss: 0.9305138885974884, Final Batch Loss: 0.3084031045436859\n",
      "Epoch 1517, Loss: 0.7021781951189041, Final Batch Loss: 0.17291222512722015\n",
      "Epoch 1518, Loss: 0.7905494868755341, Final Batch Loss: 0.23410451412200928\n",
      "Epoch 1519, Loss: 0.7409393340349197, Final Batch Loss: 0.18205006420612335\n",
      "Epoch 1520, Loss: 0.9296131432056427, Final Batch Loss: 0.3579084873199463\n",
      "Epoch 1521, Loss: 0.7654452919960022, Final Batch Loss: 0.24073247611522675\n",
      "Epoch 1522, Loss: 0.8204636424779892, Final Batch Loss: 0.3369884192943573\n",
      "Epoch 1523, Loss: 0.8120282888412476, Final Batch Loss: 0.2509746551513672\n",
      "Epoch 1524, Loss: 0.8688477873802185, Final Batch Loss: 0.31305786967277527\n",
      "Epoch 1525, Loss: 0.9307846575975418, Final Batch Loss: 0.3696998655796051\n",
      "Epoch 1526, Loss: 0.773903101682663, Final Batch Loss: 0.2202301025390625\n",
      "Epoch 1527, Loss: 0.7307515740394592, Final Batch Loss: 0.2576170265674591\n",
      "Epoch 1528, Loss: 0.8841306567192078, Final Batch Loss: 0.36128586530685425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1529, Loss: 0.7729925662279129, Final Batch Loss: 0.2531716823577881\n",
      "Epoch 1530, Loss: 0.7848782241344452, Final Batch Loss: 0.2504250109195709\n",
      "Epoch 1531, Loss: 0.7407642304897308, Final Batch Loss: 0.20444202423095703\n",
      "Epoch 1532, Loss: 0.7826901078224182, Final Batch Loss: 0.1421234905719757\n",
      "Epoch 1533, Loss: 0.820011168718338, Final Batch Loss: 0.3038327991962433\n",
      "Epoch 1534, Loss: 0.7462247610092163, Final Batch Loss: 0.23269502818584442\n",
      "Epoch 1535, Loss: 0.7734108120203018, Final Batch Loss: 0.20143403112888336\n",
      "Epoch 1536, Loss: 0.8859858959913254, Final Batch Loss: 0.400969535112381\n",
      "Epoch 1537, Loss: 0.7584187239408493, Final Batch Loss: 0.24665531516075134\n",
      "Epoch 1538, Loss: 0.827819213271141, Final Batch Loss: 0.2449042946100235\n",
      "Epoch 1539, Loss: 0.8092496693134308, Final Batch Loss: 0.3014167845249176\n",
      "Epoch 1540, Loss: 0.7632044702768326, Final Batch Loss: 0.2399311512708664\n",
      "Epoch 1541, Loss: 0.7631410956382751, Final Batch Loss: 0.24464184045791626\n",
      "Epoch 1542, Loss: 0.7568875998258591, Final Batch Loss: 0.23420731723308563\n",
      "Epoch 1543, Loss: 0.6981481164693832, Final Batch Loss: 0.16352300345897675\n",
      "Epoch 1544, Loss: 0.7537575662136078, Final Batch Loss: 0.21292391419410706\n",
      "Epoch 1545, Loss: 0.7749580293893814, Final Batch Loss: 0.2846715748310089\n",
      "Epoch 1546, Loss: 0.7344726175069809, Final Batch Loss: 0.24771244823932648\n",
      "Epoch 1547, Loss: 0.8495274186134338, Final Batch Loss: 0.3551505506038666\n",
      "Epoch 1548, Loss: 0.8273459672927856, Final Batch Loss: 0.3007402718067169\n",
      "Epoch 1549, Loss: 0.8085978627204895, Final Batch Loss: 0.28386303782463074\n",
      "Epoch 1550, Loss: 0.7766486704349518, Final Batch Loss: 0.26718878746032715\n",
      "Epoch 1551, Loss: 0.827301412820816, Final Batch Loss: 0.22699815034866333\n",
      "Epoch 1552, Loss: 0.8928206861019135, Final Batch Loss: 0.34545424580574036\n",
      "Epoch 1553, Loss: 0.8113659173250198, Final Batch Loss: 0.29368075728416443\n",
      "Epoch 1554, Loss: 0.7509230375289917, Final Batch Loss: 0.2760626971721649\n",
      "Epoch 1555, Loss: 0.7716409415006638, Final Batch Loss: 0.25779372453689575\n",
      "Epoch 1556, Loss: 0.7201182544231415, Final Batch Loss: 0.20923539996147156\n",
      "Epoch 1557, Loss: 0.8517220616340637, Final Batch Loss: 0.29651767015457153\n",
      "Epoch 1558, Loss: 0.86940036714077, Final Batch Loss: 0.20625929534435272\n",
      "Epoch 1559, Loss: 0.7917310893535614, Final Batch Loss: 0.2585335373878479\n",
      "Epoch 1560, Loss: 0.8493291586637497, Final Batch Loss: 0.24687673151493073\n",
      "Epoch 1561, Loss: 0.8057959973812103, Final Batch Loss: 0.2320217788219452\n",
      "Epoch 1562, Loss: 0.7496970742940903, Final Batch Loss: 0.2567923665046692\n",
      "Epoch 1563, Loss: 0.813143715262413, Final Batch Loss: 0.2306482046842575\n",
      "Epoch 1564, Loss: 0.7963700145483017, Final Batch Loss: 0.323779821395874\n",
      "Epoch 1565, Loss: 0.859584391117096, Final Batch Loss: 0.3546690046787262\n",
      "Epoch 1566, Loss: 0.8150370121002197, Final Batch Loss: 0.30567988753318787\n",
      "Epoch 1567, Loss: 0.9130375683307648, Final Batch Loss: 0.3749029338359833\n",
      "Epoch 1568, Loss: 0.841974526643753, Final Batch Loss: 0.3615563213825226\n",
      "Epoch 1569, Loss: 0.741189494729042, Final Batch Loss: 0.23768727481365204\n",
      "Epoch 1570, Loss: 0.7389123141765594, Final Batch Loss: 0.22696994245052338\n",
      "Epoch 1571, Loss: 0.815241664648056, Final Batch Loss: 0.31200721859931946\n",
      "Epoch 1572, Loss: 0.8056536912918091, Final Batch Loss: 0.25201401114463806\n",
      "Epoch 1573, Loss: 0.8311584144830704, Final Batch Loss: 0.31694740056991577\n",
      "Epoch 1574, Loss: 0.7376445680856705, Final Batch Loss: 0.208412304520607\n",
      "Epoch 1575, Loss: 0.8717576861381531, Final Batch Loss: 0.38245657086372375\n",
      "Epoch 1576, Loss: 0.8158438503742218, Final Batch Loss: 0.26956745982170105\n",
      "Epoch 1577, Loss: 0.7653188407421112, Final Batch Loss: 0.2065492570400238\n",
      "Epoch 1578, Loss: 0.796320378780365, Final Batch Loss: 0.2700093686580658\n",
      "Epoch 1579, Loss: 0.7806829363107681, Final Batch Loss: 0.236518993973732\n",
      "Epoch 1580, Loss: 0.786624550819397, Final Batch Loss: 0.2758059799671173\n",
      "Epoch 1581, Loss: 0.8046903312206268, Final Batch Loss: 0.2825365662574768\n",
      "Epoch 1582, Loss: 0.6804501861333847, Final Batch Loss: 0.17957553267478943\n",
      "Epoch 1583, Loss: 0.958933562040329, Final Batch Loss: 0.39126288890838623\n",
      "Epoch 1584, Loss: 0.7992122024297714, Final Batch Loss: 0.23725758492946625\n",
      "Epoch 1585, Loss: 0.8242284953594208, Final Batch Loss: 0.3198479413986206\n",
      "Epoch 1586, Loss: 0.8820350021123886, Final Batch Loss: 0.3582727313041687\n",
      "Epoch 1587, Loss: 0.7849710881710052, Final Batch Loss: 0.2645051181316376\n",
      "Epoch 1588, Loss: 0.8195052444934845, Final Batch Loss: 0.2501054108142853\n",
      "Epoch 1589, Loss: 0.826179563999176, Final Batch Loss: 0.29367491602897644\n",
      "Epoch 1590, Loss: 0.8375552892684937, Final Batch Loss: 0.24496978521347046\n",
      "Epoch 1591, Loss: 0.8235829621553421, Final Batch Loss: 0.3142831325531006\n",
      "Epoch 1592, Loss: 0.7893095761537552, Final Batch Loss: 0.2851409316062927\n",
      "Epoch 1593, Loss: 0.7758485376834869, Final Batch Loss: 0.21167677640914917\n",
      "Epoch 1594, Loss: 0.7240737527608871, Final Batch Loss: 0.14715947210788727\n",
      "Epoch 1595, Loss: 0.7026679962873459, Final Batch Loss: 0.20147188007831573\n",
      "Epoch 1596, Loss: 0.8583499491214752, Final Batch Loss: 0.31004008650779724\n",
      "Epoch 1597, Loss: 0.7517403960227966, Final Batch Loss: 0.26551440358161926\n",
      "Epoch 1598, Loss: 0.738105520606041, Final Batch Loss: 0.2531030774116516\n",
      "Epoch 1599, Loss: 0.7306051999330521, Final Batch Loss: 0.26085224747657776\n",
      "Epoch 1600, Loss: 0.6932040303945541, Final Batch Loss: 0.15526722371578217\n",
      "Epoch 1601, Loss: 0.7402282357215881, Final Batch Loss: 0.2576403319835663\n",
      "Epoch 1602, Loss: 0.7732314318418503, Final Batch Loss: 0.2262662798166275\n",
      "Epoch 1603, Loss: 0.6970726102590561, Final Batch Loss: 0.1654043346643448\n",
      "Epoch 1604, Loss: 0.7921800315380096, Final Batch Loss: 0.23148339986801147\n",
      "Epoch 1605, Loss: 0.8795329928398132, Final Batch Loss: 0.28913986682891846\n",
      "Epoch 1606, Loss: 0.7994632124900818, Final Batch Loss: 0.2551589012145996\n",
      "Epoch 1607, Loss: 0.7870182693004608, Final Batch Loss: 0.26108318567276\n",
      "Epoch 1608, Loss: 0.7250740230083466, Final Batch Loss: 0.17220383882522583\n",
      "Epoch 1609, Loss: 0.8887557089328766, Final Batch Loss: 0.29945501685142517\n",
      "Epoch 1610, Loss: 0.8228495121002197, Final Batch Loss: 0.19529595971107483\n",
      "Epoch 1611, Loss: 0.6776084005832672, Final Batch Loss: 0.2390415221452713\n",
      "Epoch 1612, Loss: 0.6823782026767731, Final Batch Loss: 0.196198970079422\n",
      "Epoch 1613, Loss: 0.6804605722427368, Final Batch Loss: 0.1739082634449005\n",
      "Epoch 1614, Loss: 0.7456978112459183, Final Batch Loss: 0.21256379783153534\n",
      "Epoch 1615, Loss: 0.7266442626714706, Final Batch Loss: 0.2521842122077942\n",
      "Epoch 1616, Loss: 0.8031104803085327, Final Batch Loss: 0.1914260983467102\n",
      "Epoch 1617, Loss: 0.730752170085907, Final Batch Loss: 0.2871350049972534\n",
      "Epoch 1618, Loss: 0.8158978223800659, Final Batch Loss: 0.2944522202014923\n",
      "Epoch 1619, Loss: 0.8098932951688766, Final Batch Loss: 0.24184690415859222\n",
      "Epoch 1620, Loss: 0.7431104332208633, Final Batch Loss: 0.24655072391033173\n",
      "Epoch 1621, Loss: 0.7490827292203903, Final Batch Loss: 0.2558734714984894\n",
      "Epoch 1622, Loss: 0.7958081513643265, Final Batch Loss: 0.31239259243011475\n",
      "Epoch 1623, Loss: 0.7927370965480804, Final Batch Loss: 0.2150963842868805\n",
      "Epoch 1624, Loss: 0.7792728990316391, Final Batch Loss: 0.23756058514118195\n",
      "Epoch 1625, Loss: 0.7112148106098175, Final Batch Loss: 0.25346672534942627\n",
      "Epoch 1626, Loss: 0.8641200065612793, Final Batch Loss: 0.34247684478759766\n",
      "Epoch 1627, Loss: 0.8218880146741867, Final Batch Loss: 0.2147536426782608\n",
      "Epoch 1628, Loss: 0.7960223704576492, Final Batch Loss: 0.19291268289089203\n",
      "Epoch 1629, Loss: 0.8031418919563293, Final Batch Loss: 0.2772209942340851\n",
      "Epoch 1630, Loss: 0.6978378593921661, Final Batch Loss: 0.16509681940078735\n",
      "Epoch 1631, Loss: 0.6893694698810577, Final Batch Loss: 0.16546759009361267\n",
      "Epoch 1632, Loss: 0.7577733248472214, Final Batch Loss: 0.2617180049419403\n",
      "Epoch 1633, Loss: 0.810951292514801, Final Batch Loss: 0.26657089591026306\n",
      "Epoch 1634, Loss: 0.7784803062677383, Final Batch Loss: 0.21091149747371674\n",
      "Epoch 1635, Loss: 0.7830444276332855, Final Batch Loss: 0.2650884985923767\n",
      "Epoch 1636, Loss: 0.7130941301584244, Final Batch Loss: 0.21825188398361206\n",
      "Epoch 1637, Loss: 0.6941924840211868, Final Batch Loss: 0.2098066210746765\n",
      "Epoch 1638, Loss: 0.8099459558725357, Final Batch Loss: 0.32188284397125244\n",
      "Epoch 1639, Loss: 0.8263784348964691, Final Batch Loss: 0.250887930393219\n",
      "Epoch 1640, Loss: 0.7978984117507935, Final Batch Loss: 0.23140393197536469\n",
      "Epoch 1641, Loss: 0.7185472995042801, Final Batch Loss: 0.23672203719615936\n",
      "Epoch 1642, Loss: 0.7414591610431671, Final Batch Loss: 0.24632520973682404\n",
      "Epoch 1643, Loss: 0.7574716210365295, Final Batch Loss: 0.2215910255908966\n",
      "Epoch 1644, Loss: 0.6918685436248779, Final Batch Loss: 0.21616055071353912\n",
      "Epoch 1645, Loss: 0.7442885637283325, Final Batch Loss: 0.20092815160751343\n",
      "Epoch 1646, Loss: 0.8058595508337021, Final Batch Loss: 0.2752198874950409\n",
      "Epoch 1647, Loss: 0.6916427165269852, Final Batch Loss: 0.2162267565727234\n",
      "Epoch 1648, Loss: 0.8361968249082565, Final Batch Loss: 0.33467209339141846\n",
      "Epoch 1649, Loss: 0.8550730645656586, Final Batch Loss: 0.32969629764556885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1650, Loss: 0.8843950182199478, Final Batch Loss: 0.38564664125442505\n",
      "Epoch 1651, Loss: 0.7847968935966492, Final Batch Loss: 0.20010745525360107\n",
      "Epoch 1652, Loss: 0.7648918181657791, Final Batch Loss: 0.21954555809497833\n",
      "Epoch 1653, Loss: 0.7851631194353104, Final Batch Loss: 0.2483716756105423\n",
      "Epoch 1654, Loss: 0.8178964704275131, Final Batch Loss: 0.21690993010997772\n",
      "Epoch 1655, Loss: 0.7013361155986786, Final Batch Loss: 0.2330990731716156\n",
      "Epoch 1656, Loss: 0.7282331138849258, Final Batch Loss: 0.2400486320257187\n",
      "Epoch 1657, Loss: 0.7590776532888412, Final Batch Loss: 0.23691876232624054\n",
      "Epoch 1658, Loss: 0.7313662469387054, Final Batch Loss: 0.28842589259147644\n",
      "Epoch 1659, Loss: 0.8607637584209442, Final Batch Loss: 0.3367701768875122\n",
      "Epoch 1660, Loss: 0.8086341172456741, Final Batch Loss: 0.22695009410381317\n",
      "Epoch 1661, Loss: 0.8004421889781952, Final Batch Loss: 0.29050159454345703\n",
      "Epoch 1662, Loss: 0.7603027075529099, Final Batch Loss: 0.30596038699150085\n",
      "Epoch 1663, Loss: 0.7982364594936371, Final Batch Loss: 0.25740933418273926\n",
      "Epoch 1664, Loss: 0.7817956358194351, Final Batch Loss: 0.26933804154396057\n",
      "Epoch 1665, Loss: 0.8046670258045197, Final Batch Loss: 0.33526596426963806\n",
      "Epoch 1666, Loss: 0.8591217696666718, Final Batch Loss: 0.22802264988422394\n",
      "Epoch 1667, Loss: 0.7493215352296829, Final Batch Loss: 0.24745804071426392\n",
      "Epoch 1668, Loss: 0.6998224854469299, Final Batch Loss: 0.2184711992740631\n",
      "Epoch 1669, Loss: 0.7584415972232819, Final Batch Loss: 0.2311798632144928\n",
      "Epoch 1670, Loss: 0.7582041174173355, Final Batch Loss: 0.261756956577301\n",
      "Epoch 1671, Loss: 0.7875406742095947, Final Batch Loss: 0.2518543601036072\n",
      "Epoch 1672, Loss: 0.64513199031353, Final Batch Loss: 0.18235719203948975\n",
      "Epoch 1673, Loss: 0.7529873251914978, Final Batch Loss: 0.23356083035469055\n",
      "Epoch 1674, Loss: 0.7990350723266602, Final Batch Loss: 0.2857618033885956\n",
      "Epoch 1675, Loss: 0.7959878295660019, Final Batch Loss: 0.24831494688987732\n",
      "Epoch 1676, Loss: 0.7505041509866714, Final Batch Loss: 0.20683543384075165\n",
      "Epoch 1677, Loss: 0.7933476865291595, Final Batch Loss: 0.3435346186161041\n",
      "Epoch 1678, Loss: 0.8839865773916245, Final Batch Loss: 0.33761003613471985\n",
      "Epoch 1679, Loss: 0.713311105966568, Final Batch Loss: 0.24761717021465302\n",
      "Epoch 1680, Loss: 0.7685855031013489, Final Batch Loss: 0.25755050778388977\n",
      "Epoch 1681, Loss: 0.719831183552742, Final Batch Loss: 0.20309434831142426\n",
      "Epoch 1682, Loss: 0.6987641900777817, Final Batch Loss: 0.1881055384874344\n",
      "Epoch 1683, Loss: 0.7531992495059967, Final Batch Loss: 0.2821854054927826\n",
      "Epoch 1684, Loss: 0.6599225401878357, Final Batch Loss: 0.15308094024658203\n",
      "Epoch 1685, Loss: 0.8026239573955536, Final Batch Loss: 0.2712094187736511\n",
      "Epoch 1686, Loss: 0.7405059039592743, Final Batch Loss: 0.2579144239425659\n",
      "Epoch 1687, Loss: 0.796466663479805, Final Batch Loss: 0.2919243574142456\n",
      "Epoch 1688, Loss: 0.7126965075731277, Final Batch Loss: 0.2529163956642151\n",
      "Epoch 1689, Loss: 0.6468515694141388, Final Batch Loss: 0.19922462105751038\n",
      "Epoch 1690, Loss: 0.8043718636035919, Final Batch Loss: 0.26600348949432373\n",
      "Epoch 1691, Loss: 0.7143998742103577, Final Batch Loss: 0.19473063945770264\n",
      "Epoch 1692, Loss: 0.746930405497551, Final Batch Loss: 0.1969895213842392\n",
      "Epoch 1693, Loss: 0.7789526581764221, Final Batch Loss: 0.3150184750556946\n",
      "Epoch 1694, Loss: 0.7429804652929306, Final Batch Loss: 0.21933935582637787\n",
      "Epoch 1695, Loss: 0.8603592962026596, Final Batch Loss: 0.2273906022310257\n",
      "Epoch 1696, Loss: 0.7458421736955643, Final Batch Loss: 0.21752001345157623\n",
      "Epoch 1697, Loss: 0.6750012189149857, Final Batch Loss: 0.18601301312446594\n",
      "Epoch 1698, Loss: 0.8002226203680038, Final Batch Loss: 0.3029795289039612\n",
      "Epoch 1699, Loss: 0.7370707988739014, Final Batch Loss: 0.20896899700164795\n",
      "Epoch 1700, Loss: 0.6475968062877655, Final Batch Loss: 0.1938713937997818\n",
      "Epoch 1701, Loss: 0.7956143170595169, Final Batch Loss: 0.31404417753219604\n",
      "Epoch 1702, Loss: 0.738602489233017, Final Batch Loss: 0.2613977789878845\n",
      "Epoch 1703, Loss: 0.8896750509738922, Final Batch Loss: 0.3899753987789154\n",
      "Epoch 1704, Loss: 0.8072474002838135, Final Batch Loss: 0.2202174961566925\n",
      "Epoch 1705, Loss: 0.827368825674057, Final Batch Loss: 0.2708268463611603\n",
      "Epoch 1706, Loss: 0.777265340089798, Final Batch Loss: 0.2791759669780731\n",
      "Epoch 1707, Loss: 0.7532707154750824, Final Batch Loss: 0.26262935996055603\n",
      "Epoch 1708, Loss: 0.8395137786865234, Final Batch Loss: 0.3003444969654083\n",
      "Epoch 1709, Loss: 0.7838293612003326, Final Batch Loss: 0.21949082612991333\n",
      "Epoch 1710, Loss: 0.7770772129297256, Final Batch Loss: 0.26713189482688904\n",
      "Epoch 1711, Loss: 0.6681312173604965, Final Batch Loss: 0.20483675599098206\n",
      "Epoch 1712, Loss: 0.6423805505037308, Final Batch Loss: 0.20743055641651154\n",
      "Epoch 1713, Loss: 0.7790590524673462, Final Batch Loss: 0.3347514271736145\n",
      "Epoch 1714, Loss: 0.7227737605571747, Final Batch Loss: 0.21686755120754242\n",
      "Epoch 1715, Loss: 0.7735785990953445, Final Batch Loss: 0.2707395553588867\n",
      "Epoch 1716, Loss: 0.7840951234102249, Final Batch Loss: 0.24583755433559418\n",
      "Epoch 1717, Loss: 0.6586554050445557, Final Batch Loss: 0.2680802047252655\n",
      "Epoch 1718, Loss: 0.783218115568161, Final Batch Loss: 0.2434258759021759\n",
      "Epoch 1719, Loss: 0.6947600692510605, Final Batch Loss: 0.2731383144855499\n",
      "Epoch 1720, Loss: 0.7761542499065399, Final Batch Loss: 0.2018669843673706\n",
      "Epoch 1721, Loss: 0.745529517531395, Final Batch Loss: 0.31902015209198\n",
      "Epoch 1722, Loss: 0.7655677199363708, Final Batch Loss: 0.34926626086235046\n",
      "Epoch 1723, Loss: 0.7883898764848709, Final Batch Loss: 0.24988363683223724\n",
      "Epoch 1724, Loss: 0.9160130023956299, Final Batch Loss: 0.35251837968826294\n",
      "Epoch 1725, Loss: 0.7014934420585632, Final Batch Loss: 0.22808019816875458\n",
      "Epoch 1726, Loss: 0.682196706533432, Final Batch Loss: 0.2051192969083786\n",
      "Epoch 1727, Loss: 0.7240974456071854, Final Batch Loss: 0.26531416177749634\n",
      "Epoch 1728, Loss: 0.7686161696910858, Final Batch Loss: 0.3099193871021271\n",
      "Epoch 1729, Loss: 0.7277522087097168, Final Batch Loss: 0.316049188375473\n",
      "Epoch 1730, Loss: 0.741645097732544, Final Batch Loss: 0.20648440718650818\n",
      "Epoch 1731, Loss: 0.7788603901863098, Final Batch Loss: 0.2682682275772095\n",
      "Epoch 1732, Loss: 0.8500971794128418, Final Batch Loss: 0.29942581057548523\n",
      "Epoch 1733, Loss: 0.7319957315921783, Final Batch Loss: 0.15753725171089172\n",
      "Epoch 1734, Loss: 0.7191819250583649, Final Batch Loss: 0.21226651966571808\n",
      "Epoch 1735, Loss: 0.6362404525279999, Final Batch Loss: 0.18294304609298706\n",
      "Epoch 1736, Loss: 0.6129759773612022, Final Batch Loss: 0.12135500460863113\n",
      "Epoch 1737, Loss: 0.7700240761041641, Final Batch Loss: 0.29718267917633057\n",
      "Epoch 1738, Loss: 0.6727811098098755, Final Batch Loss: 0.2654898464679718\n",
      "Epoch 1739, Loss: 0.6562590897083282, Final Batch Loss: 0.1852516531944275\n",
      "Epoch 1740, Loss: 0.653597429394722, Final Batch Loss: 0.22861172258853912\n",
      "Epoch 1741, Loss: 0.7372870743274689, Final Batch Loss: 0.2559313476085663\n",
      "Epoch 1742, Loss: 0.7591287195682526, Final Batch Loss: 0.29595354199409485\n",
      "Epoch 1743, Loss: 0.7791364341974258, Final Batch Loss: 0.2720254063606262\n",
      "Epoch 1744, Loss: 0.7064227163791656, Final Batch Loss: 0.23412801325321198\n",
      "Epoch 1745, Loss: 0.7242742031812668, Final Batch Loss: 0.31156450510025024\n",
      "Epoch 1746, Loss: 0.7150705605745316, Final Batch Loss: 0.27616086602211\n",
      "Epoch 1747, Loss: 0.7778182923793793, Final Batch Loss: 0.2590439021587372\n",
      "Epoch 1748, Loss: 0.703412726521492, Final Batch Loss: 0.26848486065864563\n",
      "Epoch 1749, Loss: 0.7467597723007202, Final Batch Loss: 0.3341228663921356\n",
      "Epoch 1750, Loss: 0.6966858208179474, Final Batch Loss: 0.20310743153095245\n",
      "Epoch 1751, Loss: 0.7158182561397552, Final Batch Loss: 0.26564547419548035\n",
      "Epoch 1752, Loss: 0.7695397734642029, Final Batch Loss: 0.2525777220726013\n",
      "Epoch 1753, Loss: 0.7342933118343353, Final Batch Loss: 0.23692162334918976\n",
      "Epoch 1754, Loss: 0.6869678050279617, Final Batch Loss: 0.19980134069919586\n",
      "Epoch 1755, Loss: 0.787098690867424, Final Batch Loss: 0.31061652302742004\n",
      "Epoch 1756, Loss: 0.7044616043567657, Final Batch Loss: 0.25274860858917236\n",
      "Epoch 1757, Loss: 0.8290518075227737, Final Batch Loss: 0.24744461476802826\n",
      "Epoch 1758, Loss: 0.7232645452022552, Final Batch Loss: 0.27791205048561096\n",
      "Epoch 1759, Loss: 0.8611505031585693, Final Batch Loss: 0.33586713671684265\n",
      "Epoch 1760, Loss: 0.6693061590194702, Final Batch Loss: 0.21213717758655548\n",
      "Epoch 1761, Loss: 0.8015867918729782, Final Batch Loss: 0.29616448283195496\n",
      "Epoch 1762, Loss: 0.730310708284378, Final Batch Loss: 0.1926029920578003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1763, Loss: 0.8212391287088394, Final Batch Loss: 0.32849636673927307\n",
      "Epoch 1764, Loss: 0.803321897983551, Final Batch Loss: 0.2623072564601898\n",
      "Epoch 1765, Loss: 0.7970312386751175, Final Batch Loss: 0.2358729988336563\n",
      "Epoch 1766, Loss: 0.7413002550601959, Final Batch Loss: 0.2487322837114334\n",
      "Epoch 1767, Loss: 0.6742310225963593, Final Batch Loss: 0.23318323493003845\n",
      "Epoch 1768, Loss: 0.7360920906066895, Final Batch Loss: 0.27726346254348755\n",
      "Epoch 1769, Loss: 0.6983219236135483, Final Batch Loss: 0.2637714147567749\n",
      "Epoch 1770, Loss: 0.8113463819026947, Final Batch Loss: 0.29291555285453796\n",
      "Epoch 1771, Loss: 0.6614735424518585, Final Batch Loss: 0.14958766102790833\n",
      "Epoch 1772, Loss: 0.7657525390386581, Final Batch Loss: 0.27942049503326416\n",
      "Epoch 1773, Loss: 0.8332403898239136, Final Batch Loss: 0.283661812543869\n",
      "Epoch 1774, Loss: 0.679052084684372, Final Batch Loss: 0.209064319729805\n",
      "Epoch 1775, Loss: 0.6459362804889679, Final Batch Loss: 0.17278626561164856\n",
      "Epoch 1776, Loss: 0.6558925062417984, Final Batch Loss: 0.1848507970571518\n",
      "Epoch 1777, Loss: 0.7505394369363785, Final Batch Loss: 0.2554253339767456\n",
      "Epoch 1778, Loss: 0.8018103688955307, Final Batch Loss: 0.29522159695625305\n",
      "Epoch 1779, Loss: 0.734101802110672, Final Batch Loss: 0.1918000429868698\n",
      "Epoch 1780, Loss: 0.7424469739198685, Final Batch Loss: 0.1880383938550949\n",
      "Epoch 1781, Loss: 0.6121547818183899, Final Batch Loss: 0.134867861866951\n",
      "Epoch 1782, Loss: 0.739091157913208, Final Batch Loss: 0.266269713640213\n",
      "Epoch 1783, Loss: 0.7198083698749542, Final Batch Loss: 0.2624247372150421\n",
      "Epoch 1784, Loss: 0.7767602801322937, Final Batch Loss: 0.19355282187461853\n",
      "Epoch 1785, Loss: 0.6907563507556915, Final Batch Loss: 0.24840354919433594\n",
      "Epoch 1786, Loss: 0.6502432972192764, Final Batch Loss: 0.2306620180606842\n",
      "Epoch 1787, Loss: 0.676599994301796, Final Batch Loss: 0.2273378074169159\n",
      "Epoch 1788, Loss: 0.6585720777511597, Final Batch Loss: 0.21130195260047913\n",
      "Epoch 1789, Loss: 0.6599967181682587, Final Batch Loss: 0.2653864026069641\n",
      "Epoch 1790, Loss: 0.6382808238267899, Final Batch Loss: 0.1749604195356369\n",
      "Epoch 1791, Loss: 0.7435629367828369, Final Batch Loss: 0.22598502039909363\n",
      "Epoch 1792, Loss: 0.7878926992416382, Final Batch Loss: 0.2846447229385376\n",
      "Epoch 1793, Loss: 0.807065486907959, Final Batch Loss: 0.29879146814346313\n",
      "Epoch 1794, Loss: 0.7000257223844528, Final Batch Loss: 0.21679332852363586\n",
      "Epoch 1795, Loss: 0.7603096663951874, Final Batch Loss: 0.2515690326690674\n",
      "Epoch 1796, Loss: 0.9775427281856537, Final Batch Loss: 0.3768167495727539\n",
      "Epoch 1797, Loss: 0.6642015129327774, Final Batch Loss: 0.200987309217453\n",
      "Epoch 1798, Loss: 0.6580425053834915, Final Batch Loss: 0.205795556306839\n",
      "Epoch 1799, Loss: 0.7416629493236542, Final Batch Loss: 0.26386237144470215\n",
      "Epoch 1800, Loss: 0.7503609657287598, Final Batch Loss: 0.29255378246307373\n",
      "Epoch 1801, Loss: 0.6561209857463837, Final Batch Loss: 0.20503196120262146\n",
      "Epoch 1802, Loss: 0.7842375040054321, Final Batch Loss: 0.2708170711994171\n",
      "Epoch 1803, Loss: 0.7224489748477936, Final Batch Loss: 0.2043883353471756\n",
      "Epoch 1804, Loss: 0.6886338889598846, Final Batch Loss: 0.20221099257469177\n",
      "Epoch 1805, Loss: 0.6712191849946976, Final Batch Loss: 0.19412849843502045\n",
      "Epoch 1806, Loss: 0.7466457486152649, Final Batch Loss: 0.31016457080841064\n",
      "Epoch 1807, Loss: 0.8480923920869827, Final Batch Loss: 0.3404673635959625\n",
      "Epoch 1808, Loss: 0.805855005979538, Final Batch Loss: 0.27924272418022156\n",
      "Epoch 1809, Loss: 0.6823559701442719, Final Batch Loss: 0.23593278229236603\n",
      "Epoch 1810, Loss: 0.8258544206619263, Final Batch Loss: 0.23952040076255798\n",
      "Epoch 1811, Loss: 0.8193667531013489, Final Batch Loss: 0.31246569752693176\n",
      "Epoch 1812, Loss: 0.7197586745023727, Final Batch Loss: 0.2342638522386551\n",
      "Epoch 1813, Loss: 0.8483302444219589, Final Batch Loss: 0.34376320242881775\n",
      "Epoch 1814, Loss: 0.7067895233631134, Final Batch Loss: 0.2926105260848999\n",
      "Epoch 1815, Loss: 0.7604186981916428, Final Batch Loss: 0.2206367403268814\n",
      "Epoch 1816, Loss: 0.7372440695762634, Final Batch Loss: 0.23667296767234802\n",
      "Epoch 1817, Loss: 0.750809907913208, Final Batch Loss: 0.18561674654483795\n",
      "Epoch 1818, Loss: 0.7693110108375549, Final Batch Loss: 0.2606591284275055\n",
      "Epoch 1819, Loss: 0.6858780831098557, Final Batch Loss: 0.2084861844778061\n",
      "Epoch 1820, Loss: 0.7107241302728653, Final Batch Loss: 0.2578708827495575\n",
      "Epoch 1821, Loss: 0.6366214752197266, Final Batch Loss: 0.2502778172492981\n",
      "Epoch 1822, Loss: 0.7198173701763153, Final Batch Loss: 0.31083986163139343\n",
      "Epoch 1823, Loss: 0.7542407363653183, Final Batch Loss: 0.3155074417591095\n",
      "Epoch 1824, Loss: 0.7406469136476517, Final Batch Loss: 0.26406988501548767\n",
      "Epoch 1825, Loss: 0.7948764711618423, Final Batch Loss: 0.2325792759656906\n",
      "Epoch 1826, Loss: 0.6574824303388596, Final Batch Loss: 0.31487753987312317\n",
      "Epoch 1827, Loss: 0.5970539152622223, Final Batch Loss: 0.22902794182300568\n",
      "Epoch 1828, Loss: 0.6958434581756592, Final Batch Loss: 0.19954822957515717\n",
      "Epoch 1829, Loss: 0.7262293100357056, Final Batch Loss: 0.20029883086681366\n",
      "Epoch 1830, Loss: 0.7412041425704956, Final Batch Loss: 0.25687670707702637\n",
      "Epoch 1831, Loss: 0.6919046342372894, Final Batch Loss: 0.21444223821163177\n",
      "Epoch 1832, Loss: 0.8501778095960617, Final Batch Loss: 0.39643630385398865\n",
      "Epoch 1833, Loss: 0.696554109454155, Final Batch Loss: 0.2533712089061737\n",
      "Epoch 1834, Loss: 0.7089357078075409, Final Batch Loss: 0.20942267775535583\n",
      "Epoch 1835, Loss: 0.6932515203952789, Final Batch Loss: 0.23950307071208954\n",
      "Epoch 1836, Loss: 0.7271534353494644, Final Batch Loss: 0.24010582268238068\n",
      "Epoch 1837, Loss: 0.7678369283676147, Final Batch Loss: 0.2564697563648224\n",
      "Epoch 1838, Loss: 0.7409361898899078, Final Batch Loss: 0.2605913281440735\n",
      "Epoch 1839, Loss: 0.8067986220121384, Final Batch Loss: 0.2924792468547821\n",
      "Epoch 1840, Loss: 0.6419246047735214, Final Batch Loss: 0.2128453254699707\n",
      "Epoch 1841, Loss: 0.603422224521637, Final Batch Loss: 0.16899403929710388\n",
      "Epoch 1842, Loss: 0.6899653524160385, Final Batch Loss: 0.2890757918357849\n",
      "Epoch 1843, Loss: 0.7376370579004288, Final Batch Loss: 0.15731306374073029\n",
      "Epoch 1844, Loss: 0.6696226894855499, Final Batch Loss: 0.202890545129776\n",
      "Epoch 1845, Loss: 0.7203890234231949, Final Batch Loss: 0.23108303546905518\n",
      "Epoch 1846, Loss: 0.560584083199501, Final Batch Loss: 0.14269326627254486\n",
      "Epoch 1847, Loss: 0.7102556973695755, Final Batch Loss: 0.22972100973129272\n",
      "Epoch 1848, Loss: 0.6743321269750595, Final Batch Loss: 0.23990842700004578\n",
      "Epoch 1849, Loss: 0.7769132554531097, Final Batch Loss: 0.2772330045700073\n",
      "Epoch 1850, Loss: 0.6512580364942551, Final Batch Loss: 0.2045251727104187\n",
      "Epoch 1851, Loss: 0.5940138250589371, Final Batch Loss: 0.1688133180141449\n",
      "Epoch 1852, Loss: 0.7560629844665527, Final Batch Loss: 0.36678510904312134\n",
      "Epoch 1853, Loss: 0.6964009702205658, Final Batch Loss: 0.25847887992858887\n",
      "Epoch 1854, Loss: 0.8251994848251343, Final Batch Loss: 0.33268001675605774\n",
      "Epoch 1855, Loss: 0.6408734917640686, Final Batch Loss: 0.20693790912628174\n",
      "Epoch 1856, Loss: 0.7384573519229889, Final Batch Loss: 0.2695072591304779\n",
      "Epoch 1857, Loss: 0.7629180252552032, Final Batch Loss: 0.3003285527229309\n",
      "Epoch 1858, Loss: 0.814692810177803, Final Batch Loss: 0.30761364102363586\n",
      "Epoch 1859, Loss: 0.7949557304382324, Final Batch Loss: 0.3540652394294739\n",
      "Epoch 1860, Loss: 0.8153660297393799, Final Batch Loss: 0.3840222954750061\n",
      "Epoch 1861, Loss: 0.8194186985492706, Final Batch Loss: 0.3215861916542053\n",
      "Epoch 1862, Loss: 0.6530106961727142, Final Batch Loss: 0.21264225244522095\n",
      "Epoch 1863, Loss: 0.7383278161287308, Final Batch Loss: 0.21191346645355225\n",
      "Epoch 1864, Loss: 0.793809711933136, Final Batch Loss: 0.34198465943336487\n",
      "Epoch 1865, Loss: 0.835188090801239, Final Batch Loss: 0.28711602091789246\n",
      "Epoch 1866, Loss: 0.6052810400724411, Final Batch Loss: 0.14918562769889832\n",
      "Epoch 1867, Loss: 0.6839440912008286, Final Batch Loss: 0.2179284393787384\n",
      "Epoch 1868, Loss: 0.7149006426334381, Final Batch Loss: 0.2293500155210495\n",
      "Epoch 1869, Loss: 0.6921539008617401, Final Batch Loss: 0.18374288082122803\n",
      "Epoch 1870, Loss: 0.7315646260976791, Final Batch Loss: 0.26658156514167786\n",
      "Epoch 1871, Loss: 0.678166925907135, Final Batch Loss: 0.15037845075130463\n",
      "Epoch 1872, Loss: 0.758309856057167, Final Batch Loss: 0.2979717254638672\n",
      "Epoch 1873, Loss: 0.7240698933601379, Final Batch Loss: 0.2607506513595581\n",
      "Epoch 1874, Loss: 0.6672717183828354, Final Batch Loss: 0.20581121742725372\n",
      "Epoch 1875, Loss: 0.6726070195436478, Final Batch Loss: 0.17379461228847504\n",
      "Epoch 1876, Loss: 0.7979195713996887, Final Batch Loss: 0.32492396235466003\n",
      "Epoch 1877, Loss: 0.7814159542322159, Final Batch Loss: 0.2835983335971832\n",
      "Epoch 1878, Loss: 0.666913315653801, Final Batch Loss: 0.25163534283638\n",
      "Epoch 1879, Loss: 0.7624917775392532, Final Batch Loss: 0.23451252281665802\n",
      "Epoch 1880, Loss: 0.7214940935373306, Final Batch Loss: 0.25340205430984497\n",
      "Epoch 1881, Loss: 0.7011864185333252, Final Batch Loss: 0.22259800136089325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1882, Loss: 0.7273133844137192, Final Batch Loss: 0.24036124348640442\n",
      "Epoch 1883, Loss: 0.7012878209352493, Final Batch Loss: 0.21459929645061493\n",
      "Epoch 1884, Loss: 0.7133035510778427, Final Batch Loss: 0.2206365466117859\n",
      "Epoch 1885, Loss: 0.6536689400672913, Final Batch Loss: 0.190125972032547\n",
      "Epoch 1886, Loss: 0.6880554705858231, Final Batch Loss: 0.17079924046993256\n",
      "Epoch 1887, Loss: 0.7882183939218521, Final Batch Loss: 0.30981072783470154\n",
      "Epoch 1888, Loss: 0.65373095870018, Final Batch Loss: 0.2114873230457306\n",
      "Epoch 1889, Loss: 0.6748611032962799, Final Batch Loss: 0.19659017026424408\n",
      "Epoch 1890, Loss: 0.6962766349315643, Final Batch Loss: 0.29219481348991394\n",
      "Epoch 1891, Loss: 0.6570568382740021, Final Batch Loss: 0.22300760447978973\n",
      "Epoch 1892, Loss: 0.7386975735425949, Final Batch Loss: 0.31876832246780396\n",
      "Epoch 1893, Loss: 0.6697700172662735, Final Batch Loss: 0.19118081033229828\n",
      "Epoch 1894, Loss: 0.6428945958614349, Final Batch Loss: 0.18581216037273407\n",
      "Epoch 1895, Loss: 0.7051247805356979, Final Batch Loss: 0.1583227962255478\n",
      "Epoch 1896, Loss: 0.7775928229093552, Final Batch Loss: 0.27760422229766846\n",
      "Epoch 1897, Loss: 0.6976280361413956, Final Batch Loss: 0.23975591361522675\n",
      "Epoch 1898, Loss: 0.6791087538003922, Final Batch Loss: 0.2161177694797516\n",
      "Epoch 1899, Loss: 0.7581208646297455, Final Batch Loss: 0.33937180042266846\n",
      "Epoch 1900, Loss: 0.6924597173929214, Final Batch Loss: 0.20848898589611053\n",
      "Epoch 1901, Loss: 0.6176311075687408, Final Batch Loss: 0.1649145781993866\n",
      "Epoch 1902, Loss: 0.8227461129426956, Final Batch Loss: 0.20167173445224762\n",
      "Epoch 1903, Loss: 0.694839745759964, Final Batch Loss: 0.2775941491127014\n",
      "Epoch 1904, Loss: 0.7116582095623016, Final Batch Loss: 0.1668573021888733\n",
      "Epoch 1905, Loss: 0.7501882314682007, Final Batch Loss: 0.2644154131412506\n",
      "Epoch 1906, Loss: 0.7316745966672897, Final Batch Loss: 0.2788085639476776\n",
      "Epoch 1907, Loss: 0.7068528980016708, Final Batch Loss: 0.24842962622642517\n",
      "Epoch 1908, Loss: 0.7063234597444534, Final Batch Loss: 0.27090582251548767\n",
      "Epoch 1909, Loss: 0.6525812447071075, Final Batch Loss: 0.23540639877319336\n",
      "Epoch 1910, Loss: 0.5970950722694397, Final Batch Loss: 0.17505641281604767\n",
      "Epoch 1911, Loss: 0.7119864225387573, Final Batch Loss: 0.257465124130249\n",
      "Epoch 1912, Loss: 0.7373080998659134, Final Batch Loss: 0.2664943039417267\n",
      "Epoch 1913, Loss: 0.6504061222076416, Final Batch Loss: 0.1836816966533661\n",
      "Epoch 1914, Loss: 0.5906529128551483, Final Batch Loss: 0.15125413239002228\n",
      "Epoch 1915, Loss: 0.6589358448982239, Final Batch Loss: 0.17714759707450867\n",
      "Epoch 1916, Loss: 0.6563892811536789, Final Batch Loss: 0.23164193332195282\n",
      "Epoch 1917, Loss: 0.7124076783657074, Final Batch Loss: 0.27790504693984985\n",
      "Epoch 1918, Loss: 0.7400619685649872, Final Batch Loss: 0.21900483965873718\n",
      "Epoch 1919, Loss: 0.7743139564990997, Final Batch Loss: 0.3236650824546814\n",
      "Epoch 1920, Loss: 0.8004041165113449, Final Batch Loss: 0.26241543889045715\n",
      "Epoch 1921, Loss: 0.7208736091852188, Final Batch Loss: 0.18954278528690338\n",
      "Epoch 1922, Loss: 0.7657340615987778, Final Batch Loss: 0.21464021503925323\n",
      "Epoch 1923, Loss: 0.6795658469200134, Final Batch Loss: 0.21210293471813202\n",
      "Epoch 1924, Loss: 0.6934265643358231, Final Batch Loss: 0.28161942958831787\n",
      "Epoch 1925, Loss: 0.6827308982610703, Final Batch Loss: 0.20737096667289734\n",
      "Epoch 1926, Loss: 0.7062924653291702, Final Batch Loss: 0.2675548195838928\n",
      "Epoch 1927, Loss: 0.6781449913978577, Final Batch Loss: 0.23990803956985474\n",
      "Epoch 1928, Loss: 0.7160252928733826, Final Batch Loss: 0.23706237971782684\n",
      "Epoch 1929, Loss: 0.8587297350168228, Final Batch Loss: 0.3481094241142273\n",
      "Epoch 1930, Loss: 0.8334895670413971, Final Batch Loss: 0.2963704764842987\n",
      "Epoch 1931, Loss: 0.6652334779500961, Final Batch Loss: 0.19856064021587372\n",
      "Epoch 1932, Loss: 0.7010452449321747, Final Batch Loss: 0.2187042236328125\n",
      "Epoch 1933, Loss: 0.6826480180025101, Final Batch Loss: 0.18075990676879883\n",
      "Epoch 1934, Loss: 0.7886671870946884, Final Batch Loss: 0.2922497093677521\n",
      "Epoch 1935, Loss: 0.7027084082365036, Final Batch Loss: 0.24249213933944702\n",
      "Epoch 1936, Loss: 0.7724250555038452, Final Batch Loss: 0.2725166380405426\n",
      "Epoch 1937, Loss: 0.638113334774971, Final Batch Loss: 0.22135195136070251\n",
      "Epoch 1938, Loss: 0.6704469323158264, Final Batch Loss: 0.272839218378067\n",
      "Epoch 1939, Loss: 0.7383466213941574, Final Batch Loss: 0.2712547481060028\n",
      "Epoch 1940, Loss: 0.6058922111988068, Final Batch Loss: 0.1727965772151947\n",
      "Epoch 1941, Loss: 0.6779207587242126, Final Batch Loss: 0.17623159289360046\n",
      "Epoch 1942, Loss: 0.6702934950590134, Final Batch Loss: 0.24893715977668762\n",
      "Epoch 1943, Loss: 0.649147629737854, Final Batch Loss: 0.2415798306465149\n",
      "Epoch 1944, Loss: 0.6809014678001404, Final Batch Loss: 0.1591920405626297\n",
      "Epoch 1945, Loss: 0.7196283936500549, Final Batch Loss: 0.24905934929847717\n",
      "Epoch 1946, Loss: 0.7886077165603638, Final Batch Loss: 0.3573973774909973\n",
      "Epoch 1947, Loss: 0.6124561429023743, Final Batch Loss: 0.2020021229982376\n",
      "Epoch 1948, Loss: 0.6506427228450775, Final Batch Loss: 0.18496544659137726\n",
      "Epoch 1949, Loss: 0.6337024569511414, Final Batch Loss: 0.15661868453025818\n",
      "Epoch 1950, Loss: 0.6602035462856293, Final Batch Loss: 0.18714632093906403\n",
      "Epoch 1951, Loss: 0.7051329165697098, Final Batch Loss: 0.15555725991725922\n",
      "Epoch 1952, Loss: 0.6998238563537598, Final Batch Loss: 0.2598286271095276\n",
      "Epoch 1953, Loss: 0.612821027636528, Final Batch Loss: 0.20992174744606018\n",
      "Epoch 1954, Loss: 0.7753427624702454, Final Batch Loss: 0.36235353350639343\n",
      "Epoch 1955, Loss: 0.7123748958110809, Final Batch Loss: 0.250450074672699\n",
      "Epoch 1956, Loss: 0.6578271090984344, Final Batch Loss: 0.28309381008148193\n",
      "Epoch 1957, Loss: 0.6695382595062256, Final Batch Loss: 0.23700419068336487\n",
      "Epoch 1958, Loss: 0.6198574751615524, Final Batch Loss: 0.14542284607887268\n",
      "Epoch 1959, Loss: 0.7373320162296295, Final Batch Loss: 0.3149231970310211\n",
      "Epoch 1960, Loss: 0.7025659382343292, Final Batch Loss: 0.20651546120643616\n",
      "Epoch 1961, Loss: 0.6489090621471405, Final Batch Loss: 0.2219533771276474\n",
      "Epoch 1962, Loss: 0.7149752676486969, Final Batch Loss: 0.3102484941482544\n",
      "Epoch 1963, Loss: 0.6879109144210815, Final Batch Loss: 0.21679064631462097\n",
      "Epoch 1964, Loss: 0.724318653345108, Final Batch Loss: 0.21944722533226013\n",
      "Epoch 1965, Loss: 0.651012510061264, Final Batch Loss: 0.22614747285842896\n",
      "Epoch 1966, Loss: 0.7113488465547562, Final Batch Loss: 0.3121492564678192\n",
      "Epoch 1967, Loss: 0.6482387334108353, Final Batch Loss: 0.19495967030525208\n",
      "Epoch 1968, Loss: 0.6835843920707703, Final Batch Loss: 0.2157963365316391\n",
      "Epoch 1969, Loss: 0.5833177864551544, Final Batch Loss: 0.1799491047859192\n",
      "Epoch 1970, Loss: 0.6068014651536942, Final Batch Loss: 0.23628103733062744\n",
      "Epoch 1971, Loss: 0.668633759021759, Final Batch Loss: 0.17774809896945953\n",
      "Epoch 1972, Loss: 0.6635047793388367, Final Batch Loss: 0.2082555890083313\n",
      "Epoch 1973, Loss: 0.6358311325311661, Final Batch Loss: 0.1927834004163742\n",
      "Epoch 1974, Loss: 0.6298085004091263, Final Batch Loss: 0.2150159329175949\n",
      "Epoch 1975, Loss: 0.6506916284561157, Final Batch Loss: 0.24914930760860443\n",
      "Epoch 1976, Loss: 0.5811897069215775, Final Batch Loss: 0.16336357593536377\n",
      "Epoch 1977, Loss: 0.6792446970939636, Final Batch Loss: 0.21256639063358307\n",
      "Epoch 1978, Loss: 0.6437349021434784, Final Batch Loss: 0.20642180740833282\n",
      "Epoch 1979, Loss: 0.7292557209730148, Final Batch Loss: 0.28801751136779785\n",
      "Epoch 1980, Loss: 0.6735860854387283, Final Batch Loss: 0.23252709209918976\n",
      "Epoch 1981, Loss: 0.6852573305368423, Final Batch Loss: 0.28180453181266785\n",
      "Epoch 1982, Loss: 0.6315508633852005, Final Batch Loss: 0.18119584023952484\n",
      "Epoch 1983, Loss: 0.6153385490179062, Final Batch Loss: 0.20400138199329376\n",
      "Epoch 1984, Loss: 0.7032777667045593, Final Batch Loss: 0.19786979258060455\n",
      "Epoch 1985, Loss: 0.6369890868663788, Final Batch Loss: 0.1759258359670639\n",
      "Epoch 1986, Loss: 0.5991885513067245, Final Batch Loss: 0.21213048696517944\n",
      "Epoch 1987, Loss: 0.66020867228508, Final Batch Loss: 0.20695355534553528\n",
      "Epoch 1988, Loss: 0.586824432015419, Final Batch Loss: 0.18758624792099\n",
      "Epoch 1989, Loss: 0.7465484589338303, Final Batch Loss: 0.2947459816932678\n",
      "Epoch 1990, Loss: 0.6036771088838577, Final Batch Loss: 0.17009295523166656\n",
      "Epoch 1991, Loss: 0.6951261907815933, Final Batch Loss: 0.21019431948661804\n",
      "Epoch 1992, Loss: 0.8439439535140991, Final Batch Loss: 0.24130879342556\n",
      "Epoch 1993, Loss: 0.6919674724340439, Final Batch Loss: 0.28106385469436646\n",
      "Epoch 1994, Loss: 0.6459829062223434, Final Batch Loss: 0.18152177333831787\n",
      "Epoch 1995, Loss: 0.7286713570356369, Final Batch Loss: 0.22376857697963715\n",
      "Epoch 1996, Loss: 0.6696918904781342, Final Batch Loss: 0.24691064655780792\n",
      "Epoch 1997, Loss: 0.7228879034519196, Final Batch Loss: 0.21764490008354187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1998, Loss: 0.5749024599790573, Final Batch Loss: 0.19744671881198883\n",
      "Epoch 1999, Loss: 0.6292687505483627, Final Batch Loss: 0.23950009047985077\n",
      "Epoch 2000, Loss: 0.6504113376140594, Final Batch Loss: 0.17420296370983124\n",
      "Epoch 2001, Loss: 0.638507679104805, Final Batch Loss: 0.1433434933423996\n",
      "Epoch 2002, Loss: 0.6099565923213959, Final Batch Loss: 0.17601822316646576\n",
      "Epoch 2003, Loss: 0.6301272660493851, Final Batch Loss: 0.1652590036392212\n",
      "Epoch 2004, Loss: 0.6100245118141174, Final Batch Loss: 0.17995290458202362\n",
      "Epoch 2005, Loss: 0.6978114098310471, Final Batch Loss: 0.23400279879570007\n",
      "Epoch 2006, Loss: 0.5954956561326981, Final Batch Loss: 0.17012831568717957\n",
      "Epoch 2007, Loss: 0.7365323007106781, Final Batch Loss: 0.23921623826026917\n",
      "Epoch 2008, Loss: 0.6772500574588776, Final Batch Loss: 0.22775471210479736\n",
      "Epoch 2009, Loss: 0.6735221892595291, Final Batch Loss: 0.22998492419719696\n",
      "Epoch 2010, Loss: 0.6457396447658539, Final Batch Loss: 0.20986318588256836\n",
      "Epoch 2011, Loss: 0.6106167137622833, Final Batch Loss: 0.21326738595962524\n",
      "Epoch 2012, Loss: 0.53692626953125, Final Batch Loss: 0.15432870388031006\n",
      "Epoch 2013, Loss: 0.6443746089935303, Final Batch Loss: 0.2045828104019165\n",
      "Epoch 2014, Loss: 0.6047994941473007, Final Batch Loss: 0.21280448138713837\n",
      "Epoch 2015, Loss: 0.53406922519207, Final Batch Loss: 0.1759931594133377\n",
      "Epoch 2016, Loss: 0.6860677599906921, Final Batch Loss: 0.2783451974391937\n",
      "Epoch 2017, Loss: 0.6337062269449234, Final Batch Loss: 0.18777215480804443\n",
      "Epoch 2018, Loss: 0.6177268028259277, Final Batch Loss: 0.18697497248649597\n",
      "Epoch 2019, Loss: 0.6138573586940765, Final Batch Loss: 0.24379348754882812\n",
      "Epoch 2020, Loss: 0.7075104862451553, Final Batch Loss: 0.21245117485523224\n",
      "Epoch 2021, Loss: 0.7367594540119171, Final Batch Loss: 0.2589678466320038\n",
      "Epoch 2022, Loss: 0.5827815979719162, Final Batch Loss: 0.14272692799568176\n",
      "Epoch 2023, Loss: 0.625406414270401, Final Batch Loss: 0.19589374959468842\n",
      "Epoch 2024, Loss: 0.5595701336860657, Final Batch Loss: 0.1530446708202362\n",
      "Epoch 2025, Loss: 0.70115727186203, Final Batch Loss: 0.1870594024658203\n",
      "Epoch 2026, Loss: 0.6610013395547867, Final Batch Loss: 0.2383117526769638\n",
      "Epoch 2027, Loss: 0.5901758372783661, Final Batch Loss: 0.20460407435894012\n",
      "Epoch 2028, Loss: 0.5917413681745529, Final Batch Loss: 0.14551670849323273\n",
      "Epoch 2029, Loss: 0.6698792725801468, Final Batch Loss: 0.16113898158073425\n",
      "Epoch 2030, Loss: 0.6448047161102295, Final Batch Loss: 0.1863219141960144\n",
      "Epoch 2031, Loss: 0.71445232629776, Final Batch Loss: 0.3138216733932495\n",
      "Epoch 2032, Loss: 0.6493440121412277, Final Batch Loss: 0.25344568490982056\n",
      "Epoch 2033, Loss: 0.6194701343774796, Final Batch Loss: 0.20522277057170868\n",
      "Epoch 2034, Loss: 0.6258362531661987, Final Batch Loss: 0.197468563914299\n",
      "Epoch 2035, Loss: 0.6574187278747559, Final Batch Loss: 0.16849426925182343\n",
      "Epoch 2036, Loss: 0.7125435024499893, Final Batch Loss: 0.210380420088768\n",
      "Epoch 2037, Loss: 0.6686470210552216, Final Batch Loss: 0.1896364837884903\n",
      "Epoch 2038, Loss: 0.6388184428215027, Final Batch Loss: 0.13774363696575165\n",
      "Epoch 2039, Loss: 0.7457849830389023, Final Batch Loss: 0.20058724284172058\n",
      "Epoch 2040, Loss: 0.7142301648855209, Final Batch Loss: 0.1790316253900528\n",
      "Epoch 2041, Loss: 0.7248946577310562, Final Batch Loss: 0.2317730039358139\n",
      "Epoch 2042, Loss: 0.7039967626333237, Final Batch Loss: 0.23195183277130127\n",
      "Epoch 2043, Loss: 0.74397973716259, Final Batch Loss: 0.3081752061843872\n",
      "Epoch 2044, Loss: 0.6571115404367447, Final Batch Loss: 0.21797426044940948\n",
      "Epoch 2045, Loss: 0.6452179849147797, Final Batch Loss: 0.22860853374004364\n",
      "Epoch 2046, Loss: 0.8431749939918518, Final Batch Loss: 0.33961981534957886\n",
      "Epoch 2047, Loss: 0.6973645687103271, Final Batch Loss: 0.2396969199180603\n",
      "Epoch 2048, Loss: 0.6382725983858109, Final Batch Loss: 0.2281855195760727\n",
      "Epoch 2049, Loss: 0.651434987783432, Final Batch Loss: 0.2061951756477356\n",
      "Epoch 2050, Loss: 0.724588617682457, Final Batch Loss: 0.26515838503837585\n",
      "Epoch 2051, Loss: 0.6589947938919067, Final Batch Loss: 0.2330736666917801\n",
      "Epoch 2052, Loss: 0.5635540783405304, Final Batch Loss: 0.15154293179512024\n",
      "Epoch 2053, Loss: 0.7100532948970795, Final Batch Loss: 0.24089403450489044\n",
      "Epoch 2054, Loss: 0.6552218198776245, Final Batch Loss: 0.27568891644477844\n",
      "Epoch 2055, Loss: 0.6865953058004379, Final Batch Loss: 0.22055217623710632\n",
      "Epoch 2056, Loss: 0.6403945535421371, Final Batch Loss: 0.20159529149532318\n",
      "Epoch 2057, Loss: 0.6308018118143082, Final Batch Loss: 0.24850836396217346\n",
      "Epoch 2058, Loss: 0.6693575829267502, Final Batch Loss: 0.21047678589820862\n",
      "Epoch 2059, Loss: 0.6428103893995285, Final Batch Loss: 0.22586336731910706\n",
      "Epoch 2060, Loss: 0.5782646685838699, Final Batch Loss: 0.22283388674259186\n",
      "Epoch 2061, Loss: 0.6739947199821472, Final Batch Loss: 0.23771770298480988\n",
      "Epoch 2062, Loss: 0.6174261271953583, Final Batch Loss: 0.18955892324447632\n",
      "Epoch 2063, Loss: 0.7101779133081436, Final Batch Loss: 0.19108206033706665\n",
      "Epoch 2064, Loss: 0.7235833704471588, Final Batch Loss: 0.20638832449913025\n",
      "Epoch 2065, Loss: 0.6589232534170151, Final Batch Loss: 0.22679905593395233\n",
      "Epoch 2066, Loss: 0.5917460471391678, Final Batch Loss: 0.2079906314611435\n",
      "Epoch 2067, Loss: 0.5837395191192627, Final Batch Loss: 0.20217931270599365\n",
      "Epoch 2068, Loss: 0.6751951724290848, Final Batch Loss: 0.17857319116592407\n",
      "Epoch 2069, Loss: 0.5865505039691925, Final Batch Loss: 0.17997102439403534\n",
      "Epoch 2070, Loss: 0.6573849469423294, Final Batch Loss: 0.2400270253419876\n",
      "Epoch 2071, Loss: 0.6877687722444534, Final Batch Loss: 0.19968241453170776\n",
      "Epoch 2072, Loss: 0.6002414971590042, Final Batch Loss: 0.18172825872898102\n",
      "Epoch 2073, Loss: 0.6853243708610535, Final Batch Loss: 0.13993097841739655\n",
      "Epoch 2074, Loss: 0.6346569955348969, Final Batch Loss: 0.20591004192829132\n",
      "Epoch 2075, Loss: 0.6426291316747665, Final Batch Loss: 0.24297891557216644\n",
      "Epoch 2076, Loss: 0.6103073060512543, Final Batch Loss: 0.17917023599147797\n",
      "Epoch 2077, Loss: 0.5571497529745102, Final Batch Loss: 0.1828089952468872\n",
      "Epoch 2078, Loss: 0.5596243739128113, Final Batch Loss: 0.16869714856147766\n",
      "Epoch 2079, Loss: 0.5875574201345444, Final Batch Loss: 0.15437690913677216\n",
      "Epoch 2080, Loss: 0.5435284227132797, Final Batch Loss: 0.15593044459819794\n",
      "Epoch 2081, Loss: 0.7368162721395493, Final Batch Loss: 0.32750383019447327\n",
      "Epoch 2082, Loss: 0.6333287209272385, Final Batch Loss: 0.21210287511348724\n",
      "Epoch 2083, Loss: 0.6236067414283752, Final Batch Loss: 0.1753445267677307\n",
      "Epoch 2084, Loss: 0.6061062663793564, Final Batch Loss: 0.2364148646593094\n",
      "Epoch 2085, Loss: 0.6649567931890488, Final Batch Loss: 0.19562147557735443\n",
      "Epoch 2086, Loss: 0.5916071087121964, Final Batch Loss: 0.18257896602153778\n",
      "Epoch 2087, Loss: 0.7045630067586899, Final Batch Loss: 0.2377283126115799\n",
      "Epoch 2088, Loss: 0.6243434101343155, Final Batch Loss: 0.1986865997314453\n",
      "Epoch 2089, Loss: 0.5739939957857132, Final Batch Loss: 0.16498823463916779\n",
      "Epoch 2090, Loss: 0.7518350183963776, Final Batch Loss: 0.3375398516654968\n",
      "Epoch 2091, Loss: 0.5804590284824371, Final Batch Loss: 0.1512584537267685\n",
      "Epoch 2092, Loss: 0.709563821554184, Final Batch Loss: 0.24052561819553375\n",
      "Epoch 2093, Loss: 0.7359310388565063, Final Batch Loss: 0.32911500334739685\n",
      "Epoch 2094, Loss: 0.7031945586204529, Final Batch Loss: 0.21521279215812683\n",
      "Epoch 2095, Loss: 0.773357093334198, Final Batch Loss: 0.17191213369369507\n",
      "Epoch 2096, Loss: 0.7243966311216354, Final Batch Loss: 0.243153378367424\n",
      "Epoch 2097, Loss: 0.6815585941076279, Final Batch Loss: 0.23695175349712372\n",
      "Epoch 2098, Loss: 0.7015312016010284, Final Batch Loss: 0.24259276688098907\n",
      "Epoch 2099, Loss: 0.6590370535850525, Final Batch Loss: 0.25897538661956787\n",
      "Epoch 2100, Loss: 0.6068278402090073, Final Batch Loss: 0.21021625399589539\n",
      "Epoch 2101, Loss: 0.6203889101743698, Final Batch Loss: 0.21616202592849731\n",
      "Epoch 2102, Loss: 0.6774004697799683, Final Batch Loss: 0.2261689305305481\n",
      "Epoch 2103, Loss: 0.6331093013286591, Final Batch Loss: 0.24522627890110016\n",
      "Epoch 2104, Loss: 0.8046242892742157, Final Batch Loss: 0.2632173001766205\n",
      "Epoch 2105, Loss: 0.6563702374696732, Final Batch Loss: 0.16537517309188843\n",
      "Epoch 2106, Loss: 0.7226890027523041, Final Batch Loss: 0.265440434217453\n",
      "Epoch 2107, Loss: 0.7240916937589645, Final Batch Loss: 0.3047705590724945\n",
      "Epoch 2108, Loss: 0.782018855214119, Final Batch Loss: 0.28244975209236145\n",
      "Epoch 2109, Loss: 0.6391503363847733, Final Batch Loss: 0.24129369854927063\n",
      "Epoch 2110, Loss: 0.5917481333017349, Final Batch Loss: 0.2389136552810669\n",
      "Epoch 2111, Loss: 0.5702142715454102, Final Batch Loss: 0.1592019945383072\n",
      "Epoch 2112, Loss: 0.6169717758893967, Final Batch Loss: 0.13768741488456726\n",
      "Epoch 2113, Loss: 0.7559353113174438, Final Batch Loss: 0.31581395864486694\n",
      "Epoch 2114, Loss: 0.6144640296697617, Final Batch Loss: 0.16663840413093567\n",
      "Epoch 2115, Loss: 0.6357864439487457, Final Batch Loss: 0.21041125059127808\n",
      "Epoch 2116, Loss: 0.5561089813709259, Final Batch Loss: 0.16066770255565643\n",
      "Epoch 2117, Loss: 0.6081802248954773, Final Batch Loss: 0.15529094636440277\n",
      "Epoch 2118, Loss: 0.5296106040477753, Final Batch Loss: 0.14400476217269897\n",
      "Epoch 2119, Loss: 0.6266169846057892, Final Batch Loss: 0.21452195942401886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2120, Loss: 0.6667005717754364, Final Batch Loss: 0.19722861051559448\n",
      "Epoch 2121, Loss: 0.5824713408946991, Final Batch Loss: 0.20861119031906128\n",
      "Epoch 2122, Loss: 0.6793509125709534, Final Batch Loss: 0.24047672748565674\n",
      "Epoch 2123, Loss: 0.6974409967660904, Final Batch Loss: 0.267223596572876\n",
      "Epoch 2124, Loss: 0.6338270306587219, Final Batch Loss: 0.24298927187919617\n",
      "Epoch 2125, Loss: 0.6030697822570801, Final Batch Loss: 0.18370170891284943\n",
      "Epoch 2126, Loss: 0.615599736571312, Final Batch Loss: 0.22997988760471344\n",
      "Epoch 2127, Loss: 0.6487829089164734, Final Batch Loss: 0.1429978311061859\n",
      "Epoch 2128, Loss: 0.6285544037818909, Final Batch Loss: 0.15619954466819763\n",
      "Epoch 2129, Loss: 0.6720553338527679, Final Batch Loss: 0.20586246252059937\n",
      "Epoch 2130, Loss: 0.5484606027603149, Final Batch Loss: 0.13032497465610504\n",
      "Epoch 2131, Loss: 0.7148624062538147, Final Batch Loss: 0.3016680181026459\n",
      "Epoch 2132, Loss: 0.6339315623044968, Final Batch Loss: 0.20927733182907104\n",
      "Epoch 2133, Loss: 0.6613146513700485, Final Batch Loss: 0.23817522823810577\n",
      "Epoch 2134, Loss: 0.6004567891359329, Final Batch Loss: 0.22080416977405548\n",
      "Epoch 2135, Loss: 0.6223363429307938, Final Batch Loss: 0.2081102877855301\n",
      "Epoch 2136, Loss: 0.5933586210012436, Final Batch Loss: 0.1456867754459381\n",
      "Epoch 2137, Loss: 0.6128491163253784, Final Batch Loss: 0.15750066936016083\n",
      "Epoch 2138, Loss: 0.6517018377780914, Final Batch Loss: 0.2520618736743927\n",
      "Epoch 2139, Loss: 0.5875262022018433, Final Batch Loss: 0.1960817128419876\n",
      "Epoch 2140, Loss: 0.5790481716394424, Final Batch Loss: 0.2165813148021698\n",
      "Epoch 2141, Loss: 0.6930136978626251, Final Batch Loss: 0.21614542603492737\n",
      "Epoch 2142, Loss: 0.6605751216411591, Final Batch Loss: 0.1572723388671875\n",
      "Epoch 2143, Loss: 0.5953877121210098, Final Batch Loss: 0.1901920735836029\n",
      "Epoch 2144, Loss: 0.6305654048919678, Final Batch Loss: 0.2547493577003479\n",
      "Epoch 2145, Loss: 0.6553805619478226, Final Batch Loss: 0.23183995485305786\n",
      "Epoch 2146, Loss: 0.7303410470485687, Final Batch Loss: 0.2826521396636963\n",
      "Epoch 2147, Loss: 0.6487486511468887, Final Batch Loss: 0.18478761613368988\n",
      "Epoch 2148, Loss: 0.6192580312490463, Final Batch Loss: 0.1970740109682083\n",
      "Epoch 2149, Loss: 0.6186585128307343, Final Batch Loss: 0.2603548467159271\n",
      "Epoch 2150, Loss: 0.5539662092924118, Final Batch Loss: 0.14687055349349976\n",
      "Epoch 2151, Loss: 0.653488278388977, Final Batch Loss: 0.268318235874176\n",
      "Epoch 2152, Loss: 0.579160213470459, Final Batch Loss: 0.21881616115570068\n",
      "Epoch 2153, Loss: 0.6653701514005661, Final Batch Loss: 0.2500358819961548\n",
      "Epoch 2154, Loss: 0.7587436884641647, Final Batch Loss: 0.3168186545372009\n",
      "Epoch 2155, Loss: 0.5947177410125732, Final Batch Loss: 0.2094094604253769\n",
      "Epoch 2156, Loss: 0.6117536574602127, Final Batch Loss: 0.18682615458965302\n",
      "Epoch 2157, Loss: 0.6203395128250122, Final Batch Loss: 0.17451126873493195\n",
      "Epoch 2158, Loss: 0.6640115529298782, Final Batch Loss: 0.20446500182151794\n",
      "Epoch 2159, Loss: 0.626777395606041, Final Batch Loss: 0.17793652415275574\n",
      "Epoch 2160, Loss: 0.6987191885709763, Final Batch Loss: 0.26396864652633667\n",
      "Epoch 2161, Loss: 0.675520732998848, Final Batch Loss: 0.20653389394283295\n",
      "Epoch 2162, Loss: 0.6648100018501282, Final Batch Loss: 0.281276136636734\n",
      "Epoch 2163, Loss: 0.6752531677484512, Final Batch Loss: 0.22871966660022736\n",
      "Epoch 2164, Loss: 0.6320565342903137, Final Batch Loss: 0.2197738140821457\n",
      "Epoch 2165, Loss: 0.6464653462171555, Final Batch Loss: 0.23373480141162872\n",
      "Epoch 2166, Loss: 0.6025649458169937, Final Batch Loss: 0.21662749350070953\n",
      "Epoch 2167, Loss: 0.6968047767877579, Final Batch Loss: 0.22232124209403992\n",
      "Epoch 2168, Loss: 0.6726822704076767, Final Batch Loss: 0.3000127375125885\n",
      "Epoch 2169, Loss: 0.6066980212926865, Final Batch Loss: 0.21299166977405548\n",
      "Epoch 2170, Loss: 0.6682794839143753, Final Batch Loss: 0.17469249665737152\n",
      "Epoch 2171, Loss: 0.6856668144464493, Final Batch Loss: 0.21053926646709442\n",
      "Epoch 2172, Loss: 0.8062712550163269, Final Batch Loss: 0.265665739774704\n",
      "Epoch 2173, Loss: 0.7260979115962982, Final Batch Loss: 0.21087419986724854\n",
      "Epoch 2174, Loss: 0.6678649485111237, Final Batch Loss: 0.18204642832279205\n",
      "Epoch 2175, Loss: 0.7803843468427658, Final Batch Loss: 0.26429054141044617\n",
      "Epoch 2176, Loss: 0.5979675799608231, Final Batch Loss: 0.20622482895851135\n",
      "Epoch 2177, Loss: 0.6877604573965073, Final Batch Loss: 0.25131332874298096\n",
      "Epoch 2178, Loss: 0.5556234866380692, Final Batch Loss: 0.1427547037601471\n",
      "Epoch 2179, Loss: 0.6383067220449448, Final Batch Loss: 0.20780542492866516\n",
      "Epoch 2180, Loss: 0.5702780783176422, Final Batch Loss: 0.1648956537246704\n",
      "Epoch 2181, Loss: 0.7018305212259293, Final Batch Loss: 0.2966425120830536\n",
      "Epoch 2182, Loss: 0.6100943982601166, Final Batch Loss: 0.1897178739309311\n",
      "Epoch 2183, Loss: 0.595882773399353, Final Batch Loss: 0.17272421717643738\n",
      "Epoch 2184, Loss: 0.6562608778476715, Final Batch Loss: 0.23889866471290588\n",
      "Epoch 2185, Loss: 0.7321098297834396, Final Batch Loss: 0.25741884112358093\n",
      "Epoch 2186, Loss: 0.6005530208349228, Final Batch Loss: 0.2393956035375595\n",
      "Epoch 2187, Loss: 0.6939976513385773, Final Batch Loss: 0.32152944803237915\n",
      "Epoch 2188, Loss: 0.769717276096344, Final Batch Loss: 0.2265816330909729\n",
      "Epoch 2189, Loss: 0.6549624800682068, Final Batch Loss: 0.22076314687728882\n",
      "Epoch 2190, Loss: 0.6809799671173096, Final Batch Loss: 0.26754018664360046\n",
      "Epoch 2191, Loss: 0.7034632712602615, Final Batch Loss: 0.30430126190185547\n",
      "Epoch 2192, Loss: 0.670071616768837, Final Batch Loss: 0.238227978348732\n",
      "Epoch 2193, Loss: 0.6841567903757095, Final Batch Loss: 0.20497676730155945\n",
      "Epoch 2194, Loss: 0.6076754480600357, Final Batch Loss: 0.15691079199314117\n",
      "Epoch 2195, Loss: 0.7075487524271011, Final Batch Loss: 0.23659148812294006\n",
      "Epoch 2196, Loss: 0.6886201053857803, Final Batch Loss: 0.16391108930110931\n",
      "Epoch 2197, Loss: 0.6518793106079102, Final Batch Loss: 0.18876822292804718\n",
      "Epoch 2198, Loss: 0.7020085155963898, Final Batch Loss: 0.278870165348053\n",
      "Epoch 2199, Loss: 0.6482467204332352, Final Batch Loss: 0.25128528475761414\n",
      "Epoch 2200, Loss: 0.7163336277008057, Final Batch Loss: 0.27577972412109375\n",
      "Epoch 2201, Loss: 0.7017711251974106, Final Batch Loss: 0.27564138174057007\n",
      "Epoch 2202, Loss: 0.579955518245697, Final Batch Loss: 0.1512691229581833\n",
      "Epoch 2203, Loss: 0.5954594612121582, Final Batch Loss: 0.22587615251541138\n",
      "Epoch 2204, Loss: 0.6074559092521667, Final Batch Loss: 0.28254061937332153\n",
      "Epoch 2205, Loss: 0.6061490327119827, Final Batch Loss: 0.21591174602508545\n",
      "Epoch 2206, Loss: 0.5825954526662827, Final Batch Loss: 0.15646454691886902\n",
      "Epoch 2207, Loss: 0.5979491174221039, Final Batch Loss: 0.21440351009368896\n",
      "Epoch 2208, Loss: 0.5834125280380249, Final Batch Loss: 0.19361339509487152\n",
      "Epoch 2209, Loss: 0.604084849357605, Final Batch Loss: 0.14802658557891846\n",
      "Epoch 2210, Loss: 0.6049912571907043, Final Batch Loss: 0.1847188025712967\n",
      "Epoch 2211, Loss: 0.6087890863418579, Final Batch Loss: 0.22325631976127625\n",
      "Epoch 2212, Loss: 0.5667619109153748, Final Batch Loss: 0.19678868353366852\n",
      "Epoch 2213, Loss: 0.5374127924442291, Final Batch Loss: 0.1465248167514801\n",
      "Epoch 2214, Loss: 0.6734873056411743, Final Batch Loss: 0.30746617913246155\n",
      "Epoch 2215, Loss: 0.6392191648483276, Final Batch Loss: 0.2127043455839157\n",
      "Epoch 2216, Loss: 0.7575310170650482, Final Batch Loss: 0.3263610601425171\n",
      "Epoch 2217, Loss: 0.6489515751600266, Final Batch Loss: 0.1631491482257843\n",
      "Epoch 2218, Loss: 0.5920482575893402, Final Batch Loss: 0.13386115431785583\n",
      "Epoch 2219, Loss: 0.6383263617753983, Final Batch Loss: 0.26484209299087524\n",
      "Epoch 2220, Loss: 0.5932395607233047, Final Batch Loss: 0.18350155651569366\n",
      "Epoch 2221, Loss: 0.5812326371669769, Final Batch Loss: 0.19839154183864594\n",
      "Epoch 2222, Loss: 0.6767580062150955, Final Batch Loss: 0.2642386555671692\n",
      "Epoch 2223, Loss: 0.5644291490316391, Final Batch Loss: 0.15393954515457153\n",
      "Epoch 2224, Loss: 0.7533499449491501, Final Batch Loss: 0.29866066575050354\n",
      "Epoch 2225, Loss: 0.6032968163490295, Final Batch Loss: 0.20396097004413605\n",
      "Epoch 2226, Loss: 0.5873996317386627, Final Batch Loss: 0.15429891645908356\n",
      "Epoch 2227, Loss: 0.6601211577653885, Final Batch Loss: 0.17109887301921844\n",
      "Epoch 2228, Loss: 0.6158062368631363, Final Batch Loss: 0.18558117747306824\n",
      "Epoch 2229, Loss: 0.5984076112508774, Final Batch Loss: 0.16614656150341034\n",
      "Epoch 2230, Loss: 0.7783660441637039, Final Batch Loss: 0.3705829381942749\n",
      "Epoch 2231, Loss: 0.569391205906868, Final Batch Loss: 0.16745275259017944\n",
      "Epoch 2232, Loss: 0.6897500902414322, Final Batch Loss: 0.2753503918647766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2233, Loss: 0.6198548823595047, Final Batch Loss: 0.15685845911502838\n",
      "Epoch 2234, Loss: 0.7053787112236023, Final Batch Loss: 0.283955842256546\n",
      "Epoch 2235, Loss: 0.5786127001047134, Final Batch Loss: 0.18981358408927917\n",
      "Epoch 2236, Loss: 0.5765169262886047, Final Batch Loss: 0.17113178968429565\n",
      "Epoch 2237, Loss: 0.49668700993061066, Final Batch Loss: 0.13174070417881012\n",
      "Epoch 2238, Loss: 0.5766007304191589, Final Batch Loss: 0.24768750369548798\n",
      "Epoch 2239, Loss: 0.6160475164651871, Final Batch Loss: 0.1894998699426651\n",
      "Epoch 2240, Loss: 0.6231175065040588, Final Batch Loss: 0.14112836122512817\n",
      "Epoch 2241, Loss: 0.7200147062540054, Final Batch Loss: 0.20072761178016663\n",
      "Epoch 2242, Loss: 0.5118649005889893, Final Batch Loss: 0.13291391730308533\n",
      "Epoch 2243, Loss: 0.5434247702360153, Final Batch Loss: 0.2028338760137558\n",
      "Epoch 2244, Loss: 0.623939037322998, Final Batch Loss: 0.26615455746650696\n",
      "Epoch 2245, Loss: 0.6439655348658562, Final Batch Loss: 0.2816038429737091\n",
      "Epoch 2246, Loss: 0.6060100197792053, Final Batch Loss: 0.1689818799495697\n",
      "Epoch 2247, Loss: 0.5961303412914276, Final Batch Loss: 0.1888131946325302\n",
      "Epoch 2248, Loss: 0.7247585207223892, Final Batch Loss: 0.27428972721099854\n",
      "Epoch 2249, Loss: 0.6701956987380981, Final Batch Loss: 0.2307543158531189\n",
      "Epoch 2250, Loss: 0.6437121778726578, Final Batch Loss: 0.1868664175271988\n",
      "Epoch 2251, Loss: 0.6457073837518692, Final Batch Loss: 0.15298804640769958\n",
      "Epoch 2252, Loss: 0.6744132936000824, Final Batch Loss: 0.21276025474071503\n",
      "Epoch 2253, Loss: 0.5975903570652008, Final Batch Loss: 0.16091930866241455\n",
      "Epoch 2254, Loss: 0.7965587973594666, Final Batch Loss: 0.3487531244754791\n",
      "Epoch 2255, Loss: 0.5704845041036606, Final Batch Loss: 0.13883449137210846\n",
      "Epoch 2256, Loss: 0.6578266024589539, Final Batch Loss: 0.2082672417163849\n",
      "Epoch 2257, Loss: 0.6380168795585632, Final Batch Loss: 0.13148528337478638\n",
      "Epoch 2258, Loss: 0.645387589931488, Final Batch Loss: 0.23239551484584808\n",
      "Epoch 2259, Loss: 0.8147419691085815, Final Batch Loss: 0.3304794430732727\n",
      "Epoch 2260, Loss: 0.7034273147583008, Final Batch Loss: 0.25163012742996216\n",
      "Epoch 2261, Loss: 0.6594913005828857, Final Batch Loss: 0.23836444318294525\n",
      "Epoch 2262, Loss: 0.6276197731494904, Final Batch Loss: 0.20830205082893372\n",
      "Epoch 2263, Loss: 0.6586561053991318, Final Batch Loss: 0.21851980686187744\n",
      "Epoch 2264, Loss: 0.6988533735275269, Final Batch Loss: 0.1999211460351944\n",
      "Epoch 2265, Loss: 0.5941299051046371, Final Batch Loss: 0.13521863520145416\n",
      "Epoch 2266, Loss: 0.5630557388067245, Final Batch Loss: 0.15233580768108368\n",
      "Epoch 2267, Loss: 0.5481344312429428, Final Batch Loss: 0.2036793828010559\n",
      "Epoch 2268, Loss: 0.5821748077869415, Final Batch Loss: 0.15047642588615417\n",
      "Epoch 2269, Loss: 0.5715523958206177, Final Batch Loss: 0.172664612531662\n",
      "Epoch 2270, Loss: 0.6077394932508469, Final Batch Loss: 0.22897164523601532\n",
      "Epoch 2271, Loss: 0.6248626261949539, Final Batch Loss: 0.23586256802082062\n",
      "Epoch 2272, Loss: 0.5454552620649338, Final Batch Loss: 0.1192706972360611\n",
      "Epoch 2273, Loss: 0.5978869795799255, Final Batch Loss: 0.14014984667301178\n",
      "Epoch 2274, Loss: 0.6926563084125519, Final Batch Loss: 0.27159103751182556\n",
      "Epoch 2275, Loss: 0.6686969250440598, Final Batch Loss: 0.215824693441391\n",
      "Epoch 2276, Loss: 0.5487404763698578, Final Batch Loss: 0.15107721090316772\n",
      "Epoch 2277, Loss: 0.7093599885702133, Final Batch Loss: 0.209990993142128\n",
      "Epoch 2278, Loss: 0.7103538513183594, Final Batch Loss: 0.28517651557922363\n",
      "Epoch 2279, Loss: 0.6391431391239166, Final Batch Loss: 0.18761004507541656\n",
      "Epoch 2280, Loss: 0.6599120646715164, Final Batch Loss: 0.218617245554924\n",
      "Epoch 2281, Loss: 0.7317540049552917, Final Batch Loss: 0.3404277265071869\n",
      "Epoch 2282, Loss: 0.6295742392539978, Final Batch Loss: 0.2129012644290924\n",
      "Epoch 2283, Loss: 0.6815622746944427, Final Batch Loss: 0.2630791962146759\n",
      "Epoch 2284, Loss: 0.6209313869476318, Final Batch Loss: 0.22151564061641693\n",
      "Epoch 2285, Loss: 0.6143960356712341, Final Batch Loss: 0.19904425740242004\n",
      "Epoch 2286, Loss: 0.7370631247758865, Final Batch Loss: 0.2345488965511322\n",
      "Epoch 2287, Loss: 0.5668488591909409, Final Batch Loss: 0.13233153522014618\n",
      "Epoch 2288, Loss: 0.6017926782369614, Final Batch Loss: 0.17232240736484528\n",
      "Epoch 2289, Loss: 0.6255463510751724, Final Batch Loss: 0.26580166816711426\n",
      "Epoch 2290, Loss: 0.5284419506788254, Final Batch Loss: 0.1436673253774643\n",
      "Epoch 2291, Loss: 0.5921695828437805, Final Batch Loss: 0.14363643527030945\n",
      "Epoch 2292, Loss: 0.5914116352796555, Final Batch Loss: 0.1604974865913391\n",
      "Epoch 2293, Loss: 0.5939529687166214, Final Batch Loss: 0.1681298464536667\n",
      "Epoch 2294, Loss: 0.5454957485198975, Final Batch Loss: 0.16991233825683594\n",
      "Epoch 2295, Loss: 0.675375908613205, Final Batch Loss: 0.2599877119064331\n",
      "Epoch 2296, Loss: 0.713428869843483, Final Batch Loss: 0.338276743888855\n",
      "Epoch 2297, Loss: 0.6172677129507065, Final Batch Loss: 0.2759479582309723\n",
      "Epoch 2298, Loss: 0.6668982654809952, Final Batch Loss: 0.19144074618816376\n",
      "Epoch 2299, Loss: 0.6486853808164597, Final Batch Loss: 0.1992367058992386\n",
      "Epoch 2300, Loss: 0.532413050532341, Final Batch Loss: 0.13414646685123444\n",
      "Epoch 2301, Loss: 0.69253970682621, Final Batch Loss: 0.22002696990966797\n",
      "Epoch 2302, Loss: 0.4899093359708786, Final Batch Loss: 0.14214278757572174\n",
      "Epoch 2303, Loss: 0.5955357700586319, Final Batch Loss: 0.13595478236675262\n",
      "Epoch 2304, Loss: 0.5652149617671967, Final Batch Loss: 0.14360125362873077\n",
      "Epoch 2305, Loss: 0.773011177778244, Final Batch Loss: 0.2707701027393341\n",
      "Epoch 2306, Loss: 0.6146627217531204, Final Batch Loss: 0.14321652054786682\n",
      "Epoch 2307, Loss: 0.5768135040998459, Final Batch Loss: 0.1888103485107422\n",
      "Epoch 2308, Loss: 0.5953249037265778, Final Batch Loss: 0.18054886162281036\n",
      "Epoch 2309, Loss: 0.5722722113132477, Final Batch Loss: 0.2447817176580429\n",
      "Epoch 2310, Loss: 0.47923001646995544, Final Batch Loss: 0.16241729259490967\n",
      "Epoch 2311, Loss: 0.5467717796564102, Final Batch Loss: 0.15869633853435516\n",
      "Epoch 2312, Loss: 0.5735483318567276, Final Batch Loss: 0.1638641357421875\n",
      "Epoch 2313, Loss: 0.5770876780152321, Final Batch Loss: 0.11503317207098007\n",
      "Epoch 2314, Loss: 0.6440127193927765, Final Batch Loss: 0.2574237287044525\n",
      "Epoch 2315, Loss: 0.6016556024551392, Final Batch Loss: 0.1543625295162201\n",
      "Epoch 2316, Loss: 0.6372111290693283, Final Batch Loss: 0.24527546763420105\n",
      "Epoch 2317, Loss: 0.6442302167415619, Final Batch Loss: 0.24465923011302948\n",
      "Epoch 2318, Loss: 0.6322517693042755, Final Batch Loss: 0.24332351982593536\n",
      "Epoch 2319, Loss: 0.538623109459877, Final Batch Loss: 0.18045571446418762\n",
      "Epoch 2320, Loss: 0.6897955238819122, Final Batch Loss: 0.296943724155426\n",
      "Epoch 2321, Loss: 0.5819008946418762, Final Batch Loss: 0.1706545203924179\n",
      "Epoch 2322, Loss: 0.6178392320871353, Final Batch Loss: 0.1686253398656845\n",
      "Epoch 2323, Loss: 0.6044557839632034, Final Batch Loss: 0.18177466094493866\n",
      "Epoch 2324, Loss: 0.5257802307605743, Final Batch Loss: 0.12659263610839844\n",
      "Epoch 2325, Loss: 0.6038921773433685, Final Batch Loss: 0.19577020406723022\n",
      "Epoch 2326, Loss: 0.5518031269311905, Final Batch Loss: 0.20436260104179382\n",
      "Epoch 2327, Loss: 0.5960494428873062, Final Batch Loss: 0.19868628680706024\n",
      "Epoch 2328, Loss: 0.4881584346294403, Final Batch Loss: 0.13833202421665192\n",
      "Epoch 2329, Loss: 0.5862674713134766, Final Batch Loss: 0.17378760874271393\n",
      "Epoch 2330, Loss: 0.5360870212316513, Final Batch Loss: 0.19543303549289703\n",
      "Epoch 2331, Loss: 0.6242726594209671, Final Batch Loss: 0.162746399641037\n",
      "Epoch 2332, Loss: 0.7053085714578629, Final Batch Loss: 0.2554192841053009\n",
      "Epoch 2333, Loss: 0.5581133216619492, Final Batch Loss: 0.1933811753988266\n",
      "Epoch 2334, Loss: 0.6276614964008331, Final Batch Loss: 0.18467523157596588\n",
      "Epoch 2335, Loss: 0.5268156379461288, Final Batch Loss: 0.14366935193538666\n",
      "Epoch 2336, Loss: 0.593774139881134, Final Batch Loss: 0.2111775279045105\n",
      "Epoch 2337, Loss: 0.5833577513694763, Final Batch Loss: 0.24871575832366943\n",
      "Epoch 2338, Loss: 0.5698083341121674, Final Batch Loss: 0.19337107241153717\n",
      "Epoch 2339, Loss: 0.6510301679372787, Final Batch Loss: 0.19130869209766388\n",
      "Epoch 2340, Loss: 0.6915891915559769, Final Batch Loss: 0.31216803193092346\n",
      "Epoch 2341, Loss: 0.5910034030675888, Final Batch Loss: 0.20389190316200256\n",
      "Epoch 2342, Loss: 0.5493924915790558, Final Batch Loss: 0.16497589647769928\n",
      "Epoch 2343, Loss: 0.6281126290559769, Final Batch Loss: 0.21889851987361908\n",
      "Epoch 2344, Loss: 0.7084295302629471, Final Batch Loss: 0.30339959263801575\n",
      "Epoch 2345, Loss: 0.5483865290880203, Final Batch Loss: 0.18547599017620087\n",
      "Epoch 2346, Loss: 0.647614061832428, Final Batch Loss: 0.1624385118484497\n",
      "Epoch 2347, Loss: 0.6090777516365051, Final Batch Loss: 0.2803160846233368\n",
      "Epoch 2348, Loss: 0.5993223190307617, Final Batch Loss: 0.1592855453491211\n",
      "Epoch 2349, Loss: 0.5439703315496445, Final Batch Loss: 0.15572062134742737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2350, Loss: 0.44112974405288696, Final Batch Loss: 0.10916727781295776\n",
      "Epoch 2351, Loss: 0.5901700705289841, Final Batch Loss: 0.16415564715862274\n",
      "Epoch 2352, Loss: 0.6941096186637878, Final Batch Loss: 0.3120412826538086\n",
      "Epoch 2353, Loss: 0.5200134813785553, Final Batch Loss: 0.14649717509746552\n",
      "Epoch 2354, Loss: 0.6530735939741135, Final Batch Loss: 0.19487950205802917\n",
      "Epoch 2355, Loss: 0.5810134708881378, Final Batch Loss: 0.15432940423488617\n",
      "Epoch 2356, Loss: 0.6508802175521851, Final Batch Loss: 0.2118249535560608\n",
      "Epoch 2357, Loss: 0.616935983300209, Final Batch Loss: 0.17445038259029388\n",
      "Epoch 2358, Loss: 0.6906915307044983, Final Batch Loss: 0.28988146781921387\n",
      "Epoch 2359, Loss: 0.6396852284669876, Final Batch Loss: 0.25564318895339966\n",
      "Epoch 2360, Loss: 0.6926843672990799, Final Batch Loss: 0.3350399136543274\n",
      "Epoch 2361, Loss: 0.6821807473897934, Final Batch Loss: 0.16993093490600586\n",
      "Epoch 2362, Loss: 0.5164666324853897, Final Batch Loss: 0.10022924840450287\n",
      "Epoch 2363, Loss: 0.626288428902626, Final Batch Loss: 0.22772273421287537\n",
      "Epoch 2364, Loss: 0.6447271108627319, Final Batch Loss: 0.16208450496196747\n",
      "Epoch 2365, Loss: 0.5913245528936386, Final Batch Loss: 0.19634918868541718\n",
      "Epoch 2366, Loss: 0.6886732131242752, Final Batch Loss: 0.33647671341896057\n",
      "Epoch 2367, Loss: 0.4943578317761421, Final Batch Loss: 0.10665170103311539\n",
      "Epoch 2368, Loss: 0.6583268940448761, Final Batch Loss: 0.2893167734146118\n",
      "Epoch 2369, Loss: 0.7244608998298645, Final Batch Loss: 0.3065726161003113\n",
      "Epoch 2370, Loss: 0.6377875953912735, Final Batch Loss: 0.21211598813533783\n",
      "Epoch 2371, Loss: 0.77327761054039, Final Batch Loss: 0.2596946954727173\n",
      "Epoch 2372, Loss: 0.7700130790472031, Final Batch Loss: 0.22476106882095337\n",
      "Epoch 2373, Loss: 0.7282937616109848, Final Batch Loss: 0.33090007305145264\n",
      "Epoch 2374, Loss: 0.6157577931880951, Final Batch Loss: 0.16715338826179504\n",
      "Epoch 2375, Loss: 0.60725037753582, Final Batch Loss: 0.22157728672027588\n",
      "Epoch 2376, Loss: 0.5731398463249207, Final Batch Loss: 0.2143738865852356\n",
      "Epoch 2377, Loss: 0.5911559462547302, Final Batch Loss: 0.19145937263965607\n",
      "Epoch 2378, Loss: 0.6100009679794312, Final Batch Loss: 0.13241498172283173\n",
      "Epoch 2379, Loss: 0.5549281686544418, Final Batch Loss: 0.18137988448143005\n",
      "Epoch 2380, Loss: 0.5655248463153839, Final Batch Loss: 0.17151324450969696\n",
      "Epoch 2381, Loss: 0.6640209257602692, Final Batch Loss: 0.2931087911128998\n",
      "Epoch 2382, Loss: 0.6112515181303024, Final Batch Loss: 0.16529135406017303\n",
      "Epoch 2383, Loss: 0.6370771825313568, Final Batch Loss: 0.1735822856426239\n",
      "Epoch 2384, Loss: 0.5550594925880432, Final Batch Loss: 0.1288948506116867\n",
      "Epoch 2385, Loss: 0.7227679342031479, Final Batch Loss: 0.25628605484962463\n",
      "Epoch 2386, Loss: 0.8511103689670563, Final Batch Loss: 0.2955949306488037\n",
      "Epoch 2387, Loss: 0.674958810210228, Final Batch Loss: 0.2558367848396301\n",
      "Epoch 2388, Loss: 0.6602979600429535, Final Batch Loss: 0.23622936010360718\n",
      "Epoch 2389, Loss: 0.766158938407898, Final Batch Loss: 0.2620660066604614\n",
      "Epoch 2390, Loss: 0.6044512540102005, Final Batch Loss: 0.203542098402977\n",
      "Epoch 2391, Loss: 0.653038740158081, Final Batch Loss: 0.26612383127212524\n",
      "Epoch 2392, Loss: 0.6922901272773743, Final Batch Loss: 0.2893163859844208\n",
      "Epoch 2393, Loss: 0.804978147149086, Final Batch Loss: 0.2782929539680481\n",
      "Epoch 2394, Loss: 0.5781843811273575, Final Batch Loss: 0.17487981915473938\n",
      "Epoch 2395, Loss: 0.629206120967865, Final Batch Loss: 0.24371320009231567\n",
      "Epoch 2396, Loss: 0.7180304229259491, Final Batch Loss: 0.3132670223712921\n",
      "Epoch 2397, Loss: 0.6177803575992584, Final Batch Loss: 0.1640574038028717\n",
      "Epoch 2398, Loss: 0.6692090928554535, Final Batch Loss: 0.19956885278224945\n",
      "Epoch 2399, Loss: 0.6141772270202637, Final Batch Loss: 0.1678699105978012\n",
      "Epoch 2400, Loss: 0.5740038901567459, Final Batch Loss: 0.1744874268770218\n",
      "Epoch 2401, Loss: 0.5339955240488052, Final Batch Loss: 0.19270306825637817\n",
      "Epoch 2402, Loss: 0.5655434131622314, Final Batch Loss: 0.1540546864271164\n",
      "Epoch 2403, Loss: 0.528852641582489, Final Batch Loss: 0.13838379085063934\n",
      "Epoch 2404, Loss: 0.6326151639223099, Final Batch Loss: 0.13390228152275085\n",
      "Epoch 2405, Loss: 0.6395523995161057, Final Batch Loss: 0.20932400226593018\n",
      "Epoch 2406, Loss: 0.600554957985878, Final Batch Loss: 0.1905544549226761\n",
      "Epoch 2407, Loss: 0.5574874728918076, Final Batch Loss: 0.2271941602230072\n",
      "Epoch 2408, Loss: 0.5558063089847565, Final Batch Loss: 0.18708397448062897\n",
      "Epoch 2409, Loss: 0.5982077419757843, Final Batch Loss: 0.1568596512079239\n",
      "Epoch 2410, Loss: 0.5710409581661224, Final Batch Loss: 0.20624862611293793\n",
      "Epoch 2411, Loss: 0.5477384924888611, Final Batch Loss: 0.174660786986351\n",
      "Epoch 2412, Loss: 0.5911620855331421, Final Batch Loss: 0.14817088842391968\n",
      "Epoch 2413, Loss: 0.5478559732437134, Final Batch Loss: 0.19201168417930603\n",
      "Epoch 2414, Loss: 0.5779392123222351, Final Batch Loss: 0.2207716703414917\n",
      "Epoch 2415, Loss: 0.8050734400749207, Final Batch Loss: 0.37747707962989807\n",
      "Epoch 2416, Loss: 0.5640102028846741, Final Batch Loss: 0.1717236340045929\n",
      "Epoch 2417, Loss: 0.6754626482725143, Final Batch Loss: 0.27018189430236816\n",
      "Epoch 2418, Loss: 0.5228460282087326, Final Batch Loss: 0.17915168404579163\n",
      "Epoch 2419, Loss: 0.7873027920722961, Final Batch Loss: 0.3138539791107178\n",
      "Epoch 2420, Loss: 0.621722474694252, Final Batch Loss: 0.25288257002830505\n",
      "Epoch 2421, Loss: 0.6204525530338287, Final Batch Loss: 0.15460550785064697\n",
      "Epoch 2422, Loss: 0.5905568152666092, Final Batch Loss: 0.2334829568862915\n",
      "Epoch 2423, Loss: 0.6574749648571014, Final Batch Loss: 0.20675437152385712\n",
      "Epoch 2424, Loss: 0.6282554119825363, Final Batch Loss: 0.20970097184181213\n",
      "Epoch 2425, Loss: 0.7390407919883728, Final Batch Loss: 0.16960924863815308\n",
      "Epoch 2426, Loss: 0.617984414100647, Final Batch Loss: 0.19385483860969543\n",
      "Epoch 2427, Loss: 0.567326158285141, Final Batch Loss: 0.16250494122505188\n",
      "Epoch 2428, Loss: 0.5815517753362656, Final Batch Loss: 0.18007078766822815\n",
      "Epoch 2429, Loss: 0.6086799651384354, Final Batch Loss: 0.21512064337730408\n",
      "Epoch 2430, Loss: 0.5491842925548553, Final Batch Loss: 0.18106141686439514\n",
      "Epoch 2431, Loss: 0.6225721389055252, Final Batch Loss: 0.23708491027355194\n",
      "Epoch 2432, Loss: 0.5868558436632156, Final Batch Loss: 0.23701860010623932\n",
      "Epoch 2433, Loss: 0.6404823213815689, Final Batch Loss: 0.22162078320980072\n",
      "Epoch 2434, Loss: 0.7631588876247406, Final Batch Loss: 0.3925393223762512\n",
      "Epoch 2435, Loss: 0.7413263320922852, Final Batch Loss: 0.2718869149684906\n",
      "Epoch 2436, Loss: 0.5981326103210449, Final Batch Loss: 0.23548223078250885\n",
      "Epoch 2437, Loss: 0.5720327645540237, Final Batch Loss: 0.15713916718959808\n",
      "Epoch 2438, Loss: 0.6094879508018494, Final Batch Loss: 0.22394755482673645\n",
      "Epoch 2439, Loss: 0.5368230044841766, Final Batch Loss: 0.19421464204788208\n",
      "Epoch 2440, Loss: 0.5639626681804657, Final Batch Loss: 0.16343747079372406\n",
      "Epoch 2441, Loss: 0.6703640520572662, Final Batch Loss: 0.25924623012542725\n",
      "Epoch 2442, Loss: 0.5491951256990433, Final Batch Loss: 0.1522221565246582\n",
      "Epoch 2443, Loss: 0.7000502794981003, Final Batch Loss: 0.3348991870880127\n",
      "Epoch 2444, Loss: 0.6130379736423492, Final Batch Loss: 0.1851855218410492\n",
      "Epoch 2445, Loss: 0.6121044158935547, Final Batch Loss: 0.16882485151290894\n",
      "Epoch 2446, Loss: 0.5504928827285767, Final Batch Loss: 0.1999937891960144\n",
      "Epoch 2447, Loss: 0.5498211234807968, Final Batch Loss: 0.17867349088191986\n",
      "Epoch 2448, Loss: 0.5985523611307144, Final Batch Loss: 0.18304693698883057\n",
      "Epoch 2449, Loss: 0.5825070142745972, Final Batch Loss: 0.21125082671642303\n",
      "Epoch 2450, Loss: 0.5510584563016891, Final Batch Loss: 0.15568731725215912\n",
      "Epoch 2451, Loss: 0.57311150431633, Final Batch Loss: 0.19892482459545135\n",
      "Epoch 2452, Loss: 0.5675531029701233, Final Batch Loss: 0.15770424902439117\n",
      "Epoch 2453, Loss: 0.6230447590351105, Final Batch Loss: 0.2224249243736267\n",
      "Epoch 2454, Loss: 0.6181188821792603, Final Batch Loss: 0.21544842422008514\n",
      "Epoch 2455, Loss: 0.6001380383968353, Final Batch Loss: 0.20284952223300934\n",
      "Epoch 2456, Loss: 0.5851369351148605, Final Batch Loss: 0.16727551817893982\n",
      "Epoch 2457, Loss: 0.629649817943573, Final Batch Loss: 0.15379434823989868\n",
      "Epoch 2458, Loss: 0.680625706911087, Final Batch Loss: 0.1887992024421692\n",
      "Epoch 2459, Loss: 0.6741544157266617, Final Batch Loss: 0.19665926694869995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2460, Loss: 0.5230039954185486, Final Batch Loss: 0.16616086661815643\n",
      "Epoch 2461, Loss: 0.5352815836668015, Final Batch Loss: 0.13883820176124573\n",
      "Epoch 2462, Loss: 0.5695036798715591, Final Batch Loss: 0.15511436760425568\n",
      "Epoch 2463, Loss: 0.6266313791275024, Final Batch Loss: 0.1746804416179657\n",
      "Epoch 2464, Loss: 0.526636153459549, Final Batch Loss: 0.14175570011138916\n",
      "Epoch 2465, Loss: 0.742848351597786, Final Batch Loss: 0.2792702317237854\n",
      "Epoch 2466, Loss: 0.585943192243576, Final Batch Loss: 0.17479029297828674\n",
      "Epoch 2467, Loss: 0.5508835464715958, Final Batch Loss: 0.16515126824378967\n",
      "Epoch 2468, Loss: 0.5832271128892899, Final Batch Loss: 0.227871835231781\n",
      "Epoch 2469, Loss: 0.6371408551931381, Final Batch Loss: 0.2500932514667511\n",
      "Epoch 2470, Loss: 0.6089397519826889, Final Batch Loss: 0.2588616907596588\n",
      "Epoch 2471, Loss: 0.6060000211000443, Final Batch Loss: 0.19855724275112152\n",
      "Epoch 2472, Loss: 0.5410461947321892, Final Batch Loss: 0.12394865602254868\n",
      "Epoch 2473, Loss: 0.5537195801734924, Final Batch Loss: 0.1573341339826584\n",
      "Epoch 2474, Loss: 0.5400971919298172, Final Batch Loss: 0.1751471906900406\n",
      "Epoch 2475, Loss: 0.6858829110860825, Final Batch Loss: 0.355881005525589\n",
      "Epoch 2476, Loss: 0.6371597647666931, Final Batch Loss: 0.19798269867897034\n",
      "Epoch 2477, Loss: 0.6321577876806259, Final Batch Loss: 0.11852861940860748\n",
      "Epoch 2478, Loss: 0.4988413453102112, Final Batch Loss: 0.17502883076667786\n",
      "Epoch 2479, Loss: 0.5029649883508682, Final Batch Loss: 0.19062307476997375\n",
      "Epoch 2480, Loss: 0.49242860823869705, Final Batch Loss: 0.11688051372766495\n",
      "Epoch 2481, Loss: 0.6361977159976959, Final Batch Loss: 0.19630832970142365\n",
      "Epoch 2482, Loss: 0.5447677969932556, Final Batch Loss: 0.11293783783912659\n",
      "Epoch 2483, Loss: 0.6608325690031052, Final Batch Loss: 0.28366342186927795\n",
      "Epoch 2484, Loss: 0.6643098443746567, Final Batch Loss: 0.23942424356937408\n",
      "Epoch 2485, Loss: 0.6023413091897964, Final Batch Loss: 0.16366706788539886\n",
      "Epoch 2486, Loss: 0.5062150955200195, Final Batch Loss: 0.12894684076309204\n",
      "Epoch 2487, Loss: 0.7602540701627731, Final Batch Loss: 0.357138991355896\n",
      "Epoch 2488, Loss: 0.576633557677269, Final Batch Loss: 0.21787483990192413\n",
      "Epoch 2489, Loss: 0.5735918432474136, Final Batch Loss: 0.18527323007583618\n",
      "Epoch 2490, Loss: 0.5818396955728531, Final Batch Loss: 0.1842333823442459\n",
      "Epoch 2491, Loss: 0.6530731469392776, Final Batch Loss: 0.2742370367050171\n",
      "Epoch 2492, Loss: 0.6221365481615067, Final Batch Loss: 0.29401177167892456\n",
      "Epoch 2493, Loss: 0.49440260231494904, Final Batch Loss: 0.1544753462076187\n",
      "Epoch 2494, Loss: 0.623782217502594, Final Batch Loss: 0.2333548665046692\n",
      "Epoch 2495, Loss: 0.6165951639413834, Final Batch Loss: 0.19911380112171173\n",
      "Epoch 2496, Loss: 0.7442920804023743, Final Batch Loss: 0.333984911441803\n",
      "Epoch 2497, Loss: 0.519638903439045, Final Batch Loss: 0.11618553847074509\n",
      "Epoch 2498, Loss: 0.700139507651329, Final Batch Loss: 0.25880396366119385\n",
      "Epoch 2499, Loss: 0.646863654255867, Final Batch Loss: 0.22308029234409332\n",
      "Epoch 2500, Loss: 0.6032502800226212, Final Batch Loss: 0.1722336858510971\n",
      "Epoch 2501, Loss: 0.6026268154382706, Final Batch Loss: 0.2251523733139038\n",
      "Epoch 2502, Loss: 0.5280831158161163, Final Batch Loss: 0.17291605472564697\n",
      "Epoch 2503, Loss: 0.6651734411716461, Final Batch Loss: 0.20077075064182281\n",
      "Epoch 2504, Loss: 0.5052900016307831, Final Batch Loss: 0.14073751866817474\n",
      "Epoch 2505, Loss: 0.6515910476446152, Final Batch Loss: 0.2084607034921646\n",
      "Epoch 2506, Loss: 0.49240337312221527, Final Batch Loss: 0.14169324934482574\n",
      "Epoch 2507, Loss: 0.6186478585004807, Final Batch Loss: 0.17265614867210388\n",
      "Epoch 2508, Loss: 0.5666463673114777, Final Batch Loss: 0.13513462245464325\n",
      "Epoch 2509, Loss: 0.5487541109323502, Final Batch Loss: 0.18416982889175415\n",
      "Epoch 2510, Loss: 0.5586843639612198, Final Batch Loss: 0.14186060428619385\n",
      "Epoch 2511, Loss: 0.6162024140357971, Final Batch Loss: 0.2604130506515503\n",
      "Epoch 2512, Loss: 0.5430490225553513, Final Batch Loss: 0.2164628803730011\n",
      "Epoch 2513, Loss: 0.5898098647594452, Final Batch Loss: 0.18477021157741547\n",
      "Epoch 2514, Loss: 0.55870321393013, Final Batch Loss: 0.16242650151252747\n",
      "Epoch 2515, Loss: 0.7163475155830383, Final Batch Loss: 0.2586164176464081\n",
      "Epoch 2516, Loss: 0.6247769147157669, Final Batch Loss: 0.19434472918510437\n",
      "Epoch 2517, Loss: 0.628232330083847, Final Batch Loss: 0.20760191977024078\n",
      "Epoch 2518, Loss: 0.544817179441452, Final Batch Loss: 0.1557241827249527\n",
      "Epoch 2519, Loss: 0.5788354426622391, Final Batch Loss: 0.22043010592460632\n",
      "Epoch 2520, Loss: 0.6154673248529434, Final Batch Loss: 0.19289550185203552\n",
      "Epoch 2521, Loss: 0.4596284106373787, Final Batch Loss: 0.11541935056447983\n",
      "Epoch 2522, Loss: 0.5518733412027359, Final Batch Loss: 0.2075778990983963\n",
      "Epoch 2523, Loss: 0.6685979068279266, Final Batch Loss: 0.23777467012405396\n",
      "Epoch 2524, Loss: 0.5735222846269608, Final Batch Loss: 0.14800268411636353\n",
      "Epoch 2525, Loss: 0.6955553442239761, Final Batch Loss: 0.29749107360839844\n",
      "Epoch 2526, Loss: 0.5440966635942459, Final Batch Loss: 0.14886046946048737\n",
      "Epoch 2527, Loss: 0.49213626980781555, Final Batch Loss: 0.17705462872982025\n",
      "Epoch 2528, Loss: 0.519637793302536, Final Batch Loss: 0.15883289277553558\n",
      "Epoch 2529, Loss: 0.5834793150424957, Final Batch Loss: 0.1850103884935379\n",
      "Epoch 2530, Loss: 0.5233541876077652, Final Batch Loss: 0.17035861313343048\n",
      "Epoch 2531, Loss: 0.6420162618160248, Final Batch Loss: 0.2407512366771698\n",
      "Epoch 2532, Loss: 0.6740018278360367, Final Batch Loss: 0.2613585889339447\n",
      "Epoch 2533, Loss: 0.6520587056875229, Final Batch Loss: 0.16188165545463562\n",
      "Epoch 2534, Loss: 0.5618115961551666, Final Batch Loss: 0.18044842779636383\n",
      "Epoch 2535, Loss: 0.49146880209445953, Final Batch Loss: 0.1236925721168518\n",
      "Epoch 2536, Loss: 0.6443342119455338, Final Batch Loss: 0.21156823635101318\n",
      "Epoch 2537, Loss: 0.6167576760053635, Final Batch Loss: 0.2146759033203125\n",
      "Epoch 2538, Loss: 0.5459786951541901, Final Batch Loss: 0.19253434240818024\n",
      "Epoch 2539, Loss: 0.6334417313337326, Final Batch Loss: 0.18590769171714783\n",
      "Epoch 2540, Loss: 0.6502894759178162, Final Batch Loss: 0.1616508513689041\n",
      "Epoch 2541, Loss: 0.6151098608970642, Final Batch Loss: 0.23792171478271484\n",
      "Epoch 2542, Loss: 0.546107217669487, Final Batch Loss: 0.14879994094371796\n",
      "Epoch 2543, Loss: 0.5239223092794418, Final Batch Loss: 0.13765408098697662\n",
      "Epoch 2544, Loss: 0.6832433640956879, Final Batch Loss: 0.2679131031036377\n",
      "Epoch 2545, Loss: 0.5977796018123627, Final Batch Loss: 0.2230449765920639\n",
      "Epoch 2546, Loss: 0.667293518781662, Final Batch Loss: 0.23532333970069885\n",
      "Epoch 2547, Loss: 0.5870925635099411, Final Batch Loss: 0.27757081389427185\n",
      "Epoch 2548, Loss: 0.5665244162082672, Final Batch Loss: 0.20326492190361023\n",
      "Epoch 2549, Loss: 0.5624730437994003, Final Batch Loss: 0.23923079669475555\n",
      "Epoch 2550, Loss: 0.48989494144916534, Final Batch Loss: 0.18145601451396942\n",
      "Epoch 2551, Loss: 0.6480133980512619, Final Batch Loss: 0.2345445454120636\n",
      "Epoch 2552, Loss: 0.5537826716899872, Final Batch Loss: 0.18740053474903107\n",
      "Epoch 2553, Loss: 0.6973408758640289, Final Batch Loss: 0.19818919897079468\n",
      "Epoch 2554, Loss: 0.5987927615642548, Final Batch Loss: 0.17352299392223358\n",
      "Epoch 2555, Loss: 0.6195734143257141, Final Batch Loss: 0.24699294567108154\n",
      "Epoch 2556, Loss: 0.5540269911289215, Final Batch Loss: 0.13958396017551422\n",
      "Epoch 2557, Loss: 0.521990567445755, Final Batch Loss: 0.15110483765602112\n",
      "Epoch 2558, Loss: 0.6054043620824814, Final Batch Loss: 0.29328444600105286\n",
      "Epoch 2559, Loss: 0.5894259363412857, Final Batch Loss: 0.23712819814682007\n",
      "Epoch 2560, Loss: 0.5514299869537354, Final Batch Loss: 0.22055958211421967\n",
      "Epoch 2561, Loss: 0.5318159908056259, Final Batch Loss: 0.12892384827136993\n",
      "Epoch 2562, Loss: 0.6801844835281372, Final Batch Loss: 0.23783355951309204\n",
      "Epoch 2563, Loss: 0.5751594454050064, Final Batch Loss: 0.21830521523952484\n",
      "Epoch 2564, Loss: 0.5912441313266754, Final Batch Loss: 0.154700368642807\n",
      "Epoch 2565, Loss: 0.5746085345745087, Final Batch Loss: 0.20602677762508392\n",
      "Epoch 2566, Loss: 0.5495502203702927, Final Batch Loss: 0.18928281962871552\n",
      "Epoch 2567, Loss: 0.6461467891931534, Final Batch Loss: 0.2007632702589035\n",
      "Epoch 2568, Loss: 0.5167206972837448, Final Batch Loss: 0.16500261425971985\n",
      "Epoch 2569, Loss: 0.5654690265655518, Final Batch Loss: 0.17440123856067657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2570, Loss: 0.4895254224538803, Final Batch Loss: 0.17921370267868042\n",
      "Epoch 2571, Loss: 0.6043774634599686, Final Batch Loss: 0.21471388638019562\n",
      "Epoch 2572, Loss: 0.5736035853624344, Final Batch Loss: 0.18966709077358246\n",
      "Epoch 2573, Loss: 0.5868952125310898, Final Batch Loss: 0.18896949291229248\n",
      "Epoch 2574, Loss: 0.4955606907606125, Final Batch Loss: 0.1270437240600586\n",
      "Epoch 2575, Loss: 0.5369487106800079, Final Batch Loss: 0.1540306955575943\n",
      "Epoch 2576, Loss: 0.6857616901397705, Final Batch Loss: 0.30544811487197876\n",
      "Epoch 2577, Loss: 0.5820778161287308, Final Batch Loss: 0.20688170194625854\n",
      "Epoch 2578, Loss: 0.48072531819343567, Final Batch Loss: 0.1336130052804947\n",
      "Epoch 2579, Loss: 0.5630715638399124, Final Batch Loss: 0.1974441111087799\n",
      "Epoch 2580, Loss: 0.5032876580953598, Final Batch Loss: 0.1550038456916809\n",
      "Epoch 2581, Loss: 0.5000738799571991, Final Batch Loss: 0.14824563264846802\n",
      "Epoch 2582, Loss: 0.5751176998019218, Final Batch Loss: 0.12463846057653427\n",
      "Epoch 2583, Loss: 0.5503848642110825, Final Batch Loss: 0.21418875455856323\n",
      "Epoch 2584, Loss: 0.4873718023300171, Final Batch Loss: 0.14863328635692596\n",
      "Epoch 2585, Loss: 0.6116955280303955, Final Batch Loss: 0.16840220987796783\n",
      "Epoch 2586, Loss: 0.6340234875679016, Final Batch Loss: 0.24680739641189575\n",
      "Epoch 2587, Loss: 0.5593165010213852, Final Batch Loss: 0.16273194551467896\n",
      "Epoch 2588, Loss: 0.6219603270292282, Final Batch Loss: 0.2839953899383545\n",
      "Epoch 2589, Loss: 0.6373566687107086, Final Batch Loss: 0.17775002121925354\n",
      "Epoch 2590, Loss: 0.5580638349056244, Final Batch Loss: 0.21408142149448395\n",
      "Epoch 2591, Loss: 0.6110792607069016, Final Batch Loss: 0.19586116075515747\n",
      "Epoch 2592, Loss: 0.6512402445077896, Final Batch Loss: 0.2545095682144165\n",
      "Epoch 2593, Loss: 0.5520908534526825, Final Batch Loss: 0.16150252521038055\n",
      "Epoch 2594, Loss: 0.6222075670957565, Final Batch Loss: 0.20416243374347687\n",
      "Epoch 2595, Loss: 0.5687441825866699, Final Batch Loss: 0.18764182925224304\n",
      "Epoch 2596, Loss: 0.47465668618679047, Final Batch Loss: 0.14017808437347412\n",
      "Epoch 2597, Loss: 0.5781449526548386, Final Batch Loss: 0.24356773495674133\n",
      "Epoch 2598, Loss: 0.5547202527523041, Final Batch Loss: 0.17315320670604706\n",
      "Epoch 2599, Loss: 0.5920860916376114, Final Batch Loss: 0.23121550679206848\n",
      "Epoch 2600, Loss: 0.6203761547803879, Final Batch Loss: 0.22565726935863495\n",
      "Epoch 2601, Loss: 0.4863329380750656, Final Batch Loss: 0.16211113333702087\n",
      "Epoch 2602, Loss: 0.6130643337965012, Final Batch Loss: 0.21824954450130463\n",
      "Epoch 2603, Loss: 0.5098606050014496, Final Batch Loss: 0.1417681872844696\n",
      "Epoch 2604, Loss: 0.5912291556596756, Final Batch Loss: 0.1919538825750351\n",
      "Epoch 2605, Loss: 0.596673309803009, Final Batch Loss: 0.19088618457317352\n",
      "Epoch 2606, Loss: 0.5527335405349731, Final Batch Loss: 0.17104671895503998\n",
      "Epoch 2607, Loss: 0.540803387761116, Final Batch Loss: 0.20804764330387115\n",
      "Epoch 2608, Loss: 0.49698488414287567, Final Batch Loss: 0.16050370037555695\n",
      "Epoch 2609, Loss: 0.5025340616703033, Final Batch Loss: 0.18630680441856384\n",
      "Epoch 2610, Loss: 0.5971632450819016, Final Batch Loss: 0.23939718306064606\n",
      "Epoch 2611, Loss: 0.4949471354484558, Final Batch Loss: 0.1432628482580185\n",
      "Epoch 2612, Loss: 0.569725289940834, Final Batch Loss: 0.20494595170021057\n",
      "Epoch 2613, Loss: 0.49664588272571564, Final Batch Loss: 0.13196179270744324\n",
      "Epoch 2614, Loss: 0.5537863373756409, Final Batch Loss: 0.2193824052810669\n",
      "Epoch 2615, Loss: 0.4433954954147339, Final Batch Loss: 0.1509094387292862\n",
      "Epoch 2616, Loss: 0.6002268344163895, Final Batch Loss: 0.2556658983230591\n",
      "Epoch 2617, Loss: 0.604694589972496, Final Batch Loss: 0.22436510026454926\n",
      "Epoch 2618, Loss: 0.558361828327179, Final Batch Loss: 0.18985219299793243\n",
      "Epoch 2619, Loss: 0.555985152721405, Final Batch Loss: 0.1942957043647766\n",
      "Epoch 2620, Loss: 0.6272798925638199, Final Batch Loss: 0.22279764711856842\n",
      "Epoch 2621, Loss: 0.6172107309103012, Final Batch Loss: 0.20813049376010895\n",
      "Epoch 2622, Loss: 0.5003277361392975, Final Batch Loss: 0.1308876872062683\n",
      "Epoch 2623, Loss: 0.615612655878067, Final Batch Loss: 0.2527450621128082\n",
      "Epoch 2624, Loss: 0.459232434630394, Final Batch Loss: 0.12870261073112488\n",
      "Epoch 2625, Loss: 0.5247468799352646, Final Batch Loss: 0.228178933262825\n",
      "Epoch 2626, Loss: 0.5940794944763184, Final Batch Loss: 0.2764478623867035\n",
      "Epoch 2627, Loss: 0.5413774847984314, Final Batch Loss: 0.18833212554454803\n",
      "Epoch 2628, Loss: 0.6031297743320465, Final Batch Loss: 0.21833328902721405\n",
      "Epoch 2629, Loss: 0.5743435472249985, Final Batch Loss: 0.15439453721046448\n",
      "Epoch 2630, Loss: 0.5395396500825882, Final Batch Loss: 0.17932181060314178\n",
      "Epoch 2631, Loss: 0.4374314099550247, Final Batch Loss: 0.1464342474937439\n",
      "Epoch 2632, Loss: 0.6011689156293869, Final Batch Loss: 0.17589154839515686\n",
      "Epoch 2633, Loss: 0.5859427601099014, Final Batch Loss: 0.23380206525325775\n",
      "Epoch 2634, Loss: 0.6564448177814484, Final Batch Loss: 0.29836079478263855\n",
      "Epoch 2635, Loss: 0.6444229334592819, Final Batch Loss: 0.2428041696548462\n",
      "Epoch 2636, Loss: 0.4375516176223755, Final Batch Loss: 0.08419255912303925\n",
      "Epoch 2637, Loss: 0.5570694506168365, Final Batch Loss: 0.18733812868595123\n",
      "Epoch 2638, Loss: 0.5359298884868622, Final Batch Loss: 0.09934443235397339\n",
      "Epoch 2639, Loss: 0.5582448095083237, Final Batch Loss: 0.1448117047548294\n",
      "Epoch 2640, Loss: 0.6243155300617218, Final Batch Loss: 0.19432619214057922\n",
      "Epoch 2641, Loss: 0.519146516919136, Final Batch Loss: 0.18500028550624847\n",
      "Epoch 2642, Loss: 0.6140138059854507, Final Batch Loss: 0.24976369738578796\n",
      "Epoch 2643, Loss: 0.5726770460605621, Final Batch Loss: 0.16733668744564056\n",
      "Epoch 2644, Loss: 0.6007973253726959, Final Batch Loss: 0.16577588021755219\n",
      "Epoch 2645, Loss: 0.5140193402767181, Final Batch Loss: 0.12919080257415771\n",
      "Epoch 2646, Loss: 0.6930667757987976, Final Batch Loss: 0.35160985589027405\n",
      "Epoch 2647, Loss: 0.6252410411834717, Final Batch Loss: 0.20242321491241455\n",
      "Epoch 2648, Loss: 0.7428160160779953, Final Batch Loss: 0.3549881875514984\n",
      "Epoch 2649, Loss: 0.5054912567138672, Final Batch Loss: 0.18171052634716034\n",
      "Epoch 2650, Loss: 0.5145183354616165, Final Batch Loss: 0.1904122680425644\n",
      "Epoch 2651, Loss: 0.5540672689676285, Final Batch Loss: 0.20903876423835754\n",
      "Epoch 2652, Loss: 0.5718703418970108, Final Batch Loss: 0.13381005823612213\n",
      "Epoch 2653, Loss: 0.6073446720838547, Final Batch Loss: 0.25794780254364014\n",
      "Epoch 2654, Loss: 0.6127111315727234, Final Batch Loss: 0.21560163795948029\n",
      "Epoch 2655, Loss: 0.5169368237257004, Final Batch Loss: 0.15518969297409058\n",
      "Epoch 2656, Loss: 0.5379655957221985, Final Batch Loss: 0.16641893982887268\n",
      "Epoch 2657, Loss: 0.49321532249450684, Final Batch Loss: 0.12573771178722382\n",
      "Epoch 2658, Loss: 0.6010200083255768, Final Batch Loss: 0.2254534661769867\n",
      "Epoch 2659, Loss: 0.6826320141553879, Final Batch Loss: 0.2775934338569641\n",
      "Epoch 2660, Loss: 0.5693867802619934, Final Batch Loss: 0.17908871173858643\n",
      "Epoch 2661, Loss: 0.6395266652107239, Final Batch Loss: 0.2904704213142395\n",
      "Epoch 2662, Loss: 0.48481012880802155, Final Batch Loss: 0.17120371758937836\n",
      "Epoch 2663, Loss: 0.6577390134334564, Final Batch Loss: 0.3160557448863983\n",
      "Epoch 2664, Loss: 0.4806557148694992, Final Batch Loss: 0.1597689688205719\n",
      "Epoch 2665, Loss: 0.6493631899356842, Final Batch Loss: 0.2606543004512787\n",
      "Epoch 2666, Loss: 0.5471812784671783, Final Batch Loss: 0.1891193389892578\n",
      "Epoch 2667, Loss: 0.5366414189338684, Final Batch Loss: 0.1792616993188858\n",
      "Epoch 2668, Loss: 0.5864644944667816, Final Batch Loss: 0.20063164830207825\n",
      "Epoch 2669, Loss: 0.5615321099758148, Final Batch Loss: 0.19578038156032562\n",
      "Epoch 2670, Loss: 0.5063653588294983, Final Batch Loss: 0.17238512635231018\n",
      "Epoch 2671, Loss: 0.5290362685918808, Final Batch Loss: 0.2165292352437973\n",
      "Epoch 2672, Loss: 0.5046739280223846, Final Batch Loss: 0.16978766024112701\n",
      "Epoch 2673, Loss: 0.5065917670726776, Final Batch Loss: 0.15084633231163025\n",
      "Epoch 2674, Loss: 0.5201097428798676, Final Batch Loss: 0.11797462403774261\n",
      "Epoch 2675, Loss: 0.5176862925291061, Final Batch Loss: 0.2082182615995407\n",
      "Epoch 2676, Loss: 0.626115545630455, Final Batch Loss: 0.14511948823928833\n",
      "Epoch 2677, Loss: 0.632469892501831, Final Batch Loss: 0.21602240204811096\n",
      "Epoch 2678, Loss: 0.5293090045452118, Final Batch Loss: 0.19051390886306763\n",
      "Epoch 2679, Loss: 0.6603024303913116, Final Batch Loss: 0.3291878402233124\n",
      "Epoch 2680, Loss: 0.6004524081945419, Final Batch Loss: 0.2598271071910858\n",
      "Epoch 2681, Loss: 0.5947542190551758, Final Batch Loss: 0.16753076016902924\n",
      "Epoch 2682, Loss: 0.6068723350763321, Final Batch Loss: 0.23432186245918274\n",
      "Epoch 2683, Loss: 0.5727570205926895, Final Batch Loss: 0.16210247576236725\n",
      "Epoch 2684, Loss: 0.666017010807991, Final Batch Loss: 0.1944482922554016\n",
      "Epoch 2685, Loss: 0.521368607878685, Final Batch Loss: 0.18758568167686462\n",
      "Epoch 2686, Loss: 0.4933137893676758, Final Batch Loss: 0.15802046656608582\n",
      "Epoch 2687, Loss: 0.5684153884649277, Final Batch Loss: 0.20525823533535004\n",
      "Epoch 2688, Loss: 0.4850646108388901, Final Batch Loss: 0.18810613453388214\n",
      "Epoch 2689, Loss: 0.5360979288816452, Final Batch Loss: 0.16832324862480164\n",
      "Epoch 2690, Loss: 0.6420096755027771, Final Batch Loss: 0.23745478689670563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2691, Loss: 0.5315468013286591, Final Batch Loss: 0.1776774823665619\n",
      "Epoch 2692, Loss: 0.5481340661644936, Final Batch Loss: 0.19129827618598938\n",
      "Epoch 2693, Loss: 0.6004662066698074, Final Batch Loss: 0.2011512815952301\n",
      "Epoch 2694, Loss: 0.6130053251981735, Final Batch Loss: 0.19926480948925018\n",
      "Epoch 2695, Loss: 0.6181900277733803, Final Batch Loss: 0.25396913290023804\n",
      "Epoch 2696, Loss: 0.5322992354631424, Final Batch Loss: 0.16709694266319275\n",
      "Epoch 2697, Loss: 0.5213322639465332, Final Batch Loss: 0.1861591339111328\n",
      "Epoch 2698, Loss: 0.424821637570858, Final Batch Loss: 0.09810750931501389\n",
      "Epoch 2699, Loss: 0.5229517668485641, Final Batch Loss: 0.16395780444145203\n",
      "Epoch 2700, Loss: 0.5959660708904266, Final Batch Loss: 0.22099553048610687\n",
      "Epoch 2701, Loss: 0.5064868777990341, Final Batch Loss: 0.15593619644641876\n",
      "Epoch 2702, Loss: 0.6175060272216797, Final Batch Loss: 0.2148815542459488\n",
      "Epoch 2703, Loss: 0.5766047239303589, Final Batch Loss: 0.1595025211572647\n",
      "Epoch 2704, Loss: 0.5477180033922195, Final Batch Loss: 0.17040106654167175\n",
      "Epoch 2705, Loss: 0.5598436594009399, Final Batch Loss: 0.18809716403484344\n",
      "Epoch 2706, Loss: 0.5653238594532013, Final Batch Loss: 0.14534106850624084\n",
      "Epoch 2707, Loss: 0.48057322204113007, Final Batch Loss: 0.11564478278160095\n",
      "Epoch 2708, Loss: 0.526855394244194, Final Batch Loss: 0.1440611332654953\n",
      "Epoch 2709, Loss: 0.5664940625429153, Final Batch Loss: 0.18540169298648834\n",
      "Epoch 2710, Loss: 0.5852938294410706, Final Batch Loss: 0.1979759782552719\n",
      "Epoch 2711, Loss: 0.5677062273025513, Final Batch Loss: 0.21201328933238983\n",
      "Epoch 2712, Loss: 0.6984366178512573, Final Batch Loss: 0.21956656873226166\n",
      "Epoch 2713, Loss: 0.48655638843774796, Final Batch Loss: 0.12319100648164749\n",
      "Epoch 2714, Loss: 0.4977245181798935, Final Batch Loss: 0.1575571447610855\n",
      "Epoch 2715, Loss: 0.5363174080848694, Final Batch Loss: 0.14607378840446472\n",
      "Epoch 2716, Loss: 0.5392175316810608, Final Batch Loss: 0.2149004489183426\n",
      "Epoch 2717, Loss: 0.5572931915521622, Final Batch Loss: 0.1407252997159958\n",
      "Epoch 2718, Loss: 0.5896168202161789, Final Batch Loss: 0.22743776440620422\n",
      "Epoch 2719, Loss: 0.617221012711525, Final Batch Loss: 0.22685274481773376\n",
      "Epoch 2720, Loss: 0.5742538571357727, Final Batch Loss: 0.27034738659858704\n",
      "Epoch 2721, Loss: 0.5707119703292847, Final Batch Loss: 0.27903226017951965\n",
      "Epoch 2722, Loss: 0.516893282532692, Final Batch Loss: 0.16151443123817444\n",
      "Epoch 2723, Loss: 0.6119767874479294, Final Batch Loss: 0.2681794762611389\n",
      "Epoch 2724, Loss: 0.5645264685153961, Final Batch Loss: 0.135343536734581\n",
      "Epoch 2725, Loss: 0.41168733686208725, Final Batch Loss: 0.0922384187579155\n",
      "Epoch 2726, Loss: 0.5247812420129776, Final Batch Loss: 0.15420107543468475\n",
      "Epoch 2727, Loss: 0.5250967144966125, Final Batch Loss: 0.14489078521728516\n",
      "Epoch 2728, Loss: 0.5024443715810776, Final Batch Loss: 0.11003337800502777\n",
      "Epoch 2729, Loss: 0.5322508364915848, Final Batch Loss: 0.15335030853748322\n",
      "Epoch 2730, Loss: 0.573612242937088, Final Batch Loss: 0.15439210832118988\n",
      "Epoch 2731, Loss: 0.657346099615097, Final Batch Loss: 0.2254199981689453\n",
      "Epoch 2732, Loss: 0.62511345744133, Final Batch Loss: 0.20697185397148132\n",
      "Epoch 2733, Loss: 0.5753283947706223, Final Batch Loss: 0.20019122958183289\n",
      "Epoch 2734, Loss: 0.5393102765083313, Final Batch Loss: 0.17329220473766327\n",
      "Epoch 2735, Loss: 0.5898160636425018, Final Batch Loss: 0.18825960159301758\n",
      "Epoch 2736, Loss: 0.5286382287740707, Final Batch Loss: 0.156675323843956\n",
      "Epoch 2737, Loss: 0.4859858900308609, Final Batch Loss: 0.21126316487789154\n",
      "Epoch 2738, Loss: 0.5584637671709061, Final Batch Loss: 0.15212279558181763\n",
      "Epoch 2739, Loss: 0.5808891206979752, Final Batch Loss: 0.20797908306121826\n",
      "Epoch 2740, Loss: 0.41043396294116974, Final Batch Loss: 0.13661423325538635\n",
      "Epoch 2741, Loss: 0.5335907638072968, Final Batch Loss: 0.14385464787483215\n",
      "Epoch 2742, Loss: 0.3964305967092514, Final Batch Loss: 0.08241128921508789\n",
      "Epoch 2743, Loss: 0.49399901926517487, Final Batch Loss: 0.18303219974040985\n",
      "Epoch 2744, Loss: 0.5670276433229446, Final Batch Loss: 0.1527409851551056\n",
      "Epoch 2745, Loss: 0.4609718918800354, Final Batch Loss: 0.1195562481880188\n",
      "Epoch 2746, Loss: 0.6060073524713516, Final Batch Loss: 0.20946714282035828\n",
      "Epoch 2747, Loss: 0.5123689696192741, Final Batch Loss: 0.22327454388141632\n",
      "Epoch 2748, Loss: 0.5037424266338348, Final Batch Loss: 0.17828617990016937\n",
      "Epoch 2749, Loss: 0.4511015862226486, Final Batch Loss: 0.14096936583518982\n",
      "Epoch 2750, Loss: 0.5490948408842087, Final Batch Loss: 0.15868093073368073\n",
      "Epoch 2751, Loss: 0.5194206535816193, Final Batch Loss: 0.12427592277526855\n",
      "Epoch 2752, Loss: 0.5725358799099922, Final Batch Loss: 0.27058145403862\n",
      "Epoch 2753, Loss: 0.48848047852516174, Final Batch Loss: 0.14099182188510895\n",
      "Epoch 2754, Loss: 0.6019646972417831, Final Batch Loss: 0.23316796123981476\n",
      "Epoch 2755, Loss: 0.46059294044971466, Final Batch Loss: 0.15062962472438812\n",
      "Epoch 2756, Loss: 0.5339178740978241, Final Batch Loss: 0.19384357333183289\n",
      "Epoch 2757, Loss: 0.6606157273054123, Final Batch Loss: 0.29429948329925537\n",
      "Epoch 2758, Loss: 0.5773882418870926, Final Batch Loss: 0.21689356863498688\n",
      "Epoch 2759, Loss: 0.5409002602100372, Final Batch Loss: 0.17027005553245544\n",
      "Epoch 2760, Loss: 0.5546395778656006, Final Batch Loss: 0.1310853213071823\n",
      "Epoch 2761, Loss: 0.48206405341625214, Final Batch Loss: 0.19800443947315216\n",
      "Epoch 2762, Loss: 0.6558390706777573, Final Batch Loss: 0.20115627348423004\n",
      "Epoch 2763, Loss: 0.6626008749008179, Final Batch Loss: 0.28235653042793274\n",
      "Epoch 2764, Loss: 0.7301144003868103, Final Batch Loss: 0.30013173818588257\n",
      "Epoch 2765, Loss: 0.5659662634134293, Final Batch Loss: 0.23058077692985535\n",
      "Epoch 2766, Loss: 0.5542429685592651, Final Batch Loss: 0.19821518659591675\n",
      "Epoch 2767, Loss: 0.6373834908008575, Final Batch Loss: 0.2328871637582779\n",
      "Epoch 2768, Loss: 0.5451417565345764, Final Batch Loss: 0.19235405325889587\n",
      "Epoch 2769, Loss: 0.6051270514726639, Final Batch Loss: 0.22582589089870453\n",
      "Epoch 2770, Loss: 0.5489662438631058, Final Batch Loss: 0.10922738909721375\n",
      "Epoch 2771, Loss: 0.6556309461593628, Final Batch Loss: 0.2480946034193039\n",
      "Epoch 2772, Loss: 0.6523681432008743, Final Batch Loss: 0.15210126340389252\n",
      "Epoch 2773, Loss: 0.6015518605709076, Final Batch Loss: 0.21873323619365692\n",
      "Epoch 2774, Loss: 0.5774673670530319, Final Batch Loss: 0.22040283679962158\n",
      "Epoch 2775, Loss: 0.585068553686142, Final Batch Loss: 0.23091503977775574\n",
      "Epoch 2776, Loss: 0.5748305022716522, Final Batch Loss: 0.20694148540496826\n",
      "Epoch 2777, Loss: 0.4938940405845642, Final Batch Loss: 0.10293073952198029\n",
      "Epoch 2778, Loss: 0.5189303308725357, Final Batch Loss: 0.19721995294094086\n",
      "Epoch 2779, Loss: 0.6845838129520416, Final Batch Loss: 0.1803639829158783\n",
      "Epoch 2780, Loss: 0.5770307034254074, Final Batch Loss: 0.20567911863327026\n",
      "Epoch 2781, Loss: 0.5378758907318115, Final Batch Loss: 0.157826229929924\n",
      "Epoch 2782, Loss: 0.5178629457950592, Final Batch Loss: 0.1486516147851944\n",
      "Epoch 2783, Loss: 0.5269085764884949, Final Batch Loss: 0.15905648469924927\n",
      "Epoch 2784, Loss: 0.6083039194345474, Final Batch Loss: 0.2198568880558014\n",
      "Epoch 2785, Loss: 0.517888143658638, Final Batch Loss: 0.13091318309307098\n",
      "Epoch 2786, Loss: 0.6319612264633179, Final Batch Loss: 0.2640402019023895\n",
      "Epoch 2787, Loss: 0.4826032817363739, Final Batch Loss: 0.1492331176996231\n",
      "Epoch 2788, Loss: 0.5717057287693024, Final Batch Loss: 0.19962501525878906\n",
      "Epoch 2789, Loss: 0.5564379692077637, Final Batch Loss: 0.18121156096458435\n",
      "Epoch 2790, Loss: 0.5010595321655273, Final Batch Loss: 0.1767202764749527\n",
      "Epoch 2791, Loss: 0.5308823585510254, Final Batch Loss: 0.16065649688243866\n",
      "Epoch 2792, Loss: 0.6130959689617157, Final Batch Loss: 0.15530681610107422\n",
      "Epoch 2793, Loss: 0.4787339121103287, Final Batch Loss: 0.13814082741737366\n",
      "Epoch 2794, Loss: 0.5569414496421814, Final Batch Loss: 0.19283637404441833\n",
      "Epoch 2795, Loss: 0.5077255219221115, Final Batch Loss: 0.191494882106781\n",
      "Epoch 2796, Loss: 0.5969304591417313, Final Batch Loss: 0.14671358466148376\n",
      "Epoch 2797, Loss: 0.5135059878230095, Final Batch Loss: 0.2266102284193039\n",
      "Epoch 2798, Loss: 0.4520474374294281, Final Batch Loss: 0.15464571118354797\n",
      "Epoch 2799, Loss: 0.5872202813625336, Final Batch Loss: 0.23534119129180908\n",
      "Epoch 2800, Loss: 0.5747719556093216, Final Batch Loss: 0.15021175146102905\n",
      "Epoch 2801, Loss: 0.5815945714712143, Final Batch Loss: 0.1369364708662033\n",
      "Epoch 2802, Loss: 0.5638421922922134, Final Batch Loss: 0.18856588006019592\n",
      "Epoch 2803, Loss: 0.4851951599121094, Final Batch Loss: 0.158255472779274\n",
      "Epoch 2804, Loss: 0.4877820760011673, Final Batch Loss: 0.19514288008213043\n",
      "Epoch 2805, Loss: 0.6433402299880981, Final Batch Loss: 0.21412190794944763\n",
      "Epoch 2806, Loss: 0.5088213235139847, Final Batch Loss: 0.13952526450157166\n",
      "Epoch 2807, Loss: 0.5030094534158707, Final Batch Loss: 0.2097083479166031\n",
      "Epoch 2808, Loss: 0.48415030539035797, Final Batch Loss: 0.14126290380954742\n",
      "Epoch 2809, Loss: 0.6101437211036682, Final Batch Loss: 0.1406991332769394\n",
      "Epoch 2810, Loss: 0.47708502411842346, Final Batch Loss: 0.12671124935150146\n",
      "Epoch 2811, Loss: 0.5556423515081406, Final Batch Loss: 0.18925772607326508\n",
      "Epoch 2812, Loss: 0.5686722546815872, Final Batch Loss: 0.1310923844575882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2813, Loss: 0.6093851923942566, Final Batch Loss: 0.25599342584609985\n",
      "Epoch 2814, Loss: 0.391519658267498, Final Batch Loss: 0.0966939702630043\n",
      "Epoch 2815, Loss: 0.4833996742963791, Final Batch Loss: 0.16601811349391937\n",
      "Epoch 2816, Loss: 0.5144679769873619, Final Batch Loss: 0.12255076318979263\n",
      "Epoch 2817, Loss: 0.5433647930622101, Final Batch Loss: 0.17681221663951874\n",
      "Epoch 2818, Loss: 0.6152237504720688, Final Batch Loss: 0.20466989278793335\n",
      "Epoch 2819, Loss: 0.4036242738366127, Final Batch Loss: 0.11525655537843704\n",
      "Epoch 2820, Loss: 0.5237710922956467, Final Batch Loss: 0.15431688725948334\n",
      "Epoch 2821, Loss: 0.49012812227010727, Final Batch Loss: 0.12103135138750076\n",
      "Epoch 2822, Loss: 0.4749934524297714, Final Batch Loss: 0.1935853511095047\n",
      "Epoch 2823, Loss: 0.6235352754592896, Final Batch Loss: 0.2174026370048523\n",
      "Epoch 2824, Loss: 0.5687540397047997, Final Batch Loss: 0.2700430452823639\n",
      "Epoch 2825, Loss: 0.6406866759061813, Final Batch Loss: 0.26599767804145813\n",
      "Epoch 2826, Loss: 0.6588700115680695, Final Batch Loss: 0.24386641383171082\n",
      "Epoch 2827, Loss: 0.5097304880619049, Final Batch Loss: 0.1651189774274826\n",
      "Epoch 2828, Loss: 0.5140066742897034, Final Batch Loss: 0.1937931478023529\n",
      "Epoch 2829, Loss: 0.5040835589170456, Final Batch Loss: 0.14892642199993134\n",
      "Epoch 2830, Loss: 0.5452658385038376, Final Batch Loss: 0.15914121270179749\n",
      "Epoch 2831, Loss: 0.5223362147808075, Final Batch Loss: 0.18039843440055847\n",
      "Epoch 2832, Loss: 0.5152880102396011, Final Batch Loss: 0.19437961280345917\n",
      "Epoch 2833, Loss: 0.6221137195825577, Final Batch Loss: 0.2334793657064438\n",
      "Epoch 2834, Loss: 0.591074526309967, Final Batch Loss: 0.18337631225585938\n",
      "Epoch 2835, Loss: 0.5036488026380539, Final Batch Loss: 0.18279023468494415\n",
      "Epoch 2836, Loss: 0.5009618625044823, Final Batch Loss: 0.10830951482057571\n",
      "Epoch 2837, Loss: 0.56594218313694, Final Batch Loss: 0.15382488071918488\n",
      "Epoch 2838, Loss: 0.6329231560230255, Final Batch Loss: 0.1654602736234665\n",
      "Epoch 2839, Loss: 0.5234535336494446, Final Batch Loss: 0.13477355241775513\n",
      "Epoch 2840, Loss: 0.6116902977228165, Final Batch Loss: 0.2902417480945587\n",
      "Epoch 2841, Loss: 0.5065589547157288, Final Batch Loss: 0.14037536084651947\n",
      "Epoch 2842, Loss: 0.5002250671386719, Final Batch Loss: 0.1370054930448532\n",
      "Epoch 2843, Loss: 0.5117157399654388, Final Batch Loss: 0.17760741710662842\n",
      "Epoch 2844, Loss: 0.48445945978164673, Final Batch Loss: 0.16006620228290558\n",
      "Epoch 2845, Loss: 0.553720012307167, Final Batch Loss: 0.2246745377779007\n",
      "Epoch 2846, Loss: 0.5254056006669998, Final Batch Loss: 0.19262783229351044\n",
      "Epoch 2847, Loss: 0.4629395455121994, Final Batch Loss: 0.13503238558769226\n",
      "Epoch 2848, Loss: 0.4872477799654007, Final Batch Loss: 0.1404460370540619\n",
      "Epoch 2849, Loss: 0.6730404645204544, Final Batch Loss: 0.2648929953575134\n",
      "Epoch 2850, Loss: 0.6430105865001678, Final Batch Loss: 0.2396160066127777\n",
      "Epoch 2851, Loss: 0.5613099634647369, Final Batch Loss: 0.17700599133968353\n",
      "Epoch 2852, Loss: 0.5545655488967896, Final Batch Loss: 0.17857955396175385\n",
      "Epoch 2853, Loss: 0.5210260152816772, Final Batch Loss: 0.1679368019104004\n",
      "Epoch 2854, Loss: 0.548628181219101, Final Batch Loss: 0.2053416669368744\n",
      "Epoch 2855, Loss: 0.5602431148290634, Final Batch Loss: 0.19263561069965363\n",
      "Epoch 2856, Loss: 0.5011653751134872, Final Batch Loss: 0.15636120736598969\n",
      "Epoch 2857, Loss: 0.4828380197286606, Final Batch Loss: 0.12941676378250122\n",
      "Epoch 2858, Loss: 0.6132223457098007, Final Batch Loss: 0.20794254541397095\n",
      "Epoch 2859, Loss: 0.5281958281993866, Final Batch Loss: 0.13034093379974365\n",
      "Epoch 2860, Loss: 0.5452970713376999, Final Batch Loss: 0.18644259870052338\n",
      "Epoch 2861, Loss: 0.5535300225019455, Final Batch Loss: 0.19338618218898773\n",
      "Epoch 2862, Loss: 0.5190823525190353, Final Batch Loss: 0.15865342319011688\n",
      "Epoch 2863, Loss: 0.5687529891729355, Final Batch Loss: 0.21765059232711792\n",
      "Epoch 2864, Loss: 0.48967400193214417, Final Batch Loss: 0.1539858728647232\n",
      "Epoch 2865, Loss: 0.6612945795059204, Final Batch Loss: 0.20155735313892365\n",
      "Epoch 2866, Loss: 0.5472634732723236, Final Batch Loss: 0.16655419766902924\n",
      "Epoch 2867, Loss: 0.5452557355165482, Final Batch Loss: 0.1659320890903473\n",
      "Epoch 2868, Loss: 0.41794241964817047, Final Batch Loss: 0.11849363148212433\n",
      "Epoch 2869, Loss: 0.5161010921001434, Final Batch Loss: 0.19909191131591797\n",
      "Epoch 2870, Loss: 0.5654363483190536, Final Batch Loss: 0.1338064819574356\n",
      "Epoch 2871, Loss: 0.5074623078107834, Final Batch Loss: 0.15004044771194458\n",
      "Epoch 2872, Loss: 0.506547600030899, Final Batch Loss: 0.13903144001960754\n",
      "Epoch 2873, Loss: 0.5266060084104538, Final Batch Loss: 0.18714949488639832\n",
      "Epoch 2874, Loss: 0.49416735768318176, Final Batch Loss: 0.2105768322944641\n",
      "Epoch 2875, Loss: 0.47226712107658386, Final Batch Loss: 0.17304149270057678\n",
      "Epoch 2876, Loss: 0.7035797536373138, Final Batch Loss: 0.2965560257434845\n",
      "Epoch 2877, Loss: 0.5992352813482285, Final Batch Loss: 0.20477934181690216\n",
      "Epoch 2878, Loss: 0.6312186568975449, Final Batch Loss: 0.18668308854103088\n",
      "Epoch 2879, Loss: 0.6233204305171967, Final Batch Loss: 0.21054033935070038\n",
      "Epoch 2880, Loss: 0.4721909388899803, Final Batch Loss: 0.122675321996212\n",
      "Epoch 2881, Loss: 0.5330458581447601, Final Batch Loss: 0.19604405760765076\n",
      "Epoch 2882, Loss: 0.494117796421051, Final Batch Loss: 0.15663671493530273\n",
      "Epoch 2883, Loss: 0.6268186271190643, Final Batch Loss: 0.34157729148864746\n",
      "Epoch 2884, Loss: 0.5337454080581665, Final Batch Loss: 0.16336765885353088\n",
      "Epoch 2885, Loss: 0.488716721534729, Final Batch Loss: 0.15935471653938293\n",
      "Epoch 2886, Loss: 0.5929486155509949, Final Batch Loss: 0.17689158022403717\n",
      "Epoch 2887, Loss: 0.6014631390571594, Final Batch Loss: 0.21614305675029755\n",
      "Epoch 2888, Loss: 0.6191420257091522, Final Batch Loss: 0.1924324780702591\n",
      "Epoch 2889, Loss: 0.6254052817821503, Final Batch Loss: 0.22294342517852783\n",
      "Epoch 2890, Loss: 0.7122352421283722, Final Batch Loss: 0.17254984378814697\n",
      "Epoch 2891, Loss: 0.4583472013473511, Final Batch Loss: 0.1374015361070633\n",
      "Epoch 2892, Loss: 0.5726897567510605, Final Batch Loss: 0.16743530333042145\n",
      "Epoch 2893, Loss: 0.47861362993717194, Final Batch Loss: 0.15390513837337494\n",
      "Epoch 2894, Loss: 0.5271635502576828, Final Batch Loss: 0.19753895699977875\n",
      "Epoch 2895, Loss: 0.6466189622879028, Final Batch Loss: 0.2416081577539444\n",
      "Epoch 2896, Loss: 0.5408383756875992, Final Batch Loss: 0.16419868171215057\n",
      "Epoch 2897, Loss: 0.5433397144079208, Final Batch Loss: 0.19527693092823029\n",
      "Epoch 2898, Loss: 0.5017739534378052, Final Batch Loss: 0.1831170618534088\n",
      "Epoch 2899, Loss: 0.5586877763271332, Final Batch Loss: 0.1836034059524536\n",
      "Epoch 2900, Loss: 0.48164886981248856, Final Batch Loss: 0.14194397628307343\n",
      "Epoch 2901, Loss: 0.5222651362419128, Final Batch Loss: 0.17170117795467377\n",
      "Epoch 2902, Loss: 0.4946073144674301, Final Batch Loss: 0.12303739786148071\n",
      "Epoch 2903, Loss: 0.5007195472717285, Final Batch Loss: 0.19975009560585022\n",
      "Epoch 2904, Loss: 0.48744484782218933, Final Batch Loss: 0.15800972282886505\n",
      "Epoch 2905, Loss: 0.6485782265663147, Final Batch Loss: 0.2090756744146347\n",
      "Epoch 2906, Loss: 0.501647986471653, Final Batch Loss: 0.11969516426324844\n",
      "Epoch 2907, Loss: 0.4912782683968544, Final Batch Loss: 0.11611097306013107\n",
      "Epoch 2908, Loss: 0.39024508744478226, Final Batch Loss: 0.10951419919729233\n",
      "Epoch 2909, Loss: 0.4718590974807739, Final Batch Loss: 0.11380834877490997\n",
      "Epoch 2910, Loss: 0.49701112508773804, Final Batch Loss: 0.1783025562763214\n",
      "Epoch 2911, Loss: 0.4637291878461838, Final Batch Loss: 0.1534128487110138\n",
      "Epoch 2912, Loss: 0.4805368483066559, Final Batch Loss: 0.16538013517856598\n",
      "Epoch 2913, Loss: 0.4717547446489334, Final Batch Loss: 0.17367297410964966\n",
      "Epoch 2914, Loss: 0.49302932620048523, Final Batch Loss: 0.1993744969367981\n",
      "Epoch 2915, Loss: 0.4986424893140793, Final Batch Loss: 0.20385800302028656\n",
      "Epoch 2916, Loss: 0.5714020431041718, Final Batch Loss: 0.18774956464767456\n",
      "Epoch 2917, Loss: 0.5706419795751572, Final Batch Loss: 0.23035219311714172\n",
      "Epoch 2918, Loss: 0.438744455575943, Final Batch Loss: 0.17039640247821808\n",
      "Epoch 2919, Loss: 0.595639169216156, Final Batch Loss: 0.13215036690235138\n",
      "Epoch 2920, Loss: 0.5462915003299713, Final Batch Loss: 0.14339637756347656\n",
      "Epoch 2921, Loss: 0.4739227220416069, Final Batch Loss: 0.11227100342512131\n",
      "Epoch 2922, Loss: 0.5146090090274811, Final Batch Loss: 0.15862949192523956\n",
      "Epoch 2923, Loss: 0.43777427822351456, Final Batch Loss: 0.12185803055763245\n",
      "Epoch 2924, Loss: 0.6702799201011658, Final Batch Loss: 0.19844605028629303\n",
      "Epoch 2925, Loss: 0.5974406003952026, Final Batch Loss: 0.23552943766117096\n",
      "Epoch 2926, Loss: 0.49830180406570435, Final Batch Loss: 0.15920723974704742\n",
      "Epoch 2927, Loss: 0.5206103324890137, Final Batch Loss: 0.16536252200603485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2928, Loss: 0.5081174373626709, Final Batch Loss: 0.2210431843996048\n",
      "Epoch 2929, Loss: 0.44401179254055023, Final Batch Loss: 0.14239507913589478\n",
      "Epoch 2930, Loss: 0.47421491146087646, Final Batch Loss: 0.15245065093040466\n",
      "Epoch 2931, Loss: 0.6574656516313553, Final Batch Loss: 0.24005870521068573\n",
      "Epoch 2932, Loss: 0.5385139882564545, Final Batch Loss: 0.16098707914352417\n",
      "Epoch 2933, Loss: 0.5087628066539764, Final Batch Loss: 0.17007319629192352\n",
      "Epoch 2934, Loss: 0.6033108532428741, Final Batch Loss: 0.19179020822048187\n",
      "Epoch 2935, Loss: 0.5959562957286835, Final Batch Loss: 0.2982325255870819\n",
      "Epoch 2936, Loss: 0.6139916181564331, Final Batch Loss: 0.23577019572257996\n",
      "Epoch 2937, Loss: 0.5672067254781723, Final Batch Loss: 0.16024035215377808\n",
      "Epoch 2938, Loss: 0.541127547621727, Final Batch Loss: 0.15917503833770752\n",
      "Epoch 2939, Loss: 0.5935399979352951, Final Batch Loss: 0.15924254059791565\n",
      "Epoch 2940, Loss: 0.5776742100715637, Final Batch Loss: 0.1686764657497406\n",
      "Epoch 2941, Loss: 0.5116540044546127, Final Batch Loss: 0.14925536513328552\n",
      "Epoch 2942, Loss: 0.6286648437380791, Final Batch Loss: 0.20596100389957428\n",
      "Epoch 2943, Loss: 0.6913624852895737, Final Batch Loss: 0.2815794050693512\n",
      "Epoch 2944, Loss: 0.5305818170309067, Final Batch Loss: 0.22092576324939728\n",
      "Epoch 2945, Loss: 0.4318125620484352, Final Batch Loss: 0.1115482822060585\n",
      "Epoch 2946, Loss: 0.4946816861629486, Final Batch Loss: 0.1476566642522812\n",
      "Epoch 2947, Loss: 0.5720194876194, Final Batch Loss: 0.19529485702514648\n",
      "Epoch 2948, Loss: 0.6270595043897629, Final Batch Loss: 0.236001655459404\n",
      "Epoch 2949, Loss: 0.5653218030929565, Final Batch Loss: 0.23007585108280182\n",
      "Epoch 2950, Loss: 0.5238318294286728, Final Batch Loss: 0.1998082399368286\n",
      "Epoch 2951, Loss: 0.4795146882534027, Final Batch Loss: 0.1295670121908188\n",
      "Epoch 2952, Loss: 0.5590689033269882, Final Batch Loss: 0.1846940815448761\n",
      "Epoch 2953, Loss: 0.49981825053691864, Final Batch Loss: 0.15303857624530792\n",
      "Epoch 2954, Loss: 0.508489191532135, Final Batch Loss: 0.1576802134513855\n",
      "Epoch 2955, Loss: 0.5533752292394638, Final Batch Loss: 0.19624195992946625\n",
      "Epoch 2956, Loss: 0.6235271394252777, Final Batch Loss: 0.2625335156917572\n",
      "Epoch 2957, Loss: 0.5394847989082336, Final Batch Loss: 0.23964868485927582\n",
      "Epoch 2958, Loss: 0.5660632103681564, Final Batch Loss: 0.17188791930675507\n",
      "Epoch 2959, Loss: 0.5539457499980927, Final Batch Loss: 0.19007310271263123\n",
      "Epoch 2960, Loss: 0.5121697336435318, Final Batch Loss: 0.15863557159900665\n",
      "Epoch 2961, Loss: 0.4663725942373276, Final Batch Loss: 0.1055985540151596\n",
      "Epoch 2962, Loss: 0.46258384734392166, Final Batch Loss: 0.12220903486013412\n",
      "Epoch 2963, Loss: 0.4460214748978615, Final Batch Loss: 0.11537838727235794\n",
      "Epoch 2964, Loss: 0.5207995697855949, Final Batch Loss: 0.1674536168575287\n",
      "Epoch 2965, Loss: 0.5405784547328949, Final Batch Loss: 0.17035335302352905\n",
      "Epoch 2966, Loss: 0.5486291795969009, Final Batch Loss: 0.17611362040042877\n",
      "Epoch 2967, Loss: 0.5716862380504608, Final Batch Loss: 0.24831967055797577\n",
      "Epoch 2968, Loss: 0.4283490478992462, Final Batch Loss: 0.15035326778888702\n",
      "Epoch 2969, Loss: 0.433116190135479, Final Batch Loss: 0.10795146971940994\n",
      "Epoch 2970, Loss: 0.5345662087202072, Final Batch Loss: 0.1828804314136505\n",
      "Epoch 2971, Loss: 0.508382573723793, Final Batch Loss: 0.2085818648338318\n",
      "Epoch 2972, Loss: 0.5663737654685974, Final Batch Loss: 0.17559604346752167\n",
      "Epoch 2973, Loss: 0.434603676199913, Final Batch Loss: 0.16337478160858154\n",
      "Epoch 2974, Loss: 0.5648135989904404, Final Batch Loss: 0.18079130351543427\n",
      "Epoch 2975, Loss: 0.5106696635484695, Final Batch Loss: 0.15892581641674042\n",
      "Epoch 2976, Loss: 0.5347952395677567, Final Batch Loss: 0.15823377668857574\n",
      "Epoch 2977, Loss: 0.4969489723443985, Final Batch Loss: 0.19946368038654327\n",
      "Epoch 2978, Loss: 0.6132524609565735, Final Batch Loss: 0.20335474610328674\n",
      "Epoch 2979, Loss: 0.41717322915792465, Final Batch Loss: 0.11825106292963028\n",
      "Epoch 2980, Loss: 0.42678985744714737, Final Batch Loss: 0.11145775765180588\n",
      "Epoch 2981, Loss: 0.5684092044830322, Final Batch Loss: 0.22645078599452972\n",
      "Epoch 2982, Loss: 0.4922045171260834, Final Batch Loss: 0.12619826197624207\n",
      "Epoch 2983, Loss: 0.5836375057697296, Final Batch Loss: 0.18179908394813538\n",
      "Epoch 2984, Loss: 0.570509746670723, Final Batch Loss: 0.21178439259529114\n",
      "Epoch 2985, Loss: 0.48163415491580963, Final Batch Loss: 0.19795319437980652\n",
      "Epoch 2986, Loss: 0.5312027782201767, Final Batch Loss: 0.19547955691814423\n",
      "Epoch 2987, Loss: 0.4453916698694229, Final Batch Loss: 0.14259041845798492\n",
      "Epoch 2988, Loss: 0.4559248387813568, Final Batch Loss: 0.15387815237045288\n",
      "Epoch 2989, Loss: 0.5796118527650833, Final Batch Loss: 0.26133280992507935\n",
      "Epoch 2990, Loss: 0.5530139654874802, Final Batch Loss: 0.17440447211265564\n",
      "Epoch 2991, Loss: 0.6228399127721786, Final Batch Loss: 0.2507745623588562\n",
      "Epoch 2992, Loss: 0.5095602571964264, Final Batch Loss: 0.168559730052948\n",
      "Epoch 2993, Loss: 0.5470425188541412, Final Batch Loss: 0.1545332670211792\n",
      "Epoch 2994, Loss: 0.6216811984777451, Final Batch Loss: 0.2987709045410156\n",
      "Epoch 2995, Loss: 0.5533951967954636, Final Batch Loss: 0.195138081908226\n",
      "Epoch 2996, Loss: 0.4422130435705185, Final Batch Loss: 0.14095549285411835\n",
      "Epoch 2997, Loss: 0.48856594413518906, Final Batch Loss: 0.18376383185386658\n",
      "Epoch 2998, Loss: 0.46555623412132263, Final Batch Loss: 0.1759541928768158\n",
      "Epoch 2999, Loss: 0.5862441658973694, Final Batch Loss: 0.2317345291376114\n",
      "Epoch 3000, Loss: 0.5699622482061386, Final Batch Loss: 0.23246341943740845\n",
      "Epoch 3001, Loss: 0.5577806681394577, Final Batch Loss: 0.16798362135887146\n",
      "Epoch 3002, Loss: 0.4856870174407959, Final Batch Loss: 0.17104052007198334\n",
      "Epoch 3003, Loss: 0.4857977405190468, Final Batch Loss: 0.1490219235420227\n",
      "Epoch 3004, Loss: 0.6534765362739563, Final Batch Loss: 0.21808451414108276\n",
      "Epoch 3005, Loss: 0.6200342029333115, Final Batch Loss: 0.1747051179409027\n",
      "Epoch 3006, Loss: 0.5155178606510162, Final Batch Loss: 0.16781826317310333\n",
      "Epoch 3007, Loss: 0.560459554195404, Final Batch Loss: 0.15824012458324432\n",
      "Epoch 3008, Loss: 0.4851919263601303, Final Batch Loss: 0.18639305233955383\n",
      "Epoch 3009, Loss: 0.6328860074281693, Final Batch Loss: 0.15686573088169098\n",
      "Epoch 3010, Loss: 0.5053726136684418, Final Batch Loss: 0.16723573207855225\n",
      "Epoch 3011, Loss: 0.592206746339798, Final Batch Loss: 0.17372018098831177\n",
      "Epoch 3012, Loss: 0.5584488809108734, Final Batch Loss: 0.13379275798797607\n",
      "Epoch 3013, Loss: 0.5341244786977768, Final Batch Loss: 0.1014426201581955\n",
      "Epoch 3014, Loss: 0.6003894507884979, Final Batch Loss: 0.21324405074119568\n",
      "Epoch 3015, Loss: 0.5232809409499168, Final Batch Loss: 0.11030507832765579\n",
      "Epoch 3016, Loss: 0.4824633151292801, Final Batch Loss: 0.11559399962425232\n",
      "Epoch 3017, Loss: 0.5432369858026505, Final Batch Loss: 0.19821777939796448\n",
      "Epoch 3018, Loss: 0.5535658746957779, Final Batch Loss: 0.1524709165096283\n",
      "Epoch 3019, Loss: 0.4536712095141411, Final Batch Loss: 0.14958295226097107\n",
      "Epoch 3020, Loss: 0.6267007440328598, Final Batch Loss: 0.21997477114200592\n",
      "Epoch 3021, Loss: 0.5084733068943024, Final Batch Loss: 0.13349004089832306\n",
      "Epoch 3022, Loss: 0.624271422624588, Final Batch Loss: 0.24474531412124634\n",
      "Epoch 3023, Loss: 0.5186541378498077, Final Batch Loss: 0.14567473530769348\n",
      "Epoch 3024, Loss: 0.4801644831895828, Final Batch Loss: 0.18006163835525513\n",
      "Epoch 3025, Loss: 0.5167151093482971, Final Batch Loss: 0.15374605357646942\n",
      "Epoch 3026, Loss: 0.49590225517749786, Final Batch Loss: 0.1721910983324051\n",
      "Epoch 3027, Loss: 0.5556866228580475, Final Batch Loss: 0.2164974808692932\n",
      "Epoch 3028, Loss: 0.471261128783226, Final Batch Loss: 0.20318950712680817\n",
      "Epoch 3029, Loss: 0.5365380793809891, Final Batch Loss: 0.17601926624774933\n",
      "Epoch 3030, Loss: 0.5317670553922653, Final Batch Loss: 0.1364690214395523\n",
      "Epoch 3031, Loss: 0.5354226380586624, Final Batch Loss: 0.1836337298154831\n",
      "Epoch 3032, Loss: 0.46967361867427826, Final Batch Loss: 0.13739502429962158\n",
      "Epoch 3033, Loss: 0.49267420172691345, Final Batch Loss: 0.1602993607521057\n",
      "Epoch 3034, Loss: 0.4657253324985504, Final Batch Loss: 0.14541397988796234\n",
      "Epoch 3035, Loss: 0.5001707375049591, Final Batch Loss: 0.14675427973270416\n",
      "Epoch 3036, Loss: 0.6382260918617249, Final Batch Loss: 0.24047456681728363\n",
      "Epoch 3037, Loss: 0.5015904009342194, Final Batch Loss: 0.18055611848831177\n",
      "Epoch 3038, Loss: 0.5126778930425644, Final Batch Loss: 0.16830165684223175\n",
      "Epoch 3039, Loss: 0.5137044042348862, Final Batch Loss: 0.18778620660305023\n",
      "Epoch 3040, Loss: 0.5439475625753403, Final Batch Loss: 0.18883667886257172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3041, Loss: 0.4723222851753235, Final Batch Loss: 0.18477295339107513\n",
      "Epoch 3042, Loss: 0.47886502742767334, Final Batch Loss: 0.15825004875659943\n",
      "Epoch 3043, Loss: 0.4934225007891655, Final Batch Loss: 0.09449663013219833\n",
      "Epoch 3044, Loss: 0.5190825834870338, Final Batch Loss: 0.1449340432882309\n",
      "Epoch 3045, Loss: 0.49148085713386536, Final Batch Loss: 0.10146071016788483\n",
      "Epoch 3046, Loss: 0.5221195071935654, Final Batch Loss: 0.1270398050546646\n",
      "Epoch 3047, Loss: 0.4594785273075104, Final Batch Loss: 0.12658779323101044\n",
      "Epoch 3048, Loss: 0.49082837253808975, Final Batch Loss: 0.19084694981575012\n",
      "Epoch 3049, Loss: 0.5557144731283188, Final Batch Loss: 0.21863093972206116\n",
      "Epoch 3050, Loss: 0.5666573494672775, Final Batch Loss: 0.21255134046077728\n",
      "Epoch 3051, Loss: 0.5192335471510887, Final Batch Loss: 0.2374643087387085\n",
      "Epoch 3052, Loss: 0.5105760991573334, Final Batch Loss: 0.14933720231056213\n",
      "Epoch 3053, Loss: 0.513149306178093, Final Batch Loss: 0.1430506855249405\n",
      "Epoch 3054, Loss: 0.47074897587299347, Final Batch Loss: 0.1455969363451004\n",
      "Epoch 3055, Loss: 0.4720653221011162, Final Batch Loss: 0.09849313646554947\n",
      "Epoch 3056, Loss: 0.5971893221139908, Final Batch Loss: 0.2721294164657593\n",
      "Epoch 3057, Loss: 0.4737003445625305, Final Batch Loss: 0.17913232743740082\n",
      "Epoch 3058, Loss: 0.5551082342863083, Final Batch Loss: 0.1415611356496811\n",
      "Epoch 3059, Loss: 0.5633979886770248, Final Batch Loss: 0.18825893104076385\n",
      "Epoch 3060, Loss: 0.6273552924394608, Final Batch Loss: 0.19366371631622314\n",
      "Epoch 3061, Loss: 0.595398023724556, Final Batch Loss: 0.2844774127006531\n",
      "Epoch 3062, Loss: 0.6004962027072906, Final Batch Loss: 0.2327519655227661\n",
      "Epoch 3063, Loss: 0.433221660554409, Final Batch Loss: 0.08065804094076157\n",
      "Epoch 3064, Loss: 0.4980250746011734, Final Batch Loss: 0.14395245909690857\n",
      "Epoch 3065, Loss: 0.5347149521112442, Final Batch Loss: 0.12219507992267609\n",
      "Epoch 3066, Loss: 0.62863390147686, Final Batch Loss: 0.20321409404277802\n",
      "Epoch 3067, Loss: 0.5723106265068054, Final Batch Loss: 0.22250954806804657\n",
      "Epoch 3068, Loss: 0.5229537934064865, Final Batch Loss: 0.14250430464744568\n",
      "Epoch 3069, Loss: 0.47856223583221436, Final Batch Loss: 0.11019416153430939\n",
      "Epoch 3070, Loss: 0.41659634560346603, Final Batch Loss: 0.08846206218004227\n",
      "Epoch 3071, Loss: 0.5272505134344101, Final Batch Loss: 0.1765439361333847\n",
      "Epoch 3072, Loss: 0.603123277425766, Final Batch Loss: 0.2566199004650116\n",
      "Epoch 3073, Loss: 0.6683474034070969, Final Batch Loss: 0.2527875006198883\n",
      "Epoch 3074, Loss: 0.55752794444561, Final Batch Loss: 0.15423060953617096\n",
      "Epoch 3075, Loss: 0.5304014384746552, Final Batch Loss: 0.14092256128787994\n",
      "Epoch 3076, Loss: 0.5712291151285172, Final Batch Loss: 0.22669026255607605\n",
      "Epoch 3077, Loss: 0.5925472378730774, Final Batch Loss: 0.16288606822490692\n",
      "Epoch 3078, Loss: 0.466046005487442, Final Batch Loss: 0.12289285659790039\n",
      "Epoch 3079, Loss: 0.46468813717365265, Final Batch Loss: 0.1448299139738083\n",
      "Epoch 3080, Loss: 0.5024234652519226, Final Batch Loss: 0.180796816945076\n",
      "Epoch 3081, Loss: 0.503139041364193, Final Batch Loss: 0.2237490713596344\n",
      "Epoch 3082, Loss: 0.43732667714357376, Final Batch Loss: 0.0830347016453743\n",
      "Epoch 3083, Loss: 0.4717266112565994, Final Batch Loss: 0.1446821242570877\n",
      "Epoch 3084, Loss: 0.4555266499519348, Final Batch Loss: 0.13233919441699982\n",
      "Epoch 3085, Loss: 0.4836977422237396, Final Batch Loss: 0.10173805058002472\n",
      "Epoch 3086, Loss: 0.44078968465328217, Final Batch Loss: 0.16537532210350037\n",
      "Epoch 3087, Loss: 0.5023394078016281, Final Batch Loss: 0.17553672194480896\n",
      "Epoch 3088, Loss: 0.4888610541820526, Final Batch Loss: 0.126084566116333\n",
      "Epoch 3089, Loss: 0.5035920888185501, Final Batch Loss: 0.26517611742019653\n",
      "Epoch 3090, Loss: 0.6291770786046982, Final Batch Loss: 0.22192595899105072\n",
      "Epoch 3091, Loss: 0.636417493224144, Final Batch Loss: 0.282010942697525\n",
      "Epoch 3092, Loss: 0.49139952659606934, Final Batch Loss: 0.13402406871318817\n",
      "Epoch 3093, Loss: 0.5686648488044739, Final Batch Loss: 0.16756829619407654\n",
      "Epoch 3094, Loss: 0.5464633405208588, Final Batch Loss: 0.16817504167556763\n",
      "Epoch 3095, Loss: 0.6073452085256577, Final Batch Loss: 0.2547055780887604\n",
      "Epoch 3096, Loss: 0.7107418030500412, Final Batch Loss: 0.3360227942466736\n",
      "Epoch 3097, Loss: 0.45810408145189285, Final Batch Loss: 0.10796701163053513\n",
      "Epoch 3098, Loss: 0.5195567905902863, Final Batch Loss: 0.14614237844944\n",
      "Epoch 3099, Loss: 0.543645054101944, Final Batch Loss: 0.15873108804225922\n",
      "Epoch 3100, Loss: 0.6350067704916, Final Batch Loss: 0.1995071917772293\n",
      "Epoch 3101, Loss: 0.4733303189277649, Final Batch Loss: 0.12944339215755463\n",
      "Epoch 3102, Loss: 0.5153652280569077, Final Batch Loss: 0.15688343346118927\n",
      "Epoch 3103, Loss: 0.5199475437402725, Final Batch Loss: 0.16873835027217865\n",
      "Epoch 3104, Loss: 0.5170774832367897, Final Batch Loss: 0.11668919771909714\n",
      "Epoch 3105, Loss: 0.5459408909082413, Final Batch Loss: 0.2013612687587738\n",
      "Epoch 3106, Loss: 0.5630021840333939, Final Batch Loss: 0.1766730695962906\n",
      "Epoch 3107, Loss: 0.5882172286510468, Final Batch Loss: 0.18611344695091248\n",
      "Epoch 3108, Loss: 0.6095646321773529, Final Batch Loss: 0.18637841939926147\n",
      "Epoch 3109, Loss: 0.6474904417991638, Final Batch Loss: 0.2573651671409607\n",
      "Epoch 3110, Loss: 0.5096426010131836, Final Batch Loss: 0.16338221728801727\n",
      "Epoch 3111, Loss: 0.3842754065990448, Final Batch Loss: 0.08582587540149689\n",
      "Epoch 3112, Loss: 0.5232146829366684, Final Batch Loss: 0.17404742538928986\n",
      "Epoch 3113, Loss: 0.5702678710222244, Final Batch Loss: 0.16171647608280182\n",
      "Epoch 3114, Loss: 0.5086009949445724, Final Batch Loss: 0.15033100545406342\n",
      "Epoch 3115, Loss: 0.5962594598531723, Final Batch Loss: 0.21047180891036987\n",
      "Epoch 3116, Loss: 0.5289300084114075, Final Batch Loss: 0.22118303179740906\n",
      "Epoch 3117, Loss: 0.5115157961845398, Final Batch Loss: 0.18029330670833588\n",
      "Epoch 3118, Loss: 0.6548138558864594, Final Batch Loss: 0.2830432653427124\n",
      "Epoch 3119, Loss: 0.5929404497146606, Final Batch Loss: 0.22974075376987457\n",
      "Epoch 3120, Loss: 0.5080633163452148, Final Batch Loss: 0.18913231790065765\n",
      "Epoch 3121, Loss: 0.520337387919426, Final Batch Loss: 0.18215613067150116\n",
      "Epoch 3122, Loss: 0.5267917811870575, Final Batch Loss: 0.11988720297813416\n",
      "Epoch 3123, Loss: 0.5466961562633514, Final Batch Loss: 0.22004741430282593\n",
      "Epoch 3124, Loss: 0.6073533296585083, Final Batch Loss: 0.17561611533164978\n",
      "Epoch 3125, Loss: 0.4889557212591171, Final Batch Loss: 0.13778580725193024\n",
      "Epoch 3126, Loss: 0.4559510052204132, Final Batch Loss: 0.10965576767921448\n",
      "Epoch 3127, Loss: 0.623917356133461, Final Batch Loss: 0.19226433336734772\n",
      "Epoch 3128, Loss: 0.5076866745948792, Final Batch Loss: 0.11650614440441132\n",
      "Epoch 3129, Loss: 0.49951576441526413, Final Batch Loss: 0.10521050542593002\n",
      "Epoch 3130, Loss: 0.5508344769477844, Final Batch Loss: 0.1332886517047882\n",
      "Epoch 3131, Loss: 0.5504624396562576, Final Batch Loss: 0.20897167921066284\n",
      "Epoch 3132, Loss: 0.5281974971294403, Final Batch Loss: 0.14476808905601501\n",
      "Epoch 3133, Loss: 0.545675665140152, Final Batch Loss: 0.20110705494880676\n",
      "Epoch 3134, Loss: 0.5352604389190674, Final Batch Loss: 0.1790904700756073\n",
      "Epoch 3135, Loss: 0.40769757330417633, Final Batch Loss: 0.160161092877388\n",
      "Epoch 3136, Loss: 0.49727514386177063, Final Batch Loss: 0.20265783369541168\n",
      "Epoch 3137, Loss: 0.4469204545021057, Final Batch Loss: 0.16262921690940857\n",
      "Epoch 3138, Loss: 0.49368102848529816, Final Batch Loss: 0.1312781572341919\n",
      "Epoch 3139, Loss: 0.519772119820118, Final Batch Loss: 0.12511028349399567\n",
      "Epoch 3140, Loss: 0.45367439091205597, Final Batch Loss: 0.1381799578666687\n",
      "Epoch 3141, Loss: 0.5035428330302238, Final Batch Loss: 0.12048300355672836\n",
      "Epoch 3142, Loss: 0.622227743268013, Final Batch Loss: 0.24301867187023163\n",
      "Epoch 3143, Loss: 0.48550187051296234, Final Batch Loss: 0.16796880960464478\n",
      "Epoch 3144, Loss: 0.446176677942276, Final Batch Loss: 0.14947661757469177\n",
      "Epoch 3145, Loss: 0.6126174330711365, Final Batch Loss: 0.15913106501102448\n",
      "Epoch 3146, Loss: 0.5056467354297638, Final Batch Loss: 0.16955207288265228\n",
      "Epoch 3147, Loss: 0.5186251923441887, Final Batch Loss: 0.19320206344127655\n",
      "Epoch 3148, Loss: 0.606564536690712, Final Batch Loss: 0.2342860996723175\n",
      "Epoch 3149, Loss: 0.4918723553419113, Final Batch Loss: 0.12701347470283508\n",
      "Epoch 3150, Loss: 0.57172691822052, Final Batch Loss: 0.10975527763366699\n",
      "Epoch 3151, Loss: 0.44511863589286804, Final Batch Loss: 0.13945069909095764\n",
      "Epoch 3152, Loss: 0.4580446928739548, Final Batch Loss: 0.11247174441814423\n",
      "Epoch 3153, Loss: 0.4219646230340004, Final Batch Loss: 0.1388111412525177\n",
      "Epoch 3154, Loss: 0.5120415836572647, Final Batch Loss: 0.1635608971118927\n",
      "Epoch 3155, Loss: 0.4694627821445465, Final Batch Loss: 0.18302269279956818\n",
      "Epoch 3156, Loss: 0.4713546857237816, Final Batch Loss: 0.1164952889084816\n",
      "Epoch 3157, Loss: 0.5160795897245407, Final Batch Loss: 0.25149601697921753\n",
      "Epoch 3158, Loss: 0.48436175286769867, Final Batch Loss: 0.1116500198841095\n",
      "Epoch 3159, Loss: 0.5658901035785675, Final Batch Loss: 0.2049611210823059\n",
      "Epoch 3160, Loss: 0.48534443229436874, Final Batch Loss: 0.1073278859257698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3161, Loss: 0.5093972086906433, Final Batch Loss: 0.18942728638648987\n",
      "Epoch 3162, Loss: 0.5937325954437256, Final Batch Loss: 0.29176220297813416\n",
      "Epoch 3163, Loss: 0.5452263355255127, Final Batch Loss: 0.20575399696826935\n",
      "Epoch 3164, Loss: 0.48527857661247253, Final Batch Loss: 0.14021532237529755\n",
      "Epoch 3165, Loss: 0.4982941597700119, Final Batch Loss: 0.2188214212656021\n",
      "Epoch 3166, Loss: 0.549016609787941, Final Batch Loss: 0.19350546598434448\n",
      "Epoch 3167, Loss: 0.46510832011699677, Final Batch Loss: 0.1452050805091858\n",
      "Epoch 3168, Loss: 0.53421451151371, Final Batch Loss: 0.21900752186775208\n",
      "Epoch 3169, Loss: 0.5820255130529404, Final Batch Loss: 0.19826066493988037\n",
      "Epoch 3170, Loss: 0.5048842132091522, Final Batch Loss: 0.1648527979850769\n",
      "Epoch 3171, Loss: 0.5174503773450851, Final Batch Loss: 0.1159401535987854\n",
      "Epoch 3172, Loss: 0.46140794456005096, Final Batch Loss: 0.14938391745090485\n",
      "Epoch 3173, Loss: 0.5160364210605621, Final Batch Loss: 0.1772255301475525\n",
      "Epoch 3174, Loss: 0.48003244400024414, Final Batch Loss: 0.1905045062303543\n",
      "Epoch 3175, Loss: 0.59048892557621, Final Batch Loss: 0.18828120827674866\n",
      "Epoch 3176, Loss: 0.47822849452495575, Final Batch Loss: 0.124958336353302\n",
      "Epoch 3177, Loss: 0.4503944516181946, Final Batch Loss: 0.13912738859653473\n",
      "Epoch 3178, Loss: 0.4696699380874634, Final Batch Loss: 0.14904482662677765\n",
      "Epoch 3179, Loss: 0.552205465734005, Final Batch Loss: 0.12182044237852097\n",
      "Epoch 3180, Loss: 0.48832882940769196, Final Batch Loss: 0.12714681029319763\n",
      "Epoch 3181, Loss: 0.5950268805027008, Final Batch Loss: 0.2401435226202011\n",
      "Epoch 3182, Loss: 0.510199174284935, Final Batch Loss: 0.16988058388233185\n",
      "Epoch 3183, Loss: 0.4597625881433487, Final Batch Loss: 0.1588645577430725\n",
      "Epoch 3184, Loss: 0.45227983593940735, Final Batch Loss: 0.1532965451478958\n",
      "Epoch 3185, Loss: 0.44791263341903687, Final Batch Loss: 0.13969488441944122\n",
      "Epoch 3186, Loss: 0.5184897929430008, Final Batch Loss: 0.15059277415275574\n",
      "Epoch 3187, Loss: 0.5791631042957306, Final Batch Loss: 0.15650111436843872\n",
      "Epoch 3188, Loss: 0.5035182237625122, Final Batch Loss: 0.18112713098526\n",
      "Epoch 3189, Loss: 0.4561528041958809, Final Batch Loss: 0.11190500110387802\n",
      "Epoch 3190, Loss: 0.5746086835861206, Final Batch Loss: 0.22447791695594788\n",
      "Epoch 3191, Loss: 0.4498975872993469, Final Batch Loss: 0.13812382519245148\n",
      "Epoch 3192, Loss: 0.48233553767204285, Final Batch Loss: 0.14777109026908875\n",
      "Epoch 3193, Loss: 0.6209254264831543, Final Batch Loss: 0.21625147759914398\n",
      "Epoch 3194, Loss: 0.545845240354538, Final Batch Loss: 0.12688171863555908\n",
      "Epoch 3195, Loss: 0.5068541765213013, Final Batch Loss: 0.18673719465732574\n",
      "Epoch 3196, Loss: 0.37880874425172806, Final Batch Loss: 0.08455859869718552\n",
      "Epoch 3197, Loss: 0.5898665189743042, Final Batch Loss: 0.22613351047039032\n",
      "Epoch 3198, Loss: 0.5304347425699234, Final Batch Loss: 0.18909484148025513\n",
      "Epoch 3199, Loss: 0.48475390672683716, Final Batch Loss: 0.11319197714328766\n",
      "Epoch 3200, Loss: 0.43735025078058243, Final Batch Loss: 0.12369460612535477\n",
      "Epoch 3201, Loss: 0.4404548406600952, Final Batch Loss: 0.10859374701976776\n",
      "Epoch 3202, Loss: 0.48231152445077896, Final Batch Loss: 0.12121491879224777\n",
      "Epoch 3203, Loss: 0.5432960540056229, Final Batch Loss: 0.20852001011371613\n",
      "Epoch 3204, Loss: 0.5166532248258591, Final Batch Loss: 0.1670188009738922\n",
      "Epoch 3205, Loss: 0.5029446631669998, Final Batch Loss: 0.14848721027374268\n",
      "Epoch 3206, Loss: 0.4119883254170418, Final Batch Loss: 0.08999397605657578\n",
      "Epoch 3207, Loss: 0.5479151159524918, Final Batch Loss: 0.17691732943058014\n",
      "Epoch 3208, Loss: 0.5292306393384933, Final Batch Loss: 0.1785370260477066\n",
      "Epoch 3209, Loss: 0.5929542183876038, Final Batch Loss: 0.16442114114761353\n",
      "Epoch 3210, Loss: 0.48437081277370453, Final Batch Loss: 0.13123594224452972\n",
      "Epoch 3211, Loss: 0.5059483572840691, Final Batch Loss: 0.1953224092721939\n",
      "Epoch 3212, Loss: 0.5722587406635284, Final Batch Loss: 0.2081741839647293\n",
      "Epoch 3213, Loss: 0.6103832870721817, Final Batch Loss: 0.2758362889289856\n",
      "Epoch 3214, Loss: 0.5598410069942474, Final Batch Loss: 0.12648767232894897\n",
      "Epoch 3215, Loss: 0.49729400873184204, Final Batch Loss: 0.1834445744752884\n",
      "Epoch 3216, Loss: 0.6018846333026886, Final Batch Loss: 0.2027953863143921\n",
      "Epoch 3217, Loss: 0.5890002250671387, Final Batch Loss: 0.2311837375164032\n",
      "Epoch 3218, Loss: 0.5138539224863052, Final Batch Loss: 0.19549570977687836\n",
      "Epoch 3219, Loss: 0.5265983790159225, Final Batch Loss: 0.14505009353160858\n",
      "Epoch 3220, Loss: 0.4612036645412445, Final Batch Loss: 0.13263456523418427\n",
      "Epoch 3221, Loss: 0.451545849442482, Final Batch Loss: 0.18203435838222504\n",
      "Epoch 3222, Loss: 0.5162845402956009, Final Batch Loss: 0.20800311863422394\n",
      "Epoch 3223, Loss: 0.5804784297943115, Final Batch Loss: 0.17584209144115448\n",
      "Epoch 3224, Loss: 0.5388438031077385, Final Batch Loss: 0.11404000967741013\n",
      "Epoch 3225, Loss: 0.46599656343460083, Final Batch Loss: 0.1275217980146408\n",
      "Epoch 3226, Loss: 0.5083926022052765, Final Batch Loss: 0.13246303796768188\n",
      "Epoch 3227, Loss: 0.46064749360084534, Final Batch Loss: 0.20078913867473602\n",
      "Epoch 3228, Loss: 0.5022644698619843, Final Batch Loss: 0.1741100549697876\n",
      "Epoch 3229, Loss: 0.5060491412878036, Final Batch Loss: 0.13259446620941162\n",
      "Epoch 3230, Loss: 0.5547006726264954, Final Batch Loss: 0.14152315258979797\n",
      "Epoch 3231, Loss: 0.4528304636478424, Final Batch Loss: 0.1830836534500122\n",
      "Epoch 3232, Loss: 0.46892453730106354, Final Batch Loss: 0.16933073103427887\n",
      "Epoch 3233, Loss: 0.5994248390197754, Final Batch Loss: 0.17804525792598724\n",
      "Epoch 3234, Loss: 0.4243272989988327, Final Batch Loss: 0.13745245337486267\n",
      "Epoch 3235, Loss: 0.5624073296785355, Final Batch Loss: 0.22072352468967438\n",
      "Epoch 3236, Loss: 0.5201806277036667, Final Batch Loss: 0.18229633569717407\n",
      "Epoch 3237, Loss: 0.5341012328863144, Final Batch Loss: 0.20756177604198456\n",
      "Epoch 3238, Loss: 0.56829634308815, Final Batch Loss: 0.2395223081111908\n",
      "Epoch 3239, Loss: 0.6211264729499817, Final Batch Loss: 0.19024591147899628\n",
      "Epoch 3240, Loss: 0.5981417298316956, Final Batch Loss: 0.24906732141971588\n",
      "Epoch 3241, Loss: 0.4787467047572136, Final Batch Loss: 0.1049768254160881\n",
      "Epoch 3242, Loss: 0.45880086719989777, Final Batch Loss: 0.1461077183485031\n",
      "Epoch 3243, Loss: 0.4579515904188156, Final Batch Loss: 0.1573931723833084\n",
      "Epoch 3244, Loss: 0.5215830504894257, Final Batch Loss: 0.21159817278385162\n",
      "Epoch 3245, Loss: 0.6676018536090851, Final Batch Loss: 0.2790238559246063\n",
      "Epoch 3246, Loss: 0.5797374397516251, Final Batch Loss: 0.2654930651187897\n",
      "Epoch 3247, Loss: 0.509006530046463, Final Batch Loss: 0.16485349833965302\n",
      "Epoch 3248, Loss: 0.5047761127352715, Final Batch Loss: 0.1901879757642746\n",
      "Epoch 3249, Loss: 0.5000268742442131, Final Batch Loss: 0.11824642866849899\n",
      "Epoch 3250, Loss: 0.505418062210083, Final Batch Loss: 0.16678616404533386\n",
      "Epoch 3251, Loss: 0.46346549689769745, Final Batch Loss: 0.17223751544952393\n",
      "Epoch 3252, Loss: 0.5007428526878357, Final Batch Loss: 0.24463875591754913\n",
      "Epoch 3253, Loss: 0.5362177640199661, Final Batch Loss: 0.201449453830719\n",
      "Epoch 3254, Loss: 0.47840219736099243, Final Batch Loss: 0.1452234387397766\n",
      "Epoch 3255, Loss: 0.6285695731639862, Final Batch Loss: 0.2286462038755417\n",
      "Epoch 3256, Loss: 0.5035735070705414, Final Batch Loss: 0.15089425444602966\n",
      "Epoch 3257, Loss: 0.5563875734806061, Final Batch Loss: 0.2527250051498413\n",
      "Epoch 3258, Loss: 0.5372253507375717, Final Batch Loss: 0.208720862865448\n",
      "Epoch 3259, Loss: 0.45330461859703064, Final Batch Loss: 0.14389576017856598\n",
      "Epoch 3260, Loss: 0.49217426031827927, Final Batch Loss: 0.11360586434602737\n",
      "Epoch 3261, Loss: 0.5774770230054855, Final Batch Loss: 0.15411213040351868\n",
      "Epoch 3262, Loss: 0.4456368088722229, Final Batch Loss: 0.17707771062850952\n",
      "Epoch 3263, Loss: 0.4529103711247444, Final Batch Loss: 0.1158968135714531\n",
      "Epoch 3264, Loss: 0.5176703706383705, Final Batch Loss: 0.10900305956602097\n",
      "Epoch 3265, Loss: 0.6188328713178635, Final Batch Loss: 0.24924395978450775\n",
      "Epoch 3266, Loss: 0.5644304901361465, Final Batch Loss: 0.14821502566337585\n",
      "Epoch 3267, Loss: 0.5631342828273773, Final Batch Loss: 0.1787516474723816\n",
      "Epoch 3268, Loss: 0.4852156937122345, Final Batch Loss: 0.14850935339927673\n",
      "Epoch 3269, Loss: 0.47480326890945435, Final Batch Loss: 0.13616949319839478\n",
      "Epoch 3270, Loss: 0.5951993316411972, Final Batch Loss: 0.16594956815242767\n",
      "Epoch 3271, Loss: 0.5550533682107925, Final Batch Loss: 0.22537913918495178\n",
      "Epoch 3272, Loss: 0.5017815381288528, Final Batch Loss: 0.17870822548866272\n",
      "Epoch 3273, Loss: 0.5290795564651489, Final Batch Loss: 0.16607394814491272\n",
      "Epoch 3274, Loss: 0.5110523104667664, Final Batch Loss: 0.14814049005508423\n",
      "Epoch 3275, Loss: 0.5070431530475616, Final Batch Loss: 0.16406968235969543\n",
      "Epoch 3276, Loss: 0.44495756924152374, Final Batch Loss: 0.1359046846628189\n",
      "Epoch 3277, Loss: 0.43651996552944183, Final Batch Loss: 0.14842785894870758\n",
      "Epoch 3278, Loss: 0.5491278246045113, Final Batch Loss: 0.24302415549755096\n",
      "Epoch 3279, Loss: 0.4490402415394783, Final Batch Loss: 0.18460135161876678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3280, Loss: 0.447189524769783, Final Batch Loss: 0.17056164145469666\n",
      "Epoch 3281, Loss: 0.48206666111946106, Final Batch Loss: 0.12355999648571014\n",
      "Epoch 3282, Loss: 0.43691594153642654, Final Batch Loss: 0.1109243705868721\n",
      "Epoch 3283, Loss: 0.46332694590091705, Final Batch Loss: 0.17901460826396942\n",
      "Epoch 3284, Loss: 0.5105005502700806, Final Batch Loss: 0.17629995942115784\n",
      "Epoch 3285, Loss: 0.4575873017311096, Final Batch Loss: 0.10497802495956421\n",
      "Epoch 3286, Loss: 0.43830399215221405, Final Batch Loss: 0.16644300520420074\n",
      "Epoch 3287, Loss: 0.48543010652065277, Final Batch Loss: 0.2063271850347519\n",
      "Epoch 3288, Loss: 0.4479430317878723, Final Batch Loss: 0.14349593222141266\n",
      "Epoch 3289, Loss: 0.6791661381721497, Final Batch Loss: 0.23492930829524994\n",
      "Epoch 3290, Loss: 0.6127209663391113, Final Batch Loss: 0.20490503311157227\n",
      "Epoch 3291, Loss: 0.49680908024311066, Final Batch Loss: 0.16872361302375793\n",
      "Epoch 3292, Loss: 0.4559625834226608, Final Batch Loss: 0.19968809187412262\n",
      "Epoch 3293, Loss: 0.47446107864379883, Final Batch Loss: 0.15165841579437256\n",
      "Epoch 3294, Loss: 0.4790565073490143, Final Batch Loss: 0.15017621219158173\n",
      "Epoch 3295, Loss: 0.5743293911218643, Final Batch Loss: 0.18587219715118408\n",
      "Epoch 3296, Loss: 0.6262340247631073, Final Batch Loss: 0.275871604681015\n",
      "Epoch 3297, Loss: 0.4324220046401024, Final Batch Loss: 0.10932204872369766\n",
      "Epoch 3298, Loss: 0.4653009921312332, Final Batch Loss: 0.1438731700181961\n",
      "Epoch 3299, Loss: 0.4913908392190933, Final Batch Loss: 0.17930811643600464\n",
      "Epoch 3300, Loss: 0.4684353470802307, Final Batch Loss: 0.12920133769512177\n",
      "Epoch 3301, Loss: 0.5090211033821106, Final Batch Loss: 0.1554369330406189\n",
      "Epoch 3302, Loss: 0.4932020306587219, Final Batch Loss: 0.17581579089164734\n",
      "Epoch 3303, Loss: 0.5996082723140717, Final Batch Loss: 0.22037655115127563\n",
      "Epoch 3304, Loss: 0.5332354828715324, Final Batch Loss: 0.2282758206129074\n",
      "Epoch 3305, Loss: 0.6132979243993759, Final Batch Loss: 0.1768755316734314\n",
      "Epoch 3306, Loss: 0.4013267606496811, Final Batch Loss: 0.10984613001346588\n",
      "Epoch 3307, Loss: 0.5347061604261398, Final Batch Loss: 0.23382921516895294\n",
      "Epoch 3308, Loss: 0.5066241770982742, Final Batch Loss: 0.1939970999956131\n",
      "Epoch 3309, Loss: 0.5317156314849854, Final Batch Loss: 0.17754106223583221\n",
      "Epoch 3310, Loss: 0.5188778638839722, Final Batch Loss: 0.14907638728618622\n",
      "Epoch 3311, Loss: 0.5261206328868866, Final Batch Loss: 0.13537663221359253\n",
      "Epoch 3312, Loss: 0.5036757737398148, Final Batch Loss: 0.16175240278244019\n",
      "Epoch 3313, Loss: 0.5843684077262878, Final Batch Loss: 0.19878123700618744\n",
      "Epoch 3314, Loss: 0.5109831988811493, Final Batch Loss: 0.21453095972537994\n",
      "Epoch 3315, Loss: 0.5025787055492401, Final Batch Loss: 0.14945049583911896\n",
      "Epoch 3316, Loss: 0.5053416192531586, Final Batch Loss: 0.17358244955539703\n",
      "Epoch 3317, Loss: 0.4801193103194237, Final Batch Loss: 0.19481785595417023\n",
      "Epoch 3318, Loss: 0.4149211347103119, Final Batch Loss: 0.11166954040527344\n",
      "Epoch 3319, Loss: 0.49943646788597107, Final Batch Loss: 0.1571890413761139\n",
      "Epoch 3320, Loss: 0.5368493348360062, Final Batch Loss: 0.13193809986114502\n",
      "Epoch 3321, Loss: 0.41328228265047073, Final Batch Loss: 0.12280412763357162\n",
      "Epoch 3322, Loss: 0.5058719962835312, Final Batch Loss: 0.14217409491539001\n",
      "Epoch 3323, Loss: 0.6386441141366959, Final Batch Loss: 0.23943883180618286\n",
      "Epoch 3324, Loss: 0.4407307580113411, Final Batch Loss: 0.11002791672945023\n",
      "Epoch 3325, Loss: 0.40540438890457153, Final Batch Loss: 0.13142089545726776\n",
      "Epoch 3326, Loss: 0.5047147572040558, Final Batch Loss: 0.17985625565052032\n",
      "Epoch 3327, Loss: 0.4669489935040474, Final Batch Loss: 0.11708176881074905\n",
      "Epoch 3328, Loss: 0.40073970705270767, Final Batch Loss: 0.07137107104063034\n",
      "Epoch 3329, Loss: 0.5005215555429459, Final Batch Loss: 0.13951453566551208\n",
      "Epoch 3330, Loss: 0.49710600078105927, Final Batch Loss: 0.16842344403266907\n",
      "Epoch 3331, Loss: 0.5657677501440048, Final Batch Loss: 0.18466202914714813\n",
      "Epoch 3332, Loss: 0.5186447650194168, Final Batch Loss: 0.21982626616954803\n",
      "Epoch 3333, Loss: 0.5285319462418556, Final Batch Loss: 0.23900634050369263\n",
      "Epoch 3334, Loss: 0.4847943186759949, Final Batch Loss: 0.14639338850975037\n",
      "Epoch 3335, Loss: 0.49963095784187317, Final Batch Loss: 0.12883897125720978\n",
      "Epoch 3336, Loss: 0.5586202144622803, Final Batch Loss: 0.24242980778217316\n",
      "Epoch 3337, Loss: 0.5365946888923645, Final Batch Loss: 0.2087670862674713\n",
      "Epoch 3338, Loss: 0.7196332216262817, Final Batch Loss: 0.3297947347164154\n",
      "Epoch 3339, Loss: 0.5758229494094849, Final Batch Loss: 0.31772753596305847\n",
      "Epoch 3340, Loss: 0.44739481806755066, Final Batch Loss: 0.12733586132526398\n",
      "Epoch 3341, Loss: 0.506936252117157, Final Batch Loss: 0.1569395512342453\n",
      "Epoch 3342, Loss: 0.6256186664104462, Final Batch Loss: 0.255573570728302\n",
      "Epoch 3343, Loss: 0.5830771774053574, Final Batch Loss: 0.24212118983268738\n",
      "Epoch 3344, Loss: 0.6505077928304672, Final Batch Loss: 0.19199612736701965\n",
      "Epoch 3345, Loss: 0.4568876773118973, Final Batch Loss: 0.15795838832855225\n",
      "Epoch 3346, Loss: 0.5602457225322723, Final Batch Loss: 0.1684318333864212\n",
      "Epoch 3347, Loss: 0.6888249814510345, Final Batch Loss: 0.27261605858802795\n",
      "Epoch 3348, Loss: 0.4938606917858124, Final Batch Loss: 0.14263850450515747\n",
      "Epoch 3349, Loss: 0.4524141848087311, Final Batch Loss: 0.13828574120998383\n",
      "Epoch 3350, Loss: 0.5297392010688782, Final Batch Loss: 0.15644626319408417\n",
      "Epoch 3351, Loss: 0.5627321004867554, Final Batch Loss: 0.24723611772060394\n",
      "Epoch 3352, Loss: 0.4453061446547508, Final Batch Loss: 0.11934489011764526\n",
      "Epoch 3353, Loss: 0.4982522875070572, Final Batch Loss: 0.14834478497505188\n",
      "Epoch 3354, Loss: 0.4733850955963135, Final Batch Loss: 0.16626080870628357\n",
      "Epoch 3355, Loss: 0.5215653777122498, Final Batch Loss: 0.21426773071289062\n",
      "Epoch 3356, Loss: 0.47266659140586853, Final Batch Loss: 0.19001226127147675\n",
      "Epoch 3357, Loss: 0.5034793466329575, Final Batch Loss: 0.17473267018795013\n",
      "Epoch 3358, Loss: 0.45012635737657547, Final Batch Loss: 0.1231362447142601\n",
      "Epoch 3359, Loss: 0.5615859776735306, Final Batch Loss: 0.1780024915933609\n",
      "Epoch 3360, Loss: 0.49751514196395874, Final Batch Loss: 0.21317586302757263\n",
      "Epoch 3361, Loss: 0.3929837718605995, Final Batch Loss: 0.1335492879152298\n",
      "Epoch 3362, Loss: 0.5321269407868385, Final Batch Loss: 0.22645671665668488\n",
      "Epoch 3363, Loss: 0.43839409202337265, Final Batch Loss: 0.09156591445207596\n",
      "Epoch 3364, Loss: 0.4291468858718872, Final Batch Loss: 0.14154398441314697\n",
      "Epoch 3365, Loss: 0.42408911883831024, Final Batch Loss: 0.12530025839805603\n",
      "Epoch 3366, Loss: 0.5907889008522034, Final Batch Loss: 0.1864681988954544\n",
      "Epoch 3367, Loss: 0.5083376988768578, Final Batch Loss: 0.2039502114057541\n",
      "Epoch 3368, Loss: 0.5770649611949921, Final Batch Loss: 0.13228541612625122\n",
      "Epoch 3369, Loss: 0.478001207113266, Final Batch Loss: 0.19894956052303314\n",
      "Epoch 3370, Loss: 0.4231729209423065, Final Batch Loss: 0.12957435846328735\n",
      "Epoch 3371, Loss: 0.4723101407289505, Final Batch Loss: 0.13745605945587158\n",
      "Epoch 3372, Loss: 0.5809513479471207, Final Batch Loss: 0.20392166078090668\n",
      "Epoch 3373, Loss: 0.5120113492012024, Final Batch Loss: 0.17757025361061096\n",
      "Epoch 3374, Loss: 0.6497551500797272, Final Batch Loss: 0.323533833026886\n",
      "Epoch 3375, Loss: 0.5697131007909775, Final Batch Loss: 0.23095610737800598\n",
      "Epoch 3376, Loss: 0.6266036927700043, Final Batch Loss: 0.1831517517566681\n",
      "Epoch 3377, Loss: 0.6287317425012589, Final Batch Loss: 0.1979501098394394\n",
      "Epoch 3378, Loss: 0.5930093228816986, Final Batch Loss: 0.14358915388584137\n",
      "Epoch 3379, Loss: 0.5672533288598061, Final Batch Loss: 0.12060066312551498\n",
      "Epoch 3380, Loss: 0.46233057975769043, Final Batch Loss: 0.14608590304851532\n",
      "Epoch 3381, Loss: 0.5712013691663742, Final Batch Loss: 0.20377366244792938\n",
      "Epoch 3382, Loss: 0.5321468561887741, Final Batch Loss: 0.19658717513084412\n",
      "Epoch 3383, Loss: 0.5450552478432655, Final Batch Loss: 0.22909313440322876\n",
      "Epoch 3384, Loss: 0.4518406540155411, Final Batch Loss: 0.1271776258945465\n",
      "Epoch 3385, Loss: 0.4035662114620209, Final Batch Loss: 0.1268954575061798\n",
      "Epoch 3386, Loss: 0.6346613019704819, Final Batch Loss: 0.25795978307724\n",
      "Epoch 3387, Loss: 0.6174200773239136, Final Batch Loss: 0.22074508666992188\n",
      "Epoch 3388, Loss: 0.4555474519729614, Final Batch Loss: 0.13820615410804749\n",
      "Epoch 3389, Loss: 0.5396540760993958, Final Batch Loss: 0.1522289514541626\n",
      "Epoch 3390, Loss: 0.5467473119497299, Final Batch Loss: 0.26404038071632385\n",
      "Epoch 3391, Loss: 0.49342553317546844, Final Batch Loss: 0.17594577372074127\n",
      "Epoch 3392, Loss: 0.5614677518606186, Final Batch Loss: 0.2324034720659256\n",
      "Epoch 3393, Loss: 0.5810534060001373, Final Batch Loss: 0.2637445032596588\n",
      "Epoch 3394, Loss: 0.5399868488311768, Final Batch Loss: 0.1702239066362381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3395, Loss: 0.4403121545910835, Final Batch Loss: 0.12209057062864304\n",
      "Epoch 3396, Loss: 0.5544416755437851, Final Batch Loss: 0.2113332748413086\n",
      "Epoch 3397, Loss: 0.3710874766111374, Final Batch Loss: 0.09013305604457855\n",
      "Epoch 3398, Loss: 0.48170433938503265, Final Batch Loss: 0.22282256186008453\n",
      "Epoch 3399, Loss: 0.5151222348213196, Final Batch Loss: 0.13804525136947632\n",
      "Epoch 3400, Loss: 0.44418906420469284, Final Batch Loss: 0.11701304465532303\n",
      "Epoch 3401, Loss: 0.506318062543869, Final Batch Loss: 0.17337466776371002\n",
      "Epoch 3402, Loss: 0.5489086210727692, Final Batch Loss: 0.17534396052360535\n",
      "Epoch 3403, Loss: 0.4079195633530617, Final Batch Loss: 0.10517992824316025\n",
      "Epoch 3404, Loss: 0.47846969962120056, Final Batch Loss: 0.12862296402454376\n",
      "Epoch 3405, Loss: 0.580076202750206, Final Batch Loss: 0.20461368560791016\n",
      "Epoch 3406, Loss: 0.5054351985454559, Final Batch Loss: 0.19949987530708313\n",
      "Epoch 3407, Loss: 0.5142385512590408, Final Batch Loss: 0.13937439024448395\n",
      "Epoch 3408, Loss: 0.4774450957775116, Final Batch Loss: 0.17700164020061493\n",
      "Epoch 3409, Loss: 0.5873235017061234, Final Batch Loss: 0.2195291519165039\n",
      "Epoch 3410, Loss: 0.6248853206634521, Final Batch Loss: 0.2470649927854538\n",
      "Epoch 3411, Loss: 0.5539283156394958, Final Batch Loss: 0.253943532705307\n",
      "Epoch 3412, Loss: 0.4796315133571625, Final Batch Loss: 0.18307019770145416\n",
      "Epoch 3413, Loss: 0.49818553030490875, Final Batch Loss: 0.16630850732326508\n",
      "Epoch 3414, Loss: 0.5944128632545471, Final Batch Loss: 0.24782125651836395\n",
      "Epoch 3415, Loss: 0.5728022307157516, Final Batch Loss: 0.30480194091796875\n",
      "Epoch 3416, Loss: 0.5709033012390137, Final Batch Loss: 0.19414758682250977\n",
      "Epoch 3417, Loss: 0.5311727672815323, Final Batch Loss: 0.16950762271881104\n",
      "Epoch 3418, Loss: 0.4853193610906601, Final Batch Loss: 0.11102870106697083\n",
      "Epoch 3419, Loss: 0.5355972424149513, Final Batch Loss: 0.21501301229000092\n",
      "Epoch 3420, Loss: 0.4669886380434036, Final Batch Loss: 0.18505044281482697\n",
      "Epoch 3421, Loss: 0.4970141500234604, Final Batch Loss: 0.22686707973480225\n",
      "Epoch 3422, Loss: 0.48906950652599335, Final Batch Loss: 0.14099407196044922\n",
      "Epoch 3423, Loss: 0.48977044224739075, Final Batch Loss: 0.17404252290725708\n",
      "Epoch 3424, Loss: 0.49875399470329285, Final Batch Loss: 0.16500090062618256\n",
      "Epoch 3425, Loss: 0.4538993686437607, Final Batch Loss: 0.11920700967311859\n",
      "Epoch 3426, Loss: 0.5096371918916702, Final Batch Loss: 0.16776372492313385\n",
      "Epoch 3427, Loss: 0.4437451586127281, Final Batch Loss: 0.14383605122566223\n",
      "Epoch 3428, Loss: 0.4955623000860214, Final Batch Loss: 0.1834593564271927\n",
      "Epoch 3429, Loss: 0.4565007835626602, Final Batch Loss: 0.12244944274425507\n",
      "Epoch 3430, Loss: 0.5324706137180328, Final Batch Loss: 0.13865827023983002\n",
      "Epoch 3431, Loss: 0.6184477359056473, Final Batch Loss: 0.13988691568374634\n",
      "Epoch 3432, Loss: 0.5186401009559631, Final Batch Loss: 0.18958164751529694\n",
      "Epoch 3433, Loss: 0.5547038614749908, Final Batch Loss: 0.21288949251174927\n",
      "Epoch 3434, Loss: 0.4507095143198967, Final Batch Loss: 0.12085629254579544\n",
      "Epoch 3435, Loss: 0.5048679932951927, Final Batch Loss: 0.25118377804756165\n",
      "Epoch 3436, Loss: 0.45591655373573303, Final Batch Loss: 0.11462309956550598\n",
      "Epoch 3437, Loss: 0.4649388790130615, Final Batch Loss: 0.13596393167972565\n",
      "Epoch 3438, Loss: 0.5234118103981018, Final Batch Loss: 0.17992530763149261\n",
      "Epoch 3439, Loss: 0.5065727382898331, Final Batch Loss: 0.13388556241989136\n",
      "Epoch 3440, Loss: 0.47991301864385605, Final Batch Loss: 0.18578679859638214\n",
      "Epoch 3441, Loss: 0.42442934960126877, Final Batch Loss: 0.14971014857292175\n",
      "Epoch 3442, Loss: 0.5261961668729782, Final Batch Loss: 0.16196566820144653\n",
      "Epoch 3443, Loss: 0.4989153742790222, Final Batch Loss: 0.13457255065441132\n",
      "Epoch 3444, Loss: 0.5030634105205536, Final Batch Loss: 0.17862337827682495\n",
      "Epoch 3445, Loss: 0.46344849467277527, Final Batch Loss: 0.13359276950359344\n",
      "Epoch 3446, Loss: 0.4421090930700302, Final Batch Loss: 0.13558471202850342\n",
      "Epoch 3447, Loss: 0.6024882048368454, Final Batch Loss: 0.23424361646175385\n",
      "Epoch 3448, Loss: 0.5273311734199524, Final Batch Loss: 0.1493447870016098\n",
      "Epoch 3449, Loss: 0.47750890254974365, Final Batch Loss: 0.17741142213344574\n",
      "Epoch 3450, Loss: 0.5683322101831436, Final Batch Loss: 0.21353253722190857\n",
      "Epoch 3451, Loss: 0.435586079955101, Final Batch Loss: 0.15093593299388885\n",
      "Epoch 3452, Loss: 0.4045601710677147, Final Batch Loss: 0.13283641636371613\n",
      "Epoch 3453, Loss: 0.5117194205522537, Final Batch Loss: 0.1704895943403244\n",
      "Epoch 3454, Loss: 0.42937470972537994, Final Batch Loss: 0.12507769465446472\n",
      "Epoch 3455, Loss: 0.47608622163534164, Final Batch Loss: 0.11735158413648605\n",
      "Epoch 3456, Loss: 0.5487904101610184, Final Batch Loss: 0.21385419368743896\n",
      "Epoch 3457, Loss: 0.5299410670995712, Final Batch Loss: 0.17291364073753357\n",
      "Epoch 3458, Loss: 0.49407778680324554, Final Batch Loss: 0.1519794911146164\n",
      "Epoch 3459, Loss: 0.5375912189483643, Final Batch Loss: 0.17700599133968353\n",
      "Epoch 3460, Loss: 0.5319009870290756, Final Batch Loss: 0.2213858813047409\n",
      "Epoch 3461, Loss: 0.49140799790620804, Final Batch Loss: 0.11932110041379929\n",
      "Epoch 3462, Loss: 0.5446595251560211, Final Batch Loss: 0.16635553538799286\n",
      "Epoch 3463, Loss: 0.5249086022377014, Final Batch Loss: 0.20694750547409058\n",
      "Epoch 3464, Loss: 0.43137866258621216, Final Batch Loss: 0.11516690254211426\n",
      "Epoch 3465, Loss: 0.41253337264060974, Final Batch Loss: 0.158516988158226\n",
      "Epoch 3466, Loss: 0.5169224441051483, Final Batch Loss: 0.22738823294639587\n",
      "Epoch 3467, Loss: 0.5511718392372131, Final Batch Loss: 0.1612524539232254\n",
      "Epoch 3468, Loss: 0.6081975847482681, Final Batch Loss: 0.16622555255889893\n",
      "Epoch 3469, Loss: 0.5892464220523834, Final Batch Loss: 0.19381196796894073\n",
      "Epoch 3470, Loss: 0.5069000720977783, Final Batch Loss: 0.17194858193397522\n",
      "Epoch 3471, Loss: 0.4233636111021042, Final Batch Loss: 0.14937560260295868\n",
      "Epoch 3472, Loss: 0.5048479735851288, Final Batch Loss: 0.19934605062007904\n",
      "Epoch 3473, Loss: 0.52411749958992, Final Batch Loss: 0.20610108971595764\n",
      "Epoch 3474, Loss: 0.5510812550783157, Final Batch Loss: 0.18448956310749054\n",
      "Epoch 3475, Loss: 0.5628567487001419, Final Batch Loss: 0.2730492949485779\n",
      "Epoch 3476, Loss: 0.4061943292617798, Final Batch Loss: 0.12887351214885712\n",
      "Epoch 3477, Loss: 0.4594961851835251, Final Batch Loss: 0.1664379984140396\n",
      "Epoch 3478, Loss: 0.5361349433660507, Final Batch Loss: 0.21039727330207825\n",
      "Epoch 3479, Loss: 0.42046112567186356, Final Batch Loss: 0.09422662109136581\n",
      "Epoch 3480, Loss: 0.5113267749547958, Final Batch Loss: 0.1938353180885315\n",
      "Epoch 3481, Loss: 0.48170676827430725, Final Batch Loss: 0.21713806688785553\n",
      "Epoch 3482, Loss: 0.49812576174736023, Final Batch Loss: 0.1732225865125656\n",
      "Epoch 3483, Loss: 0.5015378445386887, Final Batch Loss: 0.15461428463459015\n",
      "Epoch 3484, Loss: 0.5049582868814468, Final Batch Loss: 0.15492504835128784\n",
      "Epoch 3485, Loss: 0.4413827285170555, Final Batch Loss: 0.17576485872268677\n",
      "Epoch 3486, Loss: 0.4183184504508972, Final Batch Loss: 0.12615716457366943\n",
      "Epoch 3487, Loss: 0.550077885389328, Final Batch Loss: 0.1508285105228424\n",
      "Epoch 3488, Loss: 0.39366012066602707, Final Batch Loss: 0.07981366664171219\n",
      "Epoch 3489, Loss: 0.5055110454559326, Final Batch Loss: 0.15134510397911072\n",
      "Epoch 3490, Loss: 0.3826819136738777, Final Batch Loss: 0.13818173110485077\n",
      "Epoch 3491, Loss: 0.5296248346567154, Final Batch Loss: 0.21973653137683868\n",
      "Epoch 3492, Loss: 0.500989243388176, Final Batch Loss: 0.18205048143863678\n",
      "Epoch 3493, Loss: 0.4278602600097656, Final Batch Loss: 0.14741985499858856\n",
      "Epoch 3494, Loss: 0.41264381259679794, Final Batch Loss: 0.09055512398481369\n",
      "Epoch 3495, Loss: 0.6067858934402466, Final Batch Loss: 0.2275840789079666\n",
      "Epoch 3496, Loss: 0.4374701455235481, Final Batch Loss: 0.17474666237831116\n",
      "Epoch 3497, Loss: 0.4113472029566765, Final Batch Loss: 0.1167166605591774\n",
      "Epoch 3498, Loss: 0.5282948017120361, Final Batch Loss: 0.13482072949409485\n",
      "Epoch 3499, Loss: 0.48030976951122284, Final Batch Loss: 0.15439797937870026\n",
      "Epoch 3500, Loss: 0.48987801373004913, Final Batch Loss: 0.20079299807548523\n",
      "Epoch 3501, Loss: 0.4564845412969589, Final Batch Loss: 0.12564893066883087\n",
      "Epoch 3502, Loss: 0.5454358011484146, Final Batch Loss: 0.15236705541610718\n",
      "Epoch 3503, Loss: 0.44716551899909973, Final Batch Loss: 0.1594359427690506\n",
      "Epoch 3504, Loss: 0.42284823954105377, Final Batch Loss: 0.13459381461143494\n",
      "Epoch 3505, Loss: 0.4938420057296753, Final Batch Loss: 0.1808338761329651\n",
      "Epoch 3506, Loss: 0.46402110904455185, Final Batch Loss: 0.12053964287042618\n",
      "Epoch 3507, Loss: 0.3623526096343994, Final Batch Loss: 0.06815221160650253\n",
      "Epoch 3508, Loss: 0.585352897644043, Final Batch Loss: 0.19475141167640686\n",
      "Epoch 3509, Loss: 0.48089252412319183, Final Batch Loss: 0.14495782554149628\n",
      "Epoch 3510, Loss: 0.49508683383464813, Final Batch Loss: 0.1928994059562683\n",
      "Epoch 3511, Loss: 0.36125650256872177, Final Batch Loss: 0.0789785161614418\n",
      "Epoch 3512, Loss: 0.5826726108789444, Final Batch Loss: 0.14679422974586487\n",
      "Epoch 3513, Loss: 0.42758195847272873, Final Batch Loss: 0.11762497574090958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3514, Loss: 0.40712355822324753, Final Batch Loss: 0.1373063176870346\n",
      "Epoch 3515, Loss: 0.4873989075422287, Final Batch Loss: 0.18230566382408142\n",
      "Epoch 3516, Loss: 0.3808293268084526, Final Batch Loss: 0.10022149235010147\n",
      "Epoch 3517, Loss: 0.4592069312930107, Final Batch Loss: 0.17682911455631256\n",
      "Epoch 3518, Loss: 0.4717152789235115, Final Batch Loss: 0.23429328203201294\n",
      "Epoch 3519, Loss: 0.4806481897830963, Final Batch Loss: 0.15906678140163422\n",
      "Epoch 3520, Loss: 0.44242796301841736, Final Batch Loss: 0.1281587779521942\n",
      "Epoch 3521, Loss: 0.4112061932682991, Final Batch Loss: 0.14283743500709534\n",
      "Epoch 3522, Loss: 0.4372975677251816, Final Batch Loss: 0.16869652271270752\n",
      "Epoch 3523, Loss: 0.4453756660223007, Final Batch Loss: 0.1297663301229477\n",
      "Epoch 3524, Loss: 0.5975828617811203, Final Batch Loss: 0.2552909553050995\n",
      "Epoch 3525, Loss: 0.47908399254083633, Final Batch Loss: 0.17516911029815674\n",
      "Epoch 3526, Loss: 0.49399904906749725, Final Batch Loss: 0.13199664652347565\n",
      "Epoch 3527, Loss: 0.40631794184446335, Final Batch Loss: 0.14154377579689026\n",
      "Epoch 3528, Loss: 0.5409957468509674, Final Batch Loss: 0.16038735210895538\n",
      "Epoch 3529, Loss: 0.45711784064769745, Final Batch Loss: 0.12852917611598969\n",
      "Epoch 3530, Loss: 0.4921135902404785, Final Batch Loss: 0.15597909688949585\n",
      "Epoch 3531, Loss: 0.5101031064987183, Final Batch Loss: 0.2245440036058426\n",
      "Epoch 3532, Loss: 0.49464407563209534, Final Batch Loss: 0.17099745571613312\n",
      "Epoch 3533, Loss: 0.3701925650238991, Final Batch Loss: 0.098932646214962\n",
      "Epoch 3534, Loss: 0.5217595100402832, Final Batch Loss: 0.15380921959877014\n",
      "Epoch 3535, Loss: 0.5558027178049088, Final Batch Loss: 0.243366077542305\n",
      "Epoch 3536, Loss: 0.4615611210465431, Final Batch Loss: 0.11815815418958664\n",
      "Epoch 3537, Loss: 0.5049201771616936, Final Batch Loss: 0.11644989997148514\n",
      "Epoch 3538, Loss: 0.4252031296491623, Final Batch Loss: 0.12315733730792999\n",
      "Epoch 3539, Loss: 0.49680881202220917, Final Batch Loss: 0.14729170501232147\n",
      "Epoch 3540, Loss: 0.5131551921367645, Final Batch Loss: 0.0708395391702652\n",
      "Epoch 3541, Loss: 0.6742603480815887, Final Batch Loss: 0.32474473118782043\n",
      "Epoch 3542, Loss: 0.5535037070512772, Final Batch Loss: 0.17583142220973969\n",
      "Epoch 3543, Loss: 0.5072986260056496, Final Batch Loss: 0.09560414403676987\n",
      "Epoch 3544, Loss: 0.46479976177215576, Final Batch Loss: 0.14443902671337128\n",
      "Epoch 3545, Loss: 0.5342495292425156, Final Batch Loss: 0.18503788113594055\n",
      "Epoch 3546, Loss: 0.4627406373620033, Final Batch Loss: 0.12495162338018417\n",
      "Epoch 3547, Loss: 0.5197251886129379, Final Batch Loss: 0.19242189824581146\n",
      "Epoch 3548, Loss: 0.45307885110378265, Final Batch Loss: 0.13559366762638092\n",
      "Epoch 3549, Loss: 0.5968155562877655, Final Batch Loss: 0.15298767387866974\n",
      "Epoch 3550, Loss: 0.5657524615526199, Final Batch Loss: 0.25053730607032776\n",
      "Epoch 3551, Loss: 0.502410963177681, Final Batch Loss: 0.17668800055980682\n",
      "Epoch 3552, Loss: 0.42421185970306396, Final Batch Loss: 0.1320214718580246\n",
      "Epoch 3553, Loss: 0.43946388363838196, Final Batch Loss: 0.13735896348953247\n",
      "Epoch 3554, Loss: 0.6054352521896362, Final Batch Loss: 0.24618633091449738\n",
      "Epoch 3555, Loss: 0.4850337356328964, Final Batch Loss: 0.13331204652786255\n",
      "Epoch 3556, Loss: 0.5305399149656296, Final Batch Loss: 0.14977307617664337\n",
      "Epoch 3557, Loss: 0.4946140795946121, Final Batch Loss: 0.14349418878555298\n",
      "Epoch 3558, Loss: 0.439277321100235, Final Batch Loss: 0.14815659821033478\n",
      "Epoch 3559, Loss: 0.5258221924304962, Final Batch Loss: 0.11901743710041046\n",
      "Epoch 3560, Loss: 0.5334947109222412, Final Batch Loss: 0.20822323858737946\n",
      "Epoch 3561, Loss: 0.5229519009590149, Final Batch Loss: 0.16216860711574554\n",
      "Epoch 3562, Loss: 0.5650897175073624, Final Batch Loss: 0.27583202719688416\n",
      "Epoch 3563, Loss: 0.4334803596138954, Final Batch Loss: 0.18936322629451752\n",
      "Epoch 3564, Loss: 0.3848031237721443, Final Batch Loss: 0.09565465897321701\n",
      "Epoch 3565, Loss: 0.4088321775197983, Final Batch Loss: 0.13943342864513397\n",
      "Epoch 3566, Loss: 0.37590956687927246, Final Batch Loss: 0.1256479024887085\n",
      "Epoch 3567, Loss: 0.5124664753675461, Final Batch Loss: 0.14125452935695648\n",
      "Epoch 3568, Loss: 0.4819819778203964, Final Batch Loss: 0.17277392745018005\n",
      "Epoch 3569, Loss: 0.5551208108663559, Final Batch Loss: 0.17616969347000122\n",
      "Epoch 3570, Loss: 0.417288675904274, Final Batch Loss: 0.13506397604942322\n",
      "Epoch 3571, Loss: 0.44693276286125183, Final Batch Loss: 0.15007388591766357\n",
      "Epoch 3572, Loss: 0.5075682923197746, Final Batch Loss: 0.11361560970544815\n",
      "Epoch 3573, Loss: 0.40657442808151245, Final Batch Loss: 0.13686391711235046\n",
      "Epoch 3574, Loss: 0.38494014739990234, Final Batch Loss: 0.10462599992752075\n",
      "Epoch 3575, Loss: 0.40792403370141983, Final Batch Loss: 0.1621048003435135\n",
      "Epoch 3576, Loss: 0.559766873717308, Final Batch Loss: 0.19134825468063354\n",
      "Epoch 3577, Loss: 0.596198782324791, Final Batch Loss: 0.1501096934080124\n",
      "Epoch 3578, Loss: 0.35817740485072136, Final Batch Loss: 0.056685131043195724\n",
      "Epoch 3579, Loss: 0.5837672054767609, Final Batch Loss: 0.2173183411359787\n",
      "Epoch 3580, Loss: 0.45395927131175995, Final Batch Loss: 0.14974702894687653\n",
      "Epoch 3581, Loss: 0.4986221343278885, Final Batch Loss: 0.15899579226970673\n",
      "Epoch 3582, Loss: 0.3970353752374649, Final Batch Loss: 0.11529356241226196\n",
      "Epoch 3583, Loss: 0.4748935028910637, Final Batch Loss: 0.11317373067140579\n",
      "Epoch 3584, Loss: 0.3652595281600952, Final Batch Loss: 0.09524352848529816\n",
      "Epoch 3585, Loss: 0.5493644028902054, Final Batch Loss: 0.17825046181678772\n",
      "Epoch 3586, Loss: 0.41703200340270996, Final Batch Loss: 0.09981924295425415\n",
      "Epoch 3587, Loss: 0.6159375309944153, Final Batch Loss: 0.24679245054721832\n",
      "Epoch 3588, Loss: 0.5059545040130615, Final Batch Loss: 0.17986291646957397\n",
      "Epoch 3589, Loss: 0.4814768433570862, Final Batch Loss: 0.22628146409988403\n",
      "Epoch 3590, Loss: 0.47782741487026215, Final Batch Loss: 0.1383967101573944\n",
      "Epoch 3591, Loss: 0.47553611546754837, Final Batch Loss: 0.09843321889638901\n",
      "Epoch 3592, Loss: 0.46561211347579956, Final Batch Loss: 0.15369457006454468\n",
      "Epoch 3593, Loss: 0.5895048528909683, Final Batch Loss: 0.24276503920555115\n",
      "Epoch 3594, Loss: 0.44121209532022476, Final Batch Loss: 0.12017206102609634\n",
      "Epoch 3595, Loss: 0.5120960026979446, Final Batch Loss: 0.17867106199264526\n",
      "Epoch 3596, Loss: 0.42939935624599457, Final Batch Loss: 0.1382121741771698\n",
      "Epoch 3597, Loss: 0.5442216470837593, Final Batch Loss: 0.264945387840271\n",
      "Epoch 3598, Loss: 0.4880864769220352, Final Batch Loss: 0.14372004568576813\n",
      "Epoch 3599, Loss: 0.46162066608667374, Final Batch Loss: 0.10423415154218674\n",
      "Epoch 3600, Loss: 0.4278459995985031, Final Batch Loss: 0.12785276770591736\n",
      "Epoch 3601, Loss: 0.48985330760478973, Final Batch Loss: 0.1874297857284546\n",
      "Epoch 3602, Loss: 0.49709151685237885, Final Batch Loss: 0.22477152943611145\n",
      "Epoch 3603, Loss: 0.5692322701215744, Final Batch Loss: 0.18046730756759644\n",
      "Epoch 3604, Loss: 0.5158338695764542, Final Batch Loss: 0.17320314049720764\n",
      "Epoch 3605, Loss: 0.649557814002037, Final Batch Loss: 0.2578662931919098\n",
      "Epoch 3606, Loss: 0.5085975378751755, Final Batch Loss: 0.12804512679576874\n",
      "Epoch 3607, Loss: 0.5647010207176208, Final Batch Loss: 0.21674753725528717\n",
      "Epoch 3608, Loss: 0.44300732016563416, Final Batch Loss: 0.14116404950618744\n",
      "Epoch 3609, Loss: 0.4171890616416931, Final Batch Loss: 0.12551186978816986\n",
      "Epoch 3610, Loss: 0.481485053896904, Final Batch Loss: 0.1720971167087555\n",
      "Epoch 3611, Loss: 0.492846742272377, Final Batch Loss: 0.1178348958492279\n",
      "Epoch 3612, Loss: 0.38152553886175156, Final Batch Loss: 0.1314210593700409\n",
      "Epoch 3613, Loss: 0.5244252383708954, Final Batch Loss: 0.19418436288833618\n",
      "Epoch 3614, Loss: 0.39800070971250534, Final Batch Loss: 0.10836172848939896\n",
      "Epoch 3615, Loss: 0.4906984120607376, Final Batch Loss: 0.0990278571844101\n",
      "Epoch 3616, Loss: 0.4812825322151184, Final Batch Loss: 0.15330463647842407\n",
      "Epoch 3617, Loss: 0.5031340792775154, Final Batch Loss: 0.2464728057384491\n",
      "Epoch 3618, Loss: 0.4679137319326401, Final Batch Loss: 0.18533892929553986\n",
      "Epoch 3619, Loss: 0.4290076941251755, Final Batch Loss: 0.10186594724655151\n",
      "Epoch 3620, Loss: 0.6187963038682938, Final Batch Loss: 0.26157671213150024\n",
      "Epoch 3621, Loss: 0.460700660943985, Final Batch Loss: 0.16499289870262146\n",
      "Epoch 3622, Loss: 0.4860735535621643, Final Batch Loss: 0.19660255312919617\n",
      "Epoch 3623, Loss: 0.4608666002750397, Final Batch Loss: 0.15980975329875946\n",
      "Epoch 3624, Loss: 0.484530970454216, Final Batch Loss: 0.1771046668291092\n",
      "Epoch 3625, Loss: 0.5779142826795578, Final Batch Loss: 0.2268780767917633\n",
      "Epoch 3626, Loss: 0.6001995354890823, Final Batch Loss: 0.2669960558414459\n",
      "Epoch 3627, Loss: 0.4703165292739868, Final Batch Loss: 0.14678823947906494\n",
      "Epoch 3628, Loss: 0.47213412821292877, Final Batch Loss: 0.14513403177261353\n",
      "Epoch 3629, Loss: 0.49342086911201477, Final Batch Loss: 0.13827736675739288\n",
      "Epoch 3630, Loss: 0.5777552276849747, Final Batch Loss: 0.16768181324005127\n",
      "Epoch 3631, Loss: 0.5275200679898262, Final Batch Loss: 0.20752330124378204\n",
      "Epoch 3632, Loss: 0.48593689501285553, Final Batch Loss: 0.17133475840091705\n",
      "Epoch 3633, Loss: 0.4779282659292221, Final Batch Loss: 0.14468726515769958\n",
      "Epoch 3634, Loss: 0.4339519664645195, Final Batch Loss: 0.09984780102968216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3635, Loss: 0.47705475986003876, Final Batch Loss: 0.15735375881195068\n",
      "Epoch 3636, Loss: 0.42370161414146423, Final Batch Loss: 0.12715446949005127\n",
      "Epoch 3637, Loss: 0.5542075783014297, Final Batch Loss: 0.2347303032875061\n",
      "Epoch 3638, Loss: 0.45450907200574875, Final Batch Loss: 0.08312638849020004\n",
      "Epoch 3639, Loss: 0.5015858262777328, Final Batch Loss: 0.20470044016838074\n",
      "Epoch 3640, Loss: 0.4948164373636246, Final Batch Loss: 0.18745918571949005\n",
      "Epoch 3641, Loss: 0.5026964545249939, Final Batch Loss: 0.16293908655643463\n",
      "Epoch 3642, Loss: 0.46041131764650345, Final Batch Loss: 0.10839986056089401\n",
      "Epoch 3643, Loss: 0.3771144151687622, Final Batch Loss: 0.07767841964960098\n",
      "Epoch 3644, Loss: 0.50480817258358, Final Batch Loss: 0.18301647901535034\n",
      "Epoch 3645, Loss: 0.5129644125699997, Final Batch Loss: 0.20301169157028198\n",
      "Epoch 3646, Loss: 0.39647141098976135, Final Batch Loss: 0.12770062685012817\n",
      "Epoch 3647, Loss: 0.45905178785324097, Final Batch Loss: 0.15062455832958221\n",
      "Epoch 3648, Loss: 0.521183505654335, Final Batch Loss: 0.1307276040315628\n",
      "Epoch 3649, Loss: 0.42448441684246063, Final Batch Loss: 0.14434632658958435\n",
      "Epoch 3650, Loss: 0.4603138864040375, Final Batch Loss: 0.1788090467453003\n",
      "Epoch 3651, Loss: 0.5149926394224167, Final Batch Loss: 0.194203719496727\n",
      "Epoch 3652, Loss: 0.43707944452762604, Final Batch Loss: 0.16933119297027588\n",
      "Epoch 3653, Loss: 0.43346523493528366, Final Batch Loss: 0.16391287744045258\n",
      "Epoch 3654, Loss: 0.5316047519445419, Final Batch Loss: 0.22044676542282104\n",
      "Epoch 3655, Loss: 0.5890206843614578, Final Batch Loss: 0.24841730296611786\n",
      "Epoch 3656, Loss: 0.4821305498480797, Final Batch Loss: 0.2013225108385086\n",
      "Epoch 3657, Loss: 0.47482337057590485, Final Batch Loss: 0.14708714187145233\n",
      "Epoch 3658, Loss: 0.37658897042274475, Final Batch Loss: 0.08652912080287933\n",
      "Epoch 3659, Loss: 0.5181933641433716, Final Batch Loss: 0.20550261437892914\n",
      "Epoch 3660, Loss: 0.43989527225494385, Final Batch Loss: 0.11946415901184082\n",
      "Epoch 3661, Loss: 0.5034691467881203, Final Batch Loss: 0.13589677214622498\n",
      "Epoch 3662, Loss: 0.5153511315584183, Final Batch Loss: 0.20028644800186157\n",
      "Epoch 3663, Loss: 0.45797787606716156, Final Batch Loss: 0.16100160777568817\n",
      "Epoch 3664, Loss: 0.49078477919101715, Final Batch Loss: 0.16272705793380737\n",
      "Epoch 3665, Loss: 0.5380047708749771, Final Batch Loss: 0.22143936157226562\n",
      "Epoch 3666, Loss: 0.46324513852596283, Final Batch Loss: 0.15239101648330688\n",
      "Epoch 3667, Loss: 0.49951377511024475, Final Batch Loss: 0.2325601875782013\n",
      "Epoch 3668, Loss: 0.465598925948143, Final Batch Loss: 0.1474706530570984\n",
      "Epoch 3669, Loss: 0.5586853474378586, Final Batch Loss: 0.16846570372581482\n",
      "Epoch 3670, Loss: 0.5579518303275108, Final Batch Loss: 0.2379709631204605\n",
      "Epoch 3671, Loss: 0.44375329464673996, Final Batch Loss: 0.15951555967330933\n",
      "Epoch 3672, Loss: 0.5218506157398224, Final Batch Loss: 0.12594906985759735\n",
      "Epoch 3673, Loss: 0.4822133332490921, Final Batch Loss: 0.13014976680278778\n",
      "Epoch 3674, Loss: 0.541163370013237, Final Batch Loss: 0.16311508417129517\n",
      "Epoch 3675, Loss: 0.4174964278936386, Final Batch Loss: 0.10139976441860199\n",
      "Epoch 3676, Loss: 0.3794272765517235, Final Batch Loss: 0.09196912497282028\n",
      "Epoch 3677, Loss: 0.48144765198230743, Final Batch Loss: 0.14448599517345428\n",
      "Epoch 3678, Loss: 0.5161961615085602, Final Batch Loss: 0.2067360281944275\n",
      "Epoch 3679, Loss: 0.48459287732839584, Final Batch Loss: 0.11085430532693863\n",
      "Epoch 3680, Loss: 0.46433573961257935, Final Batch Loss: 0.19522735476493835\n",
      "Epoch 3681, Loss: 0.4824869781732559, Final Batch Loss: 0.10153812170028687\n",
      "Epoch 3682, Loss: 0.49159662425518036, Final Batch Loss: 0.23029328882694244\n",
      "Epoch 3683, Loss: 0.439445823431015, Final Batch Loss: 0.17796902358531952\n",
      "Epoch 3684, Loss: 0.39898114651441574, Final Batch Loss: 0.14765411615371704\n",
      "Epoch 3685, Loss: 0.43750129640102386, Final Batch Loss: 0.12079130113124847\n",
      "Epoch 3686, Loss: 0.3932366967201233, Final Batch Loss: 0.1896747499704361\n",
      "Epoch 3687, Loss: 0.450564369559288, Final Batch Loss: 0.16047847270965576\n",
      "Epoch 3688, Loss: 0.49807627499103546, Final Batch Loss: 0.16992327570915222\n",
      "Epoch 3689, Loss: 0.49409378319978714, Final Batch Loss: 0.17648108303546906\n",
      "Epoch 3690, Loss: 0.45064281672239304, Final Batch Loss: 0.13870780169963837\n",
      "Epoch 3691, Loss: 0.4272494539618492, Final Batch Loss: 0.1117250993847847\n",
      "Epoch 3692, Loss: 0.4274704232811928, Final Batch Loss: 0.17486268281936646\n",
      "Epoch 3693, Loss: 0.3743979185819626, Final Batch Loss: 0.13180476427078247\n",
      "Epoch 3694, Loss: 0.38792524486780167, Final Batch Loss: 0.0971694216132164\n",
      "Epoch 3695, Loss: 0.3907860070466995, Final Batch Loss: 0.10156673192977905\n",
      "Epoch 3696, Loss: 0.5181011855602264, Final Batch Loss: 0.11180680990219116\n",
      "Epoch 3697, Loss: 0.4773997366428375, Final Batch Loss: 0.1782413125038147\n",
      "Epoch 3698, Loss: 0.39291903376579285, Final Batch Loss: 0.12782514095306396\n",
      "Epoch 3699, Loss: 0.518963947892189, Final Batch Loss: 0.2051771581172943\n",
      "Epoch 3700, Loss: 0.5402911305427551, Final Batch Loss: 0.23866508901119232\n",
      "Epoch 3701, Loss: 0.4232979416847229, Final Batch Loss: 0.1242654025554657\n",
      "Epoch 3702, Loss: 0.4650474637746811, Final Batch Loss: 0.1985960304737091\n",
      "Epoch 3703, Loss: 0.4628998637199402, Final Batch Loss: 0.09721517562866211\n",
      "Epoch 3704, Loss: 0.4712374806404114, Final Batch Loss: 0.15964777767658234\n",
      "Epoch 3705, Loss: 0.4149637594819069, Final Batch Loss: 0.1004323735833168\n",
      "Epoch 3706, Loss: 0.5657385140657425, Final Batch Loss: 0.2072606086730957\n",
      "Epoch 3707, Loss: 0.5006254464387894, Final Batch Loss: 0.1638536900281906\n",
      "Epoch 3708, Loss: 0.6117092370986938, Final Batch Loss: 0.24327941238880157\n",
      "Epoch 3709, Loss: 0.4038078561425209, Final Batch Loss: 0.1920180469751358\n",
      "Epoch 3710, Loss: 0.4898330494761467, Final Batch Loss: 0.09890327602624893\n",
      "Epoch 3711, Loss: 0.4341812878847122, Final Batch Loss: 0.16726812720298767\n",
      "Epoch 3712, Loss: 0.5386423319578171, Final Batch Loss: 0.18232886493206024\n",
      "Epoch 3713, Loss: 0.5556196123361588, Final Batch Loss: 0.22733385860919952\n",
      "Epoch 3714, Loss: 0.47745147347450256, Final Batch Loss: 0.1396203637123108\n",
      "Epoch 3715, Loss: 0.3837182745337486, Final Batch Loss: 0.09199937433004379\n",
      "Epoch 3716, Loss: 0.3557219132781029, Final Batch Loss: 0.1300407201051712\n",
      "Epoch 3717, Loss: 0.47183702886104584, Final Batch Loss: 0.1581861525774002\n",
      "Epoch 3718, Loss: 0.4717971235513687, Final Batch Loss: 0.11193418502807617\n",
      "Epoch 3719, Loss: 0.46643298864364624, Final Batch Loss: 0.19519677758216858\n",
      "Epoch 3720, Loss: 0.4236403629183769, Final Batch Loss: 0.08131466060876846\n",
      "Epoch 3721, Loss: 0.42491598427295685, Final Batch Loss: 0.11809161305427551\n",
      "Epoch 3722, Loss: 0.39998751133680344, Final Batch Loss: 0.14120109379291534\n",
      "Epoch 3723, Loss: 0.427155539393425, Final Batch Loss: 0.09826399385929108\n",
      "Epoch 3724, Loss: 0.3963124230504036, Final Batch Loss: 0.1028081551194191\n",
      "Epoch 3725, Loss: 0.49385515600442886, Final Batch Loss: 0.19642606377601624\n",
      "Epoch 3726, Loss: 0.40545935183763504, Final Batch Loss: 0.16733382642269135\n",
      "Epoch 3727, Loss: 0.4525429457426071, Final Batch Loss: 0.1375875622034073\n",
      "Epoch 3728, Loss: 0.4007163867354393, Final Batch Loss: 0.1322479546070099\n",
      "Epoch 3729, Loss: 0.38269903510808945, Final Batch Loss: 0.13315634429454803\n",
      "Epoch 3730, Loss: 0.4465372860431671, Final Batch Loss: 0.18359149992465973\n",
      "Epoch 3731, Loss: 0.41581620275974274, Final Batch Loss: 0.12947304546833038\n",
      "Epoch 3732, Loss: 0.4593873471021652, Final Batch Loss: 0.11444070935249329\n",
      "Epoch 3733, Loss: 0.4506911039352417, Final Batch Loss: 0.12619400024414062\n",
      "Epoch 3734, Loss: 0.43773726373910904, Final Batch Loss: 0.11531160026788712\n",
      "Epoch 3735, Loss: 0.47477061301469803, Final Batch Loss: 0.23323409259319305\n",
      "Epoch 3736, Loss: 0.5333130359649658, Final Batch Loss: 0.2076369673013687\n",
      "Epoch 3737, Loss: 0.509751707315445, Final Batch Loss: 0.13773341476917267\n",
      "Epoch 3738, Loss: 0.48087678849697113, Final Batch Loss: 0.1766418069601059\n",
      "Epoch 3739, Loss: 0.4925289899110794, Final Batch Loss: 0.14486928284168243\n",
      "Epoch 3740, Loss: 0.5149310156702995, Final Batch Loss: 0.1797957420349121\n",
      "Epoch 3741, Loss: 0.3908543139696121, Final Batch Loss: 0.09435850381851196\n",
      "Epoch 3742, Loss: 0.42970670759677887, Final Batch Loss: 0.13945335149765015\n",
      "Epoch 3743, Loss: 0.5085764974355698, Final Batch Loss: 0.19284144043922424\n",
      "Epoch 3744, Loss: 0.3920408710837364, Final Batch Loss: 0.08726022392511368\n",
      "Epoch 3745, Loss: 0.3878885731101036, Final Batch Loss: 0.11880456656217575\n",
      "Epoch 3746, Loss: 0.485181599855423, Final Batch Loss: 0.18298931419849396\n",
      "Epoch 3747, Loss: 0.36197975277900696, Final Batch Loss: 0.1170632392168045\n",
      "Epoch 3748, Loss: 0.44311853498220444, Final Batch Loss: 0.10893320292234421\n",
      "Epoch 3749, Loss: 0.5107662975788116, Final Batch Loss: 0.1490294337272644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3750, Loss: 0.5044569671154022, Final Batch Loss: 0.1275903582572937\n",
      "Epoch 3751, Loss: 0.443581722676754, Final Batch Loss: 0.11449763923883438\n",
      "Epoch 3752, Loss: 0.4821169674396515, Final Batch Loss: 0.16821961104869843\n",
      "Epoch 3753, Loss: 0.386092834174633, Final Batch Loss: 0.16106319427490234\n",
      "Epoch 3754, Loss: 0.5447782725095749, Final Batch Loss: 0.1649022251367569\n",
      "Epoch 3755, Loss: 0.4243399649858475, Final Batch Loss: 0.13134825229644775\n",
      "Epoch 3756, Loss: 0.5926089286804199, Final Batch Loss: 0.222892627120018\n",
      "Epoch 3757, Loss: 0.41452428698539734, Final Batch Loss: 0.11740003526210785\n",
      "Epoch 3758, Loss: 0.44675055146217346, Final Batch Loss: 0.16484133899211884\n",
      "Epoch 3759, Loss: 0.4977511167526245, Final Batch Loss: 0.18219371140003204\n",
      "Epoch 3760, Loss: 0.5240060091018677, Final Batch Loss: 0.18371474742889404\n",
      "Epoch 3761, Loss: 0.416701003909111, Final Batch Loss: 0.13542252779006958\n",
      "Epoch 3762, Loss: 0.4702892005443573, Final Batch Loss: 0.13157770037651062\n",
      "Epoch 3763, Loss: 0.5756546854972839, Final Batch Loss: 0.24727503955364227\n",
      "Epoch 3764, Loss: 0.47144558280706406, Final Batch Loss: 0.07892628759145737\n",
      "Epoch 3765, Loss: 0.3943735733628273, Final Batch Loss: 0.11942952871322632\n",
      "Epoch 3766, Loss: 0.3268984332680702, Final Batch Loss: 0.1057848185300827\n",
      "Epoch 3767, Loss: 0.4263397082686424, Final Batch Loss: 0.18304339051246643\n",
      "Epoch 3768, Loss: 0.46343299746513367, Final Batch Loss: 0.17776520550251007\n",
      "Epoch 3769, Loss: 0.41412685811519623, Final Batch Loss: 0.12761004269123077\n",
      "Epoch 3770, Loss: 0.5526013523340225, Final Batch Loss: 0.16287699341773987\n",
      "Epoch 3771, Loss: 0.47094549983739853, Final Batch Loss: 0.1176883652806282\n",
      "Epoch 3772, Loss: 0.4415587782859802, Final Batch Loss: 0.12173895537853241\n",
      "Epoch 3773, Loss: 0.5478208512067795, Final Batch Loss: 0.13996818661689758\n",
      "Epoch 3774, Loss: 0.4496728777885437, Final Batch Loss: 0.11557118594646454\n",
      "Epoch 3775, Loss: 0.5727440863847733, Final Batch Loss: 0.2323649376630783\n",
      "Epoch 3776, Loss: 0.506991907954216, Final Batch Loss: 0.1782788187265396\n",
      "Epoch 3777, Loss: 0.48654644191265106, Final Batch Loss: 0.1362120509147644\n",
      "Epoch 3778, Loss: 0.4903477430343628, Final Batch Loss: 0.21763096749782562\n",
      "Epoch 3779, Loss: 0.5858703553676605, Final Batch Loss: 0.2558160722255707\n",
      "Epoch 3780, Loss: 0.36199603229761124, Final Batch Loss: 0.13300158083438873\n",
      "Epoch 3781, Loss: 0.4353006035089493, Final Batch Loss: 0.14641952514648438\n",
      "Epoch 3782, Loss: 0.4546719193458557, Final Batch Loss: 0.1362767070531845\n",
      "Epoch 3783, Loss: 0.6186192035675049, Final Batch Loss: 0.30932503938674927\n",
      "Epoch 3784, Loss: 0.4194679856300354, Final Batch Loss: 0.1396895796060562\n",
      "Epoch 3785, Loss: 0.4338819235563278, Final Batch Loss: 0.141582190990448\n",
      "Epoch 3786, Loss: 0.45710141956806183, Final Batch Loss: 0.0918535441160202\n",
      "Epoch 3787, Loss: 0.4853079915046692, Final Batch Loss: 0.15291225910186768\n",
      "Epoch 3788, Loss: 0.42159540206193924, Final Batch Loss: 0.12043476104736328\n",
      "Epoch 3789, Loss: 0.5186769366264343, Final Batch Loss: 0.15007920563220978\n",
      "Epoch 3790, Loss: 0.423494428396225, Final Batch Loss: 0.09218883514404297\n",
      "Epoch 3791, Loss: 0.568904459476471, Final Batch Loss: 0.2763282060623169\n",
      "Epoch 3792, Loss: 0.4618157222867012, Final Batch Loss: 0.1588665246963501\n",
      "Epoch 3793, Loss: 0.46891868859529495, Final Batch Loss: 0.10599435120820999\n",
      "Epoch 3794, Loss: 0.4766869992017746, Final Batch Loss: 0.188409686088562\n",
      "Epoch 3795, Loss: 0.4692161902785301, Final Batch Loss: 0.1889512985944748\n",
      "Epoch 3796, Loss: 0.5074705109000206, Final Batch Loss: 0.21077461540699005\n",
      "Epoch 3797, Loss: 0.48635852336883545, Final Batch Loss: 0.13467156887054443\n",
      "Epoch 3798, Loss: 0.4803796112537384, Final Batch Loss: 0.11324505507946014\n",
      "Epoch 3799, Loss: 0.6176798641681671, Final Batch Loss: 0.21516290307044983\n",
      "Epoch 3800, Loss: 0.5082771331071854, Final Batch Loss: 0.1445593535900116\n",
      "Epoch 3801, Loss: 0.5004292577505112, Final Batch Loss: 0.19312474131584167\n",
      "Epoch 3802, Loss: 0.42760687321424484, Final Batch Loss: 0.1212398037314415\n",
      "Epoch 3803, Loss: 0.4945822060108185, Final Batch Loss: 0.18493027985095978\n",
      "Epoch 3804, Loss: 0.5470584183931351, Final Batch Loss: 0.1500462293624878\n",
      "Epoch 3805, Loss: 0.40512529015541077, Final Batch Loss: 0.14998437464237213\n",
      "Epoch 3806, Loss: 0.5137865096330643, Final Batch Loss: 0.17984597384929657\n",
      "Epoch 3807, Loss: 0.5818827301263809, Final Batch Loss: 0.21188293397426605\n",
      "Epoch 3808, Loss: 0.5481822937726974, Final Batch Loss: 0.15325003862380981\n",
      "Epoch 3809, Loss: 0.5519296079874039, Final Batch Loss: 0.2327217161655426\n",
      "Epoch 3810, Loss: 0.5461446940898895, Final Batch Loss: 0.17123137414455414\n",
      "Epoch 3811, Loss: 0.49696969985961914, Final Batch Loss: 0.15198029577732086\n",
      "Epoch 3812, Loss: 0.46630752086639404, Final Batch Loss: 0.15047237277030945\n",
      "Epoch 3813, Loss: 0.506899893283844, Final Batch Loss: 0.15383514761924744\n",
      "Epoch 3814, Loss: 0.46273742616176605, Final Batch Loss: 0.1322905272245407\n",
      "Epoch 3815, Loss: 0.4262184724211693, Final Batch Loss: 0.19189034402370453\n",
      "Epoch 3816, Loss: 0.43482062220573425, Final Batch Loss: 0.16096092760562897\n",
      "Epoch 3817, Loss: 0.45824697613716125, Final Batch Loss: 0.13459070026874542\n",
      "Epoch 3818, Loss: 0.3913456127047539, Final Batch Loss: 0.10433616489171982\n",
      "Epoch 3819, Loss: 0.45551350712776184, Final Batch Loss: 0.175634503364563\n",
      "Epoch 3820, Loss: 0.4612869471311569, Final Batch Loss: 0.15104027092456818\n",
      "Epoch 3821, Loss: 0.43990589678287506, Final Batch Loss: 0.14403805136680603\n",
      "Epoch 3822, Loss: 0.3815755024552345, Final Batch Loss: 0.09698916226625443\n",
      "Epoch 3823, Loss: 0.5252065062522888, Final Batch Loss: 0.11588136851787567\n",
      "Epoch 3824, Loss: 0.4576127529144287, Final Batch Loss: 0.1610766053199768\n",
      "Epoch 3825, Loss: 0.387628510594368, Final Batch Loss: 0.1140887662768364\n",
      "Epoch 3826, Loss: 0.49860818684101105, Final Batch Loss: 0.1414954960346222\n",
      "Epoch 3827, Loss: 0.48648596554994583, Final Batch Loss: 0.15976093709468842\n",
      "Epoch 3828, Loss: 0.7235361188650131, Final Batch Loss: 0.419838547706604\n",
      "Epoch 3829, Loss: 0.5786217749118805, Final Batch Loss: 0.25717291235923767\n",
      "Epoch 3830, Loss: 0.5000105798244476, Final Batch Loss: 0.19037380814552307\n",
      "Epoch 3831, Loss: 0.45947757363319397, Final Batch Loss: 0.10636742413043976\n",
      "Epoch 3832, Loss: 0.41600681841373444, Final Batch Loss: 0.046149179339408875\n",
      "Epoch 3833, Loss: 0.46902261674404144, Final Batch Loss: 0.13186439871788025\n",
      "Epoch 3834, Loss: 0.5150939524173737, Final Batch Loss: 0.18850067257881165\n",
      "Epoch 3835, Loss: 0.5568450838327408, Final Batch Loss: 0.19908742606639862\n",
      "Epoch 3836, Loss: 0.5467051118612289, Final Batch Loss: 0.16095753014087677\n",
      "Epoch 3837, Loss: 0.413979671895504, Final Batch Loss: 0.12255657464265823\n",
      "Epoch 3838, Loss: 0.40514957904815674, Final Batch Loss: 0.13898493349552155\n",
      "Epoch 3839, Loss: 0.45910126715898514, Final Batch Loss: 0.12478750199079514\n",
      "Epoch 3840, Loss: 0.4457310810685158, Final Batch Loss: 0.1848628968000412\n",
      "Epoch 3841, Loss: 0.44754811376333237, Final Batch Loss: 0.08833371847867966\n",
      "Epoch 3842, Loss: 0.4577479809522629, Final Batch Loss: 0.1472385972738266\n",
      "Epoch 3843, Loss: 0.4455457031726837, Final Batch Loss: 0.13851593434810638\n",
      "Epoch 3844, Loss: 0.5001024603843689, Final Batch Loss: 0.16126537322998047\n",
      "Epoch 3845, Loss: 0.5403076782822609, Final Batch Loss: 0.251618891954422\n",
      "Epoch 3846, Loss: 0.4922226667404175, Final Batch Loss: 0.15964601933956146\n",
      "Epoch 3847, Loss: 0.42725570499897003, Final Batch Loss: 0.14636912941932678\n",
      "Epoch 3848, Loss: 0.3596538081765175, Final Batch Loss: 0.12415854632854462\n",
      "Epoch 3849, Loss: 0.4383234903216362, Final Batch Loss: 0.13011641800403595\n",
      "Epoch 3850, Loss: 0.4743807911872864, Final Batch Loss: 0.15259291231632233\n",
      "Epoch 3851, Loss: 0.48057354986667633, Final Batch Loss: 0.1343510001897812\n",
      "Epoch 3852, Loss: 0.422684945166111, Final Batch Loss: 0.09699693322181702\n",
      "Epoch 3853, Loss: 0.5227711796760559, Final Batch Loss: 0.22495637834072113\n",
      "Epoch 3854, Loss: 0.4412910044193268, Final Batch Loss: 0.1694353073835373\n",
      "Epoch 3855, Loss: 0.39990437775850296, Final Batch Loss: 0.17680011689662933\n",
      "Epoch 3856, Loss: 0.3673037737607956, Final Batch Loss: 0.1183379665017128\n",
      "Epoch 3857, Loss: 0.4836226552724838, Final Batch Loss: 0.1554815173149109\n",
      "Epoch 3858, Loss: 0.4494542181491852, Final Batch Loss: 0.1684558093547821\n",
      "Epoch 3859, Loss: 0.5167525857686996, Final Batch Loss: 0.22998680174350739\n",
      "Epoch 3860, Loss: 0.5102633088827133, Final Batch Loss: 0.13753080368041992\n",
      "Epoch 3861, Loss: 0.4793389067053795, Final Batch Loss: 0.0646124854683876\n",
      "Epoch 3862, Loss: 0.39792750030755997, Final Batch Loss: 0.1354590356349945\n",
      "Epoch 3863, Loss: 0.4947303682565689, Final Batch Loss: 0.17269881069660187\n",
      "Epoch 3864, Loss: 0.48447538912296295, Final Batch Loss: 0.14523731172084808\n",
      "Epoch 3865, Loss: 0.45965810865163803, Final Batch Loss: 0.09436433762311935\n",
      "Epoch 3866, Loss: 0.6112791001796722, Final Batch Loss: 0.22397978603839874\n",
      "Epoch 3867, Loss: 0.47664643824100494, Final Batch Loss: 0.2165985405445099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3868, Loss: 0.47386766225099564, Final Batch Loss: 0.19574621319770813\n",
      "Epoch 3869, Loss: 0.5780435651540756, Final Batch Loss: 0.18205447494983673\n",
      "Epoch 3870, Loss: 0.5156051963567734, Final Batch Loss: 0.15608368813991547\n",
      "Epoch 3871, Loss: 0.5238527953624725, Final Batch Loss: 0.17804141342639923\n",
      "Epoch 3872, Loss: 0.45194076001644135, Final Batch Loss: 0.1647673398256302\n",
      "Epoch 3873, Loss: 0.4910079166293144, Final Batch Loss: 0.15818090736865997\n",
      "Epoch 3874, Loss: 0.48323312401771545, Final Batch Loss: 0.1474693864583969\n",
      "Epoch 3875, Loss: 0.4963092505931854, Final Batch Loss: 0.1477842628955841\n",
      "Epoch 3876, Loss: 0.49386870861053467, Final Batch Loss: 0.17342215776443481\n",
      "Epoch 3877, Loss: 0.4006524235010147, Final Batch Loss: 0.1530727595090866\n",
      "Epoch 3878, Loss: 0.38606420904397964, Final Batch Loss: 0.11273019015789032\n",
      "Epoch 3879, Loss: 0.6175419464707375, Final Batch Loss: 0.3940799832344055\n",
      "Epoch 3880, Loss: 0.6407052278518677, Final Batch Loss: 0.31360888481140137\n",
      "Epoch 3881, Loss: 0.5897497236728668, Final Batch Loss: 0.14816823601722717\n",
      "Epoch 3882, Loss: 0.4586388170719147, Final Batch Loss: 0.1458553969860077\n",
      "Epoch 3883, Loss: 0.4635291174054146, Final Batch Loss: 0.12263978272676468\n",
      "Epoch 3884, Loss: 0.44970376789569855, Final Batch Loss: 0.14750197529792786\n",
      "Epoch 3885, Loss: 0.539364367723465, Final Batch Loss: 0.19672483205795288\n",
      "Epoch 3886, Loss: 0.46896645426750183, Final Batch Loss: 0.17881810665130615\n",
      "Epoch 3887, Loss: 0.49294501543045044, Final Batch Loss: 0.15710878372192383\n",
      "Epoch 3888, Loss: 0.44086529314517975, Final Batch Loss: 0.1634645164012909\n",
      "Epoch 3889, Loss: 0.5271161943674088, Final Batch Loss: 0.16391980648040771\n",
      "Epoch 3890, Loss: 0.42878154665231705, Final Batch Loss: 0.15733152627944946\n",
      "Epoch 3891, Loss: 0.47526074200868607, Final Batch Loss: 0.17049071192741394\n",
      "Epoch 3892, Loss: 0.5218632370233536, Final Batch Loss: 0.13792413473129272\n",
      "Epoch 3893, Loss: 0.41670579463243484, Final Batch Loss: 0.08826791495084763\n",
      "Epoch 3894, Loss: 0.4497758373618126, Final Batch Loss: 0.09999851137399673\n",
      "Epoch 3895, Loss: 0.5142362639307976, Final Batch Loss: 0.11744477599859238\n",
      "Epoch 3896, Loss: 0.5215689986944199, Final Batch Loss: 0.22305287420749664\n",
      "Epoch 3897, Loss: 0.4044181704521179, Final Batch Loss: 0.1860370635986328\n",
      "Epoch 3898, Loss: 0.4960051327943802, Final Batch Loss: 0.15583248436450958\n",
      "Epoch 3899, Loss: 0.4432305097579956, Final Batch Loss: 0.0852346420288086\n",
      "Epoch 3900, Loss: 0.5215772837400436, Final Batch Loss: 0.1583319455385208\n",
      "Epoch 3901, Loss: 0.4657311886548996, Final Batch Loss: 0.16225089132785797\n",
      "Epoch 3902, Loss: 0.4725956618785858, Final Batch Loss: 0.15552812814712524\n",
      "Epoch 3903, Loss: 0.39420562982559204, Final Batch Loss: 0.11926891654729843\n",
      "Epoch 3904, Loss: 0.5061410069465637, Final Batch Loss: 0.17873461544513702\n",
      "Epoch 3905, Loss: 0.5382276922464371, Final Batch Loss: 0.26123860478401184\n",
      "Epoch 3906, Loss: 0.38460923731327057, Final Batch Loss: 0.14038747549057007\n",
      "Epoch 3907, Loss: 0.4347325637936592, Final Batch Loss: 0.10745733231306076\n",
      "Epoch 3908, Loss: 0.5385838449001312, Final Batch Loss: 0.12687194347381592\n",
      "Epoch 3909, Loss: 0.39252177625894547, Final Batch Loss: 0.11991588026285172\n",
      "Epoch 3910, Loss: 0.47229716181755066, Final Batch Loss: 0.17339001595973969\n",
      "Epoch 3911, Loss: 0.45569904148578644, Final Batch Loss: 0.14030396938323975\n",
      "Epoch 3912, Loss: 0.37206774950027466, Final Batch Loss: 0.10373099893331528\n",
      "Epoch 3913, Loss: 0.5520203709602356, Final Batch Loss: 0.18571701645851135\n",
      "Epoch 3914, Loss: 0.6166118234395981, Final Batch Loss: 0.2609815299510956\n",
      "Epoch 3915, Loss: 0.4899122938513756, Final Batch Loss: 0.11063652485609055\n",
      "Epoch 3916, Loss: 0.4950512424111366, Final Batch Loss: 0.1811188906431198\n",
      "Epoch 3917, Loss: 0.5286751389503479, Final Batch Loss: 0.11833803355693817\n",
      "Epoch 3918, Loss: 0.570516049861908, Final Batch Loss: 0.21220189332962036\n",
      "Epoch 3919, Loss: 0.553805023431778, Final Batch Loss: 0.1832413226366043\n",
      "Epoch 3920, Loss: 0.464633971452713, Final Batch Loss: 0.16398906707763672\n",
      "Epoch 3921, Loss: 0.4351322203874588, Final Batch Loss: 0.14371372759342194\n",
      "Epoch 3922, Loss: 0.43312545120716095, Final Batch Loss: 0.1544393002986908\n",
      "Epoch 3923, Loss: 0.5599794685840607, Final Batch Loss: 0.1618407666683197\n",
      "Epoch 3924, Loss: 0.5129498839378357, Final Batch Loss: 0.15880849957466125\n",
      "Epoch 3925, Loss: 0.5999429821968079, Final Batch Loss: 0.26067498326301575\n",
      "Epoch 3926, Loss: 0.4889611303806305, Final Batch Loss: 0.23599126935005188\n",
      "Epoch 3927, Loss: 0.5108199864625931, Final Batch Loss: 0.1902678906917572\n",
      "Epoch 3928, Loss: 0.4498409777879715, Final Batch Loss: 0.13327935338020325\n",
      "Epoch 3929, Loss: 0.45145075768232346, Final Batch Loss: 0.19665567576885223\n",
      "Epoch 3930, Loss: 0.5122174024581909, Final Batch Loss: 0.1596924066543579\n",
      "Epoch 3931, Loss: 0.47799694538116455, Final Batch Loss: 0.16438265144824982\n",
      "Epoch 3932, Loss: 0.47047843039035797, Final Batch Loss: 0.17249761521816254\n",
      "Epoch 3933, Loss: 0.5251192599534988, Final Batch Loss: 0.20044288039207458\n",
      "Epoch 3934, Loss: 0.4812571331858635, Final Batch Loss: 0.21029894053936005\n",
      "Epoch 3935, Loss: 0.5776110142469406, Final Batch Loss: 0.27681058645248413\n",
      "Epoch 3936, Loss: 0.47210025042295456, Final Batch Loss: 0.11800950020551682\n",
      "Epoch 3937, Loss: 0.4590996950864792, Final Batch Loss: 0.1920277327299118\n",
      "Epoch 3938, Loss: 0.40766704827547073, Final Batch Loss: 0.10083945840597153\n",
      "Epoch 3939, Loss: 0.44368498027324677, Final Batch Loss: 0.11710315942764282\n",
      "Epoch 3940, Loss: 0.539669394493103, Final Batch Loss: 0.203237384557724\n",
      "Epoch 3941, Loss: 0.4916600286960602, Final Batch Loss: 0.23691536486148834\n",
      "Epoch 3942, Loss: 0.585845872759819, Final Batch Loss: 0.2249126434326172\n",
      "Epoch 3943, Loss: 0.38149046897888184, Final Batch Loss: 0.11879058927297592\n",
      "Epoch 3944, Loss: 0.49285484850406647, Final Batch Loss: 0.2054370790719986\n",
      "Epoch 3945, Loss: 0.39093901962041855, Final Batch Loss: 0.1408906728029251\n",
      "Epoch 3946, Loss: 0.40644974261522293, Final Batch Loss: 0.088620625436306\n",
      "Epoch 3947, Loss: 0.4317808598279953, Final Batch Loss: 0.139007106423378\n",
      "Epoch 3948, Loss: 0.434309221804142, Final Batch Loss: 0.12823446094989777\n",
      "Epoch 3949, Loss: 0.39382204413414, Final Batch Loss: 0.07953333854675293\n",
      "Epoch 3950, Loss: 0.4572245702147484, Final Batch Loss: 0.14374133944511414\n",
      "Epoch 3951, Loss: 0.4218050092458725, Final Batch Loss: 0.10445539653301239\n",
      "Epoch 3952, Loss: 0.5164816081523895, Final Batch Loss: 0.14906014502048492\n",
      "Epoch 3953, Loss: 0.40907521545886993, Final Batch Loss: 0.11700363457202911\n",
      "Epoch 3954, Loss: 0.5824950933456421, Final Batch Loss: 0.2933715283870697\n",
      "Epoch 3955, Loss: 0.47824452817440033, Final Batch Loss: 0.24698016047477722\n",
      "Epoch 3956, Loss: 0.5839674174785614, Final Batch Loss: 0.2587084472179413\n",
      "Epoch 3957, Loss: 0.5083446651697159, Final Batch Loss: 0.1342076063156128\n",
      "Epoch 3958, Loss: 0.5920689702033997, Final Batch Loss: 0.14950327575206757\n",
      "Epoch 3959, Loss: 0.5706851333379745, Final Batch Loss: 0.1548643857240677\n",
      "Epoch 3960, Loss: 0.4709954857826233, Final Batch Loss: 0.12361381947994232\n",
      "Epoch 3961, Loss: 0.5027175843715668, Final Batch Loss: 0.15438060462474823\n",
      "Epoch 3962, Loss: 0.5707408636808395, Final Batch Loss: 0.2485235035419464\n",
      "Epoch 3963, Loss: 0.444609098136425, Final Batch Loss: 0.11843592673540115\n",
      "Epoch 3964, Loss: 0.42119116336107254, Final Batch Loss: 0.10378871113061905\n",
      "Epoch 3965, Loss: 0.5132518857717514, Final Batch Loss: 0.12571869790554047\n",
      "Epoch 3966, Loss: 0.40123817324638367, Final Batch Loss: 0.16765253245830536\n",
      "Epoch 3967, Loss: 0.43202903121709824, Final Batch Loss: 0.19096727669239044\n",
      "Epoch 3968, Loss: 0.37477682530879974, Final Batch Loss: 0.1014600396156311\n",
      "Epoch 3969, Loss: 0.4370197504758835, Final Batch Loss: 0.12036524713039398\n",
      "Epoch 3970, Loss: 0.43080900609493256, Final Batch Loss: 0.13054274022579193\n",
      "Epoch 3971, Loss: 0.38435541093349457, Final Batch Loss: 0.08689889311790466\n",
      "Epoch 3972, Loss: 0.3822038248181343, Final Batch Loss: 0.130408376455307\n",
      "Epoch 3973, Loss: 0.4500269442796707, Final Batch Loss: 0.08083528280258179\n",
      "Epoch 3974, Loss: 0.5364807546138763, Final Batch Loss: 0.1569540649652481\n",
      "Epoch 3975, Loss: 0.4472656697034836, Final Batch Loss: 0.10763289034366608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3976, Loss: 0.41195790469646454, Final Batch Loss: 0.09696419537067413\n",
      "Epoch 3977, Loss: 0.39839453250169754, Final Batch Loss: 0.09643783420324326\n",
      "Epoch 3978, Loss: 0.5113970190286636, Final Batch Loss: 0.20906057953834534\n",
      "Epoch 3979, Loss: 0.45039480924606323, Final Batch Loss: 0.13309262692928314\n",
      "Epoch 3980, Loss: 0.4436645433306694, Final Batch Loss: 0.12403848022222519\n",
      "Epoch 3981, Loss: 0.44228218495845795, Final Batch Loss: 0.18686990439891815\n",
      "Epoch 3982, Loss: 0.4114929735660553, Final Batch Loss: 0.07260727882385254\n",
      "Epoch 3983, Loss: 0.6075992584228516, Final Batch Loss: 0.23108434677124023\n",
      "Epoch 3984, Loss: 0.500113844871521, Final Batch Loss: 0.11065466701984406\n",
      "Epoch 3985, Loss: 0.6534255146980286, Final Batch Loss: 0.2674347758293152\n",
      "Epoch 3986, Loss: 0.43187467008829117, Final Batch Loss: 0.1241389587521553\n",
      "Epoch 3987, Loss: 0.39183177053928375, Final Batch Loss: 0.11314257979393005\n",
      "Epoch 3988, Loss: 0.47088296711444855, Final Batch Loss: 0.1549975574016571\n",
      "Epoch 3989, Loss: 0.43313920497894287, Final Batch Loss: 0.12374833226203918\n",
      "Epoch 3990, Loss: 0.42893800884485245, Final Batch Loss: 0.15899384021759033\n",
      "Epoch 3991, Loss: 0.36628180742263794, Final Batch Loss: 0.11792856454849243\n",
      "Epoch 3992, Loss: 0.43495936691761017, Final Batch Loss: 0.15089373290538788\n",
      "Epoch 3993, Loss: 0.47598325461149216, Final Batch Loss: 0.11937274783849716\n",
      "Epoch 3994, Loss: 0.4116172641515732, Final Batch Loss: 0.12130768597126007\n",
      "Epoch 3995, Loss: 0.44111935794353485, Final Batch Loss: 0.11998263001441956\n",
      "Epoch 3996, Loss: 0.4920050948858261, Final Batch Loss: 0.12664511799812317\n",
      "Epoch 3997, Loss: 0.45202256739139557, Final Batch Loss: 0.190481498837471\n",
      "Epoch 3998, Loss: 0.3899018242955208, Final Batch Loss: 0.11731967329978943\n",
      "Epoch 3999, Loss: 0.37884677946567535, Final Batch Loss: 0.10591928660869598\n",
      "Epoch 4000, Loss: 0.6058918237686157, Final Batch Loss: 0.15512718260288239\n",
      "Epoch 4001, Loss: 0.42276185750961304, Final Batch Loss: 0.12841826677322388\n",
      "Epoch 4002, Loss: 0.5011112987995148, Final Batch Loss: 0.1585618257522583\n",
      "Epoch 4003, Loss: 0.5220903158187866, Final Batch Loss: 0.25962182879447937\n",
      "Epoch 4004, Loss: 0.511282667517662, Final Batch Loss: 0.12584473192691803\n",
      "Epoch 4005, Loss: 0.4488109350204468, Final Batch Loss: 0.1447046548128128\n",
      "Epoch 4006, Loss: 0.4795684665441513, Final Batch Loss: 0.16087469458580017\n",
      "Epoch 4007, Loss: 0.5834617763757706, Final Batch Loss: 0.24854370951652527\n",
      "Epoch 4008, Loss: 0.4802691787481308, Final Batch Loss: 0.14113759994506836\n",
      "Epoch 4009, Loss: 0.5258438736200333, Final Batch Loss: 0.16349129378795624\n",
      "Epoch 4010, Loss: 0.43610675632953644, Final Batch Loss: 0.1688854843378067\n",
      "Epoch 4011, Loss: 0.41315601766109467, Final Batch Loss: 0.14119797945022583\n",
      "Epoch 4012, Loss: 0.5483949035406113, Final Batch Loss: 0.1912701427936554\n",
      "Epoch 4013, Loss: 0.44291727989912033, Final Batch Loss: 0.09914370626211166\n",
      "Epoch 4014, Loss: 0.4558417797088623, Final Batch Loss: 0.1721297949552536\n",
      "Epoch 4015, Loss: 0.38840046525001526, Final Batch Loss: 0.16366232931613922\n",
      "Epoch 4016, Loss: 0.5461735874414444, Final Batch Loss: 0.23955020308494568\n",
      "Epoch 4017, Loss: 0.4872725307941437, Final Batch Loss: 0.17660652101039886\n",
      "Epoch 4018, Loss: 0.5156141668558121, Final Batch Loss: 0.12874610722064972\n",
      "Epoch 4019, Loss: 0.42582733929157257, Final Batch Loss: 0.1320848912000656\n",
      "Epoch 4020, Loss: 0.4106736332178116, Final Batch Loss: 0.10667063295841217\n",
      "Epoch 4021, Loss: 0.4271155446767807, Final Batch Loss: 0.079503133893013\n",
      "Epoch 4022, Loss: 0.559500128030777, Final Batch Loss: 0.22615858912467957\n",
      "Epoch 4023, Loss: 0.3992796093225479, Final Batch Loss: 0.128298819065094\n",
      "Epoch 4024, Loss: 0.45324842631816864, Final Batch Loss: 0.12089506536722183\n",
      "Epoch 4025, Loss: 0.3972928822040558, Final Batch Loss: 0.08281471580266953\n",
      "Epoch 4026, Loss: 0.509622223675251, Final Batch Loss: 0.09128735214471817\n",
      "Epoch 4027, Loss: 0.4838673174381256, Final Batch Loss: 0.16389289498329163\n",
      "Epoch 4028, Loss: 0.48001570999622345, Final Batch Loss: 0.14573541283607483\n",
      "Epoch 4029, Loss: 0.43798981606960297, Final Batch Loss: 0.15843094885349274\n",
      "Epoch 4030, Loss: 0.50129733979702, Final Batch Loss: 0.19218818843364716\n",
      "Epoch 4031, Loss: 0.5577542036771774, Final Batch Loss: 0.20801541209220886\n",
      "Epoch 4032, Loss: 0.43788689374923706, Final Batch Loss: 0.15437699854373932\n",
      "Epoch 4033, Loss: 0.422667495906353, Final Batch Loss: 0.08884973078966141\n",
      "Epoch 4034, Loss: 0.41474681347608566, Final Batch Loss: 0.13220082223415375\n",
      "Epoch 4035, Loss: 0.4480476677417755, Final Batch Loss: 0.13162143528461456\n",
      "Epoch 4036, Loss: 0.4556339234113693, Final Batch Loss: 0.179404616355896\n",
      "Epoch 4037, Loss: 0.5335869193077087, Final Batch Loss: 0.1797068864107132\n",
      "Epoch 4038, Loss: 0.482211098074913, Final Batch Loss: 0.13702593743801117\n",
      "Epoch 4039, Loss: 0.4244000166654587, Final Batch Loss: 0.1317109763622284\n",
      "Epoch 4040, Loss: 0.5146232098340988, Final Batch Loss: 0.14495663344860077\n",
      "Epoch 4041, Loss: 0.42821987718343735, Final Batch Loss: 0.11564715951681137\n",
      "Epoch 4042, Loss: 0.4016970321536064, Final Batch Loss: 0.10690846294164658\n",
      "Epoch 4043, Loss: 0.38024094700813293, Final Batch Loss: 0.14469222724437714\n",
      "Epoch 4044, Loss: 0.3294425457715988, Final Batch Loss: 0.0741610899567604\n",
      "Epoch 4045, Loss: 0.5660833045840263, Final Batch Loss: 0.2683100998401642\n",
      "Epoch 4046, Loss: 0.4122287705540657, Final Batch Loss: 0.10462319105863571\n",
      "Epoch 4047, Loss: 0.455739825963974, Final Batch Loss: 0.20200417935848236\n",
      "Epoch 4048, Loss: 0.4950532019138336, Final Batch Loss: 0.16177093982696533\n",
      "Epoch 4049, Loss: 0.4409206807613373, Final Batch Loss: 0.12776324152946472\n",
      "Epoch 4050, Loss: 0.44696612656116486, Final Batch Loss: 0.1736917644739151\n",
      "Epoch 4051, Loss: 0.44112297892570496, Final Batch Loss: 0.10233058035373688\n",
      "Epoch 4052, Loss: 0.4948439598083496, Final Batch Loss: 0.15457119047641754\n",
      "Epoch 4053, Loss: 0.44802936166524887, Final Batch Loss: 0.08920501917600632\n",
      "Epoch 4054, Loss: 0.42642560601234436, Final Batch Loss: 0.13323451578617096\n",
      "Epoch 4055, Loss: 0.5166235715150833, Final Batch Loss: 0.1878369301557541\n",
      "Epoch 4056, Loss: 0.5972047597169876, Final Batch Loss: 0.18256875872612\n",
      "Epoch 4057, Loss: 0.5174189656972885, Final Batch Loss: 0.13031211495399475\n",
      "Epoch 4058, Loss: 0.43101777136325836, Final Batch Loss: 0.14212626218795776\n",
      "Epoch 4059, Loss: 0.5212829858064651, Final Batch Loss: 0.21428944170475006\n",
      "Epoch 4060, Loss: 0.36124541610479355, Final Batch Loss: 0.08500581234693527\n",
      "Epoch 4061, Loss: 0.5170944854617119, Final Batch Loss: 0.23161056637763977\n",
      "Epoch 4062, Loss: 0.47571611404418945, Final Batch Loss: 0.13248242437839508\n",
      "Epoch 4063, Loss: 0.45902542769908905, Final Batch Loss: 0.15032339096069336\n",
      "Epoch 4064, Loss: 0.5147427022457123, Final Batch Loss: 0.20211324095726013\n",
      "Epoch 4065, Loss: 0.44851309061050415, Final Batch Loss: 0.14932386577129364\n",
      "Epoch 4066, Loss: 0.5399182960391045, Final Batch Loss: 0.27208009362220764\n",
      "Epoch 4067, Loss: 0.48225484788417816, Final Batch Loss: 0.1728689968585968\n",
      "Epoch 4068, Loss: 0.4209815785288811, Final Batch Loss: 0.14225779473781586\n",
      "Epoch 4069, Loss: 0.37835317105054855, Final Batch Loss: 0.13992595672607422\n",
      "Epoch 4070, Loss: 0.36920779943466187, Final Batch Loss: 0.1311521977186203\n",
      "Epoch 4071, Loss: 0.3893870785832405, Final Batch Loss: 0.08858124166727066\n",
      "Epoch 4072, Loss: 0.41822099685668945, Final Batch Loss: 0.0861877053976059\n",
      "Epoch 4073, Loss: 0.4984677582979202, Final Batch Loss: 0.1872902661561966\n",
      "Epoch 4074, Loss: 0.3932819366455078, Final Batch Loss: 0.1107928678393364\n",
      "Epoch 4075, Loss: 0.4506758153438568, Final Batch Loss: 0.17812353372573853\n",
      "Epoch 4076, Loss: 0.5582509115338326, Final Batch Loss: 0.27167215943336487\n",
      "Epoch 4077, Loss: 0.4060951694846153, Final Batch Loss: 0.11923149973154068\n",
      "Epoch 4078, Loss: 0.4141268953680992, Final Batch Loss: 0.09480451792478561\n",
      "Epoch 4079, Loss: 0.45515646040439606, Final Batch Loss: 0.15110330283641815\n",
      "Epoch 4080, Loss: 0.4564560651779175, Final Batch Loss: 0.12210133671760559\n",
      "Epoch 4081, Loss: 0.5122063159942627, Final Batch Loss: 0.18533584475517273\n",
      "Epoch 4082, Loss: 0.48557499051094055, Final Batch Loss: 0.1314188838005066\n",
      "Epoch 4083, Loss: 0.5143622383475304, Final Batch Loss: 0.08752428740262985\n",
      "Epoch 4084, Loss: 0.4170372858643532, Final Batch Loss: 0.09755793958902359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4085, Loss: 0.49908529222011566, Final Batch Loss: 0.1555968075990677\n",
      "Epoch 4086, Loss: 0.49416086077690125, Final Batch Loss: 0.18801943957805634\n",
      "Epoch 4087, Loss: 0.48134608566761017, Final Batch Loss: 0.18070250749588013\n",
      "Epoch 4088, Loss: 0.48144596815109253, Final Batch Loss: 0.13293348252773285\n",
      "Epoch 4089, Loss: 0.5374815464019775, Final Batch Loss: 0.23987062275409698\n",
      "Epoch 4090, Loss: 0.5244162529706955, Final Batch Loss: 0.16932813823223114\n",
      "Epoch 4091, Loss: 0.41312067210674286, Final Batch Loss: 0.13154710829257965\n",
      "Epoch 4092, Loss: 0.6252803355455399, Final Batch Loss: 0.28498759865760803\n",
      "Epoch 4093, Loss: 0.38605014234781265, Final Batch Loss: 0.11743933707475662\n",
      "Epoch 4094, Loss: 0.4322979301214218, Final Batch Loss: 0.13096150755882263\n",
      "Epoch 4095, Loss: 0.49901731312274933, Final Batch Loss: 0.1558157503604889\n",
      "Epoch 4096, Loss: 0.45688917487859726, Final Batch Loss: 0.1318114697933197\n",
      "Epoch 4097, Loss: 0.41954392194747925, Final Batch Loss: 0.10994786024093628\n",
      "Epoch 4098, Loss: 0.49272923171520233, Final Batch Loss: 0.1912105828523636\n",
      "Epoch 4099, Loss: 0.4872007593512535, Final Batch Loss: 0.19582445919513702\n",
      "Epoch 4100, Loss: 0.5030042827129364, Final Batch Loss: 0.14330700039863586\n",
      "Epoch 4101, Loss: 0.3816503509879112, Final Batch Loss: 0.14430074393749237\n",
      "Epoch 4102, Loss: 0.4707004725933075, Final Batch Loss: 0.14582809805870056\n",
      "Epoch 4103, Loss: 0.5121397078037262, Final Batch Loss: 0.15405970811843872\n",
      "Epoch 4104, Loss: 0.4515088349580765, Final Batch Loss: 0.13655957579612732\n",
      "Epoch 4105, Loss: 0.430783212184906, Final Batch Loss: 0.1013040691614151\n",
      "Epoch 4106, Loss: 0.500823512673378, Final Batch Loss: 0.11230693757534027\n",
      "Epoch 4107, Loss: 0.49440161138772964, Final Batch Loss: 0.10451885312795639\n",
      "Epoch 4108, Loss: 0.49520382285118103, Final Batch Loss: 0.17071689665317535\n",
      "Epoch 4109, Loss: 0.37404046952724457, Final Batch Loss: 0.15386629104614258\n",
      "Epoch 4110, Loss: 0.47357016801834106, Final Batch Loss: 0.20275890827178955\n",
      "Epoch 4111, Loss: 0.4677860736846924, Final Batch Loss: 0.12926128506660461\n",
      "Epoch 4112, Loss: 0.5049673765897751, Final Batch Loss: 0.19649359583854675\n",
      "Epoch 4113, Loss: 0.5240803956985474, Final Batch Loss: 0.15221013128757477\n",
      "Epoch 4114, Loss: 0.3896571546792984, Final Batch Loss: 0.13845933973789215\n",
      "Epoch 4115, Loss: 0.39121659845113754, Final Batch Loss: 0.0648067519068718\n",
      "Epoch 4116, Loss: 0.40558839589357376, Final Batch Loss: 0.12544403970241547\n",
      "Epoch 4117, Loss: 0.4306939020752907, Final Batch Loss: 0.1098652258515358\n",
      "Epoch 4118, Loss: 0.49605153501033783, Final Batch Loss: 0.23023639619350433\n",
      "Epoch 4119, Loss: 0.5445997267961502, Final Batch Loss: 0.20964252948760986\n",
      "Epoch 4120, Loss: 0.43185533583164215, Final Batch Loss: 0.10038164258003235\n",
      "Epoch 4121, Loss: 0.4252183362841606, Final Batch Loss: 0.17684818804264069\n",
      "Epoch 4122, Loss: 0.49549342691898346, Final Batch Loss: 0.14573432505130768\n",
      "Epoch 4123, Loss: 0.36209385097026825, Final Batch Loss: 0.09848879277706146\n",
      "Epoch 4124, Loss: 0.4719354063272476, Final Batch Loss: 0.17168334126472473\n",
      "Epoch 4125, Loss: 0.3648891821503639, Final Batch Loss: 0.13023057579994202\n",
      "Epoch 4126, Loss: 0.3975413143634796, Final Batch Loss: 0.15141291916370392\n",
      "Epoch 4127, Loss: 0.5123038440942764, Final Batch Loss: 0.14095468819141388\n",
      "Epoch 4128, Loss: 0.42955613136291504, Final Batch Loss: 0.15176507830619812\n",
      "Epoch 4129, Loss: 0.4731118977069855, Final Batch Loss: 0.19569562375545502\n",
      "Epoch 4130, Loss: 0.5028956085443497, Final Batch Loss: 0.1455632895231247\n",
      "Epoch 4131, Loss: 0.3474491387605667, Final Batch Loss: 0.14667893946170807\n",
      "Epoch 4132, Loss: 0.4213697761297226, Final Batch Loss: 0.19652307033538818\n",
      "Epoch 4133, Loss: 0.4714348614215851, Final Batch Loss: 0.17892567813396454\n",
      "Epoch 4134, Loss: 0.5063558369874954, Final Batch Loss: 0.13646501302719116\n",
      "Epoch 4135, Loss: 0.5201739072799683, Final Batch Loss: 0.20417647063732147\n",
      "Epoch 4136, Loss: 0.462336465716362, Final Batch Loss: 0.16593360900878906\n",
      "Epoch 4137, Loss: 0.4781230762600899, Final Batch Loss: 0.12223822623491287\n",
      "Epoch 4138, Loss: 0.5712734460830688, Final Batch Loss: 0.24010086059570312\n",
      "Epoch 4139, Loss: 0.44447895884513855, Final Batch Loss: 0.15082678198814392\n",
      "Epoch 4140, Loss: 0.5924176871776581, Final Batch Loss: 0.13478805124759674\n",
      "Epoch 4141, Loss: 0.624886766076088, Final Batch Loss: 0.1873266100883484\n",
      "Epoch 4142, Loss: 0.4622883200645447, Final Batch Loss: 0.14775750041007996\n",
      "Epoch 4143, Loss: 0.5375027656555176, Final Batch Loss: 0.1953383982181549\n",
      "Epoch 4144, Loss: 0.4625532850623131, Final Batch Loss: 0.11656490713357925\n",
      "Epoch 4145, Loss: 0.4658561795949936, Final Batch Loss: 0.18515457212924957\n",
      "Epoch 4146, Loss: 0.5610410273075104, Final Batch Loss: 0.24433688819408417\n",
      "Epoch 4147, Loss: 0.6446849703788757, Final Batch Loss: 0.30372515320777893\n",
      "Epoch 4148, Loss: 0.46818068623542786, Final Batch Loss: 0.16087433695793152\n",
      "Epoch 4149, Loss: 0.5757351666688919, Final Batch Loss: 0.18574877083301544\n",
      "Epoch 4150, Loss: 0.5102474093437195, Final Batch Loss: 0.16461126506328583\n",
      "Epoch 4151, Loss: 0.43973200023174286, Final Batch Loss: 0.13041292130947113\n",
      "Epoch 4152, Loss: 0.5196853280067444, Final Batch Loss: 0.1965053379535675\n",
      "Epoch 4153, Loss: 0.5047075599431992, Final Batch Loss: 0.14099492132663727\n",
      "Epoch 4154, Loss: 0.46506407856941223, Final Batch Loss: 0.15429344773292542\n",
      "Epoch 4155, Loss: 0.3612051159143448, Final Batch Loss: 0.13054685294628143\n",
      "Epoch 4156, Loss: 0.5728738158941269, Final Batch Loss: 0.24208933115005493\n",
      "Epoch 4157, Loss: 0.48033423721790314, Final Batch Loss: 0.19289451837539673\n",
      "Epoch 4158, Loss: 0.46374425292015076, Final Batch Loss: 0.15653552114963531\n",
      "Epoch 4159, Loss: 0.46883589774370193, Final Batch Loss: 0.1087627038359642\n",
      "Epoch 4160, Loss: 0.41996488720178604, Final Batch Loss: 0.11664361506700516\n",
      "Epoch 4161, Loss: 0.441074475646019, Final Batch Loss: 0.13173401355743408\n",
      "Epoch 4162, Loss: 0.47203412652015686, Final Batch Loss: 0.19189995527267456\n",
      "Epoch 4163, Loss: 0.43133530020713806, Final Batch Loss: 0.1988345831632614\n",
      "Epoch 4164, Loss: 0.45560553669929504, Final Batch Loss: 0.16484759747982025\n",
      "Epoch 4165, Loss: 0.5573018491268158, Final Batch Loss: 0.27172937989234924\n",
      "Epoch 4166, Loss: 0.4564066603779793, Final Batch Loss: 0.11892244964838028\n",
      "Epoch 4167, Loss: 0.395462729036808, Final Batch Loss: 0.09362303465604782\n",
      "Epoch 4168, Loss: 0.5735927075147629, Final Batch Loss: 0.14278064668178558\n",
      "Epoch 4169, Loss: 0.3896174356341362, Final Batch Loss: 0.06717346608638763\n",
      "Epoch 4170, Loss: 0.3745391219854355, Final Batch Loss: 0.12226279824972153\n",
      "Epoch 4171, Loss: 0.4533824920654297, Final Batch Loss: 0.1589849889278412\n",
      "Epoch 4172, Loss: 0.485332190990448, Final Batch Loss: 0.17579318583011627\n",
      "Epoch 4173, Loss: 0.45170462131500244, Final Batch Loss: 0.15378528833389282\n",
      "Epoch 4174, Loss: 0.4223702698945999, Final Batch Loss: 0.18308240175247192\n",
      "Epoch 4175, Loss: 0.5083146244287491, Final Batch Loss: 0.16238120198249817\n",
      "Epoch 4176, Loss: 0.40658295154571533, Final Batch Loss: 0.13129478693008423\n",
      "Epoch 4177, Loss: 0.4753558337688446, Final Batch Loss: 0.19366560876369476\n",
      "Epoch 4178, Loss: 0.4233655631542206, Final Batch Loss: 0.09757715463638306\n",
      "Epoch 4179, Loss: 0.5484225749969482, Final Batch Loss: 0.2446976900100708\n",
      "Epoch 4180, Loss: 0.36031047999858856, Final Batch Loss: 0.1097375825047493\n",
      "Epoch 4181, Loss: 0.4929623305797577, Final Batch Loss: 0.14700962603092194\n",
      "Epoch 4182, Loss: 0.43201112747192383, Final Batch Loss: 0.1416098028421402\n",
      "Epoch 4183, Loss: 0.386274091899395, Final Batch Loss: 0.08595040440559387\n",
      "Epoch 4184, Loss: 0.3844510093331337, Final Batch Loss: 0.07053222507238388\n",
      "Epoch 4185, Loss: 0.4299207404255867, Final Batch Loss: 0.13709533214569092\n",
      "Epoch 4186, Loss: 0.4885442852973938, Final Batch Loss: 0.23679275810718536\n",
      "Epoch 4187, Loss: 0.5770846605300903, Final Batch Loss: 0.16037102043628693\n",
      "Epoch 4188, Loss: 0.5717082619667053, Final Batch Loss: 0.16730673611164093\n",
      "Epoch 4189, Loss: 0.37818581610918045, Final Batch Loss: 0.12526001036167145\n",
      "Epoch 4190, Loss: 0.4930693358182907, Final Batch Loss: 0.1828107386827469\n",
      "Epoch 4191, Loss: 0.4614981859922409, Final Batch Loss: 0.16666212677955627\n",
      "Epoch 4192, Loss: 0.4960453510284424, Final Batch Loss: 0.19716306030750275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4193, Loss: 0.4571687877178192, Final Batch Loss: 0.18096302449703217\n",
      "Epoch 4194, Loss: 0.6509738564491272, Final Batch Loss: 0.15308457612991333\n",
      "Epoch 4195, Loss: 0.4738331139087677, Final Batch Loss: 0.1885586977005005\n",
      "Epoch 4196, Loss: 0.4448494464159012, Final Batch Loss: 0.1605648249387741\n",
      "Epoch 4197, Loss: 0.5337421745061874, Final Batch Loss: 0.13967154920101166\n",
      "Epoch 4198, Loss: 0.4115797132253647, Final Batch Loss: 0.11499696224927902\n",
      "Epoch 4199, Loss: 0.5437557697296143, Final Batch Loss: 0.16591434180736542\n",
      "Epoch 4200, Loss: 0.4671845957636833, Final Batch Loss: 0.12331721931695938\n",
      "Epoch 4201, Loss: 0.4424648806452751, Final Batch Loss: 0.16101506352424622\n",
      "Epoch 4202, Loss: 0.3901744857430458, Final Batch Loss: 0.09844488650560379\n",
      "Epoch 4203, Loss: 0.4268139451742172, Final Batch Loss: 0.14980313181877136\n",
      "Epoch 4204, Loss: 0.41748711466789246, Final Batch Loss: 0.09996145963668823\n",
      "Epoch 4205, Loss: 0.5238640978932381, Final Batch Loss: 0.2674238681793213\n",
      "Epoch 4206, Loss: 0.4555249363183975, Final Batch Loss: 0.18731342256069183\n",
      "Epoch 4207, Loss: 0.3728163465857506, Final Batch Loss: 0.09921089559793472\n",
      "Epoch 4208, Loss: 0.4718455523252487, Final Batch Loss: 0.22273415327072144\n",
      "Epoch 4209, Loss: 0.4270065277814865, Final Batch Loss: 0.13736869394779205\n",
      "Epoch 4210, Loss: 0.4465944766998291, Final Batch Loss: 0.14535100758075714\n",
      "Epoch 4211, Loss: 0.4489228427410126, Final Batch Loss: 0.19619569182395935\n",
      "Epoch 4212, Loss: 0.3919111341238022, Final Batch Loss: 0.08665139973163605\n",
      "Epoch 4213, Loss: 0.5471446812152863, Final Batch Loss: 0.17104104161262512\n",
      "Epoch 4214, Loss: 0.4550882577896118, Final Batch Loss: 0.16097697615623474\n",
      "Epoch 4215, Loss: 0.41697903722524643, Final Batch Loss: 0.12006660550832748\n",
      "Epoch 4216, Loss: 0.4202948659658432, Final Batch Loss: 0.15673014521598816\n",
      "Epoch 4217, Loss: 0.5258530080318451, Final Batch Loss: 0.19867458939552307\n",
      "Epoch 4218, Loss: 0.40722405910491943, Final Batch Loss: 0.09707231819629669\n",
      "Epoch 4219, Loss: 0.6508062034845352, Final Batch Loss: 0.24692115187644958\n",
      "Epoch 4220, Loss: 0.6222176849842072, Final Batch Loss: 0.11618703603744507\n",
      "Epoch 4221, Loss: 0.4691872000694275, Final Batch Loss: 0.17074982821941376\n",
      "Epoch 4222, Loss: 0.3902759253978729, Final Batch Loss: 0.08929045498371124\n",
      "Epoch 4223, Loss: 0.4338288754224777, Final Batch Loss: 0.07435540854930878\n",
      "Epoch 4224, Loss: 0.40586472302675247, Final Batch Loss: 0.1580752730369568\n",
      "Epoch 4225, Loss: 0.5259964019060135, Final Batch Loss: 0.1635385900735855\n",
      "Epoch 4226, Loss: 0.4823831021785736, Final Batch Loss: 0.19542674720287323\n",
      "Epoch 4227, Loss: 0.4036001116037369, Final Batch Loss: 0.15205039083957672\n",
      "Epoch 4228, Loss: 0.3914477154612541, Final Batch Loss: 0.13036754727363586\n",
      "Epoch 4229, Loss: 0.3999874219298363, Final Batch Loss: 0.09565890580415726\n",
      "Epoch 4230, Loss: 0.38438187539577484, Final Batch Loss: 0.12540018558502197\n",
      "Epoch 4231, Loss: 0.6057606041431427, Final Batch Loss: 0.3163861930370331\n",
      "Epoch 4232, Loss: 0.5396017208695412, Final Batch Loss: 0.30531689524650574\n",
      "Epoch 4233, Loss: 0.48993341624736786, Final Batch Loss: 0.13811758160591125\n",
      "Epoch 4234, Loss: 0.3868810459971428, Final Batch Loss: 0.13719859719276428\n",
      "Epoch 4235, Loss: 0.3937828615307808, Final Batch Loss: 0.09973901510238647\n",
      "Epoch 4236, Loss: 0.3606294095516205, Final Batch Loss: 0.07883447408676147\n",
      "Epoch 4237, Loss: 0.5432883948087692, Final Batch Loss: 0.27125951647758484\n",
      "Epoch 4238, Loss: 0.4433649778366089, Final Batch Loss: 0.16489435732364655\n",
      "Epoch 4239, Loss: 0.32557065784931183, Final Batch Loss: 0.10986683517694473\n",
      "Epoch 4240, Loss: 0.45011408627033234, Final Batch Loss: 0.13763496279716492\n",
      "Epoch 4241, Loss: 0.505898043513298, Final Batch Loss: 0.18293441832065582\n",
      "Epoch 4242, Loss: 0.4736025184392929, Final Batch Loss: 0.10438503324985504\n",
      "Epoch 4243, Loss: 0.4647825062274933, Final Batch Loss: 0.21586044132709503\n",
      "Epoch 4244, Loss: 0.5562514364719391, Final Batch Loss: 0.21057488024234772\n",
      "Epoch 4245, Loss: 0.43127163499593735, Final Batch Loss: 0.1381470263004303\n",
      "Epoch 4246, Loss: 0.4601013958454132, Final Batch Loss: 0.17910684645175934\n",
      "Epoch 4247, Loss: 0.46100468188524246, Final Batch Loss: 0.16006705164909363\n",
      "Epoch 4248, Loss: 0.5142419189214706, Final Batch Loss: 0.18389463424682617\n",
      "Epoch 4249, Loss: 0.48480580747127533, Final Batch Loss: 0.1985599845647812\n",
      "Epoch 4250, Loss: 0.4535449743270874, Final Batch Loss: 0.15976503491401672\n",
      "Epoch 4251, Loss: 0.4486646056175232, Final Batch Loss: 0.1618010699748993\n",
      "Epoch 4252, Loss: 0.5384780466556549, Final Batch Loss: 0.11948616802692413\n",
      "Epoch 4253, Loss: 0.47499416768550873, Final Batch Loss: 0.2341638058423996\n",
      "Epoch 4254, Loss: 0.5672493427991867, Final Batch Loss: 0.2393091917037964\n",
      "Epoch 4255, Loss: 0.4343806952238083, Final Batch Loss: 0.13690444827079773\n",
      "Epoch 4256, Loss: 0.4708629995584488, Final Batch Loss: 0.17893411219120026\n",
      "Epoch 4257, Loss: 0.49560362100601196, Final Batch Loss: 0.16789191961288452\n",
      "Epoch 4258, Loss: 0.5522720217704773, Final Batch Loss: 0.16903027892112732\n",
      "Epoch 4259, Loss: 0.3699006363749504, Final Batch Loss: 0.09088408201932907\n",
      "Epoch 4260, Loss: 0.46511009335517883, Final Batch Loss: 0.16235630214214325\n",
      "Epoch 4261, Loss: 0.42348331212997437, Final Batch Loss: 0.14758731424808502\n",
      "Epoch 4262, Loss: 0.4070843756198883, Final Batch Loss: 0.14321976900100708\n",
      "Epoch 4263, Loss: 0.36704111099243164, Final Batch Loss: 0.08999684453010559\n",
      "Epoch 4264, Loss: 0.4825355112552643, Final Batch Loss: 0.14924940466880798\n",
      "Epoch 4265, Loss: 0.6445071995258331, Final Batch Loss: 0.3178204298019409\n",
      "Epoch 4266, Loss: 0.5008606463670731, Final Batch Loss: 0.20642150938510895\n",
      "Epoch 4267, Loss: 0.5350815653800964, Final Batch Loss: 0.18178300559520721\n",
      "Epoch 4268, Loss: 0.49796754866838455, Final Batch Loss: 0.255505234003067\n",
      "Epoch 4269, Loss: 0.5509990751743317, Final Batch Loss: 0.20691454410552979\n",
      "Epoch 4270, Loss: 0.5859870463609695, Final Batch Loss: 0.21787796914577484\n",
      "Epoch 4271, Loss: 0.4645703583955765, Final Batch Loss: 0.08056479692459106\n",
      "Epoch 4272, Loss: 0.4872313588857651, Final Batch Loss: 0.13913366198539734\n",
      "Epoch 4273, Loss: 0.39654631167650223, Final Batch Loss: 0.1552867293357849\n",
      "Epoch 4274, Loss: 0.42689622193574905, Final Batch Loss: 0.10764297097921371\n",
      "Epoch 4275, Loss: 0.5152851790189743, Final Batch Loss: 0.20929557085037231\n",
      "Epoch 4276, Loss: 0.5393232107162476, Final Batch Loss: 0.14709334075450897\n",
      "Epoch 4277, Loss: 0.47787658870220184, Final Batch Loss: 0.11821751296520233\n",
      "Epoch 4278, Loss: 0.6070893555879593, Final Batch Loss: 0.2195153385400772\n",
      "Epoch 4279, Loss: 0.4479805901646614, Final Batch Loss: 0.1189856305718422\n",
      "Epoch 4280, Loss: 0.41160328686237335, Final Batch Loss: 0.15061348676681519\n",
      "Epoch 4281, Loss: 0.41241494566202164, Final Batch Loss: 0.11032334715127945\n",
      "Epoch 4282, Loss: 0.4388686493039131, Final Batch Loss: 0.1811596155166626\n",
      "Epoch 4283, Loss: 0.46332137286663055, Final Batch Loss: 0.14981809258460999\n",
      "Epoch 4284, Loss: 0.40261880308389664, Final Batch Loss: 0.09800942242145538\n",
      "Epoch 4285, Loss: 0.4999712258577347, Final Batch Loss: 0.23819425702095032\n",
      "Epoch 4286, Loss: 0.4148841127753258, Final Batch Loss: 0.13407674431800842\n",
      "Epoch 4287, Loss: 0.46857474744319916, Final Batch Loss: 0.18104030191898346\n",
      "Epoch 4288, Loss: 0.48872140049934387, Final Batch Loss: 0.1366509646177292\n",
      "Epoch 4289, Loss: 0.5180828869342804, Final Batch Loss: 0.2086128145456314\n",
      "Epoch 4290, Loss: 0.42497721314430237, Final Batch Loss: 0.17258942127227783\n",
      "Epoch 4291, Loss: 0.521380141377449, Final Batch Loss: 0.2101120501756668\n",
      "Epoch 4292, Loss: 0.5278844833374023, Final Batch Loss: 0.18907752633094788\n",
      "Epoch 4293, Loss: 0.47825048863887787, Final Batch Loss: 0.19820700585842133\n",
      "Epoch 4294, Loss: 0.38841918855905533, Final Batch Loss: 0.14218728244304657\n",
      "Epoch 4295, Loss: 0.48630523681640625, Final Batch Loss: 0.15568938851356506\n",
      "Epoch 4296, Loss: 0.44773921370506287, Final Batch Loss: 0.13139310479164124\n",
      "Epoch 4297, Loss: 0.4516678526997566, Final Batch Loss: 0.17321941256523132\n",
      "Epoch 4298, Loss: 0.4026721715927124, Final Batch Loss: 0.15249092876911163\n",
      "Epoch 4299, Loss: 0.4301019385457039, Final Batch Loss: 0.12048757821321487\n",
      "Epoch 4300, Loss: 0.458797350525856, Final Batch Loss: 0.12199142575263977\n",
      "Epoch 4301, Loss: 0.59405218064785, Final Batch Loss: 0.19095586240291595\n",
      "Epoch 4302, Loss: 0.44345012307167053, Final Batch Loss: 0.14571914076805115\n",
      "Epoch 4303, Loss: 0.4502420574426651, Final Batch Loss: 0.16162002086639404\n",
      "Epoch 4304, Loss: 0.4184315800666809, Final Batch Loss: 0.11150692403316498\n",
      "Epoch 4305, Loss: 0.5911654978990555, Final Batch Loss: 0.21031714975833893\n",
      "Epoch 4306, Loss: 0.48838484287261963, Final Batch Loss: 0.1525116264820099\n",
      "Epoch 4307, Loss: 0.5885885655879974, Final Batch Loss: 0.2493913769721985\n",
      "Epoch 4308, Loss: 0.5289716497063637, Final Batch Loss: 0.18056894838809967\n",
      "Epoch 4309, Loss: 0.6303817480802536, Final Batch Loss: 0.27313342690467834\n",
      "Epoch 4310, Loss: 0.49491220712661743, Final Batch Loss: 0.17313365638256073\n",
      "Epoch 4311, Loss: 0.4469093978404999, Final Batch Loss: 0.12409009039402008\n",
      "Epoch 4312, Loss: 0.4872376024723053, Final Batch Loss: 0.20693297684192657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4313, Loss: 0.5423111319541931, Final Batch Loss: 0.17450781166553497\n",
      "Epoch 4314, Loss: 0.5423547476530075, Final Batch Loss: 0.18184016644954681\n",
      "Epoch 4315, Loss: 0.4081309139728546, Final Batch Loss: 0.15786850452423096\n",
      "Epoch 4316, Loss: 0.6187614351511002, Final Batch Loss: 0.24515676498413086\n",
      "Epoch 4317, Loss: 0.4110362082719803, Final Batch Loss: 0.16576847434043884\n",
      "Epoch 4318, Loss: 0.6299249529838562, Final Batch Loss: 0.27203568816185\n",
      "Epoch 4319, Loss: 0.4559142142534256, Final Batch Loss: 0.12504562735557556\n",
      "Epoch 4320, Loss: 0.5863360911607742, Final Batch Loss: 0.22321441769599915\n",
      "Epoch 4321, Loss: 0.4148404374718666, Final Batch Loss: 0.09645361453294754\n",
      "Epoch 4322, Loss: 0.4822192043066025, Final Batch Loss: 0.17936928570270538\n",
      "Epoch 4323, Loss: 0.5470816195011139, Final Batch Loss: 0.18561719357967377\n",
      "Epoch 4324, Loss: 0.42331061512231827, Final Batch Loss: 0.14470429718494415\n",
      "Epoch 4325, Loss: 0.4723712205886841, Final Batch Loss: 0.1775561273097992\n",
      "Epoch 4326, Loss: 0.4304039925336838, Final Batch Loss: 0.16390946507453918\n",
      "Epoch 4327, Loss: 0.41869359463453293, Final Batch Loss: 0.0900234580039978\n",
      "Epoch 4328, Loss: 0.5201705396175385, Final Batch Loss: 0.18657976388931274\n",
      "Epoch 4329, Loss: 0.4062981903553009, Final Batch Loss: 0.12136390805244446\n",
      "Epoch 4330, Loss: 0.4198535829782486, Final Batch Loss: 0.13839851319789886\n",
      "Epoch 4331, Loss: 0.45981909334659576, Final Batch Loss: 0.18648022413253784\n",
      "Epoch 4332, Loss: 0.5173414349555969, Final Batch Loss: 0.15966901183128357\n",
      "Epoch 4333, Loss: 0.5211344286799431, Final Batch Loss: 0.12283720821142197\n",
      "Epoch 4334, Loss: 0.41054878383874893, Final Batch Loss: 0.12759146094322205\n",
      "Epoch 4335, Loss: 0.44401247799396515, Final Batch Loss: 0.11254023015499115\n",
      "Epoch 4336, Loss: 0.5818087458610535, Final Batch Loss: 0.29681044816970825\n",
      "Epoch 4337, Loss: 0.5269899070262909, Final Batch Loss: 0.2721934914588928\n",
      "Epoch 4338, Loss: 0.48821595311164856, Final Batch Loss: 0.1420116126537323\n",
      "Epoch 4339, Loss: 0.5486263185739517, Final Batch Loss: 0.17310993373394012\n",
      "Epoch 4340, Loss: 0.4329627752304077, Final Batch Loss: 0.15692231059074402\n",
      "Epoch 4341, Loss: 0.3848457634449005, Final Batch Loss: 0.15844689309597015\n",
      "Epoch 4342, Loss: 0.291342630982399, Final Batch Loss: 0.10020800679922104\n",
      "Epoch 4343, Loss: 0.38895317167043686, Final Batch Loss: 0.09527216106653214\n",
      "Epoch 4344, Loss: 0.5622017085552216, Final Batch Loss: 0.19513681530952454\n",
      "Epoch 4345, Loss: 0.5124785974621773, Final Batch Loss: 0.12316303700208664\n",
      "Epoch 4346, Loss: 0.5099823325872421, Final Batch Loss: 0.19184237718582153\n",
      "Epoch 4347, Loss: 0.48089833557605743, Final Batch Loss: 0.2137744277715683\n",
      "Epoch 4348, Loss: 0.4349525421857834, Final Batch Loss: 0.13382533192634583\n",
      "Epoch 4349, Loss: 0.45184674113988876, Final Batch Loss: 0.20610369741916656\n",
      "Epoch 4350, Loss: 0.5271041691303253, Final Batch Loss: 0.18682430684566498\n",
      "Epoch 4351, Loss: 0.4505276530981064, Final Batch Loss: 0.15868166089057922\n",
      "Epoch 4352, Loss: 0.45089007169008255, Final Batch Loss: 0.21200047433376312\n",
      "Epoch 4353, Loss: 0.3603072464466095, Final Batch Loss: 0.09169888496398926\n",
      "Epoch 4354, Loss: 0.4057546406984329, Final Batch Loss: 0.13545316457748413\n",
      "Epoch 4355, Loss: 0.52112877368927, Final Batch Loss: 0.13431930541992188\n",
      "Epoch 4356, Loss: 0.4945501536130905, Final Batch Loss: 0.14534913003444672\n",
      "Epoch 4357, Loss: 0.4248540699481964, Final Batch Loss: 0.16013115644454956\n",
      "Epoch 4358, Loss: 0.488640159368515, Final Batch Loss: 0.1956683248281479\n",
      "Epoch 4359, Loss: 0.4446949437260628, Final Batch Loss: 0.10381153970956802\n",
      "Epoch 4360, Loss: 0.4762464165687561, Final Batch Loss: 0.15781012177467346\n",
      "Epoch 4361, Loss: 0.3872556686401367, Final Batch Loss: 0.16849960386753082\n",
      "Epoch 4362, Loss: 0.4635660946369171, Final Batch Loss: 0.14884266257286072\n",
      "Epoch 4363, Loss: 0.42692001909017563, Final Batch Loss: 0.10970602184534073\n",
      "Epoch 4364, Loss: 0.4793287292122841, Final Batch Loss: 0.13365866243839264\n",
      "Epoch 4365, Loss: 0.5459624081850052, Final Batch Loss: 0.2826336622238159\n",
      "Epoch 4366, Loss: 0.3623083308339119, Final Batch Loss: 0.1181420385837555\n",
      "Epoch 4367, Loss: 0.4612465500831604, Final Batch Loss: 0.1386340856552124\n",
      "Epoch 4368, Loss: 0.408407099545002, Final Batch Loss: 0.09364328533411026\n",
      "Epoch 4369, Loss: 0.37355123460292816, Final Batch Loss: 0.0897214263677597\n",
      "Epoch 4370, Loss: 0.575239509344101, Final Batch Loss: 0.20484930276870728\n",
      "Epoch 4371, Loss: 0.4579019993543625, Final Batch Loss: 0.18551240861415863\n",
      "Epoch 4372, Loss: 0.5248932093381882, Final Batch Loss: 0.17660507559776306\n",
      "Epoch 4373, Loss: 0.39182617515325546, Final Batch Loss: 0.12964703142642975\n",
      "Epoch 4374, Loss: 0.44134508073329926, Final Batch Loss: 0.14801107347011566\n",
      "Epoch 4375, Loss: 0.44848451018333435, Final Batch Loss: 0.14299699664115906\n",
      "Epoch 4376, Loss: 0.43519554287195206, Final Batch Loss: 0.15883313119411469\n",
      "Epoch 4377, Loss: 0.5306929796934128, Final Batch Loss: 0.18960875272750854\n",
      "Epoch 4378, Loss: 0.4198729693889618, Final Batch Loss: 0.07220162451267242\n",
      "Epoch 4379, Loss: 0.47815049439668655, Final Batch Loss: 0.10540821403265\n",
      "Epoch 4380, Loss: 0.34404299408197403, Final Batch Loss: 0.07204001396894455\n",
      "Epoch 4381, Loss: 0.48458489775657654, Final Batch Loss: 0.17316091060638428\n",
      "Epoch 4382, Loss: 0.4153353422880173, Final Batch Loss: 0.13879121840000153\n",
      "Epoch 4383, Loss: 0.5194303542375565, Final Batch Loss: 0.1870797574520111\n",
      "Epoch 4384, Loss: 0.43915554881095886, Final Batch Loss: 0.19366474449634552\n",
      "Epoch 4385, Loss: 0.5818450078368187, Final Batch Loss: 0.2911458909511566\n",
      "Epoch 4386, Loss: 0.4765845984220505, Final Batch Loss: 0.19728928804397583\n",
      "Epoch 4387, Loss: 0.436468705534935, Final Batch Loss: 0.1294342428445816\n",
      "Epoch 4388, Loss: 0.4057021290063858, Final Batch Loss: 0.13443395495414734\n",
      "Epoch 4389, Loss: 0.4379127025604248, Final Batch Loss: 0.18916019797325134\n",
      "Epoch 4390, Loss: 0.633291944861412, Final Batch Loss: 0.23172448575496674\n",
      "Epoch 4391, Loss: 0.4418722167611122, Final Batch Loss: 0.16228048503398895\n",
      "Epoch 4392, Loss: 0.439235121011734, Final Batch Loss: 0.18284562230110168\n",
      "Epoch 4393, Loss: 0.5420550256967545, Final Batch Loss: 0.17199154198169708\n",
      "Epoch 4394, Loss: 0.43122923374176025, Final Batch Loss: 0.1653665006160736\n",
      "Epoch 4395, Loss: 0.48083608597517014, Final Batch Loss: 0.16935721039772034\n",
      "Epoch 4396, Loss: 0.6274086236953735, Final Batch Loss: 0.2414979487657547\n",
      "Epoch 4397, Loss: 0.5010180398821831, Final Batch Loss: 0.12032590806484222\n",
      "Epoch 4398, Loss: 0.4964786767959595, Final Batch Loss: 0.13267193734645844\n",
      "Epoch 4399, Loss: 0.5373101681470871, Final Batch Loss: 0.26799920201301575\n",
      "Epoch 4400, Loss: 0.47363506257534027, Final Batch Loss: 0.149366557598114\n",
      "Epoch 4401, Loss: 0.4852542281150818, Final Batch Loss: 0.13874807953834534\n",
      "Epoch 4402, Loss: 0.4825650453567505, Final Batch Loss: 0.1361832469701767\n",
      "Epoch 4403, Loss: 0.5116206407546997, Final Batch Loss: 0.1324026733636856\n",
      "Epoch 4404, Loss: 0.5750638544559479, Final Batch Loss: 0.19888940453529358\n",
      "Epoch 4405, Loss: 0.4565327912569046, Final Batch Loss: 0.12283101677894592\n",
      "Epoch 4406, Loss: 0.4566941559314728, Final Batch Loss: 0.18350686132907867\n",
      "Epoch 4407, Loss: 0.4166581481695175, Final Batch Loss: 0.10015013813972473\n",
      "Epoch 4408, Loss: 0.47112002968788147, Final Batch Loss: 0.21260394155979156\n",
      "Epoch 4409, Loss: 0.4949333071708679, Final Batch Loss: 0.1871308535337448\n",
      "Epoch 4410, Loss: 0.4327910840511322, Final Batch Loss: 0.14104300737380981\n",
      "Epoch 4411, Loss: 0.47019001841545105, Final Batch Loss: 0.14462915062904358\n",
      "Epoch 4412, Loss: 0.42323771864175797, Final Batch Loss: 0.12395461648702621\n",
      "Epoch 4413, Loss: 0.37733422964811325, Final Batch Loss: 0.14033298194408417\n",
      "Epoch 4414, Loss: 0.4655783325433731, Final Batch Loss: 0.15290793776512146\n",
      "Epoch 4415, Loss: 0.5487177819013596, Final Batch Loss: 0.26993075013160706\n",
      "Epoch 4416, Loss: 0.4257806986570358, Final Batch Loss: 0.15970471501350403\n",
      "Epoch 4417, Loss: 0.4118310958147049, Final Batch Loss: 0.14009606838226318\n",
      "Epoch 4418, Loss: 0.45190098881721497, Final Batch Loss: 0.14219330251216888\n",
      "Epoch 4419, Loss: 0.4072798565030098, Final Batch Loss: 0.12809279561042786\n",
      "Epoch 4420, Loss: 0.3556210696697235, Final Batch Loss: 0.1225300282239914\n",
      "Epoch 4421, Loss: 0.3821490481495857, Final Batch Loss: 0.09154204279184341\n",
      "Epoch 4422, Loss: 0.4782882332801819, Final Batch Loss: 0.1835940182209015\n",
      "Epoch 4423, Loss: 0.37568528205156326, Final Batch Loss: 0.08563477545976639\n",
      "Epoch 4424, Loss: 0.38793855160474777, Final Batch Loss: 0.10359527170658112\n",
      "Epoch 4425, Loss: 0.3717050999403, Final Batch Loss: 0.1475508064031601\n",
      "Epoch 4426, Loss: 0.3874603286385536, Final Batch Loss: 0.1042509451508522\n",
      "Epoch 4427, Loss: 0.34693649411201477, Final Batch Loss: 0.08922669291496277\n",
      "Epoch 4428, Loss: 0.47034671902656555, Final Batch Loss: 0.2577999234199524\n",
      "Epoch 4429, Loss: 0.4614522233605385, Final Batch Loss: 0.08346699923276901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4430, Loss: 0.5381138175725937, Final Batch Loss: 0.17108038067817688\n",
      "Epoch 4431, Loss: 0.4658866375684738, Final Batch Loss: 0.14789915084838867\n",
      "Epoch 4432, Loss: 0.41756734251976013, Final Batch Loss: 0.173226997256279\n",
      "Epoch 4433, Loss: 0.4351436272263527, Final Batch Loss: 0.19309470057487488\n",
      "Epoch 4434, Loss: 0.3610099032521248, Final Batch Loss: 0.1335604041814804\n",
      "Epoch 4435, Loss: 0.5087239891290665, Final Batch Loss: 0.127313494682312\n",
      "Epoch 4436, Loss: 0.4264140725135803, Final Batch Loss: 0.12204205244779587\n",
      "Epoch 4437, Loss: 0.4627046436071396, Final Batch Loss: 0.17266780138015747\n",
      "Epoch 4438, Loss: 0.4969380646944046, Final Batch Loss: 0.18862643837928772\n",
      "Epoch 4439, Loss: 0.3791452720761299, Final Batch Loss: 0.08259467780590057\n",
      "Epoch 4440, Loss: 0.4619012624025345, Final Batch Loss: 0.1574629247188568\n",
      "Epoch 4441, Loss: 0.4640606790781021, Final Batch Loss: 0.15899719297885895\n",
      "Epoch 4442, Loss: 0.4524244889616966, Final Batch Loss: 0.2131841629743576\n",
      "Epoch 4443, Loss: 0.5303166955709457, Final Batch Loss: 0.19758112728595734\n",
      "Epoch 4444, Loss: 0.49054597318172455, Final Batch Loss: 0.19093377888202667\n",
      "Epoch 4445, Loss: 0.43836861848831177, Final Batch Loss: 0.12185242772102356\n",
      "Epoch 4446, Loss: 0.5510444194078445, Final Batch Loss: 0.2512764632701874\n",
      "Epoch 4447, Loss: 0.4337351992726326, Final Batch Loss: 0.11265525966882706\n",
      "Epoch 4448, Loss: 0.4406987726688385, Final Batch Loss: 0.13070593774318695\n",
      "Epoch 4449, Loss: 0.5133807808160782, Final Batch Loss: 0.17863041162490845\n",
      "Epoch 4450, Loss: 0.5480205416679382, Final Batch Loss: 0.24872349202632904\n",
      "Epoch 4451, Loss: 0.35393258929252625, Final Batch Loss: 0.11238132417201996\n",
      "Epoch 4452, Loss: 0.4503718838095665, Final Batch Loss: 0.18128879368305206\n",
      "Epoch 4453, Loss: 0.3673217445611954, Final Batch Loss: 0.0955640971660614\n",
      "Epoch 4454, Loss: 0.49318814277648926, Final Batch Loss: 0.19567865133285522\n",
      "Epoch 4455, Loss: 0.34712492674589157, Final Batch Loss: 0.11352860182523727\n",
      "Epoch 4456, Loss: 0.43839582055807114, Final Batch Loss: 0.113605797290802\n",
      "Epoch 4457, Loss: 0.45100873708724976, Final Batch Loss: 0.14937305450439453\n",
      "Epoch 4458, Loss: 0.4247298538684845, Final Batch Loss: 0.15266120433807373\n",
      "Epoch 4459, Loss: 0.419105164706707, Final Batch Loss: 0.10622035712003708\n",
      "Epoch 4460, Loss: 0.4723983407020569, Final Batch Loss: 0.1510215699672699\n",
      "Epoch 4461, Loss: 0.41568803787231445, Final Batch Loss: 0.10962772369384766\n",
      "Epoch 4462, Loss: 0.3934556245803833, Final Batch Loss: 0.12597891688346863\n",
      "Epoch 4463, Loss: 0.47950010001659393, Final Batch Loss: 0.18082007765769958\n",
      "Epoch 4464, Loss: 0.518685519695282, Final Batch Loss: 0.1190737932920456\n",
      "Epoch 4465, Loss: 0.421889528632164, Final Batch Loss: 0.15070408582687378\n",
      "Epoch 4466, Loss: 0.5117428302764893, Final Batch Loss: 0.2643093466758728\n",
      "Epoch 4467, Loss: 0.4525955319404602, Final Batch Loss: 0.15906469523906708\n",
      "Epoch 4468, Loss: 0.44737502187490463, Final Batch Loss: 0.10952084511518478\n",
      "Epoch 4469, Loss: 0.3856278732419014, Final Batch Loss: 0.1759939193725586\n",
      "Epoch 4470, Loss: 0.6507585495710373, Final Batch Loss: 0.18847228586673737\n",
      "Epoch 4471, Loss: 0.44197598844766617, Final Batch Loss: 0.09728307276964188\n",
      "Epoch 4472, Loss: 0.3549884334206581, Final Batch Loss: 0.12397453933954239\n",
      "Epoch 4473, Loss: 0.4703838527202606, Final Batch Loss: 0.1791694313287735\n",
      "Epoch 4474, Loss: 0.3997261971235275, Final Batch Loss: 0.11743728816509247\n",
      "Epoch 4475, Loss: 0.4703797847032547, Final Batch Loss: 0.176188662648201\n",
      "Epoch 4476, Loss: 0.48396532237529755, Final Batch Loss: 0.14892779290676117\n",
      "Epoch 4477, Loss: 0.4635099321603775, Final Batch Loss: 0.1786484569311142\n",
      "Epoch 4478, Loss: 0.45008082687854767, Final Batch Loss: 0.10960559546947479\n",
      "Epoch 4479, Loss: 0.4143311604857445, Final Batch Loss: 0.09588520973920822\n",
      "Epoch 4480, Loss: 0.4869568943977356, Final Batch Loss: 0.09068898856639862\n",
      "Epoch 4481, Loss: 0.4708794504404068, Final Batch Loss: 0.1018417477607727\n",
      "Epoch 4482, Loss: 0.33023974299430847, Final Batch Loss: 0.110692597925663\n",
      "Epoch 4483, Loss: 0.4940663203597069, Final Batch Loss: 0.19779974222183228\n",
      "Epoch 4484, Loss: 0.48460938036441803, Final Batch Loss: 0.16451388597488403\n",
      "Epoch 4485, Loss: 0.5543737560510635, Final Batch Loss: 0.22282736003398895\n",
      "Epoch 4486, Loss: 0.4263343960046768, Final Batch Loss: 0.14272558689117432\n",
      "Epoch 4487, Loss: 0.4619790017604828, Final Batch Loss: 0.17318095266819\n",
      "Epoch 4488, Loss: 0.5614544749259949, Final Batch Loss: 0.19169814884662628\n",
      "Epoch 4489, Loss: 0.405457504093647, Final Batch Loss: 0.11616263538599014\n",
      "Epoch 4490, Loss: 0.520080178976059, Final Batch Loss: 0.16225594282150269\n",
      "Epoch 4491, Loss: 0.45525217801332474, Final Batch Loss: 0.2056015133857727\n",
      "Epoch 4492, Loss: 0.5152651816606522, Final Batch Loss: 0.1423216015100479\n",
      "Epoch 4493, Loss: 0.3851996213197708, Final Batch Loss: 0.1449500471353531\n",
      "Epoch 4494, Loss: 0.5699910223484039, Final Batch Loss: 0.26652249693870544\n",
      "Epoch 4495, Loss: 0.4166790656745434, Final Batch Loss: 0.05577942356467247\n",
      "Epoch 4496, Loss: 0.457539439201355, Final Batch Loss: 0.1525932103395462\n",
      "Epoch 4497, Loss: 0.5093965530395508, Final Batch Loss: 0.24481531977653503\n",
      "Epoch 4498, Loss: 0.5479230284690857, Final Batch Loss: 0.1692749708890915\n",
      "Epoch 4499, Loss: 0.4493786245584488, Final Batch Loss: 0.1733381301164627\n",
      "Epoch 4500, Loss: 0.44841431081295013, Final Batch Loss: 0.14161677658557892\n",
      "Epoch 4501, Loss: 0.5344598740339279, Final Batch Loss: 0.24896620213985443\n",
      "Epoch 4502, Loss: 0.4378778636455536, Final Batch Loss: 0.17888425290584564\n",
      "Epoch 4503, Loss: 0.554119348526001, Final Batch Loss: 0.21166275441646576\n",
      "Epoch 4504, Loss: 0.3711470514535904, Final Batch Loss: 0.16432708501815796\n",
      "Epoch 4505, Loss: 0.4112226217985153, Final Batch Loss: 0.13261131942272186\n",
      "Epoch 4506, Loss: 0.5481591522693634, Final Batch Loss: 0.24447554349899292\n",
      "Epoch 4507, Loss: 0.382935032248497, Final Batch Loss: 0.07774695754051208\n",
      "Epoch 4508, Loss: 0.3648636192083359, Final Batch Loss: 0.1361810863018036\n",
      "Epoch 4509, Loss: 0.4776804447174072, Final Batch Loss: 0.14202891290187836\n",
      "Epoch 4510, Loss: 0.41969534754753113, Final Batch Loss: 0.1471421867609024\n",
      "Epoch 4511, Loss: 0.4707241728901863, Final Batch Loss: 0.21437200903892517\n",
      "Epoch 4512, Loss: 0.4542585760354996, Final Batch Loss: 0.17623421549797058\n",
      "Epoch 4513, Loss: 0.4566168189048767, Final Batch Loss: 0.1680230051279068\n",
      "Epoch 4514, Loss: 0.5892210304737091, Final Batch Loss: 0.27751424908638\n",
      "Epoch 4515, Loss: 0.4620513767004013, Final Batch Loss: 0.1679852455854416\n",
      "Epoch 4516, Loss: 0.3878535106778145, Final Batch Loss: 0.0919298604130745\n",
      "Epoch 4517, Loss: 0.4578879699110985, Final Batch Loss: 0.08299697190523148\n",
      "Epoch 4518, Loss: 0.392580971121788, Final Batch Loss: 0.09981349110603333\n",
      "Epoch 4519, Loss: 0.5716075301170349, Final Batch Loss: 0.22702772915363312\n",
      "Epoch 4520, Loss: 0.3596651628613472, Final Batch Loss: 0.09824762493371964\n",
      "Epoch 4521, Loss: 0.4170946627855301, Final Batch Loss: 0.09812401235103607\n",
      "Epoch 4522, Loss: 0.4284512549638748, Final Batch Loss: 0.15711115300655365\n",
      "Epoch 4523, Loss: 0.4267493858933449, Final Batch Loss: 0.1678662747144699\n",
      "Epoch 4524, Loss: 0.44033485651016235, Final Batch Loss: 0.17275743186473846\n",
      "Epoch 4525, Loss: 0.47491954267024994, Final Batch Loss: 0.18651193380355835\n",
      "Epoch 4526, Loss: 0.46688975393772125, Final Batch Loss: 0.12341910600662231\n",
      "Epoch 4527, Loss: 0.45114216208457947, Final Batch Loss: 0.15800723433494568\n",
      "Epoch 4528, Loss: 0.3250192403793335, Final Batch Loss: 0.11066529899835587\n",
      "Epoch 4529, Loss: 0.46339428424835205, Final Batch Loss: 0.19371575117111206\n",
      "Epoch 4530, Loss: 0.38568607717752457, Final Batch Loss: 0.09626971185207367\n",
      "Epoch 4531, Loss: 0.4012359753251076, Final Batch Loss: 0.16913257539272308\n",
      "Epoch 4532, Loss: 0.4496193528175354, Final Batch Loss: 0.16550807654857635\n",
      "Epoch 4533, Loss: 0.5065559297800064, Final Batch Loss: 0.17994557321071625\n",
      "Epoch 4534, Loss: 0.3865859732031822, Final Batch Loss: 0.13494990766048431\n",
      "Epoch 4535, Loss: 0.32184259593486786, Final Batch Loss: 0.08664087951183319\n",
      "Epoch 4536, Loss: 0.44148488342761993, Final Batch Loss: 0.1059177815914154\n",
      "Epoch 4537, Loss: 0.33034008741378784, Final Batch Loss: 0.12812909483909607\n",
      "Epoch 4538, Loss: 0.3906113803386688, Final Batch Loss: 0.08255940675735474\n",
      "Epoch 4539, Loss: 0.5462796241044998, Final Batch Loss: 0.1958431452512741\n",
      "Epoch 4540, Loss: 0.5589895695447922, Final Batch Loss: 0.18633876740932465\n",
      "Epoch 4541, Loss: 0.44983720779418945, Final Batch Loss: 0.11249718070030212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4542, Loss: 0.45241865515708923, Final Batch Loss: 0.1518816500902176\n",
      "Epoch 4543, Loss: 0.38066455721855164, Final Batch Loss: 0.13852666318416595\n",
      "Epoch 4544, Loss: 0.5884749889373779, Final Batch Loss: 0.19052615761756897\n",
      "Epoch 4545, Loss: 0.5750162899494171, Final Batch Loss: 0.16103099286556244\n",
      "Epoch 4546, Loss: 0.5571713745594025, Final Batch Loss: 0.23352715373039246\n",
      "Epoch 4547, Loss: 0.38370151817798615, Final Batch Loss: 0.14643335342407227\n",
      "Epoch 4548, Loss: 0.4633272588253021, Final Batch Loss: 0.10544413328170776\n",
      "Epoch 4549, Loss: 0.43004441261291504, Final Batch Loss: 0.13561396300792694\n",
      "Epoch 4550, Loss: 0.5109570771455765, Final Batch Loss: 0.1924286037683487\n",
      "Epoch 4551, Loss: 0.3622833490371704, Final Batch Loss: 0.08951309323310852\n",
      "Epoch 4552, Loss: 0.3091781958937645, Final Batch Loss: 0.07800950109958649\n",
      "Epoch 4553, Loss: 0.419867642223835, Final Batch Loss: 0.16408900916576385\n",
      "Epoch 4554, Loss: 0.3900865763425827, Final Batch Loss: 0.13177312910556793\n",
      "Epoch 4555, Loss: 0.4002178683876991, Final Batch Loss: 0.15591946244239807\n",
      "Epoch 4556, Loss: 0.43588224798440933, Final Batch Loss: 0.19099700450897217\n",
      "Epoch 4557, Loss: 0.44469188898801804, Final Batch Loss: 0.11818846315145493\n",
      "Epoch 4558, Loss: 0.371384359896183, Final Batch Loss: 0.09330949932336807\n",
      "Epoch 4559, Loss: 0.41495421528816223, Final Batch Loss: 0.1387176215648651\n",
      "Epoch 4560, Loss: 0.485138438642025, Final Batch Loss: 0.20356978476047516\n",
      "Epoch 4561, Loss: 0.5329908803105354, Final Batch Loss: 0.12109386175870895\n",
      "Epoch 4562, Loss: 0.431877925992012, Final Batch Loss: 0.1374010145664215\n",
      "Epoch 4563, Loss: 0.4107286036014557, Final Batch Loss: 0.15312239527702332\n",
      "Epoch 4564, Loss: 0.43409765511751175, Final Batch Loss: 0.1505546271800995\n",
      "Epoch 4565, Loss: 0.5314024537801743, Final Batch Loss: 0.17776015400886536\n",
      "Epoch 4566, Loss: 0.474574014544487, Final Batch Loss: 0.13525401055812836\n",
      "Epoch 4567, Loss: 0.3201463371515274, Final Batch Loss: 0.05239236354827881\n",
      "Epoch 4568, Loss: 0.4128071665763855, Final Batch Loss: 0.14123904705047607\n",
      "Epoch 4569, Loss: 0.4086656719446182, Final Batch Loss: 0.13593105971813202\n",
      "Epoch 4570, Loss: 0.43104588240385056, Final Batch Loss: 0.10679350048303604\n",
      "Epoch 4571, Loss: 0.3828524574637413, Final Batch Loss: 0.1405378133058548\n",
      "Epoch 4572, Loss: 0.4939512610435486, Final Batch Loss: 0.13285616040229797\n",
      "Epoch 4573, Loss: 0.47014427185058594, Final Batch Loss: 0.12267740070819855\n",
      "Epoch 4574, Loss: 0.5079174041748047, Final Batch Loss: 0.2686757743358612\n",
      "Epoch 4575, Loss: 0.3480336368083954, Final Batch Loss: 0.13784359395503998\n",
      "Epoch 4576, Loss: 0.43172550201416016, Final Batch Loss: 0.1359664797782898\n",
      "Epoch 4577, Loss: 0.4743661880493164, Final Batch Loss: 0.12729133665561676\n",
      "Epoch 4578, Loss: 0.4136539101600647, Final Batch Loss: 0.16657456755638123\n",
      "Epoch 4579, Loss: 0.4237139895558357, Final Batch Loss: 0.16460181772708893\n",
      "Epoch 4580, Loss: 0.4006681516766548, Final Batch Loss: 0.11149998754262924\n",
      "Epoch 4581, Loss: 0.3677843436598778, Final Batch Loss: 0.08299171179533005\n",
      "Epoch 4582, Loss: 0.42898858338594437, Final Batch Loss: 0.09877267479896545\n",
      "Epoch 4583, Loss: 0.4843668192625046, Final Batch Loss: 0.15688610076904297\n",
      "Epoch 4584, Loss: 0.41923320293426514, Final Batch Loss: 0.15790672600269318\n",
      "Epoch 4585, Loss: 0.4685257747769356, Final Batch Loss: 0.11503308266401291\n",
      "Epoch 4586, Loss: 0.4329545423388481, Final Batch Loss: 0.1705487221479416\n",
      "Epoch 4587, Loss: 0.41889968514442444, Final Batch Loss: 0.10906428098678589\n",
      "Epoch 4588, Loss: 0.4737342447042465, Final Batch Loss: 0.20540010929107666\n",
      "Epoch 4589, Loss: 0.48055338859558105, Final Batch Loss: 0.22371689975261688\n",
      "Epoch 4590, Loss: 0.4969293922185898, Final Batch Loss: 0.21430878341197968\n",
      "Epoch 4591, Loss: 0.369593009352684, Final Batch Loss: 0.11137205362319946\n",
      "Epoch 4592, Loss: 0.3455594927072525, Final Batch Loss: 0.11810974031686783\n",
      "Epoch 4593, Loss: 0.3892056569457054, Final Batch Loss: 0.12735852599143982\n",
      "Epoch 4594, Loss: 0.4645621180534363, Final Batch Loss: 0.1863810420036316\n",
      "Epoch 4595, Loss: 0.4960878789424896, Final Batch Loss: 0.13001908361911774\n",
      "Epoch 4596, Loss: 0.4126741960644722, Final Batch Loss: 0.1742837131023407\n",
      "Epoch 4597, Loss: 0.42068933323025703, Final Batch Loss: 0.056433890014886856\n",
      "Epoch 4598, Loss: 0.34650493413209915, Final Batch Loss: 0.07348296791315079\n",
      "Epoch 4599, Loss: 0.40631982311606407, Final Batch Loss: 0.06230654940009117\n",
      "Epoch 4600, Loss: 0.3294663801789284, Final Batch Loss: 0.11674404889345169\n",
      "Epoch 4601, Loss: 0.43234865367412567, Final Batch Loss: 0.1533627063035965\n",
      "Epoch 4602, Loss: 0.5365011245012283, Final Batch Loss: 0.208090141415596\n",
      "Epoch 4603, Loss: 0.3944733962416649, Final Batch Loss: 0.12704680860042572\n",
      "Epoch 4604, Loss: 0.37761101871728897, Final Batch Loss: 0.12492284178733826\n",
      "Epoch 4605, Loss: 0.4856713116168976, Final Batch Loss: 0.15624672174453735\n",
      "Epoch 4606, Loss: 0.47853751480579376, Final Batch Loss: 0.14009006321430206\n",
      "Epoch 4607, Loss: 0.3245110586285591, Final Batch Loss: 0.10359815508127213\n",
      "Epoch 4608, Loss: 0.47963622212409973, Final Batch Loss: 0.15732964873313904\n",
      "Epoch 4609, Loss: 0.43646423518657684, Final Batch Loss: 0.12603327631950378\n",
      "Epoch 4610, Loss: 0.5271101146936417, Final Batch Loss: 0.19851453602313995\n",
      "Epoch 4611, Loss: 0.406834252178669, Final Batch Loss: 0.13820913434028625\n",
      "Epoch 4612, Loss: 0.38703007251024246, Final Batch Loss: 0.12082527577877045\n",
      "Epoch 4613, Loss: 0.419689305126667, Final Batch Loss: 0.12088590115308762\n",
      "Epoch 4614, Loss: 0.41711439937353134, Final Batch Loss: 0.1473044753074646\n",
      "Epoch 4615, Loss: 0.4015587493777275, Final Batch Loss: 0.11424306035041809\n",
      "Epoch 4616, Loss: 0.4492573067545891, Final Batch Loss: 0.17351503670215607\n",
      "Epoch 4617, Loss: 0.47748996317386627, Final Batch Loss: 0.21420134603977203\n",
      "Epoch 4618, Loss: 0.4111398905515671, Final Batch Loss: 0.12602300941944122\n",
      "Epoch 4619, Loss: 0.4824473559856415, Final Batch Loss: 0.17908093333244324\n",
      "Epoch 4620, Loss: 0.5351193994283676, Final Batch Loss: 0.23783834278583527\n",
      "Epoch 4621, Loss: 0.5215844064950943, Final Batch Loss: 0.22124776244163513\n",
      "Epoch 4622, Loss: 0.42295654118061066, Final Batch Loss: 0.13479582965373993\n",
      "Epoch 4623, Loss: 0.44300413131713867, Final Batch Loss: 0.1342959851026535\n",
      "Epoch 4624, Loss: 0.41403182595968246, Final Batch Loss: 0.0940418466925621\n",
      "Epoch 4625, Loss: 0.4296136125922203, Final Batch Loss: 0.12098110467195511\n",
      "Epoch 4626, Loss: 0.37056146562099457, Final Batch Loss: 0.11791224777698517\n",
      "Epoch 4627, Loss: 0.3730298578739166, Final Batch Loss: 0.07977135479450226\n",
      "Epoch 4628, Loss: 0.4485067278146744, Final Batch Loss: 0.13993103802204132\n",
      "Epoch 4629, Loss: 0.42104221135377884, Final Batch Loss: 0.17215204238891602\n",
      "Epoch 4630, Loss: 0.393399715423584, Final Batch Loss: 0.10504616796970367\n",
      "Epoch 4631, Loss: 0.4745483100414276, Final Batch Loss: 0.1545918881893158\n",
      "Epoch 4632, Loss: 0.521163173019886, Final Batch Loss: 0.10776963084936142\n",
      "Epoch 4633, Loss: 0.4638740122318268, Final Batch Loss: 0.15954288840293884\n",
      "Epoch 4634, Loss: 0.44838329404592514, Final Batch Loss: 0.17788641154766083\n",
      "Epoch 4635, Loss: 0.5142130851745605, Final Batch Loss: 0.22564786672592163\n",
      "Epoch 4636, Loss: 0.472010537981987, Final Batch Loss: 0.14872488379478455\n",
      "Epoch 4637, Loss: 0.42577578872442245, Final Batch Loss: 0.10997030884027481\n",
      "Epoch 4638, Loss: 0.4320932775735855, Final Batch Loss: 0.17627660930156708\n",
      "Epoch 4639, Loss: 0.4803774058818817, Final Batch Loss: 0.10576599836349487\n",
      "Epoch 4640, Loss: 0.37473874539136887, Final Batch Loss: 0.11306077986955643\n",
      "Epoch 4641, Loss: 0.3798392713069916, Final Batch Loss: 0.12330763041973114\n",
      "Epoch 4642, Loss: 0.5138915926218033, Final Batch Loss: 0.206683948636055\n",
      "Epoch 4643, Loss: 0.4213814362883568, Final Batch Loss: 0.16560937464237213\n",
      "Epoch 4644, Loss: 0.45423537492752075, Final Batch Loss: 0.16887763142585754\n",
      "Epoch 4645, Loss: 0.517289437353611, Final Batch Loss: 0.124435193836689\n",
      "Epoch 4646, Loss: 0.402901291847229, Final Batch Loss: 0.14419862627983093\n",
      "Epoch 4647, Loss: 0.3956110253930092, Final Batch Loss: 0.1200520470738411\n",
      "Epoch 4648, Loss: 0.4846304655075073, Final Batch Loss: 0.19543717801570892\n",
      "Epoch 4649, Loss: 0.4355824440717697, Final Batch Loss: 0.1571398824453354\n",
      "Epoch 4650, Loss: 0.4881826192140579, Final Batch Loss: 0.18787652254104614\n",
      "Epoch 4651, Loss: 0.4159543365240097, Final Batch Loss: 0.16147547960281372\n",
      "Epoch 4652, Loss: 0.4896891340613365, Final Batch Loss: 0.0972503051161766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4653, Loss: 0.4128994941711426, Final Batch Loss: 0.16764025390148163\n",
      "Epoch 4654, Loss: 0.3549548350274563, Final Batch Loss: 0.05916130170226097\n",
      "Epoch 4655, Loss: 0.3787071853876114, Final Batch Loss: 0.08538801968097687\n",
      "Epoch 4656, Loss: 0.3651565760374069, Final Batch Loss: 0.10919982194900513\n",
      "Epoch 4657, Loss: 0.32471849769353867, Final Batch Loss: 0.11516063660383224\n",
      "Epoch 4658, Loss: 0.40638355910778046, Final Batch Loss: 0.1532505303621292\n",
      "Epoch 4659, Loss: 0.37762535363435745, Final Batch Loss: 0.07854873687028885\n",
      "Epoch 4660, Loss: 0.42791692167520523, Final Batch Loss: 0.10250798612833023\n",
      "Epoch 4661, Loss: 0.45061735808849335, Final Batch Loss: 0.19254842400550842\n",
      "Epoch 4662, Loss: 0.39273542165756226, Final Batch Loss: 0.14357039332389832\n",
      "Epoch 4663, Loss: 0.5140551030635834, Final Batch Loss: 0.1811273694038391\n",
      "Epoch 4664, Loss: 0.44445547461509705, Final Batch Loss: 0.15729981660842896\n",
      "Epoch 4665, Loss: 0.36087216436862946, Final Batch Loss: 0.14463375508785248\n",
      "Epoch 4666, Loss: 0.3985859751701355, Final Batch Loss: 0.10739432275295258\n",
      "Epoch 4667, Loss: 0.3328906185925007, Final Batch Loss: 0.05800854042172432\n",
      "Epoch 4668, Loss: 0.3935818672180176, Final Batch Loss: 0.11611312627792358\n",
      "Epoch 4669, Loss: 0.5393963754177094, Final Batch Loss: 0.22981694340705872\n",
      "Epoch 4670, Loss: 0.40628253668546677, Final Batch Loss: 0.18404905498027802\n",
      "Epoch 4671, Loss: 0.3906836435198784, Final Batch Loss: 0.12953457236289978\n",
      "Epoch 4672, Loss: 0.5527184084057808, Final Batch Loss: 0.2677132785320282\n",
      "Epoch 4673, Loss: 0.5023111999034882, Final Batch Loss: 0.18455012142658234\n",
      "Epoch 4674, Loss: 0.3793821558356285, Final Batch Loss: 0.09001383930444717\n",
      "Epoch 4675, Loss: 0.5460445880889893, Final Batch Loss: 0.17853668332099915\n",
      "Epoch 4676, Loss: 0.41402262449264526, Final Batch Loss: 0.13448499143123627\n",
      "Epoch 4677, Loss: 0.35194582492113113, Final Batch Loss: 0.09000685065984726\n",
      "Epoch 4678, Loss: 0.4584503620862961, Final Batch Loss: 0.12414076924324036\n",
      "Epoch 4679, Loss: 0.523091658949852, Final Batch Loss: 0.2126653492450714\n",
      "Epoch 4680, Loss: 0.38907986879348755, Final Batch Loss: 0.07591823488473892\n",
      "Epoch 4681, Loss: 0.5028893053531647, Final Batch Loss: 0.13644708693027496\n",
      "Epoch 4682, Loss: 0.47848527133464813, Final Batch Loss: 0.2098672240972519\n",
      "Epoch 4683, Loss: 0.4333205372095108, Final Batch Loss: 0.128688246011734\n",
      "Epoch 4684, Loss: 0.41230326890945435, Final Batch Loss: 0.13328373432159424\n",
      "Epoch 4685, Loss: 0.385830856859684, Final Batch Loss: 0.12786982953548431\n",
      "Epoch 4686, Loss: 0.4428577795624733, Final Batch Loss: 0.14342595636844635\n",
      "Epoch 4687, Loss: 0.35018518567085266, Final Batch Loss: 0.10530953109264374\n",
      "Epoch 4688, Loss: 0.36595381051301956, Final Batch Loss: 0.10859913378953934\n",
      "Epoch 4689, Loss: 0.4800288826227188, Final Batch Loss: 0.1470586061477661\n",
      "Epoch 4690, Loss: 0.46160583198070526, Final Batch Loss: 0.15687616169452667\n",
      "Epoch 4691, Loss: 0.4114528000354767, Final Batch Loss: 0.12089456617832184\n",
      "Epoch 4692, Loss: 0.36222081631422043, Final Batch Loss: 0.07541420310735703\n",
      "Epoch 4693, Loss: 0.4176074415445328, Final Batch Loss: 0.14504073560237885\n",
      "Epoch 4694, Loss: 0.44793589413166046, Final Batch Loss: 0.12571996450424194\n",
      "Epoch 4695, Loss: 0.47053324431180954, Final Batch Loss: 0.22379609942436218\n",
      "Epoch 4696, Loss: 0.49625176191329956, Final Batch Loss: 0.07313166558742523\n",
      "Epoch 4697, Loss: 0.714729554951191, Final Batch Loss: 0.3068186342716217\n",
      "Epoch 4698, Loss: 0.4957890063524246, Final Batch Loss: 0.1739620417356491\n",
      "Epoch 4699, Loss: 0.4448288679122925, Final Batch Loss: 0.15618406236171722\n",
      "Epoch 4700, Loss: 0.5629351884126663, Final Batch Loss: 0.18528582155704498\n",
      "Epoch 4701, Loss: 0.4809815362095833, Final Batch Loss: 0.10430959612131119\n",
      "Epoch 4702, Loss: 0.47012294828891754, Final Batch Loss: 0.14177285134792328\n",
      "Epoch 4703, Loss: 0.46591171622276306, Final Batch Loss: 0.19392642378807068\n",
      "Epoch 4704, Loss: 0.507525771856308, Final Batch Loss: 0.19237811863422394\n",
      "Epoch 4705, Loss: 0.5074135065078735, Final Batch Loss: 0.14246636629104614\n",
      "Epoch 4706, Loss: 0.41653233021497726, Final Batch Loss: 0.10132726281881332\n",
      "Epoch 4707, Loss: 0.45997487008571625, Final Batch Loss: 0.10623732209205627\n",
      "Epoch 4708, Loss: 0.4278557747602463, Final Batch Loss: 0.14704471826553345\n",
      "Epoch 4709, Loss: 0.6420092880725861, Final Batch Loss: 0.2796618640422821\n",
      "Epoch 4710, Loss: 0.44649676978588104, Final Batch Loss: 0.15048734843730927\n",
      "Epoch 4711, Loss: 0.3939666152000427, Final Batch Loss: 0.18732179701328278\n",
      "Epoch 4712, Loss: 0.4674759954214096, Final Batch Loss: 0.16528016328811646\n",
      "Epoch 4713, Loss: 0.40191931277513504, Final Batch Loss: 0.18186965584754944\n",
      "Epoch 4714, Loss: 0.38678787648677826, Final Batch Loss: 0.10016196966171265\n",
      "Epoch 4715, Loss: 0.4068279266357422, Final Batch Loss: 0.1618374139070511\n",
      "Epoch 4716, Loss: 0.3800775930285454, Final Batch Loss: 0.10809562355279922\n",
      "Epoch 4717, Loss: 0.45894091576337814, Final Batch Loss: 0.16200676560401917\n",
      "Epoch 4718, Loss: 0.4197176769375801, Final Batch Loss: 0.11301719397306442\n",
      "Epoch 4719, Loss: 0.4676646962761879, Final Batch Loss: 0.21398821473121643\n",
      "Epoch 4720, Loss: 0.3784846365451813, Final Batch Loss: 0.09031669795513153\n",
      "Epoch 4721, Loss: 0.451484352350235, Final Batch Loss: 0.1492464691400528\n",
      "Epoch 4722, Loss: 0.4003538563847542, Final Batch Loss: 0.17083321511745453\n",
      "Epoch 4723, Loss: 0.5082609057426453, Final Batch Loss: 0.1861756294965744\n",
      "Epoch 4724, Loss: 0.4760841801762581, Final Batch Loss: 0.12234336882829666\n",
      "Epoch 4725, Loss: 0.3723004385828972, Final Batch Loss: 0.10258788615465164\n",
      "Epoch 4726, Loss: 0.39924994856119156, Final Batch Loss: 0.08969198912382126\n",
      "Epoch 4727, Loss: 0.36638467013835907, Final Batch Loss: 0.10952559113502502\n",
      "Epoch 4728, Loss: 0.37648120522499084, Final Batch Loss: 0.12206336110830307\n",
      "Epoch 4729, Loss: 0.43994635343551636, Final Batch Loss: 0.1579481065273285\n",
      "Epoch 4730, Loss: 0.31749188527464867, Final Batch Loss: 0.053249116986989975\n",
      "Epoch 4731, Loss: 0.4185945391654968, Final Batch Loss: 0.1501171737909317\n",
      "Epoch 4732, Loss: 0.5581414252519608, Final Batch Loss: 0.1822236180305481\n",
      "Epoch 4733, Loss: 0.5628557428717613, Final Batch Loss: 0.30175191164016724\n",
      "Epoch 4734, Loss: 0.6641600877046585, Final Batch Loss: 0.36629030108451843\n",
      "Epoch 4735, Loss: 0.4330015927553177, Final Batch Loss: 0.13242381811141968\n",
      "Epoch 4736, Loss: 0.35124409198760986, Final Batch Loss: 0.11716657131910324\n",
      "Epoch 4737, Loss: 0.46050308644771576, Final Batch Loss: 0.1448812186717987\n",
      "Epoch 4738, Loss: 0.4490331783890724, Final Batch Loss: 0.15673139691352844\n",
      "Epoch 4739, Loss: 0.4421834126114845, Final Batch Loss: 0.13754862546920776\n",
      "Epoch 4740, Loss: 0.3842301145195961, Final Batch Loss: 0.0919027104973793\n",
      "Epoch 4741, Loss: 0.4082949683070183, Final Batch Loss: 0.12602068483829498\n",
      "Epoch 4742, Loss: 0.4906378239393234, Final Batch Loss: 0.15109936892986298\n",
      "Epoch 4743, Loss: 0.4355578199028969, Final Batch Loss: 0.1669347584247589\n",
      "Epoch 4744, Loss: 0.4006775990128517, Final Batch Loss: 0.08966010063886642\n",
      "Epoch 4745, Loss: 0.3516021892428398, Final Batch Loss: 0.07634801417589188\n",
      "Epoch 4746, Loss: 0.4798785373568535, Final Batch Loss: 0.11014733463525772\n",
      "Epoch 4747, Loss: 0.3805916756391525, Final Batch Loss: 0.129255473613739\n",
      "Epoch 4748, Loss: 0.34426604956388474, Final Batch Loss: 0.08988549560308456\n",
      "Epoch 4749, Loss: 0.4142833948135376, Final Batch Loss: 0.1354549080133438\n",
      "Epoch 4750, Loss: 0.4451185166835785, Final Batch Loss: 0.09838557243347168\n",
      "Epoch 4751, Loss: 0.3924138993024826, Final Batch Loss: 0.13840125501155853\n",
      "Epoch 4752, Loss: 0.4506220519542694, Final Batch Loss: 0.15440331399440765\n",
      "Epoch 4753, Loss: 0.40911765396595, Final Batch Loss: 0.1110888123512268\n",
      "Epoch 4754, Loss: 0.43861889839172363, Final Batch Loss: 0.1718844473361969\n",
      "Epoch 4755, Loss: 0.4391910135746002, Final Batch Loss: 0.11187655478715897\n",
      "Epoch 4756, Loss: 0.43961551785469055, Final Batch Loss: 0.15471790730953217\n",
      "Epoch 4757, Loss: 0.44242943823337555, Final Batch Loss: 0.17234066128730774\n",
      "Epoch 4758, Loss: 0.4263898432254791, Final Batch Loss: 0.14486601948738098\n",
      "Epoch 4759, Loss: 0.41080302745103836, Final Batch Loss: 0.16469985246658325\n",
      "Epoch 4760, Loss: 0.43457555770874023, Final Batch Loss: 0.1910296082496643\n",
      "Epoch 4761, Loss: 0.37779686599969864, Final Batch Loss: 0.14652088284492493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4762, Loss: 0.5131600797176361, Final Batch Loss: 0.20198342204093933\n",
      "Epoch 4763, Loss: 0.5183060169219971, Final Batch Loss: 0.20891313254833221\n",
      "Epoch 4764, Loss: 0.4929462745785713, Final Batch Loss: 0.15886765718460083\n",
      "Epoch 4765, Loss: 0.3718007206916809, Final Batch Loss: 0.1531090885400772\n",
      "Epoch 4766, Loss: 0.5280414298176765, Final Batch Loss: 0.23249667882919312\n",
      "Epoch 4767, Loss: 0.44564400613307953, Final Batch Loss: 0.12258648872375488\n",
      "Epoch 4768, Loss: 0.40696682780981064, Final Batch Loss: 0.12952598929405212\n",
      "Epoch 4769, Loss: 0.4709276258945465, Final Batch Loss: 0.1584918051958084\n",
      "Epoch 4770, Loss: 0.4476172626018524, Final Batch Loss: 0.18663261830806732\n",
      "Epoch 4771, Loss: 0.5181242078542709, Final Batch Loss: 0.18330733478069305\n",
      "Epoch 4772, Loss: 0.5002754032611847, Final Batch Loss: 0.15994450449943542\n",
      "Epoch 4773, Loss: 0.38520700484514236, Final Batch Loss: 0.09706566482782364\n",
      "Epoch 4774, Loss: 0.4179753065109253, Final Batch Loss: 0.1384221464395523\n",
      "Epoch 4775, Loss: 0.4236605018377304, Final Batch Loss: 0.1468132734298706\n",
      "Epoch 4776, Loss: 0.500928670167923, Final Batch Loss: 0.137844517827034\n",
      "Epoch 4777, Loss: 0.46215538680553436, Final Batch Loss: 0.13912880420684814\n",
      "Epoch 4778, Loss: 0.46870654821395874, Final Batch Loss: 0.1928897649049759\n",
      "Epoch 4779, Loss: 0.44026049971580505, Final Batch Loss: 0.2140125334262848\n",
      "Epoch 4780, Loss: 0.5159159004688263, Final Batch Loss: 0.17750336229801178\n",
      "Epoch 4781, Loss: 0.3269553631544113, Final Batch Loss: 0.0637173056602478\n",
      "Epoch 4782, Loss: 0.4912228062748909, Final Batch Loss: 0.2709041237831116\n",
      "Epoch 4783, Loss: 0.40970130264759064, Final Batch Loss: 0.09735126793384552\n",
      "Epoch 4784, Loss: 0.44132449477910995, Final Batch Loss: 0.15556557476520538\n",
      "Epoch 4785, Loss: 0.34889406710863113, Final Batch Loss: 0.11178287863731384\n",
      "Epoch 4786, Loss: 0.45422352850437164, Final Batch Loss: 0.15857917070388794\n",
      "Epoch 4787, Loss: 0.40959538519382477, Final Batch Loss: 0.13036394119262695\n",
      "Epoch 4788, Loss: 0.4031710550189018, Final Batch Loss: 0.11873535066843033\n",
      "Epoch 4789, Loss: 0.356688916683197, Final Batch Loss: 0.10545522719621658\n",
      "Epoch 4790, Loss: 0.5076040029525757, Final Batch Loss: 0.19258511066436768\n",
      "Epoch 4791, Loss: 0.7197937220335007, Final Batch Loss: 0.3852168321609497\n",
      "Epoch 4792, Loss: 0.44341688603162766, Final Batch Loss: 0.18639959394931793\n",
      "Epoch 4793, Loss: 0.36445416510105133, Final Batch Loss: 0.138006791472435\n",
      "Epoch 4794, Loss: 0.5553169846534729, Final Batch Loss: 0.19525562226772308\n",
      "Epoch 4795, Loss: 0.5011017173528671, Final Batch Loss: 0.20432856678962708\n",
      "Epoch 4796, Loss: 0.49998804926872253, Final Batch Loss: 0.18555361032485962\n",
      "Epoch 4797, Loss: 0.4865562319755554, Final Batch Loss: 0.2415003627538681\n",
      "Epoch 4798, Loss: 0.4971689134836197, Final Batch Loss: 0.1701963245868683\n",
      "Epoch 4799, Loss: 0.5565349608659744, Final Batch Loss: 0.17177756130695343\n",
      "Epoch 4800, Loss: 0.4970990717411041, Final Batch Loss: 0.13790571689605713\n",
      "Epoch 4801, Loss: 0.36755024641752243, Final Batch Loss: 0.12873141467571259\n",
      "Epoch 4802, Loss: 0.5534445643424988, Final Batch Loss: 0.20277835428714752\n",
      "Epoch 4803, Loss: 0.3718626797199249, Final Batch Loss: 0.1506544053554535\n",
      "Epoch 4804, Loss: 0.32917577028274536, Final Batch Loss: 0.12438926845788956\n",
      "Epoch 4805, Loss: 0.3572138324379921, Final Batch Loss: 0.09486711770296097\n",
      "Epoch 4806, Loss: 0.4430703967809677, Final Batch Loss: 0.11597350239753723\n",
      "Epoch 4807, Loss: 0.46684592962265015, Final Batch Loss: 0.15689754486083984\n",
      "Epoch 4808, Loss: 0.4633507952094078, Final Batch Loss: 0.07807295769453049\n",
      "Epoch 4809, Loss: 0.3829262852668762, Final Batch Loss: 0.12873582541942596\n",
      "Epoch 4810, Loss: 0.4787219762802124, Final Batch Loss: 0.2343336045742035\n",
      "Epoch 4811, Loss: 0.48299577832221985, Final Batch Loss: 0.2050604671239853\n",
      "Epoch 4812, Loss: 0.45642517507076263, Final Batch Loss: 0.14071060717105865\n",
      "Epoch 4813, Loss: 0.41953006386756897, Final Batch Loss: 0.10248531401157379\n",
      "Epoch 4814, Loss: 0.39029280096292496, Final Batch Loss: 0.07914873212575912\n",
      "Epoch 4815, Loss: 0.42670203745365143, Final Batch Loss: 0.1724940538406372\n",
      "Epoch 4816, Loss: 0.4375588968396187, Final Batch Loss: 0.10193382948637009\n",
      "Epoch 4817, Loss: 0.4618118852376938, Final Batch Loss: 0.18567287921905518\n",
      "Epoch 4818, Loss: 0.3990466669201851, Final Batch Loss: 0.17252808809280396\n",
      "Epoch 4819, Loss: 0.5381722822785378, Final Batch Loss: 0.20616929233074188\n",
      "Epoch 4820, Loss: 0.7536936849355698, Final Batch Loss: 0.3082331120967865\n",
      "Epoch 4821, Loss: 0.4252964034676552, Final Batch Loss: 0.1657022386789322\n",
      "Epoch 4822, Loss: 0.4350527748465538, Final Batch Loss: 0.17456325888633728\n",
      "Epoch 4823, Loss: 0.5675439387559891, Final Batch Loss: 0.1455359160900116\n",
      "Epoch 4824, Loss: 0.5397512912750244, Final Batch Loss: 0.1782539188861847\n",
      "Epoch 4825, Loss: 0.4476114362478256, Final Batch Loss: 0.17506545782089233\n",
      "Epoch 4826, Loss: 0.4263821691274643, Final Batch Loss: 0.1705596148967743\n",
      "Epoch 4827, Loss: 0.41253963112831116, Final Batch Loss: 0.1368897706270218\n",
      "Epoch 4828, Loss: 0.47471147775650024, Final Batch Loss: 0.1743052750825882\n",
      "Epoch 4829, Loss: 0.5997107923030853, Final Batch Loss: 0.261407732963562\n",
      "Epoch 4830, Loss: 0.4249398559331894, Final Batch Loss: 0.15300992131233215\n",
      "Epoch 4831, Loss: 0.5544753968715668, Final Batch Loss: 0.24237944185733795\n",
      "Epoch 4832, Loss: 0.3765360340476036, Final Batch Loss: 0.09475795179605484\n",
      "Epoch 4833, Loss: 0.4508597105741501, Final Batch Loss: 0.2136530578136444\n",
      "Epoch 4834, Loss: 0.40276217460632324, Final Batch Loss: 0.08550652861595154\n",
      "Epoch 4835, Loss: 0.5538870096206665, Final Batch Loss: 0.26926252245903015\n",
      "Epoch 4836, Loss: 0.4185342937707901, Final Batch Loss: 0.13940054178237915\n",
      "Epoch 4837, Loss: 0.3549507260322571, Final Batch Loss: 0.09749797731637955\n",
      "Epoch 4838, Loss: 0.35109876841306686, Final Batch Loss: 0.0828760415315628\n",
      "Epoch 4839, Loss: 0.3778334781527519, Final Batch Loss: 0.10916870087385178\n",
      "Epoch 4840, Loss: 0.39001069217920303, Final Batch Loss: 0.1040208712220192\n",
      "Epoch 4841, Loss: 0.5057322233915329, Final Batch Loss: 0.14860612154006958\n",
      "Epoch 4842, Loss: 0.42663510888814926, Final Batch Loss: 0.1628022938966751\n",
      "Epoch 4843, Loss: 0.4686575010418892, Final Batch Loss: 0.17341503500938416\n",
      "Epoch 4844, Loss: 0.5209745317697525, Final Batch Loss: 0.18021231889724731\n",
      "Epoch 4845, Loss: 0.42087262868881226, Final Batch Loss: 0.18327517807483673\n",
      "Epoch 4846, Loss: 0.4787631630897522, Final Batch Loss: 0.17408019304275513\n",
      "Epoch 4847, Loss: 0.4783250167965889, Final Batch Loss: 0.1589292287826538\n",
      "Epoch 4848, Loss: 0.32754605263471603, Final Batch Loss: 0.08901054412126541\n",
      "Epoch 4849, Loss: 0.3862752094864845, Final Batch Loss: 0.12149464339017868\n",
      "Epoch 4850, Loss: 0.38389431685209274, Final Batch Loss: 0.16141192615032196\n",
      "Epoch 4851, Loss: 0.41053950786590576, Final Batch Loss: 0.12489576637744904\n",
      "Epoch 4852, Loss: 0.40437255799770355, Final Batch Loss: 0.10048146545886993\n",
      "Epoch 4853, Loss: 0.4480671063065529, Final Batch Loss: 0.0943169966340065\n",
      "Epoch 4854, Loss: 0.39537104964256287, Final Batch Loss: 0.12684141099452972\n",
      "Epoch 4855, Loss: 0.4444318860769272, Final Batch Loss: 0.09931604564189911\n",
      "Epoch 4856, Loss: 0.43035829067230225, Final Batch Loss: 0.1872560679912567\n",
      "Epoch 4857, Loss: 0.38681796938180923, Final Batch Loss: 0.10587180405855179\n",
      "Epoch 4858, Loss: 0.4605976566672325, Final Batch Loss: 0.19008593261241913\n",
      "Epoch 4859, Loss: 0.5375303328037262, Final Batch Loss: 0.1425781548023224\n",
      "Epoch 4860, Loss: 0.5247016549110413, Final Batch Loss: 0.14681628346443176\n",
      "Epoch 4861, Loss: 0.4381846860051155, Final Batch Loss: 0.19964179396629333\n",
      "Epoch 4862, Loss: 0.457683227956295, Final Batch Loss: 0.21413780748844147\n",
      "Epoch 4863, Loss: 0.5654040575027466, Final Batch Loss: 0.15258429944515228\n",
      "Epoch 4864, Loss: 0.44787437468767166, Final Batch Loss: 0.18843987584114075\n",
      "Epoch 4865, Loss: 0.5298053324222565, Final Batch Loss: 0.1720447987318039\n",
      "Epoch 4866, Loss: 0.5282659977674484, Final Batch Loss: 0.1654938906431198\n",
      "Epoch 4867, Loss: 0.41190895438194275, Final Batch Loss: 0.11185505986213684\n",
      "Epoch 4868, Loss: 0.4003143534064293, Final Batch Loss: 0.14681291580200195\n",
      "Epoch 4869, Loss: 0.39861270040273666, Final Batch Loss: 0.11936133354902267\n",
      "Epoch 4870, Loss: 0.4256174862384796, Final Batch Loss: 0.15465639531612396\n",
      "Epoch 4871, Loss: 0.46058325469493866, Final Batch Loss: 0.1699640303850174\n",
      "Epoch 4872, Loss: 0.415616475045681, Final Batch Loss: 0.12455462664365768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4873, Loss: 0.41228944063186646, Final Batch Loss: 0.138278067111969\n",
      "Epoch 4874, Loss: 0.433736652135849, Final Batch Loss: 0.1327134668827057\n",
      "Epoch 4875, Loss: 0.41243748366832733, Final Batch Loss: 0.11492429673671722\n",
      "Epoch 4876, Loss: 0.5156259387731552, Final Batch Loss: 0.09854595363140106\n",
      "Epoch 4877, Loss: 0.3942326530814171, Final Batch Loss: 0.14936695992946625\n",
      "Epoch 4878, Loss: 0.4471952021121979, Final Batch Loss: 0.18211810290813446\n",
      "Epoch 4879, Loss: 0.43675410002470016, Final Batch Loss: 0.14460568130016327\n",
      "Epoch 4880, Loss: 0.46364420652389526, Final Batch Loss: 0.17876453697681427\n",
      "Epoch 4881, Loss: 0.481264665722847, Final Batch Loss: 0.1537526547908783\n",
      "Epoch 4882, Loss: 0.4902113825082779, Final Batch Loss: 0.24515345692634583\n",
      "Epoch 4883, Loss: 0.4604165032505989, Final Batch Loss: 0.13365252315998077\n",
      "Epoch 4884, Loss: 0.5980794280767441, Final Batch Loss: 0.19337718188762665\n",
      "Epoch 4885, Loss: 0.5458622872829437, Final Batch Loss: 0.23410122096538544\n",
      "Epoch 4886, Loss: 0.4818897843360901, Final Batch Loss: 0.13925951719284058\n",
      "Epoch 4887, Loss: 0.4859766364097595, Final Batch Loss: 0.09236261248588562\n",
      "Epoch 4888, Loss: 0.45057281106710434, Final Batch Loss: 0.1534413844347\n",
      "Epoch 4889, Loss: 0.4211882948875427, Final Batch Loss: 0.1323128342628479\n",
      "Epoch 4890, Loss: 0.5894747525453568, Final Batch Loss: 0.16600410640239716\n",
      "Epoch 4891, Loss: 0.5091576129198074, Final Batch Loss: 0.18974259495735168\n",
      "Epoch 4892, Loss: 0.4163181483745575, Final Batch Loss: 0.11283223330974579\n",
      "Epoch 4893, Loss: 0.5132935494184494, Final Batch Loss: 0.16708777844905853\n",
      "Epoch 4894, Loss: 0.42355892062187195, Final Batch Loss: 0.12879833579063416\n",
      "Epoch 4895, Loss: 0.4695817679166794, Final Batch Loss: 0.12648430466651917\n",
      "Epoch 4896, Loss: 0.5071076452732086, Final Batch Loss: 0.16540656983852386\n",
      "Epoch 4897, Loss: 0.5184984281659126, Final Batch Loss: 0.2836535573005676\n",
      "Epoch 4898, Loss: 0.44567348062992096, Final Batch Loss: 0.1537237912416458\n",
      "Epoch 4899, Loss: 0.43922561407089233, Final Batch Loss: 0.16981977224349976\n",
      "Epoch 4900, Loss: 0.39929571747779846, Final Batch Loss: 0.13845598697662354\n",
      "Epoch 4901, Loss: 0.4431922510266304, Final Batch Loss: 0.1998109072446823\n",
      "Epoch 4902, Loss: 0.41240672767162323, Final Batch Loss: 0.16719529032707214\n",
      "Epoch 4903, Loss: 0.41970106959342957, Final Batch Loss: 0.16032883524894714\n",
      "Epoch 4904, Loss: 0.4011423960328102, Final Batch Loss: 0.08659201115369797\n",
      "Epoch 4905, Loss: 0.42621150612831116, Final Batch Loss: 0.11395899951457977\n",
      "Epoch 4906, Loss: 0.43352609872817993, Final Batch Loss: 0.1263105720281601\n",
      "Epoch 4907, Loss: 0.3800673186779022, Final Batch Loss: 0.118483766913414\n",
      "Epoch 4908, Loss: 0.44488468766212463, Final Batch Loss: 0.18758517503738403\n",
      "Epoch 4909, Loss: 0.46074149012565613, Final Batch Loss: 0.1092337965965271\n",
      "Epoch 4910, Loss: 0.4288913458585739, Final Batch Loss: 0.12969902157783508\n",
      "Epoch 4911, Loss: 0.4259166568517685, Final Batch Loss: 0.0816890150308609\n",
      "Epoch 4912, Loss: 0.3469714894890785, Final Batch Loss: 0.10162809491157532\n",
      "Epoch 4913, Loss: 0.451033279299736, Final Batch Loss: 0.12539008259773254\n",
      "Epoch 4914, Loss: 0.49474965780973434, Final Batch Loss: 0.20021672546863556\n",
      "Epoch 4915, Loss: 0.43112562596797943, Final Batch Loss: 0.141200453042984\n",
      "Epoch 4916, Loss: 0.4583614245057106, Final Batch Loss: 0.19111481308937073\n",
      "Epoch 4917, Loss: 0.3666824772953987, Final Batch Loss: 0.10557227581739426\n",
      "Epoch 4918, Loss: 0.4287322387099266, Final Batch Loss: 0.1561235785484314\n",
      "Epoch 4919, Loss: 0.4291430413722992, Final Batch Loss: 0.1808553785085678\n",
      "Epoch 4920, Loss: 0.4985453635454178, Final Batch Loss: 0.1865423321723938\n",
      "Epoch 4921, Loss: 0.49769654870033264, Final Batch Loss: 0.1760023832321167\n",
      "Epoch 4922, Loss: 0.4955616444349289, Final Batch Loss: 0.1838793009519577\n",
      "Epoch 4923, Loss: 0.45327625423669815, Final Batch Loss: 0.1163838729262352\n",
      "Epoch 4924, Loss: 0.4943395107984543, Final Batch Loss: 0.13495594263076782\n",
      "Epoch 4925, Loss: 0.34483057260513306, Final Batch Loss: 0.07812352478504181\n",
      "Epoch 4926, Loss: 0.4449571669101715, Final Batch Loss: 0.14433731138706207\n",
      "Epoch 4927, Loss: 0.437160387635231, Final Batch Loss: 0.09302973747253418\n",
      "Epoch 4928, Loss: 0.41067415475845337, Final Batch Loss: 0.16171562671661377\n",
      "Epoch 4929, Loss: 0.465506836771965, Final Batch Loss: 0.13883084058761597\n",
      "Epoch 4930, Loss: 0.4363804906606674, Final Batch Loss: 0.14474447071552277\n",
      "Epoch 4931, Loss: 0.44856662303209305, Final Batch Loss: 0.1315508782863617\n",
      "Epoch 4932, Loss: 0.49507853388786316, Final Batch Loss: 0.12556791305541992\n",
      "Epoch 4933, Loss: 0.4594004452228546, Final Batch Loss: 0.13391031324863434\n",
      "Epoch 4934, Loss: 0.6690600141882896, Final Batch Loss: 0.3612375557422638\n",
      "Epoch 4935, Loss: 0.4337126910686493, Final Batch Loss: 0.16481192409992218\n",
      "Epoch 4936, Loss: 0.4214804098010063, Final Batch Loss: 0.14656022191047668\n",
      "Epoch 4937, Loss: 0.5122388452291489, Final Batch Loss: 0.1681709885597229\n",
      "Epoch 4938, Loss: 0.4362645596265793, Final Batch Loss: 0.16835762560367584\n",
      "Epoch 4939, Loss: 0.4834032356739044, Final Batch Loss: 0.07783235609531403\n",
      "Epoch 4940, Loss: 0.377334363758564, Final Batch Loss: 0.15097838640213013\n",
      "Epoch 4941, Loss: 0.409598208963871, Final Batch Loss: 0.0804581567645073\n",
      "Epoch 4942, Loss: 0.4611479490995407, Final Batch Loss: 0.14456447958946228\n",
      "Epoch 4943, Loss: 0.4146393686532974, Final Batch Loss: 0.1336154192686081\n",
      "Epoch 4944, Loss: 0.4251471757888794, Final Batch Loss: 0.12457624077796936\n",
      "Epoch 4945, Loss: 0.63663549721241, Final Batch Loss: 0.22364209592342377\n",
      "Epoch 4946, Loss: 0.5151199698448181, Final Batch Loss: 0.18761350214481354\n",
      "Epoch 4947, Loss: 0.3947981670498848, Final Batch Loss: 0.1509547233581543\n",
      "Epoch 4948, Loss: 0.39702165871858597, Final Batch Loss: 0.09974668174982071\n",
      "Epoch 4949, Loss: 0.46358928084373474, Final Batch Loss: 0.17449375987052917\n",
      "Epoch 4950, Loss: 0.378244087100029, Final Batch Loss: 0.11699798703193665\n",
      "Epoch 4951, Loss: 0.3949125334620476, Final Batch Loss: 0.16243213415145874\n",
      "Epoch 4952, Loss: 0.46354369074106216, Final Batch Loss: 0.10797680169343948\n",
      "Epoch 4953, Loss: 0.42785758525133133, Final Batch Loss: 0.12340047210454941\n",
      "Epoch 4954, Loss: 0.4199834614992142, Final Batch Loss: 0.08047908544540405\n",
      "Epoch 4955, Loss: 0.41230250149965286, Final Batch Loss: 0.0891474112868309\n",
      "Epoch 4956, Loss: 0.4031596854329109, Final Batch Loss: 0.13100527226924896\n",
      "Epoch 4957, Loss: 0.3973081260919571, Final Batch Loss: 0.11740660667419434\n",
      "Epoch 4958, Loss: 0.4553942307829857, Final Batch Loss: 0.16885416209697723\n",
      "Epoch 4959, Loss: 0.45947256684303284, Final Batch Loss: 0.13254784047603607\n",
      "Epoch 4960, Loss: 0.464203342795372, Final Batch Loss: 0.10761700570583344\n",
      "Epoch 4961, Loss: 0.46424514055252075, Final Batch Loss: 0.12668846547603607\n",
      "Epoch 4962, Loss: 0.4226393476128578, Final Batch Loss: 0.15830568969249725\n",
      "Epoch 4963, Loss: 0.4223679453134537, Final Batch Loss: 0.09411671757698059\n",
      "Epoch 4964, Loss: 0.428116112947464, Final Batch Loss: 0.14587116241455078\n",
      "Epoch 4965, Loss: 0.5636517405509949, Final Batch Loss: 0.23926858603954315\n",
      "Epoch 4966, Loss: 0.5233430862426758, Final Batch Loss: 0.22557145357131958\n",
      "Epoch 4967, Loss: 0.46885861456394196, Final Batch Loss: 0.21439512073993683\n",
      "Epoch 4968, Loss: 0.41269709914922714, Final Batch Loss: 0.10386253148317337\n",
      "Epoch 4969, Loss: 0.46617627143859863, Final Batch Loss: 0.14358222484588623\n",
      "Epoch 4970, Loss: 0.481550395488739, Final Batch Loss: 0.20341135561466217\n",
      "Epoch 4971, Loss: 0.38461460918188095, Final Batch Loss: 0.12125569581985474\n",
      "Epoch 4972, Loss: 0.4090842977166176, Final Batch Loss: 0.09939988702535629\n",
      "Epoch 4973, Loss: 0.39238229393959045, Final Batch Loss: 0.15491138398647308\n",
      "Epoch 4974, Loss: 0.47647614777088165, Final Batch Loss: 0.15142814815044403\n",
      "Epoch 4975, Loss: 0.4981987476348877, Final Batch Loss: 0.2318350076675415\n",
      "Epoch 4976, Loss: 0.5224068611860275, Final Batch Loss: 0.22189368307590485\n",
      "Epoch 4977, Loss: 0.5038899481296539, Final Batch Loss: 0.1915196031332016\n",
      "Epoch 4978, Loss: 0.39248480647802353, Final Batch Loss: 0.0744546428322792\n",
      "Epoch 4979, Loss: 0.3852495476603508, Final Batch Loss: 0.15961045026779175\n",
      "Epoch 4980, Loss: 0.4392019882798195, Final Batch Loss: 0.18022367358207703\n",
      "Epoch 4981, Loss: 0.3575029596686363, Final Batch Loss: 0.07838074117898941\n",
      "Epoch 4982, Loss: 0.4058701992034912, Final Batch Loss: 0.19503381848335266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4983, Loss: 0.3795461878180504, Final Batch Loss: 0.11430060118436813\n",
      "Epoch 4984, Loss: 0.3648841455578804, Final Batch Loss: 0.10381095111370087\n",
      "Epoch 4985, Loss: 0.3622572347521782, Final Batch Loss: 0.13097268342971802\n",
      "Epoch 4986, Loss: 0.4739703983068466, Final Batch Loss: 0.1941596120595932\n",
      "Epoch 4987, Loss: 0.5111630111932755, Final Batch Loss: 0.16886018216609955\n",
      "Epoch 4988, Loss: 0.40399497002363205, Final Batch Loss: 0.15199965238571167\n",
      "Epoch 4989, Loss: 0.6158257722854614, Final Batch Loss: 0.21132346987724304\n",
      "Epoch 4990, Loss: 0.4004140645265579, Final Batch Loss: 0.13969598710536957\n",
      "Epoch 4991, Loss: 0.45544082671403885, Final Batch Loss: 0.14274634420871735\n",
      "Epoch 4992, Loss: 0.48735038936138153, Final Batch Loss: 0.136031836271286\n",
      "Epoch 4993, Loss: 0.45050664246082306, Final Batch Loss: 0.17609968781471252\n",
      "Epoch 4994, Loss: 0.3694951832294464, Final Batch Loss: 0.13966180384159088\n",
      "Epoch 4995, Loss: 0.4208468645811081, Final Batch Loss: 0.16304315626621246\n",
      "Epoch 4996, Loss: 0.5315846502780914, Final Batch Loss: 0.17491574585437775\n",
      "Epoch 4997, Loss: 0.44746680557727814, Final Batch Loss: 0.18382982909679413\n",
      "Epoch 4998, Loss: 0.35193371772766113, Final Batch Loss: 0.10041393339633942\n",
      "Epoch 4999, Loss: 0.4925047308206558, Final Batch Loss: 0.1675160974264145\n",
      "Epoch 5000, Loss: 0.4043659195303917, Final Batch Loss: 0.11189976334571838\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40  0  0  0  1]\n",
      " [ 0 28  0  2  0]\n",
      " [ 0  0 31  2  0]\n",
      " [ 0  0  3 31  0]\n",
      " [ 0  0  0  0 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.97561   0.98765        41\n",
      "           1    1.00000   0.93333   0.96552        30\n",
      "           2    0.91176   0.93939   0.92537        33\n",
      "           3    0.88571   0.91176   0.89855        34\n",
      "           4    0.95000   1.00000   0.97436        19\n",
      "\n",
      "    accuracy                        0.94904       157\n",
      "   macro avg    0.94950   0.95202   0.95029       157\n",
      "weighted avg    0.95065   0.94904   0.94943       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38  0  0  0  0]\n",
      " [ 0 35  0  0  0]\n",
      " [ 0  0 27  0  0]\n",
      " [ 0  0  0 29  0]\n",
      " [ 0  0  6 17  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        38\n",
      "           1    1.00000   1.00000   1.00000        35\n",
      "           2    0.81818   1.00000   0.90000        27\n",
      "           3    0.63043   1.00000   0.77333        29\n",
      "           4    1.00000   0.17857   0.30303        28\n",
      "\n",
      "    accuracy                        0.85350       157\n",
      "   macro avg    0.88972   0.83571   0.79527       157\n",
      "weighted avg    0.90047   0.85350   0.81663       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(usr_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(usr_vectors[0], preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
