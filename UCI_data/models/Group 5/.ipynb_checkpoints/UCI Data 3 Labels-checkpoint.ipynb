{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '125 tBodyGyro-std()-Y',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '138 tBodyGyro-energy()-Y',\n",
    " '165 tBodyGyroJerk-std()-Y',\n",
    " '168 tBodyGyroJerk-mad()-Y',\n",
    " '178 tBodyGyroJerk-energy()-Y',\n",
    " '181 tBodyGyroJerk-iqr()-Y',\n",
    " '425 fBodyGyro-mean()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '431 fBodyGyro-mad()-Y',\n",
    " '441 fBodyGyro-energy()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '478 fBodyGyro-bandsEnergy()-25,32',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '204 tBodyAccMag-max()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '217 tGravityAccMag-max()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '275 fBodyAcc-max()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '506 fBodyAccMag-max()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>42 tGravityAcc-mean()-Y</th>\n",
       "      <th>43 tGravityAcc-mean()-Z</th>\n",
       "      <th>51 tGravityAcc-max()-Y</th>\n",
       "      <th>52 tGravityAcc-max()-Z</th>\n",
       "      <th>54 tGravityAcc-min()-Y</th>\n",
       "      <th>55 tGravityAcc-min()-Z</th>\n",
       "      <th>56 tGravityAcc-sma()</th>\n",
       "      <th>59 tGravityAcc-energy()-Z</th>\n",
       "      <th>125 tBodyGyro-std()-Y</th>\n",
       "      <th>128 tBodyGyro-mad()-Y</th>\n",
       "      <th>...</th>\n",
       "      <th>282 fBodyAcc-energy()-X</th>\n",
       "      <th>303 fBodyAcc-bandsEnergy()-1,8</th>\n",
       "      <th>311 fBodyAcc-bandsEnergy()-1,16</th>\n",
       "      <th>315 fBodyAcc-bandsEnergy()-1,24</th>\n",
       "      <th>504 fBodyAccMag-std()</th>\n",
       "      <th>505 fBodyAccMag-mad()</th>\n",
       "      <th>506 fBodyAccMag-max()</th>\n",
       "      <th>509 fBodyAccMag-energy()</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.140840</td>\n",
       "      <td>0.115375</td>\n",
       "      <td>-0.161265</td>\n",
       "      <td>0.124660</td>\n",
       "      <td>-0.123213</td>\n",
       "      <td>0.056483</td>\n",
       "      <td>-0.375426</td>\n",
       "      <td>-0.975510</td>\n",
       "      <td>-0.976623</td>\n",
       "      <td>-0.976353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999968</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>-0.956134</td>\n",
       "      <td>-0.948870</td>\n",
       "      <td>-0.974321</td>\n",
       "      <td>-0.998285</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.141551</td>\n",
       "      <td>0.109379</td>\n",
       "      <td>-0.161343</td>\n",
       "      <td>0.122586</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.383430</td>\n",
       "      <td>-0.978500</td>\n",
       "      <td>-0.989046</td>\n",
       "      <td>-0.989038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.975866</td>\n",
       "      <td>-0.975777</td>\n",
       "      <td>-0.978226</td>\n",
       "      <td>-0.999472</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.142010</td>\n",
       "      <td>0.101884</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.094566</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.401602</td>\n",
       "      <td>-0.981672</td>\n",
       "      <td>-0.993552</td>\n",
       "      <td>-0.994122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-0.999972</td>\n",
       "      <td>-0.989015</td>\n",
       "      <td>-0.985594</td>\n",
       "      <td>-0.993062</td>\n",
       "      <td>-0.999807</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.143976</td>\n",
       "      <td>0.099850</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.093425</td>\n",
       "      <td>-0.121336</td>\n",
       "      <td>0.095753</td>\n",
       "      <td>-0.400278</td>\n",
       "      <td>-0.982420</td>\n",
       "      <td>-0.992407</td>\n",
       "      <td>-0.993142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999975</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-0.986742</td>\n",
       "      <td>-0.983524</td>\n",
       "      <td>-0.990230</td>\n",
       "      <td>-0.999770</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.148750</td>\n",
       "      <td>0.094486</td>\n",
       "      <td>-0.166786</td>\n",
       "      <td>0.091682</td>\n",
       "      <td>-0.121834</td>\n",
       "      <td>0.094059</td>\n",
       "      <td>-0.400477</td>\n",
       "      <td>-0.984363</td>\n",
       "      <td>-0.992378</td>\n",
       "      <td>-0.992542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.990063</td>\n",
       "      <td>-0.992324</td>\n",
       "      <td>-0.990506</td>\n",
       "      <td>-0.999873</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>-0.222004</td>\n",
       "      <td>-0.039492</td>\n",
       "      <td>-0.214233</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.071977</td>\n",
       "      <td>-0.405132</td>\n",
       "      <td>-0.995193</td>\n",
       "      <td>0.084878</td>\n",
       "      <td>0.065142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674230</td>\n",
       "      <td>-0.684177</td>\n",
       "      <td>-0.666429</td>\n",
       "      <td>-0.668164</td>\n",
       "      <td>-0.232600</td>\n",
       "      <td>-0.007392</td>\n",
       "      <td>-0.401674</td>\n",
       "      <td>-0.584282</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>-0.242054</td>\n",
       "      <td>-0.039863</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.358934</td>\n",
       "      <td>-0.995151</td>\n",
       "      <td>0.098249</td>\n",
       "      <td>0.091791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.705580</td>\n",
       "      <td>-0.726986</td>\n",
       "      <td>-0.704444</td>\n",
       "      <td>-0.705435</td>\n",
       "      <td>-0.275373</td>\n",
       "      <td>-0.172448</td>\n",
       "      <td>-0.410577</td>\n",
       "      <td>-0.632536</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>-0.236950</td>\n",
       "      <td>-0.026805</td>\n",
       "      <td>-0.249134</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.216004</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.377025</td>\n",
       "      <td>-0.995450</td>\n",
       "      <td>0.185902</td>\n",
       "      <td>0.170686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.692379</td>\n",
       "      <td>-0.655263</td>\n",
       "      <td>-0.674515</td>\n",
       "      <td>-0.684729</td>\n",
       "      <td>-0.220288</td>\n",
       "      <td>-0.216074</td>\n",
       "      <td>-0.362904</td>\n",
       "      <td>-0.641170</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>-0.233230</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.244267</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.210542</td>\n",
       "      <td>-0.040009</td>\n",
       "      <td>-0.440050</td>\n",
       "      <td>-0.998824</td>\n",
       "      <td>0.190360</td>\n",
       "      <td>0.178939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693098</td>\n",
       "      <td>-0.643425</td>\n",
       "      <td>-0.677215</td>\n",
       "      <td>-0.685088</td>\n",
       "      <td>-0.234539</td>\n",
       "      <td>-0.220443</td>\n",
       "      <td>-0.397687</td>\n",
       "      <td>-0.663579</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>-0.233292</td>\n",
       "      <td>-0.020954</td>\n",
       "      <td>-0.240956</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>-0.212149</td>\n",
       "      <td>-0.047491</td>\n",
       "      <td>-0.432003</td>\n",
       "      <td>-0.998144</td>\n",
       "      <td>0.022216</td>\n",
       "      <td>-0.073681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.731037</td>\n",
       "      <td>-0.709495</td>\n",
       "      <td>-0.728519</td>\n",
       "      <td>-0.727441</td>\n",
       "      <td>-0.342670</td>\n",
       "      <td>-0.146649</td>\n",
       "      <td>-0.620014</td>\n",
       "      <td>-0.698087</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      42 tGravityAcc-mean()-Y  43 tGravityAcc-mean()-Z  \\\n",
       "0                   -0.140840                 0.115375   \n",
       "1                   -0.141551                 0.109379   \n",
       "2                   -0.142010                 0.101884   \n",
       "3                   -0.143976                 0.099850   \n",
       "4                   -0.148750                 0.094486   \n",
       "...                       ...                      ...   \n",
       "7347                -0.222004                -0.039492   \n",
       "7348                -0.242054                -0.039863   \n",
       "7349                -0.236950                -0.026805   \n",
       "7350                -0.233230                -0.004984   \n",
       "7351                -0.233292                -0.020954   \n",
       "\n",
       "      51 tGravityAcc-max()-Y  52 tGravityAcc-max()-Z  54 tGravityAcc-min()-Y  \\\n",
       "0                  -0.161265                0.124660               -0.123213   \n",
       "1                  -0.161343                0.122586               -0.114893   \n",
       "2                  -0.163711                0.094566               -0.114893   \n",
       "3                  -0.163711                0.093425               -0.121336   \n",
       "4                  -0.166786                0.091682               -0.121834   \n",
       "...                      ...                     ...                     ...   \n",
       "7347               -0.214233               -0.016391               -0.234998   \n",
       "7348               -0.231477               -0.016391               -0.234998   \n",
       "7349               -0.249134                0.024684               -0.216004   \n",
       "7350               -0.244267                0.024684               -0.210542   \n",
       "7351               -0.240956                0.003031               -0.212149   \n",
       "\n",
       "      55 tGravityAcc-min()-Z  56 tGravityAcc-sma()  59 tGravityAcc-energy()-Z  \\\n",
       "0                   0.056483             -0.375426                  -0.975510   \n",
       "1                   0.102764             -0.383430                  -0.978500   \n",
       "2                   0.102764             -0.401602                  -0.981672   \n",
       "3                   0.095753             -0.400278                  -0.982420   \n",
       "4                   0.094059             -0.400477                  -0.984363   \n",
       "...                      ...                   ...                        ...   \n",
       "7347               -0.071977             -0.405132                  -0.995193   \n",
       "7348               -0.068919             -0.358934                  -0.995151   \n",
       "7349               -0.068919             -0.377025                  -0.995450   \n",
       "7350               -0.040009             -0.440050                  -0.998824   \n",
       "7351               -0.047491             -0.432003                  -0.998144   \n",
       "\n",
       "      125 tBodyGyro-std()-Y  128 tBodyGyro-mad()-Y  ...  \\\n",
       "0                 -0.976623              -0.976353  ...   \n",
       "1                 -0.989046              -0.989038  ...   \n",
       "2                 -0.993552              -0.994122  ...   \n",
       "3                 -0.992407              -0.993142  ...   \n",
       "4                 -0.992378              -0.992542  ...   \n",
       "...                     ...                    ...  ...   \n",
       "7347               0.084878               0.065142  ...   \n",
       "7348               0.098249               0.091791  ...   \n",
       "7349               0.185902               0.170686  ...   \n",
       "7350               0.190360               0.178939  ...   \n",
       "7351               0.022216              -0.073681  ...   \n",
       "\n",
       "      282 fBodyAcc-energy()-X  303 fBodyAcc-bandsEnergy()-1,8  \\\n",
       "0                   -0.999968                       -0.999963   \n",
       "1                   -0.999991                       -0.999996   \n",
       "2                   -0.999969                       -0.999989   \n",
       "3                   -0.999975                       -0.999989   \n",
       "4                   -0.999990                       -0.999994   \n",
       "...                       ...                             ...   \n",
       "7347                -0.674230                       -0.684177   \n",
       "7348                -0.705580                       -0.726986   \n",
       "7349                -0.692379                       -0.655263   \n",
       "7350                -0.693098                       -0.643425   \n",
       "7351                -0.731037                       -0.709495   \n",
       "\n",
       "      311 fBodyAcc-bandsEnergy()-1,16  315 fBodyAcc-bandsEnergy()-1,24  \\\n",
       "0                           -0.999969                        -0.999971   \n",
       "1                           -0.999994                        -0.999992   \n",
       "2                           -0.999983                        -0.999972   \n",
       "3                           -0.999986                        -0.999977   \n",
       "4                           -0.999993                        -0.999991   \n",
       "...                               ...                              ...   \n",
       "7347                        -0.666429                        -0.668164   \n",
       "7348                        -0.704444                        -0.705435   \n",
       "7349                        -0.674515                        -0.684729   \n",
       "7350                        -0.677215                        -0.685088   \n",
       "7351                        -0.728519                        -0.727441   \n",
       "\n",
       "      504 fBodyAccMag-std()  505 fBodyAccMag-mad()  506 fBodyAccMag-max()  \\\n",
       "0                 -0.956134              -0.948870              -0.974321   \n",
       "1                 -0.975866              -0.975777              -0.978226   \n",
       "2                 -0.989015              -0.985594              -0.993062   \n",
       "3                 -0.986742              -0.983524              -0.990230   \n",
       "4                 -0.990063              -0.992324              -0.990506   \n",
       "...                     ...                    ...                    ...   \n",
       "7347              -0.232600              -0.007392              -0.401674   \n",
       "7348              -0.275373              -0.172448              -0.410577   \n",
       "7349              -0.220288              -0.216074              -0.362904   \n",
       "7350              -0.234539              -0.220443              -0.397687   \n",
       "7351              -0.342670              -0.146649              -0.620014   \n",
       "\n",
       "      509 fBodyAccMag-energy()  Activity  Subject  \n",
       "0                    -0.998285         5        1  \n",
       "1                    -0.999472         5        1  \n",
       "2                    -0.999807         5        1  \n",
       "3                    -0.999770         5        1  \n",
       "4                    -0.999873         5        1  \n",
       "...                        ...       ...      ...  \n",
       "7347                 -0.584282         2       30  \n",
       "7348                 -0.632536         2       30  \n",
       "7349                 -0.641170         2       30  \n",
       "7350                 -0.663579         2       30  \n",
       "7351                 -0.698087         2       30  \n",
       "\n",
       "[7352 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names = pd.read_csv('../../data/features.txt', delimiter = '\\n', header = None)\n",
    "train_column_names = train_names.values.tolist()\n",
    "train_column_names = [k for row in train_column_names for k in row]\n",
    "\n",
    "train_data = pd.read_csv('../../data/X_train.txt', delim_whitespace = True, header = None)\n",
    "train_data.columns = train_column_names\n",
    "\n",
    "### Single dataframe column\n",
    "y_train = pd.read_csv('../../data/y_train.txt', header = None)\n",
    "y_train.columns = ['Activity']\n",
    "\n",
    "y_train_subject = pd.read_csv('../../data/subject_train.txt', header = None)\n",
    "y_train_subject.columns = ['Subject']\n",
    "\n",
    "X_train_1 = train_data[sub_features]\n",
    "X_train_2 = train_data[act_features]\n",
    "X_train_data = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "\n",
    "X_train_data = pd.concat([X_train_data, y_train, y_train_subject], axis = 1)\n",
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_data[(X_train_data['Subject'].isin([19, 21, 22])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,:-2].values\n",
    "y_train = X_train_data[(X_train_data['Subject'].isin([19, 21, 22])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,-2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y_train)):\n",
    "    if y_train[k] == 1:\n",
    "        y_train[k] = 0\n",
    "    elif y_train[k] == 3:\n",
    "        y_train[k] = 1\n",
    "    else:\n",
    "        y_train[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.15, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 30),\n",
    "            classifier_block(30, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.276047110557556, Final Batch Loss: 1.1254788637161255\n",
      "Epoch 2, Loss: 2.257022976875305, Final Batch Loss: 1.1208080053329468\n",
      "Epoch 3, Loss: 2.2427080869674683, Final Batch Loss: 1.1303187608718872\n",
      "Epoch 4, Loss: 2.228219747543335, Final Batch Loss: 1.1130030155181885\n",
      "Epoch 5, Loss: 2.219546318054199, Final Batch Loss: 1.1095623970031738\n",
      "Epoch 6, Loss: 2.2049797773361206, Final Batch Loss: 1.1027452945709229\n",
      "Epoch 7, Loss: 2.188579559326172, Final Batch Loss: 1.0899256467819214\n",
      "Epoch 8, Loss: 2.1700387001037598, Final Batch Loss: 1.0758167505264282\n",
      "Epoch 9, Loss: 2.1614712476730347, Final Batch Loss: 1.0737117528915405\n",
      "Epoch 10, Loss: 2.1410681009292603, Final Batch Loss: 1.0720646381378174\n",
      "Epoch 11, Loss: 2.1060487031936646, Final Batch Loss: 1.0486496686935425\n",
      "Epoch 12, Loss: 2.0891895294189453, Final Batch Loss: 1.0337570905685425\n",
      "Epoch 13, Loss: 2.0708318948745728, Final Batch Loss: 1.038000226020813\n",
      "Epoch 14, Loss: 2.026038408279419, Final Batch Loss: 1.0041621923446655\n",
      "Epoch 15, Loss: 2.018385171890259, Final Batch Loss: 1.0056432485580444\n",
      "Epoch 16, Loss: 1.967913806438446, Final Batch Loss: 0.9618440270423889\n",
      "Epoch 17, Loss: 1.9470117688179016, Final Batch Loss: 0.9800359606742859\n",
      "Epoch 18, Loss: 1.90948885679245, Final Batch Loss: 0.9435689449310303\n",
      "Epoch 19, Loss: 1.8714781403541565, Final Batch Loss: 0.9568384885787964\n",
      "Epoch 20, Loss: 1.8166567087173462, Final Batch Loss: 0.8941874504089355\n",
      "Epoch 21, Loss: 1.7710991501808167, Final Batch Loss: 0.8787151575088501\n",
      "Epoch 22, Loss: 1.7044400572776794, Final Batch Loss: 0.8670336008071899\n",
      "Epoch 23, Loss: 1.6676478385925293, Final Batch Loss: 0.8174152374267578\n",
      "Epoch 24, Loss: 1.6274811625480652, Final Batch Loss: 0.8140562772750854\n",
      "Epoch 25, Loss: 1.5590330362319946, Final Batch Loss: 0.7741528153419495\n",
      "Epoch 26, Loss: 1.5055812001228333, Final Batch Loss: 0.6978902816772461\n",
      "Epoch 27, Loss: 1.4383184313774109, Final Batch Loss: 0.7039681673049927\n",
      "Epoch 28, Loss: 1.3881977200508118, Final Batch Loss: 0.7084582448005676\n",
      "Epoch 29, Loss: 1.3527595400810242, Final Batch Loss: 0.6749988794326782\n",
      "Epoch 30, Loss: 1.2685588598251343, Final Batch Loss: 0.6079458594322205\n",
      "Epoch 31, Loss: 1.269611656665802, Final Batch Loss: 0.6332313418388367\n",
      "Epoch 32, Loss: 1.2063327431678772, Final Batch Loss: 0.5801548957824707\n",
      "Epoch 33, Loss: 1.1534166932106018, Final Batch Loss: 0.5699272155761719\n",
      "Epoch 34, Loss: 1.0905318856239319, Final Batch Loss: 0.5157437324523926\n",
      "Epoch 35, Loss: 1.053690254688263, Final Batch Loss: 0.5210672616958618\n",
      "Epoch 36, Loss: 1.0323041379451752, Final Batch Loss: 0.49123772978782654\n",
      "Epoch 37, Loss: 0.9963037073612213, Final Batch Loss: 0.5047317147254944\n",
      "Epoch 38, Loss: 0.960852861404419, Final Batch Loss: 0.5019559860229492\n",
      "Epoch 39, Loss: 0.9350447058677673, Final Batch Loss: 0.4635497033596039\n",
      "Epoch 40, Loss: 0.8667380213737488, Final Batch Loss: 0.4135129451751709\n",
      "Epoch 41, Loss: 0.827149897813797, Final Batch Loss: 0.41728371381759644\n",
      "Epoch 42, Loss: 0.7876577973365784, Final Batch Loss: 0.3868650794029236\n",
      "Epoch 43, Loss: 0.7552975714206696, Final Batch Loss: 0.38238590955734253\n",
      "Epoch 44, Loss: 0.7450729012489319, Final Batch Loss: 0.3666439652442932\n",
      "Epoch 45, Loss: 0.6661320626735687, Final Batch Loss: 0.3080763518810272\n",
      "Epoch 46, Loss: 0.6397124230861664, Final Batch Loss: 0.33253154158592224\n",
      "Epoch 47, Loss: 0.5703935325145721, Final Batch Loss: 0.26917532086372375\n",
      "Epoch 48, Loss: 0.5963983535766602, Final Batch Loss: 0.28218477964401245\n",
      "Epoch 49, Loss: 0.5036556124687195, Final Batch Loss: 0.25873076915740967\n",
      "Epoch 50, Loss: 0.4909541755914688, Final Batch Loss: 0.2388531118631363\n",
      "Epoch 51, Loss: 0.4678792506456375, Final Batch Loss: 0.23251907527446747\n",
      "Epoch 52, Loss: 0.4563751220703125, Final Batch Loss: 0.2006908357143402\n",
      "Epoch 53, Loss: 0.44599007070064545, Final Batch Loss: 0.22890649735927582\n",
      "Epoch 54, Loss: 0.4163229912519455, Final Batch Loss: 0.20423220098018646\n",
      "Epoch 55, Loss: 0.34052154421806335, Final Batch Loss: 0.18861928582191467\n",
      "Epoch 56, Loss: 0.3176507353782654, Final Batch Loss: 0.16062964498996735\n",
      "Epoch 57, Loss: 0.28637224435806274, Final Batch Loss: 0.13629016280174255\n",
      "Epoch 58, Loss: 0.3074578046798706, Final Batch Loss: 0.1607733517885208\n",
      "Epoch 59, Loss: 0.2854112684726715, Final Batch Loss: 0.14184358716011047\n",
      "Epoch 60, Loss: 0.2945564538240433, Final Batch Loss: 0.15687961876392365\n",
      "Epoch 61, Loss: 0.23593638837337494, Final Batch Loss: 0.14330998063087463\n",
      "Epoch 62, Loss: 0.25539252161979675, Final Batch Loss: 0.11366477608680725\n",
      "Epoch 63, Loss: 0.2168436497449875, Final Batch Loss: 0.11797776073217392\n",
      "Epoch 64, Loss: 0.20289962738752365, Final Batch Loss: 0.07358787208795547\n",
      "Epoch 65, Loss: 0.20045389235019684, Final Batch Loss: 0.08965040743350983\n",
      "Epoch 66, Loss: 0.1495847851037979, Final Batch Loss: 0.07481369376182556\n",
      "Epoch 67, Loss: 0.17865335941314697, Final Batch Loss: 0.08046569675207138\n",
      "Epoch 68, Loss: 0.16734174638986588, Final Batch Loss: 0.08441620320081711\n",
      "Epoch 69, Loss: 0.12719714641571045, Final Batch Loss: 0.05588693916797638\n",
      "Epoch 70, Loss: 0.14472248777747154, Final Batch Loss: 0.08530298620462418\n",
      "Epoch 71, Loss: 0.1510089635848999, Final Batch Loss: 0.07730959355831146\n",
      "Epoch 72, Loss: 0.09892755374312401, Final Batch Loss: 0.04711134731769562\n",
      "Epoch 73, Loss: 0.12534823641180992, Final Batch Loss: 0.05302612856030464\n",
      "Epoch 74, Loss: 0.14665837585926056, Final Batch Loss: 0.07712867110967636\n",
      "Epoch 75, Loss: 0.14010708779096603, Final Batch Loss: 0.06814314424991608\n",
      "Epoch 76, Loss: 0.1073121428489685, Final Batch Loss: 0.06356094032526016\n",
      "Epoch 77, Loss: 0.112491175532341, Final Batch Loss: 0.06681004911661148\n",
      "Epoch 78, Loss: 0.11659170314669609, Final Batch Loss: 0.05250554904341698\n",
      "Epoch 79, Loss: 0.08747204393148422, Final Batch Loss: 0.042703282088041306\n",
      "Epoch 80, Loss: 0.0920771174132824, Final Batch Loss: 0.04678543284535408\n",
      "Epoch 81, Loss: 0.059312956407666206, Final Batch Loss: 0.015360550954937935\n",
      "Epoch 82, Loss: 0.06572576239705086, Final Batch Loss: 0.01968541368842125\n",
      "Epoch 83, Loss: 0.06037174351513386, Final Batch Loss: 0.04161425307393074\n",
      "Epoch 84, Loss: 0.10941997915506363, Final Batch Loss: 0.053879283368587494\n",
      "Epoch 85, Loss: 0.07969295233488083, Final Batch Loss: 0.037456922233104706\n",
      "Epoch 86, Loss: 0.07785018160939217, Final Batch Loss: 0.036977678537368774\n",
      "Epoch 87, Loss: 0.073099285364151, Final Batch Loss: 0.03965580463409424\n",
      "Epoch 88, Loss: 0.060595035552978516, Final Batch Loss: 0.028652966022491455\n",
      "Epoch 89, Loss: 0.07144445367157459, Final Batch Loss: 0.030718253925442696\n",
      "Epoch 90, Loss: 0.04434596560895443, Final Batch Loss: 0.016553040593862534\n",
      "Epoch 91, Loss: 0.07420765422284603, Final Batch Loss: 0.0450812503695488\n",
      "Epoch 92, Loss: 0.045870861038565636, Final Batch Loss: 0.020537951961159706\n",
      "Epoch 93, Loss: 0.05868392437696457, Final Batch Loss: 0.023115988820791245\n",
      "Epoch 94, Loss: 0.05824139527976513, Final Batch Loss: 0.03435925394296646\n",
      "Epoch 95, Loss: 0.07213946431875229, Final Batch Loss: 0.03286193683743477\n",
      "Epoch 96, Loss: 0.06796012073755264, Final Batch Loss: 0.03487701714038849\n",
      "Epoch 97, Loss: 0.05638847313821316, Final Batch Loss: 0.012405389919877052\n",
      "Epoch 98, Loss: 0.04449034482240677, Final Batch Loss: 0.02148885279893875\n",
      "Epoch 99, Loss: 0.04135040566325188, Final Batch Loss: 0.02429276518523693\n",
      "Epoch 100, Loss: 0.049327073618769646, Final Batch Loss: 0.017280975356698036\n",
      "Epoch 101, Loss: 0.042338777333498, Final Batch Loss: 0.019555291160941124\n",
      "Epoch 102, Loss: 0.07502415031194687, Final Batch Loss: 0.04418519511818886\n",
      "Epoch 103, Loss: 0.04038035590201616, Final Batch Loss: 0.01521144900470972\n",
      "Epoch 104, Loss: 0.040544940158724785, Final Batch Loss: 0.02439957857131958\n",
      "Epoch 105, Loss: 0.05431610718369484, Final Batch Loss: 0.0255271103233099\n",
      "Epoch 106, Loss: 0.0390552319586277, Final Batch Loss: 0.02040695771574974\n",
      "Epoch 107, Loss: 0.04423266276717186, Final Batch Loss: 0.01587929204106331\n",
      "Epoch 108, Loss: 0.08205920830368996, Final Batch Loss: 0.03215523809194565\n",
      "Epoch 109, Loss: 0.04891152121126652, Final Batch Loss: 0.011571461334824562\n",
      "Epoch 110, Loss: 0.05675290711224079, Final Batch Loss: 0.03029661625623703\n",
      "Epoch 111, Loss: 0.03614191338419914, Final Batch Loss: 0.026723893359303474\n",
      "Epoch 112, Loss: 0.07049339637160301, Final Batch Loss: 0.031766533851623535\n",
      "Epoch 113, Loss: 0.028588950168341398, Final Batch Loss: 0.0077248974703252316\n",
      "Epoch 114, Loss: 0.03989475034177303, Final Batch Loss: 0.02789340913295746\n",
      "Epoch 115, Loss: 0.04250527825206518, Final Batch Loss: 0.012955713085830212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116, Loss: 0.028790081851184368, Final Batch Loss: 0.016104621812701225\n",
      "Epoch 117, Loss: 0.03143813367933035, Final Batch Loss: 0.016514433547854424\n",
      "Epoch 118, Loss: 0.03087565954774618, Final Batch Loss: 0.014690962620079517\n",
      "Epoch 119, Loss: 0.04963775351643562, Final Batch Loss: 0.02252604439854622\n",
      "Epoch 120, Loss: 0.025336490012705326, Final Batch Loss: 0.013173060491681099\n",
      "Epoch 121, Loss: 0.03815083485096693, Final Batch Loss: 0.011353555135428905\n",
      "Epoch 122, Loss: 0.028862865641713142, Final Batch Loss: 0.012733038514852524\n",
      "Epoch 123, Loss: 0.06434216722846031, Final Batch Loss: 0.026243876665830612\n",
      "Epoch 124, Loss: 0.026597021147608757, Final Batch Loss: 0.014846709556877613\n",
      "Epoch 125, Loss: 0.019700856879353523, Final Batch Loss: 0.01036963239312172\n",
      "Epoch 126, Loss: 0.01815255917608738, Final Batch Loss: 0.008011579513549805\n",
      "Epoch 127, Loss: 0.05038653500378132, Final Batch Loss: 0.0169698353856802\n",
      "Epoch 128, Loss: 0.029432207345962524, Final Batch Loss: 0.013257194310426712\n",
      "Epoch 129, Loss: 0.02228429727256298, Final Batch Loss: 0.005038030445575714\n",
      "Epoch 130, Loss: 0.02651525754481554, Final Batch Loss: 0.012592615559697151\n",
      "Epoch 131, Loss: 0.018358754459768534, Final Batch Loss: 0.005411819089204073\n",
      "Epoch 132, Loss: 0.020108836703002453, Final Batch Loss: 0.010435515083372593\n",
      "Epoch 133, Loss: 0.023256909102201462, Final Batch Loss: 0.011290419846773148\n",
      "Epoch 134, Loss: 0.018911941908299923, Final Batch Loss: 0.010394738987088203\n",
      "Epoch 135, Loss: 0.03986339271068573, Final Batch Loss: 0.028414955362677574\n",
      "Epoch 136, Loss: 0.022160825319588184, Final Batch Loss: 0.006732787936925888\n",
      "Epoch 137, Loss: 0.020249537657946348, Final Batch Loss: 0.012697654776275158\n",
      "Epoch 138, Loss: 0.03552794735878706, Final Batch Loss: 0.023646481335163116\n",
      "Epoch 139, Loss: 0.02321233320981264, Final Batch Loss: 0.005062776617705822\n",
      "Epoch 140, Loss: 0.010678938357159495, Final Batch Loss: 0.0029980617109686136\n",
      "Epoch 141, Loss: 0.043685926124453545, Final Batch Loss: 0.01567261293530464\n",
      "Epoch 142, Loss: 0.017064541578292847, Final Batch Loss: 0.004962495528161526\n",
      "Epoch 143, Loss: 0.0398908406496048, Final Batch Loss: 0.025334838777780533\n",
      "Epoch 144, Loss: 0.042152997106313705, Final Batch Loss: 0.01641986332833767\n",
      "Epoch 145, Loss: 0.03827859740704298, Final Batch Loss: 0.030017361044883728\n",
      "Epoch 146, Loss: 0.04913623444736004, Final Batch Loss: 0.01665450818836689\n",
      "Epoch 147, Loss: 0.025900444015860558, Final Batch Loss: 0.0074627455323934555\n",
      "Epoch 148, Loss: 0.028867854736745358, Final Batch Loss: 0.011592055670917034\n",
      "Epoch 149, Loss: 0.028203587513417006, Final Batch Loss: 0.0047418042086064816\n",
      "Epoch 150, Loss: 0.013757721520960331, Final Batch Loss: 0.004766394384205341\n",
      "Epoch 151, Loss: 0.013184099225327373, Final Batch Loss: 0.0027218142058700323\n",
      "Epoch 152, Loss: 0.027241445146501064, Final Batch Loss: 0.009728104807436466\n",
      "Epoch 153, Loss: 0.027477712370455265, Final Batch Loss: 0.014597376808524132\n",
      "Epoch 154, Loss: 0.02095153694972396, Final Batch Loss: 0.005955285858362913\n",
      "Epoch 155, Loss: 0.03746307408437133, Final Batch Loss: 0.03141370415687561\n",
      "Epoch 156, Loss: 0.01925202878192067, Final Batch Loss: 0.007636907044798136\n",
      "Epoch 157, Loss: 0.04510464984923601, Final Batch Loss: 0.03341052681207657\n",
      "Epoch 158, Loss: 0.027835410088300705, Final Batch Loss: 0.008624350652098656\n",
      "Epoch 159, Loss: 0.020129401236772537, Final Batch Loss: 0.006199711933732033\n",
      "Epoch 160, Loss: 0.009519615210592747, Final Batch Loss: 0.00509544275701046\n",
      "Epoch 161, Loss: 0.023544993717223406, Final Batch Loss: 0.006325226742774248\n",
      "Epoch 162, Loss: 0.015596131561324, Final Batch Loss: 0.0037006333004683256\n",
      "Epoch 163, Loss: 0.02626133430749178, Final Batch Loss: 0.01261204108595848\n",
      "Epoch 164, Loss: 0.009912993293255568, Final Batch Loss: 0.005404995754361153\n",
      "Epoch 165, Loss: 0.024928923696279526, Final Batch Loss: 0.01413194090127945\n",
      "Epoch 166, Loss: 0.01581981871277094, Final Batch Loss: 0.011373116634786129\n",
      "Epoch 167, Loss: 0.016333206556737423, Final Batch Loss: 0.007945945486426353\n",
      "Epoch 168, Loss: 0.020559905096888542, Final Batch Loss: 0.004620915278792381\n",
      "Epoch 169, Loss: 0.02731460379436612, Final Batch Loss: 0.022686626762151718\n",
      "Epoch 170, Loss: 0.027757837902754545, Final Batch Loss: 0.022191695868968964\n",
      "Epoch 171, Loss: 0.020928533747792244, Final Batch Loss: 0.0045750439167022705\n",
      "Epoch 172, Loss: 0.009038329822942615, Final Batch Loss: 0.00249718246050179\n",
      "Epoch 173, Loss: 0.010994356591254473, Final Batch Loss: 0.0033113770186901093\n",
      "Epoch 174, Loss: 0.014124467968940735, Final Batch Loss: 0.007871168665587902\n",
      "Epoch 175, Loss: 0.01990390126593411, Final Batch Loss: 0.00200674613006413\n",
      "Epoch 176, Loss: 0.024839578662067652, Final Batch Loss: 0.007442752365022898\n",
      "Epoch 177, Loss: 0.019513897597789764, Final Batch Loss: 0.014978429302573204\n",
      "Epoch 178, Loss: 0.027236261405050755, Final Batch Loss: 0.023491116240620613\n",
      "Epoch 179, Loss: 0.03011916484683752, Final Batch Loss: 0.007994798012077808\n",
      "Epoch 180, Loss: 0.015250914730131626, Final Batch Loss: 0.006106577813625336\n",
      "Epoch 181, Loss: 0.012689429800957441, Final Batch Loss: 0.004459978546947241\n",
      "Epoch 182, Loss: 0.015032135415822268, Final Batch Loss: 0.003384591545909643\n",
      "Epoch 183, Loss: 0.017092965077608824, Final Batch Loss: 0.010836596600711346\n",
      "Epoch 184, Loss: 0.02267185994423926, Final Batch Loss: 0.0034524763468652964\n",
      "Epoch 185, Loss: 0.02160791726782918, Final Batch Loss: 0.017590709030628204\n",
      "Epoch 186, Loss: 0.009904615115374327, Final Batch Loss: 0.006337963044643402\n",
      "Epoch 187, Loss: 0.017339630983769894, Final Batch Loss: 0.010612634010612965\n",
      "Epoch 188, Loss: 0.012854611035436392, Final Batch Loss: 0.00889303907752037\n",
      "Epoch 189, Loss: 0.005633654538542032, Final Batch Loss: 0.0024934178218245506\n",
      "Epoch 190, Loss: 0.031285882694646716, Final Batch Loss: 0.027539808303117752\n",
      "Epoch 191, Loss: 0.020829982357099652, Final Batch Loss: 0.01781071163713932\n",
      "Epoch 192, Loss: 0.04456535214558244, Final Batch Loss: 0.03687669336795807\n",
      "Epoch 193, Loss: 0.010290626436471939, Final Batch Loss: 0.005673164967447519\n",
      "Epoch 194, Loss: 0.014822948025539517, Final Batch Loss: 0.011127573437988758\n",
      "Epoch 195, Loss: 0.009843874722719193, Final Batch Loss: 0.0075820633210241795\n",
      "Epoch 196, Loss: 0.022462460212409496, Final Batch Loss: 0.006590290926396847\n",
      "Epoch 197, Loss: 0.03244501352310181, Final Batch Loss: 0.0022138282656669617\n",
      "Epoch 198, Loss: 0.019365165382623672, Final Batch Loss: 0.014718686230480671\n",
      "Epoch 199, Loss: 0.006712759262882173, Final Batch Loss: 0.00163952203001827\n",
      "Epoch 200, Loss: 0.029785423073917627, Final Batch Loss: 0.004610077012330294\n",
      "Epoch 201, Loss: 0.006999164121225476, Final Batch Loss: 0.0038813219871371984\n",
      "Epoch 202, Loss: 0.0334954340942204, Final Batch Loss: 0.003937544766813517\n",
      "Epoch 203, Loss: 0.014390603639185429, Final Batch Loss: 0.0025884490460157394\n",
      "Epoch 204, Loss: 0.009127934696152806, Final Batch Loss: 0.006174011621624231\n",
      "Epoch 205, Loss: 0.01987619884312153, Final Batch Loss: 0.007864948362112045\n",
      "Epoch 206, Loss: 0.011656330898404121, Final Batch Loss: 0.006569793913513422\n",
      "Epoch 207, Loss: 0.01172491256147623, Final Batch Loss: 0.00539679080247879\n",
      "Epoch 208, Loss: 0.004709772765636444, Final Batch Loss: 0.0023925919085741043\n",
      "Epoch 209, Loss: 0.013423267053440213, Final Batch Loss: 0.009992368519306183\n",
      "Epoch 210, Loss: 0.016550855711102486, Final Batch Loss: 0.0076296646147966385\n",
      "Epoch 211, Loss: 0.008306731237098575, Final Batch Loss: 0.003068686230108142\n",
      "Epoch 212, Loss: 0.03741238755173981, Final Batch Loss: 0.033513814210891724\n",
      "Epoch 213, Loss: 0.012997831916436553, Final Batch Loss: 0.009418288245797157\n",
      "Epoch 214, Loss: 0.009451507590711117, Final Batch Loss: 0.004433386493474245\n",
      "Epoch 215, Loss: 0.009346670936793089, Final Batch Loss: 0.006522252690047026\n",
      "Epoch 216, Loss: 0.017162110656499863, Final Batch Loss: 0.013505361042916775\n",
      "Epoch 217, Loss: 0.031075996113941073, Final Batch Loss: 0.02911379560828209\n",
      "Epoch 218, Loss: 0.009349120780825615, Final Batch Loss: 0.005144166760146618\n",
      "Epoch 219, Loss: 0.015614684205502272, Final Batch Loss: 0.009743171744048595\n",
      "Epoch 220, Loss: 0.017440649680793285, Final Batch Loss: 0.0030305208638310432\n",
      "Epoch 221, Loss: 0.028147772420197725, Final Batch Loss: 0.007165007758885622\n",
      "Epoch 222, Loss: 0.01582819689065218, Final Batch Loss: 0.005130182020366192\n",
      "Epoch 223, Loss: 0.015296523459255695, Final Batch Loss: 0.011324629187583923\n",
      "Epoch 224, Loss: 0.005878558149561286, Final Batch Loss: 0.0016835404094308615\n",
      "Epoch 225, Loss: 0.009010671870782971, Final Batch Loss: 0.006312419660389423\n",
      "Epoch 226, Loss: 0.01761201163753867, Final Batch Loss: 0.013280489481985569\n",
      "Epoch 227, Loss: 0.019327176734805107, Final Batch Loss: 0.007518850266933441\n",
      "Epoch 228, Loss: 0.007584056118503213, Final Batch Loss: 0.005173229146748781\n",
      "Epoch 229, Loss: 0.025340983411297202, Final Batch Loss: 0.022770710289478302\n",
      "Epoch 230, Loss: 0.02636601682752371, Final Batch Loss: 0.01945924200117588\n",
      "Epoch 231, Loss: 0.013836337719112635, Final Batch Loss: 0.004824144300073385\n",
      "Epoch 232, Loss: 0.007496147183701396, Final Batch Loss: 0.003511089598760009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233, Loss: 0.02220829832367599, Final Batch Loss: 0.0039059303235262632\n",
      "Epoch 234, Loss: 0.0041563683189451694, Final Batch Loss: 0.0015901396982371807\n",
      "Epoch 235, Loss: 0.011711013270542026, Final Batch Loss: 0.0014811193104833364\n",
      "Epoch 236, Loss: 0.004968658206053078, Final Batch Loss: 0.0018201248021796346\n",
      "Epoch 237, Loss: 0.00882718013599515, Final Batch Loss: 0.0010472978465259075\n",
      "Epoch 238, Loss: 0.016109673073515296, Final Batch Loss: 0.013804583810269833\n",
      "Epoch 239, Loss: 0.014548066654242575, Final Batch Loss: 0.0014371877769008279\n",
      "Epoch 240, Loss: 0.009790318086743355, Final Batch Loss: 0.005020786076784134\n",
      "Epoch 241, Loss: 0.004553600098006427, Final Batch Loss: 0.001562379184179008\n",
      "Epoch 242, Loss: 0.004328089067712426, Final Batch Loss: 0.002197781577706337\n",
      "Epoch 243, Loss: 0.01510087912902236, Final Batch Loss: 0.010200131684541702\n",
      "Epoch 244, Loss: 0.012015970889478922, Final Batch Loss: 0.004073220770806074\n",
      "Epoch 245, Loss: 0.025589918717741966, Final Batch Loss: 0.0016227997839450836\n",
      "Epoch 246, Loss: 0.009898084914311767, Final Batch Loss: 0.0010546983685344458\n",
      "Epoch 247, Loss: 0.008558147819712758, Final Batch Loss: 0.006588602438569069\n",
      "Epoch 248, Loss: 0.00930779054760933, Final Batch Loss: 0.005322164390236139\n",
      "Epoch 249, Loss: 0.013240201398730278, Final Batch Loss: 0.009496929123997688\n",
      "Epoch 250, Loss: 0.0079269262496382, Final Batch Loss: 0.0010550736915320158\n",
      "Epoch 251, Loss: 0.007419942645356059, Final Batch Loss: 0.005002291407436132\n",
      "Epoch 252, Loss: 0.016199269331991673, Final Batch Loss: 0.009085098281502724\n",
      "Epoch 253, Loss: 0.017512365244328976, Final Batch Loss: 0.01041899062693119\n",
      "Epoch 254, Loss: 0.0281725050881505, Final Batch Loss: 0.02524123154580593\n",
      "Epoch 255, Loss: 0.004176856949925423, Final Batch Loss: 0.0012963046319782734\n",
      "Epoch 256, Loss: 0.0059417034790385514, Final Batch Loss: 0.0003449740179348737\n",
      "Epoch 257, Loss: 0.018904825206846, Final Batch Loss: 0.002521888818591833\n",
      "Epoch 258, Loss: 0.008637795690447092, Final Batch Loss: 0.00690356595441699\n",
      "Epoch 259, Loss: 0.02426003967411816, Final Batch Loss: 0.022327188402414322\n",
      "Epoch 260, Loss: 0.009269028552807868, Final Batch Loss: 0.0017031781608238816\n",
      "Epoch 261, Loss: 0.010238152812235057, Final Batch Loss: 0.001821923884563148\n",
      "Epoch 262, Loss: 0.0038787134690210223, Final Batch Loss: 0.001057312940247357\n",
      "Epoch 263, Loss: 0.00977760972455144, Final Batch Loss: 0.005778302904218435\n",
      "Epoch 264, Loss: 0.0028446499491110444, Final Batch Loss: 0.0010386682115495205\n",
      "Epoch 265, Loss: 0.009307313594035804, Final Batch Loss: 0.007899424061179161\n",
      "Epoch 266, Loss: 0.017598592676222324, Final Batch Loss: 0.010914086364209652\n",
      "Epoch 267, Loss: 0.003983449889346957, Final Batch Loss: 0.001013939967378974\n",
      "Epoch 268, Loss: 0.004350371425971389, Final Batch Loss: 0.0012381183914840221\n",
      "Epoch 269, Loss: 0.0214587040245533, Final Batch Loss: 0.007575183175504208\n",
      "Epoch 270, Loss: 0.008274444378912449, Final Batch Loss: 0.004111464601010084\n",
      "Epoch 271, Loss: 0.004605664173141122, Final Batch Loss: 0.002328625414520502\n",
      "Epoch 272, Loss: 0.0044004046358168125, Final Batch Loss: 0.0028212943580001593\n",
      "Epoch 273, Loss: 0.013011490344069898, Final Batch Loss: 0.011896075680851936\n",
      "Epoch 274, Loss: 0.007963239215314388, Final Batch Loss: 0.003348355647176504\n",
      "Epoch 275, Loss: 0.009211797383613884, Final Batch Loss: 0.0013099435018375516\n",
      "Epoch 276, Loss: 0.01811105478554964, Final Batch Loss: 0.015854476019740105\n",
      "Epoch 277, Loss: 0.013405019650235772, Final Batch Loss: 0.011180559173226357\n",
      "Epoch 278, Loss: 0.0037658768706023693, Final Batch Loss: 0.0015128636732697487\n",
      "Epoch 279, Loss: 0.005079337628558278, Final Batch Loss: 0.002754095708951354\n",
      "Epoch 280, Loss: 0.0035955572384409606, Final Batch Loss: 0.0006933381664566696\n",
      "Epoch 281, Loss: 0.021716049639508128, Final Batch Loss: 0.018870389088988304\n",
      "Epoch 282, Loss: 0.0032015664037317038, Final Batch Loss: 0.0011315965093672276\n",
      "Epoch 283, Loss: 0.008732692804187536, Final Batch Loss: 0.0021388009190559387\n",
      "Epoch 284, Loss: 0.013573184376582503, Final Batch Loss: 0.003235287731513381\n",
      "Epoch 285, Loss: 0.0031962417997419834, Final Batch Loss: 0.001568743959069252\n",
      "Epoch 286, Loss: 0.012504807440564036, Final Batch Loss: 0.0024377505760639906\n",
      "Epoch 287, Loss: 0.009191316552460194, Final Batch Loss: 0.004555853083729744\n",
      "Epoch 288, Loss: 0.017978162970393896, Final Batch Loss: 0.0036492426879704\n",
      "Epoch 289, Loss: 0.006629824754782021, Final Batch Loss: 0.0017416073242202401\n",
      "Epoch 290, Loss: 0.011755390092730522, Final Batch Loss: 0.00561429001390934\n",
      "Epoch 291, Loss: 0.006527544464915991, Final Batch Loss: 0.0018205414526164532\n",
      "Epoch 292, Loss: 0.005192477139644325, Final Batch Loss: 0.0015397717943415046\n",
      "Epoch 293, Loss: 0.008837023517116904, Final Batch Loss: 0.008226963691413403\n",
      "Epoch 294, Loss: 0.0017894536722451448, Final Batch Loss: 0.001024028635583818\n",
      "Epoch 295, Loss: 0.008457498624920845, Final Batch Loss: 0.007384567987173796\n",
      "Epoch 296, Loss: 0.004697715397924185, Final Batch Loss: 0.0035135382786393166\n",
      "Epoch 297, Loss: 0.010561152012087405, Final Batch Loss: 0.0011867393041029572\n",
      "Epoch 298, Loss: 0.016899259528145194, Final Batch Loss: 0.0029458783101290464\n",
      "Epoch 299, Loss: 0.005786572000943124, Final Batch Loss: 0.0014262361219152808\n",
      "Epoch 300, Loss: 0.006538389949128032, Final Batch Loss: 0.001984301721677184\n",
      "Epoch 301, Loss: 0.012014883803203702, Final Batch Loss: 0.008167541585862637\n",
      "Epoch 302, Loss: 0.04062015423551202, Final Batch Loss: 0.03676362335681915\n",
      "Epoch 303, Loss: 0.0063565189484506845, Final Batch Loss: 0.003529838053509593\n",
      "Epoch 304, Loss: 0.00212347530759871, Final Batch Loss: 0.0010541477240622044\n",
      "Epoch 305, Loss: 0.008965412504039705, Final Batch Loss: 0.0012550473911687732\n",
      "Epoch 306, Loss: 0.00963238999247551, Final Batch Loss: 0.003421185538172722\n",
      "Epoch 307, Loss: 0.003542891819961369, Final Batch Loss: 0.0016866414807736874\n",
      "Epoch 308, Loss: 0.0023836164036765695, Final Batch Loss: 0.0008783037774264812\n",
      "Epoch 309, Loss: 0.006418672273866832, Final Batch Loss: 0.0051837824285030365\n",
      "Epoch 310, Loss: 0.011070926673710346, Final Batch Loss: 0.001041863113641739\n",
      "Epoch 311, Loss: 0.001794506679289043, Final Batch Loss: 0.000692194327712059\n",
      "Epoch 312, Loss: 0.00723672891035676, Final Batch Loss: 0.002483211923390627\n",
      "Epoch 313, Loss: 0.008354357327334583, Final Batch Loss: 0.0008488110033795238\n",
      "Epoch 314, Loss: 0.004044075612910092, Final Batch Loss: 0.0023882195819169283\n",
      "Epoch 315, Loss: 0.006501925876364112, Final Batch Loss: 0.0013242948334664106\n",
      "Epoch 316, Loss: 0.007239157101139426, Final Batch Loss: 0.0037888456135988235\n",
      "Epoch 317, Loss: 0.0031594333704560995, Final Batch Loss: 0.0012313768966123462\n",
      "Epoch 318, Loss: 0.0027705206302925944, Final Batch Loss: 0.0015599880134686828\n",
      "Epoch 319, Loss: 0.002460922347381711, Final Batch Loss: 0.0012570106191560626\n",
      "Epoch 320, Loss: 0.006235881941393018, Final Batch Loss: 0.005065997131168842\n",
      "Epoch 321, Loss: 0.010207628540229052, Final Batch Loss: 0.0005766560207121074\n",
      "Epoch 322, Loss: 0.005206167814321816, Final Batch Loss: 0.0035992416087538004\n",
      "Epoch 323, Loss: 0.0064312724862247705, Final Batch Loss: 0.0034236067440360785\n",
      "Epoch 324, Loss: 0.0036910417256876826, Final Batch Loss: 0.0025007997173815966\n",
      "Epoch 325, Loss: 0.003640406299382448, Final Batch Loss: 0.0009927735663950443\n",
      "Epoch 326, Loss: 0.005700836423784494, Final Batch Loss: 0.0013349419459700584\n",
      "Epoch 327, Loss: 0.014064307208172977, Final Batch Loss: 0.012874767184257507\n",
      "Epoch 328, Loss: 0.020257695112377405, Final Batch Loss: 0.0035722260363399982\n",
      "Epoch 329, Loss: 0.0014247455983422697, Final Batch Loss: 0.0005166015471331775\n",
      "Epoch 330, Loss: 0.002780734561383724, Final Batch Loss: 0.0004104054532945156\n",
      "Epoch 331, Loss: 0.003045300836674869, Final Batch Loss: 0.0019559860229492188\n",
      "Epoch 332, Loss: 0.013618056138511747, Final Batch Loss: 0.0009369816980324686\n",
      "Epoch 333, Loss: 0.0032889138674363494, Final Batch Loss: 0.0011091922642663121\n",
      "Epoch 334, Loss: 0.0036669368273578584, Final Batch Loss: 0.0007646395242772996\n",
      "Epoch 335, Loss: 0.005981559632346034, Final Batch Loss: 0.001847273437306285\n",
      "Epoch 336, Loss: 0.004427523352205753, Final Batch Loss: 0.003483364125713706\n",
      "Epoch 337, Loss: 0.006315698497928679, Final Batch Loss: 0.001812883303500712\n",
      "Epoch 338, Loss: 0.008556492393836379, Final Batch Loss: 0.0075209299102425575\n",
      "Epoch 339, Loss: 0.007590217050164938, Final Batch Loss: 0.0014278455637395382\n",
      "Epoch 340, Loss: 0.006390904221916571, Final Batch Loss: 0.0004428323882166296\n",
      "Epoch 341, Loss: 0.009568349516484886, Final Batch Loss: 0.009212249889969826\n",
      "Epoch 342, Loss: 0.010779787320643663, Final Batch Loss: 0.006725955288857222\n",
      "Epoch 343, Loss: 0.005228713387623429, Final Batch Loss: 0.0008969374466687441\n",
      "Epoch 344, Loss: 0.009744309703819454, Final Batch Loss: 0.001832876238040626\n",
      "Epoch 345, Loss: 0.008913411758840084, Final Batch Loss: 0.00661657378077507\n",
      "Epoch 346, Loss: 0.006293459155131131, Final Batch Loss: 0.005547571927309036\n",
      "Epoch 347, Loss: 0.03187729325145483, Final Batch Loss: 0.009501799009740353\n",
      "Epoch 348, Loss: 0.00401191774290055, Final Batch Loss: 0.0014171708608046174\n",
      "Epoch 349, Loss: 0.0062609154265373945, Final Batch Loss: 0.00459655188024044\n",
      "Epoch 350, Loss: 0.002189772727433592, Final Batch Loss: 0.001639004796743393\n",
      "Epoch 351, Loss: 0.006840390677098185, Final Batch Loss: 0.0006866478943265975\n",
      "Epoch 352, Loss: 0.004144702106714249, Final Batch Loss: 0.0021483320742845535\n",
      "Epoch 353, Loss: 0.002291559416335076, Final Batch Loss: 0.001708990428596735\n",
      "Epoch 354, Loss: 0.020684047951363027, Final Batch Loss: 0.001638933434151113\n",
      "Epoch 355, Loss: 0.016099884640425444, Final Batch Loss: 0.0012539266608655453\n",
      "Epoch 356, Loss: 0.0014695707359351218, Final Batch Loss: 0.0006519028684124351\n",
      "Epoch 357, Loss: 0.0018410957127343863, Final Batch Loss: 0.0003781623381655663\n",
      "Epoch 358, Loss: 0.007984445430338383, Final Batch Loss: 0.003969099372625351\n",
      "Epoch 359, Loss: 0.002437428687699139, Final Batch Loss: 0.0017180789727717638\n",
      "Epoch 360, Loss: 0.009770999662578106, Final Batch Loss: 0.005055732559412718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361, Loss: 0.002602852589916438, Final Batch Loss: 0.002341016661375761\n",
      "Epoch 362, Loss: 0.0017603462329134345, Final Batch Loss: 0.0010245483135804534\n",
      "Epoch 363, Loss: 0.012762896833010018, Final Batch Loss: 0.0011759429471567273\n",
      "Epoch 364, Loss: 0.013001476414501667, Final Batch Loss: 0.006334768142551184\n",
      "Epoch 365, Loss: 0.012946262257173657, Final Batch Loss: 0.0038772879634052515\n",
      "Epoch 366, Loss: 0.0019941123318858445, Final Batch Loss: 0.0012380302650853992\n",
      "Epoch 367, Loss: 0.004217119829263538, Final Batch Loss: 0.0008702123886905611\n",
      "Epoch 368, Loss: 0.010055773658677936, Final Batch Loss: 0.007953121326863766\n",
      "Epoch 369, Loss: 0.004779679700732231, Final Batch Loss: 0.0003438149578869343\n",
      "Epoch 370, Loss: 0.02166453725658357, Final Batch Loss: 0.017984548583626747\n",
      "Epoch 371, Loss: 0.0024958541325759143, Final Batch Loss: 0.0003581628843676299\n",
      "Epoch 372, Loss: 0.0042371670715510845, Final Batch Loss: 0.0006540766917169094\n",
      "Epoch 373, Loss: 0.00500482926145196, Final Batch Loss: 0.002747624646872282\n",
      "Epoch 374, Loss: 0.0063794925808906555, Final Batch Loss: 0.0010096309706568718\n",
      "Epoch 375, Loss: 0.016221416590269655, Final Batch Loss: 0.015904700383543968\n",
      "Epoch 376, Loss: 0.0005204760964261368, Final Batch Loss: 0.00028369895881041884\n",
      "Epoch 377, Loss: 0.001762794447131455, Final Batch Loss: 0.0008314416045323014\n",
      "Epoch 378, Loss: 0.0034509802935644984, Final Batch Loss: 0.0022914798464626074\n",
      "Epoch 379, Loss: 0.0035272338427603245, Final Batch Loss: 0.001379999564960599\n",
      "Epoch 380, Loss: 0.0037222258979454637, Final Batch Loss: 0.00115173717495054\n",
      "Epoch 381, Loss: 0.005162714805919677, Final Batch Loss: 0.00435565086081624\n",
      "Epoch 382, Loss: 0.0029913512989878654, Final Batch Loss: 0.0011966752354055643\n",
      "Epoch 383, Loss: 0.0035129289026372135, Final Batch Loss: 0.000702743127476424\n",
      "Epoch 384, Loss: 0.0040801564464345574, Final Batch Loss: 0.0035234810784459114\n",
      "Epoch 385, Loss: 0.0018234594608657062, Final Batch Loss: 0.0013635556679219007\n",
      "Epoch 386, Loss: 0.0026202426524832845, Final Batch Loss: 0.0019877811428159475\n",
      "Epoch 387, Loss: 0.0024873471120372415, Final Batch Loss: 0.0012993605341762304\n",
      "Epoch 388, Loss: 0.0026670449296943843, Final Batch Loss: 0.002116147195920348\n",
      "Epoch 389, Loss: 0.003350301180034876, Final Batch Loss: 0.0024521395098417997\n",
      "Epoch 390, Loss: 0.011084335623309016, Final Batch Loss: 0.0031361475121229887\n",
      "Epoch 391, Loss: 0.006163621321320534, Final Batch Loss: 0.004513560328632593\n",
      "Epoch 392, Loss: 0.0030633913120254874, Final Batch Loss: 0.0005673352861776948\n",
      "Epoch 393, Loss: 0.0012252716696821153, Final Batch Loss: 0.0005074849468655884\n",
      "Epoch 394, Loss: 0.013931999215856194, Final Batch Loss: 0.013291941024363041\n",
      "Epoch 395, Loss: 0.005852709291502833, Final Batch Loss: 0.002504822099581361\n",
      "Epoch 396, Loss: 0.006179692572914064, Final Batch Loss: 0.0013477647444233298\n",
      "Epoch 397, Loss: 0.01408314611762762, Final Batch Loss: 0.0058642057701945305\n",
      "Epoch 398, Loss: 0.0010627508163452148, Final Batch Loss: 0.0005920571857132018\n",
      "Epoch 399, Loss: 0.011560408864170313, Final Batch Loss: 0.006337462924420834\n",
      "Epoch 400, Loss: 0.01103708811569959, Final Batch Loss: 0.0012383881257846951\n",
      "Epoch 401, Loss: 0.0013099098578095436, Final Batch Loss: 0.00040562532376497984\n",
      "Epoch 402, Loss: 0.0010678992257453501, Final Batch Loss: 0.0005842748214490712\n",
      "Epoch 403, Loss: 0.011980447685346007, Final Batch Loss: 0.009707776829600334\n",
      "Epoch 404, Loss: 0.002205211145337671, Final Batch Loss: 0.0009267038549296558\n",
      "Epoch 405, Loss: 0.0009485482005402446, Final Batch Loss: 0.00016106595285236835\n",
      "Epoch 406, Loss: 0.011326680309139192, Final Batch Loss: 0.0007781389867886901\n",
      "Epoch 407, Loss: 0.0033284653909504414, Final Batch Loss: 0.0019315636018291116\n",
      "Epoch 408, Loss: 0.004418864380568266, Final Batch Loss: 0.002065172651782632\n",
      "Epoch 409, Loss: 0.003383021103218198, Final Batch Loss: 0.0004168583545833826\n",
      "Epoch 410, Loss: 0.0013344957842491567, Final Batch Loss: 0.0005195420817472041\n",
      "Epoch 411, Loss: 0.0006741721590515226, Final Batch Loss: 0.000342437851941213\n",
      "Epoch 412, Loss: 0.00928717793431133, Final Batch Loss: 0.0012006232282146811\n",
      "Epoch 413, Loss: 0.005182044813409448, Final Batch Loss: 0.0038314005360007286\n",
      "Epoch 414, Loss: 0.0015220603090710938, Final Batch Loss: 0.0006822437280789018\n",
      "Epoch 415, Loss: 0.005044830031692982, Final Batch Loss: 0.0035417594481259584\n",
      "Epoch 416, Loss: 0.0012007855693809688, Final Batch Loss: 0.0007425959338434041\n",
      "Epoch 417, Loss: 0.01073549222201109, Final Batch Loss: 0.005218688398599625\n",
      "Epoch 418, Loss: 0.0030598300509154797, Final Batch Loss: 0.0005708779208362103\n",
      "Epoch 419, Loss: 0.0018100894521921873, Final Batch Loss: 0.0008396502817049623\n",
      "Epoch 420, Loss: 0.0022792285890318453, Final Batch Loss: 0.001448310911655426\n",
      "Epoch 421, Loss: 0.0012234169989824295, Final Batch Loss: 0.0008348326082341373\n",
      "Epoch 422, Loss: 0.003267873893491924, Final Batch Loss: 0.0016488786786794662\n",
      "Epoch 423, Loss: 0.014293793472461402, Final Batch Loss: 0.013738492503762245\n",
      "Epoch 424, Loss: 0.0036395058850757778, Final Batch Loss: 0.0005791729199700058\n",
      "Epoch 425, Loss: 0.0009968295344151556, Final Batch Loss: 0.0003621316864155233\n",
      "Epoch 426, Loss: 0.003771806543227285, Final Batch Loss: 0.003364649135619402\n",
      "Epoch 427, Loss: 0.001149770905612968, Final Batch Loss: 0.000925318687222898\n",
      "Epoch 428, Loss: 0.005565156461670995, Final Batch Loss: 0.0021880799904465675\n",
      "Epoch 429, Loss: 0.0008902978734113276, Final Batch Loss: 0.0006318390369415283\n",
      "Epoch 430, Loss: 0.001489151210989803, Final Batch Loss: 0.0008894366910681129\n",
      "Epoch 431, Loss: 0.002195044857216999, Final Batch Loss: 0.00206949096173048\n",
      "Epoch 432, Loss: 0.0039018295938149095, Final Batch Loss: 0.0005867722211405635\n",
      "Epoch 433, Loss: 0.0017322813509963453, Final Batch Loss: 0.0007587461150251329\n",
      "Epoch 434, Loss: 0.0007801806787028909, Final Batch Loss: 0.00035125072463415563\n",
      "Epoch 435, Loss: 0.00394151039654389, Final Batch Loss: 0.0004817993030883372\n",
      "Epoch 436, Loss: 0.004252844402799383, Final Batch Loss: 0.0037940179463475943\n",
      "Epoch 437, Loss: 0.001497745543019846, Final Batch Loss: 0.00032876982004381716\n",
      "Epoch 438, Loss: 0.007386818062514067, Final Batch Loss: 0.004465093836188316\n",
      "Epoch 439, Loss: 0.0072317993035539985, Final Batch Loss: 0.006473251152783632\n",
      "Epoch 440, Loss: 0.009457480162382126, Final Batch Loss: 0.005371151026338339\n",
      "Epoch 441, Loss: 0.0023003638489171863, Final Batch Loss: 0.0008283508941531181\n",
      "Epoch 442, Loss: 0.0013854565331712365, Final Batch Loss: 0.00043309025932103395\n",
      "Epoch 443, Loss: 0.006065642461180687, Final Batch Loss: 0.005439333152025938\n",
      "Epoch 444, Loss: 0.0048229548847302794, Final Batch Loss: 0.004493325483053923\n",
      "Epoch 445, Loss: 0.00645020161755383, Final Batch Loss: 0.003903732867911458\n",
      "Epoch 446, Loss: 0.002105438325088471, Final Batch Loss: 0.0004469234845601022\n",
      "Epoch 447, Loss: 0.0038002798100933433, Final Batch Loss: 0.000975813833065331\n",
      "Epoch 448, Loss: 0.0006856196996523067, Final Batch Loss: 0.0005430993624031544\n",
      "Epoch 449, Loss: 0.0012159209582023323, Final Batch Loss: 0.00044671312207356095\n",
      "Epoch 450, Loss: 0.003252931230235845, Final Batch Loss: 0.00042371038580313325\n",
      "Epoch 451, Loss: 0.003939278714824468, Final Batch Loss: 0.00350756268016994\n",
      "Epoch 452, Loss: 0.0029628996271640062, Final Batch Loss: 0.0021808817982673645\n",
      "Epoch 453, Loss: 0.006852366263046861, Final Batch Loss: 0.005783961154520512\n",
      "Epoch 454, Loss: 0.0015083201578818262, Final Batch Loss: 0.000564799876883626\n",
      "Epoch 455, Loss: 0.005294664995744824, Final Batch Loss: 0.004520700313150883\n",
      "Epoch 456, Loss: 0.001519300218205899, Final Batch Loss: 0.0009660521754994988\n",
      "Epoch 457, Loss: 0.0023863238748162985, Final Batch Loss: 0.0005078759277239442\n",
      "Epoch 458, Loss: 0.00044132734183222055, Final Batch Loss: 0.00017948681488633156\n",
      "Epoch 459, Loss: 0.00083251362957526, Final Batch Loss: 0.0001902705553220585\n",
      "Epoch 460, Loss: 0.0004215977678541094, Final Batch Loss: 0.00015021744184195995\n",
      "Epoch 461, Loss: 0.0012063681206200272, Final Batch Loss: 0.0002914982324000448\n",
      "Epoch 462, Loss: 0.0029079453670419753, Final Batch Loss: 0.0003937185392715037\n",
      "Epoch 463, Loss: 0.0009779813117347658, Final Batch Loss: 0.0007021963247098029\n",
      "Epoch 464, Loss: 0.007424993964377791, Final Batch Loss: 0.0007201280095614493\n",
      "Epoch 465, Loss: 0.011476016661617905, Final Batch Loss: 0.0006571245030499995\n",
      "Epoch 466, Loss: 0.0030762231908738613, Final Batch Loss: 0.0006107238586992025\n",
      "Epoch 467, Loss: 0.0007778909057378769, Final Batch Loss: 0.0005740387132391334\n",
      "Epoch 468, Loss: 0.005971173522993922, Final Batch Loss: 0.005292876157909632\n",
      "Epoch 469, Loss: 0.003938892274163663, Final Batch Loss: 0.0020934282802045345\n",
      "Epoch 470, Loss: 0.0008496962545905262, Final Batch Loss: 0.0006915510748513043\n",
      "Epoch 471, Loss: 0.0034748436883091927, Final Batch Loss: 0.0012616231106221676\n",
      "Epoch 472, Loss: 0.0024716793559491634, Final Batch Loss: 0.0010364599293097854\n",
      "Epoch 473, Loss: 0.0010257510584779084, Final Batch Loss: 0.0004967552376911044\n",
      "Epoch 474, Loss: 0.0007081885414663702, Final Batch Loss: 0.00043738700333051383\n",
      "Epoch 475, Loss: 0.0016941886278800666, Final Batch Loss: 0.0009042118908837438\n",
      "Epoch 476, Loss: 0.0011981107527390122, Final Batch Loss: 0.0005943389842286706\n",
      "Epoch 477, Loss: 0.007094452157616615, Final Batch Loss: 0.004116167780011892\n",
      "Epoch 478, Loss: 0.004819318186491728, Final Batch Loss: 0.003572064684703946\n",
      "Epoch 479, Loss: 0.0022631275933235884, Final Batch Loss: 0.0009713764302432537\n",
      "Epoch 480, Loss: 0.011090533807873726, Final Batch Loss: 0.0037424908950924873\n",
      "Epoch 481, Loss: 0.001240017416421324, Final Batch Loss: 0.00010945001849904656\n",
      "Epoch 482, Loss: 0.003502912411931902, Final Batch Loss: 0.0004540419322438538\n",
      "Epoch 483, Loss: 0.0023818352492526174, Final Batch Loss: 0.0010764246108010411\n",
      "Epoch 484, Loss: 0.0006328801246127114, Final Batch Loss: 0.00041876890463754535\n",
      "Epoch 485, Loss: 0.010168265784159303, Final Batch Loss: 0.007660900242626667\n",
      "Epoch 486, Loss: 0.00341092178132385, Final Batch Loss: 0.00027560105081647635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487, Loss: 0.0011308355169603601, Final Batch Loss: 0.00018047682533506304\n",
      "Epoch 488, Loss: 0.005484748922754079, Final Batch Loss: 0.00484437495470047\n",
      "Epoch 489, Loss: 0.005934884073212743, Final Batch Loss: 0.0013591570314019918\n",
      "Epoch 490, Loss: 0.010945844231173396, Final Batch Loss: 0.0032616935204714537\n",
      "Epoch 491, Loss: 0.0007153980841394514, Final Batch Loss: 0.00029339909087866545\n",
      "Epoch 492, Loss: 0.0028100443305447698, Final Batch Loss: 0.0004927305271849036\n",
      "Epoch 493, Loss: 0.0010348378273192793, Final Batch Loss: 0.0002718442410696298\n",
      "Epoch 494, Loss: 0.0011799991480074823, Final Batch Loss: 0.0005109196063131094\n",
      "Epoch 495, Loss: 0.001051974861184135, Final Batch Loss: 0.0003064618504140526\n",
      "Epoch 496, Loss: 0.0006001739093335345, Final Batch Loss: 0.00023625510220881552\n",
      "Epoch 497, Loss: 0.0008351912256330252, Final Batch Loss: 0.0003094027633778751\n",
      "Epoch 498, Loss: 0.0008491300686728209, Final Batch Loss: 0.00017729340470395982\n",
      "Epoch 499, Loss: 0.004741439770441502, Final Batch Loss: 0.004624767694622278\n",
      "Epoch 500, Loss: 0.010728903114795685, Final Batch Loss: 0.006001243833452463\n",
      "Epoch 501, Loss: 0.002917700505349785, Final Batch Loss: 0.0008190139778889716\n",
      "Epoch 502, Loss: 0.007428994489600882, Final Batch Loss: 0.007021368481218815\n",
      "Epoch 503, Loss: 0.006130686262622476, Final Batch Loss: 0.0035263781901448965\n",
      "Epoch 504, Loss: 0.008470523229334503, Final Batch Loss: 0.008164288476109505\n",
      "Epoch 505, Loss: 0.00311970565962838, Final Batch Loss: 9.963516640709713e-05\n",
      "Epoch 506, Loss: 0.010199492622632533, Final Batch Loss: 0.009737486951053143\n",
      "Epoch 507, Loss: 0.0018920099828392267, Final Batch Loss: 0.000644660321995616\n",
      "Epoch 508, Loss: 0.006928182352567092, Final Batch Loss: 0.00024510748335160315\n",
      "Epoch 509, Loss: 0.005881772405700758, Final Batch Loss: 0.005552191287279129\n",
      "Epoch 510, Loss: 0.008673413656651974, Final Batch Loss: 0.004494525026530027\n",
      "Epoch 511, Loss: 0.0020869188010692596, Final Batch Loss: 0.0013786243507638574\n",
      "Epoch 512, Loss: 0.000585665853577666, Final Batch Loss: 0.0004375932039692998\n",
      "Epoch 513, Loss: 0.007000167475780472, Final Batch Loss: 0.00661360053345561\n",
      "Epoch 514, Loss: 0.004278420936316252, Final Batch Loss: 0.002720997203141451\n",
      "Epoch 515, Loss: 0.004282524168957025, Final Batch Loss: 0.0007240763516165316\n",
      "Epoch 516, Loss: 0.0039959269925020635, Final Batch Loss: 0.0007031419663690031\n",
      "Epoch 517, Loss: 0.011017345357686281, Final Batch Loss: 0.008316071704030037\n",
      "Epoch 518, Loss: 0.010719008976593614, Final Batch Loss: 0.0075443945825099945\n",
      "Epoch 519, Loss: 0.0017997876275330782, Final Batch Loss: 0.0007354019908234477\n",
      "Epoch 520, Loss: 0.00623738206923008, Final Batch Loss: 0.003944597207009792\n",
      "Epoch 521, Loss: 0.0012872798833996058, Final Batch Loss: 0.0003390478668734431\n",
      "Epoch 522, Loss: 0.012602162343682721, Final Batch Loss: 0.012436985969543457\n",
      "Epoch 523, Loss: 0.008133291703416035, Final Batch Loss: 0.0003340970433782786\n",
      "Epoch 524, Loss: 0.007825222768587992, Final Batch Loss: 0.00048701322521083057\n",
      "Epoch 525, Loss: 0.0005715041043004021, Final Batch Loss: 0.0003920319431927055\n",
      "Epoch 526, Loss: 0.0003683195245685056, Final Batch Loss: 0.000172183194081299\n",
      "Epoch 527, Loss: 0.0035287251230329275, Final Batch Loss: 0.0013690113555639982\n",
      "Epoch 528, Loss: 0.0005541636637644842, Final Batch Loss: 0.00020963164570275694\n",
      "Epoch 529, Loss: 0.003704764589201659, Final Batch Loss: 0.00025262002600356936\n",
      "Epoch 530, Loss: 0.00034054991556331515, Final Batch Loss: 0.00018999555322807282\n",
      "Epoch 531, Loss: 0.0008843252144288272, Final Batch Loss: 0.00013144410331733525\n",
      "Epoch 532, Loss: 0.0015544996713288128, Final Batch Loss: 0.0010588541626930237\n",
      "Epoch 533, Loss: 0.0037208659923635423, Final Batch Loss: 0.0034830595832318068\n",
      "Epoch 534, Loss: 0.0024571348112658598, Final Batch Loss: 8.272185368696228e-05\n",
      "Epoch 535, Loss: 0.0007306469196919352, Final Batch Loss: 0.000316479621687904\n",
      "Epoch 536, Loss: 0.008172583533450961, Final Batch Loss: 0.007726647891104221\n",
      "Epoch 537, Loss: 0.0038674555253237486, Final Batch Loss: 0.0012891348451375961\n",
      "Epoch 538, Loss: 0.0014125657617114484, Final Batch Loss: 0.000642351689748466\n",
      "Epoch 539, Loss: 0.005092834515380673, Final Batch Loss: 0.00011750163685064763\n",
      "Epoch 540, Loss: 0.003909408580511808, Final Batch Loss: 0.002929558278992772\n",
      "Epoch 541, Loss: 0.0010249744518660009, Final Batch Loss: 0.0006136127631179988\n",
      "Epoch 542, Loss: 0.0027071909862570465, Final Batch Loss: 0.0024092593230307102\n",
      "Epoch 543, Loss: 0.003615392924984917, Final Batch Loss: 0.003176604164764285\n",
      "Epoch 544, Loss: 0.0007891455024946481, Final Batch Loss: 0.00028498543542809784\n",
      "Epoch 545, Loss: 0.003691696561872959, Final Batch Loss: 0.0015873939264565706\n",
      "Epoch 546, Loss: 0.0008626616036053747, Final Batch Loss: 0.000570629897993058\n",
      "Epoch 547, Loss: 0.007597685791552067, Final Batch Loss: 0.0060606482438743114\n",
      "Epoch 548, Loss: 0.0014995199453551322, Final Batch Loss: 0.0012744356645271182\n",
      "Epoch 549, Loss: 0.0007433298451360315, Final Batch Loss: 0.0002825638803187758\n",
      "Epoch 550, Loss: 0.003724865324329585, Final Batch Loss: 0.0032164324074983597\n",
      "Epoch 551, Loss: 0.0011191528756171465, Final Batch Loss: 0.0002792106242850423\n",
      "Epoch 552, Loss: 0.0028508869581855834, Final Batch Loss: 0.0001780498423613608\n",
      "Epoch 553, Loss: 0.0014514988870359957, Final Batch Loss: 0.0013228668831288815\n",
      "Epoch 554, Loss: 0.0018736725323833525, Final Batch Loss: 0.0011355923488736153\n",
      "Epoch 555, Loss: 0.004521103342995048, Final Batch Loss: 0.004248915705829859\n",
      "Epoch 556, Loss: 0.0007773535908199847, Final Batch Loss: 0.0002654477139003575\n",
      "Epoch 557, Loss: 0.0007611194741912186, Final Batch Loss: 0.0004659723781514913\n",
      "Epoch 558, Loss: 0.0009521490283077583, Final Batch Loss: 0.00011488176824059337\n",
      "Epoch 559, Loss: 0.000914464530069381, Final Batch Loss: 0.0005413886974565685\n",
      "Epoch 560, Loss: 0.0016212333284784108, Final Batch Loss: 0.0002649856323841959\n",
      "Epoch 561, Loss: 0.0008508258033543825, Final Batch Loss: 0.0003083499614149332\n",
      "Epoch 562, Loss: 0.0025281757989432663, Final Batch Loss: 0.00014281048788689077\n",
      "Epoch 563, Loss: 0.0034705839352682233, Final Batch Loss: 0.0012342057889327407\n",
      "Epoch 564, Loss: 0.004350151750259101, Final Batch Loss: 0.0002326009562239051\n",
      "Epoch 565, Loss: 0.00042633365228539333, Final Batch Loss: 0.00031901709735393524\n",
      "Epoch 566, Loss: 0.00212505622766912, Final Batch Loss: 0.0013486921088770032\n",
      "Epoch 567, Loss: 0.0044318397413007915, Final Batch Loss: 0.0002681689220480621\n",
      "Epoch 568, Loss: 0.0012014132807962596, Final Batch Loss: 0.0005508526810444891\n",
      "Epoch 569, Loss: 0.004364990163594484, Final Batch Loss: 0.0021393229253590107\n",
      "Epoch 570, Loss: 0.0004691915964940563, Final Batch Loss: 8.429326408077031e-05\n",
      "Epoch 571, Loss: 0.012017820496112108, Final Batch Loss: 0.010779991745948792\n",
      "Epoch 572, Loss: 0.001235029601957649, Final Batch Loss: 0.0007559297373518348\n",
      "Epoch 573, Loss: 0.00034644678817130625, Final Batch Loss: 0.00013164899428375065\n",
      "Epoch 574, Loss: 0.015309722512029111, Final Batch Loss: 0.014387880451977253\n",
      "Epoch 575, Loss: 0.0023515198845416307, Final Batch Loss: 0.0007788743823766708\n",
      "Epoch 576, Loss: 0.0012688589340541512, Final Batch Loss: 0.0009867571061477065\n",
      "Epoch 577, Loss: 0.00100987809128128, Final Batch Loss: 0.00035198949626646936\n",
      "Epoch 578, Loss: 0.002003306697588414, Final Batch Loss: 0.0006553367129527032\n",
      "Epoch 579, Loss: 0.0009346871520392597, Final Batch Loss: 0.0002781677758321166\n",
      "Epoch 580, Loss: 0.0013052066788077354, Final Batch Loss: 0.0006861479487270117\n",
      "Epoch 581, Loss: 0.0027272789739072323, Final Batch Loss: 0.0019560684449970722\n",
      "Epoch 582, Loss: 0.0009466918127145618, Final Batch Loss: 0.00039757267222739756\n",
      "Epoch 583, Loss: 0.0017897291691042483, Final Batch Loss: 0.00036545697366818786\n",
      "Epoch 584, Loss: 0.0008693126874277368, Final Batch Loss: 0.0006647130358032882\n",
      "Epoch 585, Loss: 0.0026926842983812094, Final Batch Loss: 0.0020773829892277718\n",
      "Epoch 586, Loss: 0.00099154410418123, Final Batch Loss: 0.0001595084904693067\n",
      "Epoch 587, Loss: 0.002216937005869113, Final Batch Loss: 0.002035928890109062\n",
      "Epoch 588, Loss: 0.013305613305419683, Final Batch Loss: 0.0041185966692864895\n",
      "Epoch 589, Loss: 0.0005694252031389624, Final Batch Loss: 0.00031892640981823206\n",
      "Epoch 590, Loss: 0.0008835991320665926, Final Batch Loss: 0.0006140008335933089\n",
      "Epoch 591, Loss: 0.000678788754157722, Final Batch Loss: 0.0005214776610955596\n",
      "Epoch 592, Loss: 0.002292018965817988, Final Batch Loss: 0.000332184717990458\n",
      "Epoch 593, Loss: 0.0009524272463750094, Final Batch Loss: 0.00038899239734746516\n",
      "Epoch 594, Loss: 0.0013766679621767253, Final Batch Loss: 0.0010084196692332625\n",
      "Epoch 595, Loss: 0.0008323354995809495, Final Batch Loss: 0.00034304463770240545\n",
      "Epoch 596, Loss: 0.0055470040533691645, Final Batch Loss: 0.00456364406272769\n",
      "Epoch 597, Loss: 0.0005526659806491807, Final Batch Loss: 0.0002329125563846901\n",
      "Epoch 598, Loss: 0.0004162873956374824, Final Batch Loss: 0.00021565055067185313\n",
      "Epoch 599, Loss: 0.0036277264589443803, Final Batch Loss: 0.0007747031049802899\n",
      "Epoch 600, Loss: 0.0004823534545721486, Final Batch Loss: 0.0001141006505349651\n",
      "Epoch 601, Loss: 0.00021318785002222285, Final Batch Loss: 0.0001244790619239211\n",
      "Epoch 602, Loss: 0.015228273812681437, Final Batch Loss: 0.004021080676466227\n",
      "Epoch 603, Loss: 0.0004364495543995872, Final Batch Loss: 0.00036507644108496606\n",
      "Epoch 604, Loss: 0.02510629768949002, Final Batch Loss: 0.00017880822997540236\n",
      "Epoch 605, Loss: 0.0003577528550522402, Final Batch Loss: 0.00012634503946173936\n",
      "Epoch 606, Loss: 0.004189117928035557, Final Batch Loss: 0.0016384058399125934\n",
      "Epoch 607, Loss: 0.0007783312175888568, Final Batch Loss: 0.000499512127134949\n",
      "Epoch 608, Loss: 0.0017218584544025362, Final Batch Loss: 0.0007454531150870025\n",
      "Epoch 609, Loss: 0.009505200374405831, Final Batch Loss: 0.0004525884869508445\n",
      "Epoch 610, Loss: 0.000707255705492571, Final Batch Loss: 0.00020137804676778615\n",
      "Epoch 611, Loss: 0.004185199592029676, Final Batch Loss: 0.0037230446469038725\n",
      "Epoch 612, Loss: 0.000774636137066409, Final Batch Loss: 0.00030002149287611246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 613, Loss: 0.003007220453582704, Final Batch Loss: 0.0025782249867916107\n",
      "Epoch 614, Loss: 0.005200179701205343, Final Batch Loss: 0.00024567771470174193\n",
      "Epoch 615, Loss: 0.0012781178811565042, Final Batch Loss: 0.0006659265491180122\n",
      "Epoch 616, Loss: 0.0003156839848088566, Final Batch Loss: 3.915923662134446e-05\n",
      "Epoch 617, Loss: 0.007203032495453954, Final Batch Loss: 0.002245313720777631\n",
      "Epoch 618, Loss: 0.00093283255409915, Final Batch Loss: 0.00023005880939308554\n",
      "Epoch 619, Loss: 0.012139773229137063, Final Batch Loss: 0.010759606026113033\n",
      "Epoch 620, Loss: 0.0037169645947869867, Final Batch Loss: 0.0033179998863488436\n",
      "Epoch 621, Loss: 0.0013326987100299448, Final Batch Loss: 0.00029913565958850086\n",
      "Epoch 622, Loss: 0.00026171307399636135, Final Batch Loss: 0.00014137658581603318\n",
      "Epoch 623, Loss: 0.0007472141005564481, Final Batch Loss: 0.0004892964498139918\n",
      "Epoch 624, Loss: 0.002174681518226862, Final Batch Loss: 0.0020482863765209913\n",
      "Epoch 625, Loss: 0.004510878003202379, Final Batch Loss: 0.002751771127805114\n",
      "Epoch 626, Loss: 0.002630115701322211, Final Batch Loss: 4.793422340299003e-05\n",
      "Epoch 627, Loss: 0.0010906068491749465, Final Batch Loss: 0.0008103130385279655\n",
      "Epoch 628, Loss: 0.006826038588769734, Final Batch Loss: 0.0006097393343225121\n",
      "Epoch 629, Loss: 0.003658951201941818, Final Batch Loss: 0.0005583953461609781\n",
      "Epoch 630, Loss: 0.002863349160179496, Final Batch Loss: 0.0017520731780678034\n",
      "Epoch 631, Loss: 0.004169334191828966, Final Batch Loss: 0.0014060726389288902\n",
      "Epoch 632, Loss: 0.0022407701471820474, Final Batch Loss: 0.000652116839773953\n",
      "Epoch 633, Loss: 0.0006503501645056531, Final Batch Loss: 7.032426947262138e-05\n",
      "Epoch 634, Loss: 0.00033978561259573326, Final Batch Loss: 0.0002280978806084022\n",
      "Epoch 635, Loss: 0.00869622710160911, Final Batch Loss: 0.004999896977096796\n",
      "Epoch 636, Loss: 0.017874697921797633, Final Batch Loss: 0.0031729580368846655\n",
      "Epoch 637, Loss: 0.0006695618722005747, Final Batch Loss: 0.0005760401836596429\n",
      "Epoch 638, Loss: 0.0022221684484975412, Final Batch Loss: 0.00017862646200228482\n",
      "Epoch 639, Loss: 0.0011260407809459139, Final Batch Loss: 4.3707044824259356e-05\n",
      "Epoch 640, Loss: 0.011046499283111189, Final Batch Loss: 0.010932279750704765\n",
      "Epoch 641, Loss: 0.00219028809806332, Final Batch Loss: 0.00139483786188066\n",
      "Epoch 642, Loss: 0.009530803188681602, Final Batch Loss: 0.005637367255985737\n",
      "Epoch 643, Loss: 0.00045925701851956546, Final Batch Loss: 0.0001179271494038403\n",
      "Epoch 644, Loss: 0.0005979729248792864, Final Batch Loss: 6.509092781925574e-05\n",
      "Epoch 645, Loss: 0.0014480403042398393, Final Batch Loss: 0.000509025645442307\n",
      "Epoch 646, Loss: 0.002501689246855676, Final Batch Loss: 0.0019706503953784704\n",
      "Epoch 647, Loss: 0.01391531151602976, Final Batch Loss: 0.00012903191964142025\n",
      "Epoch 648, Loss: 0.0006413491501007229, Final Batch Loss: 0.00042241456685587764\n",
      "Epoch 649, Loss: 0.0011481029214337468, Final Batch Loss: 0.0003540165489539504\n",
      "Epoch 650, Loss: 0.0002442871991661377, Final Batch Loss: 0.00011951690976275131\n",
      "Epoch 651, Loss: 0.0003361162707733456, Final Batch Loss: 5.989231067360379e-05\n",
      "Epoch 652, Loss: 0.0009537540900055319, Final Batch Loss: 0.0005995765677653253\n",
      "Epoch 653, Loss: 0.0009132096893154085, Final Batch Loss: 0.00012286636047065258\n",
      "Epoch 654, Loss: 0.0007417458109557629, Final Batch Loss: 0.00020634237444028258\n",
      "Epoch 655, Loss: 0.0058235481265001, Final Batch Loss: 0.0004602514090947807\n",
      "Epoch 656, Loss: 0.0038003131048753858, Final Batch Loss: 0.0006566202500835061\n",
      "Epoch 657, Loss: 0.0031685216818004847, Final Batch Loss: 0.0002102807629853487\n",
      "Epoch 658, Loss: 0.026123646181076765, Final Batch Loss: 0.02025403454899788\n",
      "Epoch 659, Loss: 0.0007578459335491061, Final Batch Loss: 0.00041632502689026296\n",
      "Epoch 660, Loss: 0.002772075997199863, Final Batch Loss: 0.00036886887392029166\n",
      "Epoch 661, Loss: 0.003145549329929054, Final Batch Loss: 0.002145462902262807\n",
      "Epoch 662, Loss: 0.02099959455881617, Final Batch Loss: 0.020966406911611557\n",
      "Epoch 663, Loss: 0.008663283893838525, Final Batch Loss: 0.0038763589691370726\n",
      "Epoch 664, Loss: 0.0011433666659286246, Final Batch Loss: 0.0009720719535835087\n",
      "Epoch 665, Loss: 0.00439140695380047, Final Batch Loss: 0.00043949560495093465\n",
      "Epoch 666, Loss: 0.004025866812298773, Final Batch Loss: 5.9103196690557525e-05\n",
      "Epoch 667, Loss: 0.0003099815130553907, Final Batch Loss: 2.3236460037878715e-05\n",
      "Epoch 668, Loss: 0.005350096267648041, Final Batch Loss: 0.0018627782119438052\n",
      "Epoch 669, Loss: 0.006405701977200806, Final Batch Loss: 0.005116682033985853\n",
      "Epoch 670, Loss: 0.026601709265378304, Final Batch Loss: 0.00024088269856292754\n",
      "Epoch 671, Loss: 0.009316729483543895, Final Batch Loss: 0.009164049290120602\n",
      "Epoch 672, Loss: 0.0006679965590592474, Final Batch Loss: 0.00027183600468561053\n",
      "Epoch 673, Loss: 0.0035967269068351015, Final Batch Loss: 0.0002070198388537392\n",
      "Epoch 674, Loss: 0.0007163865957409143, Final Batch Loss: 0.0005536783137358725\n",
      "Epoch 675, Loss: 0.0017618147539906204, Final Batch Loss: 0.0010392731055617332\n",
      "Epoch 676, Loss: 0.0006767776794731617, Final Batch Loss: 0.0005850819288752973\n",
      "Epoch 677, Loss: 0.0011836386402137578, Final Batch Loss: 0.0005373203894123435\n",
      "Epoch 678, Loss: 0.010717305354773998, Final Batch Loss: 0.008112599141895771\n",
      "Epoch 679, Loss: 0.0017963802674785256, Final Batch Loss: 0.0007168689044192433\n",
      "Epoch 680, Loss: 0.0003565881052054465, Final Batch Loss: 7.68491008784622e-05\n",
      "Epoch 681, Loss: 0.0004548936849460006, Final Batch Loss: 0.00015461412840522826\n",
      "Epoch 682, Loss: 0.0022098944755271077, Final Batch Loss: 0.00033952260855585337\n",
      "Epoch 683, Loss: 0.002146048951544799, Final Batch Loss: 4.6800836571492255e-05\n",
      "Epoch 684, Loss: 0.002105474181007594, Final Batch Loss: 0.00031717767706140876\n",
      "Epoch 685, Loss: 0.006984768959227949, Final Batch Loss: 0.006282198708504438\n",
      "Epoch 686, Loss: 0.0016041420167312026, Final Batch Loss: 0.0009817950194701552\n",
      "Epoch 687, Loss: 0.000947633117903024, Final Batch Loss: 0.0006805857410654426\n",
      "Epoch 688, Loss: 0.0029795842128805816, Final Batch Loss: 0.0020328571554273367\n",
      "Epoch 689, Loss: 0.0006023852911312133, Final Batch Loss: 0.0001625373843125999\n",
      "Epoch 690, Loss: 0.002931910363258794, Final Batch Loss: 0.00042924194713123143\n",
      "Epoch 691, Loss: 0.004550800833385438, Final Batch Loss: 0.00400480767711997\n",
      "Epoch 692, Loss: 0.005986464791931212, Final Batch Loss: 0.001946158823557198\n",
      "Epoch 693, Loss: 0.0005766715621575713, Final Batch Loss: 0.0002945929591078311\n",
      "Epoch 694, Loss: 0.00021597852173727006, Final Batch Loss: 0.00010434397700009868\n",
      "Epoch 695, Loss: 0.0002918732170655858, Final Batch Loss: 5.7100154663203284e-05\n",
      "Epoch 696, Loss: 0.011234698700718582, Final Batch Loss: 0.00974210537970066\n",
      "Epoch 697, Loss: 0.00032538961386308074, Final Batch Loss: 0.0002063518186332658\n",
      "Epoch 698, Loss: 0.00019348558998899534, Final Batch Loss: 0.0001273199013667181\n",
      "Epoch 699, Loss: 0.0006127572996774688, Final Batch Loss: 8.168689964804798e-05\n",
      "Epoch 700, Loss: 0.0005617292335955426, Final Batch Loss: 0.00042221133480779827\n",
      "Epoch 701, Loss: 0.00196272085304372, Final Batch Loss: 0.001634561107493937\n",
      "Epoch 702, Loss: 0.005989602534100413, Final Batch Loss: 0.0036105671897530556\n",
      "Epoch 703, Loss: 0.015371911809779704, Final Batch Loss: 0.0003348846221342683\n",
      "Epoch 704, Loss: 0.001390105957398191, Final Batch Loss: 0.0012219194322824478\n",
      "Epoch 705, Loss: 0.0006488199869636446, Final Batch Loss: 0.0004094201431144029\n",
      "Epoch 706, Loss: 0.000615526078036055, Final Batch Loss: 0.00018946570344269276\n",
      "Epoch 707, Loss: 0.0009483582980465144, Final Batch Loss: 0.00046959685278125107\n",
      "Epoch 708, Loss: 0.0006689620931865647, Final Batch Loss: 0.00018676136096473783\n",
      "Epoch 709, Loss: 0.0029375936137512326, Final Batch Loss: 0.001738080638460815\n",
      "Epoch 710, Loss: 0.0010466079402249306, Final Batch Loss: 0.0008158246637322009\n",
      "Epoch 711, Loss: 0.0008846556156640872, Final Batch Loss: 0.00018246354011353105\n",
      "Epoch 712, Loss: 0.0012991746771149337, Final Batch Loss: 0.0005310123669914901\n",
      "Epoch 713, Loss: 0.0011633652611635625, Final Batch Loss: 0.00026252458337694407\n",
      "Epoch 714, Loss: 0.0006885920010972768, Final Batch Loss: 0.0002925698063336313\n",
      "Epoch 715, Loss: 0.0011759408080251887, Final Batch Loss: 0.00024038234550971538\n",
      "Epoch 716, Loss: 0.00204601397854276, Final Batch Loss: 0.0001734751567710191\n",
      "Epoch 717, Loss: 0.0005278158205328509, Final Batch Loss: 0.00038949333247728646\n",
      "Epoch 718, Loss: 0.0009004237363114953, Final Batch Loss: 0.00021823233691975474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 719, Loss: 0.001295858295634389, Final Batch Loss: 0.0002799995709210634\n",
      "Epoch 720, Loss: 0.004627369111403823, Final Batch Loss: 0.004213194362819195\n",
      "Epoch 721, Loss: 0.00028408133948687464, Final Batch Loss: 0.00013677292736247182\n",
      "Epoch 722, Loss: 0.000563238252652809, Final Batch Loss: 0.0003463100001681596\n",
      "Epoch 723, Loss: 0.0025919499748852104, Final Batch Loss: 0.0002047893067356199\n",
      "Epoch 724, Loss: 0.010961015534121543, Final Batch Loss: 0.00030191132100299\n",
      "Epoch 725, Loss: 0.0011272114934399724, Final Batch Loss: 0.0005720832850784063\n",
      "Epoch 726, Loss: 0.0015268450370058417, Final Batch Loss: 0.000225743162445724\n",
      "Epoch 727, Loss: 0.0007796304125804454, Final Batch Loss: 0.00023339720792137086\n",
      "Epoch 728, Loss: 0.002666369764483534, Final Batch Loss: 0.00015488638018723577\n",
      "Epoch 729, Loss: 0.010366541406256147, Final Batch Loss: 0.010198996402323246\n",
      "Epoch 730, Loss: 0.0037075652508065104, Final Batch Loss: 0.0030658820178359747\n",
      "Epoch 731, Loss: 0.004216010798700154, Final Batch Loss: 0.001687203417532146\n",
      "Epoch 732, Loss: 0.007367515383521095, Final Batch Loss: 0.007176967803388834\n",
      "Epoch 733, Loss: 0.0007312892485060729, Final Batch Loss: 7.86038363003172e-05\n",
      "Epoch 734, Loss: 0.0037301622796803713, Final Batch Loss: 0.0012759929522871971\n",
      "Epoch 735, Loss: 0.005121808615513146, Final Batch Loss: 0.004383178893476725\n",
      "Epoch 736, Loss: 0.004483200900722295, Final Batch Loss: 0.003939145710319281\n",
      "Epoch 737, Loss: 0.001286418701056391, Final Batch Loss: 0.0007869121036492288\n",
      "Epoch 738, Loss: 0.0003520309255691245, Final Batch Loss: 0.00011866411659866571\n",
      "Epoch 739, Loss: 0.004392334492877126, Final Batch Loss: 0.0017818822525441647\n",
      "Epoch 740, Loss: 0.0006808780890423805, Final Batch Loss: 0.0003114942810498178\n",
      "Epoch 741, Loss: 0.010514187859371305, Final Batch Loss: 0.002195782260969281\n",
      "Epoch 742, Loss: 0.00019431711552897468, Final Batch Loss: 6.211359141161665e-05\n",
      "Epoch 743, Loss: 0.0010938247432932258, Final Batch Loss: 0.0008609594660811126\n",
      "Epoch 744, Loss: 0.004664408625103533, Final Batch Loss: 0.0033556760754436255\n",
      "Epoch 745, Loss: 0.0031890684040263295, Final Batch Loss: 0.0003731906181201339\n",
      "Epoch 746, Loss: 0.01343851414276287, Final Batch Loss: 0.0004202776472084224\n",
      "Epoch 747, Loss: 0.0006814698863308877, Final Batch Loss: 0.0003636393812485039\n",
      "Epoch 748, Loss: 0.0006192487198859453, Final Batch Loss: 0.0004141138924751431\n",
      "Epoch 749, Loss: 0.000491300888825208, Final Batch Loss: 0.0003003289457410574\n",
      "Epoch 750, Loss: 0.002818718901835382, Final Batch Loss: 0.00039155117701739073\n",
      "Epoch 751, Loss: 0.0003511013273964636, Final Batch Loss: 7.064389501465484e-05\n",
      "Epoch 752, Loss: 0.002163265031413175, Final Batch Loss: 0.00017503918206784874\n",
      "Epoch 753, Loss: 0.0031815916299819946, Final Batch Loss: 0.0002818489447236061\n",
      "Epoch 754, Loss: 0.0005820394726470113, Final Batch Loss: 0.000317117664963007\n",
      "Epoch 755, Loss: 0.0019830963865388185, Final Batch Loss: 0.001496914541348815\n",
      "Epoch 756, Loss: 0.0028505231966846623, Final Batch Loss: 6.818419933551922e-05\n",
      "Epoch 757, Loss: 0.0009420342685189098, Final Batch Loss: 0.0003803578729275614\n",
      "Epoch 758, Loss: 0.011064797028666362, Final Batch Loss: 0.010910299606621265\n",
      "Epoch 759, Loss: 0.0013668412939296104, Final Batch Loss: 4.7570363676641136e-05\n",
      "Epoch 760, Loss: 0.004346305155195296, Final Batch Loss: 0.0030113719403743744\n",
      "Epoch 761, Loss: 0.003744534682482481, Final Batch Loss: 0.0003383224830031395\n",
      "Epoch 762, Loss: 0.004992806585505605, Final Batch Loss: 0.0014477390795946121\n",
      "Epoch 763, Loss: 0.0015043835664982907, Final Batch Loss: 8.265178621513769e-05\n",
      "Epoch 764, Loss: 0.000495518499519676, Final Batch Loss: 0.00016004336066544056\n",
      "Epoch 765, Loss: 0.0004090981528861448, Final Batch Loss: 0.0001745347835822031\n",
      "Epoch 766, Loss: 0.004422828642418608, Final Batch Loss: 0.0002630470262374729\n",
      "Epoch 767, Loss: 0.00020503095947788097, Final Batch Loss: 4.848926982958801e-05\n",
      "Epoch 768, Loss: 0.0031466167711187154, Final Batch Loss: 0.002926424378529191\n",
      "Epoch 769, Loss: 0.0017723617202136666, Final Batch Loss: 8.922259439714253e-05\n",
      "Epoch 770, Loss: 0.004608870614902116, Final Batch Loss: 7.445098890457302e-05\n",
      "Epoch 771, Loss: 0.0018597342423163354, Final Batch Loss: 0.00013387849321588874\n",
      "Epoch 772, Loss: 0.0007253857329487801, Final Batch Loss: 0.000572309538256377\n",
      "Epoch 773, Loss: 0.0010290107020409778, Final Batch Loss: 8.826110570225865e-05\n",
      "Epoch 774, Loss: 0.00017639018915360793, Final Batch Loss: 8.215368143282831e-05\n",
      "Epoch 775, Loss: 0.0002502316056052223, Final Batch Loss: 0.00012097173021174967\n",
      "Epoch 776, Loss: 0.006527444202220067, Final Batch Loss: 0.006141997408121824\n",
      "Epoch 777, Loss: 0.0007296393014257774, Final Batch Loss: 7.319140422623605e-05\n",
      "Epoch 778, Loss: 0.03917181889846688, Final Batch Loss: 0.03907397761940956\n",
      "Epoch 779, Loss: 0.0004803540723514743, Final Batch Loss: 0.00011538540275068954\n",
      "Epoch 780, Loss: 0.005160699947737157, Final Batch Loss: 0.000738398521207273\n",
      "Epoch 781, Loss: 0.0006554616411449388, Final Batch Loss: 0.00015300519589800388\n",
      "Epoch 782, Loss: 0.031056302970682736, Final Batch Loss: 0.03093649446964264\n",
      "Epoch 783, Loss: 0.0008879236120264977, Final Batch Loss: 0.0004171424370724708\n",
      "Epoch 784, Loss: 0.006833751045633107, Final Batch Loss: 0.0002406414714641869\n",
      "Epoch 785, Loss: 0.010091423871926963, Final Batch Loss: 0.009389815852046013\n",
      "Epoch 786, Loss: 0.002164958932553418, Final Batch Loss: 0.00014126459427643567\n",
      "Epoch 787, Loss: 0.00014375324462889694, Final Batch Loss: 4.175876165390946e-05\n",
      "Epoch 788, Loss: 0.0009700421651359648, Final Batch Loss: 0.0006061587482690811\n",
      "Epoch 789, Loss: 0.00071500834019389, Final Batch Loss: 0.0001038012997014448\n",
      "Epoch 790, Loss: 0.0007847701053833589, Final Batch Loss: 0.0005828545545227826\n",
      "Epoch 791, Loss: 0.0008656022255308926, Final Batch Loss: 0.00033806945430114865\n",
      "Epoch 792, Loss: 0.0007206118025351316, Final Batch Loss: 0.00018085134797729552\n",
      "Epoch 793, Loss: 0.0019718805997399613, Final Batch Loss: 0.00015321098908316344\n",
      "Epoch 794, Loss: 0.00037102881469763815, Final Batch Loss: 0.00013201936963014305\n",
      "Epoch 795, Loss: 0.00341813538398128, Final Batch Loss: 8.711095142643899e-05\n",
      "Epoch 796, Loss: 0.0003673313476610929, Final Batch Loss: 0.00016266925376839936\n",
      "Epoch 797, Loss: 0.00167093490017578, Final Batch Loss: 0.0006745944847352803\n",
      "Epoch 798, Loss: 0.0017886190034914762, Final Batch Loss: 0.0015443245647475123\n",
      "Epoch 799, Loss: 0.0005425528070190921, Final Batch Loss: 0.00022570184955839068\n",
      "Epoch 800, Loss: 0.004652967152651399, Final Batch Loss: 0.00018710357835516334\n",
      "Epoch 801, Loss: 0.008892776444554329, Final Batch Loss: 0.005158983636647463\n",
      "Epoch 802, Loss: 0.006224209268111736, Final Batch Loss: 0.00574580579996109\n",
      "Epoch 803, Loss: 0.0007315507682505995, Final Batch Loss: 0.00037560012424364686\n",
      "Epoch 804, Loss: 0.00033301635266980156, Final Batch Loss: 8.28938718768768e-05\n",
      "Epoch 805, Loss: 0.003800600112299435, Final Batch Loss: 0.00015055369294714183\n",
      "Epoch 806, Loss: 0.0016975494800135493, Final Batch Loss: 0.0005429337034001946\n",
      "Epoch 807, Loss: 0.005939745111390948, Final Batch Loss: 0.003119917819276452\n",
      "Epoch 808, Loss: 0.0005597745039267465, Final Batch Loss: 0.0004815563734155148\n",
      "Epoch 809, Loss: 0.0038322500186040998, Final Batch Loss: 0.002257782034575939\n",
      "Epoch 810, Loss: 0.0013023228966630995, Final Batch Loss: 0.0010960582876577973\n",
      "Epoch 811, Loss: 0.000671255009365268, Final Batch Loss: 0.0002291034470545128\n",
      "Epoch 812, Loss: 0.0019118778873234987, Final Batch Loss: 0.0009883606107905507\n",
      "Epoch 813, Loss: 0.0028245967550901696, Final Batch Loss: 0.002724204445257783\n",
      "Epoch 814, Loss: 0.0026321208279114217, Final Batch Loss: 3.3092190278694034e-05\n",
      "Epoch 815, Loss: 0.004486718215048313, Final Batch Loss: 0.004080936778336763\n",
      "Epoch 816, Loss: 0.0015459045607713051, Final Batch Loss: 0.001455612131394446\n",
      "Epoch 817, Loss: 0.0007293756571016274, Final Batch Loss: 0.00011238620936637744\n",
      "Epoch 818, Loss: 0.00299456890206784, Final Batch Loss: 0.0026359788607805967\n",
      "Epoch 819, Loss: 0.004798875888809562, Final Batch Loss: 0.004458733834326267\n",
      "Epoch 820, Loss: 0.005680542875779793, Final Batch Loss: 0.00560825876891613\n",
      "Epoch 821, Loss: 0.0010824637865880504, Final Batch Loss: 0.0010377829894423485\n",
      "Epoch 822, Loss: 0.0024297150666825473, Final Batch Loss: 0.002107860753312707\n",
      "Epoch 823, Loss: 0.0005856021889485419, Final Batch Loss: 0.00039574841503053904\n",
      "Epoch 824, Loss: 0.0007827220542822033, Final Batch Loss: 0.00025368595379404724\n",
      "Epoch 825, Loss: 0.00435754464706406, Final Batch Loss: 0.003781727282330394\n",
      "Epoch 826, Loss: 0.002902575070038438, Final Batch Loss: 0.0006862061563879251\n",
      "Epoch 827, Loss: 0.0004217850510030985, Final Batch Loss: 0.00013148717698641121\n",
      "Epoch 828, Loss: 0.002180047355068382, Final Batch Loss: 0.00010344784095650539\n",
      "Epoch 829, Loss: 0.00959991678246297, Final Batch Loss: 0.00015056427218951285\n",
      "Epoch 830, Loss: 0.00984826336207334, Final Batch Loss: 0.00011100924166385084\n",
      "Epoch 831, Loss: 0.00028110503080824856, Final Batch Loss: 1.9397857613512315e-05\n",
      "Epoch 832, Loss: 0.00023422318190569058, Final Batch Loss: 0.0001089615179807879\n",
      "Epoch 833, Loss: 0.00028570952417794615, Final Batch Loss: 0.0001614760112715885\n",
      "Epoch 834, Loss: 0.0009586602973286062, Final Batch Loss: 0.000632107665296644\n",
      "Epoch 835, Loss: 0.0025890173274092376, Final Batch Loss: 0.002353576710447669\n",
      "Epoch 836, Loss: 0.0003374119332875125, Final Batch Loss: 0.00021903465676587075\n",
      "Epoch 837, Loss: 0.0015395735681522638, Final Batch Loss: 0.0012859903508797288\n",
      "Epoch 838, Loss: 0.0028153817111160606, Final Batch Loss: 0.0027166560757905245\n",
      "Epoch 839, Loss: 0.000668269261950627, Final Batch Loss: 0.0005233222036622465\n",
      "Epoch 840, Loss: 0.00079046179598663, Final Batch Loss: 0.00012108364899177104\n",
      "Epoch 841, Loss: 0.0013945029641035944, Final Batch Loss: 0.0004570187593344599\n",
      "Epoch 842, Loss: 0.0006073622134863399, Final Batch Loss: 8.225501369452104e-05\n",
      "Epoch 843, Loss: 0.0054729661787860096, Final Batch Loss: 0.0007852336275391281\n",
      "Epoch 844, Loss: 0.0025595976621843874, Final Batch Loss: 0.0005652697873301804\n",
      "Epoch 845, Loss: 0.0006442373269237578, Final Batch Loss: 0.00029902489040978253\n",
      "Epoch 846, Loss: 0.005556440504733473, Final Batch Loss: 0.00036247732350602746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 847, Loss: 0.0001808421111491043, Final Batch Loss: 3.976773950853385e-05\n",
      "Epoch 848, Loss: 0.0020676905987784266, Final Batch Loss: 0.0001430879347026348\n",
      "Epoch 849, Loss: 0.0038174624205566943, Final Batch Loss: 0.003219342092052102\n",
      "Epoch 850, Loss: 0.002774285283521749, Final Batch Loss: 0.002627286361530423\n",
      "Epoch 851, Loss: 0.0009440707799512893, Final Batch Loss: 0.0007160326931625605\n",
      "Epoch 852, Loss: 0.0051457101362757385, Final Batch Loss: 0.004987188149243593\n",
      "Epoch 853, Loss: 0.0013269080664031208, Final Batch Loss: 0.0009514007833786309\n",
      "Epoch 854, Loss: 0.002426203471259214, Final Batch Loss: 6.635639874730259e-05\n",
      "Epoch 855, Loss: 0.00034057193261105567, Final Batch Loss: 0.00012905991752631962\n",
      "Epoch 856, Loss: 0.0040690177484066226, Final Batch Loss: 7.151443423936144e-05\n",
      "Epoch 857, Loss: 0.011814342753496021, Final Batch Loss: 0.0005120541318319738\n",
      "Epoch 858, Loss: 0.00031087436218513176, Final Batch Loss: 0.00011471108155092224\n",
      "Epoch 859, Loss: 0.0017024277476593852, Final Batch Loss: 0.000548018142580986\n",
      "Epoch 860, Loss: 0.0038643815205432475, Final Batch Loss: 0.0034702415578067303\n",
      "Epoch 861, Loss: 0.00044071856245864183, Final Batch Loss: 0.000311239215079695\n",
      "Epoch 862, Loss: 0.0008490226828143932, Final Batch Loss: 0.0007373226108029485\n",
      "Epoch 863, Loss: 0.0009305420680902898, Final Batch Loss: 0.0006218047928996384\n",
      "Epoch 864, Loss: 0.0008279168687295169, Final Batch Loss: 0.00025142650702036917\n",
      "Epoch 865, Loss: 0.0005616531561827287, Final Batch Loss: 0.00042820285307243466\n",
      "Epoch 866, Loss: 0.005021863093134016, Final Batch Loss: 0.004322945140302181\n",
      "Epoch 867, Loss: 0.00045077399045112543, Final Batch Loss: 0.0003939940652344376\n",
      "Epoch 868, Loss: 0.001450103271054104, Final Batch Loss: 0.0010115019977092743\n",
      "Epoch 869, Loss: 0.0017998223593167495, Final Batch Loss: 4.172247645328753e-05\n",
      "Epoch 870, Loss: 0.0005577206793532241, Final Batch Loss: 4.4152391637908295e-05\n",
      "Epoch 871, Loss: 0.0002961113532364834, Final Batch Loss: 4.059293496538885e-05\n",
      "Epoch 872, Loss: 0.0029277871071826667, Final Batch Loss: 0.0028490028344094753\n",
      "Epoch 873, Loss: 0.002869813295546919, Final Batch Loss: 0.0005057131056673825\n",
      "Epoch 874, Loss: 0.004143879152252339, Final Batch Loss: 0.004023237619549036\n",
      "Epoch 875, Loss: 0.00016718442202545702, Final Batch Loss: 0.00010345369082642719\n",
      "Epoch 876, Loss: 0.001510847418103367, Final Batch Loss: 0.0008676415891386569\n",
      "Epoch 877, Loss: 0.001497879740782082, Final Batch Loss: 0.0013357707066461444\n",
      "Epoch 878, Loss: 0.000292364667984657, Final Batch Loss: 0.00017012956959661096\n",
      "Epoch 879, Loss: 0.0002301290151081048, Final Batch Loss: 0.00011897755030076951\n",
      "Epoch 880, Loss: 0.0037148165283724666, Final Batch Loss: 0.0013767847558483481\n",
      "Epoch 881, Loss: 0.00020781254715984687, Final Batch Loss: 9.430522186448798e-05\n",
      "Epoch 882, Loss: 0.00030577574216295034, Final Batch Loss: 0.00013308459892868996\n",
      "Epoch 883, Loss: 0.00035369377292227, Final Batch Loss: 0.00018456968246027827\n",
      "Epoch 884, Loss: 0.0001030362727760803, Final Batch Loss: 5.48485477338545e-05\n",
      "Epoch 885, Loss: 0.011763495567720383, Final Batch Loss: 0.011513360776007175\n",
      "Epoch 886, Loss: 7.500583888031542e-05, Final Batch Loss: 3.91045214200858e-05\n",
      "Epoch 887, Loss: 0.0004072506708325818, Final Batch Loss: 9.718145884107798e-05\n",
      "Epoch 888, Loss: 0.00016279597002721857, Final Batch Loss: 2.8702574127237312e-05\n",
      "Epoch 889, Loss: 0.0006230556773516582, Final Batch Loss: 2.3431961380993016e-05\n",
      "Epoch 890, Loss: 0.001001472701318562, Final Batch Loss: 0.000296957790851593\n",
      "Epoch 891, Loss: 0.00018109472148353234, Final Batch Loss: 3.751651820493862e-05\n",
      "Epoch 892, Loss: 0.0016185891290660948, Final Batch Loss: 0.0015583416679874063\n",
      "Epoch 893, Loss: 0.00020656746346503496, Final Batch Loss: 6.064427725505084e-05\n",
      "Epoch 894, Loss: 0.006752270142897032, Final Batch Loss: 0.006583759095519781\n",
      "Epoch 895, Loss: 0.0002615884950500913, Final Batch Loss: 0.00013974234752822667\n",
      "Epoch 896, Loss: 0.0006696082855341956, Final Batch Loss: 0.00046635023318231106\n",
      "Epoch 897, Loss: 0.00027831575425807387, Final Batch Loss: 0.00023196078836917877\n",
      "Epoch 898, Loss: 0.006386468419805169, Final Batch Loss: 0.0003068645019084215\n",
      "Epoch 899, Loss: 0.00011370932043064386, Final Batch Loss: 7.205629663076252e-05\n",
      "Epoch 900, Loss: 0.0011106348101748154, Final Batch Loss: 9.764770220499486e-05\n",
      "Epoch 901, Loss: 0.0074344218883197755, Final Batch Loss: 0.007135268300771713\n",
      "Epoch 902, Loss: 0.00019212151892133988, Final Batch Loss: 0.00014580141578335315\n",
      "Epoch 903, Loss: 0.0002889804163714871, Final Batch Loss: 0.000127295934362337\n",
      "Epoch 904, Loss: 0.00031391130323754624, Final Batch Loss: 0.00023798779875505716\n",
      "Epoch 905, Loss: 0.002417881609289907, Final Batch Loss: 0.00017067613953258842\n",
      "Epoch 906, Loss: 0.004141053708735853, Final Batch Loss: 0.003526531159877777\n",
      "Epoch 907, Loss: 0.010781575576402247, Final Batch Loss: 0.00955152977257967\n",
      "Epoch 908, Loss: 0.0002710975822992623, Final Batch Loss: 0.0001293571258429438\n",
      "Epoch 909, Loss: 0.00013478766049956903, Final Batch Loss: 7.66024604672566e-05\n",
      "Epoch 910, Loss: 0.0005773570883320644, Final Batch Loss: 7.020997873041779e-05\n",
      "Epoch 911, Loss: 0.0004780852032126859, Final Batch Loss: 9.401772695127875e-05\n",
      "Epoch 912, Loss: 0.007009759898210177, Final Batch Loss: 0.00697341188788414\n",
      "Epoch 913, Loss: 0.0005662017720169388, Final Batch Loss: 7.716312393313274e-05\n",
      "Epoch 914, Loss: 0.0007417867454933003, Final Batch Loss: 0.00013525843678507954\n",
      "Epoch 915, Loss: 0.0030134834814816713, Final Batch Loss: 0.0014626695774495602\n",
      "Epoch 916, Loss: 0.002921734514529817, Final Batch Loss: 0.0028032443951815367\n",
      "Epoch 917, Loss: 0.0001404952290613437, Final Batch Loss: 2.4249786292784847e-05\n",
      "Epoch 918, Loss: 0.0004878596228081733, Final Batch Loss: 0.00016576063353568316\n",
      "Epoch 919, Loss: 0.0007963170792208984, Final Batch Loss: 0.000568521092645824\n",
      "Epoch 920, Loss: 0.0012910800869576633, Final Batch Loss: 0.0009137428132817149\n",
      "Epoch 921, Loss: 0.005340283620171249, Final Batch Loss: 0.0037737428210675716\n",
      "Epoch 922, Loss: 0.0012450881695258431, Final Batch Loss: 5.7195771660190076e-05\n",
      "Epoch 923, Loss: 0.002137319213943556, Final Batch Loss: 0.00029438352794386446\n",
      "Epoch 924, Loss: 0.00020129203403485008, Final Batch Loss: 0.0001506415574112907\n",
      "Epoch 925, Loss: 0.0036987698986195028, Final Batch Loss: 0.003433018457144499\n",
      "Epoch 926, Loss: 0.000447945756604895, Final Batch Loss: 0.0001258430420421064\n",
      "Epoch 927, Loss: 0.000187437664862955, Final Batch Loss: 0.00015641965728718787\n",
      "Epoch 928, Loss: 0.0015875036842771806, Final Batch Loss: 8.886642899597064e-05\n",
      "Epoch 929, Loss: 0.00016756995319155976, Final Batch Loss: 7.517421181546524e-05\n",
      "Epoch 930, Loss: 0.000136215916427318, Final Batch Loss: 0.0001081728478311561\n",
      "Epoch 931, Loss: 0.0016509212437085807, Final Batch Loss: 0.000501330301631242\n",
      "Epoch 932, Loss: 0.0007786241767462343, Final Batch Loss: 0.00040989238186739385\n",
      "Epoch 933, Loss: 0.0002519728004699573, Final Batch Loss: 7.21974647603929e-05\n",
      "Epoch 934, Loss: 0.00015123050980037078, Final Batch Loss: 6.847870827186853e-05\n",
      "Epoch 935, Loss: 0.0010636963415890932, Final Batch Loss: 0.0005999172572046518\n",
      "Epoch 936, Loss: 0.0006648142007179558, Final Batch Loss: 0.0002315224555786699\n",
      "Epoch 937, Loss: 0.0011529706825967878, Final Batch Loss: 0.00017012233729474247\n",
      "Epoch 938, Loss: 0.001165132358437404, Final Batch Loss: 5.2250659791752696e-05\n",
      "Epoch 939, Loss: 0.002673969604074955, Final Batch Loss: 0.001058721449226141\n",
      "Epoch 940, Loss: 0.0035526530700735748, Final Batch Loss: 0.00015380344120785594\n",
      "Epoch 941, Loss: 0.0036311455332906917, Final Batch Loss: 0.003432073863223195\n",
      "Epoch 942, Loss: 0.006453871028497815, Final Batch Loss: 0.005163952708244324\n",
      "Epoch 943, Loss: 0.0003502085091895424, Final Batch Loss: 0.00028530924464575946\n",
      "Epoch 944, Loss: 0.0023641363659407943, Final Batch Loss: 0.00011977143003605306\n",
      "Epoch 945, Loss: 0.0026135633961530402, Final Batch Loss: 0.002461037365719676\n",
      "Epoch 946, Loss: 0.0033196600270457566, Final Batch Loss: 0.0009515639976598322\n",
      "Epoch 947, Loss: 0.002517394721508026, Final Batch Loss: 0.001067904639057815\n",
      "Epoch 948, Loss: 0.00033960113796638325, Final Batch Loss: 0.00022606489073950797\n",
      "Epoch 949, Loss: 0.0012381708656903356, Final Batch Loss: 0.0012047352502122521\n",
      "Epoch 950, Loss: 0.0018380341061856598, Final Batch Loss: 0.0016445904038846493\n",
      "Epoch 951, Loss: 0.00022320374409900978, Final Batch Loss: 4.669700138038024e-05\n",
      "Epoch 952, Loss: 0.00014041681242815685, Final Batch Loss: 2.5502200514893048e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953, Loss: 0.0026795999729074538, Final Batch Loss: 4.4599699322134256e-05\n",
      "Epoch 954, Loss: 0.0005238965095486492, Final Batch Loss: 0.0002351311268284917\n",
      "Epoch 955, Loss: 0.00027032001344196033, Final Batch Loss: 2.9687491405638866e-05\n",
      "Epoch 956, Loss: 0.0006408101071428973, Final Batch Loss: 0.0006046892958693206\n",
      "Epoch 957, Loss: 0.0015936842537485063, Final Batch Loss: 0.0002711668494157493\n",
      "Epoch 958, Loss: 0.00032919579098233953, Final Batch Loss: 0.00023328681709244847\n",
      "Epoch 959, Loss: 0.0016346668417099863, Final Batch Loss: 0.0002582230663392693\n",
      "Epoch 960, Loss: 0.0003260882731410675, Final Batch Loss: 0.00024427042808383703\n",
      "Epoch 961, Loss: 0.0034760444905259646, Final Batch Loss: 2.522915747249499e-05\n",
      "Epoch 962, Loss: 0.003347140795085579, Final Batch Loss: 0.0032936320640146732\n",
      "Epoch 963, Loss: 0.0001490246577304788, Final Batch Loss: 8.149624773068354e-05\n",
      "Epoch 964, Loss: 0.0018541236640885472, Final Batch Loss: 0.0006817984394729137\n",
      "Epoch 965, Loss: 0.0003937947294616606, Final Batch Loss: 0.00036901276325806975\n",
      "Epoch 966, Loss: 0.005538349039852619, Final Batch Loss: 0.005487164482474327\n",
      "Epoch 967, Loss: 0.0039715132443234324, Final Batch Loss: 0.002463866723701358\n",
      "Epoch 968, Loss: 0.0005582543280979735, Final Batch Loss: 1.480845548940124e-05\n",
      "Epoch 969, Loss: 7.352309330599383e-05, Final Batch Loss: 4.283037924324162e-05\n",
      "Epoch 970, Loss: 0.00015852063006605022, Final Batch Loss: 5.78905273869168e-05\n",
      "Epoch 971, Loss: 0.0021398391982074827, Final Batch Loss: 0.0002239889872726053\n",
      "Epoch 972, Loss: 0.00039389617450069636, Final Batch Loss: 0.00019401192548684776\n",
      "Epoch 973, Loss: 0.00017856587510323152, Final Batch Loss: 5.515400698641315e-05\n",
      "Epoch 974, Loss: 8.740827979636379e-05, Final Batch Loss: 4.9092184781329706e-05\n",
      "Epoch 975, Loss: 0.00021395891235442832, Final Batch Loss: 0.0001245765306521207\n",
      "Epoch 976, Loss: 0.00011849301154143177, Final Batch Loss: 4.158009323873557e-05\n",
      "Epoch 977, Loss: 0.00016063661769294413, Final Batch Loss: 1.3829664567310829e-05\n",
      "Epoch 978, Loss: 0.0009042249002959579, Final Batch Loss: 0.0006506080972030759\n",
      "Epoch 979, Loss: 0.001264932012418285, Final Batch Loss: 8.566715405322611e-05\n",
      "Epoch 980, Loss: 0.003693873863085173, Final Batch Loss: 0.003630179911851883\n",
      "Epoch 981, Loss: 0.0007418176101054996, Final Batch Loss: 0.00024634887813590467\n",
      "Epoch 982, Loss: 0.0015543383851763792, Final Batch Loss: 0.0015173944411799312\n",
      "Epoch 983, Loss: 0.0038587579620070755, Final Batch Loss: 0.00014936254592612386\n",
      "Epoch 984, Loss: 0.0023966788794496097, Final Batch Loss: 7.605748396599665e-05\n",
      "Epoch 985, Loss: 0.0001128435687860474, Final Batch Loss: 4.216357774566859e-05\n",
      "Epoch 986, Loss: 0.0013431684055831283, Final Batch Loss: 0.00038786439108662307\n",
      "Epoch 987, Loss: 0.009900536853820086, Final Batch Loss: 0.0012891204096376896\n",
      "Epoch 988, Loss: 0.00019613153563113883, Final Batch Loss: 9.995568689191714e-05\n",
      "Epoch 989, Loss: 0.0006960933387745172, Final Batch Loss: 0.0006286542629823089\n",
      "Epoch 990, Loss: 5.7734227084438317e-05, Final Batch Loss: 2.7734164177672938e-05\n",
      "Epoch 991, Loss: 0.016038216432207264, Final Batch Loss: 0.01601300574839115\n",
      "Epoch 992, Loss: 0.0027271826402284205, Final Batch Loss: 0.000497667642775923\n",
      "Epoch 993, Loss: 9.093460539588705e-05, Final Batch Loss: 5.685374344466254e-05\n",
      "Epoch 994, Loss: 0.0005610060907201841, Final Batch Loss: 0.00023761916963849217\n",
      "Epoch 995, Loss: 9.615584167477209e-05, Final Batch Loss: 1.8355285646975972e-05\n",
      "Epoch 996, Loss: 0.0005467238224809989, Final Batch Loss: 9.315994975622743e-05\n",
      "Epoch 997, Loss: 0.00015990898828022182, Final Batch Loss: 9.582384518580511e-05\n",
      "Epoch 998, Loss: 0.0002785130200209096, Final Batch Loss: 0.00016062153736129403\n",
      "Epoch 999, Loss: 0.0019618051883298904, Final Batch Loss: 0.0016266035381704569\n",
      "Epoch 1000, Loss: 0.00019064819571212865, Final Batch Loss: 4.009814074379392e-05\n",
      "Epoch 1001, Loss: 0.009053247746123816, Final Batch Loss: 0.009027046151459217\n",
      "Epoch 1002, Loss: 0.0025159181241178885, Final Batch Loss: 0.00016329532081726938\n",
      "Epoch 1003, Loss: 0.00015492002057726495, Final Batch Loss: 0.0001157087754108943\n",
      "Epoch 1004, Loss: 0.009238427999662235, Final Batch Loss: 0.008926164358854294\n",
      "Epoch 1005, Loss: 0.0012459777790354565, Final Batch Loss: 0.00013623219274450094\n",
      "Epoch 1006, Loss: 0.00029240353069326375, Final Batch Loss: 2.7155178031534888e-05\n",
      "Epoch 1007, Loss: 0.00479519137297757, Final Batch Loss: 0.004661869257688522\n",
      "Epoch 1008, Loss: 0.000252608755545225, Final Batch Loss: 7.62914351071231e-05\n",
      "Epoch 1009, Loss: 0.0011917032461497001, Final Batch Loss: 5.797843186883256e-05\n",
      "Epoch 1010, Loss: 0.0009728950080898358, Final Batch Loss: 1.5979107047314756e-05\n",
      "Epoch 1011, Loss: 0.0010626939474605024, Final Batch Loss: 0.00034084502840414643\n",
      "Epoch 1012, Loss: 0.004236764594679698, Final Batch Loss: 0.0041496651247143745\n",
      "Epoch 1013, Loss: 0.0012715046759694815, Final Batch Loss: 0.00024040776770561934\n",
      "Epoch 1014, Loss: 0.0002214546111645177, Final Batch Loss: 0.00014231351087801158\n",
      "Epoch 1015, Loss: 0.00023803172007319517, Final Batch Loss: 0.0001772364048520103\n",
      "Epoch 1016, Loss: 0.00019178873117198236, Final Batch Loss: 4.82819632452447e-05\n",
      "Epoch 1017, Loss: 0.0003485647393972613, Final Batch Loss: 3.665398253360763e-05\n",
      "Epoch 1018, Loss: 0.005416744388639927, Final Batch Loss: 0.0033214304130524397\n",
      "Epoch 1019, Loss: 0.0005594345066128881, Final Batch Loss: 1.5051316040626261e-05\n",
      "Epoch 1020, Loss: 0.00031013903208076954, Final Batch Loss: 8.162445737980306e-05\n",
      "Epoch 1021, Loss: 0.00040026580245466903, Final Batch Loss: 6.343727727653459e-05\n",
      "Epoch 1022, Loss: 0.004308929688704666, Final Batch Loss: 7.664461008971557e-05\n",
      "Epoch 1023, Loss: 0.00023260359375854023, Final Batch Loss: 5.061304909759201e-05\n",
      "Epoch 1024, Loss: 0.0014482236001640558, Final Batch Loss: 0.0005108931218273938\n",
      "Epoch 1025, Loss: 0.0025550558311806526, Final Batch Loss: 4.704185630544089e-05\n",
      "Epoch 1026, Loss: 0.00022187035210663453, Final Batch Loss: 0.00017519031825941056\n",
      "Epoch 1027, Loss: 0.0007640297408215702, Final Batch Loss: 0.0004926034016534686\n",
      "Epoch 1028, Loss: 0.0008668657101225108, Final Batch Loss: 0.00011194354738108814\n",
      "Epoch 1029, Loss: 0.0007870238041505218, Final Batch Loss: 0.000560844549909234\n",
      "Epoch 1030, Loss: 0.002495621251000557, Final Batch Loss: 5.4656680731568485e-05\n",
      "Epoch 1031, Loss: 0.00039191454561660066, Final Batch Loss: 0.00029161240672692657\n",
      "Epoch 1032, Loss: 0.00015251172226271592, Final Batch Loss: 0.00011259234452154487\n",
      "Epoch 1033, Loss: 0.0025964129745261744, Final Batch Loss: 0.002397711155936122\n",
      "Epoch 1034, Loss: 0.0001593546912772581, Final Batch Loss: 6.230215512914583e-05\n",
      "Epoch 1035, Loss: 0.0019186729878128972, Final Batch Loss: 5.128600969328545e-05\n",
      "Epoch 1036, Loss: 0.00023961905753822066, Final Batch Loss: 0.00020258332369849086\n",
      "Epoch 1037, Loss: 0.0029920247616246343, Final Batch Loss: 0.0009045918704941869\n",
      "Epoch 1038, Loss: 0.007964734293636866, Final Batch Loss: 0.007906615734100342\n",
      "Epoch 1039, Loss: 0.0007486953400075436, Final Batch Loss: 0.0006690495065413415\n",
      "Epoch 1040, Loss: 0.00845427275635302, Final Batch Loss: 0.0032711911480873823\n",
      "Epoch 1041, Loss: 0.0003449040414125193, Final Batch Loss: 3.6703528166981414e-05\n",
      "Epoch 1042, Loss: 0.0018894526874646544, Final Batch Loss: 0.0013737523695454001\n",
      "Epoch 1043, Loss: 0.00022492030620924197, Final Batch Loss: 0.00017845463298726827\n",
      "Epoch 1044, Loss: 0.00022020662800059654, Final Batch Loss: 3.150783959426917e-05\n",
      "Epoch 1045, Loss: 0.0017148214974440634, Final Batch Loss: 0.00030146160861477256\n",
      "Epoch 1046, Loss: 6.463047611759976e-05, Final Batch Loss: 4.304003232391551e-05\n",
      "Epoch 1047, Loss: 0.0012360616601654328, Final Batch Loss: 6.41878941678442e-05\n",
      "Epoch 1048, Loss: 9.78680000116583e-05, Final Batch Loss: 5.6941338698379695e-05\n",
      "Epoch 1049, Loss: 0.004288903146516532, Final Batch Loss: 0.0002429952728562057\n",
      "Epoch 1050, Loss: 0.0005192871612962335, Final Batch Loss: 7.714092498645186e-05\n",
      "Epoch 1051, Loss: 0.00017706944527162705, Final Batch Loss: 1.991165663639549e-05\n",
      "Epoch 1052, Loss: 0.0029260490118758753, Final Batch Loss: 0.0028838585130870342\n",
      "Epoch 1053, Loss: 0.001695983504760079, Final Batch Loss: 0.00011098819959443063\n",
      "Epoch 1054, Loss: 0.0001990199161809869, Final Batch Loss: 0.00010797700088005513\n",
      "Epoch 1055, Loss: 0.0007163238769862801, Final Batch Loss: 0.0005360270733945072\n",
      "Epoch 1056, Loss: 0.003509828820824623, Final Batch Loss: 0.00017312541604042053\n",
      "Epoch 1057, Loss: 0.00037683012487832457, Final Batch Loss: 0.00029392604483291507\n",
      "Epoch 1058, Loss: 0.00032563853164901957, Final Batch Loss: 6.183180812513456e-05\n",
      "Epoch 1059, Loss: 8.128138324536849e-05, Final Batch Loss: 1.5276180420187302e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1060, Loss: 0.00038777923327870667, Final Batch Loss: 0.00023883424000814557\n",
      "Epoch 1061, Loss: 0.00039723680674796924, Final Batch Loss: 7.870714034652337e-05\n",
      "Epoch 1062, Loss: 0.0008790293795755133, Final Batch Loss: 9.989032696466893e-05\n",
      "Epoch 1063, Loss: 0.002484581527824048, Final Batch Loss: 0.0001210517730214633\n",
      "Epoch 1064, Loss: 0.002986475818033796, Final Batch Loss: 0.00289108045399189\n",
      "Epoch 1065, Loss: 0.00034121649514418095, Final Batch Loss: 0.00025608279975131154\n",
      "Epoch 1066, Loss: 0.0040048919909168035, Final Batch Loss: 0.0038583925925195217\n",
      "Epoch 1067, Loss: 0.00037563664227491245, Final Batch Loss: 0.0003287246508989483\n",
      "Epoch 1068, Loss: 0.0002268195621581981, Final Batch Loss: 0.0002164074103347957\n",
      "Epoch 1069, Loss: 0.000558715924853459, Final Batch Loss: 0.0001455618184991181\n",
      "Epoch 1070, Loss: 0.00021404895960586146, Final Batch Loss: 2.289481199113652e-05\n",
      "Epoch 1071, Loss: 0.0013056818424956873, Final Batch Loss: 0.00022562041704077274\n",
      "Epoch 1072, Loss: 0.009623245961847715, Final Batch Loss: 6.902839231770486e-05\n",
      "Epoch 1073, Loss: 0.0013914111186750233, Final Batch Loss: 0.00028166320407763124\n",
      "Epoch 1074, Loss: 0.00032138932147063315, Final Batch Loss: 0.00017492938786745071\n",
      "Epoch 1075, Loss: 0.0011742959541152231, Final Batch Loss: 9.878008131636307e-05\n",
      "Epoch 1076, Loss: 0.000501215661643073, Final Batch Loss: 0.0003343154676258564\n",
      "Epoch 1077, Loss: 0.00032704302975616883, Final Batch Loss: 0.00029972995980642736\n",
      "Epoch 1078, Loss: 0.0027532164531294256, Final Batch Loss: 0.0003213380987290293\n",
      "Epoch 1079, Loss: 0.0006356193207466276, Final Batch Loss: 2.158641473215539e-05\n",
      "Epoch 1080, Loss: 0.0001867917162599042, Final Batch Loss: 3.711036697495729e-05\n",
      "Epoch 1081, Loss: 0.0075815484742634, Final Batch Loss: 0.007548635825514793\n",
      "Epoch 1082, Loss: 0.00018991088290931657, Final Batch Loss: 0.00010469075641594827\n",
      "Epoch 1083, Loss: 0.0005068380123702809, Final Batch Loss: 0.000147546743392013\n",
      "Epoch 1084, Loss: 0.0009747803214850137, Final Batch Loss: 0.000951344904024154\n",
      "Epoch 1085, Loss: 0.0002126718100043945, Final Batch Loss: 0.00014899051166139543\n",
      "Epoch 1086, Loss: 0.0017924255735124461, Final Batch Loss: 6.38765559415333e-05\n",
      "Epoch 1087, Loss: 0.00012405544566718163, Final Batch Loss: 1.2527631952252705e-05\n",
      "Epoch 1088, Loss: 0.0002969924680655822, Final Batch Loss: 0.00014249805826693773\n",
      "Epoch 1089, Loss: 0.0007507347327191383, Final Batch Loss: 0.0002959469857160002\n",
      "Epoch 1090, Loss: 0.0005913794084335677, Final Batch Loss: 0.0005336498143151402\n",
      "Epoch 1091, Loss: 0.000768242243793793, Final Batch Loss: 0.00016977069026324898\n",
      "Epoch 1092, Loss: 0.005209589158766903, Final Batch Loss: 0.005097690038383007\n",
      "Epoch 1093, Loss: 0.001987873634789139, Final Batch Loss: 0.0012592317070811987\n",
      "Epoch 1094, Loss: 0.001689566022832878, Final Batch Loss: 0.001616966095753014\n",
      "Epoch 1095, Loss: 0.0003313984489068389, Final Batch Loss: 0.0002935914963018149\n",
      "Epoch 1096, Loss: 0.004326412465161411, Final Batch Loss: 3.4789100027410313e-05\n",
      "Epoch 1097, Loss: 0.004823447787202895, Final Batch Loss: 0.003582573728635907\n",
      "Epoch 1098, Loss: 0.000916710210731253, Final Batch Loss: 0.00023837914341129363\n",
      "Epoch 1099, Loss: 8.529968727088999e-05, Final Batch Loss: 6.816573295509443e-05\n",
      "Epoch 1100, Loss: 8.423365579801612e-05, Final Batch Loss: 2.3561013222206384e-05\n",
      "Epoch 1101, Loss: 0.0005917732341913506, Final Batch Loss: 0.00048241563490591943\n",
      "Epoch 1102, Loss: 0.002092974692459393, Final Batch Loss: 1.160261581389932e-05\n",
      "Epoch 1103, Loss: 0.0024869695771485567, Final Batch Loss: 0.001204811967909336\n",
      "Epoch 1104, Loss: 0.00011484064452815801, Final Batch Loss: 6.406613829312846e-05\n",
      "Epoch 1105, Loss: 8.141634680214338e-05, Final Batch Loss: 3.15036995743867e-05\n",
      "Epoch 1106, Loss: 0.0005396573615144007, Final Batch Loss: 6.677066994598135e-05\n",
      "Epoch 1107, Loss: 0.00040577400068286806, Final Batch Loss: 0.00015670213906560093\n",
      "Epoch 1108, Loss: 0.00029583978539449163, Final Batch Loss: 0.00025690029724501073\n",
      "Epoch 1109, Loss: 0.0002818022621795535, Final Batch Loss: 0.0002472203050274402\n",
      "Epoch 1110, Loss: 0.00030038002296350896, Final Batch Loss: 0.00017579020641278476\n",
      "Epoch 1111, Loss: 0.00160181091632694, Final Batch Loss: 0.00034378119744360447\n",
      "Epoch 1112, Loss: 0.0013829844101564959, Final Batch Loss: 0.00019375579722691327\n",
      "Epoch 1113, Loss: 0.006970901496970328, Final Batch Loss: 0.006924615707248449\n",
      "Epoch 1114, Loss: 0.0020038614165969193, Final Batch Loss: 0.0015114285051822662\n",
      "Epoch 1115, Loss: 0.0008808912461972795, Final Batch Loss: 0.0007841206388548017\n",
      "Epoch 1116, Loss: 0.0006940416351426393, Final Batch Loss: 0.00038744029006920755\n",
      "Epoch 1117, Loss: 0.0057063798303715885, Final Batch Loss: 0.005152582656592131\n",
      "Epoch 1118, Loss: 0.00022572757370653562, Final Batch Loss: 0.0002000441454583779\n",
      "Epoch 1119, Loss: 0.0030113455541140866, Final Batch Loss: 4.150245149503462e-05\n",
      "Epoch 1120, Loss: 0.0002293328543601092, Final Batch Loss: 0.00019383500330150127\n",
      "Epoch 1121, Loss: 0.00010502540317247622, Final Batch Loss: 3.930538150598295e-05\n",
      "Epoch 1122, Loss: 0.002137145238521043, Final Batch Loss: 3.2049814763013273e-05\n",
      "Epoch 1123, Loss: 0.0007004166327533312, Final Batch Loss: 8.123496809275821e-05\n",
      "Epoch 1124, Loss: 0.0008603542810305953, Final Batch Loss: 0.00023787020472809672\n",
      "Epoch 1125, Loss: 0.00017152232248918153, Final Batch Loss: 4.4208882172824815e-05\n",
      "Epoch 1126, Loss: 0.00014093346180743538, Final Batch Loss: 9.33689734665677e-05\n",
      "Epoch 1127, Loss: 0.00025463688871241175, Final Batch Loss: 0.0002005052665481344\n",
      "Epoch 1128, Loss: 0.0008116987009998411, Final Batch Loss: 0.000507751596160233\n",
      "Epoch 1129, Loss: 0.00019464940851321444, Final Batch Loss: 9.007329208543524e-05\n",
      "Epoch 1130, Loss: 0.0012638290791073814, Final Batch Loss: 0.00013600617239717394\n",
      "Epoch 1131, Loss: 8.676977813593112e-05, Final Batch Loss: 7.089912105584517e-05\n",
      "Epoch 1132, Loss: 0.0011520523912622593, Final Batch Loss: 0.0010959868086501956\n",
      "Epoch 1133, Loss: 0.00449191529332893, Final Batch Loss: 0.00011714903666870669\n",
      "Epoch 1134, Loss: 0.0003313819470349699, Final Batch Loss: 0.00012876234541181475\n",
      "Epoch 1135, Loss: 0.000374348703189753, Final Batch Loss: 0.00024583074264228344\n",
      "Epoch 1136, Loss: 0.00015106327191460878, Final Batch Loss: 6.530710379593074e-05\n",
      "Epoch 1137, Loss: 0.00042981727892765775, Final Batch Loss: 0.00035031576408073306\n",
      "Epoch 1138, Loss: 0.002680573692487087, Final Batch Loss: 3.06915826513432e-05\n",
      "Epoch 1139, Loss: 0.00023633279488421977, Final Batch Loss: 9.570604015607387e-05\n",
      "Epoch 1140, Loss: 0.0020023846009280533, Final Batch Loss: 0.0015251539880409837\n",
      "Epoch 1141, Loss: 0.00010701554856495932, Final Batch Loss: 5.969710764475167e-05\n",
      "Epoch 1142, Loss: 0.00036779132278752513, Final Batch Loss: 0.00031023850897327065\n",
      "Epoch 1143, Loss: 0.0045438287779688835, Final Batch Loss: 0.00010043196380138397\n",
      "Epoch 1144, Loss: 0.0038472232581625576, Final Batch Loss: 0.0038360124453902245\n",
      "Epoch 1145, Loss: 0.003372853505425155, Final Batch Loss: 0.0021172601263970137\n",
      "Epoch 1146, Loss: 8.37671359477099e-05, Final Batch Loss: 4.9481579480925575e-05\n",
      "Epoch 1147, Loss: 0.0006983347593632061, Final Batch Loss: 4.3793745135189965e-05\n",
      "Epoch 1148, Loss: 0.00013015085278311744, Final Batch Loss: 7.801787432981655e-05\n",
      "Epoch 1149, Loss: 0.0017555028898641467, Final Batch Loss: 0.0003659958019852638\n",
      "Epoch 1150, Loss: 0.0021720282966271043, Final Batch Loss: 0.0015179908368736506\n",
      "Epoch 1151, Loss: 0.0005675471111317165, Final Batch Loss: 0.00046249397564679384\n",
      "Epoch 1152, Loss: 5.7251559155702125e-05, Final Batch Loss: 4.373631963972002e-05\n",
      "Epoch 1153, Loss: 0.004910481482511386, Final Batch Loss: 0.004618524573743343\n",
      "Epoch 1154, Loss: 0.00018321243987884372, Final Batch Loss: 6.077977013774216e-05\n",
      "Epoch 1155, Loss: 0.00299339386401698, Final Batch Loss: 0.0008086421876214445\n",
      "Epoch 1156, Loss: 3.9235416352312313e-05, Final Batch Loss: 7.512332103942754e-06\n",
      "Epoch 1157, Loss: 0.0012816396047128364, Final Batch Loss: 0.00021977249707560986\n",
      "Epoch 1158, Loss: 0.00012448384950403124, Final Batch Loss: 0.00010175402712775394\n",
      "Epoch 1159, Loss: 0.0009661367221269757, Final Batch Loss: 0.00013544471585191786\n",
      "Epoch 1160, Loss: 0.0028664858364209067, Final Batch Loss: 4.622967026080005e-05\n",
      "Epoch 1161, Loss: 0.00010914279664575588, Final Batch Loss: 2.02490027731983e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1162, Loss: 0.0003319419774925336, Final Batch Loss: 0.0002905086148530245\n",
      "Epoch 1163, Loss: 0.0003850156062981114, Final Batch Loss: 3.7645266274921596e-05\n",
      "Epoch 1164, Loss: 0.0002458828530507162, Final Batch Loss: 7.764610927551985e-05\n",
      "Epoch 1165, Loss: 0.0024396862390858587, Final Batch Loss: 0.002405397593975067\n",
      "Epoch 1166, Loss: 0.00010169772031076718, Final Batch Loss: 3.0172663173289038e-05\n",
      "Epoch 1167, Loss: 0.00013910236157244071, Final Batch Loss: 6.69447545078583e-05\n",
      "Epoch 1168, Loss: 0.0035157615347998217, Final Batch Loss: 0.0033896644599735737\n",
      "Epoch 1169, Loss: 0.00011950314365094528, Final Batch Loss: 0.00010027366079157218\n",
      "Epoch 1170, Loss: 0.0006236197368707508, Final Batch Loss: 0.0003179479972459376\n",
      "Epoch 1171, Loss: 0.00034520924964454025, Final Batch Loss: 0.0001904733362607658\n",
      "Epoch 1172, Loss: 9.234382741851732e-05, Final Batch Loss: 6.620251224376261e-05\n",
      "Epoch 1173, Loss: 4.6793911678832956e-05, Final Batch Loss: 1.8010066924034618e-05\n",
      "Epoch 1174, Loss: 0.000615870434558019, Final Batch Loss: 0.0005541552091017365\n",
      "Epoch 1175, Loss: 0.01536431408021599, Final Batch Loss: 0.014281999319791794\n",
      "Epoch 1176, Loss: 0.00011739573528757319, Final Batch Loss: 5.006307765142992e-05\n",
      "Epoch 1177, Loss: 0.00013856618534191512, Final Batch Loss: 0.00010187760199187323\n",
      "Epoch 1178, Loss: 0.0010019071924034506, Final Batch Loss: 6.738063530065119e-05\n",
      "Epoch 1179, Loss: 3.195026488356234e-05, Final Batch Loss: 3.5731807201955235e-06\n",
      "Epoch 1180, Loss: 0.000780418653448578, Final Batch Loss: 0.0007001422927714884\n",
      "Epoch 1181, Loss: 0.00010182855112361722, Final Batch Loss: 3.0118262657197192e-05\n",
      "Epoch 1182, Loss: 2.775715256575495e-05, Final Batch Loss: 1.573316694702953e-05\n",
      "Epoch 1183, Loss: 0.0018849791267712135, Final Batch Loss: 5.606345439446159e-05\n",
      "Epoch 1184, Loss: 0.00021258245760691352, Final Batch Loss: 0.0001649845507927239\n",
      "Epoch 1185, Loss: 0.0023207056510727853, Final Batch Loss: 0.00038881038199178874\n",
      "Epoch 1186, Loss: 0.0004692196125688497, Final Batch Loss: 5.485810470418073e-05\n",
      "Epoch 1187, Loss: 0.0037476211437024176, Final Batch Loss: 0.0032862492371350527\n",
      "Epoch 1188, Loss: 7.563510553154629e-05, Final Batch Loss: 2.3665046683163382e-05\n",
      "Epoch 1189, Loss: 0.00035848722109221853, Final Batch Loss: 0.0002985193277709186\n",
      "Epoch 1190, Loss: 0.0004213637512293644, Final Batch Loss: 0.00034412796958349645\n",
      "Epoch 1191, Loss: 0.0015677439769206103, Final Batch Loss: 0.0015488432254642248\n",
      "Epoch 1192, Loss: 0.0008025365023058839, Final Batch Loss: 0.0006990625406615436\n",
      "Epoch 1193, Loss: 0.00015244807582348585, Final Batch Loss: 9.332370245829225e-05\n",
      "Epoch 1194, Loss: 0.0047838933824095875, Final Batch Loss: 0.004458922892808914\n",
      "Epoch 1195, Loss: 0.0020016572198073845, Final Batch Loss: 4.542998431134038e-05\n",
      "Epoch 1196, Loss: 7.133760300348513e-05, Final Batch Loss: 4.577627623802982e-05\n",
      "Epoch 1197, Loss: 0.0019999401993118227, Final Batch Loss: 0.0015622269129380584\n",
      "Epoch 1198, Loss: 0.0050637503154575825, Final Batch Loss: 0.0038444260135293007\n",
      "Epoch 1199, Loss: 0.0010608963511913316, Final Batch Loss: 0.0010376863647252321\n",
      "Epoch 1200, Loss: 0.0016267393402813468, Final Batch Loss: 0.0015897095436230302\n",
      "Epoch 1201, Loss: 2.8854163247160614e-05, Final Batch Loss: 1.2665110261877999e-05\n",
      "Epoch 1202, Loss: 0.0028614992916118354, Final Batch Loss: 0.002844366244971752\n",
      "Epoch 1203, Loss: 8.36671497381758e-05, Final Batch Loss: 1.6051028069341555e-05\n",
      "Epoch 1204, Loss: 0.001070132668246515, Final Batch Loss: 0.00012857526598963886\n",
      "Epoch 1205, Loss: 0.00019089585839537904, Final Batch Loss: 0.00010278011905029416\n",
      "Epoch 1206, Loss: 0.003517344084684737, Final Batch Loss: 0.0032866986002773046\n",
      "Epoch 1207, Loss: 0.0006953412957955152, Final Batch Loss: 0.0003420385764911771\n",
      "Epoch 1208, Loss: 0.004467556544113904, Final Batch Loss: 0.0035190507769584656\n",
      "Epoch 1209, Loss: 3.872384149872232e-05, Final Batch Loss: 1.669704943196848e-05\n",
      "Epoch 1210, Loss: 0.00017275745267397724, Final Batch Loss: 0.00014780806668568403\n",
      "Epoch 1211, Loss: 4.889526098850183e-05, Final Batch Loss: 2.4240500351879746e-05\n",
      "Epoch 1212, Loss: 0.01981519402761478, Final Batch Loss: 0.019652368500828743\n",
      "Epoch 1213, Loss: 0.000815786283055786, Final Batch Loss: 3.281076351413503e-05\n",
      "Epoch 1214, Loss: 0.00337173804291524, Final Batch Loss: 0.00038384474464692175\n",
      "Epoch 1215, Loss: 0.0001891541933218832, Final Batch Loss: 7.97953089204384e-06\n",
      "Epoch 1216, Loss: 0.0007625828729942441, Final Batch Loss: 0.0005116657121106982\n",
      "Epoch 1217, Loss: 0.00017477011351729743, Final Batch Loss: 1.7458482034271583e-05\n",
      "Epoch 1218, Loss: 0.0012081620516255498, Final Batch Loss: 7.30130122974515e-05\n",
      "Epoch 1219, Loss: 1.0911229537668987e-05, Final Batch Loss: 2.498231651770766e-06\n",
      "Epoch 1220, Loss: 0.00032157667010324076, Final Batch Loss: 5.3138712246436626e-05\n",
      "Epoch 1221, Loss: 6.390175940396148e-05, Final Batch Loss: 6.150137323857052e-06\n",
      "Epoch 1222, Loss: 2.360438884352334e-05, Final Batch Loss: 1.313622033194406e-05\n",
      "Epoch 1223, Loss: 6.674953965557506e-05, Final Batch Loss: 1.1106060810561758e-05\n",
      "Epoch 1224, Loss: 8.879964298103005e-05, Final Batch Loss: 4.438869655132294e-05\n",
      "Epoch 1225, Loss: 8.742728459765203e-05, Final Batch Loss: 5.5816428357502446e-05\n",
      "Epoch 1226, Loss: 0.00011168442506459542, Final Batch Loss: 7.595299393869936e-05\n",
      "Epoch 1227, Loss: 0.0010508618215681054, Final Batch Loss: 4.213598003843799e-05\n",
      "Epoch 1228, Loss: 0.0007042144388833549, Final Batch Loss: 0.0006715229246765375\n",
      "Epoch 1229, Loss: 0.00014047769582248293, Final Batch Loss: 9.044666512636468e-06\n",
      "Epoch 1230, Loss: 0.0020837710835621692, Final Batch Loss: 6.166907405713573e-05\n",
      "Epoch 1231, Loss: 2.209577723988332e-05, Final Batch Loss: 1.0273715815856121e-05\n",
      "Epoch 1232, Loss: 0.000277879873465281, Final Batch Loss: 0.00010968324932036921\n",
      "Epoch 1233, Loss: 0.007141430316551123, Final Batch Loss: 0.007065487094223499\n",
      "Epoch 1234, Loss: 0.00048116210018633865, Final Batch Loss: 3.940667011193e-05\n",
      "Epoch 1235, Loss: 0.0001053475552907912, Final Batch Loss: 7.294829629245214e-06\n",
      "Epoch 1236, Loss: 9.14355150598567e-05, Final Batch Loss: 2.2870812244946137e-05\n",
      "Epoch 1237, Loss: 0.0001831523040891625, Final Batch Loss: 1.8189144611824304e-05\n",
      "Epoch 1238, Loss: 0.0005231453324086033, Final Batch Loss: 8.003270340850577e-05\n",
      "Epoch 1239, Loss: 0.0001641810558794532, Final Batch Loss: 0.00013794886763207614\n",
      "Epoch 1240, Loss: 7.705856478423811e-05, Final Batch Loss: 4.114957482670434e-05\n",
      "Epoch 1241, Loss: 0.00012738271470880136, Final Batch Loss: 8.998747216537595e-05\n",
      "Epoch 1242, Loss: 0.001697972265901626, Final Batch Loss: 1.5653751688660122e-05\n",
      "Epoch 1243, Loss: 0.00030208658972696867, Final Batch Loss: 2.7776555725722574e-05\n",
      "Epoch 1244, Loss: 4.693007076639333e-05, Final Batch Loss: 4.0547332901041955e-05\n",
      "Epoch 1245, Loss: 0.00014117936370894313, Final Batch Loss: 7.915990136098117e-05\n",
      "Epoch 1246, Loss: 0.00011572441326279659, Final Batch Loss: 9.965581557480618e-05\n",
      "Epoch 1247, Loss: 0.0015659553464502096, Final Batch Loss: 0.00023553625214844942\n",
      "Epoch 1248, Loss: 0.0018664988747332245, Final Batch Loss: 0.00020816296455450356\n",
      "Epoch 1249, Loss: 0.0018049408135993872, Final Batch Loss: 2.1327814465621486e-05\n",
      "Epoch 1250, Loss: 5.775579575129086e-05, Final Batch Loss: 1.4633843420597259e-05\n",
      "Epoch 1251, Loss: 0.00013902071623306256, Final Batch Loss: 0.00012275569315534085\n",
      "Epoch 1252, Loss: 0.0012964013494638493, Final Batch Loss: 1.5001720385043882e-05\n",
      "Epoch 1253, Loss: 0.001735297148115933, Final Batch Loss: 0.0008158117416314781\n",
      "Epoch 1254, Loss: 4.248170989740174e-05, Final Batch Loss: 2.9410794013529085e-05\n",
      "Epoch 1255, Loss: 0.00017426722479285672, Final Batch Loss: 5.7488046877551824e-05\n",
      "Epoch 1256, Loss: 0.004426523548318073, Final Batch Loss: 0.004274202510714531\n",
      "Epoch 1257, Loss: 7.033654401311651e-05, Final Batch Loss: 2.9834194720024243e-05\n",
      "Epoch 1258, Loss: 0.0001597459049662575, Final Batch Loss: 9.32467301026918e-05\n",
      "Epoch 1259, Loss: 0.00013679960102308542, Final Batch Loss: 1.5568584785796702e-05\n",
      "Epoch 1260, Loss: 0.0006010536035319092, Final Batch Loss: 0.0005766695830971003\n",
      "Epoch 1261, Loss: 0.0002541330104577355, Final Batch Loss: 3.5610726627055556e-05\n",
      "Epoch 1262, Loss: 0.0018229865454486571, Final Batch Loss: 9.830985072767362e-05\n",
      "Epoch 1263, Loss: 0.0006224727112567052, Final Batch Loss: 0.0003831039066426456\n",
      "Epoch 1264, Loss: 0.0009715771029732423, Final Batch Loss: 8.685254215379246e-06\n",
      "Epoch 1265, Loss: 0.0031739501464471687, Final Batch Loss: 0.0031591409351676702\n",
      "Epoch 1266, Loss: 7.812897092662752e-05, Final Batch Loss: 6.517940346384421e-05\n",
      "Epoch 1267, Loss: 0.003670949110528454, Final Batch Loss: 0.003396967425942421\n",
      "Epoch 1268, Loss: 3.011388480445021e-05, Final Batch Loss: 2.2704729417455383e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1269, Loss: 0.00010837545778485946, Final Batch Loss: 8.877224172465503e-05\n",
      "Epoch 1270, Loss: 0.0027331938326824456, Final Batch Loss: 0.002418419811874628\n",
      "Epoch 1271, Loss: 0.004013418947579339, Final Batch Loss: 0.0039520105347037315\n",
      "Epoch 1272, Loss: 0.0007198987586889416, Final Batch Loss: 0.0006787398015148938\n",
      "Epoch 1273, Loss: 7.735808935649402e-05, Final Batch Loss: 7.543407991761342e-05\n",
      "Epoch 1274, Loss: 0.0002035481811617501, Final Batch Loss: 9.032302477862686e-05\n",
      "Epoch 1275, Loss: 0.00019348309524502838, Final Batch Loss: 0.00018261831428389996\n",
      "Epoch 1276, Loss: 0.00010542545351199806, Final Batch Loss: 7.725536124780774e-05\n",
      "Epoch 1277, Loss: 0.00011219659609196242, Final Batch Loss: 8.539926784578711e-05\n",
      "Epoch 1278, Loss: 0.00021964779989502858, Final Batch Loss: 0.00020293945271987468\n",
      "Epoch 1279, Loss: 6.304738599283155e-05, Final Batch Loss: 1.0141489838133566e-05\n",
      "Epoch 1280, Loss: 0.00044054626778233796, Final Batch Loss: 0.0001240692363353446\n",
      "Epoch 1281, Loss: 0.00013474744628183544, Final Batch Loss: 6.742536788806319e-05\n",
      "Epoch 1282, Loss: 0.00024225326978921657, Final Batch Loss: 8.198795512726065e-06\n",
      "Epoch 1283, Loss: 7.707211261731572e-05, Final Batch Loss: 3.298271258245222e-05\n",
      "Epoch 1284, Loss: 0.0002201241259172093, Final Batch Loss: 0.00017983971338253468\n",
      "Epoch 1285, Loss: 0.00030602312290284317, Final Batch Loss: 0.00029647667543031275\n",
      "Epoch 1286, Loss: 0.0004941339502693154, Final Batch Loss: 0.0003750888572540134\n",
      "Epoch 1287, Loss: 0.00011725136209861375, Final Batch Loss: 4.7675890527898446e-05\n",
      "Epoch 1288, Loss: 0.00023783039796398953, Final Batch Loss: 8.974332740763202e-05\n",
      "Epoch 1289, Loss: 0.00029887443815823644, Final Batch Loss: 5.029122985433787e-05\n",
      "Epoch 1290, Loss: 0.0004117609150853241, Final Batch Loss: 1.7240769011550583e-05\n",
      "Epoch 1291, Loss: 0.000266171100520296, Final Batch Loss: 0.0002482363488525152\n",
      "Epoch 1292, Loss: 0.0004505287070060149, Final Batch Loss: 0.0002043048880295828\n",
      "Epoch 1293, Loss: 8.141562193486607e-05, Final Batch Loss: 7.713876402704045e-05\n",
      "Epoch 1294, Loss: 0.0005337713882909156, Final Batch Loss: 9.83498539426364e-05\n",
      "Epoch 1295, Loss: 0.00010997012759617064, Final Batch Loss: 2.4181064873118885e-05\n",
      "Epoch 1296, Loss: 0.0024970870417746482, Final Batch Loss: 2.251266960229259e-05\n",
      "Epoch 1297, Loss: 0.0009270472257867368, Final Batch Loss: 0.0009234406752511859\n",
      "Epoch 1298, Loss: 0.00011758871369238477, Final Batch Loss: 9.710639278637245e-05\n",
      "Epoch 1299, Loss: 0.0031863522017374635, Final Batch Loss: 0.00027746299747377634\n",
      "Epoch 1300, Loss: 0.00047015455493237823, Final Batch Loss: 0.0002674944989848882\n",
      "Epoch 1301, Loss: 2.342121661058627e-05, Final Batch Loss: 1.5436489775311202e-05\n",
      "Epoch 1302, Loss: 0.002921937411883846, Final Batch Loss: 0.0027729703579097986\n",
      "Epoch 1303, Loss: 1.785311815183377e-05, Final Batch Loss: 1.0131232556886971e-05\n",
      "Epoch 1304, Loss: 0.0007884289516368881, Final Batch Loss: 0.00022201555839274079\n",
      "Epoch 1305, Loss: 0.0005508136964635924, Final Batch Loss: 0.0004225445445626974\n",
      "Epoch 1306, Loss: 0.015724996337667108, Final Batch Loss: 0.0015310423914343119\n",
      "Epoch 1307, Loss: 0.01196899359638337, Final Batch Loss: 0.011819782666862011\n",
      "Epoch 1308, Loss: 0.00017062419283320196, Final Batch Loss: 0.00010984826076310128\n",
      "Epoch 1309, Loss: 0.0006638027261942625, Final Batch Loss: 0.00012274918844923377\n",
      "Epoch 1310, Loss: 0.003540735866408795, Final Batch Loss: 0.0032360029872506857\n",
      "Epoch 1311, Loss: 0.009974797503673472, Final Batch Loss: 0.0001713012024993077\n",
      "Epoch 1312, Loss: 0.00017294668941758573, Final Batch Loss: 7.639628165634349e-05\n",
      "Epoch 1313, Loss: 0.0001843210484366864, Final Batch Loss: 9.860892896540463e-05\n",
      "Epoch 1314, Loss: 0.002458176328218542, Final Batch Loss: 0.002353953430429101\n",
      "Epoch 1315, Loss: 0.0006228830898180604, Final Batch Loss: 0.0005615038680844009\n",
      "Epoch 1316, Loss: 0.0006310833159659524, Final Batch Loss: 0.0005908887833356857\n",
      "Epoch 1317, Loss: 0.0038581127300858498, Final Batch Loss: 0.0004928379785269499\n",
      "Epoch 1318, Loss: 0.00011945041114813648, Final Batch Loss: 7.274933159351349e-05\n",
      "Epoch 1319, Loss: 0.0005472085613291711, Final Batch Loss: 0.00016183452680706978\n",
      "Epoch 1320, Loss: 0.0002429174492135644, Final Batch Loss: 0.0001587698352523148\n",
      "Epoch 1321, Loss: 0.00014053577797312755, Final Batch Loss: 0.00012170593981863931\n",
      "Epoch 1322, Loss: 0.0015340100799221545, Final Batch Loss: 0.00032290947274304926\n",
      "Epoch 1323, Loss: 0.0004984974511899054, Final Batch Loss: 0.0001479089551139623\n",
      "Epoch 1324, Loss: 0.0009394256048835814, Final Batch Loss: 0.0005449572927318513\n",
      "Epoch 1325, Loss: 0.0001856759117799811, Final Batch Loss: 0.00011665091005852446\n",
      "Epoch 1326, Loss: 0.00019619935483206064, Final Batch Loss: 3.879473661072552e-05\n",
      "Epoch 1327, Loss: 0.0014698792656417936, Final Batch Loss: 0.0010614016791805625\n",
      "Epoch 1328, Loss: 0.0022786950576119125, Final Batch Loss: 0.0015164902433753014\n",
      "Epoch 1329, Loss: 0.001415710685250815, Final Batch Loss: 0.0013342078309506178\n",
      "Epoch 1330, Loss: 0.0008893587328202557, Final Batch Loss: 0.0008376837940886617\n",
      "Epoch 1331, Loss: 0.0032098572264658287, Final Batch Loss: 0.000174529806827195\n",
      "Epoch 1332, Loss: 0.0006887724666739814, Final Batch Loss: 7.028475374681875e-05\n",
      "Epoch 1333, Loss: 0.0008526532874384429, Final Batch Loss: 0.000822441594209522\n",
      "Epoch 1334, Loss: 0.00021624695364153013, Final Batch Loss: 0.0001219891055370681\n",
      "Epoch 1335, Loss: 0.0006629456402151845, Final Batch Loss: 6.619394844165072e-05\n",
      "Epoch 1336, Loss: 0.0005028302839491516, Final Batch Loss: 0.00024023826699703932\n",
      "Epoch 1337, Loss: 0.00040651680319570005, Final Batch Loss: 0.000271473458269611\n",
      "Epoch 1338, Loss: 7.022469617368188e-05, Final Batch Loss: 5.112759390613064e-05\n",
      "Epoch 1339, Loss: 0.00012824344594264403, Final Batch Loss: 4.288544732844457e-05\n",
      "Epoch 1340, Loss: 0.0001392270132782869, Final Batch Loss: 0.0001075220643542707\n",
      "Epoch 1341, Loss: 0.0021926599292783067, Final Batch Loss: 0.0001804958301363513\n",
      "Epoch 1342, Loss: 8.443421756965108e-05, Final Batch Loss: 3.616996400523931e-05\n",
      "Epoch 1343, Loss: 0.00043634364192257635, Final Batch Loss: 3.0462786526186392e-05\n",
      "Epoch 1344, Loss: 0.0027516169284353964, Final Batch Loss: 0.0026308053638786077\n",
      "Epoch 1345, Loss: 0.005294012953527272, Final Batch Loss: 0.0017410245491191745\n",
      "Epoch 1346, Loss: 0.00038293506077025086, Final Batch Loss: 0.00021917289996054024\n",
      "Epoch 1347, Loss: 0.002576471073552966, Final Batch Loss: 0.0006876239785924554\n",
      "Epoch 1348, Loss: 0.0006755450849595945, Final Batch Loss: 4.487305341172032e-05\n",
      "Epoch 1349, Loss: 0.00027919850617763586, Final Batch Loss: 0.00023856076586525887\n",
      "Epoch 1350, Loss: 0.00032390850537922233, Final Batch Loss: 6.0471895267255604e-05\n",
      "Epoch 1351, Loss: 0.00010639889478625264, Final Batch Loss: 4.930114300805144e-06\n",
      "Epoch 1352, Loss: 0.0008930447220336646, Final Batch Loss: 0.00042174459667876363\n",
      "Epoch 1353, Loss: 7.465899034286849e-05, Final Batch Loss: 3.1461862818105146e-05\n",
      "Epoch 1354, Loss: 0.0003940753813367337, Final Batch Loss: 0.0002610627270769328\n",
      "Epoch 1355, Loss: 0.00011104216901003383, Final Batch Loss: 7.671948696952313e-05\n",
      "Epoch 1356, Loss: 0.0023657531128264964, Final Batch Loss: 0.0003230628208257258\n",
      "Epoch 1357, Loss: 0.0008814576431177557, Final Batch Loss: 0.0006921435706317425\n",
      "Epoch 1358, Loss: 0.0001344851298199501, Final Batch Loss: 5.7814653700916097e-05\n",
      "Epoch 1359, Loss: 0.00011395806632208405, Final Batch Loss: 0.00010022372589446604\n",
      "Epoch 1360, Loss: 0.00019992921443190426, Final Batch Loss: 8.342161163454875e-05\n",
      "Epoch 1361, Loss: 0.006039991378202103, Final Batch Loss: 4.253150837030262e-05\n",
      "Epoch 1362, Loss: 0.003380059526534751, Final Batch Loss: 0.0030979851726442575\n",
      "Epoch 1363, Loss: 0.003034764900803566, Final Batch Loss: 0.001249892171472311\n",
      "Epoch 1364, Loss: 0.0007690296388318529, Final Batch Loss: 1.1464208000688814e-05\n",
      "Epoch 1365, Loss: 0.00013492581274476834, Final Batch Loss: 3.71110400010366e-05\n",
      "Epoch 1366, Loss: 0.0030103651852186886, Final Batch Loss: 8.687381523486692e-06\n",
      "Epoch 1367, Loss: 0.005398984591010958, Final Batch Loss: 8.517509559169412e-05\n",
      "Epoch 1368, Loss: 6.474641531895031e-05, Final Batch Loss: 3.5925372685596813e-06\n",
      "Epoch 1369, Loss: 3.228873720217962e-05, Final Batch Loss: 8.301167326862924e-06\n",
      "Epoch 1370, Loss: 0.004484499688260257, Final Batch Loss: 0.002716638147830963\n",
      "Epoch 1371, Loss: 0.00011031323083443567, Final Batch Loss: 4.776667628902942e-05\n",
      "Epoch 1372, Loss: 0.015027223935248912, Final Batch Loss: 0.0150097431614995\n",
      "Epoch 1373, Loss: 5.614603105641436e-05, Final Batch Loss: 1.9605946363299154e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1374, Loss: 0.00015874646123847924, Final Batch Loss: 0.00011875867494381964\n",
      "Epoch 1375, Loss: 0.009401437889209774, Final Batch Loss: 1.0012711754825432e-05\n",
      "Epoch 1376, Loss: 0.0020993384950998006, Final Batch Loss: 0.0020771007984876633\n",
      "Epoch 1377, Loss: 0.020147687140706694, Final Batch Loss: 4.6922210458433256e-05\n",
      "Epoch 1378, Loss: 0.001689019347395515, Final Batch Loss: 1.567529034218751e-05\n",
      "Epoch 1379, Loss: 0.0016772968447185121, Final Batch Loss: 2.5861219910439104e-05\n",
      "Epoch 1380, Loss: 8.649163282825612e-05, Final Batch Loss: 4.356264980742708e-05\n",
      "Epoch 1381, Loss: 0.000268863579549361, Final Batch Loss: 5.31771729583852e-05\n",
      "Epoch 1382, Loss: 0.0002141850272892043, Final Batch Loss: 7.787610229570419e-05\n",
      "Epoch 1383, Loss: 0.00036047295725438744, Final Batch Loss: 7.135317719075829e-05\n",
      "Epoch 1384, Loss: 0.00010100836516357958, Final Batch Loss: 1.6087768017314374e-05\n",
      "Epoch 1385, Loss: 0.0003991680277977139, Final Batch Loss: 0.000306155503494665\n",
      "Epoch 1386, Loss: 0.0005553143710130826, Final Batch Loss: 0.00014253043627832085\n",
      "Epoch 1387, Loss: 0.006216081892489456, Final Batch Loss: 0.006009282544255257\n",
      "Epoch 1388, Loss: 0.0004062231419084128, Final Batch Loss: 4.407279993756674e-05\n",
      "Epoch 1389, Loss: 0.0015250480864779092, Final Batch Loss: 9.221715299645439e-05\n",
      "Epoch 1390, Loss: 0.0014931084515410475, Final Batch Loss: 5.3886549721937627e-05\n",
      "Epoch 1391, Loss: 0.0006295794701145496, Final Batch Loss: 0.0006069012451916933\n",
      "Epoch 1392, Loss: 0.001502781677118037, Final Batch Loss: 8.264408825198188e-05\n",
      "Epoch 1393, Loss: 0.00042147871863562614, Final Batch Loss: 0.0003403732553124428\n",
      "Epoch 1394, Loss: 0.0019499068985169288, Final Batch Loss: 4.911431096843444e-05\n",
      "Epoch 1395, Loss: 0.00035512114118319005, Final Batch Loss: 5.2756236982531846e-05\n",
      "Epoch 1396, Loss: 0.00026347827952122316, Final Batch Loss: 6.731889880029485e-05\n",
      "Epoch 1397, Loss: 0.00022728698968421668, Final Batch Loss: 1.5594036085531116e-05\n",
      "Epoch 1398, Loss: 9.223595770890824e-05, Final Batch Loss: 2.643090920173563e-05\n",
      "Epoch 1399, Loss: 0.000713737666956149, Final Batch Loss: 0.0005098056863062084\n",
      "Epoch 1400, Loss: 0.0010544830474827904, Final Batch Loss: 7.95726737123914e-06\n",
      "Epoch 1401, Loss: 0.0010574358748272061, Final Batch Loss: 0.0006254189065657556\n",
      "Epoch 1402, Loss: 0.000294922534521902, Final Batch Loss: 0.0002536318788770586\n",
      "Epoch 1403, Loss: 0.0011400866642361507, Final Batch Loss: 7.4021503678523e-05\n",
      "Epoch 1404, Loss: 6.959802885830868e-05, Final Batch Loss: 4.8714853619458154e-05\n",
      "Epoch 1405, Loss: 0.0013561561863753013, Final Batch Loss: 0.0013180653331801295\n",
      "Epoch 1406, Loss: 0.0003904433560819598, Final Batch Loss: 2.8952914362889715e-05\n",
      "Epoch 1407, Loss: 0.0064867353066802025, Final Batch Loss: 0.003143747802823782\n",
      "Epoch 1408, Loss: 0.0006516822086268803, Final Batch Loss: 2.3579230401082896e-05\n",
      "Epoch 1409, Loss: 0.0011720189068000764, Final Batch Loss: 0.0007609872845932841\n",
      "Epoch 1410, Loss: 5.465185495268088e-05, Final Batch Loss: 2.4450457203784026e-05\n",
      "Epoch 1411, Loss: 0.0011459016823209822, Final Batch Loss: 0.00027188356034457684\n",
      "Epoch 1412, Loss: 0.00011975178767897887, Final Batch Loss: 0.00010596495121717453\n",
      "Epoch 1413, Loss: 0.007094707892974839, Final Batch Loss: 7.707401528023183e-05\n",
      "Epoch 1414, Loss: 0.00010591964382911101, Final Batch Loss: 6.804907025070861e-05\n",
      "Epoch 1415, Loss: 0.0011333950387779623, Final Batch Loss: 0.00038437676266767085\n",
      "Epoch 1416, Loss: 0.007057719451040612, Final Batch Loss: 0.007035450078547001\n",
      "Epoch 1417, Loss: 0.0003065067758143414, Final Batch Loss: 0.00025355539401061833\n",
      "Epoch 1418, Loss: 0.00828812038525939, Final Batch Loss: 0.0021303598769009113\n",
      "Epoch 1419, Loss: 0.00019649104433483444, Final Batch Loss: 3.25770779454615e-05\n",
      "Epoch 1420, Loss: 0.00011000054291798733, Final Batch Loss: 7.062065560603514e-05\n",
      "Epoch 1421, Loss: 0.0004999841103199287, Final Batch Loss: 8.740265002415981e-06\n",
      "Epoch 1422, Loss: 7.799488776072394e-05, Final Batch Loss: 2.292132739967201e-05\n",
      "Epoch 1423, Loss: 0.0001603596429049503, Final Batch Loss: 0.00011939935939153656\n",
      "Epoch 1424, Loss: 0.0003627132173278369, Final Batch Loss: 0.00030970197985880077\n",
      "Epoch 1425, Loss: 0.003665308940981049, Final Batch Loss: 5.4849318985361606e-05\n",
      "Epoch 1426, Loss: 0.003986012721725274, Final Batch Loss: 6.490486703114584e-05\n",
      "Epoch 1427, Loss: 0.001875067944638431, Final Batch Loss: 0.0015803184360265732\n",
      "Epoch 1428, Loss: 4.625540168490261e-05, Final Batch Loss: 2.6203866582363844e-05\n",
      "Epoch 1429, Loss: 4.9481737733003683e-05, Final Batch Loss: 1.5650750356144272e-05\n",
      "Epoch 1430, Loss: 0.0015637951364624314, Final Batch Loss: 6.090010720072314e-05\n",
      "Epoch 1431, Loss: 0.00013372751709539443, Final Batch Loss: 8.774493471719325e-05\n",
      "Epoch 1432, Loss: 7.334954989346443e-05, Final Batch Loss: 1.2697814781859051e-05\n",
      "Epoch 1433, Loss: 0.00016276429960271344, Final Batch Loss: 0.00010107878188136965\n",
      "Epoch 1434, Loss: 0.00010175711486226646, Final Batch Loss: 7.699821253481787e-06\n",
      "Epoch 1435, Loss: 7.45979004932451e-05, Final Batch Loss: 6.162650242913514e-05\n",
      "Epoch 1436, Loss: 0.00015680883370805532, Final Batch Loss: 0.00010980526712955907\n",
      "Epoch 1437, Loss: 0.00048215554852504283, Final Batch Loss: 0.0004013485158793628\n",
      "Epoch 1438, Loss: 0.0009505913076282013, Final Batch Loss: 0.000940635334700346\n",
      "Epoch 1439, Loss: 0.00016986200353130698, Final Batch Loss: 0.00012212117144372314\n",
      "Epoch 1440, Loss: 0.00027935190473726834, Final Batch Loss: 5.142075224284781e-06\n",
      "Epoch 1441, Loss: 9.958549708244391e-05, Final Batch Loss: 8.940637053456157e-05\n",
      "Epoch 1442, Loss: 3.686113086587284e-05, Final Batch Loss: 8.147828339133412e-06\n",
      "Epoch 1443, Loss: 0.001941206637184223, Final Batch Loss: 5.574552687903633e-06\n",
      "Epoch 1444, Loss: 0.001195077296870295, Final Batch Loss: 4.697728581959382e-05\n",
      "Epoch 1445, Loss: 0.0002011119322560262, Final Batch Loss: 0.00014195697440300137\n",
      "Epoch 1446, Loss: 0.002084816434944514, Final Batch Loss: 2.126218896592036e-05\n",
      "Epoch 1447, Loss: 0.0018168652459280565, Final Batch Loss: 6.024220783729106e-05\n",
      "Epoch 1448, Loss: 4.482675103645306e-05, Final Batch Loss: 3.456679769442417e-05\n",
      "Epoch 1449, Loss: 0.00044740181328961626, Final Batch Loss: 0.00033700731000863016\n",
      "Epoch 1450, Loss: 3.396391275600763e-05, Final Batch Loss: 2.6198993509751745e-05\n",
      "Epoch 1451, Loss: 0.00048326743717552745, Final Batch Loss: 6.6095585680159274e-06\n",
      "Epoch 1452, Loss: 9.19257327041123e-05, Final Batch Loss: 4.655649172491394e-05\n",
      "Epoch 1453, Loss: 0.002870770884328522, Final Batch Loss: 0.0026680000592023134\n",
      "Epoch 1454, Loss: 0.0008411032249568962, Final Batch Loss: 9.630803106119856e-05\n",
      "Epoch 1455, Loss: 0.0003621580726758111, Final Batch Loss: 1.9844959751935676e-05\n",
      "Epoch 1456, Loss: 9.462321486353176e-05, Final Batch Loss: 1.5113179870240856e-05\n",
      "Epoch 1457, Loss: 0.0019080682905041613, Final Batch Loss: 7.44797071092762e-05\n",
      "Epoch 1458, Loss: 0.00012828245235141367, Final Batch Loss: 7.2707116487436e-05\n",
      "Epoch 1459, Loss: 0.003188614035025239, Final Batch Loss: 0.0029516371432691813\n",
      "Epoch 1460, Loss: 0.0006158652104204521, Final Batch Loss: 0.0005157515406608582\n",
      "Epoch 1461, Loss: 0.00752137356903404, Final Batch Loss: 0.005835652817040682\n",
      "Epoch 1462, Loss: 3.0381334909179714e-05, Final Batch Loss: 2.4002625650609843e-05\n",
      "Epoch 1463, Loss: 9.219241837854497e-05, Final Batch Loss: 4.411087866174057e-05\n",
      "Epoch 1464, Loss: 0.00017513030979898758, Final Batch Loss: 4.075610559084453e-05\n",
      "Epoch 1465, Loss: 0.0024804760496408562, Final Batch Loss: 2.7603264243225567e-06\n",
      "Epoch 1466, Loss: 0.0002599004947114736, Final Batch Loss: 4.161710967309773e-05\n",
      "Epoch 1467, Loss: 0.0035923592149629258, Final Batch Loss: 4.318806895753369e-05\n",
      "Epoch 1468, Loss: 0.0026112055202247575, Final Batch Loss: 0.0026009902358055115\n",
      "Epoch 1469, Loss: 8.652473297843244e-05, Final Batch Loss: 1.2459820936783217e-05\n",
      "Epoch 1470, Loss: 0.00023021860761218704, Final Batch Loss: 0.00019598707149270922\n",
      "Epoch 1471, Loss: 0.001460003435568069, Final Batch Loss: 1.3924904123996384e-05\n",
      "Epoch 1472, Loss: 4.2472404857107904e-05, Final Batch Loss: 8.367124792130198e-06\n",
      "Epoch 1473, Loss: 0.00024594878050265834, Final Batch Loss: 0.00012686729314737022\n",
      "Epoch 1474, Loss: 0.00012598602552316152, Final Batch Loss: 8.100348350126296e-05\n",
      "Epoch 1475, Loss: 0.00012043816968798637, Final Batch Loss: 4.114746843697503e-05\n",
      "Epoch 1476, Loss: 0.0007226818706840277, Final Batch Loss: 8.887978037819266e-05\n",
      "Epoch 1477, Loss: 0.00013250552729004994, Final Batch Loss: 0.00010553169704508036\n",
      "Epoch 1478, Loss: 3.802364608418429e-05, Final Batch Loss: 8.277324923255946e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1479, Loss: 0.0020052651525475085, Final Batch Loss: 0.0007589811575599015\n",
      "Epoch 1480, Loss: 0.004242879222147167, Final Batch Loss: 0.0005760841304436326\n",
      "Epoch 1481, Loss: 0.0010890958892559865, Final Batch Loss: 2.3508846425102092e-05\n",
      "Epoch 1482, Loss: 0.0002800936526909936, Final Batch Loss: 0.0002554194943513721\n",
      "Epoch 1483, Loss: 0.0011564180567802396, Final Batch Loss: 3.7812798836966977e-05\n",
      "Epoch 1484, Loss: 0.0006748994856025092, Final Batch Loss: 5.161016451893374e-05\n",
      "Epoch 1485, Loss: 0.0006289247021413757, Final Batch Loss: 8.851819984556641e-06\n",
      "Epoch 1486, Loss: 0.011290108763205353, Final Batch Loss: 2.5603898393455893e-05\n",
      "Epoch 1487, Loss: 0.0031791185174370185, Final Batch Loss: 0.0031573374290019274\n",
      "Epoch 1488, Loss: 0.0009948665683623403, Final Batch Loss: 0.000870983290951699\n",
      "Epoch 1489, Loss: 0.0017484965137555264, Final Batch Loss: 0.00010739018762251362\n",
      "Epoch 1490, Loss: 0.00011971874391747406, Final Batch Loss: 0.00011132841609651223\n",
      "Epoch 1491, Loss: 0.0005069752805866301, Final Batch Loss: 0.0002531884238123894\n",
      "Epoch 1492, Loss: 9.514702469459735e-05, Final Batch Loss: 5.969553967588581e-05\n",
      "Epoch 1493, Loss: 0.0005319857009453699, Final Batch Loss: 4.4804284698329866e-05\n",
      "Epoch 1494, Loss: 0.002726936274484615, Final Batch Loss: 0.002704425249248743\n",
      "Epoch 1495, Loss: 3.958721208618954e-05, Final Batch Loss: 2.1661515347659588e-05\n",
      "Epoch 1496, Loss: 0.0003152036624669563, Final Batch Loss: 5.702640555682592e-05\n",
      "Epoch 1497, Loss: 0.0008742512436583638, Final Batch Loss: 0.0008097633253782988\n",
      "Epoch 1498, Loss: 0.0012067736320204858, Final Batch Loss: 0.0012012155493721366\n",
      "Epoch 1499, Loss: 0.0002881341222291667, Final Batch Loss: 2.868707952075056e-06\n",
      "Epoch 1500, Loss: 0.0015362057238235138, Final Batch Loss: 3.893122629960999e-05\n",
      "Epoch 1501, Loss: 0.00011028558219550177, Final Batch Loss: 1.0767740604933351e-05\n",
      "Epoch 1502, Loss: 0.00023166432220023125, Final Batch Loss: 4.3992025894112885e-05\n",
      "Epoch 1503, Loss: 0.006448303884099005, Final Batch Loss: 8.523533324478194e-06\n",
      "Epoch 1504, Loss: 0.00013808106268697884, Final Batch Loss: 0.00010859271424124017\n",
      "Epoch 1505, Loss: 7.6255058957031e-05, Final Batch Loss: 3.760117033380084e-05\n",
      "Epoch 1506, Loss: 0.0012226013823237736, Final Batch Loss: 3.293260306236334e-05\n",
      "Epoch 1507, Loss: 0.002255258441437036, Final Batch Loss: 0.002093762159347534\n",
      "Epoch 1508, Loss: 0.003815449890680611, Final Batch Loss: 0.00025008583907037973\n",
      "Epoch 1509, Loss: 0.001563846308272332, Final Batch Loss: 0.0007847415399737656\n",
      "Epoch 1510, Loss: 0.0012666215989156626, Final Batch Loss: 6.188215775182471e-05\n",
      "Epoch 1511, Loss: 0.00016243825302808546, Final Batch Loss: 0.00010406739602331072\n",
      "Epoch 1512, Loss: 0.04595649193834106, Final Batch Loss: 1.5552601325907744e-05\n",
      "Epoch 1513, Loss: 0.000276168196251092, Final Batch Loss: 6.711284186167177e-06\n",
      "Epoch 1514, Loss: 0.0003383473558642436, Final Batch Loss: 1.4657958672614768e-05\n",
      "Epoch 1515, Loss: 0.00010451347770867869, Final Batch Loss: 1.8474471289664507e-05\n",
      "Epoch 1516, Loss: 0.0021920960507486598, Final Batch Loss: 1.2109020644857083e-05\n",
      "Epoch 1517, Loss: 0.00015201049609459005, Final Batch Loss: 0.00012157085438957438\n",
      "Epoch 1518, Loss: 0.0019613484546425752, Final Batch Loss: 4.835076833842322e-05\n",
      "Epoch 1519, Loss: 0.0057637644349597394, Final Batch Loss: 0.005702143535017967\n",
      "Epoch 1520, Loss: 3.7649037039955147e-05, Final Batch Loss: 1.5718798749730922e-05\n",
      "Epoch 1521, Loss: 8.662299160278053e-05, Final Batch Loss: 6.863631369924406e-06\n",
      "Epoch 1522, Loss: 0.0001926976110553369, Final Batch Loss: 0.0001685583993094042\n",
      "Epoch 1523, Loss: 6.757118535460904e-05, Final Batch Loss: 5.1973449444631115e-05\n",
      "Epoch 1524, Loss: 0.004387962158943992, Final Batch Loss: 0.004308617673814297\n",
      "Epoch 1525, Loss: 6.421638317988254e-05, Final Batch Loss: 2.8573034796863794e-05\n",
      "Epoch 1526, Loss: 0.0013463853902067058, Final Batch Loss: 0.0012903407914564013\n",
      "Epoch 1527, Loss: 0.00030800807689956855, Final Batch Loss: 7.314576578210108e-06\n",
      "Epoch 1528, Loss: 0.0002715240261750296, Final Batch Loss: 0.0001423697976861149\n",
      "Epoch 1529, Loss: 3.152384033455746e-05, Final Batch Loss: 2.2411417376133613e-05\n",
      "Epoch 1530, Loss: 0.0034701870754361153, Final Batch Loss: 0.0015610373811796308\n",
      "Epoch 1531, Loss: 0.00011137899127788842, Final Batch Loss: 5.5928259826032445e-05\n",
      "Epoch 1532, Loss: 0.0015765890129841864, Final Batch Loss: 0.00010490446584299207\n",
      "Epoch 1533, Loss: 0.000604906007538375, Final Batch Loss: 0.0005978430854156613\n",
      "Epoch 1534, Loss: 0.0002265042348881252, Final Batch Loss: 0.0001540893572382629\n",
      "Epoch 1535, Loss: 0.00023887094994279323, Final Batch Loss: 6.703757208015304e-06\n",
      "Epoch 1536, Loss: 9.961784144252306e-05, Final Batch Loss: 6.082605068513658e-06\n",
      "Epoch 1537, Loss: 0.0010311180740245618, Final Batch Loss: 3.352631028974429e-05\n",
      "Epoch 1538, Loss: 0.00011132077543152263, Final Batch Loss: 2.651925569807645e-06\n",
      "Epoch 1539, Loss: 0.0005510019982466474, Final Batch Loss: 0.00018826570885721594\n",
      "Epoch 1540, Loss: 0.000887910122401081, Final Batch Loss: 0.00067687634145841\n",
      "Epoch 1541, Loss: 0.0002771712825051509, Final Batch Loss: 0.000182303658220917\n",
      "Epoch 1542, Loss: 0.0001339580358035164, Final Batch Loss: 0.00010924825619440526\n",
      "Epoch 1543, Loss: 0.0018272154502483318, Final Batch Loss: 1.21994180517504e-05\n",
      "Epoch 1544, Loss: 0.00010985986045852769, Final Batch Loss: 1.7153690350824036e-05\n",
      "Epoch 1545, Loss: 0.0010420211947348434, Final Batch Loss: 4.150891982135363e-05\n",
      "Epoch 1546, Loss: 0.0004452531866263598, Final Batch Loss: 0.00017605230095796287\n",
      "Epoch 1547, Loss: 0.0003610365729400655, Final Batch Loss: 0.0003429846838116646\n",
      "Epoch 1548, Loss: 0.0020613269007299095, Final Batch Loss: 8.602385059930384e-05\n",
      "Epoch 1549, Loss: 0.0009309422166552395, Final Batch Loss: 0.0004057536425534636\n",
      "Epoch 1550, Loss: 0.00012097787111997604, Final Batch Loss: 6.829324411228299e-05\n",
      "Epoch 1551, Loss: 0.001148024050053209, Final Batch Loss: 8.631398668512702e-05\n",
      "Epoch 1552, Loss: 0.012846465200709645, Final Batch Loss: 0.012736193835735321\n",
      "Epoch 1553, Loss: 0.008090351191640366, Final Batch Loss: 0.008040081709623337\n",
      "Epoch 1554, Loss: 0.0015959987649694085, Final Batch Loss: 0.00016007083468139172\n",
      "Epoch 1555, Loss: 0.0003352001140228822, Final Batch Loss: 1.5066739251778927e-05\n",
      "Epoch 1556, Loss: 0.0032318715093424544, Final Batch Loss: 0.0030857704114168882\n",
      "Epoch 1557, Loss: 0.00019986749794043135, Final Batch Loss: 1.7926400687429123e-05\n",
      "Epoch 1558, Loss: 0.0012348572381597478, Final Batch Loss: 2.594547186163254e-05\n",
      "Epoch 1559, Loss: 0.0027485294522193726, Final Batch Loss: 0.002692238660529256\n",
      "Epoch 1560, Loss: 0.00010568815741862636, Final Batch Loss: 9.282989049097523e-05\n",
      "Epoch 1561, Loss: 0.032797422050862224, Final Batch Loss: 1.5631108908564784e-05\n",
      "Epoch 1562, Loss: 0.0020250302122803987, Final Batch Loss: 1.4136669960862491e-05\n",
      "Epoch 1563, Loss: 0.0022303365431071143, Final Batch Loss: 1.4643536815128755e-05\n",
      "Epoch 1564, Loss: 0.0030863965075695887, Final Batch Loss: 0.00011505793372634798\n",
      "Epoch 1565, Loss: 0.003056262678001076, Final Batch Loss: 0.002526987809687853\n",
      "Epoch 1566, Loss: 0.0022369557354977587, Final Batch Loss: 0.0022085998207330704\n",
      "Epoch 1567, Loss: 6.708215369144455e-05, Final Batch Loss: 3.357494279043749e-05\n",
      "Epoch 1568, Loss: 0.000172146363183856, Final Batch Loss: 1.5821162378415465e-05\n",
      "Epoch 1569, Loss: 0.0014369001564773498, Final Batch Loss: 2.8182561436551623e-05\n",
      "Epoch 1570, Loss: 0.0005179292784305289, Final Batch Loss: 0.0001292242232011631\n",
      "Epoch 1571, Loss: 0.00038617864447587635, Final Batch Loss: 2.5114690288319252e-05\n",
      "Epoch 1572, Loss: 0.012925579911097884, Final Batch Loss: 0.00981680117547512\n",
      "Epoch 1573, Loss: 0.001652623886911897, Final Batch Loss: 1.987571522477083e-05\n",
      "Epoch 1574, Loss: 0.0027235432935412973, Final Batch Loss: 0.0024035433307290077\n",
      "Epoch 1575, Loss: 0.0018963574057124788, Final Batch Loss: 0.001888748724013567\n",
      "Epoch 1576, Loss: 6.228510392247699e-05, Final Batch Loss: 2.646224675117992e-05\n",
      "Epoch 1577, Loss: 0.00010607026479192427, Final Batch Loss: 7.054777142911917e-06\n",
      "Epoch 1578, Loss: 0.0019469089747872204, Final Batch Loss: 0.00011167218326590955\n",
      "Epoch 1579, Loss: 0.00029229827123344876, Final Batch Loss: 3.064267002628185e-05\n",
      "Epoch 1580, Loss: 0.0002759070775937289, Final Batch Loss: 2.517324173822999e-05\n",
      "Epoch 1581, Loss: 0.002113679947797209, Final Batch Loss: 0.00030785234412178397\n",
      "Epoch 1582, Loss: 0.00016762415543780662, Final Batch Loss: 0.000134101472212933\n",
      "Epoch 1583, Loss: 0.004448315070476383, Final Batch Loss: 6.304954877123237e-05\n",
      "Epoch 1584, Loss: 0.0035573667846620083, Final Batch Loss: 0.002978014759719372\n",
      "Epoch 1585, Loss: 4.400941907078959e-05, Final Batch Loss: 1.8546990759205073e-05\n",
      "Epoch 1586, Loss: 0.00047923486840772966, Final Batch Loss: 0.0004767950449604541\n",
      "Epoch 1587, Loss: 3.772484978981083e-05, Final Batch Loss: 1.2499248441599775e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1588, Loss: 9.302884063799866e-05, Final Batch Loss: 3.1031802791403607e-05\n",
      "Epoch 1589, Loss: 0.0007655959052499384, Final Batch Loss: 0.000494832347612828\n",
      "Epoch 1590, Loss: 0.0049232367891818285, Final Batch Loss: 6.402540020644665e-05\n",
      "Epoch 1591, Loss: 6.748807936673984e-05, Final Batch Loss: 2.4739751097513363e-05\n",
      "Epoch 1592, Loss: 0.00045153128303354606, Final Batch Loss: 0.0004015036975033581\n",
      "Epoch 1593, Loss: 0.0012847431935369968, Final Batch Loss: 0.001148901879787445\n",
      "Epoch 1594, Loss: 3.964302231906913e-05, Final Batch Loss: 2.9632703444804065e-05\n",
      "Epoch 1595, Loss: 4.401179830892943e-05, Final Batch Loss: 1.6987749404506758e-05\n",
      "Epoch 1596, Loss: 0.0007805488567100838, Final Batch Loss: 0.0007073982269503176\n",
      "Epoch 1597, Loss: 0.0005148173349880381, Final Batch Loss: 0.0004898828337900341\n",
      "Epoch 1598, Loss: 0.0019310597417643294, Final Batch Loss: 3.572761488612741e-05\n",
      "Epoch 1599, Loss: 0.00039735386963002384, Final Batch Loss: 0.00011060069664381444\n",
      "Epoch 1600, Loss: 4.9919995944947004e-05, Final Batch Loss: 1.885704114101827e-05\n",
      "Epoch 1601, Loss: 4.206094490655232e-05, Final Batch Loss: 3.1179435609374195e-05\n",
      "Epoch 1602, Loss: 0.0010777148127090186, Final Batch Loss: 0.0009050387307070196\n",
      "Epoch 1603, Loss: 4.555834129860159e-05, Final Batch Loss: 2.3892784156487323e-05\n",
      "Epoch 1604, Loss: 0.0005316478127497248, Final Batch Loss: 0.00044088222784921527\n",
      "Epoch 1605, Loss: 3.7809751574968686e-05, Final Batch Loss: 6.544412372022634e-06\n",
      "Epoch 1606, Loss: 0.00011654244372039102, Final Batch Loss: 6.47624910925515e-05\n",
      "Epoch 1607, Loss: 7.807438851159532e-05, Final Batch Loss: 1.8140615793527104e-05\n",
      "Epoch 1608, Loss: 9.48088381846901e-05, Final Batch Loss: 4.135967174079269e-05\n",
      "Epoch 1609, Loss: 0.0008239371854870114, Final Batch Loss: 0.000786885735578835\n",
      "Epoch 1610, Loss: 0.002378308384322736, Final Batch Loss: 9.835634955379646e-06\n",
      "Epoch 1611, Loss: 7.341575201280648e-05, Final Batch Loss: 6.61472586216405e-05\n",
      "Epoch 1612, Loss: 0.0025444956845603883, Final Batch Loss: 0.0005111819482408464\n",
      "Epoch 1613, Loss: 0.002099096862366423, Final Batch Loss: 0.00021011472563259304\n",
      "Epoch 1614, Loss: 0.0006961491017136723, Final Batch Loss: 0.0005527457688003778\n",
      "Epoch 1615, Loss: 0.00024172538542188704, Final Batch Loss: 9.189854608848691e-05\n",
      "Epoch 1616, Loss: 0.0031385613256134093, Final Batch Loss: 0.00016985140973702073\n",
      "Epoch 1617, Loss: 0.0010798160128615564, Final Batch Loss: 2.9475302653736435e-05\n",
      "Epoch 1618, Loss: 0.0001154477649834007, Final Batch Loss: 6.115236465120688e-05\n",
      "Epoch 1619, Loss: 0.0005374852662498597, Final Batch Loss: 0.0005095828673802316\n",
      "Epoch 1620, Loss: 9.778041749086697e-05, Final Batch Loss: 9.394587686983868e-05\n",
      "Epoch 1621, Loss: 4.1325846268591704e-05, Final Batch Loss: 3.374837979208678e-05\n",
      "Epoch 1622, Loss: 0.00036484061274677515, Final Batch Loss: 0.00013352304813452065\n",
      "Epoch 1623, Loss: 0.0013921858335379511, Final Batch Loss: 0.001348897349089384\n",
      "Epoch 1624, Loss: 0.00010813212975335773, Final Batch Loss: 2.7311141820973717e-05\n",
      "Epoch 1625, Loss: 0.00019634678756119683, Final Batch Loss: 0.0001538549258839339\n",
      "Epoch 1626, Loss: 0.0001534263192297658, Final Batch Loss: 0.00012655419413931668\n",
      "Epoch 1627, Loss: 0.001925521472003311, Final Batch Loss: 1.6399018932133913e-05\n",
      "Epoch 1628, Loss: 0.0004885339149041101, Final Batch Loss: 0.00032653429661877453\n",
      "Epoch 1629, Loss: 7.604220809298567e-05, Final Batch Loss: 3.9985829062061384e-05\n",
      "Epoch 1630, Loss: 0.0010004175128415227, Final Batch Loss: 6.817671237513423e-05\n",
      "Epoch 1631, Loss: 6.240061338758096e-05, Final Batch Loss: 5.4610285587841645e-05\n",
      "Epoch 1632, Loss: 2.9483685466402676e-05, Final Batch Loss: 2.0819363271584734e-05\n",
      "Epoch 1633, Loss: 0.0015681539371144027, Final Batch Loss: 3.0008464818820357e-05\n",
      "Epoch 1634, Loss: 0.00021050839859526604, Final Batch Loss: 9.613909060135484e-05\n",
      "Epoch 1635, Loss: 0.0011178386339452118, Final Batch Loss: 0.0008224254124797881\n",
      "Epoch 1636, Loss: 0.0011495958933664951, Final Batch Loss: 0.0010922022629529238\n",
      "Epoch 1637, Loss: 0.0018193575087934732, Final Batch Loss: 0.0015070316148921847\n",
      "Epoch 1638, Loss: 0.0033854300345410593, Final Batch Loss: 4.516747139859945e-06\n",
      "Epoch 1639, Loss: 0.005609255204035435, Final Batch Loss: 0.0055272625759243965\n",
      "Epoch 1640, Loss: 0.00027315384431858547, Final Batch Loss: 3.4346379834460095e-05\n",
      "Epoch 1641, Loss: 0.0001995650145545369, Final Batch Loss: 1.890169187390711e-05\n",
      "Epoch 1642, Loss: 0.001098866378015373, Final Batch Loss: 0.0010539793875068426\n",
      "Epoch 1643, Loss: 0.00012336613099250826, Final Batch Loss: 4.33763443652424e-06\n",
      "Epoch 1644, Loss: 0.0002207970101153478, Final Batch Loss: 5.3593626944348216e-05\n",
      "Epoch 1645, Loss: 4.1493301978334785e-05, Final Batch Loss: 2.3642372980248183e-05\n",
      "Epoch 1646, Loss: 7.17622388037853e-05, Final Batch Loss: 4.194171924609691e-05\n",
      "Epoch 1647, Loss: 5.640574045173707e-06, Final Batch Loss: 4.116629497730173e-06\n",
      "Epoch 1648, Loss: 0.0009866534091997892, Final Batch Loss: 6.360802217386663e-05\n",
      "Epoch 1649, Loss: 0.0016028874088078737, Final Batch Loss: 0.0010347211500629783\n",
      "Epoch 1650, Loss: 0.008221048949053511, Final Batch Loss: 0.008096953853964806\n",
      "Epoch 1651, Loss: 9.471486737311352e-05, Final Batch Loss: 4.332594471634366e-06\n",
      "Epoch 1652, Loss: 8.023190594030893e-05, Final Batch Loss: 4.414404884300893e-06\n",
      "Epoch 1653, Loss: 0.00021673949504474876, Final Batch Loss: 8.406156666751485e-06\n",
      "Epoch 1654, Loss: 0.000761014631279977, Final Batch Loss: 2.8732920327456668e-05\n",
      "Epoch 1655, Loss: 0.00612636093137553, Final Batch Loss: 0.006080337334424257\n",
      "Epoch 1656, Loss: 0.00010272146573697682, Final Batch Loss: 1.0286317774443887e-05\n",
      "Epoch 1657, Loss: 4.086952822035528e-05, Final Batch Loss: 3.592114808270708e-05\n",
      "Epoch 1658, Loss: 0.00015810261174920015, Final Batch Loss: 5.65694244869519e-05\n",
      "Epoch 1659, Loss: 0.00013104334357194602, Final Batch Loss: 3.511582326609641e-05\n",
      "Epoch 1660, Loss: 0.0004255757376085967, Final Batch Loss: 0.00032062604441307485\n",
      "Epoch 1661, Loss: 0.0012202718353364617, Final Batch Loss: 0.0008297181339003146\n",
      "Epoch 1662, Loss: 0.0003711703757289797, Final Batch Loss: 2.777614281512797e-05\n",
      "Epoch 1663, Loss: 5.716985924664186e-05, Final Batch Loss: 8.863303264661226e-06\n",
      "Epoch 1664, Loss: 0.0006351041374728084, Final Batch Loss: 0.000600947707425803\n",
      "Epoch 1665, Loss: 2.9189064662205055e-05, Final Batch Loss: 1.852160676207859e-05\n",
      "Epoch 1666, Loss: 2.8542677682708018e-05, Final Batch Loss: 7.769880539854057e-06\n",
      "Epoch 1667, Loss: 0.00013937543917563744, Final Batch Loss: 2.9153325158404186e-05\n",
      "Epoch 1668, Loss: 3.395461089894525e-05, Final Batch Loss: 3.388418463146081e-06\n",
      "Epoch 1669, Loss: 0.0029775849980069324, Final Batch Loss: 2.2118489141575992e-05\n",
      "Epoch 1670, Loss: 7.296263106582046e-06, Final Batch Loss: 1.6933169035837636e-06\n",
      "Epoch 1671, Loss: 0.00017586521425982937, Final Batch Loss: 0.00011482720583444461\n",
      "Epoch 1672, Loss: 0.010949915803394106, Final Batch Loss: 1.0185472092416603e-05\n",
      "Epoch 1673, Loss: 5.1651801868501934e-05, Final Batch Loss: 2.7789908472186653e-06\n",
      "Epoch 1674, Loss: 0.0005736084785894491, Final Batch Loss: 0.0005653119296766818\n",
      "Epoch 1675, Loss: 0.0014116933743935078, Final Batch Loss: 0.00039436956285499036\n",
      "Epoch 1676, Loss: 2.2925838948140154e-05, Final Batch Loss: 1.7250382370548323e-05\n",
      "Epoch 1677, Loss: 0.0007533855896326713, Final Batch Loss: 2.067587774945423e-05\n",
      "Epoch 1678, Loss: 0.0034816986062651267, Final Batch Loss: 1.8044293028651737e-05\n",
      "Epoch 1679, Loss: 6.830569145677146e-05, Final Batch Loss: 3.045045923499856e-05\n",
      "Epoch 1680, Loss: 0.00029809217812726274, Final Batch Loss: 6.315079372143373e-05\n",
      "Epoch 1681, Loss: 0.0005423619440989569, Final Batch Loss: 0.0003352350613567978\n",
      "Epoch 1682, Loss: 0.0001538521610200405, Final Batch Loss: 9.476002014707774e-05\n",
      "Epoch 1683, Loss: 0.0012876421114924597, Final Batch Loss: 1.0557765563135035e-05\n",
      "Epoch 1684, Loss: 0.00013394020061241463, Final Batch Loss: 8.218888251576573e-05\n",
      "Epoch 1685, Loss: 0.0005695854815712664, Final Batch Loss: 4.3086245568702e-05\n",
      "Epoch 1686, Loss: 5.5181417337735184e-05, Final Batch Loss: 3.212394949514419e-05\n",
      "Epoch 1687, Loss: 0.0017378906359226676, Final Batch Loss: 2.9282049581524916e-05\n",
      "Epoch 1688, Loss: 0.0026170444616582245, Final Batch Loss: 0.0022274258080869913\n",
      "Epoch 1689, Loss: 7.704553354415111e-05, Final Batch Loss: 4.239072950440459e-05\n",
      "Epoch 1690, Loss: 0.00040477345464751124, Final Batch Loss: 4.914170131087303e-05\n",
      "Epoch 1691, Loss: 0.0017007985807140358, Final Batch Loss: 0.001616153516806662\n",
      "Epoch 1692, Loss: 7.425437797792256e-05, Final Batch Loss: 6.34234311291948e-06\n",
      "Epoch 1693, Loss: 0.00014247350190998986, Final Batch Loss: 3.4504555515013635e-05\n",
      "Epoch 1694, Loss: 0.0025972980947699398, Final Batch Loss: 0.0023522458504885435\n",
      "Epoch 1695, Loss: 0.00022014794376445934, Final Batch Loss: 0.0001311174564762041\n",
      "Epoch 1696, Loss: 0.0003381829446880147, Final Batch Loss: 6.269624282140285e-05\n",
      "Epoch 1697, Loss: 0.0016938030494202394, Final Batch Loss: 5.7087909226538613e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1698, Loss: 0.0005681902985088527, Final Batch Loss: 0.00028279810794629157\n",
      "Epoch 1699, Loss: 9.80872639502195e-05, Final Batch Loss: 3.6134217680228176e-06\n",
      "Epoch 1700, Loss: 0.0020413862366694957, Final Batch Loss: 0.0018389781471341848\n",
      "Epoch 1701, Loss: 0.005484224778683711, Final Batch Loss: 0.005478301085531712\n",
      "Epoch 1702, Loss: 0.0011152034276165068, Final Batch Loss: 0.0008850516169331968\n",
      "Epoch 1703, Loss: 0.00020823621889576316, Final Batch Loss: 3.981872578151524e-05\n",
      "Epoch 1704, Loss: 0.0008003501570783556, Final Batch Loss: 0.0005011062021367252\n",
      "Epoch 1705, Loss: 0.000181221052116598, Final Batch Loss: 0.00015298173821065575\n",
      "Epoch 1706, Loss: 0.00017698150622891262, Final Batch Loss: 7.426610682159662e-05\n",
      "Epoch 1707, Loss: 0.00013200623834563885, Final Batch Loss: 0.0001097519343602471\n",
      "Epoch 1708, Loss: 0.00014862408715998754, Final Batch Loss: 0.00013155322812963277\n",
      "Epoch 1709, Loss: 0.00012344119022600353, Final Batch Loss: 0.0001001563505269587\n",
      "Epoch 1710, Loss: 0.004392860602820292, Final Batch Loss: 0.0002813210303429514\n",
      "Epoch 1711, Loss: 0.0002897757021855796, Final Batch Loss: 9.637713446863927e-06\n",
      "Epoch 1712, Loss: 8.874101695255376e-05, Final Batch Loss: 2.029200186370872e-05\n",
      "Epoch 1713, Loss: 0.00025464868667768314, Final Batch Loss: 0.00020366832904983312\n",
      "Epoch 1714, Loss: 0.00025067890908303525, Final Batch Loss: 1.4785831581320963e-06\n",
      "Epoch 1715, Loss: 0.0001027311000143527, Final Batch Loss: 9.353497262054589e-06\n",
      "Epoch 1716, Loss: 0.00011140731658088043, Final Batch Loss: 6.407301407307386e-05\n",
      "Epoch 1717, Loss: 0.00016128380775626283, Final Batch Loss: 0.00013574295735452324\n",
      "Epoch 1718, Loss: 0.0003490541857900098, Final Batch Loss: 0.00018919241847470403\n",
      "Epoch 1719, Loss: 0.0006420939898816869, Final Batch Loss: 0.0005985877942293882\n",
      "Epoch 1720, Loss: 0.029067714931443334, Final Batch Loss: 0.0032637708354741335\n",
      "Epoch 1721, Loss: 0.0027066172460763482, Final Batch Loss: 0.0026948926970362663\n",
      "Epoch 1722, Loss: 0.00011936629744013771, Final Batch Loss: 9.795087680686265e-05\n",
      "Epoch 1723, Loss: 2.566309649409959e-05, Final Batch Loss: 7.169569471443538e-06\n",
      "Epoch 1724, Loss: 3.7730078929598676e-05, Final Batch Loss: 3.046867459488567e-05\n",
      "Epoch 1725, Loss: 8.121180508169346e-05, Final Batch Loss: 4.698088741861284e-05\n",
      "Epoch 1726, Loss: 8.380604231206235e-05, Final Batch Loss: 6.417945405701175e-05\n",
      "Epoch 1727, Loss: 0.0024975322448881343, Final Batch Loss: 0.0002086391468765214\n",
      "Epoch 1728, Loss: 1.8593435697766836e-05, Final Batch Loss: 1.459195800634916e-06\n",
      "Epoch 1729, Loss: 0.006586732735740952, Final Batch Loss: 0.00017181124712806195\n",
      "Epoch 1730, Loss: 4.012547651655041e-05, Final Batch Loss: 7.657123205717653e-06\n",
      "Epoch 1731, Loss: 2.9178409931773786e-05, Final Batch Loss: 1.3829571798851248e-05\n",
      "Epoch 1732, Loss: 0.00035380430290388176, Final Batch Loss: 1.4548169019690249e-05\n",
      "Epoch 1733, Loss: 0.0004902982473140582, Final Batch Loss: 0.00021075097902212292\n",
      "Epoch 1734, Loss: 0.002708194879232906, Final Batch Loss: 0.0026019285432994366\n",
      "Epoch 1735, Loss: 0.00033285890458500944, Final Batch Loss: 0.0003085883508902043\n",
      "Epoch 1736, Loss: 3.6172096770314965e-05, Final Batch Loss: 1.5072379937919322e-05\n",
      "Epoch 1737, Loss: 0.0002641059836605564, Final Batch Loss: 6.641667278017849e-05\n",
      "Epoch 1738, Loss: 0.0002993082453031093, Final Batch Loss: 0.0002034831268247217\n",
      "Epoch 1739, Loss: 6.638099557676469e-05, Final Batch Loss: 1.1604684004851151e-06\n",
      "Epoch 1740, Loss: 3.8892580050742254e-05, Final Batch Loss: 2.0044939446961507e-05\n",
      "Epoch 1741, Loss: 0.000612641922543844, Final Batch Loss: 6.750231023033848e-06\n",
      "Epoch 1742, Loss: 2.1574188849626807e-05, Final Batch Loss: 1.5698853530921042e-05\n",
      "Epoch 1743, Loss: 0.001998884723889205, Final Batch Loss: 6.565478997799801e-06\n",
      "Epoch 1744, Loss: 3.379972349648597e-05, Final Batch Loss: 8.287327545986045e-06\n",
      "Epoch 1745, Loss: 0.0004624571338354144, Final Batch Loss: 0.00041618820978328586\n",
      "Epoch 1746, Loss: 0.00010064333093851019, Final Batch Loss: 9.931727981893346e-05\n",
      "Epoch 1747, Loss: 0.0005875016486243112, Final Batch Loss: 0.0005695547442883253\n",
      "Epoch 1748, Loss: 0.00034072376547555905, Final Batch Loss: 1.825317849579733e-05\n",
      "Epoch 1749, Loss: 0.0005444029438876896, Final Batch Loss: 0.0005308953113853931\n",
      "Epoch 1750, Loss: 0.0019100438221357763, Final Batch Loss: 0.0003364416188560426\n",
      "Epoch 1751, Loss: 5.552460424951278e-05, Final Batch Loss: 1.2048432836309075e-05\n",
      "Epoch 1752, Loss: 8.708111545274733e-05, Final Batch Loss: 9.306440006184857e-06\n",
      "Epoch 1753, Loss: 0.001842893565481063, Final Batch Loss: 8.230460662161931e-05\n",
      "Epoch 1754, Loss: 0.00014742234623099648, Final Batch Loss: 1.5080366893016617e-06\n",
      "Epoch 1755, Loss: 0.0002676674848771654, Final Batch Loss: 4.208157042739913e-05\n",
      "Epoch 1756, Loss: 0.004483032946154708, Final Batch Loss: 0.00444105826318264\n",
      "Epoch 1757, Loss: 0.0019115920295007527, Final Batch Loss: 0.00019332690862938762\n",
      "Epoch 1758, Loss: 0.00010678893886506557, Final Batch Loss: 3.56756936525926e-05\n",
      "Epoch 1759, Loss: 1.2843705235354719e-05, Final Batch Loss: 3.5322257190273376e-06\n",
      "Epoch 1760, Loss: 0.01648212185182274, Final Batch Loss: 3.093462964898208e-06\n",
      "Epoch 1761, Loss: 0.0002963693950732704, Final Batch Loss: 3.178734550601803e-05\n",
      "Epoch 1762, Loss: 0.0012521123644546606, Final Batch Loss: 0.00011129354970762506\n",
      "Epoch 1763, Loss: 0.0002635090108924487, Final Batch Loss: 6.678417321381858e-06\n",
      "Epoch 1764, Loss: 0.0007705697353230789, Final Batch Loss: 0.0006144321523606777\n",
      "Epoch 1765, Loss: 0.00016020808379835216, Final Batch Loss: 1.5201711903500836e-05\n",
      "Epoch 1766, Loss: 6.941276660654694e-05, Final Batch Loss: 3.184712477377616e-05\n",
      "Epoch 1767, Loss: 0.00019306454123579897, Final Batch Loss: 3.8920599763514474e-05\n",
      "Epoch 1768, Loss: 0.0011135773675050586, Final Batch Loss: 0.0008669275557622313\n",
      "Epoch 1769, Loss: 0.0017103038699133322, Final Batch Loss: 0.00015406559396069497\n",
      "Epoch 1770, Loss: 0.00010784084224724211, Final Batch Loss: 3.269543594797142e-05\n",
      "Epoch 1771, Loss: 0.00013563072570832446, Final Batch Loss: 3.26658773701638e-05\n",
      "Epoch 1772, Loss: 0.000331092465785332, Final Batch Loss: 0.0001573653134983033\n",
      "Epoch 1773, Loss: 0.00023498428345192224, Final Batch Loss: 0.00010938414197880775\n",
      "Epoch 1774, Loss: 0.004206758632790297, Final Batch Loss: 0.00034897768637165427\n",
      "Epoch 1775, Loss: 0.000258068299444858, Final Batch Loss: 3.905071207555011e-05\n",
      "Epoch 1776, Loss: 0.00030647070525446907, Final Batch Loss: 2.2953237930778414e-05\n",
      "Epoch 1777, Loss: 0.0012757960575981997, Final Batch Loss: 0.00010672056669136509\n",
      "Epoch 1778, Loss: 0.00022601203818339854, Final Batch Loss: 0.00015487406926695257\n",
      "Epoch 1779, Loss: 0.0014927972806617618, Final Batch Loss: 0.0011540488339960575\n",
      "Epoch 1780, Loss: 0.0004918776685371995, Final Batch Loss: 0.0003687532152980566\n",
      "Epoch 1781, Loss: 0.0005366215118556283, Final Batch Loss: 0.00044094331678934395\n",
      "Epoch 1782, Loss: 0.0003775622317334637, Final Batch Loss: 0.00018324164557270706\n",
      "Epoch 1783, Loss: 0.0009903601312544197, Final Batch Loss: 0.000821454159449786\n",
      "Epoch 1784, Loss: 0.004711950779892504, Final Batch Loss: 0.0011472253827378154\n",
      "Epoch 1785, Loss: 0.00041626581514719874, Final Batch Loss: 0.00015013593656476587\n",
      "Epoch 1786, Loss: 0.001671061989327427, Final Batch Loss: 5.352441075956449e-05\n",
      "Epoch 1787, Loss: 7.931187428766862e-05, Final Batch Loss: 1.4863944670651108e-05\n",
      "Epoch 1788, Loss: 0.0024079851355054416, Final Batch Loss: 7.625841681146994e-05\n",
      "Epoch 1789, Loss: 0.0022142333327792585, Final Batch Loss: 0.00032835936872288585\n",
      "Epoch 1790, Loss: 0.004879646468907595, Final Batch Loss: 0.002812961582094431\n",
      "Epoch 1791, Loss: 0.00017838234271039255, Final Batch Loss: 4.0401053411187604e-05\n",
      "Epoch 1792, Loss: 0.0006912826502230018, Final Batch Loss: 0.0001684857124928385\n",
      "Epoch 1793, Loss: 0.0008993215415102895, Final Batch Loss: 3.546799052855931e-05\n",
      "Epoch 1794, Loss: 0.00010447037129779346, Final Batch Loss: 2.2494339646073058e-05\n",
      "Epoch 1795, Loss: 0.00035981972177978605, Final Batch Loss: 0.00022398395230993629\n",
      "Epoch 1796, Loss: 6.273172311921371e-05, Final Batch Loss: 1.4762254977540579e-05\n",
      "Epoch 1797, Loss: 0.0002420415257802233, Final Batch Loss: 0.00010661188571248204\n",
      "Epoch 1798, Loss: 9.36441429075785e-05, Final Batch Loss: 2.2599691874347627e-05\n",
      "Epoch 1799, Loss: 0.0004356102435849607, Final Batch Loss: 0.00018329313024878502\n",
      "Epoch 1800, Loss: 0.001090722714252479, Final Batch Loss: 8.129371963150334e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1801, Loss: 0.002881968001020141, Final Batch Loss: 0.002720058662816882\n",
      "Epoch 1802, Loss: 0.0012349308344710153, Final Batch Loss: 2.1302501409081742e-05\n",
      "Epoch 1803, Loss: 0.00030570007220376283, Final Batch Loss: 0.00015931665257085115\n",
      "Epoch 1804, Loss: 6.957467667234596e-05, Final Batch Loss: 4.33734203397762e-05\n",
      "Epoch 1805, Loss: 0.0004137670766795054, Final Batch Loss: 0.00014831173757556826\n",
      "Epoch 1806, Loss: 9.410511120222509e-05, Final Batch Loss: 6.893148383824155e-05\n",
      "Epoch 1807, Loss: 0.004513944732025266, Final Batch Loss: 0.002531450940296054\n",
      "Epoch 1808, Loss: 0.002778223282803083, Final Batch Loss: 0.002741019008681178\n",
      "Epoch 1809, Loss: 0.0003631268491517403, Final Batch Loss: 0.00035121681867167354\n",
      "Epoch 1810, Loss: 9.314219278167002e-05, Final Batch Loss: 4.464841549634002e-05\n",
      "Epoch 1811, Loss: 0.0028523064247565344, Final Batch Loss: 0.0026179964188486338\n",
      "Epoch 1812, Loss: 4.043308399559464e-05, Final Batch Loss: 2.516514723538421e-05\n",
      "Epoch 1813, Loss: 0.000998975852780859, Final Batch Loss: 1.8178279788116924e-05\n",
      "Epoch 1814, Loss: 0.0008929414052545326, Final Batch Loss: 1.7558080799062736e-05\n",
      "Epoch 1815, Loss: 0.00015838577382965013, Final Batch Loss: 2.1336098143365234e-05\n",
      "Epoch 1816, Loss: 0.0024555935815442353, Final Batch Loss: 0.002403431572020054\n",
      "Epoch 1817, Loss: 0.004582910216413438, Final Batch Loss: 0.00453694723546505\n",
      "Epoch 1818, Loss: 3.818655568466056e-05, Final Batch Loss: 4.703366357716732e-06\n",
      "Epoch 1819, Loss: 4.216440902382601e-05, Final Batch Loss: 7.886688763392158e-06\n",
      "Epoch 1820, Loss: 0.0011977355170529336, Final Batch Loss: 0.0007452932186424732\n",
      "Epoch 1821, Loss: 0.00010168188600800931, Final Batch Loss: 1.1887757864315063e-05\n",
      "Epoch 1822, Loss: 6.10619317740202e-05, Final Batch Loss: 3.9229096728377044e-05\n",
      "Epoch 1823, Loss: 0.0014375736354850233, Final Batch Loss: 0.0007420296315103769\n",
      "Epoch 1824, Loss: 0.0007918290357338265, Final Batch Loss: 0.00022582536621484905\n",
      "Epoch 1825, Loss: 7.135886835385463e-05, Final Batch Loss: 4.250033725838875e-06\n",
      "Epoch 1826, Loss: 0.00014486014333670028, Final Batch Loss: 9.572650742484257e-05\n",
      "Epoch 1827, Loss: 0.00012061905727023259, Final Batch Loss: 2.3391548893414438e-05\n",
      "Epoch 1828, Loss: 0.0020855920483882073, Final Batch Loss: 0.0020622138399630785\n",
      "Epoch 1829, Loss: 0.00032094988637254573, Final Batch Loss: 0.0002650985261425376\n",
      "Epoch 1830, Loss: 0.0005722539754060563, Final Batch Loss: 0.0005384903051890433\n",
      "Epoch 1831, Loss: 0.0034482565242797136, Final Batch Loss: 0.0005753268487751484\n",
      "Epoch 1832, Loss: 4.3728221498895437e-05, Final Batch Loss: 3.458214632701129e-05\n",
      "Epoch 1833, Loss: 0.00026182745614278247, Final Batch Loss: 0.0002543690206948668\n",
      "Epoch 1834, Loss: 5.320315540302545e-05, Final Batch Loss: 7.866008672863245e-06\n",
      "Epoch 1835, Loss: 0.00019183259792043827, Final Batch Loss: 0.00015124079072847962\n",
      "Epoch 1836, Loss: 0.0003447791896178387, Final Batch Loss: 3.3043492294382304e-05\n",
      "Epoch 1837, Loss: 9.968693484552205e-05, Final Batch Loss: 4.783743497682735e-05\n",
      "Epoch 1838, Loss: 0.002042739634816826, Final Batch Loss: 1.0672240932763088e-05\n",
      "Epoch 1839, Loss: 4.972584406459646e-05, Final Batch Loss: 2.296492084497004e-06\n",
      "Epoch 1840, Loss: 8.46192633616738e-05, Final Batch Loss: 3.616714820964262e-05\n",
      "Epoch 1841, Loss: 0.00013168676014174707, Final Batch Loss: 3.405016832402907e-05\n",
      "Epoch 1842, Loss: 0.00032776698026282247, Final Batch Loss: 0.0003064392367377877\n",
      "Epoch 1843, Loss: 0.0003880511321767699, Final Batch Loss: 0.00035506836138665676\n",
      "Epoch 1844, Loss: 9.514821067568846e-05, Final Batch Loss: 8.220773452194408e-05\n",
      "Epoch 1845, Loss: 0.0004471612464840291, Final Batch Loss: 0.00042057581595145166\n",
      "Epoch 1846, Loss: 0.0010224113921140088, Final Batch Loss: 1.1873429684783332e-05\n",
      "Epoch 1847, Loss: 0.0008127810301630234, Final Batch Loss: 6.3020138441061135e-06\n",
      "Epoch 1848, Loss: 7.160525456129108e-05, Final Batch Loss: 5.475304351421073e-05\n",
      "Epoch 1849, Loss: 0.0001309374965785537, Final Batch Loss: 0.00010668034519767389\n",
      "Epoch 1850, Loss: 4.796206940227421e-05, Final Batch Loss: 1.3524620044336189e-05\n",
      "Epoch 1851, Loss: 4.658599050344492e-05, Final Batch Loss: 3.7596566926367814e-06\n",
      "Epoch 1852, Loss: 0.00015951292698446196, Final Batch Loss: 0.000137083072331734\n",
      "Epoch 1853, Loss: 7.769849617034197e-05, Final Batch Loss: 4.6917972213122994e-05\n",
      "Epoch 1854, Loss: 0.00013148437938070856, Final Batch Loss: 9.454583778278902e-05\n",
      "Epoch 1855, Loss: 0.0005956535314908251, Final Batch Loss: 0.00037083050119690597\n",
      "Epoch 1856, Loss: 0.0003137525600322988, Final Batch Loss: 5.32430931343697e-06\n",
      "Epoch 1857, Loss: 0.00027394798962632194, Final Batch Loss: 0.00022242256090976298\n",
      "Epoch 1858, Loss: 8.426160093222279e-05, Final Batch Loss: 6.033098543412052e-05\n",
      "Epoch 1859, Loss: 4.455195721675409e-06, Final Batch Loss: 1.9353037714608945e-06\n",
      "Epoch 1860, Loss: 0.0003037541391677223, Final Batch Loss: 4.7538480430375785e-05\n",
      "Epoch 1861, Loss: 0.00185472809289422, Final Batch Loss: 0.0018493159441277385\n",
      "Epoch 1862, Loss: 5.3287869377527386e-05, Final Batch Loss: 2.7753882022807375e-05\n",
      "Epoch 1863, Loss: 0.00015056465190355084, Final Batch Loss: 4.608243671100354e-06\n",
      "Epoch 1864, Loss: 0.00014961900160415098, Final Batch Loss: 2.5512992579024285e-05\n",
      "Epoch 1865, Loss: 0.0009188355215883348, Final Batch Loss: 0.0008717129821889102\n",
      "Epoch 1866, Loss: 0.0025881583242153283, Final Batch Loss: 0.0025468887761235237\n",
      "Epoch 1867, Loss: 0.0019587300048442557, Final Batch Loss: 0.000232587059144862\n",
      "Epoch 1868, Loss: 0.00014068201562622562, Final Batch Loss: 0.00010366748028900474\n",
      "Epoch 1869, Loss: 0.0002953103776235366, Final Batch Loss: 3.920440576621331e-06\n",
      "Epoch 1870, Loss: 0.00010145379019377287, Final Batch Loss: 4.013336365460418e-06\n",
      "Epoch 1871, Loss: 0.0010311499081581132, Final Batch Loss: 0.0010020816698670387\n",
      "Epoch 1872, Loss: 1.6079934539448004e-05, Final Batch Loss: 7.896515853644814e-06\n",
      "Epoch 1873, Loss: 0.009303611219365848, Final Batch Loss: 0.009258171543478966\n",
      "Epoch 1874, Loss: 0.00019615298515418544, Final Batch Loss: 0.00015245912072714418\n",
      "Epoch 1875, Loss: 8.088192771538161e-05, Final Batch Loss: 2.6280169549863786e-05\n",
      "Epoch 1876, Loss: 0.0004304098474676721, Final Batch Loss: 0.00039415888022631407\n",
      "Epoch 1877, Loss: 3.5572790693549905e-05, Final Batch Loss: 2.487363417458255e-05\n",
      "Epoch 1878, Loss: 3.1686880902270786e-05, Final Batch Loss: 1.9772094674408436e-05\n",
      "Epoch 1879, Loss: 0.0027961807791143656, Final Batch Loss: 0.0014209122164174914\n",
      "Epoch 1880, Loss: 2.7818894977826858e-05, Final Batch Loss: 6.982165814406471e-06\n",
      "Epoch 1881, Loss: 6.209500224940712e-05, Final Batch Loss: 7.80361096985871e-06\n",
      "Epoch 1882, Loss: 2.7338823201716878e-05, Final Batch Loss: 1.346464705420658e-05\n",
      "Epoch 1883, Loss: 0.0005542280077861506, Final Batch Loss: 5.76277216168819e-06\n",
      "Epoch 1884, Loss: 6.535546060604247e-05, Final Batch Loss: 1.2559474953377503e-06\n",
      "Epoch 1885, Loss: 0.00015674638416385278, Final Batch Loss: 5.0279981223866343e-05\n",
      "Epoch 1886, Loss: 6.571458243342931e-05, Final Batch Loss: 6.040976586518809e-05\n",
      "Epoch 1887, Loss: 0.00018638546680449508, Final Batch Loss: 0.00015013180382084101\n",
      "Epoch 1888, Loss: 1.4112043118075235e-05, Final Batch Loss: 1.0297503649780992e-06\n",
      "Epoch 1889, Loss: 4.229592923365999e-05, Final Batch Loss: 2.6787914976011962e-05\n",
      "Epoch 1890, Loss: 2.5891431448599178e-05, Final Batch Loss: 3.99995712996315e-07\n",
      "Epoch 1891, Loss: 0.00011344548420311185, Final Batch Loss: 7.196872502390761e-06\n",
      "Epoch 1892, Loss: 8.853933832142502e-05, Final Batch Loss: 3.157115133944899e-05\n",
      "Epoch 1893, Loss: 0.00011614783579716459, Final Batch Loss: 6.253381434362382e-05\n",
      "Epoch 1894, Loss: 3.641200873971684e-05, Final Batch Loss: 8.055575563048478e-06\n",
      "Epoch 1895, Loss: 0.0006974975367484149, Final Batch Loss: 0.0006892241071909666\n",
      "Epoch 1896, Loss: 0.0002891817434829136, Final Batch Loss: 4.189614173810696e-06\n",
      "Epoch 1897, Loss: 8.835810149321333e-05, Final Batch Loss: 5.383384632295929e-05\n",
      "Epoch 1898, Loss: 3.6617187106458005e-05, Final Batch Loss: 7.034549525997136e-06\n",
      "Epoch 1899, Loss: 2.7166088329977356e-05, Final Batch Loss: 1.0928499250439927e-05\n",
      "Epoch 1900, Loss: 0.0005005073908250779, Final Batch Loss: 0.00045326913823373616\n",
      "Epoch 1901, Loss: 7.75874782448227e-05, Final Batch Loss: 7.422554335789755e-05\n",
      "Epoch 1902, Loss: 2.5315393941127695e-05, Final Batch Loss: 1.2700499610218685e-05\n",
      "Epoch 1903, Loss: 0.0006189809791976586, Final Batch Loss: 0.00010007091623265296\n",
      "Epoch 1904, Loss: 0.0016115760590764694, Final Batch Loss: 0.00011291621922282502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1905, Loss: 0.00011546335372258909, Final Batch Loss: 4.963749597663991e-05\n",
      "Epoch 1906, Loss: 0.001068855017365422, Final Batch Loss: 0.0009823690634220839\n",
      "Epoch 1907, Loss: 0.0003296470272289298, Final Batch Loss: 6.7376126935414504e-06\n",
      "Epoch 1908, Loss: 6.392371506080963e-05, Final Batch Loss: 2.113667142111808e-05\n",
      "Epoch 1909, Loss: 0.0032470537116751075, Final Batch Loss: 0.00026620703283697367\n",
      "Epoch 1910, Loss: 0.0004733907408080995, Final Batch Loss: 0.00012889722711406648\n",
      "Epoch 1911, Loss: 3.936800749215763e-05, Final Batch Loss: 1.71859901456628e-05\n",
      "Epoch 1912, Loss: 4.602444278134499e-05, Final Batch Loss: 1.927802622958552e-05\n",
      "Epoch 1913, Loss: 0.00033708522096276283, Final Batch Loss: 0.00024163817579392344\n",
      "Epoch 1914, Loss: 0.00027725154359359294, Final Batch Loss: 0.0001242381549673155\n",
      "Epoch 1915, Loss: 2.6208329245491768e-05, Final Batch Loss: 2.389068868069444e-05\n",
      "Epoch 1916, Loss: 0.0009626739656596328, Final Batch Loss: 3.647571247711312e-06\n",
      "Epoch 1917, Loss: 0.00014598122106690425, Final Batch Loss: 0.00013088095874991268\n",
      "Epoch 1918, Loss: 0.008297940933516657, Final Batch Loss: 0.008290482684969902\n",
      "Epoch 1919, Loss: 1.4775215277040843e-05, Final Batch Loss: 1.0272615327266976e-05\n",
      "Epoch 1920, Loss: 0.00011894226940967201, Final Batch Loss: 3.478184453342692e-06\n",
      "Epoch 1921, Loss: 0.0016579875704110236, Final Batch Loss: 1.0987026826114743e-06\n",
      "Epoch 1922, Loss: 9.282526434617466e-06, Final Batch Loss: 3.0094045087025734e-06\n",
      "Epoch 1923, Loss: 0.0022024673235137016, Final Batch Loss: 0.0001742060121614486\n",
      "Epoch 1924, Loss: 0.00015208324930426897, Final Batch Loss: 8.751628229219932e-06\n",
      "Epoch 1925, Loss: 7.96392801021284e-05, Final Batch Loss: 7.454657406924525e-06\n",
      "Epoch 1926, Loss: 0.0008083708639787801, Final Batch Loss: 1.7887036847241689e-06\n",
      "Epoch 1927, Loss: 1.7482449038652703e-05, Final Batch Loss: 9.471975317865144e-06\n",
      "Epoch 1928, Loss: 0.0011387875667878689, Final Batch Loss: 1.908712192744133e-06\n",
      "Epoch 1929, Loss: 4.7855282900854945e-05, Final Batch Loss: 4.139725933782756e-05\n",
      "Epoch 1930, Loss: 0.0007547367958977702, Final Batch Loss: 0.0007441714406013489\n",
      "Epoch 1931, Loss: 0.00047084482366699376, Final Batch Loss: 1.5582759260723833e-06\n",
      "Epoch 1932, Loss: 1.706078410279588e-05, Final Batch Loss: 2.651685008459026e-06\n",
      "Epoch 1933, Loss: 0.0001366130727546988, Final Batch Loss: 0.00012438863632269204\n",
      "Epoch 1934, Loss: 0.00034029567905236036, Final Batch Loss: 2.4267923436127603e-05\n",
      "Epoch 1935, Loss: 0.0008113625308396877, Final Batch Loss: 7.813979209458921e-06\n",
      "Epoch 1936, Loss: 0.0009099561466427986, Final Batch Loss: 4.338278449722566e-05\n",
      "Epoch 1937, Loss: 0.0001186244035125128, Final Batch Loss: 0.00011214270489290357\n",
      "Epoch 1938, Loss: 2.7709322239388712e-05, Final Batch Loss: 8.418408469879068e-06\n",
      "Epoch 1939, Loss: 1.7203029699430772e-05, Final Batch Loss: 2.822227429533086e-07\n",
      "Epoch 1940, Loss: 3.0001060622453224e-05, Final Batch Loss: 1.2693691132881213e-05\n",
      "Epoch 1941, Loss: 0.020480472678400474, Final Batch Loss: 0.020476842299103737\n",
      "Epoch 1942, Loss: 0.00016216758785958518, Final Batch Loss: 5.820020760438638e-06\n",
      "Epoch 1943, Loss: 5.882520144950831e-05, Final Batch Loss: 4.9159996706293896e-05\n",
      "Epoch 1944, Loss: 6.759972984582419e-05, Final Batch Loss: 8.47797218739288e-06\n",
      "Epoch 1945, Loss: 0.00013792677145829657, Final Batch Loss: 1.2615747436939273e-05\n",
      "Epoch 1946, Loss: 3.67875491065206e-05, Final Batch Loss: 3.0215505830710754e-06\n",
      "Epoch 1947, Loss: 4.7429537517018616e-05, Final Batch Loss: 2.549038254073821e-05\n",
      "Epoch 1948, Loss: 0.0005502181375049986, Final Batch Loss: 0.00011028757580788806\n",
      "Epoch 1949, Loss: 0.00020762954954989254, Final Batch Loss: 6.601432687602937e-06\n",
      "Epoch 1950, Loss: 1.081815958059451e-05, Final Batch Loss: 2.394845296294079e-06\n",
      "Epoch 1951, Loss: 0.0018434420999255963, Final Batch Loss: 0.0018218416953459382\n",
      "Epoch 1952, Loss: 0.00020493278736921638, Final Batch Loss: 0.00020345367374829948\n",
      "Epoch 1953, Loss: 0.00017907323035615264, Final Batch Loss: 1.3517415027308743e-05\n",
      "Epoch 1954, Loss: 1.5698649349360494e-05, Final Batch Loss: 3.892491349688498e-06\n",
      "Epoch 1955, Loss: 0.0010897713946178555, Final Batch Loss: 0.0009610296692699194\n",
      "Epoch 1956, Loss: 0.0007192083664904203, Final Batch Loss: 2.564318265285692e-06\n",
      "Epoch 1957, Loss: 4.100299975107191e-05, Final Batch Loss: 2.844416485459078e-05\n",
      "Epoch 1958, Loss: 0.0005871054581803037, Final Batch Loss: 0.0005789371207356453\n",
      "Epoch 1959, Loss: 4.2929499613819644e-05, Final Batch Loss: 1.0616447980282828e-05\n",
      "Epoch 1960, Loss: 9.23232983041089e-05, Final Batch Loss: 5.814195174025372e-05\n",
      "Epoch 1961, Loss: 0.00011279357750026975, Final Batch Loss: 8.401695595239289e-06\n",
      "Epoch 1962, Loss: 8.786554622020049e-05, Final Batch Loss: 2.3802328996680444e-06\n",
      "Epoch 1963, Loss: 8.402697494602762e-05, Final Batch Loss: 3.0371615139301866e-05\n",
      "Epoch 1964, Loss: 1.3292336006998084e-05, Final Batch Loss: 2.705708538996987e-06\n",
      "Epoch 1965, Loss: 0.00022402215836336836, Final Batch Loss: 0.00010188554733758792\n",
      "Epoch 1966, Loss: 8.563499523006612e-05, Final Batch Loss: 3.7388099372037686e-06\n",
      "Epoch 1967, Loss: 0.00365347020306217, Final Batch Loss: 1.9901208361261524e-05\n",
      "Epoch 1968, Loss: 1.1830959010694642e-05, Final Batch Loss: 4.067034751642495e-06\n",
      "Epoch 1969, Loss: 0.00025524673765175976, Final Batch Loss: 4.868007454206236e-05\n",
      "Epoch 1970, Loss: 0.000715141362434224, Final Batch Loss: 0.0007091420702636242\n",
      "Epoch 1971, Loss: 7.019870645308401e-05, Final Batch Loss: 3.929750164388679e-06\n",
      "Epoch 1972, Loss: 0.0002315641451104966, Final Batch Loss: 0.000230365403695032\n",
      "Epoch 1973, Loss: 7.903312871349044e-05, Final Batch Loss: 5.057703674538061e-05\n",
      "Epoch 1974, Loss: 0.0025458144409640227, Final Batch Loss: 4.2000730900326744e-05\n",
      "Epoch 1975, Loss: 4.166024791629752e-05, Final Batch Loss: 3.5619970731204376e-05\n",
      "Epoch 1976, Loss: 0.0012052365291310707, Final Batch Loss: 0.0011973308864980936\n",
      "Epoch 1977, Loss: 0.00010202776593359886, Final Batch Loss: 2.9837128749932162e-06\n",
      "Epoch 1978, Loss: 6.227359517652076e-05, Final Batch Loss: 2.643579682626296e-05\n",
      "Epoch 1979, Loss: 5.620655974780675e-05, Final Batch Loss: 3.384064257261343e-05\n",
      "Epoch 1980, Loss: 7.954313605296193e-05, Final Batch Loss: 9.647587830841076e-06\n",
      "Epoch 1981, Loss: 4.0829220324667403e-05, Final Batch Loss: 3.606374593800865e-05\n",
      "Epoch 1982, Loss: 0.00019984621030744165, Final Batch Loss: 3.360463597346097e-05\n",
      "Epoch 1983, Loss: 9.32495495362673e-05, Final Batch Loss: 7.779052248224616e-05\n",
      "Epoch 1984, Loss: 0.003447663795668632, Final Batch Loss: 0.003376615233719349\n",
      "Epoch 1985, Loss: 0.001833882382925367, Final Batch Loss: 0.0017774535808712244\n",
      "Epoch 1986, Loss: 8.066753798630089e-05, Final Batch Loss: 8.6811269284226e-06\n",
      "Epoch 1987, Loss: 2.7433880632088403e-05, Final Batch Loss: 1.059212763721007e-06\n",
      "Epoch 1988, Loss: 0.0014665706621599384, Final Batch Loss: 0.0014020567759871483\n",
      "Epoch 1989, Loss: 0.001245895226020366, Final Batch Loss: 6.269721779972315e-06\n",
      "Epoch 1990, Loss: 8.803315358818509e-05, Final Batch Loss: 8.520895062247291e-05\n",
      "Epoch 1991, Loss: 0.0007822956467862241, Final Batch Loss: 4.6289169404190034e-05\n",
      "Epoch 1992, Loss: 0.0008767195831751451, Final Batch Loss: 0.0006999180186539888\n",
      "Epoch 1993, Loss: 7.069391472214193e-05, Final Batch Loss: 6.835519889136776e-05\n",
      "Epoch 1994, Loss: 1.784024050266453e-05, Final Batch Loss: 1.6369735021726228e-05\n",
      "Epoch 1995, Loss: 1.5222996808006428e-05, Final Batch Loss: 1.4068137716094498e-05\n",
      "Epoch 1996, Loss: 0.00010659049075911753, Final Batch Loss: 3.403124355827458e-05\n",
      "Epoch 1997, Loss: 6.187396866152994e-05, Final Batch Loss: 9.428295015823096e-06\n",
      "Epoch 1998, Loss: 0.0013837740407325327, Final Batch Loss: 0.0012974980054423213\n",
      "Epoch 1999, Loss: 0.0006667063289569342, Final Batch Loss: 2.27705550059909e-06\n",
      "Epoch 2000, Loss: 2.7713643248716835e-05, Final Batch Loss: 1.8760190869215876e-05\n",
      "Epoch 2001, Loss: 0.00019469000494609645, Final Batch Loss: 2.6963282380165765e-06\n",
      "Epoch 2002, Loss: 2.5161702069453895e-05, Final Batch Loss: 1.4179686331772245e-05\n",
      "Epoch 2003, Loss: 0.0019559963839128613, Final Batch Loss: 0.0016258935211226344\n",
      "Epoch 2004, Loss: 1.5908831755950814e-05, Final Batch Loss: 1.2616657841135748e-05\n",
      "Epoch 2005, Loss: 0.000109897675429238, Final Batch Loss: 7.89395926403813e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2006, Loss: 0.000795025108345726, Final Batch Loss: 0.000787389581091702\n",
      "Epoch 2007, Loss: 0.0003903662509401329, Final Batch Loss: 0.00027449915069155395\n",
      "Epoch 2008, Loss: 0.0011207969509996474, Final Batch Loss: 0.0006484314217232168\n",
      "Epoch 2009, Loss: 2.249027329526143e-05, Final Batch Loss: 6.960840437386651e-06\n",
      "Epoch 2010, Loss: 0.0017868199647637084, Final Batch Loss: 0.0017408066196367145\n",
      "Epoch 2011, Loss: 0.001979780214242055, Final Batch Loss: 0.0019584596157073975\n",
      "Epoch 2012, Loss: 1.7023996406351216e-05, Final Batch Loss: 9.200363820127677e-06\n",
      "Epoch 2013, Loss: 0.0009007479056890588, Final Batch Loss: 0.0008447626023553312\n",
      "Epoch 2014, Loss: 9.078752282221103e-05, Final Batch Loss: 8.30772623885423e-05\n",
      "Epoch 2015, Loss: 3.925141118088504e-05, Final Batch Loss: 3.7805682950420305e-05\n",
      "Epoch 2016, Loss: 0.00017386357922077877, Final Batch Loss: 0.00016799372679088265\n",
      "Epoch 2017, Loss: 0.0014678300667583244, Final Batch Loss: 0.0014387049013748765\n",
      "Epoch 2018, Loss: 4.157876355748158e-05, Final Batch Loss: 1.306028752878774e-05\n",
      "Epoch 2019, Loss: 0.0003730980279215146, Final Batch Loss: 0.00036440358962863684\n",
      "Epoch 2020, Loss: 3.0125736884656362e-05, Final Batch Loss: 2.6036756025860086e-05\n",
      "Epoch 2021, Loss: 1.9605860870797187e-05, Final Batch Loss: 1.0487276085768826e-05\n",
      "Epoch 2022, Loss: 0.0004898928891634569, Final Batch Loss: 0.00032875160104595125\n",
      "Epoch 2023, Loss: 6.48706318315817e-05, Final Batch Loss: 3.9380054658977315e-05\n",
      "Epoch 2024, Loss: 2.7285323085379787e-05, Final Batch Loss: 6.367385140038095e-06\n",
      "Epoch 2025, Loss: 3.4779190173139796e-05, Final Batch Loss: 9.56296753429342e-06\n",
      "Epoch 2026, Loss: 2.5459149583184626e-05, Final Batch Loss: 1.1583080777199939e-05\n",
      "Epoch 2027, Loss: 2.2949500362301478e-05, Final Batch Loss: 2.722954832279356e-06\n",
      "Epoch 2028, Loss: 0.0013755495638179127, Final Batch Loss: 0.0013645776780322194\n",
      "Epoch 2029, Loss: 1.682543057768271e-06, Final Batch Loss: 3.97120089701275e-07\n",
      "Epoch 2030, Loss: 6.572240999958012e-05, Final Batch Loss: 2.7440948542789556e-05\n",
      "Epoch 2031, Loss: 0.0005420925899670692, Final Batch Loss: 0.0005323915393091738\n",
      "Epoch 2032, Loss: 0.00017464630440144902, Final Batch Loss: 6.987051506257558e-07\n",
      "Epoch 2033, Loss: 0.0007037580982114378, Final Batch Loss: 0.0007025021477602422\n",
      "Epoch 2034, Loss: 0.008881503538873403, Final Batch Loss: 0.00888051651418209\n",
      "Epoch 2035, Loss: 0.001021885402906264, Final Batch Loss: 0.0010192078771069646\n",
      "Epoch 2036, Loss: 0.0005017086706402551, Final Batch Loss: 0.0005004574777558446\n",
      "Epoch 2037, Loss: 4.168518353253603e-05, Final Batch Loss: 2.202821269747801e-05\n",
      "Epoch 2038, Loss: 0.027177591808140278, Final Batch Loss: 0.003452482633292675\n",
      "Epoch 2039, Loss: 2.5866495434456738e-05, Final Batch Loss: 4.825331870961236e-06\n",
      "Epoch 2040, Loss: 1.2005903272438445e-05, Final Batch Loss: 1.1263962733210064e-05\n",
      "Epoch 2041, Loss: 0.0010447087197462679, Final Batch Loss: 0.001036975416354835\n",
      "Epoch 2042, Loss: 0.001202558385557495, Final Batch Loss: 4.1125211282633245e-05\n",
      "Epoch 2043, Loss: 4.789716240338748e-05, Final Batch Loss: 1.5076296222105157e-05\n",
      "Epoch 2044, Loss: 4.2628351593521074e-05, Final Batch Loss: 3.3534417980263242e-06\n",
      "Epoch 2045, Loss: 0.00011854251943077543, Final Batch Loss: 0.00011241975880693644\n",
      "Epoch 2046, Loss: 2.8082453809474828e-05, Final Batch Loss: 2.4994400519062765e-05\n",
      "Epoch 2047, Loss: 1.4370343251357554e-05, Final Batch Loss: 9.693599167803768e-06\n",
      "Epoch 2048, Loss: 0.0004325013833295088, Final Batch Loss: 3.1105806556297466e-05\n",
      "Epoch 2049, Loss: 1.5912282265162503e-06, Final Batch Loss: 3.777328743126418e-07\n",
      "Epoch 2050, Loss: 0.0009766011514784623, Final Batch Loss: 1.0929668405879056e-06\n",
      "Epoch 2051, Loss: 0.004684133235059562, Final Batch Loss: 0.0046564266085624695\n",
      "Epoch 2052, Loss: 4.482454642129596e-05, Final Batch Loss: 3.8639846025034785e-05\n",
      "Epoch 2053, Loss: 0.0002425648272037506, Final Batch Loss: 0.0001805126667022705\n",
      "Epoch 2054, Loss: 0.0007894369746281882, Final Batch Loss: 0.0007784510380588472\n",
      "Epoch 2055, Loss: 0.0012926850623102837, Final Batch Loss: 4.2656125742723816e-07\n",
      "Epoch 2056, Loss: 0.0006332294942694716, Final Batch Loss: 0.0006027098861522973\n",
      "Epoch 2057, Loss: 6.827213314863911e-05, Final Batch Loss: 3.5483355986798415e-06\n",
      "Epoch 2058, Loss: 0.000145713674100989, Final Batch Loss: 0.00013470427074935287\n",
      "Epoch 2059, Loss: 0.00011054975948354695, Final Batch Loss: 2.118280463037081e-06\n",
      "Epoch 2060, Loss: 1.6485686728628934e-05, Final Batch Loss: 1.4129299415799323e-05\n",
      "Epoch 2061, Loss: 6.97213229159388e-05, Final Batch Loss: 2.7430335194367217e-06\n",
      "Epoch 2062, Loss: 0.0013524190781026846, Final Batch Loss: 0.0013432649429887533\n",
      "Epoch 2063, Loss: 1.3560418210545322e-05, Final Batch Loss: 6.629094968957361e-06\n",
      "Epoch 2064, Loss: 0.0012252601172804134, Final Batch Loss: 0.0012103874469175935\n",
      "Epoch 2065, Loss: 4.103420906176325e-05, Final Batch Loss: 1.7195317923324183e-05\n",
      "Epoch 2066, Loss: 5.244104613666423e-05, Final Batch Loss: 2.359145219088532e-05\n",
      "Epoch 2067, Loss: 0.00019443719065748155, Final Batch Loss: 0.0001121340537793003\n",
      "Epoch 2068, Loss: 0.0007947722970129689, Final Batch Loss: 0.0007762677269056439\n",
      "Epoch 2069, Loss: 0.00010137014214706142, Final Batch Loss: 9.797960956348106e-05\n",
      "Epoch 2070, Loss: 0.000541472900295048, Final Batch Loss: 0.000515508174430579\n",
      "Epoch 2071, Loss: 0.00021271810965117766, Final Batch Loss: 0.00020287028746679425\n",
      "Epoch 2072, Loss: 0.00010991226372425444, Final Batch Loss: 6.539288733620197e-05\n",
      "Epoch 2073, Loss: 4.9283497901342344e-05, Final Batch Loss: 1.2433257325028535e-05\n",
      "Epoch 2074, Loss: 6.075361125112977e-05, Final Batch Loss: 9.825804227148183e-06\n",
      "Epoch 2075, Loss: 6.378309808496851e-05, Final Batch Loss: 2.1856752937310375e-05\n",
      "Epoch 2076, Loss: 0.005025626545830164, Final Batch Loss: 4.259908018866554e-05\n",
      "Epoch 2077, Loss: 2.8772713221769664e-05, Final Batch Loss: 2.5584797185729258e-05\n",
      "Epoch 2078, Loss: 0.00015603530755470274, Final Batch Loss: 3.910196937795263e-06\n",
      "Epoch 2079, Loss: 5.0892349008790916e-05, Final Batch Loss: 6.654941444139695e-06\n",
      "Epoch 2080, Loss: 0.00017241663954337128, Final Batch Loss: 4.003674621344544e-05\n",
      "Epoch 2081, Loss: 0.003877344075590372, Final Batch Loss: 0.0019967015832662582\n",
      "Epoch 2082, Loss: 5.6387248150713276e-05, Final Batch Loss: 4.5813914766767994e-05\n",
      "Epoch 2083, Loss: 5.0273672599132624e-05, Final Batch Loss: 4.983117105439305e-05\n",
      "Epoch 2084, Loss: 0.000286399637843715, Final Batch Loss: 0.00028033892158418894\n",
      "Epoch 2085, Loss: 3.0331984817166813e-05, Final Batch Loss: 1.42154185596155e-05\n",
      "Epoch 2086, Loss: 0.0002062528656097129, Final Batch Loss: 0.00018653186270967126\n",
      "Epoch 2087, Loss: 0.001229052766575478, Final Batch Loss: 0.00017088056483771652\n",
      "Epoch 2088, Loss: 1.4764264733457821e-05, Final Batch Loss: 2.2797355541115394e-06\n",
      "Epoch 2089, Loss: 4.078964707332489e-06, Final Batch Loss: 5.845414534633164e-07\n",
      "Epoch 2090, Loss: 6.511394667541026e-05, Final Batch Loss: 3.3856899790407624e-06\n",
      "Epoch 2091, Loss: 0.001929375637701014, Final Batch Loss: 4.402018748805858e-05\n",
      "Epoch 2092, Loss: 0.00012187307402200531, Final Batch Loss: 9.465426410315558e-05\n",
      "Epoch 2093, Loss: 0.0007748761818220373, Final Batch Loss: 3.786375964409672e-05\n",
      "Epoch 2094, Loss: 4.05279772621725e-05, Final Batch Loss: 3.694736005854793e-05\n",
      "Epoch 2095, Loss: 0.0031543803866043163, Final Batch Loss: 4.63300375486142e-06\n",
      "Epoch 2096, Loss: 4.5785864585923264e-05, Final Batch Loss: 1.502964096289361e-06\n",
      "Epoch 2097, Loss: 8.004741357581224e-05, Final Batch Loss: 7.133802137104794e-05\n",
      "Epoch 2098, Loss: 1.6741514400564483e-05, Final Batch Loss: 2.0027225673402427e-06\n",
      "Epoch 2099, Loss: 9.891494028124725e-05, Final Batch Loss: 8.422852260991931e-05\n",
      "Epoch 2100, Loss: 5.9659765611286275e-05, Final Batch Loss: 2.8801552616641857e-05\n",
      "Epoch 2101, Loss: 1.7713824945531087e-05, Final Batch Loss: 1.0861946066142991e-05\n",
      "Epoch 2102, Loss: 8.358808008779306e-05, Final Batch Loss: 6.922943430254236e-05\n",
      "Epoch 2103, Loss: 0.046634617747258744, Final Batch Loss: 0.046624667942523956\n",
      "Epoch 2104, Loss: 0.000302053929772228, Final Batch Loss: 0.00015792640624567866\n",
      "Epoch 2105, Loss: 7.098066635080613e-05, Final Batch Loss: 2.3660835722694173e-05\n",
      "Epoch 2106, Loss: 0.001391689780575689, Final Batch Loss: 9.583369683241472e-05\n",
      "Epoch 2107, Loss: 0.00013680047777597792, Final Batch Loss: 5.902036718907766e-05\n",
      "Epoch 2108, Loss: 0.0004087801426067017, Final Batch Loss: 7.233939686557278e-05\n",
      "Epoch 2109, Loss: 4.663390700443415e-05, Final Batch Loss: 3.5648979974212125e-05\n",
      "Epoch 2110, Loss: 0.00044002327194903046, Final Batch Loss: 0.0002902516280300915\n",
      "Epoch 2111, Loss: 0.015692029512138106, Final Batch Loss: 0.015668118372559547\n",
      "Epoch 2112, Loss: 0.0005537674805964343, Final Batch Loss: 3.9181548345368356e-05\n",
      "Epoch 2113, Loss: 2.0269269953132607e-05, Final Batch Loss: 6.544002644659486e-06\n",
      "Epoch 2114, Loss: 0.00027585617499426007, Final Batch Loss: 7.562206883449107e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2115, Loss: 8.659066588734277e-05, Final Batch Loss: 5.949068145127967e-05\n",
      "Epoch 2116, Loss: 7.721546535321977e-05, Final Batch Loss: 2.4234379452536814e-05\n",
      "Epoch 2117, Loss: 3.787950845435262e-05, Final Batch Loss: 1.5424247976625338e-05\n",
      "Epoch 2118, Loss: 0.00014587973782909103, Final Batch Loss: 4.3271731556160375e-05\n",
      "Epoch 2119, Loss: 0.00010437088894832414, Final Batch Loss: 9.202723595080897e-05\n",
      "Epoch 2120, Loss: 0.0019606804353315965, Final Batch Loss: 0.0019526024116203189\n",
      "Epoch 2121, Loss: 2.2251474774748203e-05, Final Batch Loss: 3.5574587400333257e-06\n",
      "Epoch 2122, Loss: 0.0012656931874062138, Final Batch Loss: 2.3538821096735774e-06\n",
      "Epoch 2123, Loss: 3.5154160286765546e-05, Final Batch Loss: 1.936087937792763e-05\n",
      "Epoch 2124, Loss: 0.0030351097811944783, Final Batch Loss: 0.0027103712782263756\n",
      "Epoch 2125, Loss: 0.0013084145684842952, Final Batch Loss: 0.00127679412253201\n",
      "Epoch 2126, Loss: 1.893330136226723e-05, Final Batch Loss: 1.866345883172471e-06\n",
      "Epoch 2127, Loss: 0.0001509844933025306, Final Batch Loss: 0.000127135164802894\n",
      "Epoch 2128, Loss: 0.00028742624272126704, Final Batch Loss: 8.318906475324184e-05\n",
      "Epoch 2129, Loss: 5.2060638154216576e-05, Final Batch Loss: 4.5417338697006926e-05\n",
      "Epoch 2130, Loss: 0.0008200455704354681, Final Batch Loss: 0.0006988688837736845\n",
      "Epoch 2131, Loss: 5.020550270273816e-05, Final Batch Loss: 1.8007214748649858e-05\n",
      "Epoch 2132, Loss: 0.0006397049583029002, Final Batch Loss: 0.0001471348514314741\n",
      "Epoch 2133, Loss: 0.002546358882682398, Final Batch Loss: 0.0025261302944272757\n",
      "Epoch 2134, Loss: 0.00022301790886558592, Final Batch Loss: 0.0001491504954174161\n",
      "Epoch 2135, Loss: 0.001945756090208306, Final Batch Loss: 0.0019204301061108708\n",
      "Epoch 2136, Loss: 3.805261439993046e-05, Final Batch Loss: 1.687448275333736e-05\n",
      "Epoch 2137, Loss: 0.0001974917067855131, Final Batch Loss: 0.000190152510185726\n",
      "Epoch 2138, Loss: 0.001387027765304083, Final Batch Loss: 0.0013368533691391349\n",
      "Epoch 2139, Loss: 0.000998627074295655, Final Batch Loss: 0.0009316871874034405\n",
      "Epoch 2140, Loss: 3.1304014555644244e-05, Final Batch Loss: 1.3555521945818327e-05\n",
      "Epoch 2141, Loss: 0.0001732477503537666, Final Batch Loss: 0.00016464668442495167\n",
      "Epoch 2142, Loss: 0.0019389182280065143, Final Batch Loss: 1.7212887541973032e-06\n",
      "Epoch 2143, Loss: 2.3462313947675284e-05, Final Batch Loss: 7.992547580215614e-06\n",
      "Epoch 2144, Loss: 4.3583331716945395e-05, Final Batch Loss: 2.1627989553962834e-05\n",
      "Epoch 2145, Loss: 0.0004582333604048472, Final Batch Loss: 1.6577960195718333e-05\n",
      "Epoch 2146, Loss: 0.0004493711940085632, Final Batch Loss: 0.0004436494782567024\n",
      "Epoch 2147, Loss: 0.00019111310393782333, Final Batch Loss: 6.825870514148846e-05\n",
      "Epoch 2148, Loss: 2.537971067795297e-05, Final Batch Loss: 1.0373093573434744e-05\n",
      "Epoch 2149, Loss: 0.000360471831754694, Final Batch Loss: 0.0003557691816240549\n",
      "Epoch 2150, Loss: 0.00016740969294914976, Final Batch Loss: 6.656471668975428e-05\n",
      "Epoch 2151, Loss: 7.620168025823659e-05, Final Batch Loss: 7.033640576992184e-05\n",
      "Epoch 2152, Loss: 6.157936832096311e-05, Final Batch Loss: 5.257377324596746e-06\n",
      "Epoch 2153, Loss: 7.590181894556736e-06, Final Batch Loss: 2.9582799925265135e-06\n",
      "Epoch 2154, Loss: 1.8649855519470293e-05, Final Batch Loss: 9.464542927162256e-06\n",
      "Epoch 2155, Loss: 5.8591833294485696e-05, Final Batch Loss: 2.04765146918362e-05\n",
      "Epoch 2156, Loss: 0.00011580133286770433, Final Batch Loss: 0.00010239311814075336\n",
      "Epoch 2157, Loss: 0.0004384568644582032, Final Batch Loss: 5.314111604093341e-07\n",
      "Epoch 2158, Loss: 8.016343781491742e-05, Final Batch Loss: 1.62312644533813e-05\n",
      "Epoch 2159, Loss: 0.0009149096658802591, Final Batch Loss: 0.0008810351137071848\n",
      "Epoch 2160, Loss: 8.67192929945304e-05, Final Batch Loss: 1.0601425856293645e-05\n",
      "Epoch 2161, Loss: 1.2991653647986823e-05, Final Batch Loss: 3.757892272915342e-06\n",
      "Epoch 2162, Loss: 2.0022050193801988e-05, Final Batch Loss: 1.1453832485130988e-05\n",
      "Epoch 2163, Loss: 0.00011369798994564917, Final Batch Loss: 1.824366881919559e-05\n",
      "Epoch 2164, Loss: 9.212386612489354e-05, Final Batch Loss: 9.128893725574017e-05\n",
      "Epoch 2165, Loss: 4.828891178476624e-05, Final Batch Loss: 1.959362271009013e-05\n",
      "Epoch 2166, Loss: 0.0001782504841685295, Final Batch Loss: 0.00014476760406978428\n",
      "Epoch 2167, Loss: 0.00016078118369478034, Final Batch Loss: 0.00014641339657828212\n",
      "Epoch 2168, Loss: 0.0034437405338394456, Final Batch Loss: 3.781797568080947e-05\n",
      "Epoch 2169, Loss: 0.0007943595173856011, Final Batch Loss: 2.1540536181419156e-05\n",
      "Epoch 2170, Loss: 0.0006559363318956457, Final Batch Loss: 9.7735806775745e-05\n",
      "Epoch 2171, Loss: 0.00018734049808699638, Final Batch Loss: 8.596508268965408e-05\n",
      "Epoch 2172, Loss: 0.0005590594519162551, Final Batch Loss: 0.00045513585791923106\n",
      "Epoch 2173, Loss: 0.00017670220404397696, Final Batch Loss: 2.3475135094486177e-05\n",
      "Epoch 2174, Loss: 4.3729169192374684e-05, Final Batch Loss: 9.503148248768412e-06\n",
      "Epoch 2175, Loss: 0.00022875503782415763, Final Batch Loss: 0.00010645931615727022\n",
      "Epoch 2176, Loss: 0.0006039948057150468, Final Batch Loss: 9.455780673306435e-05\n",
      "Epoch 2177, Loss: 1.0323131959921739e-05, Final Batch Loss: 1.4412349855774664e-06\n",
      "Epoch 2178, Loss: 1.4593520972994156e-05, Final Batch Loss: 3.1696226869826205e-06\n",
      "Epoch 2179, Loss: 0.00010798339280881919, Final Batch Loss: 4.4246120523894206e-05\n",
      "Epoch 2180, Loss: 0.00010526155801926507, Final Batch Loss: 3.0747642085771076e-06\n",
      "Epoch 2181, Loss: 0.0002798536152113229, Final Batch Loss: 0.00021643647050950676\n",
      "Epoch 2182, Loss: 9.143265560851432e-05, Final Batch Loss: 2.1117248252267018e-05\n",
      "Epoch 2183, Loss: 0.0001218242277900572, Final Batch Loss: 8.669859198562335e-06\n",
      "Epoch 2184, Loss: 0.005975565065455157, Final Batch Loss: 2.4090644728858024e-05\n",
      "Epoch 2185, Loss: 1.7591589426046994e-05, Final Batch Loss: 1.2725023452730966e-06\n",
      "Epoch 2186, Loss: 0.003216188033547951, Final Batch Loss: 2.9465514671755955e-05\n",
      "Epoch 2187, Loss: 7.581426280012238e-05, Final Batch Loss: 7.342262961174129e-06\n",
      "Epoch 2188, Loss: 3.2487754651810974e-05, Final Batch Loss: 9.903831596602686e-06\n",
      "Epoch 2189, Loss: 4.0365365293837385e-05, Final Batch Loss: 3.541090336511843e-05\n",
      "Epoch 2190, Loss: 0.0011782868532463908, Final Batch Loss: 0.00010015442967414856\n",
      "Epoch 2191, Loss: 1.1951838928325742e-05, Final Batch Loss: 1.2014014600936207e-06\n",
      "Epoch 2192, Loss: 8.7803331325631e-05, Final Batch Loss: 2.0242948721715948e-06\n",
      "Epoch 2193, Loss: 9.26497159525752e-06, Final Batch Loss: 6.238029982341686e-06\n",
      "Epoch 2194, Loss: 6.0263550039962865e-05, Final Batch Loss: 4.8796275223139673e-05\n",
      "Epoch 2195, Loss: 0.00012139641330577433, Final Batch Loss: 8.564745803596452e-05\n",
      "Epoch 2196, Loss: 0.0002800803531499696, Final Batch Loss: 7.2328739406657405e-06\n",
      "Epoch 2197, Loss: 0.005935945575402002, Final Batch Loss: 0.005917094647884369\n",
      "Epoch 2198, Loss: 0.00010917790086750756, Final Batch Loss: 5.113189672556473e-06\n",
      "Epoch 2199, Loss: 0.00012573180538311135, Final Batch Loss: 0.0001043239826685749\n",
      "Epoch 2200, Loss: 7.298948531797578e-06, Final Batch Loss: 3.612138073094684e-07\n",
      "Epoch 2201, Loss: 6.992273938521976e-06, Final Batch Loss: 4.5924839469080325e-06\n",
      "Epoch 2202, Loss: 2.8666277103184257e-05, Final Batch Loss: 1.6240433978964575e-05\n",
      "Epoch 2203, Loss: 0.00010149881109100534, Final Batch Loss: 5.640114068228286e-06\n",
      "Epoch 2204, Loss: 0.0008328709834586334, Final Batch Loss: 1.5123248431336833e-06\n",
      "Epoch 2205, Loss: 0.0006569746747118188, Final Batch Loss: 1.5655297829653136e-05\n",
      "Epoch 2206, Loss: 5.108416189614218e-05, Final Batch Loss: 7.462132998625748e-06\n",
      "Epoch 2207, Loss: 0.0007145647327888582, Final Batch Loss: 2.887369646487059e-06\n",
      "Epoch 2208, Loss: 1.1614962204475887e-05, Final Batch Loss: 4.312397777539445e-06\n",
      "Epoch 2209, Loss: 0.0003140739972877782, Final Batch Loss: 0.0003019269206561148\n",
      "Epoch 2210, Loss: 7.477800409105839e-06, Final Batch Loss: 4.804391664947616e-06\n",
      "Epoch 2211, Loss: 0.00013965333346277475, Final Batch Loss: 0.00013489161210600287\n",
      "Epoch 2212, Loss: 0.0006417549166144454, Final Batch Loss: 2.697081981750671e-06\n",
      "Epoch 2213, Loss: 6.0161782130307984e-05, Final Batch Loss: 5.2329294703667983e-05\n",
      "Epoch 2214, Loss: 0.0001609470673429314, Final Batch Loss: 3.500051752780564e-05\n",
      "Epoch 2215, Loss: 0.0003284710655862, Final Batch Loss: 0.0002688803360797465\n",
      "Epoch 2216, Loss: 0.003098128004012324, Final Batch Loss: 0.003094606101512909\n",
      "Epoch 2217, Loss: 0.000845675668642798, Final Batch Loss: 4.098655153939035e-06\n",
      "Epoch 2218, Loss: 9.601117380952928e-05, Final Batch Loss: 1.7706517610349692e-05\n",
      "Epoch 2219, Loss: 0.0006479322383938779, Final Batch Loss: 1.5065944580783253e-06\n",
      "Epoch 2220, Loss: 8.980622078524902e-05, Final Batch Loss: 1.8159720639232546e-05\n",
      "Epoch 2221, Loss: 0.00018110626842826605, Final Batch Loss: 0.00014267615915741771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2222, Loss: 9.394299740961287e-05, Final Batch Loss: 7.2170169005403295e-06\n",
      "Epoch 2223, Loss: 0.0001833820715546608, Final Batch Loss: 0.00013720216520596296\n",
      "Epoch 2224, Loss: 0.01935478304676508, Final Batch Loss: 6.977516932238359e-06\n",
      "Epoch 2225, Loss: 0.00018521145830163732, Final Batch Loss: 9.247967682313174e-06\n",
      "Epoch 2226, Loss: 0.00016118981193358195, Final Batch Loss: 6.331647909973981e-06\n",
      "Epoch 2227, Loss: 0.0003684821449496667, Final Batch Loss: 1.0682942047424149e-05\n",
      "Epoch 2228, Loss: 8.585108662373386e-05, Final Batch Loss: 4.848455864703283e-05\n",
      "Epoch 2229, Loss: 0.00025140350408037193, Final Batch Loss: 2.6015452021965757e-05\n",
      "Epoch 2230, Loss: 0.0062720609403186245, Final Batch Loss: 0.006247684359550476\n",
      "Epoch 2231, Loss: 0.0001828565618779976, Final Batch Loss: 1.884294397314079e-05\n",
      "Epoch 2232, Loss: 0.00037385990799521096, Final Batch Loss: 3.7752168282167986e-05\n",
      "Epoch 2233, Loss: 0.00024952899366326164, Final Batch Loss: 0.0002365503169130534\n",
      "Epoch 2234, Loss: 0.00015671152141294442, Final Batch Loss: 3.1994972232496366e-05\n",
      "Epoch 2235, Loss: 0.00013445577133097686, Final Batch Loss: 3.726292561623268e-05\n",
      "Epoch 2236, Loss: 5.5847458497737534e-06, Final Batch Loss: 2.2196438749233494e-06\n",
      "Epoch 2237, Loss: 0.0018454557284712791, Final Batch Loss: 0.00028841232415288687\n",
      "Epoch 2238, Loss: 0.001153831894043833, Final Batch Loss: 3.0309311114251614e-06\n",
      "Epoch 2239, Loss: 5.402014267019695e-05, Final Batch Loss: 4.2225226934533566e-05\n",
      "Epoch 2240, Loss: 0.0001287090144614922, Final Batch Loss: 9.618643161957152e-06\n",
      "Epoch 2241, Loss: 0.002503389634512132, Final Batch Loss: 0.0024567516520619392\n",
      "Epoch 2242, Loss: 3.485278102743905e-05, Final Batch Loss: 2.5988432753365487e-05\n",
      "Epoch 2243, Loss: 0.009665201650932431, Final Batch Loss: 0.0020813390146940947\n",
      "Epoch 2244, Loss: 1.5008902892077458e-05, Final Batch Loss: 1.3573193427873775e-05\n",
      "Epoch 2245, Loss: 6.742584446328692e-05, Final Batch Loss: 4.3565687519731e-05\n",
      "Epoch 2246, Loss: 0.0009140705042227637, Final Batch Loss: 5.063273056293838e-05\n",
      "Epoch 2247, Loss: 0.00031937386893332587, Final Batch Loss: 6.2270141825138126e-06\n",
      "Epoch 2248, Loss: 0.00021121215831954032, Final Batch Loss: 8.710594556760043e-05\n",
      "Epoch 2249, Loss: 0.0001897915226436453, Final Batch Loss: 5.221694664214738e-06\n",
      "Epoch 2250, Loss: 2.2165838345244993e-05, Final Batch Loss: 6.818224392191041e-06\n",
      "Epoch 2251, Loss: 0.01211665803930373, Final Batch Loss: 0.012075529433786869\n",
      "Epoch 2252, Loss: 4.94432715640869e-05, Final Batch Loss: 2.1371100956457667e-05\n",
      "Epoch 2253, Loss: 0.00010186621511820704, Final Batch Loss: 2.8708855097647756e-05\n",
      "Epoch 2254, Loss: 0.0013899243513151305, Final Batch Loss: 2.383094579272438e-05\n",
      "Epoch 2255, Loss: 4.598520422405272e-05, Final Batch Loss: 4.464485391508788e-05\n",
      "Epoch 2256, Loss: 6.072245741961524e-05, Final Batch Loss: 4.004440415883437e-05\n",
      "Epoch 2257, Loss: 0.010935742175206542, Final Batch Loss: 0.002403051359578967\n",
      "Epoch 2258, Loss: 0.00014718957663717447, Final Batch Loss: 6.693730938422959e-06\n",
      "Epoch 2259, Loss: 0.002002521818212699, Final Batch Loss: 0.0019014276331290603\n",
      "Epoch 2260, Loss: 0.0003626102552516386, Final Batch Loss: 0.00011498104140628129\n",
      "Epoch 2261, Loss: 0.002290215838002041, Final Batch Loss: 0.00037712175981141627\n",
      "Epoch 2262, Loss: 7.004801409493666e-05, Final Batch Loss: 1.721846820146311e-05\n",
      "Epoch 2263, Loss: 2.6863992388825864e-05, Final Batch Loss: 1.804024213925004e-05\n",
      "Epoch 2264, Loss: 0.0005263274069875479, Final Batch Loss: 9.981656330637634e-05\n",
      "Epoch 2265, Loss: 0.003366440156241879, Final Batch Loss: 0.00043483576155267656\n",
      "Epoch 2266, Loss: 0.00013273268086777534, Final Batch Loss: 0.00011180347064509988\n",
      "Epoch 2267, Loss: 1.6478984434797894e-05, Final Batch Loss: 1.131244789576158e-05\n",
      "Epoch 2268, Loss: 2.27562422878691e-05, Final Batch Loss: 3.428088348300662e-06\n",
      "Epoch 2269, Loss: 3.0821722248219885e-05, Final Batch Loss: 1.8883523807744496e-05\n",
      "Epoch 2270, Loss: 0.0033608056728553493, Final Batch Loss: 5.274788782116957e-05\n",
      "Epoch 2271, Loss: 6.993799843257875e-06, Final Batch Loss: 4.064812856086064e-06\n",
      "Epoch 2272, Loss: 0.00027742904785554856, Final Batch Loss: 8.183233148884028e-05\n",
      "Epoch 2273, Loss: 0.001950819094417966, Final Batch Loss: 2.0146069800830446e-05\n",
      "Epoch 2274, Loss: 0.0007266831889864989, Final Batch Loss: 0.0006701255915686488\n",
      "Epoch 2275, Loss: 0.00014824007666902617, Final Batch Loss: 7.867696695029736e-05\n",
      "Epoch 2276, Loss: 0.0006102577426645439, Final Batch Loss: 4.3815885874209926e-05\n",
      "Epoch 2277, Loss: 0.00016868860029717325, Final Batch Loss: 0.00016400872846134007\n",
      "Epoch 2278, Loss: 0.0018061956579913385, Final Batch Loss: 0.0017504113493487239\n",
      "Epoch 2279, Loss: 4.378954145067837e-05, Final Batch Loss: 3.8949794543441385e-05\n",
      "Epoch 2280, Loss: 8.913018245948479e-05, Final Batch Loss: 3.3585529308766127e-06\n",
      "Epoch 2281, Loss: 3.5689459764398634e-05, Final Batch Loss: 2.2228152374736965e-05\n",
      "Epoch 2282, Loss: 6.314570600807201e-05, Final Batch Loss: 1.9557848645490594e-05\n",
      "Epoch 2283, Loss: 0.0006143581563264888, Final Batch Loss: 0.000609701732173562\n",
      "Epoch 2284, Loss: 0.0002524227456888184, Final Batch Loss: 1.757504651322961e-05\n",
      "Epoch 2285, Loss: 3.8967420096014393e-05, Final Batch Loss: 6.0567685977730434e-06\n",
      "Epoch 2286, Loss: 0.0008570727986807469, Final Batch Loss: 5.607793355011381e-05\n",
      "Epoch 2287, Loss: 0.00010465710147400387, Final Batch Loss: 6.932450196472928e-05\n",
      "Epoch 2288, Loss: 0.0002329205526621081, Final Batch Loss: 7.465344242518768e-05\n",
      "Epoch 2289, Loss: 0.003282722330368415, Final Batch Loss: 0.0032705022022128105\n",
      "Epoch 2290, Loss: 0.00010429786561871879, Final Batch Loss: 5.676222644979134e-05\n",
      "Epoch 2291, Loss: 0.00022076635650591925, Final Batch Loss: 0.00015960141899995506\n",
      "Epoch 2292, Loss: 2.2239574491322855e-05, Final Batch Loss: 1.933093471961911e-06\n",
      "Epoch 2293, Loss: 0.0004386046111903852, Final Batch Loss: 2.7583611881709658e-05\n",
      "Epoch 2294, Loss: 0.0010391616215201793, Final Batch Loss: 9.290683010476641e-06\n",
      "Epoch 2295, Loss: 9.092629989027046e-05, Final Batch Loss: 9.84301368589513e-06\n",
      "Epoch 2296, Loss: 5.155175722393324e-05, Final Batch Loss: 4.779910887009464e-05\n",
      "Epoch 2297, Loss: 7.696764168940717e-05, Final Batch Loss: 1.4776524949411396e-05\n",
      "Epoch 2298, Loss: 1.1836322300950997e-05, Final Batch Loss: 6.231353836483322e-06\n",
      "Epoch 2299, Loss: 0.00017803898663260043, Final Batch Loss: 0.00014757082681171596\n",
      "Epoch 2300, Loss: 9.245768160326406e-05, Final Batch Loss: 6.072993346606381e-05\n",
      "Epoch 2301, Loss: 0.0005738106556236744, Final Batch Loss: 0.00028582598315551877\n",
      "Epoch 2302, Loss: 8.079278268269263e-05, Final Batch Loss: 5.3818428568774834e-05\n",
      "Epoch 2303, Loss: 0.0001038407453961554, Final Batch Loss: 9.079347364604473e-05\n",
      "Epoch 2304, Loss: 5.189525290916208e-05, Final Batch Loss: 9.70041764958296e-06\n",
      "Epoch 2305, Loss: 3.177669623255497e-05, Final Batch Loss: 1.9715629605343565e-05\n",
      "Epoch 2306, Loss: 0.0001003144498099573, Final Batch Loss: 2.332068106625229e-05\n",
      "Epoch 2307, Loss: 0.00038943073377595283, Final Batch Loss: 0.0003474279656074941\n",
      "Epoch 2308, Loss: 0.0004893989389529452, Final Batch Loss: 0.0003444307076279074\n",
      "Epoch 2309, Loss: 9.424083691556007e-05, Final Batch Loss: 8.576943218940869e-05\n",
      "Epoch 2310, Loss: 9.762796253198758e-05, Final Batch Loss: 4.747448110720143e-05\n",
      "Epoch 2311, Loss: 1.2214636171847815e-05, Final Batch Loss: 5.458599389385199e-06\n",
      "Epoch 2312, Loss: 2.0584841422532918e-05, Final Batch Loss: 6.722080343024572e-06\n",
      "Epoch 2313, Loss: 2.2441724240707117e-05, Final Batch Loss: 2.9661666758329375e-06\n",
      "Epoch 2314, Loss: 0.0002646895986799791, Final Batch Loss: 0.00025745417224243283\n",
      "Epoch 2315, Loss: 8.800785099083441e-05, Final Batch Loss: 8.162901940522715e-05\n",
      "Epoch 2316, Loss: 0.00022556578915100545, Final Batch Loss: 0.00010581829701550305\n",
      "Epoch 2317, Loss: 0.00034180159855168313, Final Batch Loss: 0.00022777145204599947\n",
      "Epoch 2318, Loss: 0.05261185055860551, Final Batch Loss: 9.846350440056995e-05\n",
      "Epoch 2319, Loss: 0.00010057195322588086, Final Batch Loss: 3.35124132107012e-05\n",
      "Epoch 2320, Loss: 0.0020799029060754037, Final Batch Loss: 0.0020787494722753763\n",
      "Epoch 2321, Loss: 4.052615986438468e-05, Final Batch Loss: 1.0824463970493525e-05\n",
      "Epoch 2322, Loss: 0.003477518097497523, Final Batch Loss: 0.002982752164825797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2323, Loss: 0.00026400179194752127, Final Batch Loss: 1.658963446971029e-05\n",
      "Epoch 2324, Loss: 0.00041888888517860323, Final Batch Loss: 0.00033990052179433405\n",
      "Epoch 2325, Loss: 0.00017370526984450407, Final Batch Loss: 4.46328085672576e-05\n",
      "Epoch 2326, Loss: 0.0006381779458024539, Final Batch Loss: 9.920247975969687e-05\n",
      "Epoch 2327, Loss: 0.00010245543307974003, Final Batch Loss: 8.78477658261545e-06\n",
      "Epoch 2328, Loss: 0.011464923381026892, Final Batch Loss: 8.505529876856599e-06\n",
      "Epoch 2329, Loss: 0.00030084574973443523, Final Batch Loss: 0.00010930431744782254\n",
      "Epoch 2330, Loss: 0.00013509824020729866, Final Batch Loss: 1.841289304138627e-05\n",
      "Epoch 2331, Loss: 4.8239077841572e-05, Final Batch Loss: 1.296542086492991e-05\n",
      "Epoch 2332, Loss: 5.4780388381914236e-05, Final Batch Loss: 3.1880452297627926e-05\n",
      "Epoch 2333, Loss: 8.172082198143471e-05, Final Batch Loss: 1.893023909360636e-05\n",
      "Epoch 2334, Loss: 0.000494118172355229, Final Batch Loss: 0.00043932098196819425\n",
      "Epoch 2335, Loss: 0.0005438630978460424, Final Batch Loss: 0.0004577257495839149\n",
      "Epoch 2336, Loss: 8.551144128432497e-05, Final Batch Loss: 5.821546074002981e-05\n",
      "Epoch 2337, Loss: 0.0003036293255718192, Final Batch Loss: 6.5500553318997845e-06\n",
      "Epoch 2338, Loss: 0.0031201096244330984, Final Batch Loss: 1.2793065252481028e-05\n",
      "Epoch 2339, Loss: 0.0001733184326440096, Final Batch Loss: 0.00011331689893268049\n",
      "Epoch 2340, Loss: 0.002223914736532606, Final Batch Loss: 0.0021876052487641573\n",
      "Epoch 2341, Loss: 6.604377631447278e-05, Final Batch Loss: 2.1952564566163346e-05\n",
      "Epoch 2342, Loss: 0.0001149919189629145, Final Batch Loss: 3.68004257325083e-05\n",
      "Epoch 2343, Loss: 0.00029367563547566533, Final Batch Loss: 0.00022390161757357419\n",
      "Epoch 2344, Loss: 0.0013998592912685126, Final Batch Loss: 0.0013388131046667695\n",
      "Epoch 2345, Loss: 7.530514267273247e-05, Final Batch Loss: 3.1330720958067104e-05\n",
      "Epoch 2346, Loss: 0.0018285434489371255, Final Batch Loss: 0.0018035218818113208\n",
      "Epoch 2347, Loss: 0.00019386470557947177, Final Batch Loss: 0.0001778073055902496\n",
      "Epoch 2348, Loss: 0.0004432870882737916, Final Batch Loss: 2.3175187379820272e-05\n",
      "Epoch 2349, Loss: 0.00015193671970337164, Final Batch Loss: 2.1658210243913345e-05\n",
      "Epoch 2350, Loss: 9.689517901279032e-05, Final Batch Loss: 5.434244667412713e-05\n",
      "Epoch 2351, Loss: 3.1247232527675806e-05, Final Batch Loss: 1.786576376616722e-06\n",
      "Epoch 2352, Loss: 0.0008993089577415958, Final Batch Loss: 0.00014499750977847725\n",
      "Epoch 2353, Loss: 0.005436636183731025, Final Batch Loss: 4.677861215895973e-05\n",
      "Epoch 2354, Loss: 0.0005262670365482336, Final Batch Loss: 1.3844857676303945e-05\n",
      "Epoch 2355, Loss: 0.001447972288588062, Final Batch Loss: 4.028299008496106e-05\n",
      "Epoch 2356, Loss: 0.00019053339747188147, Final Batch Loss: 0.00017773306171875447\n",
      "Epoch 2357, Loss: 7.910763451945968e-05, Final Batch Loss: 4.925761095364578e-05\n",
      "Epoch 2358, Loss: 0.0017806205141823739, Final Batch Loss: 0.00031512274290435016\n",
      "Epoch 2359, Loss: 0.0015949426360748475, Final Batch Loss: 2.165510341001209e-05\n",
      "Epoch 2360, Loss: 4.272480873623863e-05, Final Batch Loss: 1.6422540284111165e-05\n",
      "Epoch 2361, Loss: 7.301749428734183e-05, Final Batch Loss: 8.548115147277713e-06\n",
      "Epoch 2362, Loss: 0.000120506718303659, Final Batch Loss: 9.851291542872787e-05\n",
      "Epoch 2363, Loss: 3.4942607726407005e-05, Final Batch Loss: 2.2331437321554404e-06\n",
      "Epoch 2364, Loss: 0.0001025905376081937, Final Batch Loss: 6.713956281600986e-06\n",
      "Epoch 2365, Loss: 0.00025014355560415424, Final Batch Loss: 0.0002245647192467004\n",
      "Epoch 2366, Loss: 0.00016002202028175816, Final Batch Loss: 7.219560939120129e-05\n",
      "Epoch 2367, Loss: 0.001552975914819399, Final Batch Loss: 3.757881131605245e-05\n",
      "Epoch 2368, Loss: 0.0014583567390218377, Final Batch Loss: 0.0007732119993306696\n",
      "Epoch 2369, Loss: 0.0002543280861573294, Final Batch Loss: 0.00017148867482319474\n",
      "Epoch 2370, Loss: 0.00012113623961340636, Final Batch Loss: 9.784591384232044e-05\n",
      "Epoch 2371, Loss: 2.38451148106833e-05, Final Batch Loss: 6.991454029048327e-06\n",
      "Epoch 2372, Loss: 2.578142175480025e-05, Final Batch Loss: 1.4903637747920584e-05\n",
      "Epoch 2373, Loss: 9.408362620888511e-05, Final Batch Loss: 4.6887080316082574e-06\n",
      "Epoch 2374, Loss: 0.0002635336904859287, Final Batch Loss: 1.0864566320378799e-05\n",
      "Epoch 2375, Loss: 3.712549005285837e-05, Final Batch Loss: 8.526767487637699e-06\n",
      "Epoch 2376, Loss: 8.019068536668783e-05, Final Batch Loss: 7.345355697907507e-05\n",
      "Epoch 2377, Loss: 0.00010138187826669309, Final Batch Loss: 1.6302541553159244e-05\n",
      "Epoch 2378, Loss: 0.00017274782203458017, Final Batch Loss: 0.00015992003318388015\n",
      "Epoch 2379, Loss: 9.751156358106527e-05, Final Batch Loss: 1.975438863155432e-06\n",
      "Epoch 2380, Loss: 4.161185324846883e-05, Final Batch Loss: 6.057868176867487e-06\n",
      "Epoch 2381, Loss: 0.0003608051920309663, Final Batch Loss: 0.000268799252808094\n",
      "Epoch 2382, Loss: 0.00047104996656344156, Final Batch Loss: 4.991411969967885e-06\n",
      "Epoch 2383, Loss: 5.6309258070541546e-05, Final Batch Loss: 4.715613977168687e-05\n",
      "Epoch 2384, Loss: 4.5186585339251906e-05, Final Batch Loss: 1.604646968189627e-05\n",
      "Epoch 2385, Loss: 0.0003053934833587846, Final Batch Loss: 1.602963857294526e-05\n",
      "Epoch 2386, Loss: 3.7798167795699555e-05, Final Batch Loss: 2.8785701942979358e-05\n",
      "Epoch 2387, Loss: 0.0001551898312754929, Final Batch Loss: 8.344480011146516e-05\n",
      "Epoch 2388, Loss: 0.001043145079165697, Final Batch Loss: 3.2860785722732544e-05\n",
      "Epoch 2389, Loss: 0.0003114967930741841, Final Batch Loss: 0.00030285565298981965\n",
      "Epoch 2390, Loss: 0.00011178903514519334, Final Batch Loss: 0.00010352862591389567\n",
      "Epoch 2391, Loss: 0.0001295077527174726, Final Batch Loss: 0.00010725006723077968\n",
      "Epoch 2392, Loss: 9.781951621334883e-05, Final Batch Loss: 6.408597528206883e-06\n",
      "Epoch 2393, Loss: 1.7215785874213907e-05, Final Batch Loss: 2.595789510451141e-06\n",
      "Epoch 2394, Loss: 0.00011892067141161533, Final Batch Loss: 0.00010713086521718651\n",
      "Epoch 2395, Loss: 0.00024917924719147777, Final Batch Loss: 9.421707432011317e-07\n",
      "Epoch 2396, Loss: 0.0001660024354350753, Final Batch Loss: 0.00010318757995264605\n",
      "Epoch 2397, Loss: 0.00010012530765379779, Final Batch Loss: 8.282833732664585e-05\n",
      "Epoch 2398, Loss: 0.0018195239654232864, Final Batch Loss: 1.3429304999590386e-05\n",
      "Epoch 2399, Loss: 0.00020435381156858057, Final Batch Loss: 1.6635414795018733e-05\n",
      "Epoch 2400, Loss: 2.5202506549248938e-05, Final Batch Loss: 5.101775059301872e-06\n",
      "Epoch 2401, Loss: 0.004218357472836942, Final Batch Loss: 2.43293789026211e-06\n",
      "Epoch 2402, Loss: 0.0005888707637495827, Final Batch Loss: 0.0005663610063493252\n",
      "Epoch 2403, Loss: 0.0001470003444410395, Final Batch Loss: 0.00011230412928853184\n",
      "Epoch 2404, Loss: 1.8206703316536732e-05, Final Batch Loss: 3.6989895306760445e-06\n",
      "Epoch 2405, Loss: 0.00014132275100564584, Final Batch Loss: 9.662003867560998e-05\n",
      "Epoch 2406, Loss: 2.7056245926360134e-05, Final Batch Loss: 1.7069271052605473e-05\n",
      "Epoch 2407, Loss: 0.00012061642701155506, Final Batch Loss: 5.776762918685563e-05\n",
      "Epoch 2408, Loss: 3.921608458767878e-05, Final Batch Loss: 4.550850462692324e-06\n",
      "Epoch 2409, Loss: 0.001026436145707521, Final Batch Loss: 1.1008645515175886e-06\n",
      "Epoch 2410, Loss: 0.0007848789773561293, Final Batch Loss: 0.000781926151830703\n",
      "Epoch 2411, Loss: 3.136235091005801e-05, Final Batch Loss: 5.790797786175972e-06\n",
      "Epoch 2412, Loss: 6.052745391116332e-05, Final Batch Loss: 1.6265033764284453e-06\n",
      "Epoch 2413, Loss: 7.888030449976213e-05, Final Batch Loss: 4.590104799717665e-05\n",
      "Epoch 2414, Loss: 0.00011052821355406195, Final Batch Loss: 0.00010270386701449752\n",
      "Epoch 2415, Loss: 1.7968863630812848e-05, Final Batch Loss: 3.816867774730781e-06\n",
      "Epoch 2416, Loss: 0.0010849158170458395, Final Batch Loss: 0.0010283298324793577\n",
      "Epoch 2417, Loss: 0.00145662970317062, Final Batch Loss: 0.0013848363887518644\n",
      "Epoch 2418, Loss: 2.03749173124379e-05, Final Batch Loss: 1.4078197636990808e-05\n",
      "Epoch 2419, Loss: 6.660273720626719e-05, Final Batch Loss: 5.134137245477177e-05\n",
      "Epoch 2420, Loss: 0.0039983101096368046, Final Batch Loss: 1.0004071555158589e-05\n",
      "Epoch 2421, Loss: 0.0008706973919743177, Final Batch Loss: 0.0008689918322488666\n",
      "Epoch 2422, Loss: 4.106594860786572e-05, Final Batch Loss: 2.7214797228225507e-05\n",
      "Epoch 2423, Loss: 8.238445661845617e-05, Final Batch Loss: 5.391715239966288e-05\n",
      "Epoch 2424, Loss: 0.012805421024950192, Final Batch Loss: 2.9999096113897394e-06\n",
      "Epoch 2425, Loss: 0.0025404946063645184, Final Batch Loss: 0.0023035246413201094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2426, Loss: 0.0042512958170846105, Final Batch Loss: 0.001305504352785647\n",
      "Epoch 2427, Loss: 3.840495992335491e-05, Final Batch Loss: 1.696915933280252e-05\n",
      "Epoch 2428, Loss: 3.658184459709446e-05, Final Batch Loss: 5.981989943393273e-06\n",
      "Epoch 2429, Loss: 0.00010133718387805857, Final Batch Loss: 4.044662637170404e-05\n",
      "Epoch 2430, Loss: 9.567932283971459e-05, Final Batch Loss: 4.9553767894394696e-05\n",
      "Epoch 2431, Loss: 0.0004091488335689064, Final Batch Loss: 3.407484837225638e-05\n",
      "Epoch 2432, Loss: 0.0015778675879118964, Final Batch Loss: 3.365862357895821e-05\n",
      "Epoch 2433, Loss: 0.00012555957800941542, Final Batch Loss: 8.635564881842583e-05\n",
      "Epoch 2434, Loss: 6.071392044759705e-05, Final Batch Loss: 6.8974563873780426e-06\n",
      "Epoch 2435, Loss: 0.0013510870221580262, Final Batch Loss: 1.1641083801805507e-05\n",
      "Epoch 2436, Loss: 2.05368155548058e-05, Final Batch Loss: 1.4162109437165782e-05\n",
      "Epoch 2437, Loss: 0.0023443252430297434, Final Batch Loss: 0.0014492679620161653\n",
      "Epoch 2438, Loss: 0.003924609831301495, Final Batch Loss: 9.183163638226688e-05\n",
      "Epoch 2439, Loss: 0.0029595856394735165, Final Batch Loss: 5.541847349377349e-05\n",
      "Epoch 2440, Loss: 0.0022117808694019914, Final Batch Loss: 0.0014828741550445557\n",
      "Epoch 2441, Loss: 1.3244630281405989e-05, Final Batch Loss: 2.0293364286771975e-06\n",
      "Epoch 2442, Loss: 4.510478720476385e-05, Final Batch Loss: 2.672073787834961e-05\n",
      "Epoch 2443, Loss: 0.001957182597834617, Final Batch Loss: 0.0015973113477230072\n",
      "Epoch 2444, Loss: 0.00020066463366674725, Final Batch Loss: 0.00018070182704832405\n",
      "Epoch 2445, Loss: 0.0023025093260002905, Final Batch Loss: 1.2154750038462225e-05\n",
      "Epoch 2446, Loss: 0.00013439446240681718, Final Batch Loss: 1.6064169585661148e-06\n",
      "Epoch 2447, Loss: 0.0006131269656179938, Final Batch Loss: 0.0005562175647355616\n",
      "Epoch 2448, Loss: 4.156001728006231e-05, Final Batch Loss: 2.689781695153215e-06\n",
      "Epoch 2449, Loss: 7.057199559312721e-05, Final Batch Loss: 6.766075966879725e-05\n",
      "Epoch 2450, Loss: 0.0003226878889108775, Final Batch Loss: 0.0003170477575622499\n",
      "Epoch 2451, Loss: 9.774640784598887e-05, Final Batch Loss: 8.766706741880625e-06\n",
      "Epoch 2452, Loss: 7.419783651130274e-05, Final Batch Loss: 4.1163046262227e-05\n",
      "Epoch 2453, Loss: 0.0008445141284028068, Final Batch Loss: 0.0007589794113300741\n",
      "Epoch 2454, Loss: 0.00018791150796459988, Final Batch Loss: 0.00014047873264644295\n",
      "Epoch 2455, Loss: 9.1889152827207e-05, Final Batch Loss: 4.796033681486733e-05\n",
      "Epoch 2456, Loss: 0.0002471227908245055, Final Batch Loss: 0.00023610173957422376\n",
      "Epoch 2457, Loss: 6.292373927863082e-05, Final Batch Loss: 4.382814040582161e-06\n",
      "Epoch 2458, Loss: 0.00015406629813696782, Final Batch Loss: 3.680708914544084e-06\n",
      "Epoch 2459, Loss: 5.953861546004191e-05, Final Batch Loss: 3.067323632421903e-05\n",
      "Epoch 2460, Loss: 0.00022456495207734406, Final Batch Loss: 3.485489287413657e-05\n",
      "Epoch 2461, Loss: 0.0010202584380749613, Final Batch Loss: 0.0003651869192253798\n",
      "Epoch 2462, Loss: 6.509787817776669e-05, Final Batch Loss: 5.738555410061963e-05\n",
      "Epoch 2463, Loss: 0.00023522333594883094, Final Batch Loss: 0.0002324894885532558\n",
      "Epoch 2464, Loss: 1.0214304438704858e-05, Final Batch Loss: 8.516850357409567e-06\n",
      "Epoch 2465, Loss: 6.47065744487918e-05, Final Batch Loss: 2.9477005227818154e-06\n",
      "Epoch 2466, Loss: 1.5107152648852207e-05, Final Batch Loss: 6.9973575591575354e-06\n",
      "Epoch 2467, Loss: 0.000368567110854201, Final Batch Loss: 0.00016280717682093382\n",
      "Epoch 2468, Loss: 2.7595039682637434e-05, Final Batch Loss: 2.345559187233448e-05\n",
      "Epoch 2469, Loss: 0.0011621864140352045, Final Batch Loss: 1.2085400840078364e-06\n",
      "Epoch 2470, Loss: 0.0013413713313639164, Final Batch Loss: 0.0008095689699985087\n",
      "Epoch 2471, Loss: 0.0001259030213986989, Final Batch Loss: 0.00011111835192423314\n",
      "Epoch 2472, Loss: 8.334673839272e-05, Final Batch Loss: 4.019214611616917e-05\n",
      "Epoch 2473, Loss: 0.0001896894900710322, Final Batch Loss: 0.00016776929260231555\n",
      "Epoch 2474, Loss: 8.570127465645783e-05, Final Batch Loss: 8.890569006325677e-06\n",
      "Epoch 2475, Loss: 0.00017848170955403475, Final Batch Loss: 4.221986273478251e-06\n",
      "Epoch 2476, Loss: 0.00014659147655038396, Final Batch Loss: 0.00014055345673114061\n",
      "Epoch 2477, Loss: 1.0027976259152638e-05, Final Batch Loss: 5.799805421702331e-06\n",
      "Epoch 2478, Loss: 3.415874016354792e-05, Final Batch Loss: 1.1847243513329886e-05\n",
      "Epoch 2479, Loss: 9.15489658837032e-06, Final Batch Loss: 3.588806748666684e-06\n",
      "Epoch 2480, Loss: 7.020893781373161e-05, Final Batch Loss: 6.432797363231657e-06\n",
      "Epoch 2481, Loss: 0.0001353537845716346, Final Batch Loss: 9.908427455229685e-05\n",
      "Epoch 2482, Loss: 0.0003281929766671965, Final Batch Loss: 2.741088428592775e-05\n",
      "Epoch 2483, Loss: 0.003142465136534156, Final Batch Loss: 7.399355581583222e-06\n",
      "Epoch 2484, Loss: 9.104648643187829e-05, Final Batch Loss: 7.09296591594466e-06\n",
      "Epoch 2485, Loss: 3.841333273157943e-05, Final Batch Loss: 2.0297278751968406e-05\n",
      "Epoch 2486, Loss: 0.00020673179284358412, Final Batch Loss: 0.0002062001294689253\n",
      "Epoch 2487, Loss: 4.165122538779542e-05, Final Batch Loss: 1.4699677421958768e-06\n",
      "Epoch 2488, Loss: 0.0002614394779811846, Final Batch Loss: 1.273621637665201e-05\n",
      "Epoch 2489, Loss: 1.97643562387384e-05, Final Batch Loss: 2.9671059564861935e-06\n",
      "Epoch 2490, Loss: 0.00037867861828999594, Final Batch Loss: 0.0003151038254145533\n",
      "Epoch 2491, Loss: 2.420059422547638e-05, Final Batch Loss: 2.109383058268577e-05\n",
      "Epoch 2492, Loss: 0.0002969344423036091, Final Batch Loss: 0.0002113286464009434\n",
      "Epoch 2493, Loss: 1.0168168273594347e-05, Final Batch Loss: 6.966427008592291e-06\n",
      "Epoch 2494, Loss: 1.1840950719488319e-05, Final Batch Loss: 6.927365120645845e-06\n",
      "Epoch 2495, Loss: 0.00011671252650558017, Final Batch Loss: 1.4709086826769635e-05\n",
      "Epoch 2496, Loss: 3.545959680195665e-05, Final Batch Loss: 2.9544275093940087e-05\n",
      "Epoch 2497, Loss: 1.2259501545486273e-05, Final Batch Loss: 6.662246050836984e-06\n",
      "Epoch 2498, Loss: 3.7864803289267e-05, Final Batch Loss: 6.762150860595284e-06\n",
      "Epoch 2499, Loss: 9.280166523240041e-06, Final Batch Loss: 6.7389819378149696e-06\n",
      "Epoch 2500, Loss: 2.3220994080475066e-05, Final Batch Loss: 9.621064236853272e-06\n",
      "Epoch 2501, Loss: 0.00037634600244018657, Final Batch Loss: 3.539875024216599e-06\n",
      "Epoch 2502, Loss: 0.000987243933877835, Final Batch Loss: 0.000985136954113841\n",
      "Epoch 2503, Loss: 1.099273777072085e-05, Final Batch Loss: 5.231681370787555e-06\n",
      "Epoch 2504, Loss: 0.0007369837476289831, Final Batch Loss: 0.00010608796583255753\n",
      "Epoch 2505, Loss: 0.004595051222167967, Final Batch Loss: 1.1051824913010933e-06\n",
      "Epoch 2506, Loss: 9.379279845234123e-06, Final Batch Loss: 7.102109975676285e-07\n",
      "Epoch 2507, Loss: 6.087969700274698e-05, Final Batch Loss: 1.0046376246464206e-06\n",
      "Epoch 2508, Loss: 1.5677615920139942e-05, Final Batch Loss: 1.3569147085945588e-05\n",
      "Epoch 2509, Loss: 0.0009455511877831668, Final Batch Loss: 6.807800900787697e-07\n",
      "Epoch 2510, Loss: 0.0008257134877567296, Final Batch Loss: 9.480613698542584e-06\n",
      "Epoch 2511, Loss: 0.006845683790743351, Final Batch Loss: 0.003934730309993029\n",
      "Epoch 2512, Loss: 5.814463293063454e-06, Final Batch Loss: 3.1339723136625253e-06\n",
      "Epoch 2513, Loss: 1.7068642705453385e-05, Final Batch Loss: 1.4570406392522273e-06\n",
      "Epoch 2514, Loss: 9.060076081368607e-05, Final Batch Loss: 6.125685104052536e-06\n",
      "Epoch 2515, Loss: 1.435871422472701e-05, Final Batch Loss: 3.5223404211137677e-06\n",
      "Epoch 2516, Loss: 2.5443931690460886e-05, Final Batch Loss: 2.6856057502300246e-06\n",
      "Epoch 2517, Loss: 3.647927815109142e-05, Final Batch Loss: 3.147419192828238e-05\n",
      "Epoch 2518, Loss: 0.0012171407724963501, Final Batch Loss: 0.0010415094438940287\n",
      "Epoch 2519, Loss: 0.00039876172377262264, Final Batch Loss: 2.1716710762120783e-05\n",
      "Epoch 2520, Loss: 0.0001842359433794627, Final Batch Loss: 1.3369231965043582e-05\n",
      "Epoch 2521, Loss: 0.0012388937175273895, Final Batch Loss: 0.00032222375739365816\n",
      "Epoch 2522, Loss: 7.66015605222492e-05, Final Batch Loss: 6.895376372995088e-06\n",
      "Epoch 2523, Loss: 5.661398120082595e-06, Final Batch Loss: 7.001522703831142e-07\n",
      "Epoch 2524, Loss: 1.128833559960185e-05, Final Batch Loss: 2.760158395176404e-06\n",
      "Epoch 2525, Loss: 0.001016974808408122, Final Batch Loss: 0.0010048173135146499\n",
      "Epoch 2526, Loss: 0.00548831717333087, Final Batch Loss: 0.005476741120219231\n",
      "Epoch 2527, Loss: 0.00010047607065644115, Final Batch Loss: 5.635639899992384e-05\n",
      "Epoch 2528, Loss: 8.591958612669259e-05, Final Batch Loss: 8.143387094605714e-05\n",
      "Epoch 2529, Loss: 0.0027420287078712136, Final Batch Loss: 2.8551468858495355e-05\n",
      "Epoch 2530, Loss: 0.000541507857178658, Final Batch Loss: 0.0005371416336856782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2531, Loss: 6.4430830661876826e-06, Final Batch Loss: 2.027818709393614e-06\n",
      "Epoch 2532, Loss: 5.528839392354712e-05, Final Batch Loss: 2.5941990315914154e-06\n",
      "Epoch 2533, Loss: 2.20456486204057e-05, Final Batch Loss: 1.025685287459055e-05\n",
      "Epoch 2534, Loss: 0.0005191188649860123, Final Batch Loss: 0.0005172464880160987\n",
      "Epoch 2535, Loss: 3.7753568051357433e-05, Final Batch Loss: 8.437773999503406e-07\n",
      "Epoch 2536, Loss: 1.0336334526073188e-05, Final Batch Loss: 5.253868039289955e-06\n",
      "Epoch 2537, Loss: 2.6924265057459706e-05, Final Batch Loss: 3.837100393866422e-06\n",
      "Epoch 2538, Loss: 7.344395635300316e-05, Final Batch Loss: 4.902485670754686e-06\n",
      "Epoch 2539, Loss: 0.0015956973620632198, Final Batch Loss: 0.0015751556493341923\n",
      "Epoch 2540, Loss: 4.3606960389297456e-05, Final Batch Loss: 2.3680211597820744e-05\n",
      "Epoch 2541, Loss: 5.1380161494307686e-06, Final Batch Loss: 2.530331585148815e-06\n",
      "Epoch 2542, Loss: 0.0010927559778792784, Final Batch Loss: 0.0010021115886047482\n",
      "Epoch 2543, Loss: 1.1526940397743601e-05, Final Batch Loss: 6.395237051037839e-06\n",
      "Epoch 2544, Loss: 1.3371964158181981e-06, Final Batch Loss: 1.1561849788677137e-07\n",
      "Epoch 2545, Loss: 8.728446118766442e-06, Final Batch Loss: 3.815267518803012e-06\n",
      "Epoch 2546, Loss: 6.03404970433985e-05, Final Batch Loss: 1.5776587360960548e-06\n",
      "Epoch 2547, Loss: 7.055199966998771e-05, Final Batch Loss: 3.6727480619447306e-05\n",
      "Epoch 2548, Loss: 0.0008625256450613961, Final Batch Loss: 0.00022061947674956173\n",
      "Epoch 2549, Loss: 0.00011108048056485131, Final Batch Loss: 3.319489042041823e-05\n",
      "Epoch 2550, Loss: 0.0001843956201810215, Final Batch Loss: 4.760797764902236e-06\n",
      "Epoch 2551, Loss: 0.00013494074755726615, Final Batch Loss: 7.63363732403377e-06\n",
      "Epoch 2552, Loss: 8.264288567261246e-06, Final Batch Loss: 1.3536435972127947e-06\n",
      "Epoch 2553, Loss: 0.00011908517626579851, Final Batch Loss: 5.778945342171937e-05\n",
      "Epoch 2554, Loss: 1.9676537476698286e-05, Final Batch Loss: 1.648725628911052e-05\n",
      "Epoch 2555, Loss: 4.914175042358693e-05, Final Batch Loss: 3.429823846090585e-05\n",
      "Epoch 2556, Loss: 1.7005143490678165e-05, Final Batch Loss: 2.3883540052338503e-06\n",
      "Epoch 2557, Loss: 5.3475434583560855e-05, Final Batch Loss: 1.4211456118573551e-06\n",
      "Epoch 2558, Loss: 1.1442154800533899e-05, Final Batch Loss: 9.869172572507523e-06\n",
      "Epoch 2559, Loss: 3.531095012476726e-05, Final Batch Loss: 3.468726936262101e-05\n",
      "Epoch 2560, Loss: 0.00010048240363857985, Final Batch Loss: 6.944202937120281e-07\n",
      "Epoch 2561, Loss: 0.00011105485828011297, Final Batch Loss: 4.774857734446414e-05\n",
      "Epoch 2562, Loss: 0.0005911349362577312, Final Batch Loss: 0.0004927788977511227\n",
      "Epoch 2563, Loss: 0.00027981500534224324, Final Batch Loss: 0.00026491197058930993\n",
      "Epoch 2564, Loss: 3.842177648039069e-05, Final Batch Loss: 2.7393012715037912e-05\n",
      "Epoch 2565, Loss: 5.013769714423688e-05, Final Batch Loss: 2.3890252123237588e-06\n",
      "Epoch 2566, Loss: 0.00014767956963623874, Final Batch Loss: 4.772174361278303e-05\n",
      "Epoch 2567, Loss: 0.0001441572530893609, Final Batch Loss: 0.00014039095549378544\n",
      "Epoch 2568, Loss: 9.931571412380436e-06, Final Batch Loss: 8.421175152761862e-06\n",
      "Epoch 2569, Loss: 0.0017542171335662715, Final Batch Loss: 0.00174612773116678\n",
      "Epoch 2570, Loss: 8.935165533330292e-05, Final Batch Loss: 2.1970663510728627e-05\n",
      "Epoch 2571, Loss: 5.8682083093231086e-05, Final Batch Loss: 1.8671262580483017e-07\n",
      "Epoch 2572, Loss: 0.000980496335614589, Final Batch Loss: 0.0009757872903719544\n",
      "Epoch 2573, Loss: 9.454174801248882e-05, Final Batch Loss: 1.938139803314698e-06\n",
      "Epoch 2574, Loss: 0.002992505009387969, Final Batch Loss: 2.509289151930716e-05\n",
      "Epoch 2575, Loss: 1.6857424952831934e-05, Final Batch Loss: 2.0938839497830486e-06\n",
      "Epoch 2576, Loss: 2.20471615648421e-05, Final Batch Loss: 1.6547608538530767e-05\n",
      "Epoch 2577, Loss: 0.002676263162129544, Final Batch Loss: 1.1489626103866613e-06\n",
      "Epoch 2578, Loss: 3.2039591133070644e-05, Final Batch Loss: 2.90649441012647e-05\n",
      "Epoch 2579, Loss: 0.0006240342790988507, Final Batch Loss: 0.0006045952904969454\n",
      "Epoch 2580, Loss: 4.9712401732904254e-05, Final Batch Loss: 4.7632936912123114e-05\n",
      "Epoch 2581, Loss: 0.0005687027587555349, Final Batch Loss: 0.0001950746518559754\n",
      "Epoch 2582, Loss: 0.00034413982939440757, Final Batch Loss: 0.00011739601904992014\n",
      "Epoch 2583, Loss: 7.866109513088304e-06, Final Batch Loss: 6.3393795244337525e-06\n",
      "Epoch 2584, Loss: 2.614900188291358e-05, Final Batch Loss: 2.4510656658094376e-05\n",
      "Epoch 2585, Loss: 7.912526962172706e-05, Final Batch Loss: 7.500011270167306e-05\n",
      "Epoch 2586, Loss: 0.00032272914631903404, Final Batch Loss: 1.4346617717819754e-05\n",
      "Epoch 2587, Loss: 2.585811489552725e-05, Final Batch Loss: 1.4861434465274215e-05\n",
      "Epoch 2588, Loss: 6.533212520309917e-05, Final Batch Loss: 1.8599469342461816e-07\n",
      "Epoch 2589, Loss: 0.0001543374160064559, Final Batch Loss: 1.137486378866015e-06\n",
      "Epoch 2590, Loss: 9.466254141443642e-06, Final Batch Loss: 7.785985872033052e-06\n",
      "Epoch 2591, Loss: 1.4728450423717732e-05, Final Batch Loss: 7.992050996108446e-06\n",
      "Epoch 2592, Loss: 0.0018461882718838751, Final Batch Loss: 0.0005686337244696915\n",
      "Epoch 2593, Loss: 0.001432320967751366, Final Batch Loss: 2.463048758727382e-06\n",
      "Epoch 2594, Loss: 8.418684501521057e-06, Final Batch Loss: 4.611099484463921e-06\n",
      "Epoch 2595, Loss: 0.00010300148187525338, Final Batch Loss: 9.043471072800457e-05\n",
      "Epoch 2596, Loss: 2.5077126338146627e-05, Final Batch Loss: 2.0684399714809842e-05\n",
      "Epoch 2597, Loss: 0.0004471208230825141, Final Batch Loss: 0.00024258722260128707\n",
      "Epoch 2598, Loss: 1.1885527385402384e-05, Final Batch Loss: 1.1481173714855686e-05\n",
      "Epoch 2599, Loss: 0.00016176141070900485, Final Batch Loss: 7.611022010678425e-05\n",
      "Epoch 2600, Loss: 0.0001157380156655563, Final Batch Loss: 1.9266281015006825e-06\n",
      "Epoch 2601, Loss: 6.650692512266687e-06, Final Batch Loss: 2.8367196591716493e-06\n",
      "Epoch 2602, Loss: 0.00011477575390017591, Final Batch Loss: 5.752933429903351e-05\n",
      "Epoch 2603, Loss: 2.7711256734619383e-05, Final Batch Loss: 2.20159472519299e-05\n",
      "Epoch 2604, Loss: 0.00015589926078973804, Final Batch Loss: 2.1476642359630205e-05\n",
      "Epoch 2605, Loss: 5.428360850601166e-06, Final Batch Loss: 4.136685220146319e-06\n",
      "Epoch 2606, Loss: 0.0001749415860103909, Final Batch Loss: 0.00012006587348878384\n",
      "Epoch 2607, Loss: 4.426967461768072e-05, Final Batch Loss: 3.603338700486347e-05\n",
      "Epoch 2608, Loss: 7.299675780814141e-05, Final Batch Loss: 1.8729922885540873e-05\n",
      "Epoch 2609, Loss: 1.751131162563979e-05, Final Batch Loss: 1.4856783309369348e-05\n",
      "Epoch 2610, Loss: 6.228369443306292e-06, Final Batch Loss: 9.802189424590324e-07\n",
      "Epoch 2611, Loss: 4.8889562435761036e-05, Final Batch Loss: 4.811379767488688e-05\n",
      "Epoch 2612, Loss: 0.0001863378711277619, Final Batch Loss: 0.00015197535685729235\n",
      "Epoch 2613, Loss: 3.680187541021951e-05, Final Batch Loss: 5.64434174066264e-07\n",
      "Epoch 2614, Loss: 2.2038258066459093e-05, Final Batch Loss: 1.806915861379821e-05\n",
      "Epoch 2615, Loss: 1.6037104160204763e-05, Final Batch Loss: 3.987295258411905e-06\n",
      "Epoch 2616, Loss: 3.275696508353576e-05, Final Batch Loss: 1.1417978384997696e-06\n",
      "Epoch 2617, Loss: 9.869122186501045e-05, Final Batch Loss: 8.098651596810669e-05\n",
      "Epoch 2618, Loss: 7.719656105109607e-05, Final Batch Loss: 2.3602228793606628e-06\n",
      "Epoch 2619, Loss: 0.021053448680504516, Final Batch Loss: 0.02104428969323635\n",
      "Epoch 2620, Loss: 0.00021747559003415518, Final Batch Loss: 0.00020211620721966028\n",
      "Epoch 2621, Loss: 3.411382294871146e-05, Final Batch Loss: 2.3903005057945848e-05\n",
      "Epoch 2622, Loss: 2.59772300523764e-05, Final Batch Loss: 1.983201400435064e-05\n",
      "Epoch 2623, Loss: 4.650811115425313e-05, Final Batch Loss: 3.3817246730905026e-05\n",
      "Epoch 2624, Loss: 4.0800124224915635e-05, Final Batch Loss: 1.8447708498570137e-06\n",
      "Epoch 2625, Loss: 0.01771785517621538, Final Batch Loss: 4.602721219271189e-06\n",
      "Epoch 2626, Loss: 3.773722710320726e-05, Final Batch Loss: 2.416129245830234e-05\n",
      "Epoch 2627, Loss: 0.00010883836512221023, Final Batch Loss: 6.545080395881087e-05\n",
      "Epoch 2628, Loss: 7.759983418509364e-06, Final Batch Loss: 3.3748224268492777e-06\n",
      "Epoch 2629, Loss: 3.7179654555075103e-05, Final Batch Loss: 2.786875938909361e-06\n",
      "Epoch 2630, Loss: 5.642019868901116e-05, Final Batch Loss: 4.995320068701403e-06\n",
      "Epoch 2631, Loss: 4.801856539415894e-05, Final Batch Loss: 4.040226122015156e-05\n",
      "Epoch 2632, Loss: 2.1842136447958183e-05, Final Batch Loss: 1.5184213225438725e-05\n",
      "Epoch 2633, Loss: 0.00024477974511682987, Final Batch Loss: 8.227789658121765e-05\n",
      "Epoch 2634, Loss: 0.0009904100052153808, Final Batch Loss: 1.6500898709637113e-06\n",
      "Epoch 2635, Loss: 0.0009729011608214932, Final Batch Loss: 0.0009708584984764457\n",
      "Epoch 2636, Loss: 6.8728191990885534e-06, Final Batch Loss: 5.966860499029281e-06\n",
      "Epoch 2637, Loss: 3.124165914414334e-06, Final Batch Loss: 2.1037660644651623e-06\n",
      "Epoch 2638, Loss: 0.00046028275505705096, Final Batch Loss: 2.946938593595405e-06\n",
      "Epoch 2639, Loss: 0.00026839919155463576, Final Batch Loss: 8.225682540796697e-05\n",
      "Epoch 2640, Loss: 7.065100817271741e-05, Final Batch Loss: 6.0499140090541914e-05\n",
      "Epoch 2641, Loss: 0.0030753251826354244, Final Batch Loss: 4.588645879266551e-06\n",
      "Epoch 2642, Loss: 0.013341122720703424, Final Batch Loss: 0.013331330381333828\n",
      "Epoch 2643, Loss: 0.00023198273265734315, Final Batch Loss: 0.00013432589184958488\n",
      "Epoch 2644, Loss: 7.72094772401033e-05, Final Batch Loss: 2.910908187914174e-05\n",
      "Epoch 2645, Loss: 7.136416866160289e-05, Final Batch Loss: 6.873228267068043e-05\n",
      "Epoch 2646, Loss: 0.00014270086739998078, Final Batch Loss: 0.0001305940095335245\n",
      "Epoch 2647, Loss: 0.00012117356891394593, Final Batch Loss: 5.264507854008116e-05\n",
      "Epoch 2648, Loss: 2.3164370759332087e-05, Final Batch Loss: 1.0210145774181001e-05\n",
      "Epoch 2649, Loss: 1.9343584881426068e-05, Final Batch Loss: 1.5153218555497006e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2650, Loss: 0.0005761381707998225, Final Batch Loss: 0.0005543037550523877\n",
      "Epoch 2651, Loss: 0.0002759338676696643, Final Batch Loss: 0.0002068981557385996\n",
      "Epoch 2652, Loss: 0.00037862808676436543, Final Batch Loss: 0.00033168401569128036\n",
      "Epoch 2653, Loss: 0.01839822191686835, Final Batch Loss: 0.00022098641784396023\n",
      "Epoch 2654, Loss: 0.0001384628667437937, Final Batch Loss: 2.3866723495302722e-05\n",
      "Epoch 2655, Loss: 2.1987946183799068e-05, Final Batch Loss: 5.583437541645253e-06\n",
      "Epoch 2656, Loss: 4.935565812047571e-05, Final Batch Loss: 2.5494444344076328e-05\n",
      "Epoch 2657, Loss: 4.661576258513378e-05, Final Batch Loss: 8.336254722962622e-06\n",
      "Epoch 2658, Loss: 0.001122084868256934, Final Batch Loss: 0.00018589910177979618\n",
      "Epoch 2659, Loss: 0.0001975842533283867, Final Batch Loss: 2.7108275389764458e-05\n",
      "Epoch 2660, Loss: 0.00017573248987901025, Final Batch Loss: 5.3642750572180375e-05\n",
      "Epoch 2661, Loss: 0.0010456135532876942, Final Batch Loss: 3.104692223132588e-05\n",
      "Epoch 2662, Loss: 0.004292026982511743, Final Batch Loss: 1.1696369256242178e-05\n",
      "Epoch 2663, Loss: 2.128672622347949e-05, Final Batch Loss: 1.7284864952671342e-06\n",
      "Epoch 2664, Loss: 0.014040840091183782, Final Batch Loss: 0.00015059602446854115\n",
      "Epoch 2665, Loss: 0.0009780116961337626, Final Batch Loss: 0.0002728143590502441\n",
      "Epoch 2666, Loss: 0.0005046680525992997, Final Batch Loss: 8.758466719882563e-05\n",
      "Epoch 2667, Loss: 0.00012593100473168306, Final Batch Loss: 1.4903151168255135e-05\n",
      "Epoch 2668, Loss: 0.00016363948498110403, Final Batch Loss: 3.2148350328498054e-06\n",
      "Epoch 2669, Loss: 6.298242442426272e-05, Final Batch Loss: 4.678369441535324e-05\n",
      "Epoch 2670, Loss: 0.00022981606161920354, Final Batch Loss: 0.0002122043661074713\n",
      "Epoch 2671, Loss: 0.00034344766163485474, Final Batch Loss: 0.0003402874863240868\n",
      "Epoch 2672, Loss: 5.642787846227293e-05, Final Batch Loss: 5.808350124425488e-06\n",
      "Epoch 2673, Loss: 2.2058072318031918e-05, Final Batch Loss: 1.1625364095380064e-05\n",
      "Epoch 2674, Loss: 0.00026668302598409355, Final Batch Loss: 2.127577317878604e-05\n",
      "Epoch 2675, Loss: 2.8488699626905145e-05, Final Batch Loss: 5.649277682095999e-06\n",
      "Epoch 2676, Loss: 0.00020625947581720538, Final Batch Loss: 0.00015979069576133043\n",
      "Epoch 2677, Loss: 0.0001226808708452154, Final Batch Loss: 3.2100662792799994e-05\n",
      "Epoch 2678, Loss: 7.579646444355603e-05, Final Batch Loss: 9.077737558982335e-06\n",
      "Epoch 2679, Loss: 6.955808203201741e-05, Final Batch Loss: 4.791365790879354e-05\n",
      "Epoch 2680, Loss: 5.882526784262154e-05, Final Batch Loss: 4.15841604990419e-05\n",
      "Epoch 2681, Loss: 5.325597885530442e-05, Final Batch Loss: 4.3100535549456254e-05\n",
      "Epoch 2682, Loss: 6.154213951958809e-05, Final Batch Loss: 4.086758417543024e-05\n",
      "Epoch 2683, Loss: 6.477158058260102e-05, Final Batch Loss: 2.0366214812383987e-05\n",
      "Epoch 2684, Loss: 9.181218592857476e-05, Final Batch Loss: 1.9956058167736046e-05\n",
      "Epoch 2685, Loss: 3.636256224126555e-05, Final Batch Loss: 1.8359458408667706e-05\n",
      "Epoch 2686, Loss: 5.991656507831067e-05, Final Batch Loss: 4.272391379345208e-06\n",
      "Epoch 2687, Loss: 6.197967923071701e-05, Final Batch Loss: 3.815111267613247e-05\n",
      "Epoch 2688, Loss: 0.0004663655490730889, Final Batch Loss: 3.3909025660250336e-05\n",
      "Epoch 2689, Loss: 3.2464055038872175e-05, Final Batch Loss: 1.3970562577014789e-05\n",
      "Epoch 2690, Loss: 1.3835413483320735e-05, Final Batch Loss: 5.771185897174291e-06\n",
      "Epoch 2691, Loss: 6.967593890294665e-05, Final Batch Loss: 5.671264079865068e-05\n",
      "Epoch 2692, Loss: 5.654978440361447e-05, Final Batch Loss: 4.908630944555625e-05\n",
      "Epoch 2693, Loss: 0.0004892432607448427, Final Batch Loss: 2.660350401129108e-05\n",
      "Epoch 2694, Loss: 2.1192794065427734e-05, Final Batch Loss: 3.46512524629361e-06\n",
      "Epoch 2695, Loss: 0.0013267284375615418, Final Batch Loss: 0.0009820085251703858\n",
      "Epoch 2696, Loss: 6.0358344853739254e-05, Final Batch Loss: 4.979328878107481e-05\n",
      "Epoch 2697, Loss: 9.021725145430537e-05, Final Batch Loss: 3.2994475986924954e-06\n",
      "Epoch 2698, Loss: 9.017284719448071e-05, Final Batch Loss: 7.717165863141418e-05\n",
      "Epoch 2699, Loss: 0.00010472509529790841, Final Batch Loss: 5.918976239627227e-05\n",
      "Epoch 2700, Loss: 0.0015782345617481042, Final Batch Loss: 0.0015251636505126953\n",
      "Epoch 2701, Loss: 0.00017289670404352364, Final Batch Loss: 6.019472948537441e-06\n",
      "Epoch 2702, Loss: 6.143039809103357e-05, Final Batch Loss: 1.3041001693636645e-05\n",
      "Epoch 2703, Loss: 0.002390758425462991, Final Batch Loss: 0.0014611107762902975\n",
      "Epoch 2704, Loss: 0.00010004039927480335, Final Batch Loss: 3.0439534839388216e-06\n",
      "Epoch 2705, Loss: 3.251462294429075e-05, Final Batch Loss: 3.6334276956040412e-06\n",
      "Epoch 2706, Loss: 4.863940193899907e-05, Final Batch Loss: 1.9683799109770916e-05\n",
      "Epoch 2707, Loss: 0.00011699551760102622, Final Batch Loss: 4.524359610513784e-05\n",
      "Epoch 2708, Loss: 0.004341798673522135, Final Batch Loss: 1.0388742339273449e-05\n",
      "Epoch 2709, Loss: 0.00036463332071434706, Final Batch Loss: 0.0003192070289514959\n",
      "Epoch 2710, Loss: 7.948844722704962e-05, Final Batch Loss: 5.2457620768109336e-05\n",
      "Epoch 2711, Loss: 3.621991982072359e-05, Final Batch Loss: 2.661031248862855e-05\n",
      "Epoch 2712, Loss: 3.959086643590126e-05, Final Batch Loss: 1.7199939975398593e-05\n",
      "Epoch 2713, Loss: 1.6380085980927106e-05, Final Batch Loss: 5.034802597947419e-06\n",
      "Epoch 2714, Loss: 6.941348874534015e-05, Final Batch Loss: 5.980568676022813e-05\n",
      "Epoch 2715, Loss: 5.097473149362486e-05, Final Batch Loss: 1.5708001228631474e-05\n",
      "Epoch 2716, Loss: 5.512659572559642e-05, Final Batch Loss: 4.3623658712022007e-05\n",
      "Epoch 2717, Loss: 3.118257336609531e-05, Final Batch Loss: 1.2859078196925111e-05\n",
      "Epoch 2718, Loss: 4.361040373623837e-05, Final Batch Loss: 2.5839202862698585e-05\n",
      "Epoch 2719, Loss: 5.595687616732903e-05, Final Batch Loss: 2.0025687263114378e-05\n",
      "Epoch 2720, Loss: 3.233030804494774e-05, Final Batch Loss: 1.3557925058194087e-06\n",
      "Epoch 2721, Loss: 9.21988466870971e-05, Final Batch Loss: 5.273080023471266e-05\n",
      "Epoch 2722, Loss: 0.000410499531426467, Final Batch Loss: 0.00029498242656700313\n",
      "Epoch 2723, Loss: 6.581107868441904e-05, Final Batch Loss: 6.279459194047377e-05\n",
      "Epoch 2724, Loss: 6.371664130710997e-05, Final Batch Loss: 2.8670925530605018e-05\n",
      "Epoch 2725, Loss: 0.003080604505385054, Final Batch Loss: 2.0523095827229554e-06\n",
      "Epoch 2726, Loss: 4.3323127101757564e-05, Final Batch Loss: 3.677576387417503e-05\n",
      "Epoch 2727, Loss: 9.758231044543209e-06, Final Batch Loss: 4.417406216816744e-06\n",
      "Epoch 2728, Loss: 2.71250210062135e-05, Final Batch Loss: 4.469142368179746e-06\n",
      "Epoch 2729, Loss: 7.25047411833657e-05, Final Batch Loss: 5.375683031161316e-05\n",
      "Epoch 2730, Loss: 0.0005099231366330059, Final Batch Loss: 1.8543143596616574e-05\n",
      "Epoch 2731, Loss: 0.000350182359397877, Final Batch Loss: 0.00027415636577643454\n",
      "Epoch 2732, Loss: 0.001598682618350722, Final Batch Loss: 0.0013851444236934185\n",
      "Epoch 2733, Loss: 0.002868627851967176, Final Batch Loss: 1.5003096450527664e-05\n",
      "Epoch 2734, Loss: 0.0020770047303813044, Final Batch Loss: 1.8447030015522614e-05\n",
      "Epoch 2735, Loss: 7.732197263976559e-05, Final Batch Loss: 1.1908385204151273e-05\n",
      "Epoch 2736, Loss: 0.00017056872638931964, Final Batch Loss: 0.00016286858590319753\n",
      "Epoch 2737, Loss: 1.795240314095281e-05, Final Batch Loss: 1.08920121419942e-05\n",
      "Epoch 2738, Loss: 4.8191188398050144e-05, Final Batch Loss: 2.1850295524927787e-05\n",
      "Epoch 2739, Loss: 3.859831849695183e-05, Final Batch Loss: 1.8596654626890086e-05\n",
      "Epoch 2740, Loss: 7.783226465107873e-05, Final Batch Loss: 5.101282295072451e-05\n",
      "Epoch 2741, Loss: 9.138329733104911e-05, Final Batch Loss: 7.236134842969477e-05\n",
      "Epoch 2742, Loss: 0.0016608228906989098, Final Batch Loss: 0.0005557623226195574\n",
      "Epoch 2743, Loss: 3.982789348810911e-05, Final Batch Loss: 2.2285741579253227e-05\n",
      "Epoch 2744, Loss: 3.182330783602083e-05, Final Batch Loss: 3.748192284547258e-06\n",
      "Epoch 2745, Loss: 0.0012313717452343553, Final Batch Loss: 0.00029663779423572123\n",
      "Epoch 2746, Loss: 2.0987479729228653e-05, Final Batch Loss: 9.262425010092556e-06\n",
      "Epoch 2747, Loss: 0.000778347418076919, Final Batch Loss: 1.4763687659069546e-06\n",
      "Epoch 2748, Loss: 3.392841972527094e-05, Final Batch Loss: 1.7261760149267502e-05\n",
      "Epoch 2749, Loss: 0.00015653408081561793, Final Batch Loss: 2.0536203010124154e-05\n",
      "Epoch 2750, Loss: 3.163523683724634e-05, Final Batch Loss: 2.788092206174042e-05\n",
      "Epoch 2751, Loss: 0.0022797029887442477, Final Batch Loss: 0.002219939138740301\n",
      "Epoch 2752, Loss: 6.060448686184827e-05, Final Batch Loss: 3.2007519621402025e-05\n",
      "Epoch 2753, Loss: 0.0016525688145065942, Final Batch Loss: 2.837160764102009e-06\n",
      "Epoch 2754, Loss: 0.0016607846628176048, Final Batch Loss: 0.0015907678753137589\n",
      "Epoch 2755, Loss: 0.0001585766885909834, Final Batch Loss: 9.594086805009283e-07\n",
      "Epoch 2756, Loss: 0.00015836789316381328, Final Batch Loss: 0.0001496371260145679\n",
      "Epoch 2757, Loss: 0.0002654228374012746, Final Batch Loss: 0.00021172422566451132\n",
      "Epoch 2758, Loss: 0.0031750242924317718, Final Batch Loss: 0.00044612737838178873\n",
      "Epoch 2759, Loss: 0.020247927954187617, Final Batch Loss: 0.02015751041471958\n",
      "Epoch 2760, Loss: 3.296211434644647e-05, Final Batch Loss: 1.683193477219902e-05\n",
      "Epoch 2761, Loss: 0.0005360658644804062, Final Batch Loss: 3.381191390872118e-06\n",
      "Epoch 2762, Loss: 7.470247328456026e-05, Final Batch Loss: 1.7544347429065965e-05\n",
      "Epoch 2763, Loss: 7.774506684654625e-05, Final Batch Loss: 1.4610978723794688e-05\n",
      "Epoch 2764, Loss: 0.0017059688834706321, Final Batch Loss: 0.0016512017464265227\n",
      "Epoch 2765, Loss: 9.707452045404352e-05, Final Batch Loss: 4.465729580260813e-05\n",
      "Epoch 2766, Loss: 0.0006824588608651538, Final Batch Loss: 0.0006677285418845713\n",
      "Epoch 2767, Loss: 0.0005914914218010381, Final Batch Loss: 1.8076985725201666e-05\n",
      "Epoch 2768, Loss: 0.0002645667682372732, Final Batch Loss: 0.00023762782802805305\n",
      "Epoch 2769, Loss: 2.196444552282628e-05, Final Batch Loss: 1.917097506520804e-05\n",
      "Epoch 2770, Loss: 4.0224560166279844e-05, Final Batch Loss: 1.5037109051263542e-06\n",
      "Epoch 2771, Loss: 4.274442471796647e-05, Final Batch Loss: 2.7451047571958043e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2772, Loss: 0.00043771435593953356, Final Batch Loss: 0.0004034434969071299\n",
      "Epoch 2773, Loss: 9.209914423990995e-06, Final Batch Loss: 2.6481334316486027e-06\n",
      "Epoch 2774, Loss: 2.2035329948266735e-05, Final Batch Loss: 1.715217331366148e-05\n",
      "Epoch 2775, Loss: 6.704309816996101e-05, Final Batch Loss: 5.564920138567686e-05\n",
      "Epoch 2776, Loss: 8.327999137236475e-05, Final Batch Loss: 1.7298433476753416e-06\n",
      "Epoch 2777, Loss: 1.053453729582543e-05, Final Batch Loss: 2.5592773909011157e-06\n",
      "Epoch 2778, Loss: 5.866097262696712e-05, Final Batch Loss: 5.3050258429721e-05\n",
      "Epoch 2779, Loss: 9.9539143320726e-05, Final Batch Loss: 5.74499199501588e-06\n",
      "Epoch 2780, Loss: 0.0006950168472030782, Final Batch Loss: 9.288633918913547e-06\n",
      "Epoch 2781, Loss: 1.94013840655316e-05, Final Batch Loss: 1.7500418607596657e-06\n",
      "Epoch 2782, Loss: 0.00012078466534148902, Final Batch Loss: 1.2035437976010144e-05\n",
      "Epoch 2783, Loss: 2.424854119453812e-05, Final Batch Loss: 6.104878593760077e-06\n",
      "Epoch 2784, Loss: 5.6434349971823394e-05, Final Batch Loss: 3.95305069105234e-05\n",
      "Epoch 2785, Loss: 2.6232416075799847e-05, Final Batch Loss: 6.685632342851022e-06\n",
      "Epoch 2786, Loss: 8.728525608603377e-05, Final Batch Loss: 2.7804102501249872e-05\n",
      "Epoch 2787, Loss: 0.0012995718425372615, Final Batch Loss: 0.0001469301205361262\n",
      "Epoch 2788, Loss: 2.9945487767690793e-05, Final Batch Loss: 1.6762120139901526e-05\n",
      "Epoch 2789, Loss: 0.00024225650122389197, Final Batch Loss: 2.743476943578571e-05\n",
      "Epoch 2790, Loss: 4.724609789263923e-05, Final Batch Loss: 3.1702988053439185e-05\n",
      "Epoch 2791, Loss: 0.0011061329641961493, Final Batch Loss: 4.776716377818957e-05\n",
      "Epoch 2792, Loss: 0.0012839708639376113, Final Batch Loss: 1.42757073717803e-06\n",
      "Epoch 2793, Loss: 2.9423234082059935e-05, Final Batch Loss: 1.087027158064302e-05\n",
      "Epoch 2794, Loss: 0.0001362428206448385, Final Batch Loss: 3.9163182918855455e-06\n",
      "Epoch 2795, Loss: 3.5806328924081754e-05, Final Batch Loss: 8.163365237123799e-06\n",
      "Epoch 2796, Loss: 7.79177990750668e-06, Final Batch Loss: 1.3859845182651043e-07\n",
      "Epoch 2797, Loss: 0.00024182586821552832, Final Batch Loss: 4.825475116376765e-06\n",
      "Epoch 2798, Loss: 9.44989243123473e-06, Final Batch Loss: 1.6229624577590585e-07\n",
      "Epoch 2799, Loss: 9.307286381954327e-05, Final Batch Loss: 5.807583511341363e-05\n",
      "Epoch 2800, Loss: 0.0001317953283432871, Final Batch Loss: 5.8818928664550185e-05\n",
      "Epoch 2801, Loss: 0.003151901863020612, Final Batch Loss: 2.3281998437596485e-05\n",
      "Epoch 2802, Loss: 1.3778368156636134e-05, Final Batch Loss: 7.394451586151263e-06\n",
      "Epoch 2803, Loss: 0.00020778899579454446, Final Batch Loss: 1.162239732366288e-05\n",
      "Epoch 2804, Loss: 3.6224877476342954e-05, Final Batch Loss: 6.356716767186299e-06\n",
      "Epoch 2805, Loss: 0.00013808250878355466, Final Batch Loss: 8.722924394533038e-05\n",
      "Epoch 2806, Loss: 7.015520532149822e-05, Final Batch Loss: 3.304616257082671e-05\n",
      "Epoch 2807, Loss: 8.743626312934794e-05, Final Batch Loss: 8.223400800488889e-05\n",
      "Epoch 2808, Loss: 8.031470315472689e-06, Final Batch Loss: 3.894786914315773e-06\n",
      "Epoch 2809, Loss: 0.000134497433236902, Final Batch Loss: 2.3279314973478904e-06\n",
      "Epoch 2810, Loss: 0.0007849023641028907, Final Batch Loss: 3.132549682050012e-05\n",
      "Epoch 2811, Loss: 0.00020659542860812508, Final Batch Loss: 2.9626644391100854e-06\n",
      "Epoch 2812, Loss: 5.772195254394319e-05, Final Batch Loss: 4.725318285636604e-05\n",
      "Epoch 2813, Loss: 0.0005427655014500488, Final Batch Loss: 2.1303789253579453e-05\n",
      "Epoch 2814, Loss: 0.000206240303668892, Final Batch Loss: 0.00014522885612677783\n",
      "Epoch 2815, Loss: 4.5949709601700306e-05, Final Batch Loss: 2.5749315682332963e-05\n",
      "Epoch 2816, Loss: 3.838142083623097e-05, Final Batch Loss: 3.555764851626009e-05\n",
      "Epoch 2817, Loss: 0.0003629724378697574, Final Batch Loss: 0.00031073502032086253\n",
      "Epoch 2818, Loss: 2.3796655113983434e-05, Final Batch Loss: 1.4109154108155053e-05\n",
      "Epoch 2819, Loss: 0.000404530372179579, Final Batch Loss: 0.00011719104804797098\n",
      "Epoch 2820, Loss: 0.00011974926019320264, Final Batch Loss: 0.00010869298421312124\n",
      "Epoch 2821, Loss: 6.93219462846173e-05, Final Batch Loss: 4.926096517010592e-05\n",
      "Epoch 2822, Loss: 0.0003793313033213508, Final Batch Loss: 3.9640397631046653e-07\n",
      "Epoch 2823, Loss: 0.00030328980938065797, Final Batch Loss: 2.152596425730735e-05\n",
      "Epoch 2824, Loss: 0.0007388846897811163, Final Batch Loss: 3.6173634725855663e-05\n",
      "Epoch 2825, Loss: 6.030965778336395e-06, Final Batch Loss: 2.7969285838480573e-06\n",
      "Epoch 2826, Loss: 0.00015496582454943564, Final Batch Loss: 0.00014442080282606184\n",
      "Epoch 2827, Loss: 2.090951375066652e-05, Final Batch Loss: 1.4069431017560419e-05\n",
      "Epoch 2828, Loss: 0.0005305215946691533, Final Batch Loss: 1.5776951158841257e-06\n",
      "Epoch 2829, Loss: 0.0001332672982243821, Final Batch Loss: 9.250987932318822e-05\n",
      "Epoch 2830, Loss: 4.618956700142007e-05, Final Batch Loss: 1.6289865016005933e-05\n",
      "Epoch 2831, Loss: 5.105210891542811e-05, Final Batch Loss: 1.0448342209201655e-06\n",
      "Epoch 2832, Loss: 2.9196775358286686e-05, Final Batch Loss: 9.29075395106338e-06\n",
      "Epoch 2833, Loss: 0.00024340101572306594, Final Batch Loss: 9.538801350572612e-06\n",
      "Epoch 2834, Loss: 0.00041542867711541476, Final Batch Loss: 1.3539906831283588e-05\n",
      "Epoch 2835, Loss: 7.570065554318717e-05, Final Batch Loss: 1.4241776625567582e-05\n",
      "Epoch 2836, Loss: 0.0018740907307801535, Final Batch Loss: 5.094892912893556e-06\n",
      "Epoch 2837, Loss: 1.4221051429785803e-05, Final Batch Loss: 3.375165817942616e-07\n",
      "Epoch 2838, Loss: 2.7069458838013816e-05, Final Batch Loss: 3.0947965115046827e-06\n",
      "Epoch 2839, Loss: 0.0012765241335728206, Final Batch Loss: 7.49244136386551e-05\n",
      "Epoch 2840, Loss: 1.5409141042255214e-05, Final Batch Loss: 2.373212510065059e-06\n",
      "Epoch 2841, Loss: 0.00044205994254298275, Final Batch Loss: 1.0419083082524594e-05\n",
      "Epoch 2842, Loss: 0.004423687045346014, Final Batch Loss: 0.00014429008297156543\n",
      "Epoch 2843, Loss: 1.2533409517345717e-05, Final Batch Loss: 3.711500994540984e-06\n",
      "Epoch 2844, Loss: 0.0007078127791828592, Final Batch Loss: 0.0007002045749686658\n",
      "Epoch 2845, Loss: 0.0001759398173817317, Final Batch Loss: 0.00017134369409177452\n",
      "Epoch 2846, Loss: 0.00014991011084930506, Final Batch Loss: 6.280946763581596e-06\n",
      "Epoch 2847, Loss: 6.266214359129663e-05, Final Batch Loss: 5.3506587391893845e-06\n",
      "Epoch 2848, Loss: 2.772109382931376e-05, Final Batch Loss: 1.131189947045641e-05\n",
      "Epoch 2849, Loss: 0.00023448581669072155, Final Batch Loss: 9.418736226507463e-06\n",
      "Epoch 2850, Loss: 1.2975701793038752e-05, Final Batch Loss: 1.1286859262327198e-05\n",
      "Epoch 2851, Loss: 8.9634794221638e-05, Final Batch Loss: 2.975446932396153e-06\n",
      "Epoch 2852, Loss: 7.615954271500414e-05, Final Batch Loss: 3.525990734942752e-07\n",
      "Epoch 2853, Loss: 2.4591087367298314e-05, Final Batch Loss: 4.152776909904787e-06\n",
      "Epoch 2854, Loss: 0.00029457840719260275, Final Batch Loss: 3.961593029089272e-05\n",
      "Epoch 2855, Loss: 6.17347232036991e-05, Final Batch Loss: 3.1980176572687924e-05\n",
      "Epoch 2856, Loss: 0.0002046975088205727, Final Batch Loss: 1.004645241664548e-06\n",
      "Epoch 2857, Loss: 3.4059759173032944e-05, Final Batch Loss: 7.460996584995883e-07\n",
      "Epoch 2858, Loss: 4.156175263148043e-05, Final Batch Loss: 1.077189963893943e-07\n",
      "Epoch 2859, Loss: 2.277661906191497e-05, Final Batch Loss: 1.770235576259438e-05\n",
      "Epoch 2860, Loss: 0.005385688738897443, Final Batch Loss: 0.004793263040482998\n",
      "Epoch 2861, Loss: 1.0294136245647678e-05, Final Batch Loss: 2.7854930522153154e-06\n",
      "Epoch 2862, Loss: 3.521032931530499e-05, Final Batch Loss: 4.340500254329527e-06\n",
      "Epoch 2863, Loss: 0.001660677353356732, Final Batch Loss: 0.0016063963994383812\n",
      "Epoch 2864, Loss: 0.00035300987292430364, Final Batch Loss: 1.5782421542098746e-05\n",
      "Epoch 2865, Loss: 0.0008493369350617286, Final Batch Loss: 0.0008286944939754903\n",
      "Epoch 2866, Loss: 1.0541835649746645e-05, Final Batch Loss: 8.795723260845989e-06\n",
      "Epoch 2867, Loss: 2.29444585784222e-05, Final Batch Loss: 4.103042556380387e-06\n",
      "Epoch 2868, Loss: 1.5027686458779499e-05, Final Batch Loss: 1.03576812762185e-05\n",
      "Epoch 2869, Loss: 0.0001756469594056398, Final Batch Loss: 0.0001725343317957595\n",
      "Epoch 2870, Loss: 0.0002287438946950715, Final Batch Loss: 1.0146042768610641e-05\n",
      "Epoch 2871, Loss: 0.00042464899888727814, Final Batch Loss: 0.00017023370310198516\n",
      "Epoch 2872, Loss: 0.0001783922689355677, Final Batch Loss: 0.00015904493920970708\n",
      "Epoch 2873, Loss: 3.9719798223813996e-05, Final Batch Loss: 3.130402910755947e-05\n",
      "Epoch 2874, Loss: 7.456023013219237e-05, Final Batch Loss: 3.0060993594815955e-05\n",
      "Epoch 2875, Loss: 0.00119988656069836, Final Batch Loss: 0.0011956222588196397\n",
      "Epoch 2876, Loss: 0.00019816822577922721, Final Batch Loss: 0.0001953112951014191\n",
      "Epoch 2877, Loss: 5.353308552003e-05, Final Batch Loss: 2.052347372227814e-05\n",
      "Epoch 2878, Loss: 2.9538040280385758e-06, Final Batch Loss: 1.1267053423580364e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2879, Loss: 0.00010292020670021884, Final Batch Loss: 7.122502574929968e-05\n",
      "Epoch 2880, Loss: 1.1622204169725592e-05, Final Batch Loss: 1.7880616951515549e-06\n",
      "Epoch 2881, Loss: 0.0005447400744742481, Final Batch Loss: 0.0005416194908320904\n",
      "Epoch 2882, Loss: 5.127819167682901e-05, Final Batch Loss: 2.0838342607021332e-05\n",
      "Epoch 2883, Loss: 4.052123586006928e-05, Final Batch Loss: 2.2415029889089055e-05\n",
      "Epoch 2884, Loss: 6.139669039839646e-05, Final Batch Loss: 3.149430085613858e-06\n",
      "Epoch 2885, Loss: 2.2955628395493477e-05, Final Batch Loss: 2.0179354009997041e-07\n",
      "Epoch 2886, Loss: 5.0603495481027494e-05, Final Batch Loss: 5.013047848478891e-05\n",
      "Epoch 2887, Loss: 8.328631110998685e-06, Final Batch Loss: 6.09825747233117e-06\n",
      "Epoch 2888, Loss: 1.9353616153239273e-05, Final Batch Loss: 1.075964974006638e-05\n",
      "Epoch 2889, Loss: 0.00021287143590598134, Final Batch Loss: 8.973681360657793e-06\n",
      "Epoch 2890, Loss: 0.0011722191993612796, Final Batch Loss: 0.00026963072014041245\n",
      "Epoch 2891, Loss: 8.487192462780513e-05, Final Batch Loss: 8.056678780121729e-06\n",
      "Epoch 2892, Loss: 2.86364438579767e-05, Final Batch Loss: 9.162739843304735e-06\n",
      "Epoch 2893, Loss: 0.0005816053308080882, Final Batch Loss: 0.0005125616444274783\n",
      "Epoch 2894, Loss: 0.0003506169232423417, Final Batch Loss: 8.675190474605188e-05\n",
      "Epoch 2895, Loss: 0.0006877218766021542, Final Batch Loss: 2.236156433355063e-06\n",
      "Epoch 2896, Loss: 0.0005443414472665609, Final Batch Loss: 9.285201940656407e-07\n",
      "Epoch 2897, Loss: 4.261431786289904e-05, Final Batch Loss: 3.858756826957688e-05\n",
      "Epoch 2898, Loss: 4.789710033037409e-06, Final Batch Loss: 4.053485554322833e-06\n",
      "Epoch 2899, Loss: 5.748604507971322e-05, Final Batch Loss: 5.370611324906349e-05\n",
      "Epoch 2900, Loss: 0.0014006401397637092, Final Batch Loss: 0.0013532593147829175\n",
      "Epoch 2901, Loss: 1.3937044286649325e-05, Final Batch Loss: 2.154955154765048e-06\n",
      "Epoch 2902, Loss: 8.494860480823263e-06, Final Batch Loss: 1.322681669080339e-06\n",
      "Epoch 2903, Loss: 2.082856917695608e-05, Final Batch Loss: 9.503816727374215e-06\n",
      "Epoch 2904, Loss: 0.0025396064738743007, Final Batch Loss: 0.002090826164931059\n",
      "Epoch 2905, Loss: 0.00502785584603771, Final Batch Loss: 3.0571659408451524e-06\n",
      "Epoch 2906, Loss: 5.2328490710351616e-05, Final Batch Loss: 3.243577521061525e-05\n",
      "Epoch 2907, Loss: 2.1371765797084663e-05, Final Batch Loss: 1.265258379135048e-05\n",
      "Epoch 2908, Loss: 0.0010211019834969193, Final Batch Loss: 1.620702096261084e-05\n",
      "Epoch 2909, Loss: 3.140965350212355e-05, Final Batch Loss: 2.059471853499417e-06\n",
      "Epoch 2910, Loss: 3.0863080155540956e-05, Final Batch Loss: 2.6515554054640234e-05\n",
      "Epoch 2911, Loss: 0.0012924915849907848, Final Batch Loss: 0.0012881089933216572\n",
      "Epoch 2912, Loss: 6.081606670704787e-06, Final Batch Loss: 1.265310174858314e-06\n",
      "Epoch 2913, Loss: 9.00610120879719e-05, Final Batch Loss: 8.402859748457558e-06\n",
      "Epoch 2914, Loss: 6.990210522417328e-06, Final Batch Loss: 9.65856770562823e-07\n",
      "Epoch 2915, Loss: 5.592749948846176e-05, Final Batch Loss: 4.5713226427324116e-05\n",
      "Epoch 2916, Loss: 0.0008383427076523731, Final Batch Loss: 1.5072902215251816e-06\n",
      "Epoch 2917, Loss: 7.045495294732973e-05, Final Batch Loss: 2.2674186766380444e-05\n",
      "Epoch 2918, Loss: 0.00045513139775721356, Final Batch Loss: 0.0003893809043802321\n",
      "Epoch 2919, Loss: 0.0005054611673358522, Final Batch Loss: 0.0005043020355515182\n",
      "Epoch 2920, Loss: 4.932119463774143e-05, Final Batch Loss: 1.3218620551924687e-05\n",
      "Epoch 2921, Loss: 9.448920877730416e-06, Final Batch Loss: 1.4699493249281659e-06\n",
      "Epoch 2922, Loss: 0.000534991042513866, Final Batch Loss: 4.82303585158661e-06\n",
      "Epoch 2923, Loss: 6.797769674449228e-05, Final Batch Loss: 4.5559681893792e-06\n",
      "Epoch 2924, Loss: 0.0006221327957973699, Final Batch Loss: 1.1458006156317424e-05\n",
      "Epoch 2925, Loss: 6.86576222506119e-05, Final Batch Loss: 4.482752046897076e-06\n",
      "Epoch 2926, Loss: 1.7146518075605854e-05, Final Batch Loss: 7.354828994721174e-06\n",
      "Epoch 2927, Loss: 0.00029746269137831405, Final Batch Loss: 1.613909989828244e-05\n",
      "Epoch 2928, Loss: 7.20545467629563e-05, Final Batch Loss: 4.038826227770187e-05\n",
      "Epoch 2929, Loss: 0.0007902284851297736, Final Batch Loss: 0.0007402991759590805\n",
      "Epoch 2930, Loss: 1.5977784187271027e-05, Final Batch Loss: 1.5021753824839834e-05\n",
      "Epoch 2931, Loss: 4.3992728024022654e-05, Final Batch Loss: 3.3391243050573394e-05\n",
      "Epoch 2932, Loss: 0.00020240228536749783, Final Batch Loss: 3.009454530911171e-06\n",
      "Epoch 2933, Loss: 0.0005057306470916956, Final Batch Loss: 1.0991257113346364e-05\n",
      "Epoch 2934, Loss: 1.2890002608401119e-05, Final Batch Loss: 2.8629535790969385e-06\n",
      "Epoch 2935, Loss: 9.871033989838907e-05, Final Batch Loss: 5.3022945394332055e-06\n",
      "Epoch 2936, Loss: 0.0001586843700351892, Final Batch Loss: 0.00014866756100673229\n",
      "Epoch 2937, Loss: 6.315921154964599e-06, Final Batch Loss: 2.6332413654017728e-06\n",
      "Epoch 2938, Loss: 5.091614912089426e-05, Final Batch Loss: 3.105173527728766e-05\n",
      "Epoch 2939, Loss: 0.02727422324824147, Final Batch Loss: 0.0001069681893568486\n",
      "Epoch 2940, Loss: 0.00011215642825845862, Final Batch Loss: 0.00010672557255020365\n",
      "Epoch 2941, Loss: 5.944660097156884e-05, Final Batch Loss: 1.2147568668297026e-05\n",
      "Epoch 2942, Loss: 0.006438512667955365, Final Batch Loss: 4.233544314047322e-05\n",
      "Epoch 2943, Loss: 0.00030695208988618106, Final Batch Loss: 0.00017658789874985814\n",
      "Epoch 2944, Loss: 0.0037724213407273055, Final Batch Loss: 0.0037589040584862232\n",
      "Epoch 2945, Loss: 0.0002582161614554934, Final Batch Loss: 3.196793113602325e-05\n",
      "Epoch 2946, Loss: 0.00019705799786606804, Final Batch Loss: 1.9849023374263197e-05\n",
      "Epoch 2947, Loss: 0.0006006622843415244, Final Batch Loss: 0.0005823601968586445\n",
      "Epoch 2948, Loss: 0.00010930861026281491, Final Batch Loss: 5.587359191849828e-05\n",
      "Epoch 2949, Loss: 0.00032261871092487127, Final Batch Loss: 0.00010379689047113061\n",
      "Epoch 2950, Loss: 0.004412128335388843, Final Batch Loss: 0.00011552705109352246\n",
      "Epoch 2951, Loss: 5.816817792947404e-05, Final Batch Loss: 1.4821478544035926e-05\n",
      "Epoch 2952, Loss: 2.7380933261156315e-05, Final Batch Loss: 2.2260892365011387e-05\n",
      "Epoch 2953, Loss: 0.00033942806476261467, Final Batch Loss: 0.00023970699112396687\n",
      "Epoch 2954, Loss: 6.048783325240947e-05, Final Batch Loss: 1.929073187056929e-05\n",
      "Epoch 2955, Loss: 0.0001522068450867664, Final Batch Loss: 0.0001160128231276758\n",
      "Epoch 2956, Loss: 6.296536594163626e-05, Final Batch Loss: 2.3926473659230396e-05\n",
      "Epoch 2957, Loss: 8.375859761144966e-05, Final Batch Loss: 2.176347334170714e-05\n",
      "Epoch 2958, Loss: 0.0017876882925520476, Final Batch Loss: 0.0017827420961111784\n",
      "Epoch 2959, Loss: 0.0014710618197568692, Final Batch Loss: 0.0013596699573099613\n",
      "Epoch 2960, Loss: 3.100880894635338e-05, Final Batch Loss: 3.386039679753594e-06\n",
      "Epoch 2961, Loss: 0.0008455082497675903, Final Batch Loss: 9.150838741334155e-05\n",
      "Epoch 2962, Loss: 0.00010974656470352784, Final Batch Loss: 4.26874466938898e-05\n",
      "Epoch 2963, Loss: 2.7012556529371068e-05, Final Batch Loss: 9.56270559981931e-06\n",
      "Epoch 2964, Loss: 3.968472356064012e-05, Final Batch Loss: 2.7797910661320202e-05\n",
      "Epoch 2965, Loss: 0.00015180979607976042, Final Batch Loss: 9.718359069665894e-05\n",
      "Epoch 2966, Loss: 0.0002716948183660861, Final Batch Loss: 2.1330979507183656e-05\n",
      "Epoch 2967, Loss: 0.0001817319825931918, Final Batch Loss: 3.19092177960556e-05\n",
      "Epoch 2968, Loss: 0.0005120110217831098, Final Batch Loss: 0.0004881721979472786\n",
      "Epoch 2969, Loss: 2.413871516182553e-05, Final Batch Loss: 5.669668098562397e-06\n",
      "Epoch 2970, Loss: 0.0010404969016235555, Final Batch Loss: 2.845508606696967e-05\n",
      "Epoch 2971, Loss: 0.00013747042248724028, Final Batch Loss: 0.00012035330291837454\n",
      "Epoch 2972, Loss: 0.0010342905425204663, Final Batch Loss: 1.5343552149715833e-05\n",
      "Epoch 2973, Loss: 7.259570884343702e-05, Final Batch Loss: 2.7495991162140854e-05\n",
      "Epoch 2974, Loss: 0.0030118495342321694, Final Batch Loss: 0.000767511606682092\n",
      "Epoch 2975, Loss: 8.994145900942385e-06, Final Batch Loss: 5.406139734986937e-06\n",
      "Epoch 2976, Loss: 0.00014462256513070315, Final Batch Loss: 2.157097333110869e-05\n",
      "Epoch 2977, Loss: 1.6663240785419475e-05, Final Batch Loss: 9.311143912782427e-06\n",
      "Epoch 2978, Loss: 0.00014902516340953298, Final Batch Loss: 3.4973669244209304e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2979, Loss: 0.0003755756151804235, Final Batch Loss: 0.00035444306558929384\n",
      "Epoch 2980, Loss: 5.143513135408284e-05, Final Batch Loss: 4.132466347073205e-05\n",
      "Epoch 2981, Loss: 9.43466347962385e-05, Final Batch Loss: 1.9046607121708803e-05\n",
      "Epoch 2982, Loss: 5.4966609241091646e-05, Final Batch Loss: 3.279747397755273e-05\n",
      "Epoch 2983, Loss: 0.003142567176837474, Final Batch Loss: 0.00037892285035923123\n",
      "Epoch 2984, Loss: 8.929906198318349e-05, Final Batch Loss: 8.08013355708681e-05\n",
      "Epoch 2985, Loss: 1.1527948799994192e-05, Final Batch Loss: 1.0312003269064007e-06\n",
      "Epoch 2986, Loss: 0.003611096879467368, Final Batch Loss: 9.696534834802151e-05\n",
      "Epoch 2987, Loss: 5.4041031035012566e-05, Final Batch Loss: 4.31773041782435e-05\n",
      "Epoch 2988, Loss: 1.98854986592778e-05, Final Batch Loss: 1.4558058865077328e-05\n",
      "Epoch 2989, Loss: 3.408042471164663e-05, Final Batch Loss: 3.1473748549615266e-06\n",
      "Epoch 2990, Loss: 6.35402948319097e-05, Final Batch Loss: 9.494245205132756e-06\n",
      "Epoch 2991, Loss: 4.261348976797308e-05, Final Batch Loss: 3.5964370908914134e-05\n",
      "Epoch 2992, Loss: 3.306196867924882e-05, Final Batch Loss: 2.094154478982091e-05\n",
      "Epoch 2993, Loss: 4.7914389597281115e-05, Final Batch Loss: 5.919050181546481e-06\n",
      "Epoch 2994, Loss: 1.265574883291265e-05, Final Batch Loss: 5.414754014054779e-06\n",
      "Epoch 2995, Loss: 5.992131627863273e-05, Final Batch Loss: 7.548074790975079e-06\n",
      "Epoch 2996, Loss: 9.074690183297207e-06, Final Batch Loss: 1.109490199269203e-06\n",
      "Epoch 2997, Loss: 0.00014892720082571032, Final Batch Loss: 9.440297617402393e-06\n",
      "Epoch 2998, Loss: 0.0002928905009866867, Final Batch Loss: 0.00028957147151231766\n",
      "Epoch 2999, Loss: 6.838330045866314e-05, Final Batch Loss: 5.5487806093879044e-05\n",
      "Epoch 3000, Loss: 3.208479847671697e-05, Final Batch Loss: 2.923076863226015e-06\n",
      "Epoch 3001, Loss: 0.00023478703860746464, Final Batch Loss: 0.00022362680465448648\n",
      "Epoch 3002, Loss: 7.993493272806518e-05, Final Batch Loss: 1.7628615751164034e-05\n",
      "Epoch 3003, Loss: 0.00017272459581363364, Final Batch Loss: 0.00016700697597116232\n",
      "Epoch 3004, Loss: 0.00011375798112567281, Final Batch Loss: 7.318768439290579e-06\n",
      "Epoch 3005, Loss: 0.003334782914862444, Final Batch Loss: 1.1123620424768887e-06\n",
      "Epoch 3006, Loss: 1.488187945142272e-05, Final Batch Loss: 1.1281131264695432e-06\n",
      "Epoch 3007, Loss: 6.295026469160803e-05, Final Batch Loss: 4.762413300340995e-05\n",
      "Epoch 3008, Loss: 6.799107495680801e-06, Final Batch Loss: 4.639280177798355e-06\n",
      "Epoch 3009, Loss: 2.5528696824039798e-05, Final Batch Loss: 6.795692570449319e-06\n",
      "Epoch 3010, Loss: 8.570081809011754e-05, Final Batch Loss: 6.116661825217307e-05\n",
      "Epoch 3011, Loss: 3.774174228965421e-05, Final Batch Loss: 2.6331149456382263e-06\n",
      "Epoch 3012, Loss: 0.000957107249632827, Final Batch Loss: 1.159469502454158e-05\n",
      "Epoch 3013, Loss: 2.408754426141968e-06, Final Batch Loss: 3.504442247503903e-07\n",
      "Epoch 3014, Loss: 0.0008067473845585482, Final Batch Loss: 1.4493738490273245e-05\n",
      "Epoch 3015, Loss: 0.0006531875187647529, Final Batch Loss: 0.0006270731100812554\n",
      "Epoch 3016, Loss: 1.4634766785093234e-05, Final Batch Loss: 1.7026034129230538e-06\n",
      "Epoch 3017, Loss: 1.60948852681031e-05, Final Batch Loss: 5.082731604488799e-06\n",
      "Epoch 3018, Loss: 3.85112471121829e-05, Final Batch Loss: 1.571715074533131e-05\n",
      "Epoch 3019, Loss: 0.00010577927469057613, Final Batch Loss: 9.996456356020644e-05\n",
      "Epoch 3020, Loss: 6.396128128471901e-05, Final Batch Loss: 6.234586635400774e-06\n",
      "Epoch 3021, Loss: 0.00015232792247843463, Final Batch Loss: 4.528557838057168e-06\n",
      "Epoch 3022, Loss: 1.056061000781483e-05, Final Batch Loss: 5.1002862164750695e-06\n",
      "Epoch 3023, Loss: 2.8239097673576907e-05, Final Batch Loss: 2.713661388042965e-06\n",
      "Epoch 3024, Loss: 1.757408881530864e-05, Final Batch Loss: 1.2527387298177928e-05\n",
      "Epoch 3025, Loss: 6.364486125676194e-06, Final Batch Loss: 3.1897216103971004e-06\n",
      "Epoch 3026, Loss: 5.334554089131416e-05, Final Batch Loss: 6.933971690159524e-06\n",
      "Epoch 3027, Loss: 4.084674583282322e-05, Final Batch Loss: 2.869811942218803e-05\n",
      "Epoch 3028, Loss: 0.000809633856988512, Final Batch Loss: 0.0007459561456926167\n",
      "Epoch 3029, Loss: 7.454480874002911e-05, Final Batch Loss: 5.5201049690367654e-05\n",
      "Epoch 3030, Loss: 9.338394738733768e-05, Final Batch Loss: 4.864135189563967e-05\n",
      "Epoch 3031, Loss: 6.27661356702447e-05, Final Batch Loss: 4.7761077439645305e-05\n",
      "Epoch 3032, Loss: 0.00018072551006298454, Final Batch Loss: 1.3342430520424386e-06\n",
      "Epoch 3033, Loss: 1.343936423836567e-05, Final Batch Loss: 1.01260666269809e-05\n",
      "Epoch 3034, Loss: 0.00015064014024801509, Final Batch Loss: 5.644340603794262e-07\n",
      "Epoch 3035, Loss: 0.00018395453662378713, Final Batch Loss: 0.00011805204849224538\n",
      "Epoch 3036, Loss: 0.00012983504029762116, Final Batch Loss: 0.0001250754139618948\n",
      "Epoch 3037, Loss: 0.0004247139804647304, Final Batch Loss: 0.00036699240445159376\n",
      "Epoch 3038, Loss: 1.951866488525411e-05, Final Batch Loss: 1.8465430912328884e-05\n",
      "Epoch 3039, Loss: 1.1289345366094494e-05, Final Batch Loss: 4.809459369425895e-06\n",
      "Epoch 3040, Loss: 0.00016945086099440232, Final Batch Loss: 0.00014835574256721884\n",
      "Epoch 3041, Loss: 0.0008290537953143939, Final Batch Loss: 0.000654946721624583\n",
      "Epoch 3042, Loss: 0.0026528204325586557, Final Batch Loss: 0.0005315057933330536\n",
      "Epoch 3043, Loss: 0.00011080854528700002, Final Batch Loss: 3.9971830119611695e-05\n",
      "Epoch 3044, Loss: 0.0007491189608117566, Final Batch Loss: 0.00017583945009391755\n",
      "Epoch 3045, Loss: 2.3174243324319832e-05, Final Batch Loss: 9.460935871175025e-06\n",
      "Epoch 3046, Loss: 9.993599360313965e-05, Final Batch Loss: 7.689438461966347e-06\n",
      "Epoch 3047, Loss: 8.969604004960274e-05, Final Batch Loss: 4.463449840841349e-06\n",
      "Epoch 3048, Loss: 2.7010395569959655e-05, Final Batch Loss: 3.4502954804338515e-06\n",
      "Epoch 3049, Loss: 0.0003501403087398103, Final Batch Loss: 6.276357567003288e-07\n",
      "Epoch 3050, Loss: 0.004630195733625442, Final Batch Loss: 0.00432105828076601\n",
      "Epoch 3051, Loss: 0.000716978809577995, Final Batch Loss: 1.060882095771376e-05\n",
      "Epoch 3052, Loss: 2.6975922082783654e-05, Final Batch Loss: 1.5684054233133793e-05\n",
      "Epoch 3053, Loss: 3.8185818993952125e-05, Final Batch Loss: 3.2713840482756495e-05\n",
      "Epoch 3054, Loss: 9.694188520370517e-06, Final Batch Loss: 4.060932951688301e-06\n",
      "Epoch 3055, Loss: 0.00027816842339234427, Final Batch Loss: 0.00019247875025030226\n",
      "Epoch 3056, Loss: 1.6597412837882075e-05, Final Batch Loss: 2.642704259869788e-07\n",
      "Epoch 3057, Loss: 0.0004939956997986883, Final Batch Loss: 3.760328399948776e-05\n",
      "Epoch 3058, Loss: 8.820253242447507e-06, Final Batch Loss: 4.030422587675275e-06\n",
      "Epoch 3059, Loss: 0.00019428712766966783, Final Batch Loss: 0.0001725068868836388\n",
      "Epoch 3060, Loss: 8.154550778272096e-05, Final Batch Loss: 5.437014624476433e-05\n",
      "Epoch 3061, Loss: 1.5087687643244863e-05, Final Batch Loss: 8.220250492740888e-06\n",
      "Epoch 3062, Loss: 4.304086814954644e-06, Final Batch Loss: 3.112053036602447e-06\n",
      "Epoch 3063, Loss: 0.00010136293576579192, Final Batch Loss: 9.627902909414843e-05\n",
      "Epoch 3064, Loss: 0.0006324073901851079, Final Batch Loss: 0.0006238769274204969\n",
      "Epoch 3065, Loss: 4.993783022655407e-06, Final Batch Loss: 2.1535852283705026e-06\n",
      "Epoch 3066, Loss: 2.904052348640107e-05, Final Batch Loss: 3.089043502768618e-06\n",
      "Epoch 3067, Loss: 6.018788280925946e-05, Final Batch Loss: 8.721789527044166e-06\n",
      "Epoch 3068, Loss: 0.00025579059547453653, Final Batch Loss: 0.00025200514937750995\n",
      "Epoch 3069, Loss: 4.297963323551812e-05, Final Batch Loss: 1.1942233868467156e-06\n",
      "Epoch 3070, Loss: 0.00029452469516400015, Final Batch Loss: 7.939393071865197e-06\n",
      "Epoch 3071, Loss: 0.00026050606174976565, Final Batch Loss: 0.00025462551275268197\n",
      "Epoch 3072, Loss: 3.293435565865366e-05, Final Batch Loss: 2.071022754535079e-05\n",
      "Epoch 3073, Loss: 0.0004221936551402905, Final Batch Loss: 0.0004092507006134838\n",
      "Epoch 3074, Loss: 0.00029567071760538965, Final Batch Loss: 2.7007496100850403e-05\n",
      "Epoch 3075, Loss: 5.160841737961164e-06, Final Batch Loss: 2.357372750338982e-06\n",
      "Epoch 3076, Loss: 4.740065196529031e-05, Final Batch Loss: 3.744779314729385e-05\n",
      "Epoch 3077, Loss: 2.7965132176177576e-05, Final Batch Loss: 2.59880289377179e-06\n",
      "Epoch 3078, Loss: 0.0006184329404277378, Final Batch Loss: 0.0006152786663733423\n",
      "Epoch 3079, Loss: 0.00105985245318152, Final Batch Loss: 0.0006659758510068059\n",
      "Epoch 3080, Loss: 0.0006985768820868543, Final Batch Loss: 1.5776865893712966e-06\n",
      "Epoch 3081, Loss: 0.00047042168807820417, Final Batch Loss: 4.188510138192214e-05\n",
      "Epoch 3082, Loss: 9.03759337234078e-06, Final Batch Loss: 3.975240815634606e-06\n",
      "Epoch 3083, Loss: 1.2522867280040373e-05, Final Batch Loss: 6.125521281319379e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3084, Loss: 8.286994125228375e-05, Final Batch Loss: 5.227619476499967e-05\n",
      "Epoch 3085, Loss: 2.153817627004173e-05, Final Batch Loss: 2.083342224068474e-05\n",
      "Epoch 3086, Loss: 0.001936925463184025, Final Batch Loss: 3.1956452062331664e-07\n",
      "Epoch 3087, Loss: 0.0008405080825468758, Final Batch Loss: 4.757481292472221e-06\n",
      "Epoch 3088, Loss: 8.936516678659245e-05, Final Batch Loss: 2.0056475477758795e-05\n",
      "Epoch 3089, Loss: 8.29988396162662e-05, Final Batch Loss: 7.934850873425603e-05\n",
      "Epoch 3090, Loss: 6.150570720819815e-05, Final Batch Loss: 2.446450025672675e-06\n",
      "Epoch 3091, Loss: 7.173165795393288e-05, Final Batch Loss: 7.953567546792328e-06\n",
      "Epoch 3092, Loss: 0.0006108461893745698, Final Batch Loss: 0.0005575811374001205\n",
      "Epoch 3093, Loss: 0.00011856524452014128, Final Batch Loss: 0.0001113688776968047\n",
      "Epoch 3094, Loss: 0.0005722795633573696, Final Batch Loss: 4.409250777825946e-07\n",
      "Epoch 3095, Loss: 2.1302817572177446e-06, Final Batch Loss: 5.759309829045378e-07\n",
      "Epoch 3096, Loss: 7.305307690330665e-06, Final Batch Loss: 3.580054453777848e-06\n",
      "Epoch 3097, Loss: 5.5029332543199416e-05, Final Batch Loss: 4.890559284831397e-05\n",
      "Epoch 3098, Loss: 1.1242926575505408e-05, Final Batch Loss: 4.921987056150101e-06\n",
      "Epoch 3099, Loss: 6.502393136997853e-05, Final Batch Loss: 1.3622126289192238e-06\n",
      "Epoch 3100, Loss: 4.2581790694384836e-05, Final Batch Loss: 4.113097020308487e-06\n",
      "Epoch 3101, Loss: 5.765084324593772e-06, Final Batch Loss: 3.294376483609085e-06\n",
      "Epoch 3102, Loss: 1.1657187542368774e-05, Final Batch Loss: 1.5000207440607483e-06\n",
      "Epoch 3103, Loss: 0.000684782033204101, Final Batch Loss: 0.0004593018675222993\n",
      "Epoch 3104, Loss: 9.125295036938041e-05, Final Batch Loss: 1.9838989828713238e-05\n",
      "Epoch 3105, Loss: 4.523242978393682e-05, Final Batch Loss: 3.9740575630276e-06\n",
      "Epoch 3106, Loss: 1.2199679702007415e-06, Final Batch Loss: 3.102287280398741e-07\n",
      "Epoch 3107, Loss: 0.0001533426038804464, Final Batch Loss: 6.443508755182847e-05\n",
      "Epoch 3108, Loss: 3.182624095643405e-05, Final Batch Loss: 4.9337249947711825e-06\n",
      "Epoch 3109, Loss: 0.00022689121215080377, Final Batch Loss: 0.00021413904323708266\n",
      "Epoch 3110, Loss: 0.00014029266822035424, Final Batch Loss: 0.00010021664638770744\n",
      "Epoch 3111, Loss: 1.739812398682261e-05, Final Batch Loss: 1.568787411088124e-05\n",
      "Epoch 3112, Loss: 5.180829066375736e-05, Final Batch Loss: 8.770128260948695e-06\n",
      "Epoch 3113, Loss: 2.380732951223763e-06, Final Batch Loss: 6.470273206105048e-07\n",
      "Epoch 3114, Loss: 1.1380354081325095e-06, Final Batch Loss: 3.518827185189366e-08\n",
      "Epoch 3115, Loss: 0.000560359261726262, Final Batch Loss: 2.3728051019134e-05\n",
      "Epoch 3116, Loss: 0.0008010909787117271, Final Batch Loss: 0.0007931991131044924\n",
      "Epoch 3117, Loss: 2.459246570651885e-05, Final Batch Loss: 1.4906177966622636e-05\n",
      "Epoch 3118, Loss: 0.00035656326690514106, Final Batch Loss: 1.9443354176473804e-05\n",
      "Epoch 3119, Loss: 0.00025383154934388585, Final Batch Loss: 2.086782842525281e-05\n",
      "Epoch 3120, Loss: 7.953856038511731e-05, Final Batch Loss: 1.0571497114142403e-05\n",
      "Epoch 3121, Loss: 4.183121973255766e-06, Final Batch Loss: 2.061520717688836e-06\n",
      "Epoch 3122, Loss: 3.3146197893074714e-05, Final Batch Loss: 9.44196835916955e-06\n",
      "Epoch 3123, Loss: 7.126957279979251e-05, Final Batch Loss: 3.778360041906126e-05\n",
      "Epoch 3124, Loss: 2.569083835624042e-05, Final Batch Loss: 2.1549189114011824e-05\n",
      "Epoch 3125, Loss: 0.0007266668844749802, Final Batch Loss: 1.0785888662212528e-06\n",
      "Epoch 3126, Loss: 2.9570838250947418e-05, Final Batch Loss: 3.9579576878168155e-06\n",
      "Epoch 3127, Loss: 4.55055846941832e-05, Final Batch Loss: 4.0105387597577646e-05\n",
      "Epoch 3128, Loss: 6.496908554254333e-05, Final Batch Loss: 5.790099748992361e-05\n",
      "Epoch 3129, Loss: 3.779992402996868e-05, Final Batch Loss: 1.685332608758472e-05\n",
      "Epoch 3130, Loss: 8.437678843620233e-06, Final Batch Loss: 2.2476779122371227e-06\n",
      "Epoch 3131, Loss: 7.08635593582585e-06, Final Batch Loss: 4.4703219828079455e-06\n",
      "Epoch 3132, Loss: 0.00041048361254070187, Final Batch Loss: 1.1309909496048931e-05\n",
      "Epoch 3133, Loss: 9.221710229212476e-06, Final Batch Loss: 1.118043314818351e-06\n",
      "Epoch 3134, Loss: 0.0004828442652069498, Final Batch Loss: 7.15240093995817e-06\n",
      "Epoch 3135, Loss: 1.287934685478831e-05, Final Batch Loss: 1.1705427823471837e-05\n",
      "Epoch 3136, Loss: 2.0544769085972803e-06, Final Batch Loss: 5.716168516300968e-07\n",
      "Epoch 3137, Loss: 1.1947908205911517e-05, Final Batch Loss: 1.8805776562658139e-06\n",
      "Epoch 3138, Loss: 6.734266935382038e-05, Final Batch Loss: 3.649940845207311e-05\n",
      "Epoch 3139, Loss: 8.896506869859877e-06, Final Batch Loss: 1.442649363525561e-06\n",
      "Epoch 3140, Loss: 5.462093479025043e-05, Final Batch Loss: 2.183086706963877e-07\n",
      "Epoch 3141, Loss: 2.1182371710892767e-05, Final Batch Loss: 7.876759809732903e-06\n",
      "Epoch 3142, Loss: 6.29660480626626e-05, Final Batch Loss: 4.47773199994117e-05\n",
      "Epoch 3143, Loss: 2.1301428091646812e-05, Final Batch Loss: 1.9787135897786357e-05\n",
      "Epoch 3144, Loss: 6.5334995724697364e-06, Final Batch Loss: 4.869935764872935e-06\n",
      "Epoch 3145, Loss: 0.00010172335589686554, Final Batch Loss: 1.8784527355819591e-06\n",
      "Epoch 3146, Loss: 1.0336475497751962e-06, Final Batch Loss: 7.504078780584678e-07\n",
      "Epoch 3147, Loss: 3.8834099086670903e-05, Final Batch Loss: 3.3239546610275283e-05\n",
      "Epoch 3148, Loss: 0.0003882169839926064, Final Batch Loss: 0.0003744896675925702\n",
      "Epoch 3149, Loss: 2.4983580146908935e-06, Final Batch Loss: 1.650112835704931e-06\n",
      "Epoch 3150, Loss: 0.00012655249429371906, Final Batch Loss: 0.00012416088429745287\n",
      "Epoch 3151, Loss: 4.282693498680601e-05, Final Batch Loss: 3.141022170893848e-05\n",
      "Epoch 3152, Loss: 0.0008041897308430634, Final Batch Loss: 0.0007707514450885355\n",
      "Epoch 3153, Loss: 8.177861445801682e-06, Final Batch Loss: 6.39218023934518e-06\n",
      "Epoch 3154, Loss: 6.753343996024341e-06, Final Batch Loss: 3.776331141125411e-06\n",
      "Epoch 3155, Loss: 2.134204919457261e-06, Final Batch Loss: 7.28162035557034e-07\n",
      "Epoch 3156, Loss: 2.910373041231651e-05, Final Batch Loss: 1.7128462786786258e-05\n",
      "Epoch 3157, Loss: 0.0003571365405150573, Final Batch Loss: 0.00034888385562226176\n",
      "Epoch 3158, Loss: 1.7357473268475587e-05, Final Batch Loss: 5.838225547449838e-07\n",
      "Epoch 3159, Loss: 4.740777421829989e-05, Final Batch Loss: 3.7030504245194606e-06\n",
      "Epoch 3160, Loss: 1.3768784356216202e-05, Final Batch Loss: 5.371532552089775e-06\n",
      "Epoch 3161, Loss: 9.863047671387903e-05, Final Batch Loss: 7.742959860479459e-05\n",
      "Epoch 3162, Loss: 2.0928241610818077e-05, Final Batch Loss: 1.720490945444908e-05\n",
      "Epoch 3163, Loss: 2.2298782482721435e-05, Final Batch Loss: 1.5230549479383626e-06\n",
      "Epoch 3164, Loss: 1.4932681324353325e-05, Final Batch Loss: 1.1354300113453064e-05\n",
      "Epoch 3165, Loss: 3.414579407490237e-05, Final Batch Loss: 3.266909334342927e-05\n",
      "Epoch 3166, Loss: 3.103687140537659e-05, Final Batch Loss: 7.850468136894051e-06\n",
      "Epoch 3167, Loss: 3.393715905986028e-05, Final Batch Loss: 2.5507051759632304e-05\n",
      "Epoch 3168, Loss: 3.0383863531824318e-06, Final Batch Loss: 1.99558030544722e-06\n",
      "Epoch 3169, Loss: 2.1440878981593414e-05, Final Batch Loss: 2.7739913548430195e-06\n",
      "Epoch 3170, Loss: 1.481604101627454e-06, Final Batch Loss: 6.84365147662902e-07\n",
      "Epoch 3171, Loss: 6.534418901082972e-06, Final Batch Loss: 5.643226359097753e-06\n",
      "Epoch 3172, Loss: 0.0005185784111745306, Final Batch Loss: 3.2460238799103536e-06\n",
      "Epoch 3173, Loss: 1.502674786024727e-05, Final Batch Loss: 6.257017048483249e-06\n",
      "Epoch 3174, Loss: 0.0002857978379324777, Final Batch Loss: 0.00026037273346446455\n",
      "Epoch 3175, Loss: 8.855600322021928e-05, Final Batch Loss: 2.1535627183766337e-06\n",
      "Epoch 3176, Loss: 2.600177936074033e-05, Final Batch Loss: 2.4904120436985977e-05\n",
      "Epoch 3177, Loss: 0.00011316682412143564, Final Batch Loss: 6.055014637240674e-06\n",
      "Epoch 3178, Loss: 1.732614964566892e-05, Final Batch Loss: 8.664515007694717e-06\n",
      "Epoch 3179, Loss: 1.812968480408017e-05, Final Batch Loss: 1.705309477983974e-05\n",
      "Epoch 3180, Loss: 0.000140633881528629, Final Batch Loss: 4.852591155213304e-05\n",
      "Epoch 3181, Loss: 3.3066171454265714e-05, Final Batch Loss: 2.9000304493820295e-05\n",
      "Epoch 3182, Loss: 1.0886526979447808e-05, Final Batch Loss: 4.567236828734167e-07\n",
      "Epoch 3183, Loss: 0.0013175520919617156, Final Batch Loss: 9.012049417833623e-07\n",
      "Epoch 3184, Loss: 2.186641995649552e-05, Final Batch Loss: 5.3122357712709345e-06\n",
      "Epoch 3185, Loss: 1.2306600240208354e-05, Final Batch Loss: 2.5206196596627706e-07\n",
      "Epoch 3186, Loss: 8.219823598665243e-06, Final Batch Loss: 1.8898982716564205e-06\n",
      "Epoch 3187, Loss: 9.904283899686561e-06, Final Batch Loss: 9.628197403799277e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3188, Loss: 0.0007516237010349869, Final Batch Loss: 1.450126637791982e-05\n",
      "Epoch 3189, Loss: 4.93242927745996e-06, Final Batch Loss: 2.0251113141966925e-07\n",
      "Epoch 3190, Loss: 0.0005013887243876525, Final Batch Loss: 3.888836090482073e-06\n",
      "Epoch 3191, Loss: 5.526299162283976e-06, Final Batch Loss: 5.367036919778911e-06\n",
      "Epoch 3192, Loss: 4.1245882130169775e-05, Final Batch Loss: 2.9925211492809467e-05\n",
      "Epoch 3193, Loss: 0.00011483028720249422, Final Batch Loss: 8.885132410796359e-05\n",
      "Epoch 3194, Loss: 7.972784669618704e-05, Final Batch Loss: 1.0850621947611216e-06\n",
      "Epoch 3195, Loss: 0.00015916656593617518, Final Batch Loss: 7.047814506222494e-06\n",
      "Epoch 3196, Loss: 0.00010738813580246642, Final Batch Loss: 1.3621240213979036e-05\n",
      "Epoch 3197, Loss: 4.7847772293607704e-05, Final Batch Loss: 2.098376899084542e-05\n",
      "Epoch 3198, Loss: 0.005154877551774462, Final Batch Loss: 2.4272588916574023e-07\n",
      "Epoch 3199, Loss: 2.6020645066182624e-05, Final Batch Loss: 4.1435470166106825e-07\n",
      "Epoch 3200, Loss: 0.0002828365977620706, Final Batch Loss: 0.00023373891599476337\n",
      "Epoch 3201, Loss: 1.4939722916551545e-05, Final Batch Loss: 9.479072673457267e-07\n",
      "Epoch 3202, Loss: 0.00042595257036737166, Final Batch Loss: 0.0003766570589505136\n",
      "Epoch 3203, Loss: 0.0008683390660735313, Final Batch Loss: 2.251027399324812e-05\n",
      "Epoch 3204, Loss: 2.1661440769094042e-05, Final Batch Loss: 4.390129106468521e-06\n",
      "Epoch 3205, Loss: 5.5840738241386134e-05, Final Batch Loss: 4.791198080056347e-05\n",
      "Epoch 3206, Loss: 3.2873050486159627e-06, Final Batch Loss: 1.2595161251738318e-06\n",
      "Epoch 3207, Loss: 4.269662724709633e-06, Final Batch Loss: 3.877851781908248e-07\n",
      "Epoch 3208, Loss: 1.155237850980484e-05, Final Batch Loss: 7.41069652576698e-06\n",
      "Epoch 3209, Loss: 0.0003829351649073942, Final Batch Loss: 0.0003790247137658298\n",
      "Epoch 3210, Loss: 0.00044904497735842597, Final Batch Loss: 1.7139855117420666e-05\n",
      "Epoch 3211, Loss: 1.3861002571502468e-05, Final Batch Loss: 8.149076165864244e-06\n",
      "Epoch 3212, Loss: 0.00027840244092658395, Final Batch Loss: 0.0002662892802618444\n",
      "Epoch 3213, Loss: 0.0003141979700558295, Final Batch Loss: 3.839844339381671e-06\n",
      "Epoch 3214, Loss: 8.45657048813564e-05, Final Batch Loss: 8.436066855210811e-05\n",
      "Epoch 3215, Loss: 1.3902172099733434e-05, Final Batch Loss: 1.5080593129823683e-07\n",
      "Epoch 3216, Loss: 4.271793784482725e-06, Final Batch Loss: 3.6771925806533545e-06\n",
      "Epoch 3217, Loss: 1.0721585681494616e-05, Final Batch Loss: 9.898588359646965e-06\n",
      "Epoch 3218, Loss: 0.0009755153150763363, Final Batch Loss: 0.0005929036997258663\n",
      "Epoch 3219, Loss: 1.2617812899407e-05, Final Batch Loss: 2.8011008907924406e-06\n",
      "Epoch 3220, Loss: 0.004493963421282388, Final Batch Loss: 2.5951126190193463e-06\n",
      "Epoch 3221, Loss: 4.254086832133908e-06, Final Batch Loss: 3.7553265883616405e-06\n",
      "Epoch 3222, Loss: 0.00031507962086152475, Final Batch Loss: 4.976562308911525e-07\n",
      "Epoch 3223, Loss: 0.00021100402059914813, Final Batch Loss: 4.3446030417726433e-07\n",
      "Epoch 3224, Loss: 0.002888430196662739, Final Batch Loss: 2.913230900958297e-06\n",
      "Epoch 3225, Loss: 0.0004105224829800136, Final Batch Loss: 0.00040902828914113343\n",
      "Epoch 3226, Loss: 4.788040132552851e-05, Final Batch Loss: 7.9817164078122e-06\n",
      "Epoch 3227, Loss: 3.396335978322895e-05, Final Batch Loss: 1.1198683750990313e-05\n",
      "Epoch 3228, Loss: 4.377450022730045e-05, Final Batch Loss: 2.244173811050132e-05\n",
      "Epoch 3229, Loss: 0.0026214312165393494, Final Batch Loss: 0.0025840462185442448\n",
      "Epoch 3230, Loss: 5.181445999369316e-06, Final Batch Loss: 4.1081248127738945e-06\n",
      "Epoch 3231, Loss: 1.4799621794736595e-06, Final Batch Loss: 2.807861392284394e-07\n",
      "Epoch 3232, Loss: 0.000157595497512375, Final Batch Loss: 0.0001472596195526421\n",
      "Epoch 3233, Loss: 2.9072805318719475e-06, Final Batch Loss: 4.825760697713122e-07\n",
      "Epoch 3234, Loss: 4.6019109277040116e-05, Final Batch Loss: 4.3920423195231706e-05\n",
      "Epoch 3235, Loss: 4.536817506561874e-06, Final Batch Loss: 8.617517011089149e-08\n",
      "Epoch 3236, Loss: 6.910727279318962e-05, Final Batch Loss: 6.578875763807446e-05\n",
      "Epoch 3237, Loss: 4.360974708106369e-05, Final Batch Loss: 3.0834700737614185e-05\n",
      "Epoch 3238, Loss: 1.5535594684479292e-05, Final Batch Loss: 2.793128260236699e-06\n",
      "Epoch 3239, Loss: 3.669264020800256e-05, Final Batch Loss: 5.357074428502528e-07\n",
      "Epoch 3240, Loss: 0.0003354785585543141, Final Batch Loss: 0.0003335875808261335\n",
      "Epoch 3241, Loss: 4.157987621056236e-05, Final Batch Loss: 1.866258912741614e-06\n",
      "Epoch 3242, Loss: 0.001327505697503284, Final Batch Loss: 3.626467730555305e-07\n",
      "Epoch 3243, Loss: 4.400735917897691e-06, Final Batch Loss: 3.5391258279560134e-06\n",
      "Epoch 3244, Loss: 7.838929104764247e-05, Final Batch Loss: 7.630383333889768e-05\n",
      "Epoch 3245, Loss: 7.204156236184645e-05, Final Batch Loss: 1.7147754078905564e-06\n",
      "Epoch 3246, Loss: 1.1801432606262097e-05, Final Batch Loss: 8.688815569257713e-07\n",
      "Epoch 3247, Loss: 1.6447372672701022e-06, Final Batch Loss: 4.617527338268701e-07\n",
      "Epoch 3248, Loss: 0.00035106924815409, Final Batch Loss: 6.728675089107128e-06\n",
      "Epoch 3249, Loss: 4.6566026682626216e-05, Final Batch Loss: 4.6419161662925035e-05\n",
      "Epoch 3250, Loss: 2.792830098741206e-06, Final Batch Loss: 4.955078836132998e-08\n",
      "Epoch 3251, Loss: 0.00015551538308500312, Final Batch Loss: 2.4967837816802785e-05\n",
      "Epoch 3252, Loss: 0.0006017554201207531, Final Batch Loss: 0.0005996479303576052\n",
      "Epoch 3253, Loss: 2.1354329760470137e-05, Final Batch Loss: 2.1018639017711394e-05\n",
      "Epoch 3254, Loss: 8.042965919230483e-05, Final Batch Loss: 5.477364084072178e-06\n",
      "Epoch 3255, Loss: 4.7695224566268735e-05, Final Batch Loss: 3.283874684711918e-05\n",
      "Epoch 3256, Loss: 2.6776768208947033e-05, Final Batch Loss: 8.924329449655488e-06\n",
      "Epoch 3257, Loss: 0.0012115206035332449, Final Batch Loss: 1.7850824178822222e-06\n",
      "Epoch 3258, Loss: 5.450492750469493e-06, Final Batch Loss: 1.7235066707144142e-08\n",
      "Epoch 3259, Loss: 8.100355807982851e-05, Final Batch Loss: 6.763342389604077e-05\n",
      "Epoch 3260, Loss: 1.1449039902799996e-05, Final Batch Loss: 3.7280874494172167e-06\n",
      "Epoch 3261, Loss: 5.426896336757636e-07, Final Batch Loss: 4.315867840887222e-07\n",
      "Epoch 3262, Loss: 0.00016665180010022596, Final Batch Loss: 0.00011927613377338275\n",
      "Epoch 3263, Loss: 0.0033815645309474007, Final Batch Loss: 1.113092835680618e-07\n",
      "Epoch 3264, Loss: 1.0954886874969816e-05, Final Batch Loss: 2.98105760521139e-06\n",
      "Epoch 3265, Loss: 9.592525020707399e-05, Final Batch Loss: 6.396116077667102e-05\n",
      "Epoch 3266, Loss: 0.0001026586431294163, Final Batch Loss: 0.00010211219341726974\n",
      "Epoch 3267, Loss: 0.00022919325328984996, Final Batch Loss: 0.00022576576157007366\n",
      "Epoch 3268, Loss: 1.511798836872913e-05, Final Batch Loss: 6.72715759719722e-06\n",
      "Epoch 3269, Loss: 0.00010142040980554157, Final Batch Loss: 9.992518607759848e-05\n",
      "Epoch 3270, Loss: 6.95418157192762e-06, Final Batch Loss: 3.282483930888702e-06\n",
      "Epoch 3271, Loss: 0.000251856703471276, Final Batch Loss: 1.2455710020731203e-05\n",
      "Epoch 3272, Loss: 6.926831634146424e-05, Final Batch Loss: 5.026891258808064e-08\n",
      "Epoch 3273, Loss: 2.191887631397549e-06, Final Batch Loss: 1.2954681096744025e-06\n",
      "Epoch 3274, Loss: 5.141688461662852e-06, Final Batch Loss: 3.2779903449409176e-06\n",
      "Epoch 3275, Loss: 7.175303966278079e-05, Final Batch Loss: 7.126524724299088e-05\n",
      "Epoch 3276, Loss: 0.00017044355627149343, Final Batch Loss: 0.00011612667003646493\n",
      "Epoch 3277, Loss: 1.8422668688344856e-06, Final Batch Loss: 1.6300755305564962e-06\n",
      "Epoch 3278, Loss: 0.0010298692909600504, Final Batch Loss: 0.0010238365503028035\n",
      "Epoch 3279, Loss: 3.3200506777575356e-05, Final Batch Loss: 2.9819315386703238e-05\n",
      "Epoch 3280, Loss: 0.0008682517554916558, Final Batch Loss: 0.0008585128816775978\n",
      "Epoch 3281, Loss: 8.229334298448521e-07, Final Batch Loss: 5.773658813268412e-07\n",
      "Epoch 3282, Loss: 2.1112264221301302e-05, Final Batch Loss: 1.3130204024491832e-05\n",
      "Epoch 3283, Loss: 8.538396201629439e-06, Final Batch Loss: 1.9030258613383921e-07\n",
      "Epoch 3284, Loss: 8.493000950693386e-05, Final Batch Loss: 1.0322878551960457e-05\n",
      "Epoch 3285, Loss: 0.0008288601802632911, Final Batch Loss: 2.3849801436881535e-05\n",
      "Epoch 3286, Loss: 3.6584649024007376e-05, Final Batch Loss: 2.8644175472436473e-05\n",
      "Epoch 3287, Loss: 1.1932767847611103e-05, Final Batch Loss: 7.224134606076404e-07\n",
      "Epoch 3288, Loss: 0.00011998679428870673, Final Batch Loss: 5.464785317599308e-07\n",
      "Epoch 3289, Loss: 0.0001496750292062643, Final Batch Loss: 0.0001437590253772214\n",
      "Epoch 3290, Loss: 9.401689339938457e-06, Final Batch Loss: 2.9398399874480674e-06\n",
      "Epoch 3291, Loss: 0.00019447643275327664, Final Batch Loss: 1.3716193336676952e-07\n",
      "Epoch 3292, Loss: 1.0273666930515901e-06, Final Batch Loss: 7.841816795917111e-07\n",
      "Epoch 3293, Loss: 3.1504874868915067e-06, Final Batch Loss: 2.3923421395011246e-06\n",
      "Epoch 3294, Loss: 1.3261842440215332e-05, Final Batch Loss: 4.3590077325461607e-07\n",
      "Epoch 3295, Loss: 2.5360027166243526e-05, Final Batch Loss: 2.340609353268519e-05\n",
      "Epoch 3296, Loss: 1.3800994537405131e-05, Final Batch Loss: 1.3544458852265961e-05\n",
      "Epoch 3297, Loss: 3.603657137318805e-05, Final Batch Loss: 1.9214360236219363e-06\n",
      "Epoch 3298, Loss: 0.015537866918748477, Final Batch Loss: 1.0519906936679035e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3299, Loss: 4.995577342015167e-06, Final Batch Loss: 1.0017282647822867e-06\n",
      "Epoch 3300, Loss: 3.649021778073802e-06, Final Batch Loss: 3.096855834883172e-06\n",
      "Epoch 3301, Loss: 0.00040616247861180454, Final Batch Loss: 6.876607949379832e-05\n",
      "Epoch 3302, Loss: 1.891691783839633e-05, Final Batch Loss: 1.7103699065046385e-05\n",
      "Epoch 3303, Loss: 9.757006409927271e-05, Final Batch Loss: 2.202880205004476e-05\n",
      "Epoch 3304, Loss: 6.055898359136336e-05, Final Batch Loss: 1.2114493301851326e-06\n",
      "Epoch 3305, Loss: 4.831558777596001e-05, Final Batch Loss: 2.987385983033164e-07\n",
      "Epoch 3306, Loss: 0.00018163178538088687, Final Batch Loss: 8.039412932703272e-06\n",
      "Epoch 3307, Loss: 4.629627710528439e-05, Final Batch Loss: 8.171946319635026e-07\n",
      "Epoch 3308, Loss: 5.418652676780766e-06, Final Batch Loss: 4.456926035345532e-06\n",
      "Epoch 3309, Loss: 0.00014957092707845732, Final Batch Loss: 0.00014547773753292859\n",
      "Epoch 3310, Loss: 7.175291477778956e-05, Final Batch Loss: 1.4095895721766283e-06\n",
      "Epoch 3311, Loss: 5.1279430408612825e-06, Final Batch Loss: 1.993286332435673e-06\n",
      "Epoch 3312, Loss: 0.0018471997462938816, Final Batch Loss: 0.0018458599224686623\n",
      "Epoch 3313, Loss: 1.5209747232347581e-05, Final Batch Loss: 3.181284569109266e-07\n",
      "Epoch 3314, Loss: 4.255793925267426e-06, Final Batch Loss: 3.2387416126766766e-07\n",
      "Epoch 3315, Loss: 9.976993493410191e-05, Final Batch Loss: 9.91934648482129e-05\n",
      "Epoch 3316, Loss: 0.0009982358094475785, Final Batch Loss: 3.3090252600231906e-06\n",
      "Epoch 3317, Loss: 0.00031485259169272695, Final Batch Loss: 0.00031478345044888556\n",
      "Epoch 3318, Loss: 7.844746221508103e-07, Final Batch Loss: 4.998054237148608e-07\n",
      "Epoch 3319, Loss: 0.00017630497052323335, Final Batch Loss: 6.082456138756243e-07\n",
      "Epoch 3320, Loss: 0.0003106742042291444, Final Batch Loss: 0.00027617914020083845\n",
      "Epoch 3321, Loss: 2.0895443867630092e-05, Final Batch Loss: 5.954366770311026e-06\n",
      "Epoch 3322, Loss: 2.1259120899230766e-06, Final Batch Loss: 1.584715846547624e-06\n",
      "Epoch 3323, Loss: 0.00012094797659756296, Final Batch Loss: 0.00012028519267914817\n",
      "Epoch 3324, Loss: 3.119672470575097e-05, Final Batch Loss: 2.1615556988763274e-07\n",
      "Epoch 3325, Loss: 1.2461691198950575e-06, Final Batch Loss: 7.712487786193378e-07\n",
      "Epoch 3326, Loss: 3.2717311455598974e-05, Final Batch Loss: 3.196535544702783e-05\n",
      "Epoch 3327, Loss: 0.00020543509572235052, Final Batch Loss: 1.959710516530322e-06\n",
      "Epoch 3328, Loss: 0.0001742275053402409, Final Batch Loss: 0.00017243185720872134\n",
      "Epoch 3329, Loss: 2.8676574004293798e-05, Final Batch Loss: 4.775452566718741e-07\n",
      "Epoch 3330, Loss: 1.605090960765665e-05, Final Batch Loss: 1.5682987850595964e-06\n",
      "Epoch 3331, Loss: 7.085715878929477e-06, Final Batch Loss: 2.6400866772746667e-06\n",
      "Epoch 3332, Loss: 1.7387355342179944e-06, Final Batch Loss: 1.199938537865819e-06\n",
      "Epoch 3333, Loss: 4.284999431547476e-05, Final Batch Loss: 3.119720713584684e-05\n",
      "Epoch 3334, Loss: 6.380541071848711e-05, Final Batch Loss: 3.5703151297639124e-06\n",
      "Epoch 3335, Loss: 2.6786251368093872e-05, Final Batch Loss: 2.4918594476730505e-07\n",
      "Epoch 3336, Loss: 0.0014269754210545216, Final Batch Loss: 2.8704587748507038e-05\n",
      "Epoch 3337, Loss: 2.1113512957526837e-05, Final Batch Loss: 2.045977998932358e-05\n",
      "Epoch 3338, Loss: 7.689177778047451e-06, Final Batch Loss: 6.7842065618606284e-06\n",
      "Epoch 3339, Loss: 7.0314924869308015e-06, Final Batch Loss: 9.658099315856816e-07\n",
      "Epoch 3340, Loss: 1.1646545090115978e-05, Final Batch Loss: 9.3633016149397e-06\n",
      "Epoch 3341, Loss: 5.835676748766616e-05, Final Batch Loss: 2.7288853843288052e-08\n",
      "Epoch 3342, Loss: 4.717130195786012e-05, Final Batch Loss: 8.128295121423434e-06\n",
      "Epoch 3343, Loss: 5.948409807388089e-06, Final Batch Loss: 4.262531547283288e-06\n",
      "Epoch 3344, Loss: 8.980220468401967e-05, Final Batch Loss: 2.779127044050256e-07\n",
      "Epoch 3345, Loss: 7.823316991562024e-05, Final Batch Loss: 3.756209844141267e-05\n",
      "Epoch 3346, Loss: 1.6434427607237012e-05, Final Batch Loss: 1.3995288554724539e-06\n",
      "Epoch 3347, Loss: 3.4272165976290125e-05, Final Batch Loss: 2.4797367586870678e-05\n",
      "Epoch 3348, Loss: 3.3742222740329453e-06, Final Batch Loss: 2.293274292242131e-06\n",
      "Epoch 3349, Loss: 7.567213629045e-05, Final Batch Loss: 7.451212150044739e-05\n",
      "Epoch 3350, Loss: 0.00013438526761433423, Final Batch Loss: 4.3087160861432494e-07\n",
      "Epoch 3351, Loss: 0.0003502319523249753, Final Batch Loss: 0.00010748157365014777\n",
      "Epoch 3352, Loss: 8.349280813035875e-05, Final Batch Loss: 8.183690079022199e-05\n",
      "Epoch 3353, Loss: 1.5319345493480796e-05, Final Batch Loss: 3.3463861655036453e-06\n",
      "Epoch 3354, Loss: 4.2186182326986454e-05, Final Batch Loss: 1.967195021279622e-05\n",
      "Epoch 3355, Loss: 1.868060235210578e-05, Final Batch Loss: 3.815948275587289e-06\n",
      "Epoch 3356, Loss: 7.025947365946195e-05, Final Batch Loss: 6.743636913597584e-05\n",
      "Epoch 3357, Loss: 2.9969896360171333e-06, Final Batch Loss: 2.8382037271512672e-06\n",
      "Epoch 3358, Loss: 1.3157331068214262e-05, Final Batch Loss: 1.104374405258568e-05\n",
      "Epoch 3359, Loss: 7.025079958111746e-05, Final Batch Loss: 5.1829001677106135e-06\n",
      "Epoch 3360, Loss: 4.003039975941647e-06, Final Batch Loss: 4.969404017174384e-07\n",
      "Epoch 3361, Loss: 0.0009133357100381545, Final Batch Loss: 6.118218607298331e-07\n",
      "Epoch 3362, Loss: 0.00015519333101110533, Final Batch Loss: 6.333237251965329e-05\n",
      "Epoch 3363, Loss: 9.22295055261202e-06, Final Batch Loss: 8.009508746908978e-06\n",
      "Epoch 3364, Loss: 8.284242221634486e-05, Final Batch Loss: 4.1015869101102e-06\n",
      "Epoch 3365, Loss: 0.00020154276558059792, Final Batch Loss: 7.683613603148842e-07\n",
      "Epoch 3366, Loss: 2.4909359240155027e-05, Final Batch Loss: 4.481063342609559e-07\n",
      "Epoch 3367, Loss: 6.930355809231514e-06, Final Batch Loss: 7.612133856582659e-08\n",
      "Epoch 3368, Loss: 0.00016628602929813496, Final Batch Loss: 2.694198656172375e-06\n",
      "Epoch 3369, Loss: 1.0598957487673033e-05, Final Batch Loss: 1.0182693586102687e-06\n",
      "Epoch 3370, Loss: 1.6546772712899838e-05, Final Batch Loss: 1.0538290553085972e-05\n",
      "Epoch 3371, Loss: 1.0174210046898224e-05, Final Batch Loss: 2.2754213659936795e-06\n",
      "Epoch 3372, Loss: 0.0012073680405109144, Final Batch Loss: 0.001207132008858025\n",
      "Epoch 3373, Loss: 0.0007364876655628905, Final Batch Loss: 0.000605669105425477\n",
      "Epoch 3374, Loss: 2.1326232399587752e-05, Final Batch Loss: 2.027103073487524e-05\n",
      "Epoch 3375, Loss: 6.564865179825574e-05, Final Batch Loss: 5.4635063861496747e-05\n",
      "Epoch 3376, Loss: 4.3948351780898065e-05, Final Batch Loss: 6.678583730490573e-08\n",
      "Epoch 3377, Loss: 9.753111214649834e-06, Final Batch Loss: 6.836364150331065e-07\n",
      "Epoch 3378, Loss: 2.9537102932408743e-06, Final Batch Loss: 2.105448402289767e-06\n",
      "Epoch 3379, Loss: 3.443057789809245e-05, Final Batch Loss: 2.7791315915237647e-07\n",
      "Epoch 3380, Loss: 2.794113633797224e-07, Final Batch Loss: 5.6731902731144146e-08\n",
      "Epoch 3381, Loss: 0.00010374106429367203, Final Batch Loss: 2.5349660859319556e-07\n",
      "Epoch 3382, Loss: 6.560725296367309e-05, Final Batch Loss: 3.824695795628941e-06\n",
      "Epoch 3383, Loss: 5.4719912913725466e-05, Final Batch Loss: 2.0107581377715178e-08\n",
      "Epoch 3384, Loss: 0.0004237750445099664, Final Batch Loss: 5.542639883060474e-06\n",
      "Epoch 3385, Loss: 0.00024988035147543997, Final Batch Loss: 5.307195533532649e-05\n",
      "Epoch 3386, Loss: 8.781623796494387e-05, Final Batch Loss: 3.9712062971375417e-07\n",
      "Epoch 3387, Loss: 3.3229470659534854e-06, Final Batch Loss: 2.9548361908382503e-06\n",
      "Epoch 3388, Loss: 1.566844827038949e-05, Final Batch Loss: 1.531797715870198e-05\n",
      "Epoch 3389, Loss: 3.6459424990198386e-07, Final Batch Loss: 7.324887718596074e-08\n",
      "Epoch 3390, Loss: 1.77595647983253e-05, Final Batch Loss: 1.531982525193598e-05\n",
      "Epoch 3391, Loss: 3.328389675516519e-05, Final Batch Loss: 3.2220610592048615e-05\n",
      "Epoch 3392, Loss: 1.2611991984101678e-07, Final Batch Loss: 1.184905258355684e-07\n",
      "Epoch 3393, Loss: 0.0003327738509142364, Final Batch Loss: 4.4949542825634126e-06\n",
      "Epoch 3394, Loss: 1.9673586990620606e-06, Final Batch Loss: 1.45061463285856e-07\n",
      "Epoch 3395, Loss: 8.056901606323663e-05, Final Batch Loss: 1.669819357630331e-05\n",
      "Epoch 3396, Loss: 4.111724319955101e-05, Final Batch Loss: 2.2038248062017374e-06\n",
      "Epoch 3397, Loss: 3.486294076537888e-06, Final Batch Loss: 2.3557438453281065e-06\n",
      "Epoch 3398, Loss: 2.7376027219361276e-05, Final Batch Loss: 2.974291646751226e-06\n",
      "Epoch 3399, Loss: 3.9430404701334965e-05, Final Batch Loss: 2.3698209616895838e-08\n",
      "Epoch 3400, Loss: 1.7533919162815437e-05, Final Batch Loss: 1.6989743016893044e-06\n",
      "Epoch 3401, Loss: 1.1709638272350276e-06, Final Batch Loss: 8.071446586654929e-07\n",
      "Epoch 3402, Loss: 6.727367917847005e-06, Final Batch Loss: 6.428394499380374e-06\n",
      "Epoch 3403, Loss: 3.7642926145053934e-05, Final Batch Loss: 3.3561489544808865e-05\n",
      "Epoch 3404, Loss: 1.7633311770737237e-06, Final Batch Loss: 8.402083295777629e-08\n",
      "Epoch 3405, Loss: 8.646663900435669e-07, Final Batch Loss: 1.1274573807895649e-07\n",
      "Epoch 3406, Loss: 1.4399736983250477e-05, Final Batch Loss: 7.741148237982998e-07\n",
      "Epoch 3407, Loss: 8.919657602746156e-06, Final Batch Loss: 7.908843144832645e-06\n",
      "Epoch 3408, Loss: 1.7846695072876173e-06, Final Batch Loss: 1.3722127505388926e-06\n",
      "Epoch 3409, Loss: 2.4959514348665834e-06, Final Batch Loss: 9.729938028613105e-07\n",
      "Epoch 3410, Loss: 3.8740378613510984e-05, Final Batch Loss: 3.8297410355880857e-05\n",
      "Epoch 3411, Loss: 3.202708603566862e-05, Final Batch Loss: 3.899174316757126e-06\n",
      "Epoch 3412, Loss: 0.00017295065663347486, Final Batch Loss: 0.00016048930410761386\n",
      "Epoch 3413, Loss: 3.988206231042568e-06, Final Batch Loss: 3.5900559396395693e-06\n",
      "Epoch 3414, Loss: 3.3245928534597624e-05, Final Batch Loss: 3.0061864890740253e-06\n",
      "Epoch 3415, Loss: 0.00010152150389330927, Final Batch Loss: 1.7313441276201047e-05\n",
      "Epoch 3416, Loss: 1.6022139561755466e-05, Final Batch Loss: 2.7858120574819623e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3417, Loss: 1.53488639398347e-05, Final Batch Loss: 1.787302039701899e-06\n",
      "Epoch 3418, Loss: 2.57746950182991e-05, Final Batch Loss: 2.4374316126341e-05\n",
      "Epoch 3419, Loss: 8.230633686423516e-05, Final Batch Loss: 8.216042624553666e-05\n",
      "Epoch 3420, Loss: 0.00012656564817348226, Final Batch Loss: 3.9137543694778287e-07\n",
      "Epoch 3421, Loss: 2.8191637397867453e-06, Final Batch Loss: 2.7595592655416112e-06\n",
      "Epoch 3422, Loss: 9.681348771550802e-06, Final Batch Loss: 2.3626266454357392e-07\n",
      "Epoch 3423, Loss: 8.866507002380786e-06, Final Batch Loss: 8.743483704165556e-06\n",
      "Epoch 3424, Loss: 0.00011658230356359489, Final Batch Loss: 2.8725126721695915e-09\n",
      "Epoch 3425, Loss: 3.785084481933154e-05, Final Batch Loss: 2.7370586394681595e-05\n",
      "Epoch 3426, Loss: 7.039158845145721e-05, Final Batch Loss: 6.091984687373042e-05\n",
      "Epoch 3427, Loss: 0.00011588142956497904, Final Batch Loss: 1.8698658550420078e-06\n",
      "Epoch 3428, Loss: 6.544901270899572e-05, Final Batch Loss: 2.801817117870087e-06\n",
      "Epoch 3429, Loss: 3.869827537528181e-06, Final Batch Loss: 5.737769015468075e-07\n",
      "Epoch 3430, Loss: 4.18232128929219e-07, Final Batch Loss: 1.2926302694893366e-08\n",
      "Epoch 3431, Loss: 4.083999101567315e-05, Final Batch Loss: 3.915308843716048e-05\n",
      "Epoch 3432, Loss: 1.0087257678037531e-06, Final Batch Loss: 9.529359203952481e-07\n",
      "Epoch 3433, Loss: 0.003687682049076102, Final Batch Loss: 0.0036816748324781656\n",
      "Epoch 3434, Loss: 1.0854736729015713e-05, Final Batch Loss: 8.912992598197889e-06\n",
      "Epoch 3435, Loss: 6.486211248102336e-06, Final Batch Loss: 5.72140470467275e-06\n",
      "Epoch 3436, Loss: 3.407925169085502e-05, Final Batch Loss: 1.3097501323500182e-06\n",
      "Epoch 3437, Loss: 0.000459775525087025, Final Batch Loss: 7.892498251749203e-05\n",
      "Epoch 3438, Loss: 1.4978629820916467e-06, Final Batch Loss: 1.256717183650835e-07\n",
      "Epoch 3439, Loss: 5.675017121120618e-06, Final Batch Loss: 4.9769546421885025e-06\n",
      "Epoch 3440, Loss: 6.401830705549116e-06, Final Batch Loss: 1.4362558253822044e-08\n",
      "Epoch 3441, Loss: 3.258914568959881e-05, Final Batch Loss: 6.168671689010807e-07\n",
      "Epoch 3442, Loss: 0.0017031991324643059, Final Batch Loss: 6.951327691240294e-07\n",
      "Epoch 3443, Loss: 2.374818936345946e-05, Final Batch Loss: 3.037642670733476e-07\n",
      "Epoch 3444, Loss: 7.73690976529906e-06, Final Batch Loss: 1.7205250060214894e-06\n",
      "Epoch 3445, Loss: 1.4885135145803474e-05, Final Batch Loss: 2.9443230076253712e-08\n",
      "Epoch 3446, Loss: 2.980845703604018e-05, Final Batch Loss: 7.827576808949743e-08\n",
      "Epoch 3447, Loss: 1.4239022448236938e-05, Final Batch Loss: 1.2928728210681584e-05\n",
      "Epoch 3448, Loss: 4.115491741174537e-05, Final Batch Loss: 1.658865897979922e-07\n",
      "Epoch 3449, Loss: 5.851437236970014e-07, Final Batch Loss: 4.358946341653791e-07\n",
      "Epoch 3450, Loss: 4.10509064749931e-05, Final Batch Loss: 9.353193490824196e-06\n",
      "Epoch 3451, Loss: 0.00011203515879287806, Final Batch Loss: 0.00011127942707389593\n",
      "Epoch 3452, Loss: 3.3613623600103892e-06, Final Batch Loss: 2.589395762697677e-06\n",
      "Epoch 3453, Loss: 4.525092427343225e-05, Final Batch Loss: 2.4272358700727636e-07\n",
      "Epoch 3454, Loss: 3.082446437474573e-05, Final Batch Loss: 2.2554362658411264e-05\n",
      "Epoch 3455, Loss: 0.0005840661624176846, Final Batch Loss: 2.3051777020555164e-07\n",
      "Epoch 3456, Loss: 0.0002002994675649461, Final Batch Loss: 1.2078177178409533e-06\n",
      "Epoch 3457, Loss: 2.1245298924554845e-06, Final Batch Loss: 1.1346384809485244e-07\n",
      "Epoch 3458, Loss: 4.974566479631903e-06, Final Batch Loss: 9.083739200832497e-07\n",
      "Epoch 3459, Loss: 4.7941259708750295e-06, Final Batch Loss: 3.2460393413202837e-06\n",
      "Epoch 3460, Loss: 0.00029242276505669906, Final Batch Loss: 3.6911515621795843e-07\n",
      "Epoch 3461, Loss: 0.00037459525643157576, Final Batch Loss: 3.217138839772815e-07\n",
      "Epoch 3462, Loss: 6.314295364973077e-05, Final Batch Loss: 2.736491069299518e-06\n",
      "Epoch 3463, Loss: 2.915544655479607e-06, Final Batch Loss: 1.882795913843438e-06\n",
      "Epoch 3464, Loss: 1.955494745686792e-06, Final Batch Loss: 8.043021892945035e-08\n",
      "Epoch 3465, Loss: 0.00024804924260024563, Final Batch Loss: 6.156393737910548e-06\n",
      "Epoch 3466, Loss: 6.402928534043895e-07, Final Batch Loss: 3.34642834332044e-07\n",
      "Epoch 3467, Loss: 3.7656156166576693e-06, Final Batch Loss: 3.3688963867462007e-06\n",
      "Epoch 3468, Loss: 6.383467371051665e-05, Final Batch Loss: 5.467314622364938e-05\n",
      "Epoch 3469, Loss: 6.119151669281564e-05, Final Batch Loss: 4.80417043036141e-07\n",
      "Epoch 3470, Loss: 5.1860901919553726e-06, Final Batch Loss: 4.258417618530075e-07\n",
      "Epoch 3471, Loss: 2.7981479433947243e-05, Final Batch Loss: 2.3171587599790655e-05\n",
      "Epoch 3472, Loss: 1.8294675783181447e-05, Final Batch Loss: 8.214963145292131e-07\n",
      "Epoch 3473, Loss: 4.674016736316844e-06, Final Batch Loss: 4.962187176715815e-07\n",
      "Epoch 3474, Loss: 8.17573138078842e-06, Final Batch Loss: 8.02266822574893e-06\n",
      "Epoch 3475, Loss: 0.0005679372538907046, Final Batch Loss: 0.0005653612315654755\n",
      "Epoch 3476, Loss: 9.892369661201883e-07, Final Batch Loss: 9.744550197865465e-07\n",
      "Epoch 3477, Loss: 9.527566589895287e-05, Final Batch Loss: 7.500674200855428e-06\n",
      "Epoch 3478, Loss: 0.0023314305883559427, Final Batch Loss: 2.246845951958676e-06\n",
      "Epoch 3479, Loss: 8.870270090710619e-05, Final Batch Loss: 5.507927767212095e-07\n",
      "Epoch 3480, Loss: 5.029435925507642e-07, Final Batch Loss: 2.692947873583762e-07\n",
      "Epoch 3481, Loss: 0.00010565047819000029, Final Batch Loss: 1.9315932604513364e-06\n",
      "Epoch 3482, Loss: 1.1135741715406766e-05, Final Batch Loss: 4.2908595787594095e-06\n",
      "Epoch 3483, Loss: 0.00018328932469557913, Final Batch Loss: 0.00018048333004117012\n",
      "Epoch 3484, Loss: 2.652289026627841e-06, Final Batch Loss: 1.2724387943308102e-06\n",
      "Epoch 3485, Loss: 4.916259399578848e-06, Final Batch Loss: 1.6320974509653752e-06\n",
      "Epoch 3486, Loss: 6.269633558986243e-05, Final Batch Loss: 4.7248046030290425e-05\n",
      "Epoch 3487, Loss: 4.103801984456368e-06, Final Batch Loss: 1.7986442344408715e-06\n",
      "Epoch 3488, Loss: 5.389510207010062e-07, Final Batch Loss: 9.407427370433652e-08\n",
      "Epoch 3489, Loss: 5.109086123411544e-05, Final Batch Loss: 2.60307097050827e-05\n",
      "Epoch 3490, Loss: 2.862556414129358e-06, Final Batch Loss: 2.1721189114032313e-06\n",
      "Epoch 3491, Loss: 0.00017711088730720803, Final Batch Loss: 7.367707439698279e-07\n",
      "Epoch 3492, Loss: 1.8561451646803562e-05, Final Batch Loss: 1.0412797024628162e-07\n",
      "Epoch 3493, Loss: 1.6479365569921356e-06, Final Batch Loss: 1.45061363809873e-07\n",
      "Epoch 3494, Loss: 5.304188834998058e-05, Final Batch Loss: 4.856007217313163e-05\n",
      "Epoch 3495, Loss: 1.2829151287974128e-06, Final Batch Loss: 6.319519485487035e-08\n",
      "Epoch 3496, Loss: 2.0089391796318523e-05, Final Batch Loss: 6.864937631689827e-07\n",
      "Epoch 3497, Loss: 4.7968953111876544e-06, Final Batch Loss: 4.624281700671418e-06\n",
      "Epoch 3498, Loss: 0.00011182335765624885, Final Batch Loss: 8.850185622577555e-06\n",
      "Epoch 3499, Loss: 0.00010860072188734193, Final Batch Loss: 1.446224359824555e-06\n",
      "Epoch 3500, Loss: 4.520827644682868e-06, Final Batch Loss: 8.222016845138569e-07\n",
      "Epoch 3501, Loss: 2.900031972785655e-05, Final Batch Loss: 2.5788931452552788e-05\n",
      "Epoch 3502, Loss: 0.0001907925078938888, Final Batch Loss: 2.003552452833901e-07\n",
      "Epoch 3503, Loss: 2.030952509812778e-05, Final Batch Loss: 1.2063965186825953e-06\n",
      "Epoch 3504, Loss: 3.054324770346284e-05, Final Batch Loss: 7.151282261474989e-06\n",
      "Epoch 3505, Loss: 2.559847338545751e-07, Final Batch Loss: 4.093327632403998e-08\n",
      "Epoch 3506, Loss: 7.757080755510515e-07, Final Batch Loss: 7.518662528127606e-07\n",
      "Epoch 3507, Loss: 2.2599994906613574e-06, Final Batch Loss: 2.187997324654134e-06\n",
      "Epoch 3508, Loss: 1.731276455529951e-06, Final Batch Loss: 4.2440169067958777e-07\n",
      "Epoch 3509, Loss: 0.0005099848402778662, Final Batch Loss: 0.0005094980006106198\n",
      "Epoch 3510, Loss: 9.112873203775962e-05, Final Batch Loss: 8.817945490591228e-05\n",
      "Epoch 3511, Loss: 1.2408964714438753e-05, Final Batch Loss: 7.683956226856026e-08\n",
      "Epoch 3512, Loss: 3.2952847988099165e-06, Final Batch Loss: 3.1360229968413478e-06\n",
      "Epoch 3513, Loss: 8.235502946263296e-06, Final Batch Loss: 3.261905703766388e-06\n",
      "Epoch 3514, Loss: 4.076083807547093e-05, Final Batch Loss: 2.333903665885373e-07\n",
      "Epoch 3515, Loss: 2.7111724421047256e-06, Final Batch Loss: 5.500677389136399e-07\n",
      "Epoch 3516, Loss: 2.553694486095992e-06, Final Batch Loss: 2.502196139175794e-06\n",
      "Epoch 3517, Loss: 1.1685760199497963e-05, Final Batch Loss: 2.2189871629052504e-07\n",
      "Epoch 3518, Loss: 0.0005141020410519559, Final Batch Loss: 6.0296257288428023e-05\n",
      "Epoch 3519, Loss: 0.001103225467431912, Final Batch Loss: 0.0010993657633662224\n",
      "Epoch 3520, Loss: 3.6710339657020086e-05, Final Batch Loss: 9.514818088973698e-07\n",
      "Epoch 3521, Loss: 1.6437305134786584e-06, Final Batch Loss: 1.680414811744413e-07\n",
      "Epoch 3522, Loss: 6.651072908425704e-05, Final Batch Loss: 8.497438102494925e-06\n",
      "Epoch 3523, Loss: 3.6242900591787475e-07, Final Batch Loss: 1.278265244764043e-07\n",
      "Epoch 3524, Loss: 2.1522569113585632e-05, Final Batch Loss: 1.5504205293837003e-05\n",
      "Epoch 3525, Loss: 3.686247964651557e-05, Final Batch Loss: 2.787758239719551e-05\n",
      "Epoch 3526, Loss: 2.6394264921236754e-05, Final Batch Loss: 2.602042877697386e-05\n",
      "Epoch 3527, Loss: 5.339586956409903e-05, Final Batch Loss: 5.33100392203778e-05\n",
      "Epoch 3528, Loss: 4.023907706596219e-06, Final Batch Loss: 3.2838918286870467e-06\n",
      "Epoch 3529, Loss: 2.2257755745158647e-06, Final Batch Loss: 1.4547634918926633e-06\n",
      "Epoch 3530, Loss: 1.4598398365706089e-05, Final Batch Loss: 1.1232164069951978e-05\n",
      "Epoch 3531, Loss: 2.7395500865168287e-05, Final Batch Loss: 1.6450355815322837e-06\n",
      "Epoch 3532, Loss: 3.4099354522254544e-06, Final Batch Loss: 3.2950181321211858e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3533, Loss: 1.3292130240927236e-05, Final Batch Loss: 4.236949990854555e-08\n",
      "Epoch 3534, Loss: 2.3339196673077822e-06, Final Batch Loss: 1.8389914657745976e-06\n",
      "Epoch 3535, Loss: 2.1308613668225007e-05, Final Batch Loss: 5.184797373658512e-07\n",
      "Epoch 3536, Loss: 1.930911764702614e-06, Final Batch Loss: 1.3391683069130522e-06\n",
      "Epoch 3537, Loss: 2.7972438587653414e-05, Final Batch Loss: 6.391336171418516e-08\n",
      "Epoch 3538, Loss: 0.0021875384376244256, Final Batch Loss: 1.7958340094992309e-06\n",
      "Epoch 3539, Loss: 0.0002077161143461126, Final Batch Loss: 0.00020389180281199515\n",
      "Epoch 3540, Loss: 8.517514402228699e-06, Final Batch Loss: 1.1180324008819298e-06\n",
      "Epoch 3541, Loss: 1.505882245567136e-07, Final Batch Loss: 9.62289306016828e-08\n",
      "Epoch 3542, Loss: 2.9401887786661973e-06, Final Batch Loss: 1.7262410665352945e-06\n",
      "Epoch 3543, Loss: 0.001268371648620814, Final Batch Loss: 0.0012370898621156812\n",
      "Epoch 3544, Loss: 3.2191740046982886e-06, Final Batch Loss: 1.0965520687022945e-06\n",
      "Epoch 3545, Loss: 0.0046174088201951236, Final Batch Loss: 4.6254106564447284e-05\n",
      "Epoch 3546, Loss: 6.9591532394497335e-06, Final Batch Loss: 2.8437571586437116e-07\n",
      "Epoch 3547, Loss: 1.0914891390712e-06, Final Batch Loss: 1.9748404156416655e-07\n",
      "Epoch 3548, Loss: 7.198232515293057e-05, Final Batch Loss: 6.467301136581227e-05\n",
      "Epoch 3549, Loss: 0.0003933217337817041, Final Batch Loss: 0.0003923338372260332\n",
      "Epoch 3550, Loss: 6.300101449596696e-05, Final Batch Loss: 1.9610779418144375e-06\n",
      "Epoch 3551, Loss: 0.0001372274900290904, Final Batch Loss: 0.00013644597493112087\n",
      "Epoch 3552, Loss: 1.0198047220910667e-05, Final Batch Loss: 5.543201041291468e-06\n",
      "Epoch 3553, Loss: 1.5882559409874375e-05, Final Batch Loss: 1.4914555777068017e-06\n",
      "Epoch 3554, Loss: 0.0035770615795627236, Final Batch Loss: 0.002976441290229559\n",
      "Epoch 3555, Loss: 0.0005103740350023145, Final Batch Loss: 5.20639332535211e-06\n",
      "Epoch 3556, Loss: 1.087037123426171e-06, Final Batch Loss: 1.0398302947578486e-06\n",
      "Epoch 3557, Loss: 0.00036655023518505914, Final Batch Loss: 3.061582674490637e-06\n",
      "Epoch 3558, Loss: 0.000975850283566615, Final Batch Loss: 0.0009730362216942012\n",
      "Epoch 3559, Loss: 4.144510234027621e-05, Final Batch Loss: 4.103836909052916e-05\n",
      "Epoch 3560, Loss: 0.00023118689853163232, Final Batch Loss: 0.0002307882677996531\n",
      "Epoch 3561, Loss: 0.000471353752022452, Final Batch Loss: 5.385949819469715e-08\n",
      "Epoch 3562, Loss: 0.0005499614175619172, Final Batch Loss: 4.1363585978615447e-07\n",
      "Epoch 3563, Loss: 2.181153061542318e-05, Final Batch Loss: 2.1369518435676582e-05\n",
      "Epoch 3564, Loss: 4.944490967773163e-06, Final Batch Loss: 6.269127084124193e-07\n",
      "Epoch 3565, Loss: 4.5249827081761396e-05, Final Batch Loss: 3.9496356407653366e-07\n",
      "Epoch 3566, Loss: 0.0001091843623726163, Final Batch Loss: 2.9422404622891918e-05\n",
      "Epoch 3567, Loss: 1.254696417163359e-05, Final Batch Loss: 3.497252691886388e-07\n",
      "Epoch 3568, Loss: 3.766451732190035e-05, Final Batch Loss: 3.477345308056101e-05\n",
      "Epoch 3569, Loss: 0.004548317938315449, Final Batch Loss: 0.004532007034868002\n",
      "Epoch 3570, Loss: 0.000259897413343424, Final Batch Loss: 0.00020127090101595968\n",
      "Epoch 3571, Loss: 5.496246785696712e-06, Final Batch Loss: 9.615207545721205e-07\n",
      "Epoch 3572, Loss: 5.465766859025223e-05, Final Batch Loss: 1.723507203621466e-08\n",
      "Epoch 3573, Loss: 0.0001576146314619109, Final Batch Loss: 5.5487580539193004e-05\n",
      "Epoch 3574, Loss: 7.08291145201656e-06, Final Batch Loss: 5.773581506218761e-07\n",
      "Epoch 3575, Loss: 4.471642526482356e-06, Final Batch Loss: 7.46849337929234e-08\n",
      "Epoch 3576, Loss: 0.000366159823443013, Final Batch Loss: 2.3206152945931535e-06\n",
      "Epoch 3577, Loss: 9.725999206011693e-06, Final Batch Loss: 3.590587027701986e-07\n",
      "Epoch 3578, Loss: 3.774370594555876e-05, Final Batch Loss: 3.712574107339606e-05\n",
      "Epoch 3579, Loss: 9.236167720416688e-06, Final Batch Loss: 9.263822420280121e-08\n",
      "Epoch 3580, Loss: 1.3577140180132119e-05, Final Batch Loss: 7.408325927826809e-06\n",
      "Epoch 3581, Loss: 1.4497289612336317e-05, Final Batch Loss: 9.51086803979706e-06\n",
      "Epoch 3582, Loss: 2.7249677145846363e-06, Final Batch Loss: 3.3607733485041535e-07\n",
      "Epoch 3583, Loss: 7.401806169582414e-05, Final Batch Loss: 2.1554510567511898e-06\n",
      "Epoch 3584, Loss: 0.0004269554410711862, Final Batch Loss: 0.000400657212594524\n",
      "Epoch 3585, Loss: 7.035845338343449e-06, Final Batch Loss: 1.0053791577036009e-08\n",
      "Epoch 3586, Loss: 2.0221619934090995e-06, Final Batch Loss: 1.773761368895066e-07\n",
      "Epoch 3587, Loss: 4.879070161223353e-06, Final Batch Loss: 3.602687684178818e-06\n",
      "Epoch 3588, Loss: 2.417609557880951e-06, Final Batch Loss: 1.1346384809485244e-07\n",
      "Epoch 3589, Loss: 4.5642520035471534e-05, Final Batch Loss: 4.022369012091076e-06\n",
      "Epoch 3590, Loss: 5.267621963866986e-05, Final Batch Loss: 3.2314692361978814e-05\n",
      "Epoch 3591, Loss: 1.52426810018369e-05, Final Batch Loss: 9.636823961045593e-07\n",
      "Epoch 3592, Loss: 0.00014172921893873536, Final Batch Loss: 2.62833253827921e-07\n",
      "Epoch 3593, Loss: 1.1155991956002254e-05, Final Batch Loss: 9.27473320189165e-06\n",
      "Epoch 3594, Loss: 2.7582655548030743e-05, Final Batch Loss: 2.404165206826292e-05\n",
      "Epoch 3595, Loss: 8.056473859596736e-06, Final Batch Loss: 5.974704322397884e-07\n",
      "Epoch 3596, Loss: 1.328510151665796e-06, Final Batch Loss: 1.5080614446105756e-07\n",
      "Epoch 3597, Loss: 2.885915677097728e-06, Final Batch Loss: 2.7738594781112624e-06\n",
      "Epoch 3598, Loss: 0.0005032939725424512, Final Batch Loss: 0.0005027074948884547\n",
      "Epoch 3599, Loss: 5.577380264298881e-07, Final Batch Loss: 8.18662115875668e-08\n",
      "Epoch 3600, Loss: 2.7702428724296624e-06, Final Batch Loss: 5.507940841198433e-07\n",
      "Epoch 3601, Loss: 1.453502682124963e-05, Final Batch Loss: 6.6656130002229474e-06\n",
      "Epoch 3602, Loss: 6.0055170024497784e-05, Final Batch Loss: 5.745811358792707e-05\n",
      "Epoch 3603, Loss: 7.21569008987899e-07, Final Batch Loss: 3.159762229643093e-08\n",
      "Epoch 3604, Loss: 1.0293186733179027e-05, Final Batch Loss: 9.163090908259619e-07\n",
      "Epoch 3605, Loss: 7.006568694123416e-07, Final Batch Loss: 4.078879101143684e-07\n",
      "Epoch 3606, Loss: 9.707873459774419e-06, Final Batch Loss: 6.340049822028959e-06\n",
      "Epoch 3607, Loss: 3.304624533484457e-05, Final Batch Loss: 1.896655885502696e-05\n",
      "Epoch 3608, Loss: 2.713846811275289e-06, Final Batch Loss: 1.8088351225742372e-06\n",
      "Epoch 3609, Loss: 9.994234960686299e-05, Final Batch Loss: 4.011278633697657e-06\n",
      "Epoch 3610, Loss: 4.227373574394733e-05, Final Batch Loss: 3.4141954529332e-05\n",
      "Epoch 3611, Loss: 0.0006343326558635454, Final Batch Loss: 0.0006276401691138744\n",
      "Epoch 3612, Loss: 4.068676275892358e-05, Final Batch Loss: 9.945804322342156e-07\n",
      "Epoch 3613, Loss: 0.001812556737831983, Final Batch Loss: 1.747722535583307e-06\n",
      "Epoch 3614, Loss: 2.0415779999893857e-06, Final Batch Loss: 1.4727304460393498e-06\n",
      "Epoch 3615, Loss: 6.366837897076039e-05, Final Batch Loss: 1.5439245544257574e-06\n",
      "Epoch 3616, Loss: 3.907791892743262e-06, Final Batch Loss: 2.2080914732214296e-06\n",
      "Epoch 3617, Loss: 0.0014601219613723515, Final Batch Loss: 0.0014544184086844325\n",
      "Epoch 3618, Loss: 7.597574858664302e-05, Final Batch Loss: 7.391998951788992e-05\n",
      "Epoch 3619, Loss: 0.0001657705440720747, Final Batch Loss: 1.6478886664117454e-06\n",
      "Epoch 3620, Loss: 1.687031937080974e-05, Final Batch Loss: 4.165070208728139e-07\n",
      "Epoch 3621, Loss: 2.9664503813364718e-06, Final Batch Loss: 7.33172043965169e-07\n",
      "Epoch 3622, Loss: 0.007183247554849004, Final Batch Loss: 2.0091717942705145e-06\n",
      "Epoch 3623, Loss: 0.000678326835441112, Final Batch Loss: 1.1645798622339498e-05\n",
      "Epoch 3624, Loss: 0.00010661343674200907, Final Batch Loss: 1.059191504282353e-06\n",
      "Epoch 3625, Loss: 0.00026837931242340574, Final Batch Loss: 1.170543910689048e-07\n",
      "Epoch 3626, Loss: 6.06268630320983e-05, Final Batch Loss: 4.380568441320065e-08\n",
      "Epoch 3627, Loss: 1.1281881597824395e-06, Final Batch Loss: 1.888652150228154e-07\n",
      "Epoch 3628, Loss: 0.0002012752256632666, Final Batch Loss: 3.56704094883753e-06\n",
      "Epoch 3629, Loss: 2.1384982176186895e-06, Final Batch Loss: 4.272722264886397e-07\n",
      "Epoch 3630, Loss: 0.001010407075227704, Final Batch Loss: 0.0009637383627705276\n",
      "Epoch 3631, Loss: 5.774545385861529e-06, Final Batch Loss: 2.2764315588119644e-07\n",
      "Epoch 3632, Loss: 0.0005187753886275459, Final Batch Loss: 5.8565219660522416e-05\n",
      "Epoch 3633, Loss: 1.3759777630184544e-05, Final Batch Loss: 8.548036021238659e-06\n",
      "Epoch 3634, Loss: 0.00011747602866307716, Final Batch Loss: 0.00011444355186540633\n",
      "Epoch 3635, Loss: 0.0004935481920256279, Final Batch Loss: 0.0004722395970020443\n",
      "Epoch 3636, Loss: 1.7343643264666753e-05, Final Batch Loss: 4.3445965047794743e-07\n",
      "Epoch 3637, Loss: 2.7548264895926877e-06, Final Batch Loss: 2.6618436095304787e-06\n",
      "Epoch 3638, Loss: 1.9046053296278842e-05, Final Batch Loss: 1.8235474271932617e-05\n",
      "Epoch 3639, Loss: 1.70836462416446e-05, Final Batch Loss: 1.6245870938291773e-05\n",
      "Epoch 3640, Loss: 1.1847722930724558e-05, Final Batch Loss: 1.0823543561855331e-05\n",
      "Epoch 3641, Loss: 8.587246043134655e-06, Final Batch Loss: 8.01029455033131e-06\n",
      "Epoch 3642, Loss: 1.534844037109906e-05, Final Batch Loss: 3.7557643395302875e-07\n",
      "Epoch 3643, Loss: 1.8431044054523227e-05, Final Batch Loss: 1.3219917036622064e-06\n",
      "Epoch 3644, Loss: 0.0007657040696358308, Final Batch Loss: 9.948584192898124e-05\n",
      "Epoch 3645, Loss: 6.7462858623912325e-06, Final Batch Loss: 3.22791856888216e-06\n",
      "Epoch 3646, Loss: 8.435038978404918e-07, Final Batch Loss: 7.180967713793507e-07\n",
      "Epoch 3647, Loss: 2.0028824962992076e-06, Final Batch Loss: 1.6142674894581432e-06\n",
      "Epoch 3648, Loss: 1.061030168614252e-06, Final Batch Loss: 9.694702640672404e-08\n",
      "Epoch 3649, Loss: 0.0009505445636932564, Final Batch Loss: 0.0009463947499170899\n",
      "Epoch 3650, Loss: 5.513917699317972e-06, Final Batch Loss: 4.586514023685595e-06\n",
      "Epoch 3651, Loss: 2.490229391582943e-07, Final Batch Loss: 8.83296209508444e-08\n",
      "Epoch 3652, Loss: 0.0001574084364222017, Final Batch Loss: 0.00015711566084064543\n",
      "Epoch 3653, Loss: 0.00041316313740935584, Final Batch Loss: 3.5063510495092487e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3654, Loss: 7.60355283091485e-06, Final Batch Loss: 5.1719412113016006e-06\n",
      "Epoch 3655, Loss: 0.00035438336479387544, Final Batch Loss: 0.00035404672962613404\n",
      "Epoch 3656, Loss: 0.00042495452998991823, Final Batch Loss: 2.9910142984590493e-06\n",
      "Epoch 3657, Loss: 8.437381906478691e-07, Final Batch Loss: 3.5906408957231406e-09\n",
      "Epoch 3658, Loss: 0.0003827012669717078, Final Batch Loss: 1.096527739719022e-06\n",
      "Epoch 3659, Loss: 9.818037156605897e-07, Final Batch Loss: 9.055099212673667e-07\n",
      "Epoch 3660, Loss: 4.659664455175516e-06, Final Batch Loss: 2.157008566427976e-06\n",
      "Epoch 3661, Loss: 0.0008617653220426291, Final Batch Loss: 0.00019295260426588356\n",
      "Epoch 3662, Loss: 3.500367078856925e-05, Final Batch Loss: 3.478719008853659e-05\n",
      "Epoch 3663, Loss: 1.1190233038860242e-05, Final Batch Loss: 1.9461216993477137e-07\n",
      "Epoch 3664, Loss: 4.087237130079302e-06, Final Batch Loss: 3.2771120004326804e-06\n",
      "Epoch 3665, Loss: 1.7205072708748048e-06, Final Batch Loss: 7.49694322621508e-07\n",
      "Epoch 3666, Loss: 0.002593939041616977, Final Batch Loss: 0.00257269199937582\n",
      "Epoch 3667, Loss: 4.8609009866140696e-05, Final Batch Loss: 4.7826648597038e-07\n",
      "Epoch 3668, Loss: 5.248342286989782e-06, Final Batch Loss: 5.2211626098142006e-06\n",
      "Epoch 3669, Loss: 1.5384165408249828e-06, Final Batch Loss: 8.236694384322618e-07\n",
      "Epoch 3670, Loss: 8.853583608470217e-07, Final Batch Loss: 3.9137165686042863e-07\n",
      "Epoch 3671, Loss: 0.00012755614443449304, Final Batch Loss: 7.280342833837494e-05\n",
      "Epoch 3672, Loss: 7.214317179204954e-07, Final Batch Loss: 3.561873143098637e-07\n",
      "Epoch 3673, Loss: 0.0002566932528225152, Final Batch Loss: 1.0369114988861838e-06\n",
      "Epoch 3674, Loss: 3.22517657878052e-05, Final Batch Loss: 5.728659289161442e-06\n",
      "Epoch 3675, Loss: 8.261595303338254e-05, Final Batch Loss: 7.805412315065041e-05\n",
      "Epoch 3676, Loss: 0.00021062647533653944, Final Batch Loss: 2.085815822283621e-06\n",
      "Epoch 3677, Loss: 7.640245257789502e-06, Final Batch Loss: 4.954975338478107e-06\n",
      "Epoch 3678, Loss: 0.000133305069610401, Final Batch Loss: 1.4937002390524867e-07\n",
      "Epoch 3679, Loss: 2.4163666353160806e-05, Final Batch Loss: 8.617281537226518e-07\n",
      "Epoch 3680, Loss: 0.00015069510391185759, Final Batch Loss: 1.019209867081372e-05\n",
      "Epoch 3681, Loss: 0.00025160904256438243, Final Batch Loss: 1.414700392388113e-07\n",
      "Epoch 3682, Loss: 1.4787071336286317e-06, Final Batch Loss: 8.064088206083397e-07\n",
      "Epoch 3683, Loss: 5.4250220316021114e-08, Final Batch Loss: 3.2315721654185836e-08\n",
      "Epoch 3684, Loss: 2.040875222064642e-05, Final Batch Loss: 5.091463890494197e-07\n",
      "Epoch 3685, Loss: 4.775449441751789e-05, Final Batch Loss: 4.7624318540329114e-05\n",
      "Epoch 3686, Loss: 1.2865978419540625e-05, Final Batch Loss: 9.931462727763574e-07\n",
      "Epoch 3687, Loss: 3.431086071259415e-06, Final Batch Loss: 3.0515293474309146e-06\n",
      "Epoch 3688, Loss: 1.1995319297852802e-06, Final Batch Loss: 8.761133329926452e-08\n",
      "Epoch 3689, Loss: 1.4253105405259703e-05, Final Batch Loss: 7.892059556979802e-07\n",
      "Epoch 3690, Loss: 7.388285894194269e-06, Final Batch Loss: 3.293298277640133e-06\n",
      "Epoch 3691, Loss: 3.0189132758096093e-06, Final Batch Loss: 1.0627459232637193e-06\n",
      "Epoch 3692, Loss: 0.000168878025306185, Final Batch Loss: 9.909786058415193e-07\n",
      "Epoch 3693, Loss: 2.120625454438141e-05, Final Batch Loss: 1.960465425554503e-07\n",
      "Epoch 3694, Loss: 2.333644985696992e-06, Final Batch Loss: 8.761121250699944e-08\n",
      "Epoch 3695, Loss: 1.3713948874283233e-05, Final Batch Loss: 3.729382342498866e-06\n",
      "Epoch 3696, Loss: 7.705899426468932e-05, Final Batch Loss: 1.5583302115373954e-07\n",
      "Epoch 3697, Loss: 1.7167103294468689e-06, Final Batch Loss: 1.2537217344288365e-06\n",
      "Epoch 3698, Loss: 7.716605091445672e-05, Final Batch Loss: 3.2961747820081655e-07\n",
      "Epoch 3699, Loss: 0.00014786934116273187, Final Batch Loss: 2.419688826194033e-06\n",
      "Epoch 3700, Loss: 6.870597811570178e-06, Final Batch Loss: 4.1651386339935925e-08\n",
      "Epoch 3701, Loss: 1.5452734487553244e-06, Final Batch Loss: 1.2272266758373007e-06\n",
      "Epoch 3702, Loss: 0.00018093283222242462, Final Batch Loss: 0.00017923417908605188\n",
      "Epoch 3703, Loss: 1.4115763491417965e-06, Final Batch Loss: 6.319520196029771e-08\n",
      "Epoch 3704, Loss: 0.00021019263813215616, Final Batch Loss: 4.955081678303941e-08\n",
      "Epoch 3705, Loss: 1.7143548120657215e-05, Final Batch Loss: 5.882312052563066e-06\n",
      "Epoch 3706, Loss: 3.9168484136098414e-05, Final Batch Loss: 3.861584991682321e-05\n",
      "Epoch 3707, Loss: 0.0001881949938251637, Final Batch Loss: 0.00018051263759844005\n",
      "Epoch 3708, Loss: 1.7214467789017363e-05, Final Batch Loss: 4.205384811939439e-06\n",
      "Epoch 3709, Loss: 1.743557999134282e-05, Final Batch Loss: 1.7297297745244578e-05\n",
      "Epoch 3710, Loss: 8.121727148591162e-07, Final Batch Loss: 3.9065432133611466e-07\n",
      "Epoch 3711, Loss: 1.4020401522429893e-05, Final Batch Loss: 6.324226433207514e-06\n",
      "Epoch 3712, Loss: 9.66518452969467e-05, Final Batch Loss: 4.423598056746414e-07\n",
      "Epoch 3713, Loss: 3.1148322250373894e-06, Final Batch Loss: 1.72685304278275e-06\n",
      "Epoch 3714, Loss: 4.5230594025724713e-07, Final Batch Loss: 6.750367731456208e-08\n",
      "Epoch 3715, Loss: 2.6490887989893963e-06, Final Batch Loss: 7.640520038876275e-07\n",
      "Epoch 3716, Loss: 2.4906426915549673e-05, Final Batch Loss: 1.9934634110541083e-05\n",
      "Epoch 3717, Loss: 0.00019631668692454696, Final Batch Loss: 1.670297933742404e-06\n",
      "Epoch 3718, Loss: 0.0004686553684223327, Final Batch Loss: 1.3688691069546621e-05\n",
      "Epoch 3719, Loss: 6.268301831369172e-06, Final Batch Loss: 1.2802986475435318e-06\n",
      "Epoch 3720, Loss: 6.847933585163446e-05, Final Batch Loss: 1.8958419900627632e-07\n",
      "Epoch 3721, Loss: 0.00018330803234789528, Final Batch Loss: 0.0001828998647397384\n",
      "Epoch 3722, Loss: 6.459505428324519e-07, Final Batch Loss: 8.043003418833905e-08\n",
      "Epoch 3723, Loss: 5.873827331015491e-05, Final Batch Loss: 5.1191150305385236e-06\n",
      "Epoch 3724, Loss: 1.8886037821630453e-05, Final Batch Loss: 5.550920718633279e-07\n",
      "Epoch 3725, Loss: 2.410090687021693e-06, Final Batch Loss: 2.2136352981760865e-06\n",
      "Epoch 3726, Loss: 9.73842543317005e-05, Final Batch Loss: 6.126309017417952e-05\n",
      "Epoch 3727, Loss: 5.349188413106276e-06, Final Batch Loss: 5.147488082002383e-06\n",
      "Epoch 3728, Loss: 0.0003188667178619653, Final Batch Loss: 0.0001947856944752857\n",
      "Epoch 3729, Loss: 1.7981719565796084e-05, Final Batch Loss: 1.4547876162396278e-05\n",
      "Epoch 3730, Loss: 2.125019946674911e-07, Final Batch Loss: 7.755767938988356e-08\n",
      "Epoch 3731, Loss: 1.4333630673490916e-06, Final Batch Loss: 1.2135442375438288e-06\n",
      "Epoch 3732, Loss: 4.376481410872657e-05, Final Batch Loss: 1.6653015336487442e-05\n",
      "Epoch 3733, Loss: 8.282609314846923e-06, Final Batch Loss: 2.7792505079560215e-06\n",
      "Epoch 3734, Loss: 1.2228119715018693e-05, Final Batch Loss: 1.1926289516850375e-05\n",
      "Epoch 3735, Loss: 4.784481518527173e-06, Final Batch Loss: 5.471898134601361e-07\n",
      "Epoch 3736, Loss: 8.399503670375452e-07, Final Batch Loss: 6.606769176187299e-08\n",
      "Epoch 3737, Loss: 1.3826068425260019e-05, Final Batch Loss: 5.097715984447859e-06\n",
      "Epoch 3738, Loss: 3.486744162728428e-06, Final Batch Loss: 2.1865098460693844e-06\n",
      "Epoch 3739, Loss: 0.0002359115885610663, Final Batch Loss: 8.782069471635623e-07\n",
      "Epoch 3740, Loss: 3.179061209834799e-07, Final Batch Loss: 2.5134461623110838e-08\n",
      "Epoch 3741, Loss: 2.8507238766906084e-05, Final Batch Loss: 2.2171050659380853e-05\n",
      "Epoch 3742, Loss: 0.00011690074825310148, Final Batch Loss: 7.072219159454107e-05\n",
      "Epoch 3743, Loss: 3.577369223251026e-05, Final Batch Loss: 3.5682616726262495e-05\n",
      "Epoch 3744, Loss: 7.335639708117014e-06, Final Batch Loss: 3.260248888636852e-07\n",
      "Epoch 3745, Loss: 1.3462219143889342e-05, Final Batch Loss: 6.894013893088413e-08\n",
      "Epoch 3746, Loss: 3.7320006640584324e-06, Final Batch Loss: 2.6902343961410224e-06\n",
      "Epoch 3747, Loss: 6.357549550983776e-05, Final Batch Loss: 9.622868191172529e-08\n",
      "Epoch 3748, Loss: 1.2706883126156754e-05, Final Batch Loss: 1.0740383913798723e-05\n",
      "Epoch 3749, Loss: 0.0004896012646895542, Final Batch Loss: 0.00048451978364028037\n",
      "Epoch 3750, Loss: 1.3400826446741121e-05, Final Batch Loss: 5.601218617812265e-07\n",
      "Epoch 3751, Loss: 7.014193244003764e-07, Final Batch Loss: 5.407274557001074e-07\n",
      "Epoch 3752, Loss: 5.069344695129985e-07, Final Batch Loss: 2.5421425675631326e-07\n",
      "Epoch 3753, Loss: 1.9168151993653737e-05, Final Batch Loss: 1.2975852769159246e-05\n",
      "Epoch 3754, Loss: 0.00016469462570967153, Final Batch Loss: 4.058623017044738e-05\n",
      "Epoch 3755, Loss: 4.528489583321971e-06, Final Batch Loss: 2.1902629043779598e-07\n",
      "Epoch 3756, Loss: 3.552164066888963e-06, Final Batch Loss: 3.481592329990235e-06\n",
      "Epoch 3757, Loss: 9.056518990746554e-06, Final Batch Loss: 6.822205023127026e-08\n",
      "Epoch 3758, Loss: 4.560437616873969e-06, Final Batch Loss: 4.137024006922729e-06\n",
      "Epoch 3759, Loss: 4.713690145763394e-06, Final Batch Loss: 4.174400146439439e-06\n",
      "Epoch 3760, Loss: 2.319560223895678e-06, Final Batch Loss: 1.907101591314131e-06\n",
      "Epoch 3761, Loss: 0.00020817769809688969, Final Batch Loss: 2.1543838713000696e-08\n",
      "Epoch 3762, Loss: 1.8419504783651064e-06, Final Batch Loss: 1.8138171071768738e-06\n",
      "Epoch 3763, Loss: 6.849347987269994e-05, Final Batch Loss: 2.326719794609744e-07\n",
      "Epoch 3764, Loss: 1.4362701961090352e-06, Final Batch Loss: 1.2208175803607446e-08\n",
      "Epoch 3765, Loss: 3.422443626277527e-06, Final Batch Loss: 2.562784857218503e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3766, Loss: 8.02932931946998e-05, Final Batch Loss: 7.31858381186612e-05\n",
      "Epoch 3767, Loss: 3.209315195817908e-07, Final Batch Loss: 1.2495348755692248e-07\n",
      "Epoch 3768, Loss: 8.730290517178219e-06, Final Batch Loss: 7.916831236798316e-06\n",
      "Epoch 3769, Loss: 7.190853011707077e-06, Final Batch Loss: 2.458616563671967e-06\n",
      "Epoch 3770, Loss: 2.818782377289608e-06, Final Batch Loss: 1.9271499240858248e-06\n",
      "Epoch 3771, Loss: 9.916100225382252e-06, Final Batch Loss: 5.43973192179692e-06\n",
      "Epoch 3772, Loss: 1.1608131273987965e-06, Final Batch Loss: 8.933107551456487e-07\n",
      "Epoch 3773, Loss: 3.2000614282878814e-06, Final Batch Loss: 1.5804181430212338e-06\n",
      "Epoch 3774, Loss: 6.767780519112421e-06, Final Batch Loss: 4.9731934268493205e-06\n",
      "Epoch 3775, Loss: 0.0013241532905112763, Final Batch Loss: 0.001324053155258298\n",
      "Epoch 3776, Loss: 3.2060704370451276e-05, Final Batch Loss: 2.753781927822274e-06\n",
      "Epoch 3777, Loss: 9.285479563914123e-06, Final Batch Loss: 7.649125109310262e-06\n",
      "Epoch 3778, Loss: 0.0007395562524834531, Final Batch Loss: 4.966025699104648e-06\n",
      "Epoch 3779, Loss: 1.0284304892138607e-06, Final Batch Loss: 4.567205849070888e-07\n",
      "Epoch 3780, Loss: 1.8193234723185014e-06, Final Batch Loss: 4.337389896136301e-07\n",
      "Epoch 3781, Loss: 7.616381803643435e-05, Final Batch Loss: 7.597642252221704e-05\n",
      "Epoch 3782, Loss: 8.565678513150488e-07, Final Batch Loss: 4.064486631705222e-07\n",
      "Epoch 3783, Loss: 4.249307630743715e-05, Final Batch Loss: 5.197736300033284e-06\n",
      "Epoch 3784, Loss: 2.28468041996166e-06, Final Batch Loss: 1.5251241620717337e-06\n",
      "Epoch 3785, Loss: 5.377399610928535e-05, Final Batch Loss: 2.8006974517325034e-08\n",
      "Epoch 3786, Loss: 0.00011681854875433828, Final Batch Loss: 1.0915454851101458e-07\n",
      "Epoch 3787, Loss: 4.458764237824653e-07, Final Batch Loss: 2.484677850134176e-07\n",
      "Epoch 3788, Loss: 7.388983362943691e-07, Final Batch Loss: 2.549340933910571e-07\n",
      "Epoch 3789, Loss: 0.0002891135991376359, Final Batch Loss: 0.0002562301233410835\n",
      "Epoch 3790, Loss: 4.96058021326462e-07, Final Batch Loss: 9.981914672607672e-08\n",
      "Epoch 3791, Loss: 1.6942170077527408e-05, Final Batch Loss: 6.703071449010167e-06\n",
      "Epoch 3792, Loss: 0.001807497362904087, Final Batch Loss: 8.624189717920672e-07\n",
      "Epoch 3793, Loss: 0.0001723981658159346, Final Batch Loss: 1.7450285838549462e-07\n",
      "Epoch 3794, Loss: 0.0007363589902524836, Final Batch Loss: 0.0006186396349221468\n",
      "Epoch 3795, Loss: 6.810691684222547e-05, Final Batch Loss: 2.094678166031372e-06\n",
      "Epoch 3796, Loss: 1.7847251996272462e-06, Final Batch Loss: 2.5852600060716213e-08\n",
      "Epoch 3797, Loss: 1.8174680747051752e-06, Final Batch Loss: 1.628642621653853e-06\n",
      "Epoch 3798, Loss: 1.427532367870299e-06, Final Batch Loss: 9.449907452108164e-07\n",
      "Epoch 3799, Loss: 6.366144725689082e-05, Final Batch Loss: 6.011939603922656e-06\n",
      "Epoch 3800, Loss: 4.23309111852177e-06, Final Batch Loss: 3.734229778729059e-07\n",
      "Epoch 3801, Loss: 5.552821329501967e-05, Final Batch Loss: 6.635165732404857e-07\n",
      "Epoch 3802, Loss: 0.0001428643751069103, Final Batch Loss: 0.0001427189417881891\n",
      "Epoch 3803, Loss: 1.2364416335231e-07, Final Batch Loss: 3.590637476236225e-08\n",
      "Epoch 3804, Loss: 1.0243142014587647e-06, Final Batch Loss: 8.57422890021553e-07\n",
      "Epoch 3805, Loss: 2.259916470848111e-06, Final Batch Loss: 1.5647163991161506e-06\n",
      "Epoch 3806, Loss: 0.00044109280861448497, Final Batch Loss: 0.00017049301823135465\n",
      "Epoch 3807, Loss: 1.5885226716250145e-06, Final Batch Loss: 1.5560977999484749e-06\n",
      "Epoch 3808, Loss: 0.0029727370445016277, Final Batch Loss: 0.0029690819792449474\n",
      "Epoch 3809, Loss: 1.0157773715491203e-06, Final Batch Loss: 7.554282319688355e-07\n",
      "Epoch 3810, Loss: 1.5822618934180355e-05, Final Batch Loss: 2.932376901298994e-06\n",
      "Epoch 3811, Loss: 2.5367174174562024e-05, Final Batch Loss: 2.5244151402148418e-05\n",
      "Epoch 3812, Loss: 3.064170499555985e-06, Final Batch Loss: 2.8524561912490753e-06\n",
      "Epoch 3813, Loss: 1.5322013553031866e-05, Final Batch Loss: 3.0017514518476673e-07\n",
      "Epoch 3814, Loss: 4.778408424499503e-07, Final Batch Loss: 3.1237962616614823e-07\n",
      "Epoch 3815, Loss: 0.00021536668646149337, Final Batch Loss: 7.889437256380916e-05\n",
      "Epoch 3816, Loss: 0.002647077664732933, Final Batch Loss: 0.0015430605271831155\n",
      "Epoch 3817, Loss: 5.131145712766738e-07, Final Batch Loss: 7.253052558553463e-08\n",
      "Epoch 3818, Loss: 0.0008348098926944658, Final Batch Loss: 0.00015775357314851135\n",
      "Epoch 3819, Loss: 0.0008721224085093127, Final Batch Loss: 1.357559176540235e-05\n",
      "Epoch 3820, Loss: 0.0002590841757417195, Final Batch Loss: 1.4362559142000464e-08\n",
      "Epoch 3821, Loss: 3.338171634226228e-05, Final Batch Loss: 6.750385495024602e-08\n",
      "Epoch 3822, Loss: 0.00220288714626804, Final Batch Loss: 0.0014745594235137105\n",
      "Epoch 3823, Loss: 6.325214712887828e-06, Final Batch Loss: 5.2671521189040504e-06\n",
      "Epoch 3824, Loss: 0.0012176622840343043, Final Batch Loss: 0.00017977091192733496\n",
      "Epoch 3825, Loss: 4.620981962943915e-05, Final Batch Loss: 2.28935186896706e-05\n",
      "Epoch 3826, Loss: 1.5041053131881199e-05, Final Batch Loss: 1.4630511032009963e-05\n",
      "Epoch 3827, Loss: 1.5308654468526584e-06, Final Batch Loss: 1.9820048180463345e-07\n",
      "Epoch 3828, Loss: 1.1231893722651876e-05, Final Batch Loss: 7.339101557590766e-07\n",
      "Epoch 3829, Loss: 1.6071385289251339e-06, Final Batch Loss: 8.330266609846149e-08\n",
      "Epoch 3830, Loss: 0.0003863098547753907, Final Batch Loss: 2.021305817834218e-06\n",
      "Epoch 3831, Loss: 1.5251913737301948e-05, Final Batch Loss: 6.064459284971235e-06\n",
      "Epoch 3832, Loss: 0.00014263650200518896, Final Batch Loss: 2.462340944475727e-06\n",
      "Epoch 3833, Loss: 4.0609841107652755e-06, Final Batch Loss: 2.6806096684595104e-06\n",
      "Epoch 3834, Loss: 4.3253884541627485e-05, Final Batch Loss: 3.376070526428521e-05\n",
      "Epoch 3835, Loss: 0.0004614163349287992, Final Batch Loss: 0.00045908812899142504\n",
      "Epoch 3836, Loss: 1.0792025932460092e-05, Final Batch Loss: 4.884566806140356e-06\n",
      "Epoch 3837, Loss: 4.5822320032584685e-05, Final Batch Loss: 4.437985694494273e-07\n",
      "Epoch 3838, Loss: 2.8201418814433055e-05, Final Batch Loss: 1.6588629137004318e-07\n",
      "Epoch 3839, Loss: 1.1552372143341927e-05, Final Batch Loss: 2.6755910766951274e-06\n",
      "Epoch 3840, Loss: 6.0320676311675925e-06, Final Batch Loss: 3.448417146501015e-06\n",
      "Epoch 3841, Loss: 1.7039769772964064e-05, Final Batch Loss: 1.2610386875167023e-05\n",
      "Epoch 3842, Loss: 9.851773370428418e-07, Final Batch Loss: 3.109466319983767e-07\n",
      "Epoch 3843, Loss: 7.914972411526833e-05, Final Batch Loss: 6.840614514658228e-05\n",
      "Epoch 3844, Loss: 3.904319498815312e-06, Final Batch Loss: 5.486321583703102e-07\n",
      "Epoch 3845, Loss: 0.0004008099185739411, Final Batch Loss: 0.00038108901935629547\n",
      "Epoch 3846, Loss: 9.52794312070182e-06, Final Batch Loss: 2.0714830952783814e-06\n",
      "Epoch 3847, Loss: 1.2152867725490069e-06, Final Batch Loss: 4.409243388181494e-07\n",
      "Epoch 3848, Loss: 1.348898678088517e-06, Final Batch Loss: 3.008933902037825e-07\n",
      "Epoch 3849, Loss: 2.121759088424824e-06, Final Batch Loss: 4.667825947990423e-08\n",
      "Epoch 3850, Loss: 9.582509846950416e-06, Final Batch Loss: 4.483894826989854e-06\n",
      "Epoch 3851, Loss: 5.9285041515977355e-06, Final Batch Loss: 2.4874150312825805e-06\n",
      "Epoch 3852, Loss: 9.710881840874208e-06, Final Batch Loss: 3.61587262887042e-06\n",
      "Epoch 3853, Loss: 0.00021448808911372907, Final Batch Loss: 0.00018291898595634848\n",
      "Epoch 3854, Loss: 0.0021328477523638867, Final Batch Loss: 8.775699825491756e-06\n",
      "Epoch 3855, Loss: 8.289947800221853e-06, Final Batch Loss: 4.3669483602570836e-06\n",
      "Epoch 3856, Loss: 4.395954647407052e-06, Final Batch Loss: 3.2735185868659755e-06\n",
      "Epoch 3857, Loss: 0.0004147534387897167, Final Batch Loss: 1.4865200625990838e-07\n",
      "Epoch 3858, Loss: 5.218602268541872e-06, Final Batch Loss: 4.204402557661524e-06\n",
      "Epoch 3859, Loss: 0.0002858860134438146, Final Batch Loss: 0.00026372959837317467\n",
      "Epoch 3860, Loss: 0.0005135060882821563, Final Batch Loss: 0.0005096303066238761\n",
      "Epoch 3861, Loss: 1.0789856560222688e-05, Final Batch Loss: 2.8628771815419896e-06\n",
      "Epoch 3862, Loss: 0.0008052740379298484, Final Batch Loss: 2.4960393147921422e-06\n",
      "Epoch 3863, Loss: 4.960181354363158e-05, Final Batch Loss: 2.853924115697737e-06\n",
      "Epoch 3864, Loss: 0.0004973748759198315, Final Batch Loss: 6.829099561400653e-07\n",
      "Epoch 3865, Loss: 9.102844700237256e-07, Final Batch Loss: 1.8312219651761552e-07\n",
      "Epoch 3866, Loss: 0.000205805594305275, Final Batch Loss: 0.00016693418729119003\n",
      "Epoch 3867, Loss: 4.030625746054284e-06, Final Batch Loss: 1.7011881254802574e-06\n",
      "Epoch 3868, Loss: 1.5481991198385003e-05, Final Batch Loss: 4.05734084552023e-07\n",
      "Epoch 3869, Loss: 0.0004999461816623807, Final Batch Loss: 0.00046177537296898663\n",
      "Epoch 3870, Loss: 3.3455803986726096e-05, Final Batch Loss: 3.077875226153992e-05\n",
      "Epoch 3871, Loss: 1.4165822790346283e-05, Final Batch Loss: 1.302626401411544e-06\n",
      "Epoch 3872, Loss: 1.7805955110361538e-06, Final Batch Loss: 1.3528841691368143e-06\n",
      "Epoch 3873, Loss: 0.00013137186033418402, Final Batch Loss: 9.205016976920888e-05\n",
      "Epoch 3874, Loss: 0.0002896263007059474, Final Batch Loss: 0.0002895643119700253\n",
      "Epoch 3875, Loss: 0.00032306662967585, Final Batch Loss: 0.0003227223642170429\n",
      "Epoch 3876, Loss: 3.131239623144211e-07, Final Batch Loss: 8.043016919145884e-08\n",
      "Epoch 3877, Loss: 2.3239416577780503e-06, Final Batch Loss: 5.436022547655739e-07\n",
      "Epoch 3878, Loss: 8.131824586143921e-05, Final Batch Loss: 4.1938335471058963e-07\n",
      "Epoch 3879, Loss: 3.314733066872577e-05, Final Batch Loss: 2.8404247132129967e-05\n",
      "Epoch 3880, Loss: 2.078853344755771e-05, Final Batch Loss: 8.330266609846149e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3881, Loss: 1.4013254684641652e-05, Final Batch Loss: 3.662430287931784e-07\n",
      "Epoch 3882, Loss: 6.629945033864715e-06, Final Batch Loss: 5.385950885283819e-08\n",
      "Epoch 3883, Loss: 7.398339565156675e-05, Final Batch Loss: 1.0125566518581763e-07\n",
      "Epoch 3884, Loss: 1.1517411735439964e-06, Final Batch Loss: 3.569056730157172e-07\n",
      "Epoch 3885, Loss: 1.8401465240458492e-06, Final Batch Loss: 9.76618366621551e-07\n",
      "Epoch 3886, Loss: 2.1664405736032677e-07, Final Batch Loss: 1.5942379150146735e-07\n",
      "Epoch 3887, Loss: 9.466037226957269e-06, Final Batch Loss: 1.9588351278798655e-06\n",
      "Epoch 3888, Loss: 1.0237670394985798e-05, Final Batch Loss: 3.734261611043621e-08\n",
      "Epoch 3889, Loss: 5.22964155891259e-06, Final Batch Loss: 5.019835043640342e-06\n",
      "Epoch 3890, Loss: 8.408342546317726e-05, Final Batch Loss: 3.228044806746766e-05\n",
      "Epoch 3891, Loss: 1.1611679667566932e-05, Final Batch Loss: 1.09055035864003e-05\n",
      "Epoch 3892, Loss: 4.7060995711945e-05, Final Batch Loss: 3.046399615413975e-05\n",
      "Epoch 3893, Loss: 1.712496828076837e-05, Final Batch Loss: 1.7406471215508645e-06\n",
      "Epoch 3894, Loss: 5.340583697943657e-06, Final Batch Loss: 1.7571370563018718e-06\n",
      "Epoch 3895, Loss: 2.3807461957403575e-05, Final Batch Loss: 1.2926216186315287e-07\n",
      "Epoch 3896, Loss: 3.5026662317250157e-06, Final Batch Loss: 1.105149067370803e-06\n",
      "Epoch 3897, Loss: 3.761233574550715e-05, Final Batch Loss: 3.5295488487463444e-05\n",
      "Epoch 3898, Loss: 3.149957308323792e-06, Final Batch Loss: 2.861473376469803e-06\n",
      "Epoch 3899, Loss: 2.607635542517528e-05, Final Batch Loss: 1.1608851309574675e-05\n",
      "Epoch 3900, Loss: 0.00027762008630816126, Final Batch Loss: 0.0002714247675612569\n",
      "Epoch 3901, Loss: 3.728317824425176e-05, Final Batch Loss: 9.178926120512187e-06\n",
      "Epoch 3902, Loss: 3.417537300265394e-06, Final Batch Loss: 6.032012151990784e-07\n",
      "Epoch 3903, Loss: 0.0013248527075120364, Final Batch Loss: 0.0013129700673744082\n",
      "Epoch 3904, Loss: 5.763336275776965e-06, Final Batch Loss: 2.011310243688058e-06\n",
      "Epoch 3905, Loss: 1.6193701043221154e-05, Final Batch Loss: 1.6054942534537986e-05\n",
      "Epoch 3906, Loss: 2.3138814711387568e-05, Final Batch Loss: 2.3042493921821006e-05\n",
      "Epoch 3907, Loss: 0.0001411583689332474, Final Batch Loss: 5.01628419442568e-05\n",
      "Epoch 3908, Loss: 1.1301658986440088e-06, Final Batch Loss: 9.198845987157256e-07\n",
      "Epoch 3909, Loss: 1.8695836388360476e-05, Final Batch Loss: 4.402736976771848e-06\n",
      "Epoch 3910, Loss: 0.0002609600473988394, Final Batch Loss: 4.5154579311201815e-06\n",
      "Epoch 3911, Loss: 1.5979146155586932e-05, Final Batch Loss: 1.420403532392811e-05\n",
      "Epoch 3912, Loss: 1.3018988738622284e-05, Final Batch Loss: 1.1026546417269856e-05\n",
      "Epoch 3913, Loss: 6.629057054396981e-07, Final Batch Loss: 2.671412175914156e-07\n",
      "Epoch 3914, Loss: 3.125836154360684e-07, Final Batch Loss: 5.026897564874844e-09\n",
      "Epoch 3915, Loss: 3.48387261510652e-05, Final Batch Loss: 4.825661108043278e-06\n",
      "Epoch 3916, Loss: 1.9428929931564198e-07, Final Batch Loss: 1.7378532390921464e-07\n",
      "Epoch 3917, Loss: 1.0894639913772153e-05, Final Batch Loss: 5.888638554552017e-08\n",
      "Epoch 3918, Loss: 0.0006437523476989782, Final Batch Loss: 2.1543840489357535e-08\n",
      "Epoch 3919, Loss: 1.076553121492907e-05, Final Batch Loss: 3.5958344142272836e-06\n",
      "Epoch 3920, Loss: 5.464090884288453e-05, Final Batch Loss: 5.344317833078094e-05\n",
      "Epoch 3921, Loss: 3.60189420689494e-06, Final Batch Loss: 9.033709034156345e-07\n",
      "Epoch 3922, Loss: 2.840385320723726e-06, Final Batch Loss: 4.911875635116303e-07\n",
      "Epoch 3923, Loss: 3.1279600420930365e-06, Final Batch Loss: 2.2839903977001086e-06\n",
      "Epoch 3924, Loss: 1.0603013961940633e-05, Final Batch Loss: 9.192002892177698e-08\n",
      "Epoch 3925, Loss: 1.8857022041629534e-05, Final Batch Loss: 1.6372960089938715e-05\n",
      "Epoch 3926, Loss: 1.382874788191657e-05, Final Batch Loss: 1.3416770343610551e-05\n",
      "Epoch 3927, Loss: 1.011813338891443e-06, Final Batch Loss: 6.570531922989176e-07\n",
      "Epoch 3928, Loss: 9.47102847703718e-07, Final Batch Loss: 4.488224760734738e-07\n",
      "Epoch 3929, Loss: 0.0006362336571328342, Final Batch Loss: 0.00036474797525443137\n",
      "Epoch 3930, Loss: 6.112880317488134e-07, Final Batch Loss: 2.8725128942141964e-09\n",
      "Epoch 3931, Loss: 0.0006514658778087323, Final Batch Loss: 0.0006489679217338562\n",
      "Epoch 3932, Loss: 0.0001939898561431619, Final Batch Loss: 0.0001925169926835224\n",
      "Epoch 3933, Loss: 9.24568257687497e-06, Final Batch Loss: 6.499344635813031e-06\n",
      "Epoch 3934, Loss: 7.620840705158116e-07, Final Batch Loss: 6.261869884838234e-07\n",
      "Epoch 3935, Loss: 1.2885754131275462e-05, Final Batch Loss: 3.2817711144161876e-06\n",
      "Epoch 3936, Loss: 1.0958478071643185e-06, Final Batch Loss: 3.238735359900602e-07\n",
      "Epoch 3937, Loss: 8.877709205989959e-05, Final Batch Loss: 5.5797909226384945e-06\n",
      "Epoch 3938, Loss: 1.6096144918265054e-05, Final Batch Loss: 9.873579074337613e-07\n",
      "Epoch 3939, Loss: 2.704386935192815e-05, Final Batch Loss: 2.650316855579149e-05\n",
      "Epoch 3940, Loss: 5.778216035423611e-06, Final Batch Loss: 4.0213919305642776e-07\n",
      "Epoch 3941, Loss: 1.1754362759575088e-05, Final Batch Loss: 1.1343816368025728e-05\n",
      "Epoch 3942, Loss: 6.59950806038978e-05, Final Batch Loss: 6.329076131805778e-05\n",
      "Epoch 3943, Loss: 3.8269387232503504e-06, Final Batch Loss: 7.971209470269969e-08\n",
      "Epoch 3944, Loss: 1.3765073333615874e-05, Final Batch Loss: 2.6714150180850993e-07\n",
      "Epoch 3945, Loss: 2.0766058810295362e-06, Final Batch Loss: 1.2774605693266494e-06\n",
      "Epoch 3946, Loss: 4.0694131371310505e-06, Final Batch Loss: 2.470320055181219e-07\n",
      "Epoch 3947, Loss: 0.0006102561688976493, Final Batch Loss: 0.0006094336858950555\n",
      "Epoch 3948, Loss: 2.2070518184591492e-05, Final Batch Loss: 1.7809486507758265e-07\n",
      "Epoch 3949, Loss: 4.803241063200403e-05, Final Batch Loss: 1.874304871307686e-07\n",
      "Epoch 3950, Loss: 1.4049882793187862e-05, Final Batch Loss: 1.1363332305336371e-05\n",
      "Epoch 3951, Loss: 1.5926402801014206e-06, Final Batch Loss: 5.026897120785634e-09\n",
      "Epoch 3952, Loss: 2.3316530928241264e-06, Final Batch Loss: 5.50073025351594e-07\n",
      "Epoch 3953, Loss: 7.773601534921681e-06, Final Batch Loss: 5.5295711121061686e-08\n",
      "Epoch 3954, Loss: 6.749485379486941e-07, Final Batch Loss: 5.967476113255543e-07\n",
      "Epoch 3955, Loss: 2.7403221110944287e-05, Final Batch Loss: 3.030474999832222e-07\n",
      "Epoch 3956, Loss: 1.39980388667027e-05, Final Batch Loss: 1.0021153684647288e-05\n",
      "Epoch 3957, Loss: 8.60553996062663e-06, Final Batch Loss: 7.42508063922287e-07\n",
      "Epoch 3958, Loss: 6.08934395529559e-06, Final Batch Loss: 7.68395551631329e-08\n",
      "Epoch 3959, Loss: 0.00025821073722909205, Final Batch Loss: 1.717971099424176e-05\n",
      "Epoch 3960, Loss: 1.066502261437563e-05, Final Batch Loss: 1.0480965102033224e-05\n",
      "Epoch 3961, Loss: 0.000177809017486652, Final Batch Loss: 0.00017401053628418595\n",
      "Epoch 3962, Loss: 0.00012072357640136033, Final Batch Loss: 6.134439172456041e-05\n",
      "Epoch 3963, Loss: 1.432148579283421e-05, Final Batch Loss: 1.4104052752372809e-05\n",
      "Epoch 3964, Loss: 7.153211072363774e-07, Final Batch Loss: 2.154382627850282e-08\n",
      "Epoch 3965, Loss: 4.978373941888492e-05, Final Batch Loss: 4.975655974703841e-05\n",
      "Epoch 3966, Loss: 5.183924020712993e-06, Final Batch Loss: 5.129564669914544e-06\n",
      "Epoch 3967, Loss: 1.8852655784939998e-05, Final Batch Loss: 2.203547637691372e-06\n",
      "Epoch 3968, Loss: 3.350306627680766e-07, Final Batch Loss: 1.5080686921464803e-08\n",
      "Epoch 3969, Loss: 5.253749748135306e-06, Final Batch Loss: 4.963837909599533e-06\n",
      "Epoch 3970, Loss: 8.773314675636357e-06, Final Batch Loss: 4.777327831106959e-06\n",
      "Epoch 3971, Loss: 2.3002691250439966e-05, Final Batch Loss: 3.2302109502779786e-06\n",
      "Epoch 3972, Loss: 1.8273271109592315e-06, Final Batch Loss: 1.658051360209356e-06\n",
      "Epoch 3973, Loss: 1.3343899851747665e-07, Final Batch Loss: 4.0933262113185265e-08\n",
      "Epoch 3974, Loss: 9.848441118265328e-05, Final Batch Loss: 2.6001246169471415e-06\n",
      "Epoch 3975, Loss: 0.00013066774228498446, Final Batch Loss: 2.4416310751007586e-08\n",
      "Epoch 3976, Loss: 1.9775457360537985e-07, Final Batch Loss: 8.617505642405376e-08\n",
      "Epoch 3977, Loss: 9.199595979225705e-06, Final Batch Loss: 7.535733402619371e-06\n",
      "Epoch 3978, Loss: 2.5081735174126152e-05, Final Batch Loss: 3.633626590726635e-07\n",
      "Epoch 3979, Loss: 1.1535776025084488e-05, Final Batch Loss: 1.106325271393871e-05\n",
      "Epoch 3980, Loss: 3.8644832784484606e-05, Final Batch Loss: 2.9149114197934978e-06\n",
      "Epoch 3981, Loss: 9.181841846839234e-07, Final Batch Loss: 6.721394925079949e-07\n",
      "Epoch 3982, Loss: 4.563350216812978e-06, Final Batch Loss: 1.73188425378612e-06\n",
      "Epoch 3983, Loss: 8.558920328027853e-08, Final Batch Loss: 5.88863642292381e-08\n",
      "Epoch 3984, Loss: 3.27107386510761e-06, Final Batch Loss: 9.93849653241341e-07\n",
      "Epoch 3985, Loss: 1.0435402844954922e-05, Final Batch Loss: 1.042252824845491e-05\n",
      "Epoch 3986, Loss: 6.082309923272078e-06, Final Batch Loss: 9.407447976172989e-08\n",
      "Epoch 3987, Loss: 2.386114900332359e-06, Final Batch Loss: 7.971205207013554e-08\n",
      "Epoch 3988, Loss: 1.0002324955848962e-05, Final Batch Loss: 9.602269528841134e-06\n",
      "Epoch 3989, Loss: 4.6344011650489847e-07, Final Batch Loss: 3.475699088539841e-07\n",
      "Epoch 3990, Loss: 4.248235825343727e-06, Final Batch Loss: 8.631415653326258e-07\n",
      "Epoch 3991, Loss: 1.8029060129265417e-06, Final Batch Loss: 1.9389278804737842e-07\n",
      "Epoch 3992, Loss: 3.476205847618985e-07, Final Batch Loss: 1.2208090538479155e-07\n",
      "Epoch 3993, Loss: 1.3494326651652955e-06, Final Batch Loss: 3.7198324775999936e-07\n",
      "Epoch 3994, Loss: 7.011026212921934e-07, Final Batch Loss: 6.419749070118996e-07\n",
      "Epoch 3995, Loss: 1.0747426244961389e-05, Final Batch Loss: 5.213406666371156e-07\n",
      "Epoch 3996, Loss: 2.55234084534095e-06, Final Batch Loss: 5.565245260186202e-07\n",
      "Epoch 3997, Loss: 3.780973763412021e-06, Final Batch Loss: 9.335609973959436e-08\n",
      "Epoch 3998, Loss: 5.073819409062708e-07, Final Batch Loss: 7.109440502972575e-08\n",
      "Epoch 3999, Loss: 5.073029615232372e-05, Final Batch Loss: 3.058065431105206e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4000, Loss: 1.940902848218684e-06, Final Batch Loss: 1.6257237120953505e-06\n",
      "Epoch 4001, Loss: 2.605762517760013e-06, Final Batch Loss: 2.158496727133752e-06\n",
      "Epoch 4002, Loss: 2.307401132384257e-06, Final Batch Loss: 7.468335070370813e-07\n",
      "Epoch 4003, Loss: 2.794378501924655e-07, Final Batch Loss: 4.308768009053665e-09\n",
      "Epoch 4004, Loss: 7.309572902158834e-05, Final Batch Loss: 3.9561484300065786e-05\n",
      "Epoch 4005, Loss: 4.038822822849397e-06, Final Batch Loss: 1.3069862347947492e-07\n",
      "Epoch 4006, Loss: 4.9838641757560254e-05, Final Batch Loss: 1.1805005897258525e-06\n",
      "Epoch 4007, Loss: 1.6169243366448427e-07, Final Batch Loss: 1.3069809767785046e-07\n",
      "Epoch 4008, Loss: 0.00010016250962507911, Final Batch Loss: 3.8922724343137816e-05\n",
      "Epoch 4009, Loss: 0.0004207703022984788, Final Batch Loss: 0.0003396502579562366\n",
      "Epoch 4010, Loss: 1.9360957594471984e-05, Final Batch Loss: 3.2544267014600337e-06\n",
      "Epoch 4011, Loss: 7.058181665797747e-07, Final Batch Loss: 6.261866474233102e-07\n",
      "Epoch 4012, Loss: 0.0009445660107303411, Final Batch Loss: 0.000498143199365586\n",
      "Epoch 4013, Loss: 1.8973082660522778e-05, Final Batch Loss: 2.19585945160361e-06\n",
      "Epoch 4014, Loss: 2.6420587659004013e-05, Final Batch Loss: 2.5972383809858002e-05\n",
      "Epoch 4015, Loss: 6.640648734901333e-06, Final Batch Loss: 2.5304502742073964e-06\n",
      "Epoch 4016, Loss: 0.0007659890033053784, Final Batch Loss: 9.766507247377376e-08\n",
      "Epoch 4017, Loss: 2.80152755749441e-06, Final Batch Loss: 1.2587479432113469e-06\n",
      "Epoch 4018, Loss: 0.00020283867993953208, Final Batch Loss: 1.0269209838043025e-07\n",
      "Epoch 4019, Loss: 0.0001856957747463639, Final Batch Loss: 5.048273692409566e-07\n",
      "Epoch 4020, Loss: 3.821408313342545e-06, Final Batch Loss: 7.992590553840273e-07\n",
      "Epoch 4021, Loss: 0.00010333468526368961, Final Batch Loss: 1.7293197743128985e-05\n",
      "Epoch 4022, Loss: 4.615846535216406e-06, Final Batch Loss: 4.402702415973181e-06\n",
      "Epoch 4023, Loss: 8.139240833315853e-06, Final Batch Loss: 7.189014468167443e-06\n",
      "Epoch 4024, Loss: 0.0054830873518767476, Final Batch Loss: 0.005479572340846062\n",
      "Epoch 4025, Loss: 3.914860206677417e-06, Final Batch Loss: 3.885296337102773e-06\n",
      "Epoch 4026, Loss: 1.6472699527980694e-05, Final Batch Loss: 1.9676615181651869e-07\n",
      "Epoch 4027, Loss: 0.00013896180030315008, Final Batch Loss: 0.00013640697579830885\n",
      "Epoch 4028, Loss: 8.679701914426907e-06, Final Batch Loss: 1.4362563360847957e-09\n",
      "Epoch 4029, Loss: 0.0002527140204620082, Final Batch Loss: 3.841339275822975e-05\n",
      "Epoch 4030, Loss: 9.657767077442259e-05, Final Batch Loss: 2.1569067030213773e-05\n",
      "Epoch 4031, Loss: 3.0451821658061817e-05, Final Batch Loss: 5.275322109810077e-06\n",
      "Epoch 4032, Loss: 0.0015089104810437348, Final Batch Loss: 1.4362564471070982e-09\n",
      "Epoch 4033, Loss: 7.538997238043521e-06, Final Batch Loss: 5.905155376240145e-06\n",
      "Epoch 4034, Loss: 1.9608021935013653e-06, Final Batch Loss: 6.463152679714312e-09\n",
      "Epoch 4035, Loss: 5.540876870213651e-06, Final Batch Loss: 7.827570414065121e-08\n",
      "Epoch 4036, Loss: 2.4116482864044997e-06, Final Batch Loss: 8.61753779446417e-09\n",
      "Epoch 4037, Loss: 0.0354206092117062, Final Batch Loss: 1.4362564471070982e-09\n",
      "Epoch 4038, Loss: 2.4230312511974716e-06, Final Batch Loss: 3.231574297046791e-08\n",
      "Epoch 4039, Loss: 2.6159947523751725e-06, Final Batch Loss: 2.587861445135786e-06\n",
      "Epoch 4040, Loss: 0.0002341931758564897, Final Batch Loss: 0.00015374085342045873\n",
      "Epoch 4041, Loss: 2.2655188445241947e-05, Final Batch Loss: 2.159287396352738e-05\n",
      "Epoch 4042, Loss: 0.0024114007556903516, Final Batch Loss: 0.002411337336525321\n",
      "Epoch 4043, Loss: 0.000173576934656694, Final Batch Loss: 0.00017351351561956108\n",
      "Epoch 4044, Loss: 0.00046935718446761143, Final Batch Loss: 3.5188261193752624e-08\n",
      "Epoch 4045, Loss: 0.00043275950440602173, Final Batch Loss: 6.139845254438114e-07\n",
      "Epoch 4046, Loss: 0.00018826725442977477, Final Batch Loss: 0.00018738182552624494\n",
      "Epoch 4047, Loss: 0.00017687982345648834, Final Batch Loss: 2.1399920058229327e-07\n",
      "Epoch 4048, Loss: 2.6645344547659988e-05, Final Batch Loss: 2.626626519486308e-05\n",
      "Epoch 4049, Loss: 1.6751490079514042e-06, Final Batch Loss: 1.1001008033417747e-06\n",
      "Epoch 4050, Loss: 6.464051409693639e-07, Final Batch Loss: 3.1309915016208834e-07\n",
      "Epoch 4051, Loss: 0.00016626128604002588, Final Batch Loss: 0.0001653620129218325\n",
      "Epoch 4052, Loss: 0.0007784868330560357, Final Batch Loss: 1.1274552491613576e-07\n",
      "Epoch 4053, Loss: 3.3981716114794835e-05, Final Batch Loss: 1.7333471987512894e-05\n",
      "Epoch 4054, Loss: 1.550039974063111e-05, Final Batch Loss: 1.4511959307128564e-05\n",
      "Epoch 4055, Loss: 5.812321228582107e-05, Final Batch Loss: 1.7953199815679e-08\n",
      "Epoch 4056, Loss: 2.265880084451055e-06, Final Batch Loss: 1.036204935189744e-06\n",
      "Epoch 4057, Loss: 0.00034393623597850365, Final Batch Loss: 3.734264453214564e-08\n",
      "Epoch 4058, Loss: 4.269217834007577e-05, Final Batch Loss: 4.617626927938545e-06\n",
      "Epoch 4059, Loss: 5.6551891702838475e-06, Final Batch Loss: 1.2028015135001624e-06\n",
      "Epoch 4060, Loss: 4.973529783569575e-07, Final Batch Loss: 6.391326934362951e-08\n",
      "Epoch 4061, Loss: 1.8187315617979039e-06, Final Batch Loss: 6.319427257039933e-07\n",
      "Epoch 4062, Loss: 7.970523654421413e-07, Final Batch Loss: 3.0878814527568466e-07\n",
      "Epoch 4063, Loss: 0.0003704553986381143, Final Batch Loss: 5.845380428581848e-07\n",
      "Epoch 4064, Loss: 1.6701004597052815e-06, Final Batch Loss: 1.3916322814111481e-06\n",
      "Epoch 4065, Loss: 1.2784413634392422e-06, Final Batch Loss: 3.016136318478857e-08\n",
      "Epoch 4066, Loss: 1.4074820683163125e-05, Final Batch Loss: 1.2611038982868195e-05\n",
      "Epoch 4067, Loss: 1.8944511225527094e-05, Final Batch Loss: 1.7294834833592176e-05\n",
      "Epoch 4068, Loss: 8.705587162438633e-05, Final Batch Loss: 1.0269206285329346e-07\n",
      "Epoch 4069, Loss: 3.994926487393968e-06, Final Batch Loss: 9.852107041297131e-07\n",
      "Epoch 4070, Loss: 1.031871946111096e-06, Final Batch Loss: 7.25306819049365e-08\n",
      "Epoch 4071, Loss: 0.000452543897125679, Final Batch Loss: 1.4362464639816608e-07\n",
      "Epoch 4072, Loss: 5.714890285446472e-07, Final Batch Loss: 5.38587300979998e-07\n",
      "Epoch 4073, Loss: 2.1886080858735113e-07, Final Batch Loss: 1.7737609425694245e-07\n",
      "Epoch 4074, Loss: 1.7356570083393308e-06, Final Batch Loss: 6.671274945801997e-07\n",
      "Epoch 4075, Loss: 5.504407909029396e-06, Final Batch Loss: 2.7462333491712343e-06\n",
      "Epoch 4076, Loss: 3.314575255330965e-05, Final Batch Loss: 8.330275136358978e-08\n",
      "Epoch 4077, Loss: 2.1343520870686916e-06, Final Batch Loss: 7.468183298442455e-07\n",
      "Epoch 4078, Loss: 0.00023351771240953667, Final Batch Loss: 4.5241982604693476e-08\n",
      "Epoch 4079, Loss: 0.0008792062471485451, Final Batch Loss: 5.601391706022696e-08\n",
      "Epoch 4080, Loss: 3.083701527017979e-05, Final Batch Loss: 4.7396365943086494e-08\n",
      "Epoch 4081, Loss: 5.70738734495535e-06, Final Batch Loss: 2.7140026759298053e-06\n",
      "Epoch 4082, Loss: 0.0006443009224312846, Final Batch Loss: 0.0006407072069123387\n",
      "Epoch 4083, Loss: 1.0804617676107853e-06, Final Batch Loss: 1.0785544191094232e-06\n",
      "Epoch 4084, Loss: 3.4290631845124153e-07, Final Batch Loss: 1.9461157307887333e-07\n",
      "Epoch 4085, Loss: 1.937348656610993e-06, Final Batch Loss: 4.868865062235272e-07\n",
      "Epoch 4086, Loss: 0.008395269513130188, Final Batch Loss: 0.006090647540986538\n",
      "Epoch 4087, Loss: 5.441514906578959e-05, Final Batch Loss: 4.840086376134423e-07\n",
      "Epoch 4088, Loss: 5.9660904298652895e-05, Final Batch Loss: 5.528379188035615e-05\n",
      "Epoch 4089, Loss: 7.507848840759834e-05, Final Batch Loss: 1.6903713913052343e-06\n",
      "Epoch 4090, Loss: 2.0074337442110846e-05, Final Batch Loss: 6.527693017233105e-07\n",
      "Epoch 4091, Loss: 4.156022725965158e-05, Final Batch Loss: 4.0577553590992466e-05\n",
      "Epoch 4092, Loss: 1.3255042574655818e-06, Final Batch Loss: 1.1195118077012012e-06\n",
      "Epoch 4093, Loss: 3.71912960872578e-05, Final Batch Loss: 3.38089739670977e-05\n",
      "Epoch 4094, Loss: 3.136082307264587e-05, Final Batch Loss: 4.0214001728600124e-07\n",
      "Epoch 4095, Loss: 1.2426933324150014e-05, Final Batch Loss: 1.2022588634863496e-05\n",
      "Epoch 4096, Loss: 1.4934732206484114e-07, Final Batch Loss: 8.402079032521215e-08\n",
      "Epoch 4097, Loss: 0.0003914203953172546, Final Batch Loss: 5.711755875381641e-05\n",
      "Epoch 4098, Loss: 3.504898415940261e-07, Final Batch Loss: 6.391320539478329e-08\n",
      "Epoch 4099, Loss: 9.296154985349858e-05, Final Batch Loss: 8.390501898247749e-05\n",
      "Epoch 4100, Loss: 4.6064895741437795e-05, Final Batch Loss: 4.1491362935630605e-05\n",
      "Epoch 4101, Loss: 0.0001236606930774542, Final Batch Loss: 0.0001232692156918347\n",
      "Epoch 4102, Loss: 3.7725607739957923e-06, Final Batch Loss: 8.73924761890521e-07\n",
      "Epoch 4103, Loss: 1.7093341284635244e-05, Final Batch Loss: 1.1412498679419514e-05\n",
      "Epoch 4104, Loss: 2.560943278240302e-05, Final Batch Loss: 3.5115874652547063e-07\n",
      "Epoch 4105, Loss: 0.0007667319964639319, Final Batch Loss: 1.7786164789868053e-06\n",
      "Epoch 4106, Loss: 0.00010057682793362943, Final Batch Loss: 1.4362556477465205e-08\n",
      "Epoch 4107, Loss: 1.7753657175489934e-06, Final Batch Loss: 3.454174475336913e-07\n",
      "Epoch 4108, Loss: 4.4246806680803275e-06, Final Batch Loss: 1.9963803765676857e-07\n",
      "Epoch 4109, Loss: 7.410544412778108e-06, Final Batch Loss: 3.0606195196014596e-06\n",
      "Epoch 4110, Loss: 0.0015833703391763265, Final Batch Loss: 7.94344214227749e-06\n",
      "Epoch 4111, Loss: 6.066457672204706e-06, Final Batch Loss: 1.388032842442044e-06\n",
      "Epoch 4112, Loss: 0.0001369988412989187, Final Batch Loss: 0.0001357352884951979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4113, Loss: 3.403827918191382e-06, Final Batch Loss: 5.902835482629598e-07\n",
      "Epoch 4114, Loss: 0.0001730261299144331, Final Batch Loss: 2.5978094981837785e-06\n",
      "Epoch 4115, Loss: 5.470320775202708e-05, Final Batch Loss: 2.652458533702884e-06\n",
      "Epoch 4116, Loss: 5.137641892360989e-06, Final Batch Loss: 3.122721182080568e-06\n",
      "Epoch 4117, Loss: 4.376308510245508e-06, Final Batch Loss: 3.63367774980361e-07\n",
      "Epoch 4118, Loss: 0.0002023528577410616, Final Batch Loss: 0.00020037172362208366\n",
      "Epoch 4119, Loss: 1.5675982467655558e-05, Final Batch Loss: 8.9686063802219e-06\n",
      "Epoch 4120, Loss: 3.6764887227036525e-05, Final Batch Loss: 5.752126526203938e-07\n",
      "Epoch 4121, Loss: 9.501849035586929e-06, Final Batch Loss: 3.697850388562074e-06\n",
      "Epoch 4122, Loss: 9.284623423866378e-06, Final Batch Loss: 4.81144653008414e-08\n",
      "Epoch 4123, Loss: 0.029310034778973204, Final Batch Loss: 0.029285535216331482\n",
      "Epoch 4124, Loss: 6.809596868606604e-07, Final Batch Loss: 4.287152535198402e-07\n",
      "Epoch 4125, Loss: 0.0002104793456965126, Final Batch Loss: 0.0001417702151229605\n",
      "Epoch 4126, Loss: 3.931133193191272e-06, Final Batch Loss: 2.9873686457904114e-07\n",
      "Epoch 4127, Loss: 0.0004376696172752048, Final Batch Loss: 1.8671306278861266e-08\n",
      "Epoch 4128, Loss: 1.17456015686912e-05, Final Batch Loss: 3.1618233151675668e-06\n",
      "Epoch 4129, Loss: 0.0027083328495791648, Final Batch Loss: 0.0026801936328411102\n",
      "Epoch 4130, Loss: 0.0001719004044389294, Final Batch Loss: 0.00016929570119827986\n",
      "Epoch 4131, Loss: 4.156186705017717e-06, Final Batch Loss: 1.5296028266220674e-07\n",
      "Epoch 4132, Loss: 0.004332934444391867, Final Batch Loss: 2.440384923829697e-05\n",
      "Epoch 4133, Loss: 0.0003918821576007758, Final Batch Loss: 2.2903959688846953e-06\n",
      "Epoch 4134, Loss: 0.011818063911050558, Final Batch Loss: 0.0040587387047708035\n",
      "Epoch 4135, Loss: 8.449143177102769e-05, Final Batch Loss: 5.9604353452868963e-08\n",
      "Epoch 4136, Loss: 2.5668396403943916e-06, Final Batch Loss: 2.4247426608781097e-06\n",
      "Epoch 4137, Loss: 0.0007155942103054258, Final Batch Loss: 0.0007100127986632288\n",
      "Epoch 4138, Loss: 2.2419731408263033e-05, Final Batch Loss: 7.532920562880463e-07\n",
      "Epoch 4139, Loss: 0.0003045161756745074, Final Batch Loss: 3.619297422119416e-05\n",
      "Epoch 4140, Loss: 8.559059745039121e-05, Final Batch Loss: 4.947806928612408e-07\n",
      "Epoch 4141, Loss: 5.088549028187117e-05, Final Batch Loss: 4.853376231039874e-05\n",
      "Epoch 4142, Loss: 0.00011782104411395267, Final Batch Loss: 0.00010767800267785788\n",
      "Epoch 4143, Loss: 9.15069517759548e-06, Final Batch Loss: 5.879048785573104e-06\n",
      "Epoch 4144, Loss: 5.687121415576257e-06, Final Batch Loss: 7.956670060593751e-07\n",
      "Epoch 4145, Loss: 1.144763950833294e-05, Final Batch Loss: 8.622438144811895e-06\n",
      "Epoch 4146, Loss: 3.823117594947689e-05, Final Batch Loss: 2.889972620323533e-06\n",
      "Epoch 4147, Loss: 0.0002745393089753634, Final Batch Loss: 2.812618276948342e-06\n",
      "Epoch 4148, Loss: 0.0006784303113818169, Final Batch Loss: 0.00013280310668051243\n",
      "Epoch 4149, Loss: 2.654054219419777e-05, Final Batch Loss: 2.4954664695542306e-05\n",
      "Epoch 4150, Loss: 4.659184014599305e-06, Final Batch Loss: 1.996867013076553e-06\n",
      "Epoch 4151, Loss: 1.0376962791269762e-05, Final Batch Loss: 1.3456885881169e-06\n",
      "Epoch 4152, Loss: 1.5168112440733239e-05, Final Batch Loss: 7.52455980546074e-06\n",
      "Epoch 4153, Loss: 0.0044036152539774776, Final Batch Loss: 0.0009368878090754151\n",
      "Epoch 4154, Loss: 0.001677155642028083, Final Batch Loss: 0.0016602211399003863\n",
      "Epoch 4155, Loss: 0.00021627835258186678, Final Batch Loss: 0.0002121637371601537\n",
      "Epoch 4156, Loss: 1.577157502197224e-05, Final Batch Loss: 1.445759062335128e-05\n",
      "Epoch 4157, Loss: 2.211694990705837e-06, Final Batch Loss: 2.0300208234402817e-06\n",
      "Epoch 4158, Loss: 0.00022957142471113912, Final Batch Loss: 0.00022766760957892984\n",
      "Epoch 4159, Loss: 2.429407970794273e-06, Final Batch Loss: 6.692776537420286e-07\n",
      "Epoch 4160, Loss: 3.747048140212428e-06, Final Batch Loss: 1.7456354726164136e-06\n",
      "Epoch 4161, Loss: 2.503792438801611e-05, Final Batch Loss: 1.7408921848982573e-05\n",
      "Epoch 4162, Loss: 0.0026749729813673184, Final Batch Loss: 0.0026704708579927683\n",
      "Epoch 4163, Loss: 0.0002657102395513533, Final Batch Loss: 2.800698517546607e-08\n",
      "Epoch 4164, Loss: 0.0002088024525619403, Final Batch Loss: 0.00020290289830882102\n",
      "Epoch 4165, Loss: 8.22602754340096e-05, Final Batch Loss: 2.3769948143126385e-07\n",
      "Epoch 4166, Loss: 8.948944696385297e-06, Final Batch Loss: 7.68487916502636e-06\n",
      "Epoch 4167, Loss: 7.935696885397192e-06, Final Batch Loss: 2.3687948669248726e-06\n",
      "Epoch 4168, Loss: 1.720945465422119e-05, Final Batch Loss: 5.317464001564076e-06\n",
      "Epoch 4169, Loss: 1.2601418802660191e-05, Final Batch Loss: 1.0596054380584974e-05\n",
      "Epoch 4170, Loss: 4.867878047321028e-07, Final Batch Loss: 1.0628281899016656e-07\n",
      "Epoch 4171, Loss: 6.887445670145098e-05, Final Batch Loss: 3.896312045981176e-05\n",
      "Epoch 4172, Loss: 0.0004178580111329211, Final Batch Loss: 9.888299246085808e-07\n",
      "Epoch 4173, Loss: 0.00024687651489330165, Final Batch Loss: 0.0002447316946927458\n",
      "Epoch 4174, Loss: 4.2921484464386594e-06, Final Batch Loss: 2.4693363229744136e-06\n",
      "Epoch 4175, Loss: 0.00021272863159538247, Final Batch Loss: 3.356002343934961e-05\n",
      "Epoch 4176, Loss: 2.5098373853893463e-05, Final Batch Loss: 2.49248059844831e-05\n",
      "Epoch 4177, Loss: 0.0006723334613525367, Final Batch Loss: 2.322247837582836e-06\n",
      "Epoch 4178, Loss: 0.0006975986943871249, Final Batch Loss: 5.620840966003016e-06\n",
      "Epoch 4179, Loss: 1.2267045121916453e-05, Final Batch Loss: 1.0410395589133259e-05\n",
      "Epoch 4180, Loss: 1.2554543900478166e-05, Final Batch Loss: 8.888218872016296e-06\n",
      "Epoch 4181, Loss: 0.00010487539316272887, Final Batch Loss: 3.4084898743458325e-06\n",
      "Epoch 4182, Loss: 3.265204156832624e-06, Final Batch Loss: 5.213550480220874e-07\n",
      "Epoch 4183, Loss: 3.2011606663218117e-06, Final Batch Loss: 5.895734602745506e-07\n",
      "Epoch 4184, Loss: 0.0002711296092456905, Final Batch Loss: 1.1095178706455044e-05\n",
      "Epoch 4185, Loss: 6.271831443882547e-05, Final Batch Loss: 3.368157194927335e-05\n",
      "Epoch 4186, Loss: 4.970947429683292e-05, Final Batch Loss: 1.2605299161805306e-05\n",
      "Epoch 4187, Loss: 0.00040870183147490025, Final Batch Loss: 0.0003850027278531343\n",
      "Epoch 4188, Loss: 2.1478859579815435e-06, Final Batch Loss: 6.104081506919101e-08\n",
      "Epoch 4189, Loss: 4.756648422699072e-06, Final Batch Loss: 6.685665994154988e-07\n",
      "Epoch 4190, Loss: 9.690044498711359e-05, Final Batch Loss: 7.56228546379134e-05\n",
      "Epoch 4191, Loss: 0.0012316213615122251, Final Batch Loss: 9.634915477363393e-05\n",
      "Epoch 4192, Loss: 6.702171049255412e-06, Final Batch Loss: 3.0206601877580397e-06\n",
      "Epoch 4193, Loss: 4.391108996060211e-05, Final Batch Loss: 2.693673195608426e-05\n",
      "Epoch 4194, Loss: 3.522972917835432e-06, Final Batch Loss: 2.960320898637292e-06\n",
      "Epoch 4195, Loss: 0.0003071392634410586, Final Batch Loss: 5.250614321994362e-06\n",
      "Epoch 4196, Loss: 3.6672867281595245e-05, Final Batch Loss: 3.3620017347857356e-05\n",
      "Epoch 4197, Loss: 1.853244611993432e-05, Final Batch Loss: 1.436019465472782e-05\n",
      "Epoch 4198, Loss: 0.00012876335858891252, Final Batch Loss: 9.922137905959971e-06\n",
      "Epoch 4199, Loss: 4.036860127598629e-05, Final Batch Loss: 3.489679511403665e-05\n",
      "Epoch 4200, Loss: 0.00011242603972050347, Final Batch Loss: 0.00011168600030941889\n",
      "Epoch 4201, Loss: 8.487202342166711e-05, Final Batch Loss: 1.0455411256771185e-06\n",
      "Epoch 4202, Loss: 5.487655175784312e-05, Final Batch Loss: 1.4361783087224467e-06\n",
      "Epoch 4203, Loss: 2.8274126123051246e-05, Final Batch Loss: 9.019517506203556e-07\n",
      "Epoch 4204, Loss: 3.087933373535634e-05, Final Batch Loss: 2.7359552404959686e-05\n",
      "Epoch 4205, Loss: 1.5349516360174675e-06, Final Batch Loss: 1.3995303334013443e-06\n",
      "Epoch 4206, Loss: 1.194625042444386e-05, Final Batch Loss: 8.98209327715449e-06\n",
      "Epoch 4207, Loss: 5.3141053513172665e-06, Final Batch Loss: 1.644324015614984e-06\n",
      "Epoch 4208, Loss: 0.0002845042845365242, Final Batch Loss: 0.0002725500671658665\n",
      "Epoch 4209, Loss: 0.0002476173430068229, Final Batch Loss: 1.6299926528517972e-06\n",
      "Epoch 4210, Loss: 6.378162424880429e-06, Final Batch Loss: 2.0112627225898905e-06\n",
      "Epoch 4211, Loss: 0.0013950062296430588, Final Batch Loss: 0.0013943229569122195\n",
      "Epoch 4212, Loss: 5.822446837555617e-06, Final Batch Loss: 5.053325367043726e-06\n",
      "Epoch 4213, Loss: 8.408300118389889e-06, Final Batch Loss: 6.987108918110607e-07\n",
      "Epoch 4214, Loss: 4.406497396303166e-06, Final Batch Loss: 1.6767227180025657e-06\n",
      "Epoch 4215, Loss: 1.1852504428588873e-05, Final Batch Loss: 1.1473898666736204e-05\n",
      "Epoch 4216, Loss: 4.488370177568868e-05, Final Batch Loss: 9.469666110817343e-06\n",
      "Epoch 4217, Loss: 7.534774510986608e-06, Final Batch Loss: 6.912036951689515e-06\n",
      "Epoch 4218, Loss: 0.00012100224461164544, Final Batch Loss: 0.0001205230291816406\n",
      "Epoch 4219, Loss: 0.00014063560979593603, Final Batch Loss: 2.373817778789089e-06\n",
      "Epoch 4220, Loss: 0.00011234747216803953, Final Batch Loss: 2.8354741516523063e-05\n",
      "Epoch 4221, Loss: 1.821071913354899e-05, Final Batch Loss: 1.757845893735066e-05\n",
      "Epoch 4222, Loss: 1.2496761883085128e-05, Final Batch Loss: 8.871111276675947e-06\n",
      "Epoch 4223, Loss: 3.554443583198008e-05, Final Batch Loss: 2.106870397255989e-06\n",
      "Epoch 4224, Loss: 0.0023429144821420778, Final Batch Loss: 4.1671581129776314e-05\n",
      "Epoch 4225, Loss: 4.159441459705704e-06, Final Batch Loss: 2.5641240881668637e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4226, Loss: 8.581027657328377e-07, Final Batch Loss: 1.910211437916587e-07\n",
      "Epoch 4227, Loss: 0.00014412568634725176, Final Batch Loss: 0.00014065792493056506\n",
      "Epoch 4228, Loss: 2.427573417662643e-05, Final Batch Loss: 4.098397766938433e-06\n",
      "Epoch 4229, Loss: 5.626316749385296e-06, Final Batch Loss: 5.077486548543675e-06\n",
      "Epoch 4230, Loss: 3.89809233070082e-06, Final Batch Loss: 4.301535625472752e-07\n",
      "Epoch 4231, Loss: 1.24924640658719e-05, Final Batch Loss: 6.909513103892095e-06\n",
      "Epoch 4232, Loss: 3.288977609372523e-06, Final Batch Loss: 9.608332902644179e-07\n",
      "Epoch 4233, Loss: 5.797837047794019e-06, Final Batch Loss: 3.737218321475666e-06\n",
      "Epoch 4234, Loss: 6.819948248448782e-05, Final Batch Loss: 1.2441440048860386e-05\n",
      "Epoch 4235, Loss: 2.211915784755547e-06, Final Batch Loss: 1.3650853816216113e-06\n",
      "Epoch 4236, Loss: 5.118189847053145e-06, Final Batch Loss: 2.343860160181066e-06\n",
      "Epoch 4237, Loss: 5.281040557747474e-06, Final Batch Loss: 2.312964852535515e-06\n",
      "Epoch 4238, Loss: 4.120826440612291e-05, Final Batch Loss: 3.998425745521672e-05\n",
      "Epoch 4239, Loss: 0.0006046657172760206, Final Batch Loss: 5.601278303402069e-07\n",
      "Epoch 4240, Loss: 2.8933670250808063e-06, Final Batch Loss: 2.4098710582620697e-06\n",
      "Epoch 4241, Loss: 2.6499374484956206e-05, Final Batch Loss: 1.1001342272720649e-06\n",
      "Epoch 4242, Loss: 8.245573553722352e-06, Final Batch Loss: 7.170856406446546e-06\n",
      "Epoch 4243, Loss: 1.133622225779618e-05, Final Batch Loss: 2.0322858063082094e-07\n",
      "Epoch 4244, Loss: 5.118389481140184e-06, Final Batch Loss: 9.87377234196174e-07\n",
      "Epoch 4245, Loss: 5.360431623557815e-05, Final Batch Loss: 5.553972187044565e-06\n",
      "Epoch 4246, Loss: 0.0002862210112652974, Final Batch Loss: 0.00026761810295283794\n",
      "Epoch 4247, Loss: 3.029789968422847e-05, Final Batch Loss: 2.2797443307354115e-05\n",
      "Epoch 4248, Loss: 6.259487327042734e-05, Final Batch Loss: 5.162731213204097e-06\n",
      "Epoch 4249, Loss: 4.5088423576089554e-05, Final Batch Loss: 3.415465835132636e-05\n",
      "Epoch 4250, Loss: 0.00019813280312064308, Final Batch Loss: 9.71566691987391e-07\n",
      "Epoch 4251, Loss: 1.169477044982159e-06, Final Batch Loss: 1.4147063609470933e-07\n",
      "Epoch 4252, Loss: 3.6694729342645616e-05, Final Batch Loss: 7.181282235535491e-10\n",
      "Epoch 4253, Loss: 6.329106554403552e-05, Final Batch Loss: 4.502302999753738e-06\n",
      "Epoch 4254, Loss: 7.7450559274439e-05, Final Batch Loss: 7.32558619347401e-05\n",
      "Epoch 4255, Loss: 1.8816716362834995e-06, Final Batch Loss: 1.8296964299224783e-06\n",
      "Epoch 4256, Loss: 7.75597578694942e-06, Final Batch Loss: 8.157740580827522e-07\n",
      "Epoch 4257, Loss: 8.049183543334948e-05, Final Batch Loss: 1.2621935638890136e-05\n",
      "Epoch 4258, Loss: 3.714932063303422e-05, Final Batch Loss: 7.697948603890836e-06\n",
      "Epoch 4259, Loss: 1.022880769596668e-05, Final Batch Loss: 5.039718416810501e-06\n",
      "Epoch 4260, Loss: 1.3962988134608167e-06, Final Batch Loss: 9.909932714435854e-07\n",
      "Epoch 4261, Loss: 1.0126044799108058e-05, Final Batch Loss: 9.14858901523985e-06\n",
      "Epoch 4262, Loss: 3.885294193395339e-05, Final Batch Loss: 6.391331197619365e-08\n",
      "Epoch 4263, Loss: 1.4799666530507238e-05, Final Batch Loss: 7.252924092426838e-07\n",
      "Epoch 4264, Loss: 0.0004645426834031241, Final Batch Loss: 0.0004453136643860489\n",
      "Epoch 4265, Loss: 5.573564976657508e-06, Final Batch Loss: 1.932897021106328e-06\n",
      "Epoch 4266, Loss: 0.003384310781257227, Final Batch Loss: 5.447215517051518e-05\n",
      "Epoch 4267, Loss: 4.2404244595672935e-06, Final Batch Loss: 8.595395684096729e-07\n",
      "Epoch 4268, Loss: 2.7691225170656253e-06, Final Batch Loss: 3.02326185419588e-07\n",
      "Epoch 4269, Loss: 0.0026144776129513048, Final Batch Loss: 7.013414142420515e-05\n",
      "Epoch 4270, Loss: 1.9140157405672653e-05, Final Batch Loss: 1.763960790412966e-05\n",
      "Epoch 4271, Loss: 2.561167656267571e-05, Final Batch Loss: 6.283373181759089e-07\n",
      "Epoch 4272, Loss: 3.040074545879179e-05, Final Batch Loss: 2.869908894354012e-05\n",
      "Epoch 4273, Loss: 4.2066140622409876e-05, Final Batch Loss: 4.053463999298401e-05\n",
      "Epoch 4274, Loss: 3.557144668775436e-05, Final Batch Loss: 3.327571539557539e-05\n",
      "Epoch 4275, Loss: 2.0468379261728842e-05, Final Batch Loss: 3.490619747026358e-06\n",
      "Epoch 4276, Loss: 6.228710185496311e-05, Final Batch Loss: 1.8634425487107364e-06\n",
      "Epoch 4277, Loss: 5.090916783956345e-05, Final Batch Loss: 2.1352247131289914e-05\n",
      "Epoch 4278, Loss: 1.0003851684814435e-05, Final Batch Loss: 2.44640636992699e-06\n",
      "Epoch 4279, Loss: 6.661427687504329e-05, Final Batch Loss: 5.493848220794462e-05\n",
      "Epoch 4280, Loss: 0.00011597191132750595, Final Batch Loss: 0.00010727746848715469\n",
      "Epoch 4281, Loss: 1.1247060683672316e-05, Final Batch Loss: 4.730131877295207e-06\n",
      "Epoch 4282, Loss: 9.016778130899183e-05, Final Batch Loss: 4.80094640806783e-05\n",
      "Epoch 4283, Loss: 4.3779458792414516e-05, Final Batch Loss: 1.2083182809874415e-05\n",
      "Epoch 4284, Loss: 9.61745922722912e-06, Final Batch Loss: 7.123913746909238e-06\n",
      "Epoch 4285, Loss: 3.166370299823029e-05, Final Batch Loss: 1.3277800690048025e-06\n",
      "Epoch 4286, Loss: 0.0035910326423618244, Final Batch Loss: 0.003580103861168027\n",
      "Epoch 4287, Loss: 0.00043764903966803104, Final Batch Loss: 0.00022073958825785667\n",
      "Epoch 4288, Loss: 3.2546657166676596e-05, Final Batch Loss: 1.5704099496360868e-06\n",
      "Epoch 4289, Loss: 1.4583249139832333e-05, Final Batch Loss: 2.0049565137014724e-06\n",
      "Epoch 4290, Loss: 5.597363497145125e-06, Final Batch Loss: 2.3695561139902566e-06\n",
      "Epoch 4291, Loss: 8.18967237137258e-05, Final Batch Loss: 3.536081567290239e-05\n",
      "Epoch 4292, Loss: 1.465810873924056e-05, Final Batch Loss: 9.190386663249228e-06\n",
      "Epoch 4293, Loss: 0.00017801298054109793, Final Batch Loss: 0.0001620505645405501\n",
      "Epoch 4294, Loss: 6.547504881382338e-05, Final Batch Loss: 6.047375427442603e-05\n",
      "Epoch 4295, Loss: 7.718823326285928e-05, Final Batch Loss: 4.442016143002547e-05\n",
      "Epoch 4296, Loss: 3.6244841112420545e-05, Final Batch Loss: 2.995071781697334e-06\n",
      "Epoch 4297, Loss: 7.450739758496638e-05, Final Batch Loss: 1.7587111869943328e-05\n",
      "Epoch 4298, Loss: 0.00027235445031692507, Final Batch Loss: 3.8530461097252555e-06\n",
      "Epoch 4299, Loss: 9.237912854587194e-05, Final Batch Loss: 8.008324221009389e-05\n",
      "Epoch 4300, Loss: 8.093520591501147e-05, Final Batch Loss: 5.453902849694714e-05\n",
      "Epoch 4301, Loss: 1.8274086869496386e-05, Final Batch Loss: 1.5037758203106932e-05\n",
      "Epoch 4302, Loss: 0.0007136866333894432, Final Batch Loss: 0.00026401819195598364\n",
      "Epoch 4303, Loss: 6.135689331188132e-05, Final Batch Loss: 1.4721594254751835e-07\n",
      "Epoch 4304, Loss: 0.00024300083896378055, Final Batch Loss: 0.00014219421427696943\n",
      "Epoch 4305, Loss: 1.4605895898966992e-05, Final Batch Loss: 1.3061496247246396e-05\n",
      "Epoch 4306, Loss: 0.00010488178759260336, Final Batch Loss: 1.3219506399764214e-05\n",
      "Epoch 4307, Loss: 5.816532075186842e-05, Final Batch Loss: 4.851854555454338e-06\n",
      "Epoch 4308, Loss: 6.79934537402005e-05, Final Batch Loss: 1.1092030945292208e-05\n",
      "Epoch 4309, Loss: 0.004243818839313462, Final Batch Loss: 0.00041368117672391236\n",
      "Epoch 4310, Loss: 8.42717895466194e-06, Final Batch Loss: 5.475433226820314e-06\n",
      "Epoch 4311, Loss: 0.00038392432487910355, Final Batch Loss: 2.1328322930003196e-07\n",
      "Epoch 4312, Loss: 0.00013517897332349094, Final Batch Loss: 4.9405980462324806e-06\n",
      "Epoch 4313, Loss: 2.113312575602322e-05, Final Batch Loss: 4.832234026252991e-06\n",
      "Epoch 4314, Loss: 1.0408554544483195e-05, Final Batch Loss: 2.7659677925839787e-06\n",
      "Epoch 4315, Loss: 6.776567357746899e-05, Final Batch Loss: 6.697796197840944e-05\n",
      "Epoch 4316, Loss: 0.00017037045381584903, Final Batch Loss: 1.0890150406339671e-05\n",
      "Epoch 4317, Loss: 2.2618682123720646e-05, Final Batch Loss: 3.2707739592297003e-06\n",
      "Epoch 4318, Loss: 0.00026286504453310044, Final Batch Loss: 0.0002489804173819721\n",
      "Epoch 4319, Loss: 6.979544968999107e-05, Final Batch Loss: 5.254351435723947e-06\n",
      "Epoch 4320, Loss: 2.633579606481362e-05, Final Batch Loss: 7.932771040941589e-06\n",
      "Epoch 4321, Loss: 1.7060208847397007e-05, Final Batch Loss: 1.2960807907802518e-05\n",
      "Epoch 4322, Loss: 0.00011699912647600286, Final Batch Loss: 0.00010328146163374186\n",
      "Epoch 4323, Loss: 1.7379611676915374e-05, Final Batch Loss: 1.586239341122564e-05\n",
      "Epoch 4324, Loss: 0.00012015760148642585, Final Batch Loss: 4.257416003383696e-05\n",
      "Epoch 4325, Loss: 0.0012620737061297405, Final Batch Loss: 1.913004780362826e-06\n",
      "Epoch 4326, Loss: 1.9089784188963677e-06, Final Batch Loss: 1.8455827444086026e-07\n",
      "Epoch 4327, Loss: 2.191406611018465e-05, Final Batch Loss: 1.6440331819467247e-05\n",
      "Epoch 4328, Loss: 0.0001697564885034808, Final Batch Loss: 1.0395772733318154e-05\n",
      "Epoch 4329, Loss: 1.0372936003477662e-05, Final Batch Loss: 7.090955477906391e-06\n",
      "Epoch 4330, Loss: 1.4233984529710142e-05, Final Batch Loss: 6.769816081941826e-06\n",
      "Epoch 4331, Loss: 9.867301560007036e-05, Final Batch Loss: 3.531794936861843e-05\n",
      "Epoch 4332, Loss: 7.803232961123285e-06, Final Batch Loss: 3.4182392028014874e-07\n",
      "Epoch 4333, Loss: 4.059489151586604e-05, Final Batch Loss: 3.4388133371976437e-06\n",
      "Epoch 4334, Loss: 1.3056143870926462e-05, Final Batch Loss: 1.6595486158621497e-06\n",
      "Epoch 4335, Loss: 5.216767431193148e-05, Final Batch Loss: 2.0466586647671647e-07\n",
      "Epoch 4336, Loss: 4.5479655454983e-06, Final Batch Loss: 2.532524604248465e-06\n",
      "Epoch 4337, Loss: 0.0007731786190561252, Final Batch Loss: 3.02153239317704e-06\n",
      "Epoch 4338, Loss: 1.793326828192221e-05, Final Batch Loss: 3.7469171729753725e-06\n",
      "Epoch 4339, Loss: 1.7727463159644685e-06, Final Batch Loss: 1.1934116628253832e-06\n",
      "Epoch 4340, Loss: 0.002070026375690759, Final Batch Loss: 4.3087300127808703e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4341, Loss: 3.3938884200779285e-06, Final Batch Loss: 2.4918838903431606e-07\n",
      "Epoch 4342, Loss: 0.00024528627182007767, Final Batch Loss: 0.00023655961558688432\n",
      "Epoch 4343, Loss: 3.83590931960498e-05, Final Batch Loss: 7.84144958743127e-06\n",
      "Epoch 4344, Loss: 3.3006676858349238e-06, Final Batch Loss: 1.813139533624053e-06\n",
      "Epoch 4345, Loss: 6.537239300996589e-07, Final Batch Loss: 2.3554167682959815e-07\n",
      "Epoch 4346, Loss: 6.236082072064164e-06, Final Batch Loss: 2.621651901790756e-06\n",
      "Epoch 4347, Loss: 1.6843160665303003e-05, Final Batch Loss: 8.664918823342305e-06\n",
      "Epoch 4348, Loss: 1.2395736348480568e-05, Final Batch Loss: 1.1855016964545939e-05\n",
      "Epoch 4349, Loss: 1.606861542313709e-05, Final Batch Loss: 1.6731760297261644e-06\n",
      "Epoch 4350, Loss: 3.7824491982973996e-06, Final Batch Loss: 1.3284767419463606e-06\n",
      "Epoch 4351, Loss: 0.00039891606540010116, Final Batch Loss: 0.0003988221287727356\n",
      "Epoch 4352, Loss: 7.276474320860871e-06, Final Batch Loss: 9.809328957999242e-07\n",
      "Epoch 4353, Loss: 0.0007142026768178766, Final Batch Loss: 3.333585254949867e-06\n",
      "Epoch 4354, Loss: 6.080974640099157e-05, Final Batch Loss: 5.7891986216418445e-05\n",
      "Epoch 4355, Loss: 2.047031046004122e-06, Final Batch Loss: 5.680224717252713e-07\n",
      "Epoch 4356, Loss: 1.6116996874870892e-06, Final Batch Loss: 1.493697681098638e-07\n",
      "Epoch 4357, Loss: 3.4319737238774906e-06, Final Batch Loss: 1.7881167480027216e-07\n",
      "Epoch 4358, Loss: 7.147753876779461e-05, Final Batch Loss: 1.4681642824143637e-05\n",
      "Epoch 4359, Loss: 0.00036557285659455374, Final Batch Loss: 8.071280035437667e-07\n",
      "Epoch 4360, Loss: 0.00023099791837921657, Final Batch Loss: 3.034279188796063e-06\n",
      "Epoch 4361, Loss: 4.85848340758821e-06, Final Batch Loss: 4.242924205755116e-06\n",
      "Epoch 4362, Loss: 1.4224146980268415e-06, Final Batch Loss: 6.699951882183086e-07\n",
      "Epoch 4363, Loss: 8.976890462975007e-05, Final Batch Loss: 8.958151011029258e-05\n",
      "Epoch 4364, Loss: 0.00017933564959093928, Final Batch Loss: 1.2516975402832031e-05\n",
      "Epoch 4365, Loss: 9.864793071301392e-07, Final Batch Loss: 5.773609359494003e-07\n",
      "Epoch 4366, Loss: 4.921751326492085e-06, Final Batch Loss: 4.332400749262888e-06\n",
      "Epoch 4367, Loss: 8.440284773314488e-07, Final Batch Loss: 6.714143410135875e-07\n",
      "Epoch 4368, Loss: 4.971586633928382e-06, Final Batch Loss: 4.561992682283744e-06\n",
      "Epoch 4369, Loss: 8.218252514780033e-05, Final Batch Loss: 1.7091406334657222e-07\n",
      "Epoch 4370, Loss: 2.6067233420690172e-06, Final Batch Loss: 1.4475937177849119e-06\n",
      "Epoch 4371, Loss: 0.00027981250627817644, Final Batch Loss: 3.18781553687586e-06\n",
      "Epoch 4372, Loss: 7.3464668730593985e-06, Final Batch Loss: 5.2286250138422474e-06\n",
      "Epoch 4373, Loss: 0.00021690499124815688, Final Batch Loss: 8.059108949964866e-05\n",
      "Epoch 4374, Loss: 0.002019722669501789, Final Batch Loss: 5.545998283196241e-05\n",
      "Epoch 4375, Loss: 1.3741222915086837e-06, Final Batch Loss: 7.5329586479711e-07\n",
      "Epoch 4376, Loss: 0.0012232788430992514, Final Batch Loss: 0.00042450023465789855\n",
      "Epoch 4377, Loss: 7.300321925640674e-06, Final Batch Loss: 2.5134281145255954e-07\n",
      "Epoch 4378, Loss: 1.3853767853788668e-05, Final Batch Loss: 1.910201206101192e-07\n",
      "Epoch 4379, Loss: 2.6680892553088142e-06, Final Batch Loss: 1.723507025985782e-08\n",
      "Epoch 4380, Loss: 1.1015591923069223e-06, Final Batch Loss: 9.170243515654874e-07\n",
      "Epoch 4381, Loss: 4.3270547536167214e-06, Final Batch Loss: 1.1849034819988447e-07\n",
      "Epoch 4382, Loss: 0.0007252191398947616, Final Batch Loss: 0.0007172288023866713\n",
      "Epoch 4383, Loss: 4.226756260550246e-07, Final Batch Loss: 1.6947730330230115e-07\n",
      "Epoch 4384, Loss: 3.134240074587069e-06, Final Batch Loss: 3.655233342669817e-07\n",
      "Epoch 4385, Loss: 8.418137099397427e-06, Final Batch Loss: 7.99961185293796e-07\n",
      "Epoch 4386, Loss: 3.3897341040756146e-06, Final Batch Loss: 3.712637521857687e-07\n",
      "Epoch 4387, Loss: 0.0002182565981456719, Final Batch Loss: 0.00021686921536456794\n",
      "Epoch 4388, Loss: 0.0001157837456702282, Final Batch Loss: 2.3769705137510755e-07\n",
      "Epoch 4389, Loss: 0.00029587965400423855, Final Batch Loss: 7.354276021942496e-05\n",
      "Epoch 4390, Loss: 6.073358463254408e-06, Final Batch Loss: 3.64085508408607e-07\n",
      "Epoch 4391, Loss: 7.699716947939805e-05, Final Batch Loss: 9.192003602720433e-08\n",
      "Epoch 4392, Loss: 4.646510612360544e-05, Final Batch Loss: 4.1076461343436677e-07\n",
      "Epoch 4393, Loss: 1.2769438839654867e-07, Final Batch Loss: 9.479267504275413e-08\n",
      "Epoch 4394, Loss: 2.0981327679692185e-06, Final Batch Loss: 6.462844339694129e-07\n",
      "Epoch 4395, Loss: 0.00010726274058470153, Final Batch Loss: 1.2810401130991522e-06\n",
      "Epoch 4396, Loss: 2.150314287518995e-06, Final Batch Loss: 6.685441462650488e-07\n",
      "Epoch 4397, Loss: 0.00029602833183162147, Final Batch Loss: 0.0002945756132248789\n",
      "Epoch 4398, Loss: 7.33324031898519e-06, Final Batch Loss: 5.24870483786799e-06\n",
      "Epoch 4399, Loss: 1.6618757925357386e-05, Final Batch Loss: 1.7163218046789552e-07\n",
      "Epoch 4400, Loss: 8.11597050187629e-06, Final Batch Loss: 7.656306479475461e-06\n",
      "Epoch 4401, Loss: 6.796092293370748e-07, Final Batch Loss: 2.1471913669302012e-07\n",
      "Epoch 4402, Loss: 1.2340899047558196e-05, Final Batch Loss: 1.89284128282452e-06\n",
      "Epoch 4403, Loss: 1.2117965937363806e-06, Final Batch Loss: 1.0843695719131574e-07\n",
      "Epoch 4404, Loss: 7.682644718443044e-05, Final Batch Loss: 4.2275365558452904e-05\n",
      "Epoch 4405, Loss: 1.278865375375915e-05, Final Batch Loss: 2.0107568943217302e-08\n",
      "Epoch 4406, Loss: 0.0001829455542292635, Final Batch Loss: 1.7656385580266942e-06\n",
      "Epoch 4407, Loss: 2.9344544259402028e-05, Final Batch Loss: 2.7450494599179365e-05\n",
      "Epoch 4408, Loss: 0.00035079336339549627, Final Batch Loss: 0.00033751773298718035\n",
      "Epoch 4409, Loss: 4.055037879879819e-05, Final Batch Loss: 2.558886080805678e-06\n",
      "Epoch 4410, Loss: 0.0002476916561136022, Final Batch Loss: 0.00010966468835249543\n",
      "Epoch 4411, Loss: 8.309700390896069e-06, Final Batch Loss: 2.319513470183665e-07\n",
      "Epoch 4412, Loss: 2.0332186325688895e-05, Final Batch Loss: 2.2261959387037678e-08\n",
      "Epoch 4413, Loss: 4.118491290228121e-06, Final Batch Loss: 3.62020477950864e-06\n",
      "Epoch 4414, Loss: 3.115066775194464e-06, Final Batch Loss: 5.960454529940762e-08\n",
      "Epoch 4415, Loss: 2.1534023062486085e-06, Final Batch Loss: 9.852207085714326e-07\n",
      "Epoch 4416, Loss: 1.5778779925312847e-05, Final Batch Loss: 4.527692908595782e-06\n",
      "Epoch 4417, Loss: 3.1166059955012315e-05, Final Batch Loss: 5.744889790548768e-07\n",
      "Epoch 4418, Loss: 8.349168547283625e-05, Final Batch Loss: 1.1975199413427617e-05\n",
      "Epoch 4419, Loss: 7.525346802594868e-05, Final Batch Loss: 3.281812723798794e-07\n",
      "Epoch 4420, Loss: 0.00012079937005182728, Final Batch Loss: 0.000101420511782635\n",
      "Epoch 4421, Loss: 1.6588998960287427e-05, Final Batch Loss: 6.348120678012492e-07\n",
      "Epoch 4422, Loss: 8.728434099225524e-05, Final Batch Loss: 2.412888022718107e-07\n",
      "Epoch 4423, Loss: 1.2870694945377181e-06, Final Batch Loss: 3.296162276456016e-07\n",
      "Epoch 4424, Loss: 4.028364705277454e-05, Final Batch Loss: 3.989979813923128e-05\n",
      "Epoch 4425, Loss: 0.00020471916195674567, Final Batch Loss: 0.00020155739912297577\n",
      "Epoch 4426, Loss: 7.075368841924501e-07, Final Batch Loss: 3.971196065322147e-07\n",
      "Epoch 4427, Loss: 1.749759974245535e-06, Final Batch Loss: 4.6676535703227273e-07\n",
      "Epoch 4428, Loss: 9.866729878638125e-05, Final Batch Loss: 9.854332165559754e-05\n",
      "Epoch 4429, Loss: 9.488284376857337e-06, Final Batch Loss: 4.188919319858542e-06\n",
      "Epoch 4430, Loss: 1.1135565046060947e-05, Final Batch Loss: 9.81671291810926e-06\n",
      "Epoch 4431, Loss: 2.6156268859267584e-05, Final Batch Loss: 2.786045797620318e-06\n",
      "Epoch 4432, Loss: 0.0005703431116330648, Final Batch Loss: 0.0005700770416297019\n",
      "Epoch 4433, Loss: 6.314802476481418e-06, Final Batch Loss: 5.091344519314589e-07\n",
      "Epoch 4434, Loss: 5.135266201250488e-05, Final Batch Loss: 4.5464650611393154e-05\n",
      "Epoch 4435, Loss: 0.00011716027438524179, Final Batch Loss: 8.653265103930607e-05\n",
      "Epoch 4436, Loss: 1.7217627146237646e-06, Final Batch Loss: 1.3736780601902865e-06\n",
      "Epoch 4437, Loss: 2.3958064190310324e-06, Final Batch Loss: 1.227995340968846e-07\n",
      "Epoch 4438, Loss: 3.842906721729378e-06, Final Batch Loss: 2.54595988735673e-06\n",
      "Epoch 4439, Loss: 5.8537825225357665e-05, Final Batch Loss: 5.7639554142951965e-05\n",
      "Epoch 4440, Loss: 2.190310851801769e-06, Final Batch Loss: 1.6796402633190155e-06\n",
      "Epoch 4441, Loss: 8.533255808629292e-07, Final Batch Loss: 7.755763675731941e-08\n",
      "Epoch 4442, Loss: 5.017707417209749e-05, Final Batch Loss: 1.6300259630952496e-06\n",
      "Epoch 4443, Loss: 1.9497741305940508e-05, Final Batch Loss: 1.9358505596756004e-05\n",
      "Epoch 4444, Loss: 1.8581000631456845e-06, Final Batch Loss: 2.570845936133992e-07\n",
      "Epoch 4445, Loss: 0.00033488743611087557, Final Batch Loss: 2.8725326046696864e-05\n",
      "Epoch 4446, Loss: 1.3277936432132265e-05, Final Batch Loss: 4.881397671852028e-06\n",
      "Epoch 4447, Loss: 5.654194444559835e-05, Final Batch Loss: 7.640495596206165e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4448, Loss: 0.00016152297155258566, Final Batch Loss: 1.5654526350772358e-06\n",
      "Epoch 4449, Loss: 2.5774274503564953e-06, Final Batch Loss: 3.5906408957231406e-09\n",
      "Epoch 4450, Loss: 2.147949271602556e-05, Final Batch Loss: 1.5171400264080148e-05\n",
      "Epoch 4451, Loss: 5.665076969307847e-06, Final Batch Loss: 3.7041991163278e-06\n",
      "Epoch 4452, Loss: 0.0008028752001791872, Final Batch Loss: 3.6623737287300173e-07\n",
      "Epoch 4453, Loss: 4.02091936848592e-05, Final Batch Loss: 1.9942084691138007e-05\n",
      "Epoch 4454, Loss: 2.999532000558247e-06, Final Batch Loss: 4.358947194305074e-07\n",
      "Epoch 4455, Loss: 0.0003740798404692214, Final Batch Loss: 0.0003737160295713693\n",
      "Epoch 4456, Loss: 2.5418884092687222e-05, Final Batch Loss: 2.516187305445783e-05\n",
      "Epoch 4457, Loss: 9.749277577952853e-05, Final Batch Loss: 9.98194025214616e-08\n",
      "Epoch 4458, Loss: 0.0019643487617031496, Final Batch Loss: 4.633024673239561e-06\n",
      "Epoch 4459, Loss: 0.00023544137638964457, Final Batch Loss: 0.00023460078227799386\n",
      "Epoch 4460, Loss: 0.002856370629160665, Final Batch Loss: 0.002833261853083968\n",
      "Epoch 4461, Loss: 2.3556326823381823e-05, Final Batch Loss: 1.413133986716275e-06\n",
      "Epoch 4462, Loss: 0.00016479288751725107, Final Batch Loss: 2.0162653527222574e-05\n",
      "Epoch 4463, Loss: 4.447501680715504e-05, Final Batch Loss: 4.3773154175141826e-05\n",
      "Epoch 4464, Loss: 1.742385245506739e-05, Final Batch Loss: 1.6331063307006843e-05\n",
      "Epoch 4465, Loss: 1.6268812430553226e-06, Final Batch Loss: 1.1820012559837778e-06\n",
      "Epoch 4466, Loss: 1.9752583170884463e-05, Final Batch Loss: 9.902549891194212e-07\n",
      "Epoch 4467, Loss: 1.6050399892719724e-05, Final Batch Loss: 7.590272730340075e-07\n",
      "Epoch 4468, Loss: 3.118679927638368e-06, Final Batch Loss: 2.813037326632184e-06\n",
      "Epoch 4469, Loss: 2.5844843435152143e-05, Final Batch Loss: 5.371438192014466e-07\n",
      "Epoch 4470, Loss: 1.09414283855358e-06, Final Batch Loss: 9.77318336481403e-07\n",
      "Epoch 4471, Loss: 0.0003586491984322038, Final Batch Loss: 0.00035848564584739506\n",
      "Epoch 4472, Loss: 1.824674305339613e-05, Final Batch Loss: 1.793203773559071e-05\n",
      "Epoch 4473, Loss: 1.4094658027374862e-06, Final Batch Loss: 1.3312646842678078e-06\n",
      "Epoch 4474, Loss: 5.32621743332129e-06, Final Batch Loss: 9.327900443167891e-07\n",
      "Epoch 4475, Loss: 0.00038434448451951653, Final Batch Loss: 0.00038429489359259605\n",
      "Epoch 4476, Loss: 1.2460116749934969e-05, Final Batch Loss: 2.4052526441664668e-06\n",
      "Epoch 4477, Loss: 9.709097099630526e-07, Final Batch Loss: 3.159762229643093e-08\n",
      "Epoch 4478, Loss: 9.626064456824679e-05, Final Batch Loss: 7.417559390887618e-05\n",
      "Epoch 4479, Loss: 4.2626404592738254e-05, Final Batch Loss: 3.666173870442435e-05\n",
      "Epoch 4480, Loss: 5.684595848265417e-06, Final Batch Loss: 1.2567191731704952e-07\n",
      "Epoch 4481, Loss: 0.00029211251634819746, Final Batch Loss: 0.0002919179678428918\n",
      "Epoch 4482, Loss: 2.37453896261286e-05, Final Batch Loss: 8.632919161755126e-06\n",
      "Epoch 4483, Loss: 7.566207997911079e-07, Final Batch Loss: 6.893869226587412e-07\n",
      "Epoch 4484, Loss: 2.1318582525964302e-06, Final Batch Loss: 6.304994144556986e-07\n",
      "Epoch 4485, Loss: 2.6202077556547465e-06, Final Batch Loss: 2.5992269456764916e-06\n",
      "Epoch 4486, Loss: 2.420497449140413e-06, Final Batch Loss: 7.181282235535491e-10\n",
      "Epoch 4487, Loss: 2.671351660410437e-05, Final Batch Loss: 1.6372415529986029e-06\n",
      "Epoch 4488, Loss: 3.543672391970176e-05, Final Batch Loss: 2.2770469513488933e-05\n",
      "Epoch 4489, Loss: 2.4617864653464494e-06, Final Batch Loss: 2.097485776175745e-06\n",
      "Epoch 4490, Loss: 5.7699235185282305e-06, Final Batch Loss: 2.017606675508432e-06\n",
      "Epoch 4491, Loss: 0.00012272867661522469, Final Batch Loss: 2.2783342501497827e-06\n",
      "Epoch 4492, Loss: 7.90447279541695e-06, Final Batch Loss: 1.9845822407660307e-06\n",
      "Epoch 4493, Loss: 6.361247670838566e-07, Final Batch Loss: 1.8743044449820445e-07\n",
      "Epoch 4494, Loss: 1.1274152242890523e-06, Final Batch Loss: 1.011067411127442e-06\n",
      "Epoch 4495, Loss: 1.0700519339934544e-05, Final Batch Loss: 7.346156394305581e-07\n",
      "Epoch 4496, Loss: 1.457403959648218e-05, Final Batch Loss: 1.348073419649154e-05\n",
      "Epoch 4497, Loss: 3.201611889380729e-06, Final Batch Loss: 1.090053274310776e-06\n",
      "Epoch 4498, Loss: 2.7501104113980546e-06, Final Batch Loss: 4.143520300203818e-07\n",
      "Epoch 4499, Loss: 0.00032146970866264724, Final Batch Loss: 3.734262676857725e-08\n",
      "Epoch 4500, Loss: 1.9096655705652665e-05, Final Batch Loss: 1.0748121894721407e-05\n",
      "Epoch 4501, Loss: 8.518843941374143e-07, Final Batch Loss: 7.288622327905614e-07\n",
      "Epoch 4502, Loss: 0.0005254128600427066, Final Batch Loss: 1.1323206308588851e-05\n",
      "Epoch 4503, Loss: 2.8531771022244357e-05, Final Batch Loss: 2.8315766030573286e-05\n",
      "Epoch 4504, Loss: 5.501425732745702e-07, Final Batch Loss: 1.4865187836221594e-07\n",
      "Epoch 4505, Loss: 2.1212203762388526e-06, Final Batch Loss: 2.843752042736014e-07\n",
      "Epoch 4506, Loss: 2.0184668869660527e-06, Final Batch Loss: 1.1059097460019984e-07\n",
      "Epoch 4507, Loss: 2.0076678310942953e-06, Final Batch Loss: 4.947709157931968e-07\n",
      "Epoch 4508, Loss: 1.5202804291902794e-05, Final Batch Loss: 1.4949131582397968e-05\n",
      "Epoch 4509, Loss: 5.472635962178174e-07, Final Batch Loss: 8.617524827059242e-08\n",
      "Epoch 4510, Loss: 2.6833554876759536e-05, Final Batch Loss: 7.396702272899347e-08\n",
      "Epoch 4511, Loss: 6.232730271449327e-06, Final Batch Loss: 1.4506068168884667e-07\n",
      "Epoch 4512, Loss: 0.00031347003732662415, Final Batch Loss: 3.497252691886388e-07\n",
      "Epoch 4513, Loss: 8.65745741975843e-05, Final Batch Loss: 7.892094436101615e-05\n",
      "Epoch 4514, Loss: 8.972116916083905e-07, Final Batch Loss: 7.75576722844562e-08\n",
      "Epoch 4515, Loss: 1.644073213569186e-06, Final Batch Loss: 2.298008006107466e-08\n",
      "Epoch 4516, Loss: 6.927504898612824e-07, Final Batch Loss: 5.177524258215271e-07\n",
      "Epoch 4517, Loss: 0.00020804925638628902, Final Batch Loss: 1.687590582832854e-07\n",
      "Epoch 4518, Loss: 1.6609260811151216e-06, Final Batch Loss: 1.5646056681362097e-06\n",
      "Epoch 4519, Loss: 2.1693751428131236e-05, Final Batch Loss: 5.60139099547996e-08\n",
      "Epoch 4520, Loss: 8.121536382077466e-06, Final Batch Loss: 5.306839625518478e-07\n",
      "Epoch 4521, Loss: 1.6991654092635144e-06, Final Batch Loss: 5.672968654835131e-07\n",
      "Epoch 4522, Loss: 1.8872848102091666e-06, Final Batch Loss: 1.5554118135696626e-06\n",
      "Epoch 4523, Loss: 3.54721507846989e-05, Final Batch Loss: 6.247705641726498e-08\n",
      "Epoch 4524, Loss: 3.9364260373986326e-05, Final Batch Loss: 2.27697855734732e-05\n",
      "Epoch 4525, Loss: 4.019518229370078e-07, Final Batch Loss: 2.9371099685704394e-07\n",
      "Epoch 4526, Loss: 1.262255219103281e-05, Final Batch Loss: 6.104065164436179e-08\n",
      "Epoch 4527, Loss: 0.000445462882225911, Final Batch Loss: 0.0004446447128430009\n",
      "Epoch 4528, Loss: 4.653640331753195e-06, Final Batch Loss: 4.381845883472124e-06\n",
      "Epoch 4529, Loss: 0.0005285538467241224, Final Batch Loss: 0.0005285266670398414\n",
      "Epoch 4530, Loss: 0.0018714054364465937, Final Batch Loss: 1.7163043253276555e-07\n",
      "Epoch 4531, Loss: 9.945666192834324e-07, Final Batch Loss: 3.4325660180911655e-07\n",
      "Epoch 4532, Loss: 1.6980826330836862e-05, Final Batch Loss: 1.3293433767103124e-05\n",
      "Epoch 4533, Loss: 3.107776365141035e-06, Final Batch Loss: 2.4397556899202755e-06\n",
      "Epoch 4534, Loss: 1.0220202142363632e-06, Final Batch Loss: 8.88983436198032e-07\n",
      "Epoch 4535, Loss: 4.55974874569165e-06, Final Batch Loss: 6.319511669516942e-08\n",
      "Epoch 4536, Loss: 4.283921089154319e-05, Final Batch Loss: 4.218453977955505e-05\n",
      "Epoch 4537, Loss: 3.254281443787477e-05, Final Batch Loss: 3.084795753238723e-05\n",
      "Epoch 4538, Loss: 5.268779025868753e-05, Final Batch Loss: 5.237928780843504e-05\n",
      "Epoch 4539, Loss: 1.1532806610148327e-05, Final Batch Loss: 2.082551588955539e-07\n",
      "Epoch 4540, Loss: 0.0005238821736384125, Final Batch Loss: 3.8077828321547713e-06\n",
      "Epoch 4541, Loss: 4.4589585002086096e-07, Final Batch Loss: 2.527785341044364e-07\n",
      "Epoch 4542, Loss: 1.5627525087325012e-06, Final Batch Loss: 1.4921808997314656e-06\n",
      "Epoch 4543, Loss: 9.492947128819651e-06, Final Batch Loss: 2.586424898254336e-06\n",
      "Epoch 4544, Loss: 5.135060810346204e-06, Final Batch Loss: 1.6516942480393482e-08\n",
      "Epoch 4545, Loss: 0.00024239668709924445, Final Batch Loss: 0.00016787614731583744\n",
      "Epoch 4546, Loss: 2.988067535625305e-07, Final Batch Loss: 1.3716211810788081e-07\n",
      "Epoch 4547, Loss: 7.411484682506853e-05, Final Batch Loss: 7.346209167735651e-05\n",
      "Epoch 4548, Loss: 2.224370382464258e-05, Final Batch Loss: 2.286876224388834e-06\n",
      "Epoch 4549, Loss: 1.4475606093355964e-05, Final Batch Loss: 3.6839557537859946e-07\n",
      "Epoch 4550, Loss: 0.00045606190721514395, Final Batch Loss: 0.00045587451313622296\n",
      "Epoch 4551, Loss: 0.00028558444660120585, Final Batch Loss: 0.0002822329697664827\n",
      "Epoch 4552, Loss: 8.698061918721578e-06, Final Batch Loss: 8.619384061603341e-06\n",
      "Epoch 4553, Loss: 2.6375936919009746e-06, Final Batch Loss: 4.236943240698565e-08\n",
      "Epoch 4554, Loss: 2.44576258410234e-05, Final Batch Loss: 1.969594450201839e-06\n",
      "Epoch 4555, Loss: 1.0090303135257273e-06, Final Batch Loss: 7.338994691963308e-07\n",
      "Epoch 4556, Loss: 2.945922278740909e-05, Final Batch Loss: 1.6400532331317663e-05\n",
      "Epoch 4557, Loss: 5.8881507811747724e-05, Final Batch Loss: 7.530767561547691e-06\n",
      "Epoch 4558, Loss: 1.616862891751225e-05, Final Batch Loss: 5.345614681573352e-06\n",
      "Epoch 4559, Loss: 2.049509549628681e-06, Final Batch Loss: 8.61753601810733e-09\n",
      "Epoch 4560, Loss: 1.916666224843766e-06, Final Batch Loss: 5.026884153380706e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4561, Loss: 1.392392307764112e-05, Final Batch Loss: 1.306983250515259e-07\n",
      "Epoch 4562, Loss: 0.0021361607250582892, Final Batch Loss: 3.7409936339827254e-05\n",
      "Epoch 4563, Loss: 2.6054547817011553e-06, Final Batch Loss: 1.0197398125910695e-07\n",
      "Epoch 4564, Loss: 0.00010660468979040161, Final Batch Loss: 6.624809611821547e-05\n",
      "Epoch 4565, Loss: 8.510669502470591e-08, Final Batch Loss: 5.74501619610146e-08\n",
      "Epoch 4566, Loss: 2.0623798889118916e-05, Final Batch Loss: 2.0589466657838784e-05\n",
      "Epoch 4567, Loss: 2.389077403464057e-06, Final Batch Loss: 1.5080681592394285e-08\n",
      "Epoch 4568, Loss: 5.937451351201162e-05, Final Batch Loss: 7.941333024064079e-06\n",
      "Epoch 4569, Loss: 1.490597369979696e-07, Final Batch Loss: 1.3141676902250765e-07\n",
      "Epoch 4570, Loss: 4.38813903542723e-05, Final Batch Loss: 4.293015445000492e-05\n",
      "Epoch 4571, Loss: 1.9392896319914144e-06, Final Batch Loss: 1.3909484550822526e-06\n",
      "Epoch 4572, Loss: 3.9774312021734204e-07, Final Batch Loss: 1.7235064930787303e-08\n",
      "Epoch 4573, Loss: 1.5336529486376094e-05, Final Batch Loss: 8.272650120488834e-07\n",
      "Epoch 4574, Loss: 9.800808811633033e-06, Final Batch Loss: 2.133394673364819e-06\n",
      "Epoch 4575, Loss: 1.332895449568383e-07, Final Batch Loss: 3.5906408957231406e-09\n",
      "Epoch 4576, Loss: 4.4244164243423256e-07, Final Batch Loss: 4.52420287899713e-08\n",
      "Epoch 4577, Loss: 5.786509973404463e-06, Final Batch Loss: 2.7400021735957125e-06\n",
      "Epoch 4578, Loss: 1.8837526170045749e-06, Final Batch Loss: 1.6048071529439767e-06\n",
      "Epoch 4579, Loss: 1.2564029492345696e-06, Final Batch Loss: 1.2544956007332075e-06\n",
      "Epoch 4580, Loss: 7.7986381086248e-05, Final Batch Loss: 1.342894506706216e-07\n",
      "Epoch 4581, Loss: 0.0024258248723825204, Final Batch Loss: 1.149002244460462e-07\n",
      "Epoch 4582, Loss: 3.6242623195903434e-06, Final Batch Loss: 3.3786980111472076e-06\n",
      "Epoch 4583, Loss: 9.442463124287315e-06, Final Batch Loss: 2.7636206141323783e-06\n",
      "Epoch 4584, Loss: 4.577189679366711e-05, Final Batch Loss: 3.529909690769273e-06\n",
      "Epoch 4585, Loss: 9.9288567412259e-07, Final Batch Loss: 6.872388098599913e-07\n",
      "Epoch 4586, Loss: 4.073318621067301e-06, Final Batch Loss: 4.028972853120649e-06\n",
      "Epoch 4587, Loss: 0.0017786180261794016, Final Batch Loss: 1.2567139151542506e-07\n",
      "Epoch 4588, Loss: 6.893237411986775e-07, Final Batch Loss: 3.741392902156804e-07\n",
      "Epoch 4589, Loss: 7.277925806192798e-05, Final Batch Loss: 2.1317614482541103e-06\n",
      "Epoch 4590, Loss: 3.6505120704077854e-07, Final Batch Loss: 6.894005366575584e-08\n",
      "Epoch 4591, Loss: 4.2749770415184685e-05, Final Batch Loss: 4.243744842824526e-05\n",
      "Epoch 4592, Loss: 6.80492555602541e-05, Final Batch Loss: 3.5860173284163466e-06\n",
      "Epoch 4593, Loss: 1.0338146338995102e-07, Final Batch Loss: 3.662449543639923e-08\n",
      "Epoch 4594, Loss: 4.275134779163636e-05, Final Batch Loss: 1.8578581148176454e-05\n",
      "Epoch 4595, Loss: 4.338082419508282e-06, Final Batch Loss: 7.927692990961077e-07\n",
      "Epoch 4596, Loss: 0.00015197518223430961, Final Batch Loss: 5.7506171287968755e-05\n",
      "Epoch 4597, Loss: 2.9890268153920374e-06, Final Batch Loss: 7.899406462286152e-09\n",
      "Epoch 4598, Loss: 8.53771004472037e-06, Final Batch Loss: 8.18915395939257e-06\n",
      "Epoch 4599, Loss: 1.4155165473539455e-05, Final Batch Loss: 3.590558037558367e-07\n",
      "Epoch 4600, Loss: 1.025146811173272e-05, Final Batch Loss: 7.612142383095488e-08\n",
      "Epoch 4601, Loss: 3.5933554443090543e-07, Final Batch Loss: 1.299802221410573e-07\n",
      "Epoch 4602, Loss: 1.0380788157959842e-05, Final Batch Loss: 1.0335488696000539e-05\n",
      "Epoch 4603, Loss: 2.7156587265153576e-05, Final Batch Loss: 4.193747997760511e-07\n",
      "Epoch 4604, Loss: 3.033214710512766e-06, Final Batch Loss: 1.6732278140807466e-07\n",
      "Epoch 4605, Loss: 3.7171301983107696e-06, Final Batch Loss: 9.586345868228818e-07\n",
      "Epoch 4606, Loss: 3.9559492392982065e-07, Final Batch Loss: 7.612132435497188e-08\n",
      "Epoch 4607, Loss: 1.1724987462713443e-05, Final Batch Loss: 2.4416340949073856e-08\n",
      "Epoch 4608, Loss: 4.9210721044801176e-06, Final Batch Loss: 3.87686668545939e-06\n",
      "Epoch 4609, Loss: 0.003863407066091895, Final Batch Loss: 0.0036173544358462095\n",
      "Epoch 4610, Loss: 1.126387360272929e-06, Final Batch Loss: 6.34795014775591e-07\n",
      "Epoch 4611, Loss: 1.6771776358837087e-06, Final Batch Loss: 1.1841356126751634e-06\n",
      "Epoch 4612, Loss: 3.868557914898929e-06, Final Batch Loss: 3.810383987001842e-06\n",
      "Epoch 4613, Loss: 5.64146660053666e-06, Final Batch Loss: 1.8814819213730516e-07\n",
      "Epoch 4614, Loss: 1.1819094389409202e-05, Final Batch Loss: 1.0125560123697142e-07\n",
      "Epoch 4615, Loss: 3.734267792765422e-07, Final Batch Loss: 2.5564963834767696e-07\n",
      "Epoch 4616, Loss: 4.097430235106003e-07, Final Batch Loss: 9.694704772300611e-08\n",
      "Epoch 4617, Loss: 3.373100746273394e-06, Final Batch Loss: 3.278210670032422e-06\n",
      "Epoch 4618, Loss: 0.0001883112417999655, Final Batch Loss: 1.5461817383766174e-05\n",
      "Epoch 4619, Loss: 2.1059910750409472e-05, Final Batch Loss: 1.8066417396767065e-05\n",
      "Epoch 4620, Loss: 1.5171258027635304e-07, Final Batch Loss: 2.0107560061433105e-08\n",
      "Epoch 4621, Loss: 2.5121445332842995e-06, Final Batch Loss: 1.0699496897359495e-06\n",
      "Epoch 4622, Loss: 5.645976563783961e-05, Final Batch Loss: 5.639825394609943e-05\n",
      "Epoch 4623, Loss: 2.701404216765013e-06, Final Batch Loss: 3.3033845880936497e-08\n",
      "Epoch 4624, Loss: 1.4428330104010456e-06, Final Batch Loss: 1.3055046110821422e-06\n",
      "Epoch 4625, Loss: 3.8995406626440854e-05, Final Batch Loss: 1.4075250476253132e-07\n",
      "Epoch 4626, Loss: 4.442366059720371e-05, Final Batch Loss: 4.4078438804717734e-05\n",
      "Epoch 4627, Loss: 1.59695327468512e-05, Final Batch Loss: 8.545698193529461e-08\n",
      "Epoch 4628, Loss: 8.289182801490824e-06, Final Batch Loss: 7.87960016168654e-06\n",
      "Epoch 4629, Loss: 2.639547074068105e-05, Final Batch Loss: 4.575965249387082e-06\n",
      "Epoch 4630, Loss: 6.479708667939121e-05, Final Batch Loss: 6.28706329734996e-05\n",
      "Epoch 4631, Loss: 8.702549436634399e-08, Final Batch Loss: 6.0322683737013e-08\n",
      "Epoch 4632, Loss: 3.8109272537667493e-07, Final Batch Loss: 8.689307406939406e-08\n",
      "Epoch 4633, Loss: 0.00011728560752999329, Final Batch Loss: 1.968147671504994e-06\n",
      "Epoch 4634, Loss: 1.9337024355081667e-06, Final Batch Loss: 1.6852760609253892e-06\n",
      "Epoch 4635, Loss: 5.29353471279137e-07, Final Batch Loss: 8.114797367397841e-08\n",
      "Epoch 4636, Loss: 7.678216573658858e-08, Final Batch Loss: 2.8725122280803816e-09\n",
      "Epoch 4637, Loss: 2.7290428761261865e-06, Final Batch Loss: 1.2386929029162275e-06\n",
      "Epoch 4638, Loss: 7.24764277038048e-07, Final Batch Loss: 4.1435106368226116e-07\n",
      "Epoch 4639, Loss: 5.582791914093832e-06, Final Batch Loss: 4.779401933774352e-06\n",
      "Epoch 4640, Loss: 3.397597652110562e-06, Final Batch Loss: 2.7534126729733543e-06\n",
      "Epoch 4641, Loss: 5.44072217056879e-07, Final Batch Loss: 4.308768897232085e-09\n",
      "Epoch 4642, Loss: 2.696224363774036e-07, Final Batch Loss: 2.3195234177819657e-07\n",
      "Epoch 4643, Loss: 3.3031262773874914e-06, Final Batch Loss: 1.7312844420303009e-06\n",
      "Epoch 4644, Loss: 8.905212069976187e-07, Final Batch Loss: 7.317360655179073e-07\n",
      "Epoch 4645, Loss: 7.558979682187328e-07, Final Batch Loss: 7.482685759896412e-07\n",
      "Epoch 4646, Loss: 8.374510418462933e-08, Final Batch Loss: 7.468520379916299e-08\n",
      "Epoch 4647, Loss: 0.06606009073584573, Final Batch Loss: 4.813291161553934e-05\n",
      "Epoch 4648, Loss: 6.544376992678735e-05, Final Batch Loss: 2.2770624127588235e-05\n",
      "Epoch 4649, Loss: 3.3436800777053577e-06, Final Batch Loss: 2.9155387437640456e-07\n",
      "Epoch 4650, Loss: 2.6901000751422544e-06, Final Batch Loss: 2.0321178908488946e-06\n",
      "Epoch 4651, Loss: 0.00012662102328064861, Final Batch Loss: 3.5906321471657066e-08\n",
      "Epoch 4652, Loss: 3.328336442010027e-07, Final Batch Loss: 1.4362564471070982e-09\n",
      "Epoch 4653, Loss: 2.2905836885911413e-05, Final Batch Loss: 2.8992162697250023e-06\n",
      "Epoch 4654, Loss: 8.007403984322536e-08, Final Batch Loss: 5.098700839312187e-08\n",
      "Epoch 4655, Loss: 0.00015860726870187136, Final Batch Loss: 8.092976599982649e-07\n",
      "Epoch 4656, Loss: 8.202100421073055e-08, Final Batch Loss: 1.4362564471070982e-09\n",
      "Epoch 4657, Loss: 0.0011284626292322741, Final Batch Loss: 0.0011284120846539736\n",
      "Epoch 4658, Loss: 7.619245678824882e-07, Final Batch Loss: 1.7163050358703913e-07\n",
      "Epoch 4659, Loss: 0.0002886700294766342, Final Batch Loss: 5.891595719731413e-06\n",
      "Epoch 4660, Loss: 1.1017851193173556e-05, Final Batch Loss: 9.407226571056526e-07\n",
      "Epoch 4661, Loss: 1.8309323081666662e-05, Final Batch Loss: 1.77471501956461e-05\n",
      "Epoch 4662, Loss: 0.0002890281508314274, Final Batch Loss: 3.403880270980153e-07\n",
      "Epoch 4663, Loss: 1.0598094988267803e-06, Final Batch Loss: 1.0440738833494834e-06\n",
      "Epoch 4664, Loss: 6.708892215101514e-06, Final Batch Loss: 1.4929360077076126e-06\n",
      "Epoch 4665, Loss: 3.2378819838640993e-06, Final Batch Loss: 2.089717696662774e-07\n",
      "Epoch 4666, Loss: 1.2034717201458989e-05, Final Batch Loss: 7.9674036896904e-06\n",
      "Epoch 4667, Loss: 2.9797519118801574e-07, Final Batch Loss: 2.269267724841484e-07\n",
      "Epoch 4668, Loss: 3.813335752056446e-05, Final Batch Loss: 2.1134561393409967e-05\n",
      "Epoch 4669, Loss: 3.181119154760381e-07, Final Batch Loss: 1.9461170097656577e-07\n",
      "Epoch 4670, Loss: 1.923827505834197e-05, Final Batch Loss: 1.7378088159603067e-05\n",
      "Epoch 4671, Loss: 7.788221765281378e-07, Final Batch Loss: 1.0843715614328175e-07\n",
      "Epoch 4672, Loss: 4.122614711832284e-07, Final Batch Loss: 3.6839259109910927e-07\n",
      "Epoch 4673, Loss: 2.000808310143043e-07, Final Batch Loss: 1.9102093062883796e-07\n",
      "Epoch 4674, Loss: 3.4114836466869747e-07, Final Batch Loss: 1.127453685967339e-07\n",
      "Epoch 4675, Loss: 1.0133991218630456e-05, Final Batch Loss: 1.4362564471070982e-09\n",
      "Epoch 4676, Loss: 0.000154554587425082, Final Batch Loss: 0.00015139604511205107\n",
      "Epoch 4677, Loss: 6.253748133744352e-05, Final Batch Loss: 7.181281347357071e-09\n",
      "Epoch 4678, Loss: 2.199287294502028e-07, Final Batch Loss: 8.689296038255634e-08\n",
      "Epoch 4679, Loss: 0.00011773144396443058, Final Batch Loss: 1.321346587701555e-07\n",
      "Epoch 4680, Loss: 7.617126951409148e-07, Final Batch Loss: 7.181282235535491e-10\n",
      "Epoch 4681, Loss: 1.0458759447828925e-05, Final Batch Loss: 1.0218916941084899e-05\n",
      "Epoch 4682, Loss: 3.2037987196531503e-07, Final Batch Loss: 4.6678270138045264e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4683, Loss: 9.154579021064535e-06, Final Batch Loss: 8.61753601810733e-09\n",
      "Epoch 4684, Loss: 1.060197625690762e-06, Final Batch Loss: 7.89940912682141e-09\n",
      "Epoch 4685, Loss: 0.00031287071701058267, Final Batch Loss: 1.5008785680947767e-07\n",
      "Epoch 4686, Loss: 6.41427511105519e-08, Final Batch Loss: 2.1543846706606473e-09\n",
      "Epoch 4687, Loss: 2.2268702082328673e-07, Final Batch Loss: 1.2064467114214494e-07\n",
      "Epoch 4688, Loss: 2.9142673497517535e-05, Final Batch Loss: 7.877609959905385e-07\n",
      "Epoch 4689, Loss: 4.546146587358635e-05, Final Batch Loss: 2.003565384711692e-07\n",
      "Epoch 4690, Loss: 4.870330769790598e-07, Final Batch Loss: 4.0644795262778644e-07\n",
      "Epoch 4691, Loss: 8.227298167184927e-07, Final Batch Loss: 3.5259171227153274e-07\n",
      "Epoch 4692, Loss: 1.2189706524168287e-06, Final Batch Loss: 1.938920206612238e-07\n",
      "Epoch 4693, Loss: 7.758943366198423e-05, Final Batch Loss: 2.0107567166860463e-08\n",
      "Epoch 4694, Loss: 3.268361616903803e-05, Final Batch Loss: 3.25353212247137e-05\n",
      "Epoch 4695, Loss: 8.048861520215667e-05, Final Batch Loss: 8.048146264627576e-05\n",
      "Epoch 4696, Loss: 1.9213382984162308e-05, Final Batch Loss: 1.2357959349174052e-05\n",
      "Epoch 4697, Loss: 9.43774862207647e-05, Final Batch Loss: 2.723965280893026e-06\n",
      "Epoch 4698, Loss: 2.113260779879056e-05, Final Batch Loss: 4.073381205671467e-06\n",
      "Epoch 4699, Loss: 5.927466277810822e-07, Final Batch Loss: 1.2926304471250205e-08\n",
      "Epoch 4700, Loss: 3.240891336986351e-05, Final Batch Loss: 4.1003758610713703e-07\n",
      "Epoch 4701, Loss: 1.4806565706848573e-07, Final Batch Loss: 2.1543846706606473e-09\n",
      "Epoch 4702, Loss: 6.130027399020577e-07, Final Batch Loss: 6.096648803577409e-07\n",
      "Epoch 4703, Loss: 2.0590889704408255e-06, Final Batch Loss: 2.3267149629191408e-07\n",
      "Epoch 4704, Loss: 2.4451073841191828e-05, Final Batch Loss: 2.3478391085518524e-05\n",
      "Epoch 4705, Loss: 2.4821801236640795e-07, Final Batch Loss: 6.463150903357473e-09\n",
      "Epoch 4706, Loss: 8.902312970349158e-06, Final Batch Loss: 8.756878742133267e-06\n",
      "Epoch 4707, Loss: 2.195901913637499e-06, Final Batch Loss: 1.4439867754845181e-06\n",
      "Epoch 4708, Loss: 0.00013700791907567123, Final Batch Loss: 0.00013696786481887102\n",
      "Epoch 4709, Loss: 8.424938414464123e-05, Final Batch Loss: 7.601412562507903e-06\n",
      "Epoch 4710, Loss: 5.952178128154628e-06, Final Batch Loss: 3.6552233950715163e-07\n",
      "Epoch 4711, Loss: 8.022888198411238e-05, Final Batch Loss: 7.918948540464044e-05\n",
      "Epoch 4712, Loss: 9.391026651428547e-05, Final Batch Loss: 7.487089533242397e-06\n",
      "Epoch 4713, Loss: 0.00012619182304263177, Final Batch Loss: 4.739628423067188e-08\n",
      "Epoch 4714, Loss: 1.2492183032009052e-05, Final Batch Loss: 1.0018413377110846e-05\n",
      "Epoch 4715, Loss: 7.963136283706262e-07, Final Batch Loss: 3.633642506883916e-07\n",
      "Epoch 4716, Loss: 3.2388000841265807e-06, Final Batch Loss: 1.0771921132857187e-08\n",
      "Epoch 4717, Loss: 7.65178137953626e-05, Final Batch Loss: 1.3449573089019395e-05\n",
      "Epoch 4718, Loss: 2.430228391858691e-07, Final Batch Loss: 7.899392073795752e-08\n",
      "Epoch 4719, Loss: 2.3424429400620284e-06, Final Batch Loss: 8.430538400716614e-07\n",
      "Epoch 4720, Loss: 0.00013244889760244405, Final Batch Loss: 9.613125257601496e-06\n",
      "Epoch 4721, Loss: 7.397115723506431e-06, Final Batch Loss: 1.5798718777659815e-07\n",
      "Epoch 4722, Loss: 1.8007054869428885e-07, Final Batch Loss: 1.6516940704036642e-08\n",
      "Epoch 4723, Loss: 4.162912170535549e-07, Final Batch Loss: 5.745024456160763e-09\n",
      "Epoch 4724, Loss: 0.001380197022697871, Final Batch Loss: 1.7952977771074075e-07\n",
      "Epoch 4725, Loss: 7.078072243871247e-06, Final Batch Loss: 1.910195663867853e-07\n",
      "Epoch 4726, Loss: 0.0009959520249367415, Final Batch Loss: 0.000994174275547266\n",
      "Epoch 4727, Loss: 3.996875761913543e-06, Final Batch Loss: 3.0671092190459603e-06\n",
      "Epoch 4728, Loss: 1.1147033873726286e-07, Final Batch Loss: 3.2315721654185836e-08\n",
      "Epoch 4729, Loss: 3.505054337438196e-05, Final Batch Loss: 3.7942081689834595e-06\n",
      "Epoch 4730, Loss: 8.865542042713059e-07, Final Batch Loss: 2.1184612819524773e-07\n",
      "Epoch 4731, Loss: 4.1088400237754286e-08, Final Batch Loss: 2.010757960135834e-08\n",
      "Epoch 4732, Loss: 5.431259375576758e-07, Final Batch Loss: 5.745024456160763e-09\n",
      "Epoch 4733, Loss: 4.1982269038953746e-07, Final Batch Loss: 1.1274581623865743e-07\n",
      "Epoch 4734, Loss: 3.781943191949466e-08, Final Batch Loss: 3.734259479415414e-08\n",
      "Epoch 4735, Loss: 1.6662623210095262e-06, Final Batch Loss: 1.005375196427849e-07\n",
      "Epoch 4736, Loss: 8.096457982276206e-06, Final Batch Loss: 9.766490194351718e-08\n",
      "Epoch 4737, Loss: 7.684315733058611e-06, Final Batch Loss: 1.0333251339034177e-06\n",
      "Epoch 4738, Loss: 0.0005019409704800637, Final Batch Loss: 3.991544417658588e-06\n",
      "Epoch 4739, Loss: 0.00017488626903627846, Final Batch Loss: 0.00017462162941228598\n",
      "Epoch 4740, Loss: 2.406691635314928e-06, Final Batch Loss: 6.778847705390945e-07\n",
      "Epoch 4741, Loss: 5.7474744235452846e-05, Final Batch Loss: 7.181282235535491e-10\n",
      "Epoch 4742, Loss: 4.208785640003043e-06, Final Batch Loss: 1.9565829916246003e-06\n",
      "Epoch 4743, Loss: 8.809930388764542e-06, Final Batch Loss: 3.15975761111531e-08\n",
      "Epoch 4744, Loss: 7.061772322458637e-08, Final Batch Loss: 1.1490048024143107e-08\n",
      "Epoch 4745, Loss: 1.2143969080113948e-05, Final Batch Loss: 1.2128710295655765e-05\n",
      "Epoch 4746, Loss: 4.6827665300952503e-08, Final Batch Loss: 2.4416344501787535e-08\n",
      "Epoch 4747, Loss: 4.366929961463484e-05, Final Batch Loss: 1.227987951324394e-07\n",
      "Epoch 4748, Loss: 2.4555801019232604e-06, Final Batch Loss: 2.3349409730144544e-06\n",
      "Epoch 4749, Loss: 1.3741017954593815e-06, Final Batch Loss: 1.3721944469580194e-06\n",
      "Epoch 4750, Loss: 2.159188785100241e-06, Final Batch Loss: 2.128194410033757e-06\n",
      "Epoch 4751, Loss: 2.9930103737640934e-05, Final Batch Loss: 8.61753512992891e-09\n",
      "Epoch 4752, Loss: 0.0024194540728785796, Final Batch Loss: 1.8387594536761753e-05\n",
      "Epoch 4753, Loss: 0.0012353782681202574, Final Batch Loss: 0.001235226634889841\n",
      "Epoch 4754, Loss: 1.3916265061197919e-05, Final Batch Loss: 9.83059408099507e-07\n",
      "Epoch 4755, Loss: 1.2671968931954325e-06, Final Batch Loss: 9.910090170706098e-08\n",
      "Epoch 4756, Loss: 7.239282959403681e-05, Final Batch Loss: 1.694769764526427e-07\n",
      "Epoch 4757, Loss: 1.0662159155572226e-07, Final Batch Loss: 7.18125150456217e-08\n",
      "Epoch 4758, Loss: 1.5917658657826905e-07, Final Batch Loss: 3.8060726126332156e-08\n",
      "Epoch 4759, Loss: 6.525894715281311e-06, Final Batch Loss: 6.514927463285858e-06\n",
      "Epoch 4760, Loss: 2.5758830958011458e-05, Final Batch Loss: 8.689326591593272e-08\n",
      "Epoch 4761, Loss: 2.6233578864776064e-06, Final Batch Loss: 2.678568762348732e-07\n",
      "Epoch 4762, Loss: 1.0371503917916414e-06, Final Batch Loss: 1.0319051853002748e-06\n",
      "Epoch 4763, Loss: 1.4724130572574268e-05, Final Batch Loss: 1.0843702824558932e-07\n",
      "Epoch 4764, Loss: 1.2439675600717237e-07, Final Batch Loss: 4.5241982604693476e-08\n",
      "Epoch 4765, Loss: 0.0017149825620208503, Final Batch Loss: 1.3873253692509024e-06\n",
      "Epoch 4766, Loss: 1.163018993111109e-06, Final Batch Loss: 7.310153478101711e-07\n",
      "Epoch 4767, Loss: 1.0598081189527875e-05, Final Batch Loss: 7.583153092127759e-07\n",
      "Epoch 4768, Loss: 1.3060698655920078e-07, Final Batch Loss: 1.0771884006999244e-07\n",
      "Epoch 4769, Loss: 1.374966046796544e-06, Final Batch Loss: 2.1687267803827126e-07\n",
      "Epoch 4770, Loss: 0.00010005952697156317, Final Batch Loss: 6.864914894322283e-07\n",
      "Epoch 4771, Loss: 1.0874145539574442e-07, Final Batch Loss: 5.745024456160763e-09\n",
      "Epoch 4772, Loss: 5.917562759805151e-07, Final Batch Loss: 4.21526806348993e-07\n",
      "Epoch 4773, Loss: 0.0013092349909129553, Final Batch Loss: 7.884736987762153e-07\n",
      "Epoch 4774, Loss: 2.6906414518634847e-07, Final Batch Loss: 3.303384232822282e-08\n",
      "Epoch 4775, Loss: 9.214760680720246e-06, Final Batch Loss: 1.3285308853028255e-07\n",
      "Epoch 4776, Loss: 1.890535151005679e-05, Final Batch Loss: 1.8614007785799913e-05\n",
      "Epoch 4777, Loss: 7.011195801709391e-08, Final Batch Loss: 6.391307749709085e-08\n",
      "Epoch 4778, Loss: 3.2144099577635643e-06, Final Batch Loss: 2.672282562343753e-06\n",
      "Epoch 4779, Loss: 0.00020270726417948026, Final Batch Loss: 2.9524484489229508e-05\n",
      "Epoch 4780, Loss: 3.2869945556512903e-06, Final Batch Loss: 3.23215840580815e-06\n",
      "Epoch 4781, Loss: 1.720878412214688e-06, Final Batch Loss: 3.877887522207857e-08\n",
      "Epoch 4782, Loss: 3.4524591114859504e-06, Final Batch Loss: 2.9012630875513423e-06\n",
      "Epoch 4783, Loss: 6.882843202049571e-07, Final Batch Loss: 6.563362831002451e-07\n",
      "Epoch 4784, Loss: 1.8218879699105628e-05, Final Batch Loss: 1.819551471271552e-05\n",
      "Epoch 4785, Loss: 5.732012198222947e-07, Final Batch Loss: 4.897555641036888e-07\n",
      "Epoch 4786, Loss: 1.7469172917117248e-06, Final Batch Loss: 8.638628514745506e-07\n",
      "Epoch 4787, Loss: 1.667550804995699e-05, Final Batch Loss: 1.3194137864047661e-05\n",
      "Epoch 4788, Loss: 9.17686719503763e-07, Final Batch Loss: 7.274311428773217e-07\n",
      "Epoch 4789, Loss: 4.915035809460733e-07, Final Batch Loss: 3.662449543639923e-08\n",
      "Epoch 4790, Loss: 6.054597108118287e-07, Final Batch Loss: 5.673127816407941e-07\n",
      "Epoch 4791, Loss: 2.4793102937792355e-05, Final Batch Loss: 4.021509880658414e-08\n",
      "Epoch 4792, Loss: 1.57602904948817e-07, Final Batch Loss: 6.175893929594167e-08\n",
      "Epoch 4793, Loss: 1.0328556896865848e-05, Final Batch Loss: 3.382323541245569e-07\n",
      "Epoch 4794, Loss: 4.291909343479006e-06, Final Batch Loss: 2.5852594731645695e-08\n",
      "Epoch 4795, Loss: 0.0009705915290396661, Final Batch Loss: 0.0009356365771964192\n",
      "Epoch 4796, Loss: 2.325536655689575e-06, Final Batch Loss: 2.276899522257736e-06\n",
      "Epoch 4797, Loss: 7.858412232053524e-07, Final Batch Loss: 1.8886510133597767e-07\n",
      "Epoch 4798, Loss: 6.292514598271737e-08, Final Batch Loss: 5.529575375362583e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4799, Loss: 6.047390108676609e-07, Final Batch Loss: 5.69453163734579e-07\n",
      "Epoch 4800, Loss: 0.0002512590355134847, Final Batch Loss: 5.026896232607214e-09\n",
      "Epoch 4801, Loss: 1.8408652294965577e-05, Final Batch Loss: 3.2235332128038863e-06\n",
      "Epoch 4802, Loss: 6.75423672191755e-05, Final Batch Loss: 6.588267569895834e-05\n",
      "Epoch 4803, Loss: 0.00523550559266539, Final Batch Loss: 9.622856111946021e-08\n",
      "Epoch 4804, Loss: 1.3835448839927267e-06, Final Batch Loss: 6.76444187774905e-07\n",
      "Epoch 4805, Loss: 1.5772347481401994e-06, Final Batch Loss: 1.5424257071572356e-06\n",
      "Epoch 4806, Loss: 4.0101118429447524e-05, Final Batch Loss: 2.76350874628406e-06\n",
      "Epoch 4807, Loss: 5.284153205309394e-05, Final Batch Loss: 5.274187424220145e-05\n",
      "Epoch 4808, Loss: 4.642029443857609e-05, Final Batch Loss: 1.0814524102897849e-06\n",
      "Epoch 4809, Loss: 2.7314363819641585e-06, Final Batch Loss: 1.994768354052212e-06\n",
      "Epoch 4810, Loss: 3.977061174964547e-05, Final Batch Loss: 3.0376583026736625e-07\n",
      "Epoch 4811, Loss: 9.960288830157538e-06, Final Batch Loss: 9.936446986102965e-06\n",
      "Epoch 4812, Loss: 0.0024692398452543785, Final Batch Loss: 0.0024680192582309246\n",
      "Epoch 4813, Loss: 4.2855153026266635e-07, Final Batch Loss: 2.6785841100718244e-07\n",
      "Epoch 4814, Loss: 5.343075173414036e-06, Final Batch Loss: 5.114673058415065e-06\n",
      "Epoch 4815, Loss: 8.11010991128569e-05, Final Batch Loss: 2.382339062023675e-06\n",
      "Epoch 4816, Loss: 4.463162667889264e-06, Final Batch Loss: 4.375424850877607e-06\n",
      "Epoch 4817, Loss: 8.62830182200014e-05, Final Batch Loss: 8.594638347858563e-05\n",
      "Epoch 4818, Loss: 7.00961578559145e-07, Final Batch Loss: 2.455959986491507e-07\n",
      "Epoch 4819, Loss: 4.754705628329248e-06, Final Batch Loss: 1.3284555961945443e-06\n",
      "Epoch 4820, Loss: 0.000415087040764206, Final Batch Loss: 2.2477239269846905e-07\n",
      "Epoch 4821, Loss: 1.7264903107161444e-07, Final Batch Loss: 6.822207154755233e-08\n",
      "Epoch 4822, Loss: 6.97926680004457e-05, Final Batch Loss: 2.5755032766028307e-05\n",
      "Epoch 4823, Loss: 1.241261676909744e-05, Final Batch Loss: 4.272755802503525e-07\n",
      "Epoch 4824, Loss: 8.232020036302856e-06, Final Batch Loss: 1.6006040368665708e-06\n",
      "Epoch 4825, Loss: 8.644957816272836e-07, Final Batch Loss: 6.965829157934422e-08\n",
      "Epoch 4826, Loss: 0.00044552974554790126, Final Batch Loss: 0.0004440073389559984\n",
      "Epoch 4827, Loss: 4.859117893829534e-06, Final Batch Loss: 3.90657646676118e-07\n",
      "Epoch 4828, Loss: 5.734046681027394e-06, Final Batch Loss: 4.604014065989759e-06\n",
      "Epoch 4829, Loss: 2.545864390413044e-06, Final Batch Loss: 2.5201152311637998e-06\n",
      "Epoch 4830, Loss: 8.077841584963608e-06, Final Batch Loss: 7.687318429816514e-06\n",
      "Epoch 4831, Loss: 3.435313237787341e-05, Final Batch Loss: 3.4117576433345675e-05\n",
      "Epoch 4832, Loss: 1.703509653339097e-07, Final Batch Loss: 8.976581966635422e-08\n",
      "Epoch 4833, Loss: 1.6423375086560554e-06, Final Batch Loss: 1.1273657491983613e-06\n",
      "Epoch 4834, Loss: 5.226005526992594e-06, Final Batch Loss: 4.945629825670039e-06\n",
      "Epoch 4835, Loss: 8.968503664164018e-06, Final Batch Loss: 4.021385962005297e-07\n",
      "Epoch 4836, Loss: 0.00034707837471614766, Final Batch Loss: 8.265240012406139e-07\n",
      "Epoch 4837, Loss: 8.872279977367725e-07, Final Batch Loss: 3.260214498368441e-07\n",
      "Epoch 4838, Loss: 4.1234537917489433e-07, Final Batch Loss: 3.231571810147216e-08\n",
      "Epoch 4839, Loss: 9.404203501617303e-05, Final Batch Loss: 3.885040314344224e-06\n",
      "Epoch 4840, Loss: 2.814430132502821e-05, Final Batch Loss: 2.7856296583195217e-05\n",
      "Epoch 4841, Loss: 1.058189752711769e-06, Final Batch Loss: 7.496828402508982e-07\n",
      "Epoch 4842, Loss: 0.00013518255582312122, Final Batch Loss: 4.184087447356433e-05\n",
      "Epoch 4843, Loss: 1.0769469781735097e-05, Final Batch Loss: 9.282771316065919e-06\n",
      "Epoch 4844, Loss: 0.0005635866474662521, Final Batch Loss: 0.0005635198904201388\n",
      "Epoch 4845, Loss: 2.1597536203898926e-06, Final Batch Loss: 1.8374172441326664e-06\n",
      "Epoch 4846, Loss: 0.00019233111743233167, Final Batch Loss: 0.00017984573787543923\n",
      "Epoch 4847, Loss: 1.3902740363391786e-06, Final Batch Loss: 9.859264764600084e-07\n",
      "Epoch 4848, Loss: 5.225371751294006e-06, Final Batch Loss: 5.47911440662574e-07\n",
      "Epoch 4849, Loss: 7.130752806006058e-07, Final Batch Loss: 4.732289085040975e-07\n",
      "Epoch 4850, Loss: 2.4755028391609812e-06, Final Batch Loss: 2.0220518308633473e-06\n",
      "Epoch 4851, Loss: 0.008583179293507825, Final Batch Loss: 2.0107561837789945e-08\n",
      "Epoch 4852, Loss: 2.87583367253319e-06, Final Batch Loss: 2.241664333269e-06\n",
      "Epoch 4853, Loss: 6.18270863395054e-07, Final Batch Loss: 6.111183097345929e-07\n",
      "Epoch 4854, Loss: 4.7148839527721975e-05, Final Batch Loss: 1.256715194131175e-07\n",
      "Epoch 4855, Loss: 6.150917641889464e-07, Final Batch Loss: 4.129167621158558e-07\n",
      "Epoch 4856, Loss: 1.3191164867976113e-05, Final Batch Loss: 1.7235066707144142e-08\n",
      "Epoch 4857, Loss: 7.770944284857251e-05, Final Batch Loss: 6.550278340000659e-05\n",
      "Epoch 4858, Loss: 5.513850354077476e-07, Final Batch Loss: 5.199138968237094e-07\n",
      "Epoch 4859, Loss: 0.01168795041065529, Final Batch Loss: 1.5080681592394285e-08\n",
      "Epoch 4860, Loss: 4.068838484272419e-05, Final Batch Loss: 2.19206071960798e-06\n",
      "Epoch 4861, Loss: 7.62483360006172e-07, Final Batch Loss: 2.1543833383930178e-08\n",
      "Epoch 4862, Loss: 1.0733613180491375e-06, Final Batch Loss: 2.5852068574749865e-07\n",
      "Epoch 4863, Loss: 3.5519055927579757e-06, Final Batch Loss: 1.8288843648406328e-06\n",
      "Epoch 4864, Loss: 0.000110087395910341, Final Batch Loss: 0.00010995960474247113\n",
      "Epoch 4865, Loss: 8.59924389118305e-06, Final Batch Loss: 2.5134475833965553e-08\n",
      "Epoch 4866, Loss: 9.4252678550788e-08, Final Batch Loss: 1.938944826918032e-08\n",
      "Epoch 4867, Loss: 1.29670645776514e-07, Final Batch Loss: 5.2423267504764226e-08\n",
      "Epoch 4868, Loss: 3.2004889476411336e-06, Final Batch Loss: 3.913672230737575e-07\n",
      "Epoch 4869, Loss: 0.0012285580742172897, Final Batch Loss: 3.442459274083376e-06\n",
      "Epoch 4870, Loss: 1.2701413822924223e-06, Final Batch Loss: 6.247691430871782e-08\n",
      "Epoch 4871, Loss: 3.705197374870295e-05, Final Batch Loss: 2.6929407681564044e-07\n",
      "Epoch 4872, Loss: 2.910313489934424e-05, Final Batch Loss: 1.0197366151487586e-07\n",
      "Epoch 4873, Loss: 7.05032125551952e-05, Final Batch Loss: 1.4567240214091726e-05\n",
      "Epoch 4874, Loss: 6.435553512318393e-08, Final Batch Loss: 5.529563296136075e-08\n",
      "Epoch 4875, Loss: 1.309918182812453e-07, Final Batch Loss: 8.473882218140716e-08\n",
      "Epoch 4876, Loss: 0.00011870328489749227, Final Batch Loss: 0.00011648562940536067\n",
      "Epoch 4877, Loss: 5.711121708884548e-08, Final Batch Loss: 3.231570389061744e-08\n",
      "Epoch 4878, Loss: 9.209939472842876e-06, Final Batch Loss: 4.308768897232085e-09\n",
      "Epoch 4879, Loss: 0.0003123035648968653, Final Batch Loss: 1.3541598491428886e-05\n",
      "Epoch 4880, Loss: 2.3008738310181798e-06, Final Batch Loss: 2.2064607492211508e-06\n",
      "Epoch 4881, Loss: 8.202524838907266e-06, Final Batch Loss: 7.554998319392325e-06\n",
      "Epoch 4882, Loss: 5.421960622697952e-06, Final Batch Loss: 4.5146207412471995e-06\n",
      "Epoch 4883, Loss: 6.3927839732969005e-06, Final Batch Loss: 4.818473939849355e-07\n",
      "Epoch 4884, Loss: 1.7724459127066439e-06, Final Batch Loss: 1.1130897803468542e-07\n",
      "Epoch 4885, Loss: 4.3039797645860745e-06, Final Batch Loss: 2.2261637866449746e-07\n",
      "Epoch 4886, Loss: 1.906589410793913e-07, Final Batch Loss: 4.0933262113185265e-08\n",
      "Epoch 4887, Loss: 5.50577317159906e-06, Final Batch Loss: 1.2926304471250205e-08\n",
      "Epoch 4888, Loss: 1.1958231738162794e-07, Final Batch Loss: 9.335629869156037e-08\n",
      "Epoch 4889, Loss: 3.2458296789883434e-05, Final Batch Loss: 3.016133476307914e-08\n",
      "Epoch 4890, Loss: 6.7374792706687e-05, Final Batch Loss: 2.640381353558041e-05\n",
      "Epoch 4891, Loss: 7.036247831138098e-05, Final Batch Loss: 6.994048453634605e-05\n",
      "Epoch 4892, Loss: 6.93771362909601e-05, Final Batch Loss: 6.936378485988826e-05\n",
      "Epoch 4893, Loss: 6.578861047046303e-05, Final Batch Loss: 4.926170618091419e-07\n",
      "Epoch 4894, Loss: 1.913977484946372e-06, Final Batch Loss: 3.762884261959698e-07\n",
      "Epoch 4895, Loss: 0.0001508477658518359, Final Batch Loss: 0.0001506622793385759\n",
      "Epoch 4896, Loss: 0.0020805499348099943, Final Batch Loss: 7.89940912682141e-09\n",
      "Epoch 4897, Loss: 1.0055063292213617e-05, Final Batch Loss: 6.104074401491744e-08\n",
      "Epoch 4898, Loss: 1.8199745532854195e-06, Final Batch Loss: 3.303381035379971e-08\n",
      "Epoch 4899, Loss: 5.904804197598423e-06, Final Batch Loss: 5.432762463897234e-06\n",
      "Epoch 4900, Loss: 2.0902673996125998e-06, Final Batch Loss: 6.4631522356251025e-09\n",
      "Epoch 4901, Loss: 1.8048554579763731e-06, Final Batch Loss: 1.1029954976038425e-06\n",
      "Epoch 4902, Loss: 3.3779484027718354e-06, Final Batch Loss: 2.2620706374709698e-07\n",
      "Epoch 4903, Loss: 8.415204092671047e-06, Final Batch Loss: 3.1395763926411746e-06\n",
      "Epoch 4904, Loss: 2.3180491552921012e-05, Final Batch Loss: 0.0\n",
      "Epoch 4905, Loss: 4.0347940455376374e-07, Final Batch Loss: 2.585229594842531e-07\n",
      "Epoch 4906, Loss: 4.672441946240724e-06, Final Batch Loss: 2.68448775386787e-06\n",
      "Epoch 4907, Loss: 4.709149266091117e-07, Final Batch Loss: 1.2998083320781006e-07\n",
      "Epoch 4908, Loss: 4.3468268273727517e-07, Final Batch Loss: 7.468515406117149e-08\n",
      "Epoch 4909, Loss: 6.624631396334735e-06, Final Batch Loss: 2.2710921712132404e-06\n",
      "Epoch 4910, Loss: 6.819983859429612e-05, Final Batch Loss: 6.813355867052451e-05\n",
      "Epoch 4911, Loss: 3.382660725037567e-05, Final Batch Loss: 2.651095564942807e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4912, Loss: 0.00020170689094811678, Final Batch Loss: 5.532157956622541e-06\n",
      "Epoch 4913, Loss: 4.029346808920309e-05, Final Batch Loss: 3.980949259130284e-05\n",
      "Epoch 4914, Loss: 0.0020159922050879686, Final Batch Loss: 1.2120602150389459e-05\n",
      "Epoch 4915, Loss: 5.949444364716783e-06, Final Batch Loss: 1.005378891250075e-08\n",
      "Epoch 4916, Loss: 0.0006903874885892947, Final Batch Loss: 1.0110519497175119e-06\n",
      "Epoch 4917, Loss: 1.1549115441766844e-06, Final Batch Loss: 8.114822946936329e-08\n",
      "Epoch 4918, Loss: 1.3904600315584048e-07, Final Batch Loss: 1.3141661270310578e-07\n",
      "Epoch 4919, Loss: 2.483444822587444e-05, Final Batch Loss: 8.258447792286461e-08\n",
      "Epoch 4920, Loss: 0.01102767602037602, Final Batch Loss: 0.011024422943592072\n",
      "Epoch 4921, Loss: 2.998628225725497e-07, Final Batch Loss: 4.3805673755059615e-08\n",
      "Epoch 4922, Loss: 3.899162024367797e-07, Final Batch Loss: 8.617498536978019e-08\n",
      "Epoch 4923, Loss: 5.936351087143521e-06, Final Batch Loss: 8.832925857404916e-08\n",
      "Epoch 4924, Loss: 3.7004116077099525e-05, Final Batch Loss: 7.181281347357071e-09\n",
      "Epoch 4925, Loss: 3.340388394512672e-05, Final Batch Loss: 2.6570715405682677e-08\n",
      "Epoch 4926, Loss: 7.355623736771122e-07, Final Batch Loss: 6.750041734449042e-07\n",
      "Epoch 4927, Loss: 4.109466715362942e-06, Final Batch Loss: 1.3285256272865809e-07\n",
      "Epoch 4928, Loss: 5.892665910778305e-08, Final Batch Loss: 9.335664685750089e-09\n",
      "Epoch 4929, Loss: 1.986788529251271e-07, Final Batch Loss: 1.9389451821894e-08\n",
      "Epoch 4930, Loss: 1.7477287705958133e-07, Final Batch Loss: 3.5906406736785357e-09\n",
      "Epoch 4931, Loss: 2.0665527834751174e-05, Final Batch Loss: 2.0554902221192606e-05\n",
      "Epoch 4932, Loss: 0.0026194984966423362, Final Batch Loss: 0.002506442368030548\n",
      "Epoch 4933, Loss: 1.5858479173402884e-05, Final Batch Loss: 1.357896735498798e-06\n",
      "Epoch 4934, Loss: 1.4307862006290861e-06, Final Batch Loss: 1.1490046247786267e-08\n",
      "Epoch 4935, Loss: 1.4362266824718972e-06, Final Batch Loss: 4.854489930039563e-07\n",
      "Epoch 4936, Loss: 5.641124376509765e-07, Final Batch Loss: 1.2926304471250205e-08\n",
      "Epoch 4937, Loss: 6.055218000255991e-05, Final Batch Loss: 2.8072763598174788e-05\n",
      "Epoch 4938, Loss: 0.00026716280513028323, Final Batch Loss: 0.00026600799174048007\n",
      "Epoch 4939, Loss: 9.372306870147895e-06, Final Batch Loss: 9.32843795453664e-06\n",
      "Epoch 4940, Loss: 1.5300149993180412e-05, Final Batch Loss: 5.960448490327508e-08\n",
      "Epoch 4941, Loss: 2.772241714410484e-05, Final Batch Loss: 2.080951162497513e-06\n",
      "Epoch 4942, Loss: 0.000178410999069456, Final Batch Loss: 6.125998334027827e-05\n",
      "Epoch 4943, Loss: 1.7260205034119736e-06, Final Batch Loss: 2.298007828471782e-08\n",
      "Epoch 4944, Loss: 4.703513423187644e-07, Final Batch Loss: 4.6892083105376514e-07\n",
      "Epoch 4945, Loss: 9.342856372995811e-07, Final Batch Loss: 1.1849088821236364e-07\n",
      "Epoch 4946, Loss: 1.3595631505936012e-05, Final Batch Loss: 1.3577511708717793e-05\n",
      "Epoch 4947, Loss: 4.348886672289609e-05, Final Batch Loss: 9.910094433962513e-08\n",
      "Epoch 4948, Loss: 1.904166282429287e-06, Final Batch Loss: 2.4487800942551985e-07\n",
      "Epoch 4949, Loss: 0.0002177283856781287, Final Batch Loss: 1.795319803932216e-08\n",
      "Epoch 4950, Loss: 3.408012617001077e-05, Final Batch Loss: 2.709090585995e-05\n",
      "Epoch 4951, Loss: 6.451871513490914e-06, Final Batch Loss: 4.9253262659476604e-06\n",
      "Epoch 4952, Loss: 2.9538178210941624e-05, Final Batch Loss: 1.2136334248680214e-07\n",
      "Epoch 4953, Loss: 6.942837296719517e-05, Final Batch Loss: 1.1065561693612835e-06\n",
      "Epoch 4954, Loss: 2.6465314388879335e-06, Final Batch Loss: 7.181282235535491e-10\n",
      "Epoch 4955, Loss: 4.216425821823577e-06, Final Batch Loss: 3.888847004418494e-06\n",
      "Epoch 4956, Loss: 1.3400608054325858e-06, Final Batch Loss: 5.256604254100239e-07\n",
      "Epoch 4957, Loss: 1.5964039334903646e-06, Final Batch Loss: 7.324516104745271e-07\n",
      "Epoch 4958, Loss: 6.626410051779885e-06, Final Batch Loss: 7.181281347357071e-09\n",
      "Epoch 4959, Loss: 0.00022640170575982665, Final Batch Loss: 0.00022626771533396095\n",
      "Epoch 4960, Loss: 2.0731753238578676e-06, Final Batch Loss: 1.3183880582801066e-06\n",
      "Epoch 4961, Loss: 2.1077489442689057e-07, Final Batch Loss: 4.308768453142875e-09\n",
      "Epoch 4962, Loss: 0.00023803350268281065, Final Batch Loss: 1.8181563063990325e-06\n",
      "Epoch 4963, Loss: 9.068172460047208e-06, Final Batch Loss: 3.0591678523705923e-07\n",
      "Epoch 4964, Loss: 4.568378699332243e-06, Final Batch Loss: 1.4037893834029092e-06\n",
      "Epoch 4965, Loss: 0.00026281513419235125, Final Batch Loss: 0.0002264026552438736\n",
      "Epoch 4966, Loss: 4.834111169316202e-05, Final Batch Loss: 4.057350508901436e-07\n",
      "Epoch 4967, Loss: 0.0001395584040437825, Final Batch Loss: 0.00010236624075332657\n",
      "Epoch 4968, Loss: 1.3998812899984614e-06, Final Batch Loss: 2.0107568943217302e-08\n",
      "Epoch 4969, Loss: 2.0410991114161448e-05, Final Batch Loss: 2.038428829109762e-05\n",
      "Epoch 4970, Loss: 3.5144709045198397e-06, Final Batch Loss: 5.033942898080568e-07\n",
      "Epoch 4971, Loss: 1.270026785959999e-06, Final Batch Loss: 2.0251113141966925e-07\n",
      "Epoch 4972, Loss: 7.706116502959048e-05, Final Batch Loss: 7.64026990509592e-05\n",
      "Epoch 4973, Loss: 8.587666116000037e-06, Final Batch Loss: 7.644591278221924e-06\n",
      "Epoch 4974, Loss: 1.5724860418231401e-06, Final Batch Loss: 1.315475742558192e-06\n",
      "Epoch 4975, Loss: 0.00010064733578474261, Final Batch Loss: 4.792242179973982e-05\n",
      "Epoch 4976, Loss: 2.70455849715745e-06, Final Batch Loss: 2.691683903321973e-06\n",
      "Epoch 4977, Loss: 4.368494346351781e-05, Final Batch Loss: 1.2998070531011763e-07\n",
      "Epoch 4978, Loss: 9.753394443201557e-07, Final Batch Loss: 6.463151347446683e-09\n",
      "Epoch 4979, Loss: 4.0715493252463375e-06, Final Batch Loss: 4.061058916704496e-06\n",
      "Epoch 4980, Loss: 9.6484661882279e-07, Final Batch Loss: 3.5906408957231406e-09\n",
      "Epoch 4981, Loss: 3.1458772582482197e-06, Final Batch Loss: 5.701796226276201e-07\n",
      "Epoch 4982, Loss: 4.393542985781096e-05, Final Batch Loss: 2.639100785017945e-05\n",
      "Epoch 4983, Loss: 0.00011824908688140567, Final Batch Loss: 0.00011322795762680471\n",
      "Epoch 4984, Loss: 8.867701826176244e-07, Final Batch Loss: 8.653125291857577e-07\n",
      "Epoch 4985, Loss: 5.506579822167623e-05, Final Batch Loss: 5.489318573381752e-05\n",
      "Epoch 4986, Loss: 2.2587808643947938e-05, Final Batch Loss: 2.0872396362392465e-06\n",
      "Epoch 4987, Loss: 7.861086143634566e-05, Final Batch Loss: 7.828327943570912e-05\n",
      "Epoch 4988, Loss: 3.7636101968274716e-06, Final Batch Loss: 1.938944826918032e-08\n",
      "Epoch 4989, Loss: 1.3344029127893009e-05, Final Batch Loss: 1.9532961914592306e-07\n",
      "Epoch 4990, Loss: 1.7232829492286328e-06, Final Batch Loss: 9.838323933308857e-08\n",
      "Epoch 4991, Loss: 8.193646226573037e-05, Final Batch Loss: 7.463458314305171e-05\n",
      "Epoch 4992, Loss: 0.00010202256152069822, Final Batch Loss: 3.6120826507612946e-07\n",
      "Epoch 4993, Loss: 2.5893751853800495e-07, Final Batch Loss: 6.391326223820215e-08\n",
      "Epoch 4994, Loss: 0.00012701763787958953, Final Batch Loss: 0.00012660757056437433\n",
      "Epoch 4995, Loss: 6.844540848760516e-05, Final Batch Loss: 6.733356713084504e-05\n",
      "Epoch 4996, Loss: 2.3747011994146305e-05, Final Batch Loss: 8.545192144993052e-07\n",
      "Epoch 4997, Loss: 3.71828510310479e-05, Final Batch Loss: 3.682952592498623e-05\n",
      "Epoch 4998, Loss: 3.129427824433151e-06, Final Batch Loss: 4.524193286670197e-08\n",
      "Epoch 4999, Loss: 1.1273883657736405e-06, Final Batch Loss: 1.0649229125192505e-06\n",
      "Epoch 5000, Loss: 0.0010296867694705725, Final Batch Loss: 0.0006635509198531508\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 1 18  0]\n",
      " [ 0  0 39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.941     1.000     0.970        16\n",
      "           1      1.000     0.947     0.973        19\n",
      "           2      1.000     1.000     1.000        39\n",
      "\n",
      "    accuracy                          0.986        74\n",
      "   macro avg      0.980     0.982     0.981        74\n",
      "weighted avg      0.987     0.986     0.987        74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../../saved_models/UCI 3 Label Classifier Group 4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
