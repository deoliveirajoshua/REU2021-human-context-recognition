{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '125 tBodyGyro-std()-Y',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '138 tBodyGyro-energy()-Y',\n",
    " '165 tBodyGyroJerk-std()-Y',\n",
    " '168 tBodyGyroJerk-mad()-Y',\n",
    " '178 tBodyGyroJerk-energy()-Y',\n",
    " '181 tBodyGyroJerk-iqr()-Y',\n",
    " '425 fBodyGyro-mean()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '431 fBodyGyro-mad()-Y',\n",
    " '441 fBodyGyro-energy()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '478 fBodyGyro-bandsEnergy()-25,32',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '204 tBodyAccMag-max()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '217 tGravityAccMag-max()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '275 fBodyAcc-max()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '506 fBodyAccMag-max()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 9)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [23, 25, 27]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.6581971645355225, Final Batch Loss: 2.3276689052581787\n",
      "Epoch 2, Loss: 4.636362552642822, Final Batch Loss: 2.3187096118927\n",
      "Epoch 3, Loss: 4.621701717376709, Final Batch Loss: 2.312567710876465\n",
      "Epoch 4, Loss: 4.596620321273804, Final Batch Loss: 2.298973560333252\n",
      "Epoch 5, Loss: 4.567766427993774, Final Batch Loss: 2.275578022003174\n",
      "Epoch 6, Loss: 4.546075820922852, Final Batch Loss: 2.2594542503356934\n",
      "Epoch 7, Loss: 4.528770446777344, Final Batch Loss: 2.26294207572937\n",
      "Epoch 8, Loss: 4.51008415222168, Final Batch Loss: 2.2530200481414795\n",
      "Epoch 9, Loss: 4.481331825256348, Final Batch Loss: 2.2376646995544434\n",
      "Epoch 10, Loss: 4.456157922744751, Final Batch Loss: 2.213451623916626\n",
      "Epoch 11, Loss: 4.436905860900879, Final Batch Loss: 2.215338706970215\n",
      "Epoch 12, Loss: 4.410337924957275, Final Batch Loss: 2.210038185119629\n",
      "Epoch 13, Loss: 4.387431621551514, Final Batch Loss: 2.1917552947998047\n",
      "Epoch 14, Loss: 4.3548924922943115, Final Batch Loss: 2.163865089416504\n",
      "Epoch 15, Loss: 4.323284387588501, Final Batch Loss: 2.1692018508911133\n",
      "Epoch 16, Loss: 4.283111810684204, Final Batch Loss: 2.1321094036102295\n",
      "Epoch 17, Loss: 4.249130725860596, Final Batch Loss: 2.128971815109253\n",
      "Epoch 18, Loss: 4.198678255081177, Final Batch Loss: 2.120339870452881\n",
      "Epoch 19, Loss: 4.144310235977173, Final Batch Loss: 2.061825752258301\n",
      "Epoch 20, Loss: 4.084560871124268, Final Batch Loss: 2.0366735458374023\n",
      "Epoch 21, Loss: 4.018992900848389, Final Batch Loss: 1.9961674213409424\n",
      "Epoch 22, Loss: 3.949876308441162, Final Batch Loss: 1.9664398431777954\n",
      "Epoch 23, Loss: 3.885443329811096, Final Batch Loss: 1.9393261671066284\n",
      "Epoch 24, Loss: 3.8051127195358276, Final Batch Loss: 1.9078487157821655\n",
      "Epoch 25, Loss: 3.7294498682022095, Final Batch Loss: 1.8255970478057861\n",
      "Epoch 26, Loss: 3.643190383911133, Final Batch Loss: 1.7715532779693604\n",
      "Epoch 27, Loss: 3.5411133766174316, Final Batch Loss: 1.7677620649337769\n",
      "Epoch 28, Loss: 3.443459391593933, Final Batch Loss: 1.757917881011963\n",
      "Epoch 29, Loss: 3.341882824897766, Final Batch Loss: 1.6273770332336426\n",
      "Epoch 30, Loss: 3.2308582067489624, Final Batch Loss: 1.6089504957199097\n",
      "Epoch 31, Loss: 3.1762335300445557, Final Batch Loss: 1.517715573310852\n",
      "Epoch 32, Loss: 3.094764471054077, Final Batch Loss: 1.520074725151062\n",
      "Epoch 33, Loss: 3.0023412704467773, Final Batch Loss: 1.4860795736312866\n",
      "Epoch 34, Loss: 2.93370521068573, Final Batch Loss: 1.457115888595581\n",
      "Epoch 35, Loss: 2.848307490348816, Final Batch Loss: 1.4204821586608887\n",
      "Epoch 36, Loss: 2.809816598892212, Final Batch Loss: 1.4478036165237427\n",
      "Epoch 37, Loss: 2.7256808280944824, Final Batch Loss: 1.3165051937103271\n",
      "Epoch 38, Loss: 2.7023978233337402, Final Batch Loss: 1.3750144243240356\n",
      "Epoch 39, Loss: 2.5975770950317383, Final Batch Loss: 1.2585220336914062\n",
      "Epoch 40, Loss: 2.5718718767166138, Final Batch Loss: 1.2736055850982666\n",
      "Epoch 41, Loss: 2.488874912261963, Final Batch Loss: 1.2114837169647217\n",
      "Epoch 42, Loss: 2.467413544654846, Final Batch Loss: 1.2281250953674316\n",
      "Epoch 43, Loss: 2.4148740768432617, Final Batch Loss: 1.2271901369094849\n",
      "Epoch 44, Loss: 2.3671480417251587, Final Batch Loss: 1.1713711023330688\n",
      "Epoch 45, Loss: 2.2899069786071777, Final Batch Loss: 1.168624997138977\n",
      "Epoch 46, Loss: 2.2332379817962646, Final Batch Loss: 1.0899852514266968\n",
      "Epoch 47, Loss: 2.1485953330993652, Final Batch Loss: 1.0509792566299438\n",
      "Epoch 48, Loss: 2.0621449947357178, Final Batch Loss: 0.994968056678772\n",
      "Epoch 49, Loss: 1.9962748289108276, Final Batch Loss: 0.9842289686203003\n",
      "Epoch 50, Loss: 1.9184579849243164, Final Batch Loss: 0.9772747159004211\n",
      "Epoch 51, Loss: 1.8722501397132874, Final Batch Loss: 0.9591318964958191\n",
      "Epoch 52, Loss: 1.7347863912582397, Final Batch Loss: 0.8496863842010498\n",
      "Epoch 53, Loss: 1.603363037109375, Final Batch Loss: 0.7987822890281677\n",
      "Epoch 54, Loss: 1.5289570689201355, Final Batch Loss: 0.7446445822715759\n",
      "Epoch 55, Loss: 1.434967279434204, Final Batch Loss: 0.7050100564956665\n",
      "Epoch 56, Loss: 1.411660611629486, Final Batch Loss: 0.6861711144447327\n",
      "Epoch 57, Loss: 1.3880582451820374, Final Batch Loss: 0.6612560749053955\n",
      "Epoch 58, Loss: 1.2960630655288696, Final Batch Loss: 0.6598199605941772\n",
      "Epoch 59, Loss: 1.2543416023254395, Final Batch Loss: 0.6018953919410706\n",
      "Epoch 60, Loss: 1.174176573753357, Final Batch Loss: 0.5805699825286865\n",
      "Epoch 61, Loss: 1.2378171682357788, Final Batch Loss: 0.6390185356140137\n",
      "Epoch 62, Loss: 1.214698851108551, Final Batch Loss: 0.6170123815536499\n",
      "Epoch 63, Loss: 1.064144492149353, Final Batch Loss: 0.5470845699310303\n",
      "Epoch 64, Loss: 1.0899840593338013, Final Batch Loss: 0.5299628376960754\n",
      "Epoch 65, Loss: 1.1241150498390198, Final Batch Loss: 0.5678122639656067\n",
      "Epoch 66, Loss: 1.08237624168396, Final Batch Loss: 0.5297108292579651\n",
      "Epoch 67, Loss: 1.0297051072120667, Final Batch Loss: 0.516753613948822\n",
      "Epoch 68, Loss: 1.0313931703567505, Final Batch Loss: 0.5064347982406616\n",
      "Epoch 69, Loss: 1.0113236010074615, Final Batch Loss: 0.47189411520957947\n",
      "Epoch 70, Loss: 0.9434822499752045, Final Batch Loss: 0.43830206990242004\n",
      "Epoch 71, Loss: 0.9418867230415344, Final Batch Loss: 0.4842183291912079\n",
      "Epoch 72, Loss: 0.9377816319465637, Final Batch Loss: 0.4178358316421509\n",
      "Epoch 73, Loss: 0.962130606174469, Final Batch Loss: 0.46836793422698975\n",
      "Epoch 74, Loss: 0.9634057879447937, Final Batch Loss: 0.4820984899997711\n",
      "Epoch 75, Loss: 0.957605391740799, Final Batch Loss: 0.5062116980552673\n",
      "Epoch 76, Loss: 0.9284097254276276, Final Batch Loss: 0.47469955682754517\n",
      "Epoch 77, Loss: 0.9618388116359711, Final Batch Loss: 0.4835423529148102\n",
      "Epoch 78, Loss: 0.8801522552967072, Final Batch Loss: 0.4120771884918213\n",
      "Epoch 79, Loss: 0.8825961053371429, Final Batch Loss: 0.45896220207214355\n",
      "Epoch 80, Loss: 0.8494322299957275, Final Batch Loss: 0.4282873272895813\n",
      "Epoch 81, Loss: 0.8723203837871552, Final Batch Loss: 0.46104446053504944\n",
      "Epoch 82, Loss: 0.8651196658611298, Final Batch Loss: 0.4331029951572418\n",
      "Epoch 83, Loss: 0.8808659017086029, Final Batch Loss: 0.3910653591156006\n",
      "Epoch 84, Loss: 0.8308218717575073, Final Batch Loss: 0.42580315470695496\n",
      "Epoch 85, Loss: 0.8154974579811096, Final Batch Loss: 0.4249841570854187\n",
      "Epoch 86, Loss: 0.8286802172660828, Final Batch Loss: 0.4091128706932068\n",
      "Epoch 87, Loss: 0.8423947989940643, Final Batch Loss: 0.4665778875350952\n",
      "Epoch 88, Loss: 0.7874171733856201, Final Batch Loss: 0.41444888710975647\n",
      "Epoch 89, Loss: 0.8116895854473114, Final Batch Loss: 0.4232754707336426\n",
      "Epoch 90, Loss: 0.839611291885376, Final Batch Loss: 0.4283313751220703\n",
      "Epoch 91, Loss: 0.7843056917190552, Final Batch Loss: 0.3806445896625519\n",
      "Epoch 92, Loss: 0.8058644533157349, Final Batch Loss: 0.38682249188423157\n",
      "Epoch 93, Loss: 0.8034304976463318, Final Batch Loss: 0.4172477424144745\n",
      "Epoch 94, Loss: 0.7868084907531738, Final Batch Loss: 0.3933529257774353\n",
      "Epoch 95, Loss: 0.7551790177822113, Final Batch Loss: 0.37558677792549133\n",
      "Epoch 96, Loss: 0.8067609369754791, Final Batch Loss: 0.3536006808280945\n",
      "Epoch 97, Loss: 0.7276871204376221, Final Batch Loss: 0.3597715198993683\n",
      "Epoch 98, Loss: 0.7363508641719818, Final Batch Loss: 0.36317840218544006\n",
      "Epoch 99, Loss: 0.717237263917923, Final Batch Loss: 0.40104058384895325\n",
      "Epoch 100, Loss: 0.6881158351898193, Final Batch Loss: 0.3555487096309662\n",
      "Epoch 101, Loss: 0.684794157743454, Final Batch Loss: 0.34591948986053467\n",
      "Epoch 102, Loss: 0.6608120501041412, Final Batch Loss: 0.2918298840522766\n",
      "Epoch 103, Loss: 0.6416010856628418, Final Batch Loss: 0.32606241106987\n",
      "Epoch 104, Loss: 0.6335514187812805, Final Batch Loss: 0.34119218587875366\n",
      "Epoch 105, Loss: 0.6585240066051483, Final Batch Loss: 0.3068696856498718\n",
      "Epoch 106, Loss: 0.622796893119812, Final Batch Loss: 0.33414673805236816\n",
      "Epoch 107, Loss: 0.6718404293060303, Final Batch Loss: 0.342981219291687\n",
      "Epoch 108, Loss: 0.5606045126914978, Final Batch Loss: 0.25700604915618896\n",
      "Epoch 109, Loss: 0.538961261510849, Final Batch Loss: 0.2609879970550537\n",
      "Epoch 110, Loss: 0.5380754470825195, Final Batch Loss: 0.22995489835739136\n",
      "Epoch 111, Loss: 0.5178537964820862, Final Batch Loss: 0.2830062210559845\n",
      "Epoch 112, Loss: 0.5414084792137146, Final Batch Loss: 0.24551919102668762\n",
      "Epoch 113, Loss: 0.47872763872146606, Final Batch Loss: 0.24998460710048676\n",
      "Epoch 114, Loss: 0.5613934695720673, Final Batch Loss: 0.2752370536327362\n",
      "Epoch 115, Loss: 0.47733570635318756, Final Batch Loss: 0.23600563406944275\n",
      "Epoch 116, Loss: 0.4742759019136429, Final Batch Loss: 0.21213991940021515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117, Loss: 0.41146180033683777, Final Batch Loss: 0.20727378129959106\n",
      "Epoch 118, Loss: 0.42499756813049316, Final Batch Loss: 0.20774629712104797\n",
      "Epoch 119, Loss: 0.41605985164642334, Final Batch Loss: 0.20761975646018982\n",
      "Epoch 120, Loss: 0.45146577060222626, Final Batch Loss: 0.22076736390590668\n",
      "Epoch 121, Loss: 0.4088220000267029, Final Batch Loss: 0.20533987879753113\n",
      "Epoch 122, Loss: 0.39419645071029663, Final Batch Loss: 0.19950512051582336\n",
      "Epoch 123, Loss: 0.4453068971633911, Final Batch Loss: 0.2251034677028656\n",
      "Epoch 124, Loss: 0.40099678933620453, Final Batch Loss: 0.20903867483139038\n",
      "Epoch 125, Loss: 0.3641014099121094, Final Batch Loss: 0.16491347551345825\n",
      "Epoch 126, Loss: 0.3813464045524597, Final Batch Loss: 0.21783749759197235\n",
      "Epoch 127, Loss: 0.2928570359945297, Final Batch Loss: 0.14866508543491364\n",
      "Epoch 128, Loss: 0.3168323189020157, Final Batch Loss: 0.1519295573234558\n",
      "Epoch 129, Loss: 0.3635846823453903, Final Batch Loss: 0.1798103004693985\n",
      "Epoch 130, Loss: 0.2790237292647362, Final Batch Loss: 0.16235196590423584\n",
      "Epoch 131, Loss: 0.32235395908355713, Final Batch Loss: 0.143588125705719\n",
      "Epoch 132, Loss: 0.3089563548564911, Final Batch Loss: 0.12260793149471283\n",
      "Epoch 133, Loss: 0.29451456665992737, Final Batch Loss: 0.1497822403907776\n",
      "Epoch 134, Loss: 0.2782755047082901, Final Batch Loss: 0.1586104929447174\n",
      "Epoch 135, Loss: 0.26895981281995773, Final Batch Loss: 0.11341347545385361\n",
      "Epoch 136, Loss: 0.2947999835014343, Final Batch Loss: 0.16723375022411346\n",
      "Epoch 137, Loss: 0.29709190130233765, Final Batch Loss: 0.16406333446502686\n",
      "Epoch 138, Loss: 0.22320092469453812, Final Batch Loss: 0.09219614416360855\n",
      "Epoch 139, Loss: 0.2658529579639435, Final Batch Loss: 0.07711395621299744\n",
      "Epoch 140, Loss: 0.2825137674808502, Final Batch Loss: 0.14707772433757782\n",
      "Epoch 141, Loss: 0.2925660014152527, Final Batch Loss: 0.15109817683696747\n",
      "Epoch 142, Loss: 0.27734000235795975, Final Batch Loss: 0.15528258681297302\n",
      "Epoch 143, Loss: 0.22361759841442108, Final Batch Loss: 0.10538503527641296\n",
      "Epoch 144, Loss: 0.2152208685874939, Final Batch Loss: 0.12839259207248688\n",
      "Epoch 145, Loss: 0.26210346817970276, Final Batch Loss: 0.13549615442752838\n",
      "Epoch 146, Loss: 0.2501337304711342, Final Batch Loss: 0.11836300045251846\n",
      "Epoch 147, Loss: 0.251085489988327, Final Batch Loss: 0.11712752282619476\n",
      "Epoch 148, Loss: 0.2319280430674553, Final Batch Loss: 0.1391623467206955\n",
      "Epoch 149, Loss: 0.32116930186748505, Final Batch Loss: 0.17437973618507385\n",
      "Epoch 150, Loss: 0.2447134107351303, Final Batch Loss: 0.11060558259487152\n",
      "Epoch 151, Loss: 0.2261350005865097, Final Batch Loss: 0.10158589482307434\n",
      "Epoch 152, Loss: 0.2635098919272423, Final Batch Loss: 0.13956034183502197\n",
      "Epoch 153, Loss: 0.2336360067129135, Final Batch Loss: 0.09377467632293701\n",
      "Epoch 154, Loss: 0.20364131033420563, Final Batch Loss: 0.1136469691991806\n",
      "Epoch 155, Loss: 0.1883394569158554, Final Batch Loss: 0.09827940911054611\n",
      "Epoch 156, Loss: 0.21251272410154343, Final Batch Loss: 0.1306847184896469\n",
      "Epoch 157, Loss: 0.1857641413807869, Final Batch Loss: 0.0792432427406311\n",
      "Epoch 158, Loss: 0.1937347650527954, Final Batch Loss: 0.06300489604473114\n",
      "Epoch 159, Loss: 0.24506986141204834, Final Batch Loss: 0.13398177921772003\n",
      "Epoch 160, Loss: 0.22418182343244553, Final Batch Loss: 0.089060939848423\n",
      "Epoch 161, Loss: 0.1994185969233513, Final Batch Loss: 0.09835444390773773\n",
      "Epoch 162, Loss: 0.16435810178518295, Final Batch Loss: 0.10362741351127625\n",
      "Epoch 163, Loss: 0.21845059096813202, Final Batch Loss: 0.08290186524391174\n",
      "Epoch 164, Loss: 0.18654938787221909, Final Batch Loss: 0.06751585751771927\n",
      "Epoch 165, Loss: 0.20048139244318008, Final Batch Loss: 0.08902960270643234\n",
      "Epoch 166, Loss: 0.1614793911576271, Final Batch Loss: 0.08896321058273315\n",
      "Epoch 167, Loss: 0.1990804448723793, Final Batch Loss: 0.09124305099248886\n",
      "Epoch 168, Loss: 0.19801852107048035, Final Batch Loss: 0.11458886414766312\n",
      "Epoch 169, Loss: 0.21031202375888824, Final Batch Loss: 0.09854312986135483\n",
      "Epoch 170, Loss: 0.15292389690876007, Final Batch Loss: 0.06223125010728836\n",
      "Epoch 171, Loss: 0.15381748229265213, Final Batch Loss: 0.048921823501586914\n",
      "Epoch 172, Loss: 0.1641285941004753, Final Batch Loss: 0.06802941113710403\n",
      "Epoch 173, Loss: 0.17675966769456863, Final Batch Loss: 0.09049341827630997\n",
      "Epoch 174, Loss: 0.2124505415558815, Final Batch Loss: 0.11420902609825134\n",
      "Epoch 175, Loss: 0.1819474771618843, Final Batch Loss: 0.07448969036340714\n",
      "Epoch 176, Loss: 0.18602585047483444, Final Batch Loss: 0.06725461781024933\n",
      "Epoch 177, Loss: 0.131094329059124, Final Batch Loss: 0.06348618865013123\n",
      "Epoch 178, Loss: 0.14481139183044434, Final Batch Loss: 0.08588233590126038\n",
      "Epoch 179, Loss: 0.12741965800523758, Final Batch Loss: 0.061785802245140076\n",
      "Epoch 180, Loss: 0.12653398886322975, Final Batch Loss: 0.058068614453077316\n",
      "Epoch 181, Loss: 0.1467648595571518, Final Batch Loss: 0.04875659942626953\n",
      "Epoch 182, Loss: 0.1141742654144764, Final Batch Loss: 0.06600943952798843\n",
      "Epoch 183, Loss: 0.17128518223762512, Final Batch Loss: 0.04716450721025467\n",
      "Epoch 184, Loss: 0.1544078290462494, Final Batch Loss: 0.09460722655057907\n",
      "Epoch 185, Loss: 0.22454942762851715, Final Batch Loss: 0.09795920550823212\n",
      "Epoch 186, Loss: 0.19288459420204163, Final Batch Loss: 0.09760463237762451\n",
      "Epoch 187, Loss: 0.17763682454824448, Final Batch Loss: 0.10883324593305588\n",
      "Epoch 188, Loss: 0.10382506251335144, Final Batch Loss: 0.042352624237537384\n",
      "Epoch 189, Loss: 0.13663091510534286, Final Batch Loss: 0.05262606590986252\n",
      "Epoch 190, Loss: 0.14105866849422455, Final Batch Loss: 0.07156646996736526\n",
      "Epoch 191, Loss: 0.14928161352872849, Final Batch Loss: 0.0769987553358078\n",
      "Epoch 192, Loss: 0.1152508296072483, Final Batch Loss: 0.045057933777570724\n",
      "Epoch 193, Loss: 0.13004424795508385, Final Batch Loss: 0.034377116709947586\n",
      "Epoch 194, Loss: 0.139109805226326, Final Batch Loss: 0.06374243646860123\n",
      "Epoch 195, Loss: 0.13189328461885452, Final Batch Loss: 0.03833731263875961\n",
      "Epoch 196, Loss: 0.10286171734333038, Final Batch Loss: 0.04547036439180374\n",
      "Epoch 197, Loss: 0.11486021429300308, Final Batch Loss: 0.052130527794361115\n",
      "Epoch 198, Loss: 0.16818084567785263, Final Batch Loss: 0.10534073412418365\n",
      "Epoch 199, Loss: 0.1488453410565853, Final Batch Loss: 0.09041687101125717\n",
      "Epoch 200, Loss: 0.10372868552803993, Final Batch Loss: 0.04030207172036171\n",
      "Epoch 201, Loss: 0.11374589800834656, Final Batch Loss: 0.05657953396439552\n",
      "Epoch 202, Loss: 0.10426236316561699, Final Batch Loss: 0.04249362275004387\n",
      "Epoch 203, Loss: 0.15474289283156395, Final Batch Loss: 0.09226315468549728\n",
      "Epoch 204, Loss: 0.09831657260656357, Final Batch Loss: 0.055894121527671814\n",
      "Epoch 205, Loss: 0.12812557071447372, Final Batch Loss: 0.05707333981990814\n",
      "Epoch 206, Loss: 0.13284847512841225, Final Batch Loss: 0.056127216666936874\n",
      "Epoch 207, Loss: 0.09536857903003693, Final Batch Loss: 0.04279721900820732\n",
      "Epoch 208, Loss: 0.07695036008954048, Final Batch Loss: 0.04560309275984764\n",
      "Epoch 209, Loss: 0.15222042053937912, Final Batch Loss: 0.0831436812877655\n",
      "Epoch 210, Loss: 0.14243876188993454, Final Batch Loss: 0.08097582310438156\n",
      "Epoch 211, Loss: 0.10275283083319664, Final Batch Loss: 0.059836577624082565\n",
      "Epoch 212, Loss: 0.1255948171019554, Final Batch Loss: 0.06297732144594193\n",
      "Epoch 213, Loss: 0.1137406975030899, Final Batch Loss: 0.04821719974279404\n",
      "Epoch 214, Loss: 0.12645722180604935, Final Batch Loss: 0.054683126509189606\n",
      "Epoch 215, Loss: 0.09736397489905357, Final Batch Loss: 0.06474006921052933\n",
      "Epoch 216, Loss: 0.12695008143782616, Final Batch Loss: 0.07641983032226562\n",
      "Epoch 217, Loss: 0.09092603623867035, Final Batch Loss: 0.04469133913516998\n",
      "Epoch 218, Loss: 0.12121204286813736, Final Batch Loss: 0.07103034108877182\n",
      "Epoch 219, Loss: 0.11243176087737083, Final Batch Loss: 0.024943727999925613\n",
      "Epoch 220, Loss: 0.08934828825294971, Final Batch Loss: 0.024669187143445015\n",
      "Epoch 221, Loss: 0.11521681770682335, Final Batch Loss: 0.07612939178943634\n",
      "Epoch 222, Loss: 0.06363986432552338, Final Batch Loss: 0.03880210220813751\n",
      "Epoch 223, Loss: 0.10630681365728378, Final Batch Loss: 0.0631861463189125\n",
      "Epoch 224, Loss: 0.09756708145141602, Final Batch Loss: 0.038212794810533524\n",
      "Epoch 225, Loss: 0.12270811200141907, Final Batch Loss: 0.06936152279376984\n",
      "Epoch 226, Loss: 0.05649474076926708, Final Batch Loss: 0.030142271891236305\n",
      "Epoch 227, Loss: 0.10545230656862259, Final Batch Loss: 0.05420142412185669\n",
      "Epoch 228, Loss: 0.10148054361343384, Final Batch Loss: 0.059685397893190384\n",
      "Epoch 229, Loss: 0.13278083875775337, Final Batch Loss: 0.08879861235618591\n",
      "Epoch 230, Loss: 0.09130934998393059, Final Batch Loss: 0.02465910091996193\n",
      "Epoch 231, Loss: 0.08478187769651413, Final Batch Loss: 0.02953420579433441\n",
      "Epoch 232, Loss: 0.12472378090023994, Final Batch Loss: 0.09268825501203537\n",
      "Epoch 233, Loss: 0.09797145426273346, Final Batch Loss: 0.06419794261455536\n",
      "Epoch 234, Loss: 0.11901591718196869, Final Batch Loss: 0.06132708117365837\n",
      "Epoch 235, Loss: 0.06448280066251755, Final Batch Loss: 0.03313760459423065\n",
      "Epoch 236, Loss: 0.10782652348279953, Final Batch Loss: 0.060172419995069504\n",
      "Epoch 237, Loss: 0.09277868270874023, Final Batch Loss: 0.027736134827136993\n",
      "Epoch 238, Loss: 0.10638198629021645, Final Batch Loss: 0.06138215214014053\n",
      "Epoch 239, Loss: 0.08817343786358833, Final Batch Loss: 0.04169352352619171\n",
      "Epoch 240, Loss: 0.08316602557897568, Final Batch Loss: 0.03030475229024887\n",
      "Epoch 241, Loss: 0.11609949171543121, Final Batch Loss: 0.046431124210357666\n",
      "Epoch 242, Loss: 0.09601058065891266, Final Batch Loss: 0.055897973477840424\n",
      "Epoch 243, Loss: 0.15164245665073395, Final Batch Loss: 0.10548440366983414\n",
      "Epoch 244, Loss: 0.0680746603757143, Final Batch Loss: 0.04153278470039368\n",
      "Epoch 245, Loss: 0.07650554925203323, Final Batch Loss: 0.0403287336230278\n",
      "Epoch 246, Loss: 0.060303645208477974, Final Batch Loss: 0.036432668566703796\n",
      "Epoch 247, Loss: 0.04921174794435501, Final Batch Loss: 0.03228586167097092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248, Loss: 0.08290024660527706, Final Batch Loss: 0.061936136335134506\n",
      "Epoch 249, Loss: 0.08900962956249714, Final Batch Loss: 0.06152114272117615\n",
      "Epoch 250, Loss: 0.05852106213569641, Final Batch Loss: 0.020820636302232742\n",
      "Epoch 251, Loss: 0.09347428008913994, Final Batch Loss: 0.043929025530815125\n",
      "Epoch 252, Loss: 0.0715149324387312, Final Batch Loss: 0.023835795000195503\n",
      "Epoch 253, Loss: 0.07694831117987633, Final Batch Loss: 0.03770304098725319\n",
      "Epoch 254, Loss: 0.09392693266272545, Final Batch Loss: 0.058015406131744385\n",
      "Epoch 255, Loss: 0.06345197930932045, Final Batch Loss: 0.04607947915792465\n",
      "Epoch 256, Loss: 0.04766027256846428, Final Batch Loss: 0.014856413006782532\n",
      "Epoch 257, Loss: 0.07063003256917, Final Batch Loss: 0.01806177943944931\n",
      "Epoch 258, Loss: 0.06935320049524307, Final Batch Loss: 0.0379236601293087\n",
      "Epoch 259, Loss: 0.08663555607199669, Final Batch Loss: 0.045857105404138565\n",
      "Epoch 260, Loss: 0.075257976539433, Final Batch Loss: 0.014868863858282566\n",
      "Epoch 261, Loss: 0.06982224434614182, Final Batch Loss: 0.04910387843847275\n",
      "Epoch 262, Loss: 0.07491761073470116, Final Batch Loss: 0.03749891743063927\n",
      "Epoch 263, Loss: 0.06642702966928482, Final Batch Loss: 0.023987215012311935\n",
      "Epoch 264, Loss: 0.08795508369803429, Final Batch Loss: 0.0401499904692173\n",
      "Epoch 265, Loss: 0.08407151699066162, Final Batch Loss: 0.04265385493636131\n",
      "Epoch 266, Loss: 0.0870102122426033, Final Batch Loss: 0.046540845185518265\n",
      "Epoch 267, Loss: 0.11220085248351097, Final Batch Loss: 0.06323889642953873\n",
      "Epoch 268, Loss: 0.06087027117609978, Final Batch Loss: 0.034201882779598236\n",
      "Epoch 269, Loss: 0.06471897847950459, Final Batch Loss: 0.024173865094780922\n",
      "Epoch 270, Loss: 0.061190301552414894, Final Batch Loss: 0.03071555308997631\n",
      "Epoch 271, Loss: 0.07996369153261185, Final Batch Loss: 0.02130957320332527\n",
      "Epoch 272, Loss: 0.0738839078694582, Final Batch Loss: 0.028372658416628838\n",
      "Epoch 273, Loss: 0.11881685629487038, Final Batch Loss: 0.046353530138731\n",
      "Epoch 274, Loss: 0.0886869952082634, Final Batch Loss: 0.05112697556614876\n",
      "Epoch 275, Loss: 0.07533423788845539, Final Batch Loss: 0.05220497027039528\n",
      "Epoch 276, Loss: 0.05291517823934555, Final Batch Loss: 0.016183774918317795\n",
      "Epoch 277, Loss: 0.06994110159575939, Final Batch Loss: 0.02123691327869892\n",
      "Epoch 278, Loss: 0.06940150819718838, Final Batch Loss: 0.040470171719789505\n",
      "Epoch 279, Loss: 0.05089458264410496, Final Batch Loss: 0.04039623588323593\n",
      "Epoch 280, Loss: 0.08344600722193718, Final Batch Loss: 0.03959103673696518\n",
      "Epoch 281, Loss: 0.06031741760671139, Final Batch Loss: 0.03403715044260025\n",
      "Epoch 282, Loss: 0.05807512439787388, Final Batch Loss: 0.03766541928052902\n",
      "Epoch 283, Loss: 0.09045498445630074, Final Batch Loss: 0.0664336234331131\n",
      "Epoch 284, Loss: 0.07941525988280773, Final Batch Loss: 0.054937079548835754\n",
      "Epoch 285, Loss: 0.0505347540602088, Final Batch Loss: 0.015522274188697338\n",
      "Epoch 286, Loss: 0.06832938827574253, Final Batch Loss: 0.022454416379332542\n",
      "Epoch 287, Loss: 0.0625632219016552, Final Batch Loss: 0.042018454521894455\n",
      "Epoch 288, Loss: 0.07173441164195538, Final Batch Loss: 0.025346001610159874\n",
      "Epoch 289, Loss: 0.06551540829241276, Final Batch Loss: 0.04993096739053726\n",
      "Epoch 290, Loss: 0.08629221469163895, Final Batch Loss: 0.06346216797828674\n",
      "Epoch 291, Loss: 0.05796507187187672, Final Batch Loss: 0.03612859547138214\n",
      "Epoch 292, Loss: 0.059526349417865276, Final Batch Loss: 0.012489589862525463\n",
      "Epoch 293, Loss: 0.05779785290360451, Final Batch Loss: 0.01775820553302765\n",
      "Epoch 294, Loss: 0.059544408693909645, Final Batch Loss: 0.026860052719712257\n",
      "Epoch 295, Loss: 0.0866235475987196, Final Batch Loss: 0.06020190566778183\n",
      "Epoch 296, Loss: 0.05673234537243843, Final Batch Loss: 0.020988717675209045\n",
      "Epoch 297, Loss: 0.05759170651435852, Final Batch Loss: 0.02675584703683853\n",
      "Epoch 298, Loss: 0.07006046548485756, Final Batch Loss: 0.03920181468129158\n",
      "Epoch 299, Loss: 0.044378697872161865, Final Batch Loss: 0.019281331449747086\n",
      "Epoch 300, Loss: 0.08741324953734875, Final Batch Loss: 0.06761336326599121\n",
      "Epoch 301, Loss: 0.10041958466172218, Final Batch Loss: 0.04396561160683632\n",
      "Epoch 302, Loss: 0.050717974081635475, Final Batch Loss: 0.026821088045835495\n",
      "Epoch 303, Loss: 0.05996920354664326, Final Batch Loss: 0.031900983303785324\n",
      "Epoch 304, Loss: 0.08929290249943733, Final Batch Loss: 0.0459914430975914\n",
      "Epoch 305, Loss: 0.07428153976798058, Final Batch Loss: 0.04695958271622658\n",
      "Epoch 306, Loss: 0.07995590195059776, Final Batch Loss: 0.027377933263778687\n",
      "Epoch 307, Loss: 0.06710792519152164, Final Batch Loss: 0.04637143388390541\n",
      "Epoch 308, Loss: 0.05820604972541332, Final Batch Loss: 0.031780701130628586\n",
      "Epoch 309, Loss: 0.03439571289345622, Final Batch Loss: 0.00761489337310195\n",
      "Epoch 310, Loss: 0.09930168092250824, Final Batch Loss: 0.0765446275472641\n",
      "Epoch 311, Loss: 0.060375237837433815, Final Batch Loss: 0.03962699696421623\n",
      "Epoch 312, Loss: 0.06836246326565742, Final Batch Loss: 0.023757819086313248\n",
      "Epoch 313, Loss: 0.09050798788666725, Final Batch Loss: 0.03193722665309906\n",
      "Epoch 314, Loss: 0.05194522626698017, Final Batch Loss: 0.016326935961842537\n",
      "Epoch 315, Loss: 0.07983573898673058, Final Batch Loss: 0.0387408509850502\n",
      "Epoch 316, Loss: 0.025693594478070736, Final Batch Loss: 0.00933400820940733\n",
      "Epoch 317, Loss: 0.03199730906635523, Final Batch Loss: 0.00960442703217268\n",
      "Epoch 318, Loss: 0.05635444074869156, Final Batch Loss: 0.038654059171676636\n",
      "Epoch 319, Loss: 0.05051772762089968, Final Batch Loss: 0.015331790782511234\n",
      "Epoch 320, Loss: 0.06034239940345287, Final Batch Loss: 0.016434838995337486\n",
      "Epoch 321, Loss: 0.059278388507664204, Final Batch Loss: 0.008507953025400639\n",
      "Epoch 322, Loss: 0.08334546815603971, Final Batch Loss: 0.06775905936956406\n",
      "Epoch 323, Loss: 0.059508729726076126, Final Batch Loss: 0.021481089293956757\n",
      "Epoch 324, Loss: 0.07421225309371948, Final Batch Loss: 0.03326626494526863\n",
      "Epoch 325, Loss: 0.04512302204966545, Final Batch Loss: 0.01645832695066929\n",
      "Epoch 326, Loss: 0.07363524287939072, Final Batch Loss: 0.043516796082258224\n",
      "Epoch 327, Loss: 0.05669987201690674, Final Batch Loss: 0.03823239356279373\n",
      "Epoch 328, Loss: 0.05846160277724266, Final Batch Loss: 0.015654273331165314\n",
      "Epoch 329, Loss: 0.07004465349018574, Final Batch Loss: 0.041122615337371826\n",
      "Epoch 330, Loss: 0.05641987733542919, Final Batch Loss: 0.03452103212475777\n",
      "Epoch 331, Loss: 0.058448126539587975, Final Batch Loss: 0.021536586806178093\n",
      "Epoch 332, Loss: 0.07263922691345215, Final Batch Loss: 0.03025144711136818\n",
      "Epoch 333, Loss: 0.02963530458509922, Final Batch Loss: 0.008692797273397446\n",
      "Epoch 334, Loss: 0.06811973825097084, Final Batch Loss: 0.03530915081501007\n",
      "Epoch 335, Loss: 0.07299836352467537, Final Batch Loss: 0.039459217339754105\n",
      "Epoch 336, Loss: 0.07324137911200523, Final Batch Loss: 0.034733548760414124\n",
      "Epoch 337, Loss: 0.04267389886081219, Final Batch Loss: 0.01956775225698948\n",
      "Epoch 338, Loss: 0.03260538727045059, Final Batch Loss: 0.023010138422250748\n",
      "Epoch 339, Loss: 0.051322062499821186, Final Batch Loss: 0.0370376855134964\n",
      "Epoch 340, Loss: 0.04766133241355419, Final Batch Loss: 0.02746865153312683\n",
      "Epoch 341, Loss: 0.04202115349471569, Final Batch Loss: 0.023963870480656624\n",
      "Epoch 342, Loss: 0.0686827227473259, Final Batch Loss: 0.03329763934016228\n",
      "Epoch 343, Loss: 0.048089757561683655, Final Batch Loss: 0.014954406768083572\n",
      "Epoch 344, Loss: 0.031021173112094402, Final Batch Loss: 0.006875825114548206\n",
      "Epoch 345, Loss: 0.031047203578054905, Final Batch Loss: 0.012617121450603008\n",
      "Epoch 346, Loss: 0.03668382205069065, Final Batch Loss: 0.012023156508803368\n",
      "Epoch 347, Loss: 0.0315964100882411, Final Batch Loss: 0.010063371621072292\n",
      "Epoch 348, Loss: 0.02895648591220379, Final Batch Loss: 0.008611738681793213\n",
      "Epoch 349, Loss: 0.04221564531326294, Final Batch Loss: 0.01527315378189087\n",
      "Epoch 350, Loss: 0.05491380952298641, Final Batch Loss: 0.028407758101820946\n",
      "Epoch 351, Loss: 0.05878758616745472, Final Batch Loss: 0.025489261373877525\n",
      "Epoch 352, Loss: 0.039632225409150124, Final Batch Loss: 0.023563634604215622\n",
      "Epoch 353, Loss: 0.035023199394345284, Final Batch Loss: 0.019217099994421005\n",
      "Epoch 354, Loss: 0.07127734459936619, Final Batch Loss: 0.02537657506763935\n",
      "Epoch 355, Loss: 0.06577489618211985, Final Batch Loss: 0.05881631001830101\n",
      "Epoch 356, Loss: 0.04650445096194744, Final Batch Loss: 0.021762458607554436\n",
      "Epoch 357, Loss: 0.07078499160706997, Final Batch Loss: 0.018325166776776314\n",
      "Epoch 358, Loss: 0.032820201478898525, Final Batch Loss: 0.013902596198022366\n",
      "Epoch 359, Loss: 0.0510861873626709, Final Batch Loss: 0.014928039163351059\n",
      "Epoch 360, Loss: 0.024314136244356632, Final Batch Loss: 0.01276879571378231\n",
      "Epoch 361, Loss: 0.042816977482289076, Final Batch Loss: 0.03541562333703041\n",
      "Epoch 362, Loss: 0.07313887681812048, Final Batch Loss: 0.013653530739247799\n",
      "Epoch 363, Loss: 0.03101036325097084, Final Batch Loss: 0.020228691399097443\n",
      "Epoch 364, Loss: 0.05906625837087631, Final Batch Loss: 0.04339936748147011\n",
      "Epoch 365, Loss: 0.020815256983041763, Final Batch Loss: 0.012544514611363411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366, Loss: 0.02993207424879074, Final Batch Loss: 0.017631394788622856\n",
      "Epoch 367, Loss: 0.0597545113414526, Final Batch Loss: 0.037126827985048294\n",
      "Epoch 368, Loss: 0.04854267556220293, Final Batch Loss: 0.0349075123667717\n",
      "Epoch 369, Loss: 0.028929652646183968, Final Batch Loss: 0.012928139418363571\n",
      "Epoch 370, Loss: 0.06436705589294434, Final Batch Loss: 0.04223056137561798\n",
      "Epoch 371, Loss: 0.04045131802558899, Final Batch Loss: 0.019295668229460716\n",
      "Epoch 372, Loss: 0.031564013101160526, Final Batch Loss: 0.022963661700487137\n",
      "Epoch 373, Loss: 0.03335757553577423, Final Batch Loss: 0.024269644170999527\n",
      "Epoch 374, Loss: 0.07471923530101776, Final Batch Loss: 0.058873675763607025\n",
      "Epoch 375, Loss: 0.03126103896647692, Final Batch Loss: 0.01361092273145914\n",
      "Epoch 376, Loss: 0.02775638923048973, Final Batch Loss: 0.01690831035375595\n",
      "Epoch 377, Loss: 0.07587878033518791, Final Batch Loss: 0.023822590708732605\n",
      "Epoch 378, Loss: 0.057440485805273056, Final Batch Loss: 0.029237287119030952\n",
      "Epoch 379, Loss: 0.0516017759218812, Final Batch Loss: 0.0410669781267643\n",
      "Epoch 380, Loss: 0.03335960302501917, Final Batch Loss: 0.018276982009410858\n",
      "Epoch 381, Loss: 0.04657483845949173, Final Batch Loss: 0.02468879334628582\n",
      "Epoch 382, Loss: 0.02892454620450735, Final Batch Loss: 0.015175609849393368\n",
      "Epoch 383, Loss: 0.06576274707913399, Final Batch Loss: 0.037958018481731415\n",
      "Epoch 384, Loss: 0.026307654101401567, Final Batch Loss: 0.007577524054795504\n",
      "Epoch 385, Loss: 0.07276634126901627, Final Batch Loss: 0.042169325053691864\n",
      "Epoch 386, Loss: 0.031792109832167625, Final Batch Loss: 0.020097630098462105\n",
      "Epoch 387, Loss: 0.041625022888183594, Final Batch Loss: 0.023892685770988464\n",
      "Epoch 388, Loss: 0.05636401614174247, Final Batch Loss: 0.052287884056568146\n",
      "Epoch 389, Loss: 0.041173326782882214, Final Batch Loss: 0.0135671840980649\n",
      "Epoch 390, Loss: 0.03430985100567341, Final Batch Loss: 0.02601301111280918\n",
      "Epoch 391, Loss: 0.04407975496724248, Final Batch Loss: 0.036399707198143005\n",
      "Epoch 392, Loss: 0.03490974847227335, Final Batch Loss: 0.013889170251786709\n",
      "Epoch 393, Loss: 0.04456368461251259, Final Batch Loss: 0.01736995205283165\n",
      "Epoch 394, Loss: 0.06715246476233006, Final Batch Loss: 0.044037431478500366\n",
      "Epoch 395, Loss: 0.02152030309662223, Final Batch Loss: 0.015227545984089375\n",
      "Epoch 396, Loss: 0.036772601306438446, Final Batch Loss: 0.025357268750667572\n",
      "Epoch 397, Loss: 0.05126831866800785, Final Batch Loss: 0.02434523217380047\n",
      "Epoch 398, Loss: 0.012382366694509983, Final Batch Loss: 0.0072195143438875675\n",
      "Epoch 399, Loss: 0.025902757421135902, Final Batch Loss: 0.012068993411958218\n",
      "Epoch 400, Loss: 0.014859484974294901, Final Batch Loss: 0.006744657177478075\n",
      "Epoch 401, Loss: 0.0551863182336092, Final Batch Loss: 0.021947724744677544\n",
      "Epoch 402, Loss: 0.04041452147066593, Final Batch Loss: 0.013230020180344582\n",
      "Epoch 403, Loss: 0.025314227677881718, Final Batch Loss: 0.006470545195043087\n",
      "Epoch 404, Loss: 0.06970766838639975, Final Batch Loss: 0.007987174205482006\n",
      "Epoch 405, Loss: 0.04356149863451719, Final Batch Loss: 0.010126917622983456\n",
      "Epoch 406, Loss: 0.019156385213136673, Final Batch Loss: 0.01205318421125412\n",
      "Epoch 407, Loss: 0.03940286207944155, Final Batch Loss: 0.03192892670631409\n",
      "Epoch 408, Loss: 0.033095880411565304, Final Batch Loss: 0.010199622251093388\n",
      "Epoch 409, Loss: 0.07946973294019699, Final Batch Loss: 0.058675020933151245\n",
      "Epoch 410, Loss: 0.03276927303522825, Final Batch Loss: 0.022173285484313965\n",
      "Epoch 411, Loss: 0.049980657175183296, Final Batch Loss: 0.03210495784878731\n",
      "Epoch 412, Loss: 0.015511894132941961, Final Batch Loss: 0.0045677968300879\n",
      "Epoch 413, Loss: 0.04579576663672924, Final Batch Loss: 0.014112753793597221\n",
      "Epoch 414, Loss: 0.03191771823912859, Final Batch Loss: 0.010077024810016155\n",
      "Epoch 415, Loss: 0.04207689967006445, Final Batch Loss: 0.03288661316037178\n",
      "Epoch 416, Loss: 0.04187661502510309, Final Batch Loss: 0.00916717667132616\n",
      "Epoch 417, Loss: 0.050832001492381096, Final Batch Loss: 0.03383100777864456\n",
      "Epoch 418, Loss: 0.024443790316581726, Final Batch Loss: 0.016502005979418755\n",
      "Epoch 419, Loss: 0.03994632884860039, Final Batch Loss: 0.028186537325382233\n",
      "Epoch 420, Loss: 0.03194020316004753, Final Batch Loss: 0.009596709161996841\n",
      "Epoch 421, Loss: 0.018713761121034622, Final Batch Loss: 0.006603766232728958\n",
      "Epoch 422, Loss: 0.02928808843716979, Final Batch Loss: 0.005882638972252607\n",
      "Epoch 423, Loss: 0.03847646387293935, Final Batch Loss: 0.00430064694955945\n",
      "Epoch 424, Loss: 0.024631117470562458, Final Batch Loss: 0.011247868649661541\n",
      "Epoch 425, Loss: 0.03722912818193436, Final Batch Loss: 0.019486181437969208\n",
      "Epoch 426, Loss: 0.037050239741802216, Final Batch Loss: 0.014765404164791107\n",
      "Epoch 427, Loss: 0.041279236786067486, Final Batch Loss: 0.009694448672235012\n",
      "Epoch 428, Loss: 0.03303977940231562, Final Batch Loss: 0.023610835894942284\n",
      "Epoch 429, Loss: 0.017653186339884996, Final Batch Loss: 0.007741170469671488\n",
      "Epoch 430, Loss: 0.03612822946161032, Final Batch Loss: 0.025865428149700165\n",
      "Epoch 431, Loss: 0.0066838813945651054, Final Batch Loss: 0.0025693844072520733\n",
      "Epoch 432, Loss: 0.027039353735744953, Final Batch Loss: 0.01081439945846796\n",
      "Epoch 433, Loss: 0.09424458723515272, Final Batch Loss: 0.0793861597776413\n",
      "Epoch 434, Loss: 0.020621451549232006, Final Batch Loss: 0.011140728369355202\n",
      "Epoch 435, Loss: 0.017426534090191126, Final Batch Loss: 0.006866910960525274\n",
      "Epoch 436, Loss: 0.02952713007107377, Final Batch Loss: 0.0036615286953747272\n",
      "Epoch 437, Loss: 0.03462139703333378, Final Batch Loss: 0.021262703463435173\n",
      "Epoch 438, Loss: 0.03591497056186199, Final Batch Loss: 0.027067070826888084\n",
      "Epoch 439, Loss: 0.018751161638647318, Final Batch Loss: 0.004157785791903734\n",
      "Epoch 440, Loss: 0.03886328637599945, Final Batch Loss: 0.025464525446295738\n",
      "Epoch 441, Loss: 0.023752950131893158, Final Batch Loss: 0.011033168062567711\n",
      "Epoch 442, Loss: 0.013707558158785105, Final Batch Loss: 0.0028360378928482533\n",
      "Epoch 443, Loss: 0.027251239866018295, Final Batch Loss: 0.009331360459327698\n",
      "Epoch 444, Loss: 0.02059413678944111, Final Batch Loss: 0.011090741492807865\n",
      "Epoch 445, Loss: 0.04377938061952591, Final Batch Loss: 0.009121231734752655\n",
      "Epoch 446, Loss: 0.04496408440172672, Final Batch Loss: 0.02437703125178814\n",
      "Epoch 447, Loss: 0.025393270887434483, Final Batch Loss: 0.014130844734609127\n",
      "Epoch 448, Loss: 0.04618472047150135, Final Batch Loss: 0.008576413616538048\n",
      "Epoch 449, Loss: 0.025012462865561247, Final Batch Loss: 0.004270510282367468\n",
      "Epoch 450, Loss: 0.05323583958670497, Final Batch Loss: 0.004860735964030027\n",
      "Epoch 451, Loss: 0.025186562910676003, Final Batch Loss: 0.009600140154361725\n",
      "Epoch 452, Loss: 0.01467827893793583, Final Batch Loss: 0.004824169911444187\n",
      "Epoch 453, Loss: 0.022268625907599926, Final Batch Loss: 0.004434281028807163\n",
      "Epoch 454, Loss: 0.027400073129683733, Final Batch Loss: 0.007701220456510782\n",
      "Epoch 455, Loss: 0.024905125610530376, Final Batch Loss: 0.008329502306878567\n",
      "Epoch 456, Loss: 0.02454573754221201, Final Batch Loss: 0.008961562067270279\n",
      "Epoch 457, Loss: 0.012972705531865358, Final Batch Loss: 0.007676589302718639\n",
      "Epoch 458, Loss: 0.014426548033952713, Final Batch Loss: 0.009774642065167427\n",
      "Epoch 459, Loss: 0.018875373527407646, Final Batch Loss: 0.008398201316595078\n",
      "Epoch 460, Loss: 0.04577547125518322, Final Batch Loss: 0.04146481305360794\n",
      "Epoch 461, Loss: 0.014659641776233912, Final Batch Loss: 0.005811714101582766\n",
      "Epoch 462, Loss: 0.04952070862054825, Final Batch Loss: 0.044300757348537445\n",
      "Epoch 463, Loss: 0.030129476450383663, Final Batch Loss: 0.00599935557693243\n",
      "Epoch 464, Loss: 0.028655904345214367, Final Batch Loss: 0.017472997307777405\n",
      "Epoch 465, Loss: 0.031409852206707, Final Batch Loss: 0.018671894446015358\n",
      "Epoch 466, Loss: 0.035415079444646835, Final Batch Loss: 0.018675372004508972\n",
      "Epoch 467, Loss: 0.026012028567492962, Final Batch Loss: 0.017842469736933708\n",
      "Epoch 468, Loss: 0.008039033971726894, Final Batch Loss: 0.003447042778134346\n",
      "Epoch 469, Loss: 0.014620987698435783, Final Batch Loss: 0.005212198942899704\n",
      "Epoch 470, Loss: 0.03158461395651102, Final Batch Loss: 0.025933412835001945\n",
      "Epoch 471, Loss: 0.01916247932240367, Final Batch Loss: 0.014053469523787498\n",
      "Epoch 472, Loss: 0.03378979302942753, Final Batch Loss: 0.01856517791748047\n",
      "Epoch 473, Loss: 0.03158834343776107, Final Batch Loss: 0.006234498228877783\n",
      "Epoch 474, Loss: 0.02093737106770277, Final Batch Loss: 0.009091493673622608\n",
      "Epoch 475, Loss: 0.010154508985579014, Final Batch Loss: 0.006209768354892731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476, Loss: 0.028586280532181263, Final Batch Loss: 0.020018409937620163\n",
      "Epoch 477, Loss: 0.008592871250584722, Final Batch Loss: 0.0036123262252658606\n",
      "Epoch 478, Loss: 0.02958863298408687, Final Batch Loss: 0.0026814814191311598\n",
      "Epoch 479, Loss: 0.017760268412530422, Final Batch Loss: 0.0018637096509337425\n",
      "Epoch 480, Loss: 0.02718853624537587, Final Batch Loss: 0.023935772478580475\n",
      "Epoch 481, Loss: 0.04741161596029997, Final Batch Loss: 0.03899746388196945\n",
      "Epoch 482, Loss: 0.027006683871150017, Final Batch Loss: 0.009566999971866608\n",
      "Epoch 483, Loss: 0.016847729682922363, Final Batch Loss: 0.011099434457719326\n",
      "Epoch 484, Loss: 0.01022855518385768, Final Batch Loss: 0.005150030367076397\n",
      "Epoch 485, Loss: 0.013764436356723309, Final Batch Loss: 0.006637799087911844\n",
      "Epoch 486, Loss: 0.0408587115816772, Final Batch Loss: 0.00565590662881732\n",
      "Epoch 487, Loss: 0.06640011630952358, Final Batch Loss: 0.04807175695896149\n",
      "Epoch 488, Loss: 0.040547012351453304, Final Batch Loss: 0.009689646773040295\n",
      "Epoch 489, Loss: 0.027094689197838306, Final Batch Loss: 0.0172763429582119\n",
      "Epoch 490, Loss: 0.06376548763364553, Final Batch Loss: 0.051099587231874466\n",
      "Epoch 491, Loss: 0.022263189312070608, Final Batch Loss: 0.0180545374751091\n",
      "Epoch 492, Loss: 0.01946895197033882, Final Batch Loss: 0.009736658073961735\n",
      "Epoch 493, Loss: 0.05117991007864475, Final Batch Loss: 0.004008656367659569\n",
      "Epoch 494, Loss: 0.0418036263436079, Final Batch Loss: 0.02049463614821434\n",
      "Epoch 495, Loss: 0.017234553582966328, Final Batch Loss: 0.010458859615027905\n",
      "Epoch 496, Loss: 0.02644015196710825, Final Batch Loss: 0.012049058452248573\n",
      "Epoch 497, Loss: 0.010496704373508692, Final Batch Loss: 0.004496922716498375\n",
      "Epoch 498, Loss: 0.01766524650156498, Final Batch Loss: 0.004660958424210548\n",
      "Epoch 499, Loss: 0.03313303366303444, Final Batch Loss: 0.01697194203734398\n",
      "Epoch 500, Loss: 0.015382364392280579, Final Batch Loss: 0.007003084756433964\n",
      "Epoch 501, Loss: 0.023811553604900837, Final Batch Loss: 0.005197768099606037\n",
      "Epoch 502, Loss: 0.0276627354323864, Final Batch Loss: 0.018991805613040924\n",
      "Epoch 503, Loss: 0.01180569501593709, Final Batch Loss: 0.0043596127070486546\n",
      "Epoch 504, Loss: 0.015233320649713278, Final Batch Loss: 0.0072317118756473064\n",
      "Epoch 505, Loss: 0.03970085084438324, Final Batch Loss: 0.013820234686136246\n",
      "Epoch 506, Loss: 0.025049559772014618, Final Batch Loss: 0.0050020478665828705\n",
      "Epoch 507, Loss: 0.015205346047878265, Final Batch Loss: 0.007933096028864384\n",
      "Epoch 508, Loss: 0.022693726234138012, Final Batch Loss: 0.00917853694409132\n",
      "Epoch 509, Loss: 0.03135193884372711, Final Batch Loss: 0.017919618636369705\n",
      "Epoch 510, Loss: 0.026676823385059834, Final Batch Loss: 0.018589293584227562\n",
      "Epoch 511, Loss: 0.020468282513320446, Final Batch Loss: 0.01580340974032879\n",
      "Epoch 512, Loss: 0.04299886152148247, Final Batch Loss: 0.020608214661478996\n",
      "Epoch 513, Loss: 0.027545468881726265, Final Batch Loss: 0.011451995000243187\n",
      "Epoch 514, Loss: 0.01416817493736744, Final Batch Loss: 0.008760717697441578\n",
      "Epoch 515, Loss: 0.012946097180247307, Final Batch Loss: 0.004203379154205322\n",
      "Epoch 516, Loss: 0.010735028889030218, Final Batch Loss: 0.008704407140612602\n",
      "Epoch 517, Loss: 0.019060096703469753, Final Batch Loss: 0.0097975954413414\n",
      "Epoch 518, Loss: 0.009812588803470135, Final Batch Loss: 0.005612444598227739\n",
      "Epoch 519, Loss: 0.009508348070085049, Final Batch Loss: 0.004345964640378952\n",
      "Epoch 520, Loss: 0.007735961815342307, Final Batch Loss: 0.005444015376269817\n",
      "Epoch 521, Loss: 0.01218081871047616, Final Batch Loss: 0.0043283733539283276\n",
      "Epoch 522, Loss: 0.012157180812209845, Final Batch Loss: 0.0076231458224356174\n",
      "Epoch 523, Loss: 0.016252547968178988, Final Batch Loss: 0.007225607987493277\n",
      "Epoch 524, Loss: 0.012662503868341446, Final Batch Loss: 0.005504694767296314\n",
      "Epoch 525, Loss: 0.022557001560926437, Final Batch Loss: 0.017771204933524132\n",
      "Epoch 526, Loss: 0.05204929783940315, Final Batch Loss: 0.02380218543112278\n",
      "Epoch 527, Loss: 0.015066204126924276, Final Batch Loss: 0.005674444604665041\n",
      "Epoch 528, Loss: 0.010106917936354876, Final Batch Loss: 0.004908885806798935\n",
      "Epoch 529, Loss: 0.025890293065458536, Final Batch Loss: 0.020487552508711815\n",
      "Epoch 530, Loss: 0.041322735138237476, Final Batch Loss: 0.03162846341729164\n",
      "Epoch 531, Loss: 0.02238484425470233, Final Batch Loss: 0.004478793125599623\n",
      "Epoch 532, Loss: 0.014731353614479303, Final Batch Loss: 0.003151561599224806\n",
      "Epoch 533, Loss: 0.029832915868610144, Final Batch Loss: 0.0020900252275168896\n",
      "Epoch 534, Loss: 0.010429837740957737, Final Batch Loss: 0.002849527169018984\n",
      "Epoch 535, Loss: 0.013531313743442297, Final Batch Loss: 0.0017228149808943272\n",
      "Epoch 536, Loss: 0.007924858015030622, Final Batch Loss: 0.0050040800124406815\n",
      "Epoch 537, Loss: 0.00952498335391283, Final Batch Loss: 0.007443106267601252\n",
      "Epoch 538, Loss: 0.032003968954086304, Final Batch Loss: 0.0090553667396307\n",
      "Epoch 539, Loss: 0.01550068473443389, Final Batch Loss: 0.0044775367714464664\n",
      "Epoch 540, Loss: 0.031012377236038446, Final Batch Loss: 0.026443663984537125\n",
      "Epoch 541, Loss: 0.009903674246743321, Final Batch Loss: 0.003655601991340518\n",
      "Epoch 542, Loss: 0.02504903543740511, Final Batch Loss: 0.00981676671653986\n",
      "Epoch 543, Loss: 0.02091521816328168, Final Batch Loss: 0.004751382861286402\n",
      "Epoch 544, Loss: 0.008814424509182572, Final Batch Loss: 0.002388379303738475\n",
      "Epoch 545, Loss: 0.009301414713263512, Final Batch Loss: 0.0067739891819655895\n",
      "Epoch 546, Loss: 0.015181580558419228, Final Batch Loss: 0.009407122619450092\n",
      "Epoch 547, Loss: 0.006749584339559078, Final Batch Loss: 0.003658970119431615\n",
      "Epoch 548, Loss: 0.02264800388365984, Final Batch Loss: 0.0034378906711935997\n",
      "Epoch 549, Loss: 0.02560925716534257, Final Batch Loss: 0.006545341107994318\n",
      "Epoch 550, Loss: 0.05337923672050238, Final Batch Loss: 0.008216205053031445\n",
      "Epoch 551, Loss: 0.008292836602777243, Final Batch Loss: 0.003436473198235035\n",
      "Epoch 552, Loss: 0.010493995621800423, Final Batch Loss: 0.004381170962005854\n",
      "Epoch 553, Loss: 0.023586072959005833, Final Batch Loss: 0.01334395632147789\n",
      "Epoch 554, Loss: 0.020080461632460356, Final Batch Loss: 0.016886694356799126\n",
      "Epoch 555, Loss: 0.013613122748211026, Final Batch Loss: 0.0029734766576439142\n",
      "Epoch 556, Loss: 0.00809499528259039, Final Batch Loss: 0.0051367683336138725\n",
      "Epoch 557, Loss: 0.019397877622395754, Final Batch Loss: 0.012101453728973866\n",
      "Epoch 558, Loss: 0.022027622442692518, Final Batch Loss: 0.006950178649276495\n",
      "Epoch 559, Loss: 0.008609819924458861, Final Batch Loss: 0.0024390181060880423\n",
      "Epoch 560, Loss: 0.01165143446996808, Final Batch Loss: 0.00758059648796916\n",
      "Epoch 561, Loss: 0.014858910348266363, Final Batch Loss: 0.010318889282643795\n",
      "Epoch 562, Loss: 0.036494468338787556, Final Batch Loss: 0.028428256511688232\n",
      "Epoch 563, Loss: 0.019771995022892952, Final Batch Loss: 0.013279675506055355\n",
      "Epoch 564, Loss: 0.02500149793922901, Final Batch Loss: 0.01810663565993309\n",
      "Epoch 565, Loss: 0.015459444839507341, Final Batch Loss: 0.012117126025259495\n",
      "Epoch 566, Loss: 0.02311384677886963, Final Batch Loss: 0.015157838352024555\n",
      "Epoch 567, Loss: 0.017075075302273035, Final Batch Loss: 0.012553907930850983\n",
      "Epoch 568, Loss: 0.024668222293257713, Final Batch Loss: 0.02125377021729946\n",
      "Epoch 569, Loss: 0.016582750715315342, Final Batch Loss: 0.007412722334265709\n",
      "Epoch 570, Loss: 0.012458409182727337, Final Batch Loss: 0.004777700640261173\n",
      "Epoch 571, Loss: 0.009795140475034714, Final Batch Loss: 0.004711420275270939\n",
      "Epoch 572, Loss: 0.01874496869277209, Final Batch Loss: 0.0010962289525195956\n",
      "Epoch 573, Loss: 0.025197415612637997, Final Batch Loss: 0.01770133711397648\n",
      "Epoch 574, Loss: 0.009270295733585954, Final Batch Loss: 0.0024650238920003176\n",
      "Epoch 575, Loss: 0.005654607666656375, Final Batch Loss: 0.0027966853231191635\n",
      "Epoch 576, Loss: 0.00992452329955995, Final Batch Loss: 0.003486313158646226\n",
      "Epoch 577, Loss: 0.008755996823310852, Final Batch Loss: 0.0035315947607159615\n",
      "Epoch 578, Loss: 0.008630999363958836, Final Batch Loss: 0.0021546143107116222\n",
      "Epoch 579, Loss: 0.011099221184849739, Final Batch Loss: 0.006400127895176411\n",
      "Epoch 580, Loss: 0.01809179550036788, Final Batch Loss: 0.0040368284098804\n",
      "Epoch 581, Loss: 0.014862424694001675, Final Batch Loss: 0.013083257712423801\n",
      "Epoch 582, Loss: 0.03778646048158407, Final Batch Loss: 0.026987440884113312\n",
      "Epoch 583, Loss: 0.01270547998137772, Final Batch Loss: 0.010260899551212788\n",
      "Epoch 584, Loss: 0.04156312393024564, Final Batch Loss: 0.036678995937108994\n",
      "Epoch 585, Loss: 0.0046644124668091536, Final Batch Loss: 0.003120644483715296\n",
      "Epoch 586, Loss: 0.01158229960128665, Final Batch Loss: 0.006236864719539881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 587, Loss: 0.0054854737827554345, Final Batch Loss: 0.003994320519268513\n",
      "Epoch 588, Loss: 0.002944567590020597, Final Batch Loss: 0.0013899635523557663\n",
      "Epoch 589, Loss: 0.010673425393179059, Final Batch Loss: 0.0019792786333709955\n",
      "Epoch 590, Loss: 0.05386891029775143, Final Batch Loss: 0.04424183815717697\n",
      "Epoch 591, Loss: 0.020953371189534664, Final Batch Loss: 0.008207855746150017\n",
      "Epoch 592, Loss: 0.004684437881223857, Final Batch Loss: 0.0027347421273589134\n",
      "Epoch 593, Loss: 0.02924675215035677, Final Batch Loss: 0.02681460976600647\n",
      "Epoch 594, Loss: 0.008381153456866741, Final Batch Loss: 0.002572731114923954\n",
      "Epoch 595, Loss: 0.01692573819309473, Final Batch Loss: 0.013235199265182018\n",
      "Epoch 596, Loss: 0.008910335716791451, Final Batch Loss: 0.007404862903058529\n",
      "Epoch 597, Loss: 0.004717770148999989, Final Batch Loss: 0.001913845888338983\n",
      "Epoch 598, Loss: 0.05334866512566805, Final Batch Loss: 0.04569143429398537\n",
      "Epoch 599, Loss: 0.011889845598489046, Final Batch Loss: 0.005684893112629652\n",
      "Epoch 600, Loss: 0.02862891275435686, Final Batch Loss: 0.016916314139962196\n",
      "Epoch 601, Loss: 0.010875989217311144, Final Batch Loss: 0.0030761100351810455\n",
      "Epoch 602, Loss: 0.009380932664498687, Final Batch Loss: 0.006496327463537455\n",
      "Epoch 603, Loss: 0.01546356116887182, Final Batch Loss: 0.0016929426928982139\n",
      "Epoch 604, Loss: 0.011478054570034146, Final Batch Loss: 0.00835801288485527\n",
      "Epoch 605, Loss: 0.010725394124165177, Final Batch Loss: 0.0039043326396495104\n",
      "Epoch 606, Loss: 0.020983590744435787, Final Batch Loss: 0.005547218024730682\n",
      "Epoch 607, Loss: 0.03455591993406415, Final Batch Loss: 0.007702459115535021\n",
      "Epoch 608, Loss: 0.012369105825200677, Final Batch Loss: 0.0038830211851745844\n",
      "Epoch 609, Loss: 0.02202263195067644, Final Batch Loss: 0.010732226073741913\n",
      "Epoch 610, Loss: 0.012568996287882328, Final Batch Loss: 0.009242511354386806\n",
      "Epoch 611, Loss: 0.01818878366611898, Final Batch Loss: 0.014781379140913486\n",
      "Epoch 612, Loss: 0.05242711119353771, Final Batch Loss: 0.01673165149986744\n",
      "Epoch 613, Loss: 0.018237792886793613, Final Batch Loss: 0.0067095402628183365\n",
      "Epoch 614, Loss: 0.04008121229708195, Final Batch Loss: 0.021599654108285904\n",
      "Epoch 615, Loss: 0.007196279242634773, Final Batch Loss: 0.004750615917146206\n",
      "Epoch 616, Loss: 0.009831761475652456, Final Batch Loss: 0.006824695039540529\n",
      "Epoch 617, Loss: 0.011543308093678206, Final Batch Loss: 0.0009125226060859859\n",
      "Epoch 618, Loss: 0.01556935952976346, Final Batch Loss: 0.006275375839322805\n",
      "Epoch 619, Loss: 0.014773577451705933, Final Batch Loss: 0.01110187266021967\n",
      "Epoch 620, Loss: 0.012528883293271065, Final Batch Loss: 0.004060417413711548\n",
      "Epoch 621, Loss: 0.020365788601338863, Final Batch Loss: 0.007783662527799606\n",
      "Epoch 622, Loss: 0.038836339488625526, Final Batch Loss: 0.02224395051598549\n",
      "Epoch 623, Loss: 0.008554545929655433, Final Batch Loss: 0.0054468982852995396\n",
      "Epoch 624, Loss: 0.010452925227582455, Final Batch Loss: 0.005247762426733971\n",
      "Epoch 625, Loss: 0.009989249054342508, Final Batch Loss: 0.006918825674802065\n",
      "Epoch 626, Loss: 0.016777658835053444, Final Batch Loss: 0.006238442845642567\n",
      "Epoch 627, Loss: 0.00828141556121409, Final Batch Loss: 0.003756074933335185\n",
      "Epoch 628, Loss: 0.01404948579147458, Final Batch Loss: 0.002035722602158785\n",
      "Epoch 629, Loss: 0.03880831692367792, Final Batch Loss: 0.03424088656902313\n",
      "Epoch 630, Loss: 0.005431096418760717, Final Batch Loss: 0.004383686929941177\n",
      "Epoch 631, Loss: 0.005510372808203101, Final Batch Loss: 0.0006528438534587622\n",
      "Epoch 632, Loss: 0.007039260119199753, Final Batch Loss: 0.004135967697948217\n",
      "Epoch 633, Loss: 0.028093013912439346, Final Batch Loss: 0.01725580170750618\n",
      "Epoch 634, Loss: 0.0048033546190708876, Final Batch Loss: 0.002553834579885006\n",
      "Epoch 635, Loss: 0.009448329452425241, Final Batch Loss: 0.005985321011394262\n",
      "Epoch 636, Loss: 0.007886389968916774, Final Batch Loss: 0.0036133138928562403\n",
      "Epoch 637, Loss: 0.022618998773396015, Final Batch Loss: 0.019015450030565262\n",
      "Epoch 638, Loss: 0.01262599672190845, Final Batch Loss: 0.009187611751258373\n",
      "Epoch 639, Loss: 0.008687922032549977, Final Batch Loss: 0.0064183929935097694\n",
      "Epoch 640, Loss: 0.016010673251003027, Final Batch Loss: 0.00868215225636959\n",
      "Epoch 641, Loss: 0.010755919851362705, Final Batch Loss: 0.0029810406267642975\n",
      "Epoch 642, Loss: 0.011887935921549797, Final Batch Loss: 0.007778977509588003\n",
      "Epoch 643, Loss: 0.016923265531659126, Final Batch Loss: 0.007744121365249157\n",
      "Epoch 644, Loss: 0.008981058141216636, Final Batch Loss: 0.003729535499587655\n",
      "Epoch 645, Loss: 0.022646803874522448, Final Batch Loss: 0.016323255375027657\n",
      "Epoch 646, Loss: 0.010548693127930164, Final Batch Loss: 0.006326581351459026\n",
      "Epoch 647, Loss: 0.011035977397114038, Final Batch Loss: 0.005930016282945871\n",
      "Epoch 648, Loss: 0.012631286168470979, Final Batch Loss: 0.003739870386198163\n",
      "Epoch 649, Loss: 0.01721760630607605, Final Batch Loss: 0.0067474497482180595\n",
      "Epoch 650, Loss: 0.0061763080302625895, Final Batch Loss: 0.0020391137804836035\n",
      "Epoch 651, Loss: 0.010996874887496233, Final Batch Loss: 0.0065252832137048244\n",
      "Epoch 652, Loss: 0.028199175372719765, Final Batch Loss: 0.01921735890209675\n",
      "Epoch 653, Loss: 0.02172018215060234, Final Batch Loss: 0.011346724815666676\n",
      "Epoch 654, Loss: 0.007759909960441291, Final Batch Loss: 0.006180401425808668\n",
      "Epoch 655, Loss: 0.012838143156841397, Final Batch Loss: 0.010356430895626545\n",
      "Epoch 656, Loss: 0.04447554424405098, Final Batch Loss: 0.036909379065036774\n",
      "Epoch 657, Loss: 0.005968382116407156, Final Batch Loss: 0.002214078325778246\n",
      "Epoch 658, Loss: 0.0045291821006685495, Final Batch Loss: 0.0021854585502296686\n",
      "Epoch 659, Loss: 0.01876099267974496, Final Batch Loss: 0.0021679033525288105\n",
      "Epoch 660, Loss: 0.005741842440329492, Final Batch Loss: 0.00389112439006567\n",
      "Epoch 661, Loss: 0.00942959077656269, Final Batch Loss: 0.00197410024702549\n",
      "Epoch 662, Loss: 0.01998162642121315, Final Batch Loss: 0.008654017001390457\n",
      "Epoch 663, Loss: 0.022698028944432735, Final Batch Loss: 0.0048378994688391685\n",
      "Epoch 664, Loss: 0.004248853423632681, Final Batch Loss: 0.002377179218456149\n",
      "Epoch 665, Loss: 0.025275205494835973, Final Batch Loss: 0.02309187687933445\n",
      "Epoch 666, Loss: 0.016824870835989714, Final Batch Loss: 0.007007893640547991\n",
      "Epoch 667, Loss: 0.011552010895684361, Final Batch Loss: 0.0037503668572753668\n",
      "Epoch 668, Loss: 0.00748197385109961, Final Batch Loss: 0.0031082939822226763\n",
      "Epoch 669, Loss: 0.006443897727876902, Final Batch Loss: 0.004332488868385553\n",
      "Epoch 670, Loss: 0.014790261862799525, Final Batch Loss: 0.0032486103009432554\n",
      "Epoch 671, Loss: 0.020730465184897184, Final Batch Loss: 0.003660553600639105\n",
      "Epoch 672, Loss: 0.042122169630602, Final Batch Loss: 0.003462194697931409\n",
      "Epoch 673, Loss: 0.008798628812655807, Final Batch Loss: 0.005023637320846319\n",
      "Epoch 674, Loss: 0.010107251582667232, Final Batch Loss: 0.002020426793023944\n",
      "Epoch 675, Loss: 0.0059192858170717955, Final Batch Loss: 0.0038673714734613895\n",
      "Epoch 676, Loss: 0.007917491951957345, Final Batch Loss: 0.0015569704119116068\n",
      "Epoch 677, Loss: 0.01345320139080286, Final Batch Loss: 0.006693125236779451\n",
      "Epoch 678, Loss: 0.02462101192213595, Final Batch Loss: 0.002775797853246331\n",
      "Epoch 679, Loss: 0.004035643069073558, Final Batch Loss: 0.0024821453262120485\n",
      "Epoch 680, Loss: 0.022445656592026353, Final Batch Loss: 0.01900983601808548\n",
      "Epoch 681, Loss: 0.006827319273725152, Final Batch Loss: 0.0037798068951815367\n",
      "Epoch 682, Loss: 0.0189903792925179, Final Batch Loss: 0.006627436261624098\n",
      "Epoch 683, Loss: 0.015782124362885952, Final Batch Loss: 0.0021739033982157707\n",
      "Epoch 684, Loss: 0.008945111418142915, Final Batch Loss: 0.005897887051105499\n",
      "Epoch 685, Loss: 0.018608098849654198, Final Batch Loss: 0.013807512819766998\n",
      "Epoch 686, Loss: 0.011275471653789282, Final Batch Loss: 0.007235948462039232\n",
      "Epoch 687, Loss: 0.011104443459771574, Final Batch Loss: 0.009372626431286335\n",
      "Epoch 688, Loss: 0.010228915140032768, Final Batch Loss: 0.006917424499988556\n",
      "Epoch 689, Loss: 0.05052494537085295, Final Batch Loss: 0.04269184544682503\n",
      "Epoch 690, Loss: 0.012047497555613518, Final Batch Loss: 0.0038882046937942505\n",
      "Epoch 691, Loss: 0.008792819455265999, Final Batch Loss: 0.007171771489083767\n",
      "Epoch 692, Loss: 0.015337537508457899, Final Batch Loss: 0.008546099998056889\n",
      "Epoch 693, Loss: 0.006594036007300019, Final Batch Loss: 0.003987870179116726\n",
      "Epoch 694, Loss: 0.012147258035838604, Final Batch Loss: 0.009424696676433086\n",
      "Epoch 695, Loss: 0.03355664387345314, Final Batch Loss: 0.02669370546936989\n",
      "Epoch 696, Loss: 0.005769624141976237, Final Batch Loss: 0.0023464267142117023\n",
      "Epoch 697, Loss: 0.013644999824464321, Final Batch Loss: 0.0014083320274949074\n",
      "Epoch 698, Loss: 0.01979480148293078, Final Batch Loss: 0.01770034246146679\n",
      "Epoch 699, Loss: 0.00670134206302464, Final Batch Loss: 0.003198514925315976\n",
      "Epoch 700, Loss: 0.006564238632563502, Final Batch Loss: 0.005790126509964466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 701, Loss: 0.010432975366711617, Final Batch Loss: 0.0026870984584093094\n",
      "Epoch 702, Loss: 0.03788137040100992, Final Batch Loss: 0.0016246659215539694\n",
      "Epoch 703, Loss: 0.02047621225938201, Final Batch Loss: 0.006991162430495024\n",
      "Epoch 704, Loss: 0.02752386685460806, Final Batch Loss: 0.01484757475554943\n",
      "Epoch 705, Loss: 0.008188597741536796, Final Batch Loss: 0.0014257951406762004\n",
      "Epoch 706, Loss: 0.003158007748425007, Final Batch Loss: 0.0024598613381385803\n",
      "Epoch 707, Loss: 0.00925399549305439, Final Batch Loss: 0.003961044829338789\n",
      "Epoch 708, Loss: 0.019897759426385164, Final Batch Loss: 0.014886396005749702\n",
      "Epoch 709, Loss: 0.01434713217895478, Final Batch Loss: 0.001861248048953712\n",
      "Epoch 710, Loss: 0.022906824480742216, Final Batch Loss: 0.020588796585798264\n",
      "Epoch 711, Loss: 0.03518487908877432, Final Batch Loss: 0.0017103704158216715\n",
      "Epoch 712, Loss: 0.009053372079506516, Final Batch Loss: 0.0037794976960867643\n",
      "Epoch 713, Loss: 0.00507673155516386, Final Batch Loss: 0.002038651844486594\n",
      "Epoch 714, Loss: 0.013826359063386917, Final Batch Loss: 0.010928370989859104\n",
      "Epoch 715, Loss: 0.027300309389829636, Final Batch Loss: 0.025238344445824623\n",
      "Epoch 716, Loss: 0.02219156501814723, Final Batch Loss: 0.007084645796567202\n",
      "Epoch 717, Loss: 0.006523792399093509, Final Batch Loss: 0.003533056238666177\n",
      "Epoch 718, Loss: 0.006973907584324479, Final Batch Loss: 0.0049335043877363205\n",
      "Epoch 719, Loss: 0.006622217362746596, Final Batch Loss: 0.0040204087272286415\n",
      "Epoch 720, Loss: 0.005491380812600255, Final Batch Loss: 0.003550635650753975\n",
      "Epoch 721, Loss: 0.017049002461135387, Final Batch Loss: 0.008032442070543766\n",
      "Epoch 722, Loss: 0.010778431547805667, Final Batch Loss: 0.002223646966740489\n",
      "Epoch 723, Loss: 0.008517029695212841, Final Batch Loss: 0.0012184926308691502\n",
      "Epoch 724, Loss: 0.007862204336561263, Final Batch Loss: 0.0018204028019681573\n",
      "Epoch 725, Loss: 0.00959392252843827, Final Batch Loss: 0.0014892712933942676\n",
      "Epoch 726, Loss: 0.005488159134984016, Final Batch Loss: 0.0023943756241351366\n",
      "Epoch 727, Loss: 0.007660645060241222, Final Batch Loss: 0.004334485623985529\n",
      "Epoch 728, Loss: 0.007531198672950268, Final Batch Loss: 0.003188998904079199\n",
      "Epoch 729, Loss: 0.007041660603135824, Final Batch Loss: 0.005422085057944059\n",
      "Epoch 730, Loss: 0.005992482881993055, Final Batch Loss: 0.003278152085840702\n",
      "Epoch 731, Loss: 0.009626622777432203, Final Batch Loss: 0.002351978328078985\n",
      "Epoch 732, Loss: 0.008439551573246717, Final Batch Loss: 0.0041104392148554325\n",
      "Epoch 733, Loss: 0.012313623679801822, Final Batch Loss: 0.008709636516869068\n",
      "Epoch 734, Loss: 0.005710124038159847, Final Batch Loss: 0.0020314683206379414\n",
      "Epoch 735, Loss: 0.00749626848846674, Final Batch Loss: 0.00553050497546792\n",
      "Epoch 736, Loss: 0.0046733838971704245, Final Batch Loss: 0.003321659052744508\n",
      "Epoch 737, Loss: 0.04221154050901532, Final Batch Loss: 0.03488229587674141\n",
      "Epoch 738, Loss: 0.007131697842851281, Final Batch Loss: 0.004719668999314308\n",
      "Epoch 739, Loss: 0.007758344290778041, Final Batch Loss: 0.004832633771002293\n",
      "Epoch 740, Loss: 0.009939090232364833, Final Batch Loss: 0.008383301086723804\n",
      "Epoch 741, Loss: 0.03252463438548148, Final Batch Loss: 0.03029624931514263\n",
      "Epoch 742, Loss: 0.010847482946701348, Final Batch Loss: 0.009062854573130608\n",
      "Epoch 743, Loss: 0.02169787581078708, Final Batch Loss: 0.0035973030608147383\n",
      "Epoch 744, Loss: 0.023917204700410366, Final Batch Loss: 0.016944587230682373\n",
      "Epoch 745, Loss: 0.013777672778815031, Final Batch Loss: 0.008592309430241585\n",
      "Epoch 746, Loss: 0.0029492112807929516, Final Batch Loss: 0.0010584020055830479\n",
      "Epoch 747, Loss: 0.018442115746438503, Final Batch Loss: 0.016057176515460014\n",
      "Epoch 748, Loss: 0.009164015762507915, Final Batch Loss: 0.0025162301026284695\n",
      "Epoch 749, Loss: 0.013177274260669947, Final Batch Loss: 0.008664634078741074\n",
      "Epoch 750, Loss: 0.027024186216294765, Final Batch Loss: 0.025002529844641685\n",
      "Epoch 751, Loss: 0.07389629632234573, Final Batch Loss: 0.06411770731210709\n",
      "Epoch 752, Loss: 0.012246429570950568, Final Batch Loss: 0.011234499514102936\n",
      "Epoch 753, Loss: 0.010093062650412321, Final Batch Loss: 0.005196494050323963\n",
      "Epoch 754, Loss: 0.011491857352666557, Final Batch Loss: 0.010359816253185272\n",
      "Epoch 755, Loss: 0.011193446640390903, Final Batch Loss: 0.0008436262723989785\n",
      "Epoch 756, Loss: 0.008229235070757568, Final Batch Loss: 0.006763453129678965\n",
      "Epoch 757, Loss: 0.015602543484419584, Final Batch Loss: 0.0021383105777204037\n",
      "Epoch 758, Loss: 0.008905279450118542, Final Batch Loss: 0.0020542689599096775\n",
      "Epoch 759, Loss: 0.008820571005344391, Final Batch Loss: 0.004180322866886854\n",
      "Epoch 760, Loss: 0.011858574231155217, Final Batch Loss: 0.001335049164481461\n",
      "Epoch 761, Loss: 0.018076949752867222, Final Batch Loss: 0.003311673179268837\n",
      "Epoch 762, Loss: 0.007126030512154102, Final Batch Loss: 0.004731294233351946\n",
      "Epoch 763, Loss: 0.03637886489741504, Final Batch Loss: 0.03269276022911072\n",
      "Epoch 764, Loss: 0.020407684613019228, Final Batch Loss: 0.01829374022781849\n",
      "Epoch 765, Loss: 0.007836473872885108, Final Batch Loss: 0.005606405902653933\n",
      "Epoch 766, Loss: 0.00477584614418447, Final Batch Loss: 0.002482124837115407\n",
      "Epoch 767, Loss: 0.017172916093841195, Final Batch Loss: 0.0034546845126897097\n",
      "Epoch 768, Loss: 0.005379539914429188, Final Batch Loss: 0.0031158877536654472\n",
      "Epoch 769, Loss: 0.035317608853802085, Final Batch Loss: 0.032705411314964294\n",
      "Epoch 770, Loss: 0.008423389168456197, Final Batch Loss: 0.0046918196603655815\n",
      "Epoch 771, Loss: 0.038675541058182716, Final Batch Loss: 0.004642589017748833\n",
      "Epoch 772, Loss: 0.029069991316646338, Final Batch Loss: 0.002339425962418318\n",
      "Epoch 773, Loss: 0.006843248149380088, Final Batch Loss: 0.001818827586248517\n",
      "Epoch 774, Loss: 0.007670662831515074, Final Batch Loss: 0.005278570577502251\n",
      "Epoch 775, Loss: 0.00781532796099782, Final Batch Loss: 0.0037295380607247353\n",
      "Epoch 776, Loss: 0.00828373129479587, Final Batch Loss: 0.0003293359186500311\n",
      "Epoch 777, Loss: 0.0050255670212209225, Final Batch Loss: 0.003609113860875368\n",
      "Epoch 778, Loss: 0.003547145752236247, Final Batch Loss: 0.0016935218591243029\n",
      "Epoch 779, Loss: 0.003645088174380362, Final Batch Loss: 0.0015009440248832107\n",
      "Epoch 780, Loss: 0.013696552254259586, Final Batch Loss: 0.005556519143283367\n",
      "Epoch 781, Loss: 0.009670252911746502, Final Batch Loss: 0.007676518987864256\n",
      "Epoch 782, Loss: 0.008719423087313771, Final Batch Loss: 0.002744706580415368\n",
      "Epoch 783, Loss: 0.012369519856292754, Final Batch Loss: 0.0006585976225323975\n",
      "Epoch 784, Loss: 0.008730788715183735, Final Batch Loss: 0.0047399187460541725\n",
      "Epoch 785, Loss: 0.011262615211308002, Final Batch Loss: 0.0029446352273225784\n",
      "Epoch 786, Loss: 0.00465264730155468, Final Batch Loss: 0.0032289831433445215\n",
      "Epoch 787, Loss: 0.014324661577120423, Final Batch Loss: 0.011465845629572868\n",
      "Epoch 788, Loss: 0.012755372561514378, Final Batch Loss: 0.009000477381050587\n",
      "Epoch 789, Loss: 0.007460822118446231, Final Batch Loss: 0.004651625175029039\n",
      "Epoch 790, Loss: 0.0101045579649508, Final Batch Loss: 0.002339185681194067\n",
      "Epoch 791, Loss: 0.004636603174731135, Final Batch Loss: 0.0029161095153540373\n",
      "Epoch 792, Loss: 0.006316505605354905, Final Batch Loss: 0.001310788793489337\n",
      "Epoch 793, Loss: 0.0056112774182111025, Final Batch Loss: 0.003991513978689909\n",
      "Epoch 794, Loss: 0.01737441262230277, Final Batch Loss: 0.010954600758850574\n",
      "Epoch 795, Loss: 0.004089880734682083, Final Batch Loss: 0.0028606054838746786\n",
      "Epoch 796, Loss: 0.006521482369862497, Final Batch Loss: 0.001818193937651813\n",
      "Epoch 797, Loss: 0.016207259381189942, Final Batch Loss: 0.014005422592163086\n",
      "Epoch 798, Loss: 0.009202533401548862, Final Batch Loss: 0.006991119123995304\n",
      "Epoch 799, Loss: 0.005286066792905331, Final Batch Loss: 0.0020753121934831142\n",
      "Epoch 800, Loss: 0.005168368807062507, Final Batch Loss: 0.0022936961613595486\n",
      "Epoch 801, Loss: 0.0036080506397411227, Final Batch Loss: 0.0017602400621399283\n",
      "Epoch 802, Loss: 0.014142277650535107, Final Batch Loss: 0.012151670642197132\n",
      "Epoch 803, Loss: 0.004764405312016606, Final Batch Loss: 0.003651274833828211\n",
      "Epoch 804, Loss: 0.012612911872565746, Final Batch Loss: 0.001241082325577736\n",
      "Epoch 805, Loss: 0.007876986113842577, Final Batch Loss: 0.007177621126174927\n",
      "Epoch 806, Loss: 0.0025927297538146377, Final Batch Loss: 0.0007986492710188031\n",
      "Epoch 807, Loss: 0.007863770704716444, Final Batch Loss: 0.0040452564135193825\n",
      "Epoch 808, Loss: 0.007961679715663195, Final Batch Loss: 0.0025202403776347637\n",
      "Epoch 809, Loss: 0.020193112082779408, Final Batch Loss: 0.007660934701561928\n",
      "Epoch 810, Loss: 0.004260736051946878, Final Batch Loss: 0.0033312279265373945\n",
      "Epoch 811, Loss: 0.02360603678971529, Final Batch Loss: 0.0017123902216553688\n",
      "Epoch 812, Loss: 0.002515531610697508, Final Batch Loss: 0.0010839406168088317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 813, Loss: 0.015304812463000417, Final Batch Loss: 0.011949680745601654\n",
      "Epoch 814, Loss: 0.00762626517098397, Final Batch Loss: 0.0011262668995186687\n",
      "Epoch 815, Loss: 0.0022898224415257573, Final Batch Loss: 0.0012063792673870921\n",
      "Epoch 816, Loss: 0.00830706616397947, Final Batch Loss: 0.0016575659392401576\n",
      "Epoch 817, Loss: 0.008228024002164602, Final Batch Loss: 0.0008281329646706581\n",
      "Epoch 818, Loss: 0.0025433668633922935, Final Batch Loss: 0.0004341701278463006\n",
      "Epoch 819, Loss: 0.003502473409753293, Final Batch Loss: 0.0026506728027015924\n",
      "Epoch 820, Loss: 0.004274072940461338, Final Batch Loss: 0.0024094111286103725\n",
      "Epoch 821, Loss: 0.008226743375416845, Final Batch Loss: 0.007334517315030098\n",
      "Epoch 822, Loss: 0.00427563744597137, Final Batch Loss: 0.0009437846019864082\n",
      "Epoch 823, Loss: 0.007873074908275157, Final Batch Loss: 0.0005309240077622235\n",
      "Epoch 824, Loss: 0.004844987532123923, Final Batch Loss: 0.0028564592357724905\n",
      "Epoch 825, Loss: 0.008927911520004272, Final Batch Loss: 0.003036521840840578\n",
      "Epoch 826, Loss: 0.009008652647025883, Final Batch Loss: 0.007127857767045498\n",
      "Epoch 827, Loss: 0.009189412696287036, Final Batch Loss: 0.002618073718622327\n",
      "Epoch 828, Loss: 0.007011180045083165, Final Batch Loss: 0.002184906741604209\n",
      "Epoch 829, Loss: 0.0020620146533474326, Final Batch Loss: 0.0009852420771494508\n",
      "Epoch 830, Loss: 0.010452211368829012, Final Batch Loss: 0.0063743628561496735\n",
      "Epoch 831, Loss: 0.003976290812715888, Final Batch Loss: 0.0023821499198675156\n",
      "Epoch 832, Loss: 0.0037565119564533234, Final Batch Loss: 0.0016900505870580673\n",
      "Epoch 833, Loss: 0.0028586205444298685, Final Batch Loss: 0.00041274138493463397\n",
      "Epoch 834, Loss: 0.027735775336623192, Final Batch Loss: 0.018420018255710602\n",
      "Epoch 835, Loss: 0.012265451485291123, Final Batch Loss: 0.008471685461699963\n",
      "Epoch 836, Loss: 0.005030553409596905, Final Batch Loss: 0.004545935429632664\n",
      "Epoch 837, Loss: 0.009863801533356309, Final Batch Loss: 0.0029697061982005835\n",
      "Epoch 838, Loss: 0.02920355019159615, Final Batch Loss: 0.003663270967081189\n",
      "Epoch 839, Loss: 0.01434248499572277, Final Batch Loss: 0.010102269239723682\n",
      "Epoch 840, Loss: 0.004888144030701369, Final Batch Loss: 0.000696386385243386\n",
      "Epoch 841, Loss: 0.004212687606923282, Final Batch Loss: 0.0027033588849008083\n",
      "Epoch 842, Loss: 0.014338233275339007, Final Batch Loss: 0.0007049727719277143\n",
      "Epoch 843, Loss: 0.0033367883588653058, Final Batch Loss: 0.00044460638309828937\n",
      "Epoch 844, Loss: 0.0027830724138766527, Final Batch Loss: 0.0012430059723556042\n",
      "Epoch 845, Loss: 0.030442440882325172, Final Batch Loss: 0.02579663321375847\n",
      "Epoch 846, Loss: 0.006967107066884637, Final Batch Loss: 0.0028602785896509886\n",
      "Epoch 847, Loss: 0.0018122998881153762, Final Batch Loss: 0.0006980400648899376\n",
      "Epoch 848, Loss: 0.011602442245930433, Final Batch Loss: 0.00589371845126152\n",
      "Epoch 849, Loss: 0.0033159131999127567, Final Batch Loss: 0.0007943757227621973\n",
      "Epoch 850, Loss: 0.00439927470870316, Final Batch Loss: 0.002094683237373829\n",
      "Epoch 851, Loss: 0.0023766960948705673, Final Batch Loss: 0.0012915993575006723\n",
      "Epoch 852, Loss: 0.007378010544925928, Final Batch Loss: 0.0016730115748941898\n",
      "Epoch 853, Loss: 0.008007960161194205, Final Batch Loss: 0.004238944035023451\n",
      "Epoch 854, Loss: 0.004864859860390425, Final Batch Loss: 0.0019036347512155771\n",
      "Epoch 855, Loss: 0.008791000582277775, Final Batch Loss: 0.005164429545402527\n",
      "Epoch 856, Loss: 0.005520257167518139, Final Batch Loss: 0.0012426846660673618\n",
      "Epoch 857, Loss: 0.00839982321485877, Final Batch Loss: 0.0005968851037323475\n",
      "Epoch 858, Loss: 0.002257172018289566, Final Batch Loss: 0.001249235006980598\n",
      "Epoch 859, Loss: 0.0028807477792724967, Final Batch Loss: 0.0014084512367844582\n",
      "Epoch 860, Loss: 0.00424132461193949, Final Batch Loss: 0.0011200549779459834\n",
      "Epoch 861, Loss: 0.01166455214843154, Final Batch Loss: 0.0041063325479626656\n",
      "Epoch 862, Loss: 0.003852216526865959, Final Batch Loss: 0.001884653465822339\n",
      "Epoch 863, Loss: 0.009923454374074936, Final Batch Loss: 0.007777540013194084\n",
      "Epoch 864, Loss: 0.024473052471876144, Final Batch Loss: 0.008185066282749176\n",
      "Epoch 865, Loss: 0.0038417254108935595, Final Batch Loss: 0.0011698040179908276\n",
      "Epoch 866, Loss: 0.003408406861126423, Final Batch Loss: 0.0015544700436294079\n",
      "Epoch 867, Loss: 0.00791933829896152, Final Batch Loss: 0.0021787185687571764\n",
      "Epoch 868, Loss: 0.004356510355137289, Final Batch Loss: 0.001669883611612022\n",
      "Epoch 869, Loss: 0.002972556452732533, Final Batch Loss: 0.0007283749873749912\n",
      "Epoch 870, Loss: 0.005139783024787903, Final Batch Loss: 0.0035860994830727577\n",
      "Epoch 871, Loss: 0.005317269475199282, Final Batch Loss: 0.0018478726269677281\n",
      "Epoch 872, Loss: 0.01961096259765327, Final Batch Loss: 0.01745169423520565\n",
      "Epoch 873, Loss: 0.007137194508686662, Final Batch Loss: 0.00035090907476842403\n",
      "Epoch 874, Loss: 0.0037652722094208, Final Batch Loss: 0.0018096980638802052\n",
      "Epoch 875, Loss: 0.005345771729480475, Final Batch Loss: 0.0007559817167930305\n",
      "Epoch 876, Loss: 0.02328529115766287, Final Batch Loss: 0.0009397352114319801\n",
      "Epoch 877, Loss: 0.00822207098826766, Final Batch Loss: 0.002952947746962309\n",
      "Epoch 878, Loss: 0.0025660605751909316, Final Batch Loss: 0.0017719932366162539\n",
      "Epoch 879, Loss: 0.003926402423530817, Final Batch Loss: 0.0019616768695414066\n",
      "Epoch 880, Loss: 0.0074853983242064714, Final Batch Loss: 0.004255921579897404\n",
      "Epoch 881, Loss: 0.039306572172790766, Final Batch Loss: 0.033426713198423386\n",
      "Epoch 882, Loss: 0.003113836399279535, Final Batch Loss: 0.0009037625277414918\n",
      "Epoch 883, Loss: 0.016449932125397027, Final Batch Loss: 0.0012225686805322766\n",
      "Epoch 884, Loss: 0.002374082920141518, Final Batch Loss: 0.0003059398150071502\n",
      "Epoch 885, Loss: 0.009596977150067687, Final Batch Loss: 0.005889805033802986\n",
      "Epoch 886, Loss: 0.00826934538781643, Final Batch Loss: 0.0039507062174379826\n",
      "Epoch 887, Loss: 0.012540784198790789, Final Batch Loss: 0.004541380796581507\n",
      "Epoch 888, Loss: 0.00835114362416789, Final Batch Loss: 0.0006955821882002056\n",
      "Epoch 889, Loss: 0.011001819744706154, Final Batch Loss: 0.00044292211532592773\n",
      "Epoch 890, Loss: 0.016671270597726107, Final Batch Loss: 0.001089258585125208\n",
      "Epoch 891, Loss: 0.009087523445487022, Final Batch Loss: 0.007014255505055189\n",
      "Epoch 892, Loss: 0.006470247404649854, Final Batch Loss: 0.004457232542335987\n",
      "Epoch 893, Loss: 0.0038083252729848027, Final Batch Loss: 0.0022694645449519157\n",
      "Epoch 894, Loss: 0.011797775281593204, Final Batch Loss: 0.008539010770618916\n",
      "Epoch 895, Loss: 0.012767781387083232, Final Batch Loss: 0.010872569866478443\n",
      "Epoch 896, Loss: 0.0028948442777618766, Final Batch Loss: 0.0013999150833114982\n",
      "Epoch 897, Loss: 0.007559951161965728, Final Batch Loss: 0.0025027485098689795\n",
      "Epoch 898, Loss: 0.004842584021389484, Final Batch Loss: 0.004188229329884052\n",
      "Epoch 899, Loss: 0.004681030288338661, Final Batch Loss: 0.0010056227911263704\n",
      "Epoch 900, Loss: 0.002907114860136062, Final Batch Loss: 0.0008841348462738097\n",
      "Epoch 901, Loss: 0.0036548213101923466, Final Batch Loss: 0.0009379638358950615\n",
      "Epoch 902, Loss: 0.012266825884580612, Final Batch Loss: 0.0020278850570321083\n",
      "Epoch 903, Loss: 0.005220163031481206, Final Batch Loss: 0.004579309839755297\n",
      "Epoch 904, Loss: 0.00863283802755177, Final Batch Loss: 0.005894714500755072\n",
      "Epoch 905, Loss: 0.00331690174061805, Final Batch Loss: 0.002619369886815548\n",
      "Epoch 906, Loss: 0.001869615982286632, Final Batch Loss: 0.0005802587838843465\n",
      "Epoch 907, Loss: 0.002014855679590255, Final Batch Loss: 0.0008156030089594424\n",
      "Epoch 908, Loss: 0.016444626555312425, Final Batch Loss: 0.01580066978931427\n",
      "Epoch 909, Loss: 0.009261296829208732, Final Batch Loss: 0.003592739114537835\n",
      "Epoch 910, Loss: 0.019909883849322796, Final Batch Loss: 0.011402682401239872\n",
      "Epoch 911, Loss: 0.005490181501954794, Final Batch Loss: 0.0011766282841563225\n",
      "Epoch 912, Loss: 0.0025287471362389624, Final Batch Loss: 0.000652120157610625\n",
      "Epoch 913, Loss: 0.007719852961599827, Final Batch Loss: 0.0037045255303382874\n",
      "Epoch 914, Loss: 0.014714975550305098, Final Batch Loss: 0.014187642373144627\n",
      "Epoch 915, Loss: 0.007661675568670034, Final Batch Loss: 0.00561156403273344\n",
      "Epoch 916, Loss: 0.003496858407743275, Final Batch Loss: 0.0009232229785993695\n",
      "Epoch 917, Loss: 0.004989330656826496, Final Batch Loss: 0.002417262876406312\n",
      "Epoch 918, Loss: 0.005899018608033657, Final Batch Loss: 0.0032528103329241276\n",
      "Epoch 919, Loss: 0.004921481013298035, Final Batch Loss: 0.0012808104511350393\n",
      "Epoch 920, Loss: 0.004800462047569454, Final Batch Loss: 0.0014030389720574021\n",
      "Epoch 921, Loss: 0.003237935481593013, Final Batch Loss: 0.0024825653526932\n",
      "Epoch 922, Loss: 0.00581694021821022, Final Batch Loss: 0.003257175674661994\n",
      "Epoch 923, Loss: 0.01879135798662901, Final Batch Loss: 0.005849212408065796\n",
      "Epoch 924, Loss: 0.002563939895480871, Final Batch Loss: 0.0014394002500921488\n",
      "Epoch 925, Loss: 0.005918740411289036, Final Batch Loss: 0.004655258730053902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 926, Loss: 0.004655076889321208, Final Batch Loss: 0.002500997157767415\n",
      "Epoch 927, Loss: 0.02708330750465393, Final Batch Loss: 0.024256113916635513\n",
      "Epoch 928, Loss: 0.0026006398256868124, Final Batch Loss: 0.00192064861766994\n",
      "Epoch 929, Loss: 0.02230604854412377, Final Batch Loss: 0.0011125740129500628\n",
      "Epoch 930, Loss: 0.005563282524235547, Final Batch Loss: 0.004230324178934097\n",
      "Epoch 931, Loss: 0.014404960151296109, Final Batch Loss: 0.000615398574154824\n",
      "Epoch 932, Loss: 0.0035347369266673923, Final Batch Loss: 0.0022980719804763794\n",
      "Epoch 933, Loss: 0.0046410911018028855, Final Batch Loss: 0.004030690528452396\n",
      "Epoch 934, Loss: 0.009252659743651748, Final Batch Loss: 0.0036670032422989607\n",
      "Epoch 935, Loss: 0.005015574744902551, Final Batch Loss: 0.003884598147124052\n",
      "Epoch 936, Loss: 0.002857551851775497, Final Batch Loss: 0.0006830107304267585\n",
      "Epoch 937, Loss: 0.004531335667707026, Final Batch Loss: 0.0028175462502986193\n",
      "Epoch 938, Loss: 0.00274854275630787, Final Batch Loss: 0.0006349529721774161\n",
      "Epoch 939, Loss: 0.012989853858016431, Final Batch Loss: 0.011399449780583382\n",
      "Epoch 940, Loss: 0.01334846462123096, Final Batch Loss: 0.010931876488029957\n",
      "Epoch 941, Loss: 0.0018788358429446816, Final Batch Loss: 0.0006594221340492368\n",
      "Epoch 942, Loss: 0.006777484435588121, Final Batch Loss: 0.0007376573048532009\n",
      "Epoch 943, Loss: 0.002861275163013488, Final Batch Loss: 0.0023067595902830362\n",
      "Epoch 944, Loss: 0.00801619398407638, Final Batch Loss: 0.00212971237488091\n",
      "Epoch 945, Loss: 0.004385680018458515, Final Batch Loss: 0.0005775993340648711\n",
      "Epoch 946, Loss: 0.021210608072578907, Final Batch Loss: 0.0184251107275486\n",
      "Epoch 947, Loss: 0.0029355984879657626, Final Batch Loss: 0.0013879030011594296\n",
      "Epoch 948, Loss: 0.002639185870066285, Final Batch Loss: 0.002096130046993494\n",
      "Epoch 949, Loss: 0.029858384281396866, Final Batch Loss: 0.027874775230884552\n",
      "Epoch 950, Loss: 0.007760788546875119, Final Batch Loss: 0.002797287655994296\n",
      "Epoch 951, Loss: 0.002226046985015273, Final Batch Loss: 0.0011894790222868323\n",
      "Epoch 952, Loss: 0.0024359350791200995, Final Batch Loss: 0.001584098907187581\n",
      "Epoch 953, Loss: 0.004391384427435696, Final Batch Loss: 0.003336317604407668\n",
      "Epoch 954, Loss: 0.006066511443350464, Final Batch Loss: 0.005536458920687437\n",
      "Epoch 955, Loss: 0.024399995571002364, Final Batch Loss: 0.002525187795981765\n",
      "Epoch 956, Loss: 0.002454678586218506, Final Batch Loss: 0.0015973354456946254\n",
      "Epoch 957, Loss: 0.001934426836669445, Final Batch Loss: 0.0011335411109030247\n",
      "Epoch 958, Loss: 0.004718645359389484, Final Batch Loss: 0.0005294185830280185\n",
      "Epoch 959, Loss: 0.0038473334861919284, Final Batch Loss: 0.0011067736195400357\n",
      "Epoch 960, Loss: 0.004093529307283461, Final Batch Loss: 0.002972760470584035\n",
      "Epoch 961, Loss: 0.012162172701209784, Final Batch Loss: 0.004696868825703859\n",
      "Epoch 962, Loss: 0.008195949019864202, Final Batch Loss: 0.0023363230284303427\n",
      "Epoch 963, Loss: 0.0030518779531121254, Final Batch Loss: 0.0010209642350673676\n",
      "Epoch 964, Loss: 0.005404451745562255, Final Batch Loss: 0.0015883244341239333\n",
      "Epoch 965, Loss: 0.02417021046858281, Final Batch Loss: 0.0012216585455462337\n",
      "Epoch 966, Loss: 0.0038702060701325536, Final Batch Loss: 0.002031453652307391\n",
      "Epoch 967, Loss: 0.008232444291934371, Final Batch Loss: 0.001346097094938159\n",
      "Epoch 968, Loss: 0.013547475915402174, Final Batch Loss: 0.004965633619576693\n",
      "Epoch 969, Loss: 0.0013592459727078676, Final Batch Loss: 0.000823195674456656\n",
      "Epoch 970, Loss: 0.00780866970308125, Final Batch Loss: 0.0024928550701588392\n",
      "Epoch 971, Loss: 0.009478069841861725, Final Batch Loss: 0.007363287732005119\n",
      "Epoch 972, Loss: 0.004256719374097884, Final Batch Loss: 0.0010341081069782376\n",
      "Epoch 973, Loss: 0.0074055916629731655, Final Batch Loss: 0.004275142215192318\n",
      "Epoch 974, Loss: 0.0064430925995111465, Final Batch Loss: 0.00242806039750576\n",
      "Epoch 975, Loss: 0.0019935013842768967, Final Batch Loss: 0.0005708590033464134\n",
      "Epoch 976, Loss: 0.002425063867121935, Final Batch Loss: 0.0012306763092055917\n",
      "Epoch 977, Loss: 0.002920362167060375, Final Batch Loss: 0.0006841809954494238\n",
      "Epoch 978, Loss: 0.0027153586561325938, Final Batch Loss: 0.00038293367833830416\n",
      "Epoch 979, Loss: 0.001799313526134938, Final Batch Loss: 0.0002543606678955257\n",
      "Epoch 980, Loss: 0.004070545081049204, Final Batch Loss: 0.0027579779271036386\n",
      "Epoch 981, Loss: 0.007773002376779914, Final Batch Loss: 0.006392822600901127\n",
      "Epoch 982, Loss: 0.002332237083464861, Final Batch Loss: 0.0012250045547261834\n",
      "Epoch 983, Loss: 0.011223025619983673, Final Batch Loss: 0.0021262122318148613\n",
      "Epoch 984, Loss: 0.01131912600249052, Final Batch Loss: 0.006657746154814959\n",
      "Epoch 985, Loss: 0.005819567944854498, Final Batch Loss: 0.003836591960862279\n",
      "Epoch 986, Loss: 0.004006696632131934, Final Batch Loss: 0.002359450561925769\n",
      "Epoch 987, Loss: 0.004125472158193588, Final Batch Loss: 0.0027405880391597748\n",
      "Epoch 988, Loss: 0.016805545426905155, Final Batch Loss: 0.007990334182977676\n",
      "Epoch 989, Loss: 0.011557456571608782, Final Batch Loss: 0.0012570503167808056\n",
      "Epoch 990, Loss: 0.002529512858018279, Final Batch Loss: 0.0005210130475461483\n",
      "Epoch 991, Loss: 0.01500514755025506, Final Batch Loss: 0.005870479624718428\n",
      "Epoch 992, Loss: 0.0026460446533747017, Final Batch Loss: 0.0006890816730447114\n",
      "Epoch 993, Loss: 0.003468616458121687, Final Batch Loss: 0.002998771844431758\n",
      "Epoch 994, Loss: 0.007165729068219662, Final Batch Loss: 0.0014711744152009487\n",
      "Epoch 995, Loss: 0.0036625955253839493, Final Batch Loss: 0.001412178622558713\n",
      "Epoch 996, Loss: 0.0028916223673149943, Final Batch Loss: 0.0011213861871510744\n",
      "Epoch 997, Loss: 0.0031114531157072634, Final Batch Loss: 0.0026674254331737757\n",
      "Epoch 998, Loss: 0.0017557884566485882, Final Batch Loss: 0.0005103069124743342\n",
      "Epoch 999, Loss: 0.0017026627319864929, Final Batch Loss: 0.0010380159365013242\n",
      "Epoch 1000, Loss: 0.0014531908964272588, Final Batch Loss: 0.001183014246635139\n",
      "Epoch 1001, Loss: 0.0023235054686665535, Final Batch Loss: 0.000593431992456317\n",
      "Epoch 1002, Loss: 0.003358499438036233, Final Batch Loss: 0.002776368986815214\n",
      "Epoch 1003, Loss: 0.02430446119979024, Final Batch Loss: 0.003399659413844347\n",
      "Epoch 1004, Loss: 0.003153136756736785, Final Batch Loss: 0.0022123761009424925\n",
      "Epoch 1005, Loss: 0.009760240092873573, Final Batch Loss: 0.008135534822940826\n",
      "Epoch 1006, Loss: 0.006143252132460475, Final Batch Loss: 0.001987996743991971\n",
      "Epoch 1007, Loss: 0.001488674315623939, Final Batch Loss: 0.0008379817008972168\n",
      "Epoch 1008, Loss: 0.02182248653843999, Final Batch Loss: 0.00601072097197175\n",
      "Epoch 1009, Loss: 0.01640253933146596, Final Batch Loss: 0.009720657020807266\n",
      "Epoch 1010, Loss: 0.005575945368036628, Final Batch Loss: 0.0020790528506040573\n",
      "Epoch 1011, Loss: 0.0011413667816668749, Final Batch Loss: 0.0005793367163278162\n",
      "Epoch 1012, Loss: 0.004146867664530873, Final Batch Loss: 0.0009404206648468971\n",
      "Epoch 1013, Loss: 0.0023416243493556976, Final Batch Loss: 0.0005478522507473826\n",
      "Epoch 1014, Loss: 0.0033467336324974895, Final Batch Loss: 0.0015145685756579041\n",
      "Epoch 1015, Loss: 0.011463475588243455, Final Batch Loss: 0.0007481027278117836\n",
      "Epoch 1016, Loss: 0.02300678670872003, Final Batch Loss: 0.021230114623904228\n",
      "Epoch 1017, Loss: 0.005814273958094418, Final Batch Loss: 0.0010357537539675832\n",
      "Epoch 1018, Loss: 0.003335722256451845, Final Batch Loss: 0.002195357345044613\n",
      "Epoch 1019, Loss: 0.003908719634637237, Final Batch Loss: 0.0015788248274475336\n",
      "Epoch 1020, Loss: 0.004572813166305423, Final Batch Loss: 0.0022945126984268427\n",
      "Epoch 1021, Loss: 0.008507505408488214, Final Batch Loss: 0.006629308219999075\n",
      "Epoch 1022, Loss: 0.0026764818467199802, Final Batch Loss: 0.001756153884343803\n",
      "Epoch 1023, Loss: 0.010644707130268216, Final Batch Loss: 0.00698293000459671\n",
      "Epoch 1024, Loss: 0.01908768154680729, Final Batch Loss: 0.005465971305966377\n",
      "Epoch 1025, Loss: 0.002561316854553297, Final Batch Loss: 0.00033472225186415017\n",
      "Epoch 1026, Loss: 0.0064035390969365835, Final Batch Loss: 0.0007569992449134588\n",
      "Epoch 1027, Loss: 0.0028223116241861135, Final Batch Loss: 0.0023442062083631754\n",
      "Epoch 1028, Loss: 0.013076473493129015, Final Batch Loss: 0.010246708057820797\n",
      "Epoch 1029, Loss: 0.012133568874560297, Final Batch Loss: 0.0007244361331686378\n",
      "Epoch 1030, Loss: 0.0010121030791196972, Final Batch Loss: 0.000401237077312544\n",
      "Epoch 1031, Loss: 0.027854014420881867, Final Batch Loss: 0.02434413880109787\n",
      "Epoch 1032, Loss: 0.005743301473557949, Final Batch Loss: 0.004668194800615311\n",
      "Epoch 1033, Loss: 0.003073513275012374, Final Batch Loss: 0.0006095387507230043\n",
      "Epoch 1034, Loss: 0.002183327917009592, Final Batch Loss: 0.0014859820948913693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1035, Loss: 0.008009530254639685, Final Batch Loss: 0.0012965324567630887\n",
      "Epoch 1036, Loss: 0.0019685113220475614, Final Batch Loss: 0.001181532978080213\n",
      "Epoch 1037, Loss: 0.01087619224563241, Final Batch Loss: 0.00603294325992465\n",
      "Epoch 1038, Loss: 0.004398639895953238, Final Batch Loss: 0.001898465328849852\n",
      "Epoch 1039, Loss: 0.010312998085282743, Final Batch Loss: 0.0015074660768732429\n",
      "Epoch 1040, Loss: 0.0015693025197833776, Final Batch Loss: 0.0011554339434951544\n",
      "Epoch 1041, Loss: 0.0021894396049901843, Final Batch Loss: 0.001656784093938768\n",
      "Epoch 1042, Loss: 0.007742363726720214, Final Batch Loss: 0.006496134214103222\n",
      "Epoch 1043, Loss: 0.012964450870640576, Final Batch Loss: 0.011410748586058617\n",
      "Epoch 1044, Loss: 0.003194603603333235, Final Batch Loss: 0.0019201257964596152\n",
      "Epoch 1045, Loss: 0.007546411477960646, Final Batch Loss: 0.000387864769436419\n",
      "Epoch 1046, Loss: 0.021284335292875767, Final Batch Loss: 0.014570859260857105\n",
      "Epoch 1047, Loss: 0.0029814204899594188, Final Batch Loss: 0.0022057180758565664\n",
      "Epoch 1048, Loss: 0.002353358664549887, Final Batch Loss: 0.0019705621525645256\n",
      "Epoch 1049, Loss: 0.0011004885309375823, Final Batch Loss: 0.000587361108046025\n",
      "Epoch 1050, Loss: 0.002080763690173626, Final Batch Loss: 0.0006628716364502907\n",
      "Epoch 1051, Loss: 0.0115055424394086, Final Batch Loss: 0.0015439094277098775\n",
      "Epoch 1052, Loss: 0.0021903205197304487, Final Batch Loss: 0.0007676691748201847\n",
      "Epoch 1053, Loss: 0.0012070540979038924, Final Batch Loss: 0.000473734486149624\n",
      "Epoch 1054, Loss: 0.0030501019791699946, Final Batch Loss: 0.0020880152005702257\n",
      "Epoch 1055, Loss: 0.004113259841687977, Final Batch Loss: 0.002491337014362216\n",
      "Epoch 1056, Loss: 0.005772219272330403, Final Batch Loss: 0.0013825774658471346\n",
      "Epoch 1057, Loss: 0.004141738871112466, Final Batch Loss: 0.0030874707736074924\n",
      "Epoch 1058, Loss: 0.002141995122656226, Final Batch Loss: 0.0005100416019558907\n",
      "Epoch 1059, Loss: 0.003778739017434418, Final Batch Loss: 0.001065655262209475\n",
      "Epoch 1060, Loss: 0.020664845447754487, Final Batch Loss: 0.020224619656801224\n",
      "Epoch 1061, Loss: 0.002524767885915935, Final Batch Loss: 0.0007632854394614697\n",
      "Epoch 1062, Loss: 0.0017382016812916845, Final Batch Loss: 0.0013656927039846778\n",
      "Epoch 1063, Loss: 0.008486700826324522, Final Batch Loss: 0.007192128337919712\n",
      "Epoch 1064, Loss: 0.002421656041406095, Final Batch Loss: 0.0010093622840940952\n",
      "Epoch 1065, Loss: 0.0018218058976344764, Final Batch Loss: 0.0015571994008496404\n",
      "Epoch 1066, Loss: 0.013815227895975113, Final Batch Loss: 0.007762975059449673\n",
      "Epoch 1067, Loss: 0.002661125618033111, Final Batch Loss: 0.0006374296499416232\n",
      "Epoch 1068, Loss: 0.0033028158359229565, Final Batch Loss: 0.0019197280053049326\n",
      "Epoch 1069, Loss: 0.001424942398443818, Final Batch Loss: 0.0006693004979752004\n",
      "Epoch 1070, Loss: 0.006872918573208153, Final Batch Loss: 0.0050719608552753925\n",
      "Epoch 1071, Loss: 0.022198813036084175, Final Batch Loss: 0.00931139662861824\n",
      "Epoch 1072, Loss: 0.006350021983962506, Final Batch Loss: 0.0007115958142094314\n",
      "Epoch 1073, Loss: 0.0018058005953207612, Final Batch Loss: 0.0009307897416874766\n",
      "Epoch 1074, Loss: 0.004331765579991043, Final Batch Loss: 0.0032414209563285112\n",
      "Epoch 1075, Loss: 0.001512632763478905, Final Batch Loss: 0.0011245341738685966\n",
      "Epoch 1076, Loss: 0.0018463341984897852, Final Batch Loss: 0.00027047167532145977\n",
      "Epoch 1077, Loss: 0.003121422487311065, Final Batch Loss: 0.002519321395084262\n",
      "Epoch 1078, Loss: 0.008112716546747833, Final Batch Loss: 0.0009110854589380324\n",
      "Epoch 1079, Loss: 0.0118938867963152, Final Batch Loss: 0.00014118543185759336\n",
      "Epoch 1080, Loss: 0.007474667567294091, Final Batch Loss: 0.006689427886158228\n",
      "Epoch 1081, Loss: 0.007840808830223978, Final Batch Loss: 0.0071419463492929935\n",
      "Epoch 1082, Loss: 0.005160429864190519, Final Batch Loss: 0.0013004328357055783\n",
      "Epoch 1083, Loss: 0.0013561291561927646, Final Batch Loss: 0.00047283232561312616\n",
      "Epoch 1084, Loss: 0.002554135862737894, Final Batch Loss: 0.0012866925681009889\n",
      "Epoch 1085, Loss: 0.0026926142745651305, Final Batch Loss: 0.0007146765128709376\n",
      "Epoch 1086, Loss: 0.011611334048211575, Final Batch Loss: 0.006895767990499735\n",
      "Epoch 1087, Loss: 0.006392806186340749, Final Batch Loss: 0.004464895464479923\n",
      "Epoch 1088, Loss: 0.0017836315091699362, Final Batch Loss: 0.0014732637209817767\n",
      "Epoch 1089, Loss: 0.008706748252734542, Final Batch Loss: 0.0024575304705649614\n",
      "Epoch 1090, Loss: 0.0042277127504348755, Final Batch Loss: 0.0031041521579027176\n",
      "Epoch 1091, Loss: 0.0020662390743382275, Final Batch Loss: 0.0012896159896627069\n",
      "Epoch 1092, Loss: 0.00342488382011652, Final Batch Loss: 0.001578838680870831\n",
      "Epoch 1093, Loss: 0.02900015376508236, Final Batch Loss: 0.028452210128307343\n",
      "Epoch 1094, Loss: 0.0029577011591754854, Final Batch Loss: 0.0021805947180837393\n",
      "Epoch 1095, Loss: 0.0054884133860468864, Final Batch Loss: 0.0019630782771855593\n",
      "Epoch 1096, Loss: 0.00242677895585075, Final Batch Loss: 0.0005723863723687828\n",
      "Epoch 1097, Loss: 0.004020386841148138, Final Batch Loss: 0.0029338127933442593\n",
      "Epoch 1098, Loss: 0.006221166520845145, Final Batch Loss: 0.0009182004141621292\n",
      "Epoch 1099, Loss: 0.00281644327333197, Final Batch Loss: 0.0007138579967431724\n",
      "Epoch 1100, Loss: 0.0037205880507826805, Final Batch Loss: 0.0013370239175856113\n",
      "Epoch 1101, Loss: 0.0021033656084910035, Final Batch Loss: 0.0012121880427002907\n",
      "Epoch 1102, Loss: 0.003090625919867307, Final Batch Loss: 0.0005795923643745482\n",
      "Epoch 1103, Loss: 0.007760670268908143, Final Batch Loss: 0.003108970122411847\n",
      "Epoch 1104, Loss: 0.0037750283954665065, Final Batch Loss: 0.0015231085708364844\n",
      "Epoch 1105, Loss: 0.001722737099044025, Final Batch Loss: 0.0008825176628306508\n",
      "Epoch 1106, Loss: 0.003385174786671996, Final Batch Loss: 0.001241020392626524\n",
      "Epoch 1107, Loss: 0.003147346433252096, Final Batch Loss: 0.0025386211927980185\n",
      "Epoch 1108, Loss: 0.0011996181565336883, Final Batch Loss: 0.00035321508767083287\n",
      "Epoch 1109, Loss: 0.0066765270894393325, Final Batch Loss: 0.001660337089560926\n",
      "Epoch 1110, Loss: 0.0026159457047469914, Final Batch Loss: 0.001761485356837511\n",
      "Epoch 1111, Loss: 0.0028294422663748264, Final Batch Loss: 0.0017332563875243068\n",
      "Epoch 1112, Loss: 0.002743337448919192, Final Batch Loss: 0.00047454648301936686\n",
      "Epoch 1113, Loss: 0.004205013858154416, Final Batch Loss: 0.001052146079018712\n",
      "Epoch 1114, Loss: 0.003901600488461554, Final Batch Loss: 0.002595579018816352\n",
      "Epoch 1115, Loss: 0.02312110085040331, Final Batch Loss: 0.015139550901949406\n",
      "Epoch 1116, Loss: 0.00333142071031034, Final Batch Loss: 0.0007945685647428036\n",
      "Epoch 1117, Loss: 0.013916868017986417, Final Batch Loss: 0.0038104180712252855\n",
      "Epoch 1118, Loss: 0.010173521004617214, Final Batch Loss: 0.0047559356316924095\n",
      "Epoch 1119, Loss: 0.00524167949333787, Final Batch Loss: 0.003311365144327283\n",
      "Epoch 1120, Loss: 0.00379242718918249, Final Batch Loss: 0.0028586075641214848\n",
      "Epoch 1121, Loss: 0.004219751921482384, Final Batch Loss: 0.0015365685103461146\n",
      "Epoch 1122, Loss: 0.00248638354241848, Final Batch Loss: 0.0014195628464221954\n",
      "Epoch 1123, Loss: 0.0011816308251582086, Final Batch Loss: 0.0002478767419233918\n",
      "Epoch 1124, Loss: 0.0015854747034609318, Final Batch Loss: 0.0006161614437587559\n",
      "Epoch 1125, Loss: 0.0013643934798892587, Final Batch Loss: 0.00046243422548286617\n",
      "Epoch 1126, Loss: 0.0075127927120774984, Final Batch Loss: 0.00325312209315598\n",
      "Epoch 1127, Loss: 0.0012808517494704574, Final Batch Loss: 0.0009629379492253065\n",
      "Epoch 1128, Loss: 0.0321473591029644, Final Batch Loss: 0.022667599841952324\n",
      "Epoch 1129, Loss: 0.012834318447858095, Final Batch Loss: 0.00931367464363575\n",
      "Epoch 1130, Loss: 0.008217819733545184, Final Batch Loss: 0.0030172697734087706\n",
      "Epoch 1131, Loss: 0.008322839974425733, Final Batch Loss: 0.00726022943854332\n",
      "Epoch 1132, Loss: 0.0029454983305186033, Final Batch Loss: 0.0009236643090844154\n",
      "Epoch 1133, Loss: 0.00196019874420017, Final Batch Loss: 0.00035419350024312735\n",
      "Epoch 1134, Loss: 0.0014413615863304585, Final Batch Loss: 0.001092993188649416\n",
      "Epoch 1135, Loss: 0.0025759870768524706, Final Batch Loss: 0.0006453676032833755\n",
      "Epoch 1136, Loss: 0.00630907341837883, Final Batch Loss: 0.002070276066660881\n",
      "Epoch 1137, Loss: 0.005191163712879643, Final Batch Loss: 0.00030534350662492216\n",
      "Epoch 1138, Loss: 0.004414519295096397, Final Batch Loss: 0.0035521991085261106\n",
      "Epoch 1139, Loss: 0.004581099841743708, Final Batch Loss: 0.0032969098538160324\n",
      "Epoch 1140, Loss: 0.011374824214726686, Final Batch Loss: 0.0065730419009923935\n",
      "Epoch 1141, Loss: 0.01365217100828886, Final Batch Loss: 0.007066319230943918\n",
      "Epoch 1142, Loss: 0.016892633866518736, Final Batch Loss: 0.007299619261175394\n",
      "Epoch 1143, Loss: 0.020227232482284307, Final Batch Loss: 0.014591678977012634\n",
      "Epoch 1144, Loss: 0.0032511490862816572, Final Batch Loss: 0.0009356783702969551\n",
      "Epoch 1145, Loss: 0.002516056760214269, Final Batch Loss: 0.0011035852367058396\n",
      "Epoch 1146, Loss: 0.003726763156009838, Final Batch Loss: 0.00034188569406978786\n",
      "Epoch 1147, Loss: 0.0011755191953852773, Final Batch Loss: 0.0006330660544335842\n",
      "Epoch 1148, Loss: 0.003670646343380213, Final Batch Loss: 0.0024221271742135286\n",
      "Epoch 1149, Loss: 0.017504213959909976, Final Batch Loss: 0.0013535903999581933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1150, Loss: 0.0011240105231991038, Final Batch Loss: 0.0001656705717323348\n",
      "Epoch 1151, Loss: 0.007607075618579984, Final Batch Loss: 0.0023198018316179514\n",
      "Epoch 1152, Loss: 0.0024561554891988635, Final Batch Loss: 0.0009801799897104502\n",
      "Epoch 1153, Loss: 0.002207638055551797, Final Batch Loss: 0.0013027387904003263\n",
      "Epoch 1154, Loss: 0.007211539428681135, Final Batch Loss: 0.001737395767122507\n",
      "Epoch 1155, Loss: 0.002989074564538896, Final Batch Loss: 0.001991592813283205\n",
      "Epoch 1156, Loss: 0.002414630842395127, Final Batch Loss: 0.0006268589058890939\n",
      "Epoch 1157, Loss: 0.0019189438899047673, Final Batch Loss: 0.0006232931627891958\n",
      "Epoch 1158, Loss: 0.021379902260378003, Final Batch Loss: 0.018774885684251785\n",
      "Epoch 1159, Loss: 0.0009015963587444276, Final Batch Loss: 0.0003105241630692035\n",
      "Epoch 1160, Loss: 0.0013785826158709824, Final Batch Loss: 0.000759374350309372\n",
      "Epoch 1161, Loss: 0.005928198108449578, Final Batch Loss: 0.005650896113365889\n",
      "Epoch 1162, Loss: 0.018556511029601097, Final Batch Loss: 0.009057722054421902\n",
      "Epoch 1163, Loss: 0.002985238010296598, Final Batch Loss: 0.0026438941713422537\n",
      "Epoch 1164, Loss: 0.012574285152368248, Final Batch Loss: 0.01164321880787611\n",
      "Epoch 1165, Loss: 0.0024022102588787675, Final Batch Loss: 0.0008743666112422943\n",
      "Epoch 1166, Loss: 0.00386790675111115, Final Batch Loss: 0.0008162714075297117\n",
      "Epoch 1167, Loss: 0.000984751241048798, Final Batch Loss: 0.0006309777963906527\n",
      "Epoch 1168, Loss: 0.009628221043385565, Final Batch Loss: 0.008246118202805519\n",
      "Epoch 1169, Loss: 0.005533793242648244, Final Batch Loss: 0.0005478153470903635\n",
      "Epoch 1170, Loss: 0.0011343889927957207, Final Batch Loss: 0.00044487204286269844\n",
      "Epoch 1171, Loss: 0.002973041031509638, Final Batch Loss: 0.0012257862836122513\n",
      "Epoch 1172, Loss: 0.033614908636081964, Final Batch Loss: 0.0005396803026087582\n",
      "Epoch 1173, Loss: 0.008005690295249224, Final Batch Loss: 0.007008022163063288\n",
      "Epoch 1174, Loss: 0.0025425704079680145, Final Batch Loss: 0.0007953642052598298\n",
      "Epoch 1175, Loss: 0.004313351004384458, Final Batch Loss: 0.003292718203738332\n",
      "Epoch 1176, Loss: 0.0017274071578867733, Final Batch Loss: 0.0006187784601934254\n",
      "Epoch 1177, Loss: 0.005600712087471038, Final Batch Loss: 0.000829182390589267\n",
      "Epoch 1178, Loss: 0.005014621565351263, Final Batch Loss: 0.00028751222998835146\n",
      "Epoch 1179, Loss: 0.0018472523079253733, Final Batch Loss: 0.0008436730713583529\n",
      "Epoch 1180, Loss: 0.0018578169401735067, Final Batch Loss: 0.0003925779601559043\n",
      "Epoch 1181, Loss: 0.0036293854791438207, Final Batch Loss: 0.00021304933761712164\n",
      "Epoch 1182, Loss: 0.0033383065601810813, Final Batch Loss: 0.0016305792378261685\n",
      "Epoch 1183, Loss: 0.003412464866414666, Final Batch Loss: 0.0013763727620244026\n",
      "Epoch 1184, Loss: 0.003703575232066214, Final Batch Loss: 0.0023921874817460775\n",
      "Epoch 1185, Loss: 0.007177431252785027, Final Batch Loss: 0.0006798628019168973\n",
      "Epoch 1186, Loss: 0.0018270721193403006, Final Batch Loss: 0.0004783590557053685\n",
      "Epoch 1187, Loss: 0.0009507350041531026, Final Batch Loss: 0.00037303700810298324\n",
      "Epoch 1188, Loss: 0.002467932761646807, Final Batch Loss: 0.0013234175276011229\n",
      "Epoch 1189, Loss: 0.013187970616854727, Final Batch Loss: 0.0005073441425338387\n",
      "Epoch 1190, Loss: 0.0031263691489584744, Final Batch Loss: 0.002836588304489851\n",
      "Epoch 1191, Loss: 0.0007872043206589296, Final Batch Loss: 0.00020618062990251929\n",
      "Epoch 1192, Loss: 0.002954529249109328, Final Batch Loss: 0.0008317256579175591\n",
      "Epoch 1193, Loss: 0.009863089653663337, Final Batch Loss: 0.0013858209131285548\n",
      "Epoch 1194, Loss: 0.0009620877972338349, Final Batch Loss: 0.00042847273289225996\n",
      "Epoch 1195, Loss: 0.0006887820782139897, Final Batch Loss: 0.0003228374116588384\n",
      "Epoch 1196, Loss: 0.003156073624268174, Final Batch Loss: 0.0005810395814478397\n",
      "Epoch 1197, Loss: 0.0023498243535868824, Final Batch Loss: 0.00020591652719303966\n",
      "Epoch 1198, Loss: 0.003700746630784124, Final Batch Loss: 0.0029089529998600483\n",
      "Epoch 1199, Loss: 0.002644454245455563, Final Batch Loss: 0.0014778785407543182\n",
      "Epoch 1200, Loss: 0.009994599386118352, Final Batch Loss: 0.008786085061728954\n",
      "Epoch 1201, Loss: 0.014112022356130183, Final Batch Loss: 0.0013821810716763139\n",
      "Epoch 1202, Loss: 0.0020600344287231565, Final Batch Loss: 0.00039768684655427933\n",
      "Epoch 1203, Loss: 0.012076353537850082, Final Batch Loss: 0.01051984541118145\n",
      "Epoch 1204, Loss: 0.007078997557982802, Final Batch Loss: 0.0031523907091468573\n",
      "Epoch 1205, Loss: 0.005026377737522125, Final Batch Loss: 0.0026118087116628885\n",
      "Epoch 1206, Loss: 0.0025362357264384627, Final Batch Loss: 0.0010550303850322962\n",
      "Epoch 1207, Loss: 0.004701277823187411, Final Batch Loss: 0.0004561120877042413\n",
      "Epoch 1208, Loss: 0.0008169515494955704, Final Batch Loss: 0.000626717577688396\n",
      "Epoch 1209, Loss: 0.0019908054964616895, Final Batch Loss: 0.0012569781392812729\n",
      "Epoch 1210, Loss: 0.002794759231619537, Final Batch Loss: 0.0017148980405181646\n",
      "Epoch 1211, Loss: 0.004480618896195665, Final Batch Loss: 0.00028935811133123934\n",
      "Epoch 1212, Loss: 0.002858891151845455, Final Batch Loss: 0.0020951239857822657\n",
      "Epoch 1213, Loss: 0.003990447847172618, Final Batch Loss: 0.000596560537815094\n",
      "Epoch 1214, Loss: 0.004150797205511481, Final Batch Loss: 0.0032647703774273396\n",
      "Epoch 1215, Loss: 0.0019854746060445905, Final Batch Loss: 0.0008557222317904234\n",
      "Epoch 1216, Loss: 0.0021086977794766426, Final Batch Loss: 0.0010503599187359214\n",
      "Epoch 1217, Loss: 0.004291172081138939, Final Batch Loss: 0.00355714769102633\n",
      "Epoch 1218, Loss: 0.0022914576111361384, Final Batch Loss: 0.0007773122051730752\n",
      "Epoch 1219, Loss: 0.003326027072034776, Final Batch Loss: 0.0022566707339137793\n",
      "Epoch 1220, Loss: 0.002150951186195016, Final Batch Loss: 0.000838450388982892\n",
      "Epoch 1221, Loss: 0.0017365305102430284, Final Batch Loss: 0.000972114794421941\n",
      "Epoch 1222, Loss: 0.0011676228605210781, Final Batch Loss: 0.0006891645025461912\n",
      "Epoch 1223, Loss: 0.0023422876256518066, Final Batch Loss: 0.00030316709307953715\n",
      "Epoch 1224, Loss: 0.0011785280075855553, Final Batch Loss: 0.0001571905449964106\n",
      "Epoch 1225, Loss: 0.0027499588613864034, Final Batch Loss: 0.0004454116278793663\n",
      "Epoch 1226, Loss: 0.0007996444473974407, Final Batch Loss: 0.0005346920806914568\n",
      "Epoch 1227, Loss: 0.007007822976447642, Final Batch Loss: 0.0012982190819457173\n",
      "Epoch 1228, Loss: 0.0031095671001821756, Final Batch Loss: 0.0005298072937875986\n",
      "Epoch 1229, Loss: 0.0015126834332477301, Final Batch Loss: 0.0003601459029596299\n",
      "Epoch 1230, Loss: 0.0017109851469285786, Final Batch Loss: 0.0006377874524332583\n",
      "Epoch 1231, Loss: 0.005214051983784884, Final Batch Loss: 0.0004607100854627788\n",
      "Epoch 1232, Loss: 0.008596341824159026, Final Batch Loss: 0.001180190360173583\n",
      "Epoch 1233, Loss: 0.003799807047471404, Final Batch Loss: 0.0013449874240905046\n",
      "Epoch 1234, Loss: 0.0035750052193179727, Final Batch Loss: 0.0016893950523808599\n",
      "Epoch 1235, Loss: 0.001305801997659728, Final Batch Loss: 0.00035011969157494605\n",
      "Epoch 1236, Loss: 0.0019577135681174695, Final Batch Loss: 0.00161567865870893\n",
      "Epoch 1237, Loss: 0.00600362999830395, Final Batch Loss: 0.00084018858615309\n",
      "Epoch 1238, Loss: 0.005052731954492629, Final Batch Loss: 0.00038258556742221117\n",
      "Epoch 1239, Loss: 0.0010312807571608573, Final Batch Loss: 0.00022617061040364206\n",
      "Epoch 1240, Loss: 0.0036348645226098597, Final Batch Loss: 0.0030595953576266766\n",
      "Epoch 1241, Loss: 0.006488888029707596, Final Batch Loss: 0.0003924225165974349\n",
      "Epoch 1242, Loss: 0.005465789814479649, Final Batch Loss: 0.003753910306841135\n",
      "Epoch 1243, Loss: 0.001778919599018991, Final Batch Loss: 0.0006862136069685221\n",
      "Epoch 1244, Loss: 0.0019313141237944365, Final Batch Loss: 0.0005211536772549152\n",
      "Epoch 1245, Loss: 0.008143605256918818, Final Batch Loss: 0.0009273146861232817\n",
      "Epoch 1246, Loss: 0.0009573960996931419, Final Batch Loss: 0.00019097495533060282\n",
      "Epoch 1247, Loss: 0.0023594434023834765, Final Batch Loss: 0.0005251988186500967\n",
      "Epoch 1248, Loss: 0.0017847154813352972, Final Batch Loss: 0.0013607959263026714\n",
      "Epoch 1249, Loss: 0.016790973022580147, Final Batch Loss: 0.008929586969316006\n",
      "Epoch 1250, Loss: 0.023159541771747172, Final Batch Loss: 0.0006587697425857186\n",
      "Epoch 1251, Loss: 0.0008850207086652517, Final Batch Loss: 0.000283638306427747\n",
      "Epoch 1252, Loss: 0.0011658537259791046, Final Batch Loss: 0.00029476472991518676\n",
      "Epoch 1253, Loss: 0.0012923636240884662, Final Batch Loss: 0.0008155701798386872\n",
      "Epoch 1254, Loss: 0.0018901462899520993, Final Batch Loss: 0.0006499059963971376\n",
      "Epoch 1255, Loss: 0.012608983786776662, Final Batch Loss: 0.001486367778852582\n",
      "Epoch 1256, Loss: 0.001803741353796795, Final Batch Loss: 0.00047719970461912453\n",
      "Epoch 1257, Loss: 0.0006860985595267266, Final Batch Loss: 0.0002512154169380665\n",
      "Epoch 1258, Loss: 0.0010701622522901744, Final Batch Loss: 0.00083897914737463\n",
      "Epoch 1259, Loss: 0.005018271738663316, Final Batch Loss: 0.0014409597497433424\n",
      "Epoch 1260, Loss: 0.0009045633196365088, Final Batch Loss: 0.0006364199798554182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1261, Loss: 0.01127381989499554, Final Batch Loss: 0.0006393938674591482\n",
      "Epoch 1262, Loss: 0.0009231408766936511, Final Batch Loss: 0.0003275836643297225\n",
      "Epoch 1263, Loss: 0.0010306708281859756, Final Batch Loss: 0.0005296553717926145\n",
      "Epoch 1264, Loss: 0.0033471488568466157, Final Batch Loss: 0.0004029331903439015\n",
      "Epoch 1265, Loss: 0.0026503773115109652, Final Batch Loss: 0.00043714416096918285\n",
      "Epoch 1266, Loss: 0.006950309267267585, Final Batch Loss: 0.0029534988570958376\n",
      "Epoch 1267, Loss: 0.034234834369271994, Final Batch Loss: 0.03130500391125679\n",
      "Epoch 1268, Loss: 0.0061232432490214705, Final Batch Loss: 0.001443310989998281\n",
      "Epoch 1269, Loss: 0.0022779309074394405, Final Batch Loss: 0.0008596180123277009\n",
      "Epoch 1270, Loss: 0.0017844915273599327, Final Batch Loss: 0.0011338618351146579\n",
      "Epoch 1271, Loss: 0.002323698776308447, Final Batch Loss: 0.0018957844004034996\n",
      "Epoch 1272, Loss: 0.0035137918312102556, Final Batch Loss: 0.0012494828552007675\n",
      "Epoch 1273, Loss: 0.007093778112903237, Final Batch Loss: 0.0016317584086209536\n",
      "Epoch 1274, Loss: 0.00746892427559942, Final Batch Loss: 0.0015692332526668906\n",
      "Epoch 1275, Loss: 0.0009331294568255544, Final Batch Loss: 0.00045004120329394937\n",
      "Epoch 1276, Loss: 0.003006519633345306, Final Batch Loss: 0.0022332954686135054\n",
      "Epoch 1277, Loss: 0.004395926604047418, Final Batch Loss: 0.0020521352998912334\n",
      "Epoch 1278, Loss: 0.012897433014586568, Final Batch Loss: 0.0031968115363270044\n",
      "Epoch 1279, Loss: 0.0024555421841796488, Final Batch Loss: 0.0002768194244708866\n",
      "Epoch 1280, Loss: 0.0037783480365760624, Final Batch Loss: 0.00021465105237439275\n",
      "Epoch 1281, Loss: 0.016651749378070235, Final Batch Loss: 0.0005384401883929968\n",
      "Epoch 1282, Loss: 0.0010128767462447286, Final Batch Loss: 0.0004306937335059047\n",
      "Epoch 1283, Loss: 0.0016098021005745977, Final Batch Loss: 0.0011716476874426007\n",
      "Epoch 1284, Loss: 0.0014509023749269545, Final Batch Loss: 0.0011443579569458961\n",
      "Epoch 1285, Loss: 0.01602743740659207, Final Batch Loss: 0.015363180078566074\n",
      "Epoch 1286, Loss: 0.004131050081923604, Final Batch Loss: 0.0019926459062844515\n",
      "Epoch 1287, Loss: 0.0011416369525250047, Final Batch Loss: 0.0006783505086787045\n",
      "Epoch 1288, Loss: 0.0016517125768586993, Final Batch Loss: 0.00046020420268177986\n",
      "Epoch 1289, Loss: 0.00262441040831618, Final Batch Loss: 0.0004038994375150651\n",
      "Epoch 1290, Loss: 0.0038178298709681258, Final Batch Loss: 0.000198927111341618\n",
      "Epoch 1291, Loss: 0.0010079763596877456, Final Batch Loss: 0.0006351175252348185\n",
      "Epoch 1292, Loss: 0.0011250452080275863, Final Batch Loss: 0.00036126599297858775\n",
      "Epoch 1293, Loss: 0.0020114096405450255, Final Batch Loss: 0.0017776755848899484\n",
      "Epoch 1294, Loss: 0.0024494811659678817, Final Batch Loss: 0.0005758842453360558\n",
      "Epoch 1295, Loss: 0.0013417877489700913, Final Batch Loss: 0.0009789721807464957\n",
      "Epoch 1296, Loss: 0.0008452218025922775, Final Batch Loss: 0.00031495210714638233\n",
      "Epoch 1297, Loss: 0.007283139799255878, Final Batch Loss: 0.00017074664356186986\n",
      "Epoch 1298, Loss: 0.00813779589952901, Final Batch Loss: 0.0005504841101355851\n",
      "Epoch 1299, Loss: 0.004302234621718526, Final Batch Loss: 0.000532457372173667\n",
      "Epoch 1300, Loss: 0.011874706018716097, Final Batch Loss: 0.005899887997657061\n",
      "Epoch 1301, Loss: 0.0021282981615513563, Final Batch Loss: 0.00047451991122215986\n",
      "Epoch 1302, Loss: 0.0018311351886950433, Final Batch Loss: 0.000818042375613004\n",
      "Epoch 1303, Loss: 0.0010376315913163126, Final Batch Loss: 0.00011391506996005774\n",
      "Epoch 1304, Loss: 0.006761423035641201, Final Batch Loss: 0.006573029328137636\n",
      "Epoch 1305, Loss: 0.0027102077146992087, Final Batch Loss: 0.00041856791358441114\n",
      "Epoch 1306, Loss: 0.013811788754537702, Final Batch Loss: 0.01149226725101471\n",
      "Epoch 1307, Loss: 0.0065532251028344035, Final Batch Loss: 0.0009647737024351954\n",
      "Epoch 1308, Loss: 0.003290837397798896, Final Batch Loss: 0.0011779945343732834\n",
      "Epoch 1309, Loss: 0.0017857484053820372, Final Batch Loss: 0.0005205331835895777\n",
      "Epoch 1310, Loss: 0.005148494034074247, Final Batch Loss: 0.0007930918363854289\n",
      "Epoch 1311, Loss: 0.0015197213215287775, Final Batch Loss: 0.00029073128825984895\n",
      "Epoch 1312, Loss: 0.027798408293165267, Final Batch Loss: 0.0006041113520041108\n",
      "Epoch 1313, Loss: 0.002189583203289658, Final Batch Loss: 0.00016634870553389192\n",
      "Epoch 1314, Loss: 0.007576884352602065, Final Batch Loss: 0.0067687975242733955\n",
      "Epoch 1315, Loss: 0.0006846318283351138, Final Batch Loss: 0.00021195855515543371\n",
      "Epoch 1316, Loss: 0.008599703520303592, Final Batch Loss: 0.0003707095456775278\n",
      "Epoch 1317, Loss: 0.001679851848166436, Final Batch Loss: 0.0012405191082507372\n",
      "Epoch 1318, Loss: 0.0028144606621935964, Final Batch Loss: 0.0021611982956528664\n",
      "Epoch 1319, Loss: 0.005109314224682748, Final Batch Loss: 0.0014047928852960467\n",
      "Epoch 1320, Loss: 0.007056280504912138, Final Batch Loss: 0.0005255625583231449\n",
      "Epoch 1321, Loss: 0.0018206363311037421, Final Batch Loss: 0.0006100924219936132\n",
      "Epoch 1322, Loss: 0.0011814269237220287, Final Batch Loss: 0.000762780022341758\n",
      "Epoch 1323, Loss: 0.0008615416591055691, Final Batch Loss: 0.00029208004707470536\n",
      "Epoch 1324, Loss: 0.05366964789573103, Final Batch Loss: 0.0008948311442509294\n",
      "Epoch 1325, Loss: 0.0007889278349466622, Final Batch Loss: 0.0003878020215779543\n",
      "Epoch 1326, Loss: 0.00536476873094216, Final Batch Loss: 0.0007872279384173453\n",
      "Epoch 1327, Loss: 0.0014154432574287057, Final Batch Loss: 0.00036035547964274883\n",
      "Epoch 1328, Loss: 0.0077059390605427325, Final Batch Loss: 0.00747928861528635\n",
      "Epoch 1329, Loss: 0.001127218216424808, Final Batch Loss: 0.0008743469370529056\n",
      "Epoch 1330, Loss: 0.012952565506566316, Final Batch Loss: 0.012278110720217228\n",
      "Epoch 1331, Loss: 0.0023208754719235003, Final Batch Loss: 0.0013774605467915535\n",
      "Epoch 1332, Loss: 0.003232338698580861, Final Batch Loss: 0.0017517880769446492\n",
      "Epoch 1333, Loss: 0.0022240648977458477, Final Batch Loss: 0.001229254761710763\n",
      "Epoch 1334, Loss: 0.01039659240632318, Final Batch Loss: 0.009991598315536976\n",
      "Epoch 1335, Loss: 0.001239830584381707, Final Batch Loss: 0.0010665213922038674\n",
      "Epoch 1336, Loss: 0.011446894030086696, Final Batch Loss: 0.010760265402495861\n",
      "Epoch 1337, Loss: 0.011677609756588936, Final Batch Loss: 0.009135042317211628\n",
      "Epoch 1338, Loss: 0.05573540547629818, Final Batch Loss: 0.05529358610510826\n",
      "Epoch 1339, Loss: 0.019749674946069717, Final Batch Loss: 0.01136031374335289\n",
      "Epoch 1340, Loss: 0.0026863195234909654, Final Batch Loss: 0.0010957936756312847\n",
      "Epoch 1341, Loss: 0.005001434299629182, Final Batch Loss: 0.004475296940654516\n",
      "Epoch 1342, Loss: 0.006170066422782838, Final Batch Loss: 0.005126049742102623\n",
      "Epoch 1343, Loss: 0.009755029808729887, Final Batch Loss: 0.006895724218338728\n",
      "Epoch 1344, Loss: 0.0012165526859462261, Final Batch Loss: 0.000606078130658716\n",
      "Epoch 1345, Loss: 0.005090261111035943, Final Batch Loss: 0.0038266857154667377\n",
      "Epoch 1346, Loss: 0.004560288041830063, Final Batch Loss: 0.0007387134246528149\n",
      "Epoch 1347, Loss: 0.0013903186772949994, Final Batch Loss: 0.0010637345258146524\n",
      "Epoch 1348, Loss: 0.03272278280928731, Final Batch Loss: 0.031446147710084915\n",
      "Epoch 1349, Loss: 0.0024179380270652473, Final Batch Loss: 0.0009492044919170439\n",
      "Epoch 1350, Loss: 0.0024307328276336193, Final Batch Loss: 0.0010644772555679083\n",
      "Epoch 1351, Loss: 0.002014880010392517, Final Batch Loss: 0.0006012954399921\n",
      "Epoch 1352, Loss: 0.0038955201162025332, Final Batch Loss: 0.0025005026254802942\n",
      "Epoch 1353, Loss: 0.004832533420994878, Final Batch Loss: 0.0012735461350530386\n",
      "Epoch 1354, Loss: 0.002355484728468582, Final Batch Loss: 0.001915808068588376\n",
      "Epoch 1355, Loss: 0.003419803804717958, Final Batch Loss: 0.0021127171348780394\n",
      "Epoch 1356, Loss: 0.0010400539031252265, Final Batch Loss: 0.0007457121973857284\n",
      "Epoch 1357, Loss: 0.00039866691804490983, Final Batch Loss: 0.00016033125575631857\n",
      "Epoch 1358, Loss: 0.0025032018311321735, Final Batch Loss: 0.0014364811358973384\n",
      "Epoch 1359, Loss: 0.0013585393317043781, Final Batch Loss: 0.0007126143900677562\n",
      "Epoch 1360, Loss: 0.00190859311260283, Final Batch Loss: 0.0006625020178034902\n",
      "Epoch 1361, Loss: 0.0015135416761040688, Final Batch Loss: 0.0004946722183376551\n",
      "Epoch 1362, Loss: 0.010542671894654632, Final Batch Loss: 0.009500608779489994\n",
      "Epoch 1363, Loss: 0.0013513058656826615, Final Batch Loss: 0.000683300313539803\n",
      "Epoch 1364, Loss: 0.0006636033358518034, Final Batch Loss: 0.00032408887636847794\n",
      "Epoch 1365, Loss: 0.001911753206513822, Final Batch Loss: 0.0009476526756770909\n",
      "Epoch 1366, Loss: 0.0004918186750728637, Final Batch Loss: 0.0002878899103961885\n",
      "Epoch 1367, Loss: 0.0041478140046820045, Final Batch Loss: 0.003224635263904929\n",
      "Epoch 1368, Loss: 0.0028621816891245544, Final Batch Loss: 0.0005526041495613754\n",
      "Epoch 1369, Loss: 0.002534486586228013, Final Batch Loss: 0.0004546788986772299\n",
      "Epoch 1370, Loss: 0.0012185274390503764, Final Batch Loss: 0.0006102288607507944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1371, Loss: 0.001698932086583227, Final Batch Loss: 0.000739412265829742\n",
      "Epoch 1372, Loss: 0.005274814437143505, Final Batch Loss: 0.00367244565859437\n",
      "Epoch 1373, Loss: 0.003475528792478144, Final Batch Loss: 0.002016803016886115\n",
      "Epoch 1374, Loss: 0.013135057291947305, Final Batch Loss: 0.011405089870095253\n",
      "Epoch 1375, Loss: 0.000918678124435246, Final Batch Loss: 0.00036498712142929435\n",
      "Epoch 1376, Loss: 0.0012506214552558959, Final Batch Loss: 0.00098090257961303\n",
      "Epoch 1377, Loss: 0.001089803728973493, Final Batch Loss: 0.0002686709340196103\n",
      "Epoch 1378, Loss: 0.02240570925641805, Final Batch Loss: 0.0010850179241970181\n",
      "Epoch 1379, Loss: 0.0012465299805626273, Final Batch Loss: 0.0009001175058074296\n",
      "Epoch 1380, Loss: 0.0015532633115071803, Final Batch Loss: 0.0002874437777791172\n",
      "Epoch 1381, Loss: 0.005123559269122779, Final Batch Loss: 0.0035550508182495832\n",
      "Epoch 1382, Loss: 0.007807318004779518, Final Batch Loss: 0.001496536540798843\n",
      "Epoch 1383, Loss: 0.0007736037659924477, Final Batch Loss: 0.000327376852510497\n",
      "Epoch 1384, Loss: 0.0026880339719355106, Final Batch Loss: 0.0006275039631873369\n",
      "Epoch 1385, Loss: 0.002383716928306967, Final Batch Loss: 0.0004605886642821133\n",
      "Epoch 1386, Loss: 0.008710462541785091, Final Batch Loss: 0.0003755064099095762\n",
      "Epoch 1387, Loss: 0.0013552086893469095, Final Batch Loss: 0.0007322453311644495\n",
      "Epoch 1388, Loss: 0.0031191986054182053, Final Batch Loss: 0.0012107256334275007\n",
      "Epoch 1389, Loss: 0.0070305785338860005, Final Batch Loss: 0.006815011613070965\n",
      "Epoch 1390, Loss: 0.0008106895256787539, Final Batch Loss: 0.00021094194380566478\n",
      "Epoch 1391, Loss: 0.0026722881011664867, Final Batch Loss: 0.0002005991991609335\n",
      "Epoch 1392, Loss: 0.010476426221430302, Final Batch Loss: 0.009947061538696289\n",
      "Epoch 1393, Loss: 0.008458862954284996, Final Batch Loss: 0.007696190848946571\n",
      "Epoch 1394, Loss: 0.0006749392923666164, Final Batch Loss: 0.0004691903304774314\n",
      "Epoch 1395, Loss: 0.0024284184910357, Final Batch Loss: 0.0011999603593721986\n",
      "Epoch 1396, Loss: 0.0014019342488609254, Final Batch Loss: 0.0008846587734296918\n",
      "Epoch 1397, Loss: 0.00034003287146333605, Final Batch Loss: 0.0001364152558380738\n",
      "Epoch 1398, Loss: 0.0006629844137933105, Final Batch Loss: 0.0002886470756493509\n",
      "Epoch 1399, Loss: 0.009140937589108944, Final Batch Loss: 0.007151659112423658\n",
      "Epoch 1400, Loss: 0.0020466010610107332, Final Batch Loss: 0.0016377606661990285\n",
      "Epoch 1401, Loss: 0.005663211923092604, Final Batch Loss: 0.0014752470888197422\n",
      "Epoch 1402, Loss: 0.0020288070663809776, Final Batch Loss: 0.0006895492551848292\n",
      "Epoch 1403, Loss: 0.002340827777516097, Final Batch Loss: 0.0006468092906288803\n",
      "Epoch 1404, Loss: 0.0015840338310226798, Final Batch Loss: 0.001183309592306614\n",
      "Epoch 1405, Loss: 0.0011149715282954276, Final Batch Loss: 0.0006155301234684885\n",
      "Epoch 1406, Loss: 0.00342944567091763, Final Batch Loss: 0.002076918724924326\n",
      "Epoch 1407, Loss: 0.0007555956544820219, Final Batch Loss: 0.0003967074735555798\n",
      "Epoch 1408, Loss: 0.0012007245677523315, Final Batch Loss: 0.0005995274987071753\n",
      "Epoch 1409, Loss: 0.0019964005914516747, Final Batch Loss: 0.0003792688366957009\n",
      "Epoch 1410, Loss: 0.0015826309099793434, Final Batch Loss: 0.0007756105624139309\n",
      "Epoch 1411, Loss: 0.0029012818122282624, Final Batch Loss: 0.0012341599212959409\n",
      "Epoch 1412, Loss: 0.0006897624698467553, Final Batch Loss: 0.0003517621080391109\n",
      "Epoch 1413, Loss: 0.006105724460212514, Final Batch Loss: 0.005786811001598835\n",
      "Epoch 1414, Loss: 0.00235297525068745, Final Batch Loss: 0.0003783392603509128\n",
      "Epoch 1415, Loss: 0.0025623259134590626, Final Batch Loss: 0.001663154922425747\n",
      "Epoch 1416, Loss: 0.0015340758836828172, Final Batch Loss: 0.0009416397660970688\n",
      "Epoch 1417, Loss: 0.006886279326863587, Final Batch Loss: 0.005591538734734058\n",
      "Epoch 1418, Loss: 0.006275442719925195, Final Batch Loss: 0.00037295540096238256\n",
      "Epoch 1419, Loss: 0.0008435109193669632, Final Batch Loss: 0.0002277428429806605\n",
      "Epoch 1420, Loss: 0.001187202607979998, Final Batch Loss: 0.0008165020262822509\n",
      "Epoch 1421, Loss: 0.0012008564663119614, Final Batch Loss: 0.0003700376255437732\n",
      "Epoch 1422, Loss: 0.007477686507627368, Final Batch Loss: 0.0012126832734793425\n",
      "Epoch 1423, Loss: 0.012496508948970586, Final Batch Loss: 0.012199119664728642\n",
      "Epoch 1424, Loss: 0.0018296448979526758, Final Batch Loss: 0.0006544510833919048\n",
      "Epoch 1425, Loss: 0.006620977743295953, Final Batch Loss: 0.00045954270171932876\n",
      "Epoch 1426, Loss: 0.0013798915897496045, Final Batch Loss: 0.0005874020280316472\n",
      "Epoch 1427, Loss: 0.0009229373681591824, Final Batch Loss: 0.0007543704123236239\n",
      "Epoch 1428, Loss: 0.003291186294518411, Final Batch Loss: 0.0025125211104750633\n",
      "Epoch 1429, Loss: 0.001713370467768982, Final Batch Loss: 0.0012528931256383657\n",
      "Epoch 1430, Loss: 0.001290904387133196, Final Batch Loss: 0.0003916584828402847\n",
      "Epoch 1431, Loss: 0.002320031650015153, Final Batch Loss: 0.00021996979194227606\n",
      "Epoch 1432, Loss: 0.00673867209115997, Final Batch Loss: 0.00036135740811005235\n",
      "Epoch 1433, Loss: 0.007938111608382314, Final Batch Loss: 0.007444892078638077\n",
      "Epoch 1434, Loss: 0.00239471165696159, Final Batch Loss: 0.0008778520277701318\n",
      "Epoch 1435, Loss: 0.0026303472695872188, Final Batch Loss: 0.0019289316842332482\n",
      "Epoch 1436, Loss: 0.0005305238883011043, Final Batch Loss: 0.0002461269323248416\n",
      "Epoch 1437, Loss: 0.002015506150200963, Final Batch Loss: 0.0007206754526123405\n",
      "Epoch 1438, Loss: 0.007804456865414977, Final Batch Loss: 0.006378107704222202\n",
      "Epoch 1439, Loss: 0.01038608537055552, Final Batch Loss: 0.009718269109725952\n",
      "Epoch 1440, Loss: 0.0009373006905661896, Final Batch Loss: 0.0006976864533498883\n",
      "Epoch 1441, Loss: 0.001646162403631024, Final Batch Loss: 0.0002372905582888052\n",
      "Epoch 1442, Loss: 0.009159864916000515, Final Batch Loss: 0.008406579494476318\n",
      "Epoch 1443, Loss: 0.011249541537836194, Final Batch Loss: 0.007435883395373821\n",
      "Epoch 1444, Loss: 0.003405260038562119, Final Batch Loss: 0.001922226743772626\n",
      "Epoch 1445, Loss: 0.007933795917779207, Final Batch Loss: 0.0010996274650096893\n",
      "Epoch 1446, Loss: 0.006568811077158898, Final Batch Loss: 0.00034233758924528956\n",
      "Epoch 1447, Loss: 0.0008853265317156911, Final Batch Loss: 0.00042151601519435644\n",
      "Epoch 1448, Loss: 0.02530644554644823, Final Batch Loss: 0.01807553507387638\n",
      "Epoch 1449, Loss: 0.0010813949047587812, Final Batch Loss: 0.0007635046495124698\n",
      "Epoch 1450, Loss: 0.0026263189502060413, Final Batch Loss: 0.0004988298751413822\n",
      "Epoch 1451, Loss: 0.00799248251132667, Final Batch Loss: 0.0054257153533399105\n",
      "Epoch 1452, Loss: 0.02320414874702692, Final Batch Loss: 0.009926197119057178\n",
      "Epoch 1453, Loss: 0.0016665864968672395, Final Batch Loss: 0.0007675091619603336\n",
      "Epoch 1454, Loss: 0.0029074521735310555, Final Batch Loss: 0.0027293660677969456\n",
      "Epoch 1455, Loss: 0.0022587478742934763, Final Batch Loss: 3.757287049666047e-05\n",
      "Epoch 1456, Loss: 0.002923622028902173, Final Batch Loss: 0.0022250269539654255\n",
      "Epoch 1457, Loss: 0.008884777911589481, Final Batch Loss: 0.008641528896987438\n",
      "Epoch 1458, Loss: 0.010379588173236698, Final Batch Loss: 0.0009360657422803342\n",
      "Epoch 1459, Loss: 0.0019152369786752388, Final Batch Loss: 0.0001237227552337572\n",
      "Epoch 1460, Loss: 0.0004762642929563299, Final Batch Loss: 0.0002698685566429049\n",
      "Epoch 1461, Loss: 0.0006402072758646682, Final Batch Loss: 0.0004263943701516837\n",
      "Epoch 1462, Loss: 0.0006248892314033583, Final Batch Loss: 0.00023335892183240503\n",
      "Epoch 1463, Loss: 0.006897718354593962, Final Batch Loss: 0.0007776349666528404\n",
      "Epoch 1464, Loss: 0.017551589058712125, Final Batch Loss: 0.0014172561932355165\n",
      "Epoch 1465, Loss: 0.0007674130902159959, Final Batch Loss: 0.0006184570956975222\n",
      "Epoch 1466, Loss: 0.015030873968498781, Final Batch Loss: 0.0145572479814291\n",
      "Epoch 1467, Loss: 0.006160266697406769, Final Batch Loss: 0.0006395336240530014\n",
      "Epoch 1468, Loss: 0.0009737646614667028, Final Batch Loss: 0.00041888843406923115\n",
      "Epoch 1469, Loss: 0.0014255112619139254, Final Batch Loss: 0.0007544999825768173\n",
      "Epoch 1470, Loss: 0.00812840333674103, Final Batch Loss: 0.006550207268446684\n",
      "Epoch 1471, Loss: 0.004230880833347328, Final Batch Loss: 0.0002270906261401251\n",
      "Epoch 1472, Loss: 0.0024570541572757065, Final Batch Loss: 0.0005093346699140966\n",
      "Epoch 1473, Loss: 0.0013386745704337955, Final Batch Loss: 0.0008028890006244183\n",
      "Epoch 1474, Loss: 0.004621969652362168, Final Batch Loss: 0.004398806020617485\n",
      "Epoch 1475, Loss: 0.001459933555452153, Final Batch Loss: 0.00030941140721552074\n",
      "Epoch 1476, Loss: 0.0006192620057845488, Final Batch Loss: 0.0002260827604914084\n",
      "Epoch 1477, Loss: 0.0016511499998159707, Final Batch Loss: 0.0008128990884870291\n",
      "Epoch 1478, Loss: 0.004189921077340841, Final Batch Loss: 0.0013433943968266249\n",
      "Epoch 1479, Loss: 0.0034169420832768083, Final Batch Loss: 0.0005660891765728593\n",
      "Epoch 1480, Loss: 0.0025447540028835647, Final Batch Loss: 0.0024576575960963964\n",
      "Epoch 1481, Loss: 0.008160637400578707, Final Batch Loss: 0.007849736139178276\n",
      "Epoch 1482, Loss: 0.008676535479025915, Final Batch Loss: 0.00022375493426807225\n",
      "Epoch 1483, Loss: 0.0054245139472186565, Final Batch Loss: 0.0011035171337425709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1484, Loss: 0.0026459050131961703, Final Batch Loss: 0.00036111881490796804\n",
      "Epoch 1485, Loss: 0.002260374720208347, Final Batch Loss: 0.0012384651927277446\n",
      "Epoch 1486, Loss: 0.011985044955508783, Final Batch Loss: 0.011700100265443325\n",
      "Epoch 1487, Loss: 0.004544457988231443, Final Batch Loss: 0.00022360972070600837\n",
      "Epoch 1488, Loss: 0.0006347630260279402, Final Batch Loss: 0.00022551089932676405\n",
      "Epoch 1489, Loss: 0.0014296339359134436, Final Batch Loss: 0.0005104446900077164\n",
      "Epoch 1490, Loss: 0.0005816454358864576, Final Batch Loss: 0.00016182646504603326\n",
      "Epoch 1491, Loss: 0.0010175456118304282, Final Batch Loss: 0.0002671651018317789\n",
      "Epoch 1492, Loss: 0.0016878704191185534, Final Batch Loss: 0.0005896577495150268\n",
      "Epoch 1493, Loss: 0.001155384728917852, Final Batch Loss: 0.0007388177327811718\n",
      "Epoch 1494, Loss: 0.0011552055511856452, Final Batch Loss: 0.00016410906391683966\n",
      "Epoch 1495, Loss: 0.0010393893462605774, Final Batch Loss: 0.00029037881176918745\n",
      "Epoch 1496, Loss: 0.0010594874911475927, Final Batch Loss: 0.0006264137919060886\n",
      "Epoch 1497, Loss: 0.0022565029794350266, Final Batch Loss: 0.002050952520221472\n",
      "Epoch 1498, Loss: 0.002262843248900026, Final Batch Loss: 0.00072857626946643\n",
      "Epoch 1499, Loss: 0.0042462504061404616, Final Batch Loss: 0.00017449786537326872\n",
      "Epoch 1500, Loss: 0.002850577118806541, Final Batch Loss: 0.0015128343366086483\n",
      "Epoch 1501, Loss: 0.0007309697975870222, Final Batch Loss: 0.00030170261743478477\n",
      "Epoch 1502, Loss: 0.00625453086104244, Final Batch Loss: 0.005366937723010778\n",
      "Epoch 1503, Loss: 0.0008806749247014523, Final Batch Loss: 0.0006695173215121031\n",
      "Epoch 1504, Loss: 0.001459489663830027, Final Batch Loss: 0.00030215687002055347\n",
      "Epoch 1505, Loss: 0.0076867276802659035, Final Batch Loss: 0.004542992450296879\n",
      "Epoch 1506, Loss: 0.004247737844707444, Final Batch Loss: 0.00018302563694305718\n",
      "Epoch 1507, Loss: 0.00546890584519133, Final Batch Loss: 0.005345857236534357\n",
      "Epoch 1508, Loss: 0.017822761903516948, Final Batch Loss: 0.01738431118428707\n",
      "Epoch 1509, Loss: 0.0015574022982036695, Final Batch Loss: 0.0014611348742619157\n",
      "Epoch 1510, Loss: 0.0065001960610970855, Final Batch Loss: 0.0010790134547278285\n",
      "Epoch 1511, Loss: 0.0028174070175737143, Final Batch Loss: 0.0016768574714660645\n",
      "Epoch 1512, Loss: 0.0021780920797027647, Final Batch Loss: 0.0008376471814699471\n",
      "Epoch 1513, Loss: 0.03708197723608464, Final Batch Loss: 0.036101747304201126\n",
      "Epoch 1514, Loss: 0.0013829852687194943, Final Batch Loss: 0.0002574578393250704\n",
      "Epoch 1515, Loss: 0.0074004471534863114, Final Batch Loss: 0.006602247711271048\n",
      "Epoch 1516, Loss: 0.016175765777006745, Final Batch Loss: 0.001297096023336053\n",
      "Epoch 1517, Loss: 0.0035634983505588025, Final Batch Loss: 0.0003367801837157458\n",
      "Epoch 1518, Loss: 0.030582592473365366, Final Batch Loss: 0.0014884440461173654\n",
      "Epoch 1519, Loss: 0.0016218487871810794, Final Batch Loss: 0.0006348696770146489\n",
      "Epoch 1520, Loss: 0.005179188563488424, Final Batch Loss: 0.0009685334516689181\n",
      "Epoch 1521, Loss: 0.0017771641723811626, Final Batch Loss: 0.001391357509419322\n",
      "Epoch 1522, Loss: 0.005231651448411867, Final Batch Loss: 0.004817407578229904\n",
      "Epoch 1523, Loss: 0.0012878039851784706, Final Batch Loss: 0.0009394866647198796\n",
      "Epoch 1524, Loss: 0.001919871399877593, Final Batch Loss: 0.0014634400140494108\n",
      "Epoch 1525, Loss: 0.0052296401700004935, Final Batch Loss: 0.0005181770538911223\n",
      "Epoch 1526, Loss: 0.007191828452050686, Final Batch Loss: 0.003055660519748926\n",
      "Epoch 1527, Loss: 0.0008814096072455868, Final Batch Loss: 0.0007575481431558728\n",
      "Epoch 1528, Loss: 0.002240647911094129, Final Batch Loss: 0.001980674220249057\n",
      "Epoch 1529, Loss: 0.004206293117022142, Final Batch Loss: 0.004161725752055645\n",
      "Epoch 1530, Loss: 0.0012418683618307114, Final Batch Loss: 0.0006819560658186674\n",
      "Epoch 1531, Loss: 0.0015944182232487947, Final Batch Loss: 0.0011823925888165832\n",
      "Epoch 1532, Loss: 0.003060168295633048, Final Batch Loss: 0.0025284828152507544\n",
      "Epoch 1533, Loss: 0.0017729400424286723, Final Batch Loss: 0.0005056529771536589\n",
      "Epoch 1534, Loss: 0.0008398329955525696, Final Batch Loss: 0.0003483840264379978\n",
      "Epoch 1535, Loss: 0.0016807352949399501, Final Batch Loss: 0.0012392881326377392\n",
      "Epoch 1536, Loss: 0.006846089148893952, Final Batch Loss: 0.0014196482952684164\n",
      "Epoch 1537, Loss: 0.002083823084831238, Final Batch Loss: 0.0010212233755737543\n",
      "Epoch 1538, Loss: 0.005688069708412513, Final Batch Loss: 0.00028703673160634935\n",
      "Epoch 1539, Loss: 0.0015528258518315852, Final Batch Loss: 0.0010399218881502748\n",
      "Epoch 1540, Loss: 0.01706228160765022, Final Batch Loss: 0.015456837601959705\n",
      "Epoch 1541, Loss: 0.00675045745447278, Final Batch Loss: 0.005299336742609739\n",
      "Epoch 1542, Loss: 0.002103716949932277, Final Batch Loss: 0.0006348999449983239\n",
      "Epoch 1543, Loss: 0.000615039753029123, Final Batch Loss: 0.0002688616223167628\n",
      "Epoch 1544, Loss: 0.0009154025974567048, Final Batch Loss: 0.0007977570639923215\n",
      "Epoch 1545, Loss: 0.0012849863851442933, Final Batch Loss: 0.0004613017081283033\n",
      "Epoch 1546, Loss: 0.000761635456001386, Final Batch Loss: 0.00045694151776842773\n",
      "Epoch 1547, Loss: 0.003818861092440784, Final Batch Loss: 0.0027326263953000307\n",
      "Epoch 1548, Loss: 0.00248534424463287, Final Batch Loss: 0.0015905200270935893\n",
      "Epoch 1549, Loss: 0.00294781566481106, Final Batch Loss: 0.0024629360996186733\n",
      "Epoch 1550, Loss: 0.0009315122297266498, Final Batch Loss: 0.00020361192582640797\n",
      "Epoch 1551, Loss: 0.003265299033955671, Final Batch Loss: 0.0030356512870639563\n",
      "Epoch 1552, Loss: 0.0048372684977948666, Final Batch Loss: 0.0008035753853619099\n",
      "Epoch 1553, Loss: 0.0010567320714471862, Final Batch Loss: 0.00013016500452067703\n",
      "Epoch 1554, Loss: 0.001106088311644271, Final Batch Loss: 0.0008337355684489012\n",
      "Epoch 1555, Loss: 0.0023589012562297285, Final Batch Loss: 0.00011283735511824489\n",
      "Epoch 1556, Loss: 0.008893949794583023, Final Batch Loss: 0.0015740924281999469\n",
      "Epoch 1557, Loss: 0.0013502617948688567, Final Batch Loss: 0.0008333578589372337\n",
      "Epoch 1558, Loss: 0.00046656598715344444, Final Batch Loss: 0.00010469396511325613\n",
      "Epoch 1559, Loss: 0.006548769277287647, Final Batch Loss: 0.0062934355810284615\n",
      "Epoch 1560, Loss: 0.0012411909701768309, Final Batch Loss: 0.00030626615625806153\n",
      "Epoch 1561, Loss: 0.0019883710192516446, Final Batch Loss: 0.0016116222832351923\n",
      "Epoch 1562, Loss: 0.0012241207587067038, Final Batch Loss: 0.0004310740332584828\n",
      "Epoch 1563, Loss: 0.0007776167767588049, Final Batch Loss: 0.00042672117706388235\n",
      "Epoch 1564, Loss: 0.001203930180054158, Final Batch Loss: 0.0006312391487881541\n",
      "Epoch 1565, Loss: 0.0007520096842199564, Final Batch Loss: 0.00026377319591119885\n",
      "Epoch 1566, Loss: 0.02292083780048415, Final Batch Loss: 0.0005695169675163925\n",
      "Epoch 1567, Loss: 0.0012985562207177281, Final Batch Loss: 0.0007366081699728966\n",
      "Epoch 1568, Loss: 0.001021868891257327, Final Batch Loss: 5.3773568652104586e-05\n",
      "Epoch 1569, Loss: 0.0031704846187494695, Final Batch Loss: 0.0022013713605701923\n",
      "Epoch 1570, Loss: 0.000858704763231799, Final Batch Loss: 0.0006375057273544371\n",
      "Epoch 1571, Loss: 0.0013165091804694384, Final Batch Loss: 0.0008809624123387039\n",
      "Epoch 1572, Loss: 0.0027739405632019043, Final Batch Loss: 0.0007671527564525604\n",
      "Epoch 1573, Loss: 0.004157351795583963, Final Batch Loss: 0.0005067025776952505\n",
      "Epoch 1574, Loss: 0.0011635976552497596, Final Batch Loss: 0.0004331616510171443\n",
      "Epoch 1575, Loss: 0.011922306643100455, Final Batch Loss: 0.011632195673882961\n",
      "Epoch 1576, Loss: 0.001025054429192096, Final Batch Loss: 0.0005411380552686751\n",
      "Epoch 1577, Loss: 0.0012966732028871775, Final Batch Loss: 0.0009788302704691887\n",
      "Epoch 1578, Loss: 0.001654246705584228, Final Batch Loss: 0.0006948611699044704\n",
      "Epoch 1579, Loss: 0.009396850015036762, Final Batch Loss: 0.008780932053923607\n",
      "Epoch 1580, Loss: 0.001300147909205407, Final Batch Loss: 0.0006125638610683382\n",
      "Epoch 1581, Loss: 0.001067168836016208, Final Batch Loss: 0.0005194111727178097\n",
      "Epoch 1582, Loss: 0.004809215839486569, Final Batch Loss: 0.0043304734863340855\n",
      "Epoch 1583, Loss: 0.009305671323090792, Final Batch Loss: 0.008449925109744072\n",
      "Epoch 1584, Loss: 0.007399938884191215, Final Batch Loss: 0.006941951345652342\n",
      "Epoch 1585, Loss: 0.0019273491343483329, Final Batch Loss: 0.0011040983954444528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1586, Loss: 0.001048437858116813, Final Batch Loss: 0.000860187690705061\n",
      "Epoch 1587, Loss: 0.0004985623818356544, Final Batch Loss: 0.0002492000348865986\n",
      "Epoch 1588, Loss: 0.0031059356406331062, Final Batch Loss: 0.0017325534718111157\n",
      "Epoch 1589, Loss: 0.0004954633477609605, Final Batch Loss: 0.00031503502395935357\n",
      "Epoch 1590, Loss: 0.002005190122872591, Final Batch Loss: 0.0008969497866928577\n",
      "Epoch 1591, Loss: 0.002146224374882877, Final Batch Loss: 0.0009927203645929694\n",
      "Epoch 1592, Loss: 0.0018075895204674453, Final Batch Loss: 0.00021455620299093425\n",
      "Epoch 1593, Loss: 0.0010510170832276344, Final Batch Loss: 0.0005419313674792647\n",
      "Epoch 1594, Loss: 0.0010176602809224278, Final Batch Loss: 0.0003331949992571026\n",
      "Epoch 1595, Loss: 0.00046127825044095516, Final Batch Loss: 0.0002658152661751956\n",
      "Epoch 1596, Loss: 0.0022595306509174407, Final Batch Loss: 0.0006915057892911136\n",
      "Epoch 1597, Loss: 0.005709443998057395, Final Batch Loss: 0.0009019866702146828\n",
      "Epoch 1598, Loss: 0.00232968051568605, Final Batch Loss: 0.0021243663504719734\n",
      "Epoch 1599, Loss: 0.0014026688586454839, Final Batch Loss: 0.0002453545748721808\n",
      "Epoch 1600, Loss: 0.0016178585938178003, Final Batch Loss: 0.0006845439784228802\n",
      "Epoch 1601, Loss: 0.0013980606163386256, Final Batch Loss: 0.00040405700565315783\n",
      "Epoch 1602, Loss: 0.0007344648620346561, Final Batch Loss: 0.00011157816334161907\n",
      "Epoch 1603, Loss: 0.006591390294488519, Final Batch Loss: 0.006024265196174383\n",
      "Epoch 1604, Loss: 0.004962143080774695, Final Batch Loss: 0.0007330007501877844\n",
      "Epoch 1605, Loss: 0.003969587036408484, Final Batch Loss: 0.0016724063316360116\n",
      "Epoch 1606, Loss: 0.0007948035490699112, Final Batch Loss: 0.0004981855163350701\n",
      "Epoch 1607, Loss: 0.0013558311184169725, Final Batch Loss: 0.00011630119115579873\n",
      "Epoch 1608, Loss: 0.001145113681559451, Final Batch Loss: 0.0009109502425417304\n",
      "Epoch 1609, Loss: 0.0009882175145321526, Final Batch Loss: 0.0009170456323772669\n",
      "Epoch 1610, Loss: 0.0004939554637530819, Final Batch Loss: 0.00016037556633818895\n",
      "Epoch 1611, Loss: 0.0019863530178554356, Final Batch Loss: 0.00014061882393434644\n",
      "Epoch 1612, Loss: 0.0006600355263799429, Final Batch Loss: 0.00037051294930279255\n",
      "Epoch 1613, Loss: 0.001321463962085545, Final Batch Loss: 0.0005102657014504075\n",
      "Epoch 1614, Loss: 0.020341564260888845, Final Batch Loss: 0.0005784168024547398\n",
      "Epoch 1615, Loss: 0.0016537004266865551, Final Batch Loss: 0.0005631049280054867\n",
      "Epoch 1616, Loss: 0.006846435746410862, Final Batch Loss: 0.006601917557418346\n",
      "Epoch 1617, Loss: 0.0006859601708129048, Final Batch Loss: 0.000519170134793967\n",
      "Epoch 1618, Loss: 0.0007103459211066365, Final Batch Loss: 0.00013412028783932328\n",
      "Epoch 1619, Loss: 0.004057830665260553, Final Batch Loss: 0.000587984686717391\n",
      "Epoch 1620, Loss: 0.002260504581499845, Final Batch Loss: 0.0015863607404753566\n",
      "Epoch 1621, Loss: 0.0020727688970509917, Final Batch Loss: 0.00029488481231965125\n",
      "Epoch 1622, Loss: 0.0004819144232897088, Final Batch Loss: 0.00023138806864153594\n",
      "Epoch 1623, Loss: 0.0011255533318035305, Final Batch Loss: 0.0005905235302634537\n",
      "Epoch 1624, Loss: 0.011649017280433327, Final Batch Loss: 0.0008525141165591776\n",
      "Epoch 1625, Loss: 0.0006314542843028903, Final Batch Loss: 0.0003509758098516613\n",
      "Epoch 1626, Loss: 0.0010517642949707806, Final Batch Loss: 0.0006390871130861342\n",
      "Epoch 1627, Loss: 0.0005686662771040574, Final Batch Loss: 0.0003725727437995374\n",
      "Epoch 1628, Loss: 0.0034765066811814904, Final Batch Loss: 0.0009186883689835668\n",
      "Epoch 1629, Loss: 0.0008866330026648939, Final Batch Loss: 0.00026628479827195406\n",
      "Epoch 1630, Loss: 0.000237615080550313, Final Batch Loss: 8.676698780618608e-05\n",
      "Epoch 1631, Loss: 0.006966332555748522, Final Batch Loss: 0.0019381629535928369\n",
      "Epoch 1632, Loss: 0.0011223223118577152, Final Batch Loss: 0.0007437823805958033\n",
      "Epoch 1633, Loss: 0.000479190144687891, Final Batch Loss: 0.0001679935958236456\n",
      "Epoch 1634, Loss: 0.00019216633518226445, Final Batch Loss: 0.0001265659520868212\n",
      "Epoch 1635, Loss: 0.00042091752402484417, Final Batch Loss: 0.00028702468262054026\n",
      "Epoch 1636, Loss: 0.0013110509025864303, Final Batch Loss: 0.0006839670240879059\n",
      "Epoch 1637, Loss: 0.0029990343609824777, Final Batch Loss: 0.0012017734115943313\n",
      "Epoch 1638, Loss: 0.010454287054017186, Final Batch Loss: 0.00093312026001513\n",
      "Epoch 1639, Loss: 0.00555538764456287, Final Batch Loss: 0.004803603980690241\n",
      "Epoch 1640, Loss: 0.0006665048276772723, Final Batch Loss: 0.000153704357217066\n",
      "Epoch 1641, Loss: 0.0007622334669576958, Final Batch Loss: 0.00015282044478226453\n",
      "Epoch 1642, Loss: 0.001488181878812611, Final Batch Loss: 0.0013200222747400403\n",
      "Epoch 1643, Loss: 0.005196257145144045, Final Batch Loss: 0.0013203363632783294\n",
      "Epoch 1644, Loss: 0.0006954914715606719, Final Batch Loss: 0.0002557642001193017\n",
      "Epoch 1645, Loss: 0.0020534682262223214, Final Batch Loss: 0.0018417759565636516\n",
      "Epoch 1646, Loss: 0.0010081389045808464, Final Batch Loss: 0.0003895376867149025\n",
      "Epoch 1647, Loss: 0.005096787470392883, Final Batch Loss: 0.003696978325024247\n",
      "Epoch 1648, Loss: 0.0013032284914515913, Final Batch Loss: 0.0010014870204031467\n",
      "Epoch 1649, Loss: 0.01783093041740358, Final Batch Loss: 0.01691768877208233\n",
      "Epoch 1650, Loss: 0.01948551624082029, Final Batch Loss: 0.01569337025284767\n",
      "Epoch 1651, Loss: 0.002876892569474876, Final Batch Loss: 0.0023986499290913343\n",
      "Epoch 1652, Loss: 0.0009509425726719201, Final Batch Loss: 0.00024275947362184525\n",
      "Epoch 1653, Loss: 0.004845833289436996, Final Batch Loss: 0.004719668533653021\n",
      "Epoch 1654, Loss: 0.0011539118422660977, Final Batch Loss: 0.00024326550192199647\n",
      "Epoch 1655, Loss: 0.007796189398504794, Final Batch Loss: 0.0011236212449148297\n",
      "Epoch 1656, Loss: 0.008649177618281101, Final Batch Loss: 3.0205354050849564e-05\n",
      "Epoch 1657, Loss: 0.005636741989292204, Final Batch Loss: 0.0018006464233621955\n",
      "Epoch 1658, Loss: 0.0004059814236825332, Final Batch Loss: 0.00022381643066182733\n",
      "Epoch 1659, Loss: 0.015795318875461817, Final Batch Loss: 0.010449742898344994\n",
      "Epoch 1660, Loss: 0.0008469142048852518, Final Batch Loss: 0.0001144957059295848\n",
      "Epoch 1661, Loss: 0.004337028949521482, Final Batch Loss: 0.0009936728747561574\n",
      "Epoch 1662, Loss: 0.017938331118784845, Final Batch Loss: 0.0003306943690404296\n",
      "Epoch 1663, Loss: 0.001535682415124029, Final Batch Loss: 0.0007299577700905502\n",
      "Epoch 1664, Loss: 0.002396170108113438, Final Batch Loss: 0.001818524207919836\n",
      "Epoch 1665, Loss: 0.031861032053711824, Final Batch Loss: 0.00015044088650029153\n",
      "Epoch 1666, Loss: 0.0013296409451868385, Final Batch Loss: 0.0003286709252279252\n",
      "Epoch 1667, Loss: 0.00490438420092687, Final Batch Loss: 0.0003375368542037904\n",
      "Epoch 1668, Loss: 0.0005242977058514953, Final Batch Loss: 0.00016585999401286244\n",
      "Epoch 1669, Loss: 0.0008015900675673038, Final Batch Loss: 0.00047846720553934574\n",
      "Epoch 1670, Loss: 0.0007772561220917851, Final Batch Loss: 0.00012214764137752354\n",
      "Epoch 1671, Loss: 0.001021264906739816, Final Batch Loss: 0.0005668542580679059\n",
      "Epoch 1672, Loss: 0.00045615875569637865, Final Batch Loss: 0.0001581596879987046\n",
      "Epoch 1673, Loss: 0.0010465584928169847, Final Batch Loss: 0.00039797963108867407\n",
      "Epoch 1674, Loss: 0.005198802566155791, Final Batch Loss: 0.00404953071847558\n",
      "Epoch 1675, Loss: 0.0014620803704019636, Final Batch Loss: 0.0003842399164568633\n",
      "Epoch 1676, Loss: 0.0031352719524875283, Final Batch Loss: 0.001619011047296226\n",
      "Epoch 1677, Loss: 0.001969749078853056, Final Batch Loss: 0.0004114572366233915\n",
      "Epoch 1678, Loss: 0.008249799051554874, Final Batch Loss: 0.0004461279895622283\n",
      "Epoch 1679, Loss: 0.006772973691113293, Final Batch Loss: 0.006020506378263235\n",
      "Epoch 1680, Loss: 0.0009529257076792419, Final Batch Loss: 0.00022103742230683565\n",
      "Epoch 1681, Loss: 0.011161810252815485, Final Batch Loss: 0.003438233397901058\n",
      "Epoch 1682, Loss: 0.0010860963666345924, Final Batch Loss: 0.0006450736545957625\n",
      "Epoch 1683, Loss: 0.0018009199702646583, Final Batch Loss: 0.00014225064660422504\n",
      "Epoch 1684, Loss: 0.0006851147481938824, Final Batch Loss: 0.0005176740814931691\n",
      "Epoch 1685, Loss: 0.0010168926091864705, Final Batch Loss: 0.0006038048304617405\n",
      "Epoch 1686, Loss: 0.0026533323907642625, Final Batch Loss: 0.00010738681157818064\n",
      "Epoch 1687, Loss: 0.004886987153440714, Final Batch Loss: 0.0038619772531092167\n",
      "Epoch 1688, Loss: 0.0005392081802710891, Final Batch Loss: 0.00036203773925080895\n",
      "Epoch 1689, Loss: 0.010456944117322564, Final Batch Loss: 0.009183401241898537\n",
      "Epoch 1690, Loss: 0.0066839082865044475, Final Batch Loss: 0.0011801653308793902\n",
      "Epoch 1691, Loss: 0.000458267950307345, Final Batch Loss: 5.65533664484974e-05\n",
      "Epoch 1692, Loss: 0.0022010438260622323, Final Batch Loss: 0.0015881627332419157\n",
      "Epoch 1693, Loss: 0.0009708225843496621, Final Batch Loss: 0.0007077791378833354\n",
      "Epoch 1694, Loss: 0.00027892913203686476, Final Batch Loss: 0.000165714489412494\n",
      "Epoch 1695, Loss: 0.001426577742677182, Final Batch Loss: 0.0007776680868119001\n",
      "Epoch 1696, Loss: 0.007385927718132734, Final Batch Loss: 0.0005183564499020576\n",
      "Epoch 1697, Loss: 0.003102449234575033, Final Batch Loss: 0.002325734356418252\n",
      "Epoch 1698, Loss: 0.0013953690067864954, Final Batch Loss: 0.001005409867502749\n",
      "Epoch 1699, Loss: 0.006701930156850722, Final Batch Loss: 0.00010118234058609232\n",
      "Epoch 1700, Loss: 0.0005670982936862856, Final Batch Loss: 0.0002442706609144807\n",
      "Epoch 1701, Loss: 0.005887801817152649, Final Batch Loss: 0.000642809143755585\n",
      "Epoch 1702, Loss: 0.0006913096585776657, Final Batch Loss: 0.0003409792552702129\n",
      "Epoch 1703, Loss: 0.0032872541341930628, Final Batch Loss: 0.002139877760782838\n",
      "Epoch 1704, Loss: 0.0007974148902576417, Final Batch Loss: 0.00028693091007880867\n",
      "Epoch 1705, Loss: 0.0012758565717376769, Final Batch Loss: 0.0008952155476436019\n",
      "Epoch 1706, Loss: 0.003940830007195473, Final Batch Loss: 0.0019731405191123486\n",
      "Epoch 1707, Loss: 0.001875601737992838, Final Batch Loss: 0.001617439091205597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1708, Loss: 0.0022486319940071553, Final Batch Loss: 0.002051048446446657\n",
      "Epoch 1709, Loss: 0.001331193809164688, Final Batch Loss: 0.0010842526098713279\n",
      "Epoch 1710, Loss: 0.006166947248857468, Final Batch Loss: 0.005492077209055424\n",
      "Epoch 1711, Loss: 0.01021244958974421, Final Batch Loss: 0.0038459200877696276\n",
      "Epoch 1712, Loss: 0.0006960991086089052, Final Batch Loss: 0.00011859389633173123\n",
      "Epoch 1713, Loss: 0.0008142306687659584, Final Batch Loss: 0.0007022167555987835\n",
      "Epoch 1714, Loss: 0.0010163795959670097, Final Batch Loss: 0.0004129638837184757\n",
      "Epoch 1715, Loss: 0.0014769890694878995, Final Batch Loss: 0.000683824357111007\n",
      "Epoch 1716, Loss: 0.005594667163677514, Final Batch Loss: 0.00025117082986980677\n",
      "Epoch 1717, Loss: 0.001684476446826011, Final Batch Loss: 0.0005194896948523819\n",
      "Epoch 1718, Loss: 0.000616783116129227, Final Batch Loss: 0.00014399203064385802\n",
      "Epoch 1719, Loss: 0.0008509766194038093, Final Batch Loss: 0.00017837766790762544\n",
      "Epoch 1720, Loss: 0.0030099018331384286, Final Batch Loss: 0.00013674002548214048\n",
      "Epoch 1721, Loss: 0.0007242683932418004, Final Batch Loss: 0.0005813683965243399\n",
      "Epoch 1722, Loss: 0.0019327563350088894, Final Batch Loss: 0.0007355751586146653\n",
      "Epoch 1723, Loss: 0.0013977682683616877, Final Batch Loss: 0.0006782886921428144\n",
      "Epoch 1724, Loss: 0.0014787580003030598, Final Batch Loss: 0.0006857336265966296\n",
      "Epoch 1725, Loss: 0.0018995378341060132, Final Batch Loss: 0.0002850453311111778\n",
      "Epoch 1726, Loss: 0.0002792339109873865, Final Batch Loss: 5.676957152900286e-05\n",
      "Epoch 1727, Loss: 0.00455614976817742, Final Batch Loss: 0.000975506438408047\n",
      "Epoch 1728, Loss: 0.0005235879507381469, Final Batch Loss: 0.0004069639544468373\n",
      "Epoch 1729, Loss: 0.0008489917090628296, Final Batch Loss: 0.0001593669585417956\n",
      "Epoch 1730, Loss: 0.0008338322804775089, Final Batch Loss: 7.238736725412309e-05\n",
      "Epoch 1731, Loss: 0.0005437367290141992, Final Batch Loss: 0.00047106563579291105\n",
      "Epoch 1732, Loss: 0.0019932482828153297, Final Batch Loss: 0.00017408914573024958\n",
      "Epoch 1733, Loss: 0.0010558761714491993, Final Batch Loss: 0.0007108937134034932\n",
      "Epoch 1734, Loss: 0.0018732075113803148, Final Batch Loss: 0.0010950998403131962\n",
      "Epoch 1735, Loss: 0.0019346568587934598, Final Batch Loss: 0.00013701965508516878\n",
      "Epoch 1736, Loss: 0.0015414342051371932, Final Batch Loss: 0.0004936436889693141\n",
      "Epoch 1737, Loss: 0.00040633874596096575, Final Batch Loss: 0.000120163633255288\n",
      "Epoch 1738, Loss: 0.0009715527121443301, Final Batch Loss: 0.0005430373712442815\n",
      "Epoch 1739, Loss: 0.0010661517007974908, Final Batch Loss: 0.0009285396663472056\n",
      "Epoch 1740, Loss: 0.004314575053285807, Final Batch Loss: 0.0036174484994262457\n",
      "Epoch 1741, Loss: 0.008054339938098565, Final Batch Loss: 0.0004195218498352915\n",
      "Epoch 1742, Loss: 0.012370583659503609, Final Batch Loss: 0.011970840394496918\n",
      "Epoch 1743, Loss: 0.002199439040850848, Final Batch Loss: 0.0003351088962517679\n",
      "Epoch 1744, Loss: 0.00414452092081774, Final Batch Loss: 0.0001390068355249241\n",
      "Epoch 1745, Loss: 0.001944180650752969, Final Batch Loss: 0.0018019147682935\n",
      "Epoch 1746, Loss: 0.0022842339822091162, Final Batch Loss: 0.0005350274150259793\n",
      "Epoch 1747, Loss: 0.0005202297470532358, Final Batch Loss: 0.00027253886219114065\n",
      "Epoch 1748, Loss: 0.0035679922439157963, Final Batch Loss: 0.0029912216123193502\n",
      "Epoch 1749, Loss: 0.00024985027266666293, Final Batch Loss: 6.322380795609206e-05\n",
      "Epoch 1750, Loss: 0.00018162520791520365, Final Batch Loss: 0.00014773846487514675\n",
      "Epoch 1751, Loss: 0.0016112796438392252, Final Batch Loss: 0.00036672267015092075\n",
      "Epoch 1752, Loss: 0.0002781098592095077, Final Batch Loss: 0.0001837841555243358\n",
      "Epoch 1753, Loss: 0.001959898101631552, Final Batch Loss: 0.00017403176752850413\n",
      "Epoch 1754, Loss: 0.0008507125021424145, Final Batch Loss: 0.0003272361645940691\n",
      "Epoch 1755, Loss: 0.013046087231487036, Final Batch Loss: 0.0072553870268166065\n",
      "Epoch 1756, Loss: 0.0014726689842063934, Final Batch Loss: 0.00031011205282993615\n",
      "Epoch 1757, Loss: 0.0013030681293457747, Final Batch Loss: 0.0009879404678940773\n",
      "Epoch 1758, Loss: 0.0023190868087112904, Final Batch Loss: 0.0018518072320148349\n",
      "Epoch 1759, Loss: 0.00040243894181912765, Final Batch Loss: 0.00010073117300635204\n",
      "Epoch 1760, Loss: 0.0011716308326867875, Final Batch Loss: 0.0011314564617350698\n",
      "Epoch 1761, Loss: 0.0007046092214295641, Final Batch Loss: 0.00050755386473611\n",
      "Epoch 1762, Loss: 0.004340045736171305, Final Batch Loss: 0.0018197867320850492\n",
      "Epoch 1763, Loss: 0.0014487094595097005, Final Batch Loss: 0.001131153665482998\n",
      "Epoch 1764, Loss: 0.014870830404106528, Final Batch Loss: 0.0008897730731405318\n",
      "Epoch 1765, Loss: 0.0024340287782251835, Final Batch Loss: 0.0013756093103438616\n",
      "Epoch 1766, Loss: 0.004713414702564478, Final Batch Loss: 0.002731991931796074\n",
      "Epoch 1767, Loss: 0.007456078310497105, Final Batch Loss: 0.00628135958686471\n",
      "Epoch 1768, Loss: 0.007147497468395159, Final Batch Loss: 0.007002474740147591\n",
      "Epoch 1769, Loss: 0.013894637377234176, Final Batch Loss: 0.00028862737235613167\n",
      "Epoch 1770, Loss: 0.0005456338112708181, Final Batch Loss: 0.0002574909885879606\n",
      "Epoch 1771, Loss: 0.0029622561996802688, Final Batch Loss: 0.00037666631396859884\n",
      "Epoch 1772, Loss: 0.010153329640161246, Final Batch Loss: 0.0007059040362946689\n",
      "Epoch 1773, Loss: 0.04014230758184567, Final Batch Loss: 0.03966337442398071\n",
      "Epoch 1774, Loss: 0.004415874733240344, Final Batch Loss: 0.00021884952730033547\n",
      "Epoch 1775, Loss: 0.021594468780676834, Final Batch Loss: 0.021491941064596176\n",
      "Epoch 1776, Loss: 0.001093480794224888, Final Batch Loss: 0.0005020673270337284\n",
      "Epoch 1777, Loss: 0.021875842532608658, Final Batch Loss: 0.00014932925114408135\n",
      "Epoch 1778, Loss: 0.0008519042166881263, Final Batch Loss: 0.0005326068494468927\n",
      "Epoch 1779, Loss: 0.0030911463545635343, Final Batch Loss: 0.000415101065300405\n",
      "Epoch 1780, Loss: 0.009432952865608968, Final Batch Loss: 0.0002027191367233172\n",
      "Epoch 1781, Loss: 0.03253499942366034, Final Batch Loss: 0.0012426950270310044\n",
      "Epoch 1782, Loss: 0.00827229258720763, Final Batch Loss: 0.007915420457720757\n",
      "Epoch 1783, Loss: 0.007382166455499828, Final Batch Loss: 0.0004905749810859561\n",
      "Epoch 1784, Loss: 0.016442554537206888, Final Batch Loss: 0.014810904860496521\n",
      "Epoch 1785, Loss: 0.04412701682304032, Final Batch Loss: 0.04367630183696747\n",
      "Epoch 1786, Loss: 0.0015098329167813063, Final Batch Loss: 0.0003274515038356185\n",
      "Epoch 1787, Loss: 0.003344817363540642, Final Batch Loss: 0.00021759657829534262\n",
      "Epoch 1788, Loss: 0.005654967506416142, Final Batch Loss: 0.0014163098530843854\n",
      "Epoch 1789, Loss: 0.0031289506005123258, Final Batch Loss: 0.0016030807746574283\n",
      "Epoch 1790, Loss: 0.001245409861439839, Final Batch Loss: 0.0002493585052434355\n",
      "Epoch 1791, Loss: 0.004517170134931803, Final Batch Loss: 0.0032791888806968927\n",
      "Epoch 1792, Loss: 0.009496238548308611, Final Batch Loss: 0.002423431258648634\n",
      "Epoch 1793, Loss: 0.0013972666492918506, Final Batch Loss: 0.000222308692173101\n",
      "Epoch 1794, Loss: 0.0009500270243734121, Final Batch Loss: 0.0006285487324930727\n",
      "Epoch 1795, Loss: 0.005507682799361646, Final Batch Loss: 0.0012897405540570617\n",
      "Epoch 1796, Loss: 0.004335347388405353, Final Batch Loss: 0.0006270213634707034\n",
      "Epoch 1797, Loss: 0.0198539033299312, Final Batch Loss: 0.018844367936253548\n",
      "Epoch 1798, Loss: 0.002620672166813165, Final Batch Loss: 0.0019609660375863314\n",
      "Epoch 1799, Loss: 0.002289031574036926, Final Batch Loss: 0.0005230625974945724\n",
      "Epoch 1800, Loss: 0.038940596394240856, Final Batch Loss: 0.023679926991462708\n",
      "Epoch 1801, Loss: 0.015034638694487512, Final Batch Loss: 0.013767228461802006\n",
      "Epoch 1802, Loss: 0.004722908255644143, Final Batch Loss: 0.004024861380457878\n",
      "Epoch 1803, Loss: 0.003493125783279538, Final Batch Loss: 0.002023631241172552\n",
      "Epoch 1804, Loss: 0.00255849544191733, Final Batch Loss: 0.000793946732301265\n",
      "Epoch 1805, Loss: 0.0008307243115268648, Final Batch Loss: 0.0003870367363560945\n",
      "Epoch 1806, Loss: 0.004253050603438169, Final Batch Loss: 0.0004992529866285622\n",
      "Epoch 1807, Loss: 0.00548860733397305, Final Batch Loss: 0.0025082293432205915\n",
      "Epoch 1808, Loss: 0.0010763380851130933, Final Batch Loss: 0.00018896974506787956\n",
      "Epoch 1809, Loss: 0.02137075364589691, Final Batch Loss: 0.01665440760552883\n",
      "Epoch 1810, Loss: 0.0009972742409445345, Final Batch Loss: 0.000713405548594892\n",
      "Epoch 1811, Loss: 0.0018079847213812172, Final Batch Loss: 0.001164735178463161\n",
      "Epoch 1812, Loss: 0.0012502377503551543, Final Batch Loss: 0.0007538152276538312\n",
      "Epoch 1813, Loss: 0.001077371067367494, Final Batch Loss: 0.000719777715858072\n",
      "Epoch 1814, Loss: 0.003782757616136223, Final Batch Loss: 0.0005802969099022448\n",
      "Epoch 1815, Loss: 0.0009743689151946455, Final Batch Loss: 0.0002674024144653231\n",
      "Epoch 1816, Loss: 0.0026771063276100904, Final Batch Loss: 0.0003518262237776071\n",
      "Epoch 1817, Loss: 0.037529234192334116, Final Batch Loss: 0.00014709716197103262\n",
      "Epoch 1818, Loss: 0.0014349108096212149, Final Batch Loss: 0.0006284613627940416\n",
      "Epoch 1819, Loss: 0.0009718539076857269, Final Batch Loss: 0.0004978780634701252\n",
      "Epoch 1820, Loss: 0.01281055435538292, Final Batch Loss: 0.005893671419471502\n",
      "Epoch 1821, Loss: 0.006528447906021029, Final Batch Loss: 0.0004360061720944941\n",
      "Epoch 1822, Loss: 0.001323797507211566, Final Batch Loss: 0.0006643763044849038\n",
      "Epoch 1823, Loss: 0.0015568314120173454, Final Batch Loss: 0.000515444902703166\n",
      "Epoch 1824, Loss: 0.007575051102321595, Final Batch Loss: 0.006751394364982843\n",
      "Epoch 1825, Loss: 0.0020889409352093935, Final Batch Loss: 0.0015340421814471483\n",
      "Epoch 1826, Loss: 0.0018560938769951463, Final Batch Loss: 0.0006817165995016694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1827, Loss: 0.001681594061665237, Final Batch Loss: 0.0009492667159065604\n",
      "Epoch 1828, Loss: 0.0036511332145892084, Final Batch Loss: 0.00038440473144873977\n",
      "Epoch 1829, Loss: 0.0032821237109601498, Final Batch Loss: 0.0021582467015832663\n",
      "Epoch 1830, Loss: 0.0018420853302814066, Final Batch Loss: 0.0007588295848108828\n",
      "Epoch 1831, Loss: 0.00896306219510734, Final Batch Loss: 0.0022659183014184237\n",
      "Epoch 1832, Loss: 0.0010014034487539902, Final Batch Loss: 0.0007650736952200532\n",
      "Epoch 1833, Loss: 0.003083852890995331, Final Batch Loss: 0.0029212012887001038\n",
      "Epoch 1834, Loss: 0.0003889837535098195, Final Batch Loss: 0.00014743876818101853\n",
      "Epoch 1835, Loss: 0.007462739828042686, Final Batch Loss: 0.007249828893691301\n",
      "Epoch 1836, Loss: 0.005868296138942242, Final Batch Loss: 0.005221188068389893\n",
      "Epoch 1837, Loss: 0.00853709178045392, Final Batch Loss: 0.006958379875868559\n",
      "Epoch 1838, Loss: 0.0019666990847326815, Final Batch Loss: 0.0005486214649863541\n",
      "Epoch 1839, Loss: 0.0010176776559092104, Final Batch Loss: 0.0005187075585126877\n",
      "Epoch 1840, Loss: 0.0009316931827925146, Final Batch Loss: 0.0002767150290310383\n",
      "Epoch 1841, Loss: 0.0014364109374582767, Final Batch Loss: 0.0012056645937263966\n",
      "Epoch 1842, Loss: 0.001256294985068962, Final Batch Loss: 0.00015909827197901905\n",
      "Epoch 1843, Loss: 0.0008447321888525039, Final Batch Loss: 0.00047017281758598983\n",
      "Epoch 1844, Loss: 0.005397944885771722, Final Batch Loss: 0.0005999302375130355\n",
      "Epoch 1845, Loss: 0.0010526395635679364, Final Batch Loss: 0.0004826072254218161\n",
      "Epoch 1846, Loss: 0.0066579513950273395, Final Batch Loss: 0.005827016197144985\n",
      "Epoch 1847, Loss: 0.0031785336323082447, Final Batch Loss: 0.0006881766021251678\n",
      "Epoch 1848, Loss: 0.001009044557576999, Final Batch Loss: 0.00025879006716422737\n",
      "Epoch 1849, Loss: 0.00036443627323023975, Final Batch Loss: 0.00017991628556046635\n",
      "Epoch 1850, Loss: 0.002339386090170592, Final Batch Loss: 0.0017958865500986576\n",
      "Epoch 1851, Loss: 0.00036766129778698087, Final Batch Loss: 0.00023098733799997717\n",
      "Epoch 1852, Loss: 0.0005320412019500509, Final Batch Loss: 0.00016289383347611874\n",
      "Epoch 1853, Loss: 0.0008000870293471962, Final Batch Loss: 0.0003819333214778453\n",
      "Epoch 1854, Loss: 0.0006525493663502857, Final Batch Loss: 0.0004492089501582086\n",
      "Epoch 1855, Loss: 0.0004916082689305767, Final Batch Loss: 0.00011964132136199623\n",
      "Epoch 1856, Loss: 0.0026754639111459255, Final Batch Loss: 0.00028693978674709797\n",
      "Epoch 1857, Loss: 0.00175143702654168, Final Batch Loss: 0.0009413657826371491\n",
      "Epoch 1858, Loss: 0.0013071290450170636, Final Batch Loss: 0.000990136875770986\n",
      "Epoch 1859, Loss: 0.0005761536594945937, Final Batch Loss: 0.00039219146128743887\n",
      "Epoch 1860, Loss: 0.0011186036135768518, Final Batch Loss: 0.0009752331534400582\n",
      "Epoch 1861, Loss: 0.00047431112034246325, Final Batch Loss: 0.00036878560786135495\n",
      "Epoch 1862, Loss: 0.00038882090302649885, Final Batch Loss: 0.00013306552136782557\n",
      "Epoch 1863, Loss: 0.001434269273886457, Final Batch Loss: 0.00031544166267849505\n",
      "Epoch 1864, Loss: 0.006748984451405704, Final Batch Loss: 0.000583421322517097\n",
      "Epoch 1865, Loss: 0.0015070244699018076, Final Batch Loss: 0.00023058145598042756\n",
      "Epoch 1866, Loss: 0.004243286850396544, Final Batch Loss: 0.0007395896245725453\n",
      "Epoch 1867, Loss: 0.0009103608754230663, Final Batch Loss: 4.7183697461150587e-05\n",
      "Epoch 1868, Loss: 0.0009369182225782424, Final Batch Loss: 0.0006682985695078969\n",
      "Epoch 1869, Loss: 0.019244764931499958, Final Batch Loss: 0.01808357797563076\n",
      "Epoch 1870, Loss: 0.0016096156905405223, Final Batch Loss: 0.00045438652159646153\n",
      "Epoch 1871, Loss: 0.006712567585054785, Final Batch Loss: 0.0002616616548039019\n",
      "Epoch 1872, Loss: 0.0009215598547598347, Final Batch Loss: 0.0007820641039870679\n",
      "Epoch 1873, Loss: 0.0012141710903961211, Final Batch Loss: 0.00024659823975525796\n",
      "Epoch 1874, Loss: 0.0011320665071252733, Final Batch Loss: 0.0008919296087697148\n",
      "Epoch 1875, Loss: 0.00911936532065738, Final Batch Loss: 0.0001463535736547783\n",
      "Epoch 1876, Loss: 0.0033821684774011374, Final Batch Loss: 0.00031323195435106754\n",
      "Epoch 1877, Loss: 0.010342369379941374, Final Batch Loss: 0.0009407788165844977\n",
      "Epoch 1878, Loss: 0.0009889858483802527, Final Batch Loss: 0.0006007631891407073\n",
      "Epoch 1879, Loss: 0.0026773814315674827, Final Batch Loss: 0.00021876550454180688\n",
      "Epoch 1880, Loss: 0.002040774328634143, Final Batch Loss: 0.0017615562537685037\n",
      "Epoch 1881, Loss: 0.0030504792812280357, Final Batch Loss: 0.0024570736568421125\n",
      "Epoch 1882, Loss: 0.0030066354665905237, Final Batch Loss: 0.0015608969843015075\n",
      "Epoch 1883, Loss: 0.0028545260429382324, Final Batch Loss: 0.002070173155516386\n",
      "Epoch 1884, Loss: 0.002437980117974803, Final Batch Loss: 0.0004240225243847817\n",
      "Epoch 1885, Loss: 0.0015400421107187867, Final Batch Loss: 0.0012929420918226242\n",
      "Epoch 1886, Loss: 0.0007573520124424249, Final Batch Loss: 0.0005389419384300709\n",
      "Epoch 1887, Loss: 0.004395725081849378, Final Batch Loss: 8.497514500049874e-05\n",
      "Epoch 1888, Loss: 0.0017384718812536448, Final Batch Loss: 0.0003533441049512476\n",
      "Epoch 1889, Loss: 0.0006898622232256457, Final Batch Loss: 0.0005395464249886572\n",
      "Epoch 1890, Loss: 0.006153041264042258, Final Batch Loss: 0.0035940285306423903\n",
      "Epoch 1891, Loss: 0.0007100304064806551, Final Batch Loss: 0.0004145332786720246\n",
      "Epoch 1892, Loss: 0.006658417143626139, Final Batch Loss: 0.006176067516207695\n",
      "Epoch 1893, Loss: 0.0012398961407598108, Final Batch Loss: 0.000754431588575244\n",
      "Epoch 1894, Loss: 0.0007219551334856078, Final Batch Loss: 0.0001933714229380712\n",
      "Epoch 1895, Loss: 0.0046980518964119256, Final Batch Loss: 0.0006601571221835911\n",
      "Epoch 1896, Loss: 0.0010179755336139351, Final Batch Loss: 0.0007847401429899037\n",
      "Epoch 1897, Loss: 0.0011544833687366918, Final Batch Loss: 0.00023558038810733706\n",
      "Epoch 1898, Loss: 0.002906452340539545, Final Batch Loss: 0.002623156877234578\n",
      "Epoch 1899, Loss: 0.0025366346817463636, Final Batch Loss: 0.001061406685039401\n",
      "Epoch 1900, Loss: 0.0058390755293658, Final Batch Loss: 0.005707957781851292\n",
      "Epoch 1901, Loss: 0.011362257995642722, Final Batch Loss: 0.009974666871130466\n",
      "Epoch 1902, Loss: 0.001069418911356479, Final Batch Loss: 0.00071651057805866\n",
      "Epoch 1903, Loss: 0.0012267807323951274, Final Batch Loss: 0.00027614060672931373\n",
      "Epoch 1904, Loss: 0.000421148186433129, Final Batch Loss: 0.0001484055392211303\n",
      "Epoch 1905, Loss: 0.0032921383099164814, Final Batch Loss: 0.00023580444394610822\n",
      "Epoch 1906, Loss: 0.0011559982667677104, Final Batch Loss: 0.0009098004666157067\n",
      "Epoch 1907, Loss: 0.0012972214026376605, Final Batch Loss: 0.0004903876106254756\n",
      "Epoch 1908, Loss: 0.0036817809159401804, Final Batch Loss: 0.0002518528199288994\n",
      "Epoch 1909, Loss: 0.0011297814780846238, Final Batch Loss: 0.0005454751080833375\n",
      "Epoch 1910, Loss: 0.000647782493615523, Final Batch Loss: 0.00023769986000843346\n",
      "Epoch 1911, Loss: 0.0010908144977292977, Final Batch Loss: 8.641825843369588e-05\n",
      "Epoch 1912, Loss: 0.0014794767485000193, Final Batch Loss: 0.0007974888430908322\n",
      "Epoch 1913, Loss: 0.0008652476681163535, Final Batch Loss: 0.0006599500775337219\n",
      "Epoch 1914, Loss: 0.001390396326314658, Final Batch Loss: 0.0002176266280002892\n",
      "Epoch 1915, Loss: 0.0008302194182761014, Final Batch Loss: 0.0002272723359055817\n",
      "Epoch 1916, Loss: 0.0012312499166000634, Final Batch Loss: 0.00044713038369081914\n",
      "Epoch 1917, Loss: 0.014219082775525749, Final Batch Loss: 0.013116013258695602\n",
      "Epoch 1918, Loss: 0.0010340320732211694, Final Batch Loss: 9.128350939135998e-05\n",
      "Epoch 1919, Loss: 0.001851179200457409, Final Batch Loss: 0.0003729199816007167\n",
      "Epoch 1920, Loss: 0.002331293566385284, Final Batch Loss: 0.00041382855852134526\n",
      "Epoch 1921, Loss: 0.0007830005779396743, Final Batch Loss: 0.0005584645550698042\n",
      "Epoch 1922, Loss: 0.0007188845338532701, Final Batch Loss: 0.00011874137271661311\n",
      "Epoch 1923, Loss: 0.002039247890934348, Final Batch Loss: 0.0017626286717131734\n",
      "Epoch 1924, Loss: 0.00026727117801783606, Final Batch Loss: 0.0001516131014795974\n",
      "Epoch 1925, Loss: 0.0008104172302410007, Final Batch Loss: 0.00012223765952512622\n",
      "Epoch 1926, Loss: 0.0012219951022416353, Final Batch Loss: 0.0009260030346922576\n",
      "Epoch 1927, Loss: 0.0022971747093833983, Final Batch Loss: 0.0016359658911824226\n",
      "Epoch 1928, Loss: 0.0004549993755063042, Final Batch Loss: 0.0001842710917117074\n",
      "Epoch 1929, Loss: 0.00022484740475192666, Final Batch Loss: 0.000124709855299443\n",
      "Epoch 1930, Loss: 0.0007626350852660835, Final Batch Loss: 9.494519326835871e-05\n",
      "Epoch 1931, Loss: 0.006234036816749722, Final Batch Loss: 0.0006648777634836733\n",
      "Epoch 1932, Loss: 0.0012076684652129188, Final Batch Loss: 0.000992060056887567\n",
      "Epoch 1933, Loss: 0.0011749966070055962, Final Batch Loss: 0.00021794106578454375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1934, Loss: 0.0008628454233985394, Final Batch Loss: 0.00031795495306141675\n",
      "Epoch 1935, Loss: 0.0007670621562283486, Final Batch Loss: 0.0006430117646232247\n",
      "Epoch 1936, Loss: 0.00785430462565273, Final Batch Loss: 0.0006717749638482928\n",
      "Epoch 1937, Loss: 0.002520228852517903, Final Batch Loss: 0.0014501088298857212\n",
      "Epoch 1938, Loss: 0.001532434020191431, Final Batch Loss: 0.001227381406351924\n",
      "Epoch 1939, Loss: 0.001588327722856775, Final Batch Loss: 0.00030116355628706515\n",
      "Epoch 1940, Loss: 0.0011899048840859905, Final Batch Loss: 0.0010436131851747632\n",
      "Epoch 1941, Loss: 0.0015058656863402575, Final Batch Loss: 0.0012551191030070186\n",
      "Epoch 1942, Loss: 0.002636411663843319, Final Batch Loss: 0.0021890366915613413\n",
      "Epoch 1943, Loss: 0.0011303138744551688, Final Batch Loss: 0.0009005590109154582\n",
      "Epoch 1944, Loss: 0.0025831445236690342, Final Batch Loss: 0.0020775620359927416\n",
      "Epoch 1945, Loss: 0.0006993006973061711, Final Batch Loss: 0.00043107339297421277\n",
      "Epoch 1946, Loss: 0.0010274435044266284, Final Batch Loss: 0.0003291881876066327\n",
      "Epoch 1947, Loss: 0.0008019845263333991, Final Batch Loss: 0.0006220372742973268\n",
      "Epoch 1948, Loss: 0.0011384812532924116, Final Batch Loss: 0.0008147899061441422\n",
      "Epoch 1949, Loss: 0.0004549510049400851, Final Batch Loss: 0.0001706105686025694\n",
      "Epoch 1950, Loss: 0.0002285784503328614, Final Batch Loss: 8.35093596833758e-05\n",
      "Epoch 1951, Loss: 0.0017963169375434518, Final Batch Loss: 0.0016294175293296576\n",
      "Epoch 1952, Loss: 0.0015270680669345893, Final Batch Loss: 6.108728848630562e-05\n",
      "Epoch 1953, Loss: 0.00016884529759408906, Final Batch Loss: 0.0001052661900757812\n",
      "Epoch 1954, Loss: 0.002256234030937776, Final Batch Loss: 0.00013269399642013013\n",
      "Epoch 1955, Loss: 0.00026146566233364865, Final Batch Loss: 4.156995419180021e-05\n",
      "Epoch 1956, Loss: 0.0010276141110807657, Final Batch Loss: 0.0005828547873534262\n",
      "Epoch 1957, Loss: 0.0005464542919071391, Final Batch Loss: 0.00015864586748648435\n",
      "Epoch 1958, Loss: 0.0009087294529308565, Final Batch Loss: 0.00011383870878489688\n",
      "Epoch 1959, Loss: 0.00034742968273349106, Final Batch Loss: 0.00019039401377085596\n",
      "Epoch 1960, Loss: 0.003711775498231873, Final Batch Loss: 0.0035534249618649483\n",
      "Epoch 1961, Loss: 0.0008196440248866566, Final Batch Loss: 0.00011854718468384817\n",
      "Epoch 1962, Loss: 0.0014498379605356604, Final Batch Loss: 0.00013880865299142897\n",
      "Epoch 1963, Loss: 0.0006356887461151928, Final Batch Loss: 0.0004921296495012939\n",
      "Epoch 1964, Loss: 0.0006152895948616788, Final Batch Loss: 0.00018221257778350264\n",
      "Epoch 1965, Loss: 0.0024304238613694906, Final Batch Loss: 0.0010001902701333165\n",
      "Epoch 1966, Loss: 0.006545000593177974, Final Batch Loss: 0.0006316014332696795\n",
      "Epoch 1967, Loss: 0.0002453909364703577, Final Batch Loss: 3.41008671966847e-05\n",
      "Epoch 1968, Loss: 0.0008130312780849636, Final Batch Loss: 0.00016619410598650575\n",
      "Epoch 1969, Loss: 0.0006865392060717568, Final Batch Loss: 7.436254236381501e-05\n",
      "Epoch 1970, Loss: 0.0006158264586701989, Final Batch Loss: 0.0002912890340667218\n",
      "Epoch 1971, Loss: 0.0002818357679643668, Final Batch Loss: 0.00010170321183977649\n",
      "Epoch 1972, Loss: 0.0005522618957911618, Final Batch Loss: 0.0004494870372582227\n",
      "Epoch 1973, Loss: 0.008538067937479354, Final Batch Loss: 0.000155924484715797\n",
      "Epoch 1974, Loss: 0.0015658582124160603, Final Batch Loss: 0.000130527259898372\n",
      "Epoch 1975, Loss: 0.00881278037559241, Final Batch Loss: 0.008704124018549919\n",
      "Epoch 1976, Loss: 0.0002468550628691446, Final Batch Loss: 2.288349423906766e-05\n",
      "Epoch 1977, Loss: 0.010966917034238577, Final Batch Loss: 0.008353340439498425\n",
      "Epoch 1978, Loss: 0.0003390246565686539, Final Batch Loss: 0.00017888958973344415\n",
      "Epoch 1979, Loss: 0.004501158371567726, Final Batch Loss: 0.0029222092125564814\n",
      "Epoch 1980, Loss: 0.0012599212423083372, Final Batch Loss: 0.0011930424952879548\n",
      "Epoch 1981, Loss: 0.0006501523894257843, Final Batch Loss: 0.0003972644917666912\n",
      "Epoch 1982, Loss: 0.0035221705766161904, Final Batch Loss: 0.0033904951997101307\n",
      "Epoch 1983, Loss: 0.0045288733672350645, Final Batch Loss: 0.004133753478527069\n",
      "Epoch 1984, Loss: 0.00038742023753002286, Final Batch Loss: 0.0001399744360242039\n",
      "Epoch 1985, Loss: 0.0005559900964726694, Final Batch Loss: 0.00010733362432802096\n",
      "Epoch 1986, Loss: 0.00016739025522838347, Final Batch Loss: 6.0270660469541326e-05\n",
      "Epoch 1987, Loss: 0.0007358648581430316, Final Batch Loss: 0.000470529223093763\n",
      "Epoch 1988, Loss: 0.002838820611941628, Final Batch Loss: 0.00010394437413197011\n",
      "Epoch 1989, Loss: 0.0007011269917711616, Final Batch Loss: 0.00028704237774945796\n",
      "Epoch 1990, Loss: 0.00011141713184770197, Final Batch Loss: 3.4066826628986746e-05\n",
      "Epoch 1991, Loss: 0.0005218794649408665, Final Batch Loss: 3.169418414472602e-05\n",
      "Epoch 1992, Loss: 0.00020261264580767602, Final Batch Loss: 0.00015320468810386956\n",
      "Epoch 1993, Loss: 0.0035600681439973414, Final Batch Loss: 0.003112389240413904\n",
      "Epoch 1994, Loss: 0.016530419001355767, Final Batch Loss: 0.015894535928964615\n",
      "Epoch 1995, Loss: 0.0017320729966741055, Final Batch Loss: 0.0012943781912326813\n",
      "Epoch 1996, Loss: 0.00039052742067724466, Final Batch Loss: 0.00022956272005103528\n",
      "Epoch 1997, Loss: 0.0006882802554173395, Final Batch Loss: 8.684534986969084e-05\n",
      "Epoch 1998, Loss: 0.001687228330411017, Final Batch Loss: 0.001174762612208724\n",
      "Epoch 1999, Loss: 0.004127924650674686, Final Batch Loss: 0.00029920352972112596\n",
      "Epoch 2000, Loss: 0.0003306610888103023, Final Batch Loss: 0.0001639213296584785\n",
      "Epoch 2001, Loss: 0.00048469921603100374, Final Batch Loss: 0.00010858523455681279\n",
      "Epoch 2002, Loss: 0.0018302132084500045, Final Batch Loss: 0.00012616891763173044\n",
      "Epoch 2003, Loss: 0.0033378780353814363, Final Batch Loss: 0.0003346600569784641\n",
      "Epoch 2004, Loss: 0.0011284175561740994, Final Batch Loss: 0.0003600445343181491\n",
      "Epoch 2005, Loss: 0.006317498584394343, Final Batch Loss: 0.006103793624788523\n",
      "Epoch 2006, Loss: 0.0009628001425880939, Final Batch Loss: 0.0006034847465343773\n",
      "Epoch 2007, Loss: 0.0006981359038036317, Final Batch Loss: 0.00011584718595258892\n",
      "Epoch 2008, Loss: 0.0008561509021092206, Final Batch Loss: 0.0005938376416452229\n",
      "Epoch 2009, Loss: 0.0009557908633723855, Final Batch Loss: 0.0008986610337160528\n",
      "Epoch 2010, Loss: 0.0003578063769964501, Final Batch Loss: 0.0003028411010745913\n",
      "Epoch 2011, Loss: 0.008583128204918467, Final Batch Loss: 0.008432210423052311\n",
      "Epoch 2012, Loss: 0.00645992998033762, Final Batch Loss: 0.004808919504284859\n",
      "Epoch 2013, Loss: 0.00018845555860025343, Final Batch Loss: 1.4460913007496856e-05\n",
      "Epoch 2014, Loss: 0.0003096930668107234, Final Batch Loss: 6.391759234247729e-05\n",
      "Epoch 2015, Loss: 0.005007516476325691, Final Batch Loss: 0.0002708755200728774\n",
      "Epoch 2016, Loss: 0.0035477690089464886, Final Batch Loss: 0.003535190364345908\n",
      "Epoch 2017, Loss: 0.0007826687360648066, Final Batch Loss: 0.00027749777655117214\n",
      "Epoch 2018, Loss: 0.003935602959245443, Final Batch Loss: 0.0010803528130054474\n",
      "Epoch 2019, Loss: 0.0004669719055527821, Final Batch Loss: 0.00025444297352805734\n",
      "Epoch 2020, Loss: 0.004848977958317846, Final Batch Loss: 0.004292277619242668\n",
      "Epoch 2021, Loss: 0.013389139901846647, Final Batch Loss: 0.0014792676083743572\n",
      "Epoch 2022, Loss: 0.0006003648450132459, Final Batch Loss: 0.00034021917963400483\n",
      "Epoch 2023, Loss: 0.0008471323817502707, Final Batch Loss: 0.000644089188426733\n",
      "Epoch 2024, Loss: 0.0026844840467674658, Final Batch Loss: 0.00016801994934212416\n",
      "Epoch 2025, Loss: 0.0028054421418346465, Final Batch Loss: 0.002074258867651224\n",
      "Epoch 2026, Loss: 0.010277558525558561, Final Batch Loss: 0.009596958756446838\n",
      "Epoch 2027, Loss: 0.013118497998220846, Final Batch Loss: 0.012845208868384361\n",
      "Epoch 2028, Loss: 0.0005773681405116804, Final Batch Loss: 0.0005165539332665503\n",
      "Epoch 2029, Loss: 0.003909332444891334, Final Batch Loss: 0.0024017873220145702\n",
      "Epoch 2030, Loss: 0.0003530976246111095, Final Batch Loss: 0.00012918203719891608\n",
      "Epoch 2031, Loss: 0.0004246099415468052, Final Batch Loss: 0.0002238399174530059\n",
      "Epoch 2032, Loss: 0.0005006244755350053, Final Batch Loss: 0.00015297782374545932\n",
      "Epoch 2033, Loss: 0.0010526463302085176, Final Batch Loss: 5.0648945034481585e-05\n",
      "Epoch 2034, Loss: 0.0002760906209005043, Final Batch Loss: 8.516642265021801e-05\n",
      "Epoch 2035, Loss: 0.001588383034686558, Final Batch Loss: 0.0001226888707606122\n",
      "Epoch 2036, Loss: 0.0009552864648867399, Final Batch Loss: 0.0008209943771362305\n",
      "Epoch 2037, Loss: 0.0006149572145659477, Final Batch Loss: 0.0002360470243729651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2038, Loss: 0.0010558845242485404, Final Batch Loss: 0.0005975307431071997\n",
      "Epoch 2039, Loss: 0.0005770482093794271, Final Batch Loss: 0.0005169221549294889\n",
      "Epoch 2040, Loss: 0.004157863499131054, Final Batch Loss: 0.0005090513150207698\n",
      "Epoch 2041, Loss: 0.0002460289397276938, Final Batch Loss: 4.858827742282301e-05\n",
      "Epoch 2042, Loss: 0.0009550232934998348, Final Batch Loss: 9.263267565984279e-05\n",
      "Epoch 2043, Loss: 0.0051010487077292055, Final Batch Loss: 0.004824103321880102\n",
      "Epoch 2044, Loss: 0.0016417670994997025, Final Batch Loss: 0.0013476061867550015\n",
      "Epoch 2045, Loss: 0.0005112064245622605, Final Batch Loss: 0.00037752932985313237\n",
      "Epoch 2046, Loss: 0.014843564247712493, Final Batch Loss: 0.002403972437605262\n",
      "Epoch 2047, Loss: 0.001369704375974834, Final Batch Loss: 0.001150350784882903\n",
      "Epoch 2048, Loss: 0.0005502674175659195, Final Batch Loss: 0.00011256926518399268\n",
      "Epoch 2049, Loss: 0.0036622873303713277, Final Batch Loss: 0.003544835140928626\n",
      "Epoch 2050, Loss: 0.0006501821771962568, Final Batch Loss: 9.316815703641623e-05\n",
      "Epoch 2051, Loss: 0.0011880472011398524, Final Batch Loss: 0.0008857717039063573\n",
      "Epoch 2052, Loss: 0.0008710357651580125, Final Batch Loss: 0.00032366786035709083\n",
      "Epoch 2053, Loss: 0.0016141241139848717, Final Batch Loss: 0.0015526070492342114\n",
      "Epoch 2054, Loss: 0.0003826553547696676, Final Batch Loss: 0.00033469850313849747\n",
      "Epoch 2055, Loss: 0.0018227180116809905, Final Batch Loss: 0.00022225052816793323\n",
      "Epoch 2056, Loss: 0.0029532272019423544, Final Batch Loss: 0.0005468503222800791\n",
      "Epoch 2057, Loss: 0.0012623291549971327, Final Batch Loss: 0.00022415838611777872\n",
      "Epoch 2058, Loss: 0.0005309663210937288, Final Batch Loss: 3.24893590004649e-05\n",
      "Epoch 2059, Loss: 0.008613320635049604, Final Batch Loss: 0.008547148667275906\n",
      "Epoch 2060, Loss: 0.0007266892062034458, Final Batch Loss: 0.0002524669107515365\n",
      "Epoch 2061, Loss: 0.0016208135057240725, Final Batch Loss: 0.0007527662673965096\n",
      "Epoch 2062, Loss: 0.0011281049810349941, Final Batch Loss: 0.0006298551452346146\n",
      "Epoch 2063, Loss: 0.0015957893920131028, Final Batch Loss: 0.00034693587804213166\n",
      "Epoch 2064, Loss: 0.0001666770112933591, Final Batch Loss: 0.00011317643657093868\n",
      "Epoch 2065, Loss: 0.004112762428121641, Final Batch Loss: 0.0038414171431213617\n",
      "Epoch 2066, Loss: 0.0002488956961315125, Final Batch Loss: 0.00016109527496155351\n",
      "Epoch 2067, Loss: 0.005555547209951328, Final Batch Loss: 2.6717683795141056e-05\n",
      "Epoch 2068, Loss: 0.0003031694213859737, Final Batch Loss: 0.000252412079134956\n",
      "Epoch 2069, Loss: 0.001014366134768352, Final Batch Loss: 0.0006677074125036597\n",
      "Epoch 2070, Loss: 0.008515765948686749, Final Batch Loss: 0.0003539240569807589\n",
      "Epoch 2071, Loss: 0.0004810167010873556, Final Batch Loss: 0.000252906495006755\n",
      "Epoch 2072, Loss: 0.00026251061353832483, Final Batch Loss: 0.00018351156904827803\n",
      "Epoch 2073, Loss: 0.0005274379509501159, Final Batch Loss: 0.0003680358058772981\n",
      "Epoch 2074, Loss: 0.0035705050395336, Final Batch Loss: 0.003306361846625805\n",
      "Epoch 2075, Loss: 0.0011524082510732114, Final Batch Loss: 0.00037370790960267186\n",
      "Epoch 2076, Loss: 0.0004929354763589799, Final Batch Loss: 6.741349352523685e-05\n",
      "Epoch 2077, Loss: 0.00047903144150041044, Final Batch Loss: 0.00025584467221051455\n",
      "Epoch 2078, Loss: 0.00035799475517706014, Final Batch Loss: 5.638253423967399e-05\n",
      "Epoch 2079, Loss: 0.00042807501449715346, Final Batch Loss: 0.00016327561752405018\n",
      "Epoch 2080, Loss: 0.0008923920977395028, Final Batch Loss: 0.00043639898649416864\n",
      "Epoch 2081, Loss: 0.0002144054597010836, Final Batch Loss: 8.532076026313007e-05\n",
      "Epoch 2082, Loss: 0.0059133915638085455, Final Batch Loss: 0.005739287938922644\n",
      "Epoch 2083, Loss: 0.0002277856256114319, Final Batch Loss: 0.00013344392937142402\n",
      "Epoch 2084, Loss: 0.0007418028253596276, Final Batch Loss: 0.0004677283577620983\n",
      "Epoch 2085, Loss: 0.006389815825968981, Final Batch Loss: 0.003825543215498328\n",
      "Epoch 2086, Loss: 0.0028757444815710187, Final Batch Loss: 0.0008781173964962363\n",
      "Epoch 2087, Loss: 0.00011964191253355239, Final Batch Loss: 2.8067503080819733e-05\n",
      "Epoch 2088, Loss: 0.0005630501109408215, Final Batch Loss: 0.00019306411559227854\n",
      "Epoch 2089, Loss: 0.004488334525376558, Final Batch Loss: 0.0013883968349546194\n",
      "Epoch 2090, Loss: 0.0016286990721710026, Final Batch Loss: 0.0010260945418849587\n",
      "Epoch 2091, Loss: 0.0013711966457776725, Final Batch Loss: 0.00022798863938078284\n",
      "Epoch 2092, Loss: 0.001087343815015629, Final Batch Loss: 0.0008539744303561747\n",
      "Epoch 2093, Loss: 0.005459787207655609, Final Batch Loss: 0.0010697901016101241\n",
      "Epoch 2094, Loss: 0.0003765081492019817, Final Batch Loss: 8.815004548523575e-05\n",
      "Epoch 2095, Loss: 0.007119491790945176, Final Batch Loss: 5.5224263633135706e-05\n",
      "Epoch 2096, Loss: 0.00016568938372074626, Final Batch Loss: 0.0001319621514994651\n",
      "Epoch 2097, Loss: 0.0013804914196953177, Final Batch Loss: 0.0009143406641669571\n",
      "Epoch 2098, Loss: 0.02205895190127194, Final Batch Loss: 0.02143116667866707\n",
      "Epoch 2099, Loss: 0.0009702181414468214, Final Batch Loss: 0.00019223270646762103\n",
      "Epoch 2100, Loss: 0.000572926044696942, Final Batch Loss: 0.00028895778814330697\n",
      "Epoch 2101, Loss: 0.005555491225095466, Final Batch Loss: 0.0003338351671118289\n",
      "Epoch 2102, Loss: 0.001320562427281402, Final Batch Loss: 0.0010767884086817503\n",
      "Epoch 2103, Loss: 0.00018301629461348057, Final Batch Loss: 5.9341706219129264e-05\n",
      "Epoch 2104, Loss: 0.001863266050349921, Final Batch Loss: 0.0013215026119723916\n",
      "Epoch 2105, Loss: 0.009962352807633579, Final Batch Loss: 0.001661553862504661\n",
      "Epoch 2106, Loss: 0.004220641771098599, Final Batch Loss: 0.003860904136672616\n",
      "Epoch 2107, Loss: 0.0004686049433075823, Final Batch Loss: 0.00042184628546237946\n",
      "Epoch 2108, Loss: 0.0005458191590150818, Final Batch Loss: 0.00018850834749173373\n",
      "Epoch 2109, Loss: 0.0030624010832980275, Final Batch Loss: 0.0014305108925327659\n",
      "Epoch 2110, Loss: 0.0009521769970888272, Final Batch Loss: 0.00017911552276927978\n",
      "Epoch 2111, Loss: 0.0018235025781905279, Final Batch Loss: 8.323985093738884e-05\n",
      "Epoch 2112, Loss: 0.0010316679254174232, Final Batch Loss: 0.0005640461458824575\n",
      "Epoch 2113, Loss: 0.006022489091265015, Final Batch Loss: 0.005891512148082256\n",
      "Epoch 2114, Loss: 0.0015864767192397267, Final Batch Loss: 0.001326951663941145\n",
      "Epoch 2115, Loss: 0.0004946197150275111, Final Batch Loss: 0.00014896350330673158\n",
      "Epoch 2116, Loss: 0.0017291612457484007, Final Batch Loss: 0.0005456797080114484\n",
      "Epoch 2117, Loss: 0.003269266802817583, Final Batch Loss: 0.000931307440623641\n",
      "Epoch 2118, Loss: 0.0028794441022910178, Final Batch Loss: 0.0009025612962432206\n",
      "Epoch 2119, Loss: 0.0011002160608768463, Final Batch Loss: 0.000416789494920522\n",
      "Epoch 2120, Loss: 0.00010516804286453407, Final Batch Loss: 7.492875738535076e-05\n",
      "Epoch 2121, Loss: 0.0035273806424811482, Final Batch Loss: 0.0026802048087120056\n",
      "Epoch 2122, Loss: 0.00036411334076547064, Final Batch Loss: 0.0003415579558350146\n",
      "Epoch 2123, Loss: 0.0004972419410478324, Final Batch Loss: 0.00013613171176984906\n",
      "Epoch 2124, Loss: 0.00585942614270607, Final Batch Loss: 7.731878577033058e-05\n",
      "Epoch 2125, Loss: 0.0017350819834973663, Final Batch Loss: 3.9995735278353095e-05\n",
      "Epoch 2126, Loss: 0.0008903815178200603, Final Batch Loss: 0.00018847733736038208\n",
      "Epoch 2127, Loss: 0.00019047316163778305, Final Batch Loss: 4.648599133361131e-05\n",
      "Epoch 2128, Loss: 0.0008747879546717741, Final Batch Loss: 0.00010632209159666672\n",
      "Epoch 2129, Loss: 0.0010223162680631503, Final Batch Loss: 0.00019339470600243658\n",
      "Epoch 2130, Loss: 0.005760843749158084, Final Batch Loss: 0.005697158165276051\n",
      "Epoch 2131, Loss: 0.0009597486059647053, Final Batch Loss: 0.0002516029926482588\n",
      "Epoch 2132, Loss: 0.0040261647664010525, Final Batch Loss: 0.003137618536129594\n",
      "Epoch 2133, Loss: 0.0013301915460033342, Final Batch Loss: 0.0011820589425042272\n",
      "Epoch 2134, Loss: 0.0008283685820060782, Final Batch Loss: 7.57978341425769e-05\n",
      "Epoch 2135, Loss: 0.0009132844279520214, Final Batch Loss: 0.0008314948063343763\n",
      "Epoch 2136, Loss: 0.00024093523097690195, Final Batch Loss: 5.749633419327438e-05\n",
      "Epoch 2137, Loss: 0.00024318720716109965, Final Batch Loss: 0.00023227283963933587\n",
      "Epoch 2138, Loss: 0.005298459669575095, Final Batch Loss: 0.0005649628583341837\n",
      "Epoch 2139, Loss: 0.007986711847479455, Final Batch Loss: 0.007854606956243515\n",
      "Epoch 2140, Loss: 0.017175548942759633, Final Batch Loss: 0.01453992910683155\n",
      "Epoch 2141, Loss: 0.0002728975050558802, Final Batch Loss: 3.440708314883523e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2142, Loss: 0.005688048760930542, Final Batch Loss: 6.902576569700614e-05\n",
      "Epoch 2143, Loss: 0.0002661151083884761, Final Batch Loss: 0.000123269681353122\n",
      "Epoch 2144, Loss: 0.0014326149102998897, Final Batch Loss: 0.000141265380079858\n",
      "Epoch 2145, Loss: 0.0006937377474969253, Final Batch Loss: 1.9468236132524908e-05\n",
      "Epoch 2146, Loss: 0.00010834820568561554, Final Batch Loss: 2.4850953195709735e-05\n",
      "Epoch 2147, Loss: 0.0007785286725265905, Final Batch Loss: 0.0001539153017802164\n",
      "Epoch 2148, Loss: 0.0056511713191866875, Final Batch Loss: 0.0016182954423129559\n",
      "Epoch 2149, Loss: 0.020134508558840025, Final Batch Loss: 0.020015999674797058\n",
      "Epoch 2150, Loss: 0.00025965593522414565, Final Batch Loss: 9.49132809182629e-05\n",
      "Epoch 2151, Loss: 0.0009184962254948914, Final Batch Loss: 0.00043874458060599864\n",
      "Epoch 2152, Loss: 0.0014826924343651626, Final Batch Loss: 5.7226981880376115e-05\n",
      "Epoch 2153, Loss: 0.001524115476058796, Final Batch Loss: 0.0013776511186733842\n",
      "Epoch 2154, Loss: 0.0018232457077829167, Final Batch Loss: 0.0001999553496716544\n",
      "Epoch 2155, Loss: 0.0006850435311207548, Final Batch Loss: 0.00047554943012073636\n",
      "Epoch 2156, Loss: 0.000851834069180768, Final Batch Loss: 6.152909918455407e-05\n",
      "Epoch 2157, Loss: 0.0018980357563123107, Final Batch Loss: 0.0010293381055817008\n",
      "Epoch 2158, Loss: 0.00041428474651183933, Final Batch Loss: 0.00014352788275573403\n",
      "Epoch 2159, Loss: 0.0006911083910381421, Final Batch Loss: 0.0005445374990813434\n",
      "Epoch 2160, Loss: 0.0005615588743239641, Final Batch Loss: 0.00022144211106933653\n",
      "Epoch 2161, Loss: 0.00017721482072374783, Final Batch Loss: 3.359121546964161e-05\n",
      "Epoch 2162, Loss: 0.0014934331411495805, Final Batch Loss: 0.0006680471124127507\n",
      "Epoch 2163, Loss: 0.0007462941284757107, Final Batch Loss: 0.000355168420355767\n",
      "Epoch 2164, Loss: 0.0006720622859575087, Final Batch Loss: 1.6886633602553047e-05\n",
      "Epoch 2165, Loss: 0.00038658769335597754, Final Batch Loss: 0.00022500540944747627\n",
      "Epoch 2166, Loss: 0.0011133778607472777, Final Batch Loss: 0.0009868110064417124\n",
      "Epoch 2167, Loss: 0.0002330321804038249, Final Batch Loss: 3.1043826311361045e-05\n",
      "Epoch 2168, Loss: 0.013762019108980894, Final Batch Loss: 0.001993271056562662\n",
      "Epoch 2169, Loss: 0.000581493295612745, Final Batch Loss: 0.00046015530824661255\n",
      "Epoch 2170, Loss: 0.00037529745895881206, Final Batch Loss: 0.00023531100305262953\n",
      "Epoch 2171, Loss: 0.0011608727909333538, Final Batch Loss: 2.069065158138983e-05\n",
      "Epoch 2172, Loss: 0.0016272885659418534, Final Batch Loss: 6.088467125664465e-05\n",
      "Epoch 2173, Loss: 0.0002606195630505681, Final Batch Loss: 9.501035674475133e-05\n",
      "Epoch 2174, Loss: 0.004387954599224031, Final Batch Loss: 0.00327883823774755\n",
      "Epoch 2175, Loss: 0.0026859035424422473, Final Batch Loss: 0.000323640852002427\n",
      "Epoch 2176, Loss: 0.0016535384929738939, Final Batch Loss: 0.0006551383412443101\n",
      "Epoch 2177, Loss: 0.00037927483208477497, Final Batch Loss: 0.00022946410172153264\n",
      "Epoch 2178, Loss: 0.002853567973943427, Final Batch Loss: 0.002762869466096163\n",
      "Epoch 2179, Loss: 0.0009501036256551743, Final Batch Loss: 0.000408771971706301\n",
      "Epoch 2180, Loss: 0.0008160708166542463, Final Batch Loss: 5.245819193078205e-05\n",
      "Epoch 2181, Loss: 0.0010392752265033778, Final Batch Loss: 3.648470374173485e-05\n",
      "Epoch 2182, Loss: 0.001558277574076783, Final Batch Loss: 9.34182244236581e-05\n",
      "Epoch 2183, Loss: 0.0027180758770555258, Final Batch Loss: 0.0019073025323450565\n",
      "Epoch 2184, Loss: 0.0012394675140967593, Final Batch Loss: 3.2458206987939775e-05\n",
      "Epoch 2185, Loss: 0.0003300081880297512, Final Batch Loss: 0.00024494220269843936\n",
      "Epoch 2186, Loss: 0.0009908426727633923, Final Batch Loss: 0.00040632797754369676\n",
      "Epoch 2187, Loss: 0.0002586833688837942, Final Batch Loss: 0.00019846868235617876\n",
      "Epoch 2188, Loss: 0.0005156508268555626, Final Batch Loss: 0.00020570929336827248\n",
      "Epoch 2189, Loss: 0.0009452812082599849, Final Batch Loss: 0.0004172670014668256\n",
      "Epoch 2190, Loss: 0.0031812330707907677, Final Batch Loss: 0.0028873723931610584\n",
      "Epoch 2191, Loss: 0.0005700590991182253, Final Batch Loss: 0.00020604497694876045\n",
      "Epoch 2192, Loss: 0.0006022854067850858, Final Batch Loss: 0.0003075397398788482\n",
      "Epoch 2193, Loss: 7.261514474521391e-05, Final Batch Loss: 3.994221697212197e-05\n",
      "Epoch 2194, Loss: 0.0013537479826482013, Final Batch Loss: 0.0012227039551362395\n",
      "Epoch 2195, Loss: 0.0013631673355121166, Final Batch Loss: 0.0002516095119062811\n",
      "Epoch 2196, Loss: 0.009108677186304703, Final Batch Loss: 0.009010719135403633\n",
      "Epoch 2197, Loss: 0.00020216381381032988, Final Batch Loss: 7.590100722154602e-05\n",
      "Epoch 2198, Loss: 0.0008638718427391723, Final Batch Loss: 0.0007620147662237287\n",
      "Epoch 2199, Loss: 0.0038720989832654595, Final Batch Loss: 0.0032479220535606146\n",
      "Epoch 2200, Loss: 0.0004637483070837334, Final Batch Loss: 0.00016892504936549813\n",
      "Epoch 2201, Loss: 0.001957918517291546, Final Batch Loss: 0.00040759460534900427\n",
      "Epoch 2202, Loss: 0.00029501526296371594, Final Batch Loss: 5.472522025229409e-05\n",
      "Epoch 2203, Loss: 0.0008844671756378375, Final Batch Loss: 4.255942621966824e-05\n",
      "Epoch 2204, Loss: 0.007323773104872089, Final Batch Loss: 0.007244933396577835\n",
      "Epoch 2205, Loss: 0.0018580111063783988, Final Batch Loss: 0.0016812625108286738\n",
      "Epoch 2206, Loss: 0.0003878152638208121, Final Batch Loss: 0.00017046142602339387\n",
      "Epoch 2207, Loss: 0.0007244839653139934, Final Batch Loss: 0.00019370029622223228\n",
      "Epoch 2208, Loss: 0.0008856720814947039, Final Batch Loss: 0.0001622112758923322\n",
      "Epoch 2209, Loss: 0.0009774274949450046, Final Batch Loss: 0.0004066435794811696\n",
      "Epoch 2210, Loss: 0.002486862438672688, Final Batch Loss: 6.791503255954012e-05\n",
      "Epoch 2211, Loss: 0.0029493518304661848, Final Batch Loss: 0.0028736114036291838\n",
      "Epoch 2212, Loss: 0.003840780002065003, Final Batch Loss: 0.0008324322989210486\n",
      "Epoch 2213, Loss: 0.002089925925247371, Final Batch Loss: 0.0003494450356811285\n",
      "Epoch 2214, Loss: 0.0025297765805589734, Final Batch Loss: 2.1145138816791587e-05\n",
      "Epoch 2215, Loss: 0.011511638716910966, Final Batch Loss: 0.0001364256750093773\n",
      "Epoch 2216, Loss: 0.00043358822586014867, Final Batch Loss: 0.0003077703295275569\n",
      "Epoch 2217, Loss: 0.00030128796061035246, Final Batch Loss: 0.00017713844135869294\n",
      "Epoch 2218, Loss: 0.004648717887903331, Final Batch Loss: 3.9396178181050345e-05\n",
      "Epoch 2219, Loss: 0.0009709110308904201, Final Batch Loss: 0.0006091606919653714\n",
      "Epoch 2220, Loss: 0.003385284071555361, Final Batch Loss: 0.0029478471260517836\n",
      "Epoch 2221, Loss: 0.001653179817367345, Final Batch Loss: 0.0014074704376980662\n",
      "Epoch 2222, Loss: 0.0012256261161383009, Final Batch Loss: 0.001213321927934885\n",
      "Epoch 2223, Loss: 0.0009267352579627186, Final Batch Loss: 0.00039507882320322096\n",
      "Epoch 2224, Loss: 0.000263310234004166, Final Batch Loss: 0.00018924941832665354\n",
      "Epoch 2225, Loss: 0.000575215723074507, Final Batch Loss: 0.000515785242896527\n",
      "Epoch 2226, Loss: 0.003615631299908273, Final Batch Loss: 0.00023537995002698153\n",
      "Epoch 2227, Loss: 0.0003399198976694606, Final Batch Loss: 0.00022698137036059052\n",
      "Epoch 2228, Loss: 0.0013981643569422886, Final Batch Loss: 7.762019231449813e-05\n",
      "Epoch 2229, Loss: 0.00018600060866447166, Final Batch Loss: 5.222530307946727e-05\n",
      "Epoch 2230, Loss: 0.0002009814306802582, Final Batch Loss: 0.00015313852054532617\n",
      "Epoch 2231, Loss: 0.0012612105929292738, Final Batch Loss: 0.000623890315182507\n",
      "Epoch 2232, Loss: 0.004359756771009415, Final Batch Loss: 0.004236787557601929\n",
      "Epoch 2233, Loss: 0.00029057148640276864, Final Batch Loss: 0.0001842927886173129\n",
      "Epoch 2234, Loss: 0.000517543769092299, Final Batch Loss: 0.0003316940274089575\n",
      "Epoch 2235, Loss: 0.001443432891392149, Final Batch Loss: 0.00018338359950575978\n",
      "Epoch 2236, Loss: 0.0004160101598245092, Final Batch Loss: 0.00034616468474268913\n",
      "Epoch 2237, Loss: 0.004822575341677293, Final Batch Loss: 5.2359275287017226e-05\n",
      "Epoch 2238, Loss: 0.004703515380242607, Final Batch Loss: 5.134957245900296e-05\n",
      "Epoch 2239, Loss: 0.0014973719225963578, Final Batch Loss: 0.00016703362052794546\n",
      "Epoch 2240, Loss: 0.00011628626452875324, Final Batch Loss: 2.1395968360593542e-05\n",
      "Epoch 2241, Loss: 0.004205791941785719, Final Batch Loss: 5.194564437260851e-05\n",
      "Epoch 2242, Loss: 0.00017364949962939136, Final Batch Loss: 4.695262396126054e-05\n",
      "Epoch 2243, Loss: 0.000709629493940156, Final Batch Loss: 6.475083500845358e-05\n",
      "Epoch 2244, Loss: 0.00028965989622520283, Final Batch Loss: 0.0002026918373303488\n",
      "Epoch 2245, Loss: 0.005477030004840344, Final Batch Loss: 0.00028355157701298594\n",
      "Epoch 2246, Loss: 0.00020471401512622833, Final Batch Loss: 0.00010071435826830566\n",
      "Epoch 2247, Loss: 0.0006482216995209455, Final Batch Loss: 0.00024947820929810405\n",
      "Epoch 2248, Loss: 0.0009600922930985689, Final Batch Loss: 5.449325544759631e-05\n",
      "Epoch 2249, Loss: 0.0010529740975471213, Final Batch Loss: 0.00018699765496421605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2250, Loss: 0.00015718378563178703, Final Batch Loss: 2.3345310182776302e-05\n",
      "Epoch 2251, Loss: 0.00034240215609315783, Final Batch Loss: 0.00012574595166370273\n",
      "Epoch 2252, Loss: 0.0008238179143518209, Final Batch Loss: 0.00039917489630170166\n",
      "Epoch 2253, Loss: 0.00013540865984396078, Final Batch Loss: 0.00011693845590343699\n",
      "Epoch 2254, Loss: 0.0012606273958226666, Final Batch Loss: 0.0002001839311560616\n",
      "Epoch 2255, Loss: 0.0005751833978138166, Final Batch Loss: 2.135036811523605e-05\n",
      "Epoch 2256, Loss: 0.0005794126918772236, Final Batch Loss: 0.00021896995895076543\n",
      "Epoch 2257, Loss: 0.00023441524535883218, Final Batch Loss: 6.908373325131834e-05\n",
      "Epoch 2258, Loss: 0.0018470875220373273, Final Batch Loss: 0.0008015185594558716\n",
      "Epoch 2259, Loss: 3.5170083720004186e-05, Final Batch Loss: 1.7309044778812677e-05\n",
      "Epoch 2260, Loss: 0.010508202482014894, Final Batch Loss: 0.004911499563604593\n",
      "Epoch 2261, Loss: 0.00030885933119861875, Final Batch Loss: 0.00028307747561484575\n",
      "Epoch 2262, Loss: 0.009089414641493931, Final Batch Loss: 0.00030145017080940306\n",
      "Epoch 2263, Loss: 7.7549126217491e-05, Final Batch Loss: 2.4911141736083664e-05\n",
      "Epoch 2264, Loss: 0.0011518787941895425, Final Batch Loss: 0.00042615894926711917\n",
      "Epoch 2265, Loss: 0.004413573304191232, Final Batch Loss: 0.002005714224651456\n",
      "Epoch 2266, Loss: 0.00045932497596368194, Final Batch Loss: 6.847229087725282e-05\n",
      "Epoch 2267, Loss: 0.00024944244796643034, Final Batch Loss: 0.00012199511547805741\n",
      "Epoch 2268, Loss: 0.0005708282005798537, Final Batch Loss: 1.5809131582500413e-05\n",
      "Epoch 2269, Loss: 0.00020437710918486118, Final Batch Loss: 0.0001377986918669194\n",
      "Epoch 2270, Loss: 0.0032273543474730104, Final Batch Loss: 0.0001738049031700939\n",
      "Epoch 2271, Loss: 0.002071523733320646, Final Batch Loss: 8.028668526094407e-05\n",
      "Epoch 2272, Loss: 0.0025027000810950994, Final Batch Loss: 0.001509984489530325\n",
      "Epoch 2273, Loss: 0.0022016244183760136, Final Batch Loss: 0.0020481389947235584\n",
      "Epoch 2274, Loss: 0.009150350294021337, Final Batch Loss: 6.333752480713883e-06\n",
      "Epoch 2275, Loss: 0.00015512692789343419, Final Batch Loss: 1.3051675523456652e-05\n",
      "Epoch 2276, Loss: 0.000839605403598398, Final Batch Loss: 0.00042801719973795116\n",
      "Epoch 2277, Loss: 0.0007769146177452058, Final Batch Loss: 0.0004184453864581883\n",
      "Epoch 2278, Loss: 0.0006188003817442222, Final Batch Loss: 1.4369760720001068e-05\n",
      "Epoch 2279, Loss: 0.003077065688557923, Final Batch Loss: 0.0025095923338085413\n",
      "Epoch 2280, Loss: 0.004145629703998566, Final Batch Loss: 0.003119326662272215\n",
      "Epoch 2281, Loss: 0.0001252234023922938, Final Batch Loss: 0.00011490533506730571\n",
      "Epoch 2282, Loss: 0.00039815752097638324, Final Batch Loss: 0.00027689640410244465\n",
      "Epoch 2283, Loss: 0.0005646541685564443, Final Batch Loss: 0.00018757655925583094\n",
      "Epoch 2284, Loss: 0.00044432771392166615, Final Batch Loss: 0.0001507192209828645\n",
      "Epoch 2285, Loss: 0.0021624304936267436, Final Batch Loss: 0.0006554420688189566\n",
      "Epoch 2286, Loss: 0.0014473561604972929, Final Batch Loss: 0.00030693839653395116\n",
      "Epoch 2287, Loss: 0.0007672233623452485, Final Batch Loss: 0.00035239392309449613\n",
      "Epoch 2288, Loss: 0.001088112378056394, Final Batch Loss: 0.0010351774981245399\n",
      "Epoch 2289, Loss: 0.00010620730972732417, Final Batch Loss: 6.484499317593873e-05\n",
      "Epoch 2290, Loss: 0.0005510991322807968, Final Batch Loss: 0.0003543274069670588\n",
      "Epoch 2291, Loss: 0.00011845064364024438, Final Batch Loss: 3.522479164530523e-05\n",
      "Epoch 2292, Loss: 0.000322343606967479, Final Batch Loss: 0.0002863695553969592\n",
      "Epoch 2293, Loss: 0.0008506132144248113, Final Batch Loss: 0.000699080410413444\n",
      "Epoch 2294, Loss: 0.00010893194848904386, Final Batch Loss: 5.882242840016261e-05\n",
      "Epoch 2295, Loss: 0.0036224266659701243, Final Batch Loss: 0.00013173210027161986\n",
      "Epoch 2296, Loss: 0.00020422036686795764, Final Batch Loss: 2.240988760604523e-05\n",
      "Epoch 2297, Loss: 0.00055011328549881, Final Batch Loss: 0.0005260852631181479\n",
      "Epoch 2298, Loss: 0.0002539825072744861, Final Batch Loss: 0.00016093986050691456\n",
      "Epoch 2299, Loss: 0.0026296121141058393, Final Batch Loss: 0.0025802927557379007\n",
      "Epoch 2300, Loss: 0.00031773134105606005, Final Batch Loss: 9.479145955992863e-05\n",
      "Epoch 2301, Loss: 0.0001203598512802273, Final Batch Loss: 3.15946017508395e-05\n",
      "Epoch 2302, Loss: 0.00038391513226088136, Final Batch Loss: 0.00034799062996171415\n",
      "Epoch 2303, Loss: 0.002399622031589388, Final Batch Loss: 0.0023760050535202026\n",
      "Epoch 2304, Loss: 0.0037568587868008763, Final Batch Loss: 0.0034858130384236574\n",
      "Epoch 2305, Loss: 0.0032345566869480535, Final Batch Loss: 0.003112953156232834\n",
      "Epoch 2306, Loss: 4.598467239702586e-05, Final Batch Loss: 2.2304717276711017e-05\n",
      "Epoch 2307, Loss: 0.00016657162632327527, Final Batch Loss: 3.5740944440476596e-05\n",
      "Epoch 2308, Loss: 0.0019377724165678956, Final Batch Loss: 5.9378719015512615e-05\n",
      "Epoch 2309, Loss: 0.0019290063028165605, Final Batch Loss: 0.0018720708321779966\n",
      "Epoch 2310, Loss: 0.00017982111603487283, Final Batch Loss: 0.00013694226799998432\n",
      "Epoch 2311, Loss: 0.0015414551307912916, Final Batch Loss: 0.0003347802849020809\n",
      "Epoch 2312, Loss: 0.00011421497492847266, Final Batch Loss: 1.3740737813350279e-05\n",
      "Epoch 2313, Loss: 0.004400294899824075, Final Batch Loss: 0.004285621456801891\n",
      "Epoch 2314, Loss: 0.0008425970154348761, Final Batch Loss: 0.0007882013451308012\n",
      "Epoch 2315, Loss: 0.0003176195823471062, Final Batch Loss: 0.00025014017592184246\n",
      "Epoch 2316, Loss: 0.0003910223604179919, Final Batch Loss: 0.00031664653215557337\n",
      "Epoch 2317, Loss: 0.022182012093253434, Final Batch Loss: 0.0002720394404605031\n",
      "Epoch 2318, Loss: 0.003992538797319867, Final Batch Loss: 0.00019206306023988873\n",
      "Epoch 2319, Loss: 0.0005287071981001645, Final Batch Loss: 0.00021166700753383338\n",
      "Epoch 2320, Loss: 0.00034684112324612215, Final Batch Loss: 3.5776996810454875e-05\n",
      "Epoch 2321, Loss: 0.00015213659571600147, Final Batch Loss: 3.2745538192102686e-05\n",
      "Epoch 2322, Loss: 0.00017326937813777477, Final Batch Loss: 0.0001089078577933833\n",
      "Epoch 2323, Loss: 0.00011067937884945422, Final Batch Loss: 3.3250253181904554e-05\n",
      "Epoch 2324, Loss: 0.007485709706088528, Final Batch Loss: 0.0002628775255288929\n",
      "Epoch 2325, Loss: 0.0009159701730823144, Final Batch Loss: 1.8726845155470073e-05\n",
      "Epoch 2326, Loss: 0.001630322338314727, Final Batch Loss: 0.0012537052389234304\n",
      "Epoch 2327, Loss: 0.0006653851014561951, Final Batch Loss: 0.00026831720606423914\n",
      "Epoch 2328, Loss: 0.001305828132899478, Final Batch Loss: 0.0010850009275600314\n",
      "Epoch 2329, Loss: 0.003003449339303188, Final Batch Loss: 0.0001218136603711173\n",
      "Epoch 2330, Loss: 0.00122690515127033, Final Batch Loss: 0.0005048966850154102\n",
      "Epoch 2331, Loss: 0.0010911351419053972, Final Batch Loss: 0.0005687146331183612\n",
      "Epoch 2332, Loss: 0.0011407773563405499, Final Batch Loss: 0.00012771178444381803\n",
      "Epoch 2333, Loss: 0.0002745722777035553, Final Batch Loss: 2.5849283701973036e-05\n",
      "Epoch 2334, Loss: 0.00011601724327192642, Final Batch Loss: 6.385939195752144e-05\n",
      "Epoch 2335, Loss: 0.0004824347997782752, Final Batch Loss: 0.00013224421127233654\n",
      "Epoch 2336, Loss: 0.00023877929197624326, Final Batch Loss: 0.00013486815441865474\n",
      "Epoch 2337, Loss: 0.0006579331820830703, Final Batch Loss: 0.00027531178784556687\n",
      "Epoch 2338, Loss: 0.0042232289124513045, Final Batch Loss: 0.0039816428907215595\n",
      "Epoch 2339, Loss: 0.00045120409049559385, Final Batch Loss: 0.00015534779231529683\n",
      "Epoch 2340, Loss: 0.0003393004008103162, Final Batch Loss: 0.00019399069424252957\n",
      "Epoch 2341, Loss: 0.0010723728773882613, Final Batch Loss: 0.0009041577577590942\n",
      "Epoch 2342, Loss: 0.0007704336785536725, Final Batch Loss: 5.505844092112966e-05\n",
      "Epoch 2343, Loss: 0.00023278673324966803, Final Batch Loss: 8.155669638654217e-05\n",
      "Epoch 2344, Loss: 0.00029119604732841253, Final Batch Loss: 0.00012146816879976541\n",
      "Epoch 2345, Loss: 0.00034320863778702915, Final Batch Loss: 0.00010410885442979634\n",
      "Epoch 2346, Loss: 0.0004384696949273348, Final Batch Loss: 0.0002826835843734443\n",
      "Epoch 2347, Loss: 0.00033054721825465094, Final Batch Loss: 0.00031189643777906895\n",
      "Epoch 2348, Loss: 0.0005599547730525956, Final Batch Loss: 0.00043181460932828486\n",
      "Epoch 2349, Loss: 9.333616799267475e-05, Final Batch Loss: 1.8099746739608236e-05\n",
      "Epoch 2350, Loss: 0.001879604777059285, Final Batch Loss: 3.25302935380023e-05\n",
      "Epoch 2351, Loss: 0.0015061867597978562, Final Batch Loss: 0.00038987278821878135\n",
      "Epoch 2352, Loss: 0.0011262139159953222, Final Batch Loss: 0.0001531602320028469\n",
      "Epoch 2353, Loss: 0.0016052312857937068, Final Batch Loss: 0.0014998794067651033\n",
      "Epoch 2354, Loss: 0.00013815175043419003, Final Batch Loss: 5.4801923397462815e-05\n",
      "Epoch 2355, Loss: 0.0013094482710584998, Final Batch Loss: 0.000793564657215029\n",
      "Epoch 2356, Loss: 0.0018443481822032481, Final Batch Loss: 0.001755043282173574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2357, Loss: 0.0005912478154641576, Final Batch Loss: 8.082943531917408e-05\n",
      "Epoch 2358, Loss: 0.0019648759334813803, Final Batch Loss: 0.00038600488915108144\n",
      "Epoch 2359, Loss: 0.000851696779136546, Final Batch Loss: 0.0007161563262343407\n",
      "Epoch 2360, Loss: 0.0002627340109029319, Final Batch Loss: 3.0249426345108077e-05\n",
      "Epoch 2361, Loss: 0.0026311417459510267, Final Batch Loss: 0.00013340049190446734\n",
      "Epoch 2362, Loss: 0.001896865273010917, Final Batch Loss: 2.9602277209050953e-05\n",
      "Epoch 2363, Loss: 5.104327874505543e-05, Final Batch Loss: 4.392900882521644e-05\n",
      "Epoch 2364, Loss: 9.616594797989819e-05, Final Batch Loss: 1.412774327036459e-05\n",
      "Epoch 2365, Loss: 0.0004396471122163348, Final Batch Loss: 0.0003543018829077482\n",
      "Epoch 2366, Loss: 0.000278582469036337, Final Batch Loss: 0.00016096551553346217\n",
      "Epoch 2367, Loss: 0.00019455157598713413, Final Batch Loss: 9.918676369125023e-05\n",
      "Epoch 2368, Loss: 0.0004268842749297619, Final Batch Loss: 0.00034581340150907636\n",
      "Epoch 2369, Loss: 0.00015712023468950065, Final Batch Loss: 1.0741020560089964e-05\n",
      "Epoch 2370, Loss: 6.489762563433032e-05, Final Batch Loss: 3.629123602877371e-05\n",
      "Epoch 2371, Loss: 0.00012619293556781486, Final Batch Loss: 4.997846554033458e-05\n",
      "Epoch 2372, Loss: 0.0005492929994943552, Final Batch Loss: 6.434763054130599e-05\n",
      "Epoch 2373, Loss: 0.0008690430913702585, Final Batch Loss: 0.00011625883780652657\n",
      "Epoch 2374, Loss: 0.0003727730654645711, Final Batch Loss: 0.00021081443992443383\n",
      "Epoch 2375, Loss: 0.00011012826507794671, Final Batch Loss: 4.160285971011035e-05\n",
      "Epoch 2376, Loss: 0.000499045450851554, Final Batch Loss: 0.000468066573375836\n",
      "Epoch 2377, Loss: 0.002231756014225539, Final Batch Loss: 3.2807256502564996e-05\n",
      "Epoch 2378, Loss: 0.000719977542757988, Final Batch Loss: 0.00032041396480053663\n",
      "Epoch 2379, Loss: 0.0003123477945337072, Final Batch Loss: 0.00018350542814005166\n",
      "Epoch 2380, Loss: 0.00022589687432628125, Final Batch Loss: 0.00015433525550179183\n",
      "Epoch 2381, Loss: 0.0003825232415692881, Final Batch Loss: 0.00018577439186628908\n",
      "Epoch 2382, Loss: 6.296057199506322e-05, Final Batch Loss: 4.9342830607201904e-05\n",
      "Epoch 2383, Loss: 0.0005665015032718657, Final Batch Loss: 1.4002185707795434e-05\n",
      "Epoch 2384, Loss: 0.0002633546573633794, Final Batch Loss: 2.8360071155475453e-05\n",
      "Epoch 2385, Loss: 0.002568522293586284, Final Batch Loss: 0.0023553872015327215\n",
      "Epoch 2386, Loss: 0.0008160132420016453, Final Batch Loss: 0.0007903353543952107\n",
      "Epoch 2387, Loss: 0.000194216008821968, Final Batch Loss: 7.761565211694688e-05\n",
      "Epoch 2388, Loss: 0.0014495591094600968, Final Batch Loss: 0.0014144685119390488\n",
      "Epoch 2389, Loss: 0.0024573321861680597, Final Batch Loss: 0.00013337176642380655\n",
      "Epoch 2390, Loss: 0.007390833168756217, Final Batch Loss: 0.0007771870004944503\n",
      "Epoch 2391, Loss: 0.00047002421342767775, Final Batch Loss: 4.95666463393718e-05\n",
      "Epoch 2392, Loss: 0.0014248888764996082, Final Batch Loss: 0.00039628767990507185\n",
      "Epoch 2393, Loss: 0.0012951831158716232, Final Batch Loss: 0.0011696420842781663\n",
      "Epoch 2394, Loss: 0.0005673902778653428, Final Batch Loss: 0.00037631718441843987\n",
      "Epoch 2395, Loss: 0.0024243782172561623, Final Batch Loss: 2.7825160941574723e-05\n",
      "Epoch 2396, Loss: 0.0019633897754829377, Final Batch Loss: 0.0014799593482166529\n",
      "Epoch 2397, Loss: 0.0029709406589972787, Final Batch Loss: 2.6767134841065854e-05\n",
      "Epoch 2398, Loss: 0.001440005642507458, Final Batch Loss: 3.607795588322915e-05\n",
      "Epoch 2399, Loss: 0.00043504003406269476, Final Batch Loss: 0.00011609304783632979\n",
      "Epoch 2400, Loss: 0.00013702527940040454, Final Batch Loss: 5.0759736041072756e-05\n",
      "Epoch 2401, Loss: 0.0006231058328012296, Final Batch Loss: 6.367725745803909e-06\n",
      "Epoch 2402, Loss: 0.00021149289023014717, Final Batch Loss: 5.8276313211536035e-05\n",
      "Epoch 2403, Loss: 0.0004908646769763436, Final Batch Loss: 3.144042784697376e-05\n",
      "Epoch 2404, Loss: 6.491464046121109e-05, Final Batch Loss: 4.5729775592917576e-05\n",
      "Epoch 2405, Loss: 0.00026813930890057236, Final Batch Loss: 0.00017578760161995888\n",
      "Epoch 2406, Loss: 0.0009001046710181981, Final Batch Loss: 0.0003483465698082\n",
      "Epoch 2407, Loss: 0.0031268097445718013, Final Batch Loss: 9.565465006744489e-05\n",
      "Epoch 2408, Loss: 0.0002811704180203378, Final Batch Loss: 2.114317612722516e-05\n",
      "Epoch 2409, Loss: 0.00039524344174424186, Final Batch Loss: 0.0003139115287922323\n",
      "Epoch 2410, Loss: 6.914424182014045e-05, Final Batch Loss: 1.7722794609653647e-06\n",
      "Epoch 2411, Loss: 0.00011294282012386248, Final Batch Loss: 3.846560139209032e-05\n",
      "Epoch 2412, Loss: 0.00018914868633146398, Final Batch Loss: 2.0078467059647664e-05\n",
      "Epoch 2413, Loss: 0.00015623274703102652, Final Batch Loss: 1.9457651433185674e-05\n",
      "Epoch 2414, Loss: 0.010712587747548241, Final Batch Loss: 0.00010509650019230321\n",
      "Epoch 2415, Loss: 0.0003811400674749166, Final Batch Loss: 0.0003424372698646039\n",
      "Epoch 2416, Loss: 7.871044545026962e-05, Final Batch Loss: 2.613512879179325e-05\n",
      "Epoch 2417, Loss: 0.009785865260710125, Final Batch Loss: 2.7509233404998668e-05\n",
      "Epoch 2418, Loss: 0.0007478053448721766, Final Batch Loss: 0.00022537796758115292\n",
      "Epoch 2419, Loss: 0.0010216335103905294, Final Batch Loss: 5.285320003167726e-05\n",
      "Epoch 2420, Loss: 0.00018017155889538117, Final Batch Loss: 1.5798494132468477e-05\n",
      "Epoch 2421, Loss: 6.432436384784523e-05, Final Batch Loss: 3.461196320131421e-05\n",
      "Epoch 2422, Loss: 9.716328167996835e-05, Final Batch Loss: 7.125647243810818e-05\n",
      "Epoch 2423, Loss: 0.005025247854064219, Final Batch Loss: 0.004848813638091087\n",
      "Epoch 2424, Loss: 0.0005802394807687961, Final Batch Loss: 0.0004907583352178335\n",
      "Epoch 2425, Loss: 0.0003539352837833576, Final Batch Loss: 0.0003122782218270004\n",
      "Epoch 2426, Loss: 0.0008819127542665228, Final Batch Loss: 0.0007915651076473296\n",
      "Epoch 2427, Loss: 0.0003095142401434714, Final Batch Loss: 9.508143193670548e-06\n",
      "Epoch 2428, Loss: 0.00021416190429590642, Final Batch Loss: 1.778853766154498e-05\n",
      "Epoch 2429, Loss: 0.0012216273389640264, Final Batch Loss: 0.0011046385625377297\n",
      "Epoch 2430, Loss: 0.00032901246595429257, Final Batch Loss: 2.7930196665693074e-05\n",
      "Epoch 2431, Loss: 0.00216764651122503, Final Batch Loss: 0.0002582469896879047\n",
      "Epoch 2432, Loss: 0.0008932506607379764, Final Batch Loss: 0.0007979237707331777\n",
      "Epoch 2433, Loss: 0.0005508001413545571, Final Batch Loss: 6.694881449220702e-05\n",
      "Epoch 2434, Loss: 0.0010387447255197912, Final Batch Loss: 0.0005943345604464412\n",
      "Epoch 2435, Loss: 0.0013597086654044688, Final Batch Loss: 0.001091039041057229\n",
      "Epoch 2436, Loss: 0.00380444747133879, Final Batch Loss: 0.0037878379225730896\n",
      "Epoch 2437, Loss: 0.0006974896878091386, Final Batch Loss: 2.8818065402447246e-05\n",
      "Epoch 2438, Loss: 0.0003059755945287179, Final Batch Loss: 3.670852674986236e-05\n",
      "Epoch 2439, Loss: 0.00041304332262370735, Final Batch Loss: 7.851004193071276e-05\n",
      "Epoch 2440, Loss: 0.012131789939303417, Final Batch Loss: 0.012085547670722008\n",
      "Epoch 2441, Loss: 0.00041646849967946764, Final Batch Loss: 2.7730207875720225e-05\n",
      "Epoch 2442, Loss: 5.9552134644036414e-05, Final Batch Loss: 7.034225291135954e-06\n",
      "Epoch 2443, Loss: 0.00024702253722352907, Final Batch Loss: 0.0001616087683942169\n",
      "Epoch 2444, Loss: 0.014954404847230762, Final Batch Loss: 0.00020629999926313758\n",
      "Epoch 2445, Loss: 0.00026601213903632015, Final Batch Loss: 0.00018800434190779924\n",
      "Epoch 2446, Loss: 0.000201187238417333, Final Batch Loss: 2.34769941016566e-05\n",
      "Epoch 2447, Loss: 0.00010355770791647956, Final Batch Loss: 3.292762266937643e-05\n",
      "Epoch 2448, Loss: 0.00043248671863693744, Final Batch Loss: 8.05588933872059e-05\n",
      "Epoch 2449, Loss: 0.0004058090098624234, Final Batch Loss: 0.0003908697108272463\n",
      "Epoch 2450, Loss: 0.0003386532698641531, Final Batch Loss: 9.254499309463426e-05\n",
      "Epoch 2451, Loss: 0.000270994940365199, Final Batch Loss: 0.00018861501303035766\n",
      "Epoch 2452, Loss: 0.0014533530847984366, Final Batch Loss: 9.124888310907409e-05\n",
      "Epoch 2453, Loss: 0.002413785841781646, Final Batch Loss: 0.002149781910702586\n",
      "Epoch 2454, Loss: 0.00013904600928071886, Final Batch Loss: 7.688396726734936e-05\n",
      "Epoch 2455, Loss: 0.0005060754338046536, Final Batch Loss: 0.00028429669328033924\n",
      "Epoch 2456, Loss: 0.006457821920776041, Final Batch Loss: 5.295266237226315e-05\n",
      "Epoch 2457, Loss: 0.005326668455381878, Final Batch Loss: 0.005144163500517607\n",
      "Epoch 2458, Loss: 0.003252269350923598, Final Batch Loss: 9.63316997513175e-05\n",
      "Epoch 2459, Loss: 0.0059812108520418406, Final Batch Loss: 0.005609286483377218\n",
      "Epoch 2460, Loss: 0.00020454559125937521, Final Batch Loss: 8.166210318449885e-05\n",
      "Epoch 2461, Loss: 0.008825855238683289, Final Batch Loss: 0.008790228515863419\n",
      "Epoch 2462, Loss: 0.00010723343802965246, Final Batch Loss: 8.427534339716658e-05\n",
      "Epoch 2463, Loss: 0.0010800374147947878, Final Batch Loss: 0.0006646924884989858\n",
      "Epoch 2464, Loss: 0.000670573819661513, Final Batch Loss: 0.0005573591333813965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2465, Loss: 0.0017883701220853254, Final Batch Loss: 3.5473654861561954e-05\n",
      "Epoch 2466, Loss: 0.0001495804317528382, Final Batch Loss: 5.5834752856753767e-05\n",
      "Epoch 2467, Loss: 0.0005862882826477289, Final Batch Loss: 0.00012928774231113493\n",
      "Epoch 2468, Loss: 0.00042466963350307196, Final Batch Loss: 0.00015050657384563237\n",
      "Epoch 2469, Loss: 0.00036652490962296724, Final Batch Loss: 0.00019403178885113448\n",
      "Epoch 2470, Loss: 0.00019477667228784412, Final Batch Loss: 0.00010105291585205123\n",
      "Epoch 2471, Loss: 0.0007257839606609195, Final Batch Loss: 0.00044665674795396626\n",
      "Epoch 2472, Loss: 0.0007209237810457125, Final Batch Loss: 0.0005851652240380645\n",
      "Epoch 2473, Loss: 0.00011372586777724791, Final Batch Loss: 2.781085822789464e-05\n",
      "Epoch 2474, Loss: 0.0004057440091855824, Final Batch Loss: 0.00022358378919307142\n",
      "Epoch 2475, Loss: 0.0005385108015616424, Final Batch Loss: 0.0004483512311708182\n",
      "Epoch 2476, Loss: 0.0020175183308310807, Final Batch Loss: 0.0018383661517873406\n",
      "Epoch 2477, Loss: 0.0002748427359620109, Final Batch Loss: 9.946928184945136e-05\n",
      "Epoch 2478, Loss: 0.00013145679258741438, Final Batch Loss: 0.00011213309335289523\n",
      "Epoch 2479, Loss: 0.0002609626535559073, Final Batch Loss: 0.00010960279905702919\n",
      "Epoch 2480, Loss: 0.0006022335583111271, Final Batch Loss: 0.0005124422023072839\n",
      "Epoch 2481, Loss: 0.000409324886277318, Final Batch Loss: 6.783052231185138e-05\n",
      "Epoch 2482, Loss: 0.00040881541644921526, Final Batch Loss: 4.597540100803599e-05\n",
      "Epoch 2483, Loss: 0.0006893389218021184, Final Batch Loss: 0.0005873700138181448\n",
      "Epoch 2484, Loss: 0.0010336175037082285, Final Batch Loss: 0.0007422807393595576\n",
      "Epoch 2485, Loss: 8.046967559494078e-05, Final Batch Loss: 4.329914372647181e-05\n",
      "Epoch 2486, Loss: 0.00322575491736643, Final Batch Loss: 8.547861943952739e-05\n",
      "Epoch 2487, Loss: 0.000780719201429747, Final Batch Loss: 7.018730684649199e-05\n",
      "Epoch 2488, Loss: 0.0005951570929028094, Final Batch Loss: 0.0003148542018607259\n",
      "Epoch 2489, Loss: 0.0006608062249142677, Final Batch Loss: 0.0003063952608499676\n",
      "Epoch 2490, Loss: 0.00015666147555748466, Final Batch Loss: 1.9795183106907643e-05\n",
      "Epoch 2491, Loss: 0.0030472437501884997, Final Batch Loss: 4.258198896422982e-05\n",
      "Epoch 2492, Loss: 0.00035708302129933145, Final Batch Loss: 0.0003325411817058921\n",
      "Epoch 2493, Loss: 7.123924478946719e-05, Final Batch Loss: 4.4534528569784015e-05\n",
      "Epoch 2494, Loss: 0.0014957213425077498, Final Batch Loss: 0.0005342523800209165\n",
      "Epoch 2495, Loss: 0.00039285721140913665, Final Batch Loss: 0.00016664825670886785\n",
      "Epoch 2496, Loss: 8.469828026136383e-05, Final Batch Loss: 4.7229670599335805e-05\n",
      "Epoch 2497, Loss: 0.00040758577233646065, Final Batch Loss: 0.00011128631012979895\n",
      "Epoch 2498, Loss: 0.007315137656405568, Final Batch Loss: 0.002226721728220582\n",
      "Epoch 2499, Loss: 0.00010578832370811142, Final Batch Loss: 6.808707257732749e-05\n",
      "Epoch 2500, Loss: 0.0006241423543542624, Final Batch Loss: 0.000269108364591375\n",
      "Epoch 2501, Loss: 0.001884110206447076, Final Batch Loss: 0.0018520165467634797\n",
      "Epoch 2502, Loss: 0.00014914452185621485, Final Batch Loss: 7.40546893212013e-05\n",
      "Epoch 2503, Loss: 0.0032018874771893024, Final Batch Loss: 0.00038349139504134655\n",
      "Epoch 2504, Loss: 0.0007742969610262662, Final Batch Loss: 0.0005114232772029936\n",
      "Epoch 2505, Loss: 0.006526361219584942, Final Batch Loss: 0.005028805695474148\n",
      "Epoch 2506, Loss: 0.0002101382560795173, Final Batch Loss: 0.00011505842121550813\n",
      "Epoch 2507, Loss: 8.599774810136296e-05, Final Batch Loss: 1.7431371816201136e-05\n",
      "Epoch 2508, Loss: 0.00030856420926284045, Final Batch Loss: 0.0001698364212643355\n",
      "Epoch 2509, Loss: 0.0001297089456784306, Final Batch Loss: 0.00010407170339021832\n",
      "Epoch 2510, Loss: 0.00024773434415692464, Final Batch Loss: 3.140625631203875e-05\n",
      "Epoch 2511, Loss: 0.00024045677491812967, Final Batch Loss: 1.902968142530881e-05\n",
      "Epoch 2512, Loss: 0.00020575821690727025, Final Batch Loss: 0.00014315989392343909\n",
      "Epoch 2513, Loss: 0.0003985301445936784, Final Batch Loss: 0.0003678996581584215\n",
      "Epoch 2514, Loss: 0.0018944289768114686, Final Batch Loss: 0.0016196364304050803\n",
      "Epoch 2515, Loss: 0.00023293111371458508, Final Batch Loss: 1.6520240023965016e-05\n",
      "Epoch 2516, Loss: 5.2018177939316956e-05, Final Batch Loss: 6.4624432525306474e-06\n",
      "Epoch 2517, Loss: 0.0013688441858903388, Final Batch Loss: 1.5069616893015336e-05\n",
      "Epoch 2518, Loss: 0.0001532188125565881, Final Batch Loss: 0.00013780719018541276\n",
      "Epoch 2519, Loss: 0.00025105905115196947, Final Batch Loss: 0.00022841672762297094\n",
      "Epoch 2520, Loss: 0.0006119747704360634, Final Batch Loss: 0.0001310523657593876\n",
      "Epoch 2521, Loss: 0.00024853394279489294, Final Batch Loss: 0.00011994264059467241\n",
      "Epoch 2522, Loss: 0.00019840595268760808, Final Batch Loss: 3.066246063099243e-05\n",
      "Epoch 2523, Loss: 0.00015449440979864448, Final Batch Loss: 0.00014386593829840422\n",
      "Epoch 2524, Loss: 0.0001392690764987492, Final Batch Loss: 1.0089964234794024e-05\n",
      "Epoch 2525, Loss: 9.183316069538705e-05, Final Batch Loss: 8.40298380353488e-05\n",
      "Epoch 2526, Loss: 0.00012110037278034724, Final Batch Loss: 3.186805042787455e-05\n",
      "Epoch 2527, Loss: 0.0003819358244072646, Final Batch Loss: 0.00022043782519176602\n",
      "Epoch 2528, Loss: 0.00026038334908662364, Final Batch Loss: 0.00019488317775540054\n",
      "Epoch 2529, Loss: 0.00016688612413418014, Final Batch Loss: 1.5502389942412265e-05\n",
      "Epoch 2530, Loss: 0.0003841719990305137, Final Batch Loss: 0.0003330702893435955\n",
      "Epoch 2531, Loss: 0.0010264656448271126, Final Batch Loss: 0.0003351748164277524\n",
      "Epoch 2532, Loss: 0.0032646650579408742, Final Batch Loss: 0.003227747045457363\n",
      "Epoch 2533, Loss: 0.0009263770480174571, Final Batch Loss: 0.0006760790129192173\n",
      "Epoch 2534, Loss: 4.30921991210198e-05, Final Batch Loss: 5.243238774710335e-06\n",
      "Epoch 2535, Loss: 0.0005525250744540244, Final Batch Loss: 0.0005034872447140515\n",
      "Epoch 2536, Loss: 0.00030070541106397286, Final Batch Loss: 0.0001803337800083682\n",
      "Epoch 2537, Loss: 8.848058496369049e-05, Final Batch Loss: 2.1075480617582798e-05\n",
      "Epoch 2538, Loss: 0.0025269553807447664, Final Batch Loss: 0.0024507229682058096\n",
      "Epoch 2539, Loss: 0.00017103022764786147, Final Batch Loss: 0.00015997988521121442\n",
      "Epoch 2540, Loss: 0.0006311570323305205, Final Batch Loss: 0.00012448745837900788\n",
      "Epoch 2541, Loss: 0.0001396572115481831, Final Batch Loss: 1.7729420505929738e-05\n",
      "Epoch 2542, Loss: 0.0005698571621906012, Final Batch Loss: 0.00022612346219830215\n",
      "Epoch 2543, Loss: 0.0008847894059726968, Final Batch Loss: 0.000704514910466969\n",
      "Epoch 2544, Loss: 0.00023388616682495922, Final Batch Loss: 7.74411455495283e-05\n",
      "Epoch 2545, Loss: 0.0003105367868556641, Final Batch Loss: 0.00028746796306222677\n",
      "Epoch 2546, Loss: 0.002214431602624245, Final Batch Loss: 0.0021759553346782923\n",
      "Epoch 2547, Loss: 0.0014328493707580492, Final Batch Loss: 0.001243141246959567\n",
      "Epoch 2548, Loss: 3.8555192986677866e-05, Final Batch Loss: 5.304819751472678e-06\n",
      "Epoch 2549, Loss: 0.0002269912074552849, Final Batch Loss: 0.0001915795000968501\n",
      "Epoch 2550, Loss: 0.00013021327322348952, Final Batch Loss: 4.1637518734205514e-05\n",
      "Epoch 2551, Loss: 0.00011671667652990436, Final Batch Loss: 0.00010453465802129358\n",
      "Epoch 2552, Loss: 5.1515313316485845e-05, Final Batch Loss: 1.545401210023556e-05\n",
      "Epoch 2553, Loss: 0.0009613134170649573, Final Batch Loss: 0.000791262777056545\n",
      "Epoch 2554, Loss: 0.00011411501850489003, Final Batch Loss: 0.00011183727474417537\n",
      "Epoch 2555, Loss: 0.0009392175052198581, Final Batch Loss: 0.0008808636339381337\n",
      "Epoch 2556, Loss: 0.0005170750391698675, Final Batch Loss: 2.7488831619848497e-05\n",
      "Epoch 2557, Loss: 0.0004437410279933829, Final Batch Loss: 3.336136069265194e-05\n",
      "Epoch 2558, Loss: 0.00019687860549311154, Final Batch Loss: 0.00015804942813701928\n",
      "Epoch 2559, Loss: 0.0002502425923012197, Final Batch Loss: 6.185084930621088e-05\n",
      "Epoch 2560, Loss: 0.0015591083647450432, Final Batch Loss: 9.505053458269686e-05\n",
      "Epoch 2561, Loss: 0.003061015704588499, Final Batch Loss: 3.166947135468945e-05\n",
      "Epoch 2562, Loss: 0.009696675348095596, Final Batch Loss: 0.008626737631857395\n",
      "Epoch 2563, Loss: 0.0028242370826774277, Final Batch Loss: 4.3093903514090925e-05\n",
      "Epoch 2564, Loss: 8.929397336032707e-05, Final Batch Loss: 6.587224925169721e-05\n",
      "Epoch 2565, Loss: 0.0024442104040645063, Final Batch Loss: 0.001522641978226602\n",
      "Epoch 2566, Loss: 6.942446634639055e-05, Final Batch Loss: 2.9396098398137838e-05\n",
      "Epoch 2567, Loss: 3.4043509913317394e-05, Final Batch Loss: 2.2732123397872783e-05\n",
      "Epoch 2568, Loss: 0.0015793588245287538, Final Batch Loss: 0.0009621506906114519\n",
      "Epoch 2569, Loss: 0.002284517860971391, Final Batch Loss: 0.0017880641389638186\n",
      "Epoch 2570, Loss: 4.003242611361202e-05, Final Batch Loss: 2.66549159277929e-05\n",
      "Epoch 2571, Loss: 0.0010098546408698894, Final Batch Loss: 0.0009568287641741335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2572, Loss: 0.005960539332590997, Final Batch Loss: 0.005680297967046499\n",
      "Epoch 2573, Loss: 0.0010585696145426482, Final Batch Loss: 0.0006631778087466955\n",
      "Epoch 2574, Loss: 0.014320714224595577, Final Batch Loss: 0.013849771581590176\n",
      "Epoch 2575, Loss: 0.0018437434046063572, Final Batch Loss: 0.0016312008956447244\n",
      "Epoch 2576, Loss: 4.06193544222333e-05, Final Batch Loss: 4.009482381661655e-06\n",
      "Epoch 2577, Loss: 0.0005683407071046531, Final Batch Loss: 0.00017287064110860229\n",
      "Epoch 2578, Loss: 0.001360216807370307, Final Batch Loss: 2.2919663024367765e-05\n",
      "Epoch 2579, Loss: 0.0003322905540699139, Final Batch Loss: 0.0002257692103739828\n",
      "Epoch 2580, Loss: 0.0022205449640750885, Final Batch Loss: 0.0010318018030375242\n",
      "Epoch 2581, Loss: 0.0010688818938433542, Final Batch Loss: 0.0010611588368192315\n",
      "Epoch 2582, Loss: 7.627257218700834e-05, Final Batch Loss: 1.9458919268799946e-05\n",
      "Epoch 2583, Loss: 0.0005321245989762247, Final Batch Loss: 0.00035760027822107077\n",
      "Epoch 2584, Loss: 0.005073906417237595, Final Batch Loss: 0.0046274373307824135\n",
      "Epoch 2585, Loss: 0.0012356404913589358, Final Batch Loss: 0.0005442603724077344\n",
      "Epoch 2586, Loss: 0.00017718157323542982, Final Batch Loss: 5.009034066461027e-05\n",
      "Epoch 2587, Loss: 0.001406358613166958, Final Batch Loss: 0.0012695033801719546\n",
      "Epoch 2588, Loss: 0.00012165743464720435, Final Batch Loss: 6.762842531315982e-05\n",
      "Epoch 2589, Loss: 0.0007672408319194801, Final Batch Loss: 0.0007155722705647349\n",
      "Epoch 2590, Loss: 4.6946797738200985e-05, Final Batch Loss: 3.0405262805288658e-05\n",
      "Epoch 2591, Loss: 0.0011140834540128708, Final Batch Loss: 0.00036771659506484866\n",
      "Epoch 2592, Loss: 0.00021485486649908125, Final Batch Loss: 0.000160192561452277\n",
      "Epoch 2593, Loss: 2.7708492780220695e-05, Final Batch Loss: 1.6840438547660597e-05\n",
      "Epoch 2594, Loss: 0.001007860653771786, Final Batch Loss: 0.0009715657797642052\n",
      "Epoch 2595, Loss: 0.00018606276717036963, Final Batch Loss: 0.00012739788508042693\n",
      "Epoch 2596, Loss: 0.0016444114007754251, Final Batch Loss: 0.00017265618953388184\n",
      "Epoch 2597, Loss: 0.0012446094333427027, Final Batch Loss: 0.0010424611391499639\n",
      "Epoch 2598, Loss: 0.0015931952802930027, Final Batch Loss: 0.00013180056703276932\n",
      "Epoch 2599, Loss: 0.0020907665602862835, Final Batch Loss: 0.0016807829961180687\n",
      "Epoch 2600, Loss: 0.0003768240785575472, Final Batch Loss: 7.46928490116261e-05\n",
      "Epoch 2601, Loss: 0.00036138162249699235, Final Batch Loss: 0.00010445475345477462\n",
      "Epoch 2602, Loss: 0.0021534140687435865, Final Batch Loss: 0.0004037983017042279\n",
      "Epoch 2603, Loss: 0.000163426659128163, Final Batch Loss: 6.318998202914372e-05\n",
      "Epoch 2604, Loss: 0.00016913426952669397, Final Batch Loss: 6.112363917054608e-05\n",
      "Epoch 2605, Loss: 0.0002916742523666471, Final Batch Loss: 0.0001368462690152228\n",
      "Epoch 2606, Loss: 0.00128113484242931, Final Batch Loss: 0.00014465657295659184\n",
      "Epoch 2607, Loss: 0.0019756517140194774, Final Batch Loss: 0.00011279492173343897\n",
      "Epoch 2608, Loss: 0.00029983610147610307, Final Batch Loss: 0.00022856733994558454\n",
      "Epoch 2609, Loss: 0.001578486931975931, Final Batch Loss: 0.00030432333005592227\n",
      "Epoch 2610, Loss: 9.725822746986523e-05, Final Batch Loss: 5.739175685448572e-05\n",
      "Epoch 2611, Loss: 0.00033649852412054315, Final Batch Loss: 0.00022601285309065133\n",
      "Epoch 2612, Loss: 0.005330879823304713, Final Batch Loss: 0.00018717220518738031\n",
      "Epoch 2613, Loss: 0.0011390247236704454, Final Batch Loss: 0.0009734537452459335\n",
      "Epoch 2614, Loss: 0.00019758295820793137, Final Batch Loss: 9.382052667206153e-05\n",
      "Epoch 2615, Loss: 0.00016517724361619912, Final Batch Loss: 0.00010844022472156212\n",
      "Epoch 2616, Loss: 0.0007341687160078436, Final Batch Loss: 0.0003225310065317899\n",
      "Epoch 2617, Loss: 0.00024363582997466438, Final Batch Loss: 0.0002053712960332632\n",
      "Epoch 2618, Loss: 0.0036492882209131494, Final Batch Loss: 0.0035104751586914062\n",
      "Epoch 2619, Loss: 0.001802855924324831, Final Batch Loss: 0.0017943052807822824\n",
      "Epoch 2620, Loss: 0.0022978212182351854, Final Batch Loss: 0.002262464025989175\n",
      "Epoch 2621, Loss: 0.00040326599264517426, Final Batch Loss: 0.0002742329961620271\n",
      "Epoch 2622, Loss: 6.767262129869778e-05, Final Batch Loss: 2.5458148229517974e-05\n",
      "Epoch 2623, Loss: 0.0007351899093919201, Final Batch Loss: 0.0007149624289013445\n",
      "Epoch 2624, Loss: 0.003455192781984806, Final Batch Loss: 0.002092882990837097\n",
      "Epoch 2625, Loss: 0.0012659154181164922, Final Batch Loss: 0.0012428293703123927\n",
      "Epoch 2626, Loss: 0.00013863165349903284, Final Batch Loss: 0.00012643056106753647\n",
      "Epoch 2627, Loss: 0.0012143197964178398, Final Batch Loss: 0.001005965517833829\n",
      "Epoch 2628, Loss: 0.0004988808577763848, Final Batch Loss: 6.965829379623756e-05\n",
      "Epoch 2629, Loss: 2.658403172972612e-05, Final Batch Loss: 4.834882929571904e-06\n",
      "Epoch 2630, Loss: 0.0028748549812007695, Final Batch Loss: 5.5523618357256055e-05\n",
      "Epoch 2631, Loss: 0.0002665995343704708, Final Batch Loss: 8.87178975972347e-05\n",
      "Epoch 2632, Loss: 0.00022493428696179762, Final Batch Loss: 0.00015908422938082367\n",
      "Epoch 2633, Loss: 0.001071204933396075, Final Batch Loss: 0.0010032319696620107\n",
      "Epoch 2634, Loss: 0.00038200998460524715, Final Batch Loss: 0.00034110891283489764\n",
      "Epoch 2635, Loss: 0.00019077153046964668, Final Batch Loss: 0.00015055770927574486\n",
      "Epoch 2636, Loss: 0.00011061351688113064, Final Batch Loss: 9.929259977070615e-05\n",
      "Epoch 2637, Loss: 0.00031644251066609286, Final Batch Loss: 3.449341966188513e-05\n",
      "Epoch 2638, Loss: 0.0001865967806224944, Final Batch Loss: 0.00016909600526560098\n",
      "Epoch 2639, Loss: 0.0005584609334619017, Final Batch Loss: 0.0005499576800502837\n",
      "Epoch 2640, Loss: 0.0010408330708742142, Final Batch Loss: 0.00021505687618628144\n",
      "Epoch 2641, Loss: 0.00044399873877409846, Final Batch Loss: 0.0003912581014446914\n",
      "Epoch 2642, Loss: 0.002287276991410181, Final Batch Loss: 0.0001597969967406243\n",
      "Epoch 2643, Loss: 0.00041459542990196496, Final Batch Loss: 0.0002427001018077135\n",
      "Epoch 2644, Loss: 0.001912190520670265, Final Batch Loss: 0.001208379864692688\n",
      "Epoch 2645, Loss: 0.00028624245896935463, Final Batch Loss: 0.0001082302478607744\n",
      "Epoch 2646, Loss: 0.00036894283402943984, Final Batch Loss: 0.0002580320870038122\n",
      "Epoch 2647, Loss: 0.0002293833822477609, Final Batch Loss: 8.793544839136302e-05\n",
      "Epoch 2648, Loss: 0.009546822516313114, Final Batch Loss: 0.009536788798868656\n",
      "Epoch 2649, Loss: 7.870252375141717e-05, Final Batch Loss: 5.629470251733437e-06\n",
      "Epoch 2650, Loss: 0.0005476809346873779, Final Batch Loss: 3.742477929336019e-05\n",
      "Epoch 2651, Loss: 0.00010181517018281738, Final Batch Loss: 1.6985100046440493e-06\n",
      "Epoch 2652, Loss: 1.881960270111449e-05, Final Batch Loss: 4.62540629087016e-06\n",
      "Epoch 2653, Loss: 0.0003650439321063459, Final Batch Loss: 0.00013672519708052278\n",
      "Epoch 2654, Loss: 0.0001279945827263873, Final Batch Loss: 5.931150008109398e-05\n",
      "Epoch 2655, Loss: 0.0029230784421088174, Final Batch Loss: 0.002795012202113867\n",
      "Epoch 2656, Loss: 3.891162577929208e-05, Final Batch Loss: 2.3699176381342113e-05\n",
      "Epoch 2657, Loss: 4.9536511141923256e-05, Final Batch Loss: 3.3452310162829235e-05\n",
      "Epoch 2658, Loss: 6.622303772019222e-05, Final Batch Loss: 2.6324865757487714e-05\n",
      "Epoch 2659, Loss: 0.004020141903311014, Final Batch Loss: 0.0038092376198619604\n",
      "Epoch 2660, Loss: 0.0005317886134434957, Final Batch Loss: 4.6602031943621114e-05\n",
      "Epoch 2661, Loss: 0.0006830920419815811, Final Batch Loss: 8.194819201889914e-06\n",
      "Epoch 2662, Loss: 0.0004795755630766507, Final Batch Loss: 0.00042557468987070024\n",
      "Epoch 2663, Loss: 0.0007747250583634013, Final Batch Loss: 0.0007468319963663816\n",
      "Epoch 2664, Loss: 0.0002876682046917267, Final Batch Loss: 0.0002360425132792443\n",
      "Epoch 2665, Loss: 0.0007142091999412514, Final Batch Loss: 0.000672532944008708\n",
      "Epoch 2666, Loss: 0.00035012881562579423, Final Batch Loss: 0.0001468470727559179\n",
      "Epoch 2667, Loss: 2.9544765766331693e-05, Final Batch Loss: 5.164215963304741e-06\n",
      "Epoch 2668, Loss: 3.1258379749488086e-05, Final Batch Loss: 1.6449415852548555e-05\n",
      "Epoch 2669, Loss: 0.0004905070090899244, Final Batch Loss: 0.0003933479601982981\n",
      "Epoch 2670, Loss: 0.0004254726991348434, Final Batch Loss: 0.00041223669541068375\n",
      "Epoch 2671, Loss: 0.00011160668873344548, Final Batch Loss: 4.091205119038932e-05\n",
      "Epoch 2672, Loss: 0.00018647628530743532, Final Batch Loss: 0.0001270248176297173\n",
      "Epoch 2673, Loss: 8.370955674763536e-05, Final Batch Loss: 6.347770067804959e-06\n",
      "Epoch 2674, Loss: 3.972983904532157e-05, Final Batch Loss: 4.886267561232671e-06\n",
      "Epoch 2675, Loss: 0.0007276500546140596, Final Batch Loss: 0.0005263904458843172\n",
      "Epoch 2676, Loss: 0.005345365731045604, Final Batch Loss: 0.003941568545997143\n",
      "Epoch 2677, Loss: 0.0015178932226262987, Final Batch Loss: 0.0005487287417054176\n",
      "Epoch 2678, Loss: 4.4436834286898375e-05, Final Batch Loss: 4.217537207296118e-05\n",
      "Epoch 2679, Loss: 0.00034607644056450226, Final Batch Loss: 6.886139544803882e-06\n",
      "Epoch 2680, Loss: 9.059712101588957e-05, Final Batch Loss: 4.76840250485111e-05\n",
      "Epoch 2681, Loss: 5.637813592329621e-05, Final Batch Loss: 4.251847349223681e-05\n",
      "Epoch 2682, Loss: 0.000683027261402458, Final Batch Loss: 8.00308189354837e-05\n",
      "Epoch 2683, Loss: 0.0003664231644506799, Final Batch Loss: 0.0003504632622934878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2684, Loss: 6.973472954996396e-05, Final Batch Loss: 8.691496987012215e-06\n",
      "Epoch 2685, Loss: 0.0004885047092102468, Final Batch Loss: 0.00012216082541272044\n",
      "Epoch 2686, Loss: 9.04744533727353e-05, Final Batch Loss: 4.008719315606868e-06\n",
      "Epoch 2687, Loss: 0.0008730982372071594, Final Batch Loss: 0.00031690028845332563\n",
      "Epoch 2688, Loss: 0.0004893016266578343, Final Batch Loss: 2.577603663667105e-05\n",
      "Epoch 2689, Loss: 0.0018601168048917316, Final Batch Loss: 7.51294064684771e-05\n",
      "Epoch 2690, Loss: 0.00028891646206830046, Final Batch Loss: 2.5045605980267283e-06\n",
      "Epoch 2691, Loss: 0.0002600915831862949, Final Batch Loss: 7.110767910489812e-05\n",
      "Epoch 2692, Loss: 0.0046152626746334136, Final Batch Loss: 0.004504269454628229\n",
      "Epoch 2693, Loss: 0.00016816966672195122, Final Batch Loss: 7.3144597990904e-05\n",
      "Epoch 2694, Loss: 0.00024111001766868867, Final Batch Loss: 2.008620140259154e-05\n",
      "Epoch 2695, Loss: 0.00041296051495010033, Final Batch Loss: 3.985077637480572e-05\n",
      "Epoch 2696, Loss: 0.002721894074056763, Final Batch Loss: 8.10823476058431e-05\n",
      "Epoch 2697, Loss: 0.00014105373884376604, Final Batch Loss: 8.688266461831518e-06\n",
      "Epoch 2698, Loss: 0.0005830073496326804, Final Batch Loss: 0.00045373899047262967\n",
      "Epoch 2699, Loss: 5.9118237459188094e-05, Final Batch Loss: 5.379157664719969e-05\n",
      "Epoch 2700, Loss: 0.002149172829831514, Final Batch Loss: 7.434985036525177e-06\n",
      "Epoch 2701, Loss: 0.002204694232204929, Final Batch Loss: 0.0020016487687826157\n",
      "Epoch 2702, Loss: 0.006254858031752519, Final Batch Loss: 0.006113351788371801\n",
      "Epoch 2703, Loss: 0.00015527287177974358, Final Batch Loss: 8.070906915236264e-06\n",
      "Epoch 2704, Loss: 7.511755211453419e-05, Final Batch Loss: 2.8410488084773533e-05\n",
      "Epoch 2705, Loss: 0.002470107574481517, Final Batch Loss: 0.00030609668465331197\n",
      "Epoch 2706, Loss: 0.01572935050353408, Final Batch Loss: 0.004391455557197332\n",
      "Epoch 2707, Loss: 5.658374539052602e-05, Final Batch Loss: 1.54464923980413e-05\n",
      "Epoch 2708, Loss: 0.00018333655680180527, Final Batch Loss: 0.00013073104491923004\n",
      "Epoch 2709, Loss: 0.001929493693751283, Final Batch Loss: 4.77596913697198e-05\n",
      "Epoch 2710, Loss: 0.00012080477790732402, Final Batch Loss: 2.8181742891320027e-05\n",
      "Epoch 2711, Loss: 0.000891900017450098, Final Batch Loss: 0.0008692307164892554\n",
      "Epoch 2712, Loss: 0.0002243772687506862, Final Batch Loss: 4.449600965017453e-05\n",
      "Epoch 2713, Loss: 0.000674479717417853, Final Batch Loss: 0.0006346686277538538\n",
      "Epoch 2714, Loss: 3.78870417989674e-05, Final Batch Loss: 2.3999127733986825e-05\n",
      "Epoch 2715, Loss: 0.0007177211955422536, Final Batch Loss: 3.04159038932994e-05\n",
      "Epoch 2716, Loss: 0.00010970187850034563, Final Batch Loss: 9.798593055165838e-06\n",
      "Epoch 2717, Loss: 0.0005648574588121846, Final Batch Loss: 0.0004912581644020975\n",
      "Epoch 2718, Loss: 0.0006197235998115502, Final Batch Loss: 0.0005476950900629163\n",
      "Epoch 2719, Loss: 0.0010854883512365632, Final Batch Loss: 2.3931141186039895e-05\n",
      "Epoch 2720, Loss: 4.420601726451423e-05, Final Batch Loss: 1.6731555660953745e-05\n",
      "Epoch 2721, Loss: 0.000162864729645662, Final Batch Loss: 2.5063942302949727e-05\n",
      "Epoch 2722, Loss: 0.002135027461918071, Final Batch Loss: 0.0017524687573313713\n",
      "Epoch 2723, Loss: 0.0006652816373389214, Final Batch Loss: 0.0006162603967823088\n",
      "Epoch 2724, Loss: 8.165654435288161e-05, Final Batch Loss: 1.0550305887591094e-05\n",
      "Epoch 2725, Loss: 0.00037023695040261373, Final Batch Loss: 0.0003147678798995912\n",
      "Epoch 2726, Loss: 0.006877537118270993, Final Batch Loss: 0.006150299217551947\n",
      "Epoch 2727, Loss: 0.0005859543134647538, Final Batch Loss: 0.0005761981010437012\n",
      "Epoch 2728, Loss: 0.0007171392499003559, Final Batch Loss: 0.00032141778501681983\n",
      "Epoch 2729, Loss: 0.0005812854196847184, Final Batch Loss: 0.0005653111729770899\n",
      "Epoch 2730, Loss: 0.00033325939148198813, Final Batch Loss: 0.00021100862068124115\n",
      "Epoch 2731, Loss: 0.000380914265406318, Final Batch Loss: 0.00011397844355087727\n",
      "Epoch 2732, Loss: 2.622502506710589e-05, Final Batch Loss: 9.77576564764604e-06\n",
      "Epoch 2733, Loss: 0.0001844807411544025, Final Batch Loss: 5.1834198529832065e-05\n",
      "Epoch 2734, Loss: 4.762566459248774e-05, Final Batch Loss: 1.884555422293488e-05\n",
      "Epoch 2735, Loss: 0.0006552614504471421, Final Batch Loss: 0.00012745143612846732\n",
      "Epoch 2736, Loss: 7.462267012670054e-05, Final Batch Loss: 2.3146908461058047e-06\n",
      "Epoch 2737, Loss: 5.625572521239519e-05, Final Batch Loss: 1.5533041732851416e-05\n",
      "Epoch 2738, Loss: 2.762848907877924e-05, Final Batch Loss: 1.1794231795647647e-05\n",
      "Epoch 2739, Loss: 7.979503243404906e-05, Final Batch Loss: 5.39217799087055e-05\n",
      "Epoch 2740, Loss: 0.0008671377727296203, Final Batch Loss: 0.0005157742998562753\n",
      "Epoch 2741, Loss: 0.0004085907912667608, Final Batch Loss: 0.0003993038844782859\n",
      "Epoch 2742, Loss: 0.00017214735271409154, Final Batch Loss: 0.00013095283065922558\n",
      "Epoch 2743, Loss: 0.0024657764261064585, Final Batch Loss: 0.0024269400164484978\n",
      "Epoch 2744, Loss: 0.00010465331070008688, Final Batch Loss: 4.790063030668534e-05\n",
      "Epoch 2745, Loss: 0.0004893116129096597, Final Batch Loss: 0.0003329533210489899\n",
      "Epoch 2746, Loss: 0.00017529471415400621, Final Batch Loss: 4.3079785427835304e-06\n",
      "Epoch 2747, Loss: 1.8098483906214824e-05, Final Batch Loss: 1.2259625691513065e-05\n",
      "Epoch 2748, Loss: 0.0002789295667753322, Final Batch Loss: 0.0002521584974601865\n",
      "Epoch 2749, Loss: 0.0002924054570030421, Final Batch Loss: 0.00019058452744502574\n",
      "Epoch 2750, Loss: 8.398573663725983e-05, Final Batch Loss: 6.200687494128942e-05\n",
      "Epoch 2751, Loss: 0.00015646767133148387, Final Batch Loss: 0.00013597500219475478\n",
      "Epoch 2752, Loss: 0.00013615770149044693, Final Batch Loss: 8.651549433125183e-05\n",
      "Epoch 2753, Loss: 0.0003055701163248159, Final Batch Loss: 9.33288611122407e-05\n",
      "Epoch 2754, Loss: 0.0005627651553368196, Final Batch Loss: 0.0004928416456095874\n",
      "Epoch 2755, Loss: 7.304048449441325e-05, Final Batch Loss: 5.898951712879352e-06\n",
      "Epoch 2756, Loss: 0.0001246890824404545, Final Batch Loss: 5.004300328437239e-05\n",
      "Epoch 2757, Loss: 0.00014134880439087283, Final Batch Loss: 2.2717596948496066e-05\n",
      "Epoch 2758, Loss: 0.01437809348499286, Final Batch Loss: 2.000417953240685e-05\n",
      "Epoch 2759, Loss: 0.00020702237088698894, Final Batch Loss: 0.00011625964543782175\n",
      "Epoch 2760, Loss: 5.8745627029566094e-05, Final Batch Loss: 1.0776166163850576e-05\n",
      "Epoch 2761, Loss: 0.00041089521619142033, Final Batch Loss: 0.00038201475399546325\n",
      "Epoch 2762, Loss: 5.1618589168356266e-05, Final Batch Loss: 8.598536624049302e-06\n",
      "Epoch 2763, Loss: 0.0004287467490939889, Final Batch Loss: 2.262843554490246e-05\n",
      "Epoch 2764, Loss: 4.695980624092044e-05, Final Batch Loss: 1.273338511964539e-05\n",
      "Epoch 2765, Loss: 0.0002344183385503129, Final Batch Loss: 8.98213420441607e-06\n",
      "Epoch 2766, Loss: 0.0013679000549018383, Final Batch Loss: 5.693570710718632e-05\n",
      "Epoch 2767, Loss: 0.00036966601328458637, Final Batch Loss: 6.326536822598428e-05\n",
      "Epoch 2768, Loss: 0.000510835088789463, Final Batch Loss: 6.042167660780251e-05\n",
      "Epoch 2769, Loss: 5.468861672852654e-05, Final Batch Loss: 3.415489481994882e-05\n",
      "Epoch 2770, Loss: 2.3440672975993948e-05, Final Batch Loss: 5.195863650442334e-06\n",
      "Epoch 2771, Loss: 2.9982599244249286e-05, Final Batch Loss: 7.288914730452234e-06\n",
      "Epoch 2772, Loss: 0.0033011974701366853, Final Batch Loss: 0.0032431886065751314\n",
      "Epoch 2773, Loss: 0.003712831751727208, Final Batch Loss: 0.0036991264205425978\n",
      "Epoch 2774, Loss: 0.0005226507055340335, Final Batch Loss: 0.00021294433099683374\n",
      "Epoch 2775, Loss: 0.00012369376054266468, Final Batch Loss: 4.21253644162789e-05\n",
      "Epoch 2776, Loss: 0.0001585727368365042, Final Batch Loss: 8.44488458824344e-05\n",
      "Epoch 2777, Loss: 0.00013009051144763362, Final Batch Loss: 0.00010743554594228044\n",
      "Epoch 2778, Loss: 0.0008996017350000329, Final Batch Loss: 0.0007975096232257783\n",
      "Epoch 2779, Loss: 0.0006735904607921839, Final Batch Loss: 0.00040981193888001144\n",
      "Epoch 2780, Loss: 0.00010243596261716448, Final Batch Loss: 2.5465367798460647e-05\n",
      "Epoch 2781, Loss: 0.002858618874597596, Final Batch Loss: 4.178578456048854e-05\n",
      "Epoch 2782, Loss: 7.21029664418893e-05, Final Batch Loss: 2.5983265004470013e-05\n",
      "Epoch 2783, Loss: 0.00017825610848376527, Final Batch Loss: 9.45713254623115e-05\n",
      "Epoch 2784, Loss: 0.00025956226272683125, Final Batch Loss: 2.327094080101233e-05\n",
      "Epoch 2785, Loss: 9.600325392966624e-05, Final Batch Loss: 2.1132704205228947e-05\n",
      "Epoch 2786, Loss: 3.7045037061034236e-05, Final Batch Loss: 4.3718509914469905e-06\n",
      "Epoch 2787, Loss: 0.00030812330260232557, Final Batch Loss: 3.027211823791731e-05\n",
      "Epoch 2788, Loss: 0.008668600228702417, Final Batch Loss: 4.001671550213359e-05\n",
      "Epoch 2789, Loss: 0.001043148986354936, Final Batch Loss: 0.0009357352391816676\n",
      "Epoch 2790, Loss: 0.00015581158186250832, Final Batch Loss: 2.5738399926922284e-05\n",
      "Epoch 2791, Loss: 0.0013273278600536287, Final Batch Loss: 0.0007924544624984264\n",
      "Epoch 2792, Loss: 0.0005108508194098249, Final Batch Loss: 0.0004465807869564742\n",
      "Epoch 2793, Loss: 0.0017816423933254555, Final Batch Loss: 0.0016981191001832485\n",
      "Epoch 2794, Loss: 0.00011078456373070367, Final Batch Loss: 5.98082879150752e-05\n",
      "Epoch 2795, Loss: 0.00011297645505692344, Final Batch Loss: 0.00010340900189476088\n",
      "Epoch 2796, Loss: 0.0007553070172434673, Final Batch Loss: 7.982137321960181e-05\n",
      "Epoch 2797, Loss: 0.00019107257685391232, Final Batch Loss: 6.131536065367982e-05\n",
      "Epoch 2798, Loss: 0.000829891738248989, Final Batch Loss: 0.00048334471648558974\n",
      "Epoch 2799, Loss: 0.0001665265008341521, Final Batch Loss: 0.00011113796790596098\n",
      "Epoch 2800, Loss: 0.0002036563929550539, Final Batch Loss: 1.099975747820281e-06\n",
      "Epoch 2801, Loss: 0.00017894777556648478, Final Batch Loss: 0.000104162645584438\n",
      "Epoch 2802, Loss: 0.0017113286194216926, Final Batch Loss: 1.603619966772385e-05\n",
      "Epoch 2803, Loss: 2.0470001345529454e-05, Final Batch Loss: 1.610951585462317e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2804, Loss: 0.0014095762016950175, Final Batch Loss: 4.009452823083848e-05\n",
      "Epoch 2805, Loss: 0.0002199636001023464, Final Batch Loss: 0.00012097538274247199\n",
      "Epoch 2806, Loss: 7.23093990018242e-06, Final Batch Loss: 3.268535692768637e-06\n",
      "Epoch 2807, Loss: 0.00029799999902024865, Final Batch Loss: 8.17130203358829e-05\n",
      "Epoch 2808, Loss: 0.0006755996282663546, Final Batch Loss: 0.0006606280221603811\n",
      "Epoch 2809, Loss: 0.002907732268795371, Final Batch Loss: 0.0019472084240987897\n",
      "Epoch 2810, Loss: 0.0002581924964033533, Final Batch Loss: 3.6117042327532545e-05\n",
      "Epoch 2811, Loss: 4.909851304546464e-05, Final Batch Loss: 3.7539502955041826e-05\n",
      "Epoch 2812, Loss: 0.0008418956249442999, Final Batch Loss: 0.0008308980613946915\n",
      "Epoch 2813, Loss: 0.0044223874574527144, Final Batch Loss: 0.004334714729338884\n",
      "Epoch 2814, Loss: 7.370740786427632e-05, Final Batch Loss: 3.148780524497852e-05\n",
      "Epoch 2815, Loss: 0.00012928086380270543, Final Batch Loss: 9.111104191106278e-06\n",
      "Epoch 2816, Loss: 0.0001776837816578336, Final Batch Loss: 0.00012260093353688717\n",
      "Epoch 2817, Loss: 7.033504516584799e-05, Final Batch Loss: 3.978484164690599e-05\n",
      "Epoch 2818, Loss: 0.0021775102941319346, Final Batch Loss: 0.0006440798752009869\n",
      "Epoch 2819, Loss: 7.191192162281368e-05, Final Batch Loss: 2.6127914679818787e-05\n",
      "Epoch 2820, Loss: 0.00013008909627387766, Final Batch Loss: 1.5078448996064253e-05\n",
      "Epoch 2821, Loss: 0.0005185093759791926, Final Batch Loss: 0.00048609779332764447\n",
      "Epoch 2822, Loss: 5.961408987786854e-05, Final Batch Loss: 4.985722989658825e-05\n",
      "Epoch 2823, Loss: 0.0010735464020399377, Final Batch Loss: 0.00015827394963707775\n",
      "Epoch 2824, Loss: 8.922141569200903e-05, Final Batch Loss: 6.446623592637479e-05\n",
      "Epoch 2825, Loss: 0.003482656196865719, Final Batch Loss: 0.0033858073875308037\n",
      "Epoch 2826, Loss: 0.009829611837631091, Final Batch Loss: 0.00038868034607730806\n",
      "Epoch 2827, Loss: 7.323096542677376e-05, Final Batch Loss: 1.449124283681158e-05\n",
      "Epoch 2828, Loss: 0.004379362289910205, Final Batch Loss: 2.0294406567700207e-05\n",
      "Epoch 2829, Loss: 0.00503264919098001, Final Batch Loss: 2.6439520297572017e-06\n",
      "Epoch 2830, Loss: 0.0006566685187863186, Final Batch Loss: 0.0005752405268140137\n",
      "Epoch 2831, Loss: 0.0001664943920332007, Final Batch Loss: 0.00010223827848676592\n",
      "Epoch 2832, Loss: 0.00017139834017143585, Final Batch Loss: 0.00011185080802533776\n",
      "Epoch 2833, Loss: 0.0003291342218290083, Final Batch Loss: 0.00023822070215828717\n",
      "Epoch 2834, Loss: 0.00015331403847085312, Final Batch Loss: 0.00012477324344217777\n",
      "Epoch 2835, Loss: 0.00037093764694873244, Final Batch Loss: 0.00016721522842999548\n",
      "Epoch 2836, Loss: 0.00025030509823409375, Final Batch Loss: 0.00022007223742548376\n",
      "Epoch 2837, Loss: 0.00015683957826695405, Final Batch Loss: 1.753825563355349e-05\n",
      "Epoch 2838, Loss: 0.0016834666021168232, Final Batch Loss: 0.0006256690248847008\n",
      "Epoch 2839, Loss: 0.010591277867206372, Final Batch Loss: 0.010411087423563004\n",
      "Epoch 2840, Loss: 5.1697912567760795e-05, Final Batch Loss: 1.8147638911614195e-05\n",
      "Epoch 2841, Loss: 0.006720577050145948, Final Batch Loss: 0.006694253999739885\n",
      "Epoch 2842, Loss: 0.0006457434501498938, Final Batch Loss: 0.0004901281790807843\n",
      "Epoch 2843, Loss: 0.003868240863084793, Final Batch Loss: 0.0019704275764524937\n",
      "Epoch 2844, Loss: 0.00010305519390385598, Final Batch Loss: 5.2460873121162876e-05\n",
      "Epoch 2845, Loss: 0.00023645650799153373, Final Batch Loss: 4.065759276272729e-05\n",
      "Epoch 2846, Loss: 0.004214111288092681, Final Batch Loss: 1.6894229702302255e-05\n",
      "Epoch 2847, Loss: 0.0003968307592003839, Final Batch Loss: 2.9249817089294083e-05\n",
      "Epoch 2848, Loss: 0.0004412877533468418, Final Batch Loss: 7.874410221120343e-05\n",
      "Epoch 2849, Loss: 0.04703909531235695, Final Batch Loss: 0.015505969524383545\n",
      "Epoch 2850, Loss: 0.00316464900970459, Final Batch Loss: 0.001913354150019586\n",
      "Epoch 2851, Loss: 0.006670884344202932, Final Batch Loss: 5.085070006316528e-05\n",
      "Epoch 2852, Loss: 0.00016266339298454113, Final Batch Loss: 4.137042924412526e-05\n",
      "Epoch 2853, Loss: 0.005581439065281302, Final Batch Loss: 0.004800273571163416\n",
      "Epoch 2854, Loss: 0.05938455031719059, Final Batch Loss: 0.058273397386074066\n",
      "Epoch 2855, Loss: 0.0010203300626017153, Final Batch Loss: 0.00013131211744621396\n",
      "Epoch 2856, Loss: 0.005594946560449898, Final Batch Loss: 0.005333936307579279\n",
      "Epoch 2857, Loss: 0.12000914569944143, Final Batch Loss: 0.11600787192583084\n",
      "Epoch 2858, Loss: 0.02395181212341413, Final Batch Loss: 0.00015394057845696807\n",
      "Epoch 2859, Loss: 0.005524853157112375, Final Batch Loss: 0.005327255465090275\n",
      "Epoch 2860, Loss: 0.004034088691696525, Final Batch Loss: 0.002834299812093377\n",
      "Epoch 2861, Loss: 0.005970142548903823, Final Batch Loss: 0.0035854047164320946\n",
      "Epoch 2862, Loss: 0.07730264961719513, Final Batch Loss: 0.03628411516547203\n",
      "Epoch 2863, Loss: 0.0700468011200428, Final Batch Loss: 0.034375306218862534\n",
      "Epoch 2864, Loss: 0.032782205467810854, Final Batch Loss: 8.18791741039604e-05\n",
      "Epoch 2865, Loss: 0.0010396011639386415, Final Batch Loss: 0.0008525999146513641\n",
      "Epoch 2866, Loss: 0.008551280247047544, Final Batch Loss: 0.001560944365337491\n",
      "Epoch 2867, Loss: 0.007754896301776171, Final Batch Loss: 0.003938936162739992\n",
      "Epoch 2868, Loss: 0.007856737123802304, Final Batch Loss: 0.005118988920003176\n",
      "Epoch 2869, Loss: 0.05128487944602966, Final Batch Loss: 0.02389141358435154\n",
      "Epoch 2870, Loss: 0.02112458646297455, Final Batch Loss: 0.0023704133927822113\n",
      "Epoch 2871, Loss: 0.002373237395659089, Final Batch Loss: 0.0011719599133357406\n",
      "Epoch 2872, Loss: 0.0008735998126212507, Final Batch Loss: 0.0007233771029859781\n",
      "Epoch 2873, Loss: 0.000617462967056781, Final Batch Loss: 0.00019008753588423133\n",
      "Epoch 2874, Loss: 0.0005941298441030085, Final Batch Loss: 0.00014068081509321928\n",
      "Epoch 2875, Loss: 0.004904620815068483, Final Batch Loss: 0.0028899686876684427\n",
      "Epoch 2876, Loss: 0.000857903971336782, Final Batch Loss: 0.00026814249577000737\n",
      "Epoch 2877, Loss: 0.004311508382670581, Final Batch Loss: 0.0029814704321324825\n",
      "Epoch 2878, Loss: 0.009491942939348519, Final Batch Loss: 0.008624976500868797\n",
      "Epoch 2879, Loss: 0.0024438606342300773, Final Batch Loss: 0.0013377465074881911\n",
      "Epoch 2880, Loss: 0.0016712160140741616, Final Batch Loss: 0.001418852829374373\n",
      "Epoch 2881, Loss: 0.004591948410961777, Final Batch Loss: 0.0040093157440423965\n",
      "Epoch 2882, Loss: 0.0016145982808666304, Final Batch Loss: 0.001438011066056788\n",
      "Epoch 2883, Loss: 0.0022247594024520367, Final Batch Loss: 0.001825710292905569\n",
      "Epoch 2884, Loss: 0.001028045837301761, Final Batch Loss: 0.00033103267196565866\n",
      "Epoch 2885, Loss: 0.0012449666392058134, Final Batch Loss: 0.0007406517397612333\n",
      "Epoch 2886, Loss: 0.00221656053327024, Final Batch Loss: 0.002129949163645506\n",
      "Epoch 2887, Loss: 0.0005943853248027153, Final Batch Loss: 3.920571907656267e-05\n",
      "Epoch 2888, Loss: 0.0009341483237221837, Final Batch Loss: 0.000624849577434361\n",
      "Epoch 2889, Loss: 0.006898205261677504, Final Batch Loss: 0.004495464731007814\n",
      "Epoch 2890, Loss: 0.0037105116061866283, Final Batch Loss: 0.0015142506454139948\n",
      "Epoch 2891, Loss: 0.000894544329639757, Final Batch Loss: 4.468849874683656e-05\n",
      "Epoch 2892, Loss: 0.0011305309453746304, Final Batch Loss: 0.0010601547546684742\n",
      "Epoch 2893, Loss: 0.00034991221036762, Final Batch Loss: 0.0002058775135083124\n",
      "Epoch 2894, Loss: 0.0046856287808623165, Final Batch Loss: 0.00011723543866537511\n",
      "Epoch 2895, Loss: 0.0011195818078704178, Final Batch Loss: 0.0005252444534562528\n",
      "Epoch 2896, Loss: 0.00032932312751654536, Final Batch Loss: 0.00015650865680072457\n",
      "Epoch 2897, Loss: 0.0007853419228922576, Final Batch Loss: 0.0006426050094887614\n",
      "Epoch 2898, Loss: 0.0047350841196021065, Final Batch Loss: 0.00011308943794574589\n",
      "Epoch 2899, Loss: 0.0017364260274916887, Final Batch Loss: 0.0006216553738340735\n",
      "Epoch 2900, Loss: 0.0008370525320060551, Final Batch Loss: 0.0005664572236128151\n",
      "Epoch 2901, Loss: 0.008418456331128255, Final Batch Loss: 0.008303895592689514\n",
      "Epoch 2902, Loss: 0.0014826546612312086, Final Batch Loss: 0.0013963263481855392\n",
      "Epoch 2903, Loss: 0.0051643067272379994, Final Batch Loss: 0.0009645131649449468\n",
      "Epoch 2904, Loss: 0.0030098678544163704, Final Batch Loss: 0.0028201884124428034\n",
      "Epoch 2905, Loss: 0.0002647344517754391, Final Batch Loss: 0.00018416893726680428\n",
      "Epoch 2906, Loss: 0.00031996105099096894, Final Batch Loss: 0.0002072962815873325\n",
      "Epoch 2907, Loss: 0.000354128482285887, Final Batch Loss: 0.00028211792232468724\n",
      "Epoch 2908, Loss: 0.0022521279788634274, Final Batch Loss: 0.002208367921411991\n",
      "Epoch 2909, Loss: 0.00063117197714746, Final Batch Loss: 0.0003246485721319914\n",
      "Epoch 2910, Loss: 0.00029662976157851517, Final Batch Loss: 0.00013243591820355505\n",
      "Epoch 2911, Loss: 0.001415813541825628, Final Batch Loss: 0.0013554784236475825\n",
      "Epoch 2912, Loss: 0.0010888535471167415, Final Batch Loss: 0.0002373386814724654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2913, Loss: 0.014928147429600358, Final Batch Loss: 0.000145388999953866\n",
      "Epoch 2914, Loss: 0.004183519631624222, Final Batch Loss: 0.0017033619806170464\n",
      "Epoch 2915, Loss: 0.0005722247005905956, Final Batch Loss: 0.00031274123466573656\n",
      "Epoch 2916, Loss: 0.003380114329047501, Final Batch Loss: 0.0017906208522617817\n",
      "Epoch 2917, Loss: 0.0005821172235300764, Final Batch Loss: 0.00036034767981618643\n",
      "Epoch 2918, Loss: 0.0014237430441426113, Final Batch Loss: 2.9938601073808968e-05\n",
      "Epoch 2919, Loss: 0.0042507860052865, Final Batch Loss: 0.00022052388521842659\n",
      "Epoch 2920, Loss: 0.00032554300742049236, Final Batch Loss: 0.00031168950954452157\n",
      "Epoch 2921, Loss: 0.00021884115267312154, Final Batch Loss: 0.0001176949663204141\n",
      "Epoch 2922, Loss: 8.743310900172219e-05, Final Batch Loss: 3.700785237015225e-05\n",
      "Epoch 2923, Loss: 0.0006935320125194266, Final Batch Loss: 0.0005290263216011226\n",
      "Epoch 2924, Loss: 0.00040567159339843784, Final Batch Loss: 2.4906325052143075e-05\n",
      "Epoch 2925, Loss: 0.0009259433281840757, Final Batch Loss: 4.9771464546211064e-05\n",
      "Epoch 2926, Loss: 0.0004438069590833038, Final Batch Loss: 0.0002751384163275361\n",
      "Epoch 2927, Loss: 0.004068684880621731, Final Batch Loss: 0.0008486268343403935\n",
      "Epoch 2928, Loss: 0.0007126487325876951, Final Batch Loss: 0.0005207916838116944\n",
      "Epoch 2929, Loss: 0.009689020575024188, Final Batch Loss: 0.0018410185584798455\n",
      "Epoch 2930, Loss: 0.0003461577871348709, Final Batch Loss: 0.00025509801344014704\n",
      "Epoch 2931, Loss: 0.0010762376259663142, Final Batch Loss: 9.10874005057849e-05\n",
      "Epoch 2932, Loss: 0.00026015732146333903, Final Batch Loss: 5.038295057602227e-05\n",
      "Epoch 2933, Loss: 0.0013894025978515856, Final Batch Loss: 9.875016257865354e-05\n",
      "Epoch 2934, Loss: 0.0006043068278813735, Final Batch Loss: 0.000488083838718012\n",
      "Epoch 2935, Loss: 0.00042901096458081156, Final Batch Loss: 0.00010757388372439891\n",
      "Epoch 2936, Loss: 0.0014585948956664652, Final Batch Loss: 0.00026820736820809543\n",
      "Epoch 2937, Loss: 0.0009721456444822252, Final Batch Loss: 0.00034285883884876966\n",
      "Epoch 2938, Loss: 0.00022203563275979832, Final Batch Loss: 0.00012643809895962477\n",
      "Epoch 2939, Loss: 0.0002605513946036808, Final Batch Loss: 0.00017485958233010024\n",
      "Epoch 2940, Loss: 0.0006257496861508116, Final Batch Loss: 0.0004997536307200789\n",
      "Epoch 2941, Loss: 0.0029880377696827054, Final Batch Loss: 0.0026725041680037975\n",
      "Epoch 2942, Loss: 0.00015928560060274322, Final Batch Loss: 1.2871170838479884e-05\n",
      "Epoch 2943, Loss: 0.0005288055108394474, Final Batch Loss: 0.0002074125804938376\n",
      "Epoch 2944, Loss: 0.0011149914789712057, Final Batch Loss: 0.0010037716710940003\n",
      "Epoch 2945, Loss: 0.0004645362168957945, Final Batch Loss: 5.408280048868619e-05\n",
      "Epoch 2946, Loss: 0.00044902454828843474, Final Batch Loss: 6.303525879047811e-05\n",
      "Epoch 2947, Loss: 0.00011133721818623599, Final Batch Loss: 9.15067721507512e-05\n",
      "Epoch 2948, Loss: 0.0003431720324442722, Final Batch Loss: 0.0002808368008118123\n",
      "Epoch 2949, Loss: 0.0008115790478768758, Final Batch Loss: 0.00010979192302329466\n",
      "Epoch 2950, Loss: 0.0004039196137455292, Final Batch Loss: 0.00010085234680445865\n",
      "Epoch 2951, Loss: 0.0011698326998157427, Final Batch Loss: 0.00013651866174768656\n",
      "Epoch 2952, Loss: 0.005317728966474533, Final Batch Loss: 0.001177232712507248\n",
      "Epoch 2953, Loss: 0.00024913436209317297, Final Batch Loss: 0.00012467354827094823\n",
      "Epoch 2954, Loss: 0.0002635857308632694, Final Batch Loss: 7.860232290113345e-05\n",
      "Epoch 2955, Loss: 0.0007850156252970919, Final Batch Loss: 4.7781431931070983e-05\n",
      "Epoch 2956, Loss: 0.00045333849993767217, Final Batch Loss: 8.673413685755804e-05\n",
      "Epoch 2957, Loss: 0.00026654379325918853, Final Batch Loss: 5.9558296925388277e-05\n",
      "Epoch 2958, Loss: 0.0006870669749332592, Final Batch Loss: 0.00020551397756207734\n",
      "Epoch 2959, Loss: 0.0015896720869932324, Final Batch Loss: 0.00014344908413477242\n",
      "Epoch 2960, Loss: 0.0003113248822046444, Final Batch Loss: 0.00015878581325523555\n",
      "Epoch 2961, Loss: 0.0018055157797789434, Final Batch Loss: 2.5623763576732017e-05\n",
      "Epoch 2962, Loss: 0.00045226418296806514, Final Batch Loss: 0.0003550731053110212\n",
      "Epoch 2963, Loss: 0.0036577725913957693, Final Batch Loss: 0.0035580387338995934\n",
      "Epoch 2964, Loss: 0.0033512158261146396, Final Batch Loss: 0.00308889034204185\n",
      "Epoch 2965, Loss: 8.480334872729145e-05, Final Batch Loss: 5.252395203569904e-05\n",
      "Epoch 2966, Loss: 0.0002721203782130033, Final Batch Loss: 0.00018178095342591405\n",
      "Epoch 2967, Loss: 0.0009611034111003391, Final Batch Loss: 4.707072366727516e-05\n",
      "Epoch 2968, Loss: 0.00013416596993920393, Final Batch Loss: 9.831767238210887e-05\n",
      "Epoch 2969, Loss: 2.9374529731285293e-05, Final Batch Loss: 6.030747499607969e-06\n",
      "Epoch 2970, Loss: 0.0011858392354042735, Final Batch Loss: 3.07760747091379e-05\n",
      "Epoch 2971, Loss: 0.0001987663381441962, Final Batch Loss: 0.00015491271915379912\n",
      "Epoch 2972, Loss: 0.0030230602715164423, Final Batch Loss: 0.000868865754455328\n",
      "Epoch 2973, Loss: 0.0009878106866381131, Final Batch Loss: 0.0008768107509240508\n",
      "Epoch 2974, Loss: 0.0038328424998326227, Final Batch Loss: 0.0036587563809007406\n",
      "Epoch 2975, Loss: 0.007292121721548028, Final Batch Loss: 0.00011048985470551997\n",
      "Epoch 2976, Loss: 0.002129518466972513, Final Batch Loss: 5.681979746441357e-05\n",
      "Epoch 2977, Loss: 0.0003657845882116817, Final Batch Loss: 0.00032347760861739516\n",
      "Epoch 2978, Loss: 0.0004857798558077775, Final Batch Loss: 9.168218093691394e-05\n",
      "Epoch 2979, Loss: 0.00012185375817352906, Final Batch Loss: 8.707043889444321e-05\n",
      "Epoch 2980, Loss: 0.0007694479136262089, Final Batch Loss: 9.603551006875932e-05\n",
      "Epoch 2981, Loss: 0.000994131260085851, Final Batch Loss: 0.0007850080728530884\n",
      "Epoch 2982, Loss: 0.0008103016152745113, Final Batch Loss: 0.0001478099002270028\n",
      "Epoch 2983, Loss: 0.0006333749915938824, Final Batch Loss: 0.0004822183691430837\n",
      "Epoch 2984, Loss: 0.00052876457630191, Final Batch Loss: 0.0002872339391615242\n",
      "Epoch 2985, Loss: 0.0012923037866130471, Final Batch Loss: 0.00034522474743425846\n",
      "Epoch 2986, Loss: 0.00035883884265786037, Final Batch Loss: 0.00010230912448605523\n",
      "Epoch 2987, Loss: 0.0009621097415219992, Final Batch Loss: 0.0004158678639214486\n",
      "Epoch 2988, Loss: 0.0024831618648022413, Final Batch Loss: 0.001285501173697412\n",
      "Epoch 2989, Loss: 0.000533749334863387, Final Batch Loss: 0.00035193373332731426\n",
      "Epoch 2990, Loss: 0.0005358549433367443, Final Batch Loss: 1.1396351510484237e-05\n",
      "Epoch 2991, Loss: 0.011510218726471066, Final Batch Loss: 0.000985046150162816\n",
      "Epoch 2992, Loss: 0.000451184154371731, Final Batch Loss: 0.00014294862921815366\n",
      "Epoch 2993, Loss: 0.0004342373285908252, Final Batch Loss: 0.00015903034363873303\n",
      "Epoch 2994, Loss: 0.0007802530672051944, Final Batch Loss: 4.229424666846171e-05\n",
      "Epoch 2995, Loss: 0.0013305740285431966, Final Batch Loss: 0.0012662643566727638\n",
      "Epoch 2996, Loss: 0.00010627658593875822, Final Batch Loss: 2.5390012524439953e-05\n",
      "Epoch 2997, Loss: 0.0004694163362728432, Final Batch Loss: 0.00030980934388935566\n",
      "Epoch 2998, Loss: 0.0006592361605726182, Final Batch Loss: 0.0006050884840078652\n",
      "Epoch 2999, Loss: 0.00025532450126775075, Final Batch Loss: 0.000231896890909411\n",
      "Epoch 3000, Loss: 0.00012450582289602607, Final Batch Loss: 6.597080209758133e-05\n",
      "Epoch 3001, Loss: 0.00015185209485935047, Final Batch Loss: 6.420248973881826e-05\n",
      "Epoch 3002, Loss: 0.0007112360326573253, Final Batch Loss: 0.00020858028437942266\n",
      "Epoch 3003, Loss: 0.00043868939246749505, Final Batch Loss: 0.00040419146534986794\n",
      "Epoch 3004, Loss: 0.00017890697199618444, Final Batch Loss: 0.00010648942406987771\n",
      "Epoch 3005, Loss: 0.0015309380796679761, Final Batch Loss: 4.7428413381567225e-05\n",
      "Epoch 3006, Loss: 0.0013102358352625743, Final Batch Loss: 6.157044845167547e-05\n",
      "Epoch 3007, Loss: 0.002254639897728339, Final Batch Loss: 0.0017724307253956795\n",
      "Epoch 3008, Loss: 0.0005992499063722789, Final Batch Loss: 0.0003932397812604904\n",
      "Epoch 3009, Loss: 0.0022217554069356993, Final Batch Loss: 0.00010407269292045385\n",
      "Epoch 3010, Loss: 0.00039608889346709475, Final Batch Loss: 0.00010088801354868338\n",
      "Epoch 3011, Loss: 0.0003745595531654544, Final Batch Loss: 0.0002564752066973597\n",
      "Epoch 3012, Loss: 0.0002947492157545639, Final Batch Loss: 2.9626475225086324e-05\n",
      "Epoch 3013, Loss: 0.00014657924475613981, Final Batch Loss: 7.658766844542697e-05\n",
      "Epoch 3014, Loss: 0.0010025441661127843, Final Batch Loss: 8.301795605802909e-05\n",
      "Epoch 3015, Loss: 0.0001434420482837595, Final Batch Loss: 4.117278876947239e-05\n",
      "Epoch 3016, Loss: 0.0015713741013314575, Final Batch Loss: 0.0012759518576785922\n",
      "Epoch 3017, Loss: 4.484608689381275e-05, Final Batch Loss: 1.859925760072656e-05\n",
      "Epoch 3018, Loss: 0.00038024827154004015, Final Batch Loss: 0.00033822489785961807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3019, Loss: 0.0002227281620434951, Final Batch Loss: 5.004774357075803e-05\n",
      "Epoch 3020, Loss: 0.0004795303975697607, Final Batch Loss: 0.00010184443090111017\n",
      "Epoch 3021, Loss: 0.0004946354183630319, Final Batch Loss: 0.00047042558435350657\n",
      "Epoch 3022, Loss: 0.004683848237618804, Final Batch Loss: 0.00022179610095918179\n",
      "Epoch 3023, Loss: 0.00015932966925902292, Final Batch Loss: 6.940979073988274e-05\n",
      "Epoch 3024, Loss: 0.00015881592480582185, Final Batch Loss: 0.00010695154924178496\n",
      "Epoch 3025, Loss: 0.00015578672537230887, Final Batch Loss: 3.1792489608051255e-05\n",
      "Epoch 3026, Loss: 0.001866149737907108, Final Batch Loss: 3.840264253085479e-05\n",
      "Epoch 3027, Loss: 0.000814625367638655, Final Batch Loss: 0.0006318218656815588\n",
      "Epoch 3028, Loss: 0.0006261092494241893, Final Batch Loss: 0.0003739893436431885\n",
      "Epoch 3029, Loss: 9.314739145338535e-05, Final Batch Loss: 4.885433736490086e-05\n",
      "Epoch 3030, Loss: 0.0003261714937252691, Final Batch Loss: 0.0003172658907715231\n",
      "Epoch 3031, Loss: 0.0013398887695075246, Final Batch Loss: 9.421013601240702e-06\n",
      "Epoch 3032, Loss: 0.0005494789547810797, Final Batch Loss: 3.713756814249791e-05\n",
      "Epoch 3033, Loss: 0.00633626090711914, Final Batch Loss: 0.006270413752645254\n",
      "Epoch 3034, Loss: 0.0006958235753700137, Final Batch Loss: 0.0006503330077975988\n",
      "Epoch 3035, Loss: 0.00016805230188765563, Final Batch Loss: 0.00011987726611550897\n",
      "Epoch 3036, Loss: 0.00046918861153244507, Final Batch Loss: 1.4333896615426056e-05\n",
      "Epoch 3037, Loss: 0.00027784948179032654, Final Batch Loss: 0.0002153167879441753\n",
      "Epoch 3038, Loss: 0.0013056863999736379, Final Batch Loss: 5.8579926189850084e-06\n",
      "Epoch 3039, Loss: 0.0005648349615512416, Final Batch Loss: 9.220065840054303e-05\n",
      "Epoch 3040, Loss: 0.0014686078357044607, Final Batch Loss: 0.0013726733159273863\n",
      "Epoch 3041, Loss: 0.0005990536665194668, Final Batch Loss: 9.081626922124997e-05\n",
      "Epoch 3042, Loss: 0.00021571991237578914, Final Batch Loss: 7.551728776888922e-05\n",
      "Epoch 3043, Loss: 0.0027202286692045163, Final Batch Loss: 0.0026733633130788803\n",
      "Epoch 3044, Loss: 0.0004891344797215424, Final Batch Loss: 0.00041899338248185813\n",
      "Epoch 3045, Loss: 0.0004176710353931412, Final Batch Loss: 0.0002631961542647332\n",
      "Epoch 3046, Loss: 0.00012878533016191795, Final Batch Loss: 0.0001171137482742779\n",
      "Epoch 3047, Loss: 0.0006388448819052428, Final Batch Loss: 0.00012816701200790703\n",
      "Epoch 3048, Loss: 0.0007222891508718021, Final Batch Loss: 8.457137300865725e-05\n",
      "Epoch 3049, Loss: 0.0001085558840259182, Final Batch Loss: 3.15160355057742e-06\n",
      "Epoch 3050, Loss: 0.0006913516626809724, Final Batch Loss: 7.02368633938022e-05\n",
      "Epoch 3051, Loss: 0.0007378737354883924, Final Batch Loss: 0.0007092512678354979\n",
      "Epoch 3052, Loss: 0.0004148872903897427, Final Batch Loss: 0.00034465588396415114\n",
      "Epoch 3053, Loss: 0.0013492398902599234, Final Batch Loss: 4.508874917519279e-05\n",
      "Epoch 3054, Loss: 0.00021677923496099538, Final Batch Loss: 4.396957137942081e-06\n",
      "Epoch 3055, Loss: 0.00013086468425171915, Final Batch Loss: 2.772563493635971e-05\n",
      "Epoch 3056, Loss: 0.00017325895078101894, Final Batch Loss: 1.3841860891261604e-05\n",
      "Epoch 3057, Loss: 0.0001019324217850226, Final Batch Loss: 1.318053818977205e-05\n",
      "Epoch 3058, Loss: 0.00031619797209714307, Final Batch Loss: 1.234149658557726e-05\n",
      "Epoch 3059, Loss: 0.004667440480261575, Final Batch Loss: 4.1884421079885215e-05\n",
      "Epoch 3060, Loss: 0.00030805579626758117, Final Batch Loss: 0.0002881012624129653\n",
      "Epoch 3061, Loss: 0.0015610740811098367, Final Batch Loss: 0.0015460270224139094\n",
      "Epoch 3062, Loss: 0.0001947724595083855, Final Batch Loss: 4.3590924178715795e-05\n",
      "Epoch 3063, Loss: 0.0003304254059912637, Final Batch Loss: 8.030228491406888e-05\n",
      "Epoch 3064, Loss: 0.0003047364662052132, Final Batch Loss: 0.00011417545465519652\n",
      "Epoch 3065, Loss: 3.5195907912566327e-05, Final Batch Loss: 1.0052746802102774e-05\n",
      "Epoch 3066, Loss: 0.000274481630185619, Final Batch Loss: 4.032535071019083e-05\n",
      "Epoch 3067, Loss: 0.0003536832518875599, Final Batch Loss: 0.00011974567314609885\n",
      "Epoch 3068, Loss: 0.00027637313587547396, Final Batch Loss: 4.630205239664065e-06\n",
      "Epoch 3069, Loss: 5.715467705158517e-05, Final Batch Loss: 4.95918357046321e-06\n",
      "Epoch 3070, Loss: 0.00094935104061733, Final Batch Loss: 0.0009235756006091833\n",
      "Epoch 3071, Loss: 0.0020765907247550786, Final Batch Loss: 0.0018487349152565002\n",
      "Epoch 3072, Loss: 0.00033671885466901585, Final Batch Loss: 1.934056490426883e-05\n",
      "Epoch 3073, Loss: 0.000887014433828881, Final Batch Loss: 1.655489541008137e-05\n",
      "Epoch 3074, Loss: 7.472487777704373e-05, Final Batch Loss: 2.4145920178852975e-05\n",
      "Epoch 3075, Loss: 0.0008856772183207795, Final Batch Loss: 0.00012080131273251027\n",
      "Epoch 3076, Loss: 0.0007732585909252521, Final Batch Loss: 0.0007497821352444589\n",
      "Epoch 3077, Loss: 0.003535573574481532, Final Batch Loss: 0.0032272241078317165\n",
      "Epoch 3078, Loss: 0.003219888398234616, Final Batch Loss: 0.0031949016265571117\n",
      "Epoch 3079, Loss: 8.858080218487885e-05, Final Batch Loss: 5.984812742099166e-05\n",
      "Epoch 3080, Loss: 0.0012040669680573046, Final Batch Loss: 0.00105542060919106\n",
      "Epoch 3081, Loss: 5.912554115639068e-05, Final Batch Loss: 3.587525861803442e-05\n",
      "Epoch 3082, Loss: 0.0015853351142141037, Final Batch Loss: 0.001505774911493063\n",
      "Epoch 3083, Loss: 0.00018708443531068042, Final Batch Loss: 0.0001540385273983702\n",
      "Epoch 3084, Loss: 0.00010270608345308574, Final Batch Loss: 8.840439113555476e-05\n",
      "Epoch 3085, Loss: 0.0005051175539847463, Final Batch Loss: 0.0003724582202266902\n",
      "Epoch 3086, Loss: 0.0008198756841011345, Final Batch Loss: 0.00027754739858210087\n",
      "Epoch 3087, Loss: 0.004265355062671006, Final Batch Loss: 0.004183153156191111\n",
      "Epoch 3088, Loss: 0.00027443158251116984, Final Batch Loss: 0.00023853078891988844\n",
      "Epoch 3089, Loss: 0.00014433822616410907, Final Batch Loss: 1.2554568456835113e-05\n",
      "Epoch 3090, Loss: 6.358511927828658e-05, Final Batch Loss: 5.9411293477751315e-05\n",
      "Epoch 3091, Loss: 2.380227124376688e-05, Final Batch Loss: 6.018801286700182e-06\n",
      "Epoch 3092, Loss: 0.0032380257034674287, Final Batch Loss: 0.002975755836814642\n",
      "Epoch 3093, Loss: 0.0004215457593090832, Final Batch Loss: 0.0002718779433052987\n",
      "Epoch 3094, Loss: 0.0038629466725979, Final Batch Loss: 0.00016553016030229628\n",
      "Epoch 3095, Loss: 7.770556476316415e-05, Final Batch Loss: 6.122508057160303e-05\n",
      "Epoch 3096, Loss: 6.801125164201949e-05, Final Batch Loss: 3.8844980736030266e-05\n",
      "Epoch 3097, Loss: 0.0007854319046600722, Final Batch Loss: 4.562260437523946e-05\n",
      "Epoch 3098, Loss: 0.0009842228264460573, Final Batch Loss: 1.0412384654046036e-05\n",
      "Epoch 3099, Loss: 0.00047313837421825156, Final Batch Loss: 0.00045309669803828\n",
      "Epoch 3100, Loss: 0.00016863475138961803, Final Batch Loss: 2.0881487216684036e-05\n",
      "Epoch 3101, Loss: 0.007897524237705511, Final Batch Loss: 2.2918991817277856e-05\n",
      "Epoch 3102, Loss: 0.00011066061051678844, Final Batch Loss: 9.78712341748178e-05\n",
      "Epoch 3103, Loss: 0.00029897360582253896, Final Batch Loss: 0.0002716881863307208\n",
      "Epoch 3104, Loss: 0.0022144403992570005, Final Batch Loss: 3.9387748984154314e-05\n",
      "Epoch 3105, Loss: 0.00032750483933341457, Final Batch Loss: 9.23981406231178e-06\n",
      "Epoch 3106, Loss: 0.007932628155685961, Final Batch Loss: 0.0009403192671015859\n",
      "Epoch 3107, Loss: 0.00043777230894193053, Final Batch Loss: 0.00010636274237185717\n",
      "Epoch 3108, Loss: 0.0007889841072028503, Final Batch Loss: 0.00012405535380821675\n",
      "Epoch 3109, Loss: 0.0004943126696161926, Final Batch Loss: 0.00030295460601337254\n",
      "Epoch 3110, Loss: 6.657033372903243e-05, Final Batch Loss: 4.398725286591798e-05\n",
      "Epoch 3111, Loss: 0.0005317663308233023, Final Batch Loss: 6.505451165139675e-05\n",
      "Epoch 3112, Loss: 0.00022485444060293958, Final Batch Loss: 0.00011606197222135961\n",
      "Epoch 3113, Loss: 0.0007428497274304391, Final Batch Loss: 4.787297257280443e-06\n",
      "Epoch 3114, Loss: 0.0001648260913498234, Final Batch Loss: 0.0001428931427653879\n",
      "Epoch 3115, Loss: 8.594290557084605e-05, Final Batch Loss: 3.341098272358067e-05\n",
      "Epoch 3116, Loss: 0.00021392440976342186, Final Batch Loss: 3.084731724811718e-05\n",
      "Epoch 3117, Loss: 0.00013022597522649448, Final Batch Loss: 0.00012330524623394012\n",
      "Epoch 3118, Loss: 0.00012840560520999134, Final Batch Loss: 8.207015343941748e-05\n",
      "Epoch 3119, Loss: 0.0009632980872993357, Final Batch Loss: 6.304129055934027e-05\n",
      "Epoch 3120, Loss: 0.0005451833712868392, Final Batch Loss: 0.00020800213678739965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3121, Loss: 0.00023676583805354312, Final Batch Loss: 0.00020397007756400853\n",
      "Epoch 3122, Loss: 6.730732548021479e-05, Final Batch Loss: 1.2790950677299406e-05\n",
      "Epoch 3123, Loss: 0.00014099791223998182, Final Batch Loss: 2.255285289720632e-05\n",
      "Epoch 3124, Loss: 0.00033331342274323106, Final Batch Loss: 7.10356398485601e-05\n",
      "Epoch 3125, Loss: 5.8219345191901084e-05, Final Batch Loss: 8.282665476144757e-06\n",
      "Epoch 3126, Loss: 0.0003087662480538711, Final Batch Loss: 0.00026843725936487317\n",
      "Epoch 3127, Loss: 0.0011250168245169334, Final Batch Loss: 0.00011297291348455474\n",
      "Epoch 3128, Loss: 0.002133769798092544, Final Batch Loss: 0.0006070907693356276\n",
      "Epoch 3129, Loss: 0.000236256280913949, Final Batch Loss: 0.00017271956312470138\n",
      "Epoch 3130, Loss: 0.0008416525379288942, Final Batch Loss: 0.0007429680554196239\n",
      "Epoch 3131, Loss: 0.00024124353512888774, Final Batch Loss: 9.657099872129038e-05\n",
      "Epoch 3132, Loss: 0.00020229866095178295, Final Batch Loss: 0.0001790685491869226\n",
      "Epoch 3133, Loss: 0.00028380637377267703, Final Batch Loss: 6.790673796785995e-05\n",
      "Epoch 3134, Loss: 0.00011134562373626977, Final Batch Loss: 6.229941209312528e-05\n",
      "Epoch 3135, Loss: 7.582655598525889e-05, Final Batch Loss: 4.342668398749083e-05\n",
      "Epoch 3136, Loss: 0.00013731208309764042, Final Batch Loss: 4.581670509651303e-05\n",
      "Epoch 3137, Loss: 0.0007231113740999717, Final Batch Loss: 5.077907189843245e-05\n",
      "Epoch 3138, Loss: 0.00033106637420132756, Final Batch Loss: 0.00013296086399350315\n",
      "Epoch 3139, Loss: 0.00010901409041252919, Final Batch Loss: 7.267052569659427e-05\n",
      "Epoch 3140, Loss: 9.276546643377515e-05, Final Batch Loss: 8.182303281500936e-05\n",
      "Epoch 3141, Loss: 4.238077417539898e-05, Final Batch Loss: 2.5805287805269472e-05\n",
      "Epoch 3142, Loss: 9.906170089379884e-05, Final Batch Loss: 6.127177766757086e-05\n",
      "Epoch 3143, Loss: 7.669627848372329e-05, Final Batch Loss: 1.659749796090182e-05\n",
      "Epoch 3144, Loss: 0.0001468985210522078, Final Batch Loss: 0.00013251444033812732\n",
      "Epoch 3145, Loss: 0.0002845725466613658, Final Batch Loss: 3.252065653214231e-05\n",
      "Epoch 3146, Loss: 0.00022480943152913824, Final Batch Loss: 8.635099948151037e-05\n",
      "Epoch 3147, Loss: 1.188706141874718e-05, Final Batch Loss: 9.558803867548704e-06\n",
      "Epoch 3148, Loss: 2.7225362600802328e-05, Final Batch Loss: 2.0844152004428906e-06\n",
      "Epoch 3149, Loss: 9.360160402138717e-05, Final Batch Loss: 1.9422051991568878e-05\n",
      "Epoch 3150, Loss: 0.0005306746061251033, Final Batch Loss: 1.9216520740883425e-05\n",
      "Epoch 3151, Loss: 0.0005895603026147, Final Batch Loss: 0.0005456486251205206\n",
      "Epoch 3152, Loss: 0.000252305791946128, Final Batch Loss: 2.322410000488162e-05\n",
      "Epoch 3153, Loss: 8.61585385791841e-06, Final Batch Loss: 3.7421159504447132e-06\n",
      "Epoch 3154, Loss: 0.0004168186517290451, Final Batch Loss: 0.00041425530798733234\n",
      "Epoch 3155, Loss: 2.0141670006523782e-05, Final Batch Loss: 1.2835283769163652e-06\n",
      "Epoch 3156, Loss: 0.0005044448917033151, Final Batch Loss: 0.0004482177901081741\n",
      "Epoch 3157, Loss: 0.00021175833535380661, Final Batch Loss: 9.657276677899063e-05\n",
      "Epoch 3158, Loss: 0.0004074760581715964, Final Batch Loss: 8.168679050868377e-05\n",
      "Epoch 3159, Loss: 5.4698806707165204e-05, Final Batch Loss: 3.7782516301376745e-05\n",
      "Epoch 3160, Loss: 0.0003075594868278131, Final Batch Loss: 5.087415047455579e-05\n",
      "Epoch 3161, Loss: 2.0009299760204158e-05, Final Batch Loss: 3.1496781502937665e-06\n",
      "Epoch 3162, Loss: 0.0009101272444240749, Final Batch Loss: 0.0008168453350663185\n",
      "Epoch 3163, Loss: 0.0012317146465647966, Final Batch Loss: 0.00042473748908378184\n",
      "Epoch 3164, Loss: 0.0001488496345700696, Final Batch Loss: 6.834961823187768e-05\n",
      "Epoch 3165, Loss: 0.004325912275817245, Final Batch Loss: 0.003976929001510143\n",
      "Epoch 3166, Loss: 0.0005967754550511017, Final Batch Loss: 0.0004654160002246499\n",
      "Epoch 3167, Loss: 0.0003708196309162304, Final Batch Loss: 0.00015389989130198956\n",
      "Epoch 3168, Loss: 0.000598063623328926, Final Batch Loss: 1.3673317880602553e-05\n",
      "Epoch 3169, Loss: 0.00032143957150765345, Final Batch Loss: 0.00031755329109728336\n",
      "Epoch 3170, Loss: 5.221024184720591e-05, Final Batch Loss: 1.5692166925873607e-05\n",
      "Epoch 3171, Loss: 0.00022596619601245038, Final Batch Loss: 0.00019130304281134158\n",
      "Epoch 3172, Loss: 0.003712965321028605, Final Batch Loss: 0.003530448768287897\n",
      "Epoch 3173, Loss: 0.0004636154626496136, Final Batch Loss: 0.00030742419767193496\n",
      "Epoch 3174, Loss: 0.0004777174472110346, Final Batch Loss: 0.0002840269007720053\n",
      "Epoch 3175, Loss: 6.515127461170778e-05, Final Batch Loss: 4.746443664771505e-05\n",
      "Epoch 3176, Loss: 0.0004259841807652265, Final Batch Loss: 0.00022709697077516466\n",
      "Epoch 3177, Loss: 2.8492722321971087e-05, Final Batch Loss: 6.354313427436864e-06\n",
      "Epoch 3178, Loss: 0.0004111824746360071, Final Batch Loss: 0.00030953303212299943\n",
      "Epoch 3179, Loss: 0.00043210074363742024, Final Batch Loss: 8.73886892804876e-05\n",
      "Epoch 3180, Loss: 4.385508964332985e-05, Final Batch Loss: 5.8339364841231145e-06\n",
      "Epoch 3181, Loss: 0.00019282872381154448, Final Batch Loss: 6.396094977390021e-05\n",
      "Epoch 3182, Loss: 0.0003002991397806909, Final Batch Loss: 4.4759039155906066e-05\n",
      "Epoch 3183, Loss: 0.0022222999650693964, Final Batch Loss: 3.789054972003214e-05\n",
      "Epoch 3184, Loss: 0.0010438179915581713, Final Batch Loss: 1.1187544259882998e-05\n",
      "Epoch 3185, Loss: 0.0005158038711670088, Final Batch Loss: 1.3294049495016225e-05\n",
      "Epoch 3186, Loss: 0.0002972743095597252, Final Batch Loss: 0.00014432810712605715\n",
      "Epoch 3187, Loss: 0.00019780531738433638, Final Batch Loss: 3.046340225409949e-06\n",
      "Epoch 3188, Loss: 0.00020299894094932824, Final Batch Loss: 7.120447116903961e-05\n",
      "Epoch 3189, Loss: 0.02881584718124941, Final Batch Loss: 0.00014125212328508496\n",
      "Epoch 3190, Loss: 3.8694802242389414e-05, Final Batch Loss: 4.911457835987676e-06\n",
      "Epoch 3191, Loss: 0.00010509242201806046, Final Batch Loss: 7.712166552664712e-05\n",
      "Epoch 3192, Loss: 0.0007614371934323572, Final Batch Loss: 1.519699435448274e-05\n",
      "Epoch 3193, Loss: 0.0001722546949167736, Final Batch Loss: 6.842076982138678e-05\n",
      "Epoch 3194, Loss: 0.00013936694449512288, Final Batch Loss: 8.930877083912492e-05\n",
      "Epoch 3195, Loss: 0.0009178084874292836, Final Batch Loss: 0.00020108184253331274\n",
      "Epoch 3196, Loss: 1.3861615570931463e-05, Final Batch Loss: 8.327629984705709e-06\n",
      "Epoch 3197, Loss: 0.0001582435033924412, Final Batch Loss: 1.7272144759772345e-05\n",
      "Epoch 3198, Loss: 0.0001014876615954563, Final Batch Loss: 3.2491079764440656e-05\n",
      "Epoch 3199, Loss: 0.0003614904599089641, Final Batch Loss: 5.6425593356834725e-05\n",
      "Epoch 3200, Loss: 0.00014424724668060662, Final Batch Loss: 0.00013552622112911195\n",
      "Epoch 3201, Loss: 0.0009630319182178937, Final Batch Loss: 2.817980566760525e-05\n",
      "Epoch 3202, Loss: 0.00041120508103631437, Final Batch Loss: 0.0001888766564661637\n",
      "Epoch 3203, Loss: 1.2713484466075897e-05, Final Batch Loss: 6.649753231613431e-06\n",
      "Epoch 3204, Loss: 0.00040602622357255314, Final Batch Loss: 0.0003824557934422046\n",
      "Epoch 3205, Loss: 4.3512184674909804e-05, Final Batch Loss: 8.826126759231556e-06\n",
      "Epoch 3206, Loss: 0.00017406281403964385, Final Batch Loss: 7.318029383895919e-05\n",
      "Epoch 3207, Loss: 0.006546251439431217, Final Batch Loss: 2.03051240532659e-05\n",
      "Epoch 3208, Loss: 0.001163020613603294, Final Batch Loss: 0.0006488065118901432\n",
      "Epoch 3209, Loss: 8.748957770876586e-05, Final Batch Loss: 4.054573946632445e-05\n",
      "Epoch 3210, Loss: 0.00042864575516432524, Final Batch Loss: 0.0001488148991484195\n",
      "Epoch 3211, Loss: 0.0018853741930797696, Final Batch Loss: 0.0011263935593888164\n",
      "Epoch 3212, Loss: 0.0007524216780439019, Final Batch Loss: 0.00039508825284428895\n",
      "Epoch 3213, Loss: 0.005470835429150611, Final Batch Loss: 0.0004015456070192158\n",
      "Epoch 3214, Loss: 0.00016122117085615173, Final Batch Loss: 6.392838258761913e-05\n",
      "Epoch 3215, Loss: 0.007795388868544251, Final Batch Loss: 0.007661193609237671\n",
      "Epoch 3216, Loss: 0.006640035193413496, Final Batch Loss: 0.0012201042845845222\n",
      "Epoch 3217, Loss: 0.00012146523295086809, Final Batch Loss: 6.211044092196971e-05\n",
      "Epoch 3218, Loss: 0.0007936341571621597, Final Batch Loss: 0.0003938908048439771\n",
      "Epoch 3219, Loss: 0.03461675801372621, Final Batch Loss: 7.32735643396154e-05\n",
      "Epoch 3220, Loss: 0.0005350576611817814, Final Batch Loss: 0.0004635745717678219\n",
      "Epoch 3221, Loss: 0.009865013824310154, Final Batch Loss: 0.00966136809438467\n",
      "Epoch 3222, Loss: 0.0004677126562455669, Final Batch Loss: 0.00015758317022118717\n",
      "Epoch 3223, Loss: 0.0003116544830845669, Final Batch Loss: 5.2265459089539945e-05\n",
      "Epoch 3224, Loss: 0.0013279121194500476, Final Batch Loss: 0.00013877989840693772\n",
      "Epoch 3225, Loss: 0.10793369263410568, Final Batch Loss: 0.04974447563290596\n",
      "Epoch 3226, Loss: 0.0007748521747998893, Final Batch Loss: 0.00013744313037022948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3227, Loss: 0.0007157810614444315, Final Batch Loss: 0.00023193712695501745\n",
      "Epoch 3228, Loss: 0.0015390193511848338, Final Batch Loss: 0.0014664563350379467\n",
      "Epoch 3229, Loss: 0.007290928973816335, Final Batch Loss: 0.0006315357750281692\n",
      "Epoch 3230, Loss: 0.0057230081292800605, Final Batch Loss: 0.005370701663196087\n",
      "Epoch 3231, Loss: 0.0065753037051763386, Final Batch Loss: 0.00014992579235695302\n",
      "Epoch 3232, Loss: 0.0002046897825493943, Final Batch Loss: 3.3438362152082846e-05\n",
      "Epoch 3233, Loss: 0.0031429348164238036, Final Batch Loss: 0.000545112241525203\n",
      "Epoch 3234, Loss: 0.007823186868336052, Final Batch Loss: 0.0007609393796883523\n",
      "Epoch 3235, Loss: 0.004902252636384219, Final Batch Loss: 0.003957987297326326\n",
      "Epoch 3236, Loss: 0.00035820355697069317, Final Batch Loss: 0.00019233208149671555\n",
      "Epoch 3237, Loss: 0.002626848698128015, Final Batch Loss: 0.0008852121536619961\n",
      "Epoch 3238, Loss: 0.001012632652418688, Final Batch Loss: 3.664902760647237e-05\n",
      "Epoch 3239, Loss: 0.0007993157487362623, Final Batch Loss: 0.0006150653352960944\n",
      "Epoch 3240, Loss: 0.0008940009283833206, Final Batch Loss: 0.0007355526904575527\n",
      "Epoch 3241, Loss: 0.0012593294304679148, Final Batch Loss: 0.00011020927195204422\n",
      "Epoch 3242, Loss: 0.013666435159393586, Final Batch Loss: 0.013458415865898132\n",
      "Epoch 3243, Loss: 0.0031336217070929706, Final Batch Loss: 0.0006489678635261953\n",
      "Epoch 3244, Loss: 0.0036366366548463702, Final Batch Loss: 0.0013194129569455981\n",
      "Epoch 3245, Loss: 0.003556768409907818, Final Batch Loss: 0.0012698108330368996\n",
      "Epoch 3246, Loss: 0.0012517442955868319, Final Batch Loss: 0.0010928572155535221\n",
      "Epoch 3247, Loss: 0.0009672923188190907, Final Batch Loss: 0.0004860691842623055\n",
      "Epoch 3248, Loss: 0.000846370094222948, Final Batch Loss: 0.00045669381506741047\n",
      "Epoch 3249, Loss: 0.0007296300027519464, Final Batch Loss: 0.000290296709863469\n",
      "Epoch 3250, Loss: 0.00030375303322216496, Final Batch Loss: 0.00019711957429535687\n",
      "Epoch 3251, Loss: 0.005039342911913991, Final Batch Loss: 0.0004001359920948744\n",
      "Epoch 3252, Loss: 0.0014943985152058303, Final Batch Loss: 0.0008016924257390201\n",
      "Epoch 3253, Loss: 0.0006765044818166643, Final Batch Loss: 0.0002651434042491019\n",
      "Epoch 3254, Loss: 0.00016154516924871132, Final Batch Loss: 6.851385842310265e-05\n",
      "Epoch 3255, Loss: 0.002619024191517383, Final Batch Loss: 0.0022666603326797485\n",
      "Epoch 3256, Loss: 0.0008450658351648599, Final Batch Loss: 0.0005430015735328197\n",
      "Epoch 3257, Loss: 0.00021786589786643162, Final Batch Loss: 0.00011225261550862342\n",
      "Epoch 3258, Loss: 0.0004973912728019059, Final Batch Loss: 6.60747173242271e-05\n",
      "Epoch 3259, Loss: 0.01003064660471864, Final Batch Loss: 0.00023241693270392716\n",
      "Epoch 3260, Loss: 0.0004906710746581666, Final Batch Loss: 0.00038043668610043824\n",
      "Epoch 3261, Loss: 0.0061262738017831, Final Batch Loss: 0.005797453690320253\n",
      "Epoch 3262, Loss: 0.0005150645883986726, Final Batch Loss: 0.0002073746727546677\n",
      "Epoch 3263, Loss: 0.002146823004295584, Final Batch Loss: 3.0641349439974874e-05\n",
      "Epoch 3264, Loss: 0.0017496860236860812, Final Batch Loss: 0.0011359533527866006\n",
      "Epoch 3265, Loss: 0.0017940651523531415, Final Batch Loss: 8.350579446414486e-05\n",
      "Epoch 3266, Loss: 0.0024719917273614556, Final Batch Loss: 0.00021990170353092253\n",
      "Epoch 3267, Loss: 0.000938736367970705, Final Batch Loss: 0.000453427986940369\n",
      "Epoch 3268, Loss: 0.0007636996160726994, Final Batch Loss: 0.0002887464070226997\n",
      "Epoch 3269, Loss: 0.0034800166031345725, Final Batch Loss: 0.002361539052799344\n",
      "Epoch 3270, Loss: 0.0007393333944492042, Final Batch Loss: 0.0005387005512602627\n",
      "Epoch 3271, Loss: 0.0005696720909327269, Final Batch Loss: 0.00027852095081470907\n",
      "Epoch 3272, Loss: 0.0007176931576395873, Final Batch Loss: 3.51234084519092e-05\n",
      "Epoch 3273, Loss: 0.0007139630597521318, Final Batch Loss: 0.0006897098501212895\n",
      "Epoch 3274, Loss: 0.0001476893030485371, Final Batch Loss: 2.2898815586813726e-05\n",
      "Epoch 3275, Loss: 0.00018114986596629024, Final Batch Loss: 8.945923764258623e-05\n",
      "Epoch 3276, Loss: 0.003821667400188744, Final Batch Loss: 0.003252268536016345\n",
      "Epoch 3277, Loss: 0.0062249983311630785, Final Batch Loss: 0.0006111641996540129\n",
      "Epoch 3278, Loss: 0.000821803099825047, Final Batch Loss: 8.00577545305714e-05\n",
      "Epoch 3279, Loss: 0.0009803545544855297, Final Batch Loss: 0.00035248073982074857\n",
      "Epoch 3280, Loss: 0.0006295838684309274, Final Batch Loss: 0.00025793869281187654\n",
      "Epoch 3281, Loss: 0.0006907540955580771, Final Batch Loss: 0.00034583162050694227\n",
      "Epoch 3282, Loss: 0.00035822766221826896, Final Batch Loss: 0.00023660091392230242\n",
      "Epoch 3283, Loss: 0.0008493197965435684, Final Batch Loss: 0.0004154183261562139\n",
      "Epoch 3284, Loss: 0.0007829276728443801, Final Batch Loss: 0.0003131647245027125\n",
      "Epoch 3285, Loss: 0.000817201376776211, Final Batch Loss: 8.748301479499787e-05\n",
      "Epoch 3286, Loss: 0.00022797806741436943, Final Batch Loss: 0.00010197736992267892\n",
      "Epoch 3287, Loss: 0.0012491901288740337, Final Batch Loss: 0.0007788750226609409\n",
      "Epoch 3288, Loss: 0.0014420482912100852, Final Batch Loss: 0.00012893934035673738\n",
      "Epoch 3289, Loss: 0.0007408663295791484, Final Batch Loss: 8.844075637171045e-05\n",
      "Epoch 3290, Loss: 0.00036123864992987365, Final Batch Loss: 0.00012584416253957897\n",
      "Epoch 3291, Loss: 0.0009418358386028558, Final Batch Loss: 0.0007594073540531099\n",
      "Epoch 3292, Loss: 0.0008269009122159332, Final Batch Loss: 0.0004373787669464946\n",
      "Epoch 3293, Loss: 0.00017573229706613347, Final Batch Loss: 3.185211244272068e-05\n",
      "Epoch 3294, Loss: 0.00023027745373838115, Final Batch Loss: 0.00021215929882600904\n",
      "Epoch 3295, Loss: 0.000999184136162512, Final Batch Loss: 8.706118387635797e-05\n",
      "Epoch 3296, Loss: 0.001371690072119236, Final Batch Loss: 0.0009601892088539898\n",
      "Epoch 3297, Loss: 0.0013643328202306293, Final Batch Loss: 0.0012989757815375924\n",
      "Epoch 3298, Loss: 0.0021611210559058236, Final Batch Loss: 1.3723796655540355e-05\n",
      "Epoch 3299, Loss: 0.0008390565562876873, Final Batch Loss: 0.0008034548372961581\n",
      "Epoch 3300, Loss: 5.6441688684572e-05, Final Batch Loss: 4.420784171088599e-05\n",
      "Epoch 3301, Loss: 0.0021068001515232027, Final Batch Loss: 0.0012981474865227938\n",
      "Epoch 3302, Loss: 0.0005781036925327498, Final Batch Loss: 2.416233837720938e-05\n",
      "Epoch 3303, Loss: 0.00044552236795425415, Final Batch Loss: 0.00035451038274914026\n",
      "Epoch 3304, Loss: 0.000195891538169235, Final Batch Loss: 8.836194319883361e-05\n",
      "Epoch 3305, Loss: 0.0007075768808135763, Final Batch Loss: 0.00048040621913969517\n",
      "Epoch 3306, Loss: 0.00016245784718194045, Final Batch Loss: 0.0001409633841831237\n",
      "Epoch 3307, Loss: 0.00013741776456299704, Final Batch Loss: 1.6340503862011246e-05\n",
      "Epoch 3308, Loss: 0.007046548533253372, Final Batch Loss: 0.0004140393575653434\n",
      "Epoch 3309, Loss: 0.0010725051106419414, Final Batch Loss: 0.0009100873721763492\n",
      "Epoch 3310, Loss: 0.0005474791505548637, Final Batch Loss: 5.961123315501027e-05\n",
      "Epoch 3311, Loss: 0.0002955699819722213, Final Batch Loss: 0.00027022702852264047\n",
      "Epoch 3312, Loss: 0.001015833840938285, Final Batch Loss: 0.0006681469967588782\n",
      "Epoch 3313, Loss: 0.002782863735774299, Final Batch Loss: 4.5092016080161557e-05\n",
      "Epoch 3314, Loss: 0.004865715716732666, Final Batch Loss: 0.00021048678900115192\n",
      "Epoch 3315, Loss: 6.0431215388234705e-05, Final Batch Loss: 6.202888471307233e-06\n",
      "Epoch 3316, Loss: 0.0015024305612314492, Final Batch Loss: 0.001099993591196835\n",
      "Epoch 3317, Loss: 0.0009555981414450798, Final Batch Loss: 1.874787631095387e-05\n",
      "Epoch 3318, Loss: 7.026499224593863e-05, Final Batch Loss: 1.715452890493907e-05\n",
      "Epoch 3319, Loss: 0.0002905440214817645, Final Batch Loss: 0.0002656546712387353\n",
      "Epoch 3320, Loss: 0.00028546647808980197, Final Batch Loss: 0.00012258451897650957\n",
      "Epoch 3321, Loss: 8.526469264324987e-05, Final Batch Loss: 1.3990757906867657e-05\n",
      "Epoch 3322, Loss: 0.00035864897654391825, Final Batch Loss: 9.596216841600835e-05\n",
      "Epoch 3323, Loss: 0.00025490518601145595, Final Batch Loss: 0.0001061199582181871\n",
      "Epoch 3324, Loss: 0.00033905470991157927, Final Batch Loss: 4.537593122222461e-05\n",
      "Epoch 3325, Loss: 0.00040530928345106076, Final Batch Loss: 2.1594312784145586e-05\n",
      "Epoch 3326, Loss: 0.0034445658675394952, Final Batch Loss: 0.0031898696906864643\n",
      "Epoch 3327, Loss: 0.0008271753104054369, Final Batch Loss: 8.978285040939227e-05\n",
      "Epoch 3328, Loss: 6.57935515846475e-05, Final Batch Loss: 1.0322203706891742e-05\n",
      "Epoch 3329, Loss: 0.0012845374967582757, Final Batch Loss: 9.156539817922749e-06\n",
      "Epoch 3330, Loss: 0.0004027321010653395, Final Batch Loss: 5.3078507335158065e-05\n",
      "Epoch 3331, Loss: 6.811264029238373e-05, Final Batch Loss: 4.826733493246138e-05\n",
      "Epoch 3332, Loss: 7.937420468806522e-05, Final Batch Loss: 1.1320979865558911e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3333, Loss: 0.00018127087969332933, Final Batch Loss: 6.953762203920633e-05\n",
      "Epoch 3334, Loss: 0.0026283664192305878, Final Batch Loss: 0.002527015283703804\n",
      "Epoch 3335, Loss: 0.00018367336633673403, Final Batch Loss: 0.00015630087000317872\n",
      "Epoch 3336, Loss: 0.00030044039885979146, Final Batch Loss: 0.0002754676097538322\n",
      "Epoch 3337, Loss: 0.002785103155474644, Final Batch Loss: 0.002763650380074978\n",
      "Epoch 3338, Loss: 0.00030635228904429823, Final Batch Loss: 0.00014964304864406586\n",
      "Epoch 3339, Loss: 0.00018281777010997757, Final Batch Loss: 0.00012109286763006821\n",
      "Epoch 3340, Loss: 0.00037807841727044433, Final Batch Loss: 0.00028991122962906957\n",
      "Epoch 3341, Loss: 0.00020925456192344427, Final Batch Loss: 9.384217264596373e-05\n",
      "Epoch 3342, Loss: 5.52837173017906e-05, Final Batch Loss: 4.3837615521624684e-05\n",
      "Epoch 3343, Loss: 0.00017634679352340754, Final Batch Loss: 0.00015183365030679852\n",
      "Epoch 3344, Loss: 0.003012219225638546, Final Batch Loss: 0.00021367940644267946\n",
      "Epoch 3345, Loss: 0.002419500960968435, Final Batch Loss: 0.00042234628926962614\n",
      "Epoch 3346, Loss: 0.0012029914068989456, Final Batch Loss: 4.626618465408683e-05\n",
      "Epoch 3347, Loss: 0.0018415518243273254, Final Batch Loss: 5.2054845582460985e-05\n",
      "Epoch 3348, Loss: 0.0013296644574438687, Final Batch Loss: 0.0013058092445135117\n",
      "Epoch 3349, Loss: 4.857409112446476e-05, Final Batch Loss: 8.868339136824943e-06\n",
      "Epoch 3350, Loss: 0.00028990249029448023, Final Batch Loss: 0.0002787256380543113\n",
      "Epoch 3351, Loss: 0.00013054775718046585, Final Batch Loss: 9.865690117294434e-06\n",
      "Epoch 3352, Loss: 3.9528375054942444e-05, Final Batch Loss: 2.3127928216126747e-05\n",
      "Epoch 3353, Loss: 0.020191769985103747, Final Batch Loss: 0.020159900188446045\n",
      "Epoch 3354, Loss: 0.0001287227214561426, Final Batch Loss: 1.5083497601153795e-05\n",
      "Epoch 3355, Loss: 9.790334297576919e-05, Final Batch Loss: 6.085850691306405e-05\n",
      "Epoch 3356, Loss: 0.0013943607054898166, Final Batch Loss: 0.0013875254662707448\n",
      "Epoch 3357, Loss: 0.0002325471505173482, Final Batch Loss: 4.9008864152710885e-05\n",
      "Epoch 3358, Loss: 0.0014416479389183223, Final Batch Loss: 0.0005558778066188097\n",
      "Epoch 3359, Loss: 0.006472587010648567, Final Batch Loss: 0.006386850960552692\n",
      "Epoch 3360, Loss: 0.000680567929521203, Final Batch Loss: 0.0006095162243582308\n",
      "Epoch 3361, Loss: 0.00023048604634823278, Final Batch Loss: 0.00014357884356286377\n",
      "Epoch 3362, Loss: 0.00044201628043083474, Final Batch Loss: 0.00041167769813910127\n",
      "Epoch 3363, Loss: 0.0038962582575550186, Final Batch Loss: 0.003887488506734371\n",
      "Epoch 3364, Loss: 0.0007551346789114177, Final Batch Loss: 0.0004038372717332095\n",
      "Epoch 3365, Loss: 0.0012003890005871654, Final Batch Loss: 6.703299004584551e-05\n",
      "Epoch 3366, Loss: 0.0005974878658889793, Final Batch Loss: 0.00010453882714500651\n",
      "Epoch 3367, Loss: 0.013574667269494967, Final Batch Loss: 2.39117016462842e-05\n",
      "Epoch 3368, Loss: 0.00032303612533723935, Final Batch Loss: 0.00022514794545713812\n",
      "Epoch 3369, Loss: 0.0005878211522940546, Final Batch Loss: 0.00015790681936778128\n",
      "Epoch 3370, Loss: 0.0006053765100659803, Final Batch Loss: 0.0004054643795825541\n",
      "Epoch 3371, Loss: 0.00017606896835786756, Final Batch Loss: 1.7403412130079232e-05\n",
      "Epoch 3372, Loss: 0.0006260697409743443, Final Batch Loss: 0.00021094382100272924\n",
      "Epoch 3373, Loss: 0.0005047390623076353, Final Batch Loss: 4.316738704801537e-05\n",
      "Epoch 3374, Loss: 8.684118438395672e-05, Final Batch Loss: 3.746473521459848e-05\n",
      "Epoch 3375, Loss: 0.00010733612180047203, Final Batch Loss: 3.049221595574636e-05\n",
      "Epoch 3376, Loss: 0.000664544350001961, Final Batch Loss: 0.0003940191527362913\n",
      "Epoch 3377, Loss: 0.000136115984787466, Final Batch Loss: 3.631027720985003e-05\n",
      "Epoch 3378, Loss: 0.00040306951268576086, Final Batch Loss: 0.00024514071992598474\n",
      "Epoch 3379, Loss: 7.075324720062781e-05, Final Batch Loss: 2.2664922653348185e-05\n",
      "Epoch 3380, Loss: 0.000953332673816476, Final Batch Loss: 0.00011527070455485955\n",
      "Epoch 3381, Loss: 0.0032596558157820255, Final Batch Loss: 5.982656148262322e-05\n",
      "Epoch 3382, Loss: 0.00024178550665965304, Final Batch Loss: 0.000167881153174676\n",
      "Epoch 3383, Loss: 0.0004911638498015236, Final Batch Loss: 0.000464132142951712\n",
      "Epoch 3384, Loss: 0.0007304065575226559, Final Batch Loss: 1.0461436431796756e-05\n",
      "Epoch 3385, Loss: 0.003981875985118677, Final Batch Loss: 3.003681376867462e-05\n",
      "Epoch 3386, Loss: 0.001989414096897235, Final Batch Loss: 0.0019601399544626474\n",
      "Epoch 3387, Loss: 8.612452438683249e-05, Final Batch Loss: 2.746410245890729e-05\n",
      "Epoch 3388, Loss: 0.00010037789252237417, Final Batch Loss: 5.769365816377103e-05\n",
      "Epoch 3389, Loss: 0.00014860116061754525, Final Batch Loss: 0.00011007938883267343\n",
      "Epoch 3390, Loss: 0.0032490655103174504, Final Batch Loss: 4.725579856312834e-05\n",
      "Epoch 3391, Loss: 0.004052393054735148, Final Batch Loss: 0.004005512222647667\n",
      "Epoch 3392, Loss: 0.006343206303426996, Final Batch Loss: 0.006040041334927082\n",
      "Epoch 3393, Loss: 9.287190368922893e-05, Final Batch Loss: 1.799609344743658e-05\n",
      "Epoch 3394, Loss: 0.0005099931149743497, Final Batch Loss: 0.00010793772526085377\n",
      "Epoch 3395, Loss: 0.0015809345786692575, Final Batch Loss: 0.0013986860867589712\n",
      "Epoch 3396, Loss: 0.0007476559185306542, Final Batch Loss: 8.33243757369928e-05\n",
      "Epoch 3397, Loss: 0.0001908106278278865, Final Batch Loss: 0.00014081454719416797\n",
      "Epoch 3398, Loss: 0.0020585069578373805, Final Batch Loss: 0.0001737894635880366\n",
      "Epoch 3399, Loss: 0.0004881988243141677, Final Batch Loss: 1.59745650307741e-05\n",
      "Epoch 3400, Loss: 0.00029536163492593914, Final Batch Loss: 4.4245345634408295e-05\n",
      "Epoch 3401, Loss: 0.00030201101253624074, Final Batch Loss: 0.0002638658625073731\n",
      "Epoch 3402, Loss: 0.00010392691910965368, Final Batch Loss: 3.315435606054962e-05\n",
      "Epoch 3403, Loss: 0.0004364817177702207, Final Batch Loss: 0.00041015257011167705\n",
      "Epoch 3404, Loss: 0.00015415567577292677, Final Batch Loss: 9.462752132094465e-06\n",
      "Epoch 3405, Loss: 0.00015720959709142335, Final Batch Loss: 4.463396180653945e-06\n",
      "Epoch 3406, Loss: 0.0010125592816621065, Final Batch Loss: 0.0007329381187446415\n",
      "Epoch 3407, Loss: 3.6400948602022254e-05, Final Batch Loss: 2.486880703145289e-06\n",
      "Epoch 3408, Loss: 7.775384074193425e-05, Final Batch Loss: 2.3399854399031028e-05\n",
      "Epoch 3409, Loss: 0.00022185329589774483, Final Batch Loss: 6.451801255025202e-06\n",
      "Epoch 3410, Loss: 0.00019774161228269804, Final Batch Loss: 2.9027129130554385e-05\n",
      "Epoch 3411, Loss: 0.004149162603425793, Final Batch Loss: 0.0041311937384307384\n",
      "Epoch 3412, Loss: 0.0009065943595487624, Final Batch Loss: 0.0006202178774401546\n",
      "Epoch 3413, Loss: 0.0003420195571379736, Final Batch Loss: 0.00023316152510233223\n",
      "Epoch 3414, Loss: 8.02786980784731e-05, Final Batch Loss: 5.91507887293119e-05\n",
      "Epoch 3415, Loss: 0.0068322556326165795, Final Batch Loss: 0.006220842245966196\n",
      "Epoch 3416, Loss: 5.8441233704797924e-05, Final Batch Loss: 1.8258397176396102e-05\n",
      "Epoch 3417, Loss: 0.0004211651103105396, Final Batch Loss: 0.00016662254347465932\n",
      "Epoch 3418, Loss: 0.00011618363714660518, Final Batch Loss: 6.590460543520749e-05\n",
      "Epoch 3419, Loss: 7.012775085968315e-05, Final Batch Loss: 5.057253929408034e-06\n",
      "Epoch 3420, Loss: 2.5732651010912377e-05, Final Batch Loss: 1.445106045139255e-05\n",
      "Epoch 3421, Loss: 0.01431155379395932, Final Batch Loss: 0.01420732494443655\n",
      "Epoch 3422, Loss: 0.00035554929127101786, Final Batch Loss: 5.253921335679479e-05\n",
      "Epoch 3423, Loss: 0.0028234105848241597, Final Batch Loss: 0.002524595707654953\n",
      "Epoch 3424, Loss: 0.0021367665322031826, Final Batch Loss: 0.0018296621274203062\n",
      "Epoch 3425, Loss: 0.0001824594073696062, Final Batch Loss: 6.364793807733804e-05\n",
      "Epoch 3426, Loss: 0.0015995786307030357, Final Batch Loss: 0.0014820778742432594\n",
      "Epoch 3427, Loss: 0.002789231133647263, Final Batch Loss: 0.0017445683479309082\n",
      "Epoch 3428, Loss: 0.00033005086152115837, Final Batch Loss: 0.00021399062825366855\n",
      "Epoch 3429, Loss: 0.0005926150870436686, Final Batch Loss: 8.046200491662603e-06\n",
      "Epoch 3430, Loss: 0.0003338694250487606, Final Batch Loss: 1.3745567230216693e-05\n",
      "Epoch 3431, Loss: 0.0002702252386370674, Final Batch Loss: 6.297742947936058e-05\n",
      "Epoch 3432, Loss: 0.0018950811681861524, Final Batch Loss: 0.0018632843857631087\n",
      "Epoch 3433, Loss: 0.004141954210354015, Final Batch Loss: 0.0001707682095002383\n",
      "Epoch 3434, Loss: 0.0004998121876269579, Final Batch Loss: 0.00032840727362781763\n",
      "Epoch 3435, Loss: 0.0005672616061929148, Final Batch Loss: 0.000543633010238409\n",
      "Epoch 3436, Loss: 7.641683441761415e-05, Final Batch Loss: 4.9404148739995435e-05\n",
      "Epoch 3437, Loss: 0.001418816187651828, Final Batch Loss: 0.0011260147439315915\n",
      "Epoch 3438, Loss: 0.0001163272318080999, Final Batch Loss: 6.505462806671858e-05\n",
      "Epoch 3439, Loss: 0.00015306490240618587, Final Batch Loss: 5.071248597232625e-05\n",
      "Epoch 3440, Loss: 0.00010552755156822968, Final Batch Loss: 1.9564353351597674e-05\n",
      "Epoch 3441, Loss: 3.261387610109523e-05, Final Batch Loss: 2.077329372696113e-05\n",
      "Epoch 3442, Loss: 0.00027301249429001473, Final Batch Loss: 0.00022064015502110124\n",
      "Epoch 3443, Loss: 0.0005878283409401774, Final Batch Loss: 0.00034237882937304676\n",
      "Epoch 3444, Loss: 9.07514950085897e-05, Final Batch Loss: 2.4994606064865366e-05\n",
      "Epoch 3445, Loss: 0.0003067846610065317, Final Batch Loss: 0.0002869452291633934\n",
      "Epoch 3446, Loss: 0.017584009141501156, Final Batch Loss: 1.5134037312236615e-05\n",
      "Epoch 3447, Loss: 0.017825109942350537, Final Batch Loss: 8.022977272048593e-05\n",
      "Epoch 3448, Loss: 0.005370339495129883, Final Batch Loss: 0.004811778664588928\n",
      "Epoch 3449, Loss: 0.00018063396419165656, Final Batch Loss: 0.00015599429025314748\n",
      "Epoch 3450, Loss: 0.0008115034725051373, Final Batch Loss: 0.000342304672813043\n",
      "Epoch 3451, Loss: 0.0005391400918597355, Final Batch Loss: 0.0001643778959987685\n",
      "Epoch 3452, Loss: 0.0014683475892525166, Final Batch Loss: 8.973790681920946e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3453, Loss: 0.00010628295058268122, Final Batch Loss: 6.31232323939912e-05\n",
      "Epoch 3454, Loss: 0.00044691267248708755, Final Batch Loss: 0.00035966458381153643\n",
      "Epoch 3455, Loss: 0.0005614067922579125, Final Batch Loss: 0.00016159452206920832\n",
      "Epoch 3456, Loss: 0.0005640077433781698, Final Batch Loss: 0.0005024002166464925\n",
      "Epoch 3457, Loss: 0.001925850696352427, Final Batch Loss: 1.949764737219084e-05\n",
      "Epoch 3458, Loss: 0.0011923101287720783, Final Batch Loss: 7.214143352030078e-06\n",
      "Epoch 3459, Loss: 0.00036532188823912293, Final Batch Loss: 1.1833981261588633e-05\n",
      "Epoch 3460, Loss: 0.002364106709137559, Final Batch Loss: 0.001693936064839363\n",
      "Epoch 3461, Loss: 0.0005232677212916315, Final Batch Loss: 0.00034018640872091055\n",
      "Epoch 3462, Loss: 0.001210566028021276, Final Batch Loss: 0.0006218218477442861\n",
      "Epoch 3463, Loss: 0.00024596062576165423, Final Batch Loss: 6.882347952341661e-05\n",
      "Epoch 3464, Loss: 0.00021700792194678797, Final Batch Loss: 7.514242952311179e-06\n",
      "Epoch 3465, Loss: 0.00026430947036715224, Final Batch Loss: 3.7258600059431046e-05\n",
      "Epoch 3466, Loss: 8.439008524874225e-05, Final Batch Loss: 1.5017816622275859e-05\n",
      "Epoch 3467, Loss: 0.00016208489614655264, Final Batch Loss: 0.00014301140618044883\n",
      "Epoch 3468, Loss: 4.161537617619615e-05, Final Batch Loss: 2.1319247025530785e-05\n",
      "Epoch 3469, Loss: 7.377142537734471e-05, Final Batch Loss: 8.922168490244076e-06\n",
      "Epoch 3470, Loss: 0.0001771844326867722, Final Batch Loss: 1.112354948418215e-05\n",
      "Epoch 3471, Loss: 7.457894207618665e-05, Final Batch Loss: 1.4335879313875921e-05\n",
      "Epoch 3472, Loss: 0.0003464607580099255, Final Batch Loss: 0.00016750811482779682\n",
      "Epoch 3473, Loss: 1.970353514479939e-05, Final Batch Loss: 1.3539535757445265e-05\n",
      "Epoch 3474, Loss: 0.0007898007170297205, Final Batch Loss: 0.0005521697457879782\n",
      "Epoch 3475, Loss: 7.678617112105712e-05, Final Batch Loss: 1.650232297834009e-05\n",
      "Epoch 3476, Loss: 0.00408567887643585, Final Batch Loss: 1.7300051695201546e-05\n",
      "Epoch 3477, Loss: 0.00012845465607824735, Final Batch Loss: 8.288793469546363e-05\n",
      "Epoch 3478, Loss: 0.0009395740344189107, Final Batch Loss: 0.00020968698663637042\n",
      "Epoch 3479, Loss: 0.0016150590554389055, Final Batch Loss: 1.0561506314843427e-05\n",
      "Epoch 3480, Loss: 4.978452852810733e-05, Final Batch Loss: 1.1497275409055874e-05\n",
      "Epoch 3481, Loss: 0.0007229017137433402, Final Batch Loss: 0.000690459506586194\n",
      "Epoch 3482, Loss: 0.00022308660845737904, Final Batch Loss: 0.00016082229558378458\n",
      "Epoch 3483, Loss: 0.002771325991488993, Final Batch Loss: 0.001604612567462027\n",
      "Epoch 3484, Loss: 3.2104539286592626e-05, Final Batch Loss: 2.8450542686186964e-06\n",
      "Epoch 3485, Loss: 5.501502164406702e-05, Final Batch Loss: 2.796906301227864e-05\n",
      "Epoch 3486, Loss: 0.0006392636441887589, Final Batch Loss: 2.1171743355807848e-05\n",
      "Epoch 3487, Loss: 0.001660680674831383, Final Batch Loss: 0.00022349767095874995\n",
      "Epoch 3488, Loss: 3.3364685805281624e-05, Final Batch Loss: 1.448659531888552e-05\n",
      "Epoch 3489, Loss: 0.0006392467839759775, Final Batch Loss: 1.4682016626466066e-05\n",
      "Epoch 3490, Loss: 0.00015069805613165954, Final Batch Loss: 0.00014044073759578168\n",
      "Epoch 3491, Loss: 4.0031973185250536e-05, Final Batch Loss: 1.989471093111206e-05\n",
      "Epoch 3492, Loss: 0.0007871712987252977, Final Batch Loss: 2.014479468925856e-05\n",
      "Epoch 3493, Loss: 0.00022974038438405842, Final Batch Loss: 0.00012379174586385489\n",
      "Epoch 3494, Loss: 1.9888738279405516e-05, Final Batch Loss: 7.87190583650954e-06\n",
      "Epoch 3495, Loss: 9.652755034039728e-05, Final Batch Loss: 3.67354805348441e-05\n",
      "Epoch 3496, Loss: 0.0005966277967672795, Final Batch Loss: 0.00015348871238529682\n",
      "Epoch 3497, Loss: 0.00018322486721444875, Final Batch Loss: 0.00011413772881496698\n",
      "Epoch 3498, Loss: 0.01650960610822949, Final Batch Loss: 0.016501644626259804\n",
      "Epoch 3499, Loss: 0.001905766810523346, Final Batch Loss: 0.00021110396482981741\n",
      "Epoch 3500, Loss: 0.00016203242194023915, Final Batch Loss: 0.00012055492697982118\n",
      "Epoch 3501, Loss: 0.0031448849040316418, Final Batch Loss: 9.814692020881921e-05\n",
      "Epoch 3502, Loss: 0.0016837633011164144, Final Batch Loss: 0.0014417986385524273\n",
      "Epoch 3503, Loss: 0.0004362988256616518, Final Batch Loss: 0.0003346340381540358\n",
      "Epoch 3504, Loss: 0.0004803523261216469, Final Batch Loss: 6.958773155929521e-05\n",
      "Epoch 3505, Loss: 0.016264426230918616, Final Batch Loss: 0.016156913712620735\n",
      "Epoch 3506, Loss: 0.0009860384307103232, Final Batch Loss: 0.000809751742053777\n",
      "Epoch 3507, Loss: 0.0002823853719746694, Final Batch Loss: 0.00018609967082738876\n",
      "Epoch 3508, Loss: 0.0009971751787816174, Final Batch Loss: 6.79064032738097e-05\n",
      "Epoch 3509, Loss: 0.00010037157699116506, Final Batch Loss: 2.5463948986725882e-05\n",
      "Epoch 3510, Loss: 0.00011060456381528638, Final Batch Loss: 5.328668703441508e-05\n",
      "Epoch 3511, Loss: 0.0003813297298620455, Final Batch Loss: 0.0003260932571720332\n",
      "Epoch 3512, Loss: 9.730108649819158e-05, Final Batch Loss: 3.88652115361765e-05\n",
      "Epoch 3513, Loss: 0.0018846970160666388, Final Batch Loss: 0.0018256738549098372\n",
      "Epoch 3514, Loss: 0.00029824028024449944, Final Batch Loss: 7.19090603524819e-05\n",
      "Epoch 3515, Loss: 0.0008570105437684106, Final Batch Loss: 0.000833942205645144\n",
      "Epoch 3516, Loss: 9.453925304114819e-05, Final Batch Loss: 1.4305296645034105e-05\n",
      "Epoch 3517, Loss: 0.0005936661982559599, Final Batch Loss: 0.000522994960192591\n",
      "Epoch 3518, Loss: 0.0002927107898358372, Final Batch Loss: 6.833758561697323e-06\n",
      "Epoch 3519, Loss: 0.01800278393056942, Final Batch Loss: 7.843231287552044e-05\n",
      "Epoch 3520, Loss: 0.00010501919314265251, Final Batch Loss: 5.35620201844722e-05\n",
      "Epoch 3521, Loss: 0.0002706700761336833, Final Batch Loss: 7.746832852717489e-05\n",
      "Epoch 3522, Loss: 0.0003024491234100424, Final Batch Loss: 0.00020796865283045918\n",
      "Epoch 3523, Loss: 0.00017828693671617657, Final Batch Loss: 0.00011274038843112066\n",
      "Epoch 3524, Loss: 0.000346784927387489, Final Batch Loss: 0.00030537863494828343\n",
      "Epoch 3525, Loss: 0.0001670852175266191, Final Batch Loss: 5.884266556677176e-06\n",
      "Epoch 3526, Loss: 8.907973096938804e-05, Final Batch Loss: 1.896054163808003e-05\n",
      "Epoch 3527, Loss: 0.0002732008942984976, Final Batch Loss: 0.00020302986376918852\n",
      "Epoch 3528, Loss: 0.001512004073447315, Final Batch Loss: 1.9393406546441838e-05\n",
      "Epoch 3529, Loss: 0.000128781972307479, Final Batch Loss: 8.064100256888196e-05\n",
      "Epoch 3530, Loss: 0.0002628715283208294, Final Batch Loss: 2.3294325728784315e-05\n",
      "Epoch 3531, Loss: 0.00020686105563072488, Final Batch Loss: 0.00012375702499412\n",
      "Epoch 3532, Loss: 0.00036480973358266056, Final Batch Loss: 0.00022482698841486126\n",
      "Epoch 3533, Loss: 0.003790311424381798, Final Batch Loss: 0.003780934028327465\n",
      "Epoch 3534, Loss: 0.00015858260303502902, Final Batch Loss: 3.159953485010192e-05\n",
      "Epoch 3535, Loss: 2.4635544832563028e-05, Final Batch Loss: 1.1345414350216743e-05\n",
      "Epoch 3536, Loss: 0.0001147413786384277, Final Batch Loss: 2.4425782612524927e-05\n",
      "Epoch 3537, Loss: 0.0005963223538856255, Final Batch Loss: 1.5584695574943908e-05\n",
      "Epoch 3538, Loss: 4.788435126101831e-05, Final Batch Loss: 7.316580195038114e-06\n",
      "Epoch 3539, Loss: 0.012703664797300007, Final Batch Loss: 0.012642165645956993\n",
      "Epoch 3540, Loss: 0.0009561461920384318, Final Batch Loss: 0.0006468367646448314\n",
      "Epoch 3541, Loss: 0.0005095692322356626, Final Batch Loss: 2.6764042559079826e-05\n",
      "Epoch 3542, Loss: 0.0006998814933467656, Final Batch Loss: 3.1972856959328055e-05\n",
      "Epoch 3543, Loss: 0.0006323669804260135, Final Batch Loss: 0.0002163690805900842\n",
      "Epoch 3544, Loss: 0.00011360229291312862, Final Batch Loss: 9.722990944283083e-05\n",
      "Epoch 3545, Loss: 0.00018739173174253665, Final Batch Loss: 3.538422970450483e-05\n",
      "Epoch 3546, Loss: 0.005064113460321096, Final Batch Loss: 0.0050363182090222836\n",
      "Epoch 3547, Loss: 0.00012386037997202948, Final Batch Loss: 6.226256664376706e-05\n",
      "Epoch 3548, Loss: 0.00010421536535432097, Final Batch Loss: 2.118092197633814e-05\n",
      "Epoch 3549, Loss: 0.0003574473084881902, Final Batch Loss: 0.00014047666627448052\n",
      "Epoch 3550, Loss: 0.007825385226169601, Final Batch Loss: 0.00046385303721763194\n",
      "Epoch 3551, Loss: 9.456914267502725e-05, Final Batch Loss: 5.201164458412677e-05\n",
      "Epoch 3552, Loss: 0.001980854314751923, Final Batch Loss: 0.000799718196503818\n",
      "Epoch 3553, Loss: 0.0003862705489154905, Final Batch Loss: 2.2453226847574115e-05\n",
      "Epoch 3554, Loss: 8.180575059668627e-05, Final Batch Loss: 5.64577458135318e-05\n",
      "Epoch 3555, Loss: 0.0006563274182553869, Final Batch Loss: 0.0006262390525080264\n",
      "Epoch 3556, Loss: 5.7425431805313565e-05, Final Batch Loss: 1.7886059140437283e-05\n",
      "Epoch 3557, Loss: 0.0010916773462668061, Final Batch Loss: 0.000860036292579025\n",
      "Epoch 3558, Loss: 0.0001846946652221959, Final Batch Loss: 0.0001641592098167166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3559, Loss: 0.00012148390669608489, Final Batch Loss: 7.369466766249388e-05\n",
      "Epoch 3560, Loss: 0.00020141435379628092, Final Batch Loss: 7.128423021640629e-05\n",
      "Epoch 3561, Loss: 6.244313681236235e-05, Final Batch Loss: 1.114707538363291e-05\n",
      "Epoch 3562, Loss: 0.00023698634322499856, Final Batch Loss: 4.7974383051041514e-05\n",
      "Epoch 3563, Loss: 0.003799238613282796, Final Batch Loss: 7.166215073084459e-05\n",
      "Epoch 3564, Loss: 0.0002480973198544234, Final Batch Loss: 8.540434646420181e-05\n",
      "Epoch 3565, Loss: 0.0002888083108700812, Final Batch Loss: 4.5364053221419454e-05\n",
      "Epoch 3566, Loss: 0.00011050049397454131, Final Batch Loss: 1.8894579625339247e-05\n",
      "Epoch 3567, Loss: 0.00014357022519106977, Final Batch Loss: 4.901300781057216e-05\n",
      "Epoch 3568, Loss: 0.00016428017488578917, Final Batch Loss: 0.00016026015509851277\n",
      "Epoch 3569, Loss: 0.0005420840461738408, Final Batch Loss: 0.00021914680837653577\n",
      "Epoch 3570, Loss: 0.020527318076347, Final Batch Loss: 0.02041289210319519\n",
      "Epoch 3571, Loss: 0.0003093911709584063, Final Batch Loss: 2.8087981263524853e-05\n",
      "Epoch 3572, Loss: 0.00020116987980145495, Final Batch Loss: 1.5991679902072065e-05\n",
      "Epoch 3573, Loss: 0.0021273150778142735, Final Batch Loss: 0.00010583332914393395\n",
      "Epoch 3574, Loss: 0.002073011164611671, Final Batch Loss: 6.628226401517168e-05\n",
      "Epoch 3575, Loss: 0.000121432665764587, Final Batch Loss: 1.216313467011787e-05\n",
      "Epoch 3576, Loss: 0.00014807423576712608, Final Batch Loss: 0.00011310545960441232\n",
      "Epoch 3577, Loss: 0.0013219621469033882, Final Batch Loss: 0.00014480848039966077\n",
      "Epoch 3578, Loss: 0.0001404250942869112, Final Batch Loss: 5.0437331083230674e-05\n",
      "Epoch 3579, Loss: 0.0018138203995476943, Final Batch Loss: 3.420289067435078e-05\n",
      "Epoch 3580, Loss: 0.0004189113460597582, Final Batch Loss: 9.320962271885946e-05\n",
      "Epoch 3581, Loss: 0.0001406077717547305, Final Batch Loss: 6.393263902282342e-05\n",
      "Epoch 3582, Loss: 0.00032951719185803086, Final Batch Loss: 0.00013375497655943036\n",
      "Epoch 3583, Loss: 0.000501872505992651, Final Batch Loss: 0.0002569021889939904\n",
      "Epoch 3584, Loss: 0.001450218420359306, Final Batch Loss: 0.0001594225614098832\n",
      "Epoch 3585, Loss: 0.0005765124642493902, Final Batch Loss: 2.0082208720850758e-05\n",
      "Epoch 3586, Loss: 0.0007757457351544872, Final Batch Loss: 0.0006488044164143503\n",
      "Epoch 3587, Loss: 0.0018937000131700188, Final Batch Loss: 0.00047756839194335043\n",
      "Epoch 3588, Loss: 0.000443600642029196, Final Batch Loss: 0.00027483078883960843\n",
      "Epoch 3589, Loss: 0.00313999829813838, Final Batch Loss: 0.001232550130225718\n",
      "Epoch 3590, Loss: 0.011823930850368924, Final Batch Loss: 0.00015072531823534518\n",
      "Epoch 3591, Loss: 0.0042299624474253505, Final Batch Loss: 7.678670226596296e-05\n",
      "Epoch 3592, Loss: 6.403384577424731e-05, Final Batch Loss: 2.3304399292101152e-05\n",
      "Epoch 3593, Loss: 9.021531332109589e-05, Final Batch Loss: 6.274611223489046e-05\n",
      "Epoch 3594, Loss: 0.00028141339134890586, Final Batch Loss: 0.00011265983630437404\n",
      "Epoch 3595, Loss: 7.915728565421887e-05, Final Batch Loss: 5.753001823904924e-05\n",
      "Epoch 3596, Loss: 0.00026643837554729544, Final Batch Loss: 4.3608550186036155e-05\n",
      "Epoch 3597, Loss: 0.0018049593782052398, Final Batch Loss: 0.0013204680290073156\n",
      "Epoch 3598, Loss: 0.0014194165341905318, Final Batch Loss: 0.0013901395723223686\n",
      "Epoch 3599, Loss: 2.157856624762644e-05, Final Batch Loss: 6.565469902852783e-06\n",
      "Epoch 3600, Loss: 6.368856793415034e-05, Final Batch Loss: 5.7261702750111e-05\n",
      "Epoch 3601, Loss: 0.0008541762654203922, Final Batch Loss: 0.0003587886749301106\n",
      "Epoch 3602, Loss: 5.58898145754938e-05, Final Batch Loss: 1.1415963854233269e-05\n",
      "Epoch 3603, Loss: 0.0002824501061695628, Final Batch Loss: 7.232843927340582e-05\n",
      "Epoch 3604, Loss: 0.0010101179068442434, Final Batch Loss: 0.0006794296205043793\n",
      "Epoch 3605, Loss: 0.0010212717825197615, Final Batch Loss: 9.006038453662768e-05\n",
      "Epoch 3606, Loss: 0.00011924834689125419, Final Batch Loss: 6.669323920505121e-05\n",
      "Epoch 3607, Loss: 9.942301221599337e-05, Final Batch Loss: 1.9690027329488657e-05\n",
      "Epoch 3608, Loss: 0.00014684243069496006, Final Batch Loss: 9.348355524707586e-05\n",
      "Epoch 3609, Loss: 0.00023905346915853443, Final Batch Loss: 0.00023019003856461495\n",
      "Epoch 3610, Loss: 0.00022266897394729313, Final Batch Loss: 0.00019883735512848943\n",
      "Epoch 3611, Loss: 0.000121574868899188, Final Batch Loss: 2.113890332111623e-05\n",
      "Epoch 3612, Loss: 0.0002488189929863438, Final Batch Loss: 0.00010082047083415091\n",
      "Epoch 3613, Loss: 7.218188147817273e-05, Final Batch Loss: 2.2742804503650405e-05\n",
      "Epoch 3614, Loss: 0.0005079569345980417, Final Batch Loss: 5.468174276757054e-05\n",
      "Epoch 3615, Loss: 0.0005534052788789268, Final Batch Loss: 1.3273983313411009e-05\n",
      "Epoch 3616, Loss: 0.0006613302684854716, Final Batch Loss: 0.0003229250432923436\n",
      "Epoch 3617, Loss: 1.7833905531006167e-05, Final Batch Loss: 7.418307632178767e-06\n",
      "Epoch 3618, Loss: 0.00019559301836125087, Final Batch Loss: 1.6652191334287636e-05\n",
      "Epoch 3619, Loss: 4.2948721784341615e-05, Final Batch Loss: 1.1532762982824352e-05\n",
      "Epoch 3620, Loss: 0.00016187222172447946, Final Batch Loss: 0.00015596792218275368\n",
      "Epoch 3621, Loss: 0.00032737002766225487, Final Batch Loss: 0.00018082387396134436\n",
      "Epoch 3622, Loss: 0.00020592842520272825, Final Batch Loss: 2.3588678232044913e-05\n",
      "Epoch 3623, Loss: 0.00019828027143375948, Final Batch Loss: 0.00010406953515484929\n",
      "Epoch 3624, Loss: 4.9048929213313386e-05, Final Batch Loss: 4.037352482555434e-06\n",
      "Epoch 3625, Loss: 0.0001284773024963215, Final Batch Loss: 9.710899757919833e-05\n",
      "Epoch 3626, Loss: 0.0006003955350024626, Final Batch Loss: 0.00017825399118009955\n",
      "Epoch 3627, Loss: 0.0003556713636498898, Final Batch Loss: 0.00017498544184491038\n",
      "Epoch 3628, Loss: 0.00013678534469363512, Final Batch Loss: 1.0007254786614794e-05\n",
      "Epoch 3629, Loss: 2.3564329239889048e-05, Final Batch Loss: 1.3023280189372599e-05\n",
      "Epoch 3630, Loss: 2.087348639179254e-05, Final Batch Loss: 8.027179319469724e-06\n",
      "Epoch 3631, Loss: 4.4650033487414476e-05, Final Batch Loss: 4.836586413148325e-06\n",
      "Epoch 3632, Loss: 0.0006030231024851673, Final Batch Loss: 0.0005952319479547441\n",
      "Epoch 3633, Loss: 0.001759893153575831, Final Batch Loss: 8.370969226234592e-06\n",
      "Epoch 3634, Loss: 0.00014012312749400735, Final Batch Loss: 4.831676778849214e-05\n",
      "Epoch 3635, Loss: 0.00015985948448360432, Final Batch Loss: 0.00014920368266757578\n",
      "Epoch 3636, Loss: 4.859227738052141e-05, Final Batch Loss: 2.5802806703723036e-05\n",
      "Epoch 3637, Loss: 2.212193612649571e-05, Final Batch Loss: 5.72213320992887e-06\n",
      "Epoch 3638, Loss: 5.0593043852131814e-05, Final Batch Loss: 1.9466089725028723e-05\n",
      "Epoch 3639, Loss: 0.00022761614673072472, Final Batch Loss: 0.0002070197369903326\n",
      "Epoch 3640, Loss: 0.00011426421042415313, Final Batch Loss: 7.807565270923078e-05\n",
      "Epoch 3641, Loss: 3.563499467418296e-05, Final Batch Loss: 1.2580040674947668e-05\n",
      "Epoch 3642, Loss: 0.0004410011738400499, Final Batch Loss: 5.161068202141905e-06\n",
      "Epoch 3643, Loss: 0.00013678330651600845, Final Batch Loss: 3.327824015286751e-05\n",
      "Epoch 3644, Loss: 1.2960703998032841e-05, Final Batch Loss: 2.5511315016046865e-06\n",
      "Epoch 3645, Loss: 0.00020227095228619874, Final Batch Loss: 6.915739504620433e-05\n",
      "Epoch 3646, Loss: 0.00023943141559357173, Final Batch Loss: 4.516137323662406e-06\n",
      "Epoch 3647, Loss: 0.0002769674210867379, Final Batch Loss: 4.9447178753325716e-05\n",
      "Epoch 3648, Loss: 0.0016358363500330597, Final Batch Loss: 0.0003296137147117406\n",
      "Epoch 3649, Loss: 6.543586277985014e-05, Final Batch Loss: 2.3373504518531263e-05\n",
      "Epoch 3650, Loss: 0.00015108012303244323, Final Batch Loss: 6.372792995534837e-05\n",
      "Epoch 3651, Loss: 0.0005652886975440197, Final Batch Loss: 0.00011918690142920241\n",
      "Epoch 3652, Loss: 9.779931292541733e-05, Final Batch Loss: 9.561268234392628e-05\n",
      "Epoch 3653, Loss: 0.00025856165893856087, Final Batch Loss: 4.931351668346906e-06\n",
      "Epoch 3654, Loss: 0.00048740279089543037, Final Batch Loss: 0.0004356159770395607\n",
      "Epoch 3655, Loss: 3.3841941331047565e-05, Final Batch Loss: 1.5170900951488875e-05\n",
      "Epoch 3656, Loss: 0.0005591979206656106, Final Batch Loss: 3.181299689458683e-05\n",
      "Epoch 3657, Loss: 0.0004116093332413584, Final Batch Loss: 0.0001858985488070175\n",
      "Epoch 3658, Loss: 0.0009425278399248782, Final Batch Loss: 5.279958259052364e-06\n",
      "Epoch 3659, Loss: 0.002400865669187624, Final Batch Loss: 3.371120692463592e-05\n",
      "Epoch 3660, Loss: 7.585133153042989e-05, Final Batch Loss: 8.009364137251396e-06\n",
      "Epoch 3661, Loss: 0.0005693732200597879, Final Batch Loss: 0.0005307327373884618\n",
      "Epoch 3662, Loss: 2.2434635411627823e-05, Final Batch Loss: 4.65749917566427e-06\n",
      "Epoch 3663, Loss: 0.0003244474792154506, Final Batch Loss: 0.0002615795820020139\n",
      "Epoch 3664, Loss: 9.693935044197133e-05, Final Batch Loss: 1.1977687790931668e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3665, Loss: 0.0012429569032974541, Final Batch Loss: 0.0006710985326208174\n",
      "Epoch 3666, Loss: 0.0010061689026770182, Final Batch Loss: 0.0009927580831572413\n",
      "Epoch 3667, Loss: 0.0001459812410757877, Final Batch Loss: 4.984973929822445e-05\n",
      "Epoch 3668, Loss: 6.513742846436799e-05, Final Batch Loss: 4.286512194084935e-05\n",
      "Epoch 3669, Loss: 0.0005631458370771725, Final Batch Loss: 4.176916627329774e-05\n",
      "Epoch 3670, Loss: 4.2433967792021576e-05, Final Batch Loss: 2.8579766876646318e-05\n",
      "Epoch 3671, Loss: 6.828467030572938e-05, Final Batch Loss: 1.2917063031636644e-05\n",
      "Epoch 3672, Loss: 9.2243628387223e-05, Final Batch Loss: 6.631702854065225e-05\n",
      "Epoch 3673, Loss: 3.666727388917934e-05, Final Batch Loss: 1.5488889403059147e-05\n",
      "Epoch 3674, Loss: 0.0001715283069643192, Final Batch Loss: 0.00011453165643615648\n",
      "Epoch 3675, Loss: 0.002792995697745937, Final Batch Loss: 0.002773753134533763\n",
      "Epoch 3676, Loss: 0.00020706729992525652, Final Batch Loss: 0.00019295391393825412\n",
      "Epoch 3677, Loss: 0.00021739058365710662, Final Batch Loss: 0.00021177415328565985\n",
      "Epoch 3678, Loss: 0.00015914011692075292, Final Batch Loss: 0.00014975457452237606\n",
      "Epoch 3679, Loss: 0.0010353417019359767, Final Batch Loss: 0.0010180112440139055\n",
      "Epoch 3680, Loss: 0.001143640372902155, Final Batch Loss: 0.0009890131186693907\n",
      "Epoch 3681, Loss: 5.838814900016587e-06, Final Batch Loss: 1.8901299654316972e-06\n",
      "Epoch 3682, Loss: 0.00032557959411860793, Final Batch Loss: 5.551167760131648e-06\n",
      "Epoch 3683, Loss: 0.0043142422482560505, Final Batch Loss: 7.937979717098642e-06\n",
      "Epoch 3684, Loss: 7.139322224247735e-05, Final Batch Loss: 1.869279185484629e-05\n",
      "Epoch 3685, Loss: 0.00012890499056084082, Final Batch Loss: 5.703305214410648e-05\n",
      "Epoch 3686, Loss: 9.9013250292046e-05, Final Batch Loss: 6.778864189982414e-05\n",
      "Epoch 3687, Loss: 3.872421075357124e-05, Final Batch Loss: 8.060877007665113e-06\n",
      "Epoch 3688, Loss: 0.0009644220044719987, Final Batch Loss: 0.0008905430440790951\n",
      "Epoch 3689, Loss: 0.00033222696220036596, Final Batch Loss: 0.0002675499417819083\n",
      "Epoch 3690, Loss: 0.00010731025940913241, Final Batch Loss: 9.563643106957898e-05\n",
      "Epoch 3691, Loss: 8.294853478219011e-05, Final Batch Loss: 7.760390872135758e-05\n",
      "Epoch 3692, Loss: 0.0019126187253277749, Final Batch Loss: 0.00023661888553760946\n",
      "Epoch 3693, Loss: 4.742485089082038e-05, Final Batch Loss: 1.1621358680713456e-05\n",
      "Epoch 3694, Loss: 0.0004157886141911149, Final Batch Loss: 0.0002354072785237804\n",
      "Epoch 3695, Loss: 3.51506996594253e-05, Final Batch Loss: 1.3132083950040396e-05\n",
      "Epoch 3696, Loss: 0.0001339534765065764, Final Batch Loss: 0.00013155753549654037\n",
      "Epoch 3697, Loss: 3.417112088754948e-05, Final Batch Loss: 3.4475021948310314e-06\n",
      "Epoch 3698, Loss: 0.00010941859727608971, Final Batch Loss: 8.673578122397885e-06\n",
      "Epoch 3699, Loss: 0.0005466856964631006, Final Batch Loss: 0.0003972328267991543\n",
      "Epoch 3700, Loss: 0.0022172351909830468, Final Batch Loss: 1.8854307199944742e-05\n",
      "Epoch 3701, Loss: 5.274468821880873e-05, Final Batch Loss: 1.3157683497411199e-05\n",
      "Epoch 3702, Loss: 6.562713221569538e-05, Final Batch Loss: 3.7843980749130424e-07\n",
      "Epoch 3703, Loss: 0.004341028509770695, Final Batch Loss: 0.0043272944167256355\n",
      "Epoch 3704, Loss: 6.371925792336697e-05, Final Batch Loss: 4.09131189371692e-06\n",
      "Epoch 3705, Loss: 0.00015479804642382078, Final Batch Loss: 0.00010882960486924276\n",
      "Epoch 3706, Loss: 0.000415607673858176, Final Batch Loss: 8.93740616447758e-06\n",
      "Epoch 3707, Loss: 1.7948937511391705e-05, Final Batch Loss: 7.492637905670563e-06\n",
      "Epoch 3708, Loss: 0.00027854827931150794, Final Batch Loss: 7.643585558980703e-05\n",
      "Epoch 3709, Loss: 4.8447232074977364e-05, Final Batch Loss: 4.2360650695627555e-05\n",
      "Epoch 3710, Loss: 5.376921944844071e-05, Final Batch Loss: 4.236073436914012e-05\n",
      "Epoch 3711, Loss: 0.0018007029575528577, Final Batch Loss: 0.0017190477810800076\n",
      "Epoch 3712, Loss: 2.5257877496187575e-05, Final Batch Loss: 1.295552465307992e-05\n",
      "Epoch 3713, Loss: 0.0003524621333781397, Final Batch Loss: 6.550681064254604e-06\n",
      "Epoch 3714, Loss: 2.418439885332191e-05, Final Batch Loss: 2.823034947141423e-06\n",
      "Epoch 3715, Loss: 0.0006779818795621395, Final Batch Loss: 0.00018814741633832455\n",
      "Epoch 3716, Loss: 7.295523391803727e-05, Final Batch Loss: 1.186568260891363e-05\n",
      "Epoch 3717, Loss: 5.5720365708111785e-06, Final Batch Loss: 3.7369004530773964e-06\n",
      "Epoch 3718, Loss: 1.8719254057941725e-05, Final Batch Loss: 5.923213848291198e-06\n",
      "Epoch 3719, Loss: 0.0005514001531992108, Final Batch Loss: 0.0003413761151023209\n",
      "Epoch 3720, Loss: 0.004456353577552363, Final Batch Loss: 0.00011265857028774917\n",
      "Epoch 3721, Loss: 0.0005872969227311842, Final Batch Loss: 5.139055701874895e-06\n",
      "Epoch 3722, Loss: 2.5182092940667644e-05, Final Batch Loss: 8.838478606776334e-06\n",
      "Epoch 3723, Loss: 0.00011314736411804915, Final Batch Loss: 0.00010651361662894487\n",
      "Epoch 3724, Loss: 0.021763975601061247, Final Batch Loss: 0.021723538637161255\n",
      "Epoch 3725, Loss: 8.031905599636957e-05, Final Batch Loss: 4.798039299203083e-05\n",
      "Epoch 3726, Loss: 0.0001436660240869969, Final Batch Loss: 0.00010439546895213425\n",
      "Epoch 3727, Loss: 0.0011861866714752978, Final Batch Loss: 0.001162680913694203\n",
      "Epoch 3728, Loss: 0.0017375325169268763, Final Batch Loss: 0.0017305550863966346\n",
      "Epoch 3729, Loss: 0.0005741239529015729, Final Batch Loss: 0.0005563534796237946\n",
      "Epoch 3730, Loss: 0.0008630510819784831, Final Batch Loss: 0.0008174192626029253\n",
      "Epoch 3731, Loss: 0.00041691722071846016, Final Batch Loss: 0.00036346277920529246\n",
      "Epoch 3732, Loss: 0.0006192869479946239, Final Batch Loss: 1.4903346254868666e-06\n",
      "Epoch 3733, Loss: 3.503336483845487e-05, Final Batch Loss: 7.367085345322266e-06\n",
      "Epoch 3734, Loss: 2.890156611101702e-05, Final Batch Loss: 1.5588004316668957e-05\n",
      "Epoch 3735, Loss: 0.0002221412942162715, Final Batch Loss: 0.00016699195839464664\n",
      "Epoch 3736, Loss: 0.0037300674011930823, Final Batch Loss: 0.0016206213040277362\n",
      "Epoch 3737, Loss: 0.000162041839757876, Final Batch Loss: 8.047477422223892e-06\n",
      "Epoch 3738, Loss: 0.00022358427304425277, Final Batch Loss: 0.00020491171744652092\n",
      "Epoch 3739, Loss: 0.00011656727292574942, Final Batch Loss: 9.481736196903512e-05\n",
      "Epoch 3740, Loss: 6.366262459778227e-05, Final Batch Loss: 4.195441215415485e-05\n",
      "Epoch 3741, Loss: 0.00960547514114296, Final Batch Loss: 0.00949093233793974\n",
      "Epoch 3742, Loss: 0.0001646784512558952, Final Batch Loss: 6.377531099133193e-05\n",
      "Epoch 3743, Loss: 0.0005790463328594342, Final Batch Loss: 9.322502592112869e-05\n",
      "Epoch 3744, Loss: 0.0005493623611982912, Final Batch Loss: 5.952050560154021e-05\n",
      "Epoch 3745, Loss: 1.1950822681683348e-05, Final Batch Loss: 6.156301424198318e-06\n",
      "Epoch 3746, Loss: 0.0007315458205994219, Final Batch Loss: 0.00025058689061552286\n",
      "Epoch 3747, Loss: 0.00020181712534395047, Final Batch Loss: 1.9028713722946122e-05\n",
      "Epoch 3748, Loss: 0.0001464511442463845, Final Batch Loss: 6.486637721536681e-05\n",
      "Epoch 3749, Loss: 0.0036476452369242907, Final Batch Loss: 0.0029632316436618567\n",
      "Epoch 3750, Loss: 5.47208878742822e-05, Final Batch Loss: 5.1173574320273474e-05\n",
      "Epoch 3751, Loss: 0.002723434619838372, Final Batch Loss: 0.002572246128693223\n",
      "Epoch 3752, Loss: 1.3114718456108676e-05, Final Batch Loss: 6.502827432086633e-07\n",
      "Epoch 3753, Loss: 0.003945363161619753, Final Batch Loss: 0.00044426036765798926\n",
      "Epoch 3754, Loss: 0.00030691417373418517, Final Batch Loss: 1.9911592517019017e-06\n",
      "Epoch 3755, Loss: 5.142261943547055e-05, Final Batch Loss: 3.425138129387051e-05\n",
      "Epoch 3756, Loss: 9.388138641952537e-05, Final Batch Loss: 8.932562195695937e-05\n",
      "Epoch 3757, Loss: 0.0005567580519709736, Final Batch Loss: 6.210317951627076e-05\n",
      "Epoch 3758, Loss: 0.0010192680056206882, Final Batch Loss: 0.0008089504553936422\n",
      "Epoch 3759, Loss: 0.0003846300669465563, Final Batch Loss: 1.2626244824787136e-05\n",
      "Epoch 3760, Loss: 0.0008197750612453092, Final Batch Loss: 0.0007722825394012034\n",
      "Epoch 3761, Loss: 0.0011552290379768237, Final Batch Loss: 5.991254874970764e-05\n",
      "Epoch 3762, Loss: 0.0005931440755375661, Final Batch Loss: 6.558313179994002e-05\n",
      "Epoch 3763, Loss: 0.00011126531899208203, Final Batch Loss: 4.581885877996683e-05\n",
      "Epoch 3764, Loss: 0.00011827544722109451, Final Batch Loss: 3.5210300666221883e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3765, Loss: 0.0012718393190880306, Final Batch Loss: 0.0011609495850279927\n",
      "Epoch 3766, Loss: 0.00039308117266045883, Final Batch Loss: 0.00038279552245512605\n",
      "Epoch 3767, Loss: 0.007013430236838758, Final Batch Loss: 5.4589821957051754e-05\n",
      "Epoch 3768, Loss: 0.0010891236233874224, Final Batch Loss: 0.0009708842844702303\n",
      "Epoch 3769, Loss: 0.0002543245027482044, Final Batch Loss: 4.189074024907313e-05\n",
      "Epoch 3770, Loss: 0.00037187036650720984, Final Batch Loss: 0.00022645140415988863\n",
      "Epoch 3771, Loss: 0.00024592170484538656, Final Batch Loss: 2.0197459889459424e-05\n",
      "Epoch 3772, Loss: 6.419991314032814e-05, Final Batch Loss: 5.072917338111438e-05\n",
      "Epoch 3773, Loss: 0.0002112294841936091, Final Batch Loss: 1.5771418475196697e-05\n",
      "Epoch 3774, Loss: 0.0018398012616671622, Final Batch Loss: 0.0012260529911145568\n",
      "Epoch 3775, Loss: 8.393034295295365e-05, Final Batch Loss: 3.8765138015151024e-05\n",
      "Epoch 3776, Loss: 0.00013725990720558912, Final Batch Loss: 7.463886868208647e-05\n",
      "Epoch 3777, Loss: 0.00024227066023740917, Final Batch Loss: 9.771228360477835e-05\n",
      "Epoch 3778, Loss: 0.00013333425340533722, Final Batch Loss: 0.00010596828360576183\n",
      "Epoch 3779, Loss: 8.155693649314344e-05, Final Batch Loss: 5.1145889301551506e-05\n",
      "Epoch 3780, Loss: 0.0012144275533501059, Final Batch Loss: 2.9313989216461778e-05\n",
      "Epoch 3781, Loss: 0.0005417937973106746, Final Batch Loss: 4.6745732106501237e-05\n",
      "Epoch 3782, Loss: 0.0002897620288422331, Final Batch Loss: 1.3070661225356162e-05\n",
      "Epoch 3783, Loss: 0.00022233802155824378, Final Batch Loss: 0.00011261861800448969\n",
      "Epoch 3784, Loss: 0.0007246934401337057, Final Batch Loss: 0.00044388603419065475\n",
      "Epoch 3785, Loss: 0.000358906683686655, Final Batch Loss: 0.00010289527563145384\n",
      "Epoch 3786, Loss: 4.8787360356072895e-05, Final Batch Loss: 1.2035105100949295e-05\n",
      "Epoch 3787, Loss: 0.00023776561647537164, Final Batch Loss: 4.361199898994528e-05\n",
      "Epoch 3788, Loss: 0.0013314796160557307, Final Batch Loss: 2.3832872102502733e-05\n",
      "Epoch 3789, Loss: 0.0008166295228875242, Final Batch Loss: 0.0007348768413066864\n",
      "Epoch 3790, Loss: 0.00043807620386360213, Final Batch Loss: 3.5912984458263963e-05\n",
      "Epoch 3791, Loss: 0.000647908280370757, Final Batch Loss: 0.0004694075614679605\n",
      "Epoch 3792, Loss: 0.0003015627880813554, Final Batch Loss: 0.00017962644051294774\n",
      "Epoch 3793, Loss: 0.006464131627581082, Final Batch Loss: 0.00018712317978497595\n",
      "Epoch 3794, Loss: 6.1031563745928e-05, Final Batch Loss: 1.4899784218869172e-05\n",
      "Epoch 3795, Loss: 9.700066220830195e-05, Final Batch Loss: 1.665674426476471e-05\n",
      "Epoch 3796, Loss: 9.784556937120215e-05, Final Batch Loss: 9.575002331985161e-05\n",
      "Epoch 3797, Loss: 0.0008471077599097043, Final Batch Loss: 3.4014665288850665e-05\n",
      "Epoch 3798, Loss: 0.0003270556262577884, Final Batch Loss: 7.631562039023265e-05\n",
      "Epoch 3799, Loss: 0.00022745889145880938, Final Batch Loss: 9.563031198922545e-05\n",
      "Epoch 3800, Loss: 5.348048944142647e-05, Final Batch Loss: 1.5300953236874193e-05\n",
      "Epoch 3801, Loss: 0.00025068921968340874, Final Batch Loss: 3.833230584859848e-05\n",
      "Epoch 3802, Loss: 0.002985541577800177, Final Batch Loss: 0.0029074184130877256\n",
      "Epoch 3803, Loss: 0.0011195262859473587, Final Batch Loss: 8.876036190486047e-06\n",
      "Epoch 3804, Loss: 3.40604410666856e-05, Final Batch Loss: 1.4025773452885915e-05\n",
      "Epoch 3805, Loss: 0.0008628778086858802, Final Batch Loss: 5.125434108776972e-05\n",
      "Epoch 3806, Loss: 0.0007411241494992282, Final Batch Loss: 1.2000728020211682e-05\n",
      "Epoch 3807, Loss: 0.0028624935548577923, Final Batch Loss: 1.6008551028789952e-05\n",
      "Epoch 3808, Loss: 0.00017277937240578467, Final Batch Loss: 2.570160177128855e-06\n",
      "Epoch 3809, Loss: 8.96317433216609e-05, Final Batch Loss: 5.0248243496753275e-05\n",
      "Epoch 3810, Loss: 0.0003147621901007369, Final Batch Loss: 0.00023479739320464432\n",
      "Epoch 3811, Loss: 0.0002045106957666576, Final Batch Loss: 6.202846998348832e-05\n",
      "Epoch 3812, Loss: 0.00012639306805795059, Final Batch Loss: 0.00010549124999670312\n",
      "Epoch 3813, Loss: 0.00045446450167219155, Final Batch Loss: 0.00042380995000712574\n",
      "Epoch 3814, Loss: 0.00018398293104837649, Final Batch Loss: 3.191022187820636e-05\n",
      "Epoch 3815, Loss: 0.0001705684026092058, Final Batch Loss: 0.0001598906092112884\n",
      "Epoch 3816, Loss: 0.004776653557200916, Final Batch Loss: 0.0047458624467253685\n",
      "Epoch 3817, Loss: 0.0013445994118228555, Final Batch Loss: 0.00028559111524373293\n",
      "Epoch 3818, Loss: 0.0002508177421987057, Final Batch Loss: 4.770151281263679e-05\n",
      "Epoch 3819, Loss: 8.733112372283358e-05, Final Batch Loss: 1.9594875993789174e-05\n",
      "Epoch 3820, Loss: 0.000689083763063536, Final Batch Loss: 1.6014668290154077e-05\n",
      "Epoch 3821, Loss: 0.00021821993868798018, Final Batch Loss: 6.41875813016668e-05\n",
      "Epoch 3822, Loss: 2.808810268106754e-05, Final Batch Loss: 2.3666274501010776e-05\n",
      "Epoch 3823, Loss: 0.0006334792269626632, Final Batch Loss: 8.573780360165983e-05\n",
      "Epoch 3824, Loss: 0.00013481182759278454, Final Batch Loss: 9.850793139776215e-05\n",
      "Epoch 3825, Loss: 0.00038633115400443785, Final Batch Loss: 3.2852240110514686e-05\n",
      "Epoch 3826, Loss: 0.0006136129377409816, Final Batch Loss: 0.0003332979104015976\n",
      "Epoch 3827, Loss: 0.0011477832194941584, Final Batch Loss: 3.929934246116318e-05\n",
      "Epoch 3828, Loss: 0.00023434925242327154, Final Batch Loss: 7.038735202513635e-05\n",
      "Epoch 3829, Loss: 0.0011447201250120997, Final Batch Loss: 0.00026153476210311055\n",
      "Epoch 3830, Loss: 0.0012354038626654074, Final Batch Loss: 0.00020574084192048758\n",
      "Epoch 3831, Loss: 6.780475996492896e-05, Final Batch Loss: 2.3163383957580663e-05\n",
      "Epoch 3832, Loss: 0.0011077701055910438, Final Batch Loss: 0.00033268853439949453\n",
      "Epoch 3833, Loss: 0.00013637429583468474, Final Batch Loss: 9.626156679587439e-05\n",
      "Epoch 3834, Loss: 0.0002337098726457043, Final Batch Loss: 1.2317927939875517e-06\n",
      "Epoch 3835, Loss: 0.0015830970514798537, Final Batch Loss: 0.00010183478298131377\n",
      "Epoch 3836, Loss: 0.0015063696191646159, Final Batch Loss: 0.0009537359583191574\n",
      "Epoch 3837, Loss: 4.096561860933434e-05, Final Batch Loss: 3.167631439282559e-05\n",
      "Epoch 3838, Loss: 0.05691152543295175, Final Batch Loss: 0.0001317012356594205\n",
      "Epoch 3839, Loss: 5.223840616963571e-06, Final Batch Loss: 1.2393702490953729e-06\n",
      "Epoch 3840, Loss: 0.0008850387748680077, Final Batch Loss: 2.54104015766643e-05\n",
      "Epoch 3841, Loss: 0.002653014729730785, Final Batch Loss: 0.0011485995491966605\n",
      "Epoch 3842, Loss: 9.434709363631555e-05, Final Batch Loss: 4.8510396482015494e-06\n",
      "Epoch 3843, Loss: 0.00015618096222169697, Final Batch Loss: 0.0001064181633410044\n",
      "Epoch 3844, Loss: 0.0002672971422725823, Final Batch Loss: 0.0002479868708178401\n",
      "Epoch 3845, Loss: 0.0005010526147088967, Final Batch Loss: 0.0004591980832628906\n",
      "Epoch 3846, Loss: 0.0012257255730219185, Final Batch Loss: 0.0006311294855549932\n",
      "Epoch 3847, Loss: 0.00040552925202064216, Final Batch Loss: 7.534757605753839e-05\n",
      "Epoch 3848, Loss: 0.0011003610452462453, Final Batch Loss: 0.0010620623361319304\n",
      "Epoch 3849, Loss: 0.0004734230606118217, Final Batch Loss: 0.0003554585564415902\n",
      "Epoch 3850, Loss: 0.00014339296103571542, Final Batch Loss: 8.410058944718912e-05\n",
      "Epoch 3851, Loss: 0.0009856137985480018, Final Batch Loss: 4.8459281970281154e-05\n",
      "Epoch 3852, Loss: 0.004968078850652091, Final Batch Loss: 0.004832190927118063\n",
      "Epoch 3853, Loss: 0.000723284274499747, Final Batch Loss: 2.765616045508068e-05\n",
      "Epoch 3854, Loss: 0.0002742587239481509, Final Batch Loss: 0.00022024150530342013\n",
      "Epoch 3855, Loss: 0.00016544923710171133, Final Batch Loss: 4.8651832912582904e-05\n",
      "Epoch 3856, Loss: 0.00039311538694164483, Final Batch Loss: 1.198451627715258e-05\n",
      "Epoch 3857, Loss: 0.00024548816872993484, Final Batch Loss: 7.85055963206105e-05\n",
      "Epoch 3858, Loss: 0.00035112618206767365, Final Batch Loss: 0.00026504992274567485\n",
      "Epoch 3859, Loss: 0.00012333147969911806, Final Batch Loss: 0.00010157632641494274\n",
      "Epoch 3860, Loss: 0.00016233354108408093, Final Batch Loss: 0.0001214907897519879\n",
      "Epoch 3861, Loss: 0.00010524196477490477, Final Batch Loss: 5.2041323215235025e-05\n",
      "Epoch 3862, Loss: 2.7234982098889304e-05, Final Batch Loss: 5.730854809371522e-06\n",
      "Epoch 3863, Loss: 0.0003443058376433328, Final Batch Loss: 7.58294336264953e-05\n",
      "Epoch 3864, Loss: 0.00015170105325523764, Final Batch Loss: 9.32519105845131e-05\n",
      "Epoch 3865, Loss: 8.017315485631116e-05, Final Batch Loss: 6.239625508897007e-05\n",
      "Epoch 3866, Loss: 0.01173063219175674, Final Batch Loss: 0.011462495662271976\n",
      "Epoch 3867, Loss: 0.00012425993099896004, Final Batch Loss: 0.00011517983512021601\n",
      "Epoch 3868, Loss: 0.00015323698607971892, Final Batch Loss: 1.54183289851062e-05\n",
      "Epoch 3869, Loss: 0.00023289718956220895, Final Batch Loss: 1.0046467650681734e-05\n",
      "Epoch 3870, Loss: 0.0010823748089023866, Final Batch Loss: 0.0010691634379327297\n",
      "Epoch 3871, Loss: 0.0001884763732959982, Final Batch Loss: 4.681793143390678e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3872, Loss: 5.119096385897137e-05, Final Batch Loss: 1.9479033653624356e-05\n",
      "Epoch 3873, Loss: 0.0009965073058992857, Final Batch Loss: 1.3441380360745825e-05\n",
      "Epoch 3874, Loss: 0.00024123508774209768, Final Batch Loss: 0.00019855920982081443\n",
      "Epoch 3875, Loss: 0.00016530474385945126, Final Batch Loss: 8.990145579446107e-05\n",
      "Epoch 3876, Loss: 0.0002498004978406243, Final Batch Loss: 7.077218469930813e-05\n",
      "Epoch 3877, Loss: 0.0019005735666723922, Final Batch Loss: 0.0016794324619695544\n",
      "Epoch 3878, Loss: 0.010967594398607616, Final Batch Loss: 0.010947814211249352\n",
      "Epoch 3879, Loss: 0.0006836070242570713, Final Batch Loss: 0.0005750207928940654\n",
      "Epoch 3880, Loss: 0.00040209467988461256, Final Batch Loss: 0.0002313573786523193\n",
      "Epoch 3881, Loss: 0.00029827095841028495, Final Batch Loss: 8.681267900101375e-06\n",
      "Epoch 3882, Loss: 9.489892363490071e-05, Final Batch Loss: 1.554486334498506e-05\n",
      "Epoch 3883, Loss: 0.000791447761002928, Final Batch Loss: 0.00046958678285591304\n",
      "Epoch 3884, Loss: 2.568812487879768e-05, Final Batch Loss: 2.8952745196875185e-06\n",
      "Epoch 3885, Loss: 0.0003818847762886435, Final Batch Loss: 0.0003479945007711649\n",
      "Epoch 3886, Loss: 0.0018422140274196863, Final Batch Loss: 1.597846858203411e-05\n",
      "Epoch 3887, Loss: 0.00015030382201075554, Final Batch Loss: 3.9181388274300843e-05\n",
      "Epoch 3888, Loss: 5.047159925197775e-05, Final Batch Loss: 3.325609441162669e-06\n",
      "Epoch 3889, Loss: 0.0002487094279786106, Final Batch Loss: 0.00020747374219354242\n",
      "Epoch 3890, Loss: 0.005913414956694396, Final Batch Loss: 3.5953351016360102e-06\n",
      "Epoch 3891, Loss: 5.763029730587732e-05, Final Batch Loss: 2.1660749553120695e-05\n",
      "Epoch 3892, Loss: 5.178529681870714e-05, Final Batch Loss: 2.1878448023926467e-05\n",
      "Epoch 3893, Loss: 0.00017946148000191897, Final Batch Loss: 6.570742698386312e-05\n",
      "Epoch 3894, Loss: 0.0003015146139659919, Final Batch Loss: 9.475150000071153e-05\n",
      "Epoch 3895, Loss: 4.042909495183267e-05, Final Batch Loss: 2.0357632820378058e-05\n",
      "Epoch 3896, Loss: 0.004605841444572434, Final Batch Loss: 0.00018661757349036634\n",
      "Epoch 3897, Loss: 0.0005098247529531363, Final Batch Loss: 0.00048323857481591403\n",
      "Epoch 3898, Loss: 7.894413647591136e-05, Final Batch Loss: 3.76874886569567e-05\n",
      "Epoch 3899, Loss: 0.001127500356233213, Final Batch Loss: 0.0010886802338063717\n",
      "Epoch 3900, Loss: 0.001659116147493478, Final Batch Loss: 0.0015605288790538907\n",
      "Epoch 3901, Loss: 0.00039007203304208815, Final Batch Loss: 0.00024611499975435436\n",
      "Epoch 3902, Loss: 0.00032413130611530505, Final Batch Loss: 0.0002988598425872624\n",
      "Epoch 3903, Loss: 0.0004295568292036478, Final Batch Loss: 0.00042322787339799106\n",
      "Epoch 3904, Loss: 0.00011123634430987295, Final Batch Loss: 0.00010501455108169466\n",
      "Epoch 3905, Loss: 0.024848363616001734, Final Batch Loss: 1.4757059943804052e-05\n",
      "Epoch 3906, Loss: 0.0004983760009054095, Final Batch Loss: 0.00020346205565147102\n",
      "Epoch 3907, Loss: 0.00023420407524099573, Final Batch Loss: 0.00018121296307072043\n",
      "Epoch 3908, Loss: 0.004003850510343909, Final Batch Loss: 3.638234920799732e-05\n",
      "Epoch 3909, Loss: 0.000724676858226303, Final Batch Loss: 0.0007034327136352658\n",
      "Epoch 3910, Loss: 0.005149536267708754, Final Batch Loss: 4.585363421938382e-05\n",
      "Epoch 3911, Loss: 0.01872747784727835, Final Batch Loss: 2.52949284913484e-05\n",
      "Epoch 3912, Loss: 0.00012276886263862252, Final Batch Loss: 7.501150685129687e-05\n",
      "Epoch 3913, Loss: 0.002643342064402532, Final Batch Loss: 0.0025657243095338345\n",
      "Epoch 3914, Loss: 0.0008636806705908384, Final Batch Loss: 0.0008445328567177057\n",
      "Epoch 3915, Loss: 0.005645484125125222, Final Batch Loss: 3.1764546292833984e-05\n",
      "Epoch 3916, Loss: 0.00044601674017030746, Final Batch Loss: 0.00021729829313699156\n",
      "Epoch 3917, Loss: 0.0009006170148495585, Final Batch Loss: 0.0003853407979477197\n",
      "Epoch 3918, Loss: 0.046449880121144815, Final Batch Loss: 2.2063968572183512e-05\n",
      "Epoch 3919, Loss: 0.003036856478502159, Final Batch Loss: 1.0953577657346614e-05\n",
      "Epoch 3920, Loss: 0.0020888539729639888, Final Batch Loss: 0.0007114873733371496\n",
      "Epoch 3921, Loss: 0.0005285485240165144, Final Batch Loss: 0.00037482910556718707\n",
      "Epoch 3922, Loss: 0.00022908135724719614, Final Batch Loss: 5.172498640604317e-05\n",
      "Epoch 3923, Loss: 0.0003990167533629574, Final Batch Loss: 3.100775211350992e-05\n",
      "Epoch 3924, Loss: 0.0005592337474809028, Final Batch Loss: 9.903350292006508e-05\n",
      "Epoch 3925, Loss: 0.000476438675832469, Final Batch Loss: 8.80344960023649e-05\n",
      "Epoch 3926, Loss: 0.006664443499175832, Final Batch Loss: 0.006547291297465563\n",
      "Epoch 3927, Loss: 0.0006970228860154748, Final Batch Loss: 0.0003439821011852473\n",
      "Epoch 3928, Loss: 0.005039561539888382, Final Batch Loss: 0.0030358745716512203\n",
      "Epoch 3929, Loss: 0.0002190916275139898, Final Batch Loss: 0.00014846435806248337\n",
      "Epoch 3930, Loss: 0.0007669724873267114, Final Batch Loss: 0.00027754210168495774\n",
      "Epoch 3931, Loss: 0.001930565689690411, Final Batch Loss: 0.0012687108246609569\n",
      "Epoch 3932, Loss: 0.0007515880570281297, Final Batch Loss: 0.00015732870087958872\n",
      "Epoch 3933, Loss: 0.00102182240516413, Final Batch Loss: 3.748324525076896e-05\n",
      "Epoch 3934, Loss: 0.0011287459929008037, Final Batch Loss: 0.0009431622456759214\n",
      "Epoch 3935, Loss: 0.00013522827066481113, Final Batch Loss: 0.00010002780618378893\n",
      "Epoch 3936, Loss: 0.00013745705291512422, Final Batch Loss: 0.00010280925926053897\n",
      "Epoch 3937, Loss: 0.0016802015888970345, Final Batch Loss: 0.0015814356738701463\n",
      "Epoch 3938, Loss: 0.00029189596898504533, Final Batch Loss: 0.00024741815286688507\n",
      "Epoch 3939, Loss: 0.0042174143745796755, Final Batch Loss: 0.004020580090582371\n",
      "Epoch 3940, Loss: 0.004465563983103493, Final Batch Loss: 0.004430877510458231\n",
      "Epoch 3941, Loss: 0.00019805260672001168, Final Batch Loss: 1.8996848666574806e-05\n",
      "Epoch 3942, Loss: 0.0071951840072870255, Final Batch Loss: 0.0015523661859333515\n",
      "Epoch 3943, Loss: 0.00031453315023100004, Final Batch Loss: 0.00026065335259772837\n",
      "Epoch 3944, Loss: 0.000239811502979137, Final Batch Loss: 0.00014786585234105587\n",
      "Epoch 3945, Loss: 0.0007776727579766884, Final Batch Loss: 6.781094998586923e-05\n",
      "Epoch 3946, Loss: 0.0024609828251414, Final Batch Loss: 0.0017185143660753965\n",
      "Epoch 3947, Loss: 0.00013577671415987425, Final Batch Loss: 4.666294626076706e-05\n",
      "Epoch 3948, Loss: 0.0014986734895501286, Final Batch Loss: 0.00010235412628389895\n",
      "Epoch 3949, Loss: 0.00013222706911619753, Final Batch Loss: 6.124850187916309e-05\n",
      "Epoch 3950, Loss: 0.00018809899120242335, Final Batch Loss: 3.617591937654652e-05\n",
      "Epoch 3951, Loss: 0.0020016046255477704, Final Batch Loss: 0.0019125514663755894\n",
      "Epoch 3952, Loss: 0.0009665164179750718, Final Batch Loss: 0.00011499445099616423\n",
      "Epoch 3953, Loss: 0.0004354560987849254, Final Batch Loss: 3.60024168912787e-05\n",
      "Epoch 3954, Loss: 0.00021866858514840715, Final Batch Loss: 6.0448288422776386e-05\n",
      "Epoch 3955, Loss: 0.00018295769041287713, Final Batch Loss: 4.285797695047222e-05\n",
      "Epoch 3956, Loss: 0.00017852945893537253, Final Batch Loss: 8.10723431641236e-05\n",
      "Epoch 3957, Loss: 0.0002082251103274757, Final Batch Loss: 0.00019107390835415572\n",
      "Epoch 3958, Loss: 0.0021185797450016253, Final Batch Loss: 6.310611934168264e-05\n",
      "Epoch 3959, Loss: 0.0003787897585425526, Final Batch Loss: 8.852724567987025e-05\n",
      "Epoch 3960, Loss: 4.0021646782406606e-05, Final Batch Loss: 2.0816685719182715e-05\n",
      "Epoch 3961, Loss: 0.004691995825851336, Final Batch Loss: 0.00022665844880975783\n",
      "Epoch 3962, Loss: 0.00027801631222246215, Final Batch Loss: 0.00020497420337051153\n",
      "Epoch 3963, Loss: 0.0002129628737748135, Final Batch Loss: 0.00016443031199742109\n",
      "Epoch 3964, Loss: 0.001664137002080679, Final Batch Loss: 0.0005744509398937225\n",
      "Epoch 3965, Loss: 0.0001550593733554706, Final Batch Loss: 0.00011463187547633424\n",
      "Epoch 3966, Loss: 0.0001866676175268367, Final Batch Loss: 6.362235581036657e-05\n",
      "Epoch 3967, Loss: 0.0006427800726669375, Final Batch Loss: 3.055410707020201e-05\n",
      "Epoch 3968, Loss: 0.0001471865689381957, Final Batch Loss: 4.9957132432609797e-05\n",
      "Epoch 3969, Loss: 0.0001677334621490445, Final Batch Loss: 9.728722943691537e-06\n",
      "Epoch 3970, Loss: 0.0007603150515933521, Final Batch Loss: 3.341434785397723e-05\n",
      "Epoch 3971, Loss: 0.00023434557806467637, Final Batch Loss: 0.00011033898772438988\n",
      "Epoch 3972, Loss: 5.85245834372472e-05, Final Batch Loss: 3.3124513720395043e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3973, Loss: 7.548360827058787e-05, Final Batch Loss: 6.048335490049794e-05\n",
      "Epoch 3974, Loss: 0.0010638165185810067, Final Batch Loss: 0.0001166012734756805\n",
      "Epoch 3975, Loss: 0.00025125941101578064, Final Batch Loss: 2.4185446818592027e-05\n",
      "Epoch 3976, Loss: 0.00012676660480792634, Final Batch Loss: 5.9468835388543084e-05\n",
      "Epoch 3977, Loss: 0.0002210816710430663, Final Batch Loss: 0.00018521815945859998\n",
      "Epoch 3978, Loss: 0.00037575996793748345, Final Batch Loss: 1.0727037079050206e-05\n",
      "Epoch 3979, Loss: 8.697426892467774e-05, Final Batch Loss: 6.329801544779912e-05\n",
      "Epoch 3980, Loss: 0.002785396427498199, Final Batch Loss: 0.002541637746617198\n",
      "Epoch 3981, Loss: 0.0001596760303073097, Final Batch Loss: 2.5136312615359202e-05\n",
      "Epoch 3982, Loss: 8.345557398570236e-05, Final Batch Loss: 5.5531385442009196e-05\n",
      "Epoch 3983, Loss: 0.00020921983013977297, Final Batch Loss: 1.764871194609441e-05\n",
      "Epoch 3984, Loss: 0.00034237216823385097, Final Batch Loss: 1.82946132554207e-05\n",
      "Epoch 3985, Loss: 0.0009278310462832451, Final Batch Loss: 0.00038183038122951984\n",
      "Epoch 3986, Loss: 0.001986161805689335, Final Batch Loss: 0.001084376242943108\n",
      "Epoch 3987, Loss: 0.000561048072995618, Final Batch Loss: 0.00015282980166375637\n",
      "Epoch 3988, Loss: 0.0003264748665969819, Final Batch Loss: 0.00027023415896110237\n",
      "Epoch 3989, Loss: 0.00014316145825432613, Final Batch Loss: 0.00010037672473117709\n",
      "Epoch 3990, Loss: 0.0004928488760924665, Final Batch Loss: 0.0004671919741667807\n",
      "Epoch 3991, Loss: 0.00012621547102753539, Final Batch Loss: 1.4967403330956586e-05\n",
      "Epoch 3992, Loss: 0.00031226256396621466, Final Batch Loss: 0.00022353921667672694\n",
      "Epoch 3993, Loss: 5.365223660191987e-05, Final Batch Loss: 2.748042970779352e-05\n",
      "Epoch 3994, Loss: 0.0009160129993688315, Final Batch Loss: 0.0006946133798919618\n",
      "Epoch 3995, Loss: 0.00023763153149047866, Final Batch Loss: 0.00010134222247870639\n",
      "Epoch 3996, Loss: 0.00011709042519214563, Final Batch Loss: 8.619271829957142e-05\n",
      "Epoch 3997, Loss: 4.8705271183280274e-05, Final Batch Loss: 2.731001586653292e-06\n",
      "Epoch 3998, Loss: 0.00024458516418235376, Final Batch Loss: 0.00015981939213816077\n",
      "Epoch 3999, Loss: 0.00011073510904680006, Final Batch Loss: 9.763974230736494e-05\n",
      "Epoch 4000, Loss: 0.0010097773629240692, Final Batch Loss: 0.0008374317549169064\n",
      "Epoch 4001, Loss: 0.000338184843712952, Final Batch Loss: 8.976918616099283e-05\n",
      "Epoch 4002, Loss: 0.0006612692559428979, Final Batch Loss: 0.0006116909789852798\n",
      "Epoch 4003, Loss: 0.00026065020210808143, Final Batch Loss: 3.204272798029706e-05\n",
      "Epoch 4004, Loss: 0.0002475068176863715, Final Batch Loss: 0.00017113254580181092\n",
      "Epoch 4005, Loss: 0.005125921607032069, Final Batch Loss: 0.005106527358293533\n",
      "Epoch 4006, Loss: 0.011079231991971028, Final Batch Loss: 0.01107123401015997\n",
      "Epoch 4007, Loss: 4.574839385895757e-05, Final Batch Loss: 1.5198961591522675e-05\n",
      "Epoch 4008, Loss: 0.000127387153042946, Final Batch Loss: 6.26139371888712e-05\n",
      "Epoch 4009, Loss: 2.609624425531365e-05, Final Batch Loss: 1.9980874640168622e-05\n",
      "Epoch 4010, Loss: 0.0001334689764007635, Final Batch Loss: 1.196432549477322e-06\n",
      "Epoch 4011, Loss: 0.00019550928300304804, Final Batch Loss: 1.2665457688854076e-05\n",
      "Epoch 4012, Loss: 7.085336983436719e-05, Final Batch Loss: 5.150403012521565e-05\n",
      "Epoch 4013, Loss: 0.0006663318490609527, Final Batch Loss: 0.00033074404927901924\n",
      "Epoch 4014, Loss: 0.0004102129723833059, Final Batch Loss: 0.00039739932981319726\n",
      "Epoch 4015, Loss: 0.0007551797025371343, Final Batch Loss: 0.0007196997758001089\n",
      "Epoch 4016, Loss: 0.0002484229698893614, Final Batch Loss: 0.0001869195984909311\n",
      "Epoch 4017, Loss: 0.00018872320106311236, Final Batch Loss: 1.2805010555894114e-05\n",
      "Epoch 4018, Loss: 8.339281339431182e-05, Final Batch Loss: 1.5627309039700776e-05\n",
      "Epoch 4019, Loss: 0.0009106369361688849, Final Batch Loss: 0.0008937358506955206\n",
      "Epoch 4020, Loss: 3.702781668835087e-05, Final Batch Loss: 1.462748787162127e-05\n",
      "Epoch 4021, Loss: 0.00024229171685874462, Final Batch Loss: 7.738439308013767e-05\n",
      "Epoch 4022, Loss: 0.00017738117458065972, Final Batch Loss: 0.00013776675041299313\n",
      "Epoch 4023, Loss: 0.0003157350738547393, Final Batch Loss: 1.0516422662476543e-05\n",
      "Epoch 4024, Loss: 0.00014560030831489712, Final Batch Loss: 9.015441173687577e-05\n",
      "Epoch 4025, Loss: 0.0008920463424146874, Final Batch Loss: 2.894075987569522e-05\n",
      "Epoch 4026, Loss: 0.00013236165614216588, Final Batch Loss: 7.252737850649282e-05\n",
      "Epoch 4027, Loss: 0.00027255353779764846, Final Batch Loss: 8.477009396301582e-05\n",
      "Epoch 4028, Loss: 4.3477481085574254e-05, Final Batch Loss: 1.9762941519729793e-05\n",
      "Epoch 4029, Loss: 6.423416971301776e-05, Final Batch Loss: 5.387039436755003e-06\n",
      "Epoch 4030, Loss: 0.00012830787090933882, Final Batch Loss: 8.90419541974552e-05\n",
      "Epoch 4031, Loss: 0.00044495567271951586, Final Batch Loss: 0.0003732062759809196\n",
      "Epoch 4032, Loss: 0.0002090189154841937, Final Batch Loss: 9.305630374001339e-05\n",
      "Epoch 4033, Loss: 0.003191488613083493, Final Batch Loss: 7.604975689901039e-05\n",
      "Epoch 4034, Loss: 0.00011513850040500984, Final Batch Loss: 6.359667895594612e-05\n",
      "Epoch 4035, Loss: 0.0010117349738720804, Final Batch Loss: 0.0009421490831300616\n",
      "Epoch 4036, Loss: 0.0015521172026637942, Final Batch Loss: 0.0002488977333996445\n",
      "Epoch 4037, Loss: 0.000978924452283536, Final Batch Loss: 1.3505867173080333e-05\n",
      "Epoch 4038, Loss: 0.0015951034147292376, Final Batch Loss: 0.0005185279296711087\n",
      "Epoch 4039, Loss: 0.00043373799962864723, Final Batch Loss: 0.000416770315496251\n",
      "Epoch 4040, Loss: 4.324427209212445e-05, Final Batch Loss: 1.7329390175291337e-05\n",
      "Epoch 4041, Loss: 0.0001363943774776999, Final Batch Loss: 2.8012040274916217e-05\n",
      "Epoch 4042, Loss: 0.00012668254203163087, Final Batch Loss: 0.00011094653746113181\n",
      "Epoch 4043, Loss: 0.012451175338355824, Final Batch Loss: 0.0003286355349700898\n",
      "Epoch 4044, Loss: 1.317111446041963e-05, Final Batch Loss: 4.138527856412111e-06\n",
      "Epoch 4045, Loss: 1.2428091395122465e-05, Final Batch Loss: 5.3488361118070316e-06\n",
      "Epoch 4046, Loss: 0.00016755851902416907, Final Batch Loss: 0.00011525856825755909\n",
      "Epoch 4047, Loss: 0.0013935889874119312, Final Batch Loss: 0.00043268382432870567\n",
      "Epoch 4048, Loss: 0.000340135340593406, Final Batch Loss: 0.0003286154824309051\n",
      "Epoch 4049, Loss: 0.00011638082378340187, Final Batch Loss: 0.00010702173312893137\n",
      "Epoch 4050, Loss: 0.00022608642029808834, Final Batch Loss: 0.0001786463981261477\n",
      "Epoch 4051, Loss: 0.0011664360790746287, Final Batch Loss: 0.0010415519354864955\n",
      "Epoch 4052, Loss: 0.003155841631610201, Final Batch Loss: 1.4828050325377262e-06\n",
      "Epoch 4053, Loss: 0.0019038601449210546, Final Batch Loss: 6.68737538944697e-06\n",
      "Epoch 4054, Loss: 0.0001819625554162485, Final Batch Loss: 3.9731617107463535e-06\n",
      "Epoch 4055, Loss: 0.0015684115351177752, Final Batch Loss: 0.0003916110727004707\n",
      "Epoch 4056, Loss: 0.00031044001320879033, Final Batch Loss: 1.993689011214883e-06\n",
      "Epoch 4057, Loss: 0.0011500140826683491, Final Batch Loss: 0.001044061384163797\n",
      "Epoch 4058, Loss: 0.0003224749452783726, Final Batch Loss: 4.94266496389173e-05\n",
      "Epoch 4059, Loss: 0.0005141457659192383, Final Batch Loss: 8.264431380666792e-05\n",
      "Epoch 4060, Loss: 0.00011558611140571884, Final Batch Loss: 0.00011019737576134503\n",
      "Epoch 4061, Loss: 9.689269427326508e-05, Final Batch Loss: 1.299438372370787e-05\n",
      "Epoch 4062, Loss: 0.0007669537344554556, Final Batch Loss: 8.450170753349084e-06\n",
      "Epoch 4063, Loss: 0.0013754942156083416, Final Batch Loss: 2.8177437343401834e-05\n",
      "Epoch 4064, Loss: 0.00013739632777287625, Final Batch Loss: 9.12982432055287e-06\n",
      "Epoch 4065, Loss: 0.0012918688280478818, Final Batch Loss: 1.662756949372124e-05\n",
      "Epoch 4066, Loss: 0.00026376381720183417, Final Batch Loss: 0.00019327578775119036\n",
      "Epoch 4067, Loss: 0.0008207269856939092, Final Batch Loss: 3.0539362342096865e-05\n",
      "Epoch 4068, Loss: 0.00035841499266098253, Final Batch Loss: 0.00031114844023250043\n",
      "Epoch 4069, Loss: 0.0006487575592473149, Final Batch Loss: 0.000440624775364995\n",
      "Epoch 4070, Loss: 0.0008733550203032792, Final Batch Loss: 0.0006739949458278716\n",
      "Epoch 4071, Loss: 0.00010792746252263896, Final Batch Loss: 3.3483531296951696e-05\n",
      "Epoch 4072, Loss: 2.2600828742724843e-05, Final Batch Loss: 1.473669362894725e-05\n",
      "Epoch 4073, Loss: 0.00012598466855706647, Final Batch Loss: 2.3378728656098247e-05\n",
      "Epoch 4074, Loss: 0.0009102315852942411, Final Batch Loss: 0.0008811766165308654\n",
      "Epoch 4075, Loss: 0.0011687129208439728, Final Batch Loss: 0.0011456450447440147\n",
      "Epoch 4076, Loss: 0.0006312485274975188, Final Batch Loss: 6.115838914411142e-05\n",
      "Epoch 4077, Loss: 7.338152749980509e-05, Final Batch Loss: 2.1557814307016088e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4078, Loss: 5.7887744333129376e-05, Final Batch Loss: 3.289613232482225e-05\n",
      "Epoch 4079, Loss: 7.338234900089446e-05, Final Batch Loss: 3.0299657737486996e-05\n",
      "Epoch 4080, Loss: 0.0001777296929503791, Final Batch Loss: 7.914104935480282e-05\n",
      "Epoch 4081, Loss: 0.0025770028441911563, Final Batch Loss: 0.0025158552452921867\n",
      "Epoch 4082, Loss: 5.500719271367416e-05, Final Batch Loss: 1.8961072782985866e-05\n",
      "Epoch 4083, Loss: 0.00010586934149614535, Final Batch Loss: 9.779295942280442e-05\n",
      "Epoch 4084, Loss: 0.00014825469907009392, Final Batch Loss: 6.242209110496333e-06\n",
      "Epoch 4085, Loss: 0.002256442283396609, Final Batch Loss: 0.0020792477298527956\n",
      "Epoch 4086, Loss: 0.00044030802564520855, Final Batch Loss: 0.00043449195800349116\n",
      "Epoch 4087, Loss: 0.00020180925230306457, Final Batch Loss: 3.850876510114176e-06\n",
      "Epoch 4088, Loss: 6.906882481416687e-05, Final Batch Loss: 3.4579334169393405e-05\n",
      "Epoch 4089, Loss: 0.000691241497406736, Final Batch Loss: 0.0002453886263538152\n",
      "Epoch 4090, Loss: 4.081044539816503e-05, Final Batch Loss: 2.2466040263680043e-06\n",
      "Epoch 4091, Loss: 1.115172290155897e-05, Final Batch Loss: 7.140507932490436e-06\n",
      "Epoch 4092, Loss: 3.417089556023711e-05, Final Batch Loss: 2.532054713810794e-05\n",
      "Epoch 4093, Loss: 0.00043649255167110823, Final Batch Loss: 0.0003839383425656706\n",
      "Epoch 4094, Loss: 0.001810793271943112, Final Batch Loss: 7.023309080977924e-06\n",
      "Epoch 4095, Loss: 0.0041697859414853156, Final Batch Loss: 0.003779778489843011\n",
      "Epoch 4096, Loss: 0.00035639325506053865, Final Batch Loss: 0.00013578803918790072\n",
      "Epoch 4097, Loss: 0.001093216500521521, Final Batch Loss: 0.001071606413461268\n",
      "Epoch 4098, Loss: 8.200626689358614e-05, Final Batch Loss: 6.423635204555467e-05\n",
      "Epoch 4099, Loss: 0.00013803069668938406, Final Batch Loss: 3.8326270441757515e-05\n",
      "Epoch 4100, Loss: 3.1516152375843376e-05, Final Batch Loss: 1.9602279280661605e-05\n",
      "Epoch 4101, Loss: 2.4127744836732745e-05, Final Batch Loss: 1.1154331332363654e-05\n",
      "Epoch 4102, Loss: 0.0017513097191113047, Final Batch Loss: 0.0016347564524039626\n",
      "Epoch 4103, Loss: 1.7177892914332915e-05, Final Batch Loss: 8.927952876547351e-06\n",
      "Epoch 4104, Loss: 1.8944836938317167e-05, Final Batch Loss: 5.1790671022899915e-06\n",
      "Epoch 4105, Loss: 0.0029204507918620948, Final Batch Loss: 0.002869142685085535\n",
      "Epoch 4106, Loss: 0.002015953705267748, Final Batch Loss: 1.827283631428145e-05\n",
      "Epoch 4107, Loss: 5.837861590407556e-05, Final Batch Loss: 1.0528251550567802e-05\n",
      "Epoch 4108, Loss: 0.00013180503992771264, Final Batch Loss: 0.00011116427776869386\n",
      "Epoch 4109, Loss: 3.38651980200666e-05, Final Batch Loss: 9.783726454770658e-06\n",
      "Epoch 4110, Loss: 5.8544319472275674e-05, Final Batch Loss: 3.196875695721246e-05\n",
      "Epoch 4111, Loss: 0.008330016261425044, Final Batch Loss: 0.008326566778123379\n",
      "Epoch 4112, Loss: 0.0002826031413860619, Final Batch Loss: 0.00020482784020714462\n",
      "Epoch 4113, Loss: 0.0013533287255995674, Final Batch Loss: 5.334526576916687e-06\n",
      "Epoch 4114, Loss: 0.0002904403381762677, Final Batch Loss: 6.584393304365221e-06\n",
      "Epoch 4115, Loss: 1.37577540044731e-05, Final Batch Loss: 1.108765627577668e-05\n",
      "Epoch 4116, Loss: 0.000610379491263302, Final Batch Loss: 0.0005522656720131636\n",
      "Epoch 4117, Loss: 4.2463254430913366e-05, Final Batch Loss: 2.444618075969629e-05\n",
      "Epoch 4118, Loss: 0.0005324678691067675, Final Batch Loss: 1.2999130376556423e-06\n",
      "Epoch 4119, Loss: 0.00043752674264396774, Final Batch Loss: 0.0004291703808121383\n",
      "Epoch 4120, Loss: 0.00020868586580036208, Final Batch Loss: 8.689056267030537e-05\n",
      "Epoch 4121, Loss: 0.0003396460415387992, Final Batch Loss: 4.8953723307931796e-05\n",
      "Epoch 4122, Loss: 2.0012636468891287e-05, Final Batch Loss: 6.271720394579461e-06\n",
      "Epoch 4123, Loss: 0.004445589537908745, Final Batch Loss: 0.004442639648914337\n",
      "Epoch 4124, Loss: 2.9275499400682747e-05, Final Batch Loss: 9.417846740689129e-06\n",
      "Epoch 4125, Loss: 0.0018707171984715387, Final Batch Loss: 0.001646236632950604\n",
      "Epoch 4126, Loss: 0.00013778660286334343, Final Batch Loss: 9.805469744605944e-05\n",
      "Epoch 4127, Loss: 0.00012614573552127695, Final Batch Loss: 0.00011802227527368814\n",
      "Epoch 4128, Loss: 5.7740659030969255e-05, Final Batch Loss: 2.624723310873378e-05\n",
      "Epoch 4129, Loss: 9.638135088607669e-05, Final Batch Loss: 4.79063019156456e-05\n",
      "Epoch 4130, Loss: 0.00191201989127876, Final Batch Loss: 0.0019074020674452186\n",
      "Epoch 4131, Loss: 0.0005523005966097116, Final Batch Loss: 0.00043780700070783496\n",
      "Epoch 4132, Loss: 4.3603600715869106e-05, Final Batch Loss: 1.2390146366669796e-05\n",
      "Epoch 4133, Loss: 6.7962110733788e-05, Final Batch Loss: 2.6685329430620186e-06\n",
      "Epoch 4134, Loss: 2.7443319595477078e-05, Final Batch Loss: 1.4817404007771984e-05\n",
      "Epoch 4135, Loss: 0.0008108969184377202, Final Batch Loss: 3.6889093735226197e-06\n",
      "Epoch 4136, Loss: 6.638194099650718e-05, Final Batch Loss: 4.628687383956276e-05\n",
      "Epoch 4137, Loss: 5.870016320841387e-05, Final Batch Loss: 1.900206189020537e-05\n",
      "Epoch 4138, Loss: 1.7397159808751894e-05, Final Batch Loss: 1.0449171895743348e-05\n",
      "Epoch 4139, Loss: 6.284735945882858e-05, Final Batch Loss: 5.578409763984382e-05\n",
      "Epoch 4140, Loss: 4.0383076111538685e-05, Final Batch Loss: 2.9664458907063818e-06\n",
      "Epoch 4141, Loss: 2.6597324904287234e-05, Final Batch Loss: 1.4656619896413758e-05\n",
      "Epoch 4142, Loss: 1.7783676412364002e-05, Final Batch Loss: 1.1121222996735014e-05\n",
      "Epoch 4143, Loss: 0.00015250265278154984, Final Batch Loss: 0.00012116963625885546\n",
      "Epoch 4144, Loss: 0.00013176091852074023, Final Batch Loss: 7.308515705517493e-06\n",
      "Epoch 4145, Loss: 0.00020967447562725283, Final Batch Loss: 0.00019161308591719717\n",
      "Epoch 4146, Loss: 0.0002748085207713302, Final Batch Loss: 0.00023062950640451163\n",
      "Epoch 4147, Loss: 0.0003550658148014918, Final Batch Loss: 0.0003393613442312926\n",
      "Epoch 4148, Loss: 0.00023777896808496735, Final Batch Loss: 2.5505617031740258e-06\n",
      "Epoch 4149, Loss: 6.75677292747423e-05, Final Batch Loss: 4.014180740341544e-05\n",
      "Epoch 4150, Loss: 0.00029509775868064025, Final Batch Loss: 6.085138920752797e-06\n",
      "Epoch 4151, Loss: 2.6467560928722378e-05, Final Batch Loss: 1.8109871234628372e-05\n",
      "Epoch 4152, Loss: 0.000617795274592936, Final Batch Loss: 0.00024007604224607348\n",
      "Epoch 4153, Loss: 0.0023530040816694964, Final Batch Loss: 0.002339993603527546\n",
      "Epoch 4154, Loss: 0.0004912893723485467, Final Batch Loss: 5.43529449714697e-06\n",
      "Epoch 4155, Loss: 0.00010069505151477642, Final Batch Loss: 1.0674953955458477e-05\n",
      "Epoch 4156, Loss: 0.000128105741168838, Final Batch Loss: 0.00010237334208795801\n",
      "Epoch 4157, Loss: 0.004507054649366182, Final Batch Loss: 0.004487544763833284\n",
      "Epoch 4158, Loss: 0.00015479766079806723, Final Batch Loss: 0.00011038526281481609\n",
      "Epoch 4159, Loss: 5.6251505156978965e-05, Final Batch Loss: 8.229115337599069e-06\n",
      "Epoch 4160, Loss: 5.137952757650055e-05, Final Batch Loss: 1.6603666153969243e-05\n",
      "Epoch 4161, Loss: 0.0016030659317038953, Final Batch Loss: 0.0013412747066468\n",
      "Epoch 4162, Loss: 0.001920463633723557, Final Batch Loss: 0.0018549831584095955\n",
      "Epoch 4163, Loss: 2.2728993371856632e-05, Final Batch Loss: 1.571511347719934e-05\n",
      "Epoch 4164, Loss: 0.00034356585570094467, Final Batch Loss: 3.005084408869152e-06\n",
      "Epoch 4165, Loss: 2.4222123101935722e-05, Final Batch Loss: 8.372006050194614e-06\n",
      "Epoch 4166, Loss: 9.06595187188941e-06, Final Batch Loss: 3.150042175548151e-06\n",
      "Epoch 4167, Loss: 0.05743709827811472, Final Batch Loss: 5.538268396776402e-06\n",
      "Epoch 4168, Loss: 0.00019319577222631779, Final Batch Loss: 0.0001669860939728096\n",
      "Epoch 4169, Loss: 0.00017226565614691935, Final Batch Loss: 0.00013776968989986926\n",
      "Epoch 4170, Loss: 0.0005307738010742469, Final Batch Loss: 2.9621091016451828e-05\n",
      "Epoch 4171, Loss: 0.0033382568799424917, Final Batch Loss: 0.0032234699465334415\n",
      "Epoch 4172, Loss: 0.0001245671901415335, Final Batch Loss: 2.409611079201568e-05\n",
      "Epoch 4173, Loss: 0.00017097593354264973, Final Batch Loss: 0.00016533311281818897\n",
      "Epoch 4174, Loss: 0.0011736740489141084, Final Batch Loss: 0.00010824940545717254\n",
      "Epoch 4175, Loss: 0.0007227679452626035, Final Batch Loss: 5.9949918068014085e-05\n",
      "Epoch 4176, Loss: 0.0001395782019244507, Final Batch Loss: 7.098156493157148e-05\n",
      "Epoch 4177, Loss: 1.4952498986531282e-05, Final Batch Loss: 5.712580332328798e-06\n",
      "Epoch 4178, Loss: 0.0004831956257476122, Final Batch Loss: 1.419432464899728e-05\n",
      "Epoch 4179, Loss: 0.001731138485865813, Final Batch Loss: 0.0017240840243175626\n",
      "Epoch 4180, Loss: 0.00034373090784356464, Final Batch Loss: 2.5820745577220805e-05\n",
      "Epoch 4181, Loss: 0.0010167537686811556, Final Batch Loss: 0.0010138977086171508\n",
      "Epoch 4182, Loss: 0.0011849557795358123, Final Batch Loss: 1.7880303857964464e-05\n",
      "Epoch 4183, Loss: 0.00017458307047490962, Final Batch Loss: 0.00014499899407383054\n",
      "Epoch 4184, Loss: 0.00035288010258227587, Final Batch Loss: 0.0002536045212764293\n",
      "Epoch 4185, Loss: 1.3601542377728038e-05, Final Batch Loss: 7.616887160111219e-06\n",
      "Epoch 4186, Loss: 0.0004895897527603665, Final Batch Loss: 0.0004679984413087368\n",
      "Epoch 4187, Loss: 0.0004616249425453134, Final Batch Loss: 3.205415123375133e-05\n",
      "Epoch 4188, Loss: 0.004044279339723289, Final Batch Loss: 0.001313786837272346\n",
      "Epoch 4189, Loss: 0.0003026483327630558, Final Batch Loss: 0.0002976307296194136\n",
      "Epoch 4190, Loss: 0.00045313518785405904, Final Batch Loss: 0.0002725679660215974\n",
      "Epoch 4191, Loss: 0.0025226122816093266, Final Batch Loss: 0.0004083598614670336\n",
      "Epoch 4192, Loss: 4.838549148189486e-05, Final Batch Loss: 4.587104285747046e-06\n",
      "Epoch 4193, Loss: 2.940991998912068e-05, Final Batch Loss: 2.2873025955050252e-05\n",
      "Epoch 4194, Loss: 0.00010408875095890835, Final Batch Loss: 5.3282830776879564e-05\n",
      "Epoch 4195, Loss: 0.0001453012810088694, Final Batch Loss: 8.367886766791344e-05\n",
      "Epoch 4196, Loss: 0.00013236685481388122, Final Batch Loss: 2.0906496501993388e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4197, Loss: 1.9565470665838802e-05, Final Batch Loss: 7.3433325269434135e-06\n",
      "Epoch 4198, Loss: 0.0001104797593143303, Final Batch Loss: 2.4776974896667525e-05\n",
      "Epoch 4199, Loss: 1.623191656108247e-05, Final Batch Loss: 8.589376193413045e-06\n",
      "Epoch 4200, Loss: 0.0002469221071805805, Final Batch Loss: 0.0001695991086307913\n",
      "Epoch 4201, Loss: 0.000196801993297413, Final Batch Loss: 3.383090370334685e-05\n",
      "Epoch 4202, Loss: 4.9489899538457394e-05, Final Batch Loss: 2.4875012968550436e-05\n",
      "Epoch 4203, Loss: 5.2007117119501345e-05, Final Batch Loss: 3.185227978974581e-05\n",
      "Epoch 4204, Loss: 0.018405319315206725, Final Batch Loss: 0.00010269427002640441\n",
      "Epoch 4205, Loss: 0.00046666724665556103, Final Batch Loss: 0.00041807416710071266\n",
      "Epoch 4206, Loss: 0.00010568032303126529, Final Batch Loss: 5.009504820918664e-05\n",
      "Epoch 4207, Loss: 0.0005951546736469027, Final Batch Loss: 2.2576914489036426e-05\n",
      "Epoch 4208, Loss: 0.0008776879694778472, Final Batch Loss: 0.0003964559582527727\n",
      "Epoch 4209, Loss: 0.0020807071414310485, Final Batch Loss: 0.0002444173733238131\n",
      "Epoch 4210, Loss: 7.998807086551096e-05, Final Batch Loss: 2.9904274924774654e-05\n",
      "Epoch 4211, Loss: 0.0018502060484024696, Final Batch Loss: 0.0017354125156998634\n",
      "Epoch 4212, Loss: 0.002721704811847303, Final Batch Loss: 1.9998093193862587e-05\n",
      "Epoch 4213, Loss: 0.0005341595533536747, Final Batch Loss: 0.0004587904259096831\n",
      "Epoch 4214, Loss: 0.0001050427854352165, Final Batch Loss: 1.1552878277143463e-05\n",
      "Epoch 4215, Loss: 0.00010393635420768987, Final Batch Loss: 8.358027116628364e-05\n",
      "Epoch 4216, Loss: 0.00011552259093150496, Final Batch Loss: 9.465170296607539e-05\n",
      "Epoch 4217, Loss: 0.0015935835690470412, Final Batch Loss: 4.299038846511394e-05\n",
      "Epoch 4218, Loss: 9.824118751566857e-05, Final Batch Loss: 8.982242434285581e-05\n",
      "Epoch 4219, Loss: 0.00028200450105941854, Final Batch Loss: 4.764464028994553e-05\n",
      "Epoch 4220, Loss: 2.8713747269648593e-05, Final Batch Loss: 9.308681001130026e-06\n",
      "Epoch 4221, Loss: 0.001467059482820332, Final Batch Loss: 0.0013811186654493213\n",
      "Epoch 4222, Loss: 0.0003032197455468122, Final Batch Loss: 0.0002928274043370038\n",
      "Epoch 4223, Loss: 0.00018581499386982614, Final Batch Loss: 0.00018482128507457674\n",
      "Epoch 4224, Loss: 0.00011770414494094439, Final Batch Loss: 6.970337562961504e-05\n",
      "Epoch 4225, Loss: 0.00014101573106017895, Final Batch Loss: 3.464040855760686e-05\n",
      "Epoch 4226, Loss: 2.319981558684958e-05, Final Batch Loss: 2.525966010580305e-06\n",
      "Epoch 4227, Loss: 0.00013374849368119612, Final Batch Loss: 4.482366784941405e-05\n",
      "Epoch 4228, Loss: 0.0005832807364640757, Final Batch Loss: 9.150720143225044e-05\n",
      "Epoch 4229, Loss: 6.124119499872904e-05, Final Batch Loss: 1.5531839380855672e-05\n",
      "Epoch 4230, Loss: 0.0005095680608064868, Final Batch Loss: 0.0004251272766850889\n",
      "Epoch 4231, Loss: 0.0003948291086999234, Final Batch Loss: 4.855708539253101e-06\n",
      "Epoch 4232, Loss: 5.6686818425077945e-05, Final Batch Loss: 5.253264316706918e-05\n",
      "Epoch 4233, Loss: 0.0002040882536675781, Final Batch Loss: 0.0001241943973582238\n",
      "Epoch 4234, Loss: 0.00014085146813158644, Final Batch Loss: 0.00012579132453538477\n",
      "Epoch 4235, Loss: 5.528251153918973e-05, Final Batch Loss: 2.41236944020784e-06\n",
      "Epoch 4236, Loss: 0.0032119339123255486, Final Batch Loss: 1.5483494735235581e-06\n",
      "Epoch 4237, Loss: 0.0004531980493993615, Final Batch Loss: 0.00044874579180032015\n",
      "Epoch 4238, Loss: 0.0005637638703319681, Final Batch Loss: 1.0659302915883018e-06\n",
      "Epoch 4239, Loss: 7.572724916826701e-05, Final Batch Loss: 7.731773621344473e-06\n",
      "Epoch 4240, Loss: 0.0007619641983183101, Final Batch Loss: 0.000708620878867805\n",
      "Epoch 4241, Loss: 0.007948734830279136, Final Batch Loss: 3.329015817143954e-05\n",
      "Epoch 4242, Loss: 0.00028212531833560206, Final Batch Loss: 3.795430893660523e-05\n",
      "Epoch 4243, Loss: 0.00020317552480264567, Final Batch Loss: 9.286999556934461e-06\n",
      "Epoch 4244, Loss: 0.006327469969619415, Final Batch Loss: 0.006309021729975939\n",
      "Epoch 4245, Loss: 0.024133639513820526, Final Batch Loss: 2.7442454666015692e-05\n",
      "Epoch 4246, Loss: 0.0002311175467184512, Final Batch Loss: 2.8841441235272214e-06\n",
      "Epoch 4247, Loss: 0.0008364979657926597, Final Batch Loss: 1.71213541761972e-05\n",
      "Epoch 4248, Loss: 0.0001337489411525894, Final Batch Loss: 9.023502934724092e-05\n",
      "Epoch 4249, Loss: 0.0002884938985516783, Final Batch Loss: 0.00024261855287477374\n",
      "Epoch 4250, Loss: 0.0001650471949687926, Final Batch Loss: 0.00014073424972593784\n",
      "Epoch 4251, Loss: 0.00012771266665367875, Final Batch Loss: 1.912244078994263e-05\n",
      "Epoch 4252, Loss: 0.00011027040636690799, Final Batch Loss: 9.159980982076377e-05\n",
      "Epoch 4253, Loss: 0.004656048615288455, Final Batch Loss: 0.004570845514535904\n",
      "Epoch 4254, Loss: 0.00031220993696479127, Final Batch Loss: 0.00011900789831997827\n",
      "Epoch 4255, Loss: 0.0007256689568748698, Final Batch Loss: 0.00018823221034836024\n",
      "Epoch 4256, Loss: 0.0002630308190418873, Final Batch Loss: 5.582053927355446e-05\n",
      "Epoch 4257, Loss: 0.00010853129788301885, Final Batch Loss: 9.695816697785631e-05\n",
      "Epoch 4258, Loss: 0.0037396838306449354, Final Batch Loss: 8.927698945626616e-05\n",
      "Epoch 4259, Loss: 0.0022725478920619935, Final Batch Loss: 0.0004740984586533159\n",
      "Epoch 4260, Loss: 5.057095404481515e-05, Final Batch Loss: 3.3479118428658694e-05\n",
      "Epoch 4261, Loss: 0.001030664425343275, Final Batch Loss: 0.00017517595551908016\n",
      "Epoch 4262, Loss: 1.9444663394097006e-05, Final Batch Loss: 5.738516392739257e-06\n",
      "Epoch 4263, Loss: 0.000189202866749838, Final Batch Loss: 0.00011248974624322727\n",
      "Epoch 4264, Loss: 0.0003564896614989266, Final Batch Loss: 0.00028948026010766625\n",
      "Epoch 4265, Loss: 0.00012162924758740701, Final Batch Loss: 6.723882688675076e-05\n",
      "Epoch 4266, Loss: 0.000977557894657366, Final Batch Loss: 0.000814062834251672\n",
      "Epoch 4267, Loss: 0.002623895154101774, Final Batch Loss: 0.002612195210531354\n",
      "Epoch 4268, Loss: 0.00026316052390029654, Final Batch Loss: 0.00020029788720421493\n",
      "Epoch 4269, Loss: 0.0003137488238280639, Final Batch Loss: 9.617750765755773e-05\n",
      "Epoch 4270, Loss: 0.000197945394575072, Final Batch Loss: 7.657726200704928e-06\n",
      "Epoch 4271, Loss: 4.356076715339441e-05, Final Batch Loss: 2.636600584082771e-05\n",
      "Epoch 4272, Loss: 0.0005955865474334132, Final Batch Loss: 1.1283539151918376e-06\n",
      "Epoch 4273, Loss: 0.0006628662886214443, Final Batch Loss: 8.544722368242219e-05\n",
      "Epoch 4274, Loss: 0.0001763014806783758, Final Batch Loss: 0.00011096663365606219\n",
      "Epoch 4275, Loss: 0.0020319167524576187, Final Batch Loss: 9.880342986434698e-05\n",
      "Epoch 4276, Loss: 0.0005139190270710969, Final Batch Loss: 1.909680759126786e-05\n",
      "Epoch 4277, Loss: 4.5418257286655717e-05, Final Batch Loss: 2.45073351834435e-05\n",
      "Epoch 4278, Loss: 3.765665042010369e-05, Final Batch Loss: 3.840458703052718e-06\n",
      "Epoch 4279, Loss: 0.0001260290848108525, Final Batch Loss: 4.5854193331251736e-07\n",
      "Epoch 4280, Loss: 7.758799347357126e-05, Final Batch Loss: 5.134262210049201e-06\n",
      "Epoch 4281, Loss: 0.006842486383902724, Final Batch Loss: 1.1542635547812097e-05\n",
      "Epoch 4282, Loss: 7.269028333212191e-05, Final Batch Loss: 2.8467291031120112e-06\n",
      "Epoch 4283, Loss: 0.00039896620000945404, Final Batch Loss: 6.206418765941635e-05\n",
      "Epoch 4284, Loss: 0.00025714689763844945, Final Batch Loss: 4.938351412420161e-05\n",
      "Epoch 4285, Loss: 0.0012137359585722152, Final Batch Loss: 7.2599500526848715e-06\n",
      "Epoch 4286, Loss: 0.00012191377754788846, Final Batch Loss: 0.00010565987031441182\n",
      "Epoch 4287, Loss: 5.122889706399292e-05, Final Batch Loss: 3.77547403331846e-05\n",
      "Epoch 4288, Loss: 0.0005190759584365878, Final Batch Loss: 0.00048468136810697615\n",
      "Epoch 4289, Loss: 0.00024082822619675426, Final Batch Loss: 1.3318403034645598e-05\n",
      "Epoch 4290, Loss: 3.623624706960982e-05, Final Batch Loss: 1.042612439050572e-05\n",
      "Epoch 4291, Loss: 5.3248928452376276e-05, Final Batch Loss: 2.3588690964970738e-06\n",
      "Epoch 4292, Loss: 0.000837015533761587, Final Batch Loss: 0.0007803593762218952\n",
      "Epoch 4293, Loss: 0.00012798009629477747, Final Batch Loss: 7.03292535035871e-05\n",
      "Epoch 4294, Loss: 0.0001481322569816257, Final Batch Loss: 0.00013516726903617382\n",
      "Epoch 4295, Loss: 0.0005765204805356916, Final Batch Loss: 0.0005607493221759796\n",
      "Epoch 4296, Loss: 9.183372458210215e-05, Final Batch Loss: 4.3286207073833793e-05\n",
      "Epoch 4297, Loss: 8.485852595185861e-05, Final Batch Loss: 3.697742795338854e-05\n",
      "Epoch 4298, Loss: 8.589581375417765e-05, Final Batch Loss: 6.98250369168818e-05\n",
      "Epoch 4299, Loss: 2.9172270842536818e-05, Final Batch Loss: 2.4140463210642338e-05\n",
      "Epoch 4300, Loss: 0.001743149034155067, Final Batch Loss: 0.001731059979647398\n",
      "Epoch 4301, Loss: 4.782662290381268e-05, Final Batch Loss: 1.5147106751101092e-05\n",
      "Epoch 4302, Loss: 2.6398890440759715e-05, Final Batch Loss: 1.8773411284200847e-05\n",
      "Epoch 4303, Loss: 0.0001985798098758096, Final Batch Loss: 2.9860291760996915e-05\n",
      "Epoch 4304, Loss: 3.4659816265047994e-05, Final Batch Loss: 2.6079687813762575e-05\n",
      "Epoch 4305, Loss: 9.004275852930732e-05, Final Batch Loss: 1.9854578567901626e-05\n",
      "Epoch 4306, Loss: 7.455952982127201e-05, Final Batch Loss: 6.282667891355231e-05\n",
      "Epoch 4307, Loss: 0.0003105364703515079, Final Batch Loss: 1.0666899470379576e-05\n",
      "Epoch 4308, Loss: 7.356257583523984e-06, Final Batch Loss: 5.2082978072576225e-06\n",
      "Epoch 4309, Loss: 0.0002986744075315073, Final Batch Loss: 0.00022149879077915102\n",
      "Epoch 4310, Loss: 0.00014262236618378665, Final Batch Loss: 1.7982578356168233e-05\n",
      "Epoch 4311, Loss: 0.00035774497519014403, Final Batch Loss: 0.00023878677166067064\n",
      "Epoch 4312, Loss: 0.0004896648661087966, Final Batch Loss: 1.9148483261233196e-06\n",
      "Epoch 4313, Loss: 6.558242057508323e-05, Final Batch Loss: 7.916305548860691e-06\n",
      "Epoch 4314, Loss: 0.0007072080638863554, Final Batch Loss: 0.0007044345838949084\n",
      "Epoch 4315, Loss: 0.000976639114014688, Final Batch Loss: 0.0009526556823402643\n",
      "Epoch 4316, Loss: 0.00021404058361440548, Final Batch Loss: 4.961241302225972e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4317, Loss: 0.0001173700948129408, Final Batch Loss: 3.653767635114491e-05\n",
      "Epoch 4318, Loss: 0.0003113190405201749, Final Batch Loss: 0.0003006476617883891\n",
      "Epoch 4319, Loss: 3.466137013674597e-05, Final Batch Loss: 3.313602792331949e-05\n",
      "Epoch 4320, Loss: 0.000141149135743035, Final Batch Loss: 6.085866698413156e-05\n",
      "Epoch 4321, Loss: 0.002321835534530692, Final Batch Loss: 0.002215311862528324\n",
      "Epoch 4322, Loss: 1.8647661363502266e-05, Final Batch Loss: 1.8957821339427028e-06\n",
      "Epoch 4323, Loss: 6.2377548601944e-05, Final Batch Loss: 4.035817983094603e-05\n",
      "Epoch 4324, Loss: 1.14415779535193e-05, Final Batch Loss: 4.488919330469798e-06\n",
      "Epoch 4325, Loss: 5.080327525774919e-06, Final Batch Loss: 4.299280135455774e-06\n",
      "Epoch 4326, Loss: 4.530670412350446e-05, Final Batch Loss: 3.7965983210597187e-06\n",
      "Epoch 4327, Loss: 0.0018976039327753824, Final Batch Loss: 1.3159199625079054e-05\n",
      "Epoch 4328, Loss: 0.0015400928969029337, Final Batch Loss: 0.0002993950911331922\n",
      "Epoch 4329, Loss: 3.509475209284574e-05, Final Batch Loss: 5.117022737977095e-06\n",
      "Epoch 4330, Loss: 0.0020029427359986585, Final Batch Loss: 8.405546395806596e-06\n",
      "Epoch 4331, Loss: 3.444946941044691e-06, Final Batch Loss: 3.1369124826596817e-06\n",
      "Epoch 4332, Loss: 1.598727061491445e-05, Final Batch Loss: 5.159362785889243e-07\n",
      "Epoch 4333, Loss: 0.0001653214062571351, Final Batch Loss: 4.232210812915582e-07\n",
      "Epoch 4334, Loss: 0.0002314073353772983, Final Batch Loss: 5.883573612663895e-05\n",
      "Epoch 4335, Loss: 0.00023403906173768974, Final Batch Loss: 1.5200724590158643e-07\n",
      "Epoch 4336, Loss: 0.00012697202328126878, Final Batch Loss: 8.86488487594761e-05\n",
      "Epoch 4337, Loss: 0.00018143564557249192, Final Batch Loss: 0.00015988269296940416\n",
      "Epoch 4338, Loss: 1.683183745626593e-05, Final Batch Loss: 6.159390977700241e-06\n",
      "Epoch 4339, Loss: 0.000148767036080244, Final Batch Loss: 1.651512684475165e-05\n",
      "Epoch 4340, Loss: 3.279979955550516e-05, Final Batch Loss: 1.889091799966991e-05\n",
      "Epoch 4341, Loss: 0.0001883347431430593, Final Batch Loss: 9.727846918394789e-05\n",
      "Epoch 4342, Loss: 9.054712620581995e-05, Final Batch Loss: 1.5464703437828575e-06\n",
      "Epoch 4343, Loss: 0.00033212656671821605, Final Batch Loss: 0.0003105022478848696\n",
      "Epoch 4344, Loss: 0.0002850286196007801, Final Batch Loss: 0.0002795633627101779\n",
      "Epoch 4345, Loss: 0.009213933197315782, Final Batch Loss: 0.008800660260021687\n",
      "Epoch 4346, Loss: 0.00038754093475290574, Final Batch Loss: 9.883169695967808e-06\n",
      "Epoch 4347, Loss: 0.00014663327237940393, Final Batch Loss: 1.4009096048539504e-05\n",
      "Epoch 4348, Loss: 0.029052150435745716, Final Batch Loss: 0.015420141629874706\n",
      "Epoch 4349, Loss: 1.77198080564267e-05, Final Batch Loss: 9.713359759189188e-06\n",
      "Epoch 4350, Loss: 0.0001309570443481789, Final Batch Loss: 1.2690311450569425e-05\n",
      "Epoch 4351, Loss: 9.340871588392474e-05, Final Batch Loss: 9.003732702694833e-05\n",
      "Epoch 4352, Loss: 0.00013083689555060118, Final Batch Loss: 3.4809701901394874e-05\n",
      "Epoch 4353, Loss: 0.0006935004621482221, Final Batch Loss: 0.0006752258632332087\n",
      "Epoch 4354, Loss: 0.0003941053910239134, Final Batch Loss: 0.00034395104739814997\n",
      "Epoch 4355, Loss: 0.00013570084774983115, Final Batch Loss: 2.271950143040158e-05\n",
      "Epoch 4356, Loss: 0.0009785193851712393, Final Batch Loss: 1.944339783221949e-05\n",
      "Epoch 4357, Loss: 0.09821337333414704, Final Batch Loss: 0.09740106016397476\n",
      "Epoch 4358, Loss: 0.01873307500500232, Final Batch Loss: 0.0004163013072684407\n",
      "Epoch 4359, Loss: 0.03037967019372445, Final Batch Loss: 0.03035181760787964\n",
      "Epoch 4360, Loss: 0.007546907989308238, Final Batch Loss: 0.00043904013000428677\n",
      "Epoch 4361, Loss: 0.015937570060486905, Final Batch Loss: 5.558649718295783e-05\n",
      "Epoch 4362, Loss: 0.0001833551868912764, Final Batch Loss: 0.00010503859812160954\n",
      "Epoch 4363, Loss: 0.0016790092922747135, Final Batch Loss: 0.0014215405099093914\n",
      "Epoch 4364, Loss: 0.0006934026314411312, Final Batch Loss: 0.00040113157592713833\n",
      "Epoch 4365, Loss: 0.0016783304781711195, Final Batch Loss: 0.0016238191165030003\n",
      "Epoch 4366, Loss: 0.0005753767836722545, Final Batch Loss: 3.9075959648471326e-05\n",
      "Epoch 4367, Loss: 0.0002725475605984684, Final Batch Loss: 0.0002356320183025673\n",
      "Epoch 4368, Loss: 0.0006227020785445347, Final Batch Loss: 0.0004663064028136432\n",
      "Epoch 4369, Loss: 0.0007471421849913895, Final Batch Loss: 0.00027749224682338536\n",
      "Epoch 4370, Loss: 0.012195851013530046, Final Batch Loss: 0.011916997842490673\n",
      "Epoch 4371, Loss: 0.0010642490124155302, Final Batch Loss: 1.9372255337657407e-05\n",
      "Epoch 4372, Loss: 0.00029102440748829395, Final Batch Loss: 0.00012817757669836283\n",
      "Epoch 4373, Loss: 0.00036972238740418106, Final Batch Loss: 0.000104258579085581\n",
      "Epoch 4374, Loss: 0.0008313009166158736, Final Batch Loss: 0.0007817219593562186\n",
      "Epoch 4375, Loss: 0.00318057146796491, Final Batch Loss: 0.0030036126263439655\n",
      "Epoch 4376, Loss: 0.0038820696354378015, Final Batch Loss: 0.003681889269500971\n",
      "Epoch 4377, Loss: 0.0008885687566362321, Final Batch Loss: 0.0007053093868307769\n",
      "Epoch 4378, Loss: 0.00032923997059697285, Final Batch Loss: 0.00023101319675333798\n",
      "Epoch 4379, Loss: 0.008220284347771667, Final Batch Loss: 0.008054331876337528\n",
      "Epoch 4380, Loss: 0.0005036491493228823, Final Batch Loss: 0.0003410446806810796\n",
      "Epoch 4381, Loss: 0.0007875823503127322, Final Batch Loss: 0.0007023895159363747\n",
      "Epoch 4382, Loss: 0.00023474842237192206, Final Batch Loss: 5.316210081218742e-05\n",
      "Epoch 4383, Loss: 0.001505041538621299, Final Batch Loss: 6.943514745216817e-05\n",
      "Epoch 4384, Loss: 0.0011040554963983595, Final Batch Loss: 0.0005156054976396263\n",
      "Epoch 4385, Loss: 0.0005326387763489038, Final Batch Loss: 0.0001465010573156178\n",
      "Epoch 4386, Loss: 0.0004407053784234449, Final Batch Loss: 0.00014626311894971877\n",
      "Epoch 4387, Loss: 0.0017174366221297532, Final Batch Loss: 0.0001125298731494695\n",
      "Epoch 4388, Loss: 0.0004680985221057199, Final Batch Loss: 8.47698756842874e-05\n",
      "Epoch 4389, Loss: 0.0005552168586291373, Final Batch Loss: 0.00041767876246012747\n",
      "Epoch 4390, Loss: 0.00019583094399422407, Final Batch Loss: 2.815357584040612e-05\n",
      "Epoch 4391, Loss: 0.0012308075092732906, Final Batch Loss: 0.0007049276609905064\n",
      "Epoch 4392, Loss: 0.0001337452977168141, Final Batch Loss: 0.00010348603245802224\n",
      "Epoch 4393, Loss: 0.0018148076487705112, Final Batch Loss: 0.0005815715994685888\n",
      "Epoch 4394, Loss: 0.001346361983451061, Final Batch Loss: 0.00011947266466449946\n",
      "Epoch 4395, Loss: 0.0020505127467913553, Final Batch Loss: 0.00014598311099689454\n",
      "Epoch 4396, Loss: 0.00013168947771191597, Final Batch Loss: 4.122054815525189e-05\n",
      "Epoch 4397, Loss: 0.0005768759074271657, Final Batch Loss: 4.588600859278813e-05\n",
      "Epoch 4398, Loss: 0.0017353906496282434, Final Batch Loss: 0.0017082041595131159\n",
      "Epoch 4399, Loss: 0.0002483199004927883, Final Batch Loss: 2.2894158973940648e-05\n",
      "Epoch 4400, Loss: 0.0007996243368779687, Final Batch Loss: 0.0007958748028613627\n",
      "Epoch 4401, Loss: 0.003363301802892238, Final Batch Loss: 0.0029360849875956774\n",
      "Epoch 4402, Loss: 0.0004745571859530173, Final Batch Loss: 4.459718911675736e-05\n",
      "Epoch 4403, Loss: 0.00018062196613755077, Final Batch Loss: 6.40148573438637e-05\n",
      "Epoch 4404, Loss: 0.00033691075805108994, Final Batch Loss: 0.00014390672731678933\n",
      "Epoch 4405, Loss: 0.00014939178072381765, Final Batch Loss: 2.4054956156760454e-05\n",
      "Epoch 4406, Loss: 0.00013025043881498277, Final Batch Loss: 9.613272413844243e-05\n",
      "Epoch 4407, Loss: 0.0030587945684601436, Final Batch Loss: 5.463053639687132e-06\n",
      "Epoch 4408, Loss: 0.00029701957373617915, Final Batch Loss: 1.0736020158219617e-05\n",
      "Epoch 4409, Loss: 0.00037400554901978467, Final Batch Loss: 1.4185812688083388e-05\n",
      "Epoch 4410, Loss: 6.048994691809639e-05, Final Batch Loss: 3.9069731428753585e-05\n",
      "Epoch 4411, Loss: 0.0001427019578841282, Final Batch Loss: 0.00012009281635982916\n",
      "Epoch 4412, Loss: 0.0009971681865863502, Final Batch Loss: 0.00017414282774552703\n",
      "Epoch 4413, Loss: 0.0007641492411494255, Final Batch Loss: 0.000710036139935255\n",
      "Epoch 4414, Loss: 0.000396884985093493, Final Batch Loss: 0.00028543456573970616\n",
      "Epoch 4415, Loss: 0.01206395617191447, Final Batch Loss: 0.011989263817667961\n",
      "Epoch 4416, Loss: 5.7422308600507677e-05, Final Batch Loss: 3.27425186696928e-05\n",
      "Epoch 4417, Loss: 0.0007877161842770875, Final Batch Loss: 0.000615956902038306\n",
      "Epoch 4418, Loss: 0.0005955013912171125, Final Batch Loss: 0.000544340698979795\n",
      "Epoch 4419, Loss: 6.305830902419984e-05, Final Batch Loss: 4.1586055886000395e-05\n",
      "Epoch 4420, Loss: 0.0003320996020192979, Final Batch Loss: 0.0003018923453055322\n",
      "Epoch 4421, Loss: 4.8494191560166655e-05, Final Batch Loss: 6.935809778951807e-06\n",
      "Epoch 4422, Loss: 0.0012847315265389625, Final Batch Loss: 3.480349914752878e-05\n",
      "Epoch 4423, Loss: 0.0002698446187423542, Final Batch Loss: 0.00012002904259134084\n",
      "Epoch 4424, Loss: 8.605028961028438e-05, Final Batch Loss: 7.31740947230719e-05\n",
      "Epoch 4425, Loss: 0.0005860333658347372, Final Batch Loss: 4.388406887301244e-05\n",
      "Epoch 4426, Loss: 0.0008874324958014768, Final Batch Loss: 3.8396694435505196e-05\n",
      "Epoch 4427, Loss: 0.00037928667734377086, Final Batch Loss: 0.00013338142889551818\n",
      "Epoch 4428, Loss: 0.0016892779967747629, Final Batch Loss: 0.0015381834236904979\n",
      "Epoch 4429, Loss: 0.0006499910778074991, Final Batch Loss: 1.4752480637980625e-05\n",
      "Epoch 4430, Loss: 0.0007050294807413593, Final Batch Loss: 0.0005230495589785278\n",
      "Epoch 4431, Loss: 0.00042433368071215227, Final Batch Loss: 0.0003738654777407646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4432, Loss: 0.00023173828958533704, Final Batch Loss: 3.5850549465976655e-05\n",
      "Epoch 4433, Loss: 0.0001690099361439934, Final Batch Loss: 1.6685769878677092e-05\n",
      "Epoch 4434, Loss: 0.00014316812666947953, Final Batch Loss: 9.208968549501151e-05\n",
      "Epoch 4435, Loss: 0.00019433822490100283, Final Batch Loss: 0.00018695008475333452\n",
      "Epoch 4436, Loss: 0.0005002115576644428, Final Batch Loss: 0.00043855392141267657\n",
      "Epoch 4437, Loss: 0.00011492382691358216, Final Batch Loss: 3.393358565517701e-05\n",
      "Epoch 4438, Loss: 0.00015759410143800778, Final Batch Loss: 6.7477258198778145e-06\n",
      "Epoch 4439, Loss: 1.7644652871240396e-05, Final Batch Loss: 9.311563189839944e-06\n",
      "Epoch 4440, Loss: 5.921859656154993e-05, Final Batch Loss: 5.059038358012913e-06\n",
      "Epoch 4441, Loss: 0.004080950631760061, Final Batch Loss: 0.0003553625429049134\n",
      "Epoch 4442, Loss: 7.921957512735389e-05, Final Batch Loss: 4.864096626988612e-05\n",
      "Epoch 4443, Loss: 2.2856038413010538e-05, Final Batch Loss: 1.3347163076105062e-05\n",
      "Epoch 4444, Loss: 5.8533722040010616e-05, Final Batch Loss: 1.802246697479859e-05\n",
      "Epoch 4445, Loss: 0.00018888463182520354, Final Batch Loss: 1.097195581678534e-05\n",
      "Epoch 4446, Loss: 0.00023347887133695622, Final Batch Loss: 1.7710098063616897e-06\n",
      "Epoch 4447, Loss: 0.0011690482433550642, Final Batch Loss: 0.001164636225439608\n",
      "Epoch 4448, Loss: 0.00010135241609532386, Final Batch Loss: 3.846167237497866e-05\n",
      "Epoch 4449, Loss: 0.00012274676009838004, Final Batch Loss: 9.324092388851568e-05\n",
      "Epoch 4450, Loss: 0.0015607491150149144, Final Batch Loss: 0.0015240899519994855\n",
      "Epoch 4451, Loss: 0.0005852557314938167, Final Batch Loss: 0.0005691120750270784\n",
      "Epoch 4452, Loss: 0.0003374331572558731, Final Batch Loss: 0.00018575042486190796\n",
      "Epoch 4453, Loss: 0.0005429859666037373, Final Batch Loss: 5.261733167571947e-05\n",
      "Epoch 4454, Loss: 0.0001338956044492079, Final Batch Loss: 0.00010578166984487325\n",
      "Epoch 4455, Loss: 0.00012816257049053092, Final Batch Loss: 0.00012084402260370553\n",
      "Epoch 4456, Loss: 7.95444029790815e-05, Final Batch Loss: 5.046122896601446e-05\n",
      "Epoch 4457, Loss: 9.947919534170069e-05, Final Batch Loss: 5.243325722403824e-05\n",
      "Epoch 4458, Loss: 0.00020230930522302515, Final Batch Loss: 0.00019726685422938317\n",
      "Epoch 4459, Loss: 0.0014873492109472863, Final Batch Loss: 0.001453173579648137\n",
      "Epoch 4460, Loss: 0.0002411633904557675, Final Batch Loss: 0.00017861631931737065\n",
      "Epoch 4461, Loss: 5.495993173099123e-05, Final Batch Loss: 4.721393634099513e-05\n",
      "Epoch 4462, Loss: 2.8356368602544535e-05, Final Batch Loss: 8.038187843339983e-06\n",
      "Epoch 4463, Loss: 1.7783463135856437e-05, Final Batch Loss: 1.3479904737323523e-05\n",
      "Epoch 4464, Loss: 1.4299489521363284e-05, Final Batch Loss: 4.3915033529629e-06\n",
      "Epoch 4465, Loss: 5.235218850430101e-05, Final Batch Loss: 2.5588706193957478e-05\n",
      "Epoch 4466, Loss: 2.5840499347395962e-05, Final Batch Loss: 2.2807096684118733e-05\n",
      "Epoch 4467, Loss: 1.3136952929926338e-05, Final Batch Loss: 6.995424428168917e-06\n",
      "Epoch 4468, Loss: 0.0001580179450684227, Final Batch Loss: 3.123487840639427e-05\n",
      "Epoch 4469, Loss: 0.00010809371451614425, Final Batch Loss: 5.391348895500414e-05\n",
      "Epoch 4470, Loss: 7.68216596043203e-05, Final Batch Loss: 1.4468616427620873e-05\n",
      "Epoch 4471, Loss: 0.006464519716246286, Final Batch Loss: 1.824897844926454e-05\n",
      "Epoch 4472, Loss: 0.0006804872391512617, Final Batch Loss: 0.0006030804943293333\n",
      "Epoch 4473, Loss: 0.0008828215359244496, Final Batch Loss: 0.0005023711710236967\n",
      "Epoch 4474, Loss: 0.0005033491727317596, Final Batch Loss: 1.2027996945107589e-06\n",
      "Epoch 4475, Loss: 0.00014011590246809646, Final Batch Loss: 1.9463965145405382e-05\n",
      "Epoch 4476, Loss: 5.3073310482432134e-05, Final Batch Loss: 3.169076444464736e-05\n",
      "Epoch 4477, Loss: 7.657311243747245e-06, Final Batch Loss: 6.510059392894618e-06\n",
      "Epoch 4478, Loss: 8.91625622898573e-05, Final Batch Loss: 7.374578126473352e-05\n",
      "Epoch 4479, Loss: 3.207428380846977e-05, Final Batch Loss: 1.52754091686802e-05\n",
      "Epoch 4480, Loss: 0.0032173558959129878, Final Batch Loss: 0.003216129494830966\n",
      "Epoch 4481, Loss: 2.2452876692113932e-05, Final Batch Loss: 4.849068318435457e-06\n",
      "Epoch 4482, Loss: 1.2019467249047011e-05, Final Batch Loss: 5.961668193776859e-06\n",
      "Epoch 4483, Loss: 8.147812786774011e-05, Final Batch Loss: 1.4764855222892947e-06\n",
      "Epoch 4484, Loss: 0.00037645697011612356, Final Batch Loss: 0.0002952360373456031\n",
      "Epoch 4485, Loss: 8.12296275398694e-05, Final Batch Loss: 4.097315832041204e-05\n",
      "Epoch 4486, Loss: 0.000686360195686575, Final Batch Loss: 7.567021384602413e-05\n",
      "Epoch 4487, Loss: 0.0005172545402274409, Final Batch Loss: 0.0005103889852762222\n",
      "Epoch 4488, Loss: 9.966795914806426e-05, Final Batch Loss: 7.28504965081811e-05\n",
      "Epoch 4489, Loss: 0.0002519460758776404, Final Batch Loss: 0.0001020308627630584\n",
      "Epoch 4490, Loss: 5.137673542776611e-05, Final Batch Loss: 4.018480103695765e-05\n",
      "Epoch 4491, Loss: 0.00022637176152784377, Final Batch Loss: 9.169573604594916e-05\n",
      "Epoch 4492, Loss: 8.017687741812551e-05, Final Batch Loss: 6.659412611043081e-05\n",
      "Epoch 4493, Loss: 0.001079174817277817, Final Batch Loss: 5.7602428569225594e-05\n",
      "Epoch 4494, Loss: 7.415170875901822e-05, Final Batch Loss: 6.462667079176754e-05\n",
      "Epoch 4495, Loss: 5.2051912007300416e-05, Final Batch Loss: 3.4075624171236996e-06\n",
      "Epoch 4496, Loss: 9.899378892441746e-05, Final Batch Loss: 7.0188230893109e-05\n",
      "Epoch 4497, Loss: 0.0036316101359261665, Final Batch Loss: 3.4470755053916946e-05\n",
      "Epoch 4498, Loss: 0.00020167219736322295, Final Batch Loss: 0.00017588234914001077\n",
      "Epoch 4499, Loss: 0.00014571224164683372, Final Batch Loss: 0.00010988472058670595\n",
      "Epoch 4500, Loss: 0.0027572406997933285, Final Batch Loss: 0.0027362725231796503\n",
      "Epoch 4501, Loss: 0.0002806076990964357, Final Batch Loss: 7.276747055584565e-06\n",
      "Epoch 4502, Loss: 7.15194964868715e-05, Final Batch Loss: 4.4922035158379e-06\n",
      "Epoch 4503, Loss: 0.0003350229853822384, Final Batch Loss: 5.20881476404611e-05\n",
      "Epoch 4504, Loss: 0.00014152481526252814, Final Batch Loss: 0.00010101178486365825\n",
      "Epoch 4505, Loss: 3.4421112104610074e-05, Final Batch Loss: 1.342625455436064e-05\n",
      "Epoch 4506, Loss: 0.00016996732210827759, Final Batch Loss: 1.1760660527215805e-05\n",
      "Epoch 4507, Loss: 9.919793001245125e-06, Final Batch Loss: 3.7186130157351727e-06\n",
      "Epoch 4508, Loss: 0.00032974070927593857, Final Batch Loss: 0.0001611612387932837\n",
      "Epoch 4509, Loss: 0.0008940082479966804, Final Batch Loss: 0.0006813433137722313\n",
      "Epoch 4510, Loss: 0.00021252490478218533, Final Batch Loss: 0.00016801197489257902\n",
      "Epoch 4511, Loss: 0.0006583667563972995, Final Batch Loss: 0.0001481759682064876\n",
      "Epoch 4512, Loss: 0.00028684493281616597, Final Batch Loss: 3.130665390926879e-06\n",
      "Epoch 4513, Loss: 4.1765370951907244e-05, Final Batch Loss: 7.436784471792635e-06\n",
      "Epoch 4514, Loss: 5.436841365735745e-05, Final Batch Loss: 4.487815385800786e-05\n",
      "Epoch 4515, Loss: 0.0001319671246164944, Final Batch Loss: 7.811043178662658e-05\n",
      "Epoch 4516, Loss: 0.00016496815669597709, Final Batch Loss: 0.00015903718303889036\n",
      "Epoch 4517, Loss: 1.825894605644862e-05, Final Batch Loss: 1.2793073437933344e-05\n",
      "Epoch 4518, Loss: 8.983468433143571e-06, Final Batch Loss: 2.901841980929021e-06\n",
      "Epoch 4519, Loss: 0.0010145194246433675, Final Batch Loss: 0.0006615330930799246\n",
      "Epoch 4520, Loss: 0.00023904797853901982, Final Batch Loss: 4.3707259465008974e-05\n",
      "Epoch 4521, Loss: 4.285428258299362e-05, Final Batch Loss: 7.873610229580663e-06\n",
      "Epoch 4522, Loss: 0.0010385029163444415, Final Batch Loss: 0.00020950725593138486\n",
      "Epoch 4523, Loss: 2.5066546186280902e-05, Final Batch Loss: 1.807753142202273e-05\n",
      "Epoch 4524, Loss: 0.00013166698408895172, Final Batch Loss: 9.999640315072611e-05\n",
      "Epoch 4525, Loss: 9.837364086706657e-05, Final Batch Loss: 6.0860274970764294e-06\n",
      "Epoch 4526, Loss: 0.0010485117509233532, Final Batch Loss: 2.4750288503128104e-05\n",
      "Epoch 4527, Loss: 0.00017025463057507295, Final Batch Loss: 0.0001653492945479229\n",
      "Epoch 4528, Loss: 0.0001597235786903184, Final Batch Loss: 2.3147160391090438e-05\n",
      "Epoch 4529, Loss: 5.905792249905062e-05, Final Batch Loss: 6.435966952267336e-06\n",
      "Epoch 4530, Loss: 7.125252886908129e-05, Final Batch Loss: 5.405949195846915e-05\n",
      "Epoch 4531, Loss: 2.1800805370730814e-05, Final Batch Loss: 5.99625946051674e-06\n",
      "Epoch 4532, Loss: 0.000105008057289524, Final Batch Loss: 8.929553587222472e-05\n",
      "Epoch 4533, Loss: 0.0022595199407078326, Final Batch Loss: 0.0015521561726927757\n",
      "Epoch 4534, Loss: 9.676988156570587e-06, Final Batch Loss: 6.278356522670947e-06\n",
      "Epoch 4535, Loss: 3.479886709101265e-05, Final Batch Loss: 2.323591979802586e-05\n",
      "Epoch 4536, Loss: 4.170659212832106e-05, Final Batch Loss: 3.532990376697853e-05\n",
      "Epoch 4537, Loss: 7.045594884402817e-06, Final Batch Loss: 1.9287340364826377e-06\n",
      "Epoch 4538, Loss: 0.0002798659261316061, Final Batch Loss: 0.00019429750682320446\n",
      "Epoch 4539, Loss: 0.0001127848336182069, Final Batch Loss: 7.88921388448216e-05\n",
      "Epoch 4540, Loss: 0.0011215486301807687, Final Batch Loss: 1.5356854419223964e-05\n",
      "Epoch 4541, Loss: 2.1989673768985085e-05, Final Batch Loss: 1.637547029531561e-05\n",
      "Epoch 4542, Loss: 0.0042730391141958535, Final Batch Loss: 0.003548631677404046\n",
      "Epoch 4543, Loss: 4.15847262047464e-05, Final Batch Loss: 3.246677079005167e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4544, Loss: 6.001382007525535e-05, Final Batch Loss: 6.273138751566876e-06\n",
      "Epoch 4545, Loss: 0.0009219957871664519, Final Batch Loss: 0.0009192375582642853\n",
      "Epoch 4546, Loss: 0.0035157922247890383, Final Batch Loss: 0.00013469011173583567\n",
      "Epoch 4547, Loss: 0.000444230689026881, Final Batch Loss: 3.7404017348308116e-05\n",
      "Epoch 4548, Loss: 0.0029139985563233495, Final Batch Loss: 0.002304506953805685\n",
      "Epoch 4549, Loss: 3.49167239619419e-05, Final Batch Loss: 1.6056317690527067e-05\n",
      "Epoch 4550, Loss: 1.9167149503118708e-05, Final Batch Loss: 2.3588088424730813e-06\n",
      "Epoch 4551, Loss: 4.3733472807616636e-05, Final Batch Loss: 9.978119805964525e-07\n",
      "Epoch 4552, Loss: 0.0010950411087833345, Final Batch Loss: 0.0001336959539912641\n",
      "Epoch 4553, Loss: 0.009561233415297465, Final Batch Loss: 0.009543673135340214\n",
      "Epoch 4554, Loss: 0.0001501508304500021, Final Batch Loss: 8.808451821096241e-05\n",
      "Epoch 4555, Loss: 0.0002342281732126139, Final Batch Loss: 0.0001549176377011463\n",
      "Epoch 4556, Loss: 3.565930774129811e-05, Final Batch Loss: 3.980959718319355e-06\n",
      "Epoch 4557, Loss: 0.00019311131836730056, Final Batch Loss: 4.013150100945495e-05\n",
      "Epoch 4558, Loss: 0.0005822125531267375, Final Batch Loss: 0.00014088096213527024\n",
      "Epoch 4559, Loss: 7.5701198056776775e-06, Final Batch Loss: 5.520259492186597e-06\n",
      "Epoch 4560, Loss: 2.8668216145888437e-05, Final Batch Loss: 1.1254446690145414e-05\n",
      "Epoch 4561, Loss: 0.005740271648392081, Final Batch Loss: 0.005292096640914679\n",
      "Epoch 4562, Loss: 0.00030931669834899367, Final Batch Loss: 7.237797490233788e-06\n",
      "Epoch 4563, Loss: 0.001957622487680055, Final Batch Loss: 6.869134085718542e-05\n",
      "Epoch 4564, Loss: 0.0002490503902663477, Final Batch Loss: 0.00019222198170609772\n",
      "Epoch 4565, Loss: 2.321638385183178e-05, Final Batch Loss: 1.3954427231510635e-05\n",
      "Epoch 4566, Loss: 0.0002772703455775627, Final Batch Loss: 2.173373104596976e-06\n",
      "Epoch 4567, Loss: 0.0013157362409401685, Final Batch Loss: 0.00023730823886580765\n",
      "Epoch 4568, Loss: 7.810914075889741e-05, Final Batch Loss: 7.098541391314939e-05\n",
      "Epoch 4569, Loss: 3.3100706332334084e-05, Final Batch Loss: 4.492505013331538e-06\n",
      "Epoch 4570, Loss: 0.0006884484027978033, Final Batch Loss: 0.00025449544773437083\n",
      "Epoch 4571, Loss: 0.0001480200226069428, Final Batch Loss: 1.771951065165922e-05\n",
      "Epoch 4572, Loss: 6.069544360798318e-05, Final Batch Loss: 4.212134808767587e-05\n",
      "Epoch 4573, Loss: 2.8869824745925143e-05, Final Batch Loss: 2.0299479729146697e-05\n",
      "Epoch 4574, Loss: 0.00022186645674082683, Final Batch Loss: 1.3251218661025632e-05\n",
      "Epoch 4575, Loss: 0.0018358502911723917, Final Batch Loss: 2.174008659494575e-05\n",
      "Epoch 4576, Loss: 2.0271737867005868e-05, Final Batch Loss: 1.571846951264888e-05\n",
      "Epoch 4577, Loss: 0.0003250872468925081, Final Batch Loss: 3.322140400996432e-05\n",
      "Epoch 4578, Loss: 0.00022686073134536855, Final Batch Loss: 0.00017949614266399294\n",
      "Epoch 4579, Loss: 0.0014997537800809368, Final Batch Loss: 0.0012920597800984979\n",
      "Epoch 4580, Loss: 4.2201680116704665e-05, Final Batch Loss: 1.839947435655631e-05\n",
      "Epoch 4581, Loss: 0.001649994490435347, Final Batch Loss: 0.0013344826875254512\n",
      "Epoch 4582, Loss: 0.00018491626178729348, Final Batch Loss: 8.698199962964281e-06\n",
      "Epoch 4583, Loss: 1.4513279438688187e-05, Final Batch Loss: 4.652655206882628e-06\n",
      "Epoch 4584, Loss: 3.226685976187582e-05, Final Batch Loss: 6.297337222349597e-06\n",
      "Epoch 4585, Loss: 0.00010112976679010899, Final Batch Loss: 5.197582595428685e-06\n",
      "Epoch 4586, Loss: 8.3444718256942e-05, Final Batch Loss: 1.4043891496839933e-05\n",
      "Epoch 4587, Loss: 0.0015927499001691103, Final Batch Loss: 1.2431368077159277e-06\n",
      "Epoch 4588, Loss: 5.8473573517403565e-05, Final Batch Loss: 9.861674698186107e-06\n",
      "Epoch 4589, Loss: 0.00041469681355010835, Final Batch Loss: 4.090718448424013e-06\n",
      "Epoch 4590, Loss: 9.437150220037438e-05, Final Batch Loss: 4.6278848458314314e-05\n",
      "Epoch 4591, Loss: 3.7480598962247313e-05, Final Batch Loss: 9.555463975630119e-07\n",
      "Epoch 4592, Loss: 2.4962983843579423e-05, Final Batch Loss: 1.3995624613016844e-05\n",
      "Epoch 4593, Loss: 0.00010942878270725487, Final Batch Loss: 8.912548764783423e-06\n",
      "Epoch 4594, Loss: 0.00013697017857339233, Final Batch Loss: 2.7420945116318762e-05\n",
      "Epoch 4595, Loss: 5.0877794365078444e-05, Final Batch Loss: 2.2199369595909957e-06\n",
      "Epoch 4596, Loss: 3.182288764946861e-05, Final Batch Loss: 2.041246261796914e-05\n",
      "Epoch 4597, Loss: 2.2530771730089327e-05, Final Batch Loss: 3.9428337004210334e-06\n",
      "Epoch 4598, Loss: 0.00043687502284228685, Final Batch Loss: 5.63489402338746e-06\n",
      "Epoch 4599, Loss: 0.00011062548037443776, Final Batch Loss: 9.230051364284009e-05\n",
      "Epoch 4600, Loss: 3.5809976907330565e-05, Final Batch Loss: 8.635664926259778e-06\n",
      "Epoch 4601, Loss: 0.001130044996898505, Final Batch Loss: 1.6516960386070423e-05\n",
      "Epoch 4602, Loss: 0.0009622830257285386, Final Batch Loss: 0.0002785919059533626\n",
      "Epoch 4603, Loss: 0.00017301899538324506, Final Batch Loss: 1.653706249271636e-06\n",
      "Epoch 4604, Loss: 0.00011410219485696871, Final Batch Loss: 0.0001018807670334354\n",
      "Epoch 4605, Loss: 0.00012696002158918418, Final Batch Loss: 5.140997745911591e-05\n",
      "Epoch 4606, Loss: 0.00025386282868566923, Final Batch Loss: 1.0350013326387852e-06\n",
      "Epoch 4607, Loss: 4.581240864354186e-05, Final Batch Loss: 1.8776923752739094e-05\n",
      "Epoch 4608, Loss: 3.4638466786418576e-05, Final Batch Loss: 4.395388714328874e-06\n",
      "Epoch 4609, Loss: 0.00019692412752192467, Final Batch Loss: 0.00015037109551485628\n",
      "Epoch 4610, Loss: 4.35586071034777e-05, Final Batch Loss: 5.139575478096958e-06\n",
      "Epoch 4611, Loss: 0.0001226814865731285, Final Batch Loss: 1.9045919543714263e-06\n",
      "Epoch 4612, Loss: 7.816163270035759e-05, Final Batch Loss: 8.894152415450662e-06\n",
      "Epoch 4613, Loss: 1.1521467968123034e-05, Final Batch Loss: 9.613700058253016e-06\n",
      "Epoch 4614, Loss: 1.5974114830896724e-05, Final Batch Loss: 1.0359386578784324e-05\n",
      "Epoch 4615, Loss: 6.223587297427002e-05, Final Batch Loss: 2.9723292755079456e-05\n",
      "Epoch 4616, Loss: 0.00032917609496507794, Final Batch Loss: 0.0002537703257985413\n",
      "Epoch 4617, Loss: 0.00015601766790496185, Final Batch Loss: 0.0001067186749423854\n",
      "Epoch 4618, Loss: 0.001375877658574609, Final Batch Loss: 3.89927408832591e-05\n",
      "Epoch 4619, Loss: 1.532462556497194e-05, Final Batch Loss: 1.6713520381017588e-06\n",
      "Epoch 4620, Loss: 0.00010473065140104154, Final Batch Loss: 1.921130206028465e-06\n",
      "Epoch 4621, Loss: 0.0006098449011915363, Final Batch Loss: 0.000586094509344548\n",
      "Epoch 4622, Loss: 6.803392625442939e-05, Final Batch Loss: 1.3344976650842e-05\n",
      "Epoch 4623, Loss: 0.00023448903993994463, Final Batch Loss: 0.0002167640341212973\n",
      "Epoch 4624, Loss: 0.00021735425980295986, Final Batch Loss: 0.00011335416638758034\n",
      "Epoch 4625, Loss: 7.416705466312123e-05, Final Batch Loss: 9.789439900487196e-06\n",
      "Epoch 4626, Loss: 0.0006827521933701064, Final Batch Loss: 0.0006785029545426369\n",
      "Epoch 4627, Loss: 9.669369501352776e-05, Final Batch Loss: 7.587884465465322e-05\n",
      "Epoch 4628, Loss: 5.595201218966395e-05, Final Batch Loss: 5.368485290091485e-05\n",
      "Epoch 4629, Loss: 0.001405678643095598, Final Batch Loss: 1.1603650818869937e-05\n",
      "Epoch 4630, Loss: 1.1989366157649783e-05, Final Batch Loss: 1.4115526028035674e-06\n",
      "Epoch 4631, Loss: 0.00027253305597696453, Final Batch Loss: 8.34165548440069e-05\n",
      "Epoch 4632, Loss: 5.793709192403185e-06, Final Batch Loss: 9.290630487157614e-07\n",
      "Epoch 4633, Loss: 4.438052610566956e-05, Final Batch Loss: 6.256512733671116e-06\n",
      "Epoch 4634, Loss: 7.213071285150363e-06, Final Batch Loss: 3.474920276858029e-06\n",
      "Epoch 4635, Loss: 9.435202628083061e-06, Final Batch Loss: 5.617800525214989e-06\n",
      "Epoch 4636, Loss: 1.832084012676205e-05, Final Batch Loss: 1.5475156033062376e-05\n",
      "Epoch 4637, Loss: 1.3192163805797463e-05, Final Batch Loss: 4.70890563519788e-06\n",
      "Epoch 4638, Loss: 5.0048664888890926e-05, Final Batch Loss: 4.04548627557233e-05\n",
      "Epoch 4639, Loss: 7.596434215884074e-06, Final Batch Loss: 4.035736310470384e-06\n",
      "Epoch 4640, Loss: 0.0001516191114205867, Final Batch Loss: 6.480261072283611e-05\n",
      "Epoch 4641, Loss: 3.185654531989712e-05, Final Batch Loss: 2.6448198696016334e-05\n",
      "Epoch 4642, Loss: 1.8918175101134693e-05, Final Batch Loss: 2.6079319468408357e-06\n",
      "Epoch 4643, Loss: 0.0003039433445337636, Final Batch Loss: 2.4515261429769453e-06\n",
      "Epoch 4644, Loss: 7.801191168255173e-05, Final Batch Loss: 5.608042192761786e-05\n",
      "Epoch 4645, Loss: 0.0001860363918240182, Final Batch Loss: 0.00011640856246231124\n",
      "Epoch 4646, Loss: 1.1759945039102604e-05, Final Batch Loss: 7.183728598647576e-07\n",
      "Epoch 4647, Loss: 4.5778714564903566e-05, Final Batch Loss: 3.664544863113406e-07\n",
      "Epoch 4648, Loss: 0.0003841314755845815, Final Batch Loss: 0.00035812726127915084\n",
      "Epoch 4649, Loss: 0.00149201327621995, Final Batch Loss: 1.5281892046914436e-05\n",
      "Epoch 4650, Loss: 0.00020614966842913418, Final Batch Loss: 2.3227817109727766e-06\n",
      "Epoch 4651, Loss: 2.834044335031649e-05, Final Batch Loss: 1.3124322322255466e-05\n",
      "Epoch 4652, Loss: 3.464183510004659e-05, Final Batch Loss: 3.115559957223013e-05\n",
      "Epoch 4653, Loss: 9.021762252814369e-05, Final Batch Loss: 1.0949047464237083e-05\n",
      "Epoch 4654, Loss: 5.4305380217556376e-05, Final Batch Loss: 7.83239465818042e-06\n",
      "Epoch 4655, Loss: 0.0005487559901666827, Final Batch Loss: 0.00044366635847836733\n",
      "Epoch 4656, Loss: 0.00041071126599945273, Final Batch Loss: 9.8518341928866e-07\n",
      "Epoch 4657, Loss: 4.2174930797500565e-05, Final Batch Loss: 7.505612416025542e-07\n",
      "Epoch 4658, Loss: 2.5165295255646924e-05, Final Batch Loss: 2.5648612336226506e-06\n",
      "Epoch 4659, Loss: 0.0001615153903458122, Final Batch Loss: 1.0211385870206868e-06\n",
      "Epoch 4660, Loss: 0.03900939688173821, Final Batch Loss: 6.303653208306059e-05\n",
      "Epoch 4661, Loss: 0.00015943739435897442, Final Batch Loss: 0.00015009159687906504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4662, Loss: 9.922138087858912e-05, Final Batch Loss: 9.33453266043216e-05\n",
      "Epoch 4663, Loss: 0.001896886590543545, Final Batch Loss: 0.0018952168757095933\n",
      "Epoch 4664, Loss: 0.005814036710944492, Final Batch Loss: 8.869905286701396e-05\n",
      "Epoch 4665, Loss: 6.543551990034757e-06, Final Batch Loss: 3.089836582148564e-06\n",
      "Epoch 4666, Loss: 8.892336154531222e-06, Final Batch Loss: 7.675907909288071e-07\n",
      "Epoch 4667, Loss: 0.0009720309869862831, Final Batch Loss: 3.709178372446331e-06\n",
      "Epoch 4668, Loss: 0.00016428346407337813, Final Batch Loss: 8.1257121564704e-06\n",
      "Epoch 4669, Loss: 0.0005902738678287278, Final Batch Loss: 2.4224766548286425e-06\n",
      "Epoch 4670, Loss: 3.458009723544819e-05, Final Batch Loss: 3.169697265548166e-06\n",
      "Epoch 4671, Loss: 0.0003059528489757213, Final Batch Loss: 4.903874469164293e-06\n",
      "Epoch 4672, Loss: 2.147474447156128e-05, Final Batch Loss: 2.285632263010484e-06\n",
      "Epoch 4673, Loss: 0.0012504586206887325, Final Batch Loss: 5.995012088533258e-06\n",
      "Epoch 4674, Loss: 9.444649413126172e-05, Final Batch Loss: 9.006147593026981e-05\n",
      "Epoch 4675, Loss: 0.0003359485272085294, Final Batch Loss: 0.0002696829033084214\n",
      "Epoch 4676, Loss: 1.3748189758189255e-05, Final Batch Loss: 2.188373855460668e-06\n",
      "Epoch 4677, Loss: 0.00010197975143455551, Final Batch Loss: 9.713399776956066e-05\n",
      "Epoch 4678, Loss: 4.50465859103133e-05, Final Batch Loss: 3.3743493986548856e-05\n",
      "Epoch 4679, Loss: 0.0003031417199963471, Final Batch Loss: 0.00029521965188905597\n",
      "Epoch 4680, Loss: 0.0011012179575118353, Final Batch Loss: 0.0010874895378947258\n",
      "Epoch 4681, Loss: 0.0005133037620907999, Final Batch Loss: 0.0005093523068353534\n",
      "Epoch 4682, Loss: 0.00034864870031015016, Final Batch Loss: 0.00030914254602976143\n",
      "Epoch 4683, Loss: 4.020254573333659e-05, Final Batch Loss: 3.761831976589747e-05\n",
      "Epoch 4684, Loss: 1.7355388536088867e-05, Final Batch Loss: 1.0784021469589788e-05\n",
      "Epoch 4685, Loss: 5.7107947213808075e-05, Final Batch Loss: 4.2872881749644876e-05\n",
      "Epoch 4686, Loss: 0.0002469637565809535, Final Batch Loss: 1.9344604879734106e-05\n",
      "Epoch 4687, Loss: 2.230766858701827e-05, Final Batch Loss: 1.753627111611422e-05\n",
      "Epoch 4688, Loss: 6.239102822291898e-05, Final Batch Loss: 4.9075686547439545e-05\n",
      "Epoch 4689, Loss: 3.857725914713228e-06, Final Batch Loss: 3.1648924050386995e-06\n",
      "Epoch 4690, Loss: 3.04112863886985e-05, Final Batch Loss: 2.6357991373515688e-05\n",
      "Epoch 4691, Loss: 0.0006371340859914199, Final Batch Loss: 0.0001337286812486127\n",
      "Epoch 4692, Loss: 4.04741531383479e-05, Final Batch Loss: 5.444244379759766e-06\n",
      "Epoch 4693, Loss: 0.00010197575102210976, Final Batch Loss: 2.243194103357382e-05\n",
      "Epoch 4694, Loss: 0.00024824170782267174, Final Batch Loss: 0.000245651783188805\n",
      "Epoch 4695, Loss: 0.0027052113582612947, Final Batch Loss: 0.0025573819875717163\n",
      "Epoch 4696, Loss: 0.0014335212335936376, Final Batch Loss: 4.287184310669545e-06\n",
      "Epoch 4697, Loss: 0.0010518857452552766, Final Batch Loss: 0.0007454163278453052\n",
      "Epoch 4698, Loss: 0.0032152765038517828, Final Batch Loss: 7.337758233916247e-06\n",
      "Epoch 4699, Loss: 6.27575700491434e-05, Final Batch Loss: 4.366162102087401e-06\n",
      "Epoch 4700, Loss: 1.8072390048473608e-05, Final Batch Loss: 1.1650574379018508e-05\n",
      "Epoch 4701, Loss: 0.0006718823478877312, Final Batch Loss: 6.6226839408045635e-06\n",
      "Epoch 4702, Loss: 5.743186875406536e-05, Final Batch Loss: 5.1999842980876565e-05\n",
      "Epoch 4703, Loss: 1.5307169292100298e-05, Final Batch Loss: 1.387770680594258e-05\n",
      "Epoch 4704, Loss: 0.004235361650216873, Final Batch Loss: 0.004231771919876337\n",
      "Epoch 4705, Loss: 0.0008572270526201464, Final Batch Loss: 7.094260217854753e-05\n",
      "Epoch 4706, Loss: 5.761771171819419e-05, Final Batch Loss: 3.2901662052609026e-06\n",
      "Epoch 4707, Loss: 0.002660040889168158, Final Batch Loss: 0.00017380030476488173\n",
      "Epoch 4708, Loss: 0.000545672832231503, Final Batch Loss: 0.0005148776690475643\n",
      "Epoch 4709, Loss: 0.0003910361192538403, Final Batch Loss: 0.00037718951352871954\n",
      "Epoch 4710, Loss: 8.95817265700316e-05, Final Batch Loss: 3.0820137908449396e-06\n",
      "Epoch 4711, Loss: 0.0005862211837666109, Final Batch Loss: 0.0001358484587399289\n",
      "Epoch 4712, Loss: 0.00010744012979557738, Final Batch Loss: 4.482491931412369e-05\n",
      "Epoch 4713, Loss: 0.0008344557572854683, Final Batch Loss: 0.0008121132850646973\n",
      "Epoch 4714, Loss: 0.000150916057464201, Final Batch Loss: 4.533915489446372e-05\n",
      "Epoch 4715, Loss: 8.776781783126353e-06, Final Batch Loss: 8.078231076069642e-06\n",
      "Epoch 4716, Loss: 0.0001685516401721543, Final Batch Loss: 0.00016550056170672178\n",
      "Epoch 4717, Loss: 0.0037361671943472174, Final Batch Loss: 4.350885774329072e-06\n",
      "Epoch 4718, Loss: 4.25327168613876e-05, Final Batch Loss: 1.9432197859714506e-06\n",
      "Epoch 4719, Loss: 0.001625139768293593, Final Batch Loss: 7.255996024468914e-05\n",
      "Epoch 4720, Loss: 8.65072752276319e-06, Final Batch Loss: 5.239541224000277e-06\n",
      "Epoch 4721, Loss: 0.0003428555210120976, Final Batch Loss: 0.00017226154159288853\n",
      "Epoch 4722, Loss: 8.129178968374617e-05, Final Batch Loss: 3.3485608582850546e-05\n",
      "Epoch 4723, Loss: 0.00031338263215729967, Final Batch Loss: 0.00020013748144265264\n",
      "Epoch 4724, Loss: 0.00041487988164590206, Final Batch Loss: 2.8749109333148226e-06\n",
      "Epoch 4725, Loss: 4.8235909389404696e-05, Final Batch Loss: 4.5830063754692674e-05\n",
      "Epoch 4726, Loss: 0.0037199312805569207, Final Batch Loss: 3.1814429348742124e-06\n",
      "Epoch 4727, Loss: 0.0001480162245570682, Final Batch Loss: 7.352778629865497e-05\n",
      "Epoch 4728, Loss: 0.0003003787696798099, Final Batch Loss: 0.00027007132302969694\n",
      "Epoch 4729, Loss: 8.410923101109802e-06, Final Batch Loss: 5.24559618497733e-06\n",
      "Epoch 4730, Loss: 2.1821190557602677e-05, Final Batch Loss: 1.8854556401493028e-05\n",
      "Epoch 4731, Loss: 0.0050030863894789945, Final Batch Loss: 0.004965770523995161\n",
      "Epoch 4732, Loss: 0.00033954645550693385, Final Batch Loss: 1.9163573597325012e-05\n",
      "Epoch 4733, Loss: 0.00015705678833910497, Final Batch Loss: 0.0001435067824786529\n",
      "Epoch 4734, Loss: 2.7853765232066507e-06, Final Batch Loss: 1.1737488421204034e-06\n",
      "Epoch 4735, Loss: 5.272534690448083e-05, Final Batch Loss: 4.749916115542874e-05\n",
      "Epoch 4736, Loss: 2.3869265532994177e-05, Final Batch Loss: 7.925013960630167e-06\n",
      "Epoch 4737, Loss: 0.0021358137613560757, Final Batch Loss: 1.5136914726099349e-06\n",
      "Epoch 4738, Loss: 0.0008643463120279193, Final Batch Loss: 0.000858120562043041\n",
      "Epoch 4739, Loss: 3.0494126690427947e-06, Final Batch Loss: 2.6884513317781966e-06\n",
      "Epoch 4740, Loss: 1.9017783898789276e-05, Final Batch Loss: 2.4535486886634317e-07\n",
      "Epoch 4741, Loss: 3.434996233409038e-05, Final Batch Loss: 8.2747365013347e-06\n",
      "Epoch 4742, Loss: 1.4655455288448138e-05, Final Batch Loss: 9.517257240077015e-06\n",
      "Epoch 4743, Loss: 5.423772563517559e-05, Final Batch Loss: 2.2037509552319534e-05\n",
      "Epoch 4744, Loss: 0.0017207641353707004, Final Batch Loss: 0.0017172357765957713\n",
      "Epoch 4745, Loss: 1.7187865068990504e-05, Final Batch Loss: 1.2255443834874313e-05\n",
      "Epoch 4746, Loss: 0.00017163073596293543, Final Batch Loss: 1.2134313465139712e-06\n",
      "Epoch 4747, Loss: 6.58406943330192e-05, Final Batch Loss: 9.931122804118786e-06\n",
      "Epoch 4748, Loss: 0.0015681278928241227, Final Batch Loss: 3.111630576313473e-05\n",
      "Epoch 4749, Loss: 0.0013858541178706218, Final Batch Loss: 0.0013829994713887572\n",
      "Epoch 4750, Loss: 5.752376273449045e-05, Final Batch Loss: 2.9247623388073407e-05\n",
      "Epoch 4751, Loss: 0.0015657833295108503, Final Batch Loss: 0.0015646923566237092\n",
      "Epoch 4752, Loss: 5.040362975705648e-05, Final Batch Loss: 4.0135637391358614e-05\n",
      "Epoch 4753, Loss: 0.00013421779181044258, Final Batch Loss: 0.0001318572467425838\n",
      "Epoch 4754, Loss: 1.5912727633349277e-06, Final Batch Loss: 1.135898969550908e-06\n",
      "Epoch 4755, Loss: 0.005198193539399654, Final Batch Loss: 0.00042025401489809155\n",
      "Epoch 4756, Loss: 0.00014813232110100216, Final Batch Loss: 5.944669737800723e-06\n",
      "Epoch 4757, Loss: 0.0001283822743971541, Final Batch Loss: 4.888086095888866e-06\n",
      "Epoch 4758, Loss: 7.552197507720848e-05, Final Batch Loss: 2.1759421997558093e-06\n",
      "Epoch 4759, Loss: 0.0005400062873377465, Final Batch Loss: 0.0004651175404433161\n",
      "Epoch 4760, Loss: 7.915966762084281e-06, Final Batch Loss: 5.332701221050229e-06\n",
      "Epoch 4761, Loss: 0.0016854039063218806, Final Batch Loss: 4.693320533988299e-06\n",
      "Epoch 4762, Loss: 1.4613853636546992e-05, Final Batch Loss: 3.0243218134273775e-06\n",
      "Epoch 4763, Loss: 4.297493057947577e-05, Final Batch Loss: 4.158032970735803e-05\n",
      "Epoch 4764, Loss: 6.364421543025855e-05, Final Batch Loss: 4.2006550415862876e-07\n",
      "Epoch 4765, Loss: 0.002297458867815294, Final Batch Loss: 2.672127720870776e-06\n",
      "Epoch 4766, Loss: 1.0760836858025868e-05, Final Batch Loss: 2.4659577775310026e-06\n",
      "Epoch 4767, Loss: 1.7419485629943665e-05, Final Batch Loss: 3.445366928644944e-06\n",
      "Epoch 4768, Loss: 3.904491245521058e-05, Final Batch Loss: 2.9451832688209834e-06\n",
      "Epoch 4769, Loss: 0.0004080666731169913, Final Batch Loss: 0.0003691741148941219\n",
      "Epoch 4770, Loss: 1.5746495591884013e-05, Final Batch Loss: 1.6499125194968656e-06\n",
      "Epoch 4771, Loss: 0.00026811778548108123, Final Batch Loss: 0.0002648570225574076\n",
      "Epoch 4772, Loss: 0.0006577571912202984, Final Batch Loss: 0.000554983620531857\n",
      "Epoch 4773, Loss: 4.1493348362564575e-05, Final Batch Loss: 2.8005879357806407e-06\n",
      "Epoch 4774, Loss: 0.0012308518607824226, Final Batch Loss: 1.3130481420375872e-05\n",
      "Epoch 4775, Loss: 1.1058901009164401e-05, Final Batch Loss: 7.914582056400832e-06\n",
      "Epoch 4776, Loss: 0.00019289279589429498, Final Batch Loss: 6.686469714622945e-05\n",
      "Epoch 4777, Loss: 0.00033914571577042807, Final Batch Loss: 0.00032041341182775795\n",
      "Epoch 4778, Loss: 0.000697576384027343, Final Batch Loss: 0.0006906067137606442\n",
      "Epoch 4779, Loss: 0.0003982894959335681, Final Batch Loss: 0.000343664811225608\n",
      "Epoch 4780, Loss: 0.00019703933503478765, Final Batch Loss: 0.00018693777383305132\n",
      "Epoch 4781, Loss: 0.0001369585652355454, Final Batch Loss: 0.00012615257583092898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4782, Loss: 6.208292234077817e-06, Final Batch Loss: 5.6256039897562005e-06\n",
      "Epoch 4783, Loss: 3.7757064887955494e-06, Final Batch Loss: 6.370295864144282e-07\n",
      "Epoch 4784, Loss: 0.006776141248792555, Final Batch Loss: 0.006771046668291092\n",
      "Epoch 4785, Loss: 0.00020347180998214753, Final Batch Loss: 0.00020025516278110445\n",
      "Epoch 4786, Loss: 0.0006623430681429454, Final Batch Loss: 0.0006504393531940877\n",
      "Epoch 4787, Loss: 1.489039300395234e-05, Final Batch Loss: 1.1652367902570404e-05\n",
      "Epoch 4788, Loss: 0.00020191139628877863, Final Batch Loss: 8.047773008001968e-05\n",
      "Epoch 4789, Loss: 6.10669649176998e-05, Final Batch Loss: 2.4312945242854767e-05\n",
      "Epoch 4790, Loss: 0.0002889435927500017, Final Batch Loss: 0.0002354861790081486\n",
      "Epoch 4791, Loss: 9.213194607582409e-05, Final Batch Loss: 6.839980778750032e-05\n",
      "Epoch 4792, Loss: 2.079507112284773e-05, Final Batch Loss: 4.082936811755644e-06\n",
      "Epoch 4793, Loss: 0.0001182373562187422, Final Batch Loss: 0.00011273029667790979\n",
      "Epoch 4794, Loss: 0.00039990903405850986, Final Batch Loss: 0.00039028876926749945\n",
      "Epoch 4795, Loss: 8.368238070488587e-05, Final Batch Loss: 5.512544021257781e-07\n",
      "Epoch 4796, Loss: 0.0025998294800047006, Final Batch Loss: 7.339890998991905e-06\n",
      "Epoch 4797, Loss: 0.0018499061065995193, Final Batch Loss: 4.443975285539636e-06\n",
      "Epoch 4798, Loss: 0.00023750701257085893, Final Batch Loss: 2.1963927792967297e-05\n",
      "Epoch 4799, Loss: 8.360960873687873e-05, Final Batch Loss: 9.93193043541396e-06\n",
      "Epoch 4800, Loss: 1.1369617823220324e-05, Final Batch Loss: 8.69333052833099e-06\n",
      "Epoch 4801, Loss: 6.445339568017516e-05, Final Batch Loss: 4.316695412853733e-05\n",
      "Epoch 4802, Loss: 0.0005031454845720873, Final Batch Loss: 0.0004994756309315562\n",
      "Epoch 4803, Loss: 3.587652054193313e-05, Final Batch Loss: 3.086208016611636e-05\n",
      "Epoch 4804, Loss: 9.163897561847989e-05, Final Batch Loss: 8.902305853553116e-05\n",
      "Epoch 4805, Loss: 0.00011431177335907705, Final Batch Loss: 9.072579996427521e-05\n",
      "Epoch 4806, Loss: 8.755919975556026e-05, Final Batch Loss: 2.363236717428663e-06\n",
      "Epoch 4807, Loss: 0.0004255517924320884, Final Batch Loss: 8.57139311847277e-05\n",
      "Epoch 4808, Loss: 2.61502234479849e-05, Final Batch Loss: 2.4688304620212875e-05\n",
      "Epoch 4809, Loss: 1.3084626630188723e-05, Final Batch Loss: 1.1453947081463411e-05\n",
      "Epoch 4810, Loss: 5.776567559223622e-05, Final Batch Loss: 3.2650244975229725e-05\n",
      "Epoch 4811, Loss: 5.460657348521636e-06, Final Batch Loss: 1.4979184470576001e-06\n",
      "Epoch 4812, Loss: 0.0017982219869736582, Final Batch Loss: 0.00012675116886384785\n",
      "Epoch 4813, Loss: 4.6380882849916816e-06, Final Batch Loss: 1.9394421997276368e-06\n",
      "Epoch 4814, Loss: 4.993594711777405e-05, Final Batch Loss: 4.568127405946143e-05\n",
      "Epoch 4815, Loss: 0.00012668687622863217, Final Batch Loss: 0.00012001478171441704\n",
      "Epoch 4816, Loss: 0.0003014185858773999, Final Batch Loss: 0.00026498441002331674\n",
      "Epoch 4817, Loss: 0.00010070126609207364, Final Batch Loss: 4.563863512885291e-06\n",
      "Epoch 4818, Loss: 1.569649987231969e-05, Final Batch Loss: 1.4834873582003638e-05\n",
      "Epoch 4819, Loss: 0.0002552658560830423, Final Batch Loss: 8.325450266966072e-07\n",
      "Epoch 4820, Loss: 0.0009463408532610629, Final Batch Loss: 0.0008992072544060647\n",
      "Epoch 4821, Loss: 6.758433937648078e-05, Final Batch Loss: 1.0324048162146937e-05\n",
      "Epoch 4822, Loss: 0.00035990601190860616, Final Batch Loss: 8.048559720919002e-06\n",
      "Epoch 4823, Loss: 5.3778861911268905e-05, Final Batch Loss: 9.93316643871367e-06\n",
      "Epoch 4824, Loss: 2.1271548575896304e-05, Final Batch Loss: 1.218513716594316e-05\n",
      "Epoch 4825, Loss: 2.1401619051175658e-05, Final Batch Loss: 7.695946806052234e-06\n",
      "Epoch 4826, Loss: 5.9914511439274065e-05, Final Batch Loss: 3.936014763894491e-06\n",
      "Epoch 4827, Loss: 0.0005287136127662961, Final Batch Loss: 3.493839358270634e-06\n",
      "Epoch 4828, Loss: 0.001563423740321923, Final Batch Loss: 1.8416518514641211e-06\n",
      "Epoch 4829, Loss: 0.00016833024346851744, Final Batch Loss: 0.00014586806355509907\n",
      "Epoch 4830, Loss: 0.0002380298283242155, Final Batch Loss: 0.0002150616783183068\n",
      "Epoch 4831, Loss: 0.0004128268046770245, Final Batch Loss: 0.00012789139873348176\n",
      "Epoch 4832, Loss: 0.0006477623464888893, Final Batch Loss: 2.087742177536711e-05\n",
      "Epoch 4833, Loss: 0.005841546150293198, Final Batch Loss: 0.0058406344614923\n",
      "Epoch 4834, Loss: 0.00015097608411451802, Final Batch Loss: 0.00012447958579286933\n",
      "Epoch 4835, Loss: 6.685994230792858e-05, Final Batch Loss: 5.268746099318378e-05\n",
      "Epoch 4836, Loss: 0.0004401755868457258, Final Batch Loss: 0.00014264427591115236\n",
      "Epoch 4837, Loss: 8.201369041671569e-05, Final Batch Loss: 7.861977792344987e-05\n",
      "Epoch 4838, Loss: 6.858007054688642e-05, Final Batch Loss: 6.335255602607504e-05\n",
      "Epoch 4839, Loss: 4.0595131167719956e-06, Final Batch Loss: 2.7849800972035155e-06\n",
      "Epoch 4840, Loss: 0.00021316619859135244, Final Batch Loss: 1.8271684893989004e-05\n",
      "Epoch 4841, Loss: 0.006131308895419352, Final Batch Loss: 0.006103531923145056\n",
      "Epoch 4842, Loss: 7.62247144336925e-05, Final Batch Loss: 7.575932977488264e-05\n",
      "Epoch 4843, Loss: 0.00011806234942923766, Final Batch Loss: 1.4306990124168806e-05\n",
      "Epoch 4844, Loss: 2.2129186731945083e-06, Final Batch Loss: 2.0193238015053794e-06\n",
      "Epoch 4845, Loss: 0.00017926135478774086, Final Batch Loss: 6.855309038655832e-05\n",
      "Epoch 4846, Loss: 3.658394871308701e-05, Final Batch Loss: 2.885105823224876e-05\n",
      "Epoch 4847, Loss: 0.00010244634722766932, Final Batch Loss: 8.74935940373689e-05\n",
      "Epoch 4848, Loss: 0.0009657564341978286, Final Batch Loss: 0.0009602656937204301\n",
      "Epoch 4849, Loss: 4.182431962362898e-05, Final Batch Loss: 4.1365608922205865e-05\n",
      "Epoch 4850, Loss: 9.70028709161852e-05, Final Batch Loss: 9.199851774610579e-05\n",
      "Epoch 4851, Loss: 0.00024947533074737294, Final Batch Loss: 0.00024175143335014582\n",
      "Epoch 4852, Loss: 0.00023556226733489893, Final Batch Loss: 0.00019172368047293276\n",
      "Epoch 4853, Loss: 4.137359042033495e-06, Final Batch Loss: 8.117311836031149e-07\n",
      "Epoch 4854, Loss: 2.3117121372706606e-06, Final Batch Loss: 1.7299852288488182e-06\n",
      "Epoch 4855, Loss: 0.00041725650953594595, Final Batch Loss: 8.25526803964749e-05\n",
      "Epoch 4856, Loss: 0.021601629687893364, Final Batch Loss: 3.2812938570714323e-06\n",
      "Epoch 4857, Loss: 1.8199035366706084e-05, Final Batch Loss: 6.56911561236484e-06\n",
      "Epoch 4858, Loss: 0.0009086942518479191, Final Batch Loss: 5.0639813707675785e-05\n",
      "Epoch 4859, Loss: 0.00019031350393561297, Final Batch Loss: 0.00018304106197319925\n",
      "Epoch 4860, Loss: 0.0001471829818910919, Final Batch Loss: 3.0829985917080194e-05\n",
      "Epoch 4861, Loss: 0.0013617658503335406, Final Batch Loss: 2.1178955194045557e-06\n",
      "Epoch 4862, Loss: 3.447119979682611e-05, Final Batch Loss: 5.117913133290131e-06\n",
      "Epoch 4863, Loss: 0.000596128600591328, Final Batch Loss: 1.9369028450455517e-05\n",
      "Epoch 4864, Loss: 0.00011695702596625779, Final Batch Loss: 0.00010166573338210583\n",
      "Epoch 4865, Loss: 2.0386013602546882e-05, Final Batch Loss: 1.6693405996193178e-05\n",
      "Epoch 4866, Loss: 0.0003568653337424621, Final Batch Loss: 0.00011757902393583208\n",
      "Epoch 4867, Loss: 3.0634579161414877e-05, Final Batch Loss: 2.0424638933036476e-05\n",
      "Epoch 4868, Loss: 5.489036448125262e-05, Final Batch Loss: 3.097420631092973e-05\n",
      "Epoch 4869, Loss: 0.013202348698769129, Final Batch Loss: 2.738994453466148e-06\n",
      "Epoch 4870, Loss: 0.008722109538211953, Final Batch Loss: 0.008681008592247963\n",
      "Epoch 4871, Loss: 4.743231329484843e-05, Final Batch Loss: 1.7303163986071013e-05\n",
      "Epoch 4872, Loss: 0.0006357508718792815, Final Batch Loss: 6.094818309065886e-05\n",
      "Epoch 4873, Loss: 0.0002976908363052644, Final Batch Loss: 0.00021684686362277716\n",
      "Epoch 4874, Loss: 0.00031926775409374386, Final Batch Loss: 0.00012571578554343432\n",
      "Epoch 4875, Loss: 5.1298589824000373e-05, Final Batch Loss: 2.9724862542934716e-05\n",
      "Epoch 4876, Loss: 0.002697602496482432, Final Batch Loss: 0.0006778918905183673\n",
      "Epoch 4877, Loss: 0.000573438941501081, Final Batch Loss: 0.00038214068626984954\n",
      "Epoch 4878, Loss: 0.0006725340135744773, Final Batch Loss: 6.896020931890234e-05\n",
      "Epoch 4879, Loss: 7.868503439567576e-05, Final Batch Loss: 7.546981942141429e-05\n",
      "Epoch 4880, Loss: 0.00012065119881299324, Final Batch Loss: 6.879399734316394e-05\n",
      "Epoch 4881, Loss: 1.7100209333875682e-05, Final Batch Loss: 4.488194463192485e-06\n",
      "Epoch 4882, Loss: 0.00014039773759577656, Final Batch Loss: 1.3725119970331434e-05\n",
      "Epoch 4883, Loss: 0.00017894172560772859, Final Batch Loss: 1.6415153368143365e-05\n",
      "Epoch 4884, Loss: 1.851066463132156e-05, Final Batch Loss: 3.6264136724639684e-06\n",
      "Epoch 4885, Loss: 0.00013393533595262852, Final Batch Loss: 2.011732476603356e-06\n",
      "Epoch 4886, Loss: 0.0035351141268620268, Final Batch Loss: 0.003436027793213725\n",
      "Epoch 4887, Loss: 9.321945799456444e-05, Final Batch Loss: 1.6218740711337887e-05\n",
      "Epoch 4888, Loss: 8.158688615367282e-05, Final Batch Loss: 2.8124615710112266e-05\n",
      "Epoch 4889, Loss: 0.00020257835421944037, Final Batch Loss: 2.4512446543667465e-05\n",
      "Epoch 4890, Loss: 0.004690060966822784, Final Batch Loss: 6.823764852015302e-05\n",
      "Epoch 4891, Loss: 1.3310987469594693e-05, Final Batch Loss: 8.912391422200017e-06\n",
      "Epoch 4892, Loss: 3.111217483819928e-05, Final Batch Loss: 7.249884220073e-06\n",
      "Epoch 4893, Loss: 0.0027213076770067346, Final Batch Loss: 7.139693707358674e-07\n",
      "Epoch 4894, Loss: 1.1648052350210492e-05, Final Batch Loss: 3.6307392292656004e-06\n",
      "Epoch 4895, Loss: 3.020914704165989e-06, Final Batch Loss: 3.658206821910426e-07\n",
      "Epoch 4896, Loss: 2.9945710593892727e-05, Final Batch Loss: 2.3303255147766322e-05\n",
      "Epoch 4897, Loss: 3.993697350779257e-05, Final Batch Loss: 3.1803745059733046e-06\n",
      "Epoch 4898, Loss: 6.850246290923678e-05, Final Batch Loss: 6.320688498817617e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4899, Loss: 4.703837021224899e-05, Final Batch Loss: 1.3540814506995957e-05\n",
      "Epoch 4900, Loss: 0.0002896673686336726, Final Batch Loss: 0.0002116906107403338\n",
      "Epoch 4901, Loss: 0.003429141390370205, Final Batch Loss: 0.00026980836992152035\n",
      "Epoch 4902, Loss: 0.001062343477315153, Final Batch Loss: 0.0010553306201472878\n",
      "Epoch 4903, Loss: 0.00042469343429729633, Final Batch Loss: 2.261608869957854e-06\n",
      "Epoch 4904, Loss: 8.465130667900667e-05, Final Batch Loss: 7.742521120235324e-06\n",
      "Epoch 4905, Loss: 2.8538741389638744e-05, Final Batch Loss: 5.307698302203789e-06\n",
      "Epoch 4906, Loss: 9.126849545282312e-05, Final Batch Loss: 3.7116125895408913e-05\n",
      "Epoch 4907, Loss: 4.684184204961639e-05, Final Batch Loss: 2.2373340470949188e-05\n",
      "Epoch 4908, Loss: 7.133427970984485e-06, Final Batch Loss: 1.9791627892118413e-06\n",
      "Epoch 4909, Loss: 0.00047199251184792956, Final Batch Loss: 0.00046498325536958873\n",
      "Epoch 4910, Loss: 7.99600820755586e-06, Final Batch Loss: 9.340633368992712e-07\n",
      "Epoch 4911, Loss: 0.00046278993249870837, Final Batch Loss: 0.0004213107458781451\n",
      "Epoch 4912, Loss: 0.0019567856197681976, Final Batch Loss: 0.0019375963602215052\n",
      "Epoch 4913, Loss: 0.0025761187862372026, Final Batch Loss: 0.002376636490225792\n",
      "Epoch 4914, Loss: 0.0009002717124531046, Final Batch Loss: 0.0008705076761543751\n",
      "Epoch 4915, Loss: 0.001359082659462274, Final Batch Loss: 6.553192974934063e-07\n",
      "Epoch 4916, Loss: 5.629761653835885e-05, Final Batch Loss: 6.574795406777412e-06\n",
      "Epoch 4917, Loss: 0.0004182837874395773, Final Batch Loss: 8.818235073704273e-05\n",
      "Epoch 4918, Loss: 9.910885410135961e-06, Final Batch Loss: 7.362466476479312e-06\n",
      "Epoch 4919, Loss: 1.9192278159607667e-05, Final Batch Loss: 1.4517740964947734e-05\n",
      "Epoch 4920, Loss: 0.002419759228359908, Final Batch Loss: 0.001693852012977004\n",
      "Epoch 4921, Loss: 2.285092523379717e-05, Final Batch Loss: 1.951584818016272e-05\n",
      "Epoch 4922, Loss: 1.7891970060190943e-05, Final Batch Loss: 6.862329655632493e-07\n",
      "Epoch 4923, Loss: 0.0024035947462834883, Final Batch Loss: 0.0023859110660851\n",
      "Epoch 4924, Loss: 2.8003351530969667e-05, Final Batch Loss: 1.4575640534530976e-06\n",
      "Epoch 4925, Loss: 4.812934548681369e-05, Final Batch Loss: 3.9360551454592496e-05\n",
      "Epoch 4926, Loss: 0.00013443371790344827, Final Batch Loss: 5.2306011639302596e-05\n",
      "Epoch 4927, Loss: 0.007664264167033252, Final Batch Loss: 1.813935705285985e-05\n",
      "Epoch 4928, Loss: 4.332791286287829e-05, Final Batch Loss: 2.581919397925958e-05\n",
      "Epoch 4929, Loss: 2.130220264007221e-05, Final Batch Loss: 7.400155027426081e-06\n",
      "Epoch 4930, Loss: 8.192191330635978e-05, Final Batch Loss: 7.844791980460286e-05\n",
      "Epoch 4931, Loss: 4.1290634726465214e-05, Final Batch Loss: 9.862015758699272e-06\n",
      "Epoch 4932, Loss: 7.73692022448813e-06, Final Batch Loss: 4.3618174458970316e-06\n",
      "Epoch 4933, Loss: 0.000542167706953478, Final Batch Loss: 0.0005200018640607595\n",
      "Epoch 4934, Loss: 4.677429569710512e-05, Final Batch Loss: 2.1514977561309934e-05\n",
      "Epoch 4935, Loss: 7.800534604029963e-06, Final Batch Loss: 1.1699758033500984e-06\n",
      "Epoch 4936, Loss: 0.0001572936113234391, Final Batch Loss: 0.00015555181016679853\n",
      "Epoch 4937, Loss: 0.00037113359576324, Final Batch Loss: 0.000322432053508237\n",
      "Epoch 4938, Loss: 5.985257666907273e-05, Final Batch Loss: 5.2563362260116264e-05\n",
      "Epoch 4939, Loss: 3.704123719217023e-05, Final Batch Loss: 2.499874244676903e-05\n",
      "Epoch 4940, Loss: 0.00021260432549752295, Final Batch Loss: 8.072254422586411e-05\n",
      "Epoch 4941, Loss: 0.0012674452009378001, Final Batch Loss: 6.55816838843748e-05\n",
      "Epoch 4942, Loss: 9.86507711786544e-05, Final Batch Loss: 7.78295798227191e-05\n",
      "Epoch 4943, Loss: 4.975233650839073e-06, Final Batch Loss: 2.7013370527129155e-06\n",
      "Epoch 4944, Loss: 5.7727012972463854e-05, Final Batch Loss: 3.1052568374434486e-05\n",
      "Epoch 4945, Loss: 9.71536665019812e-05, Final Batch Loss: 2.2188667571754195e-05\n",
      "Epoch 4946, Loss: 0.00016437307976957527, Final Batch Loss: 0.00015983534103725106\n",
      "Epoch 4947, Loss: 1.924531920849404e-05, Final Batch Loss: 3.732382765520015e-06\n",
      "Epoch 4948, Loss: 5.326270911609754e-05, Final Batch Loss: 2.3185039026429877e-05\n",
      "Epoch 4949, Loss: 4.029776937386487e-05, Final Batch Loss: 3.2336920412490144e-05\n",
      "Epoch 4950, Loss: 0.0027430160553194582, Final Batch Loss: 0.0027022191789001226\n",
      "Epoch 4951, Loss: 9.905387560138479e-05, Final Batch Loss: 6.256911001401022e-05\n",
      "Epoch 4952, Loss: 0.00015148354907523753, Final Batch Loss: 0.00015043833991512656\n",
      "Epoch 4953, Loss: 0.0017583027329237666, Final Batch Loss: 0.0017113587819039822\n",
      "Epoch 4954, Loss: 4.959226316714194e-05, Final Batch Loss: 4.4963726395508274e-05\n",
      "Epoch 4955, Loss: 0.0001818861437641317, Final Batch Loss: 0.00016006494115572423\n",
      "Epoch 4956, Loss: 0.0002208120349678211, Final Batch Loss: 0.0002009476738749072\n",
      "Epoch 4957, Loss: 3.070296679652529e-05, Final Batch Loss: 1.9097726180916652e-05\n",
      "Epoch 4958, Loss: 0.0002575767066446133, Final Batch Loss: 0.00018995894060935825\n",
      "Epoch 4959, Loss: 1.957310269062873e-05, Final Batch Loss: 9.37842924031429e-06\n",
      "Epoch 4960, Loss: 0.0006543149065691978, Final Batch Loss: 0.0003983211936429143\n",
      "Epoch 4961, Loss: 4.04710374368733e-06, Final Batch Loss: 3.265578243372147e-06\n",
      "Epoch 4962, Loss: 0.00014502180783892982, Final Batch Loss: 2.631458846735768e-05\n",
      "Epoch 4963, Loss: 8.562847142457031e-05, Final Batch Loss: 7.080450450303033e-05\n",
      "Epoch 4964, Loss: 3.84014674637001e-06, Final Batch Loss: 6.281964033405529e-07\n",
      "Epoch 4965, Loss: 9.091078754863702e-05, Final Batch Loss: 7.367750367848203e-05\n",
      "Epoch 4966, Loss: 0.0011562539111764636, Final Batch Loss: 0.0011403737589716911\n",
      "Epoch 4967, Loss: 0.0004811793533008313, Final Batch Loss: 0.0004666509048547596\n",
      "Epoch 4968, Loss: 0.00043979504698654637, Final Batch Loss: 0.00041818973841145635\n",
      "Epoch 4969, Loss: 4.964812524121953e-05, Final Batch Loss: 1.2574287211464252e-05\n",
      "Epoch 4970, Loss: 0.0001820982633944368, Final Batch Loss: 2.1696023395634256e-05\n",
      "Epoch 4971, Loss: 1.4529418422171148e-05, Final Batch Loss: 8.354704732482787e-06\n",
      "Epoch 4972, Loss: 3.188982702795329e-06, Final Batch Loss: 2.392204351053806e-06\n",
      "Epoch 4973, Loss: 1.4417840930036618e-05, Final Batch Loss: 2.274770622534561e-06\n",
      "Epoch 4974, Loss: 1.0580835578366532e-05, Final Batch Loss: 2.370012907704222e-06\n",
      "Epoch 4975, Loss: 3.664090684196708e-06, Final Batch Loss: 7.669657975384325e-07\n",
      "Epoch 4976, Loss: 7.359822029684437e-05, Final Batch Loss: 6.242375093279406e-05\n",
      "Epoch 4977, Loss: 0.0018310454306629254, Final Batch Loss: 1.1067661034758203e-05\n",
      "Epoch 4978, Loss: 0.00024171970108000096, Final Batch Loss: 0.00021568324882537127\n",
      "Epoch 4979, Loss: 0.00018188965987064876, Final Batch Loss: 4.215741137159057e-05\n",
      "Epoch 4980, Loss: 0.0005936786546953954, Final Batch Loss: 0.00010592852049740031\n",
      "Epoch 4981, Loss: 0.0013787273474008543, Final Batch Loss: 2.8237087462912314e-05\n",
      "Epoch 4982, Loss: 2.154131789211533e-05, Final Batch Loss: 1.564790727570653e-05\n",
      "Epoch 4983, Loss: 0.0002684209002836724, Final Batch Loss: 0.0002564256137702614\n",
      "Epoch 4984, Loss: 8.676164588905522e-05, Final Batch Loss: 8.017274376470596e-05\n",
      "Epoch 4985, Loss: 0.00024798679442028515, Final Batch Loss: 1.7261652828892693e-05\n",
      "Epoch 4986, Loss: 9.066001894098008e-06, Final Batch Loss: 3.367384124430828e-06\n",
      "Epoch 4987, Loss: 1.8600128896650858e-05, Final Batch Loss: 1.5048997738631442e-05\n",
      "Epoch 4988, Loss: 2.80696403933689e-05, Final Batch Loss: 1.9006743968930095e-05\n",
      "Epoch 4989, Loss: 0.003175610938342288, Final Batch Loss: 0.0029322970658540726\n",
      "Epoch 4990, Loss: 0.000496864730280322, Final Batch Loss: 9.675317187429755e-07\n",
      "Epoch 4991, Loss: 0.02060189604529228, Final Batch Loss: 2.8446086730582465e-07\n",
      "Epoch 4992, Loss: 0.00023246343107530265, Final Batch Loss: 0.0002300938795087859\n",
      "Epoch 4993, Loss: 3.4605973269208334e-06, Final Batch Loss: 9.240043254976626e-07\n",
      "Epoch 4994, Loss: 2.350302293052664e-05, Final Batch Loss: 4.362925210443791e-06\n",
      "Epoch 4995, Loss: 2.8947271857759915e-05, Final Batch Loss: 1.1858648576890118e-05\n",
      "Epoch 4996, Loss: 0.006360405241139233, Final Batch Loss: 0.005112537648528814\n",
      "Epoch 4997, Loss: 0.0011886665779456962, Final Batch Loss: 1.966698982869275e-05\n",
      "Epoch 4998, Loss: 0.0020462318732370477, Final Batch Loss: 4.4213970795681234e-07\n",
      "Epoch 4999, Loss: 6.044408621619368e-06, Final Batch Loss: 5.409754521679133e-06\n",
      "Epoch 5000, Loss: 0.001953391178759034, Final Batch Loss: 0.0019532199949026108\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36  0  0]\n",
      " [ 0 36  0]\n",
      " [ 0  0 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        36\n",
      "           1    1.00000   1.00000   1.00000        36\n",
      "           2    1.00000   1.00000   1.00000        38\n",
      "\n",
      "    accuracy                        1.00000       110\n",
      "   macro avg    1.00000   1.00000   1.00000       110\n",
      "weighted avg    1.00000   1.00000   1.00000       110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A0 Solo GAN Group 5_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_1 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A0 Solo GAN Group 5_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_2 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A0 Solo GAN Group 5_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_3 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_1 = np.zeros(n_samples * 3)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A1 Solo GAN Group 5_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_4 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A1 Solo GAN Group 5_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_5 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A1 Solo GAN Group 5_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_6 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_2 = np.ones(n_samples * 3)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A2 Solo GAN Group 5_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_7 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A2 Solo GAN Group 5_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_8 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A2 Solo GAN Group 5_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_9 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_3 = np.ones(n_samples * 3) + 1\n",
    "\n",
    "fake_features = np.concatenate((fake_features_1, fake_features_2, fake_features_3, fake_features_4, fake_features_5, fake_features_6,\n",
    "                         fake_features_7, fake_features_8, fake_features_9))\n",
    "fake_labels = np.concatenate((y_1, y_2, y_3))\n",
    "\n",
    "fake_features = torch.Tensor(fake_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  0  0]\n",
      " [ 0 30  0]\n",
      " [ 0  0 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    1.00000   1.00000   1.00000        30\n",
      "         1.0    1.00000   1.00000   1.00000        30\n",
      "         2.0    1.00000   1.00000   1.00000        30\n",
      "\n",
      "    accuracy                        1.00000        90\n",
      "   macro avg    1.00000   1.00000   1.00000        90\n",
      "weighted avg    1.00000   1.00000   1.00000        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix((fake_labels), preds.cpu()))\n",
    "print(metrics.classification_report((fake_labels), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [23, 25, 27]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 23:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 25:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.592713832855225, Final Batch Loss: 2.28945255279541\n",
      "Epoch 2, Loss: 4.582348823547363, Final Batch Loss: 2.299422025680542\n",
      "Epoch 3, Loss: 4.5614330768585205, Final Batch Loss: 2.2721903324127197\n",
      "Epoch 4, Loss: 4.550448894500732, Final Batch Loss: 2.2759528160095215\n",
      "Epoch 5, Loss: 4.536012172698975, Final Batch Loss: 2.272475481033325\n",
      "Epoch 6, Loss: 4.5207977294921875, Final Batch Loss: 2.254392385482788\n",
      "Epoch 7, Loss: 4.505822420120239, Final Batch Loss: 2.243162155151367\n",
      "Epoch 8, Loss: 4.494362115859985, Final Batch Loss: 2.253983974456787\n",
      "Epoch 9, Loss: 4.473474740982056, Final Batch Loss: 2.2413506507873535\n",
      "Epoch 10, Loss: 4.454813241958618, Final Batch Loss: 2.236320972442627\n",
      "Epoch 11, Loss: 4.430752992630005, Final Batch Loss: 2.2075843811035156\n",
      "Epoch 12, Loss: 4.40290093421936, Final Batch Loss: 2.1948773860931396\n",
      "Epoch 13, Loss: 4.373013257980347, Final Batch Loss: 2.1801562309265137\n",
      "Epoch 14, Loss: 4.340824604034424, Final Batch Loss: 2.177187442779541\n",
      "Epoch 15, Loss: 4.298691987991333, Final Batch Loss: 2.1431474685668945\n",
      "Epoch 16, Loss: 4.248500347137451, Final Batch Loss: 2.114145040512085\n",
      "Epoch 17, Loss: 4.205902814865112, Final Batch Loss: 2.088674783706665\n",
      "Epoch 18, Loss: 4.141854286193848, Final Batch Loss: 2.058634042739868\n",
      "Epoch 19, Loss: 4.077715635299683, Final Batch Loss: 2.0382277965545654\n",
      "Epoch 20, Loss: 4.008937358856201, Final Batch Loss: 1.9986653327941895\n",
      "Epoch 21, Loss: 3.9217381477355957, Final Batch Loss: 1.944332242012024\n",
      "Epoch 22, Loss: 3.8368030786514282, Final Batch Loss: 1.909251093864441\n",
      "Epoch 23, Loss: 3.743618965148926, Final Batch Loss: 1.8714607954025269\n",
      "Epoch 24, Loss: 3.612771987915039, Final Batch Loss: 1.789128065109253\n",
      "Epoch 25, Loss: 3.531672716140747, Final Batch Loss: 1.7567893266677856\n",
      "Epoch 26, Loss: 3.4051748514175415, Final Batch Loss: 1.6924662590026855\n",
      "Epoch 27, Loss: 3.2666518688201904, Final Batch Loss: 1.6433815956115723\n",
      "Epoch 28, Loss: 3.1344475746154785, Final Batch Loss: 1.5478341579437256\n",
      "Epoch 29, Loss: 2.9805567264556885, Final Batch Loss: 1.4746357202529907\n",
      "Epoch 30, Loss: 2.980511784553528, Final Batch Loss: 1.506152868270874\n",
      "Epoch 31, Loss: 2.862404704093933, Final Batch Loss: 1.427470326423645\n",
      "Epoch 32, Loss: 2.7498427629470825, Final Batch Loss: 1.361400842666626\n",
      "Epoch 33, Loss: 2.7296500205993652, Final Batch Loss: 1.3750083446502686\n",
      "Epoch 34, Loss: 2.637105107307434, Final Batch Loss: 1.337797999382019\n",
      "Epoch 35, Loss: 2.598905563354492, Final Batch Loss: 1.3099936246871948\n",
      "Epoch 36, Loss: 2.592960000038147, Final Batch Loss: 1.325095295906067\n",
      "Epoch 37, Loss: 2.580402970314026, Final Batch Loss: 1.2686344385147095\n",
      "Epoch 38, Loss: 2.5655860900878906, Final Batch Loss: 1.319280743598938\n",
      "Epoch 39, Loss: 2.493690609931946, Final Batch Loss: 1.263439416885376\n",
      "Epoch 40, Loss: 2.4756332635879517, Final Batch Loss: 1.2582358121871948\n",
      "Epoch 41, Loss: 2.448344588279724, Final Batch Loss: 1.2003436088562012\n",
      "Epoch 42, Loss: 2.4249870777130127, Final Batch Loss: 1.2105158567428589\n",
      "Epoch 43, Loss: 2.4189449548721313, Final Batch Loss: 1.2489230632781982\n",
      "Epoch 44, Loss: 2.4253123998641968, Final Batch Loss: 1.1844865083694458\n",
      "Epoch 45, Loss: 2.4260635375976562, Final Batch Loss: 1.2288490533828735\n",
      "Epoch 46, Loss: 2.3941187858581543, Final Batch Loss: 1.2344309091567993\n",
      "Epoch 47, Loss: 2.4157209396362305, Final Batch Loss: 1.2087148427963257\n",
      "Epoch 48, Loss: 2.3801082372665405, Final Batch Loss: 1.193091869354248\n",
      "Epoch 49, Loss: 2.356105327606201, Final Batch Loss: 1.1786143779754639\n",
      "Epoch 50, Loss: 2.3344566822052, Final Batch Loss: 1.1660890579223633\n",
      "Epoch 51, Loss: 2.281062960624695, Final Batch Loss: 1.142730951309204\n",
      "Epoch 52, Loss: 2.2811527252197266, Final Batch Loss: 1.1172411441802979\n",
      "Epoch 53, Loss: 2.250961661338806, Final Batch Loss: 1.1322344541549683\n",
      "Epoch 54, Loss: 2.2262701988220215, Final Batch Loss: 1.1140893697738647\n",
      "Epoch 55, Loss: 2.2000951766967773, Final Batch Loss: 1.1171677112579346\n",
      "Epoch 56, Loss: 2.200727105140686, Final Batch Loss: 1.0785070657730103\n",
      "Epoch 57, Loss: 2.1650882959365845, Final Batch Loss: 1.1021292209625244\n",
      "Epoch 58, Loss: 2.1632999181747437, Final Batch Loss: 1.046734094619751\n",
      "Epoch 59, Loss: 2.1747459173202515, Final Batch Loss: 1.083500623703003\n",
      "Epoch 60, Loss: 2.157757878303528, Final Batch Loss: 1.0990626811981201\n",
      "Epoch 61, Loss: 2.1231168508529663, Final Batch Loss: 1.0784417390823364\n",
      "Epoch 62, Loss: 2.23276686668396, Final Batch Loss: 1.1666215658187866\n",
      "Epoch 63, Loss: 2.0848644971847534, Final Batch Loss: 1.002191185951233\n",
      "Epoch 64, Loss: 2.0747883319854736, Final Batch Loss: 1.0449457168579102\n",
      "Epoch 65, Loss: 2.1285287141799927, Final Batch Loss: 1.0698524713516235\n",
      "Epoch 66, Loss: 2.0955240726470947, Final Batch Loss: 1.0639108419418335\n",
      "Epoch 67, Loss: 2.081059455871582, Final Batch Loss: 1.0342936515808105\n",
      "Epoch 68, Loss: 2.049642562866211, Final Batch Loss: 1.0132200717926025\n",
      "Epoch 69, Loss: 2.071784019470215, Final Batch Loss: 1.0159330368041992\n",
      "Epoch 70, Loss: 1.989173710346222, Final Batch Loss: 0.9888854622840881\n",
      "Epoch 71, Loss: 1.9553181529045105, Final Batch Loss: 0.9906446933746338\n",
      "Epoch 72, Loss: 2.011769950389862, Final Batch Loss: 1.024127721786499\n",
      "Epoch 73, Loss: 2.006299614906311, Final Batch Loss: 1.022036075592041\n",
      "Epoch 74, Loss: 1.9431806206703186, Final Batch Loss: 0.9757413268089294\n",
      "Epoch 75, Loss: 2.0098354816436768, Final Batch Loss: 0.9873682260513306\n",
      "Epoch 76, Loss: 1.8934711813926697, Final Batch Loss: 0.9142975807189941\n",
      "Epoch 77, Loss: 1.9570955634117126, Final Batch Loss: 0.9532167315483093\n",
      "Epoch 78, Loss: 1.9653627276420593, Final Batch Loss: 1.0113173723220825\n",
      "Epoch 79, Loss: 1.8865039944648743, Final Batch Loss: 0.9294023513793945\n",
      "Epoch 80, Loss: 1.884462594985962, Final Batch Loss: 0.9355672001838684\n",
      "Epoch 81, Loss: 1.9604178667068481, Final Batch Loss: 1.0485448837280273\n",
      "Epoch 82, Loss: 1.8345932364463806, Final Batch Loss: 0.9262000918388367\n",
      "Epoch 83, Loss: 1.9415573477745056, Final Batch Loss: 0.9826328158378601\n",
      "Epoch 84, Loss: 1.8972672820091248, Final Batch Loss: 0.9226241111755371\n",
      "Epoch 85, Loss: 1.8560446500778198, Final Batch Loss: 0.9122956991195679\n",
      "Epoch 86, Loss: 1.8994613885879517, Final Batch Loss: 0.9780958890914917\n",
      "Epoch 87, Loss: 1.8280036449432373, Final Batch Loss: 0.8504170179367065\n",
      "Epoch 88, Loss: 1.8421991467475891, Final Batch Loss: 0.910503089427948\n",
      "Epoch 89, Loss: 1.8501001596450806, Final Batch Loss: 0.8498314619064331\n",
      "Epoch 90, Loss: 1.8445938229560852, Final Batch Loss: 0.9418564438819885\n",
      "Epoch 91, Loss: 1.869072675704956, Final Batch Loss: 0.9042458534240723\n",
      "Epoch 92, Loss: 1.8457799553871155, Final Batch Loss: 0.9274340271949768\n",
      "Epoch 93, Loss: 1.8382049798965454, Final Batch Loss: 0.9362289309501648\n",
      "Epoch 94, Loss: 1.7974213361740112, Final Batch Loss: 0.89950031042099\n",
      "Epoch 95, Loss: 1.8127086758613586, Final Batch Loss: 0.901176393032074\n",
      "Epoch 96, Loss: 1.7341615557670593, Final Batch Loss: 0.8890072703361511\n",
      "Epoch 97, Loss: 1.8269599080085754, Final Batch Loss: 0.9295083284378052\n",
      "Epoch 98, Loss: 1.827341079711914, Final Batch Loss: 0.9271907210350037\n",
      "Epoch 99, Loss: 1.759448528289795, Final Batch Loss: 0.8624556064605713\n",
      "Epoch 100, Loss: 1.7561058402061462, Final Batch Loss: 0.8839871883392334\n",
      "Epoch 101, Loss: 1.8356812000274658, Final Batch Loss: 0.9562335014343262\n",
      "Epoch 102, Loss: 1.7938827872276306, Final Batch Loss: 0.8781401515007019\n",
      "Epoch 103, Loss: 1.7763768434524536, Final Batch Loss: 0.9135666489601135\n",
      "Epoch 104, Loss: 1.7416172623634338, Final Batch Loss: 0.8745833039283752\n",
      "Epoch 105, Loss: 1.7451012134552002, Final Batch Loss: 0.8748182654380798\n",
      "Epoch 106, Loss: 1.777603268623352, Final Batch Loss: 0.8665468692779541\n",
      "Epoch 107, Loss: 1.7531166076660156, Final Batch Loss: 0.9106367826461792\n",
      "Epoch 108, Loss: 1.7130256295204163, Final Batch Loss: 0.8600288033485413\n",
      "Epoch 109, Loss: 1.8301960229873657, Final Batch Loss: 0.9155022501945496\n",
      "Epoch 110, Loss: 1.7230066657066345, Final Batch Loss: 0.9177170991897583\n",
      "Epoch 111, Loss: 1.6989747285842896, Final Batch Loss: 0.8286895155906677\n",
      "Epoch 112, Loss: 1.7088586688041687, Final Batch Loss: 0.8512935638427734\n",
      "Epoch 113, Loss: 1.7574710845947266, Final Batch Loss: 0.9078906774520874\n",
      "Epoch 114, Loss: 1.7152278423309326, Final Batch Loss: 0.826078474521637\n",
      "Epoch 115, Loss: 1.6633754968643188, Final Batch Loss: 0.8056395053863525\n",
      "Epoch 116, Loss: 1.736307680606842, Final Batch Loss: 0.8288649916648865\n",
      "Epoch 117, Loss: 1.6743947863578796, Final Batch Loss: 0.8086931109428406\n",
      "Epoch 118, Loss: 1.7308441996574402, Final Batch Loss: 0.8621944189071655\n",
      "Epoch 119, Loss: 1.694453775882721, Final Batch Loss: 0.836369514465332\n",
      "Epoch 120, Loss: 1.6853742599487305, Final Batch Loss: 0.8554455041885376\n",
      "Epoch 121, Loss: 1.6944213509559631, Final Batch Loss: 0.8569119572639465\n",
      "Epoch 122, Loss: 1.6428855061531067, Final Batch Loss: 0.776267945766449\n",
      "Epoch 123, Loss: 1.6827111840248108, Final Batch Loss: 0.8631519079208374\n",
      "Epoch 124, Loss: 1.710418939590454, Final Batch Loss: 0.8483718633651733\n",
      "Epoch 125, Loss: 1.6564632654190063, Final Batch Loss: 0.797710120677948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126, Loss: 1.619704782962799, Final Batch Loss: 0.8073249459266663\n",
      "Epoch 127, Loss: 1.6581289172172546, Final Batch Loss: 0.8561289310455322\n",
      "Epoch 128, Loss: 1.637282907962799, Final Batch Loss: 0.8151730298995972\n",
      "Epoch 129, Loss: 1.6364168524742126, Final Batch Loss: 0.7978498935699463\n",
      "Epoch 130, Loss: 1.6114662289619446, Final Batch Loss: 0.7987414002418518\n",
      "Epoch 131, Loss: 1.6039546728134155, Final Batch Loss: 0.8285960555076599\n",
      "Epoch 132, Loss: 1.665042519569397, Final Batch Loss: 0.7762026786804199\n",
      "Epoch 133, Loss: 1.6698585152626038, Final Batch Loss: 0.8753190040588379\n",
      "Epoch 134, Loss: 1.5924875140190125, Final Batch Loss: 0.7928985357284546\n",
      "Epoch 135, Loss: 1.6339794397354126, Final Batch Loss: 0.800942063331604\n",
      "Epoch 136, Loss: 1.570720374584198, Final Batch Loss: 0.774533212184906\n",
      "Epoch 137, Loss: 1.631464660167694, Final Batch Loss: 0.8236614465713501\n",
      "Epoch 138, Loss: 1.5816344618797302, Final Batch Loss: 0.8049893379211426\n",
      "Epoch 139, Loss: 1.5791565775871277, Final Batch Loss: 0.8052802681922913\n",
      "Epoch 140, Loss: 1.5728693008422852, Final Batch Loss: 0.771576464176178\n",
      "Epoch 141, Loss: 1.5930818915367126, Final Batch Loss: 0.8065569996833801\n",
      "Epoch 142, Loss: 1.584159255027771, Final Batch Loss: 0.779155969619751\n",
      "Epoch 143, Loss: 1.5637838244438171, Final Batch Loss: 0.7880975008010864\n",
      "Epoch 144, Loss: 1.508077323436737, Final Batch Loss: 0.7240848541259766\n",
      "Epoch 145, Loss: 1.5396753549575806, Final Batch Loss: 0.7923386096954346\n",
      "Epoch 146, Loss: 1.6009482741355896, Final Batch Loss: 0.8728030323982239\n",
      "Epoch 147, Loss: 1.5331554412841797, Final Batch Loss: 0.7558773159980774\n",
      "Epoch 148, Loss: 1.519047498703003, Final Batch Loss: 0.7133256793022156\n",
      "Epoch 149, Loss: 1.5065036416053772, Final Batch Loss: 0.7108153700828552\n",
      "Epoch 150, Loss: 1.5086265206336975, Final Batch Loss: 0.7437239289283752\n",
      "Epoch 151, Loss: 1.5275243520736694, Final Batch Loss: 0.7903149127960205\n",
      "Epoch 152, Loss: 1.543401062488556, Final Batch Loss: 0.8322979211807251\n",
      "Epoch 153, Loss: 1.5508025884628296, Final Batch Loss: 0.7556398510932922\n",
      "Epoch 154, Loss: 1.5213931798934937, Final Batch Loss: 0.7501232624053955\n",
      "Epoch 155, Loss: 1.5303053259849548, Final Batch Loss: 0.7567688226699829\n",
      "Epoch 156, Loss: 1.4922921657562256, Final Batch Loss: 0.7171371579170227\n",
      "Epoch 157, Loss: 1.499759018421173, Final Batch Loss: 0.7360479831695557\n",
      "Epoch 158, Loss: 1.4933124780654907, Final Batch Loss: 0.7499998211860657\n",
      "Epoch 159, Loss: 1.4711514115333557, Final Batch Loss: 0.7343588471412659\n",
      "Epoch 160, Loss: 1.4502474665641785, Final Batch Loss: 0.7299656271934509\n",
      "Epoch 161, Loss: 1.5017783641815186, Final Batch Loss: 0.7534828186035156\n",
      "Epoch 162, Loss: 1.5025246739387512, Final Batch Loss: 0.7558575868606567\n",
      "Epoch 163, Loss: 1.4455778002738953, Final Batch Loss: 0.6875248551368713\n",
      "Epoch 164, Loss: 1.4250856637954712, Final Batch Loss: 0.6953591704368591\n",
      "Epoch 165, Loss: 1.4441116452217102, Final Batch Loss: 0.7374663352966309\n",
      "Epoch 166, Loss: 1.406602382659912, Final Batch Loss: 0.6740512847900391\n",
      "Epoch 167, Loss: 1.428432583808899, Final Batch Loss: 0.7235236763954163\n",
      "Epoch 168, Loss: 1.4349862933158875, Final Batch Loss: 0.6956639885902405\n",
      "Epoch 169, Loss: 1.4339852333068848, Final Batch Loss: 0.7064386010169983\n",
      "Epoch 170, Loss: 1.4586004614830017, Final Batch Loss: 0.726956307888031\n",
      "Epoch 171, Loss: 1.4553143978118896, Final Batch Loss: 0.762981653213501\n",
      "Epoch 172, Loss: 1.390384316444397, Final Batch Loss: 0.6663232445716858\n",
      "Epoch 173, Loss: 1.3923824429512024, Final Batch Loss: 0.6426501870155334\n",
      "Epoch 174, Loss: 1.405493140220642, Final Batch Loss: 0.6372459530830383\n",
      "Epoch 175, Loss: 1.4017664790153503, Final Batch Loss: 0.6753903031349182\n",
      "Epoch 176, Loss: 1.425843060016632, Final Batch Loss: 0.6905253529548645\n",
      "Epoch 177, Loss: 1.4189268350601196, Final Batch Loss: 0.7089627385139465\n",
      "Epoch 178, Loss: 1.3925992250442505, Final Batch Loss: 0.6684643030166626\n",
      "Epoch 179, Loss: 1.4397158026695251, Final Batch Loss: 0.7842086553573608\n",
      "Epoch 180, Loss: 1.4211262464523315, Final Batch Loss: 0.7061192989349365\n",
      "Epoch 181, Loss: 1.3894901275634766, Final Batch Loss: 0.6729565262794495\n",
      "Epoch 182, Loss: 1.3547348380088806, Final Batch Loss: 0.6686813235282898\n",
      "Epoch 183, Loss: 1.4075218439102173, Final Batch Loss: 0.6192641258239746\n",
      "Epoch 184, Loss: 1.4434441328048706, Final Batch Loss: 0.7503885626792908\n",
      "Epoch 185, Loss: 1.3848323822021484, Final Batch Loss: 0.7086571455001831\n",
      "Epoch 186, Loss: 1.3531168699264526, Final Batch Loss: 0.6813311576843262\n",
      "Epoch 187, Loss: 1.4061183333396912, Final Batch Loss: 0.7296150922775269\n",
      "Epoch 188, Loss: 1.383234679698944, Final Batch Loss: 0.655027449131012\n",
      "Epoch 189, Loss: 1.3905636072158813, Final Batch Loss: 0.708040177822113\n",
      "Epoch 190, Loss: 1.3704876899719238, Final Batch Loss: 0.6781361699104309\n",
      "Epoch 191, Loss: 1.3655147552490234, Final Batch Loss: 0.7121480107307434\n",
      "Epoch 192, Loss: 1.3791945576667786, Final Batch Loss: 0.725284218788147\n",
      "Epoch 193, Loss: 1.3496814966201782, Final Batch Loss: 0.6602819561958313\n",
      "Epoch 194, Loss: 1.3640177845954895, Final Batch Loss: 0.7067083716392517\n",
      "Epoch 195, Loss: 1.3930490016937256, Final Batch Loss: 0.7462570071220398\n",
      "Epoch 196, Loss: 1.368605375289917, Final Batch Loss: 0.6748152375221252\n",
      "Epoch 197, Loss: 1.370467722415924, Final Batch Loss: 0.6446011066436768\n",
      "Epoch 198, Loss: 1.378443717956543, Final Batch Loss: 0.6913368701934814\n",
      "Epoch 199, Loss: 1.3600081205368042, Final Batch Loss: 0.6816522479057312\n",
      "Epoch 200, Loss: 1.409500539302826, Final Batch Loss: 0.7220950126647949\n",
      "Epoch 201, Loss: 1.340578854084015, Final Batch Loss: 0.6805369853973389\n",
      "Epoch 202, Loss: 1.3020519614219666, Final Batch Loss: 0.6301760673522949\n",
      "Epoch 203, Loss: 1.2863527536392212, Final Batch Loss: 0.6358282566070557\n",
      "Epoch 204, Loss: 1.3633251786231995, Final Batch Loss: 0.7239299416542053\n",
      "Epoch 205, Loss: 1.3965957760810852, Final Batch Loss: 0.7286361455917358\n",
      "Epoch 206, Loss: 1.3409042358398438, Final Batch Loss: 0.7188740372657776\n",
      "Epoch 207, Loss: 1.3597474694252014, Final Batch Loss: 0.6579574346542358\n",
      "Epoch 208, Loss: 1.3254520893096924, Final Batch Loss: 0.7103282809257507\n",
      "Epoch 209, Loss: 1.3552847504615784, Final Batch Loss: 0.7080501914024353\n",
      "Epoch 210, Loss: 1.330403745174408, Final Batch Loss: 0.6471896171569824\n",
      "Epoch 211, Loss: 1.3287484049797058, Final Batch Loss: 0.649875283241272\n",
      "Epoch 212, Loss: 1.3601373434066772, Final Batch Loss: 0.6869761347770691\n",
      "Epoch 213, Loss: 1.322462022304535, Final Batch Loss: 0.6097398996353149\n",
      "Epoch 214, Loss: 1.3059797286987305, Final Batch Loss: 0.6987623572349548\n",
      "Epoch 215, Loss: 1.326729655265808, Final Batch Loss: 0.6524743437767029\n",
      "Epoch 216, Loss: 1.2968443036079407, Final Batch Loss: 0.6518619060516357\n",
      "Epoch 217, Loss: 1.3148841857910156, Final Batch Loss: 0.6757338047027588\n",
      "Epoch 218, Loss: 1.2897379994392395, Final Batch Loss: 0.6799807548522949\n",
      "Epoch 219, Loss: 1.3122254014015198, Final Batch Loss: 0.6597750782966614\n",
      "Epoch 220, Loss: 1.3301303386688232, Final Batch Loss: 0.6893340349197388\n",
      "Epoch 221, Loss: 1.304751694202423, Final Batch Loss: 0.6891254186630249\n",
      "Epoch 222, Loss: 1.300473153591156, Final Batch Loss: 0.6565352082252502\n",
      "Epoch 223, Loss: 1.3080355525016785, Final Batch Loss: 0.6218600273132324\n",
      "Epoch 224, Loss: 1.281033456325531, Final Batch Loss: 0.6719297170639038\n",
      "Epoch 225, Loss: 1.3223256468772888, Final Batch Loss: 0.6583588123321533\n",
      "Epoch 226, Loss: 1.2986523509025574, Final Batch Loss: 0.641486406326294\n",
      "Epoch 227, Loss: 1.2582672834396362, Final Batch Loss: 0.6273401975631714\n",
      "Epoch 228, Loss: 1.2765763401985168, Final Batch Loss: 0.5964255332946777\n",
      "Epoch 229, Loss: 1.2854208946228027, Final Batch Loss: 0.6431472301483154\n",
      "Epoch 230, Loss: 1.2733713388442993, Final Batch Loss: 0.6477578282356262\n",
      "Epoch 231, Loss: 1.2540592551231384, Final Batch Loss: 0.6524332165718079\n",
      "Epoch 232, Loss: 1.2523991465568542, Final Batch Loss: 0.5842668414115906\n",
      "Epoch 233, Loss: 1.2423787713050842, Final Batch Loss: 0.6149551868438721\n",
      "Epoch 234, Loss: 1.2730939984321594, Final Batch Loss: 0.6240203380584717\n",
      "Epoch 235, Loss: 1.2686575055122375, Final Batch Loss: 0.664412260055542\n",
      "Epoch 236, Loss: 1.299602746963501, Final Batch Loss: 0.6249212026596069\n",
      "Epoch 237, Loss: 1.2576221227645874, Final Batch Loss: 0.6330400705337524\n",
      "Epoch 238, Loss: 1.262926995754242, Final Batch Loss: 0.6617922782897949\n",
      "Epoch 239, Loss: 1.2302376627922058, Final Batch Loss: 0.605922520160675\n",
      "Epoch 240, Loss: 1.2465389370918274, Final Batch Loss: 0.6312381625175476\n",
      "Epoch 241, Loss: 1.2307466864585876, Final Batch Loss: 0.5850999355316162\n",
      "Epoch 242, Loss: 1.2530621886253357, Final Batch Loss: 0.6689708232879639\n",
      "Epoch 243, Loss: 1.2032224535942078, Final Batch Loss: 0.5842035412788391\n",
      "Epoch 244, Loss: 1.2494469285011292, Final Batch Loss: 0.6474284529685974\n",
      "Epoch 245, Loss: 1.2511340975761414, Final Batch Loss: 0.6249268054962158\n",
      "Epoch 246, Loss: 1.2705222368240356, Final Batch Loss: 0.6371678113937378\n",
      "Epoch 247, Loss: 1.2306975722312927, Final Batch Loss: 0.6034512519836426\n",
      "Epoch 248, Loss: 1.1565290689468384, Final Batch Loss: 0.5663108825683594\n",
      "Epoch 249, Loss: 1.2310277819633484, Final Batch Loss: 0.623267650604248\n",
      "Epoch 250, Loss: 1.2028953433036804, Final Batch Loss: 0.6399856805801392\n",
      "Epoch 251, Loss: 1.2236834168434143, Final Batch Loss: 0.6339200735092163\n",
      "Epoch 252, Loss: 1.1946523785591125, Final Batch Loss: 0.5915555357933044\n",
      "Epoch 253, Loss: 1.1994757652282715, Final Batch Loss: 0.5902819037437439\n",
      "Epoch 254, Loss: 1.1944217085838318, Final Batch Loss: 0.5711524486541748\n",
      "Epoch 255, Loss: 1.2164673209190369, Final Batch Loss: 0.5829324126243591\n",
      "Epoch 256, Loss: 1.1919775009155273, Final Batch Loss: 0.5853484869003296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257, Loss: 1.1550130248069763, Final Batch Loss: 0.582808256149292\n",
      "Epoch 258, Loss: 1.186354398727417, Final Batch Loss: 0.576886773109436\n",
      "Epoch 259, Loss: 1.1867223381996155, Final Batch Loss: 0.5855450630187988\n",
      "Epoch 260, Loss: 1.1714747548103333, Final Batch Loss: 0.6144552826881409\n",
      "Epoch 261, Loss: 1.1534550786018372, Final Batch Loss: 0.555401623249054\n",
      "Epoch 262, Loss: 1.1798474788665771, Final Batch Loss: 0.5604533553123474\n",
      "Epoch 263, Loss: 1.1677351593971252, Final Batch Loss: 0.5512164235115051\n",
      "Epoch 264, Loss: 1.1740731000900269, Final Batch Loss: 0.5718376636505127\n",
      "Epoch 265, Loss: 1.1792755126953125, Final Batch Loss: 0.6037541031837463\n",
      "Epoch 266, Loss: 1.133442223072052, Final Batch Loss: 0.5832855105400085\n",
      "Epoch 267, Loss: 1.1450448632240295, Final Batch Loss: 0.5583735704421997\n",
      "Epoch 268, Loss: 1.1301632523536682, Final Batch Loss: 0.5652783513069153\n",
      "Epoch 269, Loss: 1.1367736458778381, Final Batch Loss: 0.5662752389907837\n",
      "Epoch 270, Loss: 1.1032909750938416, Final Batch Loss: 0.5587895512580872\n",
      "Epoch 271, Loss: 1.1179522275924683, Final Batch Loss: 0.554915726184845\n",
      "Epoch 272, Loss: 1.1045289635658264, Final Batch Loss: 0.549291729927063\n",
      "Epoch 273, Loss: 1.1069302558898926, Final Batch Loss: 0.5637341737747192\n",
      "Epoch 274, Loss: 1.1171031594276428, Final Batch Loss: 0.5453511476516724\n",
      "Epoch 275, Loss: 1.09928560256958, Final Batch Loss: 0.5536372065544128\n",
      "Epoch 276, Loss: 1.0732120275497437, Final Batch Loss: 0.5593554377555847\n",
      "Epoch 277, Loss: 1.119819164276123, Final Batch Loss: 0.575958788394928\n",
      "Epoch 278, Loss: 1.0683144330978394, Final Batch Loss: 0.5142054557800293\n",
      "Epoch 279, Loss: 1.0633010864257812, Final Batch Loss: 0.5170831680297852\n",
      "Epoch 280, Loss: 1.021593153476715, Final Batch Loss: 0.4959631562232971\n",
      "Epoch 281, Loss: 1.0219315588474274, Final Batch Loss: 0.47049883008003235\n",
      "Epoch 282, Loss: 1.0614643692970276, Final Batch Loss: 0.5248025059700012\n",
      "Epoch 283, Loss: 1.0773710012435913, Final Batch Loss: 0.5429298281669617\n",
      "Epoch 284, Loss: 1.023143708705902, Final Batch Loss: 0.48492491245269775\n",
      "Epoch 285, Loss: 1.0521232187747955, Final Batch Loss: 0.4768938720226288\n",
      "Epoch 286, Loss: 1.015381395816803, Final Batch Loss: 0.5375096797943115\n",
      "Epoch 287, Loss: 1.0154495537281036, Final Batch Loss: 0.5260305404663086\n",
      "Epoch 288, Loss: 0.9758187532424927, Final Batch Loss: 0.4864285886287689\n",
      "Epoch 289, Loss: 1.0093711018562317, Final Batch Loss: 0.5091215372085571\n",
      "Epoch 290, Loss: 0.9963674247264862, Final Batch Loss: 0.44170311093330383\n",
      "Epoch 291, Loss: 1.0008956789970398, Final Batch Loss: 0.531494677066803\n",
      "Epoch 292, Loss: 1.0376948714256287, Final Batch Loss: 0.5086414217948914\n",
      "Epoch 293, Loss: 0.9621480107307434, Final Batch Loss: 0.464979350566864\n",
      "Epoch 294, Loss: 1.0391657650470734, Final Batch Loss: 0.49756506085395813\n",
      "Epoch 295, Loss: 0.9889250099658966, Final Batch Loss: 0.4819613993167877\n",
      "Epoch 296, Loss: 0.8925290703773499, Final Batch Loss: 0.396085262298584\n",
      "Epoch 297, Loss: 0.9620201885700226, Final Batch Loss: 0.49621444940567017\n",
      "Epoch 298, Loss: 1.0260945558547974, Final Batch Loss: 0.5339609980583191\n",
      "Epoch 299, Loss: 0.9880168437957764, Final Batch Loss: 0.5003117918968201\n",
      "Epoch 300, Loss: 0.9294191896915436, Final Batch Loss: 0.47543632984161377\n",
      "Epoch 301, Loss: 0.9391235113143921, Final Batch Loss: 0.45358768105506897\n",
      "Epoch 302, Loss: 0.9718860685825348, Final Batch Loss: 0.49288132786750793\n",
      "Epoch 303, Loss: 0.9302695691585541, Final Batch Loss: 0.4466197192668915\n",
      "Epoch 304, Loss: 0.9705823957920074, Final Batch Loss: 0.49156802892684937\n",
      "Epoch 305, Loss: 0.8798268735408783, Final Batch Loss: 0.416373074054718\n",
      "Epoch 306, Loss: 0.916217178106308, Final Batch Loss: 0.4355570077896118\n",
      "Epoch 307, Loss: 0.8941912055015564, Final Batch Loss: 0.4689120352268219\n",
      "Epoch 308, Loss: 0.9521088004112244, Final Batch Loss: 0.4660309851169586\n",
      "Epoch 309, Loss: 0.93353471159935, Final Batch Loss: 0.48225560784339905\n",
      "Epoch 310, Loss: 0.8902040123939514, Final Batch Loss: 0.45338916778564453\n",
      "Epoch 311, Loss: 0.8801724314689636, Final Batch Loss: 0.46688026189804077\n",
      "Epoch 312, Loss: 0.9033320844173431, Final Batch Loss: 0.4692135453224182\n",
      "Epoch 313, Loss: 0.914436012506485, Final Batch Loss: 0.476037859916687\n",
      "Epoch 314, Loss: 0.944180816411972, Final Batch Loss: 0.46789154410362244\n",
      "Epoch 315, Loss: 0.9075103402137756, Final Batch Loss: 0.4476373791694641\n",
      "Epoch 316, Loss: 0.8919116854667664, Final Batch Loss: 0.44260507822036743\n",
      "Epoch 317, Loss: 0.8754830956459045, Final Batch Loss: 0.458636611700058\n",
      "Epoch 318, Loss: 0.8741939961910248, Final Batch Loss: 0.40432319045066833\n",
      "Epoch 319, Loss: 0.9097959399223328, Final Batch Loss: 0.43767398595809937\n",
      "Epoch 320, Loss: 0.8989512026309967, Final Batch Loss: 0.45793959498405457\n",
      "Epoch 321, Loss: 0.9185439050197601, Final Batch Loss: 0.4623301327228546\n",
      "Epoch 322, Loss: 0.8516628742218018, Final Batch Loss: 0.40012887120246887\n",
      "Epoch 323, Loss: 0.812233954668045, Final Batch Loss: 0.4037116765975952\n",
      "Epoch 324, Loss: 0.8331338465213776, Final Batch Loss: 0.3968563675880432\n",
      "Epoch 325, Loss: 0.8756763637065887, Final Batch Loss: 0.40677589178085327\n",
      "Epoch 326, Loss: 0.8898105025291443, Final Batch Loss: 0.4269450902938843\n",
      "Epoch 327, Loss: 0.814739853143692, Final Batch Loss: 0.35215163230895996\n",
      "Epoch 328, Loss: 0.8767263293266296, Final Batch Loss: 0.4558482766151428\n",
      "Epoch 329, Loss: 0.9116009473800659, Final Batch Loss: 0.44185763597488403\n",
      "Epoch 330, Loss: 0.8587526977062225, Final Batch Loss: 0.43710705637931824\n",
      "Epoch 331, Loss: 0.7545572817325592, Final Batch Loss: 0.3572773337364197\n",
      "Epoch 332, Loss: 0.8160707354545593, Final Batch Loss: 0.3669593930244446\n",
      "Epoch 333, Loss: 0.7607426345348358, Final Batch Loss: 0.38408857583999634\n",
      "Epoch 334, Loss: 0.9133399426937103, Final Batch Loss: 0.47615817189216614\n",
      "Epoch 335, Loss: 0.827181339263916, Final Batch Loss: 0.44830211997032166\n",
      "Epoch 336, Loss: 0.8072670698165894, Final Batch Loss: 0.3915282189846039\n",
      "Epoch 337, Loss: 0.809079647064209, Final Batch Loss: 0.3975543975830078\n",
      "Epoch 338, Loss: 0.815816342830658, Final Batch Loss: 0.39750513434410095\n",
      "Epoch 339, Loss: 0.7559199035167694, Final Batch Loss: 0.33953192830085754\n",
      "Epoch 340, Loss: 0.8406603932380676, Final Batch Loss: 0.4395955801010132\n",
      "Epoch 341, Loss: 0.8034379184246063, Final Batch Loss: 0.41762152314186096\n",
      "Epoch 342, Loss: 0.7782416939735413, Final Batch Loss: 0.36498716473579407\n",
      "Epoch 343, Loss: 0.806772768497467, Final Batch Loss: 0.3911677300930023\n",
      "Epoch 344, Loss: 0.8208340406417847, Final Batch Loss: 0.40904441475868225\n",
      "Epoch 345, Loss: 0.8063642382621765, Final Batch Loss: 0.38355913758277893\n",
      "Epoch 346, Loss: 0.8318500518798828, Final Batch Loss: 0.4300159811973572\n",
      "Epoch 347, Loss: 0.7771339416503906, Final Batch Loss: 0.431029736995697\n",
      "Epoch 348, Loss: 0.7581383585929871, Final Batch Loss: 0.36682114005088806\n",
      "Epoch 349, Loss: 0.7863447070121765, Final Batch Loss: 0.36285388469696045\n",
      "Epoch 350, Loss: 0.7998825311660767, Final Batch Loss: 0.3653731942176819\n",
      "Epoch 351, Loss: 0.7233502268791199, Final Batch Loss: 0.325732558965683\n",
      "Epoch 352, Loss: 0.8216794729232788, Final Batch Loss: 0.4141409695148468\n",
      "Epoch 353, Loss: 0.7716063261032104, Final Batch Loss: 0.3648134768009186\n",
      "Epoch 354, Loss: 0.7226706743240356, Final Batch Loss: 0.34114882349967957\n",
      "Epoch 355, Loss: 0.7344045042991638, Final Batch Loss: 0.3870088756084442\n",
      "Epoch 356, Loss: 0.734771192073822, Final Batch Loss: 0.3819662034511566\n",
      "Epoch 357, Loss: 0.7224337756633759, Final Batch Loss: 0.37850335240364075\n",
      "Epoch 358, Loss: 0.7698932588100433, Final Batch Loss: 0.39668527245521545\n",
      "Epoch 359, Loss: 0.7950719892978668, Final Batch Loss: 0.44112247228622437\n",
      "Epoch 360, Loss: 0.8174578249454498, Final Batch Loss: 0.434113472700119\n",
      "Epoch 361, Loss: 0.7654320895671844, Final Batch Loss: 0.364898681640625\n",
      "Epoch 362, Loss: 0.7920362651348114, Final Batch Loss: 0.3809528350830078\n",
      "Epoch 363, Loss: 0.7408957481384277, Final Batch Loss: 0.37269434332847595\n",
      "Epoch 364, Loss: 0.7276407182216644, Final Batch Loss: 0.36989858746528625\n",
      "Epoch 365, Loss: 0.7271631062030792, Final Batch Loss: 0.3119732737541199\n",
      "Epoch 366, Loss: 0.757798969745636, Final Batch Loss: 0.3382052481174469\n",
      "Epoch 367, Loss: 0.7329586148262024, Final Batch Loss: 0.383608877658844\n",
      "Epoch 368, Loss: 0.80049267411232, Final Batch Loss: 0.39230743050575256\n",
      "Epoch 369, Loss: 0.785488486289978, Final Batch Loss: 0.4101601243019104\n",
      "Epoch 370, Loss: 0.7280013561248779, Final Batch Loss: 0.3541858494281769\n",
      "Epoch 371, Loss: 0.7048478126525879, Final Batch Loss: 0.35698559880256653\n",
      "Epoch 372, Loss: 0.7535941302776337, Final Batch Loss: 0.40269047021865845\n",
      "Epoch 373, Loss: 0.7086076736450195, Final Batch Loss: 0.3517918288707733\n",
      "Epoch 374, Loss: 0.6967500448226929, Final Batch Loss: 0.3592383563518524\n",
      "Epoch 375, Loss: 0.7250122427940369, Final Batch Loss: 0.35091471672058105\n",
      "Epoch 376, Loss: 0.7463001310825348, Final Batch Loss: 0.28820204734802246\n",
      "Epoch 377, Loss: 0.7331611812114716, Final Batch Loss: 0.37030720710754395\n",
      "Epoch 378, Loss: 0.7301395833492279, Final Batch Loss: 0.35217228531837463\n",
      "Epoch 379, Loss: 0.6908542513847351, Final Batch Loss: 0.37603989243507385\n",
      "Epoch 380, Loss: 0.7568617463111877, Final Batch Loss: 0.4103190004825592\n",
      "Epoch 381, Loss: 0.7324936389923096, Final Batch Loss: 0.37370893359184265\n",
      "Epoch 382, Loss: 0.6880411505699158, Final Batch Loss: 0.36185115575790405\n",
      "Epoch 383, Loss: 0.7055374979972839, Final Batch Loss: 0.3691731095314026\n",
      "Epoch 384, Loss: 0.6981178522109985, Final Batch Loss: 0.3343189060688019\n",
      "Epoch 385, Loss: 0.6918849050998688, Final Batch Loss: 0.3328636884689331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386, Loss: 0.6800519227981567, Final Batch Loss: 0.33290690183639526\n",
      "Epoch 387, Loss: 0.6919539868831635, Final Batch Loss: 0.34291931986808777\n",
      "Epoch 388, Loss: 0.689581423997879, Final Batch Loss: 0.36826327443122864\n",
      "Epoch 389, Loss: 0.70786052942276, Final Batch Loss: 0.3295608162879944\n",
      "Epoch 390, Loss: 0.6958072185516357, Final Batch Loss: 0.32929444313049316\n",
      "Epoch 391, Loss: 0.7061509788036346, Final Batch Loss: 0.32320183515548706\n",
      "Epoch 392, Loss: 0.6731280982494354, Final Batch Loss: 0.31690531969070435\n",
      "Epoch 393, Loss: 0.6977520287036896, Final Batch Loss: 0.3508240282535553\n",
      "Epoch 394, Loss: 0.7308638393878937, Final Batch Loss: 0.40050891041755676\n",
      "Epoch 395, Loss: 0.6776743531227112, Final Batch Loss: 0.34835198521614075\n",
      "Epoch 396, Loss: 0.6494481563568115, Final Batch Loss: 0.3103172779083252\n",
      "Epoch 397, Loss: 0.6726797223091125, Final Batch Loss: 0.3054424524307251\n",
      "Epoch 398, Loss: 0.6509007513523102, Final Batch Loss: 0.2881084978580475\n",
      "Epoch 399, Loss: 0.6177370250225067, Final Batch Loss: 0.30209559202194214\n",
      "Epoch 400, Loss: 0.622970700263977, Final Batch Loss: 0.265989750623703\n",
      "Epoch 401, Loss: 0.6549266278743744, Final Batch Loss: 0.3143337666988373\n",
      "Epoch 402, Loss: 0.6169441044330597, Final Batch Loss: 0.3170735239982605\n",
      "Epoch 403, Loss: 0.6287321746349335, Final Batch Loss: 0.306277334690094\n",
      "Epoch 404, Loss: 0.6298680007457733, Final Batch Loss: 0.3041403889656067\n",
      "Epoch 405, Loss: 0.6614397764205933, Final Batch Loss: 0.3675512373447418\n",
      "Epoch 406, Loss: 0.634055882692337, Final Batch Loss: 0.3463723063468933\n",
      "Epoch 407, Loss: 0.6849346160888672, Final Batch Loss: 0.377861350774765\n",
      "Epoch 408, Loss: 0.6689100563526154, Final Batch Loss: 0.34117361903190613\n",
      "Epoch 409, Loss: 0.639072060585022, Final Batch Loss: 0.3235074281692505\n",
      "Epoch 410, Loss: 0.574106365442276, Final Batch Loss: 0.30200982093811035\n",
      "Epoch 411, Loss: 0.55614373087883, Final Batch Loss: 0.27982190251350403\n",
      "Epoch 412, Loss: 0.623407393693924, Final Batch Loss: 0.28293168544769287\n",
      "Epoch 413, Loss: 0.6470156311988831, Final Batch Loss: 0.3625141382217407\n",
      "Epoch 414, Loss: 0.5356512665748596, Final Batch Loss: 0.2738657295703888\n",
      "Epoch 415, Loss: 0.5819821059703827, Final Batch Loss: 0.29302650690078735\n",
      "Epoch 416, Loss: 0.6046260595321655, Final Batch Loss: 0.33879491686820984\n",
      "Epoch 417, Loss: 0.5808059275150299, Final Batch Loss: 0.2771751880645752\n",
      "Epoch 418, Loss: 0.6370913982391357, Final Batch Loss: 0.32664525508880615\n",
      "Epoch 419, Loss: 0.6560740172863007, Final Batch Loss: 0.3606259524822235\n",
      "Epoch 420, Loss: 0.6325346529483795, Final Batch Loss: 0.30206531286239624\n",
      "Epoch 421, Loss: 0.5792039334774017, Final Batch Loss: 0.2991555333137512\n",
      "Epoch 422, Loss: 0.5144740343093872, Final Batch Loss: 0.26451659202575684\n",
      "Epoch 423, Loss: 0.5629082173109055, Final Batch Loss: 0.23698554933071136\n",
      "Epoch 424, Loss: 0.5459073483943939, Final Batch Loss: 0.26710444688796997\n",
      "Epoch 425, Loss: 0.57958984375, Final Batch Loss: 0.262601375579834\n",
      "Epoch 426, Loss: 0.5657796859741211, Final Batch Loss: 0.31113430857658386\n",
      "Epoch 427, Loss: 0.6166675984859467, Final Batch Loss: 0.305542528629303\n",
      "Epoch 428, Loss: 0.58673956990242, Final Batch Loss: 0.28540658950805664\n",
      "Epoch 429, Loss: 0.5769280195236206, Final Batch Loss: 0.32505226135253906\n",
      "Epoch 430, Loss: 0.6005534827709198, Final Batch Loss: 0.3005029559135437\n",
      "Epoch 431, Loss: 0.5928049981594086, Final Batch Loss: 0.2957059144973755\n",
      "Epoch 432, Loss: 0.6220117211341858, Final Batch Loss: 0.29186245799064636\n",
      "Epoch 433, Loss: 0.5767201781272888, Final Batch Loss: 0.3196847438812256\n",
      "Epoch 434, Loss: 0.5665739476680756, Final Batch Loss: 0.2828536927700043\n",
      "Epoch 435, Loss: 0.5967234075069427, Final Batch Loss: 0.30460473895072937\n",
      "Epoch 436, Loss: 0.5185370296239853, Final Batch Loss: 0.23562677204608917\n",
      "Epoch 437, Loss: 0.5950705409049988, Final Batch Loss: 0.3097858130931854\n",
      "Epoch 438, Loss: 0.6277241408824921, Final Batch Loss: 0.30330586433410645\n",
      "Epoch 439, Loss: 0.5837556421756744, Final Batch Loss: 0.28156790137290955\n",
      "Epoch 440, Loss: 0.5715827643871307, Final Batch Loss: 0.30803409218788147\n",
      "Epoch 441, Loss: 0.5547296404838562, Final Batch Loss: 0.27024200558662415\n",
      "Epoch 442, Loss: 0.565008670091629, Final Batch Loss: 0.29017770290374756\n",
      "Epoch 443, Loss: 0.5157366693019867, Final Batch Loss: 0.24499234557151794\n",
      "Epoch 444, Loss: 0.5649130940437317, Final Batch Loss: 0.2941195070743561\n",
      "Epoch 445, Loss: 0.5077982544898987, Final Batch Loss: 0.24931421875953674\n",
      "Epoch 446, Loss: 0.49107740819454193, Final Batch Loss: 0.23169384896755219\n",
      "Epoch 447, Loss: 0.5138677507638931, Final Batch Loss: 0.2444223016500473\n",
      "Epoch 448, Loss: 0.521798849105835, Final Batch Loss: 0.26834630966186523\n",
      "Epoch 449, Loss: 0.5491805970668793, Final Batch Loss: 0.23332831263542175\n",
      "Epoch 450, Loss: 0.538769543170929, Final Batch Loss: 0.2596440315246582\n",
      "Epoch 451, Loss: 0.49954208731651306, Final Batch Loss: 0.2568076252937317\n",
      "Epoch 452, Loss: 0.5110285729169846, Final Batch Loss: 0.23525314033031464\n",
      "Epoch 453, Loss: 0.5174154341220856, Final Batch Loss: 0.24762094020843506\n",
      "Epoch 454, Loss: 0.5447229743003845, Final Batch Loss: 0.24254435300827026\n",
      "Epoch 455, Loss: 0.5149849504232407, Final Batch Loss: 0.23530204594135284\n",
      "Epoch 456, Loss: 0.5467609465122223, Final Batch Loss: 0.26816892623901367\n",
      "Epoch 457, Loss: 0.48738010227680206, Final Batch Loss: 0.19230394065380096\n",
      "Epoch 458, Loss: 0.5077635049819946, Final Batch Loss: 0.2663184106349945\n",
      "Epoch 459, Loss: 0.491492822766304, Final Batch Loss: 0.2571336627006531\n",
      "Epoch 460, Loss: 0.47104787826538086, Final Batch Loss: 0.2331259548664093\n",
      "Epoch 461, Loss: 0.5280752032995224, Final Batch Loss: 0.28373923897743225\n",
      "Epoch 462, Loss: 0.4770035743713379, Final Batch Loss: 0.21273842453956604\n",
      "Epoch 463, Loss: 0.4694061279296875, Final Batch Loss: 0.24525462090969086\n",
      "Epoch 464, Loss: 0.4801851511001587, Final Batch Loss: 0.18740352988243103\n",
      "Epoch 465, Loss: 0.4940723180770874, Final Batch Loss: 0.2812376916408539\n",
      "Epoch 466, Loss: 0.5345001518726349, Final Batch Loss: 0.26639431715011597\n",
      "Epoch 467, Loss: 0.5369108468294144, Final Batch Loss: 0.2422347515821457\n",
      "Epoch 468, Loss: 0.5622518658638, Final Batch Loss: 0.27702924609184265\n",
      "Epoch 469, Loss: 0.46952566504478455, Final Batch Loss: 0.21227559447288513\n",
      "Epoch 470, Loss: 0.49083831906318665, Final Batch Loss: 0.25196394324302673\n",
      "Epoch 471, Loss: 0.4929260015487671, Final Batch Loss: 0.2469935119152069\n",
      "Epoch 472, Loss: 0.4556415230035782, Final Batch Loss: 0.1759597510099411\n",
      "Epoch 473, Loss: 0.40539906919002533, Final Batch Loss: 0.19932401180267334\n",
      "Epoch 474, Loss: 0.42326170206069946, Final Batch Loss: 0.22478458285331726\n",
      "Epoch 475, Loss: 0.5363452732563019, Final Batch Loss: 0.29003530740737915\n",
      "Epoch 476, Loss: 0.40269768238067627, Final Batch Loss: 0.1828141212463379\n",
      "Epoch 477, Loss: 0.4336710721254349, Final Batch Loss: 0.23018014430999756\n",
      "Epoch 478, Loss: 0.39343856275081635, Final Batch Loss: 0.23306038975715637\n",
      "Epoch 479, Loss: 0.45333242416381836, Final Batch Loss: 0.21542364358901978\n",
      "Epoch 480, Loss: 0.4590628892183304, Final Batch Loss: 0.26242461800575256\n",
      "Epoch 481, Loss: 0.4341592639684677, Final Batch Loss: 0.24536243081092834\n",
      "Epoch 482, Loss: 0.4264714866876602, Final Batch Loss: 0.2034272849559784\n",
      "Epoch 483, Loss: 0.4347662627696991, Final Batch Loss: 0.19444698095321655\n",
      "Epoch 484, Loss: 0.3953458219766617, Final Batch Loss: 0.1722918301820755\n",
      "Epoch 485, Loss: 0.3874126523733139, Final Batch Loss: 0.16820690035820007\n",
      "Epoch 486, Loss: 0.48671428859233856, Final Batch Loss: 0.2659270763397217\n",
      "Epoch 487, Loss: 0.45105020701885223, Final Batch Loss: 0.19689296185970306\n",
      "Epoch 488, Loss: 0.4879939556121826, Final Batch Loss: 0.25350961089134216\n",
      "Epoch 489, Loss: 0.4493376612663269, Final Batch Loss: 0.2083703726530075\n",
      "Epoch 490, Loss: 0.4155868738889694, Final Batch Loss: 0.20522662997245789\n",
      "Epoch 491, Loss: 0.3948870599269867, Final Batch Loss: 0.1964954137802124\n",
      "Epoch 492, Loss: 0.43230099976062775, Final Batch Loss: 0.24825851619243622\n",
      "Epoch 493, Loss: 0.4522530734539032, Final Batch Loss: 0.2577875852584839\n",
      "Epoch 494, Loss: 0.4430816024541855, Final Batch Loss: 0.22471901774406433\n",
      "Epoch 495, Loss: 0.3883107602596283, Final Batch Loss: 0.18845708668231964\n",
      "Epoch 496, Loss: 0.4331236183643341, Final Batch Loss: 0.2464115172624588\n",
      "Epoch 497, Loss: 0.4034378379583359, Final Batch Loss: 0.22286266088485718\n",
      "Epoch 498, Loss: 0.46271736919879913, Final Batch Loss: 0.22380124032497406\n",
      "Epoch 499, Loss: 0.4212147295475006, Final Batch Loss: 0.1899721920490265\n",
      "Epoch 500, Loss: 0.4361724555492401, Final Batch Loss: 0.229646235704422\n",
      "Epoch 501, Loss: 0.464253306388855, Final Batch Loss: 0.22510801255702972\n",
      "Epoch 502, Loss: 0.4502556771039963, Final Batch Loss: 0.2328905314207077\n",
      "Epoch 503, Loss: 0.5229136049747467, Final Batch Loss: 0.23393401503562927\n",
      "Epoch 504, Loss: 0.45673583447933197, Final Batch Loss: 0.2600139379501343\n",
      "Epoch 505, Loss: 0.4348757863044739, Final Batch Loss: 0.2195006012916565\n",
      "Epoch 506, Loss: 0.43669643998146057, Final Batch Loss: 0.23651902377605438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 507, Loss: 0.4072529226541519, Final Batch Loss: 0.18107837438583374\n",
      "Epoch 508, Loss: 0.4781186878681183, Final Batch Loss: 0.23465536534786224\n",
      "Epoch 509, Loss: 0.43674229085445404, Final Batch Loss: 0.20279961824417114\n",
      "Epoch 510, Loss: 0.3932747542858124, Final Batch Loss: 0.19050383567810059\n",
      "Epoch 511, Loss: 0.4783874601125717, Final Batch Loss: 0.24778127670288086\n",
      "Epoch 512, Loss: 0.4631339907646179, Final Batch Loss: 0.26228615641593933\n",
      "Epoch 513, Loss: 0.3649882674217224, Final Batch Loss: 0.18860596418380737\n",
      "Epoch 514, Loss: 0.3968724459409714, Final Batch Loss: 0.15658840537071228\n",
      "Epoch 515, Loss: 0.4430171251296997, Final Batch Loss: 0.2415766417980194\n",
      "Epoch 516, Loss: 0.4349319487810135, Final Batch Loss: 0.2553214728832245\n",
      "Epoch 517, Loss: 0.41686050593852997, Final Batch Loss: 0.17808488011360168\n",
      "Epoch 518, Loss: 0.4855312407016754, Final Batch Loss: 0.3041589856147766\n",
      "Epoch 519, Loss: 0.4620882719755173, Final Batch Loss: 0.24694544076919556\n",
      "Epoch 520, Loss: 0.3928361088037491, Final Batch Loss: 0.16958139836788177\n",
      "Epoch 521, Loss: 0.4176495373249054, Final Batch Loss: 0.25172024965286255\n",
      "Epoch 522, Loss: 0.44460922479629517, Final Batch Loss: 0.1919851303100586\n",
      "Epoch 523, Loss: 0.4741014093160629, Final Batch Loss: 0.2225065678358078\n",
      "Epoch 524, Loss: 0.44109904766082764, Final Batch Loss: 0.2449846863746643\n",
      "Epoch 525, Loss: 0.3798578828573227, Final Batch Loss: 0.20320464670658112\n",
      "Epoch 526, Loss: 0.433241531252861, Final Batch Loss: 0.22037456929683685\n",
      "Epoch 527, Loss: 0.4787917286157608, Final Batch Loss: 0.2931128442287445\n",
      "Epoch 528, Loss: 0.40390661358833313, Final Batch Loss: 0.19189482927322388\n",
      "Epoch 529, Loss: 0.40662042796611786, Final Batch Loss: 0.20161038637161255\n",
      "Epoch 530, Loss: 0.3843732476234436, Final Batch Loss: 0.17735451459884644\n",
      "Epoch 531, Loss: 0.3875524699687958, Final Batch Loss: 0.17710533738136292\n",
      "Epoch 532, Loss: 0.45917999744415283, Final Batch Loss: 0.2751748263835907\n",
      "Epoch 533, Loss: 0.41024142503738403, Final Batch Loss: 0.21353542804718018\n",
      "Epoch 534, Loss: 0.420975461602211, Final Batch Loss: 0.1970207840204239\n",
      "Epoch 535, Loss: 0.3835863322019577, Final Batch Loss: 0.1725381463766098\n",
      "Epoch 536, Loss: 0.36380361020565033, Final Batch Loss: 0.1919815093278885\n",
      "Epoch 537, Loss: 0.37400688230991364, Final Batch Loss: 0.18528275191783905\n",
      "Epoch 538, Loss: 0.35987432301044464, Final Batch Loss: 0.16310806572437286\n",
      "Epoch 539, Loss: 0.4047454744577408, Final Batch Loss: 0.18464939296245575\n",
      "Epoch 540, Loss: 0.42931102216243744, Final Batch Loss: 0.2236500233411789\n",
      "Epoch 541, Loss: 0.40520329773426056, Final Batch Loss: 0.20098482072353363\n",
      "Epoch 542, Loss: 0.3474385589361191, Final Batch Loss: 0.15542633831501007\n",
      "Epoch 543, Loss: 0.31387458741664886, Final Batch Loss: 0.17255094647407532\n",
      "Epoch 544, Loss: 0.33581826090812683, Final Batch Loss: 0.15371932089328766\n",
      "Epoch 545, Loss: 0.36861081421375275, Final Batch Loss: 0.16204774379730225\n",
      "Epoch 546, Loss: 0.44920866191387177, Final Batch Loss: 0.24194061756134033\n",
      "Epoch 547, Loss: 0.3993285447359085, Final Batch Loss: 0.18439920246601105\n",
      "Epoch 548, Loss: 0.3699878007173538, Final Batch Loss: 0.21457301080226898\n",
      "Epoch 549, Loss: 0.3471526652574539, Final Batch Loss: 0.16498823463916779\n",
      "Epoch 550, Loss: 0.37313948571681976, Final Batch Loss: 0.1925770342350006\n",
      "Epoch 551, Loss: 0.4052444100379944, Final Batch Loss: 0.20657669007778168\n",
      "Epoch 552, Loss: 0.3681698441505432, Final Batch Loss: 0.18268626928329468\n",
      "Epoch 553, Loss: 0.3837549090385437, Final Batch Loss: 0.2128773033618927\n",
      "Epoch 554, Loss: 0.3787998855113983, Final Batch Loss: 0.18965031206607819\n",
      "Epoch 555, Loss: 0.379237562417984, Final Batch Loss: 0.16937501728534698\n",
      "Epoch 556, Loss: 0.33558332920074463, Final Batch Loss: 0.1711980700492859\n",
      "Epoch 557, Loss: 0.34709377586841583, Final Batch Loss: 0.18187326192855835\n",
      "Epoch 558, Loss: 0.41430196166038513, Final Batch Loss: 0.15188264846801758\n",
      "Epoch 559, Loss: 0.3831716477870941, Final Batch Loss: 0.2034910023212433\n",
      "Epoch 560, Loss: 0.3434237092733383, Final Batch Loss: 0.131877139210701\n",
      "Epoch 561, Loss: 0.3868090361356735, Final Batch Loss: 0.1540866196155548\n",
      "Epoch 562, Loss: 0.3676062524318695, Final Batch Loss: 0.1730552762746811\n",
      "Epoch 563, Loss: 0.36970436573028564, Final Batch Loss: 0.22223970293998718\n",
      "Epoch 564, Loss: 0.32807688415050507, Final Batch Loss: 0.1847870647907257\n",
      "Epoch 565, Loss: 0.5037302523851395, Final Batch Loss: 0.32592907547950745\n",
      "Epoch 566, Loss: 0.3994319885969162, Final Batch Loss: 0.16158427298069\n",
      "Epoch 567, Loss: 0.42819659411907196, Final Batch Loss: 0.2550676465034485\n",
      "Epoch 568, Loss: 0.37494541704654694, Final Batch Loss: 0.18220721185207367\n",
      "Epoch 569, Loss: 0.3912762701511383, Final Batch Loss: 0.19555287063121796\n",
      "Epoch 570, Loss: 0.33849118649959564, Final Batch Loss: 0.20322595536708832\n",
      "Epoch 571, Loss: 0.3953675329685211, Final Batch Loss: 0.2446596622467041\n",
      "Epoch 572, Loss: 0.3306437134742737, Final Batch Loss: 0.16669361293315887\n",
      "Epoch 573, Loss: 0.33336400985717773, Final Batch Loss: 0.1573779135942459\n",
      "Epoch 574, Loss: 0.39740994572639465, Final Batch Loss: 0.182265505194664\n",
      "Epoch 575, Loss: 0.3416592478752136, Final Batch Loss: 0.171951025724411\n",
      "Epoch 576, Loss: 0.454881951212883, Final Batch Loss: 0.26077643036842346\n",
      "Epoch 577, Loss: 0.312746062874794, Final Batch Loss: 0.12806053459644318\n",
      "Epoch 578, Loss: 0.3498513847589493, Final Batch Loss: 0.20014692842960358\n",
      "Epoch 579, Loss: 0.29380175471305847, Final Batch Loss: 0.16081038117408752\n",
      "Epoch 580, Loss: 0.4479692131280899, Final Batch Loss: 0.23831842839717865\n",
      "Epoch 581, Loss: 0.3396318554878235, Final Batch Loss: 0.17775732278823853\n",
      "Epoch 582, Loss: 0.35551466047763824, Final Batch Loss: 0.19207064807415009\n",
      "Epoch 583, Loss: 0.312560498714447, Final Batch Loss: 0.13666144013404846\n",
      "Epoch 584, Loss: 0.3469006270170212, Final Batch Loss: 0.1809128224849701\n",
      "Epoch 585, Loss: 0.3269857317209244, Final Batch Loss: 0.1361766755580902\n",
      "Epoch 586, Loss: 0.3669281303882599, Final Batch Loss: 0.1776137799024582\n",
      "Epoch 587, Loss: 0.3084089607000351, Final Batch Loss: 0.15600159764289856\n",
      "Epoch 588, Loss: 0.3070533871650696, Final Batch Loss: 0.13655704259872437\n",
      "Epoch 589, Loss: 0.33791981637477875, Final Batch Loss: 0.19349099695682526\n",
      "Epoch 590, Loss: 0.35825781524181366, Final Batch Loss: 0.20428991317749023\n",
      "Epoch 591, Loss: 0.3457079827785492, Final Batch Loss: 0.17754876613616943\n",
      "Epoch 592, Loss: 0.33460934460163116, Final Batch Loss: 0.16944515705108643\n",
      "Epoch 593, Loss: 0.3402072489261627, Final Batch Loss: 0.14711645245552063\n",
      "Epoch 594, Loss: 0.33697813749313354, Final Batch Loss: 0.14977897703647614\n",
      "Epoch 595, Loss: 0.3960185796022415, Final Batch Loss: 0.17071960866451263\n",
      "Epoch 596, Loss: 0.3129126578569412, Final Batch Loss: 0.15853570401668549\n",
      "Epoch 597, Loss: 0.3163507729768753, Final Batch Loss: 0.16361474990844727\n",
      "Epoch 598, Loss: 0.2907816618680954, Final Batch Loss: 0.1395062357187271\n",
      "Epoch 599, Loss: 0.3528796285390854, Final Batch Loss: 0.18133199214935303\n",
      "Epoch 600, Loss: 0.3503306359052658, Final Batch Loss: 0.21413007378578186\n",
      "Epoch 601, Loss: 0.3469371795654297, Final Batch Loss: 0.1927267163991928\n",
      "Epoch 602, Loss: 0.35743682086467743, Final Batch Loss: 0.22235453128814697\n",
      "Epoch 603, Loss: 0.379143089056015, Final Batch Loss: 0.2124263346195221\n",
      "Epoch 604, Loss: 0.2843761667609215, Final Batch Loss: 0.09983407706022263\n",
      "Epoch 605, Loss: 0.34724707901477814, Final Batch Loss: 0.2016170471906662\n",
      "Epoch 606, Loss: 0.2943202257156372, Final Batch Loss: 0.13785791397094727\n",
      "Epoch 607, Loss: 0.363930806517601, Final Batch Loss: 0.19010420143604279\n",
      "Epoch 608, Loss: 0.30648644268512726, Final Batch Loss: 0.15901389718055725\n",
      "Epoch 609, Loss: 0.3360713720321655, Final Batch Loss: 0.13873277604579926\n",
      "Epoch 610, Loss: 0.33957797288894653, Final Batch Loss: 0.16616939008235931\n",
      "Epoch 611, Loss: 0.3329247087240219, Final Batch Loss: 0.18461373448371887\n",
      "Epoch 612, Loss: 0.32991214096546173, Final Batch Loss: 0.15696290135383606\n",
      "Epoch 613, Loss: 0.3355565816164017, Final Batch Loss: 0.18511752784252167\n",
      "Epoch 614, Loss: 0.35548684000968933, Final Batch Loss: 0.12706580758094788\n",
      "Epoch 615, Loss: 0.3404625654220581, Final Batch Loss: 0.1489092856645584\n",
      "Epoch 616, Loss: 0.2816901132464409, Final Batch Loss: 0.10285257548093796\n",
      "Epoch 617, Loss: 0.3065115362405777, Final Batch Loss: 0.16931839287281036\n",
      "Epoch 618, Loss: 0.3511735051870346, Final Batch Loss: 0.18928636610507965\n",
      "Epoch 619, Loss: 0.3337671458721161, Final Batch Loss: 0.14322876930236816\n",
      "Epoch 620, Loss: 0.3073250949382782, Final Batch Loss: 0.13983330130577087\n",
      "Epoch 621, Loss: 0.30404387414455414, Final Batch Loss: 0.16767138242721558\n",
      "Epoch 622, Loss: 0.3060764968395233, Final Batch Loss: 0.14204028248786926\n",
      "Epoch 623, Loss: 0.3361782431602478, Final Batch Loss: 0.1603573113679886\n",
      "Epoch 624, Loss: 0.3461509793996811, Final Batch Loss: 0.21317292749881744\n",
      "Epoch 625, Loss: 0.25135939568281174, Final Batch Loss: 0.11255352944135666\n",
      "Epoch 626, Loss: 0.3036518841981888, Final Batch Loss: 0.19818159937858582\n",
      "Epoch 627, Loss: 0.3552471101284027, Final Batch Loss: 0.157925084233284\n",
      "Epoch 628, Loss: 0.26826051622629166, Final Batch Loss: 0.11839107424020767\n",
      "Epoch 629, Loss: 0.3443712592124939, Final Batch Loss: 0.17511515319347382\n",
      "Epoch 630, Loss: 0.41549187898635864, Final Batch Loss: 0.17875206470489502\n",
      "Epoch 631, Loss: 0.34253187477588654, Final Batch Loss: 0.1996820569038391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 632, Loss: 0.28010307252407074, Final Batch Loss: 0.15398746728897095\n",
      "Epoch 633, Loss: 0.35069115459918976, Final Batch Loss: 0.21698637306690216\n",
      "Epoch 634, Loss: 0.3301635980606079, Final Batch Loss: 0.1688465178012848\n",
      "Epoch 635, Loss: 0.3099231570959091, Final Batch Loss: 0.16813825070858002\n",
      "Epoch 636, Loss: 0.31410419940948486, Final Batch Loss: 0.1763649731874466\n",
      "Epoch 637, Loss: 0.28236058354377747, Final Batch Loss: 0.14329488575458527\n",
      "Epoch 638, Loss: 0.3439873158931732, Final Batch Loss: 0.20748496055603027\n",
      "Epoch 639, Loss: 0.3043883666396141, Final Batch Loss: 0.11149070411920547\n",
      "Epoch 640, Loss: 0.3058139905333519, Final Batch Loss: 0.12207437306642532\n",
      "Epoch 641, Loss: 0.28082530945539474, Final Batch Loss: 0.11049879342317581\n",
      "Epoch 642, Loss: 0.3437618464231491, Final Batch Loss: 0.18646617233753204\n",
      "Epoch 643, Loss: 0.2920110151171684, Final Batch Loss: 0.09069300442934036\n",
      "Epoch 644, Loss: 0.2993089258670807, Final Batch Loss: 0.17302639782428741\n",
      "Epoch 645, Loss: 0.34412503242492676, Final Batch Loss: 0.17613402009010315\n",
      "Epoch 646, Loss: 0.32565782964229584, Final Batch Loss: 0.1931818425655365\n",
      "Epoch 647, Loss: 0.3150569200515747, Final Batch Loss: 0.18542367219924927\n",
      "Epoch 648, Loss: 0.3286634087562561, Final Batch Loss: 0.1430957168340683\n",
      "Epoch 649, Loss: 0.3412065804004669, Final Batch Loss: 0.17861859500408173\n",
      "Epoch 650, Loss: 0.27077125012874603, Final Batch Loss: 0.13969463109970093\n",
      "Epoch 651, Loss: 0.31268058717250824, Final Batch Loss: 0.14134815335273743\n",
      "Epoch 652, Loss: 0.33887577056884766, Final Batch Loss: 0.19509370625019073\n",
      "Epoch 653, Loss: 0.30773164331912994, Final Batch Loss: 0.15945370495319366\n",
      "Epoch 654, Loss: 0.49553920328617096, Final Batch Loss: 0.24693089723587036\n",
      "Epoch 655, Loss: 0.30466243624687195, Final Batch Loss: 0.12150850892066956\n",
      "Epoch 656, Loss: 0.3480701148509979, Final Batch Loss: 0.1655295491218567\n",
      "Epoch 657, Loss: 0.35643404722213745, Final Batch Loss: 0.17002953588962555\n",
      "Epoch 658, Loss: 0.2633950859308243, Final Batch Loss: 0.12433427572250366\n",
      "Epoch 659, Loss: 0.27062389999628067, Final Batch Loss: 0.14816558361053467\n",
      "Epoch 660, Loss: 0.2691534385085106, Final Batch Loss: 0.12045017629861832\n",
      "Epoch 661, Loss: 0.3389071524143219, Final Batch Loss: 0.18045420944690704\n",
      "Epoch 662, Loss: 0.36846359074115753, Final Batch Loss: 0.2064719796180725\n",
      "Epoch 663, Loss: 0.3046426326036453, Final Batch Loss: 0.08997364342212677\n",
      "Epoch 664, Loss: 0.28290964663028717, Final Batch Loss: 0.14605039358139038\n",
      "Epoch 665, Loss: 0.3018222749233246, Final Batch Loss: 0.16068075597286224\n",
      "Epoch 666, Loss: 0.39391785860061646, Final Batch Loss: 0.24390588700771332\n",
      "Epoch 667, Loss: 0.3107346147298813, Final Batch Loss: 0.14909593760967255\n",
      "Epoch 668, Loss: 0.31826502084732056, Final Batch Loss: 0.1243840754032135\n",
      "Epoch 669, Loss: 0.3598953187465668, Final Batch Loss: 0.18022169172763824\n",
      "Epoch 670, Loss: 0.3187366724014282, Final Batch Loss: 0.11552125215530396\n",
      "Epoch 671, Loss: 0.3478882610797882, Final Batch Loss: 0.18790078163146973\n",
      "Epoch 672, Loss: 0.28583113849163055, Final Batch Loss: 0.11465704441070557\n",
      "Epoch 673, Loss: 0.3270646631717682, Final Batch Loss: 0.15949375927448273\n",
      "Epoch 674, Loss: 0.26993632316589355, Final Batch Loss: 0.1271725744009018\n",
      "Epoch 675, Loss: 0.2942242920398712, Final Batch Loss: 0.14335496723651886\n",
      "Epoch 676, Loss: 0.31179583072662354, Final Batch Loss: 0.1288263201713562\n",
      "Epoch 677, Loss: 0.3410635143518448, Final Batch Loss: 0.18895238637924194\n",
      "Epoch 678, Loss: 0.25610965490341187, Final Batch Loss: 0.13563752174377441\n",
      "Epoch 679, Loss: 0.2625211328268051, Final Batch Loss: 0.13305653631687164\n",
      "Epoch 680, Loss: 0.33878716826438904, Final Batch Loss: 0.16187070310115814\n",
      "Epoch 681, Loss: 0.33267246186733246, Final Batch Loss: 0.11463743448257446\n",
      "Epoch 682, Loss: 0.3497970998287201, Final Batch Loss: 0.2205219566822052\n",
      "Epoch 683, Loss: 0.26857805252075195, Final Batch Loss: 0.1544785499572754\n",
      "Epoch 684, Loss: 0.29505033791065216, Final Batch Loss: 0.13539570569992065\n",
      "Epoch 685, Loss: 0.2566888853907585, Final Batch Loss: 0.12062793225049973\n",
      "Epoch 686, Loss: 0.34248726069927216, Final Batch Loss: 0.19661034643650055\n",
      "Epoch 687, Loss: 0.29575298726558685, Final Batch Loss: 0.1494230180978775\n",
      "Epoch 688, Loss: 0.3050422817468643, Final Batch Loss: 0.16081927716732025\n",
      "Epoch 689, Loss: 0.2976820319890976, Final Batch Loss: 0.15512122213840485\n",
      "Epoch 690, Loss: 0.25342125445604324, Final Batch Loss: 0.15943600237369537\n",
      "Epoch 691, Loss: 0.3161109983921051, Final Batch Loss: 0.17987164855003357\n",
      "Epoch 692, Loss: 0.2570262849330902, Final Batch Loss: 0.12864941358566284\n",
      "Epoch 693, Loss: 0.27235017716884613, Final Batch Loss: 0.1616625338792801\n",
      "Epoch 694, Loss: 0.2925223186612129, Final Batch Loss: 0.12333571165800095\n",
      "Epoch 695, Loss: 0.329597532749176, Final Batch Loss: 0.17739737033843994\n",
      "Epoch 696, Loss: 0.26618553698062897, Final Batch Loss: 0.1365119218826294\n",
      "Epoch 697, Loss: 0.2873077988624573, Final Batch Loss: 0.13990013301372528\n",
      "Epoch 698, Loss: 0.29985056072473526, Final Batch Loss: 0.12415174394845963\n",
      "Epoch 699, Loss: 0.2810560017824173, Final Batch Loss: 0.12499023973941803\n",
      "Epoch 700, Loss: 0.2832031697034836, Final Batch Loss: 0.13104556500911713\n",
      "Epoch 701, Loss: 0.27254102379083633, Final Batch Loss: 0.10214609652757645\n",
      "Epoch 702, Loss: 0.2487793043255806, Final Batch Loss: 0.11881779879331589\n",
      "Epoch 703, Loss: 0.33852510154247284, Final Batch Loss: 0.14948393404483795\n",
      "Epoch 704, Loss: 0.3375159576535225, Final Batch Loss: 0.2165675014257431\n",
      "Epoch 705, Loss: 0.2972070127725601, Final Batch Loss: 0.16792616248130798\n",
      "Epoch 706, Loss: 0.23467838019132614, Final Batch Loss: 0.1194600984454155\n",
      "Epoch 707, Loss: 0.3836634010076523, Final Batch Loss: 0.23510479927062988\n",
      "Epoch 708, Loss: 0.32444077730178833, Final Batch Loss: 0.1499386429786682\n",
      "Epoch 709, Loss: 0.25222048163414, Final Batch Loss: 0.08933967351913452\n",
      "Epoch 710, Loss: 0.24774298071861267, Final Batch Loss: 0.11390195786952972\n",
      "Epoch 711, Loss: 0.2212011069059372, Final Batch Loss: 0.1174834743142128\n",
      "Epoch 712, Loss: 0.2365804985165596, Final Batch Loss: 0.12116817384958267\n",
      "Epoch 713, Loss: 0.24795867502689362, Final Batch Loss: 0.14630471169948578\n",
      "Epoch 714, Loss: 0.2930419147014618, Final Batch Loss: 0.1644746959209442\n",
      "Epoch 715, Loss: 0.2966131269931793, Final Batch Loss: 0.17796075344085693\n",
      "Epoch 716, Loss: 0.27387505769729614, Final Batch Loss: 0.12579040229320526\n",
      "Epoch 717, Loss: 0.26216280460357666, Final Batch Loss: 0.157574862241745\n",
      "Epoch 718, Loss: 0.2690403014421463, Final Batch Loss: 0.08554664254188538\n",
      "Epoch 719, Loss: 0.3284291699528694, Final Batch Loss: 0.2312150001525879\n",
      "Epoch 720, Loss: 0.27394793182611465, Final Batch Loss: 0.10497754067182541\n",
      "Epoch 721, Loss: 0.2735349088907242, Final Batch Loss: 0.14012937247753143\n",
      "Epoch 722, Loss: 0.24302059412002563, Final Batch Loss: 0.11448854207992554\n",
      "Epoch 723, Loss: 0.26246143877506256, Final Batch Loss: 0.10825774073600769\n",
      "Epoch 724, Loss: 0.29242976754903793, Final Batch Loss: 0.16899701952934265\n",
      "Epoch 725, Loss: 0.2600865215063095, Final Batch Loss: 0.1392814666032791\n",
      "Epoch 726, Loss: 0.23732656240463257, Final Batch Loss: 0.10370007157325745\n",
      "Epoch 727, Loss: 0.27237004041671753, Final Batch Loss: 0.13418623805046082\n",
      "Epoch 728, Loss: 0.23368088155984879, Final Batch Loss: 0.1142953410744667\n",
      "Epoch 729, Loss: 0.3462911546230316, Final Batch Loss: 0.228219673037529\n",
      "Epoch 730, Loss: 0.28747762739658356, Final Batch Loss: 0.15365681052207947\n",
      "Epoch 731, Loss: 0.3519735783338547, Final Batch Loss: 0.15756775438785553\n",
      "Epoch 732, Loss: 0.27003152668476105, Final Batch Loss: 0.12625724077224731\n",
      "Epoch 733, Loss: 0.3155535161495209, Final Batch Loss: 0.15696550905704498\n",
      "Epoch 734, Loss: 0.3134309649467468, Final Batch Loss: 0.16973818838596344\n",
      "Epoch 735, Loss: 0.3342355191707611, Final Batch Loss: 0.19046291708946228\n",
      "Epoch 736, Loss: 0.29400086402893066, Final Batch Loss: 0.12959332764148712\n",
      "Epoch 737, Loss: 0.24105454236268997, Final Batch Loss: 0.12044861167669296\n",
      "Epoch 738, Loss: 0.27926055341959, Final Batch Loss: 0.1651691496372223\n",
      "Epoch 739, Loss: 0.2585986405611038, Final Batch Loss: 0.11519007384777069\n",
      "Epoch 740, Loss: 0.27584807574748993, Final Batch Loss: 0.12654583156108856\n",
      "Epoch 741, Loss: 0.3291669487953186, Final Batch Loss: 0.19700273871421814\n",
      "Epoch 742, Loss: 0.2641836479306221, Final Batch Loss: 0.14377163350582123\n",
      "Epoch 743, Loss: 0.32889702171087265, Final Batch Loss: 0.12371569126844406\n",
      "Epoch 744, Loss: 0.3173547238111496, Final Batch Loss: 0.16575011610984802\n",
      "Epoch 745, Loss: 0.30777888000011444, Final Batch Loss: 0.12097381055355072\n",
      "Epoch 746, Loss: 0.2844991236925125, Final Batch Loss: 0.15019680559635162\n",
      "Epoch 747, Loss: 0.28884946554899216, Final Batch Loss: 0.11940432339906693\n",
      "Epoch 748, Loss: 0.27237799763679504, Final Batch Loss: 0.15370257198810577\n",
      "Epoch 749, Loss: 0.2511107847094536, Final Batch Loss: 0.11109975725412369\n",
      "Epoch 750, Loss: 0.33905835449695587, Final Batch Loss: 0.12525007128715515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 751, Loss: 0.2862985208630562, Final Batch Loss: 0.1768050491809845\n",
      "Epoch 752, Loss: 0.26273974031209946, Final Batch Loss: 0.15236082673072815\n",
      "Epoch 753, Loss: 0.26679256558418274, Final Batch Loss: 0.12865613400936127\n",
      "Epoch 754, Loss: 0.24309934675693512, Final Batch Loss: 0.12030467391014099\n",
      "Epoch 755, Loss: 0.28337059915065765, Final Batch Loss: 0.13195432722568512\n",
      "Epoch 756, Loss: 0.3048374354839325, Final Batch Loss: 0.16143637895584106\n",
      "Epoch 757, Loss: 0.2380773276090622, Final Batch Loss: 0.09052547812461853\n",
      "Epoch 758, Loss: 0.2601067125797272, Final Batch Loss: 0.15163369476795197\n",
      "Epoch 759, Loss: 0.2819281816482544, Final Batch Loss: 0.10470876097679138\n",
      "Epoch 760, Loss: 0.20857525616884232, Final Batch Loss: 0.08929017186164856\n",
      "Epoch 761, Loss: 0.2380218580365181, Final Batch Loss: 0.13767236471176147\n",
      "Epoch 762, Loss: 0.25925005972385406, Final Batch Loss: 0.1272474080324173\n",
      "Epoch 763, Loss: 0.25142277777194977, Final Batch Loss: 0.12953904271125793\n",
      "Epoch 764, Loss: 0.2623582184314728, Final Batch Loss: 0.13188783824443817\n",
      "Epoch 765, Loss: 0.25014840066432953, Final Batch Loss: 0.12167473137378693\n",
      "Epoch 766, Loss: 0.2688802480697632, Final Batch Loss: 0.13193124532699585\n",
      "Epoch 767, Loss: 0.27876636385917664, Final Batch Loss: 0.14006368815898895\n",
      "Epoch 768, Loss: 0.22180499136447906, Final Batch Loss: 0.14425742626190186\n",
      "Epoch 769, Loss: 0.27377136796712875, Final Batch Loss: 0.11136966198682785\n",
      "Epoch 770, Loss: 0.23477471619844437, Final Batch Loss: 0.10364293307065964\n",
      "Epoch 771, Loss: 0.264653779566288, Final Batch Loss: 0.1675569713115692\n",
      "Epoch 772, Loss: 0.2780240401625633, Final Batch Loss: 0.11091812700033188\n",
      "Epoch 773, Loss: 0.35063400864601135, Final Batch Loss: 0.208357572555542\n",
      "Epoch 774, Loss: 0.22283675521612167, Final Batch Loss: 0.13285309076309204\n",
      "Epoch 775, Loss: 0.23955311626195908, Final Batch Loss: 0.11806843429803848\n",
      "Epoch 776, Loss: 0.29745157063007355, Final Batch Loss: 0.1712319701910019\n",
      "Epoch 777, Loss: 0.21691231429576874, Final Batch Loss: 0.10544077306985855\n",
      "Epoch 778, Loss: 0.2840343117713928, Final Batch Loss: 0.14669376611709595\n",
      "Epoch 779, Loss: 0.19771166890859604, Final Batch Loss: 0.09880068153142929\n",
      "Epoch 780, Loss: 0.27579234540462494, Final Batch Loss: 0.13359087705612183\n",
      "Epoch 781, Loss: 0.2639259919524193, Final Batch Loss: 0.08997643738985062\n",
      "Epoch 782, Loss: 0.22712188959121704, Final Batch Loss: 0.11366662383079529\n",
      "Epoch 783, Loss: 0.2547749951481819, Final Batch Loss: 0.12149608880281448\n",
      "Epoch 784, Loss: 0.21880842745304108, Final Batch Loss: 0.09341390430927277\n",
      "Epoch 785, Loss: 0.2546050474047661, Final Batch Loss: 0.15923592448234558\n",
      "Epoch 786, Loss: 0.23851339519023895, Final Batch Loss: 0.14373856782913208\n",
      "Epoch 787, Loss: 0.2533045560121536, Final Batch Loss: 0.12229101359844208\n",
      "Epoch 788, Loss: 0.21243935078382492, Final Batch Loss: 0.10293234884738922\n",
      "Epoch 789, Loss: 0.26460400223731995, Final Batch Loss: 0.1548643410205841\n",
      "Epoch 790, Loss: 0.2906661778688431, Final Batch Loss: 0.20066623389720917\n",
      "Epoch 791, Loss: 0.24531525373458862, Final Batch Loss: 0.10402286052703857\n",
      "Epoch 792, Loss: 0.28812216222286224, Final Batch Loss: 0.1393185704946518\n",
      "Epoch 793, Loss: 0.3033799082040787, Final Batch Loss: 0.16774466633796692\n",
      "Epoch 794, Loss: 0.23649495840072632, Final Batch Loss: 0.07615445554256439\n",
      "Epoch 795, Loss: 0.2258862853050232, Final Batch Loss: 0.09571664035320282\n",
      "Epoch 796, Loss: 0.26970405131578445, Final Batch Loss: 0.16539746522903442\n",
      "Epoch 797, Loss: 0.21579328179359436, Final Batch Loss: 0.08787889778614044\n",
      "Epoch 798, Loss: 0.27549880743026733, Final Batch Loss: 0.17540284991264343\n",
      "Epoch 799, Loss: 0.2406632900238037, Final Batch Loss: 0.12615317106246948\n",
      "Epoch 800, Loss: 0.3277069181203842, Final Batch Loss: 0.15383487939834595\n",
      "Epoch 801, Loss: 0.25554209202528, Final Batch Loss: 0.1611345261335373\n",
      "Epoch 802, Loss: 0.2347658947110176, Final Batch Loss: 0.116073839366436\n",
      "Epoch 803, Loss: 0.29682087153196335, Final Batch Loss: 0.17881843447685242\n",
      "Epoch 804, Loss: 0.29185380041599274, Final Batch Loss: 0.14888061583042145\n",
      "Epoch 805, Loss: 0.18995850533246994, Final Batch Loss: 0.10058874636888504\n",
      "Epoch 806, Loss: 0.262225404381752, Final Batch Loss: 0.10390569269657135\n",
      "Epoch 807, Loss: 0.2163168266415596, Final Batch Loss: 0.10047302395105362\n",
      "Epoch 808, Loss: 0.30422332882881165, Final Batch Loss: 0.1523846983909607\n",
      "Epoch 809, Loss: 0.27180322259664536, Final Batch Loss: 0.16332881152629852\n",
      "Epoch 810, Loss: 0.27199628949165344, Final Batch Loss: 0.1271142065525055\n",
      "Epoch 811, Loss: 0.2491665631532669, Final Batch Loss: 0.10788097977638245\n",
      "Epoch 812, Loss: 0.3073536157608032, Final Batch Loss: 0.13888300955295563\n",
      "Epoch 813, Loss: 0.2526518478989601, Final Batch Loss: 0.13538658618927002\n",
      "Epoch 814, Loss: 0.33183014392852783, Final Batch Loss: 0.14812010526657104\n",
      "Epoch 815, Loss: 0.2040875107049942, Final Batch Loss: 0.08803585916757584\n",
      "Epoch 816, Loss: 0.2703384459018707, Final Batch Loss: 0.13473448157310486\n",
      "Epoch 817, Loss: 0.26282787322998047, Final Batch Loss: 0.11023825407028198\n",
      "Epoch 818, Loss: 0.2498084455728531, Final Batch Loss: 0.12023647129535675\n",
      "Epoch 819, Loss: 0.299730122089386, Final Batch Loss: 0.14206528663635254\n",
      "Epoch 820, Loss: 0.2570500001311302, Final Batch Loss: 0.14134737849235535\n",
      "Epoch 821, Loss: 0.23983529210090637, Final Batch Loss: 0.12641708552837372\n",
      "Epoch 822, Loss: 0.25515297800302505, Final Batch Loss: 0.1030871793627739\n",
      "Epoch 823, Loss: 0.24439475685358047, Final Batch Loss: 0.11256792396306992\n",
      "Epoch 824, Loss: 0.25854791700839996, Final Batch Loss: 0.11239089071750641\n",
      "Epoch 825, Loss: 0.2773297131061554, Final Batch Loss: 0.1644221693277359\n",
      "Epoch 826, Loss: 0.2862812578678131, Final Batch Loss: 0.11929821968078613\n",
      "Epoch 827, Loss: 0.20790033787488937, Final Batch Loss: 0.07980606704950333\n",
      "Epoch 828, Loss: 0.2427467629313469, Final Batch Loss: 0.13251537084579468\n",
      "Epoch 829, Loss: 0.2693679928779602, Final Batch Loss: 0.1360943466424942\n",
      "Epoch 830, Loss: 0.259073905646801, Final Batch Loss: 0.10569452494382858\n",
      "Epoch 831, Loss: 0.2838069945573807, Final Batch Loss: 0.1690085232257843\n",
      "Epoch 832, Loss: 0.23455965518951416, Final Batch Loss: 0.10513006150722504\n",
      "Epoch 833, Loss: 0.23440804332494736, Final Batch Loss: 0.11142028123140335\n",
      "Epoch 834, Loss: 0.19714896380901337, Final Batch Loss: 0.10023432970046997\n",
      "Epoch 835, Loss: 0.25047504901885986, Final Batch Loss: 0.12166717648506165\n",
      "Epoch 836, Loss: 0.22984515875577927, Final Batch Loss: 0.1323404461145401\n",
      "Epoch 837, Loss: 0.23199671506881714, Final Batch Loss: 0.13646230101585388\n",
      "Epoch 838, Loss: 0.2332315891981125, Final Batch Loss: 0.11166322231292725\n",
      "Epoch 839, Loss: 0.20925629138946533, Final Batch Loss: 0.0882866159081459\n",
      "Epoch 840, Loss: 0.24983512610197067, Final Batch Loss: 0.11339849978685379\n",
      "Epoch 841, Loss: 0.22690904885530472, Final Batch Loss: 0.07946493476629257\n",
      "Epoch 842, Loss: 0.23437686264514923, Final Batch Loss: 0.13614758849143982\n",
      "Epoch 843, Loss: 0.25933391600847244, Final Batch Loss: 0.16326072812080383\n",
      "Epoch 844, Loss: 0.22028522193431854, Final Batch Loss: 0.13171197474002838\n",
      "Epoch 845, Loss: 0.26572301983833313, Final Batch Loss: 0.11801791191101074\n",
      "Epoch 846, Loss: 0.29260674118995667, Final Batch Loss: 0.08565486967563629\n",
      "Epoch 847, Loss: 0.24282873421907425, Final Batch Loss: 0.11750537902116776\n",
      "Epoch 848, Loss: 0.254407599568367, Final Batch Loss: 0.11837314069271088\n",
      "Epoch 849, Loss: 0.18106984347105026, Final Batch Loss: 0.07710769027471542\n",
      "Epoch 850, Loss: 0.2328992784023285, Final Batch Loss: 0.11084538698196411\n",
      "Epoch 851, Loss: 0.24465444684028625, Final Batch Loss: 0.142655149102211\n",
      "Epoch 852, Loss: 0.22512827068567276, Final Batch Loss: 0.12174922972917557\n",
      "Epoch 853, Loss: 0.17236001417040825, Final Batch Loss: 0.06198619678616524\n",
      "Epoch 854, Loss: 0.17928723990917206, Final Batch Loss: 0.091294065117836\n",
      "Epoch 855, Loss: 0.21382619440555573, Final Batch Loss: 0.1033385768532753\n",
      "Epoch 856, Loss: 0.2507430166006088, Final Batch Loss: 0.12771831452846527\n",
      "Epoch 857, Loss: 0.22768865525722504, Final Batch Loss: 0.1050712838768959\n",
      "Epoch 858, Loss: 0.2663307189941406, Final Batch Loss: 0.1369423270225525\n",
      "Epoch 859, Loss: 0.23790094256401062, Final Batch Loss: 0.11242718994617462\n",
      "Epoch 860, Loss: 0.21285369247198105, Final Batch Loss: 0.1032017320394516\n",
      "Epoch 861, Loss: 0.2415977343916893, Final Batch Loss: 0.14934925734996796\n",
      "Epoch 862, Loss: 0.29708702117204666, Final Batch Loss: 0.12253419309854507\n",
      "Epoch 863, Loss: 0.20144132524728775, Final Batch Loss: 0.08095847070217133\n",
      "Epoch 864, Loss: 0.2535182163119316, Final Batch Loss: 0.10743433982133865\n",
      "Epoch 865, Loss: 0.214106947183609, Final Batch Loss: 0.09079305827617645\n",
      "Epoch 866, Loss: 0.26722402125597, Final Batch Loss: 0.1477888971567154\n",
      "Epoch 867, Loss: 0.2078772559762001, Final Batch Loss: 0.10941735655069351\n",
      "Epoch 868, Loss: 0.23808540403842926, Final Batch Loss: 0.09967166185379028\n",
      "Epoch 869, Loss: 0.2101457640528679, Final Batch Loss: 0.09932016581296921\n",
      "Epoch 870, Loss: 0.21989842504262924, Final Batch Loss: 0.08912798017263412\n",
      "Epoch 871, Loss: 0.18964899331331253, Final Batch Loss: 0.09209271520376205\n",
      "Epoch 872, Loss: 0.2077731005847454, Final Batch Loss: 0.06201298162341118\n",
      "Epoch 873, Loss: 0.27189091593027115, Final Batch Loss: 0.10071033984422684\n",
      "Epoch 874, Loss: 0.2419450581073761, Final Batch Loss: 0.08920390903949738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 875, Loss: 0.21870556473731995, Final Batch Loss: 0.13863568007946014\n",
      "Epoch 876, Loss: 0.23584800958633423, Final Batch Loss: 0.13810892403125763\n",
      "Epoch 877, Loss: 0.19564802199602127, Final Batch Loss: 0.10351607203483582\n",
      "Epoch 878, Loss: 0.26969679445028305, Final Batch Loss: 0.17035847902297974\n",
      "Epoch 879, Loss: 0.21690041571855545, Final Batch Loss: 0.11275158077478409\n",
      "Epoch 880, Loss: 0.21247874200344086, Final Batch Loss: 0.09939511865377426\n",
      "Epoch 881, Loss: 0.22523458302021027, Final Batch Loss: 0.1085297018289566\n",
      "Epoch 882, Loss: 0.248234823346138, Final Batch Loss: 0.14061638712882996\n",
      "Epoch 883, Loss: 0.2188824862241745, Final Batch Loss: 0.11504751443862915\n",
      "Epoch 884, Loss: 0.21792108565568924, Final Batch Loss: 0.10111759603023529\n",
      "Epoch 885, Loss: 0.26856324076652527, Final Batch Loss: 0.1487724781036377\n",
      "Epoch 886, Loss: 0.17564653232693672, Final Batch Loss: 0.06168302521109581\n",
      "Epoch 887, Loss: 0.22079408913850784, Final Batch Loss: 0.12580697238445282\n",
      "Epoch 888, Loss: 0.20676053315401077, Final Batch Loss: 0.09838631004095078\n",
      "Epoch 889, Loss: 0.2377382144331932, Final Batch Loss: 0.14427036046981812\n",
      "Epoch 890, Loss: 0.17131608724594116, Final Batch Loss: 0.0740136206150055\n",
      "Epoch 891, Loss: 0.23563998937606812, Final Batch Loss: 0.09976793825626373\n",
      "Epoch 892, Loss: 0.27425844967365265, Final Batch Loss: 0.13421401381492615\n",
      "Epoch 893, Loss: 0.22398195788264275, Final Batch Loss: 0.1637212187051773\n",
      "Epoch 894, Loss: 0.18208008259534836, Final Batch Loss: 0.0928361713886261\n",
      "Epoch 895, Loss: 0.2144305184483528, Final Batch Loss: 0.13550639152526855\n",
      "Epoch 896, Loss: 0.24541550874710083, Final Batch Loss: 0.09548969566822052\n",
      "Epoch 897, Loss: 0.2215653508901596, Final Batch Loss: 0.09818171709775925\n",
      "Epoch 898, Loss: 0.2108859270811081, Final Batch Loss: 0.0889446809887886\n",
      "Epoch 899, Loss: 0.2200521156191826, Final Batch Loss: 0.10077974200248718\n",
      "Epoch 900, Loss: 0.2211892232298851, Final Batch Loss: 0.133039653301239\n",
      "Epoch 901, Loss: 0.20937545597553253, Final Batch Loss: 0.10459122061729431\n",
      "Epoch 902, Loss: 0.2133869007229805, Final Batch Loss: 0.10057855397462845\n",
      "Epoch 903, Loss: 0.23083098977804184, Final Batch Loss: 0.0955871120095253\n",
      "Epoch 904, Loss: 0.23168857395648956, Final Batch Loss: 0.12799061834812164\n",
      "Epoch 905, Loss: 0.2610405460000038, Final Batch Loss: 0.13787424564361572\n",
      "Epoch 906, Loss: 0.2716010957956314, Final Batch Loss: 0.14935651421546936\n",
      "Epoch 907, Loss: 0.20636609941720963, Final Batch Loss: 0.116961270570755\n",
      "Epoch 908, Loss: 0.21238934993743896, Final Batch Loss: 0.09834721684455872\n",
      "Epoch 909, Loss: 0.28586186468601227, Final Batch Loss: 0.14588285982608795\n",
      "Epoch 910, Loss: 0.21084313094615936, Final Batch Loss: 0.09829811751842499\n",
      "Epoch 911, Loss: 0.25587502121925354, Final Batch Loss: 0.1297530084848404\n",
      "Epoch 912, Loss: 0.18552714586257935, Final Batch Loss: 0.08836188912391663\n",
      "Epoch 913, Loss: 0.271851509809494, Final Batch Loss: 0.10802066326141357\n",
      "Epoch 914, Loss: 0.219233937561512, Final Batch Loss: 0.10079549252986908\n",
      "Epoch 915, Loss: 0.25945693999528885, Final Batch Loss: 0.12245502322912216\n",
      "Epoch 916, Loss: 0.23307736963033676, Final Batch Loss: 0.10458806902170181\n",
      "Epoch 917, Loss: 0.23261288553476334, Final Batch Loss: 0.10843245685100555\n",
      "Epoch 918, Loss: 0.236140176653862, Final Batch Loss: 0.11305846273899078\n",
      "Epoch 919, Loss: 0.25475137680768967, Final Batch Loss: 0.1372826099395752\n",
      "Epoch 920, Loss: 0.2367529422044754, Final Batch Loss: 0.12460599839687347\n",
      "Epoch 921, Loss: 0.22073552757501602, Final Batch Loss: 0.09559016674757004\n",
      "Epoch 922, Loss: 0.21828795224428177, Final Batch Loss: 0.1301068812608719\n",
      "Epoch 923, Loss: 0.22378507256507874, Final Batch Loss: 0.09450989961624146\n",
      "Epoch 924, Loss: 0.24505756795406342, Final Batch Loss: 0.12481245398521423\n",
      "Epoch 925, Loss: 0.3161422610282898, Final Batch Loss: 0.1427319496870041\n",
      "Epoch 926, Loss: 0.2802278846502304, Final Batch Loss: 0.18182110786437988\n",
      "Epoch 927, Loss: 0.19511890411376953, Final Batch Loss: 0.07429473847150803\n",
      "Epoch 928, Loss: 0.239885613322258, Final Batch Loss: 0.12977516651153564\n",
      "Epoch 929, Loss: 0.21202339231967926, Final Batch Loss: 0.08869919180870056\n",
      "Epoch 930, Loss: 0.23080314695835114, Final Batch Loss: 0.10199475288391113\n",
      "Epoch 931, Loss: 0.2882556840777397, Final Batch Loss: 0.10921008139848709\n",
      "Epoch 932, Loss: 0.22156627476215363, Final Batch Loss: 0.11925093829631805\n",
      "Epoch 933, Loss: 0.2023307904601097, Final Batch Loss: 0.10850800573825836\n",
      "Epoch 934, Loss: 0.24320057779550552, Final Batch Loss: 0.10091830044984818\n",
      "Epoch 935, Loss: 0.20104067027568817, Final Batch Loss: 0.10925188660621643\n",
      "Epoch 936, Loss: 0.2152414694428444, Final Batch Loss: 0.09447216987609863\n",
      "Epoch 937, Loss: 0.2276841253042221, Final Batch Loss: 0.09516961872577667\n",
      "Epoch 938, Loss: 0.21953017264604568, Final Batch Loss: 0.12055379897356033\n",
      "Epoch 939, Loss: 0.21712933480739594, Final Batch Loss: 0.07640913128852844\n",
      "Epoch 940, Loss: 0.25087765604257584, Final Batch Loss: 0.15259137749671936\n",
      "Epoch 941, Loss: 0.21169637143611908, Final Batch Loss: 0.10640682280063629\n",
      "Epoch 942, Loss: 0.21618808805942535, Final Batch Loss: 0.12573015689849854\n",
      "Epoch 943, Loss: 0.23239397257566452, Final Batch Loss: 0.10007109493017197\n",
      "Epoch 944, Loss: 0.22659267485141754, Final Batch Loss: 0.10658004879951477\n",
      "Epoch 945, Loss: 0.20604972541332245, Final Batch Loss: 0.08180496841669083\n",
      "Epoch 946, Loss: 0.1826806217432022, Final Batch Loss: 0.0652080625295639\n",
      "Epoch 947, Loss: 0.20561903715133667, Final Batch Loss: 0.06600537896156311\n",
      "Epoch 948, Loss: 0.18583055585622787, Final Batch Loss: 0.10119898617267609\n",
      "Epoch 949, Loss: 0.2541719600558281, Final Batch Loss: 0.1437261700630188\n",
      "Epoch 950, Loss: 0.22813093662261963, Final Batch Loss: 0.14332085847854614\n",
      "Epoch 951, Loss: 0.2428562492132187, Final Batch Loss: 0.12069221585988998\n",
      "Epoch 952, Loss: 0.27918189764022827, Final Batch Loss: 0.14187511801719666\n",
      "Epoch 953, Loss: 0.21420105546712875, Final Batch Loss: 0.12462069094181061\n",
      "Epoch 954, Loss: 0.21463707089424133, Final Batch Loss: 0.09473270177841187\n",
      "Epoch 955, Loss: 0.18124078959226608, Final Batch Loss: 0.07733273506164551\n",
      "Epoch 956, Loss: 0.20521603524684906, Final Batch Loss: 0.10017377138137817\n",
      "Epoch 957, Loss: 0.17485424876213074, Final Batch Loss: 0.07558538764715195\n",
      "Epoch 958, Loss: 0.17537066340446472, Final Batch Loss: 0.09240036457777023\n",
      "Epoch 959, Loss: 0.2958318740129471, Final Batch Loss: 0.1406116783618927\n",
      "Epoch 960, Loss: 0.26019760966300964, Final Batch Loss: 0.1273343563079834\n",
      "Epoch 961, Loss: 0.29523010551929474, Final Batch Loss: 0.1360316127538681\n",
      "Epoch 962, Loss: 0.22508522868156433, Final Batch Loss: 0.09446728229522705\n",
      "Epoch 963, Loss: 0.2545279264450073, Final Batch Loss: 0.16428789496421814\n",
      "Epoch 964, Loss: 0.2005217894911766, Final Batch Loss: 0.11392009258270264\n",
      "Epoch 965, Loss: 0.1993541494011879, Final Batch Loss: 0.11724437773227692\n",
      "Epoch 966, Loss: 0.28455502539873123, Final Batch Loss: 0.1851877123117447\n",
      "Epoch 967, Loss: 0.19996868073940277, Final Batch Loss: 0.11054699122905731\n",
      "Epoch 968, Loss: 0.2349572777748108, Final Batch Loss: 0.13442766666412354\n",
      "Epoch 969, Loss: 0.20815425366163254, Final Batch Loss: 0.1102161630988121\n",
      "Epoch 970, Loss: 0.21000701189041138, Final Batch Loss: 0.10094799846410751\n",
      "Epoch 971, Loss: 0.2183532640337944, Final Batch Loss: 0.13682270050048828\n",
      "Epoch 972, Loss: 0.21082095056772232, Final Batch Loss: 0.11833973228931427\n",
      "Epoch 973, Loss: 0.1800631433725357, Final Batch Loss: 0.10270781069993973\n",
      "Epoch 974, Loss: 0.22394993901252747, Final Batch Loss: 0.08468417823314667\n",
      "Epoch 975, Loss: 0.2376992031931877, Final Batch Loss: 0.13123732805252075\n",
      "Epoch 976, Loss: 0.20331455767154694, Final Batch Loss: 0.10611622035503387\n",
      "Epoch 977, Loss: 0.17663368955254555, Final Batch Loss: 0.12213526666164398\n",
      "Epoch 978, Loss: 0.19250623136758804, Final Batch Loss: 0.1140163242816925\n",
      "Epoch 979, Loss: 0.18699656426906586, Final Batch Loss: 0.09319541603326797\n",
      "Epoch 980, Loss: 0.18762818723917007, Final Batch Loss: 0.09645111858844757\n",
      "Epoch 981, Loss: 0.21451357007026672, Final Batch Loss: 0.12746216356754303\n",
      "Epoch 982, Loss: 0.21162890642881393, Final Batch Loss: 0.0880725085735321\n",
      "Epoch 983, Loss: 0.19000448286533356, Final Batch Loss: 0.08862216025590897\n",
      "Epoch 984, Loss: 0.19135445356369019, Final Batch Loss: 0.09349009394645691\n",
      "Epoch 985, Loss: 0.20625508576631546, Final Batch Loss: 0.09779631346464157\n",
      "Epoch 986, Loss: 0.1900593340396881, Final Batch Loss: 0.09977953135967255\n",
      "Epoch 987, Loss: 0.2221057489514351, Final Batch Loss: 0.1200503259897232\n",
      "Epoch 988, Loss: 0.25238804519176483, Final Batch Loss: 0.09291544556617737\n",
      "Epoch 989, Loss: 0.20668719708919525, Final Batch Loss: 0.09108953177928925\n",
      "Epoch 990, Loss: 0.2202729880809784, Final Batch Loss: 0.11370855569839478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 991, Loss: 0.19823377579450607, Final Batch Loss: 0.08833035826683044\n",
      "Epoch 992, Loss: 0.21753766387701035, Final Batch Loss: 0.11958079040050507\n",
      "Epoch 993, Loss: 0.1662135198712349, Final Batch Loss: 0.07145639508962631\n",
      "Epoch 994, Loss: 0.22978021949529648, Final Batch Loss: 0.09937160462141037\n",
      "Epoch 995, Loss: 0.17088979482650757, Final Batch Loss: 0.06317081302404404\n",
      "Epoch 996, Loss: 0.19995508342981339, Final Batch Loss: 0.06528956443071365\n",
      "Epoch 997, Loss: 0.2429337501525879, Final Batch Loss: 0.14475761353969574\n",
      "Epoch 998, Loss: 0.16813960671424866, Final Batch Loss: 0.06389512121677399\n",
      "Epoch 999, Loss: 0.15984752029180527, Final Batch Loss: 0.04837407171726227\n",
      "Epoch 1000, Loss: 0.18692797422409058, Final Batch Loss: 0.07609260827302933\n",
      "Epoch 1001, Loss: 0.2060781717300415, Final Batch Loss: 0.0806504338979721\n",
      "Epoch 1002, Loss: 0.20520727336406708, Final Batch Loss: 0.07289695739746094\n",
      "Epoch 1003, Loss: 0.19883208721876144, Final Batch Loss: 0.09377410262823105\n",
      "Epoch 1004, Loss: 0.1980893537402153, Final Batch Loss: 0.11547619104385376\n",
      "Epoch 1005, Loss: 0.2042417824268341, Final Batch Loss: 0.09567955881357193\n",
      "Epoch 1006, Loss: 0.2509302794933319, Final Batch Loss: 0.1556139886379242\n",
      "Epoch 1007, Loss: 0.2144894301891327, Final Batch Loss: 0.10332485288381577\n",
      "Epoch 1008, Loss: 0.24922458082437515, Final Batch Loss: 0.14851734042167664\n",
      "Epoch 1009, Loss: 0.25527937710285187, Final Batch Loss: 0.1521715372800827\n",
      "Epoch 1010, Loss: 0.2038341760635376, Final Batch Loss: 0.10789549350738525\n",
      "Epoch 1011, Loss: 0.23909012973308563, Final Batch Loss: 0.11265391111373901\n",
      "Epoch 1012, Loss: 0.2727562487125397, Final Batch Loss: 0.08804677426815033\n",
      "Epoch 1013, Loss: 0.24953607469797134, Final Batch Loss: 0.17062246799468994\n",
      "Epoch 1014, Loss: 0.21014608442783356, Final Batch Loss: 0.11202672868967056\n",
      "Epoch 1015, Loss: 0.1599433645606041, Final Batch Loss: 0.09132959693670273\n",
      "Epoch 1016, Loss: 0.1823120340704918, Final Batch Loss: 0.06305406987667084\n",
      "Epoch 1017, Loss: 0.19217614084482193, Final Batch Loss: 0.09072685986757278\n",
      "Epoch 1018, Loss: 0.20263999700546265, Final Batch Loss: 0.09073061496019363\n",
      "Epoch 1019, Loss: 0.22371940314769745, Final Batch Loss: 0.13762600719928741\n",
      "Epoch 1020, Loss: 0.1977889984846115, Final Batch Loss: 0.08713365346193314\n",
      "Epoch 1021, Loss: 0.23459143936634064, Final Batch Loss: 0.13751409947872162\n",
      "Epoch 1022, Loss: 0.19358447939157486, Final Batch Loss: 0.09348044544458389\n",
      "Epoch 1023, Loss: 0.19802966713905334, Final Batch Loss: 0.07553643733263016\n",
      "Epoch 1024, Loss: 0.18730918318033218, Final Batch Loss: 0.09797747433185577\n",
      "Epoch 1025, Loss: 0.20489271730184555, Final Batch Loss: 0.11682526767253876\n",
      "Epoch 1026, Loss: 0.19254743307828903, Final Batch Loss: 0.07802315801382065\n",
      "Epoch 1027, Loss: 0.2880774885416031, Final Batch Loss: 0.17526459693908691\n",
      "Epoch 1028, Loss: 0.19803457707166672, Final Batch Loss: 0.11074668914079666\n",
      "Epoch 1029, Loss: 0.24217654019594193, Final Batch Loss: 0.146558940410614\n",
      "Epoch 1030, Loss: 0.20460768789052963, Final Batch Loss: 0.10545873641967773\n",
      "Epoch 1031, Loss: 0.23143988102674484, Final Batch Loss: 0.12425165623426437\n",
      "Epoch 1032, Loss: 0.2014690414071083, Final Batch Loss: 0.07970110327005386\n",
      "Epoch 1033, Loss: 0.22311637550592422, Final Batch Loss: 0.0962977334856987\n",
      "Epoch 1034, Loss: 0.17960017174482346, Final Batch Loss: 0.07145748287439346\n",
      "Epoch 1035, Loss: 0.2621505931019783, Final Batch Loss: 0.15112824738025665\n",
      "Epoch 1036, Loss: 0.20100640505552292, Final Batch Loss: 0.10604294389486313\n",
      "Epoch 1037, Loss: 0.2149781808257103, Final Batch Loss: 0.12534476816654205\n",
      "Epoch 1038, Loss: 0.2090371549129486, Final Batch Loss: 0.08907129615545273\n",
      "Epoch 1039, Loss: 0.19814641028642654, Final Batch Loss: 0.08013737946748734\n",
      "Epoch 1040, Loss: 0.2111590877175331, Final Batch Loss: 0.12338342517614365\n",
      "Epoch 1041, Loss: 0.19276583939790726, Final Batch Loss: 0.07949255406856537\n",
      "Epoch 1042, Loss: 0.19674556702375412, Final Batch Loss: 0.09505431354045868\n",
      "Epoch 1043, Loss: 0.16560674458742142, Final Batch Loss: 0.06362144649028778\n",
      "Epoch 1044, Loss: 0.15666690468788147, Final Batch Loss: 0.08894489705562592\n",
      "Epoch 1045, Loss: 0.19863229244947433, Final Batch Loss: 0.08685670047998428\n",
      "Epoch 1046, Loss: 0.1307005062699318, Final Batch Loss: 0.06266293674707413\n",
      "Epoch 1047, Loss: 0.19994362443685532, Final Batch Loss: 0.08115286380052567\n",
      "Epoch 1048, Loss: 0.20637237280607224, Final Batch Loss: 0.09966422617435455\n",
      "Epoch 1049, Loss: 0.20288735628128052, Final Batch Loss: 0.11949083209037781\n",
      "Epoch 1050, Loss: 0.1825273111462593, Final Batch Loss: 0.11971986293792725\n",
      "Epoch 1051, Loss: 0.23778270930051804, Final Batch Loss: 0.15540850162506104\n",
      "Epoch 1052, Loss: 0.16108574718236923, Final Batch Loss: 0.08038748800754547\n",
      "Epoch 1053, Loss: 0.18963467329740524, Final Batch Loss: 0.07496485114097595\n",
      "Epoch 1054, Loss: 0.2231123149394989, Final Batch Loss: 0.09957651793956757\n",
      "Epoch 1055, Loss: 0.16702132672071457, Final Batch Loss: 0.06711243093013763\n",
      "Epoch 1056, Loss: 0.23562142997980118, Final Batch Loss: 0.13508319854736328\n",
      "Epoch 1057, Loss: 0.18560149520635605, Final Batch Loss: 0.06539734452962875\n",
      "Epoch 1058, Loss: 0.22215139865875244, Final Batch Loss: 0.1496022492647171\n",
      "Epoch 1059, Loss: 0.1557541936635971, Final Batch Loss: 0.06309783458709717\n",
      "Epoch 1060, Loss: 0.1980270817875862, Final Batch Loss: 0.11572424322366714\n",
      "Epoch 1061, Loss: 0.15653318911790848, Final Batch Loss: 0.08228568732738495\n",
      "Epoch 1062, Loss: 0.21209727227687836, Final Batch Loss: 0.13176651298999786\n",
      "Epoch 1063, Loss: 0.19010091572999954, Final Batch Loss: 0.10418257117271423\n",
      "Epoch 1064, Loss: 0.2022954374551773, Final Batch Loss: 0.07304875552654266\n",
      "Epoch 1065, Loss: 0.21554994583129883, Final Batch Loss: 0.10451597720384598\n",
      "Epoch 1066, Loss: 0.14788885787129402, Final Batch Loss: 0.05977054312825203\n",
      "Epoch 1067, Loss: 0.19977770745754242, Final Batch Loss: 0.1063312217593193\n",
      "Epoch 1068, Loss: 0.1715090572834015, Final Batch Loss: 0.07784725725650787\n",
      "Epoch 1069, Loss: 0.18479081243276596, Final Batch Loss: 0.1062462106347084\n",
      "Epoch 1070, Loss: 0.1904679462313652, Final Batch Loss: 0.08220338821411133\n",
      "Epoch 1071, Loss: 0.20230774581432343, Final Batch Loss: 0.13924828171730042\n",
      "Epoch 1072, Loss: 0.21095553785562515, Final Batch Loss: 0.12270879745483398\n",
      "Epoch 1073, Loss: 0.20976842194795609, Final Batch Loss: 0.130767360329628\n",
      "Epoch 1074, Loss: 0.20595745742321014, Final Batch Loss: 0.10277478396892548\n",
      "Epoch 1075, Loss: 0.1373598836362362, Final Batch Loss: 0.05601991340517998\n",
      "Epoch 1076, Loss: 0.17675253748893738, Final Batch Loss: 0.07929414510726929\n",
      "Epoch 1077, Loss: 0.15309103205800056, Final Batch Loss: 0.059291038662195206\n",
      "Epoch 1078, Loss: 0.2199511155486107, Final Batch Loss: 0.12068700790405273\n",
      "Epoch 1079, Loss: 0.1927434206008911, Final Batch Loss: 0.0936252623796463\n",
      "Epoch 1080, Loss: 0.1807645633816719, Final Batch Loss: 0.09505576640367508\n",
      "Epoch 1081, Loss: 0.19905007630586624, Final Batch Loss: 0.07315660268068314\n",
      "Epoch 1082, Loss: 0.20362617820501328, Final Batch Loss: 0.10036308318376541\n",
      "Epoch 1083, Loss: 0.17276757210493088, Final Batch Loss: 0.0793735682964325\n",
      "Epoch 1084, Loss: 0.1695512756705284, Final Batch Loss: 0.06999338418245316\n",
      "Epoch 1085, Loss: 0.23630079627037048, Final Batch Loss: 0.11545341461896896\n",
      "Epoch 1086, Loss: 0.1668839156627655, Final Batch Loss: 0.08971618115901947\n",
      "Epoch 1087, Loss: 0.1933044120669365, Final Batch Loss: 0.09072432667016983\n",
      "Epoch 1088, Loss: 0.1948254182934761, Final Batch Loss: 0.08829186111688614\n",
      "Epoch 1089, Loss: 0.1993933543562889, Final Batch Loss: 0.11951552331447601\n",
      "Epoch 1090, Loss: 0.19308194518089294, Final Batch Loss: 0.09600304067134857\n",
      "Epoch 1091, Loss: 0.21716506034135818, Final Batch Loss: 0.1383889615535736\n",
      "Epoch 1092, Loss: 0.16617711633443832, Final Batch Loss: 0.10061457753181458\n",
      "Epoch 1093, Loss: 0.23049567639827728, Final Batch Loss: 0.0996180921792984\n",
      "Epoch 1094, Loss: 0.18995266407728195, Final Batch Loss: 0.09786425530910492\n",
      "Epoch 1095, Loss: 0.23446650058031082, Final Batch Loss: 0.1285357028245926\n",
      "Epoch 1096, Loss: 0.20977620035409927, Final Batch Loss: 0.09265227615833282\n",
      "Epoch 1097, Loss: 0.18732255697250366, Final Batch Loss: 0.10040023177862167\n",
      "Epoch 1098, Loss: 0.19287261739373207, Final Batch Loss: 0.1385878622531891\n",
      "Epoch 1099, Loss: 0.17859690636396408, Final Batch Loss: 0.09053944796323776\n",
      "Epoch 1100, Loss: 0.2640049159526825, Final Batch Loss: 0.09110786020755768\n",
      "Epoch 1101, Loss: 0.2310754805803299, Final Batch Loss: 0.09284284710884094\n",
      "Epoch 1102, Loss: 0.1822172850370407, Final Batch Loss: 0.11294004321098328\n",
      "Epoch 1103, Loss: 0.21068289875984192, Final Batch Loss: 0.1044749915599823\n",
      "Epoch 1104, Loss: 0.18840207159519196, Final Batch Loss: 0.11156000196933746\n",
      "Epoch 1105, Loss: 0.21900416910648346, Final Batch Loss: 0.146370068192482\n",
      "Epoch 1106, Loss: 0.18528854846954346, Final Batch Loss: 0.07844239473342896\n",
      "Epoch 1107, Loss: 0.20428894460201263, Final Batch Loss: 0.11186081171035767\n",
      "Epoch 1108, Loss: 0.23591365665197372, Final Batch Loss: 0.09817875176668167\n",
      "Epoch 1109, Loss: 0.2010733261704445, Final Batch Loss: 0.10404296219348907\n",
      "Epoch 1110, Loss: 0.21699751913547516, Final Batch Loss: 0.11567221581935883\n",
      "Epoch 1111, Loss: 0.19936998188495636, Final Batch Loss: 0.07627559453248978\n",
      "Epoch 1112, Loss: 0.1521289199590683, Final Batch Loss: 0.06928730756044388\n",
      "Epoch 1113, Loss: 0.16428032517433167, Final Batch Loss: 0.08125369995832443\n",
      "Epoch 1114, Loss: 0.18670596927404404, Final Batch Loss: 0.08422954380512238\n",
      "Epoch 1115, Loss: 0.19211199134588242, Final Batch Loss: 0.12866809964179993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1116, Loss: 0.176487535238266, Final Batch Loss: 0.08619001507759094\n",
      "Epoch 1117, Loss: 0.16202576458454132, Final Batch Loss: 0.06131705641746521\n",
      "Epoch 1118, Loss: 0.18838981539011002, Final Batch Loss: 0.06287270039319992\n",
      "Epoch 1119, Loss: 0.13320806249976158, Final Batch Loss: 0.05966858193278313\n",
      "Epoch 1120, Loss: 0.1942569725215435, Final Batch Loss: 0.05542292818427086\n",
      "Epoch 1121, Loss: 0.15855871886014938, Final Batch Loss: 0.07678157836198807\n",
      "Epoch 1122, Loss: 0.21820015460252762, Final Batch Loss: 0.0919434204697609\n",
      "Epoch 1123, Loss: 0.2176363617181778, Final Batch Loss: 0.11925139278173447\n",
      "Epoch 1124, Loss: 0.2141663134098053, Final Batch Loss: 0.11983747035264969\n",
      "Epoch 1125, Loss: 0.18885501474142075, Final Batch Loss: 0.08032815158367157\n",
      "Epoch 1126, Loss: 0.17105232179164886, Final Batch Loss: 0.10183815658092499\n",
      "Epoch 1127, Loss: 0.2046232968568802, Final Batch Loss: 0.10102280974388123\n",
      "Epoch 1128, Loss: 0.18295269459486008, Final Batch Loss: 0.06506145000457764\n",
      "Epoch 1129, Loss: 0.15442640334367752, Final Batch Loss: 0.08508557826280594\n",
      "Epoch 1130, Loss: 0.16845501214265823, Final Batch Loss: 0.07952368259429932\n",
      "Epoch 1131, Loss: 0.15818949788808823, Final Batch Loss: 0.06298545747995377\n",
      "Epoch 1132, Loss: 0.1455683745443821, Final Batch Loss: 0.08650561422109604\n",
      "Epoch 1133, Loss: 0.21699760854244232, Final Batch Loss: 0.11146705597639084\n",
      "Epoch 1134, Loss: 0.19719278067350388, Final Batch Loss: 0.0960964635014534\n",
      "Epoch 1135, Loss: 0.15700729191303253, Final Batch Loss: 0.0664353221654892\n",
      "Epoch 1136, Loss: 0.21973590552806854, Final Batch Loss: 0.10396979749202728\n",
      "Epoch 1137, Loss: 0.20823153108358383, Final Batch Loss: 0.1224641352891922\n",
      "Epoch 1138, Loss: 0.14687343314290047, Final Batch Loss: 0.09284215420484543\n",
      "Epoch 1139, Loss: 0.22410175204277039, Final Batch Loss: 0.09811291098594666\n",
      "Epoch 1140, Loss: 0.20597629249095917, Final Batch Loss: 0.10694421827793121\n",
      "Epoch 1141, Loss: 0.17954622209072113, Final Batch Loss: 0.09340143948793411\n",
      "Epoch 1142, Loss: 0.17051689326763153, Final Batch Loss: 0.07876695692539215\n",
      "Epoch 1143, Loss: 0.153449147939682, Final Batch Loss: 0.08816590160131454\n",
      "Epoch 1144, Loss: 0.18261591717600822, Final Batch Loss: 0.05255363509058952\n",
      "Epoch 1145, Loss: 0.20936539769172668, Final Batch Loss: 0.06831783056259155\n",
      "Epoch 1146, Loss: 0.22939440608024597, Final Batch Loss: 0.08559845387935638\n",
      "Epoch 1147, Loss: 0.19098475202918053, Final Batch Loss: 0.13846270740032196\n",
      "Epoch 1148, Loss: 0.18329107761383057, Final Batch Loss: 0.08800571411848068\n",
      "Epoch 1149, Loss: 0.24925393611192703, Final Batch Loss: 0.17390896379947662\n",
      "Epoch 1150, Loss: 0.1706477627158165, Final Batch Loss: 0.08048657327890396\n",
      "Epoch 1151, Loss: 0.20910809934139252, Final Batch Loss: 0.07606971263885498\n",
      "Epoch 1152, Loss: 0.28786660730838776, Final Batch Loss: 0.16728605329990387\n",
      "Epoch 1153, Loss: 0.1732877418398857, Final Batch Loss: 0.07256300747394562\n",
      "Epoch 1154, Loss: 0.2074229046702385, Final Batch Loss: 0.128587543964386\n",
      "Epoch 1155, Loss: 0.21176423132419586, Final Batch Loss: 0.08143170177936554\n",
      "Epoch 1156, Loss: 0.22943907976150513, Final Batch Loss: 0.1586734652519226\n",
      "Epoch 1157, Loss: 0.19750350713729858, Final Batch Loss: 0.10494058579206467\n",
      "Epoch 1158, Loss: 0.20321785658597946, Final Batch Loss: 0.11612160503864288\n",
      "Epoch 1159, Loss: 0.159224946051836, Final Batch Loss: 0.055533040314912796\n",
      "Epoch 1160, Loss: 0.23425640910863876, Final Batch Loss: 0.08127845078706741\n",
      "Epoch 1161, Loss: 0.20973464101552963, Final Batch Loss: 0.10030712932348251\n",
      "Epoch 1162, Loss: 0.18667761981487274, Final Batch Loss: 0.08403051644563675\n",
      "Epoch 1163, Loss: 0.18585781753063202, Final Batch Loss: 0.1045263484120369\n",
      "Epoch 1164, Loss: 0.1596599742770195, Final Batch Loss: 0.06681336462497711\n",
      "Epoch 1165, Loss: 0.19781195372343063, Final Batch Loss: 0.06985225528478622\n",
      "Epoch 1166, Loss: 0.18232157826423645, Final Batch Loss: 0.09929133951663971\n",
      "Epoch 1167, Loss: 0.16343384236097336, Final Batch Loss: 0.0676518976688385\n",
      "Epoch 1168, Loss: 0.1893804371356964, Final Batch Loss: 0.0733056291937828\n",
      "Epoch 1169, Loss: 0.19742218405008316, Final Batch Loss: 0.09647127240896225\n",
      "Epoch 1170, Loss: 0.19133369624614716, Final Batch Loss: 0.10054942220449448\n",
      "Epoch 1171, Loss: 0.18072187900543213, Final Batch Loss: 0.0936807319521904\n",
      "Epoch 1172, Loss: 0.1526574045419693, Final Batch Loss: 0.07764133810997009\n",
      "Epoch 1173, Loss: 0.25171592831611633, Final Batch Loss: 0.1450183093547821\n",
      "Epoch 1174, Loss: 0.17158393561840057, Final Batch Loss: 0.08850185573101044\n",
      "Epoch 1175, Loss: 0.16606272011995316, Final Batch Loss: 0.0940818265080452\n",
      "Epoch 1176, Loss: 0.1522713601589203, Final Batch Loss: 0.06591657549142838\n",
      "Epoch 1177, Loss: 0.1839332953095436, Final Batch Loss: 0.10655625909566879\n",
      "Epoch 1178, Loss: 0.170802041888237, Final Batch Loss: 0.054952219128608704\n",
      "Epoch 1179, Loss: 0.17648670077323914, Final Batch Loss: 0.09258467704057693\n",
      "Epoch 1180, Loss: 0.2052680030465126, Final Batch Loss: 0.07897388190031052\n",
      "Epoch 1181, Loss: 0.17415516823530197, Final Batch Loss: 0.10315726697444916\n",
      "Epoch 1182, Loss: 0.1785263791680336, Final Batch Loss: 0.07783146947622299\n",
      "Epoch 1183, Loss: 0.17708762735128403, Final Batch Loss: 0.07972607016563416\n",
      "Epoch 1184, Loss: 0.1838286593556404, Final Batch Loss: 0.10456078499555588\n",
      "Epoch 1185, Loss: 0.1692148596048355, Final Batch Loss: 0.08389406651258469\n",
      "Epoch 1186, Loss: 0.19468657672405243, Final Batch Loss: 0.09325665980577469\n",
      "Epoch 1187, Loss: 0.16933858767151833, Final Batch Loss: 0.12616096436977386\n",
      "Epoch 1188, Loss: 0.2123580425977707, Final Batch Loss: 0.13000856339931488\n",
      "Epoch 1189, Loss: 0.1959541290998459, Final Batch Loss: 0.06693479418754578\n",
      "Epoch 1190, Loss: 0.1571042165160179, Final Batch Loss: 0.0770329087972641\n",
      "Epoch 1191, Loss: 0.18938588351011276, Final Batch Loss: 0.09192820638418198\n",
      "Epoch 1192, Loss: 0.13382940366864204, Final Batch Loss: 0.05919373407959938\n",
      "Epoch 1193, Loss: 0.19340869039297104, Final Batch Loss: 0.08212549239397049\n",
      "Epoch 1194, Loss: 0.20287885516881943, Final Batch Loss: 0.08885326981544495\n",
      "Epoch 1195, Loss: 0.18342739343643188, Final Batch Loss: 0.08209630101919174\n",
      "Epoch 1196, Loss: 0.20934481918811798, Final Batch Loss: 0.08285921812057495\n",
      "Epoch 1197, Loss: 0.18320289254188538, Final Batch Loss: 0.08981651067733765\n",
      "Epoch 1198, Loss: 0.17063573002815247, Final Batch Loss: 0.0834035873413086\n",
      "Epoch 1199, Loss: 0.15322047472000122, Final Batch Loss: 0.08606800436973572\n",
      "Epoch 1200, Loss: 0.19198933243751526, Final Batch Loss: 0.09754464775323868\n",
      "Epoch 1201, Loss: 0.19077028334140778, Final Batch Loss: 0.07629435509443283\n",
      "Epoch 1202, Loss: 0.19773618131875992, Final Batch Loss: 0.09766219556331635\n",
      "Epoch 1203, Loss: 0.18047241121530533, Final Batch Loss: 0.09050796926021576\n",
      "Epoch 1204, Loss: 0.1912890002131462, Final Batch Loss: 0.07325538992881775\n",
      "Epoch 1205, Loss: 0.1793917566537857, Final Batch Loss: 0.09242899715900421\n",
      "Epoch 1206, Loss: 0.19653230905532837, Final Batch Loss: 0.10427464544773102\n",
      "Epoch 1207, Loss: 0.15614301711320877, Final Batch Loss: 0.07969549298286438\n",
      "Epoch 1208, Loss: 0.16854538768529892, Final Batch Loss: 0.08010157197713852\n",
      "Epoch 1209, Loss: 0.15430641174316406, Final Batch Loss: 0.08177734911441803\n",
      "Epoch 1210, Loss: 0.15683038532733917, Final Batch Loss: 0.07688821852207184\n",
      "Epoch 1211, Loss: 0.20295322686433792, Final Batch Loss: 0.0841938704252243\n",
      "Epoch 1212, Loss: 0.24144046753644943, Final Batch Loss: 0.12748229503631592\n",
      "Epoch 1213, Loss: 0.16533342748880386, Final Batch Loss: 0.0775500237941742\n",
      "Epoch 1214, Loss: 0.14041467010974884, Final Batch Loss: 0.07741960883140564\n",
      "Epoch 1215, Loss: 0.16564632952213287, Final Batch Loss: 0.08095863461494446\n",
      "Epoch 1216, Loss: 0.17076783627271652, Final Batch Loss: 0.08566656708717346\n",
      "Epoch 1217, Loss: 0.16076355427503586, Final Batch Loss: 0.06421376019716263\n",
      "Epoch 1218, Loss: 0.13937997072935104, Final Batch Loss: 0.05731610208749771\n",
      "Epoch 1219, Loss: 0.15395955368876457, Final Batch Loss: 0.09499479085206985\n",
      "Epoch 1220, Loss: 0.23139362037181854, Final Batch Loss: 0.11532438546419144\n",
      "Epoch 1221, Loss: 0.185079924762249, Final Batch Loss: 0.06775898486375809\n",
      "Epoch 1222, Loss: 0.1904529184103012, Final Batch Loss: 0.09014944732189178\n",
      "Epoch 1223, Loss: 0.16026638448238373, Final Batch Loss: 0.09164892882108688\n",
      "Epoch 1224, Loss: 0.22334768623113632, Final Batch Loss: 0.08811964839696884\n",
      "Epoch 1225, Loss: 0.18331468850374222, Final Batch Loss: 0.09427904337644577\n",
      "Epoch 1226, Loss: 0.1716158092021942, Final Batch Loss: 0.08996869623661041\n",
      "Epoch 1227, Loss: 0.1567028984427452, Final Batch Loss: 0.09157730638980865\n",
      "Epoch 1228, Loss: 0.17504654824733734, Final Batch Loss: 0.09823978692293167\n",
      "Epoch 1229, Loss: 0.16378722339868546, Final Batch Loss: 0.08267336338758469\n",
      "Epoch 1230, Loss: 0.13583188503980637, Final Batch Loss: 0.08086153864860535\n",
      "Epoch 1231, Loss: 0.16460121423006058, Final Batch Loss: 0.08087819069623947\n",
      "Epoch 1232, Loss: 0.1857936903834343, Final Batch Loss: 0.11341365426778793\n",
      "Epoch 1233, Loss: 0.21225947886705399, Final Batch Loss: 0.12174307554960251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1234, Loss: 0.16057728976011276, Final Batch Loss: 0.059183888137340546\n",
      "Epoch 1235, Loss: 0.13016968965530396, Final Batch Loss: 0.06400945782661438\n",
      "Epoch 1236, Loss: 0.134834386408329, Final Batch Loss: 0.06690965592861176\n",
      "Epoch 1237, Loss: 0.1952660158276558, Final Batch Loss: 0.10599344968795776\n",
      "Epoch 1238, Loss: 0.15851736068725586, Final Batch Loss: 0.059926412999629974\n",
      "Epoch 1239, Loss: 0.1870238333940506, Final Batch Loss: 0.09345589578151703\n",
      "Epoch 1240, Loss: 0.15134264528751373, Final Batch Loss: 0.06559544801712036\n",
      "Epoch 1241, Loss: 0.16084101796150208, Final Batch Loss: 0.062151335179805756\n",
      "Epoch 1242, Loss: 0.16006974130868912, Final Batch Loss: 0.06662266701459885\n",
      "Epoch 1243, Loss: 0.16612663120031357, Final Batch Loss: 0.10072257369756699\n",
      "Epoch 1244, Loss: 0.18351908028125763, Final Batch Loss: 0.10951842367649078\n",
      "Epoch 1245, Loss: 0.1892857402563095, Final Batch Loss: 0.09848538041114807\n",
      "Epoch 1246, Loss: 0.17416935414075851, Final Batch Loss: 0.08133324980735779\n",
      "Epoch 1247, Loss: 0.15316131711006165, Final Batch Loss: 0.07429768145084381\n",
      "Epoch 1248, Loss: 0.18045280501246452, Final Batch Loss: 0.11894278228282928\n",
      "Epoch 1249, Loss: 0.1506825052201748, Final Batch Loss: 0.05316353961825371\n",
      "Epoch 1250, Loss: 0.16549647599458694, Final Batch Loss: 0.08088783174753189\n",
      "Epoch 1251, Loss: 0.14983030408620834, Final Batch Loss: 0.07126323878765106\n",
      "Epoch 1252, Loss: 0.17376220226287842, Final Batch Loss: 0.08331984281539917\n",
      "Epoch 1253, Loss: 0.1725657656788826, Final Batch Loss: 0.07909241318702698\n",
      "Epoch 1254, Loss: 0.20164655894041061, Final Batch Loss: 0.0867215096950531\n",
      "Epoch 1255, Loss: 0.1906265765428543, Final Batch Loss: 0.11944639682769775\n",
      "Epoch 1256, Loss: 0.13771327584981918, Final Batch Loss: 0.06385987997055054\n",
      "Epoch 1257, Loss: 0.20777539163827896, Final Batch Loss: 0.1388263702392578\n",
      "Epoch 1258, Loss: 0.16481580585241318, Final Batch Loss: 0.07512624561786652\n",
      "Epoch 1259, Loss: 0.1551940068602562, Final Batch Loss: 0.06983698159456253\n",
      "Epoch 1260, Loss: 0.16739678382873535, Final Batch Loss: 0.08159766346216202\n",
      "Epoch 1261, Loss: 0.16007424145936966, Final Batch Loss: 0.09712540358304977\n",
      "Epoch 1262, Loss: 0.15979816764593124, Final Batch Loss: 0.08622286468744278\n",
      "Epoch 1263, Loss: 0.16898813843727112, Final Batch Loss: 0.09632987529039383\n",
      "Epoch 1264, Loss: 0.16640058904886246, Final Batch Loss: 0.07117091864347458\n",
      "Epoch 1265, Loss: 0.14303583279252052, Final Batch Loss: 0.06053084507584572\n",
      "Epoch 1266, Loss: 0.22667246311903, Final Batch Loss: 0.10170601308345795\n",
      "Epoch 1267, Loss: 0.166840098798275, Final Batch Loss: 0.08242923766374588\n",
      "Epoch 1268, Loss: 0.1425086408853531, Final Batch Loss: 0.04632044583559036\n",
      "Epoch 1269, Loss: 0.15372629463672638, Final Batch Loss: 0.0687360018491745\n",
      "Epoch 1270, Loss: 0.18625327199697495, Final Batch Loss: 0.10172343254089355\n",
      "Epoch 1271, Loss: 0.1838604286313057, Final Batch Loss: 0.09447146952152252\n",
      "Epoch 1272, Loss: 0.1420648992061615, Final Batch Loss: 0.04309733957052231\n",
      "Epoch 1273, Loss: 0.15293149277567863, Final Batch Loss: 0.09911269694566727\n",
      "Epoch 1274, Loss: 0.16732551902532578, Final Batch Loss: 0.09930798411369324\n",
      "Epoch 1275, Loss: 0.18786659836769104, Final Batch Loss: 0.06303831189870834\n",
      "Epoch 1276, Loss: 0.17250977456569672, Final Batch Loss: 0.09166701138019562\n",
      "Epoch 1277, Loss: 0.14381073415279388, Final Batch Loss: 0.0883793830871582\n",
      "Epoch 1278, Loss: 0.16905033588409424, Final Batch Loss: 0.07143095135688782\n",
      "Epoch 1279, Loss: 0.15849582105875015, Final Batch Loss: 0.09227456897497177\n",
      "Epoch 1280, Loss: 0.15258775651454926, Final Batch Loss: 0.0646730586886406\n",
      "Epoch 1281, Loss: 0.15825656056404114, Final Batch Loss: 0.07399892807006836\n",
      "Epoch 1282, Loss: 0.16725090891122818, Final Batch Loss: 0.07792726159095764\n",
      "Epoch 1283, Loss: 0.15051451325416565, Final Batch Loss: 0.07341211289167404\n",
      "Epoch 1284, Loss: 0.18184985220432281, Final Batch Loss: 0.08678602427244186\n",
      "Epoch 1285, Loss: 0.15782397985458374, Final Batch Loss: 0.10684217512607574\n",
      "Epoch 1286, Loss: 0.14418861269950867, Final Batch Loss: 0.08871107548475266\n",
      "Epoch 1287, Loss: 0.2031950019299984, Final Batch Loss: 0.14249634742736816\n",
      "Epoch 1288, Loss: 0.1811721995472908, Final Batch Loss: 0.09435106068849564\n",
      "Epoch 1289, Loss: 0.142677441239357, Final Batch Loss: 0.08039625734090805\n",
      "Epoch 1290, Loss: 0.2004830464720726, Final Batch Loss: 0.07711482793092728\n",
      "Epoch 1291, Loss: 0.18631165474653244, Final Batch Loss: 0.11380460113286972\n",
      "Epoch 1292, Loss: 0.1378338858485222, Final Batch Loss: 0.0571921244263649\n",
      "Epoch 1293, Loss: 0.20562054216861725, Final Batch Loss: 0.07015448808670044\n",
      "Epoch 1294, Loss: 0.1493329480290413, Final Batch Loss: 0.07442120462656021\n",
      "Epoch 1295, Loss: 0.11383534222841263, Final Batch Loss: 0.071990005671978\n",
      "Epoch 1296, Loss: 0.1428338885307312, Final Batch Loss: 0.07710328698158264\n",
      "Epoch 1297, Loss: 0.15664711594581604, Final Batch Loss: 0.08770816773176193\n",
      "Epoch 1298, Loss: 0.115537378937006, Final Batch Loss: 0.04794953390955925\n",
      "Epoch 1299, Loss: 0.22140633314847946, Final Batch Loss: 0.13242606818675995\n",
      "Epoch 1300, Loss: 0.1573151871562004, Final Batch Loss: 0.08654896169900894\n",
      "Epoch 1301, Loss: 0.13967791199684143, Final Batch Loss: 0.07855867594480515\n",
      "Epoch 1302, Loss: 0.15727993100881577, Final Batch Loss: 0.08077161014080048\n",
      "Epoch 1303, Loss: 0.1644754335284233, Final Batch Loss: 0.061304233968257904\n",
      "Epoch 1304, Loss: 0.1628611609339714, Final Batch Loss: 0.07314992696046829\n",
      "Epoch 1305, Loss: 0.12104866653680801, Final Batch Loss: 0.05112989991903305\n",
      "Epoch 1306, Loss: 0.12274285033345222, Final Batch Loss: 0.06071211397647858\n",
      "Epoch 1307, Loss: 0.17340537533164024, Final Batch Loss: 0.04913819953799248\n",
      "Epoch 1308, Loss: 0.16568302735686302, Final Batch Loss: 0.10800150036811829\n",
      "Epoch 1309, Loss: 0.15410026907920837, Final Batch Loss: 0.08057185262441635\n",
      "Epoch 1310, Loss: 0.14694110304117203, Final Batch Loss: 0.09311807155609131\n",
      "Epoch 1311, Loss: 0.22959696501493454, Final Batch Loss: 0.1244269385933876\n",
      "Epoch 1312, Loss: 0.13232582062482834, Final Batch Loss: 0.06419912725687027\n",
      "Epoch 1313, Loss: 0.13775642961263657, Final Batch Loss: 0.05617646872997284\n",
      "Epoch 1314, Loss: 0.14260109513998032, Final Batch Loss: 0.058510370552539825\n",
      "Epoch 1315, Loss: 0.14032863825559616, Final Batch Loss: 0.06424712389707565\n",
      "Epoch 1316, Loss: 0.14557404816150665, Final Batch Loss: 0.08464495837688446\n",
      "Epoch 1317, Loss: 0.21126142144203186, Final Batch Loss: 0.09954068064689636\n",
      "Epoch 1318, Loss: 0.1411401405930519, Final Batch Loss: 0.06267376989126205\n",
      "Epoch 1319, Loss: 0.1996621936559677, Final Batch Loss: 0.11686888337135315\n",
      "Epoch 1320, Loss: 0.1200266107916832, Final Batch Loss: 0.05529794096946716\n",
      "Epoch 1321, Loss: 0.15000999718904495, Final Batch Loss: 0.07569245994091034\n",
      "Epoch 1322, Loss: 0.15630119293928146, Final Batch Loss: 0.056729838252067566\n",
      "Epoch 1323, Loss: 0.19868822395801544, Final Batch Loss: 0.08811250329017639\n",
      "Epoch 1324, Loss: 0.14335131645202637, Final Batch Loss: 0.06509802490472794\n",
      "Epoch 1325, Loss: 0.2453402876853943, Final Batch Loss: 0.14587855339050293\n",
      "Epoch 1326, Loss: 0.17021938413381577, Final Batch Loss: 0.06227538734674454\n",
      "Epoch 1327, Loss: 0.2162976711988449, Final Batch Loss: 0.106252022087574\n",
      "Epoch 1328, Loss: 0.16682684049010277, Final Batch Loss: 0.10644464939832687\n",
      "Epoch 1329, Loss: 0.18771236389875412, Final Batch Loss: 0.12074441462755203\n",
      "Epoch 1330, Loss: 0.14786195755004883, Final Batch Loss: 0.07761390507221222\n",
      "Epoch 1331, Loss: 0.17062053084373474, Final Batch Loss: 0.10560997575521469\n",
      "Epoch 1332, Loss: 0.14887230843305588, Final Batch Loss: 0.06410150974988937\n",
      "Epoch 1333, Loss: 0.21669785678386688, Final Batch Loss: 0.13703079521656036\n",
      "Epoch 1334, Loss: 0.20976903289556503, Final Batch Loss: 0.1008925586938858\n",
      "Epoch 1335, Loss: 0.16619225963950157, Final Batch Loss: 0.11222986876964569\n",
      "Epoch 1336, Loss: 0.17509043961763382, Final Batch Loss: 0.10264035314321518\n",
      "Epoch 1337, Loss: 0.132133100181818, Final Batch Loss: 0.06999190896749496\n",
      "Epoch 1338, Loss: 0.18321232497692108, Final Batch Loss: 0.0896809995174408\n",
      "Epoch 1339, Loss: 0.16922259330749512, Final Batch Loss: 0.12188302725553513\n",
      "Epoch 1340, Loss: 0.12124932929873466, Final Batch Loss: 0.058156568557024\n",
      "Epoch 1341, Loss: 0.15741469338536263, Final Batch Loss: 0.050170864909887314\n",
      "Epoch 1342, Loss: 0.15865331888198853, Final Batch Loss: 0.08469875156879425\n",
      "Epoch 1343, Loss: 0.16739144921302795, Final Batch Loss: 0.08612889796495438\n",
      "Epoch 1344, Loss: 0.14598998799920082, Final Batch Loss: 0.05845468118786812\n",
      "Epoch 1345, Loss: 0.16230057924985886, Final Batch Loss: 0.08972400426864624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1346, Loss: 0.16028419882059097, Final Batch Loss: 0.08707728981971741\n",
      "Epoch 1347, Loss: 0.1793358512222767, Final Batch Loss: 0.1267809271812439\n",
      "Epoch 1348, Loss: 0.16464892774820328, Final Batch Loss: 0.073858343064785\n",
      "Epoch 1349, Loss: 0.131405808031559, Final Batch Loss: 0.06302088499069214\n",
      "Epoch 1350, Loss: 0.14277254045009613, Final Batch Loss: 0.07588735222816467\n",
      "Epoch 1351, Loss: 0.18371990323066711, Final Batch Loss: 0.10969137400388718\n",
      "Epoch 1352, Loss: 0.20115522295236588, Final Batch Loss: 0.10689526796340942\n",
      "Epoch 1353, Loss: 0.17372145503759384, Final Batch Loss: 0.09839662164449692\n",
      "Epoch 1354, Loss: 0.13520829379558563, Final Batch Loss: 0.058894045650959015\n",
      "Epoch 1355, Loss: 0.1727062314748764, Final Batch Loss: 0.08016302436590195\n",
      "Epoch 1356, Loss: 0.17581959068775177, Final Batch Loss: 0.08873790502548218\n",
      "Epoch 1357, Loss: 0.1432490386068821, Final Batch Loss: 0.06068490073084831\n",
      "Epoch 1358, Loss: 0.14900371059775352, Final Batch Loss: 0.09632571041584015\n",
      "Epoch 1359, Loss: 0.18254659324884415, Final Batch Loss: 0.08878496289253235\n",
      "Epoch 1360, Loss: 0.1258516050875187, Final Batch Loss: 0.054471585899591446\n",
      "Epoch 1361, Loss: 0.17522206157445908, Final Batch Loss: 0.06879925727844238\n",
      "Epoch 1362, Loss: 0.17000031471252441, Final Batch Loss: 0.08148986846208572\n",
      "Epoch 1363, Loss: 0.1538378819823265, Final Batch Loss: 0.08494096249341965\n",
      "Epoch 1364, Loss: 0.1416507586836815, Final Batch Loss: 0.05143380165100098\n",
      "Epoch 1365, Loss: 0.1556517407298088, Final Batch Loss: 0.07839395105838776\n",
      "Epoch 1366, Loss: 0.1372772604227066, Final Batch Loss: 0.07345505058765411\n",
      "Epoch 1367, Loss: 0.17033864557743073, Final Batch Loss: 0.07260853797197342\n",
      "Epoch 1368, Loss: 0.14010216668248177, Final Batch Loss: 0.05487877503037453\n",
      "Epoch 1369, Loss: 0.13929759711027145, Final Batch Loss: 0.07137074321508408\n",
      "Epoch 1370, Loss: 0.16713875532150269, Final Batch Loss: 0.0884050726890564\n",
      "Epoch 1371, Loss: 0.18337583541870117, Final Batch Loss: 0.0948556587100029\n",
      "Epoch 1372, Loss: 0.16882489621639252, Final Batch Loss: 0.08467178046703339\n",
      "Epoch 1373, Loss: 0.25211162120103836, Final Batch Loss: 0.1424248218536377\n",
      "Epoch 1374, Loss: 0.13715685158967972, Final Batch Loss: 0.07997607439756393\n",
      "Epoch 1375, Loss: 0.16400692611932755, Final Batch Loss: 0.09654412418603897\n",
      "Epoch 1376, Loss: 0.16504162922501564, Final Batch Loss: 0.10574158281087875\n",
      "Epoch 1377, Loss: 0.16166579723358154, Final Batch Loss: 0.08025486767292023\n",
      "Epoch 1378, Loss: 0.18929915875196457, Final Batch Loss: 0.11904491484165192\n",
      "Epoch 1379, Loss: 0.16960639506578445, Final Batch Loss: 0.06971506029367447\n",
      "Epoch 1380, Loss: 0.13855351135134697, Final Batch Loss: 0.08380991220474243\n",
      "Epoch 1381, Loss: 0.15531272441148758, Final Batch Loss: 0.0723000168800354\n",
      "Epoch 1382, Loss: 0.14671824127435684, Final Batch Loss: 0.0827983096241951\n",
      "Epoch 1383, Loss: 0.13301605358719826, Final Batch Loss: 0.05342443659901619\n",
      "Epoch 1384, Loss: 0.18412470817565918, Final Batch Loss: 0.09773461520671844\n",
      "Epoch 1385, Loss: 0.13355183601379395, Final Batch Loss: 0.07362199574708939\n",
      "Epoch 1386, Loss: 0.1362815499305725, Final Batch Loss: 0.06625572592020035\n",
      "Epoch 1387, Loss: 0.22933068126440048, Final Batch Loss: 0.11871614307165146\n",
      "Epoch 1388, Loss: 0.2577072083950043, Final Batch Loss: 0.1526346504688263\n",
      "Epoch 1389, Loss: 0.14817843958735466, Final Batch Loss: 0.08620267361402512\n",
      "Epoch 1390, Loss: 0.16096451878547668, Final Batch Loss: 0.09400613605976105\n",
      "Epoch 1391, Loss: 0.23294832557439804, Final Batch Loss: 0.15911909937858582\n",
      "Epoch 1392, Loss: 0.16704217344522476, Final Batch Loss: 0.09552913159132004\n",
      "Epoch 1393, Loss: 0.18956933915615082, Final Batch Loss: 0.10191931575536728\n",
      "Epoch 1394, Loss: 0.20596729218959808, Final Batch Loss: 0.08177004754543304\n",
      "Epoch 1395, Loss: 0.24674197286367416, Final Batch Loss: 0.140278622508049\n",
      "Epoch 1396, Loss: 0.1289673037827015, Final Batch Loss: 0.07347247004508972\n",
      "Epoch 1397, Loss: 0.2089894562959671, Final Batch Loss: 0.08850143849849701\n",
      "Epoch 1398, Loss: 0.16483911126852036, Final Batch Loss: 0.0690857544541359\n",
      "Epoch 1399, Loss: 0.14346392452716827, Final Batch Loss: 0.06718668341636658\n",
      "Epoch 1400, Loss: 0.19516921788454056, Final Batch Loss: 0.08653796464204788\n",
      "Epoch 1401, Loss: 0.13910901173949242, Final Batch Loss: 0.04979163780808449\n",
      "Epoch 1402, Loss: 0.1582646295428276, Final Batch Loss: 0.08473199605941772\n",
      "Epoch 1403, Loss: 0.18352139741182327, Final Batch Loss: 0.07140199840068817\n",
      "Epoch 1404, Loss: 0.1569097489118576, Final Batch Loss: 0.07997874170541763\n",
      "Epoch 1405, Loss: 0.1758955419063568, Final Batch Loss: 0.07579674571752548\n",
      "Epoch 1406, Loss: 0.12757541239261627, Final Batch Loss: 0.06727982312440872\n",
      "Epoch 1407, Loss: 0.1981082707643509, Final Batch Loss: 0.11477690190076828\n",
      "Epoch 1408, Loss: 0.21269062161445618, Final Batch Loss: 0.11509591341018677\n",
      "Epoch 1409, Loss: 0.17361312732100487, Final Batch Loss: 0.11745022237300873\n",
      "Epoch 1410, Loss: 0.17081915959715843, Final Batch Loss: 0.052459415048360825\n",
      "Epoch 1411, Loss: 0.21169482171535492, Final Batch Loss: 0.136672705411911\n",
      "Epoch 1412, Loss: 0.1616123467683792, Final Batch Loss: 0.08747874200344086\n",
      "Epoch 1413, Loss: 0.15779142826795578, Final Batch Loss: 0.07302065193653107\n",
      "Epoch 1414, Loss: 0.13917380571365356, Final Batch Loss: 0.0754888504743576\n",
      "Epoch 1415, Loss: 0.24697935581207275, Final Batch Loss: 0.12646439671516418\n",
      "Epoch 1416, Loss: 0.19803771376609802, Final Batch Loss: 0.07150343060493469\n",
      "Epoch 1417, Loss: 0.15551860630512238, Final Batch Loss: 0.080637127161026\n",
      "Epoch 1418, Loss: 0.15787244588136673, Final Batch Loss: 0.0697675421833992\n",
      "Epoch 1419, Loss: 0.1441861018538475, Final Batch Loss: 0.07402818650007248\n",
      "Epoch 1420, Loss: 0.12284798547625542, Final Batch Loss: 0.044418562203645706\n",
      "Epoch 1421, Loss: 0.17733397334814072, Final Batch Loss: 0.07629697024822235\n",
      "Epoch 1422, Loss: 0.12214190512895584, Final Batch Loss: 0.07316863536834717\n",
      "Epoch 1423, Loss: 0.16149353235960007, Final Batch Loss: 0.07616397738456726\n",
      "Epoch 1424, Loss: 0.21804282069206238, Final Batch Loss: 0.1221582293510437\n",
      "Epoch 1425, Loss: 0.15942135453224182, Final Batch Loss: 0.08453698456287384\n",
      "Epoch 1426, Loss: 0.15446027368307114, Final Batch Loss: 0.0828016996383667\n",
      "Epoch 1427, Loss: 0.12797992303967476, Final Batch Loss: 0.06016070768237114\n",
      "Epoch 1428, Loss: 0.14548597484827042, Final Batch Loss: 0.0493365079164505\n",
      "Epoch 1429, Loss: 0.1972389742732048, Final Batch Loss: 0.12144573032855988\n",
      "Epoch 1430, Loss: 0.19487819075584412, Final Batch Loss: 0.06407850980758667\n",
      "Epoch 1431, Loss: 0.342331126332283, Final Batch Loss: 0.2668933868408203\n",
      "Epoch 1432, Loss: 0.14090945199131966, Final Batch Loss: 0.0422171913087368\n",
      "Epoch 1433, Loss: 0.14297107607126236, Final Batch Loss: 0.0776522234082222\n",
      "Epoch 1434, Loss: 0.15456388145685196, Final Batch Loss: 0.08627213537693024\n",
      "Epoch 1435, Loss: 0.15915076434612274, Final Batch Loss: 0.0760449543595314\n",
      "Epoch 1436, Loss: 0.13650469481945038, Final Batch Loss: 0.07328184694051743\n",
      "Epoch 1437, Loss: 0.16964692622423172, Final Batch Loss: 0.09533656388521194\n",
      "Epoch 1438, Loss: 0.13528961688280106, Final Batch Loss: 0.06552145630121231\n",
      "Epoch 1439, Loss: 0.16992609202861786, Final Batch Loss: 0.08855174481868744\n",
      "Epoch 1440, Loss: 0.13906516134738922, Final Batch Loss: 0.07363361865282059\n",
      "Epoch 1441, Loss: 0.1600506827235222, Final Batch Loss: 0.0779910534620285\n",
      "Epoch 1442, Loss: 0.11124994978308678, Final Batch Loss: 0.03289670869708061\n",
      "Epoch 1443, Loss: 0.16586346924304962, Final Batch Loss: 0.07892265915870667\n",
      "Epoch 1444, Loss: 0.20799816399812698, Final Batch Loss: 0.11162277311086655\n",
      "Epoch 1445, Loss: 0.21998177468776703, Final Batch Loss: 0.08232153952121735\n",
      "Epoch 1446, Loss: 0.1407371200621128, Final Batch Loss: 0.05394328758120537\n",
      "Epoch 1447, Loss: 0.16060906648635864, Final Batch Loss: 0.08210104703903198\n",
      "Epoch 1448, Loss: 0.1681690588593483, Final Batch Loss: 0.09252653270959854\n",
      "Epoch 1449, Loss: 0.15043577551841736, Final Batch Loss: 0.07977163046598434\n",
      "Epoch 1450, Loss: 0.1450345292687416, Final Batch Loss: 0.05866522341966629\n",
      "Epoch 1451, Loss: 0.19657810032367706, Final Batch Loss: 0.12771457433700562\n",
      "Epoch 1452, Loss: 0.12701701000332832, Final Batch Loss: 0.07371141761541367\n",
      "Epoch 1453, Loss: 0.16118928045034409, Final Batch Loss: 0.07935066521167755\n",
      "Epoch 1454, Loss: 0.19788088649511337, Final Batch Loss: 0.10299372673034668\n",
      "Epoch 1455, Loss: 0.1659475862979889, Final Batch Loss: 0.09139536321163177\n",
      "Epoch 1456, Loss: 0.12852922454476357, Final Batch Loss: 0.056021351367235184\n",
      "Epoch 1457, Loss: 0.18411042541265488, Final Batch Loss: 0.10401298850774765\n",
      "Epoch 1458, Loss: 0.15535876527428627, Final Batch Loss: 0.05032285675406456\n",
      "Epoch 1459, Loss: 0.15305348485708237, Final Batch Loss: 0.06675797700881958\n",
      "Epoch 1460, Loss: 0.18438846990466118, Final Batch Loss: 0.12735587358474731\n",
      "Epoch 1461, Loss: 0.1674552783370018, Final Batch Loss: 0.09317869693040848\n",
      "Epoch 1462, Loss: 0.17079854756593704, Final Batch Loss: 0.07822542637586594\n",
      "Epoch 1463, Loss: 0.19288206845521927, Final Batch Loss: 0.11497138440608978\n",
      "Epoch 1464, Loss: 0.275750070810318, Final Batch Loss: 0.07156498730182648\n",
      "Epoch 1465, Loss: 0.14231500774621964, Final Batch Loss: 0.06272663176059723\n",
      "Epoch 1466, Loss: 0.19536864757537842, Final Batch Loss: 0.12463563680648804\n",
      "Epoch 1467, Loss: 0.11523162946105003, Final Batch Loss: 0.046860892325639725\n",
      "Epoch 1468, Loss: 0.11266974359750748, Final Batch Loss: 0.04333348572254181\n",
      "Epoch 1469, Loss: 0.16357458755373955, Final Batch Loss: 0.05889946594834328\n",
      "Epoch 1470, Loss: 0.12471383437514305, Final Batch Loss: 0.05603739246726036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1471, Loss: 0.12147499620914459, Final Batch Loss: 0.05868130177259445\n",
      "Epoch 1472, Loss: 0.17492516338825226, Final Batch Loss: 0.07980586588382721\n",
      "Epoch 1473, Loss: 0.12847768515348434, Final Batch Loss: 0.06450247019529343\n",
      "Epoch 1474, Loss: 0.18673409521579742, Final Batch Loss: 0.07770885527133942\n",
      "Epoch 1475, Loss: 0.140255406498909, Final Batch Loss: 0.07284348458051682\n",
      "Epoch 1476, Loss: 0.13822298496961594, Final Batch Loss: 0.07057151198387146\n",
      "Epoch 1477, Loss: 0.16189134120941162, Final Batch Loss: 0.05393163114786148\n",
      "Epoch 1478, Loss: 0.14600777253508568, Final Batch Loss: 0.09906742721796036\n",
      "Epoch 1479, Loss: 0.1690102145075798, Final Batch Loss: 0.08322697877883911\n",
      "Epoch 1480, Loss: 0.13259876519441605, Final Batch Loss: 0.06766204535961151\n",
      "Epoch 1481, Loss: 0.1689302995800972, Final Batch Loss: 0.0635632798075676\n",
      "Epoch 1482, Loss: 0.14996956288814545, Final Batch Loss: 0.08161409199237823\n",
      "Epoch 1483, Loss: 0.16246802359819412, Final Batch Loss: 0.06587719917297363\n",
      "Epoch 1484, Loss: 0.18967250734567642, Final Batch Loss: 0.07881006598472595\n",
      "Epoch 1485, Loss: 0.12798432260751724, Final Batch Loss: 0.05737251788377762\n",
      "Epoch 1486, Loss: 0.12798632308840752, Final Batch Loss: 0.04878968372941017\n",
      "Epoch 1487, Loss: 0.1299372836947441, Final Batch Loss: 0.0491328164935112\n",
      "Epoch 1488, Loss: 0.1360534429550171, Final Batch Loss: 0.07573478668928146\n",
      "Epoch 1489, Loss: 0.12919817119836807, Final Batch Loss: 0.06298530846834183\n",
      "Epoch 1490, Loss: 0.12990475818514824, Final Batch Loss: 0.05702510103583336\n",
      "Epoch 1491, Loss: 0.21415167301893234, Final Batch Loss: 0.14628151059150696\n",
      "Epoch 1492, Loss: 0.1471220627427101, Final Batch Loss: 0.0773351639509201\n",
      "Epoch 1493, Loss: 0.14449940249323845, Final Batch Loss: 0.08460509777069092\n",
      "Epoch 1494, Loss: 0.178685262799263, Final Batch Loss: 0.0926518440246582\n",
      "Epoch 1495, Loss: 0.15979238599538803, Final Batch Loss: 0.06814849376678467\n",
      "Epoch 1496, Loss: 0.1927649825811386, Final Batch Loss: 0.08595380187034607\n",
      "Epoch 1497, Loss: 0.16253656148910522, Final Batch Loss: 0.08171766996383667\n",
      "Epoch 1498, Loss: 0.1448284164071083, Final Batch Loss: 0.07393884658813477\n",
      "Epoch 1499, Loss: 0.16660049557685852, Final Batch Loss: 0.0962609350681305\n",
      "Epoch 1500, Loss: 0.18887223303318024, Final Batch Loss: 0.11156240850687027\n",
      "Epoch 1501, Loss: 0.1306014060974121, Final Batch Loss: 0.04416632652282715\n",
      "Epoch 1502, Loss: 0.19130060821771622, Final Batch Loss: 0.09592659771442413\n",
      "Epoch 1503, Loss: 0.16286791861057281, Final Batch Loss: 0.09143450856208801\n",
      "Epoch 1504, Loss: 0.1981280818581581, Final Batch Loss: 0.07600777596235275\n",
      "Epoch 1505, Loss: 0.149504866451025, Final Batch Loss: 0.04047417268157005\n",
      "Epoch 1506, Loss: 0.12785295397043228, Final Batch Loss: 0.051427073776721954\n",
      "Epoch 1507, Loss: 0.1652262583374977, Final Batch Loss: 0.08710755407810211\n",
      "Epoch 1508, Loss: 0.16207391396164894, Final Batch Loss: 0.12134581059217453\n",
      "Epoch 1509, Loss: 0.15933576971292496, Final Batch Loss: 0.08508498221635818\n",
      "Epoch 1510, Loss: 0.18344080448150635, Final Batch Loss: 0.06701784580945969\n",
      "Epoch 1511, Loss: 0.18673980981111526, Final Batch Loss: 0.06850293278694153\n",
      "Epoch 1512, Loss: 0.14797713607549667, Final Batch Loss: 0.0869060605764389\n",
      "Epoch 1513, Loss: 0.11977750435471535, Final Batch Loss: 0.057791806757450104\n",
      "Epoch 1514, Loss: 0.1437230035662651, Final Batch Loss: 0.07481543719768524\n",
      "Epoch 1515, Loss: 0.15041384100914001, Final Batch Loss: 0.06317870318889618\n",
      "Epoch 1516, Loss: 0.1292702630162239, Final Batch Loss: 0.061238810420036316\n",
      "Epoch 1517, Loss: 0.1532154567539692, Final Batch Loss: 0.05615125223994255\n",
      "Epoch 1518, Loss: 0.17797834426164627, Final Batch Loss: 0.08478975296020508\n",
      "Epoch 1519, Loss: 0.1411735713481903, Final Batch Loss: 0.06349024921655655\n",
      "Epoch 1520, Loss: 0.15303843468427658, Final Batch Loss: 0.08986171334981918\n",
      "Epoch 1521, Loss: 0.11950507387518883, Final Batch Loss: 0.06599126756191254\n",
      "Epoch 1522, Loss: 0.18192533403635025, Final Batch Loss: 0.07154267281293869\n",
      "Epoch 1523, Loss: 0.17101576179265976, Final Batch Loss: 0.0872616320848465\n",
      "Epoch 1524, Loss: 0.15349776297807693, Final Batch Loss: 0.06258280575275421\n",
      "Epoch 1525, Loss: 0.16217147558927536, Final Batch Loss: 0.09404965490102768\n",
      "Epoch 1526, Loss: 0.19082216173410416, Final Batch Loss: 0.12500931322574615\n",
      "Epoch 1527, Loss: 0.13881773501634598, Final Batch Loss: 0.0514153391122818\n",
      "Epoch 1528, Loss: 0.18314774334430695, Final Batch Loss: 0.07852742075920105\n",
      "Epoch 1529, Loss: 0.11227696016430855, Final Batch Loss: 0.06026921048760414\n",
      "Epoch 1530, Loss: 0.13408412784337997, Final Batch Loss: 0.06475337594747543\n",
      "Epoch 1531, Loss: 0.1303028166294098, Final Batch Loss: 0.036088794469833374\n",
      "Epoch 1532, Loss: 0.1326254978775978, Final Batch Loss: 0.06684645265340805\n",
      "Epoch 1533, Loss: 0.15562725067138672, Final Batch Loss: 0.07573910057544708\n",
      "Epoch 1534, Loss: 0.18231260031461716, Final Batch Loss: 0.10662203282117844\n",
      "Epoch 1535, Loss: 0.18887712061405182, Final Batch Loss: 0.11531616002321243\n",
      "Epoch 1536, Loss: 0.14527085423469543, Final Batch Loss: 0.0543215274810791\n",
      "Epoch 1537, Loss: 0.14534400403499603, Final Batch Loss: 0.07947276532649994\n",
      "Epoch 1538, Loss: 0.13326993212103844, Final Batch Loss: 0.06193936988711357\n",
      "Epoch 1539, Loss: 0.16548586264252663, Final Batch Loss: 0.10871750861406326\n",
      "Epoch 1540, Loss: 0.16274022683501244, Final Batch Loss: 0.05001154914498329\n",
      "Epoch 1541, Loss: 0.1360267996788025, Final Batch Loss: 0.05928397178649902\n",
      "Epoch 1542, Loss: 0.1171375922858715, Final Batch Loss: 0.0668887048959732\n",
      "Epoch 1543, Loss: 0.14456599950790405, Final Batch Loss: 0.06686406582593918\n",
      "Epoch 1544, Loss: 0.14170565828680992, Final Batch Loss: 0.08177158236503601\n",
      "Epoch 1545, Loss: 0.14667700976133347, Final Batch Loss: 0.08396334201097488\n",
      "Epoch 1546, Loss: 0.13924859464168549, Final Batch Loss: 0.06303638219833374\n",
      "Epoch 1547, Loss: 0.14500118792057037, Final Batch Loss: 0.06236114352941513\n",
      "Epoch 1548, Loss: 0.15875506401062012, Final Batch Loss: 0.0452568456530571\n",
      "Epoch 1549, Loss: 0.15762997418642044, Final Batch Loss: 0.07185646146535873\n",
      "Epoch 1550, Loss: 0.16601412743330002, Final Batch Loss: 0.09040234237909317\n",
      "Epoch 1551, Loss: 0.21343232691287994, Final Batch Loss: 0.07614566385746002\n",
      "Epoch 1552, Loss: 0.13218646124005318, Final Batch Loss: 0.05247412249445915\n",
      "Epoch 1553, Loss: 0.15622912347316742, Final Batch Loss: 0.09017056226730347\n",
      "Epoch 1554, Loss: 0.16147399693727493, Final Batch Loss: 0.09025069326162338\n",
      "Epoch 1555, Loss: 0.18443867936730385, Final Batch Loss: 0.12434151023626328\n",
      "Epoch 1556, Loss: 0.16988851130008698, Final Batch Loss: 0.09477955102920532\n",
      "Epoch 1557, Loss: 0.20413151383399963, Final Batch Loss: 0.15742400288581848\n",
      "Epoch 1558, Loss: 0.2115846574306488, Final Batch Loss: 0.10936076194047928\n",
      "Epoch 1559, Loss: 0.16013305634260178, Final Batch Loss: 0.06831911206245422\n",
      "Epoch 1560, Loss: 0.20036916434764862, Final Batch Loss: 0.11816966533660889\n",
      "Epoch 1561, Loss: 0.12671048939228058, Final Batch Loss: 0.0602225735783577\n",
      "Epoch 1562, Loss: 0.12611890956759453, Final Batch Loss: 0.07524337619543076\n",
      "Epoch 1563, Loss: 0.148441880941391, Final Batch Loss: 0.06145676225423813\n",
      "Epoch 1564, Loss: 0.1645415648818016, Final Batch Loss: 0.08845634013414383\n",
      "Epoch 1565, Loss: 0.17238695919513702, Final Batch Loss: 0.09003892540931702\n",
      "Epoch 1566, Loss: 0.1903357431292534, Final Batch Loss: 0.10380608588457108\n",
      "Epoch 1567, Loss: 0.17695051431655884, Final Batch Loss: 0.08108481764793396\n",
      "Epoch 1568, Loss: 0.14291784167289734, Final Batch Loss: 0.08461876213550568\n",
      "Epoch 1569, Loss: 0.17519265413284302, Final Batch Loss: 0.08848945051431656\n",
      "Epoch 1570, Loss: 0.14171678572893143, Final Batch Loss: 0.06412830203771591\n",
      "Epoch 1571, Loss: 0.1395389884710312, Final Batch Loss: 0.07691796869039536\n",
      "Epoch 1572, Loss: 0.17746485024690628, Final Batch Loss: 0.09733982384204865\n",
      "Epoch 1573, Loss: 0.14957891404628754, Final Batch Loss: 0.08105648308992386\n",
      "Epoch 1574, Loss: 0.2061387374997139, Final Batch Loss: 0.09779457747936249\n",
      "Epoch 1575, Loss: 0.1824505850672722, Final Batch Loss: 0.09367446601390839\n",
      "Epoch 1576, Loss: 0.18574140220880508, Final Batch Loss: 0.10421816259622574\n",
      "Epoch 1577, Loss: 0.16689442098140717, Final Batch Loss: 0.10392960160970688\n",
      "Epoch 1578, Loss: 0.15142501518130302, Final Batch Loss: 0.05824238434433937\n",
      "Epoch 1579, Loss: 0.12770384177565575, Final Batch Loss: 0.051211316138505936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1580, Loss: 0.1633954718708992, Final Batch Loss: 0.09160000085830688\n",
      "Epoch 1581, Loss: 0.1396026760339737, Final Batch Loss: 0.06414134055376053\n",
      "Epoch 1582, Loss: 0.12781773507595062, Final Batch Loss: 0.05514458566904068\n",
      "Epoch 1583, Loss: 0.11638325825333595, Final Batch Loss: 0.06701056659221649\n",
      "Epoch 1584, Loss: 0.19931402802467346, Final Batch Loss: 0.10116854310035706\n",
      "Epoch 1585, Loss: 0.14170213043689728, Final Batch Loss: 0.0795259103178978\n",
      "Epoch 1586, Loss: 0.1359732411801815, Final Batch Loss: 0.06120249256491661\n",
      "Epoch 1587, Loss: 0.16290035843849182, Final Batch Loss: 0.08351565152406693\n",
      "Epoch 1588, Loss: 0.11014934629201889, Final Batch Loss: 0.06498442590236664\n",
      "Epoch 1589, Loss: 0.12752652540802956, Final Batch Loss: 0.06176215782761574\n",
      "Epoch 1590, Loss: 0.16162516921758652, Final Batch Loss: 0.08685968816280365\n",
      "Epoch 1591, Loss: 0.1437819041311741, Final Batch Loss: 0.05699371173977852\n",
      "Epoch 1592, Loss: 0.1645968034863472, Final Batch Loss: 0.09159265458583832\n",
      "Epoch 1593, Loss: 0.16553378105163574, Final Batch Loss: 0.08713887631893158\n",
      "Epoch 1594, Loss: 0.23736242204904556, Final Batch Loss: 0.18937113881111145\n",
      "Epoch 1595, Loss: 0.17169908434152603, Final Batch Loss: 0.0636843889951706\n",
      "Epoch 1596, Loss: 0.1515365019440651, Final Batch Loss: 0.07538268715143204\n",
      "Epoch 1597, Loss: 0.14162491634488106, Final Batch Loss: 0.054784808307886124\n",
      "Epoch 1598, Loss: 0.15184395760297775, Final Batch Loss: 0.05948071926832199\n",
      "Epoch 1599, Loss: 0.13899894803762436, Final Batch Loss: 0.07104730606079102\n",
      "Epoch 1600, Loss: 0.1654282584786415, Final Batch Loss: 0.07864491641521454\n",
      "Epoch 1601, Loss: 0.14715340733528137, Final Batch Loss: 0.09824278205633163\n",
      "Epoch 1602, Loss: 0.14339717105031013, Final Batch Loss: 0.0820535272359848\n",
      "Epoch 1603, Loss: 0.14320862293243408, Final Batch Loss: 0.07478602230548859\n",
      "Epoch 1604, Loss: 0.14857835322618484, Final Batch Loss: 0.08143778890371323\n",
      "Epoch 1605, Loss: 0.1107601597905159, Final Batch Loss: 0.0724722146987915\n",
      "Epoch 1606, Loss: 0.12832342833280563, Final Batch Loss: 0.050150372087955475\n",
      "Epoch 1607, Loss: 0.1366516798734665, Final Batch Loss: 0.07090044021606445\n",
      "Epoch 1608, Loss: 0.13627023249864578, Final Batch Loss: 0.0652802512049675\n",
      "Epoch 1609, Loss: 0.1276489458978176, Final Batch Loss: 0.06603612005710602\n",
      "Epoch 1610, Loss: 0.13494138419628143, Final Batch Loss: 0.07265396416187286\n",
      "Epoch 1611, Loss: 0.15172049775719643, Final Batch Loss: 0.09285181015729904\n",
      "Epoch 1612, Loss: 0.1505596712231636, Final Batch Loss: 0.09559999406337738\n",
      "Epoch 1613, Loss: 0.20757456868886948, Final Batch Loss: 0.11618317663669586\n",
      "Epoch 1614, Loss: 0.15650396794080734, Final Batch Loss: 0.10510922223329544\n",
      "Epoch 1615, Loss: 0.16398701444268227, Final Batch Loss: 0.06034295633435249\n",
      "Epoch 1616, Loss: 0.15491119027137756, Final Batch Loss: 0.08921966701745987\n",
      "Epoch 1617, Loss: 0.2233964279294014, Final Batch Loss: 0.13549312949180603\n",
      "Epoch 1618, Loss: 0.1460881605744362, Final Batch Loss: 0.08262890577316284\n",
      "Epoch 1619, Loss: 0.1433153934776783, Final Batch Loss: 0.08089278638362885\n",
      "Epoch 1620, Loss: 0.21877111494541168, Final Batch Loss: 0.09320439398288727\n",
      "Epoch 1621, Loss: 0.13390780612826347, Final Batch Loss: 0.06230765953660011\n",
      "Epoch 1622, Loss: 0.11786425113677979, Final Batch Loss: 0.0483369380235672\n",
      "Epoch 1623, Loss: 0.1433686837553978, Final Batch Loss: 0.07633976638317108\n",
      "Epoch 1624, Loss: 0.13105414807796478, Final Batch Loss: 0.05890659987926483\n",
      "Epoch 1625, Loss: 0.1443599835038185, Final Batch Loss: 0.09263031929731369\n",
      "Epoch 1626, Loss: 0.13530759885907173, Final Batch Loss: 0.04757115617394447\n",
      "Epoch 1627, Loss: 0.1389908418059349, Final Batch Loss: 0.06903626769781113\n",
      "Epoch 1628, Loss: 0.1740327551960945, Final Batch Loss: 0.08828223496675491\n",
      "Epoch 1629, Loss: 0.13834219798445702, Final Batch Loss: 0.0766310840845108\n",
      "Epoch 1630, Loss: 0.13802092522382736, Final Batch Loss: 0.07869036495685577\n",
      "Epoch 1631, Loss: 0.1263141855597496, Final Batch Loss: 0.058600470423698425\n",
      "Epoch 1632, Loss: 0.13633698225021362, Final Batch Loss: 0.04147829860448837\n",
      "Epoch 1633, Loss: 0.14404648169875145, Final Batch Loss: 0.06166804954409599\n",
      "Epoch 1634, Loss: 0.18409086018800735, Final Batch Loss: 0.11937272548675537\n",
      "Epoch 1635, Loss: 0.151779405772686, Final Batch Loss: 0.084243543446064\n",
      "Epoch 1636, Loss: 0.13949629664421082, Final Batch Loss: 0.07122310996055603\n",
      "Epoch 1637, Loss: 0.1262650303542614, Final Batch Loss: 0.04610322043299675\n",
      "Epoch 1638, Loss: 0.1268564835190773, Final Batch Loss: 0.06263376027345657\n",
      "Epoch 1639, Loss: 0.17264381796121597, Final Batch Loss: 0.08231443911790848\n",
      "Epoch 1640, Loss: 0.10750636830925941, Final Batch Loss: 0.06423138082027435\n",
      "Epoch 1641, Loss: 0.1601816676557064, Final Batch Loss: 0.10992460697889328\n",
      "Epoch 1642, Loss: 0.1228444054722786, Final Batch Loss: 0.05450158566236496\n",
      "Epoch 1643, Loss: 0.14926446974277496, Final Batch Loss: 0.08263147622346878\n",
      "Epoch 1644, Loss: 0.13823145627975464, Final Batch Loss: 0.060246050357818604\n",
      "Epoch 1645, Loss: 0.1535528004169464, Final Batch Loss: 0.11545394361019135\n",
      "Epoch 1646, Loss: 0.15619174391031265, Final Batch Loss: 0.08629400283098221\n",
      "Epoch 1647, Loss: 0.13777538761496544, Final Batch Loss: 0.08604069799184799\n",
      "Epoch 1648, Loss: 0.17638514935970306, Final Batch Loss: 0.07905604690313339\n",
      "Epoch 1649, Loss: 0.17014892399311066, Final Batch Loss: 0.10018092393875122\n",
      "Epoch 1650, Loss: 0.14274593442678452, Final Batch Loss: 0.08215271681547165\n",
      "Epoch 1651, Loss: 0.12830450758337975, Final Batch Loss: 0.06920090317726135\n",
      "Epoch 1652, Loss: 0.1266644261777401, Final Batch Loss: 0.05598389729857445\n",
      "Epoch 1653, Loss: 0.14688120782375336, Final Batch Loss: 0.08281975984573364\n",
      "Epoch 1654, Loss: 0.12974010035395622, Final Batch Loss: 0.058300312608480453\n",
      "Epoch 1655, Loss: 0.1012127473950386, Final Batch Loss: 0.03290931135416031\n",
      "Epoch 1656, Loss: 0.10296916216611862, Final Batch Loss: 0.05571071803569794\n",
      "Epoch 1657, Loss: 0.1312260851264, Final Batch Loss: 0.04246595501899719\n",
      "Epoch 1658, Loss: 0.13798247650265694, Final Batch Loss: 0.05369963124394417\n",
      "Epoch 1659, Loss: 0.20762280374765396, Final Batch Loss: 0.12232980132102966\n",
      "Epoch 1660, Loss: 0.15719640627503395, Final Batch Loss: 0.05876981094479561\n",
      "Epoch 1661, Loss: 0.163956206291914, Final Batch Loss: 0.05718569830060005\n",
      "Epoch 1662, Loss: 0.12956712767481804, Final Batch Loss: 0.054211217910051346\n",
      "Epoch 1663, Loss: 0.17651952803134918, Final Batch Loss: 0.11586331576108932\n",
      "Epoch 1664, Loss: 0.20078246295452118, Final Batch Loss: 0.06793442368507385\n",
      "Epoch 1665, Loss: 0.14318440854549408, Final Batch Loss: 0.07865351438522339\n",
      "Epoch 1666, Loss: 0.1322629526257515, Final Batch Loss: 0.061449192464351654\n",
      "Epoch 1667, Loss: 0.1001550629734993, Final Batch Loss: 0.04769016429781914\n",
      "Epoch 1668, Loss: 0.1323588639497757, Final Batch Loss: 0.05816308408975601\n",
      "Epoch 1669, Loss: 0.13187966495752335, Final Batch Loss: 0.03861291706562042\n",
      "Epoch 1670, Loss: 0.12137575447559357, Final Batch Loss: 0.07144795358181\n",
      "Epoch 1671, Loss: 0.10080141946673393, Final Batch Loss: 0.05109645053744316\n",
      "Epoch 1672, Loss: 0.10589220747351646, Final Batch Loss: 0.05526544526219368\n",
      "Epoch 1673, Loss: 0.13661913201212883, Final Batch Loss: 0.04815985634922981\n",
      "Epoch 1674, Loss: 0.17555693536996841, Final Batch Loss: 0.10055539011955261\n",
      "Epoch 1675, Loss: 0.12507976964116096, Final Batch Loss: 0.057805370539426804\n",
      "Epoch 1676, Loss: 0.12089133635163307, Final Batch Loss: 0.07253169268369675\n",
      "Epoch 1677, Loss: 0.12320227548480034, Final Batch Loss: 0.07457330822944641\n",
      "Epoch 1678, Loss: 0.1488584652543068, Final Batch Loss: 0.06893802434206009\n",
      "Epoch 1679, Loss: 0.17576079070568085, Final Batch Loss: 0.102354995906353\n",
      "Epoch 1680, Loss: 0.2050524465739727, Final Batch Loss: 0.15352948009967804\n",
      "Epoch 1681, Loss: 0.12910575047135353, Final Batch Loss: 0.08987252414226532\n",
      "Epoch 1682, Loss: 0.12802308797836304, Final Batch Loss: 0.0567140132188797\n",
      "Epoch 1683, Loss: 0.14676206558942795, Final Batch Loss: 0.09974627196788788\n",
      "Epoch 1684, Loss: 0.09541617706418037, Final Batch Loss: 0.04974553361535072\n",
      "Epoch 1685, Loss: 0.17539750784635544, Final Batch Loss: 0.11001481860876083\n",
      "Epoch 1686, Loss: 0.15095872431993484, Final Batch Loss: 0.08788653463125229\n",
      "Epoch 1687, Loss: 0.12712058797478676, Final Batch Loss: 0.06526544690132141\n",
      "Epoch 1688, Loss: 0.1432509496808052, Final Batch Loss: 0.05321416258811951\n",
      "Epoch 1689, Loss: 0.12190720811486244, Final Batch Loss: 0.06864719092845917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1690, Loss: 0.18237623199820518, Final Batch Loss: 0.1262774020433426\n",
      "Epoch 1691, Loss: 0.11372365802526474, Final Batch Loss: 0.06110703945159912\n",
      "Epoch 1692, Loss: 0.14551037549972534, Final Batch Loss: 0.06721390783786774\n",
      "Epoch 1693, Loss: 0.14522280171513557, Final Batch Loss: 0.06037226691842079\n",
      "Epoch 1694, Loss: 0.09893084689974785, Final Batch Loss: 0.033695828169584274\n",
      "Epoch 1695, Loss: 0.16098738461732864, Final Batch Loss: 0.09056418389081955\n",
      "Epoch 1696, Loss: 0.16197291761636734, Final Batch Loss: 0.08866188675165176\n",
      "Epoch 1697, Loss: 0.13877403736114502, Final Batch Loss: 0.05813354253768921\n",
      "Epoch 1698, Loss: 0.17428619414567947, Final Batch Loss: 0.0664091631770134\n",
      "Epoch 1699, Loss: 0.11285384371876717, Final Batch Loss: 0.05126431956887245\n",
      "Epoch 1700, Loss: 0.1880076751112938, Final Batch Loss: 0.0938543900847435\n",
      "Epoch 1701, Loss: 0.12813420221209526, Final Batch Loss: 0.051986243575811386\n",
      "Epoch 1702, Loss: 0.13424108177423477, Final Batch Loss: 0.05909782648086548\n",
      "Epoch 1703, Loss: 0.15737896412611008, Final Batch Loss: 0.08973405510187149\n",
      "Epoch 1704, Loss: 0.14610178023576736, Final Batch Loss: 0.08354204148054123\n",
      "Epoch 1705, Loss: 0.14060253649950027, Final Batch Loss: 0.06666670739650726\n",
      "Epoch 1706, Loss: 0.14726188778877258, Final Batch Loss: 0.06511885672807693\n",
      "Epoch 1707, Loss: 0.152626670897007, Final Batch Loss: 0.07595469802618027\n",
      "Epoch 1708, Loss: 0.12023712694644928, Final Batch Loss: 0.05022410303354263\n",
      "Epoch 1709, Loss: 0.10597295686602592, Final Batch Loss: 0.05655599385499954\n",
      "Epoch 1710, Loss: 0.1434764787554741, Final Batch Loss: 0.07592171430587769\n",
      "Epoch 1711, Loss: 0.13317234069108963, Final Batch Loss: 0.07219231128692627\n",
      "Epoch 1712, Loss: 0.14493118226528168, Final Batch Loss: 0.08159841597080231\n",
      "Epoch 1713, Loss: 0.18070663139224052, Final Batch Loss: 0.1397443413734436\n",
      "Epoch 1714, Loss: 0.10835275426506996, Final Batch Loss: 0.039181988686323166\n",
      "Epoch 1715, Loss: 0.16708924248814583, Final Batch Loss: 0.05775368586182594\n",
      "Epoch 1716, Loss: 0.14796500280499458, Final Batch Loss: 0.05738420411944389\n",
      "Epoch 1717, Loss: 0.12692561373114586, Final Batch Loss: 0.03956448659300804\n",
      "Epoch 1718, Loss: 0.11694195494055748, Final Batch Loss: 0.05552519112825394\n",
      "Epoch 1719, Loss: 0.12705150246620178, Final Batch Loss: 0.04181968420743942\n",
      "Epoch 1720, Loss: 0.17833708971738815, Final Batch Loss: 0.11567029356956482\n",
      "Epoch 1721, Loss: 0.13901909068226814, Final Batch Loss: 0.05644789710640907\n",
      "Epoch 1722, Loss: 0.15084851533174515, Final Batch Loss: 0.07979611307382584\n",
      "Epoch 1723, Loss: 0.12024588510394096, Final Batch Loss: 0.06624031811952591\n",
      "Epoch 1724, Loss: 0.13037094846367836, Final Batch Loss: 0.05889015272259712\n",
      "Epoch 1725, Loss: 0.11616034805774689, Final Batch Loss: 0.050602056086063385\n",
      "Epoch 1726, Loss: 0.15468822419643402, Final Batch Loss: 0.07105737179517746\n",
      "Epoch 1727, Loss: 0.10211165621876717, Final Batch Loss: 0.05388106033205986\n",
      "Epoch 1728, Loss: 0.15534500777721405, Final Batch Loss: 0.08464693278074265\n",
      "Epoch 1729, Loss: 0.16356037557125092, Final Batch Loss: 0.08935600519180298\n",
      "Epoch 1730, Loss: 0.11291177198290825, Final Batch Loss: 0.06289642304182053\n",
      "Epoch 1731, Loss: 0.19691597670316696, Final Batch Loss: 0.06535186618566513\n",
      "Epoch 1732, Loss: 0.1671598255634308, Final Batch Loss: 0.059722356498241425\n",
      "Epoch 1733, Loss: 0.1279721036553383, Final Batch Loss: 0.07268076390028\n",
      "Epoch 1734, Loss: 0.10743515565991402, Final Batch Loss: 0.06549624353647232\n",
      "Epoch 1735, Loss: 0.1358732357621193, Final Batch Loss: 0.07302779704332352\n",
      "Epoch 1736, Loss: 0.18863126635551453, Final Batch Loss: 0.1034918874502182\n",
      "Epoch 1737, Loss: 0.11772453412413597, Final Batch Loss: 0.05630117654800415\n",
      "Epoch 1738, Loss: 0.17714227735996246, Final Batch Loss: 0.1030581071972847\n",
      "Epoch 1739, Loss: 0.1294868290424347, Final Batch Loss: 0.05828230828046799\n",
      "Epoch 1740, Loss: 0.15291503444314003, Final Batch Loss: 0.049508336931467056\n",
      "Epoch 1741, Loss: 0.16257337480783463, Final Batch Loss: 0.10417410731315613\n",
      "Epoch 1742, Loss: 0.138231061398983, Final Batch Loss: 0.07318779081106186\n",
      "Epoch 1743, Loss: 0.1371746063232422, Final Batch Loss: 0.07474487274885178\n",
      "Epoch 1744, Loss: 0.13143707066774368, Final Batch Loss: 0.0641072541475296\n",
      "Epoch 1745, Loss: 0.14691049605607986, Final Batch Loss: 0.07653121650218964\n",
      "Epoch 1746, Loss: 0.13511048257350922, Final Batch Loss: 0.05501826852560043\n",
      "Epoch 1747, Loss: 0.1588183343410492, Final Batch Loss: 0.09643640369176865\n",
      "Epoch 1748, Loss: 0.16231293976306915, Final Batch Loss: 0.09528367966413498\n",
      "Epoch 1749, Loss: 0.10938043892383575, Final Batch Loss: 0.049915798008441925\n",
      "Epoch 1750, Loss: 0.15277602896094322, Final Batch Loss: 0.05825883522629738\n",
      "Epoch 1751, Loss: 0.15632760152220726, Final Batch Loss: 0.11405694484710693\n",
      "Epoch 1752, Loss: 0.15393982082605362, Final Batch Loss: 0.07538449764251709\n",
      "Epoch 1753, Loss: 0.16091881692409515, Final Batch Loss: 0.09279049932956696\n",
      "Epoch 1754, Loss: 0.14698072895407677, Final Batch Loss: 0.05482594296336174\n",
      "Epoch 1755, Loss: 0.14501143991947174, Final Batch Loss: 0.09727871417999268\n",
      "Epoch 1756, Loss: 0.12227942794561386, Final Batch Loss: 0.06828662008047104\n",
      "Epoch 1757, Loss: 0.1347297467291355, Final Batch Loss: 0.06069951876997948\n",
      "Epoch 1758, Loss: 0.13415276631712914, Final Batch Loss: 0.07870899885892868\n",
      "Epoch 1759, Loss: 0.10586052760481834, Final Batch Loss: 0.05035918205976486\n",
      "Epoch 1760, Loss: 0.11707385256886482, Final Batch Loss: 0.059026993811130524\n",
      "Epoch 1761, Loss: 0.1387002095580101, Final Batch Loss: 0.07725979387760162\n",
      "Epoch 1762, Loss: 0.13196631520986557, Final Batch Loss: 0.07291407138109207\n",
      "Epoch 1763, Loss: 0.16090421006083488, Final Batch Loss: 0.10537731647491455\n",
      "Epoch 1764, Loss: 0.13202692568302155, Final Batch Loss: 0.05682747811079025\n",
      "Epoch 1765, Loss: 0.23759926855564117, Final Batch Loss: 0.17455384135246277\n",
      "Epoch 1766, Loss: 0.13549837097525597, Final Batch Loss: 0.08657494932413101\n",
      "Epoch 1767, Loss: 0.12941007316112518, Final Batch Loss: 0.06689852476119995\n",
      "Epoch 1768, Loss: 0.12805626541376114, Final Batch Loss: 0.04113950580358505\n",
      "Epoch 1769, Loss: 0.19271393865346909, Final Batch Loss: 0.07861153781414032\n",
      "Epoch 1770, Loss: 0.16864906251430511, Final Batch Loss: 0.08261212706565857\n",
      "Epoch 1771, Loss: 0.15230119228363037, Final Batch Loss: 0.06882578134536743\n",
      "Epoch 1772, Loss: 0.16525767371058464, Final Batch Loss: 0.052241552621126175\n",
      "Epoch 1773, Loss: 0.12594666332006454, Final Batch Loss: 0.055215463042259216\n",
      "Epoch 1774, Loss: 0.12556732073426247, Final Batch Loss: 0.059978585690259933\n",
      "Epoch 1775, Loss: 0.14679066091775894, Final Batch Loss: 0.08787903189659119\n",
      "Epoch 1776, Loss: 0.13056597486138344, Final Batch Loss: 0.07989794760942459\n",
      "Epoch 1777, Loss: 0.15391650795936584, Final Batch Loss: 0.09781456738710403\n",
      "Epoch 1778, Loss: 0.33062325045466423, Final Batch Loss: 0.2911401093006134\n",
      "Epoch 1779, Loss: 0.12712238729000092, Final Batch Loss: 0.06502372771501541\n",
      "Epoch 1780, Loss: 0.15008657425642014, Final Batch Loss: 0.08595007658004761\n",
      "Epoch 1781, Loss: 0.10969888418912888, Final Batch Loss: 0.054948825389146805\n",
      "Epoch 1782, Loss: 0.16711311787366867, Final Batch Loss: 0.08867544680833817\n",
      "Epoch 1783, Loss: 0.14414899051189423, Final Batch Loss: 0.07416582107543945\n",
      "Epoch 1784, Loss: 0.14535048604011536, Final Batch Loss: 0.0991118773818016\n",
      "Epoch 1785, Loss: 0.11651163548231125, Final Batch Loss: 0.04662267118692398\n",
      "Epoch 1786, Loss: 0.11365663632750511, Final Batch Loss: 0.057870667427778244\n",
      "Epoch 1787, Loss: 0.10777543112635612, Final Batch Loss: 0.05866320803761482\n",
      "Epoch 1788, Loss: 0.16167736798524857, Final Batch Loss: 0.06840478628873825\n",
      "Epoch 1789, Loss: 0.1629297472536564, Final Batch Loss: 0.1203761026263237\n",
      "Epoch 1790, Loss: 0.13229145854711533, Final Batch Loss: 0.06299038231372833\n",
      "Epoch 1791, Loss: 0.1392582431435585, Final Batch Loss: 0.07755199074745178\n",
      "Epoch 1792, Loss: 0.12803990021348, Final Batch Loss: 0.06635615229606628\n",
      "Epoch 1793, Loss: 0.12951184809207916, Final Batch Loss: 0.05594007670879364\n",
      "Epoch 1794, Loss: 0.11094250902533531, Final Batch Loss: 0.06311922520399094\n",
      "Epoch 1795, Loss: 0.1718166545033455, Final Batch Loss: 0.09393400698900223\n",
      "Epoch 1796, Loss: 0.14403437823057175, Final Batch Loss: 0.057024553418159485\n",
      "Epoch 1797, Loss: 0.11477325111627579, Final Batch Loss: 0.03719913214445114\n",
      "Epoch 1798, Loss: 0.15105173364281654, Final Batch Loss: 0.09472960233688354\n",
      "Epoch 1799, Loss: 0.13144893944263458, Final Batch Loss: 0.06988832354545593\n",
      "Epoch 1800, Loss: 0.10493279248476028, Final Batch Loss: 0.03339199721813202\n",
      "Epoch 1801, Loss: 0.10703397914767265, Final Batch Loss: 0.05231348052620888\n",
      "Epoch 1802, Loss: 0.17308512330055237, Final Batch Loss: 0.09542758762836456\n",
      "Epoch 1803, Loss: 0.18023331463336945, Final Batch Loss: 0.05883113294839859\n",
      "Epoch 1804, Loss: 0.12644356489181519, Final Batch Loss: 0.04746653884649277\n",
      "Epoch 1805, Loss: 0.13242016732692719, Final Batch Loss: 0.05594673007726669\n",
      "Epoch 1806, Loss: 0.12737957760691643, Final Batch Loss: 0.05292130634188652\n",
      "Epoch 1807, Loss: 0.1901058331131935, Final Batch Loss: 0.1113213300704956\n",
      "Epoch 1808, Loss: 0.13715213537216187, Final Batch Loss: 0.08894973993301392\n",
      "Epoch 1809, Loss: 0.1708574891090393, Final Batch Loss: 0.08063830435276031\n",
      "Epoch 1810, Loss: 0.10974246263504028, Final Batch Loss: 0.059073787182569504\n",
      "Epoch 1811, Loss: 0.13128668814897537, Final Batch Loss: 0.06808540225028992\n",
      "Epoch 1812, Loss: 0.16301561146974564, Final Batch Loss: 0.06385479122400284\n",
      "Epoch 1813, Loss: 0.16556593775749207, Final Batch Loss: 0.09250590205192566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1814, Loss: 0.1734277494251728, Final Batch Loss: 0.12735268473625183\n",
      "Epoch 1815, Loss: 0.11881161481142044, Final Batch Loss: 0.05365845561027527\n",
      "Epoch 1816, Loss: 0.15099936723709106, Final Batch Loss: 0.05013585835695267\n",
      "Epoch 1817, Loss: 0.1777506172657013, Final Batch Loss: 0.1111457496881485\n",
      "Epoch 1818, Loss: 0.12651702761650085, Final Batch Loss: 0.06580908596515656\n",
      "Epoch 1819, Loss: 0.10698190703988075, Final Batch Loss: 0.05311541631817818\n",
      "Epoch 1820, Loss: 0.12131648883223534, Final Batch Loss: 0.07754524052143097\n",
      "Epoch 1821, Loss: 0.12257317453622818, Final Batch Loss: 0.05838096886873245\n",
      "Epoch 1822, Loss: 0.13234521076083183, Final Batch Loss: 0.047343116253614426\n",
      "Epoch 1823, Loss: 0.1609572097659111, Final Batch Loss: 0.09965822845697403\n",
      "Epoch 1824, Loss: 0.15214965119957924, Final Batch Loss: 0.057954806834459305\n",
      "Epoch 1825, Loss: 0.14364340156316757, Final Batch Loss: 0.06782640516757965\n",
      "Epoch 1826, Loss: 0.15348919481039047, Final Batch Loss: 0.06197743862867355\n",
      "Epoch 1827, Loss: 0.1510990485548973, Final Batch Loss: 0.07143280655145645\n",
      "Epoch 1828, Loss: 0.14136972650885582, Final Batch Loss: 0.08144975453615189\n",
      "Epoch 1829, Loss: 0.11254648864269257, Final Batch Loss: 0.044870585203170776\n",
      "Epoch 1830, Loss: 0.14504807442426682, Final Batch Loss: 0.06895805150270462\n",
      "Epoch 1831, Loss: 0.11911079660058022, Final Batch Loss: 0.07848019897937775\n",
      "Epoch 1832, Loss: 0.14749695360660553, Final Batch Loss: 0.02155730128288269\n",
      "Epoch 1833, Loss: 0.1203717403113842, Final Batch Loss: 0.04681256040930748\n",
      "Epoch 1834, Loss: 0.12729066610336304, Final Batch Loss: 0.06066504865884781\n",
      "Epoch 1835, Loss: 0.14583920687437057, Final Batch Loss: 0.08457841724157333\n",
      "Epoch 1836, Loss: 0.15110096335411072, Final Batch Loss: 0.06761415302753448\n",
      "Epoch 1837, Loss: 0.10519194975495338, Final Batch Loss: 0.05306372046470642\n",
      "Epoch 1838, Loss: 0.1351252757012844, Final Batch Loss: 0.05776059255003929\n",
      "Epoch 1839, Loss: 0.13684731721878052, Final Batch Loss: 0.06081998348236084\n",
      "Epoch 1840, Loss: 0.1365688405930996, Final Batch Loss: 0.04543742910027504\n",
      "Epoch 1841, Loss: 0.1409042552113533, Final Batch Loss: 0.059121571481227875\n",
      "Epoch 1842, Loss: 0.1607435718178749, Final Batch Loss: 0.06720179319381714\n",
      "Epoch 1843, Loss: 0.13408252596855164, Final Batch Loss: 0.05991951376199722\n",
      "Epoch 1844, Loss: 0.16697990149259567, Final Batch Loss: 0.09579872339963913\n",
      "Epoch 1845, Loss: 0.15646734833717346, Final Batch Loss: 0.09420739859342575\n",
      "Epoch 1846, Loss: 0.1212216466665268, Final Batch Loss: 0.06503823399543762\n",
      "Epoch 1847, Loss: 0.13600243255496025, Final Batch Loss: 0.08315110951662064\n",
      "Epoch 1848, Loss: 0.12639109045267105, Final Batch Loss: 0.054298147559165955\n",
      "Epoch 1849, Loss: 0.11760088801383972, Final Batch Loss: 0.06402425467967987\n",
      "Epoch 1850, Loss: 0.12384432926774025, Final Batch Loss: 0.06549964845180511\n",
      "Epoch 1851, Loss: 0.12566760927438736, Final Batch Loss: 0.05936112999916077\n",
      "Epoch 1852, Loss: 0.1433217190206051, Final Batch Loss: 0.05906042829155922\n",
      "Epoch 1853, Loss: 0.14061219990253448, Final Batch Loss: 0.09753381460905075\n",
      "Epoch 1854, Loss: 0.1523413434624672, Final Batch Loss: 0.07298611849546432\n",
      "Epoch 1855, Loss: 0.12874824553728104, Final Batch Loss: 0.05251329392194748\n",
      "Epoch 1856, Loss: 0.16367564350366592, Final Batch Loss: 0.0746719166636467\n",
      "Epoch 1857, Loss: 0.13236922770738602, Final Batch Loss: 0.06474773585796356\n",
      "Epoch 1858, Loss: 0.1261119656264782, Final Batch Loss: 0.07326973974704742\n",
      "Epoch 1859, Loss: 0.13180787861347198, Final Batch Loss: 0.06445802748203278\n",
      "Epoch 1860, Loss: 0.14286744594573975, Final Batch Loss: 0.07174978405237198\n",
      "Epoch 1861, Loss: 0.21239927411079407, Final Batch Loss: 0.10303887724876404\n",
      "Epoch 1862, Loss: 0.14932682365179062, Final Batch Loss: 0.08987864851951599\n",
      "Epoch 1863, Loss: 0.14894334971904755, Final Batch Loss: 0.07016897201538086\n",
      "Epoch 1864, Loss: 0.12282542511820793, Final Batch Loss: 0.054589997977018356\n",
      "Epoch 1865, Loss: 0.16045283526182175, Final Batch Loss: 0.09454535692930222\n",
      "Epoch 1866, Loss: 0.1673647090792656, Final Batch Loss: 0.09727734327316284\n",
      "Epoch 1867, Loss: 0.11886544898152351, Final Batch Loss: 0.05242811515927315\n",
      "Epoch 1868, Loss: 0.17943695187568665, Final Batch Loss: 0.07630756497383118\n",
      "Epoch 1869, Loss: 0.11310803890228271, Final Batch Loss: 0.04068242758512497\n",
      "Epoch 1870, Loss: 0.13909584283828735, Final Batch Loss: 0.08070621639490128\n",
      "Epoch 1871, Loss: 0.1387360915541649, Final Batch Loss: 0.10940305888652802\n",
      "Epoch 1872, Loss: 0.11847716942429543, Final Batch Loss: 0.06475584208965302\n",
      "Epoch 1873, Loss: 0.10748131200671196, Final Batch Loss: 0.057960379868745804\n",
      "Epoch 1874, Loss: 0.14324121177196503, Final Batch Loss: 0.09867174923419952\n",
      "Epoch 1875, Loss: 0.12424860149621964, Final Batch Loss: 0.07609255611896515\n",
      "Epoch 1876, Loss: 0.13214926049113274, Final Batch Loss: 0.07858622819185257\n",
      "Epoch 1877, Loss: 0.1272105798125267, Final Batch Loss: 0.07180769741535187\n",
      "Epoch 1878, Loss: 0.1808692365884781, Final Batch Loss: 0.08187180012464523\n",
      "Epoch 1879, Loss: 0.09729735553264618, Final Batch Loss: 0.05164661258459091\n",
      "Epoch 1880, Loss: 0.1502533033490181, Final Batch Loss: 0.06734052300453186\n",
      "Epoch 1881, Loss: 0.12802013382315636, Final Batch Loss: 0.052225980907678604\n",
      "Epoch 1882, Loss: 0.10810462385416031, Final Batch Loss: 0.055525656789541245\n",
      "Epoch 1883, Loss: 0.14771495759487152, Final Batch Loss: 0.07403960078954697\n",
      "Epoch 1884, Loss: 0.14046448841691017, Final Batch Loss: 0.05617053434252739\n",
      "Epoch 1885, Loss: 0.1569576896727085, Final Batch Loss: 0.12312521040439606\n",
      "Epoch 1886, Loss: 0.12096134200692177, Final Batch Loss: 0.05800597742199898\n",
      "Epoch 1887, Loss: 0.11910470575094223, Final Batch Loss: 0.06386898458003998\n",
      "Epoch 1888, Loss: 0.11192366108298302, Final Batch Loss: 0.06339289247989655\n",
      "Epoch 1889, Loss: 0.1315366066992283, Final Batch Loss: 0.07782942056655884\n",
      "Epoch 1890, Loss: 0.1465187594294548, Final Batch Loss: 0.08219299465417862\n",
      "Epoch 1891, Loss: 0.1649010255932808, Final Batch Loss: 0.0633552297949791\n",
      "Epoch 1892, Loss: 0.130142692476511, Final Batch Loss: 0.05410567298531532\n",
      "Epoch 1893, Loss: 0.13866107538342476, Final Batch Loss: 0.09693973511457443\n",
      "Epoch 1894, Loss: 0.12753154337406158, Final Batch Loss: 0.05642784386873245\n",
      "Epoch 1895, Loss: 0.13163257017731667, Final Batch Loss: 0.056003984063863754\n",
      "Epoch 1896, Loss: 0.17348352819681168, Final Batch Loss: 0.05755862593650818\n",
      "Epoch 1897, Loss: 0.19356920570135117, Final Batch Loss: 0.12515079975128174\n",
      "Epoch 1898, Loss: 0.1286097764968872, Final Batch Loss: 0.06943438947200775\n",
      "Epoch 1899, Loss: 0.15675269812345505, Final Batch Loss: 0.10293494164943695\n",
      "Epoch 1900, Loss: 0.11228059232234955, Final Batch Loss: 0.04776722192764282\n",
      "Epoch 1901, Loss: 0.15525232255458832, Final Batch Loss: 0.0875461995601654\n",
      "Epoch 1902, Loss: 0.1385134495794773, Final Batch Loss: 0.055437106639146805\n",
      "Epoch 1903, Loss: 0.187021903693676, Final Batch Loss: 0.12391878664493561\n",
      "Epoch 1904, Loss: 0.20767274871468544, Final Batch Loss: 0.05563116446137428\n",
      "Epoch 1905, Loss: 0.18334656208753586, Final Batch Loss: 0.11835237592458725\n",
      "Epoch 1906, Loss: 0.17287830263376236, Final Batch Loss: 0.06426464021205902\n",
      "Epoch 1907, Loss: 0.13365424796938896, Final Batch Loss: 0.062115203589200974\n",
      "Epoch 1908, Loss: 0.20344427973031998, Final Batch Loss: 0.14747752249240875\n",
      "Epoch 1909, Loss: 0.14420779794454575, Final Batch Loss: 0.08136527985334396\n",
      "Epoch 1910, Loss: 0.15389861911535263, Final Batch Loss: 0.06859785318374634\n",
      "Epoch 1911, Loss: 0.13342414051294327, Final Batch Loss: 0.06997550278902054\n",
      "Epoch 1912, Loss: 0.13948771357536316, Final Batch Loss: 0.06963726133108139\n",
      "Epoch 1913, Loss: 0.12301118299365044, Final Batch Loss: 0.0647362619638443\n",
      "Epoch 1914, Loss: 0.11846696212887764, Final Batch Loss: 0.06559787690639496\n",
      "Epoch 1915, Loss: 0.1699017882347107, Final Batch Loss: 0.10505206137895584\n",
      "Epoch 1916, Loss: 0.12253060564398766, Final Batch Loss: 0.05612926557660103\n",
      "Epoch 1917, Loss: 0.17101163044571877, Final Batch Loss: 0.12143003195524216\n",
      "Epoch 1918, Loss: 0.16104748845100403, Final Batch Loss: 0.07788686454296112\n",
      "Epoch 1919, Loss: 0.11059026047587395, Final Batch Loss: 0.03497907146811485\n",
      "Epoch 1920, Loss: 0.13093506172299385, Final Batch Loss: 0.05487094447016716\n",
      "Epoch 1921, Loss: 0.11523119360208511, Final Batch Loss: 0.04512714594602585\n",
      "Epoch 1922, Loss: 0.14574875682592392, Final Batch Loss: 0.06650001555681229\n",
      "Epoch 1923, Loss: 0.1653781607747078, Final Batch Loss: 0.11458026617765427\n",
      "Epoch 1924, Loss: 0.12870535999536514, Final Batch Loss: 0.07162685692310333\n",
      "Epoch 1925, Loss: 0.1221819780766964, Final Batch Loss: 0.042297203093767166\n",
      "Epoch 1926, Loss: 0.15369531139731407, Final Batch Loss: 0.06019337847828865\n",
      "Epoch 1927, Loss: 0.12672778964042664, Final Batch Loss: 0.06308769434690475\n",
      "Epoch 1928, Loss: 0.15912815183401108, Final Batch Loss: 0.05927795171737671\n",
      "Epoch 1929, Loss: 0.10481182113289833, Final Batch Loss: 0.04573312774300575\n",
      "Epoch 1930, Loss: 0.1309027187526226, Final Batch Loss: 0.05045158788561821\n",
      "Epoch 1931, Loss: 0.1201888732612133, Final Batch Loss: 0.04359310492873192\n",
      "Epoch 1932, Loss: 0.11045624315738678, Final Batch Loss: 0.03283301740884781\n",
      "Epoch 1933, Loss: 0.1579575166106224, Final Batch Loss: 0.04330194741487503\n",
      "Epoch 1934, Loss: 0.10704261809587479, Final Batch Loss: 0.058631666004657745\n",
      "Epoch 1935, Loss: 0.12334227934479713, Final Batch Loss: 0.05872092768549919\n",
      "Epoch 1936, Loss: 0.13937842845916748, Final Batch Loss: 0.08803857862949371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1937, Loss: 0.16377266123890877, Final Batch Loss: 0.11590468138456345\n",
      "Epoch 1938, Loss: 0.09791423380374908, Final Batch Loss: 0.03827521950006485\n",
      "Epoch 1939, Loss: 0.13629771769046783, Final Batch Loss: 0.059619151055812836\n",
      "Epoch 1940, Loss: 0.16861147433519363, Final Batch Loss: 0.07248073816299438\n",
      "Epoch 1941, Loss: 0.17806429415941238, Final Batch Loss: 0.10260909795761108\n",
      "Epoch 1942, Loss: 0.11225569993257523, Final Batch Loss: 0.04805344343185425\n",
      "Epoch 1943, Loss: 0.14400694519281387, Final Batch Loss: 0.09428012371063232\n",
      "Epoch 1944, Loss: 0.16534705460071564, Final Batch Loss: 0.09645723551511765\n",
      "Epoch 1945, Loss: 0.15425467118620872, Final Batch Loss: 0.10808435082435608\n",
      "Epoch 1946, Loss: 0.17386328428983688, Final Batch Loss: 0.08170443773269653\n",
      "Epoch 1947, Loss: 0.14712153747677803, Final Batch Loss: 0.08716043084859848\n",
      "Epoch 1948, Loss: 0.1357649564743042, Final Batch Loss: 0.04314238578081131\n",
      "Epoch 1949, Loss: 0.15258769318461418, Final Batch Loss: 0.10137363523244858\n",
      "Epoch 1950, Loss: 0.14461757615208626, Final Batch Loss: 0.08219172060489655\n",
      "Epoch 1951, Loss: 0.1303517296910286, Final Batch Loss: 0.06366130709648132\n",
      "Epoch 1952, Loss: 0.14191024377942085, Final Batch Loss: 0.05367489531636238\n",
      "Epoch 1953, Loss: 0.11010340973734856, Final Batch Loss: 0.04899183288216591\n",
      "Epoch 1954, Loss: 0.13881152123212814, Final Batch Loss: 0.07120504230260849\n",
      "Epoch 1955, Loss: 0.1301770582795143, Final Batch Loss: 0.06088560074567795\n",
      "Epoch 1956, Loss: 0.14725429192185402, Final Batch Loss: 0.05937691405415535\n",
      "Epoch 1957, Loss: 0.1258390247821808, Final Batch Loss: 0.0587770938873291\n",
      "Epoch 1958, Loss: 0.10772423446178436, Final Batch Loss: 0.04802433028817177\n",
      "Epoch 1959, Loss: 0.13427256047725677, Final Batch Loss: 0.0798015221953392\n",
      "Epoch 1960, Loss: 0.20618987828493118, Final Batch Loss: 0.12878009676933289\n",
      "Epoch 1961, Loss: 0.12604645639657974, Final Batch Loss: 0.059277452528476715\n",
      "Epoch 1962, Loss: 0.18690749630331993, Final Batch Loss: 0.13532598316669464\n",
      "Epoch 1963, Loss: 0.12413381785154343, Final Batch Loss: 0.0526241809129715\n",
      "Epoch 1964, Loss: 0.14949289709329605, Final Batch Loss: 0.07045409083366394\n",
      "Epoch 1965, Loss: 0.11134979501366615, Final Batch Loss: 0.07000014185905457\n",
      "Epoch 1966, Loss: 0.15887296199798584, Final Batch Loss: 0.06837654858827591\n",
      "Epoch 1967, Loss: 0.1722647324204445, Final Batch Loss: 0.06552460789680481\n",
      "Epoch 1968, Loss: 0.15076110884547234, Final Batch Loss: 0.09870488941669464\n",
      "Epoch 1969, Loss: 0.17720241844654083, Final Batch Loss: 0.07092825323343277\n",
      "Epoch 1970, Loss: 0.1443590521812439, Final Batch Loss: 0.07797007262706757\n",
      "Epoch 1971, Loss: 0.1511508673429489, Final Batch Loss: 0.04261238873004913\n",
      "Epoch 1972, Loss: 0.13917452841997147, Final Batch Loss: 0.04326121509075165\n",
      "Epoch 1973, Loss: 0.22759928554296494, Final Batch Loss: 0.13654159009456635\n",
      "Epoch 1974, Loss: 0.13517828658223152, Final Batch Loss: 0.05495770648121834\n",
      "Epoch 1975, Loss: 0.14848686754703522, Final Batch Loss: 0.08829063177108765\n",
      "Epoch 1976, Loss: 0.15366416797041893, Final Batch Loss: 0.04332816228270531\n",
      "Epoch 1977, Loss: 0.11102234944701195, Final Batch Loss: 0.047741759568452835\n",
      "Epoch 1978, Loss: 0.14066056162118912, Final Batch Loss: 0.07443752139806747\n",
      "Epoch 1979, Loss: 0.14189363270998, Final Batch Loss: 0.08441010117530823\n",
      "Epoch 1980, Loss: 0.13367627561092377, Final Batch Loss: 0.08688480406999588\n",
      "Epoch 1981, Loss: 0.1756819486618042, Final Batch Loss: 0.09410253912210464\n",
      "Epoch 1982, Loss: 0.14918025583028793, Final Batch Loss: 0.04444241523742676\n",
      "Epoch 1983, Loss: 0.12332885339856148, Final Batch Loss: 0.06781336665153503\n",
      "Epoch 1984, Loss: 0.18377665802836418, Final Batch Loss: 0.05703708156943321\n",
      "Epoch 1985, Loss: 0.14557655900716782, Final Batch Loss: 0.0667174831032753\n",
      "Epoch 1986, Loss: 0.1342383660376072, Final Batch Loss: 0.07382723689079285\n",
      "Epoch 1987, Loss: 0.09998744353652, Final Batch Loss: 0.04565780237317085\n",
      "Epoch 1988, Loss: 0.12236359715461731, Final Batch Loss: 0.07436399906873703\n",
      "Epoch 1989, Loss: 0.11851062625646591, Final Batch Loss: 0.055295057594776154\n",
      "Epoch 1990, Loss: 0.1498483493924141, Final Batch Loss: 0.07665661722421646\n",
      "Epoch 1991, Loss: 0.1405210793018341, Final Batch Loss: 0.06905993819236755\n",
      "Epoch 1992, Loss: 0.1407575011253357, Final Batch Loss: 0.058068037033081055\n",
      "Epoch 1993, Loss: 0.15354276448488235, Final Batch Loss: 0.07381705194711685\n",
      "Epoch 1994, Loss: 0.15471336990594864, Final Batch Loss: 0.09383761882781982\n",
      "Epoch 1995, Loss: 0.12057109922170639, Final Batch Loss: 0.06452015787363052\n",
      "Epoch 1996, Loss: 0.1304851770401001, Final Batch Loss: 0.0661076083779335\n",
      "Epoch 1997, Loss: 0.10063345730304718, Final Batch Loss: 0.04236019030213356\n",
      "Epoch 1998, Loss: 0.11727393791079521, Final Batch Loss: 0.049583595246076584\n",
      "Epoch 1999, Loss: 0.1855114847421646, Final Batch Loss: 0.06581253558397293\n",
      "Epoch 2000, Loss: 0.14509747922420502, Final Batch Loss: 0.07508359104394913\n",
      "Epoch 2001, Loss: 0.11040974408388138, Final Batch Loss: 0.043558359146118164\n",
      "Epoch 2002, Loss: 0.14320220798254013, Final Batch Loss: 0.06858772039413452\n",
      "Epoch 2003, Loss: 0.11409087479114532, Final Batch Loss: 0.04916434735059738\n",
      "Epoch 2004, Loss: 0.17249459028244019, Final Batch Loss: 0.1209569126367569\n",
      "Epoch 2005, Loss: 0.15549618005752563, Final Batch Loss: 0.06529870629310608\n",
      "Epoch 2006, Loss: 0.1155574731528759, Final Batch Loss: 0.04138903692364693\n",
      "Epoch 2007, Loss: 0.1286054402589798, Final Batch Loss: 0.06986676901578903\n",
      "Epoch 2008, Loss: 0.12234247475862503, Final Batch Loss: 0.05910685658454895\n",
      "Epoch 2009, Loss: 0.1395193710923195, Final Batch Loss: 0.0650201141834259\n",
      "Epoch 2010, Loss: 0.11907639354467392, Final Batch Loss: 0.058856237679719925\n",
      "Epoch 2011, Loss: 0.22524772956967354, Final Batch Loss: 0.163086399435997\n",
      "Epoch 2012, Loss: 0.15201688185334206, Final Batch Loss: 0.10098667442798615\n",
      "Epoch 2013, Loss: 0.12632808461785316, Final Batch Loss: 0.08432424813508987\n",
      "Epoch 2014, Loss: 0.11832188442349434, Final Batch Loss: 0.04957631602883339\n",
      "Epoch 2015, Loss: 0.11830921843647957, Final Batch Loss: 0.07392038404941559\n",
      "Epoch 2016, Loss: 0.12024334445595741, Final Batch Loss: 0.07948305457830429\n",
      "Epoch 2017, Loss: 0.15537099540233612, Final Batch Loss: 0.07740288227796555\n",
      "Epoch 2018, Loss: 0.11288970708847046, Final Batch Loss: 0.05590952932834625\n",
      "Epoch 2019, Loss: 0.10239705443382263, Final Batch Loss: 0.0425943024456501\n",
      "Epoch 2020, Loss: 0.21079573780298233, Final Batch Loss: 0.13673201203346252\n",
      "Epoch 2021, Loss: 0.13046254217624664, Final Batch Loss: 0.059378378093242645\n",
      "Epoch 2022, Loss: 0.1542476788163185, Final Batch Loss: 0.07733660191297531\n",
      "Epoch 2023, Loss: 0.12554115056991577, Final Batch Loss: 0.05161911994218826\n",
      "Epoch 2024, Loss: 0.17213090509176254, Final Batch Loss: 0.10798836499452591\n",
      "Epoch 2025, Loss: 0.12086143344640732, Final Batch Loss: 0.05798839032649994\n",
      "Epoch 2026, Loss: 0.1277008019387722, Final Batch Loss: 0.03874506428837776\n",
      "Epoch 2027, Loss: 0.1086842305958271, Final Batch Loss: 0.044899437576532364\n",
      "Epoch 2028, Loss: 0.09791989997029305, Final Batch Loss: 0.04581557959318161\n",
      "Epoch 2029, Loss: 0.13135669380426407, Final Batch Loss: 0.05519305169582367\n",
      "Epoch 2030, Loss: 0.11442872881889343, Final Batch Loss: 0.05662719905376434\n",
      "Epoch 2031, Loss: 0.1357307732105255, Final Batch Loss: 0.06543011218309402\n",
      "Epoch 2032, Loss: 0.11030713096261024, Final Batch Loss: 0.0588238425552845\n",
      "Epoch 2033, Loss: 0.14557074382901192, Final Batch Loss: 0.08375526964664459\n",
      "Epoch 2034, Loss: 0.1452902853488922, Final Batch Loss: 0.07762481272220612\n",
      "Epoch 2035, Loss: 0.11786268651485443, Final Batch Loss: 0.036641284823417664\n",
      "Epoch 2036, Loss: 0.12071509659290314, Final Batch Loss: 0.06640568375587463\n",
      "Epoch 2037, Loss: 0.14361248165369034, Final Batch Loss: 0.07384079694747925\n",
      "Epoch 2038, Loss: 0.1161523088812828, Final Batch Loss: 0.08055688440799713\n",
      "Epoch 2039, Loss: 0.1322401985526085, Final Batch Loss: 0.059738799929618835\n",
      "Epoch 2040, Loss: 0.10793590173125267, Final Batch Loss: 0.052379537373781204\n",
      "Epoch 2041, Loss: 0.12193027138710022, Final Batch Loss: 0.055468715727329254\n",
      "Epoch 2042, Loss: 0.11549698561429977, Final Batch Loss: 0.046679869294166565\n",
      "Epoch 2043, Loss: 0.11529059335589409, Final Batch Loss: 0.058631908148527145\n",
      "Epoch 2044, Loss: 0.10971945151686668, Final Batch Loss: 0.06069010868668556\n",
      "Epoch 2045, Loss: 0.10941410437226295, Final Batch Loss: 0.05841359123587608\n",
      "Epoch 2046, Loss: 0.1229206807911396, Final Batch Loss: 0.053638603538274765\n",
      "Epoch 2047, Loss: 0.12264830991625786, Final Batch Loss: 0.05357856675982475\n",
      "Epoch 2048, Loss: 0.11601552739739418, Final Batch Loss: 0.04014812782406807\n",
      "Epoch 2049, Loss: 0.13352324441075325, Final Batch Loss: 0.03543144837021828\n",
      "Epoch 2050, Loss: 0.1233169287443161, Final Batch Loss: 0.07202161103487015\n",
      "Epoch 2051, Loss: 0.1121397539973259, Final Batch Loss: 0.05800608545541763\n",
      "Epoch 2052, Loss: 0.1324513852596283, Final Batch Loss: 0.062368594110012054\n",
      "Epoch 2053, Loss: 0.19719161093235016, Final Batch Loss: 0.0772823840379715\n",
      "Epoch 2054, Loss: 0.12704841420054436, Final Batch Loss: 0.05807924643158913\n",
      "Epoch 2055, Loss: 0.18208832293748856, Final Batch Loss: 0.044443197548389435\n",
      "Epoch 2056, Loss: 0.09003385528922081, Final Batch Loss: 0.05057445913553238\n",
      "Epoch 2057, Loss: 0.10359008982777596, Final Batch Loss: 0.0623166523873806\n",
      "Epoch 2058, Loss: 0.16042503342032433, Final Batch Loss: 0.11310473084449768\n",
      "Epoch 2059, Loss: 0.11572502925992012, Final Batch Loss: 0.07061788439750671\n",
      "Epoch 2060, Loss: 0.13693121075630188, Final Batch Loss: 0.05527952313423157\n",
      "Epoch 2061, Loss: 0.16018804162740707, Final Batch Loss: 0.08828546851873398\n",
      "Epoch 2062, Loss: 0.12261151894927025, Final Batch Loss: 0.05958671495318413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2063, Loss: 0.1310516707599163, Final Batch Loss: 0.06223929300904274\n",
      "Epoch 2064, Loss: 0.13886656239628792, Final Batch Loss: 0.08482197672128677\n",
      "Epoch 2065, Loss: 0.15785524621605873, Final Batch Loss: 0.10148219019174576\n",
      "Epoch 2066, Loss: 0.12833493202924728, Final Batch Loss: 0.06340501457452774\n",
      "Epoch 2067, Loss: 0.1552613526582718, Final Batch Loss: 0.05211137980222702\n",
      "Epoch 2068, Loss: 0.1898999810218811, Final Batch Loss: 0.06686036288738251\n",
      "Epoch 2069, Loss: 0.11871089413762093, Final Batch Loss: 0.04885250702500343\n",
      "Epoch 2070, Loss: 0.1374293714761734, Final Batch Loss: 0.05792464315891266\n",
      "Epoch 2071, Loss: 0.1373603269457817, Final Batch Loss: 0.07389556616544724\n",
      "Epoch 2072, Loss: 0.1531636118888855, Final Batch Loss: 0.06812824308872223\n",
      "Epoch 2073, Loss: 0.1234002597630024, Final Batch Loss: 0.07557714730501175\n",
      "Epoch 2074, Loss: 0.11744775623083115, Final Batch Loss: 0.05547461286187172\n",
      "Epoch 2075, Loss: 0.12184058129787445, Final Batch Loss: 0.07718420028686523\n",
      "Epoch 2076, Loss: 0.14009910076856613, Final Batch Loss: 0.06447146832942963\n",
      "Epoch 2077, Loss: 0.13571693748235703, Final Batch Loss: 0.06601468473672867\n",
      "Epoch 2078, Loss: 0.13097937032580376, Final Batch Loss: 0.07119037955999374\n",
      "Epoch 2079, Loss: 0.11983983218669891, Final Batch Loss: 0.06780131161212921\n",
      "Epoch 2080, Loss: 0.09943025186657906, Final Batch Loss: 0.04347674921154976\n",
      "Epoch 2081, Loss: 0.17747511714696884, Final Batch Loss: 0.08979945629835129\n",
      "Epoch 2082, Loss: 0.09825935959815979, Final Batch Loss: 0.054213982075452805\n",
      "Epoch 2083, Loss: 0.1067022904753685, Final Batch Loss: 0.04759182035923004\n",
      "Epoch 2084, Loss: 0.13089638948440552, Final Batch Loss: 0.05068272352218628\n",
      "Epoch 2085, Loss: 0.11242295801639557, Final Batch Loss: 0.05695493891835213\n",
      "Epoch 2086, Loss: 0.12862465158104897, Final Batch Loss: 0.07828018069267273\n",
      "Epoch 2087, Loss: 0.12924925237894058, Final Batch Loss: 0.04646102339029312\n",
      "Epoch 2088, Loss: 0.11233078315854073, Final Batch Loss: 0.0650126114487648\n",
      "Epoch 2089, Loss: 0.10404881462454796, Final Batch Loss: 0.05758751928806305\n",
      "Epoch 2090, Loss: 0.2250509038567543, Final Batch Loss: 0.07408434897661209\n",
      "Epoch 2091, Loss: 0.14330554381012917, Final Batch Loss: 0.060306135565042496\n",
      "Epoch 2092, Loss: 0.1264808624982834, Final Batch Loss: 0.07984530180692673\n",
      "Epoch 2093, Loss: 0.13180000334978104, Final Batch Loss: 0.06575527042150497\n",
      "Epoch 2094, Loss: 0.12809345126152039, Final Batch Loss: 0.08335545659065247\n",
      "Epoch 2095, Loss: 0.13951397314667702, Final Batch Loss: 0.0843949094414711\n",
      "Epoch 2096, Loss: 0.13253886997699738, Final Batch Loss: 0.08187748491764069\n",
      "Epoch 2097, Loss: 0.15813257545232773, Final Batch Loss: 0.07348722219467163\n",
      "Epoch 2098, Loss: 0.1182735487818718, Final Batch Loss: 0.06916261464357376\n",
      "Epoch 2099, Loss: 0.16495580226182938, Final Batch Loss: 0.11546548455953598\n",
      "Epoch 2100, Loss: 0.14095870405435562, Final Batch Loss: 0.053509026765823364\n",
      "Epoch 2101, Loss: 0.13523656129837036, Final Batch Loss: 0.07057502120733261\n",
      "Epoch 2102, Loss: 0.15008899569511414, Final Batch Loss: 0.08163975924253464\n",
      "Epoch 2103, Loss: 0.11939544975757599, Final Batch Loss: 0.06821703165769577\n",
      "Epoch 2104, Loss: 0.13610679283738136, Final Batch Loss: 0.04418858513236046\n",
      "Epoch 2105, Loss: 0.10600077360868454, Final Batch Loss: 0.04398487135767937\n",
      "Epoch 2106, Loss: 0.13277079537510872, Final Batch Loss: 0.05523901805281639\n",
      "Epoch 2107, Loss: 0.1409379132091999, Final Batch Loss: 0.05978744849562645\n",
      "Epoch 2108, Loss: 0.11411650106310844, Final Batch Loss: 0.0664563700556755\n",
      "Epoch 2109, Loss: 0.12177421525120735, Final Batch Loss: 0.07806126028299332\n",
      "Epoch 2110, Loss: 0.1350380778312683, Final Batch Loss: 0.06901203840970993\n",
      "Epoch 2111, Loss: 0.12679337710142136, Final Batch Loss: 0.06408713757991791\n",
      "Epoch 2112, Loss: 0.11426183208823204, Final Batch Loss: 0.05816962569952011\n",
      "Epoch 2113, Loss: 0.1421138271689415, Final Batch Loss: 0.04252060502767563\n",
      "Epoch 2114, Loss: 0.11988554894924164, Final Batch Loss: 0.06063048541545868\n",
      "Epoch 2115, Loss: 0.14395848289132118, Final Batch Loss: 0.08840321004390717\n",
      "Epoch 2116, Loss: 0.0970420278608799, Final Batch Loss: 0.04841428995132446\n",
      "Epoch 2117, Loss: 0.18841122463345528, Final Batch Loss: 0.13154634833335876\n",
      "Epoch 2118, Loss: 0.14126574248075485, Final Batch Loss: 0.08624382317066193\n",
      "Epoch 2119, Loss: 0.1510879024863243, Final Batch Loss: 0.07797690480947495\n",
      "Epoch 2120, Loss: 0.11199787631630898, Final Batch Loss: 0.045579943805933\n",
      "Epoch 2121, Loss: 0.13635427132248878, Final Batch Loss: 0.07814270257949829\n",
      "Epoch 2122, Loss: 0.1377849504351616, Final Batch Loss: 0.08422480523586273\n",
      "Epoch 2123, Loss: 0.12146217375993729, Final Batch Loss: 0.0543709471821785\n",
      "Epoch 2124, Loss: 0.1470705047249794, Final Batch Loss: 0.08590459823608398\n",
      "Epoch 2125, Loss: 0.15116975456476212, Final Batch Loss: 0.07236756384372711\n",
      "Epoch 2126, Loss: 0.16016873344779015, Final Batch Loss: 0.09789401292800903\n",
      "Epoch 2127, Loss: 0.10196909680962563, Final Batch Loss: 0.06282832473516464\n",
      "Epoch 2128, Loss: 0.14691068977117538, Final Batch Loss: 0.06644871830940247\n",
      "Epoch 2129, Loss: 0.16132420301437378, Final Batch Loss: 0.09306897222995758\n",
      "Epoch 2130, Loss: 0.10230530425906181, Final Batch Loss: 0.04727431759238243\n",
      "Epoch 2131, Loss: 0.13620232790708542, Final Batch Loss: 0.06658345460891724\n",
      "Epoch 2132, Loss: 0.1360100507736206, Final Batch Loss: 0.06293579936027527\n",
      "Epoch 2133, Loss: 0.1280723214149475, Final Batch Loss: 0.0671154335141182\n",
      "Epoch 2134, Loss: 0.15800593793392181, Final Batch Loss: 0.06797350943088531\n",
      "Epoch 2135, Loss: 0.14294445887207985, Final Batch Loss: 0.05899400636553764\n",
      "Epoch 2136, Loss: 0.18279621750116348, Final Batch Loss: 0.09998822957277298\n",
      "Epoch 2137, Loss: 0.11678970232605934, Final Batch Loss: 0.06939753144979477\n",
      "Epoch 2138, Loss: 0.15865308046340942, Final Batch Loss: 0.09516724199056625\n",
      "Epoch 2139, Loss: 0.16875369101762772, Final Batch Loss: 0.11301694810390472\n",
      "Epoch 2140, Loss: 0.13147886842489243, Final Batch Loss: 0.08215980976819992\n",
      "Epoch 2141, Loss: 0.13388806581497192, Final Batch Loss: 0.04442399740219116\n",
      "Epoch 2142, Loss: 0.15901276469230652, Final Batch Loss: 0.07905316352844238\n",
      "Epoch 2143, Loss: 0.10124760121107101, Final Batch Loss: 0.042558543384075165\n",
      "Epoch 2144, Loss: 0.1342729926109314, Final Batch Loss: 0.06744860857725143\n",
      "Epoch 2145, Loss: 0.1162608340382576, Final Batch Loss: 0.038452208042144775\n",
      "Epoch 2146, Loss: 0.150474451482296, Final Batch Loss: 0.10034385323524475\n",
      "Epoch 2147, Loss: 0.12938296422362328, Final Batch Loss: 0.057369645684957504\n",
      "Epoch 2148, Loss: 0.08090952411293983, Final Batch Loss: 0.032238323241472244\n",
      "Epoch 2149, Loss: 0.1130964644253254, Final Batch Loss: 0.055027108639478683\n",
      "Epoch 2150, Loss: 0.11152120307087898, Final Batch Loss: 0.06257402151823044\n",
      "Epoch 2151, Loss: 0.1700935736298561, Final Batch Loss: 0.11138750612735748\n",
      "Epoch 2152, Loss: 0.1181938648223877, Final Batch Loss: 0.04481188952922821\n",
      "Epoch 2153, Loss: 0.15458015352487564, Final Batch Loss: 0.10542530566453934\n",
      "Epoch 2154, Loss: 0.14881492033600807, Final Batch Loss: 0.08723976463079453\n",
      "Epoch 2155, Loss: 0.1257842294871807, Final Batch Loss: 0.06090587005019188\n",
      "Epoch 2156, Loss: 0.14476747810840607, Final Batch Loss: 0.07788783311843872\n",
      "Epoch 2157, Loss: 0.11016680300235748, Final Batch Loss: 0.049001991748809814\n",
      "Epoch 2158, Loss: 0.15939073637127876, Final Batch Loss: 0.10195981711149216\n",
      "Epoch 2159, Loss: 0.16293839365243912, Final Batch Loss: 0.062272995710372925\n",
      "Epoch 2160, Loss: 0.13436877354979515, Final Batch Loss: 0.035454872995615005\n",
      "Epoch 2161, Loss: 0.13290618360042572, Final Batch Loss: 0.06794585287570953\n",
      "Epoch 2162, Loss: 0.1179429404437542, Final Batch Loss: 0.06596479564905167\n",
      "Epoch 2163, Loss: 0.13030767813324928, Final Batch Loss: 0.08464393019676208\n",
      "Epoch 2164, Loss: 0.13275402784347534, Final Batch Loss: 0.05030094087123871\n",
      "Epoch 2165, Loss: 0.15284348279237747, Final Batch Loss: 0.09629752486944199\n",
      "Epoch 2166, Loss: 0.12425875291228294, Final Batch Loss: 0.07070950418710709\n",
      "Epoch 2167, Loss: 0.13490014523267746, Final Batch Loss: 0.06832234561443329\n",
      "Epoch 2168, Loss: 0.14335457608103752, Final Batch Loss: 0.05256598815321922\n",
      "Epoch 2169, Loss: 0.12812329083681107, Final Batch Loss: 0.06506440788507462\n",
      "Epoch 2170, Loss: 0.10600604489445686, Final Batch Loss: 0.04174366965889931\n",
      "Epoch 2171, Loss: 0.16831658780574799, Final Batch Loss: 0.06450191140174866\n",
      "Epoch 2172, Loss: 0.14082687348127365, Final Batch Loss: 0.09194468706846237\n",
      "Epoch 2173, Loss: 0.14070677384734154, Final Batch Loss: 0.0817236602306366\n",
      "Epoch 2174, Loss: 0.10545245930552483, Final Batch Loss: 0.04450073093175888\n",
      "Epoch 2175, Loss: 0.17736726999282837, Final Batch Loss: 0.07018493860960007\n",
      "Epoch 2176, Loss: 0.11016414314508438, Final Batch Loss: 0.04222051054239273\n",
      "Epoch 2177, Loss: 0.09396172687411308, Final Batch Loss: 0.0412980280816555\n",
      "Epoch 2178, Loss: 0.13235115632414818, Final Batch Loss: 0.061394501477479935\n",
      "Epoch 2179, Loss: 0.14558057487010956, Final Batch Loss: 0.07997553050518036\n",
      "Epoch 2180, Loss: 0.15835654735565186, Final Batch Loss: 0.10504166781902313\n",
      "Epoch 2181, Loss: 0.11466791480779648, Final Batch Loss: 0.07302545756101608\n",
      "Epoch 2182, Loss: 0.12900304421782494, Final Batch Loss: 0.05056225135922432\n",
      "Epoch 2183, Loss: 0.136969443410635, Final Batch Loss: 0.05880178138613701\n",
      "Epoch 2184, Loss: 0.09790758974850178, Final Batch Loss: 0.0284899789839983\n",
      "Epoch 2185, Loss: 0.10048110410571098, Final Batch Loss: 0.022923264652490616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2186, Loss: 0.0963161401450634, Final Batch Loss: 0.04272964969277382\n",
      "Epoch 2187, Loss: 0.12872899696230888, Final Batch Loss: 0.06983673572540283\n",
      "Epoch 2188, Loss: 0.12141237407922745, Final Batch Loss: 0.07330089062452316\n",
      "Epoch 2189, Loss: 0.13135160878300667, Final Batch Loss: 0.09685018658638\n",
      "Epoch 2190, Loss: 0.1404595486819744, Final Batch Loss: 0.0823611170053482\n",
      "Epoch 2191, Loss: 0.13468962162733078, Final Batch Loss: 0.06690363585948944\n",
      "Epoch 2192, Loss: 0.13885334134101868, Final Batch Loss: 0.10296528786420822\n",
      "Epoch 2193, Loss: 0.11771231144666672, Final Batch Loss: 0.03681964427232742\n",
      "Epoch 2194, Loss: 0.12597208470106125, Final Batch Loss: 0.07207448780536652\n",
      "Epoch 2195, Loss: 0.12280988693237305, Final Batch Loss: 0.07528992742300034\n",
      "Epoch 2196, Loss: 0.10508430749177933, Final Batch Loss: 0.05898161232471466\n",
      "Epoch 2197, Loss: 0.17778826504945755, Final Batch Loss: 0.11385929584503174\n",
      "Epoch 2198, Loss: 0.14804227650165558, Final Batch Loss: 0.06290092319250107\n",
      "Epoch 2199, Loss: 0.11284850537776947, Final Batch Loss: 0.049263402819633484\n",
      "Epoch 2200, Loss: 0.14136293530464172, Final Batch Loss: 0.06572091579437256\n",
      "Epoch 2201, Loss: 0.16327614337205887, Final Batch Loss: 0.06406646966934204\n",
      "Epoch 2202, Loss: 0.1737777218222618, Final Batch Loss: 0.08403529971837997\n",
      "Epoch 2203, Loss: 0.17029933631420135, Final Batch Loss: 0.10657817125320435\n",
      "Epoch 2204, Loss: 0.15388322621583939, Final Batch Loss: 0.06380343437194824\n",
      "Epoch 2205, Loss: 0.17530380189418793, Final Batch Loss: 0.085670605301857\n",
      "Epoch 2206, Loss: 0.1265082284808159, Final Batch Loss: 0.04118821769952774\n",
      "Epoch 2207, Loss: 0.13106921687722206, Final Batch Loss: 0.06148439273238182\n",
      "Epoch 2208, Loss: 0.13802213221788406, Final Batch Loss: 0.08986726403236389\n",
      "Epoch 2209, Loss: 0.13241546228528023, Final Batch Loss: 0.07333773374557495\n",
      "Epoch 2210, Loss: 0.12811174616217613, Final Batch Loss: 0.05734436586499214\n",
      "Epoch 2211, Loss: 0.175446055829525, Final Batch Loss: 0.0752321258187294\n",
      "Epoch 2212, Loss: 0.12716057151556015, Final Batch Loss: 0.057235293090343475\n",
      "Epoch 2213, Loss: 0.09598729759454727, Final Batch Loss: 0.04262051358819008\n",
      "Epoch 2214, Loss: 0.14187727868556976, Final Batch Loss: 0.07169706374406815\n",
      "Epoch 2215, Loss: 0.13380609452724457, Final Batch Loss: 0.05591984838247299\n",
      "Epoch 2216, Loss: 0.13844066858291626, Final Batch Loss: 0.07323503494262695\n",
      "Epoch 2217, Loss: 0.11742329970002174, Final Batch Loss: 0.038728926330804825\n",
      "Epoch 2218, Loss: 0.16940706968307495, Final Batch Loss: 0.06743507087230682\n",
      "Epoch 2219, Loss: 0.20030423253774643, Final Batch Loss: 0.1395098716020584\n",
      "Epoch 2220, Loss: 0.20666402578353882, Final Batch Loss: 0.1265948861837387\n",
      "Epoch 2221, Loss: 0.10897266864776611, Final Batch Loss: 0.05088519677519798\n",
      "Epoch 2222, Loss: 0.16011766344308853, Final Batch Loss: 0.10854439437389374\n",
      "Epoch 2223, Loss: 0.15142985805869102, Final Batch Loss: 0.10254096239805222\n",
      "Epoch 2224, Loss: 0.10888608172535896, Final Batch Loss: 0.05451108142733574\n",
      "Epoch 2225, Loss: 0.1002025231719017, Final Batch Loss: 0.042177166789770126\n",
      "Epoch 2226, Loss: 0.10860279574990273, Final Batch Loss: 0.05376697704195976\n",
      "Epoch 2227, Loss: 0.1392715647816658, Final Batch Loss: 0.07506576925516129\n",
      "Epoch 2228, Loss: 0.10945362597703934, Final Batch Loss: 0.04956207051873207\n",
      "Epoch 2229, Loss: 0.11271870881319046, Final Batch Loss: 0.0659925788640976\n",
      "Epoch 2230, Loss: 0.11407547444105148, Final Batch Loss: 0.05534190684556961\n",
      "Epoch 2231, Loss: 0.10871726274490356, Final Batch Loss: 0.038558878004550934\n",
      "Epoch 2232, Loss: 0.1150030642747879, Final Batch Loss: 0.08458679914474487\n",
      "Epoch 2233, Loss: 0.1336442455649376, Final Batch Loss: 0.07751773297786713\n",
      "Epoch 2234, Loss: 0.11170899868011475, Final Batch Loss: 0.051228106021881104\n",
      "Epoch 2235, Loss: 0.1224668137729168, Final Batch Loss: 0.0781562402844429\n",
      "Epoch 2236, Loss: 0.11172008141875267, Final Batch Loss: 0.0719931349158287\n",
      "Epoch 2237, Loss: 0.13435763493180275, Final Batch Loss: 0.07917521893978119\n",
      "Epoch 2238, Loss: 0.13769003748893738, Final Batch Loss: 0.07328161597251892\n",
      "Epoch 2239, Loss: 0.1438107006251812, Final Batch Loss: 0.08533088117837906\n",
      "Epoch 2240, Loss: 0.12544141337275505, Final Batch Loss: 0.050828736275434494\n",
      "Epoch 2241, Loss: 0.14325643703341484, Final Batch Loss: 0.08186013996601105\n",
      "Epoch 2242, Loss: 0.10655073821544647, Final Batch Loss: 0.047022346407175064\n",
      "Epoch 2243, Loss: 0.09977111965417862, Final Batch Loss: 0.04201192036271095\n",
      "Epoch 2244, Loss: 0.11137088015675545, Final Batch Loss: 0.03457983210682869\n",
      "Epoch 2245, Loss: 0.11811092123389244, Final Batch Loss: 0.07022015005350113\n",
      "Epoch 2246, Loss: 0.13886021077632904, Final Batch Loss: 0.07489301264286041\n",
      "Epoch 2247, Loss: 0.1392456479370594, Final Batch Loss: 0.043620381504297256\n",
      "Epoch 2248, Loss: 0.10705211386084557, Final Batch Loss: 0.03862786665558815\n",
      "Epoch 2249, Loss: 0.13089695572853088, Final Batch Loss: 0.051097139716148376\n",
      "Epoch 2250, Loss: 0.1280139945447445, Final Batch Loss: 0.061496440321207047\n",
      "Epoch 2251, Loss: 0.1169622428715229, Final Batch Loss: 0.05181977525353432\n",
      "Epoch 2252, Loss: 0.10370685905218124, Final Batch Loss: 0.0649210587143898\n",
      "Epoch 2253, Loss: 0.12792351469397545, Final Batch Loss: 0.05937245115637779\n",
      "Epoch 2254, Loss: 0.12934894487261772, Final Batch Loss: 0.05922728404402733\n",
      "Epoch 2255, Loss: 0.12648797407746315, Final Batch Loss: 0.051660869270563126\n",
      "Epoch 2256, Loss: 0.22167300432920456, Final Batch Loss: 0.12668007612228394\n",
      "Epoch 2257, Loss: 0.153186596930027, Final Batch Loss: 0.07829739898443222\n",
      "Epoch 2258, Loss: 0.12778078764677048, Final Batch Loss: 0.055084727704524994\n",
      "Epoch 2259, Loss: 0.12837546318769455, Final Batch Loss: 0.05481136590242386\n",
      "Epoch 2260, Loss: 0.1590447835624218, Final Batch Loss: 0.036189015954732895\n",
      "Epoch 2261, Loss: 0.159237802028656, Final Batch Loss: 0.09186149388551712\n",
      "Epoch 2262, Loss: 0.11785231158137321, Final Batch Loss: 0.06346198171377182\n",
      "Epoch 2263, Loss: 0.1526520773768425, Final Batch Loss: 0.10052365064620972\n",
      "Epoch 2264, Loss: 0.10744483768939972, Final Batch Loss: 0.0626368597149849\n",
      "Epoch 2265, Loss: 0.20641054213047028, Final Batch Loss: 0.06288225948810577\n",
      "Epoch 2266, Loss: 0.12923408672213554, Final Batch Loss: 0.08217254281044006\n",
      "Epoch 2267, Loss: 0.13983390480279922, Final Batch Loss: 0.0750463604927063\n",
      "Epoch 2268, Loss: 0.15110662579536438, Final Batch Loss: 0.06717895716428757\n",
      "Epoch 2269, Loss: 0.10812339186668396, Final Batch Loss: 0.050330232828855515\n",
      "Epoch 2270, Loss: 0.1398773528635502, Final Batch Loss: 0.03547940030694008\n",
      "Epoch 2271, Loss: 0.19732323288917542, Final Batch Loss: 0.11544423550367355\n",
      "Epoch 2272, Loss: 0.11500559002161026, Final Batch Loss: 0.053305353969335556\n",
      "Epoch 2273, Loss: 0.17883945256471634, Final Batch Loss: 0.07162919640541077\n",
      "Epoch 2274, Loss: 0.10875287652015686, Final Batch Loss: 0.033052004873752594\n",
      "Epoch 2275, Loss: 0.10711422190070152, Final Batch Loss: 0.050864122807979584\n",
      "Epoch 2276, Loss: 0.1764865145087242, Final Batch Loss: 0.09266403317451477\n",
      "Epoch 2277, Loss: 0.11879102140665054, Final Batch Loss: 0.06432834267616272\n",
      "Epoch 2278, Loss: 0.13433294743299484, Final Batch Loss: 0.06991714984178543\n",
      "Epoch 2279, Loss: 0.1268150471150875, Final Batch Loss: 0.07087971270084381\n",
      "Epoch 2280, Loss: 0.10006534308195114, Final Batch Loss: 0.056202784180641174\n",
      "Epoch 2281, Loss: 0.1295384019613266, Final Batch Loss: 0.06298212707042694\n",
      "Epoch 2282, Loss: 0.19789205119013786, Final Batch Loss: 0.13846059143543243\n",
      "Epoch 2283, Loss: 0.12323100864887238, Final Batch Loss: 0.066959448158741\n",
      "Epoch 2284, Loss: 0.11878203600645065, Final Batch Loss: 0.04960072785615921\n",
      "Epoch 2285, Loss: 0.13351523876190186, Final Batch Loss: 0.06093841791152954\n",
      "Epoch 2286, Loss: 0.09745860658586025, Final Batch Loss: 0.06671052426099777\n",
      "Epoch 2287, Loss: 0.11020984128117561, Final Batch Loss: 0.03969511762261391\n",
      "Epoch 2288, Loss: 0.169138565659523, Final Batch Loss: 0.09334583580493927\n",
      "Epoch 2289, Loss: 0.10356646776199341, Final Batch Loss: 0.05787093564867973\n",
      "Epoch 2290, Loss: 0.19110437482595444, Final Batch Loss: 0.14434440433979034\n",
      "Epoch 2291, Loss: 0.11478659883141518, Final Batch Loss: 0.07211395353078842\n",
      "Epoch 2292, Loss: 0.15717178583145142, Final Batch Loss: 0.06065422296524048\n",
      "Epoch 2293, Loss: 0.13120005652308464, Final Batch Loss: 0.08531086146831512\n",
      "Epoch 2294, Loss: 0.1458924002945423, Final Batch Loss: 0.08718293905258179\n",
      "Epoch 2295, Loss: 0.14939433708786964, Final Batch Loss: 0.05621945485472679\n",
      "Epoch 2296, Loss: 0.11262024194002151, Final Batch Loss: 0.053476519882678986\n",
      "Epoch 2297, Loss: 0.14120181649923325, Final Batch Loss: 0.08245040476322174\n",
      "Epoch 2298, Loss: 0.12761543691158295, Final Batch Loss: 0.07213389873504639\n",
      "Epoch 2299, Loss: 0.119622141122818, Final Batch Loss: 0.06205007806420326\n",
      "Epoch 2300, Loss: 0.15993929654359818, Final Batch Loss: 0.06964783370494843\n",
      "Epoch 2301, Loss: 0.18327835947275162, Final Batch Loss: 0.1332501471042633\n",
      "Epoch 2302, Loss: 0.12444594129920006, Final Batch Loss: 0.07133200764656067\n",
      "Epoch 2303, Loss: 0.13589898124337196, Final Batch Loss: 0.09498383104801178\n",
      "Epoch 2304, Loss: 0.11752168834209442, Final Batch Loss: 0.052414968609809875\n",
      "Epoch 2305, Loss: 0.14866197109222412, Final Batch Loss: 0.07368524372577667\n",
      "Epoch 2306, Loss: 0.15206250920891762, Final Batch Loss: 0.09506994485855103\n",
      "Epoch 2307, Loss: 0.12656177952885628, Final Batch Loss: 0.05459325388073921\n",
      "Epoch 2308, Loss: 0.10535350069403648, Final Batch Loss: 0.05617412179708481\n",
      "Epoch 2309, Loss: 0.13124066963791847, Final Batch Loss: 0.08542317152023315\n",
      "Epoch 2310, Loss: 0.13728433102369308, Final Batch Loss: 0.04219302535057068\n",
      "Epoch 2311, Loss: 0.1508861929178238, Final Batch Loss: 0.08394309133291245\n",
      "Epoch 2312, Loss: 0.12372957170009613, Final Batch Loss: 0.07115194201469421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2313, Loss: 0.1501479148864746, Final Batch Loss: 0.07347835600376129\n",
      "Epoch 2314, Loss: 0.1040722019970417, Final Batch Loss: 0.03976332023739815\n",
      "Epoch 2315, Loss: 0.10417990386486053, Final Batch Loss: 0.05565901845693588\n",
      "Epoch 2316, Loss: 0.11800326406955719, Final Batch Loss: 0.060660891234874725\n",
      "Epoch 2317, Loss: 0.1362440325319767, Final Batch Loss: 0.057837460190057755\n",
      "Epoch 2318, Loss: 0.11018288508057594, Final Batch Loss: 0.05046423524618149\n",
      "Epoch 2319, Loss: 0.11967933177947998, Final Batch Loss: 0.05414576828479767\n",
      "Epoch 2320, Loss: 0.10596858710050583, Final Batch Loss: 0.03316255658864975\n",
      "Epoch 2321, Loss: 0.11828262358903885, Final Batch Loss: 0.058978576213121414\n",
      "Epoch 2322, Loss: 0.09220992401242256, Final Batch Loss: 0.035573430359363556\n",
      "Epoch 2323, Loss: 0.10833925753831863, Final Batch Loss: 0.045088693499565125\n",
      "Epoch 2324, Loss: 0.09053367003798485, Final Batch Loss: 0.044314488768577576\n",
      "Epoch 2325, Loss: 0.10698531940579414, Final Batch Loss: 0.04574069380760193\n",
      "Epoch 2326, Loss: 0.18062199652194977, Final Batch Loss: 0.11724808812141418\n",
      "Epoch 2327, Loss: 0.14763911068439484, Final Batch Loss: 0.07622009515762329\n",
      "Epoch 2328, Loss: 0.09771199896931648, Final Batch Loss: 0.04711074382066727\n",
      "Epoch 2329, Loss: 0.12709388881921768, Final Batch Loss: 0.08060137927532196\n",
      "Epoch 2330, Loss: 0.10617771744728088, Final Batch Loss: 0.0455126017332077\n",
      "Epoch 2331, Loss: 0.10893246531486511, Final Batch Loss: 0.057754036039114\n",
      "Epoch 2332, Loss: 0.09830956533551216, Final Batch Loss: 0.060172513127326965\n",
      "Epoch 2333, Loss: 0.13213041797280312, Final Batch Loss: 0.06992234289646149\n",
      "Epoch 2334, Loss: 0.1265970692038536, Final Batch Loss: 0.07067620009183884\n",
      "Epoch 2335, Loss: 0.11149662733078003, Final Batch Loss: 0.04741872102022171\n",
      "Epoch 2336, Loss: 0.10073184594511986, Final Batch Loss: 0.04184029623866081\n",
      "Epoch 2337, Loss: 0.12402313575148582, Final Batch Loss: 0.07140320539474487\n",
      "Epoch 2338, Loss: 0.1014649011194706, Final Batch Loss: 0.05327421426773071\n",
      "Epoch 2339, Loss: 0.1235521212220192, Final Batch Loss: 0.07579725980758667\n",
      "Epoch 2340, Loss: 0.08283255994319916, Final Batch Loss: 0.03596316650509834\n",
      "Epoch 2341, Loss: 0.12009798362851143, Final Batch Loss: 0.060345981270074844\n",
      "Epoch 2342, Loss: 0.1173744946718216, Final Batch Loss: 0.04931215941905975\n",
      "Epoch 2343, Loss: 0.10871896520256996, Final Batch Loss: 0.06617189198732376\n",
      "Epoch 2344, Loss: 0.11753377690911293, Final Batch Loss: 0.05715932324528694\n",
      "Epoch 2345, Loss: 0.12399974465370178, Final Batch Loss: 0.048772796988487244\n",
      "Epoch 2346, Loss: 0.1023627445101738, Final Batch Loss: 0.06610109657049179\n",
      "Epoch 2347, Loss: 0.11198487877845764, Final Batch Loss: 0.05878223478794098\n",
      "Epoch 2348, Loss: 0.1367020681500435, Final Batch Loss: 0.06426682323217392\n",
      "Epoch 2349, Loss: 0.11485605686903, Final Batch Loss: 0.04205826669931412\n",
      "Epoch 2350, Loss: 0.09019042924046516, Final Batch Loss: 0.04362277314066887\n",
      "Epoch 2351, Loss: 0.10385766625404358, Final Batch Loss: 0.05300566926598549\n",
      "Epoch 2352, Loss: 0.1256938874721527, Final Batch Loss: 0.05613287538290024\n",
      "Epoch 2353, Loss: 0.0991811528801918, Final Batch Loss: 0.05060248821973801\n",
      "Epoch 2354, Loss: 0.12237120792269707, Final Batch Loss: 0.07939712703227997\n",
      "Epoch 2355, Loss: 0.10378988459706306, Final Batch Loss: 0.05544830486178398\n",
      "Epoch 2356, Loss: 0.09730077162384987, Final Batch Loss: 0.04479671269655228\n",
      "Epoch 2357, Loss: 0.10627071186900139, Final Batch Loss: 0.04991346225142479\n",
      "Epoch 2358, Loss: 0.12101970240473747, Final Batch Loss: 0.06668844819068909\n",
      "Epoch 2359, Loss: 0.12972798198461533, Final Batch Loss: 0.07899554818868637\n",
      "Epoch 2360, Loss: 0.09652162715792656, Final Batch Loss: 0.05143717676401138\n",
      "Epoch 2361, Loss: 0.10068114846944809, Final Batch Loss: 0.049898285418748856\n",
      "Epoch 2362, Loss: 0.1144568994641304, Final Batch Loss: 0.04941083490848541\n",
      "Epoch 2363, Loss: 0.12368298321962357, Final Batch Loss: 0.0454532727599144\n",
      "Epoch 2364, Loss: 0.11858591064810753, Final Batch Loss: 0.0698150172829628\n",
      "Epoch 2365, Loss: 0.10332533344626427, Final Batch Loss: 0.05796980485320091\n",
      "Epoch 2366, Loss: 0.12295463308691978, Final Batch Loss: 0.06133681535720825\n",
      "Epoch 2367, Loss: 0.10189836844801903, Final Batch Loss: 0.03882453218102455\n",
      "Epoch 2368, Loss: 0.1048782430589199, Final Batch Loss: 0.034564319998025894\n",
      "Epoch 2369, Loss: 0.1280994862318039, Final Batch Loss: 0.06465496867895126\n",
      "Epoch 2370, Loss: 0.10716474428772926, Final Batch Loss: 0.03249343857169151\n",
      "Epoch 2371, Loss: 0.09554142132401466, Final Batch Loss: 0.058603476732969284\n",
      "Epoch 2372, Loss: 0.09300059452652931, Final Batch Loss: 0.03879083693027496\n",
      "Epoch 2373, Loss: 0.1463773548603058, Final Batch Loss: 0.08226755261421204\n",
      "Epoch 2374, Loss: 0.14399105310440063, Final Batch Loss: 0.06134733557701111\n",
      "Epoch 2375, Loss: 0.11992371082305908, Final Batch Loss: 0.04366719722747803\n",
      "Epoch 2376, Loss: 0.10521693900227547, Final Batch Loss: 0.06006011366844177\n",
      "Epoch 2377, Loss: 0.10902810469269753, Final Batch Loss: 0.05050420016050339\n",
      "Epoch 2378, Loss: 0.10959570854902267, Final Batch Loss: 0.07266556471586227\n",
      "Epoch 2379, Loss: 0.13080087304115295, Final Batch Loss: 0.06637797504663467\n",
      "Epoch 2380, Loss: 0.11138293892145157, Final Batch Loss: 0.03955921530723572\n",
      "Epoch 2381, Loss: 0.14528951048851013, Final Batch Loss: 0.08076045662164688\n",
      "Epoch 2382, Loss: 0.11339474841952324, Final Batch Loss: 0.05991259217262268\n",
      "Epoch 2383, Loss: 0.10367899388074875, Final Batch Loss: 0.056066323071718216\n",
      "Epoch 2384, Loss: 0.14670997858047485, Final Batch Loss: 0.07021980732679367\n",
      "Epoch 2385, Loss: 0.14617646485567093, Final Batch Loss: 0.06834396719932556\n",
      "Epoch 2386, Loss: 0.15019598230719566, Final Batch Loss: 0.061919841915369034\n",
      "Epoch 2387, Loss: 0.09674832224845886, Final Batch Loss: 0.044600918889045715\n",
      "Epoch 2388, Loss: 0.12386219203472137, Final Batch Loss: 0.033868856728076935\n",
      "Epoch 2389, Loss: 0.13536236807703972, Final Batch Loss: 0.04991375282406807\n",
      "Epoch 2390, Loss: 0.16364430636167526, Final Batch Loss: 0.07377074658870697\n",
      "Epoch 2391, Loss: 0.12046746164560318, Final Batch Loss: 0.040401920676231384\n",
      "Epoch 2392, Loss: 0.13258004933595657, Final Batch Loss: 0.06842594593763351\n",
      "Epoch 2393, Loss: 0.1232931986451149, Final Batch Loss: 0.07002703100442886\n",
      "Epoch 2394, Loss: 0.16007579118013382, Final Batch Loss: 0.09021936357021332\n",
      "Epoch 2395, Loss: 0.10879404470324516, Final Batch Loss: 0.059208646416664124\n",
      "Epoch 2396, Loss: 0.10844334959983826, Final Batch Loss: 0.06502882391214371\n",
      "Epoch 2397, Loss: 0.11968512460589409, Final Batch Loss: 0.06530433148145676\n",
      "Epoch 2398, Loss: 0.15017539262771606, Final Batch Loss: 0.09375202655792236\n",
      "Epoch 2399, Loss: 0.12992704659700394, Final Batch Loss: 0.0435589924454689\n",
      "Epoch 2400, Loss: 0.12168238312005997, Final Batch Loss: 0.0703267976641655\n",
      "Epoch 2401, Loss: 0.11426176875829697, Final Batch Loss: 0.0389176607131958\n",
      "Epoch 2402, Loss: 0.1300366036593914, Final Batch Loss: 0.054001178592443466\n",
      "Epoch 2403, Loss: 0.12961873039603233, Final Batch Loss: 0.03915325179696083\n",
      "Epoch 2404, Loss: 0.13483185693621635, Final Batch Loss: 0.07319987565279007\n",
      "Epoch 2405, Loss: 0.1365259326994419, Final Batch Loss: 0.0831349715590477\n",
      "Epoch 2406, Loss: 0.10557331889867783, Final Batch Loss: 0.0510728619992733\n",
      "Epoch 2407, Loss: 0.1575072854757309, Final Batch Loss: 0.07846365123987198\n",
      "Epoch 2408, Loss: 0.14112868905067444, Final Batch Loss: 0.0703093409538269\n",
      "Epoch 2409, Loss: 0.11896396800875664, Final Batch Loss: 0.0733506828546524\n",
      "Epoch 2410, Loss: 0.138605035841465, Final Batch Loss: 0.06287869811058044\n",
      "Epoch 2411, Loss: 0.14192594587802887, Final Batch Loss: 0.08966745436191559\n",
      "Epoch 2412, Loss: 0.11424974724650383, Final Batch Loss: 0.05387203395366669\n",
      "Epoch 2413, Loss: 0.15953979641199112, Final Batch Loss: 0.06433234363794327\n",
      "Epoch 2414, Loss: 0.11471135541796684, Final Batch Loss: 0.06895533949136734\n",
      "Epoch 2415, Loss: 0.133833646774292, Final Batch Loss: 0.03757088631391525\n",
      "Epoch 2416, Loss: 0.09485553205013275, Final Batch Loss: 0.053346745669841766\n",
      "Epoch 2417, Loss: 0.16925621777772903, Final Batch Loss: 0.08735102415084839\n",
      "Epoch 2418, Loss: 0.10806138440966606, Final Batch Loss: 0.04629642143845558\n",
      "Epoch 2419, Loss: 0.14906394481658936, Final Batch Loss: 0.09350090473890305\n",
      "Epoch 2420, Loss: 0.11647576466202736, Final Batch Loss: 0.042120132595300674\n",
      "Epoch 2421, Loss: 0.11299684271216393, Final Batch Loss: 0.057338859885931015\n",
      "Epoch 2422, Loss: 0.1470196284353733, Final Batch Loss: 0.08708211779594421\n",
      "Epoch 2423, Loss: 0.11958825960755348, Final Batch Loss: 0.052669379860162735\n",
      "Epoch 2424, Loss: 0.09925584122538567, Final Batch Loss: 0.03492767736315727\n",
      "Epoch 2425, Loss: 0.13512872532010078, Final Batch Loss: 0.032096076756715775\n",
      "Epoch 2426, Loss: 0.13031262159347534, Final Batch Loss: 0.07215952128171921\n",
      "Epoch 2427, Loss: 0.10048102214932442, Final Batch Loss: 0.05444151163101196\n",
      "Epoch 2428, Loss: 0.18519758433103561, Final Batch Loss: 0.10570847243070602\n",
      "Epoch 2429, Loss: 0.09710665047168732, Final Batch Loss: 0.033708326518535614\n",
      "Epoch 2430, Loss: 0.127960916608572, Final Batch Loss: 0.08046004176139832\n",
      "Epoch 2431, Loss: 0.12020599842071533, Final Batch Loss: 0.04370534420013428\n",
      "Epoch 2432, Loss: 0.14188969880342484, Final Batch Loss: 0.07453039288520813\n",
      "Epoch 2433, Loss: 0.10713532753288746, Final Batch Loss: 0.07670462131500244\n",
      "Epoch 2434, Loss: 0.10028061456978321, Final Batch Loss: 0.025667252019047737\n",
      "Epoch 2435, Loss: 0.12945134937763214, Final Batch Loss: 0.029722653329372406\n",
      "Epoch 2436, Loss: 0.12193239852786064, Final Batch Loss: 0.07241575419902802\n",
      "Epoch 2437, Loss: 0.10253176465630531, Final Batch Loss: 0.042693354189395905\n",
      "Epoch 2438, Loss: 0.12907158955931664, Final Batch Loss: 0.07514638453722\n",
      "Epoch 2439, Loss: 0.11294977739453316, Final Batch Loss: 0.05087714269757271\n",
      "Epoch 2440, Loss: 0.09159498289227486, Final Batch Loss: 0.04884839430451393\n",
      "Epoch 2441, Loss: 0.1067647635936737, Final Batch Loss: 0.04999280720949173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2442, Loss: 0.10534273460507393, Final Batch Loss: 0.051412612199783325\n",
      "Epoch 2443, Loss: 0.11641929671168327, Final Batch Loss: 0.055776197463274\n",
      "Epoch 2444, Loss: 0.12603935226798058, Final Batch Loss: 0.04330748692154884\n",
      "Epoch 2445, Loss: 0.11424090340733528, Final Batch Loss: 0.06612800061702728\n",
      "Epoch 2446, Loss: 0.13599112629890442, Final Batch Loss: 0.04183697700500488\n",
      "Epoch 2447, Loss: 0.1404695138335228, Final Batch Loss: 0.06101972609758377\n",
      "Epoch 2448, Loss: 0.10356280580163002, Final Batch Loss: 0.050947029143571854\n",
      "Epoch 2449, Loss: 0.17412232980132103, Final Batch Loss: 0.12648704648017883\n",
      "Epoch 2450, Loss: 0.1324472613632679, Final Batch Loss: 0.08704068511724472\n",
      "Epoch 2451, Loss: 0.15541959553956985, Final Batch Loss: 0.060740597546100616\n",
      "Epoch 2452, Loss: 0.16045765206217766, Final Batch Loss: 0.059829678386449814\n",
      "Epoch 2453, Loss: 0.1967172622680664, Final Batch Loss: 0.1337064951658249\n",
      "Epoch 2454, Loss: 0.1715015433728695, Final Batch Loss: 0.057260628789663315\n",
      "Epoch 2455, Loss: 0.12026642635464668, Final Batch Loss: 0.04334021732211113\n",
      "Epoch 2456, Loss: 0.14638756960630417, Final Batch Loss: 0.08168484270572662\n",
      "Epoch 2457, Loss: 0.12805640697479248, Final Batch Loss: 0.04626867175102234\n",
      "Epoch 2458, Loss: 0.14341408386826515, Final Batch Loss: 0.09617682546377182\n",
      "Epoch 2459, Loss: 0.12188784405589104, Final Batch Loss: 0.07803671807050705\n",
      "Epoch 2460, Loss: 0.12369318306446075, Final Batch Loss: 0.04811626672744751\n",
      "Epoch 2461, Loss: 0.10656597465276718, Final Batch Loss: 0.0528499111533165\n",
      "Epoch 2462, Loss: 0.1393922045826912, Final Batch Loss: 0.07229366153478622\n",
      "Epoch 2463, Loss: 0.14258822426199913, Final Batch Loss: 0.06090451404452324\n",
      "Epoch 2464, Loss: 0.12280447408556938, Final Batch Loss: 0.07575001567602158\n",
      "Epoch 2465, Loss: 0.14122527465224266, Final Batch Loss: 0.09121339023113251\n",
      "Epoch 2466, Loss: 0.1460501216351986, Final Batch Loss: 0.10037792474031448\n",
      "Epoch 2467, Loss: 0.1454695239663124, Final Batch Loss: 0.08216311037540436\n",
      "Epoch 2468, Loss: 0.11053679883480072, Final Batch Loss: 0.04177772253751755\n",
      "Epoch 2469, Loss: 0.13850998878479004, Final Batch Loss: 0.07338353991508484\n",
      "Epoch 2470, Loss: 0.13213186711072922, Final Batch Loss: 0.05037986487150192\n",
      "Epoch 2471, Loss: 0.13318878784775734, Final Batch Loss: 0.078375905752182\n",
      "Epoch 2472, Loss: 0.14312855154275894, Final Batch Loss: 0.0991286188364029\n",
      "Epoch 2473, Loss: 0.12012147530913353, Final Batch Loss: 0.06346146762371063\n",
      "Epoch 2474, Loss: 0.11478433758020401, Final Batch Loss: 0.05966268107295036\n",
      "Epoch 2475, Loss: 0.14461420103907585, Final Batch Loss: 0.05577491596341133\n",
      "Epoch 2476, Loss: 0.11149827763438225, Final Batch Loss: 0.06014545261859894\n",
      "Epoch 2477, Loss: 0.14887870848178864, Final Batch Loss: 0.08156650513410568\n",
      "Epoch 2478, Loss: 0.13725776597857475, Final Batch Loss: 0.07581700384616852\n",
      "Epoch 2479, Loss: 0.1028260700404644, Final Batch Loss: 0.05026749521493912\n",
      "Epoch 2480, Loss: 0.14250919222831726, Final Batch Loss: 0.05758614093065262\n",
      "Epoch 2481, Loss: 0.1432650350034237, Final Batch Loss: 0.05960218235850334\n",
      "Epoch 2482, Loss: 0.12461680546402931, Final Batch Loss: 0.06726567447185516\n",
      "Epoch 2483, Loss: 0.130307849496603, Final Batch Loss: 0.09266582131385803\n",
      "Epoch 2484, Loss: 0.10956938192248344, Final Batch Loss: 0.05861306190490723\n",
      "Epoch 2485, Loss: 0.13322777301073074, Final Batch Loss: 0.06213432550430298\n",
      "Epoch 2486, Loss: 0.10263321176171303, Final Batch Loss: 0.04680277407169342\n",
      "Epoch 2487, Loss: 0.17678965628147125, Final Batch Loss: 0.09462186694145203\n",
      "Epoch 2488, Loss: 0.10187409445643425, Final Batch Loss: 0.04730268567800522\n",
      "Epoch 2489, Loss: 0.1027296856045723, Final Batch Loss: 0.04450526461005211\n",
      "Epoch 2490, Loss: 0.13625570759177208, Final Batch Loss: 0.05346732214093208\n",
      "Epoch 2491, Loss: 0.1601904071867466, Final Batch Loss: 0.04234164580702782\n",
      "Epoch 2492, Loss: 0.11900357529520988, Final Batch Loss: 0.0646929070353508\n",
      "Epoch 2493, Loss: 0.14493941143155098, Final Batch Loss: 0.09695535153150558\n",
      "Epoch 2494, Loss: 0.13322992250323296, Final Batch Loss: 0.051189396530389786\n",
      "Epoch 2495, Loss: 0.09606324881315231, Final Batch Loss: 0.038875844329595566\n",
      "Epoch 2496, Loss: 0.10975638404488564, Final Batch Loss: 0.03775725141167641\n",
      "Epoch 2497, Loss: 0.09013741463422775, Final Batch Loss: 0.037439342588186264\n",
      "Epoch 2498, Loss: 0.10456759482622147, Final Batch Loss: 0.046405524015426636\n",
      "Epoch 2499, Loss: 0.13576235994696617, Final Batch Loss: 0.05941711738705635\n",
      "Epoch 2500, Loss: 0.11138760671019554, Final Batch Loss: 0.0644720196723938\n",
      "Epoch 2501, Loss: 0.11098622903227806, Final Batch Loss: 0.04761773720383644\n",
      "Epoch 2502, Loss: 0.13799844682216644, Final Batch Loss: 0.0764617994427681\n",
      "Epoch 2503, Loss: 0.12652504816651344, Final Batch Loss: 0.07007813453674316\n",
      "Epoch 2504, Loss: 0.10334868356585503, Final Batch Loss: 0.04971272498369217\n",
      "Epoch 2505, Loss: 0.14065268635749817, Final Batch Loss: 0.061218492686748505\n",
      "Epoch 2506, Loss: 0.10975280404090881, Final Batch Loss: 0.04837063327431679\n",
      "Epoch 2507, Loss: 0.16052693501114845, Final Batch Loss: 0.11021941155195236\n",
      "Epoch 2508, Loss: 0.1329626739025116, Final Batch Loss: 0.06866886466741562\n",
      "Epoch 2509, Loss: 0.13778140395879745, Final Batch Loss: 0.07602103799581528\n",
      "Epoch 2510, Loss: 0.10075419768691063, Final Batch Loss: 0.051340289413928986\n",
      "Epoch 2511, Loss: 0.09722915664315224, Final Batch Loss: 0.038252800703048706\n",
      "Epoch 2512, Loss: 0.11757442355155945, Final Batch Loss: 0.06242866441607475\n",
      "Epoch 2513, Loss: 0.09379886835813522, Final Batch Loss: 0.04093928635120392\n",
      "Epoch 2514, Loss: 0.11881650611758232, Final Batch Loss: 0.06725668162107468\n",
      "Epoch 2515, Loss: 0.11381525918841362, Final Batch Loss: 0.044995877891778946\n",
      "Epoch 2516, Loss: 0.11174299195408821, Final Batch Loss: 0.05305176600813866\n",
      "Epoch 2517, Loss: 0.12075246497988701, Final Batch Loss: 0.056880880147218704\n",
      "Epoch 2518, Loss: 0.10619403794407845, Final Batch Loss: 0.050768300890922546\n",
      "Epoch 2519, Loss: 0.119423508644104, Final Batch Loss: 0.06154388189315796\n",
      "Epoch 2520, Loss: 0.10392147302627563, Final Batch Loss: 0.04869422689080238\n",
      "Epoch 2521, Loss: 0.1212705485522747, Final Batch Loss: 0.06028350442647934\n",
      "Epoch 2522, Loss: 0.1201881505548954, Final Batch Loss: 0.053958069533109665\n",
      "Epoch 2523, Loss: 0.14833148941397667, Final Batch Loss: 0.09522861987352371\n",
      "Epoch 2524, Loss: 0.10828912258148193, Final Batch Loss: 0.051601409912109375\n",
      "Epoch 2525, Loss: 0.11608735099434853, Final Batch Loss: 0.05416957288980484\n",
      "Epoch 2526, Loss: 0.1059705875813961, Final Batch Loss: 0.05274179205298424\n",
      "Epoch 2527, Loss: 0.13055895268917084, Final Batch Loss: 0.04217442125082016\n",
      "Epoch 2528, Loss: 0.10502662882208824, Final Batch Loss: 0.06084822490811348\n",
      "Epoch 2529, Loss: 0.17590585350990295, Final Batch Loss: 0.10430432111024857\n",
      "Epoch 2530, Loss: 0.10409260913729668, Final Batch Loss: 0.044088151305913925\n",
      "Epoch 2531, Loss: 0.09275520220398903, Final Batch Loss: 0.033791929483413696\n",
      "Epoch 2532, Loss: 0.1422845721244812, Final Batch Loss: 0.06610573083162308\n",
      "Epoch 2533, Loss: 0.11175920069217682, Final Batch Loss: 0.06192685663700104\n",
      "Epoch 2534, Loss: 0.11325887590646744, Final Batch Loss: 0.05223919078707695\n",
      "Epoch 2535, Loss: 0.14865824580192566, Final Batch Loss: 0.07559116184711456\n",
      "Epoch 2536, Loss: 0.13898306339979172, Final Batch Loss: 0.08001964539289474\n",
      "Epoch 2537, Loss: 0.09225012175738811, Final Batch Loss: 0.029135553166270256\n",
      "Epoch 2538, Loss: 0.15571431070566177, Final Batch Loss: 0.06282024085521698\n",
      "Epoch 2539, Loss: 0.11228036507964134, Final Batch Loss: 0.04479930177330971\n",
      "Epoch 2540, Loss: 0.11927419528365135, Final Batch Loss: 0.06418221443891525\n",
      "Epoch 2541, Loss: 0.12656254321336746, Final Batch Loss: 0.08547182381153107\n",
      "Epoch 2542, Loss: 0.23164409399032593, Final Batch Loss: 0.1650737226009369\n",
      "Epoch 2543, Loss: 0.14752503111958504, Final Batch Loss: 0.04661240056157112\n",
      "Epoch 2544, Loss: 0.11996026337146759, Final Batch Loss: 0.0690407082438469\n",
      "Epoch 2545, Loss: 0.11353416368365288, Final Batch Loss: 0.053247176110744476\n",
      "Epoch 2546, Loss: 0.1934441402554512, Final Batch Loss: 0.10700589418411255\n",
      "Epoch 2547, Loss: 0.12952685728669167, Final Batch Loss: 0.0868721678853035\n",
      "Epoch 2548, Loss: 0.1387949027121067, Final Batch Loss: 0.08153281360864639\n",
      "Epoch 2549, Loss: 0.12932666763663292, Final Batch Loss: 0.04986284300684929\n",
      "Epoch 2550, Loss: 0.10715778917074203, Final Batch Loss: 0.06416620314121246\n",
      "Epoch 2551, Loss: 0.14797013998031616, Final Batch Loss: 0.0651186853647232\n",
      "Epoch 2552, Loss: 0.0975947454571724, Final Batch Loss: 0.04389873892068863\n",
      "Epoch 2553, Loss: 0.11692818626761436, Final Batch Loss: 0.052566368132829666\n",
      "Epoch 2554, Loss: 0.10275809466838837, Final Batch Loss: 0.035893358290195465\n",
      "Epoch 2555, Loss: 0.11335841566324234, Final Batch Loss: 0.06274908035993576\n",
      "Epoch 2556, Loss: 0.14487771317362785, Final Batch Loss: 0.09788099676370621\n",
      "Epoch 2557, Loss: 0.11557123810052872, Final Batch Loss: 0.05571403726935387\n",
      "Epoch 2558, Loss: 0.12022870406508446, Final Batch Loss: 0.04911008104681969\n",
      "Epoch 2559, Loss: 0.1329224817454815, Final Batch Loss: 0.0837559625506401\n",
      "Epoch 2560, Loss: 0.10964849963784218, Final Batch Loss: 0.0682566687464714\n",
      "Epoch 2561, Loss: 0.10482652857899666, Final Batch Loss: 0.041819099336862564\n",
      "Epoch 2562, Loss: 0.12796727940440178, Final Batch Loss: 0.0693625658750534\n",
      "Epoch 2563, Loss: 0.1151597872376442, Final Batch Loss: 0.05076635628938675\n",
      "Epoch 2564, Loss: 0.15854912251234055, Final Batch Loss: 0.07865867763757706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2565, Loss: 0.1291213296353817, Final Batch Loss: 0.08613640815019608\n",
      "Epoch 2566, Loss: 0.09786379337310791, Final Batch Loss: 0.044389043003320694\n",
      "Epoch 2567, Loss: 0.20840739458799362, Final Batch Loss: 0.10854210704565048\n",
      "Epoch 2568, Loss: 0.13067985698580742, Final Batch Loss: 0.07692045718431473\n",
      "Epoch 2569, Loss: 0.12161251902580261, Final Batch Loss: 0.05546671897172928\n",
      "Epoch 2570, Loss: 0.14385828003287315, Final Batch Loss: 0.057976651936769485\n",
      "Epoch 2571, Loss: 0.1082194522023201, Final Batch Loss: 0.047040779143571854\n",
      "Epoch 2572, Loss: 0.09531339630484581, Final Batch Loss: 0.04404585808515549\n",
      "Epoch 2573, Loss: 0.10412721708416939, Final Batch Loss: 0.04406571760773659\n",
      "Epoch 2574, Loss: 0.11747664213180542, Final Batch Loss: 0.0673103779554367\n",
      "Epoch 2575, Loss: 0.0995505303144455, Final Batch Loss: 0.028377197682857513\n",
      "Epoch 2576, Loss: 0.15208544954657555, Final Batch Loss: 0.09077082574367523\n",
      "Epoch 2577, Loss: 0.10076141729950905, Final Batch Loss: 0.06326604634523392\n",
      "Epoch 2578, Loss: 0.10351412370800972, Final Batch Loss: 0.05765484645962715\n",
      "Epoch 2579, Loss: 0.11439957842230797, Final Batch Loss: 0.05232173576951027\n",
      "Epoch 2580, Loss: 0.11319111287593842, Final Batch Loss: 0.06851223856210709\n",
      "Epoch 2581, Loss: 0.08862288296222687, Final Batch Loss: 0.037557754665613174\n",
      "Epoch 2582, Loss: 0.10564205422997475, Final Batch Loss: 0.05669444054365158\n",
      "Epoch 2583, Loss: 0.1018001064658165, Final Batch Loss: 0.07052647322416306\n",
      "Epoch 2584, Loss: 0.12210967764258385, Final Batch Loss: 0.046167876571416855\n",
      "Epoch 2585, Loss: 0.10912720486521721, Final Batch Loss: 0.053000763058662415\n",
      "Epoch 2586, Loss: 0.09876952692866325, Final Batch Loss: 0.041533008217811584\n",
      "Epoch 2587, Loss: 0.09679858386516571, Final Batch Loss: 0.047622423619031906\n",
      "Epoch 2588, Loss: 0.10393080115318298, Final Batch Loss: 0.060775019228458405\n",
      "Epoch 2589, Loss: 0.13016336411237717, Final Batch Loss: 0.09066599607467651\n",
      "Epoch 2590, Loss: 0.12607136741280556, Final Batch Loss: 0.0597904808819294\n",
      "Epoch 2591, Loss: 0.1260303556919098, Final Batch Loss: 0.05300070345401764\n",
      "Epoch 2592, Loss: 0.11572104692459106, Final Batch Loss: 0.059503402560949326\n",
      "Epoch 2593, Loss: 0.09776213765144348, Final Batch Loss: 0.04919527471065521\n",
      "Epoch 2594, Loss: 0.0977885015308857, Final Batch Loss: 0.04943821579217911\n",
      "Epoch 2595, Loss: 0.11192653700709343, Final Batch Loss: 0.04116414114832878\n",
      "Epoch 2596, Loss: 0.11083835363388062, Final Batch Loss: 0.04598792642354965\n",
      "Epoch 2597, Loss: 0.10772554948925972, Final Batch Loss: 0.050976771861314774\n",
      "Epoch 2598, Loss: 0.13572799414396286, Final Batch Loss: 0.06318575143814087\n",
      "Epoch 2599, Loss: 0.11849438771605492, Final Batch Loss: 0.03837045654654503\n",
      "Epoch 2600, Loss: 0.11254074424505234, Final Batch Loss: 0.047948263585567474\n",
      "Epoch 2601, Loss: 0.14349009469151497, Final Batch Loss: 0.05303238704800606\n",
      "Epoch 2602, Loss: 0.12582232803106308, Final Batch Loss: 0.07529598474502563\n",
      "Epoch 2603, Loss: 0.11505692079663277, Final Batch Loss: 0.062268394976854324\n",
      "Epoch 2604, Loss: 0.13406728208065033, Final Batch Loss: 0.06955328583717346\n",
      "Epoch 2605, Loss: 0.09386288374662399, Final Batch Loss: 0.037198249250650406\n",
      "Epoch 2606, Loss: 0.17202310264110565, Final Batch Loss: 0.12117864191532135\n",
      "Epoch 2607, Loss: 0.11159494891762733, Final Batch Loss: 0.05388755351305008\n",
      "Epoch 2608, Loss: 0.10685297474265099, Final Batch Loss: 0.05029614642262459\n",
      "Epoch 2609, Loss: 0.12196439877152443, Final Batch Loss: 0.049482036381959915\n",
      "Epoch 2610, Loss: 0.1535620614886284, Final Batch Loss: 0.08565498143434525\n",
      "Epoch 2611, Loss: 0.10555604100227356, Final Batch Loss: 0.04304654896259308\n",
      "Epoch 2612, Loss: 0.11495207250118256, Final Batch Loss: 0.05289117991924286\n",
      "Epoch 2613, Loss: 0.12051189690828323, Final Batch Loss: 0.0570438876748085\n",
      "Epoch 2614, Loss: 0.132131427526474, Final Batch Loss: 0.06727033853530884\n",
      "Epoch 2615, Loss: 0.10630924254655838, Final Batch Loss: 0.060237541794776917\n",
      "Epoch 2616, Loss: 0.12652142345905304, Final Batch Loss: 0.08353719860315323\n",
      "Epoch 2617, Loss: 0.10756652057170868, Final Batch Loss: 0.05322880670428276\n",
      "Epoch 2618, Loss: 0.09772930294275284, Final Batch Loss: 0.06532008200883865\n",
      "Epoch 2619, Loss: 0.13575998321175575, Final Batch Loss: 0.08473265171051025\n",
      "Epoch 2620, Loss: 0.11992312967777252, Final Batch Loss: 0.049595534801483154\n",
      "Epoch 2621, Loss: 0.10314983874559402, Final Batch Loss: 0.033031679689884186\n",
      "Epoch 2622, Loss: 0.11347095668315887, Final Batch Loss: 0.07046085596084595\n",
      "Epoch 2623, Loss: 0.1397479772567749, Final Batch Loss: 0.07831709831953049\n",
      "Epoch 2624, Loss: 0.09859400615096092, Final Batch Loss: 0.04425100237131119\n",
      "Epoch 2625, Loss: 0.11396471410989761, Final Batch Loss: 0.049805209040641785\n",
      "Epoch 2626, Loss: 0.1574445441365242, Final Batch Loss: 0.07285408675670624\n",
      "Epoch 2627, Loss: 0.10806465521454811, Final Batch Loss: 0.05240045115351677\n",
      "Epoch 2628, Loss: 0.1292651891708374, Final Batch Loss: 0.06094972789287567\n",
      "Epoch 2629, Loss: 0.12347337231040001, Final Batch Loss: 0.06333420425653458\n",
      "Epoch 2630, Loss: 0.10917257145047188, Final Batch Loss: 0.06270850449800491\n",
      "Epoch 2631, Loss: 0.10401803255081177, Final Batch Loss: 0.05746353417634964\n",
      "Epoch 2632, Loss: 0.09413076192140579, Final Batch Loss: 0.044282786548137665\n",
      "Epoch 2633, Loss: 0.0889466218650341, Final Batch Loss: 0.04202647507190704\n",
      "Epoch 2634, Loss: 0.10915977880358696, Final Batch Loss: 0.06413844227790833\n",
      "Epoch 2635, Loss: 0.12679842859506607, Final Batch Loss: 0.08745964616537094\n",
      "Epoch 2636, Loss: 0.11738364398479462, Final Batch Loss: 0.08640255779027939\n",
      "Epoch 2637, Loss: 0.1195543222129345, Final Batch Loss: 0.04868491366505623\n",
      "Epoch 2638, Loss: 0.08583078533411026, Final Batch Loss: 0.05202687904238701\n",
      "Epoch 2639, Loss: 0.13763072714209557, Final Batch Loss: 0.08576439321041107\n",
      "Epoch 2640, Loss: 0.11209461838006973, Final Batch Loss: 0.04976854845881462\n",
      "Epoch 2641, Loss: 0.12963315472006798, Final Batch Loss: 0.047391634434461594\n",
      "Epoch 2642, Loss: 0.09872641414403915, Final Batch Loss: 0.04497738555073738\n",
      "Epoch 2643, Loss: 0.1273704245686531, Final Batch Loss: 0.054855622351169586\n",
      "Epoch 2644, Loss: 0.10433527454733849, Final Batch Loss: 0.06164833903312683\n",
      "Epoch 2645, Loss: 0.0883905440568924, Final Batch Loss: 0.045176975429058075\n",
      "Epoch 2646, Loss: 0.11437296867370605, Final Batch Loss: 0.07836584746837616\n",
      "Epoch 2647, Loss: 0.10583274811506271, Final Batch Loss: 0.06140446662902832\n",
      "Epoch 2648, Loss: 0.10271664336323738, Final Batch Loss: 0.05185990035533905\n",
      "Epoch 2649, Loss: 0.17471080273389816, Final Batch Loss: 0.07289598882198334\n",
      "Epoch 2650, Loss: 0.10197683796286583, Final Batch Loss: 0.0423184372484684\n",
      "Epoch 2651, Loss: 0.08123936131596565, Final Batch Loss: 0.041693054139614105\n",
      "Epoch 2652, Loss: 0.11747915297746658, Final Batch Loss: 0.07517467439174652\n",
      "Epoch 2653, Loss: 0.1724592223763466, Final Batch Loss: 0.08013930916786194\n",
      "Epoch 2654, Loss: 0.15310855954885483, Final Batch Loss: 0.10240428894758224\n",
      "Epoch 2655, Loss: 0.10462983697652817, Final Batch Loss: 0.06638260185718536\n",
      "Epoch 2656, Loss: 0.10356999188661575, Final Batch Loss: 0.04608892649412155\n",
      "Epoch 2657, Loss: 0.14673181623220444, Final Batch Loss: 0.07771191000938416\n",
      "Epoch 2658, Loss: 0.10215252637863159, Final Batch Loss: 0.05791784077882767\n",
      "Epoch 2659, Loss: 0.1186075285077095, Final Batch Loss: 0.07580690085887909\n",
      "Epoch 2660, Loss: 0.1595778837800026, Final Batch Loss: 0.09868945926427841\n",
      "Epoch 2661, Loss: 0.09324022382497787, Final Batch Loss: 0.04924808442592621\n",
      "Epoch 2662, Loss: 0.14815335720777512, Final Batch Loss: 0.08331020176410675\n",
      "Epoch 2663, Loss: 0.11519885435700417, Final Batch Loss: 0.05503304675221443\n",
      "Epoch 2664, Loss: 0.10461800917983055, Final Batch Loss: 0.031078096479177475\n",
      "Epoch 2665, Loss: 0.12850242108106613, Final Batch Loss: 0.06381992250680923\n",
      "Epoch 2666, Loss: 0.16612032055854797, Final Batch Loss: 0.03589501976966858\n",
      "Epoch 2667, Loss: 0.10450586676597595, Final Batch Loss: 0.06069687008857727\n",
      "Epoch 2668, Loss: 0.16420695930719376, Final Batch Loss: 0.11083050072193146\n",
      "Epoch 2669, Loss: 0.08918612450361252, Final Batch Loss: 0.040751732885837555\n",
      "Epoch 2670, Loss: 0.0918302945792675, Final Batch Loss: 0.04343261942267418\n",
      "Epoch 2671, Loss: 0.08471135795116425, Final Batch Loss: 0.03878238424658775\n",
      "Epoch 2672, Loss: 0.09282318130135536, Final Batch Loss: 0.037543926388025284\n",
      "Epoch 2673, Loss: 0.11039607599377632, Final Batch Loss: 0.05818821117281914\n",
      "Epoch 2674, Loss: 0.09612130001187325, Final Batch Loss: 0.0417557917535305\n",
      "Epoch 2675, Loss: 0.13002458214759827, Final Batch Loss: 0.07833915948867798\n",
      "Epoch 2676, Loss: 0.10349969193339348, Final Batch Loss: 0.051394250243902206\n",
      "Epoch 2677, Loss: 0.1131097823381424, Final Batch Loss: 0.05206110700964928\n",
      "Epoch 2678, Loss: 0.11363975331187248, Final Batch Loss: 0.05916900187730789\n",
      "Epoch 2679, Loss: 0.11473603919148445, Final Batch Loss: 0.0447617806494236\n",
      "Epoch 2680, Loss: 0.13770684972405434, Final Batch Loss: 0.053677741438150406\n",
      "Epoch 2681, Loss: 0.10684821382164955, Final Batch Loss: 0.06586476415395737\n",
      "Epoch 2682, Loss: 0.11251027882099152, Final Batch Loss: 0.06930530071258545\n",
      "Epoch 2683, Loss: 0.13143937289714813, Final Batch Loss: 0.06430450826883316\n",
      "Epoch 2684, Loss: 0.10322121530771255, Final Batch Loss: 0.03980468958616257\n",
      "Epoch 2685, Loss: 0.11898636445403099, Final Batch Loss: 0.05523793771862984\n",
      "Epoch 2686, Loss: 0.09651822596788406, Final Batch Loss: 0.048641931265592575\n",
      "Epoch 2687, Loss: 0.1427251175045967, Final Batch Loss: 0.044245630502700806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2688, Loss: 0.10622471198439598, Final Batch Loss: 0.059814367443323135\n",
      "Epoch 2689, Loss: 0.13280246034264565, Final Batch Loss: 0.05700884386897087\n",
      "Epoch 2690, Loss: 0.13875190913677216, Final Batch Loss: 0.07370223850011826\n",
      "Epoch 2691, Loss: 0.11155634000897408, Final Batch Loss: 0.04908517748117447\n",
      "Epoch 2692, Loss: 0.09855647012591362, Final Batch Loss: 0.045588891953229904\n",
      "Epoch 2693, Loss: 0.094878651201725, Final Batch Loss: 0.04639975354075432\n",
      "Epoch 2694, Loss: 0.1377558633685112, Final Batch Loss: 0.06684999912977219\n",
      "Epoch 2695, Loss: 0.11463131010532379, Final Batch Loss: 0.05896594375371933\n",
      "Epoch 2696, Loss: 0.14463840052485466, Final Batch Loss: 0.05767175927758217\n",
      "Epoch 2697, Loss: 0.1155480407178402, Final Batch Loss: 0.058189522475004196\n",
      "Epoch 2698, Loss: 0.0855116918683052, Final Batch Loss: 0.043285395950078964\n",
      "Epoch 2699, Loss: 0.09984606504440308, Final Batch Loss: 0.03817138448357582\n",
      "Epoch 2700, Loss: 0.09708403423428535, Final Batch Loss: 0.044415730983018875\n",
      "Epoch 2701, Loss: 0.08283169195055962, Final Batch Loss: 0.05004309117794037\n",
      "Epoch 2702, Loss: 0.1255313903093338, Final Batch Loss: 0.06004086881875992\n",
      "Epoch 2703, Loss: 0.11454443261027336, Final Batch Loss: 0.03483584150671959\n",
      "Epoch 2704, Loss: 0.1518152579665184, Final Batch Loss: 0.08035062253475189\n",
      "Epoch 2705, Loss: 0.09537264704704285, Final Batch Loss: 0.04604608193039894\n",
      "Epoch 2706, Loss: 0.10448761284351349, Final Batch Loss: 0.07204116880893707\n",
      "Epoch 2707, Loss: 0.09690729156136513, Final Batch Loss: 0.05344077944755554\n",
      "Epoch 2708, Loss: 0.09722919389605522, Final Batch Loss: 0.04713135585188866\n",
      "Epoch 2709, Loss: 0.10508053004741669, Final Batch Loss: 0.03316669166088104\n",
      "Epoch 2710, Loss: 0.11626971513032913, Final Batch Loss: 0.06606119126081467\n",
      "Epoch 2711, Loss: 0.10982303321361542, Final Batch Loss: 0.05194278061389923\n",
      "Epoch 2712, Loss: 0.10155605897307396, Final Batch Loss: 0.05696561932563782\n",
      "Epoch 2713, Loss: 0.10544413514435291, Final Batch Loss: 0.07818108052015305\n",
      "Epoch 2714, Loss: 0.0916440337896347, Final Batch Loss: 0.034488238394260406\n",
      "Epoch 2715, Loss: 0.12333362549543381, Final Batch Loss: 0.07841461896896362\n",
      "Epoch 2716, Loss: 0.10532199591398239, Final Batch Loss: 0.06998205929994583\n",
      "Epoch 2717, Loss: 0.09497248381376266, Final Batch Loss: 0.045062363147735596\n",
      "Epoch 2718, Loss: 0.13717807084321976, Final Batch Loss: 0.0800822302699089\n",
      "Epoch 2719, Loss: 0.10816385596990585, Final Batch Loss: 0.05537037551403046\n",
      "Epoch 2720, Loss: 0.14914138242602348, Final Batch Loss: 0.1024162769317627\n",
      "Epoch 2721, Loss: 0.11169460415840149, Final Batch Loss: 0.05930478870868683\n",
      "Epoch 2722, Loss: 0.0828251987695694, Final Batch Loss: 0.03357420116662979\n",
      "Epoch 2723, Loss: 0.13321982324123383, Final Batch Loss: 0.05381612479686737\n",
      "Epoch 2724, Loss: 0.09192980825901031, Final Batch Loss: 0.06054937094449997\n",
      "Epoch 2725, Loss: 0.12917666137218475, Final Batch Loss: 0.08927245438098907\n",
      "Epoch 2726, Loss: 0.11240039765834808, Final Batch Loss: 0.040912508964538574\n",
      "Epoch 2727, Loss: 0.09987815842032433, Final Batch Loss: 0.04952637478709221\n",
      "Epoch 2728, Loss: 0.10684182867407799, Final Batch Loss: 0.058387357741594315\n",
      "Epoch 2729, Loss: 0.13063709065318108, Final Batch Loss: 0.03695644065737724\n",
      "Epoch 2730, Loss: 0.10409123077988625, Final Batch Loss: 0.046060364693403244\n",
      "Epoch 2731, Loss: 0.1806485652923584, Final Batch Loss: 0.14101551473140717\n",
      "Epoch 2732, Loss: 0.1970795914530754, Final Batch Loss: 0.062259577214717865\n",
      "Epoch 2733, Loss: 0.12294824421405792, Final Batch Loss: 0.07179374247789383\n",
      "Epoch 2734, Loss: 0.14331644773483276, Final Batch Loss: 0.08150892704725266\n",
      "Epoch 2735, Loss: 0.10578603297472, Final Batch Loss: 0.06266560405492783\n",
      "Epoch 2736, Loss: 0.08857572823762894, Final Batch Loss: 0.042309295386075974\n",
      "Epoch 2737, Loss: 0.09850674495100975, Final Batch Loss: 0.055986884981393814\n",
      "Epoch 2738, Loss: 0.11887411400675774, Final Batch Loss: 0.060505010187625885\n",
      "Epoch 2739, Loss: 0.10612243041396141, Final Batch Loss: 0.033984068781137466\n",
      "Epoch 2740, Loss: 0.10613606870174408, Final Batch Loss: 0.055059660226106644\n",
      "Epoch 2741, Loss: 0.11520421132445335, Final Batch Loss: 0.05066661164164543\n",
      "Epoch 2742, Loss: 0.10965223982930183, Final Batch Loss: 0.07072793692350388\n",
      "Epoch 2743, Loss: 0.09107823669910431, Final Batch Loss: 0.03685355931520462\n",
      "Epoch 2744, Loss: 0.1083182729780674, Final Batch Loss: 0.05639437586069107\n",
      "Epoch 2745, Loss: 0.11258609592914581, Final Batch Loss: 0.05515891686081886\n",
      "Epoch 2746, Loss: 0.08253142237663269, Final Batch Loss: 0.047305621206760406\n",
      "Epoch 2747, Loss: 0.09513654559850693, Final Batch Loss: 0.04503776878118515\n",
      "Epoch 2748, Loss: 0.0975257083773613, Final Batch Loss: 0.03929479420185089\n",
      "Epoch 2749, Loss: 0.07894693315029144, Final Batch Loss: 0.04584074765443802\n",
      "Epoch 2750, Loss: 0.11746915429830551, Final Batch Loss: 0.06346848607063293\n",
      "Epoch 2751, Loss: 0.11128900945186615, Final Batch Loss: 0.06941105425357819\n",
      "Epoch 2752, Loss: 0.09477265924215317, Final Batch Loss: 0.04476528614759445\n",
      "Epoch 2753, Loss: 0.08558315224945545, Final Batch Loss: 0.02907506190240383\n",
      "Epoch 2754, Loss: 0.13124829903244972, Final Batch Loss: 0.07733223587274551\n",
      "Epoch 2755, Loss: 0.16033881157636642, Final Batch Loss: 0.06550181657075882\n",
      "Epoch 2756, Loss: 0.09795443713665009, Final Batch Loss: 0.03149064630270004\n",
      "Epoch 2757, Loss: 0.10635923594236374, Final Batch Loss: 0.04129529744386673\n",
      "Epoch 2758, Loss: 0.09990585595369339, Final Batch Loss: 0.04229820519685745\n",
      "Epoch 2759, Loss: 0.10157281160354614, Final Batch Loss: 0.05176388844847679\n",
      "Epoch 2760, Loss: 0.13145527243614197, Final Batch Loss: 0.08534311503171921\n",
      "Epoch 2761, Loss: 0.1369120106101036, Final Batch Loss: 0.09581995010375977\n",
      "Epoch 2762, Loss: 0.10286499932408333, Final Batch Loss: 0.05679776519536972\n",
      "Epoch 2763, Loss: 0.13550760969519615, Final Batch Loss: 0.08398325741291046\n",
      "Epoch 2764, Loss: 0.16047680377960205, Final Batch Loss: 0.09493844211101532\n",
      "Epoch 2765, Loss: 0.1263662576675415, Final Batch Loss: 0.0516105517745018\n",
      "Epoch 2766, Loss: 0.13278714194893837, Final Batch Loss: 0.08227913826704025\n",
      "Epoch 2767, Loss: 0.10962336137890816, Final Batch Loss: 0.06287804245948792\n",
      "Epoch 2768, Loss: 0.12722408771514893, Final Batch Loss: 0.048603422939777374\n",
      "Epoch 2769, Loss: 0.10425956547260284, Final Batch Loss: 0.043299898505210876\n",
      "Epoch 2770, Loss: 0.12445247545838356, Final Batch Loss: 0.08820701390504837\n",
      "Epoch 2771, Loss: 0.09674124047160149, Final Batch Loss: 0.05366240069270134\n",
      "Epoch 2772, Loss: 0.13058070838451385, Final Batch Loss: 0.07901588082313538\n",
      "Epoch 2773, Loss: 0.1264675259590149, Final Batch Loss: 0.050278909504413605\n",
      "Epoch 2774, Loss: 0.1718345806002617, Final Batch Loss: 0.06719907373189926\n",
      "Epoch 2775, Loss: 0.11775824800133705, Final Batch Loss: 0.06304232776165009\n",
      "Epoch 2776, Loss: 0.15056364238262177, Final Batch Loss: 0.09566346555948257\n",
      "Epoch 2777, Loss: 0.0972365140914917, Final Batch Loss: 0.038411933928728104\n",
      "Epoch 2778, Loss: 0.16443756595253944, Final Batch Loss: 0.11254412680864334\n",
      "Epoch 2779, Loss: 0.11894133687019348, Final Batch Loss: 0.0635557547211647\n",
      "Epoch 2780, Loss: 0.14092303439974785, Final Batch Loss: 0.05882048234343529\n",
      "Epoch 2781, Loss: 0.14032455533742905, Final Batch Loss: 0.08687011152505875\n",
      "Epoch 2782, Loss: 0.12612183019518852, Final Batch Loss: 0.052000079303979874\n",
      "Epoch 2783, Loss: 0.12753167003393173, Final Batch Loss: 0.061726972460746765\n",
      "Epoch 2784, Loss: 0.11640248820185661, Final Batch Loss: 0.04420328512787819\n",
      "Epoch 2785, Loss: 0.09167776256799698, Final Batch Loss: 0.02315426617860794\n",
      "Epoch 2786, Loss: 0.11910750344395638, Final Batch Loss: 0.055241722613573074\n",
      "Epoch 2787, Loss: 0.21205060929059982, Final Batch Loss: 0.09256117790937424\n",
      "Epoch 2788, Loss: 0.15724288672208786, Final Batch Loss: 0.0810246616601944\n",
      "Epoch 2789, Loss: 0.11401744559407234, Final Batch Loss: 0.047187235206365585\n",
      "Epoch 2790, Loss: 0.14284005388617516, Final Batch Loss: 0.05223606154322624\n",
      "Epoch 2791, Loss: 0.12928622588515282, Final Batch Loss: 0.08604393154382706\n",
      "Epoch 2792, Loss: 0.11660685762763023, Final Batch Loss: 0.06912275403738022\n",
      "Epoch 2793, Loss: 0.17178640514612198, Final Batch Loss: 0.08262539654970169\n",
      "Epoch 2794, Loss: 0.09855930879712105, Final Batch Loss: 0.053405433893203735\n",
      "Epoch 2795, Loss: 0.1104237288236618, Final Batch Loss: 0.060562849044799805\n",
      "Epoch 2796, Loss: 0.10419336333870888, Final Batch Loss: 0.06950106471776962\n",
      "Epoch 2797, Loss: 0.12663757055997849, Final Batch Loss: 0.07181521505117416\n",
      "Epoch 2798, Loss: 0.12592178955674171, Final Batch Loss: 0.07944175601005554\n",
      "Epoch 2799, Loss: 0.1109197810292244, Final Batch Loss: 0.04210938513278961\n",
      "Epoch 2800, Loss: 0.10327733680605888, Final Batch Loss: 0.03913959488272667\n",
      "Epoch 2801, Loss: 0.10711507871747017, Final Batch Loss: 0.060172904282808304\n",
      "Epoch 2802, Loss: 0.13400888070464134, Final Batch Loss: 0.05775926634669304\n",
      "Epoch 2803, Loss: 0.12150263413786888, Final Batch Loss: 0.08280463516712189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2804, Loss: 0.09796256944537163, Final Batch Loss: 0.0479104220867157\n",
      "Epoch 2805, Loss: 0.10297449678182602, Final Batch Loss: 0.04873041808605194\n",
      "Epoch 2806, Loss: 0.23840127140283585, Final Batch Loss: 0.10518031567335129\n",
      "Epoch 2807, Loss: 0.16179784387350082, Final Batch Loss: 0.10087673366069794\n",
      "Epoch 2808, Loss: 0.10878733173012733, Final Batch Loss: 0.06610433012247086\n",
      "Epoch 2809, Loss: 0.1017996072769165, Final Batch Loss: 0.05402608960866928\n",
      "Epoch 2810, Loss: 0.10111808031797409, Final Batch Loss: 0.046915020793676376\n",
      "Epoch 2811, Loss: 0.09782040491700172, Final Batch Loss: 0.05639956146478653\n",
      "Epoch 2812, Loss: 0.09930053725838661, Final Batch Loss: 0.048244599252939224\n",
      "Epoch 2813, Loss: 0.14699958264827728, Final Batch Loss: 0.05925600230693817\n",
      "Epoch 2814, Loss: 0.12720098346471786, Final Batch Loss: 0.07011940330266953\n",
      "Epoch 2815, Loss: 0.11083420738577843, Final Batch Loss: 0.05382271483540535\n",
      "Epoch 2816, Loss: 0.12355231866240501, Final Batch Loss: 0.06553341448307037\n",
      "Epoch 2817, Loss: 0.09487980976700783, Final Batch Loss: 0.052351098507642746\n",
      "Epoch 2818, Loss: 0.09362827613949776, Final Batch Loss: 0.04766509681940079\n",
      "Epoch 2819, Loss: 0.08952027186751366, Final Batch Loss: 0.03358049318194389\n",
      "Epoch 2820, Loss: 0.09256967157125473, Final Batch Loss: 0.05127954110503197\n",
      "Epoch 2821, Loss: 0.12666665762662888, Final Batch Loss: 0.07743781805038452\n",
      "Epoch 2822, Loss: 0.09556004405021667, Final Batch Loss: 0.04495592415332794\n",
      "Epoch 2823, Loss: 0.09352753683924675, Final Batch Loss: 0.03049655631184578\n",
      "Epoch 2824, Loss: 0.11272876337170601, Final Batch Loss: 0.05107526853680611\n",
      "Epoch 2825, Loss: 0.08431923016905785, Final Batch Loss: 0.032516010105609894\n",
      "Epoch 2826, Loss: 0.11353734508156776, Final Batch Loss: 0.05573359131813049\n",
      "Epoch 2827, Loss: 0.12758445367217064, Final Batch Loss: 0.06733246892690659\n",
      "Epoch 2828, Loss: 0.12587831169366837, Final Batch Loss: 0.06387665867805481\n",
      "Epoch 2829, Loss: 0.10292904078960419, Final Batch Loss: 0.056862618774175644\n",
      "Epoch 2830, Loss: 0.1306648701429367, Final Batch Loss: 0.08196572214365005\n",
      "Epoch 2831, Loss: 0.09120883606374264, Final Batch Loss: 0.02657032571732998\n",
      "Epoch 2832, Loss: 0.0879312064498663, Final Batch Loss: 0.028365517035126686\n",
      "Epoch 2833, Loss: 0.10184536501765251, Final Batch Loss: 0.06056293472647667\n",
      "Epoch 2834, Loss: 0.08592880517244339, Final Batch Loss: 0.03285239264369011\n",
      "Epoch 2835, Loss: 0.11131658405065536, Final Batch Loss: 0.0268079936504364\n",
      "Epoch 2836, Loss: 0.13818269222974777, Final Batch Loss: 0.07532480359077454\n",
      "Epoch 2837, Loss: 0.1362180858850479, Final Batch Loss: 0.07669554650783539\n",
      "Epoch 2838, Loss: 0.09706632420420647, Final Batch Loss: 0.04617445915937424\n",
      "Epoch 2839, Loss: 0.13034450635313988, Final Batch Loss: 0.050473909825086594\n",
      "Epoch 2840, Loss: 0.11942270770668983, Final Batch Loss: 0.06225863844156265\n",
      "Epoch 2841, Loss: 0.12090665847063065, Final Batch Loss: 0.0701405480504036\n",
      "Epoch 2842, Loss: 0.10738098621368408, Final Batch Loss: 0.061518069356679916\n",
      "Epoch 2843, Loss: 0.12385759502649307, Final Batch Loss: 0.060225144028663635\n",
      "Epoch 2844, Loss: 0.1468939110636711, Final Batch Loss: 0.08013232052326202\n",
      "Epoch 2845, Loss: 0.10174483805894852, Final Batch Loss: 0.06045129895210266\n",
      "Epoch 2846, Loss: 0.11131184175610542, Final Batch Loss: 0.06135213002562523\n",
      "Epoch 2847, Loss: 0.10316872596740723, Final Batch Loss: 0.056821539998054504\n",
      "Epoch 2848, Loss: 0.09363511949777603, Final Batch Loss: 0.042405299842357635\n",
      "Epoch 2849, Loss: 0.11363416165113449, Final Batch Loss: 0.04909456521272659\n",
      "Epoch 2850, Loss: 0.09792176634073257, Final Batch Loss: 0.05030087009072304\n",
      "Epoch 2851, Loss: 0.12249109148979187, Final Batch Loss: 0.03439563512802124\n",
      "Epoch 2852, Loss: 0.10660038888454437, Final Batch Loss: 0.0440298467874527\n",
      "Epoch 2853, Loss: 0.1571185067296028, Final Batch Loss: 0.08577293157577515\n",
      "Epoch 2854, Loss: 0.12890615314245224, Final Batch Loss: 0.057285375893116\n",
      "Epoch 2855, Loss: 0.10354259610176086, Final Batch Loss: 0.048926807940006256\n",
      "Epoch 2856, Loss: 0.12630706652998924, Final Batch Loss: 0.07153680920600891\n",
      "Epoch 2857, Loss: 0.11051591858267784, Final Batch Loss: 0.03683815523982048\n",
      "Epoch 2858, Loss: 0.09276263043284416, Final Batch Loss: 0.04237790033221245\n",
      "Epoch 2859, Loss: 0.11944935098290443, Final Batch Loss: 0.052689071744680405\n",
      "Epoch 2860, Loss: 0.09450986981391907, Final Batch Loss: 0.041736021637916565\n",
      "Epoch 2861, Loss: 0.09526045620441437, Final Batch Loss: 0.047717321664094925\n",
      "Epoch 2862, Loss: 0.09152460470795631, Final Batch Loss: 0.03947024419903755\n",
      "Epoch 2863, Loss: 0.10546785965561867, Final Batch Loss: 0.0640256255865097\n",
      "Epoch 2864, Loss: 0.11513777077198029, Final Batch Loss: 0.0423627570271492\n",
      "Epoch 2865, Loss: 0.10990404710173607, Final Batch Loss: 0.05864483490586281\n",
      "Epoch 2866, Loss: 0.10663016140460968, Final Batch Loss: 0.057512007653713226\n",
      "Epoch 2867, Loss: 0.1490999311208725, Final Batch Loss: 0.0842345654964447\n",
      "Epoch 2868, Loss: 0.1256546676158905, Final Batch Loss: 0.03927161544561386\n",
      "Epoch 2869, Loss: 0.14712706953287125, Final Batch Loss: 0.07533217966556549\n",
      "Epoch 2870, Loss: 0.09936844184994698, Final Batch Loss: 0.03973520174622536\n",
      "Epoch 2871, Loss: 0.11360946670174599, Final Batch Loss: 0.06409897655248642\n",
      "Epoch 2872, Loss: 0.08605256676673889, Final Batch Loss: 0.04018016904592514\n",
      "Epoch 2873, Loss: 0.10482694208621979, Final Batch Loss: 0.06465274095535278\n",
      "Epoch 2874, Loss: 0.09634315222501755, Final Batch Loss: 0.031350359320640564\n",
      "Epoch 2875, Loss: 0.12065882235765457, Final Batch Loss: 0.0669160783290863\n",
      "Epoch 2876, Loss: 0.12358779087662697, Final Batch Loss: 0.040323857218027115\n",
      "Epoch 2877, Loss: 0.1286216676235199, Final Batch Loss: 0.05768636614084244\n",
      "Epoch 2878, Loss: 0.09247338771820068, Final Batch Loss: 0.032509807497262955\n",
      "Epoch 2879, Loss: 0.11872025206685066, Final Batch Loss: 0.065803162753582\n",
      "Epoch 2880, Loss: 0.10029864311218262, Final Batch Loss: 0.05540623888373375\n",
      "Epoch 2881, Loss: 0.10513653233647346, Final Batch Loss: 0.03570076450705528\n",
      "Epoch 2882, Loss: 0.09521294012665749, Final Batch Loss: 0.05630658194422722\n",
      "Epoch 2883, Loss: 0.11552688851952553, Final Batch Loss: 0.04882794991135597\n",
      "Epoch 2884, Loss: 0.18028651550412178, Final Batch Loss: 0.12048578262329102\n",
      "Epoch 2885, Loss: 0.1050245501101017, Final Batch Loss: 0.05698706954717636\n",
      "Epoch 2886, Loss: 0.1468375287950039, Final Batch Loss: 0.05945597216486931\n",
      "Epoch 2887, Loss: 0.12286863476037979, Final Batch Loss: 0.07633136212825775\n",
      "Epoch 2888, Loss: 0.17021147161722183, Final Batch Loss: 0.09851538389921188\n",
      "Epoch 2889, Loss: 0.1141539178788662, Final Batch Loss: 0.05885393172502518\n",
      "Epoch 2890, Loss: 0.18393773958086967, Final Batch Loss: 0.12819713354110718\n",
      "Epoch 2891, Loss: 0.10072048380970955, Final Batch Loss: 0.06281305849552155\n",
      "Epoch 2892, Loss: 0.13579121977090836, Final Batch Loss: 0.04601743817329407\n",
      "Epoch 2893, Loss: 0.09872212633490562, Final Batch Loss: 0.03345409408211708\n",
      "Epoch 2894, Loss: 0.10577180236577988, Final Batch Loss: 0.06278319656848907\n",
      "Epoch 2895, Loss: 0.09518388286232948, Final Batch Loss: 0.03879097104072571\n",
      "Epoch 2896, Loss: 0.1015087366104126, Final Batch Loss: 0.05588550120592117\n",
      "Epoch 2897, Loss: 0.09441927075386047, Final Batch Loss: 0.03975294157862663\n",
      "Epoch 2898, Loss: 0.13208557665348053, Final Batch Loss: 0.04373624175786972\n",
      "Epoch 2899, Loss: 0.13673846051096916, Final Batch Loss: 0.08086854964494705\n",
      "Epoch 2900, Loss: 0.11393275484442711, Final Batch Loss: 0.06346681714057922\n",
      "Epoch 2901, Loss: 0.1193230114877224, Final Batch Loss: 0.060598913580179214\n",
      "Epoch 2902, Loss: 0.12507858499884605, Final Batch Loss: 0.056528884917497635\n",
      "Epoch 2903, Loss: 0.10815456137061119, Final Batch Loss: 0.046084288507699966\n",
      "Epoch 2904, Loss: 0.10549145936965942, Final Batch Loss: 0.046502940356731415\n",
      "Epoch 2905, Loss: 0.14783836156129837, Final Batch Loss: 0.055037982761859894\n",
      "Epoch 2906, Loss: 0.15738501399755478, Final Batch Loss: 0.08417970687150955\n",
      "Epoch 2907, Loss: 0.12110742181539536, Final Batch Loss: 0.03817512094974518\n",
      "Epoch 2908, Loss: 0.1391872838139534, Final Batch Loss: 0.04731176793575287\n",
      "Epoch 2909, Loss: 0.10966867208480835, Final Batch Loss: 0.039660319685935974\n",
      "Epoch 2910, Loss: 0.15432599931955338, Final Batch Loss: 0.07668451964855194\n",
      "Epoch 2911, Loss: 0.09624041989445686, Final Batch Loss: 0.0396396704018116\n",
      "Epoch 2912, Loss: 0.10753968358039856, Final Batch Loss: 0.0708656907081604\n",
      "Epoch 2913, Loss: 0.11102074384689331, Final Batch Loss: 0.03185078501701355\n",
      "Epoch 2914, Loss: 0.18947981297969818, Final Batch Loss: 0.1514872908592224\n",
      "Epoch 2915, Loss: 0.13403790444135666, Final Batch Loss: 0.07983186095952988\n",
      "Epoch 2916, Loss: 0.1775938831269741, Final Batch Loss: 0.1190854012966156\n",
      "Epoch 2917, Loss: 0.10454744845628738, Final Batch Loss: 0.04493104666471481\n",
      "Epoch 2918, Loss: 0.1077340692281723, Final Batch Loss: 0.04618741199374199\n",
      "Epoch 2919, Loss: 0.12546036019921303, Final Batch Loss: 0.05758107081055641\n",
      "Epoch 2920, Loss: 0.13074372336268425, Final Batch Loss: 0.07145550847053528\n",
      "Epoch 2921, Loss: 0.09860469773411751, Final Batch Loss: 0.06262614578008652\n",
      "Epoch 2922, Loss: 0.1628347784280777, Final Batch Loss: 0.10360526293516159\n",
      "Epoch 2923, Loss: 0.13481095805764198, Final Batch Loss: 0.09384994953870773\n",
      "Epoch 2924, Loss: 0.10877486690878868, Final Batch Loss: 0.05234203487634659\n",
      "Epoch 2925, Loss: 0.10456199944019318, Final Batch Loss: 0.05773215368390083\n",
      "Epoch 2926, Loss: 0.15690217912197113, Final Batch Loss: 0.06370843946933746\n",
      "Epoch 2927, Loss: 0.14319811016321182, Final Batch Loss: 0.04193772375583649\n",
      "Epoch 2928, Loss: 0.1059165932238102, Final Batch Loss: 0.05490509420633316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2929, Loss: 0.13435518369078636, Final Batch Loss: 0.08821223676204681\n",
      "Epoch 2930, Loss: 0.12477537244558334, Final Batch Loss: 0.04626665264368057\n",
      "Epoch 2931, Loss: 0.12486809492111206, Final Batch Loss: 0.04604153335094452\n",
      "Epoch 2932, Loss: 0.10575447231531143, Final Batch Loss: 0.0466231070458889\n",
      "Epoch 2933, Loss: 0.13559527695178986, Final Batch Loss: 0.07619459927082062\n",
      "Epoch 2934, Loss: 0.1345209777355194, Final Batch Loss: 0.06967798620462418\n",
      "Epoch 2935, Loss: 0.1037147156894207, Final Batch Loss: 0.061125174164772034\n",
      "Epoch 2936, Loss: 0.09209169074892998, Final Batch Loss: 0.03210367634892464\n",
      "Epoch 2937, Loss: 0.12285846471786499, Final Batch Loss: 0.06251125037670135\n",
      "Epoch 2938, Loss: 0.09814658761024475, Final Batch Loss: 0.04291970282793045\n",
      "Epoch 2939, Loss: 0.11447807773947716, Final Batch Loss: 0.05947192758321762\n",
      "Epoch 2940, Loss: 0.111651461571455, Final Batch Loss: 0.05615656077861786\n",
      "Epoch 2941, Loss: 0.25353749841451645, Final Batch Loss: 0.1004972979426384\n",
      "Epoch 2942, Loss: 0.15287581831216812, Final Batch Loss: 0.08379276841878891\n",
      "Epoch 2943, Loss: 0.13497483357787132, Final Batch Loss: 0.05542914196848869\n",
      "Epoch 2944, Loss: 0.11115622892975807, Final Batch Loss: 0.053967010229825974\n",
      "Epoch 2945, Loss: 0.08299202658236027, Final Batch Loss: 0.023620618507266045\n",
      "Epoch 2946, Loss: 0.16499894112348557, Final Batch Loss: 0.09049537777900696\n",
      "Epoch 2947, Loss: 0.10810546204447746, Final Batch Loss: 0.06274055689573288\n",
      "Epoch 2948, Loss: 0.11929171159863472, Final Batch Loss: 0.05788850411772728\n",
      "Epoch 2949, Loss: 0.1511888951063156, Final Batch Loss: 0.04347188025712967\n",
      "Epoch 2950, Loss: 0.1165493093430996, Final Batch Loss: 0.06646659225225449\n",
      "Epoch 2951, Loss: 0.10803044587373734, Final Batch Loss: 0.04736097902059555\n",
      "Epoch 2952, Loss: 0.12339756265282631, Final Batch Loss: 0.04356514289975166\n",
      "Epoch 2953, Loss: 0.1228012777864933, Final Batch Loss: 0.06323886662721634\n",
      "Epoch 2954, Loss: 0.1780131347477436, Final Batch Loss: 0.05734408274292946\n",
      "Epoch 2955, Loss: 0.16913451254367828, Final Batch Loss: 0.05772712081670761\n",
      "Epoch 2956, Loss: 0.16138314455747604, Final Batch Loss: 0.09172433614730835\n",
      "Epoch 2957, Loss: 0.10083945840597153, Final Batch Loss: 0.050496794283390045\n",
      "Epoch 2958, Loss: 0.1009720079600811, Final Batch Loss: 0.06076269969344139\n",
      "Epoch 2959, Loss: 0.12380090728402138, Final Batch Loss: 0.0761227160692215\n",
      "Epoch 2960, Loss: 0.11512941867113113, Final Batch Loss: 0.03674596548080444\n",
      "Epoch 2961, Loss: 0.10576433688402176, Final Batch Loss: 0.043818939477205276\n",
      "Epoch 2962, Loss: 0.12360985949635506, Final Batch Loss: 0.042560819536447525\n",
      "Epoch 2963, Loss: 0.10630850866436958, Final Batch Loss: 0.048571474850177765\n",
      "Epoch 2964, Loss: 0.1178065612912178, Final Batch Loss: 0.06738371402025223\n",
      "Epoch 2965, Loss: 0.09586236998438835, Final Batch Loss: 0.05175650492310524\n",
      "Epoch 2966, Loss: 0.10163707658648491, Final Batch Loss: 0.05542445182800293\n",
      "Epoch 2967, Loss: 0.166730634868145, Final Batch Loss: 0.061823032796382904\n",
      "Epoch 2968, Loss: 0.11273887008428574, Final Batch Loss: 0.05548178404569626\n",
      "Epoch 2969, Loss: 0.11663441359996796, Final Batch Loss: 0.05706131085753441\n",
      "Epoch 2970, Loss: 0.10901984572410583, Final Batch Loss: 0.045424774289131165\n",
      "Epoch 2971, Loss: 0.09570128098130226, Final Batch Loss: 0.03756317123770714\n",
      "Epoch 2972, Loss: 0.10314519889652729, Final Batch Loss: 0.02990894950926304\n",
      "Epoch 2973, Loss: 0.09419987723231316, Final Batch Loss: 0.048594046384096146\n",
      "Epoch 2974, Loss: 0.12464524060487747, Final Batch Loss: 0.07945877313613892\n",
      "Epoch 2975, Loss: 0.11290537938475609, Final Batch Loss: 0.06324244290590286\n",
      "Epoch 2976, Loss: 0.0921846330165863, Final Batch Loss: 0.044622838497161865\n",
      "Epoch 2977, Loss: 0.1222568042576313, Final Batch Loss: 0.07675567269325256\n",
      "Epoch 2978, Loss: 0.09795618429780006, Final Batch Loss: 0.05876372754573822\n",
      "Epoch 2979, Loss: 0.10496078431606293, Final Batch Loss: 0.04472813382744789\n",
      "Epoch 2980, Loss: 0.08713927865028381, Final Batch Loss: 0.03338683024048805\n",
      "Epoch 2981, Loss: 0.09216386079788208, Final Batch Loss: 0.04219977185130119\n",
      "Epoch 2982, Loss: 0.15086155012249947, Final Batch Loss: 0.09956342726945877\n",
      "Epoch 2983, Loss: 0.10398773103952408, Final Batch Loss: 0.0471663661301136\n",
      "Epoch 2984, Loss: 0.12527311220765114, Final Batch Loss: 0.06077926978468895\n",
      "Epoch 2985, Loss: 0.1365106739103794, Final Batch Loss: 0.051098909229040146\n",
      "Epoch 2986, Loss: 0.10712943226099014, Final Batch Loss: 0.06664136052131653\n",
      "Epoch 2987, Loss: 0.09009185060858727, Final Batch Loss: 0.03965815156698227\n",
      "Epoch 2988, Loss: 0.14687244221568108, Final Batch Loss: 0.05739414319396019\n",
      "Epoch 2989, Loss: 0.08778270706534386, Final Batch Loss: 0.043138537555933\n",
      "Epoch 2990, Loss: 0.10263198986649513, Final Batch Loss: 0.06335274875164032\n",
      "Epoch 2991, Loss: 0.12418025732040405, Final Batch Loss: 0.05577203631401062\n",
      "Epoch 2992, Loss: 0.09848809242248535, Final Batch Loss: 0.043959975242614746\n",
      "Epoch 2993, Loss: 0.08072233572602272, Final Batch Loss: 0.03610185533761978\n",
      "Epoch 2994, Loss: 0.10467234626412392, Final Batch Loss: 0.04938322305679321\n",
      "Epoch 2995, Loss: 0.1084304191172123, Final Batch Loss: 0.059488262981176376\n",
      "Epoch 2996, Loss: 0.16483846679329872, Final Batch Loss: 0.11818518489599228\n",
      "Epoch 2997, Loss: 0.12258823961019516, Final Batch Loss: 0.08558648824691772\n",
      "Epoch 2998, Loss: 0.0971541479229927, Final Batch Loss: 0.05182652175426483\n",
      "Epoch 2999, Loss: 0.09983236715197563, Final Batch Loss: 0.03930322453379631\n",
      "Epoch 3000, Loss: 0.09521844238042831, Final Batch Loss: 0.05294623598456383\n",
      "Epoch 3001, Loss: 0.11029567569494247, Final Batch Loss: 0.06719771027565002\n",
      "Epoch 3002, Loss: 0.14515108615159988, Final Batch Loss: 0.06303798407316208\n",
      "Epoch 3003, Loss: 0.10329682007431984, Final Batch Loss: 0.036238957196474075\n",
      "Epoch 3004, Loss: 0.23273495584726334, Final Batch Loss: 0.17964352667331696\n",
      "Epoch 3005, Loss: 0.08885012567043304, Final Batch Loss: 0.04992341622710228\n",
      "Epoch 3006, Loss: 0.10293255001306534, Final Batch Loss: 0.04565029591321945\n",
      "Epoch 3007, Loss: 0.10301703214645386, Final Batch Loss: 0.03882429003715515\n",
      "Epoch 3008, Loss: 0.12047689780592918, Final Batch Loss: 0.0630204975605011\n",
      "Epoch 3009, Loss: 0.16253169998526573, Final Batch Loss: 0.10374695807695389\n",
      "Epoch 3010, Loss: 0.11046648770570755, Final Batch Loss: 0.06198687106370926\n",
      "Epoch 3011, Loss: 0.11488455533981323, Final Batch Loss: 0.055088870227336884\n",
      "Epoch 3012, Loss: 0.12423492223024368, Final Batch Loss: 0.041440822184085846\n",
      "Epoch 3013, Loss: 0.10155070573091507, Final Batch Loss: 0.054597850888967514\n",
      "Epoch 3014, Loss: 0.08954103291034698, Final Batch Loss: 0.051887258887290955\n",
      "Epoch 3015, Loss: 0.10929618403315544, Final Batch Loss: 0.0616736076772213\n",
      "Epoch 3016, Loss: 0.1156231127679348, Final Batch Loss: 0.05807974934577942\n",
      "Epoch 3017, Loss: 0.10166595503687859, Final Batch Loss: 0.05997508391737938\n",
      "Epoch 3018, Loss: 0.09986775740981102, Final Batch Loss: 0.04307984560728073\n",
      "Epoch 3019, Loss: 0.10163408517837524, Final Batch Loss: 0.0546395406126976\n",
      "Epoch 3020, Loss: 0.12166692316532135, Final Batch Loss: 0.04235897213220596\n",
      "Epoch 3021, Loss: 0.10161987692117691, Final Batch Loss: 0.04972720891237259\n",
      "Epoch 3022, Loss: 0.09517253190279007, Final Batch Loss: 0.04071715101599693\n",
      "Epoch 3023, Loss: 0.11469634622335434, Final Batch Loss: 0.04880592226982117\n",
      "Epoch 3024, Loss: 0.09627406671643257, Final Batch Loss: 0.044539712369441986\n",
      "Epoch 3025, Loss: 0.11296230182051659, Final Batch Loss: 0.07794779539108276\n",
      "Epoch 3026, Loss: 0.11755800247192383, Final Batch Loss: 0.07011859863996506\n",
      "Epoch 3027, Loss: 0.09562738239765167, Final Batch Loss: 0.05330488085746765\n",
      "Epoch 3028, Loss: 0.15063674375414848, Final Batch Loss: 0.09545329213142395\n",
      "Epoch 3029, Loss: 0.10494503378868103, Final Batch Loss: 0.04792959243059158\n",
      "Epoch 3030, Loss: 0.11001486331224442, Final Batch Loss: 0.06208183243870735\n",
      "Epoch 3031, Loss: 0.11727317422628403, Final Batch Loss: 0.042064227163791656\n",
      "Epoch 3032, Loss: 0.1368473619222641, Final Batch Loss: 0.06706557422876358\n",
      "Epoch 3033, Loss: 0.09461193531751633, Final Batch Loss: 0.036950889974832535\n",
      "Epoch 3034, Loss: 0.13634489476680756, Final Batch Loss: 0.0822775736451149\n",
      "Epoch 3035, Loss: 0.11320631951093674, Final Batch Loss: 0.07431770861148834\n",
      "Epoch 3036, Loss: 0.1495530605316162, Final Batch Loss: 0.11895009130239487\n",
      "Epoch 3037, Loss: 0.11312674731016159, Final Batch Loss: 0.04960768669843674\n",
      "Epoch 3038, Loss: 0.09717933088541031, Final Batch Loss: 0.04560178890824318\n",
      "Epoch 3039, Loss: 0.10844001173973083, Final Batch Loss: 0.05505476891994476\n",
      "Epoch 3040, Loss: 0.15815693512558937, Final Batch Loss: 0.05342262610793114\n",
      "Epoch 3041, Loss: 0.11788371950387955, Final Batch Loss: 0.053084857761859894\n",
      "Epoch 3042, Loss: 0.10659472271800041, Final Batch Loss: 0.049074843525886536\n",
      "Epoch 3043, Loss: 0.11502278223633766, Final Batch Loss: 0.05154743418097496\n",
      "Epoch 3044, Loss: 0.12740103155374527, Final Batch Loss: 0.07011137902736664\n",
      "Epoch 3045, Loss: 0.15657402947545052, Final Batch Loss: 0.11744373291730881\n",
      "Epoch 3046, Loss: 0.12924610450863838, Final Batch Loss: 0.06775297969579697\n",
      "Epoch 3047, Loss: 0.14383971691131592, Final Batch Loss: 0.07195179909467697\n",
      "Epoch 3048, Loss: 0.12619846314191818, Final Batch Loss: 0.07389482855796814\n",
      "Epoch 3049, Loss: 0.11685319617390633, Final Batch Loss: 0.03764926269650459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3050, Loss: 0.11146211996674538, Final Batch Loss: 0.05976324900984764\n",
      "Epoch 3051, Loss: 0.09088808670639992, Final Batch Loss: 0.0334739051759243\n",
      "Epoch 3052, Loss: 0.10157890990376472, Final Batch Loss: 0.045547209680080414\n",
      "Epoch 3053, Loss: 0.09189098328351974, Final Batch Loss: 0.04545995965600014\n",
      "Epoch 3054, Loss: 0.09690415859222412, Final Batch Loss: 0.04833598434925079\n",
      "Epoch 3055, Loss: 0.10583911836147308, Final Batch Loss: 0.06437569856643677\n",
      "Epoch 3056, Loss: 0.09096274897456169, Final Batch Loss: 0.03198401257395744\n",
      "Epoch 3057, Loss: 0.12584615498781204, Final Batch Loss: 0.0616573840379715\n",
      "Epoch 3058, Loss: 0.11998844891786575, Final Batch Loss: 0.06361197680234909\n",
      "Epoch 3059, Loss: 0.0850938931107521, Final Batch Loss: 0.03868820145726204\n",
      "Epoch 3060, Loss: 0.11300607025623322, Final Batch Loss: 0.06922046095132828\n",
      "Epoch 3061, Loss: 0.1384252905845642, Final Batch Loss: 0.07098514586687088\n",
      "Epoch 3062, Loss: 0.1268206275999546, Final Batch Loss: 0.07444096356630325\n",
      "Epoch 3063, Loss: 0.12880169972777367, Final Batch Loss: 0.07922686636447906\n",
      "Epoch 3064, Loss: 0.11246594786643982, Final Batch Loss: 0.035975173115730286\n",
      "Epoch 3065, Loss: 0.11460878700017929, Final Batch Loss: 0.05798044800758362\n",
      "Epoch 3066, Loss: 0.11623908579349518, Final Batch Loss: 0.07001812756061554\n",
      "Epoch 3067, Loss: 0.11793645098805428, Final Batch Loss: 0.06105603277683258\n",
      "Epoch 3068, Loss: 0.10695123672485352, Final Batch Loss: 0.06829433143138885\n",
      "Epoch 3069, Loss: 0.12660176306962967, Final Batch Loss: 0.06072011590003967\n",
      "Epoch 3070, Loss: 0.09909363463521004, Final Batch Loss: 0.03818020597100258\n",
      "Epoch 3071, Loss: 0.10232507809996605, Final Batch Loss: 0.046227097511291504\n",
      "Epoch 3072, Loss: 0.1074627935886383, Final Batch Loss: 0.052982695400714874\n",
      "Epoch 3073, Loss: 0.13720113784074783, Final Batch Loss: 0.09264493733644485\n",
      "Epoch 3074, Loss: 0.11729895696043968, Final Batch Loss: 0.060495775192976\n",
      "Epoch 3075, Loss: 0.09582757949829102, Final Batch Loss: 0.047462671995162964\n",
      "Epoch 3076, Loss: 0.17126423865556717, Final Batch Loss: 0.07469698041677475\n",
      "Epoch 3077, Loss: 0.09498083591461182, Final Batch Loss: 0.05797914043068886\n",
      "Epoch 3078, Loss: 0.15327926352620125, Final Batch Loss: 0.10888752341270447\n",
      "Epoch 3079, Loss: 0.15613532811403275, Final Batch Loss: 0.09162362664937973\n",
      "Epoch 3080, Loss: 0.12062942236661911, Final Batch Loss: 0.057842835783958435\n",
      "Epoch 3081, Loss: 0.1118040680885315, Final Batch Loss: 0.060231637209653854\n",
      "Epoch 3082, Loss: 0.09450715035200119, Final Batch Loss: 0.03171761333942413\n",
      "Epoch 3083, Loss: 0.10090851783752441, Final Batch Loss: 0.05673394352197647\n",
      "Epoch 3084, Loss: 0.1017821803689003, Final Batch Loss: 0.05207803472876549\n",
      "Epoch 3085, Loss: 0.12042422592639923, Final Batch Loss: 0.06996007263660431\n",
      "Epoch 3086, Loss: 0.10749071091413498, Final Batch Loss: 0.055498141795396805\n",
      "Epoch 3087, Loss: 0.10878665372729301, Final Batch Loss: 0.04265940561890602\n",
      "Epoch 3088, Loss: 0.09977538138628006, Final Batch Loss: 0.05824101343750954\n",
      "Epoch 3089, Loss: 0.09993598610162735, Final Batch Loss: 0.045057762414216995\n",
      "Epoch 3090, Loss: 0.10161398723721504, Final Batch Loss: 0.032772984355688095\n",
      "Epoch 3091, Loss: 0.1088557168841362, Final Batch Loss: 0.07388757169246674\n",
      "Epoch 3092, Loss: 0.11371780186891556, Final Batch Loss: 0.05954499542713165\n",
      "Epoch 3093, Loss: 0.136510968208313, Final Batch Loss: 0.08153501898050308\n",
      "Epoch 3094, Loss: 0.13722647726535797, Final Batch Loss: 0.0685119479894638\n",
      "Epoch 3095, Loss: 0.13481679558753967, Final Batch Loss: 0.06504855304956436\n",
      "Epoch 3096, Loss: 0.09606457129120827, Final Batch Loss: 0.04433780163526535\n",
      "Epoch 3097, Loss: 0.10704416036605835, Final Batch Loss: 0.032853685319423676\n",
      "Epoch 3098, Loss: 0.11624813079833984, Final Batch Loss: 0.05213946849107742\n",
      "Epoch 3099, Loss: 0.08063820749521255, Final Batch Loss: 0.035953179001808167\n",
      "Epoch 3100, Loss: 0.11768544465303421, Final Batch Loss: 0.084800586104393\n",
      "Epoch 3101, Loss: 0.11750276386737823, Final Batch Loss: 0.07648835331201553\n",
      "Epoch 3102, Loss: 0.12828446552157402, Final Batch Loss: 0.04893230274319649\n",
      "Epoch 3103, Loss: 0.1425703503191471, Final Batch Loss: 0.09082455933094025\n",
      "Epoch 3104, Loss: 0.10139093548059464, Final Batch Loss: 0.04079252481460571\n",
      "Epoch 3105, Loss: 0.1285841464996338, Final Batch Loss: 0.04366913437843323\n",
      "Epoch 3106, Loss: 0.10276741907000542, Final Batch Loss: 0.049303293228149414\n",
      "Epoch 3107, Loss: 0.11135786399245262, Final Batch Loss: 0.04056930169463158\n",
      "Epoch 3108, Loss: 0.11005370318889618, Final Batch Loss: 0.058585312217473984\n",
      "Epoch 3109, Loss: 0.13421984761953354, Final Batch Loss: 0.05339492857456207\n",
      "Epoch 3110, Loss: 0.10585437156260014, Final Batch Loss: 0.07999445497989655\n",
      "Epoch 3111, Loss: 0.08918372355401516, Final Batch Loss: 0.027409808710217476\n",
      "Epoch 3112, Loss: 0.09431075491011143, Final Batch Loss: 0.02876628376543522\n",
      "Epoch 3113, Loss: 0.10405151173472404, Final Batch Loss: 0.04660872370004654\n",
      "Epoch 3114, Loss: 0.08422450348734856, Final Batch Loss: 0.040710899978876114\n",
      "Epoch 3115, Loss: 0.08189469575881958, Final Batch Loss: 0.03263905271887779\n",
      "Epoch 3116, Loss: 0.14633119851350784, Final Batch Loss: 0.095922090113163\n",
      "Epoch 3117, Loss: 0.10396908223628998, Final Batch Loss: 0.07529588788747787\n",
      "Epoch 3118, Loss: 0.0779153797775507, Final Batch Loss: 0.02687550149857998\n",
      "Epoch 3119, Loss: 0.09650860354304314, Final Batch Loss: 0.03421894088387489\n",
      "Epoch 3120, Loss: 0.11092368513345718, Final Batch Loss: 0.06809564679861069\n",
      "Epoch 3121, Loss: 0.1057586558163166, Final Batch Loss: 0.07240844517946243\n",
      "Epoch 3122, Loss: 0.09257391840219498, Final Batch Loss: 0.039113011211156845\n",
      "Epoch 3123, Loss: 0.11619672551751137, Final Batch Loss: 0.06723825633525848\n",
      "Epoch 3124, Loss: 0.0996982529759407, Final Batch Loss: 0.056335076689720154\n",
      "Epoch 3125, Loss: 0.10366261377930641, Final Batch Loss: 0.0501750148832798\n",
      "Epoch 3126, Loss: 0.08728818967938423, Final Batch Loss: 0.049181822687387466\n",
      "Epoch 3127, Loss: 0.10754984989762306, Final Batch Loss: 0.05589822307229042\n",
      "Epoch 3128, Loss: 0.11423689313232899, Final Batch Loss: 0.08434144407510757\n",
      "Epoch 3129, Loss: 0.10166926309466362, Final Batch Loss: 0.03910241648554802\n",
      "Epoch 3130, Loss: 0.10017602890729904, Final Batch Loss: 0.04691619798541069\n",
      "Epoch 3131, Loss: 0.1629725620150566, Final Batch Loss: 0.11198810487985611\n",
      "Epoch 3132, Loss: 0.13590602576732635, Final Batch Loss: 0.09772489219903946\n",
      "Epoch 3133, Loss: 0.09968873113393784, Final Batch Loss: 0.04933850094676018\n",
      "Epoch 3134, Loss: 0.08531321212649345, Final Batch Loss: 0.04463561624288559\n",
      "Epoch 3135, Loss: 0.11755408346652985, Final Batch Loss: 0.05368052423000336\n",
      "Epoch 3136, Loss: 0.21922697871923447, Final Batch Loss: 0.10792558640241623\n",
      "Epoch 3137, Loss: 0.0997611116617918, Final Batch Loss: 0.02825929783284664\n",
      "Epoch 3138, Loss: 0.10574682801961899, Final Batch Loss: 0.06863480061292648\n",
      "Epoch 3139, Loss: 0.08841485530138016, Final Batch Loss: 0.04968962073326111\n",
      "Epoch 3140, Loss: 0.16408082097768784, Final Batch Loss: 0.08076745271682739\n",
      "Epoch 3141, Loss: 0.13674281910061836, Final Batch Loss: 0.045919690281152725\n",
      "Epoch 3142, Loss: 0.13583648949861526, Final Batch Loss: 0.04681004583835602\n",
      "Epoch 3143, Loss: 0.13271243125200272, Final Batch Loss: 0.053960829973220825\n",
      "Epoch 3144, Loss: 0.1105792410671711, Final Batch Loss: 0.06271260976791382\n",
      "Epoch 3145, Loss: 0.13277876004576683, Final Batch Loss: 0.060145262628793716\n",
      "Epoch 3146, Loss: 0.09621662274003029, Final Batch Loss: 0.03463044390082359\n",
      "Epoch 3147, Loss: 0.09890998154878616, Final Batch Loss: 0.058893557637929916\n",
      "Epoch 3148, Loss: 0.09743193536996841, Final Batch Loss: 0.041396379470825195\n",
      "Epoch 3149, Loss: 0.13181861862540245, Final Batch Loss: 0.06175915524363518\n",
      "Epoch 3150, Loss: 0.14510465413331985, Final Batch Loss: 0.056908175349235535\n",
      "Epoch 3151, Loss: 0.11338934674859047, Final Batch Loss: 0.036856044083833694\n",
      "Epoch 3152, Loss: 0.10218887403607368, Final Batch Loss: 0.04064108803868294\n",
      "Epoch 3153, Loss: 0.12783478200435638, Final Batch Loss: 0.0613834485411644\n",
      "Epoch 3154, Loss: 0.13226845487952232, Final Batch Loss: 0.08893810212612152\n",
      "Epoch 3155, Loss: 0.12047379463911057, Final Batch Loss: 0.06634005159139633\n",
      "Epoch 3156, Loss: 0.14277052879333496, Final Batch Loss: 0.06400082260370255\n",
      "Epoch 3157, Loss: 0.09809279814362526, Final Batch Loss: 0.0526542142033577\n",
      "Epoch 3158, Loss: 0.09525828436017036, Final Batch Loss: 0.037935521453619\n",
      "Epoch 3159, Loss: 0.11532822996377945, Final Batch Loss: 0.04313686490058899\n",
      "Epoch 3160, Loss: 0.09958697482943535, Final Batch Loss: 0.06111975014209747\n",
      "Epoch 3161, Loss: 0.13636156171560287, Final Batch Loss: 0.08518737554550171\n",
      "Epoch 3162, Loss: 0.1261802539229393, Final Batch Loss: 0.041163623332977295\n",
      "Epoch 3163, Loss: 0.09898621588945389, Final Batch Loss: 0.04774472117424011\n",
      "Epoch 3164, Loss: 0.09149133786559105, Final Batch Loss: 0.03481545299291611\n",
      "Epoch 3165, Loss: 0.09932756051421165, Final Batch Loss: 0.05756755545735359\n",
      "Epoch 3166, Loss: 0.09441477060317993, Final Batch Loss: 0.04286841303110123\n",
      "Epoch 3167, Loss: 0.08149044215679169, Final Batch Loss: 0.04061257839202881\n",
      "Epoch 3168, Loss: 0.10822044685482979, Final Batch Loss: 0.07945035398006439\n",
      "Epoch 3169, Loss: 0.08451635017991066, Final Batch Loss: 0.04497338458895683\n",
      "Epoch 3170, Loss: 0.10255330428481102, Final Batch Loss: 0.05335473269224167\n",
      "Epoch 3171, Loss: 0.09309298917651176, Final Batch Loss: 0.04068315774202347\n",
      "Epoch 3172, Loss: 0.09421126917004585, Final Batch Loss: 0.051798731088638306\n",
      "Epoch 3173, Loss: 0.08556834608316422, Final Batch Loss: 0.043532539159059525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3174, Loss: 0.13980862870812416, Final Batch Loss: 0.10070917755365372\n",
      "Epoch 3175, Loss: 0.09250606968998909, Final Batch Loss: 0.03812694922089577\n",
      "Epoch 3176, Loss: 0.089908916503191, Final Batch Loss: 0.03490334749221802\n",
      "Epoch 3177, Loss: 0.15315790474414825, Final Batch Loss: 0.11006230115890503\n",
      "Epoch 3178, Loss: 0.09329263493418694, Final Batch Loss: 0.048713553696870804\n",
      "Epoch 3179, Loss: 0.11696197465062141, Final Batch Loss: 0.050122614949941635\n",
      "Epoch 3180, Loss: 0.09236137941479683, Final Batch Loss: 0.04200051724910736\n",
      "Epoch 3181, Loss: 0.10270381346344948, Final Batch Loss: 0.054052554070949554\n",
      "Epoch 3182, Loss: 0.09231020137667656, Final Batch Loss: 0.048829179257154465\n",
      "Epoch 3183, Loss: 0.1157713457942009, Final Batch Loss: 0.04939170181751251\n",
      "Epoch 3184, Loss: 0.09091570600867271, Final Batch Loss: 0.05878857150673866\n",
      "Epoch 3185, Loss: 0.15033474564552307, Final Batch Loss: 0.1060599684715271\n",
      "Epoch 3186, Loss: 0.10513095185160637, Final Batch Loss: 0.06302338093519211\n",
      "Epoch 3187, Loss: 0.1121547594666481, Final Batch Loss: 0.05551161244511604\n",
      "Epoch 3188, Loss: 0.10110372491180897, Final Batch Loss: 0.022531839087605476\n",
      "Epoch 3189, Loss: 0.13558825850486755, Final Batch Loss: 0.07219555228948593\n",
      "Epoch 3190, Loss: 0.12969356402754784, Final Batch Loss: 0.04194021597504616\n",
      "Epoch 3191, Loss: 0.14792098850011826, Final Batch Loss: 0.08540715277194977\n",
      "Epoch 3192, Loss: 0.1332353763282299, Final Batch Loss: 0.08098198473453522\n",
      "Epoch 3193, Loss: 0.09934219345450401, Final Batch Loss: 0.052758656442165375\n",
      "Epoch 3194, Loss: 0.13470951840281487, Final Batch Loss: 0.0569736547768116\n",
      "Epoch 3195, Loss: 0.12926547229290009, Final Batch Loss: 0.07201488316059113\n",
      "Epoch 3196, Loss: 0.09320874139666557, Final Batch Loss: 0.03961385414004326\n",
      "Epoch 3197, Loss: 0.09957164898514748, Final Batch Loss: 0.045343246310949326\n",
      "Epoch 3198, Loss: 0.08935263007879257, Final Batch Loss: 0.03292183578014374\n",
      "Epoch 3199, Loss: 0.11103087291121483, Final Batch Loss: 0.050225257873535156\n",
      "Epoch 3200, Loss: 0.1977562978863716, Final Batch Loss: 0.0647435262799263\n",
      "Epoch 3201, Loss: 0.08463212475180626, Final Batch Loss: 0.03365205600857735\n",
      "Epoch 3202, Loss: 0.10631709545850754, Final Batch Loss: 0.05988401547074318\n",
      "Epoch 3203, Loss: 0.10414048284292221, Final Batch Loss: 0.03679727017879486\n",
      "Epoch 3204, Loss: 0.11419443786144257, Final Batch Loss: 0.0808805599808693\n",
      "Epoch 3205, Loss: 0.09677442163228989, Final Batch Loss: 0.04475432634353638\n",
      "Epoch 3206, Loss: 0.08999569341540337, Final Batch Loss: 0.04982975125312805\n",
      "Epoch 3207, Loss: 0.12051881849765778, Final Batch Loss: 0.045934274792671204\n",
      "Epoch 3208, Loss: 0.0954594649374485, Final Batch Loss: 0.05397993326187134\n",
      "Epoch 3209, Loss: 0.10867443680763245, Final Batch Loss: 0.05305611714720726\n",
      "Epoch 3210, Loss: 0.10884922370314598, Final Batch Loss: 0.04028132185339928\n",
      "Epoch 3211, Loss: 0.09400290995836258, Final Batch Loss: 0.045548442751169205\n",
      "Epoch 3212, Loss: 0.08447448164224625, Final Batch Loss: 0.04621528461575508\n",
      "Epoch 3213, Loss: 0.10850943997502327, Final Batch Loss: 0.05554810166358948\n",
      "Epoch 3214, Loss: 0.0875532515347004, Final Batch Loss: 0.040989045053720474\n",
      "Epoch 3215, Loss: 0.08357318118214607, Final Batch Loss: 0.034901369363069534\n",
      "Epoch 3216, Loss: 0.08793003112077713, Final Batch Loss: 0.03731727972626686\n",
      "Epoch 3217, Loss: 0.08267000690102577, Final Batch Loss: 0.04062457010149956\n",
      "Epoch 3218, Loss: 0.11668174341320992, Final Batch Loss: 0.07267332077026367\n",
      "Epoch 3219, Loss: 0.1939460188150406, Final Batch Loss: 0.05422200262546539\n",
      "Epoch 3220, Loss: 0.09807400777935982, Final Batch Loss: 0.0528779961168766\n",
      "Epoch 3221, Loss: 0.10979251936078072, Final Batch Loss: 0.031375702470541\n",
      "Epoch 3222, Loss: 0.12442544475197792, Final Batch Loss: 0.052187900990247726\n",
      "Epoch 3223, Loss: 0.12500553205609322, Final Batch Loss: 0.07256490737199783\n",
      "Epoch 3224, Loss: 0.13994932547211647, Final Batch Loss: 0.09674409031867981\n",
      "Epoch 3225, Loss: 0.13450763002038002, Final Batch Loss: 0.07414363324642181\n",
      "Epoch 3226, Loss: 0.09620574489235878, Final Batch Loss: 0.04582886025309563\n",
      "Epoch 3227, Loss: 0.089337557554245, Final Batch Loss: 0.04414765164256096\n",
      "Epoch 3228, Loss: 0.13661914691329002, Final Batch Loss: 0.05371112748980522\n",
      "Epoch 3229, Loss: 0.10968061909079552, Final Batch Loss: 0.07689636200666428\n",
      "Epoch 3230, Loss: 0.11856250464916229, Final Batch Loss: 0.0562518909573555\n",
      "Epoch 3231, Loss: 0.08079813048243523, Final Batch Loss: 0.031835008412599564\n",
      "Epoch 3232, Loss: 0.12968778610229492, Final Batch Loss: 0.07558836042881012\n",
      "Epoch 3233, Loss: 0.18041589111089706, Final Batch Loss: 0.047061987221241\n",
      "Epoch 3234, Loss: 0.10892876982688904, Final Batch Loss: 0.05294952541589737\n",
      "Epoch 3235, Loss: 0.10784552618861198, Final Batch Loss: 0.051396694034338\n",
      "Epoch 3236, Loss: 0.0897566694766283, Final Batch Loss: 0.02912118472158909\n",
      "Epoch 3237, Loss: 0.1728264018893242, Final Batch Loss: 0.10350813716650009\n",
      "Epoch 3238, Loss: 0.11126179993152618, Final Batch Loss: 0.06252884864807129\n",
      "Epoch 3239, Loss: 0.12583952769637108, Final Batch Loss: 0.05017038807272911\n",
      "Epoch 3240, Loss: 0.12964478507637978, Final Batch Loss: 0.08499535173177719\n",
      "Epoch 3241, Loss: 0.10951030999422073, Final Batch Loss: 0.06265084445476532\n",
      "Epoch 3242, Loss: 0.12387105077505112, Final Batch Loss: 0.04741945117712021\n",
      "Epoch 3243, Loss: 0.09273391962051392, Final Batch Loss: 0.04096873104572296\n",
      "Epoch 3244, Loss: 0.13484055921435356, Final Batch Loss: 0.0778406411409378\n",
      "Epoch 3245, Loss: 0.11410601064562798, Final Batch Loss: 0.050197672098875046\n",
      "Epoch 3246, Loss: 0.15929628536105156, Final Batch Loss: 0.1114472970366478\n",
      "Epoch 3247, Loss: 0.14451157301664352, Final Batch Loss: 0.05029747635126114\n",
      "Epoch 3248, Loss: 0.10143041983246803, Final Batch Loss: 0.05190315097570419\n",
      "Epoch 3249, Loss: 0.1308630108833313, Final Batch Loss: 0.06113173067569733\n",
      "Epoch 3250, Loss: 0.1255030557513237, Final Batch Loss: 0.06451711058616638\n",
      "Epoch 3251, Loss: 0.12411325424909592, Final Batch Loss: 0.07543079555034637\n",
      "Epoch 3252, Loss: 0.12497249245643616, Final Batch Loss: 0.08765940368175507\n",
      "Epoch 3253, Loss: 0.11864953115582466, Final Batch Loss: 0.06862346082925797\n",
      "Epoch 3254, Loss: 0.11024858430027962, Final Batch Loss: 0.03496896103024483\n",
      "Epoch 3255, Loss: 0.12262064963579178, Final Batch Loss: 0.06210332363843918\n",
      "Epoch 3256, Loss: 0.1164318323135376, Final Batch Loss: 0.03604136407375336\n",
      "Epoch 3257, Loss: 0.1099112369120121, Final Batch Loss: 0.056596893817186356\n",
      "Epoch 3258, Loss: 0.10664736852049828, Final Batch Loss: 0.0504111722111702\n",
      "Epoch 3259, Loss: 0.10969344154000282, Final Batch Loss: 0.05889284983277321\n",
      "Epoch 3260, Loss: 0.10594677180051804, Final Batch Loss: 0.06712271273136139\n",
      "Epoch 3261, Loss: 0.09497543796896935, Final Batch Loss: 0.04830625280737877\n",
      "Epoch 3262, Loss: 0.11624523624777794, Final Batch Loss: 0.0550796277821064\n",
      "Epoch 3263, Loss: 0.09893413633108139, Final Batch Loss: 0.056301604956388474\n",
      "Epoch 3264, Loss: 0.10540632158517838, Final Batch Loss: 0.04567466676235199\n",
      "Epoch 3265, Loss: 0.10883587598800659, Final Batch Loss: 0.053053855895996094\n",
      "Epoch 3266, Loss: 0.08290549740195274, Final Batch Loss: 0.03519689291715622\n",
      "Epoch 3267, Loss: 0.11869488283991814, Final Batch Loss: 0.06344132125377655\n",
      "Epoch 3268, Loss: 0.12196104973554611, Final Batch Loss: 0.03895106166601181\n",
      "Epoch 3269, Loss: 0.10193653032183647, Final Batch Loss: 0.06728041917085648\n",
      "Epoch 3270, Loss: 0.1447763890028, Final Batch Loss: 0.04844453185796738\n",
      "Epoch 3271, Loss: 0.16261226311326027, Final Batch Loss: 0.11583691835403442\n",
      "Epoch 3272, Loss: 0.13721008598804474, Final Batch Loss: 0.08464647084474564\n",
      "Epoch 3273, Loss: 0.12219073623418808, Final Batch Loss: 0.0694870799779892\n",
      "Epoch 3274, Loss: 0.09623334556818008, Final Batch Loss: 0.03863292932510376\n",
      "Epoch 3275, Loss: 0.10215745493769646, Final Batch Loss: 0.040658675134181976\n",
      "Epoch 3276, Loss: 0.1325984001159668, Final Batch Loss: 0.0639454647898674\n",
      "Epoch 3277, Loss: 0.10591325908899307, Final Batch Loss: 0.05881775915622711\n",
      "Epoch 3278, Loss: 0.09154435992240906, Final Batch Loss: 0.05288739129900932\n",
      "Epoch 3279, Loss: 0.11242101714015007, Final Batch Loss: 0.05294657126069069\n",
      "Epoch 3280, Loss: 0.10480527207255363, Final Batch Loss: 0.05734263360500336\n",
      "Epoch 3281, Loss: 0.1140393428504467, Final Batch Loss: 0.06041480973362923\n",
      "Epoch 3282, Loss: 0.10140001401305199, Final Batch Loss: 0.03757325932383537\n",
      "Epoch 3283, Loss: 0.11396612226963043, Final Batch Loss: 0.04477909207344055\n",
      "Epoch 3284, Loss: 0.12502267956733704, Final Batch Loss: 0.08385515958070755\n",
      "Epoch 3285, Loss: 0.10153906419873238, Final Batch Loss: 0.04162132740020752\n",
      "Epoch 3286, Loss: 0.10044876486063004, Final Batch Loss: 0.03672902286052704\n",
      "Epoch 3287, Loss: 0.10203676298260689, Final Batch Loss: 0.05319633334875107\n",
      "Epoch 3288, Loss: 0.09738383814692497, Final Batch Loss: 0.04485173523426056\n",
      "Epoch 3289, Loss: 0.10828519612550735, Final Batch Loss: 0.0697527825832367\n",
      "Epoch 3290, Loss: 0.10619082674384117, Final Batch Loss: 0.05500051751732826\n",
      "Epoch 3291, Loss: 0.09346785768866539, Final Batch Loss: 0.04816471040248871\n",
      "Epoch 3292, Loss: 0.09851235896348953, Final Batch Loss: 0.04411764442920685\n",
      "Epoch 3293, Loss: 0.1301267109811306, Final Batch Loss: 0.053159188479185104\n",
      "Epoch 3294, Loss: 0.11783509701490402, Final Batch Loss: 0.04265882074832916\n",
      "Epoch 3295, Loss: 0.1011403389275074, Final Batch Loss: 0.03654119744896889\n",
      "Epoch 3296, Loss: 0.09912963584065437, Final Batch Loss: 0.053992342203855515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3297, Loss: 0.13397548533976078, Final Batch Loss: 0.02993829734623432\n",
      "Epoch 3298, Loss: 0.1014414057135582, Final Batch Loss: 0.05746719241142273\n",
      "Epoch 3299, Loss: 0.09614026919007301, Final Batch Loss: 0.0366971381008625\n",
      "Epoch 3300, Loss: 0.10905341804027557, Final Batch Loss: 0.07362788915634155\n",
      "Epoch 3301, Loss: 0.11541220173239708, Final Batch Loss: 0.057035960257053375\n",
      "Epoch 3302, Loss: 0.08821777999401093, Final Batch Loss: 0.039082057774066925\n",
      "Epoch 3303, Loss: 0.11321524903178215, Final Batch Loss: 0.06157632917165756\n",
      "Epoch 3304, Loss: 0.10176839679479599, Final Batch Loss: 0.0608268603682518\n",
      "Epoch 3305, Loss: 0.09571592882275581, Final Batch Loss: 0.04037937894463539\n",
      "Epoch 3306, Loss: 0.10149556770920753, Final Batch Loss: 0.036368656903505325\n",
      "Epoch 3307, Loss: 0.13439851626753807, Final Batch Loss: 0.07599341124296188\n",
      "Epoch 3308, Loss: 0.10277026519179344, Final Batch Loss: 0.05208297073841095\n",
      "Epoch 3309, Loss: 0.1152905598282814, Final Batch Loss: 0.04544362425804138\n",
      "Epoch 3310, Loss: 0.12047414481639862, Final Batch Loss: 0.050439707934856415\n",
      "Epoch 3311, Loss: 0.10683873668313026, Final Batch Loss: 0.05717758461833\n",
      "Epoch 3312, Loss: 0.10190147161483765, Final Batch Loss: 0.060945216566324234\n",
      "Epoch 3313, Loss: 0.18559390306472778, Final Batch Loss: 0.1286017894744873\n",
      "Epoch 3314, Loss: 0.13602858781814575, Final Batch Loss: 0.057992249727249146\n",
      "Epoch 3315, Loss: 0.1147385984659195, Final Batch Loss: 0.04820734262466431\n",
      "Epoch 3316, Loss: 0.10919599235057831, Final Batch Loss: 0.0457640215754509\n",
      "Epoch 3317, Loss: 0.13198845461010933, Final Batch Loss: 0.08219680935144424\n",
      "Epoch 3318, Loss: 0.14653196185827255, Final Batch Loss: 0.06497232615947723\n",
      "Epoch 3319, Loss: 0.1297456920146942, Final Batch Loss: 0.06216280162334442\n",
      "Epoch 3320, Loss: 0.12775897607207298, Final Batch Loss: 0.06570059061050415\n",
      "Epoch 3321, Loss: 0.11000853776931763, Final Batch Loss: 0.05253557860851288\n",
      "Epoch 3322, Loss: 0.13756704330444336, Final Batch Loss: 0.06587567925453186\n",
      "Epoch 3323, Loss: 0.1358550228178501, Final Batch Loss: 0.09798488765954971\n",
      "Epoch 3324, Loss: 0.15318606048822403, Final Batch Loss: 0.09359286725521088\n",
      "Epoch 3325, Loss: 0.1276107281446457, Final Batch Loss: 0.03979581594467163\n",
      "Epoch 3326, Loss: 0.15500593930482864, Final Batch Loss: 0.07516568899154663\n",
      "Epoch 3327, Loss: 0.09483008831739426, Final Batch Loss: 0.03325165435671806\n",
      "Epoch 3328, Loss: 0.10605106130242348, Final Batch Loss: 0.057873841375112534\n",
      "Epoch 3329, Loss: 0.14590894058346748, Final Batch Loss: 0.11120178550481796\n",
      "Epoch 3330, Loss: 0.09457168355584145, Final Batch Loss: 0.03861277550458908\n",
      "Epoch 3331, Loss: 0.09773386269807816, Final Batch Loss: 0.05048046261072159\n",
      "Epoch 3332, Loss: 0.1189919151365757, Final Batch Loss: 0.04479637369513512\n",
      "Epoch 3333, Loss: 0.10855073481798172, Final Batch Loss: 0.06145132705569267\n",
      "Epoch 3334, Loss: 0.16109643876552582, Final Batch Loss: 0.08830802887678146\n",
      "Epoch 3335, Loss: 0.11883291974663734, Final Batch Loss: 0.04455440863966942\n",
      "Epoch 3336, Loss: 0.09278910607099533, Final Batch Loss: 0.04301577806472778\n",
      "Epoch 3337, Loss: 0.10566998645663261, Final Batch Loss: 0.05242340639233589\n",
      "Epoch 3338, Loss: 0.15165552124381065, Final Batch Loss: 0.0893244668841362\n",
      "Epoch 3339, Loss: 0.1460082270205021, Final Batch Loss: 0.08794913440942764\n",
      "Epoch 3340, Loss: 0.10960981622338295, Final Batch Loss: 0.052938319742679596\n",
      "Epoch 3341, Loss: 0.1449153646826744, Final Batch Loss: 0.07849818468093872\n",
      "Epoch 3342, Loss: 0.14870498329401016, Final Batch Loss: 0.07445240765810013\n",
      "Epoch 3343, Loss: 0.09654612839221954, Final Batch Loss: 0.04406893625855446\n",
      "Epoch 3344, Loss: 0.09140593558549881, Final Batch Loss: 0.0463830903172493\n",
      "Epoch 3345, Loss: 0.10214260220527649, Final Batch Loss: 0.046870145946741104\n",
      "Epoch 3346, Loss: 0.11541035026311874, Final Batch Loss: 0.06255092471837997\n",
      "Epoch 3347, Loss: 0.14284204319119453, Final Batch Loss: 0.08471301943063736\n",
      "Epoch 3348, Loss: 0.10731998831033707, Final Batch Loss: 0.040853194892406464\n",
      "Epoch 3349, Loss: 0.10724004730582237, Final Batch Loss: 0.0614081434905529\n",
      "Epoch 3350, Loss: 0.10430734604597092, Final Batch Loss: 0.04800226911902428\n",
      "Epoch 3351, Loss: 0.12285605818033218, Final Batch Loss: 0.056387387216091156\n",
      "Epoch 3352, Loss: 0.11257127672433853, Final Batch Loss: 0.04814466834068298\n",
      "Epoch 3353, Loss: 0.14884790033102036, Final Batch Loss: 0.10024913400411606\n",
      "Epoch 3354, Loss: 0.1414124220609665, Final Batch Loss: 0.08900482207536697\n",
      "Epoch 3355, Loss: 0.1021992564201355, Final Batch Loss: 0.033367179334163666\n",
      "Epoch 3356, Loss: 0.10075481608510017, Final Batch Loss: 0.05983394384384155\n",
      "Epoch 3357, Loss: 0.10498990677297115, Final Batch Loss: 0.03104962222278118\n",
      "Epoch 3358, Loss: 0.09320727363228798, Final Batch Loss: 0.04578825458884239\n",
      "Epoch 3359, Loss: 0.10775215551257133, Final Batch Loss: 0.038417283445596695\n",
      "Epoch 3360, Loss: 0.11608178541064262, Final Batch Loss: 0.07334572076797485\n",
      "Epoch 3361, Loss: 0.09261897578835487, Final Batch Loss: 0.05769624561071396\n",
      "Epoch 3362, Loss: 0.09679711423814297, Final Batch Loss: 0.0681726336479187\n",
      "Epoch 3363, Loss: 0.1069590151309967, Final Batch Loss: 0.04320690035820007\n",
      "Epoch 3364, Loss: 0.11479299142956734, Final Batch Loss: 0.053133007138967514\n",
      "Epoch 3365, Loss: 0.09738347306847572, Final Batch Loss: 0.05407378450036049\n",
      "Epoch 3366, Loss: 0.0984579585492611, Final Batch Loss: 0.055340372025966644\n",
      "Epoch 3367, Loss: 0.15787936747074127, Final Batch Loss: 0.08559805899858475\n",
      "Epoch 3368, Loss: 0.10121265798807144, Final Batch Loss: 0.0481983982026577\n",
      "Epoch 3369, Loss: 0.12773943692445755, Final Batch Loss: 0.07350663840770721\n",
      "Epoch 3370, Loss: 0.09523960947990417, Final Batch Loss: 0.04305216297507286\n",
      "Epoch 3371, Loss: 0.11892234906554222, Final Batch Loss: 0.048496048897504807\n",
      "Epoch 3372, Loss: 0.12932060286402702, Final Batch Loss: 0.07270890474319458\n",
      "Epoch 3373, Loss: 0.0918133333325386, Final Batch Loss: 0.04169657826423645\n",
      "Epoch 3374, Loss: 0.16023509949445724, Final Batch Loss: 0.11425004154443741\n",
      "Epoch 3375, Loss: 0.11507560312747955, Final Batch Loss: 0.0770527720451355\n",
      "Epoch 3376, Loss: 0.09163887426257133, Final Batch Loss: 0.041197001934051514\n",
      "Epoch 3377, Loss: 0.11994283646345139, Final Batch Loss: 0.045801348984241486\n",
      "Epoch 3378, Loss: 0.08331868052482605, Final Batch Loss: 0.03175733983516693\n",
      "Epoch 3379, Loss: 0.1284520961344242, Final Batch Loss: 0.0475725494325161\n",
      "Epoch 3380, Loss: 0.08385263569653034, Final Batch Loss: 0.02783420868217945\n",
      "Epoch 3381, Loss: 0.10797669738531113, Final Batch Loss: 0.05157814174890518\n",
      "Epoch 3382, Loss: 0.11440476775169373, Final Batch Loss: 0.03341684490442276\n",
      "Epoch 3383, Loss: 0.13478707149624825, Final Batch Loss: 0.05803334340453148\n",
      "Epoch 3384, Loss: 0.09888047724962234, Final Batch Loss: 0.054504863917827606\n",
      "Epoch 3385, Loss: 0.10776925832033157, Final Batch Loss: 0.03711194545030594\n",
      "Epoch 3386, Loss: 0.10075996816158295, Final Batch Loss: 0.04800688102841377\n",
      "Epoch 3387, Loss: 0.10742757096886635, Final Batch Loss: 0.06411237269639969\n",
      "Epoch 3388, Loss: 0.12852414697408676, Final Batch Loss: 0.0761554092168808\n",
      "Epoch 3389, Loss: 0.10814166441559792, Final Batch Loss: 0.06944388896226883\n",
      "Epoch 3390, Loss: 0.11643954738974571, Final Batch Loss: 0.05930640548467636\n",
      "Epoch 3391, Loss: 0.1004021018743515, Final Batch Loss: 0.052680328488349915\n",
      "Epoch 3392, Loss: 0.08971333131194115, Final Batch Loss: 0.05756954476237297\n",
      "Epoch 3393, Loss: 0.1318669505417347, Final Batch Loss: 0.05877744033932686\n",
      "Epoch 3394, Loss: 0.09906477108597755, Final Batch Loss: 0.0449446476995945\n",
      "Epoch 3395, Loss: 0.11017044261097908, Final Batch Loss: 0.04997551813721657\n",
      "Epoch 3396, Loss: 0.09662961401045322, Final Batch Loss: 0.02769199199974537\n",
      "Epoch 3397, Loss: 0.17293743789196014, Final Batch Loss: 0.10493054240942001\n",
      "Epoch 3398, Loss: 0.09932713955640793, Final Batch Loss: 0.06306753307580948\n",
      "Epoch 3399, Loss: 0.08246718719601631, Final Batch Loss: 0.037537943571805954\n",
      "Epoch 3400, Loss: 0.10299880430102348, Final Batch Loss: 0.0515691414475441\n",
      "Epoch 3401, Loss: 0.12986250966787338, Final Batch Loss: 0.0661141574382782\n",
      "Epoch 3402, Loss: 0.10291900858283043, Final Batch Loss: 0.06462728977203369\n",
      "Epoch 3403, Loss: 0.0854070857167244, Final Batch Loss: 0.042910147458314896\n",
      "Epoch 3404, Loss: 0.13336268067359924, Final Batch Loss: 0.0596252977848053\n",
      "Epoch 3405, Loss: 0.09808631613850594, Final Batch Loss: 0.03635602071881294\n",
      "Epoch 3406, Loss: 0.12756998091936111, Final Batch Loss: 0.053540028631687164\n",
      "Epoch 3407, Loss: 0.1163729801774025, Final Batch Loss: 0.0540117472410202\n",
      "Epoch 3408, Loss: 0.13431250303983688, Final Batch Loss: 0.09556693583726883\n",
      "Epoch 3409, Loss: 0.09592296928167343, Final Batch Loss: 0.042599573731422424\n",
      "Epoch 3410, Loss: 0.11656343191862106, Final Batch Loss: 0.07577571272850037\n",
      "Epoch 3411, Loss: 0.13619188219308853, Final Batch Loss: 0.10028472542762756\n",
      "Epoch 3412, Loss: 0.12384810298681259, Final Batch Loss: 0.04723194241523743\n",
      "Epoch 3413, Loss: 0.11960980668663979, Final Batch Loss: 0.05408697947859764\n",
      "Epoch 3414, Loss: 0.12455779686570168, Final Batch Loss: 0.0414482019841671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3415, Loss: 0.08517185598611832, Final Batch Loss: 0.027361605316400528\n",
      "Epoch 3416, Loss: 0.0954374261200428, Final Batch Loss: 0.03783341497182846\n",
      "Epoch 3417, Loss: 0.14429113641381264, Final Batch Loss: 0.08900321274995804\n",
      "Epoch 3418, Loss: 0.10215198621153831, Final Batch Loss: 0.0520087294280529\n",
      "Epoch 3419, Loss: 0.1810751035809517, Final Batch Loss: 0.12228307127952576\n",
      "Epoch 3420, Loss: 0.09153908491134644, Final Batch Loss: 0.03094303235411644\n",
      "Epoch 3421, Loss: 0.10451417788863182, Final Batch Loss: 0.03480647876858711\n",
      "Epoch 3422, Loss: 0.13401229679584503, Final Batch Loss: 0.06987889856100082\n",
      "Epoch 3423, Loss: 0.09417356923222542, Final Batch Loss: 0.03707422316074371\n",
      "Epoch 3424, Loss: 0.09318748116493225, Final Batch Loss: 0.029245853424072266\n",
      "Epoch 3425, Loss: 0.1140107773244381, Final Batch Loss: 0.08115115761756897\n",
      "Epoch 3426, Loss: 0.10388036444783211, Final Batch Loss: 0.05306174233555794\n",
      "Epoch 3427, Loss: 0.09085690975189209, Final Batch Loss: 0.03303619846701622\n",
      "Epoch 3428, Loss: 0.09773813933134079, Final Batch Loss: 0.05579909682273865\n",
      "Epoch 3429, Loss: 0.09010262042284012, Final Batch Loss: 0.05251374840736389\n",
      "Epoch 3430, Loss: 0.10200834274291992, Final Batch Loss: 0.06856268644332886\n",
      "Epoch 3431, Loss: 0.09982456639409065, Final Batch Loss: 0.04837775230407715\n",
      "Epoch 3432, Loss: 0.09417224861681461, Final Batch Loss: 0.06637253612279892\n",
      "Epoch 3433, Loss: 0.10834221914410591, Final Batch Loss: 0.05542207509279251\n",
      "Epoch 3434, Loss: 0.12112845480442047, Final Batch Loss: 0.05580157786607742\n",
      "Epoch 3435, Loss: 0.11046840995550156, Final Batch Loss: 0.053966324776411057\n",
      "Epoch 3436, Loss: 0.11168394982814789, Final Batch Loss: 0.06302046775817871\n",
      "Epoch 3437, Loss: 0.10348951444029808, Final Batch Loss: 0.05649049952626228\n",
      "Epoch 3438, Loss: 0.09971161931753159, Final Batch Loss: 0.046422574669122696\n",
      "Epoch 3439, Loss: 0.08836839348077774, Final Batch Loss: 0.043990060687065125\n",
      "Epoch 3440, Loss: 0.1164385937154293, Final Batch Loss: 0.05142270401120186\n",
      "Epoch 3441, Loss: 0.09897957369685173, Final Batch Loss: 0.05116797238588333\n",
      "Epoch 3442, Loss: 0.08978831768035889, Final Batch Loss: 0.05632192641496658\n",
      "Epoch 3443, Loss: 0.1100859995931387, Final Batch Loss: 0.07908698171377182\n",
      "Epoch 3444, Loss: 0.13527365401387215, Final Batch Loss: 0.07692411541938782\n",
      "Epoch 3445, Loss: 0.09454537555575371, Final Batch Loss: 0.04317060112953186\n",
      "Epoch 3446, Loss: 0.1231217011809349, Final Batch Loss: 0.06699386239051819\n",
      "Epoch 3447, Loss: 0.10289515927433968, Final Batch Loss: 0.043217942118644714\n",
      "Epoch 3448, Loss: 0.09975190460681915, Final Batch Loss: 0.02946237474679947\n",
      "Epoch 3449, Loss: 0.10592455789446831, Final Batch Loss: 0.05095263570547104\n",
      "Epoch 3450, Loss: 0.12422730401158333, Final Batch Loss: 0.06057535484433174\n",
      "Epoch 3451, Loss: 0.1254803016781807, Final Batch Loss: 0.06017833948135376\n",
      "Epoch 3452, Loss: 0.09357406571507454, Final Batch Loss: 0.047331709414720535\n",
      "Epoch 3453, Loss: 0.1096811294555664, Final Batch Loss: 0.05195965990424156\n",
      "Epoch 3454, Loss: 0.11451338604092598, Final Batch Loss: 0.040416207164525986\n",
      "Epoch 3455, Loss: 0.10027285292744637, Final Batch Loss: 0.042150143533945084\n",
      "Epoch 3456, Loss: 0.10417082533240318, Final Batch Loss: 0.03590097650885582\n",
      "Epoch 3457, Loss: 0.10340498760342598, Final Batch Loss: 0.06644968688488007\n",
      "Epoch 3458, Loss: 0.11240847781300545, Final Batch Loss: 0.07243240624666214\n",
      "Epoch 3459, Loss: 0.08550731465220451, Final Batch Loss: 0.042135365307331085\n",
      "Epoch 3460, Loss: 0.10857494547963142, Final Batch Loss: 0.07239056378602982\n",
      "Epoch 3461, Loss: 0.10698103159666061, Final Batch Loss: 0.0498482808470726\n",
      "Epoch 3462, Loss: 0.10901880264282227, Final Batch Loss: 0.06355070322751999\n",
      "Epoch 3463, Loss: 0.09787267446517944, Final Batch Loss: 0.0527910552918911\n",
      "Epoch 3464, Loss: 0.11129155382514, Final Batch Loss: 0.060771048069000244\n",
      "Epoch 3465, Loss: 0.13670646399259567, Final Batch Loss: 0.04668343812227249\n",
      "Epoch 3466, Loss: 0.1287696287035942, Final Batch Loss: 0.06983397901058197\n",
      "Epoch 3467, Loss: 0.09694879874587059, Final Batch Loss: 0.05705102160573006\n",
      "Epoch 3468, Loss: 0.10464681312441826, Final Batch Loss: 0.050938673317432404\n",
      "Epoch 3469, Loss: 0.11196915805339813, Final Batch Loss: 0.06124145910143852\n",
      "Epoch 3470, Loss: 0.14641284942626953, Final Batch Loss: 0.07607947289943695\n",
      "Epoch 3471, Loss: 0.09843318536877632, Final Batch Loss: 0.0377584733068943\n",
      "Epoch 3472, Loss: 0.1060425266623497, Final Batch Loss: 0.06244152784347534\n",
      "Epoch 3473, Loss: 0.08998915553092957, Final Batch Loss: 0.04252427816390991\n",
      "Epoch 3474, Loss: 0.09744036942720413, Final Batch Loss: 0.05720687657594681\n",
      "Epoch 3475, Loss: 0.08276211097836494, Final Batch Loss: 0.0334969237446785\n",
      "Epoch 3476, Loss: 0.08988693356513977, Final Batch Loss: 0.04057767242193222\n",
      "Epoch 3477, Loss: 0.13819363713264465, Final Batch Loss: 0.06897933036088943\n",
      "Epoch 3478, Loss: 0.08674934133887291, Final Batch Loss: 0.036081746220588684\n",
      "Epoch 3479, Loss: 0.10270200110971928, Final Batch Loss: 0.02256649173796177\n",
      "Epoch 3480, Loss: 0.1282104030251503, Final Batch Loss: 0.03385061025619507\n",
      "Epoch 3481, Loss: 0.09875082969665527, Final Batch Loss: 0.05920039862394333\n",
      "Epoch 3482, Loss: 0.10468937829136848, Final Batch Loss: 0.05447998642921448\n",
      "Epoch 3483, Loss: 0.11386851593852043, Final Batch Loss: 0.05053624138236046\n",
      "Epoch 3484, Loss: 0.0823599100112915, Final Batch Loss: 0.049169041216373444\n",
      "Epoch 3485, Loss: 0.10844865068793297, Final Batch Loss: 0.053580865263938904\n",
      "Epoch 3486, Loss: 0.09163140133023262, Final Batch Loss: 0.04217998683452606\n",
      "Epoch 3487, Loss: 0.10938051342964172, Final Batch Loss: 0.06313975155353546\n",
      "Epoch 3488, Loss: 0.09725918993353844, Final Batch Loss: 0.05118097737431526\n",
      "Epoch 3489, Loss: 0.09818413853645325, Final Batch Loss: 0.05049630254507065\n",
      "Epoch 3490, Loss: 0.1433568336069584, Final Batch Loss: 0.05134807154536247\n",
      "Epoch 3491, Loss: 0.11098020151257515, Final Batch Loss: 0.0426090843975544\n",
      "Epoch 3492, Loss: 0.11203151941299438, Final Batch Loss: 0.04399152100086212\n",
      "Epoch 3493, Loss: 0.10937248170375824, Final Batch Loss: 0.061800818890333176\n",
      "Epoch 3494, Loss: 0.09827544912695885, Final Batch Loss: 0.043684106320142746\n",
      "Epoch 3495, Loss: 0.12369291856884956, Final Batch Loss: 0.06460636854171753\n",
      "Epoch 3496, Loss: 0.09676587581634521, Final Batch Loss: 0.05268890783190727\n",
      "Epoch 3497, Loss: 0.12138238921761513, Final Batch Loss: 0.05109720304608345\n",
      "Epoch 3498, Loss: 0.09803010523319244, Final Batch Loss: 0.0403900071978569\n",
      "Epoch 3499, Loss: 0.1024647206068039, Final Batch Loss: 0.059932954609394073\n",
      "Epoch 3500, Loss: 0.10975943133234978, Final Batch Loss: 0.07085536420345306\n",
      "Epoch 3501, Loss: 0.11423524841666222, Final Batch Loss: 0.047007229179143906\n",
      "Epoch 3502, Loss: 0.1277441829442978, Final Batch Loss: 0.05508630722761154\n",
      "Epoch 3503, Loss: 0.10322552174329758, Final Batch Loss: 0.05941862612962723\n",
      "Epoch 3504, Loss: 0.12396949157118797, Final Batch Loss: 0.06969378888607025\n",
      "Epoch 3505, Loss: 0.11692926287651062, Final Batch Loss: 0.034197792410850525\n",
      "Epoch 3506, Loss: 0.12782128155231476, Final Batch Loss: 0.040814824402332306\n",
      "Epoch 3507, Loss: 0.09008484706282616, Final Batch Loss: 0.03702403977513313\n",
      "Epoch 3508, Loss: 0.12949934601783752, Final Batch Loss: 0.06614792346954346\n",
      "Epoch 3509, Loss: 0.10614128038287163, Final Batch Loss: 0.06393454968929291\n",
      "Epoch 3510, Loss: 0.1065119169652462, Final Batch Loss: 0.03160015866160393\n",
      "Epoch 3511, Loss: 0.10139400884509087, Final Batch Loss: 0.04721672460436821\n",
      "Epoch 3512, Loss: 0.11517206206917763, Final Batch Loss: 0.047737617045640945\n",
      "Epoch 3513, Loss: 0.09475317969918251, Final Batch Loss: 0.05331508815288544\n",
      "Epoch 3514, Loss: 0.14342471957206726, Final Batch Loss: 0.06364196538925171\n",
      "Epoch 3515, Loss: 0.11654867976903915, Final Batch Loss: 0.0672808364033699\n",
      "Epoch 3516, Loss: 0.10253733769059181, Final Batch Loss: 0.05978213995695114\n",
      "Epoch 3517, Loss: 0.08589470386505127, Final Batch Loss: 0.03796004131436348\n",
      "Epoch 3518, Loss: 0.17180245369672775, Final Batch Loss: 0.09043056517839432\n",
      "Epoch 3519, Loss: 0.11657466739416122, Final Batch Loss: 0.07308535277843475\n",
      "Epoch 3520, Loss: 0.09957512095570564, Final Batch Loss: 0.06486307084560394\n",
      "Epoch 3521, Loss: 0.12847930192947388, Final Batch Loss: 0.04701809585094452\n",
      "Epoch 3522, Loss: 0.10513129457831383, Final Batch Loss: 0.04768464341759682\n",
      "Epoch 3523, Loss: 0.09651604667305946, Final Batch Loss: 0.04388698562979698\n",
      "Epoch 3524, Loss: 0.1226043626666069, Final Batch Loss: 0.06261832267045975\n",
      "Epoch 3525, Loss: 0.1019819863140583, Final Batch Loss: 0.03633487597107887\n",
      "Epoch 3526, Loss: 0.10597493126988411, Final Batch Loss: 0.04795299470424652\n",
      "Epoch 3527, Loss: 0.09361713379621506, Final Batch Loss: 0.051357101649045944\n",
      "Epoch 3528, Loss: 0.0957062616944313, Final Batch Loss: 0.05261249467730522\n",
      "Epoch 3529, Loss: 0.10152812674641609, Final Batch Loss: 0.05247894674539566\n",
      "Epoch 3530, Loss: 0.10672725737094879, Final Batch Loss: 0.06637296825647354\n",
      "Epoch 3531, Loss: 0.11178455129265785, Final Batch Loss: 0.05935521423816681\n",
      "Epoch 3532, Loss: 0.11994299665093422, Final Batch Loss: 0.045577045530080795\n",
      "Epoch 3533, Loss: 0.12950004264712334, Final Batch Loss: 0.02641287073493004\n",
      "Epoch 3534, Loss: 0.1150791347026825, Final Batch Loss: 0.06886373460292816\n",
      "Epoch 3535, Loss: 0.12418588995933533, Final Batch Loss: 0.060356415808200836\n",
      "Epoch 3536, Loss: 0.11407596990466118, Final Batch Loss: 0.04371348395943642\n",
      "Epoch 3537, Loss: 0.11069707572460175, Final Batch Loss: 0.07241825014352798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3538, Loss: 0.09511660039424896, Final Batch Loss: 0.07045461982488632\n",
      "Epoch 3539, Loss: 0.11267504096031189, Final Batch Loss: 0.0658041462302208\n",
      "Epoch 3540, Loss: 0.10198739543557167, Final Batch Loss: 0.06808065623044968\n",
      "Epoch 3541, Loss: 0.12956596910953522, Final Batch Loss: 0.07136351615190506\n",
      "Epoch 3542, Loss: 0.08379378914833069, Final Batch Loss: 0.05552173778414726\n",
      "Epoch 3543, Loss: 0.08855454251170158, Final Batch Loss: 0.03648021072149277\n",
      "Epoch 3544, Loss: 0.10758639499545097, Final Batch Loss: 0.054832857102155685\n",
      "Epoch 3545, Loss: 0.10520538315176964, Final Batch Loss: 0.03270816430449486\n",
      "Epoch 3546, Loss: 0.11359585449099541, Final Batch Loss: 0.061271920800209045\n",
      "Epoch 3547, Loss: 0.07586220093071461, Final Batch Loss: 0.020831415429711342\n",
      "Epoch 3548, Loss: 0.1572314128279686, Final Batch Loss: 0.08388321846723557\n",
      "Epoch 3549, Loss: 0.09786681458353996, Final Batch Loss: 0.04155963286757469\n",
      "Epoch 3550, Loss: 0.09193819016218185, Final Batch Loss: 0.04835810139775276\n",
      "Epoch 3551, Loss: 0.10993240401148796, Final Batch Loss: 0.053764715790748596\n",
      "Epoch 3552, Loss: 0.1158180870115757, Final Batch Loss: 0.056481290608644485\n",
      "Epoch 3553, Loss: 0.07738503813743591, Final Batch Loss: 0.03473305702209473\n",
      "Epoch 3554, Loss: 0.0700902845710516, Final Batch Loss: 0.02429467998445034\n",
      "Epoch 3555, Loss: 0.10984145849943161, Final Batch Loss: 0.061289455741643906\n",
      "Epoch 3556, Loss: 0.11493932455778122, Final Batch Loss: 0.07111184298992157\n",
      "Epoch 3557, Loss: 0.08966883271932602, Final Batch Loss: 0.042451824992895126\n",
      "Epoch 3558, Loss: 0.15276911854743958, Final Batch Loss: 0.07132630050182343\n",
      "Epoch 3559, Loss: 0.17915980517864227, Final Batch Loss: 0.07510104775428772\n",
      "Epoch 3560, Loss: 0.10419156774878502, Final Batch Loss: 0.058485519140958786\n",
      "Epoch 3561, Loss: 0.10769963264465332, Final Batch Loss: 0.05041433125734329\n",
      "Epoch 3562, Loss: 0.10647260397672653, Final Batch Loss: 0.06772881746292114\n",
      "Epoch 3563, Loss: 0.10571925714612007, Final Batch Loss: 0.06326332688331604\n",
      "Epoch 3564, Loss: 0.10222481936216354, Final Batch Loss: 0.04637922719120979\n",
      "Epoch 3565, Loss: 0.11921608820557594, Final Batch Loss: 0.06925549358129501\n",
      "Epoch 3566, Loss: 0.11272437125444412, Final Batch Loss: 0.060316212475299835\n",
      "Epoch 3567, Loss: 0.11798154935240746, Final Batch Loss: 0.041590865701436996\n",
      "Epoch 3568, Loss: 0.11199700459837914, Final Batch Loss: 0.04643993452191353\n",
      "Epoch 3569, Loss: 0.09738031402230263, Final Batch Loss: 0.04785318672657013\n",
      "Epoch 3570, Loss: 0.08050379902124405, Final Batch Loss: 0.047275930643081665\n",
      "Epoch 3571, Loss: 0.10682718828320503, Final Batch Loss: 0.03656643256545067\n",
      "Epoch 3572, Loss: 0.11653359234333038, Final Batch Loss: 0.04730359464883804\n",
      "Epoch 3573, Loss: 0.10470942035317421, Final Batch Loss: 0.05552244558930397\n",
      "Epoch 3574, Loss: 0.12284495681524277, Final Batch Loss: 0.04732019454240799\n",
      "Epoch 3575, Loss: 0.08913139998912811, Final Batch Loss: 0.030963320285081863\n",
      "Epoch 3576, Loss: 0.11821990087628365, Final Batch Loss: 0.07297609001398087\n",
      "Epoch 3577, Loss: 0.12874706089496613, Final Batch Loss: 0.06879202276468277\n",
      "Epoch 3578, Loss: 0.08822109922766685, Final Batch Loss: 0.04374902322888374\n",
      "Epoch 3579, Loss: 0.09045917727053165, Final Batch Loss: 0.06941238045692444\n",
      "Epoch 3580, Loss: 0.13534840941429138, Final Batch Loss: 0.07829234004020691\n",
      "Epoch 3581, Loss: 0.10703235492110252, Final Batch Loss: 0.05799150839447975\n",
      "Epoch 3582, Loss: 0.1656094491481781, Final Batch Loss: 0.11386478692293167\n",
      "Epoch 3583, Loss: 0.10815950110554695, Final Batch Loss: 0.04890134930610657\n",
      "Epoch 3584, Loss: 0.10000951960682869, Final Batch Loss: 0.05010785534977913\n",
      "Epoch 3585, Loss: 0.08724963665008545, Final Batch Loss: 0.03717644140124321\n",
      "Epoch 3586, Loss: 0.10107019171118736, Final Batch Loss: 0.07441501319408417\n",
      "Epoch 3587, Loss: 0.13182949274778366, Final Batch Loss: 0.08666349202394485\n",
      "Epoch 3588, Loss: 0.0947509128600359, Final Batch Loss: 0.026024164631962776\n",
      "Epoch 3589, Loss: 0.14185187593102455, Final Batch Loss: 0.10219110548496246\n",
      "Epoch 3590, Loss: 0.1177736222743988, Final Batch Loss: 0.04610591381788254\n",
      "Epoch 3591, Loss: 0.1700352542102337, Final Batch Loss: 0.1297055333852768\n",
      "Epoch 3592, Loss: 0.11955337598919868, Final Batch Loss: 0.040691714733839035\n",
      "Epoch 3593, Loss: 0.10728064179420471, Final Batch Loss: 0.04854780435562134\n",
      "Epoch 3594, Loss: 0.10116155445575714, Final Batch Loss: 0.053677789866924286\n",
      "Epoch 3595, Loss: 0.09756772965192795, Final Batch Loss: 0.037527620792388916\n",
      "Epoch 3596, Loss: 0.12009188905358315, Final Batch Loss: 0.06401187181472778\n",
      "Epoch 3597, Loss: 0.10304414853453636, Final Batch Loss: 0.04820434749126434\n",
      "Epoch 3598, Loss: 0.09532435238361359, Final Batch Loss: 0.04973966255784035\n",
      "Epoch 3599, Loss: 0.09245642647147179, Final Batch Loss: 0.043277863413095474\n",
      "Epoch 3600, Loss: 0.11008862778544426, Final Batch Loss: 0.0614829882979393\n",
      "Epoch 3601, Loss: 0.09788903221487999, Final Batch Loss: 0.04616035521030426\n",
      "Epoch 3602, Loss: 0.10698547586798668, Final Batch Loss: 0.03518463298678398\n",
      "Epoch 3603, Loss: 0.08831905946135521, Final Batch Loss: 0.04258057847619057\n",
      "Epoch 3604, Loss: 0.11458804085850716, Final Batch Loss: 0.04327518865466118\n",
      "Epoch 3605, Loss: 0.09712468460202217, Final Batch Loss: 0.046354226768016815\n",
      "Epoch 3606, Loss: 0.10847312211990356, Final Batch Loss: 0.06933362036943436\n",
      "Epoch 3607, Loss: 0.11197227612137794, Final Batch Loss: 0.07156271487474442\n",
      "Epoch 3608, Loss: 0.09986808523535728, Final Batch Loss: 0.06424606591463089\n",
      "Epoch 3609, Loss: 0.10171588510274887, Final Batch Loss: 0.04862113669514656\n",
      "Epoch 3610, Loss: 0.10737232118844986, Final Batch Loss: 0.05907661095261574\n",
      "Epoch 3611, Loss: 0.11572732031345367, Final Batch Loss: 0.06004773825407028\n",
      "Epoch 3612, Loss: 0.08999397978186607, Final Batch Loss: 0.05380364507436752\n",
      "Epoch 3613, Loss: 0.08722234703600407, Final Batch Loss: 0.029556693509221077\n",
      "Epoch 3614, Loss: 0.08610929548740387, Final Batch Loss: 0.033928439021110535\n",
      "Epoch 3615, Loss: 0.08305823802947998, Final Batch Loss: 0.03628881275653839\n",
      "Epoch 3616, Loss: 0.11435451358556747, Final Batch Loss: 0.07713782787322998\n",
      "Epoch 3617, Loss: 0.11763742938637733, Final Batch Loss: 0.07184118777513504\n",
      "Epoch 3618, Loss: 0.08832785487174988, Final Batch Loss: 0.038714051246643066\n",
      "Epoch 3619, Loss: 0.10845863446593285, Final Batch Loss: 0.06831461191177368\n",
      "Epoch 3620, Loss: 0.10120702162384987, Final Batch Loss: 0.050121694803237915\n",
      "Epoch 3621, Loss: 0.0767561960965395, Final Batch Loss: 0.025033751502633095\n",
      "Epoch 3622, Loss: 0.09742950648069382, Final Batch Loss: 0.06343721598386765\n",
      "Epoch 3623, Loss: 0.08986738696694374, Final Batch Loss: 0.05029821768403053\n",
      "Epoch 3624, Loss: 0.14024757221341133, Final Batch Loss: 0.05862635746598244\n",
      "Epoch 3625, Loss: 0.09659458324313164, Final Batch Loss: 0.052140578627586365\n",
      "Epoch 3626, Loss: 0.14778852835297585, Final Batch Loss: 0.04642504081130028\n",
      "Epoch 3627, Loss: 0.0904729813337326, Final Batch Loss: 0.051119450479745865\n",
      "Epoch 3628, Loss: 0.1305115818977356, Final Batch Loss: 0.06800982356071472\n",
      "Epoch 3629, Loss: 0.08259597420692444, Final Batch Loss: 0.04544956982135773\n",
      "Epoch 3630, Loss: 0.09523090720176697, Final Batch Loss: 0.05930066108703613\n",
      "Epoch 3631, Loss: 0.10244986787438393, Final Batch Loss: 0.04541916772723198\n",
      "Epoch 3632, Loss: 0.1068558394908905, Final Batch Loss: 0.05742386355996132\n",
      "Epoch 3633, Loss: 0.11054632067680359, Final Batch Loss: 0.026757091283798218\n",
      "Epoch 3634, Loss: 0.09026579186320305, Final Batch Loss: 0.04455189406871796\n",
      "Epoch 3635, Loss: 0.09408864006400108, Final Batch Loss: 0.034526340663433075\n",
      "Epoch 3636, Loss: 0.0947682224214077, Final Batch Loss: 0.04591991379857063\n",
      "Epoch 3637, Loss: 0.09156627580523491, Final Batch Loss: 0.05362429842352867\n",
      "Epoch 3638, Loss: 0.11287207528948784, Final Batch Loss: 0.06287551671266556\n",
      "Epoch 3639, Loss: 0.10857727378606796, Final Batch Loss: 0.05791105702519417\n",
      "Epoch 3640, Loss: 0.0782509297132492, Final Batch Loss: 0.03315500169992447\n",
      "Epoch 3641, Loss: 0.1128539927303791, Final Batch Loss: 0.06494169682264328\n",
      "Epoch 3642, Loss: 0.10072960332036018, Final Batch Loss: 0.03837329521775246\n",
      "Epoch 3643, Loss: 0.08553650230169296, Final Batch Loss: 0.04233336076140404\n",
      "Epoch 3644, Loss: 0.12330417335033417, Final Batch Loss: 0.03913671523332596\n",
      "Epoch 3645, Loss: 0.11895764619112015, Final Batch Loss: 0.08115598559379578\n",
      "Epoch 3646, Loss: 0.10138441622257233, Final Batch Loss: 0.059617627412080765\n",
      "Epoch 3647, Loss: 0.09935900196433067, Final Batch Loss: 0.05954184755682945\n",
      "Epoch 3648, Loss: 0.08150298148393631, Final Batch Loss: 0.04205271601676941\n",
      "Epoch 3649, Loss: 0.09360438212752342, Final Batch Loss: 0.03427799791097641\n",
      "Epoch 3650, Loss: 0.08971414715051651, Final Batch Loss: 0.03445608913898468\n",
      "Epoch 3651, Loss: 0.09116523712873459, Final Batch Loss: 0.059103984385728836\n",
      "Epoch 3652, Loss: 0.1380627043545246, Final Batch Loss: 0.045902010053396225\n",
      "Epoch 3653, Loss: 0.09603185951709747, Final Batch Loss: 0.05939307436347008\n",
      "Epoch 3654, Loss: 0.10413534194231033, Final Batch Loss: 0.05511191487312317\n",
      "Epoch 3655, Loss: 0.10129361227154732, Final Batch Loss: 0.05351978912949562\n",
      "Epoch 3656, Loss: 0.1318969428539276, Final Batch Loss: 0.07233358919620514\n",
      "Epoch 3657, Loss: 0.10334622487425804, Final Batch Loss: 0.047880399972200394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3658, Loss: 0.08840036019682884, Final Batch Loss: 0.048824768513441086\n",
      "Epoch 3659, Loss: 0.08476422354578972, Final Batch Loss: 0.03977973014116287\n",
      "Epoch 3660, Loss: 0.07634924724698067, Final Batch Loss: 0.032992079854011536\n",
      "Epoch 3661, Loss: 0.10531012713909149, Final Batch Loss: 0.043797533959150314\n",
      "Epoch 3662, Loss: 0.09586622193455696, Final Batch Loss: 0.0476265512406826\n",
      "Epoch 3663, Loss: 0.09342928230762482, Final Batch Loss: 0.05782803148031235\n",
      "Epoch 3664, Loss: 0.1354358047246933, Final Batch Loss: 0.06697248667478561\n",
      "Epoch 3665, Loss: 0.08415116742253304, Final Batch Loss: 0.035534683614969254\n",
      "Epoch 3666, Loss: 0.10965466871857643, Final Batch Loss: 0.059265390038490295\n",
      "Epoch 3667, Loss: 0.11149876564741135, Final Batch Loss: 0.059788018465042114\n",
      "Epoch 3668, Loss: 0.12459297478199005, Final Batch Loss: 0.07218907028436661\n",
      "Epoch 3669, Loss: 0.09405777975916862, Final Batch Loss: 0.04121023416519165\n",
      "Epoch 3670, Loss: 0.11577369645237923, Final Batch Loss: 0.039549510926008224\n",
      "Epoch 3671, Loss: 0.12506131827831268, Final Batch Loss: 0.06155087798833847\n",
      "Epoch 3672, Loss: 0.09621235355734825, Final Batch Loss: 0.048263609409332275\n",
      "Epoch 3673, Loss: 0.08822439983487129, Final Batch Loss: 0.05671335756778717\n",
      "Epoch 3674, Loss: 0.1038425825536251, Final Batch Loss: 0.039130862802267075\n",
      "Epoch 3675, Loss: 0.10668332129716873, Final Batch Loss: 0.06070447713136673\n",
      "Epoch 3676, Loss: 0.10023550689220428, Final Batch Loss: 0.05575818195939064\n",
      "Epoch 3677, Loss: 0.10726379603147507, Final Batch Loss: 0.05589408800005913\n",
      "Epoch 3678, Loss: 0.24523169547319412, Final Batch Loss: 0.19345712661743164\n",
      "Epoch 3679, Loss: 0.09609521925449371, Final Batch Loss: 0.047480784356594086\n",
      "Epoch 3680, Loss: 0.11908180266618729, Final Batch Loss: 0.0394606739282608\n",
      "Epoch 3681, Loss: 0.10935996472835541, Final Batch Loss: 0.03200826793909073\n",
      "Epoch 3682, Loss: 0.10265644639730453, Final Batch Loss: 0.052957575768232346\n",
      "Epoch 3683, Loss: 0.09704246744513512, Final Batch Loss: 0.04605262354016304\n",
      "Epoch 3684, Loss: 0.10309258848428726, Final Batch Loss: 0.06328871101140976\n",
      "Epoch 3685, Loss: 0.09236427769064903, Final Batch Loss: 0.043684784322977066\n",
      "Epoch 3686, Loss: 0.1019928976893425, Final Batch Loss: 0.0531921423971653\n",
      "Epoch 3687, Loss: 0.10906652733683586, Final Batch Loss: 0.04429420456290245\n",
      "Epoch 3688, Loss: 0.08833715692162514, Final Batch Loss: 0.03713340684771538\n",
      "Epoch 3689, Loss: 0.13129519671201706, Final Batch Loss: 0.0812053456902504\n",
      "Epoch 3690, Loss: 0.1531708650290966, Final Batch Loss: 0.06242804601788521\n",
      "Epoch 3691, Loss: 0.11732204630970955, Final Batch Loss: 0.06521372497081757\n",
      "Epoch 3692, Loss: 0.09626788645982742, Final Batch Loss: 0.044831592589616776\n",
      "Epoch 3693, Loss: 0.1194431222975254, Final Batch Loss: 0.07539688795804977\n",
      "Epoch 3694, Loss: 0.10661419481039047, Final Batch Loss: 0.05905619636178017\n",
      "Epoch 3695, Loss: 0.1000726968050003, Final Batch Loss: 0.06202676147222519\n",
      "Epoch 3696, Loss: 0.09286554902791977, Final Batch Loss: 0.03994869440793991\n",
      "Epoch 3697, Loss: 0.09461595118045807, Final Batch Loss: 0.06267231702804565\n",
      "Epoch 3698, Loss: 0.1012093834578991, Final Batch Loss: 0.05571337044239044\n",
      "Epoch 3699, Loss: 0.0908680371940136, Final Batch Loss: 0.04372323676943779\n",
      "Epoch 3700, Loss: 0.13195551186800003, Final Batch Loss: 0.076167993247509\n",
      "Epoch 3701, Loss: 0.1269884631037712, Final Batch Loss: 0.10071497410535812\n",
      "Epoch 3702, Loss: 0.09527366980910301, Final Batch Loss: 0.05538597330451012\n",
      "Epoch 3703, Loss: 0.09750071913003922, Final Batch Loss: 0.04740910977125168\n",
      "Epoch 3704, Loss: 0.093533243983984, Final Batch Loss: 0.04900803044438362\n",
      "Epoch 3705, Loss: 0.10485146939754486, Final Batch Loss: 0.05969318002462387\n",
      "Epoch 3706, Loss: 0.08269370719790459, Final Batch Loss: 0.03976894170045853\n",
      "Epoch 3707, Loss: 0.1077359989285469, Final Batch Loss: 0.06668049097061157\n",
      "Epoch 3708, Loss: 0.08868246898055077, Final Batch Loss: 0.047957517206668854\n",
      "Epoch 3709, Loss: 0.1312219463288784, Final Batch Loss: 0.08662924915552139\n",
      "Epoch 3710, Loss: 0.11437109485268593, Final Batch Loss: 0.049684155732393265\n",
      "Epoch 3711, Loss: 0.12143896147608757, Final Batch Loss: 0.047882694751024246\n",
      "Epoch 3712, Loss: 0.10254472494125366, Final Batch Loss: 0.04955417290329933\n",
      "Epoch 3713, Loss: 0.1260508932173252, Final Batch Loss: 0.05825507268309593\n",
      "Epoch 3714, Loss: 0.10870136693120003, Final Batch Loss: 0.04788682237267494\n",
      "Epoch 3715, Loss: 0.10235557705163956, Final Batch Loss: 0.06734669953584671\n",
      "Epoch 3716, Loss: 0.11253738030791283, Final Batch Loss: 0.05017467960715294\n",
      "Epoch 3717, Loss: 0.09465007856488228, Final Batch Loss: 0.040375832468271255\n",
      "Epoch 3718, Loss: 0.09340684115886688, Final Batch Loss: 0.05298171937465668\n",
      "Epoch 3719, Loss: 0.0948665477335453, Final Batch Loss: 0.03963235765695572\n",
      "Epoch 3720, Loss: 0.11715272441506386, Final Batch Loss: 0.05281353369355202\n",
      "Epoch 3721, Loss: 0.14685039594769478, Final Batch Loss: 0.10883034765720367\n",
      "Epoch 3722, Loss: 0.08086764439940453, Final Batch Loss: 0.04859723150730133\n",
      "Epoch 3723, Loss: 0.10521014407277107, Final Batch Loss: 0.045841317623853683\n",
      "Epoch 3724, Loss: 0.09819083660840988, Final Batch Loss: 0.04505808278918266\n",
      "Epoch 3725, Loss: 0.1083630695939064, Final Batch Loss: 0.05800987780094147\n",
      "Epoch 3726, Loss: 0.12394066900014877, Final Batch Loss: 0.05907922983169556\n",
      "Epoch 3727, Loss: 0.14820635318756104, Final Batch Loss: 0.08963826298713684\n",
      "Epoch 3728, Loss: 0.1061151996254921, Final Batch Loss: 0.05084040388464928\n",
      "Epoch 3729, Loss: 0.10270055383443832, Final Batch Loss: 0.06004917249083519\n",
      "Epoch 3730, Loss: 0.10612920671701431, Final Batch Loss: 0.06515180319547653\n",
      "Epoch 3731, Loss: 0.10635505244135857, Final Batch Loss: 0.07081235200166702\n",
      "Epoch 3732, Loss: 0.10778455063700676, Final Batch Loss: 0.039310771971940994\n",
      "Epoch 3733, Loss: 0.0862899124622345, Final Batch Loss: 0.043844640254974365\n",
      "Epoch 3734, Loss: 0.09576012566685677, Final Batch Loss: 0.05447721108794212\n",
      "Epoch 3735, Loss: 0.09368854388594627, Final Batch Loss: 0.04914373159408569\n",
      "Epoch 3736, Loss: 0.0928238034248352, Final Batch Loss: 0.05492953211069107\n",
      "Epoch 3737, Loss: 0.09063210338354111, Final Batch Loss: 0.03615058586001396\n",
      "Epoch 3738, Loss: 0.10904398560523987, Final Batch Loss: 0.04056382179260254\n",
      "Epoch 3739, Loss: 0.13907266408205032, Final Batch Loss: 0.06870869547128677\n",
      "Epoch 3740, Loss: 0.0921974927186966, Final Batch Loss: 0.037728577852249146\n",
      "Epoch 3741, Loss: 0.10848445817828178, Final Batch Loss: 0.05796550214290619\n",
      "Epoch 3742, Loss: 0.10700273513793945, Final Batch Loss: 0.05764887109398842\n",
      "Epoch 3743, Loss: 0.1088423952460289, Final Batch Loss: 0.0713736042380333\n",
      "Epoch 3744, Loss: 0.11796776205301285, Final Batch Loss: 0.08176936954259872\n",
      "Epoch 3745, Loss: 0.12222395092248917, Final Batch Loss: 0.03453557938337326\n",
      "Epoch 3746, Loss: 0.10966622829437256, Final Batch Loss: 0.06996114552021027\n",
      "Epoch 3747, Loss: 0.11684180423617363, Final Batch Loss: 0.0527290515601635\n",
      "Epoch 3748, Loss: 0.11899403855204582, Final Batch Loss: 0.05935511365532875\n",
      "Epoch 3749, Loss: 0.09400993958115578, Final Batch Loss: 0.031605347990989685\n",
      "Epoch 3750, Loss: 0.08241017162799835, Final Batch Loss: 0.024319656193256378\n",
      "Epoch 3751, Loss: 0.09347932785749435, Final Batch Loss: 0.04951893165707588\n",
      "Epoch 3752, Loss: 0.12123177945613861, Final Batch Loss: 0.04880433529615402\n",
      "Epoch 3753, Loss: 0.11261320486664772, Final Batch Loss: 0.056089840829372406\n",
      "Epoch 3754, Loss: 0.08488833531737328, Final Batch Loss: 0.031712304800748825\n",
      "Epoch 3755, Loss: 0.0924641378223896, Final Batch Loss: 0.040809303522109985\n",
      "Epoch 3756, Loss: 0.08895304426550865, Final Batch Loss: 0.04264742136001587\n",
      "Epoch 3757, Loss: 0.10211554914712906, Final Batch Loss: 0.06146187335252762\n",
      "Epoch 3758, Loss: 0.10858357325196266, Final Batch Loss: 0.06400789320468903\n",
      "Epoch 3759, Loss: 0.09533730521798134, Final Batch Loss: 0.04800615832209587\n",
      "Epoch 3760, Loss: 0.09851663559675217, Final Batch Loss: 0.052683085203170776\n",
      "Epoch 3761, Loss: 0.09520276263356209, Final Batch Loss: 0.057611625641584396\n",
      "Epoch 3762, Loss: 0.0906347706913948, Final Batch Loss: 0.03646134212613106\n",
      "Epoch 3763, Loss: 0.094964399933815, Final Batch Loss: 0.0556132011115551\n",
      "Epoch 3764, Loss: 0.09278049319982529, Final Batch Loss: 0.04029867798089981\n",
      "Epoch 3765, Loss: 0.10154008865356445, Final Batch Loss: 0.04146904870867729\n",
      "Epoch 3766, Loss: 0.1650029458105564, Final Batch Loss: 0.11005371063947678\n",
      "Epoch 3767, Loss: 0.12938447669148445, Final Batch Loss: 0.09117886424064636\n",
      "Epoch 3768, Loss: 0.0825011171400547, Final Batch Loss: 0.040824830532073975\n",
      "Epoch 3769, Loss: 0.10861621797084808, Final Batch Loss: 0.04694793000817299\n",
      "Epoch 3770, Loss: 0.08244875445961952, Final Batch Loss: 0.027237579226493835\n",
      "Epoch 3771, Loss: 0.09445243328809738, Final Batch Loss: 0.052926093339920044\n",
      "Epoch 3772, Loss: 0.11939800903201103, Final Batch Loss: 0.07245227694511414\n",
      "Epoch 3773, Loss: 0.08107881620526314, Final Batch Loss: 0.030184797942638397\n",
      "Epoch 3774, Loss: 0.0974171906709671, Final Batch Loss: 0.04235667735338211\n",
      "Epoch 3775, Loss: 0.1122758686542511, Final Batch Loss: 0.07195570319890976\n",
      "Epoch 3776, Loss: 0.1160212829709053, Final Batch Loss: 0.0695628896355629\n",
      "Epoch 3777, Loss: 0.10071830078959465, Final Batch Loss: 0.05761929228901863\n",
      "Epoch 3778, Loss: 0.09245778247714043, Final Batch Loss: 0.03709676116704941\n",
      "Epoch 3779, Loss: 0.10795533657073975, Final Batch Loss: 0.03759044408798218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3780, Loss: 0.08808314055204391, Final Batch Loss: 0.048923492431640625\n",
      "Epoch 3781, Loss: 0.10667547211050987, Final Batch Loss: 0.04316140338778496\n",
      "Epoch 3782, Loss: 0.07191212102770805, Final Batch Loss: 0.030778102576732635\n",
      "Epoch 3783, Loss: 0.0827018953859806, Final Batch Loss: 0.03496760502457619\n",
      "Epoch 3784, Loss: 0.1099255345761776, Final Batch Loss: 0.06919240951538086\n",
      "Epoch 3785, Loss: 0.10936747118830681, Final Batch Loss: 0.04418931528925896\n",
      "Epoch 3786, Loss: 0.10542240738868713, Final Batch Loss: 0.06517084687948227\n",
      "Epoch 3787, Loss: 0.1064346507191658, Final Batch Loss: 0.05612988770008087\n",
      "Epoch 3788, Loss: 0.10638735070824623, Final Batch Loss: 0.03406031057238579\n",
      "Epoch 3789, Loss: 0.08888215199112892, Final Batch Loss: 0.04526691511273384\n",
      "Epoch 3790, Loss: 0.0915484931319952, Final Batch Loss: 0.06137493997812271\n",
      "Epoch 3791, Loss: 0.0836881771683693, Final Batch Loss: 0.039883777499198914\n",
      "Epoch 3792, Loss: 0.0996975339949131, Final Batch Loss: 0.0620465911924839\n",
      "Epoch 3793, Loss: 0.093220055103302, Final Batch Loss: 0.050665345042943954\n",
      "Epoch 3794, Loss: 0.09371879696846008, Final Batch Loss: 0.04629175364971161\n",
      "Epoch 3795, Loss: 0.10098975896835327, Final Batch Loss: 0.053375668823719025\n",
      "Epoch 3796, Loss: 0.09372405707836151, Final Batch Loss: 0.051697663962841034\n",
      "Epoch 3797, Loss: 0.08334315568208694, Final Batch Loss: 0.03199583292007446\n",
      "Epoch 3798, Loss: 0.08762949891388416, Final Batch Loss: 0.05694250017404556\n",
      "Epoch 3799, Loss: 0.09316588938236237, Final Batch Loss: 0.051533401012420654\n",
      "Epoch 3800, Loss: 0.11951049789786339, Final Batch Loss: 0.06482283771038055\n",
      "Epoch 3801, Loss: 0.1169988326728344, Final Batch Loss: 0.07208456844091415\n",
      "Epoch 3802, Loss: 0.14308589696884155, Final Batch Loss: 0.07861772924661636\n",
      "Epoch 3803, Loss: 0.07769384607672691, Final Batch Loss: 0.03647741302847862\n",
      "Epoch 3804, Loss: 0.093734972178936, Final Batch Loss: 0.04519770294427872\n",
      "Epoch 3805, Loss: 0.07494255900382996, Final Batch Loss: 0.035263631492853165\n",
      "Epoch 3806, Loss: 0.11381112411618233, Final Batch Loss: 0.05549057945609093\n",
      "Epoch 3807, Loss: 0.11918843165040016, Final Batch Loss: 0.05063432827591896\n",
      "Epoch 3808, Loss: 0.12859519943594933, Final Batch Loss: 0.08912599831819534\n",
      "Epoch 3809, Loss: 0.08074285462498665, Final Batch Loss: 0.05998653918504715\n",
      "Epoch 3810, Loss: 0.10929783433675766, Final Batch Loss: 0.039157018065452576\n",
      "Epoch 3811, Loss: 0.09390074573457241, Final Batch Loss: 0.06626694649457932\n",
      "Epoch 3812, Loss: 0.08126658201217651, Final Batch Loss: 0.032921966165304184\n",
      "Epoch 3813, Loss: 0.09604926407337189, Final Batch Loss: 0.04320484772324562\n",
      "Epoch 3814, Loss: 0.12866667285561562, Final Batch Loss: 0.08607785403728485\n",
      "Epoch 3815, Loss: 0.08017923682928085, Final Batch Loss: 0.03503749892115593\n",
      "Epoch 3816, Loss: 0.10383770242333412, Final Batch Loss: 0.045338377356529236\n",
      "Epoch 3817, Loss: 0.07794510200619698, Final Batch Loss: 0.03874253109097481\n",
      "Epoch 3818, Loss: 0.09153343737125397, Final Batch Loss: 0.051316797733306885\n",
      "Epoch 3819, Loss: 0.11585206910967827, Final Batch Loss: 0.04892658069729805\n",
      "Epoch 3820, Loss: 0.11588975414633751, Final Batch Loss: 0.04110435023903847\n",
      "Epoch 3821, Loss: 0.11722742021083832, Final Batch Loss: 0.05043487995862961\n",
      "Epoch 3822, Loss: 0.09095427766442299, Final Batch Loss: 0.04635985940694809\n",
      "Epoch 3823, Loss: 0.09855672344565392, Final Batch Loss: 0.041069306433200836\n",
      "Epoch 3824, Loss: 0.07811591774225235, Final Batch Loss: 0.03168533742427826\n",
      "Epoch 3825, Loss: 0.09719585999846458, Final Batch Loss: 0.04443247243762016\n",
      "Epoch 3826, Loss: 0.10009334236383438, Final Batch Loss: 0.04431493952870369\n",
      "Epoch 3827, Loss: 0.11102234944701195, Final Batch Loss: 0.05622689798474312\n",
      "Epoch 3828, Loss: 0.10699662566184998, Final Batch Loss: 0.04634181037545204\n",
      "Epoch 3829, Loss: 0.10727499797940254, Final Batch Loss: 0.03775249794125557\n",
      "Epoch 3830, Loss: 0.13019325956702232, Final Batch Loss: 0.05568422004580498\n",
      "Epoch 3831, Loss: 0.09770218655467033, Final Batch Loss: 0.05301152169704437\n",
      "Epoch 3832, Loss: 0.09655638784170151, Final Batch Loss: 0.04281101003289223\n",
      "Epoch 3833, Loss: 0.11736098676919937, Final Batch Loss: 0.0471416637301445\n",
      "Epoch 3834, Loss: 0.10615523904561996, Final Batch Loss: 0.0687033161520958\n",
      "Epoch 3835, Loss: 0.13902254588901997, Final Batch Loss: 0.11215995997190475\n",
      "Epoch 3836, Loss: 0.0811902154237032, Final Batch Loss: 0.027041634544730186\n",
      "Epoch 3837, Loss: 0.11965752020478249, Final Batch Loss: 0.06510626524686813\n",
      "Epoch 3838, Loss: 0.10442136600613594, Final Batch Loss: 0.06423713266849518\n",
      "Epoch 3839, Loss: 0.08441930264234543, Final Batch Loss: 0.0359642468392849\n",
      "Epoch 3840, Loss: 0.11298170313239098, Final Batch Loss: 0.07537415623664856\n",
      "Epoch 3841, Loss: 0.08294274657964706, Final Batch Loss: 0.041780781000852585\n",
      "Epoch 3842, Loss: 0.0959414467215538, Final Batch Loss: 0.044898033142089844\n",
      "Epoch 3843, Loss: 0.09981189295649529, Final Batch Loss: 0.05447700619697571\n",
      "Epoch 3844, Loss: 0.11163070797920227, Final Batch Loss: 0.06527264416217804\n",
      "Epoch 3845, Loss: 0.08222744055092335, Final Batch Loss: 0.03024980239570141\n",
      "Epoch 3846, Loss: 0.10876194015145302, Final Batch Loss: 0.06410127133131027\n",
      "Epoch 3847, Loss: 0.10685852915048599, Final Batch Loss: 0.05417651683092117\n",
      "Epoch 3848, Loss: 0.09462937340140343, Final Batch Loss: 0.04573839157819748\n",
      "Epoch 3849, Loss: 0.10815883800387383, Final Batch Loss: 0.05571221932768822\n",
      "Epoch 3850, Loss: 0.11408467218279839, Final Batch Loss: 0.06161719933152199\n",
      "Epoch 3851, Loss: 0.1260649673640728, Final Batch Loss: 0.07957242429256439\n",
      "Epoch 3852, Loss: 0.08820631727576256, Final Batch Loss: 0.03210480138659477\n",
      "Epoch 3853, Loss: 0.13009829819202423, Final Batch Loss: 0.03736919164657593\n",
      "Epoch 3854, Loss: 0.12312981858849525, Final Batch Loss: 0.06493762880563736\n",
      "Epoch 3855, Loss: 0.12311729788780212, Final Batch Loss: 0.06451351940631866\n",
      "Epoch 3856, Loss: 0.08015941083431244, Final Batch Loss: 0.0447952076792717\n",
      "Epoch 3857, Loss: 0.10842237249016762, Final Batch Loss: 0.04801551252603531\n",
      "Epoch 3858, Loss: 0.12248730659484863, Final Batch Loss: 0.07662060856819153\n",
      "Epoch 3859, Loss: 0.11422128602862358, Final Batch Loss: 0.047406960278749466\n",
      "Epoch 3860, Loss: 0.08557844534516335, Final Batch Loss: 0.03896540775895119\n",
      "Epoch 3861, Loss: 0.09730205684900284, Final Batch Loss: 0.03799952566623688\n",
      "Epoch 3862, Loss: 0.09364190697669983, Final Batch Loss: 0.05046047642827034\n",
      "Epoch 3863, Loss: 0.09077471122145653, Final Batch Loss: 0.055148206651210785\n",
      "Epoch 3864, Loss: 0.10015622526407242, Final Batch Loss: 0.05947043001651764\n",
      "Epoch 3865, Loss: 0.08903075382113457, Final Batch Loss: 0.04639027640223503\n",
      "Epoch 3866, Loss: 0.0787449348717928, Final Batch Loss: 0.02841768227517605\n",
      "Epoch 3867, Loss: 0.11496132984757423, Final Batch Loss: 0.06606104224920273\n",
      "Epoch 3868, Loss: 0.14888522773981094, Final Batch Loss: 0.08427642285823822\n",
      "Epoch 3869, Loss: 0.09213046915829182, Final Batch Loss: 0.025918083265423775\n",
      "Epoch 3870, Loss: 0.13213682174682617, Final Batch Loss: 0.06979796290397644\n",
      "Epoch 3871, Loss: 0.09796540439128876, Final Batch Loss: 0.061717502772808075\n",
      "Epoch 3872, Loss: 0.07219917699694633, Final Batch Loss: 0.035020649433135986\n",
      "Epoch 3873, Loss: 0.11489615216851234, Final Batch Loss: 0.040787216275930405\n",
      "Epoch 3874, Loss: 0.11346609517931938, Final Batch Loss: 0.06023414433002472\n",
      "Epoch 3875, Loss: 0.11047810688614845, Final Batch Loss: 0.05094972252845764\n",
      "Epoch 3876, Loss: 0.09607021510601044, Final Batch Loss: 0.04873654246330261\n",
      "Epoch 3877, Loss: 0.1062249094247818, Final Batch Loss: 0.03821970522403717\n",
      "Epoch 3878, Loss: 0.11249350756406784, Final Batch Loss: 0.07331783324480057\n",
      "Epoch 3879, Loss: 0.08031335100531578, Final Batch Loss: 0.038036100566387177\n",
      "Epoch 3880, Loss: 0.09535183385014534, Final Batch Loss: 0.03947862610220909\n",
      "Epoch 3881, Loss: 0.08534030616283417, Final Batch Loss: 0.04578123986721039\n",
      "Epoch 3882, Loss: 0.1225481927394867, Final Batch Loss: 0.039671845734119415\n",
      "Epoch 3883, Loss: 0.11647434905171394, Final Batch Loss: 0.05824647471308708\n",
      "Epoch 3884, Loss: 0.11530864983797073, Final Batch Loss: 0.06497374176979065\n",
      "Epoch 3885, Loss: 0.09425139799714088, Final Batch Loss: 0.05351753160357475\n",
      "Epoch 3886, Loss: 0.11651159450411797, Final Batch Loss: 0.04400832578539848\n",
      "Epoch 3887, Loss: 0.1455780304968357, Final Batch Loss: 0.05375942215323448\n",
      "Epoch 3888, Loss: 0.10722895339131355, Final Batch Loss: 0.04805177450180054\n",
      "Epoch 3889, Loss: 0.09991750493645668, Final Batch Loss: 0.054748207330703735\n",
      "Epoch 3890, Loss: 0.10893474891781807, Final Batch Loss: 0.06776002794504166\n",
      "Epoch 3891, Loss: 0.10505401715636253, Final Batch Loss: 0.041239235550165176\n",
      "Epoch 3892, Loss: 0.09922867640852928, Final Batch Loss: 0.043085236102342606\n",
      "Epoch 3893, Loss: 0.09839605540037155, Final Batch Loss: 0.04466943442821503\n",
      "Epoch 3894, Loss: 0.089700723066926, Final Batch Loss: 0.05846021696925163\n",
      "Epoch 3895, Loss: 0.1025867611169815, Final Batch Loss: 0.05036953464150429\n",
      "Epoch 3896, Loss: 0.08427979424595833, Final Batch Loss: 0.04905278980731964\n",
      "Epoch 3897, Loss: 0.08482692763209343, Final Batch Loss: 0.043909333646297455\n",
      "Epoch 3898, Loss: 0.08414351940155029, Final Batch Loss: 0.04278446361422539\n",
      "Epoch 3899, Loss: 0.10471934825181961, Final Batch Loss: 0.05821354314684868\n",
      "Epoch 3900, Loss: 0.10290639847517014, Final Batch Loss: 0.057289835065603256\n",
      "Epoch 3901, Loss: 0.0882067084312439, Final Batch Loss: 0.04575065150856972\n",
      "Epoch 3902, Loss: 0.08943049609661102, Final Batch Loss: 0.05137955769896507\n",
      "Epoch 3903, Loss: 0.09672271087765694, Final Batch Loss: 0.032891977578401566\n",
      "Epoch 3904, Loss: 0.08336586877703667, Final Batch Loss: 0.036717489361763\n",
      "Epoch 3905, Loss: 0.0926743857562542, Final Batch Loss: 0.04839884862303734\n",
      "Epoch 3906, Loss: 0.09946246817708015, Final Batch Loss: 0.05184518173336983\n",
      "Epoch 3907, Loss: 0.13120696134865284, Final Batch Loss: 0.026957282796502113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3908, Loss: 0.07779233157634735, Final Batch Loss: 0.03220288082957268\n",
      "Epoch 3909, Loss: 0.10132143087685108, Final Batch Loss: 0.07382853329181671\n",
      "Epoch 3910, Loss: 0.09133671224117279, Final Batch Loss: 0.05616401508450508\n",
      "Epoch 3911, Loss: 0.12460324913263321, Final Batch Loss: 0.0825122818350792\n",
      "Epoch 3912, Loss: 0.11556802690029144, Final Batch Loss: 0.0683877095580101\n",
      "Epoch 3913, Loss: 0.07302010431885719, Final Batch Loss: 0.03604147210717201\n",
      "Epoch 3914, Loss: 0.12225201353430748, Final Batch Loss: 0.06957409530878067\n",
      "Epoch 3915, Loss: 0.10120703279972076, Final Batch Loss: 0.05096165090799332\n",
      "Epoch 3916, Loss: 0.07655160129070282, Final Batch Loss: 0.03621669113636017\n",
      "Epoch 3917, Loss: 0.12442855536937714, Final Batch Loss: 0.04980345815420151\n",
      "Epoch 3918, Loss: 0.1149357445538044, Final Batch Loss: 0.06690376996994019\n",
      "Epoch 3919, Loss: 0.1161760650575161, Final Batch Loss: 0.07117219269275665\n",
      "Epoch 3920, Loss: 0.08303894102573395, Final Batch Loss: 0.03848957642912865\n",
      "Epoch 3921, Loss: 0.08048590272665024, Final Batch Loss: 0.04064345732331276\n",
      "Epoch 3922, Loss: 0.08990617282688618, Final Batch Loss: 0.027162397280335426\n",
      "Epoch 3923, Loss: 0.08038781024515629, Final Batch Loss: 0.02889256738126278\n",
      "Epoch 3924, Loss: 0.08619081601500511, Final Batch Loss: 0.04132886976003647\n",
      "Epoch 3925, Loss: 0.11089771240949631, Final Batch Loss: 0.06408416479825974\n",
      "Epoch 3926, Loss: 0.10351069271564484, Final Batch Loss: 0.047952763736248016\n",
      "Epoch 3927, Loss: 0.08750063553452492, Final Batch Loss: 0.049888938665390015\n",
      "Epoch 3928, Loss: 0.11008904874324799, Final Batch Loss: 0.06551935523748398\n",
      "Epoch 3929, Loss: 0.0928096603602171, Final Batch Loss: 0.0649993047118187\n",
      "Epoch 3930, Loss: 0.11728334426879883, Final Batch Loss: 0.046634331345558167\n",
      "Epoch 3931, Loss: 0.087574802339077, Final Batch Loss: 0.03639877587556839\n",
      "Epoch 3932, Loss: 0.10075602307915688, Final Batch Loss: 0.052921418100595474\n",
      "Epoch 3933, Loss: 0.10345806553959846, Final Batch Loss: 0.05555979534983635\n",
      "Epoch 3934, Loss: 0.09395994246006012, Final Batch Loss: 0.04775362089276314\n",
      "Epoch 3935, Loss: 0.09526238031685352, Final Batch Loss: 0.0304811242967844\n",
      "Epoch 3936, Loss: 0.0878168698400259, Final Batch Loss: 0.031244391575455666\n",
      "Epoch 3937, Loss: 0.09121687337756157, Final Batch Loss: 0.05092724785208702\n",
      "Epoch 3938, Loss: 0.09143279120326042, Final Batch Loss: 0.05227377638220787\n",
      "Epoch 3939, Loss: 0.07703214511275291, Final Batch Loss: 0.034709613770246506\n",
      "Epoch 3940, Loss: 0.10550524294376373, Final Batch Loss: 0.05937013775110245\n",
      "Epoch 3941, Loss: 0.08142990618944168, Final Batch Loss: 0.043785128742456436\n",
      "Epoch 3942, Loss: 0.07931892573833466, Final Batch Loss: 0.040900856256484985\n",
      "Epoch 3943, Loss: 0.0863788053393364, Final Batch Loss: 0.045279648154973984\n",
      "Epoch 3944, Loss: 0.12875298038125038, Final Batch Loss: 0.07714073359966278\n",
      "Epoch 3945, Loss: 0.1264381743967533, Final Batch Loss: 0.058797966688871384\n",
      "Epoch 3946, Loss: 0.08904963731765747, Final Batch Loss: 0.05093325674533844\n",
      "Epoch 3947, Loss: 0.09543423727154732, Final Batch Loss: 0.04700253903865814\n",
      "Epoch 3948, Loss: 0.12260198965668678, Final Batch Loss: 0.085052490234375\n",
      "Epoch 3949, Loss: 0.14557867869734764, Final Batch Loss: 0.09384715557098389\n",
      "Epoch 3950, Loss: 0.08962498232722282, Final Batch Loss: 0.04196479171514511\n",
      "Epoch 3951, Loss: 0.10173388198018074, Final Batch Loss: 0.05173324793577194\n",
      "Epoch 3952, Loss: 0.10914579033851624, Final Batch Loss: 0.06190062686800957\n",
      "Epoch 3953, Loss: 0.09034183993935585, Final Batch Loss: 0.04252782091498375\n",
      "Epoch 3954, Loss: 0.09307358786463737, Final Batch Loss: 0.045842140913009644\n",
      "Epoch 3955, Loss: 0.09428887814283371, Final Batch Loss: 0.05092441663146019\n",
      "Epoch 3956, Loss: 0.0953235849738121, Final Batch Loss: 0.045858610421419144\n",
      "Epoch 3957, Loss: 0.10340172424912453, Final Batch Loss: 0.04939737170934677\n",
      "Epoch 3958, Loss: 0.14461979269981384, Final Batch Loss: 0.056908152997493744\n",
      "Epoch 3959, Loss: 0.10814393311738968, Final Batch Loss: 0.03303360193967819\n",
      "Epoch 3960, Loss: 0.08341634087264538, Final Batch Loss: 0.026882247999310493\n",
      "Epoch 3961, Loss: 0.08882905542850494, Final Batch Loss: 0.035997409373521805\n",
      "Epoch 3962, Loss: 0.09696310013532639, Final Batch Loss: 0.042736295610666275\n",
      "Epoch 3963, Loss: 0.10464496910572052, Final Batch Loss: 0.06372644752264023\n",
      "Epoch 3964, Loss: 0.08937522023916245, Final Batch Loss: 0.04017867147922516\n",
      "Epoch 3965, Loss: 0.08608734980225563, Final Batch Loss: 0.04770331829786301\n",
      "Epoch 3966, Loss: 0.10880981385707855, Final Batch Loss: 0.05597813054919243\n",
      "Epoch 3967, Loss: 0.08320464007556438, Final Batch Loss: 0.031184716150164604\n",
      "Epoch 3968, Loss: 0.09248190373182297, Final Batch Loss: 0.050026968121528625\n",
      "Epoch 3969, Loss: 0.09452978521585464, Final Batch Loss: 0.05913512781262398\n",
      "Epoch 3970, Loss: 0.09127215296030045, Final Batch Loss: 0.03747062757611275\n",
      "Epoch 3971, Loss: 0.09377700462937355, Final Batch Loss: 0.04232177138328552\n",
      "Epoch 3972, Loss: 0.09510495141148567, Final Batch Loss: 0.04991370812058449\n",
      "Epoch 3973, Loss: 0.09007609263062477, Final Batch Loss: 0.03645925223827362\n",
      "Epoch 3974, Loss: 0.0778072252869606, Final Batch Loss: 0.03279504552483559\n",
      "Epoch 3975, Loss: 0.08153109811246395, Final Batch Loss: 0.02842576615512371\n",
      "Epoch 3976, Loss: 0.09695563465356827, Final Batch Loss: 0.039155956357717514\n",
      "Epoch 3977, Loss: 0.08852136135101318, Final Batch Loss: 0.051407136023044586\n",
      "Epoch 3978, Loss: 0.10519759356975555, Final Batch Loss: 0.05821205675601959\n",
      "Epoch 3979, Loss: 0.09402656555175781, Final Batch Loss: 0.045170728117227554\n",
      "Epoch 3980, Loss: 0.07924540713429451, Final Batch Loss: 0.040151286870241165\n",
      "Epoch 3981, Loss: 0.09110076352953911, Final Batch Loss: 0.04287249967455864\n",
      "Epoch 3982, Loss: 0.08960042893886566, Final Batch Loss: 0.05778846889734268\n",
      "Epoch 3983, Loss: 0.08075192384421825, Final Batch Loss: 0.05026698857545853\n",
      "Epoch 3984, Loss: 0.11212008446455002, Final Batch Loss: 0.03632485121488571\n",
      "Epoch 3985, Loss: 0.0877251960337162, Final Batch Loss: 0.055215250700712204\n",
      "Epoch 3986, Loss: 0.1441625840961933, Final Batch Loss: 0.056998979300260544\n",
      "Epoch 3987, Loss: 0.12047310546040535, Final Batch Loss: 0.06777949631214142\n",
      "Epoch 3988, Loss: 0.08105868473649025, Final Batch Loss: 0.03192402422428131\n",
      "Epoch 3989, Loss: 0.09643581882119179, Final Batch Loss: 0.035557493567466736\n",
      "Epoch 3990, Loss: 0.1222190335392952, Final Batch Loss: 0.04418268799781799\n",
      "Epoch 3991, Loss: 0.11646085977554321, Final Batch Loss: 0.06997025012969971\n",
      "Epoch 3992, Loss: 0.16411419212818146, Final Batch Loss: 0.12332369387149811\n",
      "Epoch 3993, Loss: 0.13751230388879776, Final Batch Loss: 0.0558057501912117\n",
      "Epoch 3994, Loss: 0.09021822921931744, Final Batch Loss: 0.06152965500950813\n",
      "Epoch 3995, Loss: 0.12136713415384293, Final Batch Loss: 0.05258694291114807\n",
      "Epoch 3996, Loss: 0.09491537138819695, Final Batch Loss: 0.03424292057752609\n",
      "Epoch 3997, Loss: 0.1199331097304821, Final Batch Loss: 0.05660608038306236\n",
      "Epoch 3998, Loss: 0.09163954481482506, Final Batch Loss: 0.025802846997976303\n",
      "Epoch 3999, Loss: 0.09008198231458664, Final Batch Loss: 0.05246675759553909\n",
      "Epoch 4000, Loss: 0.10806525126099586, Final Batch Loss: 0.05669721961021423\n",
      "Epoch 4001, Loss: 0.08459030650556087, Final Batch Loss: 0.030071323737502098\n",
      "Epoch 4002, Loss: 0.11422115191817284, Final Batch Loss: 0.06918322294950485\n",
      "Epoch 4003, Loss: 0.11354907602071762, Final Batch Loss: 0.05433330312371254\n",
      "Epoch 4004, Loss: 0.08202671445906162, Final Batch Loss: 0.05613167956471443\n",
      "Epoch 4005, Loss: 0.10183582827448845, Final Batch Loss: 0.05059844255447388\n",
      "Epoch 4006, Loss: 0.09031223505735397, Final Batch Loss: 0.041546132415533066\n",
      "Epoch 4007, Loss: 0.08951964788138866, Final Batch Loss: 0.0257329773157835\n",
      "Epoch 4008, Loss: 0.09484737738966942, Final Batch Loss: 0.041469380259513855\n",
      "Epoch 4009, Loss: 0.0823769997805357, Final Batch Loss: 0.027491291984915733\n",
      "Epoch 4010, Loss: 0.11451178789138794, Final Batch Loss: 0.04709573835134506\n",
      "Epoch 4011, Loss: 0.09594976156949997, Final Batch Loss: 0.0433429554104805\n",
      "Epoch 4012, Loss: 0.09343485347926617, Final Batch Loss: 0.027004724368453026\n",
      "Epoch 4013, Loss: 0.09351897239685059, Final Batch Loss: 0.04094724729657173\n",
      "Epoch 4014, Loss: 0.12567169219255447, Final Batch Loss: 0.05402708798646927\n",
      "Epoch 4015, Loss: 0.08074945583939552, Final Batch Loss: 0.04406675696372986\n",
      "Epoch 4016, Loss: 0.08885135874152184, Final Batch Loss: 0.04282659664750099\n",
      "Epoch 4017, Loss: 0.10110905021429062, Final Batch Loss: 0.03140263259410858\n",
      "Epoch 4018, Loss: 0.09093090891838074, Final Batch Loss: 0.037032611668109894\n",
      "Epoch 4019, Loss: 0.18702268600463867, Final Batch Loss: 0.05094633996486664\n",
      "Epoch 4020, Loss: 0.09645255655050278, Final Batch Loss: 0.05445382371544838\n",
      "Epoch 4021, Loss: 0.10209646075963974, Final Batch Loss: 0.06363768875598907\n",
      "Epoch 4022, Loss: 0.1034284383058548, Final Batch Loss: 0.05007745698094368\n",
      "Epoch 4023, Loss: 0.10070952773094177, Final Batch Loss: 0.05876132845878601\n",
      "Epoch 4024, Loss: 0.12247829139232635, Final Batch Loss: 0.037415944039821625\n",
      "Epoch 4025, Loss: 0.08690736070275307, Final Batch Loss: 0.048770833760499954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4026, Loss: 0.14386697486042976, Final Batch Loss: 0.061767447739839554\n",
      "Epoch 4027, Loss: 0.09851521253585815, Final Batch Loss: 0.04583491012454033\n",
      "Epoch 4028, Loss: 0.09884395450353622, Final Batch Loss: 0.04805334657430649\n",
      "Epoch 4029, Loss: 0.08541770279407501, Final Batch Loss: 0.04924561083316803\n",
      "Epoch 4030, Loss: 0.09080992639064789, Final Batch Loss: 0.04786809906363487\n",
      "Epoch 4031, Loss: 0.08989445120096207, Final Batch Loss: 0.04802871495485306\n",
      "Epoch 4032, Loss: 0.12314466014504433, Final Batch Loss: 0.05354353412985802\n",
      "Epoch 4033, Loss: 0.10167818143963814, Final Batch Loss: 0.06380429863929749\n",
      "Epoch 4034, Loss: 0.09924278780817986, Final Batch Loss: 0.05680670216679573\n",
      "Epoch 4035, Loss: 0.09076743945479393, Final Batch Loss: 0.048040978610515594\n",
      "Epoch 4036, Loss: 0.09587916731834412, Final Batch Loss: 0.03547152504324913\n",
      "Epoch 4037, Loss: 0.1238018237054348, Final Batch Loss: 0.042046863585710526\n",
      "Epoch 4038, Loss: 0.09462429955601692, Final Batch Loss: 0.0533926784992218\n",
      "Epoch 4039, Loss: 0.0913330726325512, Final Batch Loss: 0.043485987931489944\n",
      "Epoch 4040, Loss: 0.09949874505400658, Final Batch Loss: 0.049169741570949554\n",
      "Epoch 4041, Loss: 0.09174764901399612, Final Batch Loss: 0.04820147156715393\n",
      "Epoch 4042, Loss: 0.1071300320327282, Final Batch Loss: 0.061380092054605484\n",
      "Epoch 4043, Loss: 0.09538879245519638, Final Batch Loss: 0.06275929510593414\n",
      "Epoch 4044, Loss: 0.09521039202809334, Final Batch Loss: 0.05172383412718773\n",
      "Epoch 4045, Loss: 0.09431323409080505, Final Batch Loss: 0.04918017238378525\n",
      "Epoch 4046, Loss: 0.09318607673048973, Final Batch Loss: 0.04204373061656952\n",
      "Epoch 4047, Loss: 0.0969984419643879, Final Batch Loss: 0.05598220229148865\n",
      "Epoch 4048, Loss: 0.10419614240527153, Final Batch Loss: 0.03765888139605522\n",
      "Epoch 4049, Loss: 0.08500239998102188, Final Batch Loss: 0.029000576585531235\n",
      "Epoch 4050, Loss: 0.10780610516667366, Final Batch Loss: 0.03688988462090492\n",
      "Epoch 4051, Loss: 0.07752382010221481, Final Batch Loss: 0.03449259698390961\n",
      "Epoch 4052, Loss: 0.08802619203925133, Final Batch Loss: 0.03665084391832352\n",
      "Epoch 4053, Loss: 0.092680923640728, Final Batch Loss: 0.054794736206531525\n",
      "Epoch 4054, Loss: 0.08870038390159607, Final Batch Loss: 0.050409264862537384\n",
      "Epoch 4055, Loss: 0.09865675494074821, Final Batch Loss: 0.04412328451871872\n",
      "Epoch 4056, Loss: 0.09056852385401726, Final Batch Loss: 0.05475800484418869\n",
      "Epoch 4057, Loss: 0.08968485891819, Final Batch Loss: 0.0443657785654068\n",
      "Epoch 4058, Loss: 0.08465997129678726, Final Batch Loss: 0.04729601368308067\n",
      "Epoch 4059, Loss: 0.1291685812175274, Final Batch Loss: 0.0709952786564827\n",
      "Epoch 4060, Loss: 0.08340083435177803, Final Batch Loss: 0.0377790592610836\n",
      "Epoch 4061, Loss: 0.08753744885325432, Final Batch Loss: 0.04187692329287529\n",
      "Epoch 4062, Loss: 0.09142488613724709, Final Batch Loss: 0.05387004092335701\n",
      "Epoch 4063, Loss: 0.1157426293939352, Final Batch Loss: 0.028031764551997185\n",
      "Epoch 4064, Loss: 0.08656325191259384, Final Batch Loss: 0.04304962232708931\n",
      "Epoch 4065, Loss: 0.13813438266515732, Final Batch Loss: 0.03804447501897812\n",
      "Epoch 4066, Loss: 0.10022971779108047, Final Batch Loss: 0.06644709408283234\n",
      "Epoch 4067, Loss: 0.10834506154060364, Final Batch Loss: 0.05133191496133804\n",
      "Epoch 4068, Loss: 0.09166859462857246, Final Batch Loss: 0.05038181692361832\n",
      "Epoch 4069, Loss: 0.1001686155796051, Final Batch Loss: 0.05175812542438507\n",
      "Epoch 4070, Loss: 0.12236646562814713, Final Batch Loss: 0.04552697390317917\n",
      "Epoch 4071, Loss: 0.08918868005275726, Final Batch Loss: 0.0560302697122097\n",
      "Epoch 4072, Loss: 0.08748854696750641, Final Batch Loss: 0.04057469591498375\n",
      "Epoch 4073, Loss: 0.0911506749689579, Final Batch Loss: 0.04656246677041054\n",
      "Epoch 4074, Loss: 0.11951899901032448, Final Batch Loss: 0.035847749561071396\n",
      "Epoch 4075, Loss: 0.07955182529985905, Final Batch Loss: 0.020093293860554695\n",
      "Epoch 4076, Loss: 0.12652745470404625, Final Batch Loss: 0.08355986326932907\n",
      "Epoch 4077, Loss: 0.1290471814572811, Final Batch Loss: 0.08210375905036926\n",
      "Epoch 4078, Loss: 0.12093133106827736, Final Batch Loss: 0.03380667045712471\n",
      "Epoch 4079, Loss: 0.14623721316456795, Final Batch Loss: 0.08799941092729568\n",
      "Epoch 4080, Loss: 0.1394411288201809, Final Batch Loss: 0.08027518540620804\n",
      "Epoch 4081, Loss: 0.11381052806973457, Final Batch Loss: 0.06051814928650856\n",
      "Epoch 4082, Loss: 0.09220615401864052, Final Batch Loss: 0.048469703644514084\n",
      "Epoch 4083, Loss: 0.13715757429599762, Final Batch Loss: 0.032963842153549194\n",
      "Epoch 4084, Loss: 0.08681877329945564, Final Batch Loss: 0.044279128313064575\n",
      "Epoch 4085, Loss: 0.08798752725124359, Final Batch Loss: 0.04857326298952103\n",
      "Epoch 4086, Loss: 0.09094713255763054, Final Batch Loss: 0.0345163531601429\n",
      "Epoch 4087, Loss: 0.0722634419798851, Final Batch Loss: 0.03744709491729736\n",
      "Epoch 4088, Loss: 0.084610216319561, Final Batch Loss: 0.044690586626529694\n",
      "Epoch 4089, Loss: 0.11196369305253029, Final Batch Loss: 0.04052368178963661\n",
      "Epoch 4090, Loss: 0.09876307100057602, Final Batch Loss: 0.05543389916419983\n",
      "Epoch 4091, Loss: 0.12238577753305435, Final Batch Loss: 0.05543240159749985\n",
      "Epoch 4092, Loss: 0.08876045420765877, Final Batch Loss: 0.04086349532008171\n",
      "Epoch 4093, Loss: 0.08068589121103287, Final Batch Loss: 0.044573936611413956\n",
      "Epoch 4094, Loss: 0.08962345868349075, Final Batch Loss: 0.033831749111413956\n",
      "Epoch 4095, Loss: 0.10776205733418465, Final Batch Loss: 0.04383436217904091\n",
      "Epoch 4096, Loss: 0.10546077415347099, Final Batch Loss: 0.06079878285527229\n",
      "Epoch 4097, Loss: 0.08411252871155739, Final Batch Loss: 0.04861462861299515\n",
      "Epoch 4098, Loss: 0.08809665217995644, Final Batch Loss: 0.049262285232543945\n",
      "Epoch 4099, Loss: 0.11439751833677292, Final Batch Loss: 0.06511152535676956\n",
      "Epoch 4100, Loss: 0.16426145285367966, Final Batch Loss: 0.04185314476490021\n",
      "Epoch 4101, Loss: 0.10065720975399017, Final Batch Loss: 0.04712245240807533\n",
      "Epoch 4102, Loss: 0.11360760778188705, Final Batch Loss: 0.08133229613304138\n",
      "Epoch 4103, Loss: 0.12790334224700928, Final Batch Loss: 0.06369414180517197\n",
      "Epoch 4104, Loss: 0.10292169079184532, Final Batch Loss: 0.06546757370233536\n",
      "Epoch 4105, Loss: 0.09357673488557339, Final Batch Loss: 0.06540031731128693\n",
      "Epoch 4106, Loss: 0.11280491948127747, Final Batch Loss: 0.06325212866067886\n",
      "Epoch 4107, Loss: 0.15181560814380646, Final Batch Loss: 0.08519776165485382\n",
      "Epoch 4108, Loss: 0.08473661355674267, Final Batch Loss: 0.02455517090857029\n",
      "Epoch 4109, Loss: 0.09956776350736618, Final Batch Loss: 0.05034039914608002\n",
      "Epoch 4110, Loss: 0.08360188454389572, Final Batch Loss: 0.0485561303794384\n",
      "Epoch 4111, Loss: 0.11123939976096153, Final Batch Loss: 0.04344181343913078\n",
      "Epoch 4112, Loss: 0.08803845196962357, Final Batch Loss: 0.0267777182161808\n",
      "Epoch 4113, Loss: 0.0868336446583271, Final Batch Loss: 0.049949999898672104\n",
      "Epoch 4114, Loss: 0.14701977372169495, Final Batch Loss: 0.11108230799436569\n",
      "Epoch 4115, Loss: 0.13463297858834267, Final Batch Loss: 0.08458103984594345\n",
      "Epoch 4116, Loss: 0.14489192515611649, Final Batch Loss: 0.05405907332897186\n",
      "Epoch 4117, Loss: 0.12008250504732132, Final Batch Loss: 0.06348607689142227\n",
      "Epoch 4118, Loss: 0.11435629427433014, Final Batch Loss: 0.05036632716655731\n",
      "Epoch 4119, Loss: 0.10141470655798912, Final Batch Loss: 0.05419113114476204\n",
      "Epoch 4120, Loss: 0.10156449303030968, Final Batch Loss: 0.03960331529378891\n",
      "Epoch 4121, Loss: 0.09260629862546921, Final Batch Loss: 0.05538273975253105\n",
      "Epoch 4122, Loss: 0.09274068474769592, Final Batch Loss: 0.03112994134426117\n",
      "Epoch 4123, Loss: 0.10395824536681175, Final Batch Loss: 0.05285705253481865\n",
      "Epoch 4124, Loss: 0.08852913975715637, Final Batch Loss: 0.0433807373046875\n",
      "Epoch 4125, Loss: 0.07150770165026188, Final Batch Loss: 0.027075769379734993\n",
      "Epoch 4126, Loss: 0.10037024319171906, Final Batch Loss: 0.05878201872110367\n",
      "Epoch 4127, Loss: 0.10457715764641762, Final Batch Loss: 0.03434501215815544\n",
      "Epoch 4128, Loss: 0.09257405996322632, Final Batch Loss: 0.03808167949318886\n",
      "Epoch 4129, Loss: 0.10447404906153679, Final Batch Loss: 0.038624729961156845\n",
      "Epoch 4130, Loss: 0.08659034594893456, Final Batch Loss: 0.04666408151388168\n",
      "Epoch 4131, Loss: 0.11146227642893791, Final Batch Loss: 0.07704740762710571\n",
      "Epoch 4132, Loss: 0.08789673447608948, Final Batch Loss: 0.044709548354148865\n",
      "Epoch 4133, Loss: 0.11948354542255402, Final Batch Loss: 0.065790556371212\n",
      "Epoch 4134, Loss: 0.10338345170021057, Final Batch Loss: 0.06553401798009872\n",
      "Epoch 4135, Loss: 0.08796285465359688, Final Batch Loss: 0.04546060413122177\n",
      "Epoch 4136, Loss: 0.10674318671226501, Final Batch Loss: 0.050307292491197586\n",
      "Epoch 4137, Loss: 0.11578724905848503, Final Batch Loss: 0.05316700413823128\n",
      "Epoch 4138, Loss: 0.13767744600772858, Final Batch Loss: 0.060799740254879\n",
      "Epoch 4139, Loss: 0.08555509522557259, Final Batch Loss: 0.04316839948296547\n",
      "Epoch 4140, Loss: 0.10938725993037224, Final Batch Loss: 0.0550161637365818\n",
      "Epoch 4141, Loss: 0.09757885336875916, Final Batch Loss: 0.05818141624331474\n",
      "Epoch 4142, Loss: 0.09576863795518875, Final Batch Loss: 0.02535373717546463\n",
      "Epoch 4143, Loss: 0.12620637938380241, Final Batch Loss: 0.058468353003263474\n",
      "Epoch 4144, Loss: 0.10129504650831223, Final Batch Loss: 0.03932439535856247\n",
      "Epoch 4145, Loss: 0.0819806270301342, Final Batch Loss: 0.03522387892007828\n",
      "Epoch 4146, Loss: 0.08544478751718998, Final Batch Loss: 0.05471353605389595\n",
      "Epoch 4147, Loss: 0.08210977539420128, Final Batch Loss: 0.046439073979854584\n",
      "Epoch 4148, Loss: 0.09955848753452301, Final Batch Loss: 0.048332422971725464\n",
      "Epoch 4149, Loss: 0.11403153836727142, Final Batch Loss: 0.06639111787080765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4150, Loss: 0.08429386094212532, Final Batch Loss: 0.048184677958488464\n",
      "Epoch 4151, Loss: 0.0820043571293354, Final Batch Loss: 0.03655539080500603\n",
      "Epoch 4152, Loss: 0.10953627154231071, Final Batch Loss: 0.069356270134449\n",
      "Epoch 4153, Loss: 0.09027449041604996, Final Batch Loss: 0.04351898655295372\n",
      "Epoch 4154, Loss: 0.09674513712525368, Final Batch Loss: 0.03126617893576622\n",
      "Epoch 4155, Loss: 0.09459458291530609, Final Batch Loss: 0.04613390564918518\n",
      "Epoch 4156, Loss: 0.08197557739913464, Final Batch Loss: 0.024354303255677223\n",
      "Epoch 4157, Loss: 0.09393845126032829, Final Batch Loss: 0.05142441391944885\n",
      "Epoch 4158, Loss: 0.08078725263476372, Final Batch Loss: 0.03185171261429787\n",
      "Epoch 4159, Loss: 0.09818335250020027, Final Batch Loss: 0.05288257822394371\n",
      "Epoch 4160, Loss: 0.08615635335445404, Final Batch Loss: 0.019821837544441223\n",
      "Epoch 4161, Loss: 0.10021267458796501, Final Batch Loss: 0.048973824828863144\n",
      "Epoch 4162, Loss: 0.14202236384153366, Final Batch Loss: 0.06658412516117096\n",
      "Epoch 4163, Loss: 0.09930627048015594, Final Batch Loss: 0.045515287667512894\n",
      "Epoch 4164, Loss: 0.08842693641781807, Final Batch Loss: 0.032028067857027054\n",
      "Epoch 4165, Loss: 0.09596069529652596, Final Batch Loss: 0.04764840006828308\n",
      "Epoch 4166, Loss: 0.13341326266527176, Final Batch Loss: 0.05669337511062622\n",
      "Epoch 4167, Loss: 0.09883205592632294, Final Batch Loss: 0.0366581492125988\n",
      "Epoch 4168, Loss: 0.10908440873026848, Final Batch Loss: 0.04396111145615578\n",
      "Epoch 4169, Loss: 0.12485917285084724, Final Batch Loss: 0.08284047245979309\n",
      "Epoch 4170, Loss: 0.13562289625406265, Final Batch Loss: 0.06968165934085846\n",
      "Epoch 4171, Loss: 0.0741720162332058, Final Batch Loss: 0.036075279116630554\n",
      "Epoch 4172, Loss: 0.10018354281783104, Final Batch Loss: 0.054848458617925644\n",
      "Epoch 4173, Loss: 0.10188502818346024, Final Batch Loss: 0.059613920748233795\n",
      "Epoch 4174, Loss: 0.08530126512050629, Final Batch Loss: 0.036349620670080185\n",
      "Epoch 4175, Loss: 0.13016920536756516, Final Batch Loss: 0.056794650852680206\n",
      "Epoch 4176, Loss: 0.11066405102610588, Final Batch Loss: 0.04781872406601906\n",
      "Epoch 4177, Loss: 0.09702802076935768, Final Batch Loss: 0.052182637155056\n",
      "Epoch 4178, Loss: 0.10719240084290504, Final Batch Loss: 0.05087955296039581\n",
      "Epoch 4179, Loss: 0.09310385212302208, Final Batch Loss: 0.03593295067548752\n",
      "Epoch 4180, Loss: 0.08100024051964283, Final Batch Loss: 0.023840202018618584\n",
      "Epoch 4181, Loss: 0.11417527496814728, Final Batch Loss: 0.05691342055797577\n",
      "Epoch 4182, Loss: 0.1015494130551815, Final Batch Loss: 0.04347118362784386\n",
      "Epoch 4183, Loss: 0.08413034491240978, Final Batch Loss: 0.05619551241397858\n",
      "Epoch 4184, Loss: 0.0875779427587986, Final Batch Loss: 0.04623454064130783\n",
      "Epoch 4185, Loss: 0.09779037907719612, Final Batch Loss: 0.049932193011045456\n",
      "Epoch 4186, Loss: 0.08854790031909943, Final Batch Loss: 0.0352947898209095\n",
      "Epoch 4187, Loss: 0.09805053472518921, Final Batch Loss: 0.05611126497387886\n",
      "Epoch 4188, Loss: 0.0940515547990799, Final Batch Loss: 0.04984142258763313\n",
      "Epoch 4189, Loss: 0.09481417015194893, Final Batch Loss: 0.06308244168758392\n",
      "Epoch 4190, Loss: 0.11265884712338448, Final Batch Loss: 0.041066933423280716\n",
      "Epoch 4191, Loss: 0.09713245555758476, Final Batch Loss: 0.044390346854925156\n",
      "Epoch 4192, Loss: 0.09816502407193184, Final Batch Loss: 0.04885842651128769\n",
      "Epoch 4193, Loss: 0.10004990175366402, Final Batch Loss: 0.042267654091119766\n",
      "Epoch 4194, Loss: 0.08712911419570446, Final Batch Loss: 0.028386002406477928\n",
      "Epoch 4195, Loss: 0.11550524458289146, Final Batch Loss: 0.06977613270282745\n",
      "Epoch 4196, Loss: 0.09566381573677063, Final Batch Loss: 0.05039173737168312\n",
      "Epoch 4197, Loss: 0.11679507046937943, Final Batch Loss: 0.04647434502840042\n",
      "Epoch 4198, Loss: 0.10336492955684662, Final Batch Loss: 0.04351356625556946\n",
      "Epoch 4199, Loss: 0.11710570007562637, Final Batch Loss: 0.05401439219713211\n",
      "Epoch 4200, Loss: 0.12917304784059525, Final Batch Loss: 0.05728524923324585\n",
      "Epoch 4201, Loss: 0.09887128137052059, Final Batch Loss: 0.028498848900198936\n",
      "Epoch 4202, Loss: 0.08801516145467758, Final Batch Loss: 0.040386609733104706\n",
      "Epoch 4203, Loss: 0.09065181016921997, Final Batch Loss: 0.03364361822605133\n",
      "Epoch 4204, Loss: 0.09138203039765358, Final Batch Loss: 0.04357996955513954\n",
      "Epoch 4205, Loss: 0.0956583060324192, Final Batch Loss: 0.04894186556339264\n",
      "Epoch 4206, Loss: 0.0906842015683651, Final Batch Loss: 0.04248839616775513\n",
      "Epoch 4207, Loss: 0.0836932398378849, Final Batch Loss: 0.049436867237091064\n",
      "Epoch 4208, Loss: 0.0861491784453392, Final Batch Loss: 0.04414040222764015\n",
      "Epoch 4209, Loss: 0.0865703672170639, Final Batch Loss: 0.03782424330711365\n",
      "Epoch 4210, Loss: 0.109770517796278, Final Batch Loss: 0.06736405938863754\n",
      "Epoch 4211, Loss: 0.09792743995785713, Final Batch Loss: 0.05561145767569542\n",
      "Epoch 4212, Loss: 0.09547749906778336, Final Batch Loss: 0.0536104179918766\n",
      "Epoch 4213, Loss: 0.08436990529298782, Final Batch Loss: 0.03233305737376213\n",
      "Epoch 4214, Loss: 0.09330440312623978, Final Batch Loss: 0.0400671623647213\n",
      "Epoch 4215, Loss: 0.10702040791511536, Final Batch Loss: 0.07495663315057755\n",
      "Epoch 4216, Loss: 0.08418045565485954, Final Batch Loss: 0.03493071347475052\n",
      "Epoch 4217, Loss: 0.08412142097949982, Final Batch Loss: 0.04622320085763931\n",
      "Epoch 4218, Loss: 0.09620512649416924, Final Batch Loss: 0.04426823928952217\n",
      "Epoch 4219, Loss: 0.09411618113517761, Final Batch Loss: 0.0429706871509552\n",
      "Epoch 4220, Loss: 0.1352616287767887, Final Batch Loss: 0.06104404106736183\n",
      "Epoch 4221, Loss: 0.09083673171699047, Final Batch Loss: 0.02886206842958927\n",
      "Epoch 4222, Loss: 0.08341017737984657, Final Batch Loss: 0.03537182882428169\n",
      "Epoch 4223, Loss: 0.0798962451517582, Final Batch Loss: 0.038185376673936844\n",
      "Epoch 4224, Loss: 0.09504653513431549, Final Batch Loss: 0.05310080200433731\n",
      "Epoch 4225, Loss: 0.09892412647604942, Final Batch Loss: 0.06446892768144608\n",
      "Epoch 4226, Loss: 0.08241209387779236, Final Batch Loss: 0.037096794694662094\n",
      "Epoch 4227, Loss: 0.08187460899353027, Final Batch Loss: 0.03627417981624603\n",
      "Epoch 4228, Loss: 0.09595652297139168, Final Batch Loss: 0.04325082525610924\n",
      "Epoch 4229, Loss: 0.0939498320221901, Final Batch Loss: 0.05126277357339859\n",
      "Epoch 4230, Loss: 0.09026985615491867, Final Batch Loss: 0.050813108682632446\n",
      "Epoch 4231, Loss: 0.09268790856003761, Final Batch Loss: 0.024987805634737015\n",
      "Epoch 4232, Loss: 0.09195377305150032, Final Batch Loss: 0.024653654545545578\n",
      "Epoch 4233, Loss: 0.09089504554867744, Final Batch Loss: 0.05606413632631302\n",
      "Epoch 4234, Loss: 0.1317434385418892, Final Batch Loss: 0.0669359564781189\n",
      "Epoch 4235, Loss: 0.09253266081213951, Final Batch Loss: 0.046157561242580414\n",
      "Epoch 4236, Loss: 0.08496721275150776, Final Batch Loss: 0.027966300025582314\n",
      "Epoch 4237, Loss: 0.08408696204423904, Final Batch Loss: 0.03703250735998154\n",
      "Epoch 4238, Loss: 0.09541573002934456, Final Batch Loss: 0.06008980795741081\n",
      "Epoch 4239, Loss: 0.07871089316904545, Final Batch Loss: 0.027972085401415825\n",
      "Epoch 4240, Loss: 0.0927143543958664, Final Batch Loss: 0.03982752934098244\n",
      "Epoch 4241, Loss: 0.08911251276731491, Final Batch Loss: 0.04290993884205818\n",
      "Epoch 4242, Loss: 0.09699253365397453, Final Batch Loss: 0.03663633391261101\n",
      "Epoch 4243, Loss: 0.11309611797332764, Final Batch Loss: 0.06182757765054703\n",
      "Epoch 4244, Loss: 0.10090411081910133, Final Batch Loss: 0.05247293785214424\n",
      "Epoch 4245, Loss: 0.09419932588934898, Final Batch Loss: 0.06024804711341858\n",
      "Epoch 4246, Loss: 0.09336409345269203, Final Batch Loss: 0.038885992020368576\n",
      "Epoch 4247, Loss: 0.09201983362436295, Final Batch Loss: 0.041079550981521606\n",
      "Epoch 4248, Loss: 0.17037516459822655, Final Batch Loss: 0.1101260781288147\n",
      "Epoch 4249, Loss: 0.15078676491975784, Final Batch Loss: 0.06338969618082047\n",
      "Epoch 4250, Loss: 0.09819437935948372, Final Batch Loss: 0.043436408042907715\n",
      "Epoch 4251, Loss: 0.10413780063390732, Final Batch Loss: 0.0490453727543354\n",
      "Epoch 4252, Loss: 0.13629701361060143, Final Batch Loss: 0.09355957061052322\n",
      "Epoch 4253, Loss: 0.07891101203858852, Final Batch Loss: 0.028061339631676674\n",
      "Epoch 4254, Loss: 0.12360099330544472, Final Batch Loss: 0.0759136825799942\n",
      "Epoch 4255, Loss: 0.12004199624061584, Final Batch Loss: 0.07188138365745544\n",
      "Epoch 4256, Loss: 0.08496123924851418, Final Batch Loss: 0.042457565665245056\n",
      "Epoch 4257, Loss: 0.1462044008076191, Final Batch Loss: 0.09951916337013245\n",
      "Epoch 4258, Loss: 0.13294299319386482, Final Batch Loss: 0.087296262383461\n",
      "Epoch 4259, Loss: 0.09413769841194153, Final Batch Loss: 0.04687415063381195\n",
      "Epoch 4260, Loss: 0.13563838601112366, Final Batch Loss: 0.06802894175052643\n",
      "Epoch 4261, Loss: 0.11120692640542984, Final Batch Loss: 0.06592274457216263\n",
      "Epoch 4262, Loss: 0.11122046038508415, Final Batch Loss: 0.04900524765253067\n",
      "Epoch 4263, Loss: 0.08121529221534729, Final Batch Loss: 0.0517251119017601\n",
      "Epoch 4264, Loss: 0.1287390999495983, Final Batch Loss: 0.07914015650749207\n",
      "Epoch 4265, Loss: 0.11163171008229256, Final Batch Loss: 0.06418974697589874\n",
      "Epoch 4266, Loss: 0.11084595322608948, Final Batch Loss: 0.04088643193244934\n",
      "Epoch 4267, Loss: 0.16969820111989975, Final Batch Loss: 0.06966175138950348\n",
      "Epoch 4268, Loss: 0.1102498322725296, Final Batch Loss: 0.05151021108031273\n",
      "Epoch 4269, Loss: 0.08912262320518494, Final Batch Loss: 0.05034845694899559\n",
      "Epoch 4270, Loss: 0.09491706266999245, Final Batch Loss: 0.03275347873568535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4271, Loss: 0.1338546723127365, Final Batch Loss: 0.05409523844718933\n",
      "Epoch 4272, Loss: 0.09354773350059986, Final Batch Loss: 0.027262860909104347\n",
      "Epoch 4273, Loss: 0.10394405946135521, Final Batch Loss: 0.051133401691913605\n",
      "Epoch 4274, Loss: 0.07980292290449142, Final Batch Loss: 0.032430849969387054\n",
      "Epoch 4275, Loss: 0.09401490539312363, Final Batch Loss: 0.05406289920210838\n",
      "Epoch 4276, Loss: 0.08878977969288826, Final Batch Loss: 0.04591789096593857\n",
      "Epoch 4277, Loss: 0.13917969167232513, Final Batch Loss: 0.07147964835166931\n",
      "Epoch 4278, Loss: 0.15633264929056168, Final Batch Loss: 0.11589749902486801\n",
      "Epoch 4279, Loss: 0.09536756575107574, Final Batch Loss: 0.042334288358688354\n",
      "Epoch 4280, Loss: 0.10159788280725479, Final Batch Loss: 0.04867633804678917\n",
      "Epoch 4281, Loss: 0.0908362865447998, Final Batch Loss: 0.04543459787964821\n",
      "Epoch 4282, Loss: 0.10827689245343208, Final Batch Loss: 0.06143129989504814\n",
      "Epoch 4283, Loss: 0.11490879021584988, Final Batch Loss: 0.08504443615674973\n",
      "Epoch 4284, Loss: 0.08622181415557861, Final Batch Loss: 0.03875911608338356\n",
      "Epoch 4285, Loss: 0.08683615736663342, Final Batch Loss: 0.059630610048770905\n",
      "Epoch 4286, Loss: 0.11056528612971306, Final Batch Loss: 0.07712153345346451\n",
      "Epoch 4287, Loss: 0.10382988303899765, Final Batch Loss: 0.058732785284519196\n",
      "Epoch 4288, Loss: 0.09213371574878693, Final Batch Loss: 0.05383548140525818\n",
      "Epoch 4289, Loss: 0.08552946336567402, Final Batch Loss: 0.030837757512927055\n",
      "Epoch 4290, Loss: 0.10793370380997658, Final Batch Loss: 0.05915805697441101\n",
      "Epoch 4291, Loss: 0.10706281289458275, Final Batch Loss: 0.05922003090381622\n",
      "Epoch 4292, Loss: 0.08971375599503517, Final Batch Loss: 0.05077249929308891\n",
      "Epoch 4293, Loss: 0.08946337923407555, Final Batch Loss: 0.044331036508083344\n",
      "Epoch 4294, Loss: 0.09507163614034653, Final Batch Loss: 0.05254315957427025\n",
      "Epoch 4295, Loss: 0.09017807617783546, Final Batch Loss: 0.04456806182861328\n",
      "Epoch 4296, Loss: 0.12028558179736137, Final Batch Loss: 0.07498957961797714\n",
      "Epoch 4297, Loss: 0.12795652076601982, Final Batch Loss: 0.08233419060707092\n",
      "Epoch 4298, Loss: 0.1780789978802204, Final Batch Loss: 0.11571383476257324\n",
      "Epoch 4299, Loss: 0.09540761262178421, Final Batch Loss: 0.05939166247844696\n",
      "Epoch 4300, Loss: 0.1150510162115097, Final Batch Loss: 0.06596729159355164\n",
      "Epoch 4301, Loss: 0.07979128882288933, Final Batch Loss: 0.03924144431948662\n",
      "Epoch 4302, Loss: 0.12805749475955963, Final Batch Loss: 0.09584090113639832\n",
      "Epoch 4303, Loss: 0.09770997241139412, Final Batch Loss: 0.05577949807047844\n",
      "Epoch 4304, Loss: 0.09377311915159225, Final Batch Loss: 0.041129861027002335\n",
      "Epoch 4305, Loss: 0.08761389926075935, Final Batch Loss: 0.024790313094854355\n",
      "Epoch 4306, Loss: 0.15412621945142746, Final Batch Loss: 0.10806964337825775\n",
      "Epoch 4307, Loss: 0.10208382457494736, Final Batch Loss: 0.06226751208305359\n",
      "Epoch 4308, Loss: 0.13123560696840286, Final Batch Loss: 0.06498873978853226\n",
      "Epoch 4309, Loss: 0.09776083379983902, Final Batch Loss: 0.06228027492761612\n",
      "Epoch 4310, Loss: 0.09857904352247715, Final Batch Loss: 0.028646955266594887\n",
      "Epoch 4311, Loss: 0.10537868365645409, Final Batch Loss: 0.061250485479831696\n",
      "Epoch 4312, Loss: 0.0881846733391285, Final Batch Loss: 0.041829437017440796\n",
      "Epoch 4313, Loss: 0.10840087756514549, Final Batch Loss: 0.05017465353012085\n",
      "Epoch 4314, Loss: 0.09936156868934631, Final Batch Loss: 0.03194800764322281\n",
      "Epoch 4315, Loss: 0.09368188679218292, Final Batch Loss: 0.04749741032719612\n",
      "Epoch 4316, Loss: 0.1116095781326294, Final Batch Loss: 0.033371344208717346\n",
      "Epoch 4317, Loss: 0.10839981585741043, Final Batch Loss: 0.0669822171330452\n",
      "Epoch 4318, Loss: 0.07312436401844025, Final Batch Loss: 0.034139346331357956\n",
      "Epoch 4319, Loss: 0.0860801413655281, Final Batch Loss: 0.04799281805753708\n",
      "Epoch 4320, Loss: 0.0907383393496275, Final Batch Loss: 0.029235990718007088\n",
      "Epoch 4321, Loss: 0.08991802483797073, Final Batch Loss: 0.03718922659754753\n",
      "Epoch 4322, Loss: 0.08547766879200935, Final Batch Loss: 0.053225573152303696\n",
      "Epoch 4323, Loss: 0.08078066259622574, Final Batch Loss: 0.04698187857866287\n",
      "Epoch 4324, Loss: 0.11585764959454536, Final Batch Loss: 0.06361810863018036\n",
      "Epoch 4325, Loss: 0.11115751042962074, Final Batch Loss: 0.05233532190322876\n",
      "Epoch 4326, Loss: 0.09995673224329948, Final Batch Loss: 0.04648103564977646\n",
      "Epoch 4327, Loss: 0.0976647362112999, Final Batch Loss: 0.03685595840215683\n",
      "Epoch 4328, Loss: 0.09572773426771164, Final Batch Loss: 0.042336951941251755\n",
      "Epoch 4329, Loss: 0.10761032626032829, Final Batch Loss: 0.0435156486928463\n",
      "Epoch 4330, Loss: 0.11062071844935417, Final Batch Loss: 0.058263689279556274\n",
      "Epoch 4331, Loss: 0.08491851761937141, Final Batch Loss: 0.026634417474269867\n",
      "Epoch 4332, Loss: 0.08190323412418365, Final Batch Loss: 0.036882903426885605\n",
      "Epoch 4333, Loss: 0.09788814932107925, Final Batch Loss: 0.059603575617074966\n",
      "Epoch 4334, Loss: 0.09971147030591965, Final Batch Loss: 0.03438737243413925\n",
      "Epoch 4335, Loss: 0.09140956401824951, Final Batch Loss: 0.04452527314424515\n",
      "Epoch 4336, Loss: 0.08143018558621407, Final Batch Loss: 0.03646606579422951\n",
      "Epoch 4337, Loss: 0.09496135078370571, Final Batch Loss: 0.029898999258875847\n",
      "Epoch 4338, Loss: 0.08829643949866295, Final Batch Loss: 0.029710207134485245\n",
      "Epoch 4339, Loss: 0.07066554576158524, Final Batch Loss: 0.044411398470401764\n",
      "Epoch 4340, Loss: 0.08283872529864311, Final Batch Loss: 0.032611459493637085\n",
      "Epoch 4341, Loss: 0.09005042165517807, Final Batch Loss: 0.052385732531547546\n",
      "Epoch 4342, Loss: 0.08115191757678986, Final Batch Loss: 0.03751734644174576\n",
      "Epoch 4343, Loss: 0.08768389374017715, Final Batch Loss: 0.04130047932267189\n",
      "Epoch 4344, Loss: 0.08662211522459984, Final Batch Loss: 0.05170426145195961\n",
      "Epoch 4345, Loss: 0.08945063501596451, Final Batch Loss: 0.05977773293852806\n",
      "Epoch 4346, Loss: 0.08858766034245491, Final Batch Loss: 0.054543636739254\n",
      "Epoch 4347, Loss: 0.08540967106819153, Final Batch Loss: 0.047940775752067566\n",
      "Epoch 4348, Loss: 0.10193318873643875, Final Batch Loss: 0.056342437863349915\n",
      "Epoch 4349, Loss: 0.0870818980038166, Final Batch Loss: 0.032436586916446686\n",
      "Epoch 4350, Loss: 0.0883030816912651, Final Batch Loss: 0.057870641350746155\n",
      "Epoch 4351, Loss: 0.08942878991365433, Final Batch Loss: 0.03604970499873161\n",
      "Epoch 4352, Loss: 0.10411405935883522, Final Batch Loss: 0.063084177672863\n",
      "Epoch 4353, Loss: 0.09084952995181084, Final Batch Loss: 0.0404004268348217\n",
      "Epoch 4354, Loss: 0.10101664066314697, Final Batch Loss: 0.04644890874624252\n",
      "Epoch 4355, Loss: 0.09605618566274643, Final Batch Loss: 0.037484560161828995\n",
      "Epoch 4356, Loss: 0.10396850109100342, Final Batch Loss: 0.061008989810943604\n",
      "Epoch 4357, Loss: 0.08327962830662727, Final Batch Loss: 0.037466201931238174\n",
      "Epoch 4358, Loss: 0.08525783754885197, Final Batch Loss: 0.030066540464758873\n",
      "Epoch 4359, Loss: 0.09692389518022537, Final Batch Loss: 0.05275651812553406\n",
      "Epoch 4360, Loss: 0.08615236729383469, Final Batch Loss: 0.04684951901435852\n",
      "Epoch 4361, Loss: 0.06719837710261345, Final Batch Loss: 0.03125796094536781\n",
      "Epoch 4362, Loss: 0.08444048836827278, Final Batch Loss: 0.05281032994389534\n",
      "Epoch 4363, Loss: 0.0916728600859642, Final Batch Loss: 0.05823749303817749\n",
      "Epoch 4364, Loss: 0.08132075890898705, Final Batch Loss: 0.034655701369047165\n",
      "Epoch 4365, Loss: 0.14419183880090714, Final Batch Loss: 0.02857305109500885\n",
      "Epoch 4366, Loss: 0.10566249117255211, Final Batch Loss: 0.06755445897579193\n",
      "Epoch 4367, Loss: 0.11803431808948517, Final Batch Loss: 0.0868319571018219\n",
      "Epoch 4368, Loss: 0.0972953550517559, Final Batch Loss: 0.0637696236371994\n",
      "Epoch 4369, Loss: 0.08957741037011147, Final Batch Loss: 0.052115339785814285\n",
      "Epoch 4370, Loss: 0.08504928648471832, Final Batch Loss: 0.037283025681972504\n",
      "Epoch 4371, Loss: 0.09224672988057137, Final Batch Loss: 0.05844800919294357\n",
      "Epoch 4372, Loss: 0.10382892936468124, Final Batch Loss: 0.04115527868270874\n",
      "Epoch 4373, Loss: 0.10359356552362442, Final Batch Loss: 0.04815877228975296\n",
      "Epoch 4374, Loss: 0.09314547851681709, Final Batch Loss: 0.04727696627378464\n",
      "Epoch 4375, Loss: 0.08662290126085281, Final Batch Loss: 0.04420669376850128\n",
      "Epoch 4376, Loss: 0.1833716183900833, Final Batch Loss: 0.1331312656402588\n",
      "Epoch 4377, Loss: 0.12331903725862503, Final Batch Loss: 0.07214024662971497\n",
      "Epoch 4378, Loss: 0.07957225665450096, Final Batch Loss: 0.04700828343629837\n",
      "Epoch 4379, Loss: 0.0833243876695633, Final Batch Loss: 0.03412507846951485\n",
      "Epoch 4380, Loss: 0.08965377509593964, Final Batch Loss: 0.0387437641620636\n",
      "Epoch 4381, Loss: 0.08624837547540665, Final Batch Loss: 0.055392391979694366\n",
      "Epoch 4382, Loss: 0.11013345792889595, Final Batch Loss: 0.044443096965551376\n",
      "Epoch 4383, Loss: 0.11892322078347206, Final Batch Loss: 0.04694892838597298\n",
      "Epoch 4384, Loss: 0.0823684073984623, Final Batch Loss: 0.044376034289598465\n",
      "Epoch 4385, Loss: 0.09325806051492691, Final Batch Loss: 0.05356195196509361\n",
      "Epoch 4386, Loss: 0.08957884460687637, Final Batch Loss: 0.045348554849624634\n",
      "Epoch 4387, Loss: 0.0868510864675045, Final Batch Loss: 0.047189854085445404\n",
      "Epoch 4388, Loss: 0.11171066761016846, Final Batch Loss: 0.05335526168346405\n",
      "Epoch 4389, Loss: 0.08402185514569283, Final Batch Loss: 0.044790249317884445\n",
      "Epoch 4390, Loss: 0.10839401558041573, Final Batch Loss: 0.03415441885590553\n",
      "Epoch 4391, Loss: 0.07728347182273865, Final Batch Loss: 0.04167540371417999\n",
      "Epoch 4392, Loss: 0.08137046545743942, Final Batch Loss: 0.04115845263004303\n",
      "Epoch 4393, Loss: 0.0840817242860794, Final Batch Loss: 0.04933781921863556\n",
      "Epoch 4394, Loss: 0.07552747428417206, Final Batch Loss: 0.036749374121427536\n",
      "Epoch 4395, Loss: 0.10070851445198059, Final Batch Loss: 0.048517026007175446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4396, Loss: 0.09236232936382294, Final Batch Loss: 0.04046766459941864\n",
      "Epoch 4397, Loss: 0.07777649536728859, Final Batch Loss: 0.025996379554271698\n",
      "Epoch 4398, Loss: 0.07974360138177872, Final Batch Loss: 0.0385756753385067\n",
      "Epoch 4399, Loss: 0.07894770056009293, Final Batch Loss: 0.04066075384616852\n",
      "Epoch 4400, Loss: 0.08599420264363289, Final Batch Loss: 0.038937341421842575\n",
      "Epoch 4401, Loss: 0.09834215044975281, Final Batch Loss: 0.049969714134931564\n",
      "Epoch 4402, Loss: 0.08084477484226227, Final Batch Loss: 0.03083266317844391\n",
      "Epoch 4403, Loss: 0.08945272862911224, Final Batch Loss: 0.04978550970554352\n",
      "Epoch 4404, Loss: 0.07975167036056519, Final Batch Loss: 0.04198534041643143\n",
      "Epoch 4405, Loss: 0.08849902078509331, Final Batch Loss: 0.029707837849855423\n",
      "Epoch 4406, Loss: 0.10027457028627396, Final Batch Loss: 0.04858177527785301\n",
      "Epoch 4407, Loss: 0.08725885860621929, Final Batch Loss: 0.05622914806008339\n",
      "Epoch 4408, Loss: 0.10600708052515984, Final Batch Loss: 0.06224774941802025\n",
      "Epoch 4409, Loss: 0.10422023385763168, Final Batch Loss: 0.05376952514052391\n",
      "Epoch 4410, Loss: 0.1261197254061699, Final Batch Loss: 0.0821005329489708\n",
      "Epoch 4411, Loss: 0.1401689201593399, Final Batch Loss: 0.040985822677612305\n",
      "Epoch 4412, Loss: 0.07549588941037655, Final Batch Loss: 0.03114176355302334\n",
      "Epoch 4413, Loss: 0.16869323700666428, Final Batch Loss: 0.11318385601043701\n",
      "Epoch 4414, Loss: 0.14518895000219345, Final Batch Loss: 0.08340457826852798\n",
      "Epoch 4415, Loss: 0.15228402987122536, Final Batch Loss: 0.09965122491121292\n",
      "Epoch 4416, Loss: 0.17805815488100052, Final Batch Loss: 0.0884660929441452\n",
      "Epoch 4417, Loss: 0.19743572920560837, Final Batch Loss: 0.062201954424381256\n",
      "Epoch 4418, Loss: 0.10944180190563202, Final Batch Loss: 0.0513606034219265\n",
      "Epoch 4419, Loss: 0.13032452017068863, Final Batch Loss: 0.06271977722644806\n",
      "Epoch 4420, Loss: 0.17236364632844925, Final Batch Loss: 0.08532910794019699\n",
      "Epoch 4421, Loss: 0.09547238796949387, Final Batch Loss: 0.04060056060552597\n",
      "Epoch 4422, Loss: 0.14830242097377777, Final Batch Loss: 0.04921415448188782\n",
      "Epoch 4423, Loss: 0.11866281554102898, Final Batch Loss: 0.07407504320144653\n",
      "Epoch 4424, Loss: 0.11333945393562317, Final Batch Loss: 0.04756547510623932\n",
      "Epoch 4425, Loss: 0.13295450061559677, Final Batch Loss: 0.054268307983875275\n",
      "Epoch 4426, Loss: 0.10503606125712395, Final Batch Loss: 0.04179983213543892\n",
      "Epoch 4427, Loss: 0.10934898257255554, Final Batch Loss: 0.052262287586927414\n",
      "Epoch 4428, Loss: 0.15093984454870224, Final Batch Loss: 0.06293700635433197\n",
      "Epoch 4429, Loss: 0.09157896414399147, Final Batch Loss: 0.06192457675933838\n",
      "Epoch 4430, Loss: 0.1190994568169117, Final Batch Loss: 0.07655677944421768\n",
      "Epoch 4431, Loss: 0.08875223994255066, Final Batch Loss: 0.04066401347517967\n",
      "Epoch 4432, Loss: 0.08634954318404198, Final Batch Loss: 0.03844805061817169\n",
      "Epoch 4433, Loss: 0.08677583187818527, Final Batch Loss: 0.02960800752043724\n",
      "Epoch 4434, Loss: 0.10736145451664925, Final Batch Loss: 0.06145453080534935\n",
      "Epoch 4435, Loss: 0.09608864039182663, Final Batch Loss: 0.043211665004491806\n",
      "Epoch 4436, Loss: 0.10717329382896423, Final Batch Loss: 0.042455948889255524\n",
      "Epoch 4437, Loss: 0.09836200624704361, Final Batch Loss: 0.04942996799945831\n",
      "Epoch 4438, Loss: 0.10843437537550926, Final Batch Loss: 0.05429605022072792\n",
      "Epoch 4439, Loss: 0.09653254598379135, Final Batch Loss: 0.057835839688777924\n",
      "Epoch 4440, Loss: 0.12239088863134384, Final Batch Loss: 0.08379510045051575\n",
      "Epoch 4441, Loss: 0.08797916769981384, Final Batch Loss: 0.03323417156934738\n",
      "Epoch 4442, Loss: 0.08684900403022766, Final Batch Loss: 0.05470557510852814\n",
      "Epoch 4443, Loss: 0.10094931349158287, Final Batch Loss: 0.06813491135835648\n",
      "Epoch 4444, Loss: 0.11202054843306541, Final Batch Loss: 0.06099647283554077\n",
      "Epoch 4445, Loss: 0.07923740893602371, Final Batch Loss: 0.025737036019563675\n",
      "Epoch 4446, Loss: 0.09260213747620583, Final Batch Loss: 0.04295681044459343\n",
      "Epoch 4447, Loss: 0.09701792523264885, Final Batch Loss: 0.05781107768416405\n",
      "Epoch 4448, Loss: 0.09437002241611481, Final Batch Loss: 0.033262599259614944\n",
      "Epoch 4449, Loss: 0.09538200870156288, Final Batch Loss: 0.03494476154446602\n",
      "Epoch 4450, Loss: 0.08922163397073746, Final Batch Loss: 0.042628612369298935\n",
      "Epoch 4451, Loss: 0.08939975127577782, Final Batch Loss: 0.04374295845627785\n",
      "Epoch 4452, Loss: 0.09653840772807598, Final Batch Loss: 0.0657239556312561\n",
      "Epoch 4453, Loss: 0.07718677446246147, Final Batch Loss: 0.035507604479789734\n",
      "Epoch 4454, Loss: 0.07688203454017639, Final Batch Loss: 0.03770380839705467\n",
      "Epoch 4455, Loss: 0.1053658165037632, Final Batch Loss: 0.05670034885406494\n",
      "Epoch 4456, Loss: 0.1160065196454525, Final Batch Loss: 0.07849407196044922\n",
      "Epoch 4457, Loss: 0.08470378071069717, Final Batch Loss: 0.038279592990875244\n",
      "Epoch 4458, Loss: 0.08761168085038662, Final Batch Loss: 0.029101526364684105\n",
      "Epoch 4459, Loss: 0.08829021081328392, Final Batch Loss: 0.034699421375989914\n",
      "Epoch 4460, Loss: 0.09207377210259438, Final Batch Loss: 0.058963529765605927\n",
      "Epoch 4461, Loss: 0.08412368968129158, Final Batch Loss: 0.042962100356817245\n",
      "Epoch 4462, Loss: 0.09124783799052238, Final Batch Loss: 0.04144209995865822\n",
      "Epoch 4463, Loss: 0.09081628918647766, Final Batch Loss: 0.04920649155974388\n",
      "Epoch 4464, Loss: 0.07756179571151733, Final Batch Loss: 0.038711801171302795\n",
      "Epoch 4465, Loss: 0.0922997985035181, Final Batch Loss: 0.024686450138688087\n",
      "Epoch 4466, Loss: 0.08393999934196472, Final Batch Loss: 0.037031564861536026\n",
      "Epoch 4467, Loss: 0.11930105462670326, Final Batch Loss: 0.07359474897384644\n",
      "Epoch 4468, Loss: 0.10322123393416405, Final Batch Loss: 0.053574543446302414\n",
      "Epoch 4469, Loss: 0.12439754232764244, Final Batch Loss: 0.06660791486501694\n",
      "Epoch 4470, Loss: 0.10222525894641876, Final Batch Loss: 0.0564473532140255\n",
      "Epoch 4471, Loss: 0.09171963483095169, Final Batch Loss: 0.03493594750761986\n",
      "Epoch 4472, Loss: 0.08509676903486252, Final Batch Loss: 0.050569966435432434\n",
      "Epoch 4473, Loss: 0.18255598843097687, Final Batch Loss: 0.05824422091245651\n",
      "Epoch 4474, Loss: 0.09566419571638107, Final Batch Loss: 0.04819579795002937\n",
      "Epoch 4475, Loss: 0.1157139465212822, Final Batch Loss: 0.05415843799710274\n",
      "Epoch 4476, Loss: 0.16649187356233597, Final Batch Loss: 0.08320622891187668\n",
      "Epoch 4477, Loss: 0.10705476626753807, Final Batch Loss: 0.05805579200387001\n",
      "Epoch 4478, Loss: 0.09534567594528198, Final Batch Loss: 0.04708278924226761\n",
      "Epoch 4479, Loss: 0.1769416481256485, Final Batch Loss: 0.11122661083936691\n",
      "Epoch 4480, Loss: 0.08367500826716423, Final Batch Loss: 0.02701880782842636\n",
      "Epoch 4481, Loss: 0.1634073443710804, Final Batch Loss: 0.11406836658716202\n",
      "Epoch 4482, Loss: 0.10831981152296066, Final Batch Loss: 0.06214908882975578\n",
      "Epoch 4483, Loss: 0.09395036846399307, Final Batch Loss: 0.02871415764093399\n",
      "Epoch 4484, Loss: 0.10608524829149246, Final Batch Loss: 0.05441681668162346\n",
      "Epoch 4485, Loss: 0.1064409501850605, Final Batch Loss: 0.05385599657893181\n",
      "Epoch 4486, Loss: 0.10898827016353607, Final Batch Loss: 0.06197027117013931\n",
      "Epoch 4487, Loss: 0.13728724420070648, Final Batch Loss: 0.04548441618680954\n",
      "Epoch 4488, Loss: 0.08475622907280922, Final Batch Loss: 0.04417875409126282\n",
      "Epoch 4489, Loss: 0.09642815962433815, Final Batch Loss: 0.0314595066010952\n",
      "Epoch 4490, Loss: 0.10490723326802254, Final Batch Loss: 0.04265594109892845\n",
      "Epoch 4491, Loss: 0.10214271396398544, Final Batch Loss: 0.033717721700668335\n",
      "Epoch 4492, Loss: 0.10580813884735107, Final Batch Loss: 0.06662440299987793\n",
      "Epoch 4493, Loss: 0.12030193582177162, Final Batch Loss: 0.0652676448225975\n",
      "Epoch 4494, Loss: 0.1001497246325016, Final Batch Loss: 0.05154000222682953\n",
      "Epoch 4495, Loss: 0.09977906197309494, Final Batch Loss: 0.05295471474528313\n",
      "Epoch 4496, Loss: 0.0912279449403286, Final Batch Loss: 0.03750453516840935\n",
      "Epoch 4497, Loss: 0.10664845257997513, Final Batch Loss: 0.059226278215646744\n",
      "Epoch 4498, Loss: 0.10375084728002548, Final Batch Loss: 0.05682717263698578\n",
      "Epoch 4499, Loss: 0.11341986432671547, Final Batch Loss: 0.07275364547967911\n",
      "Epoch 4500, Loss: 0.11362496390938759, Final Batch Loss: 0.04438019171357155\n",
      "Epoch 4501, Loss: 0.08100746385753155, Final Batch Loss: 0.02944970317184925\n",
      "Epoch 4502, Loss: 0.11025369539856911, Final Batch Loss: 0.04043306037783623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4503, Loss: 0.08740771934390068, Final Batch Loss: 0.03304858133196831\n",
      "Epoch 4504, Loss: 0.10327430814504623, Final Batch Loss: 0.04168868809938431\n",
      "Epoch 4505, Loss: 0.07689854130148888, Final Batch Loss: 0.03411953151226044\n",
      "Epoch 4506, Loss: 0.10774689167737961, Final Batch Loss: 0.05759118124842644\n",
      "Epoch 4507, Loss: 0.20811421051621437, Final Batch Loss: 0.16144630312919617\n",
      "Epoch 4508, Loss: 0.11887453496456146, Final Batch Loss: 0.0479050949215889\n",
      "Epoch 4509, Loss: 0.11110401153564453, Final Batch Loss: 0.04142434149980545\n",
      "Epoch 4510, Loss: 0.14872341603040695, Final Batch Loss: 0.0995706245303154\n",
      "Epoch 4511, Loss: 0.1297181248664856, Final Batch Loss: 0.08241744339466095\n",
      "Epoch 4512, Loss: 0.12963860481977463, Final Batch Loss: 0.0632023736834526\n",
      "Epoch 4513, Loss: 0.14432837441563606, Final Batch Loss: 0.05808902904391289\n",
      "Epoch 4514, Loss: 0.14032452553510666, Final Batch Loss: 0.07086043059825897\n",
      "Epoch 4515, Loss: 0.11780659854412079, Final Batch Loss: 0.08125478029251099\n",
      "Epoch 4516, Loss: 0.10043715685606003, Final Batch Loss: 0.04315756633877754\n",
      "Epoch 4517, Loss: 0.09024825319647789, Final Batch Loss: 0.043189771473407745\n",
      "Epoch 4518, Loss: 0.12337519228458405, Final Batch Loss: 0.08199766278266907\n",
      "Epoch 4519, Loss: 0.09979505091905594, Final Batch Loss: 0.04587510600686073\n",
      "Epoch 4520, Loss: 0.0986434854567051, Final Batch Loss: 0.0447339303791523\n",
      "Epoch 4521, Loss: 0.09353437647223473, Final Batch Loss: 0.03852733597159386\n",
      "Epoch 4522, Loss: 0.1260460652410984, Final Batch Loss: 0.05730186775326729\n",
      "Epoch 4523, Loss: 0.09273863956332207, Final Batch Loss: 0.0436428003013134\n",
      "Epoch 4524, Loss: 0.1274758093059063, Final Batch Loss: 0.07837527245283127\n",
      "Epoch 4525, Loss: 0.08134087920188904, Final Batch Loss: 0.04843611270189285\n",
      "Epoch 4526, Loss: 0.11428128555417061, Final Batch Loss: 0.048067253082990646\n",
      "Epoch 4527, Loss: 0.102618008852005, Final Batch Loss: 0.04404900595545769\n",
      "Epoch 4528, Loss: 0.10143190622329712, Final Batch Loss: 0.06584861129522324\n",
      "Epoch 4529, Loss: 0.12367426976561546, Final Batch Loss: 0.039919380098581314\n",
      "Epoch 4530, Loss: 0.12417132779955864, Final Batch Loss: 0.06506922096014023\n",
      "Epoch 4531, Loss: 0.08502878993749619, Final Batch Loss: 0.043764665722846985\n",
      "Epoch 4532, Loss: 0.14456088095903397, Final Batch Loss: 0.07555430382490158\n",
      "Epoch 4533, Loss: 0.11317728459835052, Final Batch Loss: 0.054041843861341476\n",
      "Epoch 4534, Loss: 0.10760048776865005, Final Batch Loss: 0.04535119980573654\n",
      "Epoch 4535, Loss: 0.10300992801785469, Final Batch Loss: 0.042430419474840164\n",
      "Epoch 4536, Loss: 0.09897025302052498, Final Batch Loss: 0.0323040746152401\n",
      "Epoch 4537, Loss: 0.12661252915859222, Final Batch Loss: 0.05435539782047272\n",
      "Epoch 4538, Loss: 0.12020966038107872, Final Batch Loss: 0.06658238917589188\n",
      "Epoch 4539, Loss: 0.1031797043979168, Final Batch Loss: 0.05698542296886444\n",
      "Epoch 4540, Loss: 0.09224937856197357, Final Batch Loss: 0.051223479211330414\n",
      "Epoch 4541, Loss: 0.11549108475446701, Final Batch Loss: 0.06550180166959763\n",
      "Epoch 4542, Loss: 0.10211167484521866, Final Batch Loss: 0.04325496405363083\n",
      "Epoch 4543, Loss: 0.09011516720056534, Final Batch Loss: 0.037043724209070206\n",
      "Epoch 4544, Loss: 0.10923486575484276, Final Batch Loss: 0.05388979986310005\n",
      "Epoch 4545, Loss: 0.10108842700719833, Final Batch Loss: 0.06356606632471085\n",
      "Epoch 4546, Loss: 0.0911555364727974, Final Batch Loss: 0.05552695691585541\n",
      "Epoch 4547, Loss: 0.10916249081492424, Final Batch Loss: 0.05722323805093765\n",
      "Epoch 4548, Loss: 0.09961898997426033, Final Batch Loss: 0.05205192789435387\n",
      "Epoch 4549, Loss: 0.08851348049938679, Final Batch Loss: 0.029690196737647057\n",
      "Epoch 4550, Loss: 0.107411228120327, Final Batch Loss: 0.06682681292295456\n",
      "Epoch 4551, Loss: 0.07562363147735596, Final Batch Loss: 0.03266642987728119\n",
      "Epoch 4552, Loss: 0.08916652388870716, Final Batch Loss: 0.029510313645005226\n",
      "Epoch 4553, Loss: 0.08230548352003098, Final Batch Loss: 0.03619702160358429\n",
      "Epoch 4554, Loss: 0.10618255659937859, Final Batch Loss: 0.06572820991277695\n",
      "Epoch 4555, Loss: 0.09627510607242584, Final Batch Loss: 0.03943290933966637\n",
      "Epoch 4556, Loss: 0.09106171131134033, Final Batch Loss: 0.04611190780997276\n",
      "Epoch 4557, Loss: 0.08810240402817726, Final Batch Loss: 0.031647998839616776\n",
      "Epoch 4558, Loss: 0.07916901260614395, Final Batch Loss: 0.03596017137169838\n",
      "Epoch 4559, Loss: 0.0796772874891758, Final Batch Loss: 0.029119137674570084\n",
      "Epoch 4560, Loss: 0.09838683530688286, Final Batch Loss: 0.05277533084154129\n",
      "Epoch 4561, Loss: 0.08181693591177464, Final Batch Loss: 0.030653798952698708\n",
      "Epoch 4562, Loss: 0.10241645947098732, Final Batch Loss: 0.0421348474919796\n",
      "Epoch 4563, Loss: 0.1060803160071373, Final Batch Loss: 0.03636164963245392\n",
      "Epoch 4564, Loss: 0.09651745483279228, Final Batch Loss: 0.04241160303354263\n",
      "Epoch 4565, Loss: 0.08176073059439659, Final Batch Loss: 0.032016586512327194\n",
      "Epoch 4566, Loss: 0.09042996168136597, Final Batch Loss: 0.04493887349963188\n",
      "Epoch 4567, Loss: 0.10282734036445618, Final Batch Loss: 0.05918086692690849\n",
      "Epoch 4568, Loss: 0.09101678058505058, Final Batch Loss: 0.0398886501789093\n",
      "Epoch 4569, Loss: 0.08776175603270531, Final Batch Loss: 0.03803541138768196\n",
      "Epoch 4570, Loss: 0.1108015812933445, Final Batch Loss: 0.07704377174377441\n",
      "Epoch 4571, Loss: 0.17323807254433632, Final Batch Loss: 0.12525993585586548\n",
      "Epoch 4572, Loss: 0.09874433279037476, Final Batch Loss: 0.04635332524776459\n",
      "Epoch 4573, Loss: 0.08498910069465637, Final Batch Loss: 0.04261014983057976\n",
      "Epoch 4574, Loss: 0.10114076733589172, Final Batch Loss: 0.05537565425038338\n",
      "Epoch 4575, Loss: 0.13233421742916107, Final Batch Loss: 0.06053858995437622\n",
      "Epoch 4576, Loss: 0.08748854696750641, Final Batch Loss: 0.04781438037753105\n",
      "Epoch 4577, Loss: 0.0870496816933155, Final Batch Loss: 0.03395990654826164\n",
      "Epoch 4578, Loss: 0.07723857834935188, Final Batch Loss: 0.03165135532617569\n",
      "Epoch 4579, Loss: 0.09074834361672401, Final Batch Loss: 0.02958989515900612\n",
      "Epoch 4580, Loss: 0.0881868228316307, Final Batch Loss: 0.03864448890089989\n",
      "Epoch 4581, Loss: 0.08752596378326416, Final Batch Loss: 0.05379746854305267\n",
      "Epoch 4582, Loss: 0.09989800676703453, Final Batch Loss: 0.07793048024177551\n",
      "Epoch 4583, Loss: 0.1296010985970497, Final Batch Loss: 0.06703665852546692\n",
      "Epoch 4584, Loss: 0.10350936651229858, Final Batch Loss: 0.025989636778831482\n",
      "Epoch 4585, Loss: 0.08424561843276024, Final Batch Loss: 0.03899132087826729\n",
      "Epoch 4586, Loss: 0.0907081812620163, Final Batch Loss: 0.057721298187971115\n",
      "Epoch 4587, Loss: 0.09020623192191124, Final Batch Loss: 0.055408403277397156\n",
      "Epoch 4588, Loss: 0.10116354376077652, Final Batch Loss: 0.04405241832137108\n",
      "Epoch 4589, Loss: 0.08588795736432076, Final Batch Loss: 0.05077935755252838\n",
      "Epoch 4590, Loss: 0.08198458142578602, Final Batch Loss: 0.05731472000479698\n",
      "Epoch 4591, Loss: 0.09160854667425156, Final Batch Loss: 0.056048620492219925\n",
      "Epoch 4592, Loss: 0.08162356354296207, Final Batch Loss: 0.021802524104714394\n",
      "Epoch 4593, Loss: 0.11368656158447266, Final Batch Loss: 0.051679324358701706\n",
      "Epoch 4594, Loss: 0.07832246273756027, Final Batch Loss: 0.03230956196784973\n",
      "Epoch 4595, Loss: 0.093844685703516, Final Batch Loss: 0.05648192763328552\n",
      "Epoch 4596, Loss: 0.11527667939662933, Final Batch Loss: 0.06750074774026871\n",
      "Epoch 4597, Loss: 0.11094436049461365, Final Batch Loss: 0.03795189410448074\n",
      "Epoch 4598, Loss: 0.10636000707745552, Final Batch Loss: 0.05868931859731674\n",
      "Epoch 4599, Loss: 0.09666533023118973, Final Batch Loss: 0.06212042272090912\n",
      "Epoch 4600, Loss: 0.09044620394706726, Final Batch Loss: 0.04351610690355301\n",
      "Epoch 4601, Loss: 0.08559183031320572, Final Batch Loss: 0.03388276323676109\n",
      "Epoch 4602, Loss: 0.08409957401454449, Final Batch Loss: 0.030145196244120598\n",
      "Epoch 4603, Loss: 0.0970354899764061, Final Batch Loss: 0.04095238074660301\n",
      "Epoch 4604, Loss: 0.1041301004588604, Final Batch Loss: 0.05539659038186073\n",
      "Epoch 4605, Loss: 0.07635343447327614, Final Batch Loss: 0.03737260773777962\n",
      "Epoch 4606, Loss: 0.0881781354546547, Final Batch Loss: 0.04979414492845535\n",
      "Epoch 4607, Loss: 0.11083044111728668, Final Batch Loss: 0.05583979934453964\n",
      "Epoch 4608, Loss: 0.11382434889674187, Final Batch Loss: 0.05476388335227966\n",
      "Epoch 4609, Loss: 0.1370999589562416, Final Batch Loss: 0.06708645075559616\n",
      "Epoch 4610, Loss: 0.09340664371848106, Final Batch Loss: 0.048116229474544525\n",
      "Epoch 4611, Loss: 0.0858999453485012, Final Batch Loss: 0.03804014250636101\n",
      "Epoch 4612, Loss: 0.08840541914105415, Final Batch Loss: 0.0476614348590374\n",
      "Epoch 4613, Loss: 0.10388992726802826, Final Batch Loss: 0.06498769670724869\n",
      "Epoch 4614, Loss: 0.08745334669947624, Final Batch Loss: 0.04216025769710541\n",
      "Epoch 4615, Loss: 0.1249266229569912, Final Batch Loss: 0.05541114881634712\n",
      "Epoch 4616, Loss: 0.10352767258882523, Final Batch Loss: 0.05623402073979378\n",
      "Epoch 4617, Loss: 0.10305292345583439, Final Batch Loss: 0.02296348847448826\n",
      "Epoch 4618, Loss: 0.11260120570659637, Final Batch Loss: 0.06771442294120789\n",
      "Epoch 4619, Loss: 0.08923577889800072, Final Batch Loss: 0.03394462913274765\n",
      "Epoch 4620, Loss: 0.10097432881593704, Final Batch Loss: 0.06623620539903641\n",
      "Epoch 4621, Loss: 0.09628179296851158, Final Batch Loss: 0.05446983128786087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4622, Loss: 0.09294522181153297, Final Batch Loss: 0.047973860055208206\n",
      "Epoch 4623, Loss: 0.0927330031991005, Final Batch Loss: 0.048617489635944366\n",
      "Epoch 4624, Loss: 0.13518749177455902, Final Batch Loss: 0.07215970754623413\n",
      "Epoch 4625, Loss: 0.09918446466326714, Final Batch Loss: 0.03525276109576225\n",
      "Epoch 4626, Loss: 0.11014808714389801, Final Batch Loss: 0.05627971142530441\n",
      "Epoch 4627, Loss: 0.14446235075592995, Final Batch Loss: 0.08704819530248642\n",
      "Epoch 4628, Loss: 0.12966308742761612, Final Batch Loss: 0.044301584362983704\n",
      "Epoch 4629, Loss: 0.10047056898474693, Final Batch Loss: 0.03572804108262062\n",
      "Epoch 4630, Loss: 0.11820574849843979, Final Batch Loss: 0.0619051530957222\n",
      "Epoch 4631, Loss: 0.08424264192581177, Final Batch Loss: 0.034921031445264816\n",
      "Epoch 4632, Loss: 0.0845007486641407, Final Batch Loss: 0.03922135382890701\n",
      "Epoch 4633, Loss: 0.09758774563670158, Final Batch Loss: 0.05525355786085129\n",
      "Epoch 4634, Loss: 0.10095690563321114, Final Batch Loss: 0.049170468002557755\n",
      "Epoch 4635, Loss: 0.10344172269105911, Final Batch Loss: 0.052979812026023865\n",
      "Epoch 4636, Loss: 0.08809613436460495, Final Batch Loss: 0.03352745994925499\n",
      "Epoch 4637, Loss: 0.08524413034319878, Final Batch Loss: 0.04789755120873451\n",
      "Epoch 4638, Loss: 0.09252016618847847, Final Batch Loss: 0.0332648828625679\n",
      "Epoch 4639, Loss: 0.10629121586680412, Final Batch Loss: 0.07076653093099594\n",
      "Epoch 4640, Loss: 0.09263863787055016, Final Batch Loss: 0.04693690314888954\n",
      "Epoch 4641, Loss: 0.08673306927084923, Final Batch Loss: 0.04093509539961815\n",
      "Epoch 4642, Loss: 0.08869371190667152, Final Batch Loss: 0.03454552963376045\n",
      "Epoch 4643, Loss: 0.09515878930687904, Final Batch Loss: 0.06243351474404335\n",
      "Epoch 4644, Loss: 0.09582417085766792, Final Batch Loss: 0.04904657229781151\n",
      "Epoch 4645, Loss: 0.08617274090647697, Final Batch Loss: 0.050382547080516815\n",
      "Epoch 4646, Loss: 0.1059800535440445, Final Batch Loss: 0.06804299354553223\n",
      "Epoch 4647, Loss: 0.08221060782670975, Final Batch Loss: 0.03967709839344025\n",
      "Epoch 4648, Loss: 0.10188693180680275, Final Batch Loss: 0.04169648885726929\n",
      "Epoch 4649, Loss: 0.08061319217085838, Final Batch Loss: 0.01882656291127205\n",
      "Epoch 4650, Loss: 0.08448275178670883, Final Batch Loss: 0.03535084053874016\n",
      "Epoch 4651, Loss: 0.08548587188124657, Final Batch Loss: 0.04566851630806923\n",
      "Epoch 4652, Loss: 0.08880952000617981, Final Batch Loss: 0.043455734848976135\n",
      "Epoch 4653, Loss: 0.11030473187565804, Final Batch Loss: 0.035897526890039444\n",
      "Epoch 4654, Loss: 0.09534166380763054, Final Batch Loss: 0.03414691612124443\n",
      "Epoch 4655, Loss: 0.07712276093661785, Final Batch Loss: 0.020421428605914116\n",
      "Epoch 4656, Loss: 0.1053021065890789, Final Batch Loss: 0.042907774448394775\n",
      "Epoch 4657, Loss: 0.11243394017219543, Final Batch Loss: 0.053109027445316315\n",
      "Epoch 4658, Loss: 0.09450944140553474, Final Batch Loss: 0.050632718950510025\n",
      "Epoch 4659, Loss: 0.11676615849137306, Final Batch Loss: 0.06964560598134995\n",
      "Epoch 4660, Loss: 0.09786539152264595, Final Batch Loss: 0.06375828385353088\n",
      "Epoch 4661, Loss: 0.09533414989709854, Final Batch Loss: 0.028732657432556152\n",
      "Epoch 4662, Loss: 0.08725206553936005, Final Batch Loss: 0.03660028055310249\n",
      "Epoch 4663, Loss: 0.09193950518965721, Final Batch Loss: 0.04134432226419449\n",
      "Epoch 4664, Loss: 0.07406402565538883, Final Batch Loss: 0.029321031644940376\n",
      "Epoch 4665, Loss: 0.08140095695853233, Final Batch Loss: 0.04178823158144951\n",
      "Epoch 4666, Loss: 0.08985764160752296, Final Batch Loss: 0.049356892704963684\n",
      "Epoch 4667, Loss: 0.0846068486571312, Final Batch Loss: 0.05009126290678978\n",
      "Epoch 4668, Loss: 0.0792724434286356, Final Batch Loss: 0.028232408687472343\n",
      "Epoch 4669, Loss: 0.08400079607963562, Final Batch Loss: 0.03395329415798187\n",
      "Epoch 4670, Loss: 0.09714779630303383, Final Batch Loss: 0.0620214119553566\n",
      "Epoch 4671, Loss: 0.08444616198539734, Final Batch Loss: 0.04759445786476135\n",
      "Epoch 4672, Loss: 0.10090839117765427, Final Batch Loss: 0.06631103157997131\n",
      "Epoch 4673, Loss: 0.08092844486236572, Final Batch Loss: 0.045341309159994125\n",
      "Epoch 4674, Loss: 0.082317054271698, Final Batch Loss: 0.032983262091875076\n",
      "Epoch 4675, Loss: 0.11905656009912491, Final Batch Loss: 0.06440039724111557\n",
      "Epoch 4676, Loss: 0.07821546122431755, Final Batch Loss: 0.04845964163541794\n",
      "Epoch 4677, Loss: 0.11531516164541245, Final Batch Loss: 0.08534050732851028\n",
      "Epoch 4678, Loss: 0.07765927910804749, Final Batch Loss: 0.03490675985813141\n",
      "Epoch 4679, Loss: 0.09015125408768654, Final Batch Loss: 0.03566150739789009\n",
      "Epoch 4680, Loss: 0.08606556430459023, Final Batch Loss: 0.04876277968287468\n",
      "Epoch 4681, Loss: 0.07874573022127151, Final Batch Loss: 0.04401702061295509\n",
      "Epoch 4682, Loss: 0.13875296711921692, Final Batch Loss: 0.10460790991783142\n",
      "Epoch 4683, Loss: 0.0884246714413166, Final Batch Loss: 0.03401836007833481\n",
      "Epoch 4684, Loss: 0.10922284424304962, Final Batch Loss: 0.08223148435354233\n",
      "Epoch 4685, Loss: 0.0985686257481575, Final Batch Loss: 0.06206107884645462\n",
      "Epoch 4686, Loss: 0.07465196773409843, Final Batch Loss: 0.03304435312747955\n",
      "Epoch 4687, Loss: 0.08911669999361038, Final Batch Loss: 0.054983951151371\n",
      "Epoch 4688, Loss: 0.10353163257241249, Final Batch Loss: 0.03736067935824394\n",
      "Epoch 4689, Loss: 0.08634432032704353, Final Batch Loss: 0.03453992307186127\n",
      "Epoch 4690, Loss: 0.07614935375750065, Final Batch Loss: 0.02960309199988842\n",
      "Epoch 4691, Loss: 0.08185732364654541, Final Batch Loss: 0.0386919341981411\n",
      "Epoch 4692, Loss: 0.09307930245995522, Final Batch Loss: 0.0529070720076561\n",
      "Epoch 4693, Loss: 0.09470180422067642, Final Batch Loss: 0.050272952765226364\n",
      "Epoch 4694, Loss: 0.1042710617184639, Final Batch Loss: 0.08160295337438583\n",
      "Epoch 4695, Loss: 0.0858255997300148, Final Batch Loss: 0.0429607518017292\n",
      "Epoch 4696, Loss: 0.08391508460044861, Final Batch Loss: 0.02809680625796318\n",
      "Epoch 4697, Loss: 0.09503092989325523, Final Batch Loss: 0.05470719933509827\n",
      "Epoch 4698, Loss: 0.10127584263682365, Final Batch Loss: 0.04061233252286911\n",
      "Epoch 4699, Loss: 0.10038528218865395, Final Batch Loss: 0.0665990561246872\n",
      "Epoch 4700, Loss: 0.13524236157536507, Final Batch Loss: 0.05077106133103371\n",
      "Epoch 4701, Loss: 0.11255869269371033, Final Batch Loss: 0.056786470115184784\n",
      "Epoch 4702, Loss: 0.10547828674316406, Final Batch Loss: 0.06738010793924332\n",
      "Epoch 4703, Loss: 0.08380389958620071, Final Batch Loss: 0.03793595731258392\n",
      "Epoch 4704, Loss: 0.0832141786813736, Final Batch Loss: 0.03982331603765488\n",
      "Epoch 4705, Loss: 0.08648480847477913, Final Batch Loss: 0.03056218847632408\n",
      "Epoch 4706, Loss: 0.0807761624455452, Final Batch Loss: 0.02718941867351532\n",
      "Epoch 4707, Loss: 0.08086755871772766, Final Batch Loss: 0.03471093252301216\n",
      "Epoch 4708, Loss: 0.08357651717960835, Final Batch Loss: 0.057688552886247635\n",
      "Epoch 4709, Loss: 0.09311913698911667, Final Batch Loss: 0.05144341662526131\n",
      "Epoch 4710, Loss: 0.07530918531119823, Final Batch Loss: 0.04519570246338844\n",
      "Epoch 4711, Loss: 0.0847613736987114, Final Batch Loss: 0.03669889271259308\n",
      "Epoch 4712, Loss: 0.09637711569666862, Final Batch Loss: 0.03645099699497223\n",
      "Epoch 4713, Loss: 0.08533896505832672, Final Batch Loss: 0.03842389956116676\n",
      "Epoch 4714, Loss: 0.09493117779493332, Final Batch Loss: 0.055438071489334106\n",
      "Epoch 4715, Loss: 0.12890399992465973, Final Batch Loss: 0.07504918426275253\n",
      "Epoch 4716, Loss: 0.09790948033332825, Final Batch Loss: 0.05316975340247154\n",
      "Epoch 4717, Loss: 0.08490767702460289, Final Batch Loss: 0.05119020864367485\n",
      "Epoch 4718, Loss: 0.09525410458445549, Final Batch Loss: 0.049567945301532745\n",
      "Epoch 4719, Loss: 0.08346044272184372, Final Batch Loss: 0.037902869284152985\n",
      "Epoch 4720, Loss: 0.0826309360563755, Final Batch Loss: 0.04986032471060753\n",
      "Epoch 4721, Loss: 0.08537391573190689, Final Batch Loss: 0.027410060167312622\n",
      "Epoch 4722, Loss: 0.1050075925886631, Final Batch Loss: 0.047406308352947235\n",
      "Epoch 4723, Loss: 0.0954003632068634, Final Batch Loss: 0.04587173834443092\n",
      "Epoch 4724, Loss: 0.0923035480082035, Final Batch Loss: 0.039762817323207855\n",
      "Epoch 4725, Loss: 0.08610327169299126, Final Batch Loss: 0.03971641883254051\n",
      "Epoch 4726, Loss: 0.12958280742168427, Final Batch Loss: 0.0768202468752861\n",
      "Epoch 4727, Loss: 0.08116113394498825, Final Batch Loss: 0.041611503809690475\n",
      "Epoch 4728, Loss: 0.09432548098266125, Final Batch Loss: 0.06420524418354034\n",
      "Epoch 4729, Loss: 0.07770227640867233, Final Batch Loss: 0.05122242122888565\n",
      "Epoch 4730, Loss: 0.0969523936510086, Final Batch Loss: 0.04994026944041252\n",
      "Epoch 4731, Loss: 0.10617100074887276, Final Batch Loss: 0.06779437512159348\n",
      "Epoch 4732, Loss: 0.08433618396520615, Final Batch Loss: 0.03915974870324135\n",
      "Epoch 4733, Loss: 0.10757520794868469, Final Batch Loss: 0.07048310339450836\n",
      "Epoch 4734, Loss: 0.09575054422020912, Final Batch Loss: 0.05936020612716675\n",
      "Epoch 4735, Loss: 0.10352445766329765, Final Batch Loss: 0.06051214411854744\n",
      "Epoch 4736, Loss: 0.09807730838656425, Final Batch Loss: 0.04593484848737717\n",
      "Epoch 4737, Loss: 0.10443862900137901, Final Batch Loss: 0.05390399321913719\n",
      "Epoch 4738, Loss: 0.0930953361093998, Final Batch Loss: 0.06026357784867287\n",
      "Epoch 4739, Loss: 0.10602680966258049, Final Batch Loss: 0.05577715113759041\n",
      "Epoch 4740, Loss: 0.091354850679636, Final Batch Loss: 0.05227460712194443\n",
      "Epoch 4741, Loss: 0.09846898540854454, Final Batch Loss: 0.06324419379234314\n",
      "Epoch 4742, Loss: 0.08346235379576683, Final Batch Loss: 0.038197021931409836\n",
      "Epoch 4743, Loss: 0.07743267342448235, Final Batch Loss: 0.03961033374071121\n",
      "Epoch 4744, Loss: 0.07533223927021027, Final Batch Loss: 0.0330834724009037\n",
      "Epoch 4745, Loss: 0.12529072910547256, Final Batch Loss: 0.09248398244380951\n",
      "Epoch 4746, Loss: 0.1188867948949337, Final Batch Loss: 0.07863329350948334\n",
      "Epoch 4747, Loss: 0.08214962854981422, Final Batch Loss: 0.03646564111113548\n",
      "Epoch 4748, Loss: 0.09294625371694565, Final Batch Loss: 0.03858121857047081\n",
      "Epoch 4749, Loss: 0.0996498204767704, Final Batch Loss: 0.026134859770536423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4750, Loss: 0.13907189667224884, Final Batch Loss: 0.06911943852901459\n",
      "Epoch 4751, Loss: 0.09039301052689552, Final Batch Loss: 0.041532643139362335\n",
      "Epoch 4752, Loss: 0.08901868760585785, Final Batch Loss: 0.04495299980044365\n",
      "Epoch 4753, Loss: 0.0864651557058096, Final Batch Loss: 0.02699785865843296\n",
      "Epoch 4754, Loss: 0.10172628238797188, Final Batch Loss: 0.03774956241250038\n",
      "Epoch 4755, Loss: 0.0929366908967495, Final Batch Loss: 0.0561516173183918\n",
      "Epoch 4756, Loss: 0.1410645693540573, Final Batch Loss: 0.04651271551847458\n",
      "Epoch 4757, Loss: 0.09934911131858826, Final Batch Loss: 0.04794040694832802\n",
      "Epoch 4758, Loss: 0.10200361907482147, Final Batch Loss: 0.04939728230237961\n",
      "Epoch 4759, Loss: 0.09400519356131554, Final Batch Loss: 0.047594863921403885\n",
      "Epoch 4760, Loss: 0.09719153121113777, Final Batch Loss: 0.04554501920938492\n",
      "Epoch 4761, Loss: 0.10201752558350563, Final Batch Loss: 0.05210988596081734\n",
      "Epoch 4762, Loss: 0.09349725767970085, Final Batch Loss: 0.05228007212281227\n",
      "Epoch 4763, Loss: 0.08736100792884827, Final Batch Loss: 0.0401885099709034\n",
      "Epoch 4764, Loss: 0.08559238910675049, Final Batch Loss: 0.03847915306687355\n",
      "Epoch 4765, Loss: 0.08954144641757011, Final Batch Loss: 0.041959039866924286\n",
      "Epoch 4766, Loss: 0.07902202755212784, Final Batch Loss: 0.03784267604351044\n",
      "Epoch 4767, Loss: 0.09388106316328049, Final Batch Loss: 0.049571964889764786\n",
      "Epoch 4768, Loss: 0.1029435582458973, Final Batch Loss: 0.04662713035941124\n",
      "Epoch 4769, Loss: 0.09940748289227486, Final Batch Loss: 0.048065800219774246\n",
      "Epoch 4770, Loss: 0.09172524884343147, Final Batch Loss: 0.03477160260081291\n",
      "Epoch 4771, Loss: 0.11430436000227928, Final Batch Loss: 0.07478153705596924\n",
      "Epoch 4772, Loss: 0.10032488033175468, Final Batch Loss: 0.04511014744639397\n",
      "Epoch 4773, Loss: 0.08054408431053162, Final Batch Loss: 0.0350482314825058\n",
      "Epoch 4774, Loss: 0.13014379888772964, Final Batch Loss: 0.07638806849718094\n",
      "Epoch 4775, Loss: 0.09766696393489838, Final Batch Loss: 0.05015498399734497\n",
      "Epoch 4776, Loss: 0.08042258769273758, Final Batch Loss: 0.021520942449569702\n",
      "Epoch 4777, Loss: 0.08391622453927994, Final Batch Loss: 0.025062374770641327\n",
      "Epoch 4778, Loss: 0.1213873028755188, Final Batch Loss: 0.062165744602680206\n",
      "Epoch 4779, Loss: 0.09609609097242355, Final Batch Loss: 0.04898671805858612\n",
      "Epoch 4780, Loss: 0.11243721470236778, Final Batch Loss: 0.041213508695364\n",
      "Epoch 4781, Loss: 0.09426074847579002, Final Batch Loss: 0.045033786445856094\n",
      "Epoch 4782, Loss: 0.1410573460161686, Final Batch Loss: 0.03229590877890587\n",
      "Epoch 4783, Loss: 0.13262499496340752, Final Batch Loss: 0.07655366510152817\n",
      "Epoch 4784, Loss: 0.1013917401432991, Final Batch Loss: 0.039649903774261475\n",
      "Epoch 4785, Loss: 0.08570669963955879, Final Batch Loss: 0.04782677814364433\n",
      "Epoch 4786, Loss: 0.09009488299489021, Final Batch Loss: 0.0329437218606472\n",
      "Epoch 4787, Loss: 0.0870244912803173, Final Batch Loss: 0.033773135393857956\n",
      "Epoch 4788, Loss: 0.0993642508983612, Final Batch Loss: 0.04618632048368454\n",
      "Epoch 4789, Loss: 0.11653826385736465, Final Batch Loss: 0.06432071328163147\n",
      "Epoch 4790, Loss: 0.12218167260289192, Final Batch Loss: 0.07454415410757065\n",
      "Epoch 4791, Loss: 0.10196526348590851, Final Batch Loss: 0.028319664299488068\n",
      "Epoch 4792, Loss: 0.10220706835389137, Final Batch Loss: 0.06210394948720932\n",
      "Epoch 4793, Loss: 0.07730195298790932, Final Batch Loss: 0.03903103992342949\n",
      "Epoch 4794, Loss: 0.0825476236641407, Final Batch Loss: 0.039227232336997986\n",
      "Epoch 4795, Loss: 0.09277697280049324, Final Batch Loss: 0.058783043175935745\n",
      "Epoch 4796, Loss: 0.10502506420016289, Final Batch Loss: 0.06158208101987839\n",
      "Epoch 4797, Loss: 0.09146927669644356, Final Batch Loss: 0.04666680097579956\n",
      "Epoch 4798, Loss: 0.07977567613124847, Final Batch Loss: 0.04497912526130676\n",
      "Epoch 4799, Loss: 0.09488960728049278, Final Batch Loss: 0.04378748685121536\n",
      "Epoch 4800, Loss: 0.0855763666331768, Final Batch Loss: 0.04659607261419296\n",
      "Epoch 4801, Loss: 0.08537643775343895, Final Batch Loss: 0.02361253648996353\n",
      "Epoch 4802, Loss: 0.09354187548160553, Final Batch Loss: 0.04989154636859894\n",
      "Epoch 4803, Loss: 0.08856061473488808, Final Batch Loss: 0.026618052273988724\n",
      "Epoch 4804, Loss: 0.10024256259202957, Final Batch Loss: 0.05913611501455307\n",
      "Epoch 4805, Loss: 0.11527938395738602, Final Batch Loss: 0.06530560553073883\n",
      "Epoch 4806, Loss: 0.09478935599327087, Final Batch Loss: 0.04791206121444702\n",
      "Epoch 4807, Loss: 0.07480491697788239, Final Batch Loss: 0.034147679805755615\n",
      "Epoch 4808, Loss: 0.08094795048236847, Final Batch Loss: 0.03767343983054161\n",
      "Epoch 4809, Loss: 0.08752185478806496, Final Batch Loss: 0.05091170221567154\n",
      "Epoch 4810, Loss: 0.09652182087302208, Final Batch Loss: 0.04929410293698311\n",
      "Epoch 4811, Loss: 0.10696030780673027, Final Batch Loss: 0.07169324904680252\n",
      "Epoch 4812, Loss: 0.08571133762598038, Final Batch Loss: 0.03161197155714035\n",
      "Epoch 4813, Loss: 0.12784744426608086, Final Batch Loss: 0.03594033047556877\n",
      "Epoch 4814, Loss: 0.09995219483971596, Final Batch Loss: 0.04661611467599869\n",
      "Epoch 4815, Loss: 0.10880982875823975, Final Batch Loss: 0.0346648171544075\n",
      "Epoch 4816, Loss: 0.10240166634321213, Final Batch Loss: 0.040665846318006516\n",
      "Epoch 4817, Loss: 0.08423731848597527, Final Batch Loss: 0.04019672051072121\n",
      "Epoch 4818, Loss: 0.08134174905717373, Final Batch Loss: 0.024239638820290565\n",
      "Epoch 4819, Loss: 0.10851162299513817, Final Batch Loss: 0.05969824641942978\n",
      "Epoch 4820, Loss: 0.09222922846674919, Final Batch Loss: 0.043092768639326096\n",
      "Epoch 4821, Loss: 0.08597943559288979, Final Batch Loss: 0.05098448693752289\n",
      "Epoch 4822, Loss: 0.12122855335474014, Final Batch Loss: 0.05154271423816681\n",
      "Epoch 4823, Loss: 0.08481570705771446, Final Batch Loss: 0.02325911447405815\n",
      "Epoch 4824, Loss: 0.1211792454123497, Final Batch Loss: 0.07726261019706726\n",
      "Epoch 4825, Loss: 0.1327349953353405, Final Batch Loss: 0.09601485729217529\n",
      "Epoch 4826, Loss: 0.07672454416751862, Final Batch Loss: 0.03372497484087944\n",
      "Epoch 4827, Loss: 0.09450482949614525, Final Batch Loss: 0.027816656976938248\n",
      "Epoch 4828, Loss: 0.07199742645025253, Final Batch Loss: 0.03815263509750366\n",
      "Epoch 4829, Loss: 0.09487282484769821, Final Batch Loss: 0.05478973314166069\n",
      "Epoch 4830, Loss: 0.08093356341123581, Final Batch Loss: 0.04229913279414177\n",
      "Epoch 4831, Loss: 0.10330259427428246, Final Batch Loss: 0.049403659999370575\n",
      "Epoch 4832, Loss: 0.09241526573896408, Final Batch Loss: 0.05019303038716316\n",
      "Epoch 4833, Loss: 0.09646625444293022, Final Batch Loss: 0.06131666526198387\n",
      "Epoch 4834, Loss: 0.12105874717235565, Final Batch Loss: 0.05013079196214676\n",
      "Epoch 4835, Loss: 0.1186610795557499, Final Batch Loss: 0.053290706127882004\n",
      "Epoch 4836, Loss: 0.11984985694289207, Final Batch Loss: 0.01729997619986534\n",
      "Epoch 4837, Loss: 0.08420230448246002, Final Batch Loss: 0.0404229611158371\n",
      "Epoch 4838, Loss: 0.06977536901831627, Final Batch Loss: 0.03834100067615509\n",
      "Epoch 4839, Loss: 0.11857715994119644, Final Batch Loss: 0.045125216245651245\n",
      "Epoch 4840, Loss: 0.09083830565214157, Final Batch Loss: 0.04025270417332649\n",
      "Epoch 4841, Loss: 0.0997181311249733, Final Batch Loss: 0.06093446537852287\n",
      "Epoch 4842, Loss: 0.10552430897951126, Final Batch Loss: 0.040218666195869446\n",
      "Epoch 4843, Loss: 0.09200821071863174, Final Batch Loss: 0.043685946613550186\n",
      "Epoch 4844, Loss: 0.09421718120574951, Final Batch Loss: 0.060232218354940414\n",
      "Epoch 4845, Loss: 0.09623800218105316, Final Batch Loss: 0.0416441410779953\n",
      "Epoch 4846, Loss: 0.0814327821135521, Final Batch Loss: 0.039601102471351624\n",
      "Epoch 4847, Loss: 0.09838323667645454, Final Batch Loss: 0.04473353549838066\n",
      "Epoch 4848, Loss: 0.12777520343661308, Final Batch Loss: 0.06567027419805527\n",
      "Epoch 4849, Loss: 0.09421247616410255, Final Batch Loss: 0.03218437731266022\n",
      "Epoch 4850, Loss: 0.08299661055207253, Final Batch Loss: 0.035704124718904495\n",
      "Epoch 4851, Loss: 0.09343583136796951, Final Batch Loss: 0.04263127222657204\n",
      "Epoch 4852, Loss: 0.07992701232433319, Final Batch Loss: 0.03671014681458473\n",
      "Epoch 4853, Loss: 0.08899228647351265, Final Batch Loss: 0.03508938103914261\n",
      "Epoch 4854, Loss: 0.08007420226931572, Final Batch Loss: 0.03049323335289955\n",
      "Epoch 4855, Loss: 0.11079759523272514, Final Batch Loss: 0.06715653091669083\n",
      "Epoch 4856, Loss: 0.10805120319128036, Final Batch Loss: 0.040843747556209564\n",
      "Epoch 4857, Loss: 0.10579822584986687, Final Batch Loss: 0.045118119567632675\n",
      "Epoch 4858, Loss: 0.09346598386764526, Final Batch Loss: 0.046339523047208786\n",
      "Epoch 4859, Loss: 0.10217827558517456, Final Batch Loss: 0.04893716797232628\n",
      "Epoch 4860, Loss: 0.09422437474131584, Final Batch Loss: 0.038527119904756546\n",
      "Epoch 4861, Loss: 0.124368105083704, Final Batch Loss: 0.08715610206127167\n",
      "Epoch 4862, Loss: 0.09935563430190086, Final Batch Loss: 0.04458387568593025\n",
      "Epoch 4863, Loss: 0.1499171406030655, Final Batch Loss: 0.09558867663145065\n",
      "Epoch 4864, Loss: 0.09262503869831562, Final Batch Loss: 0.03027619980275631\n",
      "Epoch 4865, Loss: 0.11254918575286865, Final Batch Loss: 0.08143145591020584\n",
      "Epoch 4866, Loss: 0.09459461271762848, Final Batch Loss: 0.05219521000981331\n",
      "Epoch 4867, Loss: 0.14385583996772766, Final Batch Loss: 0.06297856569290161\n",
      "Epoch 4868, Loss: 0.09161540120840073, Final Batch Loss: 0.036023691296577454\n",
      "Epoch 4869, Loss: 0.10387394949793816, Final Batch Loss: 0.04148213192820549\n",
      "Epoch 4870, Loss: 0.09045068547129631, Final Batch Loss: 0.017563533037900925\n",
      "Epoch 4871, Loss: 0.18922918662428856, Final Batch Loss: 0.062029313296079636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4872, Loss: 0.09016014263033867, Final Batch Loss: 0.04863593354821205\n",
      "Epoch 4873, Loss: 0.08907696232199669, Final Batch Loss: 0.019368071109056473\n",
      "Epoch 4874, Loss: 0.09658830240368843, Final Batch Loss: 0.06251917779445648\n",
      "Epoch 4875, Loss: 0.08732975460588932, Final Batch Loss: 0.02604779414832592\n",
      "Epoch 4876, Loss: 0.10135439410805702, Final Batch Loss: 0.05283473804593086\n",
      "Epoch 4877, Loss: 0.09656842052936554, Final Batch Loss: 0.05809721350669861\n",
      "Epoch 4878, Loss: 0.10247951000928879, Final Batch Loss: 0.05926154926419258\n",
      "Epoch 4879, Loss: 0.11462432146072388, Final Batch Loss: 0.0706796646118164\n",
      "Epoch 4880, Loss: 0.09321613609790802, Final Batch Loss: 0.05537528172135353\n",
      "Epoch 4881, Loss: 0.08745510876178741, Final Batch Loss: 0.051938582211732864\n",
      "Epoch 4882, Loss: 0.08816709741950035, Final Batch Loss: 0.05153356119990349\n",
      "Epoch 4883, Loss: 0.09073716774582863, Final Batch Loss: 0.044584643095731735\n",
      "Epoch 4884, Loss: 0.08614088222384453, Final Batch Loss: 0.04604707285761833\n",
      "Epoch 4885, Loss: 0.09780379757285118, Final Batch Loss: 0.0441497303545475\n",
      "Epoch 4886, Loss: 0.10124674439430237, Final Batch Loss: 0.04944468289613724\n",
      "Epoch 4887, Loss: 0.08981624990701675, Final Batch Loss: 0.04675696790218353\n",
      "Epoch 4888, Loss: 0.10131765529513359, Final Batch Loss: 0.060069337487220764\n",
      "Epoch 4889, Loss: 0.09160033613443375, Final Batch Loss: 0.03183911740779877\n",
      "Epoch 4890, Loss: 0.09984887763857841, Final Batch Loss: 0.05669672414660454\n",
      "Epoch 4891, Loss: 0.09040636941790581, Final Batch Loss: 0.03843212127685547\n",
      "Epoch 4892, Loss: 0.09065593779087067, Final Batch Loss: 0.04878880828619003\n",
      "Epoch 4893, Loss: 0.11283892765641212, Final Batch Loss: 0.041870784014463425\n",
      "Epoch 4894, Loss: 0.09737058728933334, Final Batch Loss: 0.05256548896431923\n",
      "Epoch 4895, Loss: 0.08229278773069382, Final Batch Loss: 0.04923705384135246\n",
      "Epoch 4896, Loss: 0.10138429701328278, Final Batch Loss: 0.05116788297891617\n",
      "Epoch 4897, Loss: 0.08801256865262985, Final Batch Loss: 0.0437098853290081\n",
      "Epoch 4898, Loss: 0.08532258495688438, Final Batch Loss: 0.046506039798259735\n",
      "Epoch 4899, Loss: 0.08291354030370712, Final Batch Loss: 0.03837745636701584\n",
      "Epoch 4900, Loss: 0.09435148164629936, Final Batch Loss: 0.06020238250494003\n",
      "Epoch 4901, Loss: 0.10225549712777138, Final Batch Loss: 0.06611449271440506\n",
      "Epoch 4902, Loss: 0.09546183049678802, Final Batch Loss: 0.04410463571548462\n",
      "Epoch 4903, Loss: 0.10545960441231728, Final Batch Loss: 0.04692143201828003\n",
      "Epoch 4904, Loss: 0.08075683563947678, Final Batch Loss: 0.04733710363507271\n",
      "Epoch 4905, Loss: 0.08708908036351204, Final Batch Loss: 0.06411689519882202\n",
      "Epoch 4906, Loss: 0.11084248498082161, Final Batch Loss: 0.04354317858815193\n",
      "Epoch 4907, Loss: 0.09665681794285774, Final Batch Loss: 0.03305615857243538\n",
      "Epoch 4908, Loss: 0.07798623479902744, Final Batch Loss: 0.0262946505099535\n",
      "Epoch 4909, Loss: 0.08166059851646423, Final Batch Loss: 0.04758697748184204\n",
      "Epoch 4910, Loss: 0.08463859185576439, Final Batch Loss: 0.03391455486416817\n",
      "Epoch 4911, Loss: 0.08616942539811134, Final Batch Loss: 0.05043281614780426\n",
      "Epoch 4912, Loss: 0.09100592881441116, Final Batch Loss: 0.043636906892061234\n",
      "Epoch 4913, Loss: 0.08698352426290512, Final Batch Loss: 0.04388921707868576\n",
      "Epoch 4914, Loss: 0.08112925663590431, Final Batch Loss: 0.038370441645383835\n",
      "Epoch 4915, Loss: 0.08042925596237183, Final Batch Loss: 0.0447583943605423\n",
      "Epoch 4916, Loss: 0.09210081771016121, Final Batch Loss: 0.0517517626285553\n",
      "Epoch 4917, Loss: 0.09197304025292397, Final Batch Loss: 0.055561624467372894\n",
      "Epoch 4918, Loss: 0.08711083978414536, Final Batch Loss: 0.047771308571100235\n",
      "Epoch 4919, Loss: 0.10002053156495094, Final Batch Loss: 0.04571180418133736\n",
      "Epoch 4920, Loss: 0.09565800055861473, Final Batch Loss: 0.045557789504528046\n",
      "Epoch 4921, Loss: 0.08746903017163277, Final Batch Loss: 0.0375681072473526\n",
      "Epoch 4922, Loss: 0.094950120896101, Final Batch Loss: 0.04656476154923439\n",
      "Epoch 4923, Loss: 0.09870906174182892, Final Batch Loss: 0.0458599328994751\n",
      "Epoch 4924, Loss: 0.10040633007884026, Final Batch Loss: 0.07485496997833252\n",
      "Epoch 4925, Loss: 0.11420640721917152, Final Batch Loss: 0.0562698058784008\n",
      "Epoch 4926, Loss: 0.08874496817588806, Final Batch Loss: 0.050403039902448654\n",
      "Epoch 4927, Loss: 0.08102896623313427, Final Batch Loss: 0.027830185368657112\n",
      "Epoch 4928, Loss: 0.08225864544510841, Final Batch Loss: 0.04099650681018829\n",
      "Epoch 4929, Loss: 0.09145534038543701, Final Batch Loss: 0.04503561556339264\n",
      "Epoch 4930, Loss: 0.10910891741514206, Final Batch Loss: 0.07244860380887985\n",
      "Epoch 4931, Loss: 0.093015156686306, Final Batch Loss: 0.05677245929837227\n",
      "Epoch 4932, Loss: 0.10175488516688347, Final Batch Loss: 0.06189379096031189\n",
      "Epoch 4933, Loss: 0.11025375500321388, Final Batch Loss: 0.056456826627254486\n",
      "Epoch 4934, Loss: 0.13460296764969826, Final Batch Loss: 0.05470134690403938\n",
      "Epoch 4935, Loss: 0.09308253973722458, Final Batch Loss: 0.031703539192676544\n",
      "Epoch 4936, Loss: 0.08992233499884605, Final Batch Loss: 0.05078919604420662\n",
      "Epoch 4937, Loss: 0.08389017544686794, Final Batch Loss: 0.0284449253231287\n",
      "Epoch 4938, Loss: 0.09962477162480354, Final Batch Loss: 0.056650612503290176\n",
      "Epoch 4939, Loss: 0.09495378285646439, Final Batch Loss: 0.05069794878363609\n",
      "Epoch 4940, Loss: 0.08032934740185738, Final Batch Loss: 0.04331435263156891\n",
      "Epoch 4941, Loss: 0.1026784386485815, Final Batch Loss: 0.07632694393396378\n",
      "Epoch 4942, Loss: 0.0973237119615078, Final Batch Loss: 0.07385045289993286\n",
      "Epoch 4943, Loss: 0.07913770154118538, Final Batch Loss: 0.030582241714000702\n",
      "Epoch 4944, Loss: 0.11139396950602531, Final Batch Loss: 0.0568978413939476\n",
      "Epoch 4945, Loss: 0.08985041454434395, Final Batch Loss: 0.05972432717680931\n",
      "Epoch 4946, Loss: 0.1740512028336525, Final Batch Loss: 0.10857974737882614\n",
      "Epoch 4947, Loss: 0.10823310911655426, Final Batch Loss: 0.056351594626903534\n",
      "Epoch 4948, Loss: 0.1178802028298378, Final Batch Loss: 0.06739679723978043\n",
      "Epoch 4949, Loss: 0.0980515256524086, Final Batch Loss: 0.04992241784930229\n",
      "Epoch 4950, Loss: 0.1025005653500557, Final Batch Loss: 0.03228846937417984\n",
      "Epoch 4951, Loss: 0.1170562282204628, Final Batch Loss: 0.07619713246822357\n",
      "Epoch 4952, Loss: 0.09400233998894691, Final Batch Loss: 0.04240432009100914\n",
      "Epoch 4953, Loss: 0.09160708636045456, Final Batch Loss: 0.04107995703816414\n",
      "Epoch 4954, Loss: 0.08334175124764442, Final Batch Loss: 0.04899551346898079\n",
      "Epoch 4955, Loss: 0.13738521933555603, Final Batch Loss: 0.05257031321525574\n",
      "Epoch 4956, Loss: 0.08583740517497063, Final Batch Loss: 0.0353754460811615\n",
      "Epoch 4957, Loss: 0.09038005396723747, Final Batch Loss: 0.050641972571611404\n",
      "Epoch 4958, Loss: 0.08558231964707375, Final Batch Loss: 0.04733237624168396\n",
      "Epoch 4959, Loss: 0.07723318226635456, Final Batch Loss: 0.028960129246115685\n",
      "Epoch 4960, Loss: 0.09845725074410439, Final Batch Loss: 0.03473981097340584\n",
      "Epoch 4961, Loss: 0.09002590924501419, Final Batch Loss: 0.03598088398575783\n",
      "Epoch 4962, Loss: 0.09360270574688911, Final Batch Loss: 0.047162286937236786\n",
      "Epoch 4963, Loss: 0.08081942796707153, Final Batch Loss: 0.04317348077893257\n",
      "Epoch 4964, Loss: 0.07033388502895832, Final Batch Loss: 0.03058946691453457\n",
      "Epoch 4965, Loss: 0.11849255487322807, Final Batch Loss: 0.08627031743526459\n",
      "Epoch 4966, Loss: 0.08617319911718369, Final Batch Loss: 0.045613355934619904\n",
      "Epoch 4967, Loss: 0.08657292276620865, Final Batch Loss: 0.040080517530441284\n",
      "Epoch 4968, Loss: 0.07212468609213829, Final Batch Loss: 0.02652161195874214\n",
      "Epoch 4969, Loss: 0.08576978370547295, Final Batch Loss: 0.04527977108955383\n",
      "Epoch 4970, Loss: 0.10277079977095127, Final Batch Loss: 0.02067151851952076\n",
      "Epoch 4971, Loss: 0.10918701067566872, Final Batch Loss: 0.06599391251802444\n",
      "Epoch 4972, Loss: 0.1320987530052662, Final Batch Loss: 0.04971927031874657\n",
      "Epoch 4973, Loss: 0.10085490345954895, Final Batch Loss: 0.029682181775569916\n",
      "Epoch 4974, Loss: 0.09690109640359879, Final Batch Loss: 0.05291037634015083\n",
      "Epoch 4975, Loss: 0.08057840168476105, Final Batch Loss: 0.03857940435409546\n",
      "Epoch 4976, Loss: 0.11045770347118378, Final Batch Loss: 0.05179835483431816\n",
      "Epoch 4977, Loss: 0.10722978785634041, Final Batch Loss: 0.03769860789179802\n",
      "Epoch 4978, Loss: 0.07939280197024345, Final Batch Loss: 0.03440430387854576\n",
      "Epoch 4979, Loss: 0.08286546543240547, Final Batch Loss: 0.03447715938091278\n",
      "Epoch 4980, Loss: 0.0731237381696701, Final Batch Loss: 0.04535696282982826\n",
      "Epoch 4981, Loss: 0.08526619896292686, Final Batch Loss: 0.024377282708883286\n",
      "Epoch 4982, Loss: 0.10224287956953049, Final Batch Loss: 0.0551440566778183\n",
      "Epoch 4983, Loss: 0.16412591934204102, Final Batch Loss: 0.11790269613265991\n",
      "Epoch 4984, Loss: 0.09275162220001221, Final Batch Loss: 0.047020744532346725\n",
      "Epoch 4985, Loss: 0.07538350904360414, Final Batch Loss: 0.0074873738922178745\n",
      "Epoch 4986, Loss: 0.10695833712816238, Final Batch Loss: 0.03653276711702347\n",
      "Epoch 4987, Loss: 0.10089601948857307, Final Batch Loss: 0.05940153822302818\n",
      "Epoch 4988, Loss: 0.12577231600880623, Final Batch Loss: 0.08463780581951141\n",
      "Epoch 4989, Loss: 0.09697780385613441, Final Batch Loss: 0.057568274438381195\n",
      "Epoch 4990, Loss: 0.11034619435667992, Final Batch Loss: 0.04280545935034752\n",
      "Epoch 4991, Loss: 0.08988539129495621, Final Batch Loss: 0.05112982541322708\n",
      "Epoch 4992, Loss: 0.10806045308709145, Final Batch Loss: 0.03640522435307503\n",
      "Epoch 4993, Loss: 0.08314245566725731, Final Batch Loss: 0.03845357522368431\n",
      "Epoch 4994, Loss: 0.10759604722261429, Final Batch Loss: 0.05778910592198372\n",
      "Epoch 4995, Loss: 0.08727232739329338, Final Batch Loss: 0.05305956304073334\n",
      "Epoch 4996, Loss: 0.07858611084520817, Final Batch Loss: 0.029982401058077812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4997, Loss: 0.10720906406641006, Final Batch Loss: 0.06332631409168243\n",
      "Epoch 4998, Loss: 0.1129295825958252, Final Batch Loss: 0.04486106336116791\n",
      "Epoch 4999, Loss: 0.122499980032444, Final Batch Loss: 0.05389717221260071\n",
      "Epoch 5000, Loss: 0.10784735903143883, Final Batch Loss: 0.03992145135998726\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39  0  0]\n",
      " [ 4 38  0]\n",
      " [ 1  0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.88636   1.00000   0.93976        39\n",
      "           1    1.00000   0.90476   0.95000        42\n",
      "           2    1.00000   0.96552   0.98246        29\n",
      "\n",
      "    accuracy                        0.95455       110\n",
      "   macro avg    0.96212   0.95676   0.95741       110\n",
      "weighted avg    0.95971   0.95455   0.95493       110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_labels = [0] * n_samples + [1] * n_samples + [2] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples\n",
    "fake_labels = np.asarray(fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  0  0]\n",
      " [ 2 23  5]\n",
      " [ 2  5 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.88235   1.00000   0.93750        30\n",
      "           1    0.82143   0.76667   0.79310        30\n",
      "           2    0.82143   0.76667   0.79310        30\n",
      "\n",
      "    accuracy                        0.84444        90\n",
      "   macro avg    0.84174   0.84444   0.84124        90\n",
      "weighted avg    0.84174   0.84444   0.84124        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(fake_labels, preds.cpu()))\n",
    "print(metrics.classification_report(fake_labels, preds.cpu(), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
