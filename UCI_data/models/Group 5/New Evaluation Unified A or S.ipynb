{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '125 tBodyGyro-std()-Y',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '138 tBodyGyro-energy()-Y',\n",
    " '165 tBodyGyroJerk-std()-Y',\n",
    " '168 tBodyGyroJerk-mad()-Y',\n",
    " '178 tBodyGyroJerk-energy()-Y',\n",
    " '181 tBodyGyroJerk-iqr()-Y',\n",
    " '425 fBodyGyro-mean()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '431 fBodyGyro-mad()-Y',\n",
    " '441 fBodyGyro-energy()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '478 fBodyGyro-bandsEnergy()-25,32',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '204 tBodyAccMag-max()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '217 tGravityAccMag-max()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '275 fBodyAcc-max()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '506 fBodyAccMag-max()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def get_act_matrix(batch_size, a_dim):\n",
    "    indexes = np.random.randint(a_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((len(indexes), indexes.max()+1))\n",
    "    one_hot[np.arange(len(indexes)),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "    \n",
    "def get_usr_matrix(batch_size, u_dim):\n",
    "    indexes = np.random.randint(u_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((indexes.size, indexes.max()+1))\n",
    "    one_hot[np.arange(indexes.size),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [23, 25, 27]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2210010290145874, Final Batch Loss: 1.099376916885376\n",
      "Epoch 2, Loss: 2.218256711959839, Final Batch Loss: 1.1205741167068481\n",
      "Epoch 3, Loss: 2.2056864500045776, Final Batch Loss: 1.1011734008789062\n",
      "Epoch 4, Loss: 2.195812940597534, Final Batch Loss: 1.102722406387329\n",
      "Epoch 5, Loss: 2.1909762620925903, Final Batch Loss: 1.0902897119522095\n",
      "Epoch 6, Loss: 2.1918030977249146, Final Batch Loss: 1.1062830686569214\n",
      "Epoch 7, Loss: 2.182931900024414, Final Batch Loss: 1.0880934000015259\n",
      "Epoch 8, Loss: 2.1788216829299927, Final Batch Loss: 1.0990973711013794\n",
      "Epoch 9, Loss: 2.1747478246688843, Final Batch Loss: 1.08416748046875\n",
      "Epoch 10, Loss: 2.172971248626709, Final Batch Loss: 1.1020557880401611\n",
      "Epoch 11, Loss: 2.155690550804138, Final Batch Loss: 1.0861163139343262\n",
      "Epoch 12, Loss: 2.1507601737976074, Final Batch Loss: 1.0744158029556274\n",
      "Epoch 13, Loss: 2.1456964015960693, Final Batch Loss: 1.0695973634719849\n",
      "Epoch 14, Loss: 2.1345083713531494, Final Batch Loss: 1.082378625869751\n",
      "Epoch 15, Loss: 2.108876585960388, Final Batch Loss: 1.048546552658081\n",
      "Epoch 16, Loss: 2.1084375381469727, Final Batch Loss: 1.0570571422576904\n",
      "Epoch 17, Loss: 2.0810420513153076, Final Batch Loss: 1.0274509191513062\n",
      "Epoch 18, Loss: 2.073788285255432, Final Batch Loss: 1.0328559875488281\n",
      "Epoch 19, Loss: 2.060485363006592, Final Batch Loss: 1.020887851715088\n",
      "Epoch 20, Loss: 2.032520294189453, Final Batch Loss: 1.0038174390792847\n",
      "Epoch 21, Loss: 1.999532401561737, Final Batch Loss: 0.9915844798088074\n",
      "Epoch 22, Loss: 1.986554503440857, Final Batch Loss: 0.9922679662704468\n",
      "Epoch 23, Loss: 1.9508732557296753, Final Batch Loss: 0.9767308235168457\n",
      "Epoch 24, Loss: 1.908962368965149, Final Batch Loss: 0.9530284404754639\n",
      "Epoch 25, Loss: 1.8670799732208252, Final Batch Loss: 0.9327077865600586\n",
      "Epoch 26, Loss: 1.8261871337890625, Final Batch Loss: 0.9049627184867859\n",
      "Epoch 27, Loss: 1.7845565676689148, Final Batch Loss: 0.8970202803611755\n",
      "Epoch 28, Loss: 1.729339361190796, Final Batch Loss: 0.8703093528747559\n",
      "Epoch 29, Loss: 1.672472596168518, Final Batch Loss: 0.8083972334861755\n",
      "Epoch 30, Loss: 1.595369577407837, Final Batch Loss: 0.7940294146537781\n",
      "Epoch 31, Loss: 1.5461866855621338, Final Batch Loss: 0.7640951871871948\n",
      "Epoch 32, Loss: 1.4937638640403748, Final Batch Loss: 0.7425315976142883\n",
      "Epoch 33, Loss: 1.4363219738006592, Final Batch Loss: 0.7238463759422302\n",
      "Epoch 34, Loss: 1.3692081570625305, Final Batch Loss: 0.6890974044799805\n",
      "Epoch 35, Loss: 1.2922418713569641, Final Batch Loss: 0.6210646629333496\n",
      "Epoch 36, Loss: 1.242165982723236, Final Batch Loss: 0.6221177577972412\n",
      "Epoch 37, Loss: 1.1951777338981628, Final Batch Loss: 0.5763828158378601\n",
      "Epoch 38, Loss: 1.1350841522216797, Final Batch Loss: 0.5514087080955505\n",
      "Epoch 39, Loss: 1.0664957463741302, Final Batch Loss: 0.49551400542259216\n",
      "Epoch 40, Loss: 0.9787240624427795, Final Batch Loss: 0.43891435861587524\n",
      "Epoch 41, Loss: 0.9605511128902435, Final Batch Loss: 0.452119380235672\n",
      "Epoch 42, Loss: 0.9605554342269897, Final Batch Loss: 0.49356621503829956\n",
      "Epoch 43, Loss: 0.8339221179485321, Final Batch Loss: 0.38880282640457153\n",
      "Epoch 44, Loss: 0.8182975649833679, Final Batch Loss: 0.41182276606559753\n",
      "Epoch 45, Loss: 0.7908720672130585, Final Batch Loss: 0.40420418977737427\n",
      "Epoch 46, Loss: 0.7518710494041443, Final Batch Loss: 0.3286820948123932\n",
      "Epoch 47, Loss: 0.7237966060638428, Final Batch Loss: 0.37753742933273315\n",
      "Epoch 48, Loss: 0.69170743227005, Final Batch Loss: 0.3530181348323822\n",
      "Epoch 49, Loss: 0.6449636220932007, Final Batch Loss: 0.3170701563358307\n",
      "Epoch 50, Loss: 0.6567153036594391, Final Batch Loss: 0.309271901845932\n",
      "Epoch 51, Loss: 0.5392166674137115, Final Batch Loss: 0.2645357847213745\n",
      "Epoch 52, Loss: 0.5371731817722321, Final Batch Loss: 0.25975915789604187\n",
      "Epoch 53, Loss: 0.5181004405021667, Final Batch Loss: 0.23864322900772095\n",
      "Epoch 54, Loss: 0.46853458881378174, Final Batch Loss: 0.1952889859676361\n",
      "Epoch 55, Loss: 0.4413481503725052, Final Batch Loss: 0.18278305232524872\n",
      "Epoch 56, Loss: 0.43003225326538086, Final Batch Loss: 0.2266065776348114\n",
      "Epoch 57, Loss: 0.5351589918136597, Final Batch Loss: 0.29103630781173706\n",
      "Epoch 58, Loss: 0.43250517547130585, Final Batch Loss: 0.20084615051746368\n",
      "Epoch 59, Loss: 0.35015869140625, Final Batch Loss: 0.18484064936637878\n",
      "Epoch 60, Loss: 0.46380817890167236, Final Batch Loss: 0.2220766842365265\n",
      "Epoch 61, Loss: 0.4199579805135727, Final Batch Loss: 0.2180868685245514\n",
      "Epoch 62, Loss: 0.3396749645471573, Final Batch Loss: 0.1659405529499054\n",
      "Epoch 63, Loss: 0.3218478858470917, Final Batch Loss: 0.17587065696716309\n",
      "Epoch 64, Loss: 0.3696009963750839, Final Batch Loss: 0.1939084231853485\n",
      "Epoch 65, Loss: 0.38059842586517334, Final Batch Loss: 0.17512011528015137\n",
      "Epoch 66, Loss: 0.36439256370067596, Final Batch Loss: 0.16675738990306854\n",
      "Epoch 67, Loss: 0.3102727383375168, Final Batch Loss: 0.15565501153469086\n",
      "Epoch 68, Loss: 0.34249843657016754, Final Batch Loss: 0.17611248791217804\n",
      "Epoch 69, Loss: 0.3562104105949402, Final Batch Loss: 0.18072845041751862\n",
      "Epoch 70, Loss: 0.33210331201553345, Final Batch Loss: 0.14575543999671936\n",
      "Epoch 71, Loss: 0.29803571105003357, Final Batch Loss: 0.14849863946437836\n",
      "Epoch 72, Loss: 0.2938850671052933, Final Batch Loss: 0.17635847628116608\n",
      "Epoch 73, Loss: 0.2860752195119858, Final Batch Loss: 0.12569835782051086\n",
      "Epoch 74, Loss: 0.2573174834251404, Final Batch Loss: 0.12845848500728607\n",
      "Epoch 75, Loss: 0.3535008728504181, Final Batch Loss: 0.17953987419605255\n",
      "Epoch 76, Loss: 0.26622238755226135, Final Batch Loss: 0.10979396104812622\n",
      "Epoch 77, Loss: 0.273306742310524, Final Batch Loss: 0.1275205910205841\n",
      "Epoch 78, Loss: 0.2326812818646431, Final Batch Loss: 0.10880140960216522\n",
      "Epoch 79, Loss: 0.2709706872701645, Final Batch Loss: 0.15793658792972565\n",
      "Epoch 80, Loss: 0.21470995247364044, Final Batch Loss: 0.1131947860121727\n",
      "Epoch 81, Loss: 0.2565687224268913, Final Batch Loss: 0.1228347048163414\n",
      "Epoch 82, Loss: 0.22351104766130447, Final Batch Loss: 0.10427936166524887\n",
      "Epoch 83, Loss: 0.23683109134435654, Final Batch Loss: 0.10655555874109268\n",
      "Epoch 84, Loss: 0.2615307867527008, Final Batch Loss: 0.14940209686756134\n",
      "Epoch 85, Loss: 0.2647809684276581, Final Batch Loss: 0.14956693351268768\n",
      "Epoch 86, Loss: 0.24183662980794907, Final Batch Loss: 0.13429224491119385\n",
      "Epoch 87, Loss: 0.2024359554052353, Final Batch Loss: 0.09897172451019287\n",
      "Epoch 88, Loss: 0.20046860724687576, Final Batch Loss: 0.10225692391395569\n",
      "Epoch 89, Loss: 0.18485475331544876, Final Batch Loss: 0.08396954089403152\n",
      "Epoch 90, Loss: 0.24197861552238464, Final Batch Loss: 0.12659603357315063\n",
      "Epoch 91, Loss: 0.15684037655591965, Final Batch Loss: 0.09555163979530334\n",
      "Epoch 92, Loss: 0.19306331872940063, Final Batch Loss: 0.09935426712036133\n",
      "Epoch 93, Loss: 0.17286596447229385, Final Batch Loss: 0.1097896546125412\n",
      "Epoch 94, Loss: 0.1856376975774765, Final Batch Loss: 0.08485030382871628\n",
      "Epoch 95, Loss: 0.21815568953752518, Final Batch Loss: 0.13388891518115997\n",
      "Epoch 96, Loss: 0.20974209159612656, Final Batch Loss: 0.08115603774785995\n",
      "Epoch 97, Loss: 0.1978025883436203, Final Batch Loss: 0.11211736500263214\n",
      "Epoch 98, Loss: 0.18637656420469284, Final Batch Loss: 0.10584733635187149\n",
      "Epoch 99, Loss: 0.22576437145471573, Final Batch Loss: 0.1281212419271469\n",
      "Epoch 100, Loss: 0.14091775193810463, Final Batch Loss: 0.08977881073951721\n",
      "Epoch 101, Loss: 0.186678946018219, Final Batch Loss: 0.09653294086456299\n",
      "Epoch 102, Loss: 0.14181333780288696, Final Batch Loss: 0.06433405727148056\n",
      "Epoch 103, Loss: 0.20281364768743515, Final Batch Loss: 0.09808415919542313\n",
      "Epoch 104, Loss: 0.17875616252422333, Final Batch Loss: 0.10671976208686829\n",
      "Epoch 105, Loss: 0.17916439473628998, Final Batch Loss: 0.07686693966388702\n",
      "Epoch 106, Loss: 0.14071303233504295, Final Batch Loss: 0.08660831302404404\n",
      "Epoch 107, Loss: 0.16196328401565552, Final Batch Loss: 0.0842410996556282\n",
      "Epoch 108, Loss: 0.16205066442489624, Final Batch Loss: 0.05951007455587387\n",
      "Epoch 109, Loss: 0.12255188450217247, Final Batch Loss: 0.0717136487364769\n",
      "Epoch 110, Loss: 0.20191559940576553, Final Batch Loss: 0.09711340069770813\n",
      "Epoch 111, Loss: 0.15826378762722015, Final Batch Loss: 0.1002131849527359\n",
      "Epoch 112, Loss: 0.13136791810393333, Final Batch Loss: 0.057579051703214645\n",
      "Epoch 113, Loss: 0.13481996208429337, Final Batch Loss: 0.0874122604727745\n",
      "Epoch 114, Loss: 0.13119476661086082, Final Batch Loss: 0.07364697754383087\n",
      "Epoch 115, Loss: 0.10035896301269531, Final Batch Loss: 0.05964578315615654\n",
      "Epoch 116, Loss: 0.1505284570157528, Final Batch Loss: 0.09623020142316818\n",
      "Epoch 117, Loss: 0.11637742817401886, Final Batch Loss: 0.06620858609676361\n",
      "Epoch 118, Loss: 0.12687815353274345, Final Batch Loss: 0.06716422736644745\n",
      "Epoch 119, Loss: 0.10968338325619698, Final Batch Loss: 0.03426456078886986\n",
      "Epoch 120, Loss: 0.11625053733587265, Final Batch Loss: 0.07460182160139084\n",
      "Epoch 121, Loss: 0.12145360186696053, Final Batch Loss: 0.060431212186813354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122, Loss: 0.08123305439949036, Final Batch Loss: 0.03892291709780693\n",
      "Epoch 123, Loss: 0.12660792469978333, Final Batch Loss: 0.05204271525144577\n",
      "Epoch 124, Loss: 0.12824956327676773, Final Batch Loss: 0.058128125965595245\n",
      "Epoch 125, Loss: 0.09176888316869736, Final Batch Loss: 0.042134154587984085\n",
      "Epoch 126, Loss: 0.11140896379947662, Final Batch Loss: 0.050422199070453644\n",
      "Epoch 127, Loss: 0.08848652802407742, Final Batch Loss: 0.0625363439321518\n",
      "Epoch 128, Loss: 0.11621509119868279, Final Batch Loss: 0.06204315647482872\n",
      "Epoch 129, Loss: 0.12897387146949768, Final Batch Loss: 0.06596853584051132\n",
      "Epoch 130, Loss: 0.12000427022576332, Final Batch Loss: 0.071745365858078\n",
      "Epoch 131, Loss: 0.1257382370531559, Final Batch Loss: 0.07757174223661423\n",
      "Epoch 132, Loss: 0.1260243095457554, Final Batch Loss: 0.059997234493494034\n",
      "Epoch 133, Loss: 0.10590589791536331, Final Batch Loss: 0.040114715695381165\n",
      "Epoch 134, Loss: 0.10213616117835045, Final Batch Loss: 0.06846955418586731\n",
      "Epoch 135, Loss: 0.11366181820631027, Final Batch Loss: 0.04059880971908569\n",
      "Epoch 136, Loss: 0.0766343493014574, Final Batch Loss: 0.030070973560214043\n",
      "Epoch 137, Loss: 0.09380878508090973, Final Batch Loss: 0.04296974837779999\n",
      "Epoch 138, Loss: 0.09652480483055115, Final Batch Loss: 0.0319412425160408\n",
      "Epoch 139, Loss: 0.13010497391223907, Final Batch Loss: 0.07082746177911758\n",
      "Epoch 140, Loss: 0.1289301998913288, Final Batch Loss: 0.06696213781833649\n",
      "Epoch 141, Loss: 0.09512022510170937, Final Batch Loss: 0.043607112020254135\n",
      "Epoch 142, Loss: 0.09918852150440216, Final Batch Loss: 0.02754811942577362\n",
      "Epoch 143, Loss: 0.07978198677301407, Final Batch Loss: 0.04069002345204353\n",
      "Epoch 144, Loss: 0.0772017166018486, Final Batch Loss: 0.03454579785466194\n",
      "Epoch 145, Loss: 0.11306986957788467, Final Batch Loss: 0.05241601541638374\n",
      "Epoch 146, Loss: 0.13562960363924503, Final Batch Loss: 0.019532853737473488\n",
      "Epoch 147, Loss: 0.10071045905351639, Final Batch Loss: 0.042193345725536346\n",
      "Epoch 148, Loss: 0.08168968558311462, Final Batch Loss: 0.03681907802820206\n",
      "Epoch 149, Loss: 0.07648326642811298, Final Batch Loss: 0.04725709557533264\n",
      "Epoch 150, Loss: 0.07056166045367718, Final Batch Loss: 0.05280141904950142\n",
      "Epoch 151, Loss: 0.10427005216479301, Final Batch Loss: 0.07211630046367645\n",
      "Epoch 152, Loss: 0.10203376784920692, Final Batch Loss: 0.05282922089099884\n",
      "Epoch 153, Loss: 0.08520125597715378, Final Batch Loss: 0.06046203896403313\n",
      "Epoch 154, Loss: 0.09048549085855484, Final Batch Loss: 0.053342871367931366\n",
      "Epoch 155, Loss: 0.09648042544722557, Final Batch Loss: 0.042868830263614655\n",
      "Epoch 156, Loss: 0.07484010979533195, Final Batch Loss: 0.028576046228408813\n",
      "Epoch 157, Loss: 0.06831683032214642, Final Batch Loss: 0.014526588842272758\n",
      "Epoch 158, Loss: 0.07772627472877502, Final Batch Loss: 0.043383028358221054\n",
      "Epoch 159, Loss: 0.046349553391337395, Final Batch Loss: 0.018669750541448593\n",
      "Epoch 160, Loss: 0.05921391770243645, Final Batch Loss: 0.022840391844511032\n",
      "Epoch 161, Loss: 0.0672539472579956, Final Batch Loss: 0.01893417164683342\n",
      "Epoch 162, Loss: 0.12378185242414474, Final Batch Loss: 0.08437007665634155\n",
      "Epoch 163, Loss: 0.08365487307310104, Final Batch Loss: 0.03985495865345001\n",
      "Epoch 164, Loss: 0.06983638927340508, Final Batch Loss: 0.029061678797006607\n",
      "Epoch 165, Loss: 0.08253173157572746, Final Batch Loss: 0.02422907203435898\n",
      "Epoch 166, Loss: 0.10320477932691574, Final Batch Loss: 0.030096687376499176\n",
      "Epoch 167, Loss: 0.08985671028494835, Final Batch Loss: 0.039816852658987045\n",
      "Epoch 168, Loss: 0.07212238758802414, Final Batch Loss: 0.028483383357524872\n",
      "Epoch 169, Loss: 0.08343691006302834, Final Batch Loss: 0.0375516340136528\n",
      "Epoch 170, Loss: 0.03822420723736286, Final Batch Loss: 0.012633511796593666\n",
      "Epoch 171, Loss: 0.09868978708982468, Final Batch Loss: 0.07236097007989883\n",
      "Epoch 172, Loss: 0.053031474351882935, Final Batch Loss: 0.017748404294252396\n",
      "Epoch 173, Loss: 0.04114822670817375, Final Batch Loss: 0.024816691875457764\n",
      "Epoch 174, Loss: 0.08019367605447769, Final Batch Loss: 0.03255631774663925\n",
      "Epoch 175, Loss: 0.0779278576374054, Final Batch Loss: 0.039393361657857895\n",
      "Epoch 176, Loss: 0.11245585232973099, Final Batch Loss: 0.07611113041639328\n",
      "Epoch 177, Loss: 0.05968324840068817, Final Batch Loss: 0.02280868962407112\n",
      "Epoch 178, Loss: 0.09235148131847382, Final Batch Loss: 0.04573540389537811\n",
      "Epoch 179, Loss: 0.04752824641764164, Final Batch Loss: 0.024340784177184105\n",
      "Epoch 180, Loss: 0.0913323350250721, Final Batch Loss: 0.03996075689792633\n",
      "Epoch 181, Loss: 0.06935782451182604, Final Batch Loss: 0.013452296145260334\n",
      "Epoch 182, Loss: 0.05774097889661789, Final Batch Loss: 0.02965124323964119\n",
      "Epoch 183, Loss: 0.05473610758781433, Final Batch Loss: 0.037807248532772064\n",
      "Epoch 184, Loss: 0.07640465162694454, Final Batch Loss: 0.05320620536804199\n",
      "Epoch 185, Loss: 0.03742928151041269, Final Batch Loss: 0.00919413287192583\n",
      "Epoch 186, Loss: 0.05882084742188454, Final Batch Loss: 0.024954460561275482\n",
      "Epoch 187, Loss: 0.0650684516876936, Final Batch Loss: 0.041264552623033524\n",
      "Epoch 188, Loss: 0.037473414093256, Final Batch Loss: 0.019519733265042305\n",
      "Epoch 189, Loss: 0.10567085072398186, Final Batch Loss: 0.06488870829343796\n",
      "Epoch 190, Loss: 0.08634111285209656, Final Batch Loss: 0.0441422238945961\n",
      "Epoch 191, Loss: 0.04283386468887329, Final Batch Loss: 0.022723352536559105\n",
      "Epoch 192, Loss: 0.07196256332099438, Final Batch Loss: 0.04180886596441269\n",
      "Epoch 193, Loss: 0.05872773565351963, Final Batch Loss: 0.02378050424158573\n",
      "Epoch 194, Loss: 0.07843339070677757, Final Batch Loss: 0.04096294566988945\n",
      "Epoch 195, Loss: 0.06826360896229744, Final Batch Loss: 0.05057196319103241\n",
      "Epoch 196, Loss: 0.06067227944731712, Final Batch Loss: 0.04893752932548523\n",
      "Epoch 197, Loss: 0.07631659880280495, Final Batch Loss: 0.035479020327329636\n",
      "Epoch 198, Loss: 0.06391440704464912, Final Batch Loss: 0.03662338852882385\n",
      "Epoch 199, Loss: 0.060217397287487984, Final Batch Loss: 0.03758654370903969\n",
      "Epoch 200, Loss: 0.042171670123934746, Final Batch Loss: 0.02415621280670166\n",
      "Epoch 201, Loss: 0.060326848179101944, Final Batch Loss: 0.02724345028400421\n",
      "Epoch 202, Loss: 0.05587775073945522, Final Batch Loss: 0.033393777906894684\n",
      "Epoch 203, Loss: 0.03727653995156288, Final Batch Loss: 0.020344693213701248\n",
      "Epoch 204, Loss: 0.06216054782271385, Final Batch Loss: 0.03296329453587532\n",
      "Epoch 205, Loss: 0.06954610720276833, Final Batch Loss: 0.018573619425296783\n",
      "Epoch 206, Loss: 0.03692168276757002, Final Batch Loss: 0.024993406608700752\n",
      "Epoch 207, Loss: 0.03037409856915474, Final Batch Loss: 0.009121578186750412\n",
      "Epoch 208, Loss: 0.07360154949128628, Final Batch Loss: 0.049864668399095535\n",
      "Epoch 209, Loss: 0.051040434278547764, Final Batch Loss: 0.012533639557659626\n",
      "Epoch 210, Loss: 0.028964086435735226, Final Batch Loss: 0.011486359871923923\n",
      "Epoch 211, Loss: 0.07247340679168701, Final Batch Loss: 0.037129275500774384\n",
      "Epoch 212, Loss: 0.03848813660442829, Final Batch Loss: 0.019271671772003174\n",
      "Epoch 213, Loss: 0.05898960866034031, Final Batch Loss: 0.02488667704164982\n",
      "Epoch 214, Loss: 0.04828387312591076, Final Batch Loss: 0.034965433180332184\n",
      "Epoch 215, Loss: 0.06408708728849888, Final Batch Loss: 0.03300632908940315\n",
      "Epoch 216, Loss: 0.03415486961603165, Final Batch Loss: 0.021499520167708397\n",
      "Epoch 217, Loss: 0.05535517446696758, Final Batch Loss: 0.025337617844343185\n",
      "Epoch 218, Loss: 0.06157521344721317, Final Batch Loss: 0.045797381550073624\n",
      "Epoch 219, Loss: 0.06125889532268047, Final Batch Loss: 0.03529305383563042\n",
      "Epoch 220, Loss: 0.04222933575510979, Final Batch Loss: 0.016238613054156303\n",
      "Epoch 221, Loss: 0.03846712037920952, Final Batch Loss: 0.019867684692144394\n",
      "Epoch 222, Loss: 0.06004683626815677, Final Batch Loss: 0.006296298932284117\n",
      "Epoch 223, Loss: 0.030776220373809338, Final Batch Loss: 0.01951899193227291\n",
      "Epoch 224, Loss: 0.029980480670928955, Final Batch Loss: 0.009776510298252106\n",
      "Epoch 225, Loss: 0.03283367119729519, Final Batch Loss: 0.018934931606054306\n",
      "Epoch 226, Loss: 0.052738167345523834, Final Batch Loss: 0.0291154645383358\n",
      "Epoch 227, Loss: 0.01622453797608614, Final Batch Loss: 0.005760993808507919\n",
      "Epoch 228, Loss: 0.03732567187398672, Final Batch Loss: 0.011210544966161251\n",
      "Epoch 229, Loss: 0.03140334878116846, Final Batch Loss: 0.01031979825347662\n",
      "Epoch 230, Loss: 0.05348115414381027, Final Batch Loss: 0.04043187201023102\n",
      "Epoch 231, Loss: 0.058629922568798065, Final Batch Loss: 0.03985080495476723\n",
      "Epoch 232, Loss: 0.06398037448525429, Final Batch Loss: 0.03596387058496475\n",
      "Epoch 233, Loss: 0.03142313938587904, Final Batch Loss: 0.02304317243397236\n",
      "Epoch 234, Loss: 0.03705377131700516, Final Batch Loss: 0.01407151110470295\n",
      "Epoch 235, Loss: 0.040356510784476995, Final Batch Loss: 0.005527140107005835\n",
      "Epoch 236, Loss: 0.030474682338535786, Final Batch Loss: 0.010037905536592007\n",
      "Epoch 237, Loss: 0.046390121802687645, Final Batch Loss: 0.015210572630167007\n",
      "Epoch 238, Loss: 0.07167948968708515, Final Batch Loss: 0.04644123464822769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239, Loss: 0.030637627467513084, Final Batch Loss: 0.015437518246471882\n",
      "Epoch 240, Loss: 0.026258678175508976, Final Batch Loss: 0.007814292795956135\n",
      "Epoch 241, Loss: 0.020069904159754515, Final Batch Loss: 0.00678354362025857\n",
      "Epoch 242, Loss: 0.041482944041490555, Final Batch Loss: 0.025850653648376465\n",
      "Epoch 243, Loss: 0.016723393462598324, Final Batch Loss: 0.004866982810199261\n",
      "Epoch 244, Loss: 0.05787427071481943, Final Batch Loss: 0.010320303030312061\n",
      "Epoch 245, Loss: 0.084104523062706, Final Batch Loss: 0.06320188194513321\n",
      "Epoch 246, Loss: 0.014277137815952301, Final Batch Loss: 0.0061858948320150375\n",
      "Epoch 247, Loss: 0.07641522586345673, Final Batch Loss: 0.040133874863386154\n",
      "Epoch 248, Loss: 0.029842442832887173, Final Batch Loss: 0.009768613614141941\n",
      "Epoch 249, Loss: 0.019743362441658974, Final Batch Loss: 0.010996597819030285\n",
      "Epoch 250, Loss: 0.020047073252499104, Final Batch Loss: 0.009019224904477596\n",
      "Epoch 251, Loss: 0.026421205140650272, Final Batch Loss: 0.017562229186296463\n",
      "Epoch 252, Loss: 0.023758542258292437, Final Batch Loss: 0.01651940681040287\n",
      "Epoch 253, Loss: 0.021492190659046173, Final Batch Loss: 0.01090354286134243\n",
      "Epoch 254, Loss: 0.021551458165049553, Final Batch Loss: 0.009905263781547546\n",
      "Epoch 255, Loss: 0.037317256443202496, Final Batch Loss: 0.014280532486736774\n",
      "Epoch 256, Loss: 0.046120889484882355, Final Batch Loss: 0.025260791182518005\n",
      "Epoch 257, Loss: 0.04328231327235699, Final Batch Loss: 0.013883180916309357\n",
      "Epoch 258, Loss: 0.028772643767297268, Final Batch Loss: 0.010049778036773205\n",
      "Epoch 259, Loss: 0.023953133262693882, Final Batch Loss: 0.015309225767850876\n",
      "Epoch 260, Loss: 0.04558408632874489, Final Batch Loss: 0.020335741341114044\n",
      "Epoch 261, Loss: 0.026658340357244015, Final Batch Loss: 0.01729566417634487\n",
      "Epoch 262, Loss: 0.03982370160520077, Final Batch Loss: 0.017285598441958427\n",
      "Epoch 263, Loss: 0.011156903579831123, Final Batch Loss: 0.0034434422850608826\n",
      "Epoch 264, Loss: 0.043365202844142914, Final Batch Loss: 0.02525394968688488\n",
      "Epoch 265, Loss: 0.06632162071764469, Final Batch Loss: 0.039025261998176575\n",
      "Epoch 266, Loss: 0.021224621683359146, Final Batch Loss: 0.010084637440741062\n",
      "Epoch 267, Loss: 0.02669457718729973, Final Batch Loss: 0.01839180290699005\n",
      "Epoch 268, Loss: 0.034913789480924606, Final Batch Loss: 0.027209652587771416\n",
      "Epoch 269, Loss: 0.04244169918820262, Final Batch Loss: 0.007028158288449049\n",
      "Epoch 270, Loss: 0.04184311255812645, Final Batch Loss: 0.00823543593287468\n",
      "Epoch 271, Loss: 0.034768878016620874, Final Batch Loss: 0.006455250550061464\n",
      "Epoch 272, Loss: 0.01653908146545291, Final Batch Loss: 0.006106469314545393\n",
      "Epoch 273, Loss: 0.029793929308652878, Final Batch Loss: 0.017281144857406616\n",
      "Epoch 274, Loss: 0.03452769108116627, Final Batch Loss: 0.011090299114584923\n",
      "Epoch 275, Loss: 0.024277737829834223, Final Batch Loss: 0.017181457951664925\n",
      "Epoch 276, Loss: 0.024274084717035294, Final Batch Loss: 0.012707625515758991\n",
      "Epoch 277, Loss: 0.027741282247006893, Final Batch Loss: 0.012538330629467964\n",
      "Epoch 278, Loss: 0.019472289364784956, Final Batch Loss: 0.012867660261690617\n",
      "Epoch 279, Loss: 0.0323237469419837, Final Batch Loss: 0.011972474865615368\n",
      "Epoch 280, Loss: 0.013534430880099535, Final Batch Loss: 0.006534107960760593\n",
      "Epoch 281, Loss: 0.029417290817946196, Final Batch Loss: 0.00693556061014533\n",
      "Epoch 282, Loss: 0.041783757507801056, Final Batch Loss: 0.009842697530984879\n",
      "Epoch 283, Loss: 0.025707600638270378, Final Batch Loss: 0.011011277325451374\n",
      "Epoch 284, Loss: 0.03267535474151373, Final Batch Loss: 0.015071148984134197\n",
      "Epoch 285, Loss: 0.054538412019610405, Final Batch Loss: 0.03215821459889412\n",
      "Epoch 286, Loss: 0.020460932049900293, Final Batch Loss: 0.006134467665106058\n",
      "Epoch 287, Loss: 0.031120214611291885, Final Batch Loss: 0.022070514038205147\n",
      "Epoch 288, Loss: 0.012696738354861736, Final Batch Loss: 0.004156083799898624\n",
      "Epoch 289, Loss: 0.01760507933795452, Final Batch Loss: 0.004042904824018478\n",
      "Epoch 290, Loss: 0.02832669485360384, Final Batch Loss: 0.00917359720915556\n",
      "Epoch 291, Loss: 0.09274696744978428, Final Batch Loss: 0.07429662346839905\n",
      "Epoch 292, Loss: 0.03387874737381935, Final Batch Loss: 0.010013073682785034\n",
      "Epoch 293, Loss: 0.011815134901553392, Final Batch Loss: 0.004104037303477526\n",
      "Epoch 294, Loss: 0.03242472279816866, Final Batch Loss: 0.004803893156349659\n",
      "Epoch 295, Loss: 0.05505740363150835, Final Batch Loss: 0.0070595527067780495\n",
      "Epoch 296, Loss: 0.0511794239282608, Final Batch Loss: 0.042920809239149094\n",
      "Epoch 297, Loss: 0.021403509192168713, Final Batch Loss: 0.014190448448061943\n",
      "Epoch 298, Loss: 0.028481383807957172, Final Batch Loss: 0.01166608091443777\n",
      "Epoch 299, Loss: 0.01568494806997478, Final Batch Loss: 0.00336325797252357\n",
      "Epoch 300, Loss: 0.02187329437583685, Final Batch Loss: 0.01650606282055378\n",
      "Epoch 301, Loss: 0.021172994282096624, Final Batch Loss: 0.007244177628308535\n",
      "Epoch 302, Loss: 0.013311064336448908, Final Batch Loss: 0.007954005151987076\n",
      "Epoch 303, Loss: 0.03063698299229145, Final Batch Loss: 0.02633919194340706\n",
      "Epoch 304, Loss: 0.02533440664410591, Final Batch Loss: 0.009210150688886642\n",
      "Epoch 305, Loss: 0.03036512713879347, Final Batch Loss: 0.011436584405601025\n",
      "Epoch 306, Loss: 0.024857450276613235, Final Batch Loss: 0.004623156040906906\n",
      "Epoch 307, Loss: 0.018327088095247746, Final Batch Loss: 0.009845774620771408\n",
      "Epoch 308, Loss: 0.014838555827736855, Final Batch Loss: 0.006546243093907833\n",
      "Epoch 309, Loss: 0.028622742742300034, Final Batch Loss: 0.008715176954865456\n",
      "Epoch 310, Loss: 0.028247147798538208, Final Batch Loss: 0.015344051644206047\n",
      "Epoch 311, Loss: 0.016976462211459875, Final Batch Loss: 0.004628798458725214\n",
      "Epoch 312, Loss: 0.019149875734001398, Final Batch Loss: 0.0041714743711054325\n",
      "Epoch 313, Loss: 0.046331274788826704, Final Batch Loss: 0.03962777927517891\n",
      "Epoch 314, Loss: 0.027342390967532992, Final Batch Loss: 0.024386204779148102\n",
      "Epoch 315, Loss: 0.016458040103316307, Final Batch Loss: 0.0062788138166069984\n",
      "Epoch 316, Loss: 0.006920615443959832, Final Batch Loss: 0.002700424985960126\n",
      "Epoch 317, Loss: 0.019536452367901802, Final Batch Loss: 0.008208386600017548\n",
      "Epoch 318, Loss: 0.016550338827073574, Final Batch Loss: 0.0073182424530386925\n",
      "Epoch 319, Loss: 0.04015384986996651, Final Batch Loss: 0.017664261162281036\n",
      "Epoch 320, Loss: 0.044871214777231216, Final Batch Loss: 0.016043633222579956\n",
      "Epoch 321, Loss: 0.03280904330313206, Final Batch Loss: 0.0171805452555418\n",
      "Epoch 322, Loss: 0.03590717352926731, Final Batch Loss: 0.02326241508126259\n",
      "Epoch 323, Loss: 0.035512033849954605, Final Batch Loss: 0.02463325671851635\n",
      "Epoch 324, Loss: 0.018898150883615017, Final Batch Loss: 0.005316424183547497\n",
      "Epoch 325, Loss: 0.020644997712224722, Final Batch Loss: 0.013337927870452404\n",
      "Epoch 326, Loss: 0.010313506470993161, Final Batch Loss: 0.006454215385019779\n",
      "Epoch 327, Loss: 0.012740904465317726, Final Batch Loss: 0.005663848016411066\n",
      "Epoch 328, Loss: 0.042949228547513485, Final Batch Loss: 0.02964179962873459\n",
      "Epoch 329, Loss: 0.02799193374812603, Final Batch Loss: 0.016726499423384666\n",
      "Epoch 330, Loss: 0.017249792348593473, Final Batch Loss: 0.011108013801276684\n",
      "Epoch 331, Loss: 0.01014041667804122, Final Batch Loss: 0.004673672839999199\n",
      "Epoch 332, Loss: 0.029162156395614147, Final Batch Loss: 0.011026781983673573\n",
      "Epoch 333, Loss: 0.019789602607488632, Final Batch Loss: 0.01096291933208704\n",
      "Epoch 334, Loss: 0.04446370154619217, Final Batch Loss: 0.02651171013712883\n",
      "Epoch 335, Loss: 0.033266281709074974, Final Batch Loss: 0.022044289857149124\n",
      "Epoch 336, Loss: 0.020905165933072567, Final Batch Loss: 0.010337849147617817\n",
      "Epoch 337, Loss: 0.01128794765099883, Final Batch Loss: 0.004633050877600908\n",
      "Epoch 338, Loss: 0.024598164134658873, Final Batch Loss: 0.001934989937581122\n",
      "Epoch 339, Loss: 0.04693926125764847, Final Batch Loss: 0.028142381459474564\n",
      "Epoch 340, Loss: 0.0158774983137846, Final Batch Loss: 0.011692571453750134\n",
      "Epoch 341, Loss: 0.015562253538519144, Final Batch Loss: 0.0047368803061544895\n",
      "Epoch 342, Loss: 0.024250434711575508, Final Batch Loss: 0.0021268855780363083\n",
      "Epoch 343, Loss: 0.040550386533141136, Final Batch Loss: 0.014162775129079819\n",
      "Epoch 344, Loss: 0.025285780429840088, Final Batch Loss: 0.004730110988020897\n",
      "Epoch 345, Loss: 0.006973400246351957, Final Batch Loss: 0.0022994051687419415\n",
      "Epoch 346, Loss: 0.02020066138356924, Final Batch Loss: 0.004024655558168888\n",
      "Epoch 347, Loss: 0.0209253893699497, Final Batch Loss: 0.0022808515932410955\n",
      "Epoch 348, Loss: 0.01449962705373764, Final Batch Loss: 0.007731670513749123\n",
      "Epoch 349, Loss: 0.011035990435630083, Final Batch Loss: 0.005527376662939787\n",
      "Epoch 350, Loss: 0.03795075602829456, Final Batch Loss: 0.021931009367108345\n",
      "Epoch 351, Loss: 0.02617187425494194, Final Batch Loss: 0.017452005296945572\n",
      "Epoch 352, Loss: 0.03669369895942509, Final Batch Loss: 0.002097389893606305\n",
      "Epoch 353, Loss: 0.012830441351979971, Final Batch Loss: 0.005334857385605574\n",
      "Epoch 354, Loss: 0.0070265852846205235, Final Batch Loss: 0.0017298380844295025\n",
      "Epoch 355, Loss: 0.019244777970016003, Final Batch Loss: 0.004773386754095554\n",
      "Epoch 356, Loss: 0.05131157487630844, Final Batch Loss: 0.03526240959763527\n",
      "Epoch 357, Loss: 0.028832264244556427, Final Batch Loss: 0.012728307396173477\n",
      "Epoch 358, Loss: 0.013415473513305187, Final Batch Loss: 0.0038865534588694572\n",
      "Epoch 359, Loss: 0.03698734473437071, Final Batch Loss: 0.023304512724280357\n",
      "Epoch 360, Loss: 0.014890566933900118, Final Batch Loss: 0.009127665311098099\n",
      "Epoch 361, Loss: 0.016581890638917685, Final Batch Loss: 0.00971999205648899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362, Loss: 0.014776397496461868, Final Batch Loss: 0.0052253324538469315\n",
      "Epoch 363, Loss: 0.025817206129431725, Final Batch Loss: 0.01715395599603653\n",
      "Epoch 364, Loss: 0.037985384464263916, Final Batch Loss: 0.011669909581542015\n",
      "Epoch 365, Loss: 0.01944965496659279, Final Batch Loss: 0.009347076527774334\n",
      "Epoch 366, Loss: 0.0393194577191025, Final Batch Loss: 0.03601067513227463\n",
      "Epoch 367, Loss: 0.012790870852768421, Final Batch Loss: 0.0070074936375021935\n",
      "Epoch 368, Loss: 0.03828414902091026, Final Batch Loss: 0.016425058245658875\n",
      "Epoch 369, Loss: 0.02743233833462, Final Batch Loss: 0.00335076916962862\n",
      "Epoch 370, Loss: 0.01696638949215412, Final Batch Loss: 0.0069939615204930305\n",
      "Epoch 371, Loss: 0.034032752737402916, Final Batch Loss: 0.018057778477668762\n",
      "Epoch 372, Loss: 0.0289319371804595, Final Batch Loss: 0.013755989260971546\n",
      "Epoch 373, Loss: 0.01574952807277441, Final Batch Loss: 0.010622701607644558\n",
      "Epoch 374, Loss: 0.019671378657221794, Final Batch Loss: 0.011817864142358303\n",
      "Epoch 375, Loss: 0.027654862962663174, Final Batch Loss: 0.017313890159130096\n",
      "Epoch 376, Loss: 0.016147841699421406, Final Batch Loss: 0.011461636051535606\n",
      "Epoch 377, Loss: 0.010129583301022649, Final Batch Loss: 0.006528980098664761\n",
      "Epoch 378, Loss: 0.03288151137530804, Final Batch Loss: 0.020476460456848145\n",
      "Epoch 379, Loss: 0.012242532800883055, Final Batch Loss: 0.006761845666915178\n",
      "Epoch 380, Loss: 0.05493127927184105, Final Batch Loss: 0.02472626231610775\n",
      "Epoch 381, Loss: 0.0227434067055583, Final Batch Loss: 0.012890834361314774\n",
      "Epoch 382, Loss: 0.008065982023254037, Final Batch Loss: 0.005196670535951853\n",
      "Epoch 383, Loss: 0.013904937542974949, Final Batch Loss: 0.006661032326519489\n",
      "Epoch 384, Loss: 0.006093491101637483, Final Batch Loss: 0.0013427084777504206\n",
      "Epoch 385, Loss: 0.010984377469867468, Final Batch Loss: 0.006549973506480455\n",
      "Epoch 386, Loss: 0.03654212551191449, Final Batch Loss: 0.004639305640012026\n",
      "Epoch 387, Loss: 0.013541440712288022, Final Batch Loss: 0.0022133898455649614\n",
      "Epoch 388, Loss: 0.012565310578793287, Final Batch Loss: 0.008508971892297268\n",
      "Epoch 389, Loss: 0.008681380189955235, Final Batch Loss: 0.0043420689180493355\n",
      "Epoch 390, Loss: 0.00895686075091362, Final Batch Loss: 0.004137925338000059\n",
      "Epoch 391, Loss: 0.010011331178247929, Final Batch Loss: 0.006458150688558817\n",
      "Epoch 392, Loss: 0.024690851103514433, Final Batch Loss: 0.01930343359708786\n",
      "Epoch 393, Loss: 0.009569537825882435, Final Batch Loss: 0.00550458300858736\n",
      "Epoch 394, Loss: 0.03337401058524847, Final Batch Loss: 0.014410805888473988\n",
      "Epoch 395, Loss: 0.0077722626738250256, Final Batch Loss: 0.0030840300023555756\n",
      "Epoch 396, Loss: 0.019192727748304605, Final Batch Loss: 0.01483281422406435\n",
      "Epoch 397, Loss: 0.010754349641501904, Final Batch Loss: 0.0030900863930583\n",
      "Epoch 398, Loss: 0.009849664755165577, Final Batch Loss: 0.004269123077392578\n",
      "Epoch 399, Loss: 0.01723796408623457, Final Batch Loss: 0.0031473441049456596\n",
      "Epoch 400, Loss: 0.02168407291173935, Final Batch Loss: 0.008923035115003586\n",
      "Epoch 401, Loss: 0.007678877096623182, Final Batch Loss: 0.004889224655926228\n",
      "Epoch 402, Loss: 0.01535452390089631, Final Batch Loss: 0.007214459124952555\n",
      "Epoch 403, Loss: 0.01038003247231245, Final Batch Loss: 0.004073896910995245\n",
      "Epoch 404, Loss: 0.018624641001224518, Final Batch Loss: 0.014233158901333809\n",
      "Epoch 405, Loss: 0.024608255364000797, Final Batch Loss: 0.01022840104997158\n",
      "Epoch 406, Loss: 0.010192805668339133, Final Batch Loss: 0.006906782276928425\n",
      "Epoch 407, Loss: 0.01152393314987421, Final Batch Loss: 0.006628934759646654\n",
      "Epoch 408, Loss: 0.021318829618394375, Final Batch Loss: 0.018897099420428276\n",
      "Epoch 409, Loss: 0.0055328719317913055, Final Batch Loss: 0.0021250974386930466\n",
      "Epoch 410, Loss: 0.02122089173644781, Final Batch Loss: 0.00453838799148798\n",
      "Epoch 411, Loss: 0.015059309778735042, Final Batch Loss: 0.0026768750976771116\n",
      "Epoch 412, Loss: 0.005524104461073875, Final Batch Loss: 0.0021801944822072983\n",
      "Epoch 413, Loss: 0.007077951566316187, Final Batch Loss: 0.0009908165084198117\n",
      "Epoch 414, Loss: 0.006802916061133146, Final Batch Loss: 0.0025557400658726692\n",
      "Epoch 415, Loss: 0.014404814690351486, Final Batch Loss: 0.009251095354557037\n",
      "Epoch 416, Loss: 0.036385102197527885, Final Batch Loss: 0.025566158816218376\n",
      "Epoch 417, Loss: 0.005623750621452928, Final Batch Loss: 0.0038160199765115976\n",
      "Epoch 418, Loss: 0.013124264543876052, Final Batch Loss: 0.003319109557196498\n",
      "Epoch 419, Loss: 0.018612873973324895, Final Batch Loss: 0.0012500074226409197\n",
      "Epoch 420, Loss: 0.010937236249446869, Final Batch Loss: 0.0036374274641275406\n",
      "Epoch 421, Loss: 0.00779926055110991, Final Batch Loss: 0.003759692655876279\n",
      "Epoch 422, Loss: 0.00907887239009142, Final Batch Loss: 0.006362743675708771\n",
      "Epoch 423, Loss: 0.006912954850122333, Final Batch Loss: 0.0019817266147583723\n",
      "Epoch 424, Loss: 0.017366152722388506, Final Batch Loss: 0.014084894210100174\n",
      "Epoch 425, Loss: 0.016818308271467686, Final Batch Loss: 0.0032518282532691956\n",
      "Epoch 426, Loss: 0.01122241374105215, Final Batch Loss: 0.004520750138908625\n",
      "Epoch 427, Loss: 0.029306945390999317, Final Batch Loss: 0.018531395122408867\n",
      "Epoch 428, Loss: 0.010998305398970842, Final Batch Loss: 0.007449938915669918\n",
      "Epoch 429, Loss: 0.020237584598362446, Final Batch Loss: 0.018071629106998444\n",
      "Epoch 430, Loss: 0.018884427845478058, Final Batch Loss: 0.013416179455816746\n",
      "Epoch 431, Loss: 0.013995252549648285, Final Batch Loss: 0.0029845209792256355\n",
      "Epoch 432, Loss: 0.014271280029788613, Final Batch Loss: 0.011968773789703846\n",
      "Epoch 433, Loss: 0.016993291210383177, Final Batch Loss: 0.014855965971946716\n",
      "Epoch 434, Loss: 0.005352187901735306, Final Batch Loss: 0.0011605764739215374\n",
      "Epoch 435, Loss: 0.009763996582478285, Final Batch Loss: 0.001973422709852457\n",
      "Epoch 436, Loss: 0.013218211475759745, Final Batch Loss: 0.008932838216423988\n",
      "Epoch 437, Loss: 0.022185945883393288, Final Batch Loss: 0.012197625823318958\n",
      "Epoch 438, Loss: 0.010132675524801016, Final Batch Loss: 0.004606305155903101\n",
      "Epoch 439, Loss: 0.00891108182258904, Final Batch Loss: 0.006665548775345087\n",
      "Epoch 440, Loss: 0.025454744696617126, Final Batch Loss: 0.022184476256370544\n",
      "Epoch 441, Loss: 0.006443856982514262, Final Batch Loss: 0.0027484199963510036\n",
      "Epoch 442, Loss: 0.005867612548172474, Final Batch Loss: 0.0030367709696292877\n",
      "Epoch 443, Loss: 0.019162846030667424, Final Batch Loss: 0.015865225344896317\n",
      "Epoch 444, Loss: 0.0232487665489316, Final Batch Loss: 0.003990122117102146\n",
      "Epoch 445, Loss: 0.015120471827685833, Final Batch Loss: 0.009539606980979443\n",
      "Epoch 446, Loss: 0.007345002610236406, Final Batch Loss: 0.0030337232165038586\n",
      "Epoch 447, Loss: 0.014044444542378187, Final Batch Loss: 0.005453497637063265\n",
      "Epoch 448, Loss: 0.004774091299623251, Final Batch Loss: 0.002785484306514263\n",
      "Epoch 449, Loss: 0.007949292659759521, Final Batch Loss: 0.005632159765809774\n",
      "Epoch 450, Loss: 0.005606678314507008, Final Batch Loss: 0.0034826239570975304\n",
      "Epoch 451, Loss: 0.026832202915102243, Final Batch Loss: 0.023925919085741043\n",
      "Epoch 452, Loss: 0.04209373565390706, Final Batch Loss: 0.00441150413826108\n",
      "Epoch 453, Loss: 0.023472531232982874, Final Batch Loss: 0.018313610926270485\n",
      "Epoch 454, Loss: 0.01640356075949967, Final Batch Loss: 0.002725512022152543\n",
      "Epoch 455, Loss: 0.00532608712092042, Final Batch Loss: 0.001909999642521143\n",
      "Epoch 456, Loss: 0.027358581544831395, Final Batch Loss: 0.023563478142023087\n",
      "Epoch 457, Loss: 0.014569470775313675, Final Batch Loss: 0.0019423720659688115\n",
      "Epoch 458, Loss: 0.005874063586816192, Final Batch Loss: 0.004361432511359453\n",
      "Epoch 459, Loss: 0.01583849359303713, Final Batch Loss: 0.003074224106967449\n",
      "Epoch 460, Loss: 0.005865925922989845, Final Batch Loss: 0.003124081064015627\n",
      "Epoch 461, Loss: 0.016221451456658542, Final Batch Loss: 0.001463555614463985\n",
      "Epoch 462, Loss: 0.008756519993767142, Final Batch Loss: 0.003334257984533906\n",
      "Epoch 463, Loss: 0.010700876358896494, Final Batch Loss: 0.006870012264698744\n",
      "Epoch 464, Loss: 0.004800439928658307, Final Batch Loss: 0.000993226538412273\n",
      "Epoch 465, Loss: 0.006983327679336071, Final Batch Loss: 0.0036558890715241432\n",
      "Epoch 466, Loss: 0.013405356789007783, Final Batch Loss: 0.010584089905023575\n",
      "Epoch 467, Loss: 0.0052447516354732215, Final Batch Loss: 0.004329796880483627\n",
      "Epoch 468, Loss: 0.01889801397919655, Final Batch Loss: 0.010885410010814667\n",
      "Epoch 469, Loss: 0.03621402336284518, Final Batch Loss: 0.003292068373411894\n",
      "Epoch 470, Loss: 0.006982938153669238, Final Batch Loss: 0.003118119901046157\n",
      "Epoch 471, Loss: 0.00602004281245172, Final Batch Loss: 0.0036992584355175495\n",
      "Epoch 472, Loss: 0.006979047786444426, Final Batch Loss: 0.0032778880558907986\n",
      "Epoch 473, Loss: 0.0054821178782731295, Final Batch Loss: 0.002896058838814497\n",
      "Epoch 474, Loss: 0.014367037219926715, Final Batch Loss: 0.0025734358932822943\n",
      "Epoch 475, Loss: 0.02500430913642049, Final Batch Loss: 0.004285088274627924\n",
      "Epoch 476, Loss: 0.013205524068325758, Final Batch Loss: 0.0020134071819484234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477, Loss: 0.006857580738142133, Final Batch Loss: 0.00295214238576591\n",
      "Epoch 478, Loss: 0.0247041592374444, Final Batch Loss: 0.011502167209982872\n",
      "Epoch 479, Loss: 0.01822765450924635, Final Batch Loss: 0.005239257588982582\n",
      "Epoch 480, Loss: 0.009283947059884667, Final Batch Loss: 0.0013024380896240473\n",
      "Epoch 481, Loss: 0.009916054550558329, Final Batch Loss: 0.002466723322868347\n",
      "Epoch 482, Loss: 0.01771247759461403, Final Batch Loss: 0.014177820645272732\n",
      "Epoch 483, Loss: 0.008775162510573864, Final Batch Loss: 0.004791310988366604\n",
      "Epoch 484, Loss: 0.020354495849460363, Final Batch Loss: 0.003906428348273039\n",
      "Epoch 485, Loss: 0.004129496752284467, Final Batch Loss: 0.0015589402755722404\n",
      "Epoch 486, Loss: 0.015122492564842105, Final Batch Loss: 0.002146404003724456\n",
      "Epoch 487, Loss: 0.011867280350998044, Final Batch Loss: 0.0030036114621907473\n",
      "Epoch 488, Loss: 0.01125239534303546, Final Batch Loss: 0.008213710971176624\n",
      "Epoch 489, Loss: 0.004643642343580723, Final Batch Loss: 0.0034634293988347054\n",
      "Epoch 490, Loss: 0.02131278906017542, Final Batch Loss: 0.015840062871575356\n",
      "Epoch 491, Loss: 0.006092869327403605, Final Batch Loss: 0.0013528472045436502\n",
      "Epoch 492, Loss: 0.005172975827008486, Final Batch Loss: 0.002598275663331151\n",
      "Epoch 493, Loss: 0.0060812863521277905, Final Batch Loss: 0.00393443601205945\n",
      "Epoch 494, Loss: 0.030545773217454553, Final Batch Loss: 0.0023922736290842295\n",
      "Epoch 495, Loss: 0.012390121351927519, Final Batch Loss: 0.005480785388499498\n",
      "Epoch 496, Loss: 0.01624404964968562, Final Batch Loss: 0.010691116563975811\n",
      "Epoch 497, Loss: 0.004715128103271127, Final Batch Loss: 0.00269338209182024\n",
      "Epoch 498, Loss: 0.011540069244801998, Final Batch Loss: 0.001996898092329502\n",
      "Epoch 499, Loss: 0.004867077339440584, Final Batch Loss: 0.002902391366660595\n",
      "Epoch 500, Loss: 0.007274065399542451, Final Batch Loss: 0.005335619207471609\n",
      "Epoch 501, Loss: 0.010982703417539597, Final Batch Loss: 0.006608198396861553\n",
      "Epoch 502, Loss: 0.0037551510613411665, Final Batch Loss: 0.0012880407739430666\n",
      "Epoch 503, Loss: 0.011937907431274652, Final Batch Loss: 0.008078820072114468\n",
      "Epoch 504, Loss: 0.03696947544813156, Final Batch Loss: 0.0346231684088707\n",
      "Epoch 505, Loss: 0.006737357936799526, Final Batch Loss: 0.0015481896698474884\n",
      "Epoch 506, Loss: 0.012816775357350707, Final Batch Loss: 0.003485214663669467\n",
      "Epoch 507, Loss: 0.014489824476186186, Final Batch Loss: 0.0009710440062917769\n",
      "Epoch 508, Loss: 0.03222210332751274, Final Batch Loss: 0.008999260142445564\n",
      "Epoch 509, Loss: 0.013580184546299279, Final Batch Loss: 0.0013510260032489896\n",
      "Epoch 510, Loss: 0.03252937272191048, Final Batch Loss: 0.0202790517359972\n",
      "Epoch 511, Loss: 0.03232864150777459, Final Batch Loss: 0.026849986985325813\n",
      "Epoch 512, Loss: 0.00433594174683094, Final Batch Loss: 0.0011464885901659727\n",
      "Epoch 513, Loss: 0.027123861480504274, Final Batch Loss: 0.020871056243777275\n",
      "Epoch 514, Loss: 0.04106603330001235, Final Batch Loss: 0.03475967422127724\n",
      "Epoch 515, Loss: 0.018696577521041036, Final Batch Loss: 0.015959979966282845\n",
      "Epoch 516, Loss: 0.015003898181021214, Final Batch Loss: 0.0058577219024300575\n",
      "Epoch 517, Loss: 0.012626549578271806, Final Batch Loss: 0.001871371059678495\n",
      "Epoch 518, Loss: 0.017789257690310478, Final Batch Loss: 0.004573318175971508\n",
      "Epoch 519, Loss: 0.029184944927692413, Final Batch Loss: 0.016470640897750854\n",
      "Epoch 520, Loss: 0.012238061055541039, Final Batch Loss: 0.004762382246553898\n",
      "Epoch 521, Loss: 0.021828007884323597, Final Batch Loss: 0.014443554915487766\n",
      "Epoch 522, Loss: 0.05333509109914303, Final Batch Loss: 0.02280881442129612\n",
      "Epoch 523, Loss: 0.004242673749104142, Final Batch Loss: 0.0031112574506551027\n",
      "Epoch 524, Loss: 0.013054094975814223, Final Batch Loss: 0.011266356334090233\n",
      "Epoch 525, Loss: 0.023377100937068462, Final Batch Loss: 0.00588423665612936\n",
      "Epoch 526, Loss: 0.009165678173303604, Final Batch Loss: 0.002192394807934761\n",
      "Epoch 527, Loss: 0.03411634126678109, Final Batch Loss: 0.0022158310748636723\n",
      "Epoch 528, Loss: 0.009590318193659186, Final Batch Loss: 0.006566643249243498\n",
      "Epoch 529, Loss: 0.004235071945004165, Final Batch Loss: 0.0022977457847446203\n",
      "Epoch 530, Loss: 0.007421711692586541, Final Batch Loss: 0.004664492327719927\n",
      "Epoch 531, Loss: 0.012224224861711264, Final Batch Loss: 0.009346431121230125\n",
      "Epoch 532, Loss: 0.007192287594079971, Final Batch Loss: 0.0015745358541607857\n",
      "Epoch 533, Loss: 0.00830602366477251, Final Batch Loss: 0.003185002598911524\n",
      "Epoch 534, Loss: 0.004976851167157292, Final Batch Loss: 0.0020337204914540052\n",
      "Epoch 535, Loss: 0.004670054069720209, Final Batch Loss: 0.0015722318785265088\n",
      "Epoch 536, Loss: 0.017315840115770698, Final Batch Loss: 0.0026669499929994345\n",
      "Epoch 537, Loss: 0.015015860786661506, Final Batch Loss: 0.012378152459859848\n",
      "Epoch 538, Loss: 0.010600212030112743, Final Batch Loss: 0.004602915607392788\n",
      "Epoch 539, Loss: 0.023481269367039204, Final Batch Loss: 0.019235404208302498\n",
      "Epoch 540, Loss: 0.0036838760133832693, Final Batch Loss: 0.0018481711158528924\n",
      "Epoch 541, Loss: 0.010099942330271006, Final Batch Loss: 0.004163386765867472\n",
      "Epoch 542, Loss: 0.01781740109436214, Final Batch Loss: 0.016792966052889824\n",
      "Epoch 543, Loss: 0.004160303971730173, Final Batch Loss: 0.0014821196673437953\n",
      "Epoch 544, Loss: 0.009384719538502395, Final Batch Loss: 0.007831502705812454\n",
      "Epoch 545, Loss: 0.011474712286144495, Final Batch Loss: 0.0024417941458523273\n",
      "Epoch 546, Loss: 0.0024396995431743562, Final Batch Loss: 0.0005828749272041023\n",
      "Epoch 547, Loss: 0.004422754282131791, Final Batch Loss: 0.00231321738101542\n",
      "Epoch 548, Loss: 0.0076270586578175426, Final Batch Loss: 0.0014903804985806346\n",
      "Epoch 549, Loss: 0.007220926810987294, Final Batch Loss: 0.0015794538194313645\n",
      "Epoch 550, Loss: 0.00945703824982047, Final Batch Loss: 0.003177132923156023\n",
      "Epoch 551, Loss: 0.00645037367939949, Final Batch Loss: 0.0022123767994344234\n",
      "Epoch 552, Loss: 0.015553983161225915, Final Batch Loss: 0.012406363151967525\n",
      "Epoch 553, Loss: 0.004913981072604656, Final Batch Loss: 0.0027074660174548626\n",
      "Epoch 554, Loss: 0.0053890058770775795, Final Batch Loss: 0.0029245393816381693\n",
      "Epoch 555, Loss: 0.004150434222538024, Final Batch Loss: 0.0008930019685067236\n",
      "Epoch 556, Loss: 0.026196648250333965, Final Batch Loss: 0.0017505296273157\n",
      "Epoch 557, Loss: 0.01290425704792142, Final Batch Loss: 0.010260127484798431\n",
      "Epoch 558, Loss: 0.017632250674068928, Final Batch Loss: 0.002879851497709751\n",
      "Epoch 559, Loss: 0.004818588960915804, Final Batch Loss: 0.001442554173991084\n",
      "Epoch 560, Loss: 0.007188024697825313, Final Batch Loss: 0.002855615923181176\n",
      "Epoch 561, Loss: 0.00877954566385597, Final Batch Loss: 0.006946969777345657\n",
      "Epoch 562, Loss: 0.002820866764523089, Final Batch Loss: 0.0013910518027842045\n",
      "Epoch 563, Loss: 0.007237805286422372, Final Batch Loss: 0.0017090581823140383\n",
      "Epoch 564, Loss: 0.01187031134031713, Final Batch Loss: 0.001272799214348197\n",
      "Epoch 565, Loss: 0.008735439972952008, Final Batch Loss: 0.005562110338360071\n",
      "Epoch 566, Loss: 0.03423653915524483, Final Batch Loss: 0.023047924041748047\n",
      "Epoch 567, Loss: 0.0038382954662665725, Final Batch Loss: 0.0025870036333799362\n",
      "Epoch 568, Loss: 0.0045113228261470795, Final Batch Loss: 0.002548806369304657\n",
      "Epoch 569, Loss: 0.0032055698102340102, Final Batch Loss: 0.0022357290145009756\n",
      "Epoch 570, Loss: 0.0030427383026108146, Final Batch Loss: 0.0018685522954910994\n",
      "Epoch 571, Loss: 0.01377526915166527, Final Batch Loss: 0.012028963305056095\n",
      "Epoch 572, Loss: 0.004764142679050565, Final Batch Loss: 0.0028057650197297335\n",
      "Epoch 573, Loss: 0.016662606969475746, Final Batch Loss: 0.008272531442344189\n",
      "Epoch 574, Loss: 0.008760904660448432, Final Batch Loss: 0.005390373058617115\n",
      "Epoch 575, Loss: 0.0064197329338639975, Final Batch Loss: 0.0013985561672598124\n",
      "Epoch 576, Loss: 0.011740779969841242, Final Batch Loss: 0.0028651230968534946\n",
      "Epoch 577, Loss: 0.008756322087720037, Final Batch Loss: 0.006817895453423262\n",
      "Epoch 578, Loss: 0.007072969456203282, Final Batch Loss: 0.0019336786353960633\n",
      "Epoch 579, Loss: 0.008074041455984116, Final Batch Loss: 0.0021182107739150524\n",
      "Epoch 580, Loss: 0.006367433350533247, Final Batch Loss: 0.0021401108242571354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 581, Loss: 0.010382518055848777, Final Batch Loss: 0.0014772525755688548\n",
      "Epoch 582, Loss: 0.00936314178397879, Final Batch Loss: 0.0009198746993206441\n",
      "Epoch 583, Loss: 0.012863991199992597, Final Batch Loss: 0.011440911330282688\n",
      "Epoch 584, Loss: 0.00508900685235858, Final Batch Loss: 0.002781077055260539\n",
      "Epoch 585, Loss: 0.006449542241171002, Final Batch Loss: 0.0029542569536715746\n",
      "Epoch 586, Loss: 0.009193977108225226, Final Batch Loss: 0.007831316441297531\n",
      "Epoch 587, Loss: 0.008615237660706043, Final Batch Loss: 0.0030349199660122395\n",
      "Epoch 588, Loss: 0.007198407780379057, Final Batch Loss: 0.006122151855379343\n",
      "Epoch 589, Loss: 0.015277917264029384, Final Batch Loss: 0.0013255716767162085\n",
      "Epoch 590, Loss: 0.0036605229834094644, Final Batch Loss: 0.002470101695507765\n",
      "Epoch 591, Loss: 0.009501906111836433, Final Batch Loss: 0.004989278502762318\n",
      "Epoch 592, Loss: 0.005524100968614221, Final Batch Loss: 0.0014700444880872965\n",
      "Epoch 593, Loss: 0.003426241280976683, Final Batch Loss: 0.002868878422304988\n",
      "Epoch 594, Loss: 0.00812890031374991, Final Batch Loss: 0.005062389187514782\n",
      "Epoch 595, Loss: 0.024881815421395004, Final Batch Loss: 0.023208696395158768\n",
      "Epoch 596, Loss: 0.008746205363422632, Final Batch Loss: 0.0033311997540295124\n",
      "Epoch 597, Loss: 0.01104356674477458, Final Batch Loss: 0.006133918184787035\n",
      "Epoch 598, Loss: 0.00878887320868671, Final Batch Loss: 0.0025913517456501722\n",
      "Epoch 599, Loss: 0.00443054543575272, Final Batch Loss: 0.0008992952643893659\n",
      "Epoch 600, Loss: 0.00906728208065033, Final Batch Loss: 0.007009116001427174\n",
      "Epoch 601, Loss: 0.019310916308313608, Final Batch Loss: 0.012924685142934322\n",
      "Epoch 602, Loss: 0.007867238484323025, Final Batch Loss: 0.00576454633846879\n",
      "Epoch 603, Loss: 0.0018585488433018327, Final Batch Loss: 0.00075755943544209\n",
      "Epoch 604, Loss: 0.006505013589048758, Final Batch Loss: 0.00043845284380950034\n",
      "Epoch 605, Loss: 0.0014670017990283668, Final Batch Loss: 0.0004109750152565539\n",
      "Epoch 606, Loss: 0.004874374368228018, Final Batch Loss: 0.00297325081191957\n",
      "Epoch 607, Loss: 0.003676607913803309, Final Batch Loss: 0.0028841346502304077\n",
      "Epoch 608, Loss: 0.018196105491369963, Final Batch Loss: 0.007332353387027979\n",
      "Epoch 609, Loss: 0.007588957203552127, Final Batch Loss: 0.0031645798590034246\n",
      "Epoch 610, Loss: 0.004414259805344045, Final Batch Loss: 0.0013848711969330907\n",
      "Epoch 611, Loss: 0.00522153708152473, Final Batch Loss: 0.0007616325747221708\n",
      "Epoch 612, Loss: 0.02129555307328701, Final Batch Loss: 0.020255425944924355\n",
      "Epoch 613, Loss: 0.02350481692701578, Final Batch Loss: 0.022011693567037582\n",
      "Epoch 614, Loss: 0.02149752527475357, Final Batch Loss: 0.016609270125627518\n",
      "Epoch 615, Loss: 0.008690686197951436, Final Batch Loss: 0.0031619465444236994\n",
      "Epoch 616, Loss: 0.005154568352736533, Final Batch Loss: 0.004612044431269169\n",
      "Epoch 617, Loss: 0.003161864820867777, Final Batch Loss: 0.0016757383709773421\n",
      "Epoch 618, Loss: 0.011476041283458471, Final Batch Loss: 0.0013484531082212925\n",
      "Epoch 619, Loss: 0.011701169423758984, Final Batch Loss: 0.010035349987447262\n",
      "Epoch 620, Loss: 0.004859545035287738, Final Batch Loss: 0.002066534012556076\n",
      "Epoch 621, Loss: 0.0029961596010252833, Final Batch Loss: 0.0016144990222528577\n",
      "Epoch 622, Loss: 0.002505335316527635, Final Batch Loss: 0.0004939186037518084\n",
      "Epoch 623, Loss: 0.009835938923060894, Final Batch Loss: 0.005644230637699366\n",
      "Epoch 624, Loss: 0.00423859030706808, Final Batch Loss: 0.0009312088950537145\n",
      "Epoch 625, Loss: 0.005817597499117255, Final Batch Loss: 0.00328259589150548\n",
      "Epoch 626, Loss: 0.011711184866726398, Final Batch Loss: 0.005732949357479811\n",
      "Epoch 627, Loss: 0.023261190857738256, Final Batch Loss: 0.016589121893048286\n",
      "Epoch 628, Loss: 0.006963906926102936, Final Batch Loss: 0.0017516902880743146\n",
      "Epoch 629, Loss: 0.008746599312871695, Final Batch Loss: 0.001009349711239338\n",
      "Epoch 630, Loss: 0.008279696572571993, Final Batch Loss: 0.0024659871123731136\n",
      "Epoch 631, Loss: 0.010917127598077059, Final Batch Loss: 0.002347609493881464\n",
      "Epoch 632, Loss: 0.003520622383803129, Final Batch Loss: 0.0016707372851669788\n",
      "Epoch 633, Loss: 0.0038489620201289654, Final Batch Loss: 0.0010239456314593554\n",
      "Epoch 634, Loss: 0.0063743747305125, Final Batch Loss: 0.003044368466362357\n",
      "Epoch 635, Loss: 0.028696108609437943, Final Batch Loss: 0.009888984262943268\n",
      "Epoch 636, Loss: 0.004183721961453557, Final Batch Loss: 0.002054858487099409\n",
      "Epoch 637, Loss: 0.006840035784989595, Final Batch Loss: 0.0007839291356503963\n",
      "Epoch 638, Loss: 0.0037819560384377837, Final Batch Loss: 0.0010526686673983932\n",
      "Epoch 639, Loss: 0.0029913659673184156, Final Batch Loss: 0.0018106010975316167\n",
      "Epoch 640, Loss: 0.0032994026551023126, Final Batch Loss: 0.001664502895437181\n",
      "Epoch 641, Loss: 0.004958177334628999, Final Batch Loss: 0.0033651022240519524\n",
      "Epoch 642, Loss: 0.009004013380035758, Final Batch Loss: 0.006438647396862507\n",
      "Epoch 643, Loss: 0.0125761937815696, Final Batch Loss: 0.008699603378772736\n",
      "Epoch 644, Loss: 0.023761600023135543, Final Batch Loss: 0.022152770310640335\n",
      "Epoch 645, Loss: 0.014654156286269426, Final Batch Loss: 0.004409282002598047\n",
      "Epoch 646, Loss: 0.007445064606145024, Final Batch Loss: 0.003609507577493787\n",
      "Epoch 647, Loss: 0.0024665463715791702, Final Batch Loss: 0.0013880007900297642\n",
      "Epoch 648, Loss: 0.01133213471621275, Final Batch Loss: 0.0056058685295283794\n",
      "Epoch 649, Loss: 0.004427888547070324, Final Batch Loss: 0.0031579516362398863\n",
      "Epoch 650, Loss: 0.0029275253182277083, Final Batch Loss: 0.0012467836495488882\n",
      "Epoch 651, Loss: 0.004122614162042737, Final Batch Loss: 0.0013526610564440489\n",
      "Epoch 652, Loss: 0.0066562851425260305, Final Batch Loss: 0.0008078168611973524\n",
      "Epoch 653, Loss: 0.012886105105280876, Final Batch Loss: 0.008433040231466293\n",
      "Epoch 654, Loss: 0.005740998196415603, Final Batch Loss: 0.0005444901762530208\n",
      "Epoch 655, Loss: 0.0012660823413170874, Final Batch Loss: 0.0005123193259350955\n",
      "Epoch 656, Loss: 0.0029067709110677242, Final Batch Loss: 0.0011645018821582198\n",
      "Epoch 657, Loss: 0.0027280785143375397, Final Batch Loss: 0.0009939769515767694\n",
      "Epoch 658, Loss: 0.003914340632036328, Final Batch Loss: 0.0014898641966283321\n",
      "Epoch 659, Loss: 0.0012282078387215734, Final Batch Loss: 0.000529260141775012\n",
      "Epoch 660, Loss: 0.008213754859752953, Final Batch Loss: 0.0005618907744064927\n",
      "Epoch 661, Loss: 0.004690704867243767, Final Batch Loss: 0.0022373462561517954\n",
      "Epoch 662, Loss: 0.002179574337787926, Final Batch Loss: 0.0009736496722325683\n",
      "Epoch 663, Loss: 0.01206822576932609, Final Batch Loss: 0.001987370429560542\n",
      "Epoch 664, Loss: 0.008659368264488876, Final Batch Loss: 0.006774436682462692\n",
      "Epoch 665, Loss: 0.0037500268663279712, Final Batch Loss: 0.000758168229367584\n",
      "Epoch 666, Loss: 0.004005508206319064, Final Batch Loss: 0.003544497536495328\n",
      "Epoch 667, Loss: 0.003935868386179209, Final Batch Loss: 0.002516508335247636\n",
      "Epoch 668, Loss: 0.00506720517296344, Final Batch Loss: 0.0012779281241819263\n",
      "Epoch 669, Loss: 0.00494175823405385, Final Batch Loss: 0.0014197444543242455\n",
      "Epoch 670, Loss: 0.013459170935675502, Final Batch Loss: 0.012498290278017521\n",
      "Epoch 671, Loss: 0.004472552798688412, Final Batch Loss: 0.0005335425958037376\n",
      "Epoch 672, Loss: 0.008814998203888535, Final Batch Loss: 0.005014477763324976\n",
      "Epoch 673, Loss: 0.00770263746380806, Final Batch Loss: 0.0030922945588827133\n",
      "Epoch 674, Loss: 0.003437538573052734, Final Batch Loss: 0.0028162337839603424\n",
      "Epoch 675, Loss: 0.009623512509278953, Final Batch Loss: 0.008406483568251133\n",
      "Epoch 676, Loss: 0.008938567247241735, Final Batch Loss: 0.0047990730963647366\n",
      "Epoch 677, Loss: 0.0019120850483886898, Final Batch Loss: 0.001021526288241148\n",
      "Epoch 678, Loss: 0.003582187171559781, Final Batch Loss: 0.0005694070714525878\n",
      "Epoch 679, Loss: 0.0020518798264674842, Final Batch Loss: 0.0006516752182506025\n",
      "Epoch 680, Loss: 0.003273253096267581, Final Batch Loss: 0.0017032463802024722\n",
      "Epoch 681, Loss: 0.004525928990915418, Final Batch Loss: 0.0019138138741254807\n",
      "Epoch 682, Loss: 0.001909795799292624, Final Batch Loss: 0.0007502030348405242\n",
      "Epoch 683, Loss: 0.006457941955886781, Final Batch Loss: 0.0018767224391922355\n",
      "Epoch 684, Loss: 0.003553154063411057, Final Batch Loss: 0.0024258620105683804\n",
      "Epoch 685, Loss: 0.008280482375994325, Final Batch Loss: 0.0027717396151274443\n",
      "Epoch 686, Loss: 0.002887704875320196, Final Batch Loss: 0.0013226894661784172\n",
      "Epoch 687, Loss: 0.017725731246173382, Final Batch Loss: 0.0056895911693573\n",
      "Epoch 688, Loss: 0.005503531428985298, Final Batch Loss: 0.005057381000369787\n",
      "Epoch 689, Loss: 0.005540387239307165, Final Batch Loss: 0.0010224534198641777\n",
      "Epoch 690, Loss: 0.005930177285335958, Final Batch Loss: 0.0044386605732142925\n",
      "Epoch 691, Loss: 0.004278198990505189, Final Batch Loss: 0.0008005711133591831\n",
      "Epoch 692, Loss: 0.009965641307644546, Final Batch Loss: 0.0016836224822327495\n",
      "Epoch 693, Loss: 0.00354002823587507, Final Batch Loss: 0.002689326647669077\n",
      "Epoch 694, Loss: 0.003884365549311042, Final Batch Loss: 0.002698224037885666\n",
      "Epoch 695, Loss: 0.00421680643921718, Final Batch Loss: 0.0008813193417154253\n",
      "Epoch 696, Loss: 0.011145949189085513, Final Batch Loss: 0.00019920972408726811\n",
      "Epoch 697, Loss: 0.003168649855069816, Final Batch Loss: 0.0010905711678788066\n",
      "Epoch 698, Loss: 0.010178612661547959, Final Batch Loss: 0.0013545640977099538\n",
      "Epoch 699, Loss: 0.00809748622123152, Final Batch Loss: 0.0066839177161455154\n",
      "Epoch 700, Loss: 0.002669456764124334, Final Batch Loss: 0.0017512630438432097\n",
      "Epoch 701, Loss: 0.007406150223687291, Final Batch Loss: 0.006407285574823618\n",
      "Epoch 702, Loss: 0.0041656793328002095, Final Batch Loss: 0.0010320543078705668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 703, Loss: 0.005555810173973441, Final Batch Loss: 0.0013566839043051004\n",
      "Epoch 704, Loss: 0.007746259216219187, Final Batch Loss: 0.0048059504479169846\n",
      "Epoch 705, Loss: 0.0019551756558939815, Final Batch Loss: 0.0005034377099946141\n",
      "Epoch 706, Loss: 0.009579472476616502, Final Batch Loss: 0.0010208722669631243\n",
      "Epoch 707, Loss: 0.0022735294769518077, Final Batch Loss: 0.001587431412190199\n",
      "Epoch 708, Loss: 0.003980649576988071, Final Batch Loss: 0.0034429216757416725\n",
      "Epoch 709, Loss: 0.018746363348327577, Final Batch Loss: 0.017565468326210976\n",
      "Epoch 710, Loss: 0.0038377868477255106, Final Batch Loss: 0.0013505194801837206\n",
      "Epoch 711, Loss: 0.006747018545866013, Final Batch Loss: 0.004061330575495958\n",
      "Epoch 712, Loss: 0.002614355180412531, Final Batch Loss: 0.0014866938581690192\n",
      "Epoch 713, Loss: 0.00455006625270471, Final Batch Loss: 0.0009204267407767475\n",
      "Epoch 714, Loss: 0.011419261572882533, Final Batch Loss: 0.0017846308182924986\n",
      "Epoch 715, Loss: 0.008853978535626084, Final Batch Loss: 0.0007534903124906123\n",
      "Epoch 716, Loss: 0.002618041791720316, Final Batch Loss: 0.0021645885426551104\n",
      "Epoch 717, Loss: 0.011354965099599212, Final Batch Loss: 0.010897304862737656\n",
      "Epoch 718, Loss: 0.0009401225252076983, Final Batch Loss: 0.00033726776018738747\n",
      "Epoch 719, Loss: 0.0027397657395340502, Final Batch Loss: 0.0009262284147553146\n",
      "Epoch 720, Loss: 0.002617698279209435, Final Batch Loss: 0.0013457366731017828\n",
      "Epoch 721, Loss: 0.005780085455626249, Final Batch Loss: 0.0038728269282728434\n",
      "Epoch 722, Loss: 0.007683135801926255, Final Batch Loss: 0.004278874956071377\n",
      "Epoch 723, Loss: 0.015199139714241028, Final Batch Loss: 0.012147234752774239\n",
      "Epoch 724, Loss: 0.027591707184910774, Final Batch Loss: 0.0020736027508974075\n",
      "Epoch 725, Loss: 0.010788655985379592, Final Batch Loss: 0.00021273005404509604\n",
      "Epoch 726, Loss: 0.004477745038457215, Final Batch Loss: 0.0030143391340970993\n",
      "Epoch 727, Loss: 0.00831307889893651, Final Batch Loss: 0.006589260883629322\n",
      "Epoch 728, Loss: 0.006513531319797039, Final Batch Loss: 0.0026227333582937717\n",
      "Epoch 729, Loss: 0.03409679909236729, Final Batch Loss: 0.001585639314725995\n",
      "Epoch 730, Loss: 0.03606474492698908, Final Batch Loss: 0.00204643327742815\n",
      "Epoch 731, Loss: 0.005537236807867885, Final Batch Loss: 0.004192517604678869\n",
      "Epoch 732, Loss: 0.001814578427001834, Final Batch Loss: 0.0006190675776451826\n",
      "Epoch 733, Loss: 0.0020458518993109465, Final Batch Loss: 0.001272355206310749\n",
      "Epoch 734, Loss: 0.023481368087232113, Final Batch Loss: 0.01772727444767952\n",
      "Epoch 735, Loss: 0.023353228345513344, Final Batch Loss: 0.014907901175320148\n",
      "Epoch 736, Loss: 0.008392650168389082, Final Batch Loss: 0.006416158750653267\n",
      "Epoch 737, Loss: 0.00764551036991179, Final Batch Loss: 0.00233700149692595\n",
      "Epoch 738, Loss: 0.005122181202750653, Final Batch Loss: 0.0008378393831662834\n",
      "Epoch 739, Loss: 0.03025956585770473, Final Batch Loss: 0.0005438117659650743\n",
      "Epoch 740, Loss: 0.003921037190593779, Final Batch Loss: 0.001343444804660976\n",
      "Epoch 741, Loss: 0.007183580775745213, Final Batch Loss: 0.005366346333175898\n",
      "Epoch 742, Loss: 0.006740379030816257, Final Batch Loss: 0.0013719944981858134\n",
      "Epoch 743, Loss: 0.008444210980087519, Final Batch Loss: 0.004574479069560766\n",
      "Epoch 744, Loss: 0.004417691961862147, Final Batch Loss: 0.0026791898999363184\n",
      "Epoch 745, Loss: 0.006167825311422348, Final Batch Loss: 0.002614473458379507\n",
      "Epoch 746, Loss: 0.01924532710108906, Final Batch Loss: 0.017539944499731064\n",
      "Epoch 747, Loss: 0.004944235552102327, Final Batch Loss: 0.00300005916506052\n",
      "Epoch 748, Loss: 0.029034585691988468, Final Batch Loss: 0.018577495589852333\n",
      "Epoch 749, Loss: 0.0025010090321302414, Final Batch Loss: 0.0004993989132344723\n",
      "Epoch 750, Loss: 0.008430162444710732, Final Batch Loss: 0.005168405827134848\n",
      "Epoch 751, Loss: 0.0035124151036143303, Final Batch Loss: 0.0019165949197486043\n",
      "Epoch 752, Loss: 0.009976971428841352, Final Batch Loss: 0.007027804385870695\n",
      "Epoch 753, Loss: 0.002651026952662505, Final Batch Loss: 0.00018577698210719973\n",
      "Epoch 754, Loss: 0.03528096457011998, Final Batch Loss: 0.03166729956865311\n",
      "Epoch 755, Loss: 0.026537919649854302, Final Batch Loss: 0.0023394508752971888\n",
      "Epoch 756, Loss: 0.002105169405695051, Final Batch Loss: 0.001535389106720686\n",
      "Epoch 757, Loss: 0.002977795316837728, Final Batch Loss: 0.001713406527414918\n",
      "Epoch 758, Loss: 0.006025167880579829, Final Batch Loss: 0.0016258193645626307\n",
      "Epoch 759, Loss: 0.005038661533035338, Final Batch Loss: 0.0036765700206160545\n",
      "Epoch 760, Loss: 0.0026333702262490988, Final Batch Loss: 0.00042813317850232124\n",
      "Epoch 761, Loss: 0.002189092745538801, Final Batch Loss: 0.0005587959312833846\n",
      "Epoch 762, Loss: 0.006560128415003419, Final Batch Loss: 0.0038605311419814825\n",
      "Epoch 763, Loss: 0.0024794889613986015, Final Batch Loss: 0.0022005089558660984\n",
      "Epoch 764, Loss: 0.007079217350110412, Final Batch Loss: 0.00470665143802762\n",
      "Epoch 765, Loss: 0.001910714665427804, Final Batch Loss: 0.0013008782407268882\n",
      "Epoch 766, Loss: 0.0024105114862322807, Final Batch Loss: 0.0010083001106977463\n",
      "Epoch 767, Loss: 0.0062575137708336115, Final Batch Loss: 0.0035436891485005617\n",
      "Epoch 768, Loss: 0.008612248813733459, Final Batch Loss: 0.0008318775799125433\n",
      "Epoch 769, Loss: 0.003942743758670986, Final Batch Loss: 0.0015170782571658492\n",
      "Epoch 770, Loss: 0.01333886047359556, Final Batch Loss: 0.00041794718708842993\n",
      "Epoch 771, Loss: 0.0030092300148680806, Final Batch Loss: 0.0012277340283617377\n",
      "Epoch 772, Loss: 0.0016436040459666401, Final Batch Loss: 0.0012890641810372472\n",
      "Epoch 773, Loss: 0.0033574654953554273, Final Batch Loss: 0.0020306692458689213\n",
      "Epoch 774, Loss: 0.005207586917094886, Final Batch Loss: 0.001816029311157763\n",
      "Epoch 775, Loss: 0.011676004738546908, Final Batch Loss: 0.010190020315349102\n",
      "Epoch 776, Loss: 0.003196532401489094, Final Batch Loss: 0.0003507742949295789\n",
      "Epoch 777, Loss: 0.0021813370985910296, Final Batch Loss: 0.0011645385529845953\n",
      "Epoch 778, Loss: 0.005313260015100241, Final Batch Loss: 0.0024049305357038975\n",
      "Epoch 779, Loss: 0.004640538594685495, Final Batch Loss: 0.001449872856028378\n",
      "Epoch 780, Loss: 0.006392850307747722, Final Batch Loss: 0.0022308246698230505\n",
      "Epoch 781, Loss: 0.004795478191226721, Final Batch Loss: 0.002797001274302602\n",
      "Epoch 782, Loss: 0.005504427739651874, Final Batch Loss: 0.0002744647499639541\n",
      "Epoch 783, Loss: 0.004082959494553506, Final Batch Loss: 0.00220871577039361\n",
      "Epoch 784, Loss: 0.00304185674758628, Final Batch Loss: 0.000465725373942405\n",
      "Epoch 785, Loss: 0.008913557510823011, Final Batch Loss: 0.004124215804040432\n",
      "Epoch 786, Loss: 0.012644342612475157, Final Batch Loss: 0.0011665713973343372\n",
      "Epoch 787, Loss: 0.010650517651811242, Final Batch Loss: 0.0007221086416393518\n",
      "Epoch 788, Loss: 0.003315800684504211, Final Batch Loss: 0.0016966129187494516\n",
      "Epoch 789, Loss: 0.0052104271308053285, Final Batch Loss: 0.004814996849745512\n",
      "Epoch 790, Loss: 0.0042331701843068, Final Batch Loss: 0.001880345051176846\n",
      "Epoch 791, Loss: 0.0061732998583465815, Final Batch Loss: 0.0030772534664720297\n",
      "Epoch 792, Loss: 0.0018729299190454185, Final Batch Loss: 0.0010967605048790574\n",
      "Epoch 793, Loss: 0.0029827061807736754, Final Batch Loss: 0.002002968220040202\n",
      "Epoch 794, Loss: 0.002211111888755113, Final Batch Loss: 0.0008567663026042283\n",
      "Epoch 795, Loss: 0.022920025512576103, Final Batch Loss: 0.00537780299782753\n",
      "Epoch 796, Loss: 0.0070351314498111606, Final Batch Loss: 0.005146535579115152\n",
      "Epoch 797, Loss: 0.005063515854999423, Final Batch Loss: 0.002271160949021578\n",
      "Epoch 798, Loss: 0.0034374771639704704, Final Batch Loss: 0.0027960229199379683\n",
      "Epoch 799, Loss: 0.006100298487581313, Final Batch Loss: 0.005211183335632086\n",
      "Epoch 800, Loss: 0.0019449797691777349, Final Batch Loss: 0.001099590677767992\n",
      "Epoch 801, Loss: 0.00324451518827118, Final Batch Loss: 0.0003984537033829838\n",
      "Epoch 802, Loss: 0.005286367726512253, Final Batch Loss: 0.0019136065384373069\n",
      "Epoch 803, Loss: 0.00285999511834234, Final Batch Loss: 0.000655664480291307\n",
      "Epoch 804, Loss: 0.003099585883319378, Final Batch Loss: 0.00251668319106102\n",
      "Epoch 805, Loss: 0.03240573301445693, Final Batch Loss: 0.03115900233387947\n",
      "Epoch 806, Loss: 0.009681287221610546, Final Batch Loss: 0.0030417018570005894\n",
      "Epoch 807, Loss: 0.002995150280185044, Final Batch Loss: 0.00037294544745236635\n",
      "Epoch 808, Loss: 0.012057438434567302, Final Batch Loss: 0.0006017740233801305\n",
      "Epoch 809, Loss: 0.0029283627518452704, Final Batch Loss: 0.002431856468319893\n",
      "Epoch 810, Loss: 0.0016170865565072745, Final Batch Loss: 0.001193158095702529\n",
      "Epoch 811, Loss: 0.0033208943204954267, Final Batch Loss: 0.0014248080551624298\n",
      "Epoch 812, Loss: 0.028505304595455527, Final Batch Loss: 0.0015950256492942572\n",
      "Epoch 813, Loss: 0.0012374395155347884, Final Batch Loss: 0.0005353474407456815\n",
      "Epoch 814, Loss: 0.0028431848622858524, Final Batch Loss: 0.00125009729526937\n",
      "Epoch 815, Loss: 0.0033441779669374228, Final Batch Loss: 0.0010037219617515802\n",
      "Epoch 816, Loss: 0.016241046658251435, Final Batch Loss: 0.0007697390974499285\n",
      "Epoch 817, Loss: 0.0014228774816729128, Final Batch Loss: 0.001069281599484384\n",
      "Epoch 818, Loss: 0.003198905033059418, Final Batch Loss: 0.0024837851524353027\n",
      "Epoch 819, Loss: 0.0008520922856405377, Final Batch Loss: 0.0004184585122857243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820, Loss: 0.00669837137684226, Final Batch Loss: 0.004674444440752268\n",
      "Epoch 821, Loss: 0.006351737771183252, Final Batch Loss: 0.0003288942389190197\n",
      "Epoch 822, Loss: 0.0036595683195628226, Final Batch Loss: 0.0008495846414007246\n",
      "Epoch 823, Loss: 0.0028689000755548477, Final Batch Loss: 0.0016215862706303596\n",
      "Epoch 824, Loss: 0.0033132710959762335, Final Batch Loss: 0.0018958098953589797\n",
      "Epoch 825, Loss: 0.0015578914317302406, Final Batch Loss: 0.0005244589992798865\n",
      "Epoch 826, Loss: 0.002885506139136851, Final Batch Loss: 0.001701683853752911\n",
      "Epoch 827, Loss: 0.005685986019670963, Final Batch Loss: 0.003365391166880727\n",
      "Epoch 828, Loss: 0.0017448365688323975, Final Batch Loss: 0.0007527607958763838\n",
      "Epoch 829, Loss: 0.009565123124048114, Final Batch Loss: 0.0029488455038517714\n",
      "Epoch 830, Loss: 0.012667950359173119, Final Batch Loss: 0.012168959714472294\n",
      "Epoch 831, Loss: 0.019268023141194135, Final Batch Loss: 0.0007677919347770512\n",
      "Epoch 832, Loss: 0.0011725814547389746, Final Batch Loss: 0.0005131573998369277\n",
      "Epoch 833, Loss: 0.0021390955662354827, Final Batch Loss: 0.0009464714676141739\n",
      "Epoch 834, Loss: 0.0011941720731556416, Final Batch Loss: 0.0003861008444800973\n",
      "Epoch 835, Loss: 0.0028626404237002134, Final Batch Loss: 0.0018556795548647642\n",
      "Epoch 836, Loss: 0.003205923188943416, Final Batch Loss: 0.0022571992594748735\n",
      "Epoch 837, Loss: 0.007912534987553954, Final Batch Loss: 0.001374420477077365\n",
      "Epoch 838, Loss: 0.001067137229256332, Final Batch Loss: 0.0006991559639573097\n",
      "Epoch 839, Loss: 0.008375396486371756, Final Batch Loss: 0.001207123976200819\n",
      "Epoch 840, Loss: 0.001556802075356245, Final Batch Loss: 0.0007593981572426856\n",
      "Epoch 841, Loss: 0.0018099466687999666, Final Batch Loss: 0.0012824389850720763\n",
      "Epoch 842, Loss: 0.0014644386537838727, Final Batch Loss: 0.0011611542431637645\n",
      "Epoch 843, Loss: 0.03623020660597831, Final Batch Loss: 0.0008054898353293538\n",
      "Epoch 844, Loss: 0.003453371115028858, Final Batch Loss: 0.0017694270936772227\n",
      "Epoch 845, Loss: 0.0011781177599914372, Final Batch Loss: 0.0005495409714058042\n",
      "Epoch 846, Loss: 0.001762148691341281, Final Batch Loss: 0.0005768872797489166\n",
      "Epoch 847, Loss: 0.006469095591455698, Final Batch Loss: 0.004635454621165991\n",
      "Epoch 848, Loss: 0.003944629104807973, Final Batch Loss: 0.0017813330050557852\n",
      "Epoch 849, Loss: 0.026275352109223604, Final Batch Loss: 0.005242903251200914\n",
      "Epoch 850, Loss: 0.002927783934865147, Final Batch Loss: 0.0007873578579165041\n",
      "Epoch 851, Loss: 0.002031344047281891, Final Batch Loss: 0.0016982550732791424\n",
      "Epoch 852, Loss: 0.0006345430883811787, Final Batch Loss: 0.00022815483680460602\n",
      "Epoch 853, Loss: 0.0041324637131765485, Final Batch Loss: 0.0034150893334299326\n",
      "Epoch 854, Loss: 0.006129633344244212, Final Batch Loss: 0.00532531226053834\n",
      "Epoch 855, Loss: 0.013266418362036347, Final Batch Loss: 0.0024495834950357676\n",
      "Epoch 856, Loss: 0.0014173027593642473, Final Batch Loss: 0.00100706797093153\n",
      "Epoch 857, Loss: 0.0053658741526305676, Final Batch Loss: 0.0024054590612649918\n",
      "Epoch 858, Loss: 0.02152749802917242, Final Batch Loss: 0.016129465773701668\n",
      "Epoch 859, Loss: 0.019662796985358, Final Batch Loss: 0.0057137575931847095\n",
      "Epoch 860, Loss: 0.004986416315659881, Final Batch Loss: 0.0013605232816189528\n",
      "Epoch 861, Loss: 0.010701975334086455, Final Batch Loss: 0.000229753102757968\n",
      "Epoch 862, Loss: 0.005501964362338185, Final Batch Loss: 0.0003600397612899542\n",
      "Epoch 863, Loss: 0.0032649337081238627, Final Batch Loss: 0.0025629731826484203\n",
      "Epoch 864, Loss: 0.004875385347986594, Final Batch Loss: 0.004634188488125801\n",
      "Epoch 865, Loss: 0.0016386264760512859, Final Batch Loss: 0.0013692638603970408\n",
      "Epoch 866, Loss: 0.009868411580100656, Final Batch Loss: 0.008468796499073505\n",
      "Epoch 867, Loss: 0.001908990554511547, Final Batch Loss: 0.001306407619267702\n",
      "Epoch 868, Loss: 0.005405827483627945, Final Batch Loss: 0.0003743507550098002\n",
      "Epoch 869, Loss: 0.007232223520986736, Final Batch Loss: 0.005362400319427252\n",
      "Epoch 870, Loss: 0.0007453005237039179, Final Batch Loss: 0.0003776535450015217\n",
      "Epoch 871, Loss: 0.009555761935189366, Final Batch Loss: 0.008822133764624596\n",
      "Epoch 872, Loss: 0.0030630104593001306, Final Batch Loss: 0.0005882139666937292\n",
      "Epoch 873, Loss: 0.004743786994367838, Final Batch Loss: 0.002775488654151559\n",
      "Epoch 874, Loss: 0.0014216148993000388, Final Batch Loss: 0.0005242193583399057\n",
      "Epoch 875, Loss: 0.005118053639307618, Final Batch Loss: 0.0029666621703654528\n",
      "Epoch 876, Loss: 0.0035243265447206795, Final Batch Loss: 0.00097103655571118\n",
      "Epoch 877, Loss: 0.0013766612391918898, Final Batch Loss: 0.000722606957424432\n",
      "Epoch 878, Loss: 0.003449253155849874, Final Batch Loss: 0.0028093464206904173\n",
      "Epoch 879, Loss: 0.00486448488663882, Final Batch Loss: 0.0036367946304380894\n",
      "Epoch 880, Loss: 0.0035664936585817486, Final Batch Loss: 0.0031815411057323217\n",
      "Epoch 881, Loss: 0.0022421550238505006, Final Batch Loss: 0.0017068267334252596\n",
      "Epoch 882, Loss: 0.0007347745995502919, Final Batch Loss: 0.00017977532115764916\n",
      "Epoch 883, Loss: 0.007842765771783888, Final Batch Loss: 0.006617902312427759\n",
      "Epoch 884, Loss: 0.004531766753643751, Final Batch Loss: 0.0023464267142117023\n",
      "Epoch 885, Loss: 0.003027921717148274, Final Batch Loss: 0.002356157870963216\n",
      "Epoch 886, Loss: 0.0105952019803226, Final Batch Loss: 0.003201102837920189\n",
      "Epoch 887, Loss: 0.0014511554036289454, Final Batch Loss: 0.0005568219930864871\n",
      "Epoch 888, Loss: 0.007589141023345292, Final Batch Loss: 0.0013928796397522092\n",
      "Epoch 889, Loss: 0.0045001840917393565, Final Batch Loss: 0.001641979324631393\n",
      "Epoch 890, Loss: 0.00854224106296897, Final Batch Loss: 0.0014507188461720943\n",
      "Epoch 891, Loss: 0.0028359593998175114, Final Batch Loss: 0.0002801518130581826\n",
      "Epoch 892, Loss: 0.004350025032181293, Final Batch Loss: 0.0033955343533307314\n",
      "Epoch 893, Loss: 0.003848825581371784, Final Batch Loss: 0.0011653329711407423\n",
      "Epoch 894, Loss: 0.0025091954739764333, Final Batch Loss: 0.0011203923495486379\n",
      "Epoch 895, Loss: 0.0024369247548747808, Final Batch Loss: 0.0021036958787590265\n",
      "Epoch 896, Loss: 0.013602372724562883, Final Batch Loss: 0.0028660367242991924\n",
      "Epoch 897, Loss: 0.0025620094675105065, Final Batch Loss: 0.0022786494810134172\n",
      "Epoch 898, Loss: 0.007090965518727899, Final Batch Loss: 0.004622399341315031\n",
      "Epoch 899, Loss: 0.001654277730267495, Final Batch Loss: 0.0005344123928807676\n",
      "Epoch 900, Loss: 0.004594432655721903, Final Batch Loss: 0.0021552909165620804\n",
      "Epoch 901, Loss: 0.002586828893981874, Final Batch Loss: 0.002048564376309514\n",
      "Epoch 902, Loss: 0.002326323068700731, Final Batch Loss: 0.0010057085892185569\n",
      "Epoch 903, Loss: 0.012088707706425339, Final Batch Loss: 0.011114105582237244\n",
      "Epoch 904, Loss: 0.001581406861077994, Final Batch Loss: 0.0012769651366397738\n",
      "Epoch 905, Loss: 0.0006603518268093467, Final Batch Loss: 0.0002839178778231144\n",
      "Epoch 906, Loss: 0.0038553563645109534, Final Batch Loss: 0.002068672562018037\n",
      "Epoch 907, Loss: 0.0028767928306479007, Final Batch Loss: 0.0025813726242631674\n",
      "Epoch 908, Loss: 0.004006611765362322, Final Batch Loss: 0.002264817710965872\n",
      "Epoch 909, Loss: 0.001081581984180957, Final Batch Loss: 0.0006242894451133907\n",
      "Epoch 910, Loss: 0.001080471178283915, Final Batch Loss: 0.0007836840231902897\n",
      "Epoch 911, Loss: 0.00041325570782646537, Final Batch Loss: 0.0002056427620118484\n",
      "Epoch 912, Loss: 0.006788865226553753, Final Batch Loss: 0.0004265159659553319\n",
      "Epoch 913, Loss: 0.0018457123078405857, Final Batch Loss: 0.0009912009118124843\n",
      "Epoch 914, Loss: 0.00043946364894509315, Final Batch Loss: 0.00024478856357745826\n",
      "Epoch 915, Loss: 0.004834342485992238, Final Batch Loss: 0.0004267657350283116\n",
      "Epoch 916, Loss: 0.003600901225581765, Final Batch Loss: 0.002593452576547861\n",
      "Epoch 917, Loss: 0.0008589483477408066, Final Batch Loss: 0.0006298079970292747\n",
      "Epoch 918, Loss: 0.00640225934330374, Final Batch Loss: 0.005836101248860359\n",
      "Epoch 919, Loss: 0.004841182060772553, Final Batch Loss: 0.00018896270194090903\n",
      "Epoch 920, Loss: 0.011868488509207964, Final Batch Loss: 0.010038568638265133\n",
      "Epoch 921, Loss: 0.0017631689552217722, Final Batch Loss: 0.0012450561625882983\n",
      "Epoch 922, Loss: 0.007901092409156263, Final Batch Loss: 0.0012048938078805804\n",
      "Epoch 923, Loss: 0.0051024152198806405, Final Batch Loss: 0.001003571436740458\n",
      "Epoch 924, Loss: 0.0019632793264463544, Final Batch Loss: 0.001217960612848401\n",
      "Epoch 925, Loss: 0.002404824714176357, Final Batch Loss: 0.0007790758972987533\n",
      "Epoch 926, Loss: 0.0013980188232380897, Final Batch Loss: 0.0009879099670797586\n",
      "Epoch 927, Loss: 0.007616784190759063, Final Batch Loss: 0.0008751887362450361\n",
      "Epoch 928, Loss: 0.003462029853835702, Final Batch Loss: 0.002277218271046877\n",
      "Epoch 929, Loss: 0.0012951275566592813, Final Batch Loss: 0.0009784079156816006\n",
      "Epoch 930, Loss: 0.0024611663538962603, Final Batch Loss: 0.0010216967202723026\n",
      "Epoch 931, Loss: 0.001292314234888181, Final Batch Loss: 0.0002928775211330503\n",
      "Epoch 932, Loss: 0.0023860284709371626, Final Batch Loss: 0.0006306792492978275\n",
      "Epoch 933, Loss: 0.0022816357668489218, Final Batch Loss: 0.0019449401879683137\n",
      "Epoch 934, Loss: 0.003360627160873264, Final Batch Loss: 0.0008714054129086435\n",
      "Epoch 935, Loss: 0.0012769040768034756, Final Batch Loss: 0.0003142742207273841\n",
      "Epoch 936, Loss: 0.004011257318779826, Final Batch Loss: 0.0027371137402951717\n",
      "Epoch 937, Loss: 0.004238733905367553, Final Batch Loss: 0.003048509592190385\n",
      "Epoch 938, Loss: 0.001054072577971965, Final Batch Loss: 0.0003546609659679234\n",
      "Epoch 939, Loss: 0.0038066861452534795, Final Batch Loss: 0.001110419980250299\n",
      "Epoch 940, Loss: 0.005267427419312298, Final Batch Loss: 0.0017888605361804366\n",
      "Epoch 941, Loss: 0.0018632336286827922, Final Batch Loss: 0.001059704227373004\n",
      "Epoch 942, Loss: 0.006983508443227038, Final Batch Loss: 0.0004695892275776714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 943, Loss: 0.010011953301727772, Final Batch Loss: 0.0061246599070727825\n",
      "Epoch 944, Loss: 0.001636884466279298, Final Batch Loss: 0.0007124812691472471\n",
      "Epoch 945, Loss: 0.0013839465100318193, Final Batch Loss: 0.0007329599466174841\n",
      "Epoch 946, Loss: 0.004608172923326492, Final Batch Loss: 0.0018568418454378843\n",
      "Epoch 947, Loss: 0.003697733045555651, Final Batch Loss: 0.001094022416509688\n",
      "Epoch 948, Loss: 0.0021040732972323895, Final Batch Loss: 0.0007598066003993154\n",
      "Epoch 949, Loss: 0.0015387132880277932, Final Batch Loss: 0.0009143929346464574\n",
      "Epoch 950, Loss: 0.014301328046713024, Final Batch Loss: 0.000718417635653168\n",
      "Epoch 951, Loss: 0.01020831911591813, Final Batch Loss: 0.00044234207598492503\n",
      "Epoch 952, Loss: 0.009874961571767926, Final Batch Loss: 0.002067438093945384\n",
      "Epoch 953, Loss: 0.002283094683662057, Final Batch Loss: 0.0011127826292067766\n",
      "Epoch 954, Loss: 0.0032895040640141815, Final Batch Loss: 0.0030107658822089434\n",
      "Epoch 955, Loss: 0.001891468244139105, Final Batch Loss: 0.0010398047743365169\n",
      "Epoch 956, Loss: 0.002388217893894762, Final Batch Loss: 0.0009409896447323263\n",
      "Epoch 957, Loss: 0.0015986516955308616, Final Batch Loss: 0.0008171364897862077\n",
      "Epoch 958, Loss: 0.005565984640270472, Final Batch Loss: 0.004573527257889509\n",
      "Epoch 959, Loss: 0.021156532617169432, Final Batch Loss: 0.00014953494246583432\n",
      "Epoch 960, Loss: 0.004721081641037017, Final Batch Loss: 0.00421508215367794\n",
      "Epoch 961, Loss: 0.008474568545352668, Final Batch Loss: 0.00092263676924631\n",
      "Epoch 962, Loss: 0.009543808293528855, Final Batch Loss: 0.0009908882202580571\n",
      "Epoch 963, Loss: 0.002368502551689744, Final Batch Loss: 0.000604927190579474\n",
      "Epoch 964, Loss: 0.0013082843506708741, Final Batch Loss: 0.0010118125937879086\n",
      "Epoch 965, Loss: 0.0021165687358006835, Final Batch Loss: 0.0011445542331784964\n",
      "Epoch 966, Loss: 0.0005179611616767943, Final Batch Loss: 0.00023318917374126613\n",
      "Epoch 967, Loss: 0.0026685241609811783, Final Batch Loss: 0.0022460545878857374\n",
      "Epoch 968, Loss: 0.008953119569923729, Final Batch Loss: 0.0002030757605098188\n",
      "Epoch 969, Loss: 0.010714057803852484, Final Batch Loss: 0.0004327371425461024\n",
      "Epoch 970, Loss: 0.004490408668061718, Final Batch Loss: 0.00036305756657384336\n",
      "Epoch 971, Loss: 0.0010781544260680676, Final Batch Loss: 0.0006218116614036262\n",
      "Epoch 972, Loss: 0.0021407026797533035, Final Batch Loss: 0.0015489498618990183\n",
      "Epoch 973, Loss: 0.0013156962813809514, Final Batch Loss: 0.0003659502835944295\n",
      "Epoch 974, Loss: 0.0023642954765819013, Final Batch Loss: 0.0006802005809731781\n",
      "Epoch 975, Loss: 0.002969579567434266, Final Batch Loss: 0.00046334558282978833\n",
      "Epoch 976, Loss: 0.0019751953659579158, Final Batch Loss: 0.0014470287133008242\n",
      "Epoch 977, Loss: 0.0008330743585247546, Final Batch Loss: 0.00017107711755670607\n",
      "Epoch 978, Loss: 0.0022548005072167143, Final Batch Loss: 0.0021112319082021713\n",
      "Epoch 979, Loss: 0.002302164677530527, Final Batch Loss: 0.0019418819574639201\n",
      "Epoch 980, Loss: 0.0013580713130068034, Final Batch Loss: 0.0003022638557013124\n",
      "Epoch 981, Loss: 0.015287986607290804, Final Batch Loss: 0.01354033499956131\n",
      "Epoch 982, Loss: 0.005520927021279931, Final Batch Loss: 0.004479908850044012\n",
      "Epoch 983, Loss: 0.0007918953488115221, Final Batch Loss: 0.0004720740835182369\n",
      "Epoch 984, Loss: 0.009402986805071123, Final Batch Loss: 0.00019890554540324956\n",
      "Epoch 985, Loss: 0.0004038539045723155, Final Batch Loss: 0.0001286566402995959\n",
      "Epoch 986, Loss: 0.0010040766064776108, Final Batch Loss: 0.00015898524725344032\n",
      "Epoch 987, Loss: 0.0009202589571941644, Final Batch Loss: 0.0004480270144995302\n",
      "Epoch 988, Loss: 0.008872509934008121, Final Batch Loss: 0.00681060878559947\n",
      "Epoch 989, Loss: 0.001258532633073628, Final Batch Loss: 0.0006624902016483247\n",
      "Epoch 990, Loss: 0.0008357733604498208, Final Batch Loss: 0.000565652793738991\n",
      "Epoch 991, Loss: 0.002131452492903918, Final Batch Loss: 0.0015288818394765258\n",
      "Epoch 992, Loss: 0.006825598422437906, Final Batch Loss: 0.005246755201369524\n",
      "Epoch 993, Loss: 0.00159749248996377, Final Batch Loss: 0.001014579669572413\n",
      "Epoch 994, Loss: 0.0008276200678665191, Final Batch Loss: 0.0005148984491825104\n",
      "Epoch 995, Loss: 0.0068588754802476615, Final Batch Loss: 0.0003525977663230151\n",
      "Epoch 996, Loss: 0.003338166105095297, Final Batch Loss: 0.002513865241780877\n",
      "Epoch 997, Loss: 0.0027275662287138402, Final Batch Loss: 0.0004995024646632373\n",
      "Epoch 998, Loss: 0.007806542998878285, Final Batch Loss: 0.007334176916629076\n",
      "Epoch 999, Loss: 0.0041430279379710555, Final Batch Loss: 0.0009221121435984969\n",
      "Epoch 1000, Loss: 0.011300893384031951, Final Batch Loss: 0.009568939916789532\n",
      "Epoch 1001, Loss: 0.002154392917873338, Final Batch Loss: 0.00046114230644889176\n",
      "Epoch 1002, Loss: 0.002475437067914754, Final Batch Loss: 0.0009667918202467263\n",
      "Epoch 1003, Loss: 0.030595057643949986, Final Batch Loss: 0.016611604019999504\n",
      "Epoch 1004, Loss: 0.00025741918943822384, Final Batch Loss: 8.236950088758022e-05\n",
      "Epoch 1005, Loss: 0.0032951117609627545, Final Batch Loss: 0.00026605516904965043\n",
      "Epoch 1006, Loss: 0.0029650675132870674, Final Batch Loss: 0.0007655175868421793\n",
      "Epoch 1007, Loss: 0.0007923418306745589, Final Batch Loss: 0.00036540572182275355\n",
      "Epoch 1008, Loss: 0.016558279865421355, Final Batch Loss: 0.0011793650919571519\n",
      "Epoch 1009, Loss: 0.005623771343380213, Final Batch Loss: 0.003979154396802187\n",
      "Epoch 1010, Loss: 0.0032510844757780433, Final Batch Loss: 0.00141332414932549\n",
      "Epoch 1011, Loss: 0.006316308717941865, Final Batch Loss: 0.0058518508449196815\n",
      "Epoch 1012, Loss: 0.001241576945176348, Final Batch Loss: 0.00032976604416035116\n",
      "Epoch 1013, Loss: 0.004711532616056502, Final Batch Loss: 0.0014286873629316688\n",
      "Epoch 1014, Loss: 0.0006035740370862186, Final Batch Loss: 0.0002594037214294076\n",
      "Epoch 1015, Loss: 0.002083743514958769, Final Batch Loss: 0.0014370441203936934\n",
      "Epoch 1016, Loss: 0.018862460972741246, Final Batch Loss: 0.0016841415781527758\n",
      "Epoch 1017, Loss: 0.003244157414883375, Final Batch Loss: 0.0022062950301915407\n",
      "Epoch 1018, Loss: 0.0031907360535115004, Final Batch Loss: 0.0020154700614511967\n",
      "Epoch 1019, Loss: 0.002074565039947629, Final Batch Loss: 0.0014968722825869918\n",
      "Epoch 1020, Loss: 0.0005049738247180358, Final Batch Loss: 0.00016662255802657455\n",
      "Epoch 1021, Loss: 0.0010844639618881047, Final Batch Loss: 0.0008093724027276039\n",
      "Epoch 1022, Loss: 0.0005566829931922257, Final Batch Loss: 0.00037360546411946416\n",
      "Epoch 1023, Loss: 0.004263034381438047, Final Batch Loss: 0.003975806757807732\n",
      "Epoch 1024, Loss: 0.0040419723954983056, Final Batch Loss: 0.0008195045520551503\n",
      "Epoch 1025, Loss: 0.0016751509683672339, Final Batch Loss: 0.00020402754307724535\n",
      "Epoch 1026, Loss: 0.0008931242336984724, Final Batch Loss: 0.00032018989440985024\n",
      "Epoch 1027, Loss: 0.006710408139042556, Final Batch Loss: 0.001395010738633573\n",
      "Epoch 1028, Loss: 0.005041829543188214, Final Batch Loss: 0.0020544864237308502\n",
      "Epoch 1029, Loss: 0.0018236835385323502, Final Batch Loss: 8.058982348302379e-05\n",
      "Epoch 1030, Loss: 0.002067462890408933, Final Batch Loss: 0.0014476162614300847\n",
      "Epoch 1031, Loss: 0.0017594220553291962, Final Batch Loss: 0.0016065908130258322\n",
      "Epoch 1032, Loss: 0.0008748565160203725, Final Batch Loss: 0.0004592818149831146\n",
      "Epoch 1033, Loss: 0.003809585607086774, Final Batch Loss: 0.003712213132530451\n",
      "Epoch 1034, Loss: 0.0024260986247099936, Final Batch Loss: 0.0017032806063070893\n",
      "Epoch 1035, Loss: 0.0006739698001183569, Final Batch Loss: 0.0005196082056500018\n",
      "Epoch 1036, Loss: 0.0028810324147343636, Final Batch Loss: 0.0016073717270046473\n",
      "Epoch 1037, Loss: 0.0009078845323529094, Final Batch Loss: 0.0006107554654590786\n",
      "Epoch 1038, Loss: 0.005938807153142989, Final Batch Loss: 0.004854016937315464\n",
      "Epoch 1039, Loss: 0.005739553336752579, Final Batch Loss: 0.0004516369372140616\n",
      "Epoch 1040, Loss: 0.0027834524516947567, Final Batch Loss: 0.0021263740491122007\n",
      "Epoch 1041, Loss: 0.008387235342524946, Final Batch Loss: 0.00018148717936128378\n",
      "Epoch 1042, Loss: 0.005400485533755273, Final Batch Loss: 0.0007427643868140876\n",
      "Epoch 1043, Loss: 0.0021271586883813143, Final Batch Loss: 0.0007854740833863616\n",
      "Epoch 1044, Loss: 0.010398302809335291, Final Batch Loss: 0.008776997216045856\n",
      "Epoch 1045, Loss: 0.0028511456912383437, Final Batch Loss: 0.001613069325685501\n",
      "Epoch 1046, Loss: 0.001025129691697657, Final Batch Loss: 0.0005290493136271834\n",
      "Epoch 1047, Loss: 0.011928441701456904, Final Batch Loss: 0.009366617538034916\n",
      "Epoch 1048, Loss: 0.01596364501165226, Final Batch Loss: 0.015642555430531502\n",
      "Epoch 1049, Loss: 0.000957553944317624, Final Batch Loss: 0.0007381152245216072\n",
      "Epoch 1050, Loss: 0.0008895889623090625, Final Batch Loss: 0.0004710194771178067\n",
      "Epoch 1051, Loss: 0.0014080886903684586, Final Batch Loss: 0.00039455920341424644\n",
      "Epoch 1052, Loss: 0.0025210261810570955, Final Batch Loss: 0.001460936851799488\n",
      "Epoch 1053, Loss: 0.0007301022560568526, Final Batch Loss: 0.00018574782006908208\n",
      "Epoch 1054, Loss: 0.0014918125089025125, Final Batch Loss: 0.00013041913916822523\n",
      "Epoch 1055, Loss: 0.0008451556204818189, Final Batch Loss: 0.000616467441432178\n",
      "Epoch 1056, Loss: 0.0023932171752676368, Final Batch Loss: 0.0018907577032223344\n",
      "Epoch 1057, Loss: 0.0015684421523474157, Final Batch Loss: 0.000807568954769522\n",
      "Epoch 1058, Loss: 0.0009185372036881745, Final Batch Loss: 0.0004113412578590214\n",
      "Epoch 1059, Loss: 0.004861447116127238, Final Batch Loss: 0.00441998615860939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1060, Loss: 0.01025468111038208, Final Batch Loss: 0.002339843660593033\n",
      "Epoch 1061, Loss: 0.0023388602421619, Final Batch Loss: 6.912770913913846e-05\n",
      "Epoch 1062, Loss: 0.00992384242999833, Final Batch Loss: 0.0002431056200293824\n",
      "Epoch 1063, Loss: 0.0010459100594744086, Final Batch Loss: 0.00026477203937247396\n",
      "Epoch 1064, Loss: 0.000976890092715621, Final Batch Loss: 0.00029423669911921024\n",
      "Epoch 1065, Loss: 0.0028047849773429334, Final Batch Loss: 0.0005198399885557592\n",
      "Epoch 1066, Loss: 0.0006156601884867996, Final Batch Loss: 0.00036222688504494727\n",
      "Epoch 1067, Loss: 0.0030398934613913298, Final Batch Loss: 0.0016094765160232782\n",
      "Epoch 1068, Loss: 0.004900283529423177, Final Batch Loss: 0.0017914733616635203\n",
      "Epoch 1069, Loss: 0.004161453805863857, Final Batch Loss: 0.0011212658137083054\n",
      "Epoch 1070, Loss: 0.0008711862756172195, Final Batch Loss: 0.0006501554744318128\n",
      "Epoch 1071, Loss: 0.000645927430014126, Final Batch Loss: 0.00042597271385602653\n",
      "Epoch 1072, Loss: 0.002617920923512429, Final Batch Loss: 0.0005122792790643871\n",
      "Epoch 1073, Loss: 0.0015942633035592735, Final Batch Loss: 0.001133509911596775\n",
      "Epoch 1074, Loss: 0.0013835726713296026, Final Batch Loss: 0.0012474915711209178\n",
      "Epoch 1075, Loss: 0.0010825497593032196, Final Batch Loss: 0.00022026985243428499\n",
      "Epoch 1076, Loss: 0.001962927868589759, Final Batch Loss: 0.0012859972193837166\n",
      "Epoch 1077, Loss: 0.0007047707622405142, Final Batch Loss: 0.00036838659434579313\n",
      "Epoch 1078, Loss: 0.003134447382763028, Final Batch Loss: 0.0008064424619078636\n",
      "Epoch 1079, Loss: 0.006424105493351817, Final Batch Loss: 0.003999469801783562\n",
      "Epoch 1080, Loss: 0.0014381781802512705, Final Batch Loss: 0.0007729376084171236\n",
      "Epoch 1081, Loss: 0.001808793778764084, Final Batch Loss: 0.0016275540692731738\n",
      "Epoch 1082, Loss: 0.0012986439105588943, Final Batch Loss: 0.00041820594924502075\n",
      "Epoch 1083, Loss: 0.0015648054104531184, Final Batch Loss: 0.001424063928425312\n",
      "Epoch 1084, Loss: 0.035246966406702995, Final Batch Loss: 0.011891251429915428\n",
      "Epoch 1085, Loss: 0.000546853341802489, Final Batch Loss: 7.048175757518038e-05\n",
      "Epoch 1086, Loss: 0.0035338527522981167, Final Batch Loss: 0.0020441857632249594\n",
      "Epoch 1087, Loss: 0.0017389105923939496, Final Batch Loss: 0.00025025944341905415\n",
      "Epoch 1088, Loss: 0.002379662822932005, Final Batch Loss: 0.0010384982451796532\n",
      "Epoch 1089, Loss: 0.00112043390981853, Final Batch Loss: 0.0009168115793727338\n",
      "Epoch 1090, Loss: 0.0029520883108489215, Final Batch Loss: 0.00022323912708088756\n",
      "Epoch 1091, Loss: 0.0021688162814825773, Final Batch Loss: 0.0013386710779741406\n",
      "Epoch 1092, Loss: 0.0003412328369449824, Final Batch Loss: 0.00016869927640073001\n",
      "Epoch 1093, Loss: 0.005796200479380786, Final Batch Loss: 0.0004233074141666293\n",
      "Epoch 1094, Loss: 0.002193680324126035, Final Batch Loss: 0.0006425727042369545\n",
      "Epoch 1095, Loss: 0.0015409024781547487, Final Batch Loss: 0.0003120202454738319\n",
      "Epoch 1096, Loss: 0.003939300077036023, Final Batch Loss: 0.0010573400650173426\n",
      "Epoch 1097, Loss: 0.014597273198887706, Final Batch Loss: 0.012490905821323395\n",
      "Epoch 1098, Loss: 0.004241215996444225, Final Batch Loss: 0.0035726898349821568\n",
      "Epoch 1099, Loss: 0.0004966831766068935, Final Batch Loss: 0.00015987540245987475\n",
      "Epoch 1100, Loss: 0.0006599387488677166, Final Batch Loss: 8.964243897935376e-05\n",
      "Epoch 1101, Loss: 0.001670500379987061, Final Batch Loss: 0.0009427033364772797\n",
      "Epoch 1102, Loss: 0.00424531486351043, Final Batch Loss: 0.003877249313518405\n",
      "Epoch 1103, Loss: 0.0013760700530838221, Final Batch Loss: 0.0010435952572152019\n",
      "Epoch 1104, Loss: 0.0025681897095637396, Final Batch Loss: 0.0001436755555914715\n",
      "Epoch 1105, Loss: 0.003344565280713141, Final Batch Loss: 0.0023098739329725504\n",
      "Epoch 1106, Loss: 0.00036853905476164073, Final Batch Loss: 9.377535025123507e-05\n",
      "Epoch 1107, Loss: 0.0024470476200804114, Final Batch Loss: 0.0009903014870360494\n",
      "Epoch 1108, Loss: 0.002791359496768564, Final Batch Loss: 0.0022950414568185806\n",
      "Epoch 1109, Loss: 0.0017817493062466383, Final Batch Loss: 0.0005690656835213304\n",
      "Epoch 1110, Loss: 0.005142472917214036, Final Batch Loss: 0.001983720576390624\n",
      "Epoch 1111, Loss: 0.0034070466936100274, Final Batch Loss: 0.00029958647792227566\n",
      "Epoch 1112, Loss: 0.0029622174915857613, Final Batch Loss: 0.0021065459586679935\n",
      "Epoch 1113, Loss: 0.0007810293609509245, Final Batch Loss: 0.00024332340399269015\n",
      "Epoch 1114, Loss: 0.0010604780982248485, Final Batch Loss: 0.0004352437099441886\n",
      "Epoch 1115, Loss: 0.004116584663279355, Final Batch Loss: 0.0005491595948114991\n",
      "Epoch 1116, Loss: 0.0012539931485662237, Final Batch Loss: 0.00020240632875356823\n",
      "Epoch 1117, Loss: 0.0008855980704538524, Final Batch Loss: 0.00017167412443086505\n",
      "Epoch 1118, Loss: 0.001201934996061027, Final Batch Loss: 0.0006179281626828015\n",
      "Epoch 1119, Loss: 0.0010758602438727394, Final Batch Loss: 9.679597860667855e-05\n",
      "Epoch 1120, Loss: 0.0005482095439219847, Final Batch Loss: 7.161374378483742e-05\n",
      "Epoch 1121, Loss: 0.002146033337339759, Final Batch Loss: 0.0009242750238627195\n",
      "Epoch 1122, Loss: 0.005943700147327036, Final Batch Loss: 0.0002635754062794149\n",
      "Epoch 1123, Loss: 0.0032431427389383316, Final Batch Loss: 0.0002535947132855654\n",
      "Epoch 1124, Loss: 0.003765136527363211, Final Batch Loss: 0.0030183105263859034\n",
      "Epoch 1125, Loss: 0.00042113085510209203, Final Batch Loss: 0.0002354432363063097\n",
      "Epoch 1126, Loss: 0.0005398657231125981, Final Batch Loss: 0.0003352700441610068\n",
      "Epoch 1127, Loss: 0.0022811062226537615, Final Batch Loss: 0.0020345186349004507\n",
      "Epoch 1128, Loss: 0.0003988405369454995, Final Batch Loss: 0.00012823542056139559\n",
      "Epoch 1129, Loss: 0.0007835004653315991, Final Batch Loss: 0.00046563928481191397\n",
      "Epoch 1130, Loss: 0.001331537147052586, Final Batch Loss: 0.00038714270340278745\n",
      "Epoch 1131, Loss: 0.0015045973123051226, Final Batch Loss: 0.0005183803732506931\n",
      "Epoch 1132, Loss: 0.0008583076123613864, Final Batch Loss: 0.0005240990431047976\n",
      "Epoch 1133, Loss: 0.0015447468613274395, Final Batch Loss: 0.000940888246987015\n",
      "Epoch 1134, Loss: 0.0013891502458136529, Final Batch Loss: 0.001130748656578362\n",
      "Epoch 1135, Loss: 0.005453739388030954, Final Batch Loss: 0.005309300031512976\n",
      "Epoch 1136, Loss: 0.0026157981192227453, Final Batch Loss: 0.00038378415047191083\n",
      "Epoch 1137, Loss: 0.0025076972087845206, Final Batch Loss: 0.0010635640937834978\n",
      "Epoch 1138, Loss: 0.0006477501738118008, Final Batch Loss: 0.0005170736694708467\n",
      "Epoch 1139, Loss: 0.004834129678783938, Final Batch Loss: 0.00021670080604963005\n",
      "Epoch 1140, Loss: 0.0019842282636091113, Final Batch Loss: 0.0011941517004743218\n",
      "Epoch 1141, Loss: 0.008652502612676471, Final Batch Loss: 0.007772550918161869\n",
      "Epoch 1142, Loss: 0.0004257390828570351, Final Batch Loss: 0.0003169059637002647\n",
      "Epoch 1143, Loss: 0.00129015272250399, Final Batch Loss: 0.0008631998207420111\n",
      "Epoch 1144, Loss: 0.0011649630032479763, Final Batch Loss: 0.00051239097956568\n",
      "Epoch 1145, Loss: 0.001837864052504301, Final Batch Loss: 0.0006231038132682443\n",
      "Epoch 1146, Loss: 0.0019437011796981096, Final Batch Loss: 0.0013597103534266353\n",
      "Epoch 1147, Loss: 0.0057858891086652875, Final Batch Loss: 0.0018434502417221665\n",
      "Epoch 1148, Loss: 0.00042683869833126664, Final Batch Loss: 0.00024706489057280123\n",
      "Epoch 1149, Loss: 0.0007465256203431636, Final Batch Loss: 0.00024574800045229495\n",
      "Epoch 1150, Loss: 0.001279107527807355, Final Batch Loss: 0.000515972962602973\n",
      "Epoch 1151, Loss: 0.009045557351782918, Final Batch Loss: 0.007703057490289211\n",
      "Epoch 1152, Loss: 0.0008051787881413475, Final Batch Loss: 0.00016726362810004503\n",
      "Epoch 1153, Loss: 0.004256225540302694, Final Batch Loss: 0.002571320626884699\n",
      "Epoch 1154, Loss: 0.0010172004695050418, Final Batch Loss: 0.0005024143029004335\n",
      "Epoch 1155, Loss: 0.0007888804248068482, Final Batch Loss: 0.0004581198445521295\n",
      "Epoch 1156, Loss: 0.003495724842650816, Final Batch Loss: 0.003216275479644537\n",
      "Epoch 1157, Loss: 0.0021326749119907618, Final Batch Loss: 0.0007471261778846383\n",
      "Epoch 1158, Loss: 0.0006235886394279078, Final Batch Loss: 0.00014651504170615226\n",
      "Epoch 1159, Loss: 0.0005752717552240938, Final Batch Loss: 0.00042432936606928706\n",
      "Epoch 1160, Loss: 0.003560125012882054, Final Batch Loss: 0.0025704284198582172\n",
      "Epoch 1161, Loss: 0.0008193967223633081, Final Batch Loss: 0.0003217962512280792\n",
      "Epoch 1162, Loss: 0.00020696126739494503, Final Batch Loss: 6.759182724636048e-05\n",
      "Epoch 1163, Loss: 0.0016311999934259802, Final Batch Loss: 0.0012282575480639935\n",
      "Epoch 1164, Loss: 0.0024227930698543787, Final Batch Loss: 0.0011842441745102406\n",
      "Epoch 1165, Loss: 0.0009938733273884282, Final Batch Loss: 0.0001725544425426051\n",
      "Epoch 1166, Loss: 0.0008203929173760116, Final Batch Loss: 0.0005039586103521287\n",
      "Epoch 1167, Loss: 0.001836811745306477, Final Batch Loss: 0.00011627582716755569\n",
      "Epoch 1168, Loss: 0.0018928860226878896, Final Batch Loss: 0.0017077086959034204\n",
      "Epoch 1169, Loss: 0.004868531250394881, Final Batch Loss: 0.00331711582839489\n",
      "Epoch 1170, Loss: 0.00029366153466980904, Final Batch Loss: 0.00013848993694409728\n",
      "Epoch 1171, Loss: 0.0025403514155186713, Final Batch Loss: 0.0022714121732860804\n",
      "Epoch 1172, Loss: 0.001267642597667873, Final Batch Loss: 0.0009667434496805072\n",
      "Epoch 1173, Loss: 0.0012186592211946845, Final Batch Loss: 0.0007151240715757012\n",
      "Epoch 1174, Loss: 0.0025428615044802427, Final Batch Loss: 0.0018144414061680436\n",
      "Epoch 1175, Loss: 0.0027793813205789775, Final Batch Loss: 0.0004437083553057164\n",
      "Epoch 1176, Loss: 0.006863409653306007, Final Batch Loss: 0.004112630151212215\n",
      "Epoch 1177, Loss: 0.0018554797570686787, Final Batch Loss: 0.0016719319391995668\n",
      "Epoch 1178, Loss: 0.0005909628089284524, Final Batch Loss: 0.0003795899683609605\n",
      "Epoch 1179, Loss: 0.00023353825963567942, Final Batch Loss: 0.0001388767414027825\n",
      "Epoch 1180, Loss: 0.006726338411681354, Final Batch Loss: 0.0012011815560981631\n",
      "Epoch 1181, Loss: 0.0010566118289716542, Final Batch Loss: 0.00047448353143408895\n",
      "Epoch 1182, Loss: 0.001994244521483779, Final Batch Loss: 0.0016910835402086377\n",
      "Epoch 1183, Loss: 0.009640088050218765, Final Batch Loss: 8.219734445447102e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1184, Loss: 0.0010207529121544212, Final Batch Loss: 0.00015060373698361218\n",
      "Epoch 1185, Loss: 0.0014871275634504855, Final Batch Loss: 0.0010664884466677904\n",
      "Epoch 1186, Loss: 0.00041833671275526285, Final Batch Loss: 0.0001964095572475344\n",
      "Epoch 1187, Loss: 0.0005324585799826309, Final Batch Loss: 0.0002901950792875141\n",
      "Epoch 1188, Loss: 0.001025059202220291, Final Batch Loss: 0.0004299129359424114\n",
      "Epoch 1189, Loss: 0.0007979685033205897, Final Batch Loss: 0.00032146633020602167\n",
      "Epoch 1190, Loss: 0.0008297655440401286, Final Batch Loss: 0.00030791034805588424\n",
      "Epoch 1191, Loss: 0.009286641055950895, Final Batch Loss: 0.009056194685399532\n",
      "Epoch 1192, Loss: 0.0009540146274957806, Final Batch Loss: 0.00033870319020934403\n",
      "Epoch 1193, Loss: 0.0007623307901667431, Final Batch Loss: 0.0006133903516456485\n",
      "Epoch 1194, Loss: 0.004455618094652891, Final Batch Loss: 0.001806285697966814\n",
      "Epoch 1195, Loss: 0.0008631857926957309, Final Batch Loss: 0.00017325812950730324\n",
      "Epoch 1196, Loss: 0.0027730786241590977, Final Batch Loss: 0.0007843510247766972\n",
      "Epoch 1197, Loss: 0.0346975137363188, Final Batch Loss: 0.03416203707456589\n",
      "Epoch 1198, Loss: 0.0020627834601327777, Final Batch Loss: 0.0005701022455468774\n",
      "Epoch 1199, Loss: 0.0005169964424567297, Final Batch Loss: 0.0004215482040308416\n",
      "Epoch 1200, Loss: 0.0012422146392054856, Final Batch Loss: 0.00011734355939552188\n",
      "Epoch 1201, Loss: 0.0005988995253574103, Final Batch Loss: 0.0003605250676628202\n",
      "Epoch 1202, Loss: 0.008505932986736298, Final Batch Loss: 0.000322205014526844\n",
      "Epoch 1203, Loss: 0.001971870253328234, Final Batch Loss: 0.0004930908908136189\n",
      "Epoch 1204, Loss: 0.019077634904533625, Final Batch Loss: 0.0010920600034296513\n",
      "Epoch 1205, Loss: 0.0018156466248910874, Final Batch Loss: 0.0013700471026822925\n",
      "Epoch 1206, Loss: 0.0008443721162620932, Final Batch Loss: 0.0005860751844011247\n",
      "Epoch 1207, Loss: 0.0014548325852956623, Final Batch Loss: 0.00048338124179281294\n",
      "Epoch 1208, Loss: 0.0010651122429408133, Final Batch Loss: 0.0006776339141651988\n",
      "Epoch 1209, Loss: 0.006989104091189802, Final Batch Loss: 0.005421615671366453\n",
      "Epoch 1210, Loss: 0.006263196119107306, Final Batch Loss: 0.0018598331371322274\n",
      "Epoch 1211, Loss: 0.0026194178499281406, Final Batch Loss: 0.0018580621108412743\n",
      "Epoch 1212, Loss: 0.0017256918945349753, Final Batch Loss: 0.0013490341370925307\n",
      "Epoch 1213, Loss: 0.005055467947386205, Final Batch Loss: 0.004301259759813547\n",
      "Epoch 1214, Loss: 0.01608668512199074, Final Batch Loss: 0.015775173902511597\n",
      "Epoch 1215, Loss: 0.0004564850823953748, Final Batch Loss: 0.0003242413222324103\n",
      "Epoch 1216, Loss: 0.00024749099247856066, Final Batch Loss: 3.534633287927136e-05\n",
      "Epoch 1217, Loss: 0.0027354149788152426, Final Batch Loss: 0.0003330018080305308\n",
      "Epoch 1218, Loss: 0.011569599970243871, Final Batch Loss: 0.0001688230549916625\n",
      "Epoch 1219, Loss: 0.0026997797540389, Final Batch Loss: 0.002560057444497943\n",
      "Epoch 1220, Loss: 0.0013047991087660193, Final Batch Loss: 0.0005719122709706426\n",
      "Epoch 1221, Loss: 0.002541040175856324, Final Batch Loss: 5.348246850189753e-05\n",
      "Epoch 1222, Loss: 0.0037518539538723417, Final Batch Loss: 0.0036831542383879423\n",
      "Epoch 1223, Loss: 0.0022909684921614826, Final Batch Loss: 0.0016330510843545198\n",
      "Epoch 1224, Loss: 0.00037620959483319893, Final Batch Loss: 8.495673682773486e-05\n",
      "Epoch 1225, Loss: 0.0035999430110678077, Final Batch Loss: 0.0016684612492099404\n",
      "Epoch 1226, Loss: 0.01130402134731412, Final Batch Loss: 0.0005467995069921017\n",
      "Epoch 1227, Loss: 0.003692888480145484, Final Batch Loss: 0.0009453199454583228\n",
      "Epoch 1228, Loss: 0.0009281459642807022, Final Batch Loss: 0.00013931981811765581\n",
      "Epoch 1229, Loss: 0.0011763387301471084, Final Batch Loss: 0.00019904071814380586\n",
      "Epoch 1230, Loss: 0.0016479698824696243, Final Batch Loss: 0.0007330240914598107\n",
      "Epoch 1231, Loss: 0.0008303202921524644, Final Batch Loss: 0.0005196095444262028\n",
      "Epoch 1232, Loss: 0.014683420748042408, Final Batch Loss: 9.085794590646401e-05\n",
      "Epoch 1233, Loss: 0.0022269676119321957, Final Batch Loss: 0.0021639084443449974\n",
      "Epoch 1234, Loss: 0.0006761658951290883, Final Batch Loss: 8.242481999332085e-05\n",
      "Epoch 1235, Loss: 0.0012142888153903186, Final Batch Loss: 0.0006985845975577831\n",
      "Epoch 1236, Loss: 0.0022486429661512375, Final Batch Loss: 0.0018161394400522113\n",
      "Epoch 1237, Loss: 0.002876195008866489, Final Batch Loss: 0.0013998996000736952\n",
      "Epoch 1238, Loss: 0.0016260207048617303, Final Batch Loss: 0.0009541527251712978\n",
      "Epoch 1239, Loss: 0.00027364152629161254, Final Batch Loss: 0.00010497245966689661\n",
      "Epoch 1240, Loss: 0.00036962598096579313, Final Batch Loss: 0.00011767024989239872\n",
      "Epoch 1241, Loss: 0.0010111407027579844, Final Batch Loss: 0.0005188049981370568\n",
      "Epoch 1242, Loss: 0.012097240090952255, Final Batch Loss: 0.011894998140633106\n",
      "Epoch 1243, Loss: 0.006328132178168744, Final Batch Loss: 0.0005055686342529953\n",
      "Epoch 1244, Loss: 0.002016951300902292, Final Batch Loss: 0.0018187279347330332\n",
      "Epoch 1245, Loss: 0.000522771617397666, Final Batch Loss: 0.0002371399023104459\n",
      "Epoch 1246, Loss: 0.003035603673197329, Final Batch Loss: 0.0016475568991154432\n",
      "Epoch 1247, Loss: 0.030323445913381875, Final Batch Loss: 0.02994346432387829\n",
      "Epoch 1248, Loss: 0.0010276426910422742, Final Batch Loss: 0.00043830909999087453\n",
      "Epoch 1249, Loss: 0.0059462550561875105, Final Batch Loss: 0.001307099824771285\n",
      "Epoch 1250, Loss: 0.0018027143087238073, Final Batch Loss: 0.001422896864823997\n",
      "Epoch 1251, Loss: 0.0007628539751749486, Final Batch Loss: 0.0003582420467864722\n",
      "Epoch 1252, Loss: 0.0015083739417605102, Final Batch Loss: 0.000709009647835046\n",
      "Epoch 1253, Loss: 0.002728012390434742, Final Batch Loss: 0.0015243776142597198\n",
      "Epoch 1254, Loss: 0.0032286877976730466, Final Batch Loss: 0.002709069289267063\n",
      "Epoch 1255, Loss: 0.004641944193281233, Final Batch Loss: 0.0011042639380320907\n",
      "Epoch 1256, Loss: 0.002907495421823114, Final Batch Loss: 0.000465764373075217\n",
      "Epoch 1257, Loss: 0.0016081060166470706, Final Batch Loss: 0.0007519092760048807\n",
      "Epoch 1258, Loss: 0.0007689778576605022, Final Batch Loss: 0.0005768911796621978\n",
      "Epoch 1259, Loss: 0.0027336974162608385, Final Batch Loss: 0.0011739761102944613\n",
      "Epoch 1260, Loss: 0.0022841531899757683, Final Batch Loss: 0.001654727733694017\n",
      "Epoch 1261, Loss: 0.0003637413137766998, Final Batch Loss: 0.0003363296273164451\n",
      "Epoch 1262, Loss: 0.0003472099415375851, Final Batch Loss: 0.0002564936294220388\n",
      "Epoch 1263, Loss: 0.0083577701007016, Final Batch Loss: 0.007981909438967705\n",
      "Epoch 1264, Loss: 0.0023192308144643903, Final Batch Loss: 0.0013629038585349917\n",
      "Epoch 1265, Loss: 0.001343302195891738, Final Batch Loss: 0.0006271847523748875\n",
      "Epoch 1266, Loss: 0.00048388023787993006, Final Batch Loss: 0.00043428587378002703\n",
      "Epoch 1267, Loss: 0.006150606903247535, Final Batch Loss: 0.0004064299864694476\n",
      "Epoch 1268, Loss: 0.0011658813746180385, Final Batch Loss: 0.0003161727508995682\n",
      "Epoch 1269, Loss: 0.0006405573658412322, Final Batch Loss: 0.00011380929208826274\n",
      "Epoch 1270, Loss: 0.0034764796728268266, Final Batch Loss: 0.0005201000021770597\n",
      "Epoch 1271, Loss: 0.0008716679294593632, Final Batch Loss: 0.0006271744496189058\n",
      "Epoch 1272, Loss: 0.0026439904468134046, Final Batch Loss: 0.0016371464589610696\n",
      "Epoch 1273, Loss: 0.000334486408974044, Final Batch Loss: 0.0002485433069523424\n",
      "Epoch 1274, Loss: 0.0005293244466884062, Final Batch Loss: 0.00029809342231601477\n",
      "Epoch 1275, Loss: 0.0007230338815134019, Final Batch Loss: 0.00023916870122775435\n",
      "Epoch 1276, Loss: 0.006022115318046417, Final Batch Loss: 0.005914011970162392\n",
      "Epoch 1277, Loss: 0.0019254059297963977, Final Batch Loss: 0.00014547398313879967\n",
      "Epoch 1278, Loss: 0.0075813684379681945, Final Batch Loss: 0.006082470528781414\n",
      "Epoch 1279, Loss: 0.00031994965684134513, Final Batch Loss: 0.00014074523642193526\n",
      "Epoch 1280, Loss: 0.0009773866913747042, Final Batch Loss: 0.0006146527011878788\n",
      "Epoch 1281, Loss: 0.003403829177841544, Final Batch Loss: 0.0011972296051681042\n",
      "Epoch 1282, Loss: 0.04265889327507466, Final Batch Loss: 0.04156048223376274\n",
      "Epoch 1283, Loss: 0.0032703144061088096, Final Batch Loss: 4.863027061219327e-05\n",
      "Epoch 1284, Loss: 0.0021220343187451363, Final Batch Loss: 0.0007651952328160405\n",
      "Epoch 1285, Loss: 0.002628631889820099, Final Batch Loss: 0.0002695973962545395\n",
      "Epoch 1286, Loss: 0.008555752006941475, Final Batch Loss: 0.00017886866407934576\n",
      "Epoch 1287, Loss: 0.0038854839804116637, Final Batch Loss: 0.00018220875062979758\n",
      "Epoch 1288, Loss: 0.0025835508131422102, Final Batch Loss: 0.0008519866387359798\n",
      "Epoch 1289, Loss: 0.0012425745808286592, Final Batch Loss: 0.00012750404130201787\n",
      "Epoch 1290, Loss: 0.002556758699938655, Final Batch Loss: 0.0006346991285681725\n",
      "Epoch 1291, Loss: 0.0022528596746269614, Final Batch Loss: 0.0019219076493754983\n",
      "Epoch 1292, Loss: 0.01339134806767106, Final Batch Loss: 0.0008055600337684155\n",
      "Epoch 1293, Loss: 0.013561068568378687, Final Batch Loss: 0.009410684928297997\n",
      "Epoch 1294, Loss: 0.0015512877434957772, Final Batch Loss: 0.001107490505091846\n",
      "Epoch 1295, Loss: 0.000453632979770191, Final Batch Loss: 0.00023342217900790274\n",
      "Epoch 1296, Loss: 0.0008705345535418019, Final Batch Loss: 0.00021833843493368477\n",
      "Epoch 1297, Loss: 0.005458835628814995, Final Batch Loss: 0.0005882318364456296\n",
      "Epoch 1298, Loss: 0.001530173554783687, Final Batch Loss: 0.00040397929842583835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1299, Loss: 0.0017105909064412117, Final Batch Loss: 0.0008342742803506553\n",
      "Epoch 1300, Loss: 0.0013624774874188006, Final Batch Loss: 0.0008826420526020229\n",
      "Epoch 1301, Loss: 0.0007213755743578076, Final Batch Loss: 0.00033669115509837866\n",
      "Epoch 1302, Loss: 0.0030178463202901185, Final Batch Loss: 0.0022894362919032574\n",
      "Epoch 1303, Loss: 0.0023505672288592905, Final Batch Loss: 0.0018848094623535872\n",
      "Epoch 1304, Loss: 0.0006236465414986014, Final Batch Loss: 0.00032178114634007215\n",
      "Epoch 1305, Loss: 0.001030252838972956, Final Batch Loss: 0.0005204829503782094\n",
      "Epoch 1306, Loss: 0.0013746712065767497, Final Batch Loss: 0.001162530155852437\n",
      "Epoch 1307, Loss: 0.0037034577690064907, Final Batch Loss: 0.0034415980335325003\n",
      "Epoch 1308, Loss: 0.0026699407608248293, Final Batch Loss: 0.0006380121340043843\n",
      "Epoch 1309, Loss: 0.0018861830176319927, Final Batch Loss: 0.00030996286659501493\n",
      "Epoch 1310, Loss: 0.002480560913681984, Final Batch Loss: 0.0014374349266290665\n",
      "Epoch 1311, Loss: 0.001174247488961555, Final Batch Loss: 0.0010110741714015603\n",
      "Epoch 1312, Loss: 0.0015431734209414572, Final Batch Loss: 0.0004416618903633207\n",
      "Epoch 1313, Loss: 0.01414946754812263, Final Batch Loss: 0.00013130073784850538\n",
      "Epoch 1314, Loss: 0.006921706022694707, Final Batch Loss: 0.005568739492446184\n",
      "Epoch 1315, Loss: 0.0022265843581408262, Final Batch Loss: 0.0012013092637062073\n",
      "Epoch 1316, Loss: 0.0006411306967493147, Final Batch Loss: 0.00032729830127209425\n",
      "Epoch 1317, Loss: 0.0033237708848901093, Final Batch Loss: 0.0027196805458515882\n",
      "Epoch 1318, Loss: 0.00141806376632303, Final Batch Loss: 0.0006886684568598866\n",
      "Epoch 1319, Loss: 0.0007839272439014167, Final Batch Loss: 0.0002287964161951095\n",
      "Epoch 1320, Loss: 0.0008831433951854706, Final Batch Loss: 0.00023840036010369658\n",
      "Epoch 1321, Loss: 0.0009314139897469431, Final Batch Loss: 0.0005249182577244937\n",
      "Epoch 1322, Loss: 0.0005065071163699031, Final Batch Loss: 0.00017588341142982244\n",
      "Epoch 1323, Loss: 0.0016524473176104948, Final Batch Loss: 0.0001933230523718521\n",
      "Epoch 1324, Loss: 0.002008462295634672, Final Batch Loss: 0.00031082480563782156\n",
      "Epoch 1325, Loss: 0.004934065975248814, Final Batch Loss: 0.00246649282053113\n",
      "Epoch 1326, Loss: 0.004018851672299206, Final Batch Loss: 0.00288525503128767\n",
      "Epoch 1327, Loss: 0.007693506311625242, Final Batch Loss: 0.005692696664482355\n",
      "Epoch 1328, Loss: 0.002139883697964251, Final Batch Loss: 0.001603072858415544\n",
      "Epoch 1329, Loss: 0.0010093332966789603, Final Batch Loss: 0.0003819374833256006\n",
      "Epoch 1330, Loss: 0.0010597731452435255, Final Batch Loss: 0.0006972567643970251\n",
      "Epoch 1331, Loss: 0.0031210035376716405, Final Batch Loss: 0.0004026613023597747\n",
      "Epoch 1332, Loss: 0.0005234571726759896, Final Batch Loss: 0.00014435233606491238\n",
      "Epoch 1333, Loss: 0.0014383906091097742, Final Batch Loss: 0.0003475422563496977\n",
      "Epoch 1334, Loss: 0.0036397880176082253, Final Batch Loss: 0.00044645590241998434\n",
      "Epoch 1335, Loss: 0.0024619565228931606, Final Batch Loss: 0.0003433892852626741\n",
      "Epoch 1336, Loss: 0.0010471100395079702, Final Batch Loss: 0.00034035483258776367\n",
      "Epoch 1337, Loss: 0.0023890076554380357, Final Batch Loss: 0.001796323573216796\n",
      "Epoch 1338, Loss: 0.002664711937541142, Final Batch Loss: 0.0022136052139103413\n",
      "Epoch 1339, Loss: 0.0013897209719289094, Final Batch Loss: 0.00027034865343011916\n",
      "Epoch 1340, Loss: 0.004376183496788144, Final Batch Loss: 0.00373549060896039\n",
      "Epoch 1341, Loss: 0.0007225057051982731, Final Batch Loss: 0.0004440910997800529\n",
      "Epoch 1342, Loss: 0.0013203382331994362, Final Batch Loss: 7.531734445365146e-05\n",
      "Epoch 1343, Loss: 0.00045464009599527344, Final Batch Loss: 8.685109060024843e-05\n",
      "Epoch 1344, Loss: 0.003461721120402217, Final Batch Loss: 0.0009251576848328114\n",
      "Epoch 1345, Loss: 0.012694308810750954, Final Batch Loss: 0.012587427161633968\n",
      "Epoch 1346, Loss: 0.00045271319686435163, Final Batch Loss: 0.00015207965043373406\n",
      "Epoch 1347, Loss: 0.002234669227618724, Final Batch Loss: 0.0019797412678599358\n",
      "Epoch 1348, Loss: 0.0005220575258135796, Final Batch Loss: 0.00020131981000304222\n",
      "Epoch 1349, Loss: 0.0014174326133797877, Final Batch Loss: 7.26806974853389e-05\n",
      "Epoch 1350, Loss: 0.00217036489630118, Final Batch Loss: 0.0019262516871094704\n",
      "Epoch 1351, Loss: 0.0009335213690064847, Final Batch Loss: 0.0002871594042517245\n",
      "Epoch 1352, Loss: 0.004188281047390774, Final Batch Loss: 0.0003564989019650966\n",
      "Epoch 1353, Loss: 0.0057084469590336084, Final Batch Loss: 0.0003726824652403593\n",
      "Epoch 1354, Loss: 0.0015373197384178638, Final Batch Loss: 0.0005193318938836455\n",
      "Epoch 1355, Loss: 0.0011702179326675832, Final Batch Loss: 0.0005737034371122718\n",
      "Epoch 1356, Loss: 0.0075261343736201525, Final Batch Loss: 0.005528515204787254\n",
      "Epoch 1357, Loss: 0.013681781943887472, Final Batch Loss: 0.004746904131025076\n",
      "Epoch 1358, Loss: 0.001037764537613839, Final Batch Loss: 0.000667987740598619\n",
      "Epoch 1359, Loss: 0.0005040228425059468, Final Batch Loss: 0.00028714528889395297\n",
      "Epoch 1360, Loss: 0.001300317293498665, Final Batch Loss: 0.0008545973105356097\n",
      "Epoch 1361, Loss: 0.0005479158135131001, Final Batch Loss: 0.0001861840719357133\n",
      "Epoch 1362, Loss: 0.006100729224272072, Final Batch Loss: 0.0012627859832718968\n",
      "Epoch 1363, Loss: 0.0009272702736780047, Final Batch Loss: 0.00066894490737468\n",
      "Epoch 1364, Loss: 0.0005426779243862256, Final Batch Loss: 0.00019355468975845724\n",
      "Epoch 1365, Loss: 0.000798696419224143, Final Batch Loss: 0.0002723047509789467\n",
      "Epoch 1366, Loss: 0.002185850578825921, Final Batch Loss: 0.0005311946733854711\n",
      "Epoch 1367, Loss: 0.002898583421483636, Final Batch Loss: 0.0014016597997397184\n",
      "Epoch 1368, Loss: 0.0004146615829085931, Final Batch Loss: 0.00012074572441633791\n",
      "Epoch 1369, Loss: 0.004887735020020045, Final Batch Loss: 0.004684205632656813\n",
      "Epoch 1370, Loss: 0.0005799579375889152, Final Batch Loss: 0.0002611572272144258\n",
      "Epoch 1371, Loss: 0.0017730410327203572, Final Batch Loss: 0.000345974403899163\n",
      "Epoch 1372, Loss: 0.001523196027847007, Final Batch Loss: 0.0003383818839211017\n",
      "Epoch 1373, Loss: 0.01763223801390268, Final Batch Loss: 0.017415544018149376\n",
      "Epoch 1374, Loss: 0.001043506694259122, Final Batch Loss: 0.0005861892132088542\n",
      "Epoch 1375, Loss: 0.004629933268006425, Final Batch Loss: 0.004514588974416256\n",
      "Epoch 1376, Loss: 0.0016895155058591627, Final Batch Loss: 0.00011747547978302464\n",
      "Epoch 1377, Loss: 0.0005822241728310473, Final Batch Loss: 2.7014415536541492e-05\n",
      "Epoch 1378, Loss: 0.0020380173227749765, Final Batch Loss: 0.0009282547398470342\n",
      "Epoch 1379, Loss: 0.0027203071513213217, Final Batch Loss: 0.0021425550803542137\n",
      "Epoch 1380, Loss: 0.0008553007064620033, Final Batch Loss: 0.0006179213523864746\n",
      "Epoch 1381, Loss: 0.0011256445723120123, Final Batch Loss: 0.0004709082713816315\n",
      "Epoch 1382, Loss: 0.0002517121465643868, Final Batch Loss: 0.00017049501184374094\n",
      "Epoch 1383, Loss: 0.0007755326514597982, Final Batch Loss: 0.00033970948425121605\n",
      "Epoch 1384, Loss: 0.011495061233290471, Final Batch Loss: 0.00013200940156821162\n",
      "Epoch 1385, Loss: 0.000562866625841707, Final Batch Loss: 0.0004642916319426149\n",
      "Epoch 1386, Loss: 0.0010781347518786788, Final Batch Loss: 0.00029829214327037334\n",
      "Epoch 1387, Loss: 0.0014396226906683296, Final Batch Loss: 0.00044464223901741207\n",
      "Epoch 1388, Loss: 0.0009090445528272539, Final Batch Loss: 0.00012701711966656148\n",
      "Epoch 1389, Loss: 0.002169587940443307, Final Batch Loss: 0.0015675786416977644\n",
      "Epoch 1390, Loss: 0.000545098097063601, Final Batch Loss: 0.00021181750344112515\n",
      "Epoch 1391, Loss: 0.0005569934583036229, Final Batch Loss: 7.346172060351819e-05\n",
      "Epoch 1392, Loss: 0.000311463292746339, Final Batch Loss: 0.00020942685659974813\n",
      "Epoch 1393, Loss: 0.0015225055540213361, Final Batch Loss: 0.0013513925950974226\n",
      "Epoch 1394, Loss: 0.0027355270576663315, Final Batch Loss: 0.00016710051568225026\n",
      "Epoch 1395, Loss: 0.0010169132619921584, Final Batch Loss: 0.0009713850449770689\n",
      "Epoch 1396, Loss: 0.0005593241949100047, Final Batch Loss: 0.00027177896117791533\n",
      "Epoch 1397, Loss: 0.0007460679917130619, Final Batch Loss: 0.00039893179200589657\n",
      "Epoch 1398, Loss: 0.0067076759878546, Final Batch Loss: 0.00013914541341364384\n",
      "Epoch 1399, Loss: 0.0043543719802983105, Final Batch Loss: 0.0034346214961260557\n",
      "Epoch 1400, Loss: 0.0003443099922151305, Final Batch Loss: 0.0002297660830663517\n",
      "Epoch 1401, Loss: 0.0029494439950212836, Final Batch Loss: 0.00266378466039896\n",
      "Epoch 1402, Loss: 0.002781739894999191, Final Batch Loss: 0.00029395936871878803\n",
      "Epoch 1403, Loss: 0.001654335588682443, Final Batch Loss: 0.0009837442776188254\n",
      "Epoch 1404, Loss: 0.004387918394058943, Final Batch Loss: 0.0009160474874079227\n",
      "Epoch 1405, Loss: 0.0005199619336053729, Final Batch Loss: 0.0003267860156483948\n",
      "Epoch 1406, Loss: 0.0023346149537246674, Final Batch Loss: 4.035487654618919e-05\n",
      "Epoch 1407, Loss: 0.0014006526325829327, Final Batch Loss: 0.00023527344455942512\n",
      "Epoch 1408, Loss: 0.0008350059652002528, Final Batch Loss: 0.0007382315816357732\n",
      "Epoch 1409, Loss: 0.013062159516266547, Final Batch Loss: 0.01296142302453518\n",
      "Epoch 1410, Loss: 0.00100813084281981, Final Batch Loss: 0.0008060680702328682\n",
      "Epoch 1411, Loss: 0.0025552465085638687, Final Batch Loss: 0.00012205382518004626\n",
      "Epoch 1412, Loss: 0.0005101922070025466, Final Batch Loss: 7.860882760724053e-05\n",
      "Epoch 1413, Loss: 0.0010636917577357963, Final Batch Loss: 0.00019845827773679048\n",
      "Epoch 1414, Loss: 0.0006037912098690867, Final Batch Loss: 0.00041863424121402204\n",
      "Epoch 1415, Loss: 0.0014178997662384063, Final Batch Loss: 0.0004675747186411172\n",
      "Epoch 1416, Loss: 0.003227864275686443, Final Batch Loss: 0.0010147889843210578\n",
      "Epoch 1417, Loss: 0.0018190678674727678, Final Batch Loss: 0.0012122708139941096\n",
      "Epoch 1418, Loss: 0.0007085430261213332, Final Batch Loss: 0.00018366644508205354\n",
      "Epoch 1419, Loss: 0.002991617366205901, Final Batch Loss: 0.0005066599114798009\n",
      "Epoch 1420, Loss: 0.0029795251321047544, Final Batch Loss: 0.0026422743685543537\n",
      "Epoch 1421, Loss: 0.007300820725504309, Final Batch Loss: 0.0001628222526051104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1422, Loss: 0.0006160106204333715, Final Batch Loss: 7.041478966129944e-05\n",
      "Epoch 1423, Loss: 0.000908196801901795, Final Batch Loss: 0.000749024678952992\n",
      "Epoch 1424, Loss: 0.0006312711484497413, Final Batch Loss: 0.00019557679479476064\n",
      "Epoch 1425, Loss: 0.0010832893021870404, Final Batch Loss: 0.0002943079743999988\n",
      "Epoch 1426, Loss: 0.0015180991031229496, Final Batch Loss: 0.00026286125648766756\n",
      "Epoch 1427, Loss: 0.0005907394224777818, Final Batch Loss: 0.00028660346288233995\n",
      "Epoch 1428, Loss: 0.0013675777590833604, Final Batch Loss: 0.00046438933350145817\n",
      "Epoch 1429, Loss: 0.004737738930998603, Final Batch Loss: 0.004687197972089052\n",
      "Epoch 1430, Loss: 0.00025852782709989697, Final Batch Loss: 8.401944069191813e-05\n",
      "Epoch 1431, Loss: 0.0010759332108136732, Final Batch Loss: 4.9415382818551734e-05\n",
      "Epoch 1432, Loss: 0.0008906823713914491, Final Batch Loss: 0.000770502956584096\n",
      "Epoch 1433, Loss: 0.0024187284579966217, Final Batch Loss: 0.00016481560305692255\n",
      "Epoch 1434, Loss: 0.0006929217197466642, Final Batch Loss: 0.00026480978704057634\n",
      "Epoch 1435, Loss: 0.00046171685607987456, Final Batch Loss: 0.0004050790739711374\n",
      "Epoch 1436, Loss: 0.0020458346261875704, Final Batch Loss: 0.000197615081560798\n",
      "Epoch 1437, Loss: 0.0019667348242364824, Final Batch Loss: 0.0019267749739810824\n",
      "Epoch 1438, Loss: 0.0036896258825436234, Final Batch Loss: 0.0029461649246513844\n",
      "Epoch 1439, Loss: 0.01165919576305896, Final Batch Loss: 0.009979860857129097\n",
      "Epoch 1440, Loss: 0.0009692673629615456, Final Batch Loss: 0.00028129576821811497\n",
      "Epoch 1441, Loss: 0.0019102583028143272, Final Batch Loss: 0.00013973434397485107\n",
      "Epoch 1442, Loss: 0.0009060092888830695, Final Batch Loss: 0.0008509505423717201\n",
      "Epoch 1443, Loss: 0.00038253051752690226, Final Batch Loss: 0.00015938030264806002\n",
      "Epoch 1444, Loss: 0.002246855874545872, Final Batch Loss: 0.0015192199498414993\n",
      "Epoch 1445, Loss: 0.0011505019501782954, Final Batch Loss: 0.0005453652702271938\n",
      "Epoch 1446, Loss: 0.0004239551126374863, Final Batch Loss: 0.00010173982445849106\n",
      "Epoch 1447, Loss: 0.007468095660442486, Final Batch Loss: 0.0002544127928558737\n",
      "Epoch 1448, Loss: 0.00026226813497487456, Final Batch Loss: 0.00016125079127959907\n",
      "Epoch 1449, Loss: 0.004831069818465039, Final Batch Loss: 0.00031488967943005264\n",
      "Epoch 1450, Loss: 0.0012063233807566576, Final Batch Loss: 0.00010568915604380891\n",
      "Epoch 1451, Loss: 0.0006106425717007369, Final Batch Loss: 0.00023588899057358503\n",
      "Epoch 1452, Loss: 0.006616061087697744, Final Batch Loss: 0.0011813617311418056\n",
      "Epoch 1453, Loss: 0.005610078864265233, Final Batch Loss: 0.005328476894646883\n",
      "Epoch 1454, Loss: 0.0009753104459377937, Final Batch Loss: 0.00010973872122121975\n",
      "Epoch 1455, Loss: 0.00047956351045286283, Final Batch Loss: 0.00011161088332301006\n",
      "Epoch 1456, Loss: 0.0007296355906873941, Final Batch Loss: 0.00030730298021808267\n",
      "Epoch 1457, Loss: 0.0007049067062325776, Final Batch Loss: 0.0004409148241393268\n",
      "Epoch 1458, Loss: 0.0012862017028965056, Final Batch Loss: 0.0008356549078598619\n",
      "Epoch 1459, Loss: 0.0024837125092744827, Final Batch Loss: 0.0011398791102692485\n",
      "Epoch 1460, Loss: 0.00043373950029490516, Final Batch Loss: 0.0003384347655810416\n",
      "Epoch 1461, Loss: 0.0034584389941301197, Final Batch Loss: 0.000271899247309193\n",
      "Epoch 1462, Loss: 0.002261283472762443, Final Batch Loss: 0.0002141978038707748\n",
      "Epoch 1463, Loss: 0.007188264979049563, Final Batch Loss: 0.005698443856090307\n",
      "Epoch 1464, Loss: 0.0006597243482246995, Final Batch Loss: 0.00012990663526579738\n",
      "Epoch 1465, Loss: 0.0003173252807755489, Final Batch Loss: 5.1719154726015404e-05\n",
      "Epoch 1466, Loss: 0.0006937239813851193, Final Batch Loss: 0.00045872447662986815\n",
      "Epoch 1467, Loss: 0.002017456601606682, Final Batch Loss: 0.00017545805894769728\n",
      "Epoch 1468, Loss: 0.00026047247229143977, Final Batch Loss: 9.739166125655174e-05\n",
      "Epoch 1469, Loss: 0.0007132154714781791, Final Batch Loss: 0.0001161384570877999\n",
      "Epoch 1470, Loss: 0.0005112120052217506, Final Batch Loss: 9.306301217293367e-05\n",
      "Epoch 1471, Loss: 0.005138247579452582, Final Batch Loss: 0.00020591293286997825\n",
      "Epoch 1472, Loss: 0.011031954549252987, Final Batch Loss: 0.010701492428779602\n",
      "Epoch 1473, Loss: 0.00109949114266783, Final Batch Loss: 0.0005566160543821752\n",
      "Epoch 1474, Loss: 0.000363372775609605, Final Batch Loss: 0.0002900479012168944\n",
      "Epoch 1475, Loss: 0.0026714421692304313, Final Batch Loss: 0.0003704812261275947\n",
      "Epoch 1476, Loss: 0.0009337568480987102, Final Batch Loss: 0.0002696197188924998\n",
      "Epoch 1477, Loss: 0.0027897924883291125, Final Batch Loss: 0.0016760412836447358\n",
      "Epoch 1478, Loss: 0.008285829855594784, Final Batch Loss: 0.007370836101472378\n",
      "Epoch 1479, Loss: 0.0018469971546437591, Final Batch Loss: 0.0016648577293381095\n",
      "Epoch 1480, Loss: 0.001078963337931782, Final Batch Loss: 9.285140549764037e-05\n",
      "Epoch 1481, Loss: 0.014359722379595041, Final Batch Loss: 0.0038928077556192875\n",
      "Epoch 1482, Loss: 0.0009706704586278647, Final Batch Loss: 0.0007762889727018774\n",
      "Epoch 1483, Loss: 0.0019960393547080457, Final Batch Loss: 0.0006159830954857171\n",
      "Epoch 1484, Loss: 0.00149279079050757, Final Batch Loss: 0.00119417579844594\n",
      "Epoch 1485, Loss: 0.0004742438904941082, Final Batch Loss: 0.00026044182595796883\n",
      "Epoch 1486, Loss: 0.002685839746845886, Final Batch Loss: 0.00025709831970743835\n",
      "Epoch 1487, Loss: 0.0004970934460288845, Final Batch Loss: 3.084472700720653e-05\n",
      "Epoch 1488, Loss: 0.0005793279269710183, Final Batch Loss: 0.0004205236618872732\n",
      "Epoch 1489, Loss: 0.0007134191400837153, Final Batch Loss: 0.0003686378477141261\n",
      "Epoch 1490, Loss: 0.0004482709337025881, Final Batch Loss: 0.00031480746110901237\n",
      "Epoch 1491, Loss: 0.005377292021876201, Final Batch Loss: 0.005005476530641317\n",
      "Epoch 1492, Loss: 0.0061256998451426625, Final Batch Loss: 0.005797686520963907\n",
      "Epoch 1493, Loss: 0.0005388171703089029, Final Batch Loss: 0.00034535888698883355\n",
      "Epoch 1494, Loss: 0.006277061882428825, Final Batch Loss: 0.006147916428744793\n",
      "Epoch 1495, Loss: 0.0008050191390793771, Final Batch Loss: 0.00043118177563883364\n",
      "Epoch 1496, Loss: 0.0007788569782860577, Final Batch Loss: 0.0006669155554845929\n",
      "Epoch 1497, Loss: 0.007116185850463808, Final Batch Loss: 0.006446715909987688\n",
      "Epoch 1498, Loss: 0.0001737269376462791, Final Batch Loss: 0.00012093620171071962\n",
      "Epoch 1499, Loss: 0.0006428594060707837, Final Batch Loss: 0.00035300638410262764\n",
      "Epoch 1500, Loss: 0.0005053893546573818, Final Batch Loss: 0.00023687173961661756\n",
      "Epoch 1501, Loss: 0.00044523124233819544, Final Batch Loss: 0.0001618838869035244\n",
      "Epoch 1502, Loss: 0.0010519542556721717, Final Batch Loss: 0.000757596455514431\n",
      "Epoch 1503, Loss: 0.002985760715091601, Final Batch Loss: 0.002569526433944702\n",
      "Epoch 1504, Loss: 0.0010303600574843585, Final Batch Loss: 0.0005455198115669191\n",
      "Epoch 1505, Loss: 0.0073721096268855035, Final Batch Loss: 0.007228616159409285\n",
      "Epoch 1506, Loss: 0.002290232871018816, Final Batch Loss: 6.453606329159811e-05\n",
      "Epoch 1507, Loss: 0.00043611001819954254, Final Batch Loss: 0.0003841982688754797\n",
      "Epoch 1508, Loss: 0.00018974103659274988, Final Batch Loss: 0.00016159715596586466\n",
      "Epoch 1509, Loss: 0.0011134334199596196, Final Batch Loss: 0.00022988070850260556\n",
      "Epoch 1510, Loss: 0.001667931821430102, Final Batch Loss: 0.001390511286444962\n",
      "Epoch 1511, Loss: 0.006569574878085405, Final Batch Loss: 0.006021564826369286\n",
      "Epoch 1512, Loss: 0.0026285093917977065, Final Batch Loss: 0.002377790864557028\n",
      "Epoch 1513, Loss: 0.0012772808186127804, Final Batch Loss: 0.00010722813749453053\n",
      "Epoch 1514, Loss: 0.0005304537189658731, Final Batch Loss: 0.00028978943009860814\n",
      "Epoch 1515, Loss: 0.009384256933117285, Final Batch Loss: 0.008975883945822716\n",
      "Epoch 1516, Loss: 0.0005606977756542619, Final Batch Loss: 3.885276601067744e-05\n",
      "Epoch 1517, Loss: 0.0008772342443990055, Final Batch Loss: 5.4678446758771315e-05\n",
      "Epoch 1518, Loss: 0.0005253176277619787, Final Batch Loss: 0.0004177184891887009\n",
      "Epoch 1519, Loss: 0.0004763102042488754, Final Batch Loss: 0.00014517016825266182\n",
      "Epoch 1520, Loss: 0.0002371455484535545, Final Batch Loss: 0.00013138141366653144\n",
      "Epoch 1521, Loss: 0.0017038214718922973, Final Batch Loss: 0.000674750073812902\n",
      "Epoch 1522, Loss: 0.003247133456170559, Final Batch Loss: 0.0012133994605392218\n",
      "Epoch 1523, Loss: 0.003774813114432618, Final Batch Loss: 0.003414193168282509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1524, Loss: 0.0015189697733148932, Final Batch Loss: 0.0007526213303208351\n",
      "Epoch 1525, Loss: 0.0007188572926679626, Final Batch Loss: 0.00023502226395066828\n",
      "Epoch 1526, Loss: 0.0010911249555647373, Final Batch Loss: 0.00021762243704870343\n",
      "Epoch 1527, Loss: 0.0007692911167396232, Final Batch Loss: 0.000558334868401289\n",
      "Epoch 1528, Loss: 0.000949286186369136, Final Batch Loss: 0.00025169274886138737\n",
      "Epoch 1529, Loss: 0.001753994612954557, Final Batch Loss: 0.0003545399522408843\n",
      "Epoch 1530, Loss: 0.0007451612327713519, Final Batch Loss: 0.00023542941198684275\n",
      "Epoch 1531, Loss: 0.0006556930165970698, Final Batch Loss: 8.056599472183734e-05\n",
      "Epoch 1532, Loss: 0.000389258966606576, Final Batch Loss: 0.0001184999491670169\n",
      "Epoch 1533, Loss: 0.0010818536793522071, Final Batch Loss: 0.0010224906727671623\n",
      "Epoch 1534, Loss: 0.0003269568842370063, Final Batch Loss: 0.0001273387169931084\n",
      "Epoch 1535, Loss: 0.0001841414996306412, Final Batch Loss: 0.00010674774239305407\n",
      "Epoch 1536, Loss: 0.010200333083048463, Final Batch Loss: 0.000895956763997674\n",
      "Epoch 1537, Loss: 0.004227179859299213, Final Batch Loss: 0.0005435753264464438\n",
      "Epoch 1538, Loss: 0.002056224853731692, Final Batch Loss: 0.0009338257368654013\n",
      "Epoch 1539, Loss: 0.0020764367072843015, Final Batch Loss: 0.0005908156163059175\n",
      "Epoch 1540, Loss: 0.011442214716225863, Final Batch Loss: 0.002548535820096731\n",
      "Epoch 1541, Loss: 0.001621656061615795, Final Batch Loss: 0.0010074360761791468\n",
      "Epoch 1542, Loss: 0.0020911992178298533, Final Batch Loss: 0.0014465369749814272\n",
      "Epoch 1543, Loss: 0.0005657868041453185, Final Batch Loss: 2.9122124033165164e-05\n",
      "Epoch 1544, Loss: 0.014447384513914585, Final Batch Loss: 0.01405332051217556\n",
      "Epoch 1545, Loss: 0.002275753184221685, Final Batch Loss: 0.001743185450322926\n",
      "Epoch 1546, Loss: 0.0024186596856452525, Final Batch Loss: 0.0002399071236141026\n",
      "Epoch 1547, Loss: 0.003776552533963695, Final Batch Loss: 0.003472718643024564\n",
      "Epoch 1548, Loss: 0.004635205026715994, Final Batch Loss: 0.004382570739835501\n",
      "Epoch 1549, Loss: 0.0005019662639824674, Final Batch Loss: 0.00031912385020405054\n",
      "Epoch 1550, Loss: 0.0002421116514597088, Final Batch Loss: 0.00013562660024035722\n",
      "Epoch 1551, Loss: 0.0006863551971036941, Final Batch Loss: 0.00046034937258809805\n",
      "Epoch 1552, Loss: 0.0006894782127346843, Final Batch Loss: 0.00036189056118018925\n",
      "Epoch 1553, Loss: 0.0009318068332504481, Final Batch Loss: 0.0003642926167231053\n",
      "Epoch 1554, Loss: 0.005996818887069821, Final Batch Loss: 0.0012608689721673727\n",
      "Epoch 1555, Loss: 0.012112221564166248, Final Batch Loss: 0.01197785884141922\n",
      "Epoch 1556, Loss: 0.0006771538319298998, Final Batch Loss: 0.00015353011258412153\n",
      "Epoch 1557, Loss: 0.0013839188613928854, Final Batch Loss: 0.0009201520588248968\n",
      "Epoch 1558, Loss: 0.007623245837748982, Final Batch Loss: 0.007394266314804554\n",
      "Epoch 1559, Loss: 0.0003613512162701227, Final Batch Loss: 0.00026272659306414425\n",
      "Epoch 1560, Loss: 0.0004330488736741245, Final Batch Loss: 0.0001829050888773054\n",
      "Epoch 1561, Loss: 0.01152227028796915, Final Batch Loss: 9.943686018232256e-05\n",
      "Epoch 1562, Loss: 0.0015886258333921432, Final Batch Loss: 0.00036545388866215944\n",
      "Epoch 1563, Loss: 0.0008442605612799525, Final Batch Loss: 0.00010633573401719332\n",
      "Epoch 1564, Loss: 0.0015852053475100547, Final Batch Loss: 0.0001438561885152012\n",
      "Epoch 1565, Loss: 0.002036105841398239, Final Batch Loss: 0.0018156940350309014\n",
      "Epoch 1566, Loss: 0.004144997074035928, Final Batch Loss: 0.00010810067760758102\n",
      "Epoch 1567, Loss: 0.004468912462471053, Final Batch Loss: 0.004249701276421547\n",
      "Epoch 1568, Loss: 0.000888132257387042, Final Batch Loss: 0.00045107852201908827\n",
      "Epoch 1569, Loss: 0.008202776836697012, Final Batch Loss: 0.008106437511742115\n",
      "Epoch 1570, Loss: 0.004557674750685692, Final Batch Loss: 0.0026479591615498066\n",
      "Epoch 1571, Loss: 0.0004857047606492415, Final Batch Loss: 0.00029386687674559653\n",
      "Epoch 1572, Loss: 0.0022578786592930555, Final Batch Loss: 0.0010879125911742449\n",
      "Epoch 1573, Loss: 0.0216571032324282, Final Batch Loss: 3.73977491108235e-05\n",
      "Epoch 1574, Loss: 0.00021656455646734685, Final Batch Loss: 6.796196976210922e-05\n",
      "Epoch 1575, Loss: 0.00026400486240163445, Final Batch Loss: 0.00018988590454682708\n",
      "Epoch 1576, Loss: 0.0028269315662328154, Final Batch Loss: 0.0002802227681968361\n",
      "Epoch 1577, Loss: 0.002218238470959477, Final Batch Loss: 0.00019386706117074937\n",
      "Epoch 1578, Loss: 0.0011062503617722541, Final Batch Loss: 0.00010053699952550232\n",
      "Epoch 1579, Loss: 0.004355228738859296, Final Batch Loss: 0.0027340867090970278\n",
      "Epoch 1580, Loss: 0.00015810917830094695, Final Batch Loss: 8.865790732670575e-05\n",
      "Epoch 1581, Loss: 0.0003530253961798735, Final Batch Loss: 8.732992137083784e-05\n",
      "Epoch 1582, Loss: 0.000811734062153846, Final Batch Loss: 0.00048144927131943405\n",
      "Epoch 1583, Loss: 0.0016168172587640584, Final Batch Loss: 0.000513478007633239\n",
      "Epoch 1584, Loss: 0.0005980537534924224, Final Batch Loss: 0.0004949185531586409\n",
      "Epoch 1585, Loss: 0.000626660737907514, Final Batch Loss: 0.0003105094365309924\n",
      "Epoch 1586, Loss: 0.0007005015504546463, Final Batch Loss: 0.00011374359019100666\n",
      "Epoch 1587, Loss: 0.0022473412100225687, Final Batch Loss: 0.0016989801079034805\n",
      "Epoch 1588, Loss: 0.00044945716217625886, Final Batch Loss: 0.00024803963606245816\n",
      "Epoch 1589, Loss: 0.0010857094312086701, Final Batch Loss: 0.0007555625052191317\n",
      "Epoch 1590, Loss: 0.000302440210361965, Final Batch Loss: 0.00015434535453096032\n",
      "Epoch 1591, Loss: 0.007610140222823247, Final Batch Loss: 0.00731949508190155\n",
      "Epoch 1592, Loss: 0.0018834645161405206, Final Batch Loss: 0.00029709457885473967\n",
      "Epoch 1593, Loss: 0.0004454475420061499, Final Batch Loss: 0.00011663278564810753\n",
      "Epoch 1594, Loss: 0.0002334620112378616, Final Batch Loss: 4.759208604809828e-05\n",
      "Epoch 1595, Loss: 0.0013599134981632233, Final Batch Loss: 0.0004903277149423957\n",
      "Epoch 1596, Loss: 0.0006543440977111459, Final Batch Loss: 0.00035291677340865135\n",
      "Epoch 1597, Loss: 0.0014387494011316448, Final Batch Loss: 0.0001025708916131407\n",
      "Epoch 1598, Loss: 0.004585549206240103, Final Batch Loss: 0.00037233109469525516\n",
      "Epoch 1599, Loss: 0.0013611073954962194, Final Batch Loss: 0.0007952326559461653\n",
      "Epoch 1600, Loss: 0.0005625807971227914, Final Batch Loss: 0.00027490241336636245\n",
      "Epoch 1601, Loss: 0.00020284212951082736, Final Batch Loss: 0.00012221177166793495\n",
      "Epoch 1602, Loss: 0.0007157900836318731, Final Batch Loss: 0.00028095307061448693\n",
      "Epoch 1603, Loss: 0.0004901442662230693, Final Batch Loss: 0.0004369125817902386\n",
      "Epoch 1604, Loss: 0.00054834831826156, Final Batch Loss: 8.339800842804834e-05\n",
      "Epoch 1605, Loss: 0.0005124545132275671, Final Batch Loss: 0.00022865008213557303\n",
      "Epoch 1606, Loss: 0.00048105933819897473, Final Batch Loss: 0.00021583415218628943\n",
      "Epoch 1607, Loss: 0.0014337709581013769, Final Batch Loss: 0.00023436496849171817\n",
      "Epoch 1608, Loss: 0.00024349720479222015, Final Batch Loss: 4.75168417324312e-05\n",
      "Epoch 1609, Loss: 0.0018973724254465196, Final Batch Loss: 6.1018512496957555e-05\n",
      "Epoch 1610, Loss: 0.0016504256673215423, Final Batch Loss: 5.942333154962398e-05\n",
      "Epoch 1611, Loss: 0.00021411035413620993, Final Batch Loss: 3.084642958128825e-05\n",
      "Epoch 1612, Loss: 0.0012977317092008889, Final Batch Loss: 0.0009960572933778167\n",
      "Epoch 1613, Loss: 0.0005564674647757784, Final Batch Loss: 0.00021032705262769014\n",
      "Epoch 1614, Loss: 0.0016214608331210911, Final Batch Loss: 0.0009375903755426407\n",
      "Epoch 1615, Loss: 0.0006863218732178211, Final Batch Loss: 0.00035420808126218617\n",
      "Epoch 1616, Loss: 0.0002866190188797191, Final Batch Loss: 0.00019836463616229594\n",
      "Epoch 1617, Loss: 0.0003383921430213377, Final Batch Loss: 0.00019690682529471815\n",
      "Epoch 1618, Loss: 0.0008687089357408695, Final Batch Loss: 0.0001078899294952862\n",
      "Epoch 1619, Loss: 0.00015481136870221235, Final Batch Loss: 0.00010342052701162174\n",
      "Epoch 1620, Loss: 0.00033259502379223704, Final Batch Loss: 0.0001331266830675304\n",
      "Epoch 1621, Loss: 0.0019517521723173559, Final Batch Loss: 0.0014555028174072504\n",
      "Epoch 1622, Loss: 0.00047181008267216384, Final Batch Loss: 0.0003156409366056323\n",
      "Epoch 1623, Loss: 0.0003915497800335288, Final Batch Loss: 0.0003498762962408364\n",
      "Epoch 1624, Loss: 0.00019222405171603896, Final Batch Loss: 0.00015196962340269238\n",
      "Epoch 1625, Loss: 0.0007029826228972524, Final Batch Loss: 0.00021187550737522542\n",
      "Epoch 1626, Loss: 0.0004521166119957343, Final Batch Loss: 0.00021373025083448738\n",
      "Epoch 1627, Loss: 0.0006747446022927761, Final Batch Loss: 0.0003391906793694943\n",
      "Epoch 1628, Loss: 0.0015213976294035092, Final Batch Loss: 0.0001165876310551539\n",
      "Epoch 1629, Loss: 0.0010529258142923936, Final Batch Loss: 0.0008712938288226724\n",
      "Epoch 1630, Loss: 0.0005059102986706421, Final Batch Loss: 0.00040027411887422204\n",
      "Epoch 1631, Loss: 0.0031708196620456874, Final Batch Loss: 0.0026034133043140173\n",
      "Epoch 1632, Loss: 0.0006220634386409074, Final Batch Loss: 0.00039616241701878607\n",
      "Epoch 1633, Loss: 0.003462693974142894, Final Batch Loss: 0.00021686320542357862\n",
      "Epoch 1634, Loss: 0.0003722557521541603, Final Batch Loss: 6.39326244709082e-05\n",
      "Epoch 1635, Loss: 0.0019252304336987436, Final Batch Loss: 0.0003620993229560554\n",
      "Epoch 1636, Loss: 0.0008984070373116992, Final Batch Loss: 0.0008821934461593628\n",
      "Epoch 1637, Loss: 0.001659061475947965, Final Batch Loss: 6.270135781960562e-05\n",
      "Epoch 1638, Loss: 0.00020487116125877947, Final Batch Loss: 7.053177978377789e-05\n",
      "Epoch 1639, Loss: 0.008061045489739627, Final Batch Loss: 0.00010560144437476993\n",
      "Epoch 1640, Loss: 0.0006239140057004988, Final Batch Loss: 0.000251753197517246\n",
      "Epoch 1641, Loss: 0.001130308344727382, Final Batch Loss: 0.0006592284189537168\n",
      "Epoch 1642, Loss: 0.0019369674555491656, Final Batch Loss: 0.00023764159413985908\n",
      "Epoch 1643, Loss: 0.0003481493768049404, Final Batch Loss: 0.0001713472156552598\n",
      "Epoch 1644, Loss: 0.0007374116976279765, Final Batch Loss: 0.00043241248931735754\n",
      "Epoch 1645, Loss: 0.0008942173008108512, Final Batch Loss: 0.0006687352433800697\n",
      "Epoch 1646, Loss: 0.00029858111520297825, Final Batch Loss: 5.6383811170235276e-05\n",
      "Epoch 1647, Loss: 0.00022637614529230632, Final Batch Loss: 0.00016620045062154531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1648, Loss: 0.0002777995614451356, Final Batch Loss: 0.00022650737082585692\n",
      "Epoch 1649, Loss: 0.0002492858184268698, Final Batch Loss: 4.35042311437428e-05\n",
      "Epoch 1650, Loss: 0.0014931453915778548, Final Batch Loss: 0.00010367928189225495\n",
      "Epoch 1651, Loss: 0.0004411202244227752, Final Batch Loss: 0.00015467875346075743\n",
      "Epoch 1652, Loss: 0.001682616537436843, Final Batch Loss: 0.001104595372453332\n",
      "Epoch 1653, Loss: 0.0003341561896377243, Final Batch Loss: 7.964540418470278e-05\n",
      "Epoch 1654, Loss: 0.0004342434403952211, Final Batch Loss: 0.00020490078895818442\n",
      "Epoch 1655, Loss: 0.0019925966626033187, Final Batch Loss: 0.0013456776505336165\n",
      "Epoch 1656, Loss: 0.00011501677727210335, Final Batch Loss: 3.4495536965550855e-05\n",
      "Epoch 1657, Loss: 0.0005143548478372395, Final Batch Loss: 0.0002850646560546011\n",
      "Epoch 1658, Loss: 0.0007486072136089206, Final Batch Loss: 0.000392191024729982\n",
      "Epoch 1659, Loss: 0.00013029906676820247, Final Batch Loss: 1.1567269211809617e-05\n",
      "Epoch 1660, Loss: 0.0009941223506757524, Final Batch Loss: 1.7619106074562296e-05\n",
      "Epoch 1661, Loss: 0.00019335581600898877, Final Batch Loss: 0.00010246855526929721\n",
      "Epoch 1662, Loss: 0.0004057908518007025, Final Batch Loss: 0.00012125402281526476\n",
      "Epoch 1663, Loss: 0.002210543869296089, Final Batch Loss: 0.001893776934593916\n",
      "Epoch 1664, Loss: 0.000316081554046832, Final Batch Loss: 0.0001845440419856459\n",
      "Epoch 1665, Loss: 0.0007966122793732211, Final Batch Loss: 0.0005532209179364145\n",
      "Epoch 1666, Loss: 0.0029910898956586607, Final Batch Loss: 0.0029097513761371374\n",
      "Epoch 1667, Loss: 0.0016773938477854244, Final Batch Loss: 0.0016436955193057656\n",
      "Epoch 1668, Loss: 0.00042504790690145455, Final Batch Loss: 0.000390847708331421\n",
      "Epoch 1669, Loss: 0.00030184732167981565, Final Batch Loss: 0.00014749751426279545\n",
      "Epoch 1670, Loss: 0.004338489823567215, Final Batch Loss: 3.489244409138337e-05\n",
      "Epoch 1671, Loss: 0.0013042562059126794, Final Batch Loss: 0.0010137741919606924\n",
      "Epoch 1672, Loss: 0.005641971016302705, Final Batch Loss: 0.0013114700559526682\n",
      "Epoch 1673, Loss: 0.0018923449679277837, Final Batch Loss: 0.0005339639610610902\n",
      "Epoch 1674, Loss: 0.0009895582625176758, Final Batch Loss: 0.0005638930015265942\n",
      "Epoch 1675, Loss: 0.0015261542284861207, Final Batch Loss: 0.0005244724452495575\n",
      "Epoch 1676, Loss: 0.00017339934856863692, Final Batch Loss: 6.0258629673626274e-05\n",
      "Epoch 1677, Loss: 0.013083875994198024, Final Batch Loss: 0.0128423310816288\n",
      "Epoch 1678, Loss: 0.0009597198604751611, Final Batch Loss: 2.2271453417488374e-05\n",
      "Epoch 1679, Loss: 0.0035188759793527424, Final Batch Loss: 0.0028755106031894684\n",
      "Epoch 1680, Loss: 0.0004782448668265715, Final Batch Loss: 0.00023709643573965877\n",
      "Epoch 1681, Loss: 0.0004965770349372178, Final Batch Loss: 0.0003254766343161464\n",
      "Epoch 1682, Loss: 0.005088487989269197, Final Batch Loss: 0.0048918272368609905\n",
      "Epoch 1683, Loss: 0.0035923004325013608, Final Batch Loss: 0.0002160116273444146\n",
      "Epoch 1684, Loss: 6.701205165882129e-05, Final Batch Loss: 1.9926310415030457e-05\n",
      "Epoch 1685, Loss: 0.0010025879892054945, Final Batch Loss: 7.7466742368415e-05\n",
      "Epoch 1686, Loss: 0.00020660129666794091, Final Batch Loss: 4.097500641364604e-05\n",
      "Epoch 1687, Loss: 0.0007887454412411898, Final Batch Loss: 0.00038318600854836404\n",
      "Epoch 1688, Loss: 0.0002583688619779423, Final Batch Loss: 8.223041368182749e-05\n",
      "Epoch 1689, Loss: 0.042023977839562576, Final Batch Loss: 0.041975781321525574\n",
      "Epoch 1690, Loss: 0.0003952573606511578, Final Batch Loss: 0.00013222992129158229\n",
      "Epoch 1691, Loss: 0.00011294839168840554, Final Batch Loss: 2.098412915074732e-05\n",
      "Epoch 1692, Loss: 0.00037760123086627573, Final Batch Loss: 0.00017669718363322318\n",
      "Epoch 1693, Loss: 0.0005860634555574507, Final Batch Loss: 0.0002340534410905093\n",
      "Epoch 1694, Loss: 0.000587803398957476, Final Batch Loss: 0.00045150271034799516\n",
      "Epoch 1695, Loss: 0.0010615360661176965, Final Batch Loss: 0.0008311576093547046\n",
      "Epoch 1696, Loss: 0.0026211221447738353, Final Batch Loss: 0.0025726291351020336\n",
      "Epoch 1697, Loss: 0.004766672354890034, Final Batch Loss: 0.004411444067955017\n",
      "Epoch 1698, Loss: 0.0013535848120227456, Final Batch Loss: 0.0003745772410184145\n",
      "Epoch 1699, Loss: 0.0005001027602702379, Final Batch Loss: 0.00042630385723896325\n",
      "Epoch 1700, Loss: 0.0036210054968250915, Final Batch Loss: 0.0034496935550123453\n",
      "Epoch 1701, Loss: 0.016832391775096767, Final Batch Loss: 0.016617055982351303\n",
      "Epoch 1702, Loss: 0.0012835963352699764, Final Batch Loss: 0.0011760618072003126\n",
      "Epoch 1703, Loss: 0.0004581238026730716, Final Batch Loss: 0.00033985331538133323\n",
      "Epoch 1704, Loss: 0.001653410159633495, Final Batch Loss: 0.0015081269666552544\n",
      "Epoch 1705, Loss: 0.0008667498623253778, Final Batch Loss: 0.0006883021560497582\n",
      "Epoch 1706, Loss: 0.002027280948823318, Final Batch Loss: 0.0016197627410292625\n",
      "Epoch 1707, Loss: 0.0012384684996504802, Final Batch Loss: 0.0012121913023293018\n",
      "Epoch 1708, Loss: 0.0038209576159715652, Final Batch Loss: 0.0012357665691524744\n",
      "Epoch 1709, Loss: 6.30079121037852e-05, Final Batch Loss: 4.30428481195122e-05\n",
      "Epoch 1710, Loss: 0.0006925118650542572, Final Batch Loss: 0.000453492917586118\n",
      "Epoch 1711, Loss: 0.0008172709058271721, Final Batch Loss: 0.00020467974536586553\n",
      "Epoch 1712, Loss: 0.0003411795260035433, Final Batch Loss: 0.00026137183886021376\n",
      "Epoch 1713, Loss: 0.0033728439593687654, Final Batch Loss: 0.0002940065460279584\n",
      "Epoch 1714, Loss: 0.0011273270356468856, Final Batch Loss: 0.0010031318524852395\n",
      "Epoch 1715, Loss: 0.000150685209518997, Final Batch Loss: 0.00012039771536365151\n",
      "Epoch 1716, Loss: 0.0012352591802482493, Final Batch Loss: 0.0011261480394750834\n",
      "Epoch 1717, Loss: 0.0009094700799323618, Final Batch Loss: 0.0005703272763639688\n",
      "Epoch 1718, Loss: 0.0010412137635285035, Final Batch Loss: 5.523454456124455e-05\n",
      "Epoch 1719, Loss: 0.0001678641710896045, Final Batch Loss: 6.354216748150066e-05\n",
      "Epoch 1720, Loss: 0.0007604137936141342, Final Batch Loss: 0.0004328856011852622\n",
      "Epoch 1721, Loss: 0.0018603091884870082, Final Batch Loss: 0.00014971106429584324\n",
      "Epoch 1722, Loss: 0.00013081414726912044, Final Batch Loss: 7.139457011362538e-05\n",
      "Epoch 1723, Loss: 0.003891804561135359, Final Batch Loss: 7.208164606709033e-05\n",
      "Epoch 1724, Loss: 0.0004491208674153313, Final Batch Loss: 0.0003191422438248992\n",
      "Epoch 1725, Loss: 0.0003296388022135943, Final Batch Loss: 0.0001093151222448796\n",
      "Epoch 1726, Loss: 0.0023226368648465723, Final Batch Loss: 0.00022157173953019083\n",
      "Epoch 1727, Loss: 0.0004732151865027845, Final Batch Loss: 0.0002728556573856622\n",
      "Epoch 1728, Loss: 0.0010525840043555945, Final Batch Loss: 0.00024893382214941084\n",
      "Epoch 1729, Loss: 0.0015374767244793475, Final Batch Loss: 0.0006693863542750478\n",
      "Epoch 1730, Loss: 0.002485879056621343, Final Batch Loss: 0.0024202025961130857\n",
      "Epoch 1731, Loss: 0.00033820052340161055, Final Batch Loss: 0.00019597023492679\n",
      "Epoch 1732, Loss: 0.0005012905457988381, Final Batch Loss: 0.0003442321321927011\n",
      "Epoch 1733, Loss: 0.0013023198407609016, Final Batch Loss: 0.0011897410731762648\n",
      "Epoch 1734, Loss: 0.001576500174451212, Final Batch Loss: 1.260014050785685e-05\n",
      "Epoch 1735, Loss: 0.00023847688134992495, Final Batch Loss: 0.0001727127528283745\n",
      "Epoch 1736, Loss: 0.0001409078286087606, Final Batch Loss: 6.0692265833495185e-05\n",
      "Epoch 1737, Loss: 0.0011825661058537662, Final Batch Loss: 0.0006502623436972499\n",
      "Epoch 1738, Loss: 0.002754703731625341, Final Batch Loss: 0.00015587905363645405\n",
      "Epoch 1739, Loss: 0.0003809188783634454, Final Batch Loss: 0.000255323713645339\n",
      "Epoch 1740, Loss: 0.00023901996974018402, Final Batch Loss: 5.972895087325014e-05\n",
      "Epoch 1741, Loss: 0.0003032401582458988, Final Batch Loss: 0.00021168234525248408\n",
      "Epoch 1742, Loss: 0.0011163480812683702, Final Batch Loss: 0.0009350899490527809\n",
      "Epoch 1743, Loss: 0.0007327415514737368, Final Batch Loss: 0.0004263799637556076\n",
      "Epoch 1744, Loss: 0.00030748179415240884, Final Batch Loss: 0.000135548209073022\n",
      "Epoch 1745, Loss: 0.00034046433574985713, Final Batch Loss: 0.00018249073764309287\n",
      "Epoch 1746, Loss: 0.0007085565011948347, Final Batch Loss: 0.0004638385435100645\n",
      "Epoch 1747, Loss: 0.0012359996617306024, Final Batch Loss: 0.0003258103097323328\n",
      "Epoch 1748, Loss: 0.0008381478764931671, Final Batch Loss: 0.000748363439925015\n",
      "Epoch 1749, Loss: 0.00019904640794266015, Final Batch Loss: 0.0001185068249469623\n",
      "Epoch 1750, Loss: 0.0006329325988190249, Final Batch Loss: 0.0005591542576439679\n",
      "Epoch 1751, Loss: 0.0009137537272181362, Final Batch Loss: 0.0004539942310657352\n",
      "Epoch 1752, Loss: 0.00011715209257090464, Final Batch Loss: 7.324354373849928e-05\n",
      "Epoch 1753, Loss: 0.0005643571130349301, Final Batch Loss: 1.0772397217806429e-05\n",
      "Epoch 1754, Loss: 0.000557364630367374, Final Batch Loss: 3.9253875002032146e-05\n",
      "Epoch 1755, Loss: 0.0006200117713888176, Final Batch Loss: 8.193904795916751e-05\n",
      "Epoch 1756, Loss: 0.00013569685143011156, Final Batch Loss: 2.6417046683491208e-05\n",
      "Epoch 1757, Loss: 0.0014920386638550553, Final Batch Loss: 5.086319652036764e-05\n",
      "Epoch 1758, Loss: 0.00016021380724851042, Final Batch Loss: 6.321463297354057e-05\n",
      "Epoch 1759, Loss: 0.002877666018321179, Final Batch Loss: 0.00015931121015455574\n",
      "Epoch 1760, Loss: 0.00047312288006651215, Final Batch Loss: 5.371284714783542e-05\n",
      "Epoch 1761, Loss: 0.0005605184705927968, Final Batch Loss: 0.0002031062904279679\n",
      "Epoch 1762, Loss: 0.000923757459531771, Final Batch Loss: 3.34620890498627e-05\n",
      "Epoch 1763, Loss: 0.000539667973498581, Final Batch Loss: 5.4729560361010954e-05\n",
      "Epoch 1764, Loss: 0.01706186984665692, Final Batch Loss: 0.0022188706789165735\n",
      "Epoch 1765, Loss: 0.0021940069273114204, Final Batch Loss: 0.0011729779653251171\n",
      "Epoch 1766, Loss: 7.793894656060729e-05, Final Batch Loss: 5.4581440053880215e-05\n",
      "Epoch 1767, Loss: 0.0006091789982747287, Final Batch Loss: 0.0005114701925776899\n",
      "Epoch 1768, Loss: 0.00034196211709058844, Final Batch Loss: 0.00028792856028303504\n",
      "Epoch 1769, Loss: 0.00015389140935440082, Final Batch Loss: 2.866123577405233e-05\n",
      "Epoch 1770, Loss: 0.00014641673988080584, Final Batch Loss: 8.974631055025384e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1771, Loss: 0.0004499080423556734, Final Batch Loss: 4.616547448677011e-05\n",
      "Epoch 1772, Loss: 0.001695743943855632, Final Batch Loss: 0.0016170806484296918\n",
      "Epoch 1773, Loss: 0.001044664517394267, Final Batch Loss: 0.00016315314860548824\n",
      "Epoch 1774, Loss: 0.0003043095894099679, Final Batch Loss: 3.951304461224936e-05\n",
      "Epoch 1775, Loss: 0.0002519965164538007, Final Batch Loss: 5.173688623472117e-05\n",
      "Epoch 1776, Loss: 0.00011329018525430001, Final Batch Loss: 4.2057556129293516e-05\n",
      "Epoch 1777, Loss: 0.00039957338594831526, Final Batch Loss: 0.00016189261805266142\n",
      "Epoch 1778, Loss: 0.000409794785809936, Final Batch Loss: 4.337171048973687e-05\n",
      "Epoch 1779, Loss: 0.0011151628132211044, Final Batch Loss: 0.0010020239278674126\n",
      "Epoch 1780, Loss: 0.0012133559794165194, Final Batch Loss: 0.0004425153601914644\n",
      "Epoch 1781, Loss: 0.0008147406042553484, Final Batch Loss: 0.00046920424210838974\n",
      "Epoch 1782, Loss: 0.0022839642188046128, Final Batch Loss: 0.001809511217288673\n",
      "Epoch 1783, Loss: 0.00018638392793945968, Final Batch Loss: 9.832219802774489e-05\n",
      "Epoch 1784, Loss: 0.00042619033774826676, Final Batch Loss: 0.00017973790818359703\n",
      "Epoch 1785, Loss: 0.004016685405076714, Final Batch Loss: 3.8283051253529266e-05\n",
      "Epoch 1786, Loss: 0.0062503169174306095, Final Batch Loss: 0.0007779716397635639\n",
      "Epoch 1787, Loss: 0.00021886223657929804, Final Batch Loss: 2.9127264497219585e-05\n",
      "Epoch 1788, Loss: 0.0006825503951404244, Final Batch Loss: 0.0006159812328405678\n",
      "Epoch 1789, Loss: 0.0001444447916583158, Final Batch Loss: 9.370291809318587e-05\n",
      "Epoch 1790, Loss: 0.0010470885026734322, Final Batch Loss: 0.0005622439202852547\n",
      "Epoch 1791, Loss: 0.000106423757642915, Final Batch Loss: 1.5075550436449703e-05\n",
      "Epoch 1792, Loss: 0.0011833609314635396, Final Batch Loss: 0.0005916040390729904\n",
      "Epoch 1793, Loss: 0.0016092143196146935, Final Batch Loss: 0.0012709153816103935\n",
      "Epoch 1794, Loss: 0.00025533184088999406, Final Batch Loss: 0.00010487181862117723\n",
      "Epoch 1795, Loss: 0.0014049707242520526, Final Batch Loss: 0.00010275894601363689\n",
      "Epoch 1796, Loss: 0.0019957972108386457, Final Batch Loss: 0.0016409381059929729\n",
      "Epoch 1797, Loss: 0.00045345477701630443, Final Batch Loss: 0.0001264366292161867\n",
      "Epoch 1798, Loss: 0.0005141190704307519, Final Batch Loss: 3.804839070653543e-05\n",
      "Epoch 1799, Loss: 0.00024254704112536274, Final Batch Loss: 0.00021653561270795763\n",
      "Epoch 1800, Loss: 0.000484697287902236, Final Batch Loss: 6.306279101409018e-05\n",
      "Epoch 1801, Loss: 0.0010570644353720127, Final Batch Loss: 0.0010341322049498558\n",
      "Epoch 1802, Loss: 0.006577120781003032, Final Batch Loss: 0.0065438468009233475\n",
      "Epoch 1803, Loss: 0.00019762008014367893, Final Batch Loss: 0.00012645933020394295\n",
      "Epoch 1804, Loss: 0.0004290665874577826, Final Batch Loss: 0.0004047891707159579\n",
      "Epoch 1805, Loss: 0.00036122542769589927, Final Batch Loss: 0.00033287249971181154\n",
      "Epoch 1806, Loss: 0.0002907999369199388, Final Batch Loss: 3.732120239874348e-05\n",
      "Epoch 1807, Loss: 0.0005402288807090372, Final Batch Loss: 0.0003400731657166034\n",
      "Epoch 1808, Loss: 0.0003756416845135391, Final Batch Loss: 0.0003527604858390987\n",
      "Epoch 1809, Loss: 0.00039190690586110577, Final Batch Loss: 8.834042091621086e-05\n",
      "Epoch 1810, Loss: 0.0003568433712644037, Final Batch Loss: 0.00030363447149284184\n",
      "Epoch 1811, Loss: 0.00019581597007345408, Final Batch Loss: 9.60594552452676e-05\n",
      "Epoch 1812, Loss: 0.00035240902070654556, Final Batch Loss: 0.00030131093808449805\n",
      "Epoch 1813, Loss: 0.0005017599323764443, Final Batch Loss: 0.00044010416604578495\n",
      "Epoch 1814, Loss: 0.003813758494288777, Final Batch Loss: 0.0037948251701891422\n",
      "Epoch 1815, Loss: 0.0008171380031853914, Final Batch Loss: 0.00015257264021784067\n",
      "Epoch 1816, Loss: 0.00033754476316971704, Final Batch Loss: 0.00010833133273990825\n",
      "Epoch 1817, Loss: 0.0010635563230607659, Final Batch Loss: 0.00010218584793619812\n",
      "Epoch 1818, Loss: 0.0006958508311072364, Final Batch Loss: 0.0005180911393836141\n",
      "Epoch 1819, Loss: 0.009684171265689656, Final Batch Loss: 0.009439581073820591\n",
      "Epoch 1820, Loss: 0.008955985933425836, Final Batch Loss: 0.0002127081825165078\n",
      "Epoch 1821, Loss: 0.000281035914667882, Final Batch Loss: 0.00021206532255746424\n",
      "Epoch 1822, Loss: 0.00025004573399201035, Final Batch Loss: 7.99719273345545e-05\n",
      "Epoch 1823, Loss: 0.0009536548895994201, Final Batch Loss: 0.00015828882169444114\n",
      "Epoch 1824, Loss: 0.0013423733180388808, Final Batch Loss: 0.0002279914915561676\n",
      "Epoch 1825, Loss: 0.00865702296141535, Final Batch Loss: 0.0004403243074193597\n",
      "Epoch 1826, Loss: 0.0035886958648916334, Final Batch Loss: 0.003167734481394291\n",
      "Epoch 1827, Loss: 0.0005780015198979527, Final Batch Loss: 0.00039536209078505635\n",
      "Epoch 1828, Loss: 0.0008707800589036196, Final Batch Loss: 0.00031626326381228864\n",
      "Epoch 1829, Loss: 0.0003402570146135986, Final Batch Loss: 0.00014898742665536702\n",
      "Epoch 1830, Loss: 0.0002374797622906044, Final Batch Loss: 6.685129483230412e-05\n",
      "Epoch 1831, Loss: 0.001552918751258403, Final Batch Loss: 0.0009819146944209933\n",
      "Epoch 1832, Loss: 0.004185487312497571, Final Batch Loss: 0.00028352069784887135\n",
      "Epoch 1833, Loss: 0.0018102730682585388, Final Batch Loss: 0.00140423234552145\n",
      "Epoch 1834, Loss: 0.0026390624698251486, Final Batch Loss: 0.00019032275304198265\n",
      "Epoch 1835, Loss: 0.001588293416716624, Final Batch Loss: 0.0015176006127148867\n",
      "Epoch 1836, Loss: 0.020377941807964817, Final Batch Loss: 0.0004599154053721577\n",
      "Epoch 1837, Loss: 0.0002305373036506353, Final Batch Loss: 0.00020276707073207945\n",
      "Epoch 1838, Loss: 0.00025948792608687654, Final Batch Loss: 0.00016953043814282864\n",
      "Epoch 1839, Loss: 0.01630744570866227, Final Batch Loss: 0.00949249230325222\n",
      "Epoch 1840, Loss: 0.000361419006367214, Final Batch Loss: 9.526756184641272e-05\n",
      "Epoch 1841, Loss: 8.359631465282291e-05, Final Batch Loss: 4.2868028685916215e-05\n",
      "Epoch 1842, Loss: 0.00035799897159449756, Final Batch Loss: 7.075286703184247e-05\n",
      "Epoch 1843, Loss: 0.0004975936972186901, Final Batch Loss: 0.00040721852565184236\n",
      "Epoch 1844, Loss: 0.0006555423751706257, Final Batch Loss: 0.00010454370931256562\n",
      "Epoch 1845, Loss: 0.005806411900266539, Final Batch Loss: 0.005719036795198917\n",
      "Epoch 1846, Loss: 0.013297318684635684, Final Batch Loss: 0.0003611270512919873\n",
      "Epoch 1847, Loss: 0.000968428939813748, Final Batch Loss: 0.0001765174383763224\n",
      "Epoch 1848, Loss: 0.0004127852007513866, Final Batch Loss: 6.74365583108738e-05\n",
      "Epoch 1849, Loss: 0.0008221198804676533, Final Batch Loss: 0.00048367815907113254\n",
      "Epoch 1850, Loss: 0.0005700050242012367, Final Batch Loss: 0.00013917589967604727\n",
      "Epoch 1851, Loss: 0.00026545563741819933, Final Batch Loss: 0.00015053385868668556\n",
      "Epoch 1852, Loss: 6.67931089992635e-05, Final Batch Loss: 3.9627608202863485e-05\n",
      "Epoch 1853, Loss: 0.0006088869122322649, Final Batch Loss: 0.000411687622545287\n",
      "Epoch 1854, Loss: 0.00046955047582741827, Final Batch Loss: 0.0004215254739392549\n",
      "Epoch 1855, Loss: 0.0036157266586087644, Final Batch Loss: 0.0030086913611739874\n",
      "Epoch 1856, Loss: 0.0015675596368964761, Final Batch Loss: 0.0004450560954865068\n",
      "Epoch 1857, Loss: 0.00018623631331138313, Final Batch Loss: 7.396591536235064e-05\n",
      "Epoch 1858, Loss: 0.00033317584166070446, Final Batch Loss: 0.00029570370679721236\n",
      "Epoch 1859, Loss: 0.0005247462031547911, Final Batch Loss: 0.00047203077701851726\n",
      "Epoch 1860, Loss: 0.012747291875712108, Final Batch Loss: 0.012658477760851383\n",
      "Epoch 1861, Loss: 0.0006111917900852859, Final Batch Loss: 0.0003530362737365067\n",
      "Epoch 1862, Loss: 0.010723981205956079, Final Batch Loss: 0.00011282706691417843\n",
      "Epoch 1863, Loss: 0.0033458004909334704, Final Batch Loss: 0.000216155473026447\n",
      "Epoch 1864, Loss: 0.0011498464591568336, Final Batch Loss: 0.001062787021510303\n",
      "Epoch 1865, Loss: 0.0013921816716901958, Final Batch Loss: 0.0010241298004984856\n",
      "Epoch 1866, Loss: 0.0008606057235738263, Final Batch Loss: 0.0007063614903017879\n",
      "Epoch 1867, Loss: 0.0010987152345478535, Final Batch Loss: 0.0005453179473988712\n",
      "Epoch 1868, Loss: 0.00029701668972847983, Final Batch Loss: 0.00024697554181329906\n",
      "Epoch 1869, Loss: 0.0016516668838448822, Final Batch Loss: 0.0005287781241349876\n",
      "Epoch 1870, Loss: 0.0001827339656301774, Final Batch Loss: 7.855703734094277e-05\n",
      "Epoch 1871, Loss: 0.00045326857070904225, Final Batch Loss: 0.0002675132127478719\n",
      "Epoch 1872, Loss: 0.0003916240457328968, Final Batch Loss: 0.0003153577563352883\n",
      "Epoch 1873, Loss: 0.0003556371375452727, Final Batch Loss: 0.00016674483777023852\n",
      "Epoch 1874, Loss: 0.0022706060408381745, Final Batch Loss: 0.00022074153821449727\n",
      "Epoch 1875, Loss: 0.0007832735136616975, Final Batch Loss: 0.00018261795048601925\n",
      "Epoch 1876, Loss: 0.0007320520089706406, Final Batch Loss: 3.724735870491713e-05\n",
      "Epoch 1877, Loss: 0.0004291687801014632, Final Batch Loss: 0.00015265090041793883\n",
      "Epoch 1878, Loss: 0.0006615578022319824, Final Batch Loss: 0.00014949488104321063\n",
      "Epoch 1879, Loss: 0.0009796523227123544, Final Batch Loss: 1.7789701814763248e-05\n",
      "Epoch 1880, Loss: 0.00020899472292512655, Final Batch Loss: 6.972321716602892e-05\n",
      "Epoch 1881, Loss: 0.001155978607130237, Final Batch Loss: 0.0010273664956912398\n",
      "Epoch 1882, Loss: 0.00026518304366618395, Final Batch Loss: 0.00020658319408539683\n",
      "Epoch 1883, Loss: 0.00015640696801710874, Final Batch Loss: 0.00011445416021160781\n",
      "Epoch 1884, Loss: 0.00020193879026919603, Final Batch Loss: 5.120276182424277e-05\n",
      "Epoch 1885, Loss: 0.00115901610115543, Final Batch Loss: 0.0006594780134037137\n",
      "Epoch 1886, Loss: 0.000302894004562404, Final Batch Loss: 0.00023154198424890637\n",
      "Epoch 1887, Loss: 0.0001573457702761516, Final Batch Loss: 1.6006146324798465e-05\n",
      "Epoch 1888, Loss: 0.00048423876432934776, Final Batch Loss: 0.0003994746948592365\n",
      "Epoch 1889, Loss: 0.002163787605240941, Final Batch Loss: 0.0018304954282939434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1890, Loss: 0.015618769699358381, Final Batch Loss: 0.015444733202457428\n",
      "Epoch 1891, Loss: 0.008053256868151948, Final Batch Loss: 0.007644260302186012\n",
      "Epoch 1892, Loss: 0.00037902037001913413, Final Batch Loss: 9.575045987730846e-05\n",
      "Epoch 1893, Loss: 0.001147141883848235, Final Batch Loss: 0.00026770125259645283\n",
      "Epoch 1894, Loss: 0.0019332191004650667, Final Batch Loss: 0.001801408943720162\n",
      "Epoch 1895, Loss: 0.05214859867555788, Final Batch Loss: 0.05207115784287453\n",
      "Epoch 1896, Loss: 0.005834321869770065, Final Batch Loss: 0.00018421831191517413\n",
      "Epoch 1897, Loss: 0.0011029770139430184, Final Batch Loss: 0.0010579689405858517\n",
      "Epoch 1898, Loss: 0.009802761298487894, Final Batch Loss: 0.009681579656898975\n",
      "Epoch 1899, Loss: 0.10932101681828499, Final Batch Loss: 0.06229207292199135\n",
      "Epoch 1900, Loss: 0.0682123675942421, Final Batch Loss: 0.046102721244096756\n",
      "Epoch 1901, Loss: 0.03173071990022436, Final Batch Loss: 0.0002539242268539965\n",
      "Epoch 1902, Loss: 0.001764827931765467, Final Batch Loss: 0.0015160446055233479\n",
      "Epoch 1903, Loss: 0.03888076212024316, Final Batch Loss: 0.038055479526519775\n",
      "Epoch 1904, Loss: 0.04687291756272316, Final Batch Loss: 0.02427743189036846\n",
      "Epoch 1905, Loss: 0.003135502221994102, Final Batch Loss: 0.0022609918378293514\n",
      "Epoch 1906, Loss: 0.019487434066832066, Final Batch Loss: 0.013300423510372639\n",
      "Epoch 1907, Loss: 0.0008734914736123756, Final Batch Loss: 6.775227666366845e-05\n",
      "Epoch 1908, Loss: 0.0008271837286883965, Final Batch Loss: 0.0006472829845733941\n",
      "Epoch 1909, Loss: 0.0026322253252146766, Final Batch Loss: 0.00019256530504208058\n",
      "Epoch 1910, Loss: 0.0009919128788169473, Final Batch Loss: 0.0008437936194241047\n",
      "Epoch 1911, Loss: 0.00035680964356288314, Final Batch Loss: 0.0002658032171893865\n",
      "Epoch 1912, Loss: 0.0010580588859738782, Final Batch Loss: 0.00012994931603316218\n",
      "Epoch 1913, Loss: 0.0004618252205546014, Final Batch Loss: 0.00036020384868606925\n",
      "Epoch 1914, Loss: 0.003740654472494498, Final Batch Loss: 0.003363178111612797\n",
      "Epoch 1915, Loss: 0.008041249006055295, Final Batch Loss: 0.006393866613507271\n",
      "Epoch 1916, Loss: 0.0004372856055852026, Final Batch Loss: 0.0001984724949579686\n",
      "Epoch 1917, Loss: 0.00041078205140365753, Final Batch Loss: 2.471068910381291e-05\n",
      "Epoch 1918, Loss: 0.0006883249152451754, Final Batch Loss: 0.00041369727114215493\n",
      "Epoch 1919, Loss: 0.04229073412716389, Final Batch Loss: 0.03295876830816269\n",
      "Epoch 1920, Loss: 0.0014238659350667149, Final Batch Loss: 7.716394611634314e-05\n",
      "Epoch 1921, Loss: 0.0002956835087388754, Final Batch Loss: 0.0001470421120757237\n",
      "Epoch 1922, Loss: 0.004210766695905477, Final Batch Loss: 0.0006936374702490866\n",
      "Epoch 1923, Loss: 0.0021157451847102493, Final Batch Loss: 0.00042848775046877563\n",
      "Epoch 1924, Loss: 0.0017196143744513392, Final Batch Loss: 0.0005653930129483342\n",
      "Epoch 1925, Loss: 0.0007189975585788488, Final Batch Loss: 0.0003862107696477324\n",
      "Epoch 1926, Loss: 0.00552740681450814, Final Batch Loss: 0.00072427315171808\n",
      "Epoch 1927, Loss: 0.0005496426019817591, Final Batch Loss: 0.00014331535203382373\n",
      "Epoch 1928, Loss: 0.002814025167026557, Final Batch Loss: 8.878066728357226e-05\n",
      "Epoch 1929, Loss: 0.0008710684051038697, Final Batch Loss: 0.0006978790042921901\n",
      "Epoch 1930, Loss: 0.00045742404472548515, Final Batch Loss: 0.000330183858750388\n",
      "Epoch 1931, Loss: 0.0038774499553255737, Final Batch Loss: 0.0005175573169253767\n",
      "Epoch 1932, Loss: 0.0013140393130015582, Final Batch Loss: 0.00031683125416748226\n",
      "Epoch 1933, Loss: 0.0006947200454305857, Final Batch Loss: 0.000271558208623901\n",
      "Epoch 1934, Loss: 0.016156462545040995, Final Batch Loss: 0.0005303542711772025\n",
      "Epoch 1935, Loss: 0.00232896173838526, Final Batch Loss: 0.0017803659429773688\n",
      "Epoch 1936, Loss: 0.0011787572293542325, Final Batch Loss: 0.0006026563933119178\n",
      "Epoch 1937, Loss: 0.0008639750594738871, Final Batch Loss: 0.0004489719576667994\n",
      "Epoch 1938, Loss: 0.0007337771821767092, Final Batch Loss: 0.00045896178926341236\n",
      "Epoch 1939, Loss: 0.009400053415447474, Final Batch Loss: 0.002598301973193884\n",
      "Epoch 1940, Loss: 0.0010894429287873209, Final Batch Loss: 0.00043485802598297596\n",
      "Epoch 1941, Loss: 0.0007405975920846686, Final Batch Loss: 8.114594675134867e-05\n",
      "Epoch 1942, Loss: 0.0020944472635164857, Final Batch Loss: 0.0015854575904086232\n",
      "Epoch 1943, Loss: 0.0009167137613985687, Final Batch Loss: 0.0002905377477873117\n",
      "Epoch 1944, Loss: 0.00013916096941102296, Final Batch Loss: 7.478756742784753e-05\n",
      "Epoch 1945, Loss: 0.0003734449273906648, Final Batch Loss: 0.00017907482106238604\n",
      "Epoch 1946, Loss: 0.0006498176298919134, Final Batch Loss: 7.910915155662224e-05\n",
      "Epoch 1947, Loss: 0.00016933432925725356, Final Batch Loss: 8.833708125166595e-05\n",
      "Epoch 1948, Loss: 0.0008299913024529815, Final Batch Loss: 0.00019447278464213014\n",
      "Epoch 1949, Loss: 0.0051175895787309855, Final Batch Loss: 0.00020477824728004634\n",
      "Epoch 1950, Loss: 0.0007493131270166487, Final Batch Loss: 0.0004971312009729445\n",
      "Epoch 1951, Loss: 0.004211852123262361, Final Batch Loss: 0.0001235564996022731\n",
      "Epoch 1952, Loss: 0.0005243496416369453, Final Batch Loss: 0.00024079969443846494\n",
      "Epoch 1953, Loss: 0.0008468376181554049, Final Batch Loss: 0.0005557774566113949\n",
      "Epoch 1954, Loss: 0.0015150652616284788, Final Batch Loss: 0.0009918415453284979\n",
      "Epoch 1955, Loss: 0.0012999755563214421, Final Batch Loss: 0.0007112737512215972\n",
      "Epoch 1956, Loss: 0.0002815178668242879, Final Batch Loss: 4.117459320696071e-05\n",
      "Epoch 1957, Loss: 0.0007379950693575665, Final Batch Loss: 0.0005453527555800974\n",
      "Epoch 1958, Loss: 0.0004497711342992261, Final Batch Loss: 0.00019673114002216607\n",
      "Epoch 1959, Loss: 0.0006690282170893624, Final Batch Loss: 0.0004924687091261148\n",
      "Epoch 1960, Loss: 0.0002594588768261019, Final Batch Loss: 3.131127232336439e-05\n",
      "Epoch 1961, Loss: 0.0006132351700216532, Final Batch Loss: 0.0003002528101205826\n",
      "Epoch 1962, Loss: 0.0011267617082921788, Final Batch Loss: 0.000998939387500286\n",
      "Epoch 1963, Loss: 0.0023045242414809763, Final Batch Loss: 0.0018089573131874204\n",
      "Epoch 1964, Loss: 0.0019586317939683795, Final Batch Loss: 0.0006390531780198216\n",
      "Epoch 1965, Loss: 0.0010167340806219727, Final Batch Loss: 0.0007082474767230451\n",
      "Epoch 1966, Loss: 0.0015788605087436736, Final Batch Loss: 0.0004646293236874044\n",
      "Epoch 1967, Loss: 0.0010835856010089628, Final Batch Loss: 4.5721935748588294e-05\n",
      "Epoch 1968, Loss: 0.0013539909268729389, Final Batch Loss: 0.0005772138829343021\n",
      "Epoch 1969, Loss: 0.0003092804618063383, Final Batch Loss: 5.939188849879429e-05\n",
      "Epoch 1970, Loss: 0.0022220215323613957, Final Batch Loss: 0.002028978429734707\n",
      "Epoch 1971, Loss: 0.0013871326518710703, Final Batch Loss: 0.001067367848008871\n",
      "Epoch 1972, Loss: 0.0007297937700059265, Final Batch Loss: 0.0002764782984741032\n",
      "Epoch 1973, Loss: 0.0004040838175569661, Final Batch Loss: 0.0003043351462110877\n",
      "Epoch 1974, Loss: 0.0007164725393522531, Final Batch Loss: 0.0005119762499816716\n",
      "Epoch 1975, Loss: 0.0006780025723855942, Final Batch Loss: 0.00012073913239873946\n",
      "Epoch 1976, Loss: 0.0009330935790785588, Final Batch Loss: 7.856908632675186e-05\n",
      "Epoch 1977, Loss: 0.0023649100912734866, Final Batch Loss: 0.001734709134325385\n",
      "Epoch 1978, Loss: 0.0017982537974603474, Final Batch Loss: 0.0005498882965184748\n",
      "Epoch 1979, Loss: 0.002440723590552807, Final Batch Loss: 0.0016383480979129672\n",
      "Epoch 1980, Loss: 0.00089201309310738, Final Batch Loss: 0.0006508216029033065\n",
      "Epoch 1981, Loss: 0.001046954799676314, Final Batch Loss: 0.0007798353908583522\n",
      "Epoch 1982, Loss: 0.00021770138118881732, Final Batch Loss: 0.00018031950457952917\n",
      "Epoch 1983, Loss: 0.00033504691236885265, Final Batch Loss: 9.271391172660515e-05\n",
      "Epoch 1984, Loss: 0.0007162626425269991, Final Batch Loss: 0.0001291561929974705\n",
      "Epoch 1985, Loss: 0.0028627293067984283, Final Batch Loss: 0.002549278549849987\n",
      "Epoch 1986, Loss: 0.01115849829511717, Final Batch Loss: 0.0107134860008955\n",
      "Epoch 1987, Loss: 0.00040824039024300873, Final Batch Loss: 0.0001051202998496592\n",
      "Epoch 1988, Loss: 0.00022882968187332153, Final Batch Loss: 6.436226249206811e-05\n",
      "Epoch 1989, Loss: 0.001114128390327096, Final Batch Loss: 0.0009387818281538785\n",
      "Epoch 1990, Loss: 0.0024638974864501506, Final Batch Loss: 0.0004163009871263057\n",
      "Epoch 1991, Loss: 0.00047320043813670054, Final Batch Loss: 0.0003916173009201884\n",
      "Epoch 1992, Loss: 0.002453268120007124, Final Batch Loss: 0.0024102802854031324\n",
      "Epoch 1993, Loss: 0.0006966929795453325, Final Batch Loss: 0.0006297227228060365\n",
      "Epoch 1994, Loss: 0.0006009532080497593, Final Batch Loss: 0.0002717640600167215\n",
      "Epoch 1995, Loss: 0.0004465178935788572, Final Batch Loss: 0.0001847720704972744\n",
      "Epoch 1996, Loss: 0.000982419354841113, Final Batch Loss: 0.0003418113919906318\n",
      "Epoch 1997, Loss: 0.00010269449194311164, Final Batch Loss: 5.1433933549560606e-05\n",
      "Epoch 1998, Loss: 0.001022533731884323, Final Batch Loss: 0.0007794839330017567\n",
      "Epoch 1999, Loss: 0.0001821450423449278, Final Batch Loss: 5.568876804318279e-05\n",
      "Epoch 2000, Loss: 0.0014580364804714918, Final Batch Loss: 0.0001346446806564927\n",
      "Epoch 2001, Loss: 0.006070582639949862, Final Batch Loss: 2.9014401661697775e-05\n",
      "Epoch 2002, Loss: 0.00014707315858686343, Final Batch Loss: 4.7451692807953805e-05\n",
      "Epoch 2003, Loss: 0.0001233159018738661, Final Batch Loss: 5.678828529198654e-05\n",
      "Epoch 2004, Loss: 0.002412529102002736, Final Batch Loss: 0.0023078424856066704\n",
      "Epoch 2005, Loss: 0.0008945861191023141, Final Batch Loss: 0.00031762829166837037\n",
      "Epoch 2006, Loss: 0.0008272609702544287, Final Batch Loss: 0.00014306542288977653\n",
      "Epoch 2007, Loss: 0.0015200419002212584, Final Batch Loss: 0.0010427189990878105\n",
      "Epoch 2008, Loss: 0.015036042939755134, Final Batch Loss: 0.00012510006490629166\n",
      "Epoch 2009, Loss: 0.00023022164168651216, Final Batch Loss: 3.241977174184285e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2010, Loss: 0.0002579559004516341, Final Batch Loss: 7.225355511764064e-05\n",
      "Epoch 2011, Loss: 0.00031066382507560775, Final Batch Loss: 0.0001917074987431988\n",
      "Epoch 2012, Loss: 0.0030257590406108648, Final Batch Loss: 0.0029027925338596106\n",
      "Epoch 2013, Loss: 0.005547810636926442, Final Batch Loss: 0.005045462865382433\n",
      "Epoch 2014, Loss: 0.00027993186813546345, Final Batch Loss: 0.00021792242478113621\n",
      "Epoch 2015, Loss: 0.002833890146575868, Final Batch Loss: 0.001938086817972362\n",
      "Epoch 2016, Loss: 0.003081061440752819, Final Batch Loss: 0.002827269723638892\n",
      "Epoch 2017, Loss: 0.0008047760638874024, Final Batch Loss: 0.0004553151084110141\n",
      "Epoch 2018, Loss: 0.00012552860061987303, Final Batch Loss: 5.235596836428158e-05\n",
      "Epoch 2019, Loss: 0.00045969044731464237, Final Batch Loss: 0.00023036445782054216\n",
      "Epoch 2020, Loss: 0.0032263098983094096, Final Batch Loss: 0.002836276078596711\n",
      "Epoch 2021, Loss: 0.002285553367983084, Final Batch Loss: 9.741167741594836e-05\n",
      "Epoch 2022, Loss: 0.00029690311930608004, Final Batch Loss: 0.00011207743955310434\n",
      "Epoch 2023, Loss: 0.00037681241519749165, Final Batch Loss: 0.00020089128520339727\n",
      "Epoch 2024, Loss: 0.0032388108083978295, Final Batch Loss: 0.0012397969840094447\n",
      "Epoch 2025, Loss: 0.0005533646763069555, Final Batch Loss: 0.000431657099397853\n",
      "Epoch 2026, Loss: 0.0003119126777164638, Final Batch Loss: 0.00026826129760593176\n",
      "Epoch 2027, Loss: 0.000714485562639311, Final Batch Loss: 6.954403943382204e-05\n",
      "Epoch 2028, Loss: 0.0004040769854327664, Final Batch Loss: 0.0002475233341101557\n",
      "Epoch 2029, Loss: 0.0004755815753014758, Final Batch Loss: 6.728894368279725e-05\n",
      "Epoch 2030, Loss: 0.0010604070557747036, Final Batch Loss: 0.0008813960594125092\n",
      "Epoch 2031, Loss: 0.0033188616071129218, Final Batch Loss: 0.0031640995293855667\n",
      "Epoch 2032, Loss: 0.0022520292550325394, Final Batch Loss: 0.0013096381444483995\n",
      "Epoch 2033, Loss: 0.0003855064060189761, Final Batch Loss: 0.00027355964994058013\n",
      "Epoch 2034, Loss: 0.0007838215969968587, Final Batch Loss: 0.00033706892281770706\n",
      "Epoch 2035, Loss: 0.00033775853808037937, Final Batch Loss: 0.0001339342416031286\n",
      "Epoch 2036, Loss: 0.0012151275295764208, Final Batch Loss: 0.00023480865638703108\n",
      "Epoch 2037, Loss: 0.0009116165456362069, Final Batch Loss: 0.00028631679015234113\n",
      "Epoch 2038, Loss: 0.0016144944220286561, Final Batch Loss: 0.0015941527672111988\n",
      "Epoch 2039, Loss: 0.0011689008097164333, Final Batch Loss: 0.00042001547990366817\n",
      "Epoch 2040, Loss: 0.0006586827948922291, Final Batch Loss: 0.00012008445628453046\n",
      "Epoch 2041, Loss: 0.0015663598605897278, Final Batch Loss: 0.0003725971037056297\n",
      "Epoch 2042, Loss: 0.0009263684041798115, Final Batch Loss: 0.00013229157775640488\n",
      "Epoch 2043, Loss: 0.000501164817251265, Final Batch Loss: 0.0002537583059165627\n",
      "Epoch 2044, Loss: 0.0012080757296644151, Final Batch Loss: 0.0010635416256263852\n",
      "Epoch 2045, Loss: 0.0005540402344195172, Final Batch Loss: 0.00031140976352617145\n",
      "Epoch 2046, Loss: 0.0007160727982409298, Final Batch Loss: 0.0005845694104209542\n",
      "Epoch 2047, Loss: 0.00017852406381280161, Final Batch Loss: 5.41479566891212e-05\n",
      "Epoch 2048, Loss: 0.00285612529842183, Final Batch Loss: 0.00044374511344358325\n",
      "Epoch 2049, Loss: 0.0024431373458355665, Final Batch Loss: 0.0012426878092810512\n",
      "Epoch 2050, Loss: 0.00022680035908706486, Final Batch Loss: 0.0001506507833255455\n",
      "Epoch 2051, Loss: 0.0006997793316259049, Final Batch Loss: 4.734892718261108e-05\n",
      "Epoch 2052, Loss: 0.002793729887343943, Final Batch Loss: 0.0016124412650242448\n",
      "Epoch 2053, Loss: 0.00023981197591638193, Final Batch Loss: 0.00011463669216027483\n",
      "Epoch 2054, Loss: 0.0004891706157650333, Final Batch Loss: 4.542308670352213e-05\n",
      "Epoch 2055, Loss: 0.0007060477801132947, Final Batch Loss: 0.00028593180468305945\n",
      "Epoch 2056, Loss: 0.004060201514221262, Final Batch Loss: 7.826711953384802e-05\n",
      "Epoch 2057, Loss: 0.00017141015632660128, Final Batch Loss: 0.00013788034266326576\n",
      "Epoch 2058, Loss: 0.000544404119864339, Final Batch Loss: 2.9963823180878535e-05\n",
      "Epoch 2059, Loss: 0.00042363660759292543, Final Batch Loss: 0.00032223493326455355\n",
      "Epoch 2060, Loss: 0.0002652114344527945, Final Batch Loss: 5.222139589022845e-05\n",
      "Epoch 2061, Loss: 0.011672628053929657, Final Batch Loss: 0.0005570481880567968\n",
      "Epoch 2062, Loss: 0.002703950500290375, Final Batch Loss: 1.7344245861750096e-05\n",
      "Epoch 2063, Loss: 0.0014747994791832753, Final Batch Loss: 3.845222090603784e-05\n",
      "Epoch 2064, Loss: 0.0002796694607241079, Final Batch Loss: 8.884964336175472e-05\n",
      "Epoch 2065, Loss: 0.00018549176456872374, Final Batch Loss: 5.5731929023750126e-05\n",
      "Epoch 2066, Loss: 0.0009527626389171928, Final Batch Loss: 0.0007167583098635077\n",
      "Epoch 2067, Loss: 0.003266327199526131, Final Batch Loss: 0.0011147597106173635\n",
      "Epoch 2068, Loss: 0.00012262679229024798, Final Batch Loss: 3.555748116923496e-05\n",
      "Epoch 2069, Loss: 0.0006565479270648211, Final Batch Loss: 0.00017368272528983653\n",
      "Epoch 2070, Loss: 0.0004576341016218066, Final Batch Loss: 0.0004321001179050654\n",
      "Epoch 2071, Loss: 0.00109530223562615, Final Batch Loss: 7.067184924380854e-05\n",
      "Epoch 2072, Loss: 6.040631160431076e-05, Final Batch Loss: 3.37250494339969e-05\n",
      "Epoch 2073, Loss: 0.02906821334909182, Final Batch Loss: 0.028961608186364174\n",
      "Epoch 2074, Loss: 0.0006833937368355691, Final Batch Loss: 0.00021288648713380098\n",
      "Epoch 2075, Loss: 0.0006205101071827812, Final Batch Loss: 1.8637072571436875e-05\n",
      "Epoch 2076, Loss: 0.0008164925093296915, Final Batch Loss: 0.0005542121361941099\n",
      "Epoch 2077, Loss: 0.0011102146236225963, Final Batch Loss: 0.0007514997851103544\n",
      "Epoch 2078, Loss: 0.0027071601361967623, Final Batch Loss: 0.0019963791128247976\n",
      "Epoch 2079, Loss: 0.0009592389687895775, Final Batch Loss: 0.000817192136310041\n",
      "Epoch 2080, Loss: 0.0006627277034567669, Final Batch Loss: 0.00016817195864859968\n",
      "Epoch 2081, Loss: 0.0003108678720309399, Final Batch Loss: 9.879445860860869e-05\n",
      "Epoch 2082, Loss: 0.00044784153578802943, Final Batch Loss: 0.0001809118257369846\n",
      "Epoch 2083, Loss: 0.0010140329322894104, Final Batch Loss: 8.233538392232731e-05\n",
      "Epoch 2084, Loss: 0.00023105863147065975, Final Batch Loss: 0.00018216345051769167\n",
      "Epoch 2085, Loss: 0.0008990900387289003, Final Batch Loss: 6.638247577939183e-05\n",
      "Epoch 2086, Loss: 0.004895087084150873, Final Batch Loss: 0.0002076353266602382\n",
      "Epoch 2087, Loss: 0.00044424091174732894, Final Batch Loss: 0.000257574807619676\n",
      "Epoch 2088, Loss: 0.00112297257874161, Final Batch Loss: 0.0005768986884504557\n",
      "Epoch 2089, Loss: 0.002008461393415928, Final Batch Loss: 0.0011387021513655782\n",
      "Epoch 2090, Loss: 0.0002877844381146133, Final Batch Loss: 0.00010055657185148448\n",
      "Epoch 2091, Loss: 0.0004858458851231262, Final Batch Loss: 0.00022538156190421432\n",
      "Epoch 2092, Loss: 0.00011646229177131318, Final Batch Loss: 5.340206189430319e-05\n",
      "Epoch 2093, Loss: 0.0009467382333241403, Final Batch Loss: 0.00011059071402996778\n",
      "Epoch 2094, Loss: 0.0006806729070376605, Final Batch Loss: 8.731413981877267e-05\n",
      "Epoch 2095, Loss: 0.0003204796521458775, Final Batch Loss: 0.00013755868712905794\n",
      "Epoch 2096, Loss: 0.0006373069627443328, Final Batch Loss: 0.0004719284479506314\n",
      "Epoch 2097, Loss: 0.005163692243513651, Final Batch Loss: 0.004997163079679012\n",
      "Epoch 2098, Loss: 0.00023777798196533695, Final Batch Loss: 0.00016903402865864336\n",
      "Epoch 2099, Loss: 0.0014398438797798008, Final Batch Loss: 0.0012020301073789597\n",
      "Epoch 2100, Loss: 0.0029155650845495984, Final Batch Loss: 0.002736286725848913\n",
      "Epoch 2101, Loss: 0.014358280983287841, Final Batch Loss: 0.013842764310538769\n",
      "Epoch 2102, Loss: 0.0038450369611382484, Final Batch Loss: 0.0032457790803164244\n",
      "Epoch 2103, Loss: 0.0002837926585925743, Final Batch Loss: 0.0001312672538915649\n",
      "Epoch 2104, Loss: 0.0005483319764607586, Final Batch Loss: 7.178914529504254e-05\n",
      "Epoch 2105, Loss: 0.0020679914159700274, Final Batch Loss: 0.0012119407765567303\n",
      "Epoch 2106, Loss: 0.000277321036264766, Final Batch Loss: 0.00012122965563321486\n",
      "Epoch 2107, Loss: 0.0008839416259434074, Final Batch Loss: 0.000525140087120235\n",
      "Epoch 2108, Loss: 0.0003899923467542976, Final Batch Loss: 0.00012944050831720233\n",
      "Epoch 2109, Loss: 0.000760859671572689, Final Batch Loss: 0.0007122327806428075\n",
      "Epoch 2110, Loss: 0.000756408287998056, Final Batch Loss: 0.0006955824792385101\n",
      "Epoch 2111, Loss: 0.00010734204624895938, Final Batch Loss: 1.3356115232454613e-05\n",
      "Epoch 2112, Loss: 0.0006519804410345387, Final Batch Loss: 5.669744496117346e-05\n",
      "Epoch 2113, Loss: 0.0010867957389564253, Final Batch Loss: 0.0010432114358991385\n",
      "Epoch 2114, Loss: 0.00019623279513325542, Final Batch Loss: 7.458648906322196e-05\n",
      "Epoch 2115, Loss: 0.0005010228051105514, Final Batch Loss: 0.0002756106259766966\n",
      "Epoch 2116, Loss: 0.0007418535569740925, Final Batch Loss: 3.790948903770186e-05\n",
      "Epoch 2117, Loss: 0.0016977282321022358, Final Batch Loss: 0.0016534115420654416\n",
      "Epoch 2118, Loss: 0.0010187697880610358, Final Batch Loss: 2.63243964582216e-05\n",
      "Epoch 2119, Loss: 0.00025573125458322465, Final Batch Loss: 0.0002376852062297985\n",
      "Epoch 2120, Loss: 0.0002415873132122215, Final Batch Loss: 5.923803473706357e-05\n",
      "Epoch 2121, Loss: 0.00020982811111025512, Final Batch Loss: 5.772049189545214e-05\n",
      "Epoch 2122, Loss: 0.0006748054074705578, Final Batch Loss: 0.0006199835333973169\n",
      "Epoch 2123, Loss: 0.0007742084417259321, Final Batch Loss: 0.00019244627037551254\n",
      "Epoch 2124, Loss: 0.00022790470393374562, Final Batch Loss: 9.844666055869311e-05\n",
      "Epoch 2125, Loss: 0.0001249002198164817, Final Batch Loss: 0.0001030340208671987\n",
      "Epoch 2126, Loss: 0.0002150064210582059, Final Batch Loss: 4.375558273750357e-05\n",
      "Epoch 2127, Loss: 0.0001496858094469644, Final Batch Loss: 8.455566421616822e-05\n",
      "Epoch 2128, Loss: 0.0015950689557939768, Final Batch Loss: 0.0001588247250765562\n",
      "Epoch 2129, Loss: 0.0008345940295839682, Final Batch Loss: 0.00021360507525969297\n",
      "Epoch 2130, Loss: 0.0007923793018562719, Final Batch Loss: 5.479184619616717e-05\n",
      "Epoch 2131, Loss: 0.0001313790780841373, Final Batch Loss: 5.461233376991004e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2132, Loss: 0.0013341187222977169, Final Batch Loss: 0.0012679897481575608\n",
      "Epoch 2133, Loss: 0.0003919060436601285, Final Batch Loss: 0.00033836447983048856\n",
      "Epoch 2134, Loss: 0.0009363714198116213, Final Batch Loss: 0.00039861854747869074\n",
      "Epoch 2135, Loss: 0.00035832615685649216, Final Batch Loss: 0.00011663703480735421\n",
      "Epoch 2136, Loss: 0.0021023302106186748, Final Batch Loss: 0.0011203407775610685\n",
      "Epoch 2137, Loss: 2.689322082005674e-05, Final Batch Loss: 4.685930434789043e-06\n",
      "Epoch 2138, Loss: 0.00045807065907865763, Final Batch Loss: 0.0002186435303883627\n",
      "Epoch 2139, Loss: 0.0004403360653668642, Final Batch Loss: 0.00015273902681656182\n",
      "Epoch 2140, Loss: 0.0002493381398380734, Final Batch Loss: 6.30847571301274e-05\n",
      "Epoch 2141, Loss: 0.0007857292366679758, Final Batch Loss: 0.000461076881038025\n",
      "Epoch 2142, Loss: 0.00026417487242724746, Final Batch Loss: 0.00015290841110982\n",
      "Epoch 2143, Loss: 6.507417856482789e-05, Final Batch Loss: 3.2452502637170255e-05\n",
      "Epoch 2144, Loss: 0.006315125952824019, Final Batch Loss: 0.00017302842752542347\n",
      "Epoch 2145, Loss: 0.0004205657896818593, Final Batch Loss: 0.00023999960103537887\n",
      "Epoch 2146, Loss: 0.0004092536328244023, Final Batch Loss: 5.122221045894548e-05\n",
      "Epoch 2147, Loss: 0.0002880229403672274, Final Batch Loss: 5.5586915550520644e-05\n",
      "Epoch 2148, Loss: 0.0042168773943558335, Final Batch Loss: 0.0024719079956412315\n",
      "Epoch 2149, Loss: 0.000763234731493867, Final Batch Loss: 1.6691736163920723e-05\n",
      "Epoch 2150, Loss: 5.675217653333675e-05, Final Batch Loss: 7.199081665021367e-06\n",
      "Epoch 2151, Loss: 0.00012065534247085452, Final Batch Loss: 4.3022853787988424e-05\n",
      "Epoch 2152, Loss: 0.003633832384366542, Final Batch Loss: 0.0006362349377013743\n",
      "Epoch 2153, Loss: 0.00022434769198298454, Final Batch Loss: 3.068189835175872e-05\n",
      "Epoch 2154, Loss: 0.0003765121473406907, Final Batch Loss: 0.0003401252324692905\n",
      "Epoch 2155, Loss: 0.00016027085803216323, Final Batch Loss: 9.421265713172033e-05\n",
      "Epoch 2156, Loss: 0.0010016435335273854, Final Batch Loss: 0.0009678784990683198\n",
      "Epoch 2157, Loss: 0.00044910611723025795, Final Batch Loss: 2.2636280846199952e-05\n",
      "Epoch 2158, Loss: 0.0004512942396104336, Final Batch Loss: 0.00043424259638413787\n",
      "Epoch 2159, Loss: 9.247866546502337e-05, Final Batch Loss: 6.949786620680243e-05\n",
      "Epoch 2160, Loss: 0.0005159620486665517, Final Batch Loss: 0.0003780330007430166\n",
      "Epoch 2161, Loss: 0.00022543326849699952, Final Batch Loss: 2.3165750462794676e-05\n",
      "Epoch 2162, Loss: 8.696915574546438e-05, Final Batch Loss: 1.7775439118850045e-05\n",
      "Epoch 2163, Loss: 0.00015454031381523237, Final Batch Loss: 9.688715363154188e-05\n",
      "Epoch 2164, Loss: 0.001526337960967794, Final Batch Loss: 0.0002924858417827636\n",
      "Epoch 2165, Loss: 0.0003056100249523297, Final Batch Loss: 0.00025614065816625953\n",
      "Epoch 2166, Loss: 0.00010910283981502289, Final Batch Loss: 9.736626816447824e-05\n",
      "Epoch 2167, Loss: 0.00024275942996609956, Final Batch Loss: 7.23108823876828e-05\n",
      "Epoch 2168, Loss: 0.0004934937314828858, Final Batch Loss: 0.0002703576465137303\n",
      "Epoch 2169, Loss: 0.0003218164056306705, Final Batch Loss: 0.00011801648361142725\n",
      "Epoch 2170, Loss: 0.0010987361893057823, Final Batch Loss: 0.0005158520070835948\n",
      "Epoch 2171, Loss: 0.00037254188282531686, Final Batch Loss: 4.7808473027544096e-05\n",
      "Epoch 2172, Loss: 0.00024053053857642226, Final Batch Loss: 8.953775250120088e-06\n",
      "Epoch 2173, Loss: 0.00010433411443955265, Final Batch Loss: 2.7035541279474273e-05\n",
      "Epoch 2174, Loss: 0.0004701490943261888, Final Batch Loss: 4.863715366809629e-05\n",
      "Epoch 2175, Loss: 0.00015364817954832688, Final Batch Loss: 3.888431820087135e-05\n",
      "Epoch 2176, Loss: 0.001970683122635819, Final Batch Loss: 0.001817450625821948\n",
      "Epoch 2177, Loss: 0.00012459093159122858, Final Batch Loss: 1.904754935821984e-05\n",
      "Epoch 2178, Loss: 5.3492547522182576e-05, Final Batch Loss: 2.9211732908152044e-05\n",
      "Epoch 2179, Loss: 0.0005766398644482251, Final Batch Loss: 0.0005454724305309355\n",
      "Epoch 2180, Loss: 9.403593139722943e-05, Final Batch Loss: 6.213006417965516e-05\n",
      "Epoch 2181, Loss: 0.002103628488839604, Final Batch Loss: 0.0018869349732995033\n",
      "Epoch 2182, Loss: 0.001763192645739764, Final Batch Loss: 0.0015081242891028523\n",
      "Epoch 2183, Loss: 5.5619424529140815e-05, Final Batch Loss: 1.1194861144758761e-05\n",
      "Epoch 2184, Loss: 0.00011212644994884613, Final Batch Loss: 0.0001076349726645276\n",
      "Epoch 2185, Loss: 0.00040839136272552423, Final Batch Loss: 2.569016578490846e-05\n",
      "Epoch 2186, Loss: 0.0005140868834132561, Final Batch Loss: 7.647462552995421e-06\n",
      "Epoch 2187, Loss: 0.002610001713037491, Final Batch Loss: 0.0025876264553517103\n",
      "Epoch 2188, Loss: 0.00012605441952473484, Final Batch Loss: 7.79542388045229e-05\n",
      "Epoch 2189, Loss: 0.0008327638479386223, Final Batch Loss: 1.628737481951248e-05\n",
      "Epoch 2190, Loss: 0.0007159449669416063, Final Batch Loss: 0.00011877028009621426\n",
      "Epoch 2191, Loss: 0.00013181484337110305, Final Batch Loss: 2.7510550353326835e-06\n",
      "Epoch 2192, Loss: 0.00012703689753834624, Final Batch Loss: 1.1618338248808868e-05\n",
      "Epoch 2193, Loss: 3.922434279957088e-05, Final Batch Loss: 2.8100115741835907e-05\n",
      "Epoch 2194, Loss: 0.0015924474646453746, Final Batch Loss: 0.0015501173911616206\n",
      "Epoch 2195, Loss: 0.00032985597681545187, Final Batch Loss: 5.009731466998346e-06\n",
      "Epoch 2196, Loss: 0.0006645678513450548, Final Batch Loss: 6.21369545115158e-05\n",
      "Epoch 2197, Loss: 0.0003904634213540703, Final Batch Loss: 4.2371131712570786e-05\n",
      "Epoch 2198, Loss: 0.0006027495255693793, Final Batch Loss: 0.00031111834687180817\n",
      "Epoch 2199, Loss: 0.006191117641719757, Final Batch Loss: 0.006133112125098705\n",
      "Epoch 2200, Loss: 0.0004695501847891137, Final Batch Loss: 4.509328573476523e-05\n",
      "Epoch 2201, Loss: 0.00617105420678854, Final Batch Loss: 0.0055829789489507675\n",
      "Epoch 2202, Loss: 7.088705933711026e-05, Final Batch Loss: 4.869395343121141e-05\n",
      "Epoch 2203, Loss: 0.00011809791249106638, Final Batch Loss: 1.9446397345745936e-05\n",
      "Epoch 2204, Loss: 0.00024908795921874116, Final Batch Loss: 5.73440365769784e-06\n",
      "Epoch 2205, Loss: 5.0177419325336814e-05, Final Batch Loss: 1.3927758118370548e-05\n",
      "Epoch 2206, Loss: 3.654684223874938e-05, Final Batch Loss: 8.673543561599217e-06\n",
      "Epoch 2207, Loss: 0.0010280058340867981, Final Batch Loss: 3.7419944419525564e-05\n",
      "Epoch 2208, Loss: 0.00013102597586112097, Final Batch Loss: 1.8146020011045039e-06\n",
      "Epoch 2209, Loss: 0.0002610997107694857, Final Batch Loss: 0.00014106117305345833\n",
      "Epoch 2210, Loss: 0.00023269192752195522, Final Batch Loss: 9.114061685977504e-05\n",
      "Epoch 2211, Loss: 0.00016434000281151384, Final Batch Loss: 0.00010620093235047534\n",
      "Epoch 2212, Loss: 5.542847793549299e-05, Final Batch Loss: 3.141270644846372e-05\n",
      "Epoch 2213, Loss: 0.0032443347154185176, Final Batch Loss: 0.0009284672560170293\n",
      "Epoch 2214, Loss: 0.0007925676472950727, Final Batch Loss: 0.00018055029795505106\n",
      "Epoch 2215, Loss: 0.0007969019643496722, Final Batch Loss: 0.0007147673168219626\n",
      "Epoch 2216, Loss: 0.0007551892776973546, Final Batch Loss: 0.00020748254610225558\n",
      "Epoch 2217, Loss: 0.0002017726201302139, Final Batch Loss: 2.8715670850942843e-05\n",
      "Epoch 2218, Loss: 0.00011974887274845969, Final Batch Loss: 2.6789171897689812e-05\n",
      "Epoch 2219, Loss: 0.001288482395466417, Final Batch Loss: 0.0006809725891798735\n",
      "Epoch 2220, Loss: 0.004592691213474609, Final Batch Loss: 0.00011029433517251164\n",
      "Epoch 2221, Loss: 0.00011019477096851915, Final Batch Loss: 3.247532731620595e-05\n",
      "Epoch 2222, Loss: 0.00015265989350154996, Final Batch Loss: 8.855073974700645e-05\n",
      "Epoch 2223, Loss: 1.4774568626307882e-05, Final Batch Loss: 6.023205969540868e-06\n",
      "Epoch 2224, Loss: 0.00024421595298917964, Final Batch Loss: 9.059024887392297e-05\n",
      "Epoch 2225, Loss: 0.01114645370398648, Final Batch Loss: 0.010678757913410664\n",
      "Epoch 2226, Loss: 0.0004653298092307523, Final Batch Loss: 0.0003042902972083539\n",
      "Epoch 2227, Loss: 7.593832015118096e-05, Final Batch Loss: 1.3138926078681834e-05\n",
      "Epoch 2228, Loss: 8.649727715237532e-05, Final Batch Loss: 5.955650340183638e-05\n",
      "Epoch 2229, Loss: 0.0002575151047494728, Final Batch Loss: 3.317054142826237e-05\n",
      "Epoch 2230, Loss: 0.005768810741301422, Final Batch Loss: 0.005761493928730488\n",
      "Epoch 2231, Loss: 0.0003508695517666638, Final Batch Loss: 0.0001255344832316041\n",
      "Epoch 2232, Loss: 0.00018602482305141166, Final Batch Loss: 0.00013401081378106028\n",
      "Epoch 2233, Loss: 0.00031358972046291456, Final Batch Loss: 0.00024486883194185793\n",
      "Epoch 2234, Loss: 0.0022096370739745907, Final Batch Loss: 8.746328967390582e-05\n",
      "Epoch 2235, Loss: 0.0029658034472959116, Final Batch Loss: 4.1066392441280186e-05\n",
      "Epoch 2236, Loss: 0.0007201437292678747, Final Batch Loss: 0.0006690643494948745\n",
      "Epoch 2237, Loss: 0.005887006693228614, Final Batch Loss: 0.005805545952171087\n",
      "Epoch 2238, Loss: 0.0002887795417336747, Final Batch Loss: 0.0002543871523812413\n",
      "Epoch 2239, Loss: 3.3764474665076705e-05, Final Batch Loss: 3.5269299587525893e-06\n",
      "Epoch 2240, Loss: 0.0007149116354412399, Final Batch Loss: 0.0006525369244627655\n",
      "Epoch 2241, Loss: 2.5313546757388394e-05, Final Batch Loss: 1.4318774447019678e-05\n",
      "Epoch 2242, Loss: 0.000780858943471685, Final Batch Loss: 0.0005232322146184742\n",
      "Epoch 2243, Loss: 0.006220097919140244, Final Batch Loss: 4.3336567614460364e-05\n",
      "Epoch 2244, Loss: 0.008765803213464096, Final Batch Loss: 9.91910055745393e-05\n",
      "Epoch 2245, Loss: 5.5976654948608484e-05, Final Batch Loss: 1.1150738828291651e-05\n",
      "Epoch 2246, Loss: 0.002655955031514168, Final Batch Loss: 0.0005170213989913464\n",
      "Epoch 2247, Loss: 0.0011116445530205965, Final Batch Loss: 0.0007783965556882322\n",
      "Epoch 2248, Loss: 0.005120072164572775, Final Batch Loss: 0.004048268310725689\n",
      "Epoch 2249, Loss: 0.000530161676579155, Final Batch Loss: 9.830905764829367e-05\n",
      "Epoch 2250, Loss: 0.0001683016016613692, Final Batch Loss: 0.00010357680730521679\n",
      "Epoch 2251, Loss: 0.00016404958660132252, Final Batch Loss: 2.651470640557818e-05\n",
      "Epoch 2252, Loss: 0.002644099062308669, Final Batch Loss: 0.001221079146489501\n",
      "Epoch 2253, Loss: 0.003296627997769974, Final Batch Loss: 0.00015342292317654938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2254, Loss: 0.0006491427484434098, Final Batch Loss: 0.0001439382031094283\n",
      "Epoch 2255, Loss: 5.949837486696197e-05, Final Batch Loss: 9.48466458794428e-06\n",
      "Epoch 2256, Loss: 0.0006954280252102762, Final Batch Loss: 0.0002687246596906334\n",
      "Epoch 2257, Loss: 0.00014293291133071762, Final Batch Loss: 0.00011369336425559595\n",
      "Epoch 2258, Loss: 0.0010493849695194513, Final Batch Loss: 0.0009949442464858294\n",
      "Epoch 2259, Loss: 0.0024676830507814884, Final Batch Loss: 0.0007197243394330144\n",
      "Epoch 2260, Loss: 0.0008406185370404273, Final Batch Loss: 0.000641549180727452\n",
      "Epoch 2261, Loss: 0.00032851193100214005, Final Batch Loss: 0.0001632298226468265\n",
      "Epoch 2262, Loss: 0.0001454092671338003, Final Batch Loss: 6.082428808440454e-05\n",
      "Epoch 2263, Loss: 0.00016760691505623981, Final Batch Loss: 9.7391995950602e-05\n",
      "Epoch 2264, Loss: 0.004748789826408029, Final Batch Loss: 0.0033282029908150434\n",
      "Epoch 2265, Loss: 0.00043684627144102706, Final Batch Loss: 3.0456749300356023e-06\n",
      "Epoch 2266, Loss: 0.0006763487399439327, Final Batch Loss: 9.640212374506518e-05\n",
      "Epoch 2267, Loss: 0.0003217584308004007, Final Batch Loss: 0.00021278364874888211\n",
      "Epoch 2268, Loss: 0.000250119637712487, Final Batch Loss: 6.888638381497003e-06\n",
      "Epoch 2269, Loss: 0.00046397472033277154, Final Batch Loss: 0.00010743123129941523\n",
      "Epoch 2270, Loss: 0.0005478934763232246, Final Batch Loss: 0.0003781943814828992\n",
      "Epoch 2271, Loss: 7.25165918993298e-05, Final Batch Loss: 4.1365223296452314e-05\n",
      "Epoch 2272, Loss: 0.0009458195563638583, Final Batch Loss: 0.0007176047074608505\n",
      "Epoch 2273, Loss: 0.0005325918828020804, Final Batch Loss: 7.771266245981678e-05\n",
      "Epoch 2274, Loss: 0.00018734752666205168, Final Batch Loss: 8.249643724411726e-05\n",
      "Epoch 2275, Loss: 0.00017640947044128552, Final Batch Loss: 3.588092658901587e-05\n",
      "Epoch 2276, Loss: 0.0002462348966218997, Final Batch Loss: 0.00018897296104114503\n",
      "Epoch 2277, Loss: 0.0004799785529030487, Final Batch Loss: 0.0003314865753054619\n",
      "Epoch 2278, Loss: 6.577216481673531e-05, Final Batch Loss: 1.9726376194739714e-05\n",
      "Epoch 2279, Loss: 0.0009002401784528047, Final Batch Loss: 0.00020040143863298\n",
      "Epoch 2280, Loss: 0.00043841966544277966, Final Batch Loss: 0.00023384293308481574\n",
      "Epoch 2281, Loss: 0.0038459256174974144, Final Batch Loss: 0.0002708767424337566\n",
      "Epoch 2282, Loss: 0.0005092266801511869, Final Batch Loss: 0.00010186548752244562\n",
      "Epoch 2283, Loss: 0.0005185586342122406, Final Batch Loss: 0.0003873560344800353\n",
      "Epoch 2284, Loss: 0.00015057638302096166, Final Batch Loss: 5.477443119161762e-05\n",
      "Epoch 2285, Loss: 0.00378126545183477, Final Batch Loss: 1.5675661416025832e-05\n",
      "Epoch 2286, Loss: 0.00011417601490393281, Final Batch Loss: 6.970951653784141e-05\n",
      "Epoch 2287, Loss: 0.00017328769536106847, Final Batch Loss: 0.00011443057155702263\n",
      "Epoch 2288, Loss: 0.0012436063698260114, Final Batch Loss: 0.00023972433700691909\n",
      "Epoch 2289, Loss: 0.0014042716939002275, Final Batch Loss: 0.000688515487127006\n",
      "Epoch 2290, Loss: 7.752685451123398e-05, Final Batch Loss: 8.145054380293004e-06\n",
      "Epoch 2291, Loss: 0.00019765883553191088, Final Batch Loss: 6.007018600939773e-05\n",
      "Epoch 2292, Loss: 0.00010329726501367986, Final Batch Loss: 8.807448466541246e-05\n",
      "Epoch 2293, Loss: 0.012471666588680819, Final Batch Loss: 0.012002899311482906\n",
      "Epoch 2294, Loss: 0.00045707029494224116, Final Batch Loss: 3.1867930374573916e-05\n",
      "Epoch 2295, Loss: 0.0008626789713161997, Final Batch Loss: 0.0007906115497462451\n",
      "Epoch 2296, Loss: 0.00037497924677154515, Final Batch Loss: 0.00035316019784659147\n",
      "Epoch 2297, Loss: 0.00012143646745244041, Final Batch Loss: 7.250570342876017e-05\n",
      "Epoch 2298, Loss: 0.00844303346821107, Final Batch Loss: 0.008207929320633411\n",
      "Epoch 2299, Loss: 0.006047963863238692, Final Batch Loss: 0.005277934484183788\n",
      "Epoch 2300, Loss: 0.0003173754957970232, Final Batch Loss: 0.00013157947978470474\n",
      "Epoch 2301, Loss: 0.00023263438197318465, Final Batch Loss: 0.0001503127859905362\n",
      "Epoch 2302, Loss: 0.0005487603484652936, Final Batch Loss: 8.273730054497719e-05\n",
      "Epoch 2303, Loss: 0.0006320484535535797, Final Batch Loss: 0.00047424514195881784\n",
      "Epoch 2304, Loss: 0.0008632724420749582, Final Batch Loss: 0.0008337847539223731\n",
      "Epoch 2305, Loss: 0.0007999220688361675, Final Batch Loss: 0.0001502420927863568\n",
      "Epoch 2306, Loss: 0.0011906247236765921, Final Batch Loss: 0.0009163691429421306\n",
      "Epoch 2307, Loss: 0.0006477250208263285, Final Batch Loss: 0.000596853147726506\n",
      "Epoch 2308, Loss: 0.00020720155953313224, Final Batch Loss: 0.0001676118263276294\n",
      "Epoch 2309, Loss: 0.00011614624600042589, Final Batch Loss: 8.066385635174811e-05\n",
      "Epoch 2310, Loss: 0.00021676093456335366, Final Batch Loss: 0.00020158298138994724\n",
      "Epoch 2311, Loss: 0.016036376735428348, Final Batch Loss: 0.015892338007688522\n",
      "Epoch 2312, Loss: 0.00043194145837333053, Final Batch Loss: 0.0002874933124985546\n",
      "Epoch 2313, Loss: 0.0004602125845849514, Final Batch Loss: 0.0003820950223598629\n",
      "Epoch 2314, Loss: 0.0002855700222426094, Final Batch Loss: 0.00011021432146662846\n",
      "Epoch 2315, Loss: 0.00043227583228144795, Final Batch Loss: 0.00018260384968016297\n",
      "Epoch 2316, Loss: 0.0018152461561840028, Final Batch Loss: 0.00017165191820822656\n",
      "Epoch 2317, Loss: 0.00010750988076324575, Final Batch Loss: 5.277075251797214e-05\n",
      "Epoch 2318, Loss: 0.0012310099409660324, Final Batch Loss: 6.471200322266668e-05\n",
      "Epoch 2319, Loss: 0.0002115813949785661, Final Batch Loss: 0.0001516435731900856\n",
      "Epoch 2320, Loss: 0.0018117154177161865, Final Batch Loss: 0.0017377241747453809\n",
      "Epoch 2321, Loss: 0.0028153955354355276, Final Batch Loss: 0.0023069868329912424\n",
      "Epoch 2322, Loss: 8.514005457982421e-05, Final Batch Loss: 2.3189459170680493e-05\n",
      "Epoch 2323, Loss: 0.0003483952605165541, Final Batch Loss: 0.00019206067372579128\n",
      "Epoch 2324, Loss: 0.0003853485236504639, Final Batch Loss: 5.915133897360647e-06\n",
      "Epoch 2325, Loss: 0.00014594588901672978, Final Batch Loss: 0.00012595033331308514\n",
      "Epoch 2326, Loss: 0.0002673619892448187, Final Batch Loss: 0.00015763650299049914\n",
      "Epoch 2327, Loss: 0.00036648177956521977, Final Batch Loss: 9.024895916809328e-06\n",
      "Epoch 2328, Loss: 7.260435450007208e-05, Final Batch Loss: 3.705824201460928e-05\n",
      "Epoch 2329, Loss: 0.0004017194369225763, Final Batch Loss: 0.00011860517406603321\n",
      "Epoch 2330, Loss: 0.0038186086694622645, Final Batch Loss: 0.0038070599548518658\n",
      "Epoch 2331, Loss: 0.0005935750850767363, Final Batch Loss: 2.604980909381993e-05\n",
      "Epoch 2332, Loss: 0.0015915618860162795, Final Batch Loss: 0.0007865100051276386\n",
      "Epoch 2333, Loss: 0.0003277621799497865, Final Batch Loss: 0.0002445071004331112\n",
      "Epoch 2334, Loss: 0.002622917148983106, Final Batch Loss: 0.0023905436974018812\n",
      "Epoch 2335, Loss: 0.000724844285286963, Final Batch Loss: 0.00025201941025443375\n",
      "Epoch 2336, Loss: 0.00011118536531284917, Final Batch Loss: 2.0006855265819468e-05\n",
      "Epoch 2337, Loss: 0.00018114278645953164, Final Batch Loss: 0.00016029704420361668\n",
      "Epoch 2338, Loss: 0.00011926511797355488, Final Batch Loss: 4.567691939882934e-05\n",
      "Epoch 2339, Loss: 0.0005984648742014542, Final Batch Loss: 2.643182233441621e-05\n",
      "Epoch 2340, Loss: 0.0021182213095016778, Final Batch Loss: 0.0003094084677286446\n",
      "Epoch 2341, Loss: 0.0010413919808343053, Final Batch Loss: 0.0002346722176298499\n",
      "Epoch 2342, Loss: 0.0011835810000775382, Final Batch Loss: 0.001110203331336379\n",
      "Epoch 2343, Loss: 0.006754674304829678, Final Batch Loss: 0.006730360444635153\n",
      "Epoch 2344, Loss: 0.0050623888382688165, Final Batch Loss: 0.004775659181177616\n",
      "Epoch 2345, Loss: 0.0009984797143260948, Final Batch Loss: 0.000118453630420845\n",
      "Epoch 2346, Loss: 0.00014324350922834128, Final Batch Loss: 4.986697604181245e-05\n",
      "Epoch 2347, Loss: 0.0011158450834045652, Final Batch Loss: 0.0010582468239590526\n",
      "Epoch 2348, Loss: 0.0003974427963839844, Final Batch Loss: 0.00013206306903157383\n",
      "Epoch 2349, Loss: 0.0003016487680724822, Final Batch Loss: 0.00027450607740320265\n",
      "Epoch 2350, Loss: 0.00024479255807818845, Final Batch Loss: 4.335404810262844e-05\n",
      "Epoch 2351, Loss: 0.0007612769841216505, Final Batch Loss: 0.000670309760607779\n",
      "Epoch 2352, Loss: 0.0004157795847277157, Final Batch Loss: 9.641396900406107e-05\n",
      "Epoch 2353, Loss: 0.0003949183283111779, Final Batch Loss: 0.0003839238779619336\n",
      "Epoch 2354, Loss: 0.0008832263702061027, Final Batch Loss: 0.00026945743593387306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2355, Loss: 0.0002972589718410745, Final Batch Loss: 0.00020591524662449956\n",
      "Epoch 2356, Loss: 0.0007514189928770065, Final Batch Loss: 0.0007219458930194378\n",
      "Epoch 2357, Loss: 0.0010065312089864165, Final Batch Loss: 0.00066375732421875\n",
      "Epoch 2358, Loss: 0.0013717011315748096, Final Batch Loss: 0.0012104024644941092\n",
      "Epoch 2359, Loss: 0.0004389863825053908, Final Batch Loss: 0.0001091825615731068\n",
      "Epoch 2360, Loss: 0.0017878698599815834, Final Batch Loss: 4.275424362276681e-05\n",
      "Epoch 2361, Loss: 0.00017728722195897717, Final Batch Loss: 2.4275856048916467e-05\n",
      "Epoch 2362, Loss: 0.0029236411064630374, Final Batch Loss: 0.00016096698527690023\n",
      "Epoch 2363, Loss: 0.00019574956604628824, Final Batch Loss: 0.0001513914903625846\n",
      "Epoch 2364, Loss: 0.007927533239126205, Final Batch Loss: 0.006391230039298534\n",
      "Epoch 2365, Loss: 0.0001618480237084441, Final Batch Loss: 7.44607750675641e-05\n",
      "Epoch 2366, Loss: 5.8685607655206695e-05, Final Batch Loss: 4.5409746235236526e-05\n",
      "Epoch 2367, Loss: 0.001644461300202238, Final Batch Loss: 1.2875884749519173e-05\n",
      "Epoch 2368, Loss: 6.685895095870364e-05, Final Batch Loss: 3.7848101783310995e-05\n",
      "Epoch 2369, Loss: 9.565712753101252e-05, Final Batch Loss: 2.3801276256563142e-05\n",
      "Epoch 2370, Loss: 0.00034687327934079804, Final Batch Loss: 0.00030527316266670823\n",
      "Epoch 2371, Loss: 0.00013628972374135628, Final Batch Loss: 7.925196405267343e-05\n",
      "Epoch 2372, Loss: 0.0008623823814559728, Final Batch Loss: 2.5046203518286347e-05\n",
      "Epoch 2373, Loss: 0.0004321261149016209, Final Batch Loss: 0.00011497404921101406\n",
      "Epoch 2374, Loss: 0.00026619451818987727, Final Batch Loss: 5.326294922269881e-05\n",
      "Epoch 2375, Loss: 0.0006835061794845387, Final Batch Loss: 0.0001226542954100296\n",
      "Epoch 2376, Loss: 0.00033246976090595126, Final Batch Loss: 0.00022872883710078895\n",
      "Epoch 2377, Loss: 0.0006477467322838493, Final Batch Loss: 0.0006105294451117516\n",
      "Epoch 2378, Loss: 0.0003249641667935066, Final Batch Loss: 0.00028701030532829463\n",
      "Epoch 2379, Loss: 0.00028309152548899874, Final Batch Loss: 8.851594611769542e-05\n",
      "Epoch 2380, Loss: 0.0006329108455247479, Final Batch Loss: 1.95970951608615e-05\n",
      "Epoch 2381, Loss: 0.00042436061085027177, Final Batch Loss: 0.0004141619137953967\n",
      "Epoch 2382, Loss: 0.0010704218002501875, Final Batch Loss: 0.0009763473644852638\n",
      "Epoch 2383, Loss: 0.0011697957088472322, Final Batch Loss: 9.970793325919658e-05\n",
      "Epoch 2384, Loss: 0.0010540485818637535, Final Batch Loss: 0.0009146899683400989\n",
      "Epoch 2385, Loss: 2.8059178475814406e-05, Final Batch Loss: 2.1651141651091166e-05\n",
      "Epoch 2386, Loss: 0.00015114153211470693, Final Batch Loss: 3.5740544262807816e-05\n",
      "Epoch 2387, Loss: 0.00031591926381224766, Final Batch Loss: 7.23951161489822e-05\n",
      "Epoch 2388, Loss: 0.000564500194741413, Final Batch Loss: 0.0005274945287965238\n",
      "Epoch 2389, Loss: 0.0008419325167778879, Final Batch Loss: 0.00034891781979240477\n",
      "Epoch 2390, Loss: 0.00032443545933347195, Final Batch Loss: 0.0001571882894495502\n",
      "Epoch 2391, Loss: 0.00039759928768035024, Final Batch Loss: 0.00030807784060016274\n",
      "Epoch 2392, Loss: 0.0006882580637466162, Final Batch Loss: 0.0003848705382551998\n",
      "Epoch 2393, Loss: 0.00034673519257921726, Final Batch Loss: 3.508567169774324e-05\n",
      "Epoch 2394, Loss: 0.0005309488624334335, Final Batch Loss: 0.0004223381693009287\n",
      "Epoch 2395, Loss: 0.0030658030277663784, Final Batch Loss: 5.155275630386313e-06\n",
      "Epoch 2396, Loss: 0.00017456216301070526, Final Batch Loss: 4.7427376557607204e-05\n",
      "Epoch 2397, Loss: 0.000414194098993903, Final Batch Loss: 3.1572617444908246e-05\n",
      "Epoch 2398, Loss: 0.0001860972806753125, Final Batch Loss: 3.0744322430109605e-05\n",
      "Epoch 2399, Loss: 0.002611931355204433, Final Batch Loss: 0.00038333790143951774\n",
      "Epoch 2400, Loss: 0.001838691721786745, Final Batch Loss: 0.0017230071825906634\n",
      "Epoch 2401, Loss: 0.00030785679700784385, Final Batch Loss: 0.00022932171123102307\n",
      "Epoch 2402, Loss: 0.0003160052110615652, Final Batch Loss: 4.5488628529710695e-05\n",
      "Epoch 2403, Loss: 0.0002543785340094473, Final Batch Loss: 0.00021677324548363686\n",
      "Epoch 2404, Loss: 0.0006142273487057537, Final Batch Loss: 0.00033321353839710355\n",
      "Epoch 2405, Loss: 5.078321873952518e-05, Final Batch Loss: 5.995676019665552e-06\n",
      "Epoch 2406, Loss: 0.0002485820859874366, Final Batch Loss: 2.852288707799744e-05\n",
      "Epoch 2407, Loss: 0.00021641912280756515, Final Batch Loss: 2.8152366212452762e-05\n",
      "Epoch 2408, Loss: 7.334355177590623e-05, Final Batch Loss: 4.549819277599454e-05\n",
      "Epoch 2409, Loss: 0.000355586082150694, Final Batch Loss: 6.421817670343444e-05\n",
      "Epoch 2410, Loss: 0.0009298308586949133, Final Batch Loss: 0.0009195444290526211\n",
      "Epoch 2411, Loss: 0.00023578623950015754, Final Batch Loss: 4.413795250002295e-05\n",
      "Epoch 2412, Loss: 0.00015502237511100248, Final Batch Loss: 7.202314009191468e-05\n",
      "Epoch 2413, Loss: 0.005740248132497072, Final Batch Loss: 0.004536329302936792\n",
      "Epoch 2414, Loss: 0.00022432738842326216, Final Batch Loss: 0.00020782572391908616\n",
      "Epoch 2415, Loss: 0.00034315067023271695, Final Batch Loss: 2.6053960027638823e-05\n",
      "Epoch 2416, Loss: 0.0004958955541951582, Final Batch Loss: 0.00011907676525879651\n",
      "Epoch 2417, Loss: 0.005263270722934976, Final Batch Loss: 0.00039394423947669566\n",
      "Epoch 2418, Loss: 0.009963179298210889, Final Batch Loss: 0.0003869340871460736\n",
      "Epoch 2419, Loss: 0.0008535324159311131, Final Batch Loss: 0.0006969602545723319\n",
      "Epoch 2420, Loss: 0.0011515466612763703, Final Batch Loss: 0.00014696671860292554\n",
      "Epoch 2421, Loss: 0.0008390610382775776, Final Batch Loss: 0.0007237704703584313\n",
      "Epoch 2422, Loss: 0.00022157099738251418, Final Batch Loss: 0.00015062873717397451\n",
      "Epoch 2423, Loss: 0.0021922370069660246, Final Batch Loss: 0.0016271661734208465\n",
      "Epoch 2424, Loss: 0.0003565458027878776, Final Batch Loss: 7.75137305026874e-05\n",
      "Epoch 2425, Loss: 0.0003263584221713245, Final Batch Loss: 0.00015794341743458062\n",
      "Epoch 2426, Loss: 0.0018732233584159985, Final Batch Loss: 0.00014498156087938696\n",
      "Epoch 2427, Loss: 0.000565915514016524, Final Batch Loss: 0.00016056784079410136\n",
      "Epoch 2428, Loss: 0.00010619771455822047, Final Batch Loss: 7.62038616812788e-05\n",
      "Epoch 2429, Loss: 0.00037662752583855763, Final Batch Loss: 0.0003086003998760134\n",
      "Epoch 2430, Loss: 6.554527681146283e-05, Final Batch Loss: 1.344142401649151e-05\n",
      "Epoch 2431, Loss: 3.22318874168559e-05, Final Batch Loss: 5.306822458805982e-06\n",
      "Epoch 2432, Loss: 0.0017498853412689641, Final Batch Loss: 0.001584622892551124\n",
      "Epoch 2433, Loss: 0.0002251466539746616, Final Batch Loss: 0.00019214181520510465\n",
      "Epoch 2434, Loss: 7.546479537268169e-05, Final Batch Loss: 3.3858003007480875e-05\n",
      "Epoch 2435, Loss: 0.00015126459038583562, Final Batch Loss: 9.458637941861525e-05\n",
      "Epoch 2436, Loss: 0.0010617705411277711, Final Batch Loss: 0.0009163053473457694\n",
      "Epoch 2437, Loss: 0.00010445953921589535, Final Batch Loss: 1.8342825569561683e-05\n",
      "Epoch 2438, Loss: 0.0003294903872301802, Final Batch Loss: 0.00021971836395096034\n",
      "Epoch 2439, Loss: 0.00012556046203826554, Final Batch Loss: 3.5788707464234903e-05\n",
      "Epoch 2440, Loss: 9.037671088663046e-05, Final Batch Loss: 2.839402895915555e-06\n",
      "Epoch 2441, Loss: 0.0003025187870662194, Final Batch Loss: 0.0002833249745890498\n",
      "Epoch 2442, Loss: 0.0005935676745139062, Final Batch Loss: 0.00047442290815524757\n",
      "Epoch 2443, Loss: 0.0003365495867910795, Final Batch Loss: 0.00026257120771333575\n",
      "Epoch 2444, Loss: 0.0002993103116750717, Final Batch Loss: 0.00015098776202648878\n",
      "Epoch 2445, Loss: 0.0014655638296972029, Final Batch Loss: 0.001403720467351377\n",
      "Epoch 2446, Loss: 6.610352102143224e-05, Final Batch Loss: 2.959129233204294e-05\n",
      "Epoch 2447, Loss: 0.0005688821256626397, Final Batch Loss: 0.00043339302646927536\n",
      "Epoch 2448, Loss: 0.0012489741493482143, Final Batch Loss: 0.0002689297834876925\n",
      "Epoch 2449, Loss: 0.0005077506648376584, Final Batch Loss: 6.366911111399531e-05\n",
      "Epoch 2450, Loss: 0.000504542316775769, Final Batch Loss: 6.138673052191734e-05\n",
      "Epoch 2451, Loss: 0.0013248809409560636, Final Batch Loss: 0.00020729606330860406\n",
      "Epoch 2452, Loss: 0.0004735280090244487, Final Batch Loss: 0.00028765443130396307\n",
      "Epoch 2453, Loss: 0.0002818811117322184, Final Batch Loss: 2.1094725525472313e-05\n",
      "Epoch 2454, Loss: 0.00013330648107512388, Final Batch Loss: 0.00011513791105244309\n",
      "Epoch 2455, Loss: 0.00016398846491938457, Final Batch Loss: 9.240910731023178e-05\n",
      "Epoch 2456, Loss: 0.0004579538508551195, Final Batch Loss: 0.0003588027320802212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2457, Loss: 5.7299579566461034e-05, Final Batch Loss: 3.041870513698086e-05\n",
      "Epoch 2458, Loss: 0.00014737440324097406, Final Batch Loss: 0.00013137669884599745\n",
      "Epoch 2459, Loss: 2.6742572117655072e-05, Final Batch Loss: 1.1653944966383278e-05\n",
      "Epoch 2460, Loss: 0.0020990785269532353, Final Batch Loss: 0.0003516496217343956\n",
      "Epoch 2461, Loss: 0.00010554149412200786, Final Batch Loss: 7.262602593982592e-05\n",
      "Epoch 2462, Loss: 4.5039480028208345e-05, Final Batch Loss: 2.338812919333577e-05\n",
      "Epoch 2463, Loss: 0.000984207246801816, Final Batch Loss: 5.8148158132098615e-05\n",
      "Epoch 2464, Loss: 7.098217884049518e-05, Final Batch Loss: 7.641853699169587e-06\n",
      "Epoch 2465, Loss: 0.0002609444604786404, Final Batch Loss: 4.481535597733455e-06\n",
      "Epoch 2466, Loss: 0.00014161079343466554, Final Batch Loss: 2.799282992782537e-05\n",
      "Epoch 2467, Loss: 0.0005065685691079125, Final Batch Loss: 3.5014571039937437e-05\n",
      "Epoch 2468, Loss: 0.00025791540247155353, Final Batch Loss: 8.003778202692047e-05\n",
      "Epoch 2469, Loss: 0.000771012157201767, Final Batch Loss: 0.00014801177894696593\n",
      "Epoch 2470, Loss: 0.00019414269263506867, Final Batch Loss: 1.6974943719105795e-05\n",
      "Epoch 2471, Loss: 0.0007974594191182405, Final Batch Loss: 0.0006016621482558548\n",
      "Epoch 2472, Loss: 0.00027009938457922544, Final Batch Loss: 2.7836509616463445e-05\n",
      "Epoch 2473, Loss: 0.006076784720789874, Final Batch Loss: 0.006019855849444866\n",
      "Epoch 2474, Loss: 0.0006548469245899469, Final Batch Loss: 0.0005504958098754287\n",
      "Epoch 2475, Loss: 0.0005858424701727927, Final Batch Loss: 0.00017158963601104915\n",
      "Epoch 2476, Loss: 6.662080159003381e-05, Final Batch Loss: 4.6187593397917226e-05\n",
      "Epoch 2477, Loss: 0.00010998251309501939, Final Batch Loss: 2.3221928131533787e-05\n",
      "Epoch 2478, Loss: 0.00030753787177673075, Final Batch Loss: 0.0003022727614734322\n",
      "Epoch 2479, Loss: 0.0004428798274602741, Final Batch Loss: 0.0002559706917963922\n",
      "Epoch 2480, Loss: 0.0005338959163054824, Final Batch Loss: 8.662289474159479e-06\n",
      "Epoch 2481, Loss: 3.879942414641846e-05, Final Batch Loss: 3.2158332032850012e-06\n",
      "Epoch 2482, Loss: 0.0014555332199961413, Final Batch Loss: 0.0014239210868254304\n",
      "Epoch 2483, Loss: 0.00020879034855170175, Final Batch Loss: 0.00012325427087489516\n",
      "Epoch 2484, Loss: 0.000443916316726245, Final Batch Loss: 0.00024289714929182082\n",
      "Epoch 2485, Loss: 0.00020608976410585456, Final Batch Loss: 2.9374710720730945e-05\n",
      "Epoch 2486, Loss: 5.8025199905387126e-05, Final Batch Loss: 5.0844810175476596e-05\n",
      "Epoch 2487, Loss: 0.00020792794384760782, Final Batch Loss: 0.00013162652612663805\n",
      "Epoch 2488, Loss: 5.339390099834418e-05, Final Batch Loss: 1.118611453421181e-05\n",
      "Epoch 2489, Loss: 3.859786011162214e-05, Final Batch Loss: 2.8911155823152512e-05\n",
      "Epoch 2490, Loss: 5.1187302233302034e-05, Final Batch Loss: 2.4660839699208736e-05\n",
      "Epoch 2491, Loss: 0.00020529528410406783, Final Batch Loss: 0.00015203871589619666\n",
      "Epoch 2492, Loss: 0.000652268819976598, Final Batch Loss: 0.000313880096655339\n",
      "Epoch 2493, Loss: 0.00011881043337780284, Final Batch Loss: 5.199869519856293e-06\n",
      "Epoch 2494, Loss: 0.00019193661501049064, Final Batch Loss: 0.0001658213877817616\n",
      "Epoch 2495, Loss: 0.00014247743820305914, Final Batch Loss: 5.216767021920532e-05\n",
      "Epoch 2496, Loss: 9.430638692720095e-05, Final Batch Loss: 1.2369740034046117e-05\n",
      "Epoch 2497, Loss: 0.0013523430097848177, Final Batch Loss: 0.0011075460352003574\n",
      "Epoch 2498, Loss: 0.00016362109454348683, Final Batch Loss: 7.695953536313027e-05\n",
      "Epoch 2499, Loss: 0.0009949339646482258, Final Batch Loss: 0.0009826282039284706\n",
      "Epoch 2500, Loss: 7.573792572657112e-05, Final Batch Loss: 9.98295763565693e-06\n",
      "Epoch 2501, Loss: 0.0007999690133146942, Final Batch Loss: 4.3635780457407236e-05\n",
      "Epoch 2502, Loss: 0.010322659480152652, Final Batch Loss: 0.00037458373117260635\n",
      "Epoch 2503, Loss: 0.0001581055166752776, Final Batch Loss: 1.972342397493776e-05\n",
      "Epoch 2504, Loss: 5.020897515350953e-05, Final Batch Loss: 2.383643550274428e-05\n",
      "Epoch 2505, Loss: 0.04074982476049627, Final Batch Loss: 1.5880135833867826e-05\n",
      "Epoch 2506, Loss: 0.0031213136153382948, Final Batch Loss: 0.0030946421902626753\n",
      "Epoch 2507, Loss: 0.0012935194245073944, Final Batch Loss: 0.0001043671800289303\n",
      "Epoch 2508, Loss: 0.0006361589184962213, Final Batch Loss: 0.00039180341991595924\n",
      "Epoch 2509, Loss: 0.000887901607711683, Final Batch Loss: 2.805891381285619e-05\n",
      "Epoch 2510, Loss: 5.8178449762635864e-05, Final Batch Loss: 4.626436566468328e-05\n",
      "Epoch 2511, Loss: 0.0005034030764363706, Final Batch Loss: 0.00028199402731843293\n",
      "Epoch 2512, Loss: 0.01702474764897488, Final Batch Loss: 0.01660401187837124\n",
      "Epoch 2513, Loss: 0.0005381335504353046, Final Batch Loss: 0.00013611215399578214\n",
      "Epoch 2514, Loss: 0.001838434487581253, Final Batch Loss: 0.0016124884132295847\n",
      "Epoch 2515, Loss: 0.00020663365648943, Final Batch Loss: 0.00014941779954824597\n",
      "Epoch 2516, Loss: 8.77432148627122e-05, Final Batch Loss: 1.4341164387587924e-05\n",
      "Epoch 2517, Loss: 0.006509682585601695, Final Batch Loss: 0.006344848312437534\n",
      "Epoch 2518, Loss: 0.0008694009848113637, Final Batch Loss: 3.542018748703413e-05\n",
      "Epoch 2519, Loss: 0.0015033205272629857, Final Batch Loss: 0.0002643187763169408\n",
      "Epoch 2520, Loss: 0.00045648645391338505, Final Batch Loss: 5.4564563470194116e-05\n",
      "Epoch 2521, Loss: 0.0006005199247738346, Final Batch Loss: 0.0003854042151942849\n",
      "Epoch 2522, Loss: 0.00018703695241129026, Final Batch Loss: 4.40529765910469e-05\n",
      "Epoch 2523, Loss: 0.00043900585296796635, Final Batch Loss: 0.00032087555155158043\n",
      "Epoch 2524, Loss: 0.0027984514599666, Final Batch Loss: 0.002276411047205329\n",
      "Epoch 2525, Loss: 0.00044229668856132776, Final Batch Loss: 7.788925722707063e-05\n",
      "Epoch 2526, Loss: 0.0010734327006503008, Final Batch Loss: 0.0009590759291313589\n",
      "Epoch 2527, Loss: 0.005216451012529433, Final Batch Loss: 0.00029386638198047876\n",
      "Epoch 2528, Loss: 0.0003498303340165876, Final Batch Loss: 0.00023290407261811197\n",
      "Epoch 2529, Loss: 0.003452437638770789, Final Batch Loss: 0.0003605300444178283\n",
      "Epoch 2530, Loss: 0.0011332386638969183, Final Batch Loss: 0.0005043006385676563\n",
      "Epoch 2531, Loss: 0.0009601686324458569, Final Batch Loss: 0.0008133427472785115\n",
      "Epoch 2532, Loss: 0.0004160986572969705, Final Batch Loss: 0.00026134561630897224\n",
      "Epoch 2533, Loss: 0.00013608220433525275, Final Batch Loss: 2.6037150746560656e-05\n",
      "Epoch 2534, Loss: 0.0021499443319044076, Final Batch Loss: 0.0020697847940027714\n",
      "Epoch 2535, Loss: 0.00042741899233078584, Final Batch Loss: 6.357771781040356e-05\n",
      "Epoch 2536, Loss: 0.0007957842990435893, Final Batch Loss: 0.0007710768841207027\n",
      "Epoch 2537, Loss: 0.0003969143253925722, Final Batch Loss: 0.00036595974233932793\n",
      "Epoch 2538, Loss: 0.00033913755760295317, Final Batch Loss: 6.156047311378643e-05\n",
      "Epoch 2539, Loss: 4.393679409986362e-05, Final Batch Loss: 3.137347084702924e-05\n",
      "Epoch 2540, Loss: 0.0006118586316006258, Final Batch Loss: 0.0005077925161458552\n",
      "Epoch 2541, Loss: 0.00040341956628253683, Final Batch Loss: 3.689520963234827e-05\n",
      "Epoch 2542, Loss: 0.0001387909233017126, Final Batch Loss: 2.8487980671343394e-05\n",
      "Epoch 2543, Loss: 0.0006110052709118463, Final Batch Loss: 7.832740811863914e-05\n",
      "Epoch 2544, Loss: 0.00032397643371950835, Final Batch Loss: 0.00017261689936276525\n",
      "Epoch 2545, Loss: 0.00015482089293072931, Final Batch Loss: 9.92155764834024e-05\n",
      "Epoch 2546, Loss: 0.00018282443852513097, Final Batch Loss: 2.360663711442612e-05\n",
      "Epoch 2547, Loss: 0.0002587562703411095, Final Batch Loss: 9.331719047622755e-05\n",
      "Epoch 2548, Loss: 0.0007927092665340751, Final Batch Loss: 0.00019388753571547568\n",
      "Epoch 2549, Loss: 0.00025250633552786894, Final Batch Loss: 0.00021037932310719043\n",
      "Epoch 2550, Loss: 0.00029417113546514884, Final Batch Loss: 0.00011165154137415811\n",
      "Epoch 2551, Loss: 0.00012220253120176494, Final Batch Loss: 5.5921642342582345e-05\n",
      "Epoch 2552, Loss: 0.0002959777630167082, Final Batch Loss: 0.0002185257471865043\n",
      "Epoch 2553, Loss: 0.00043155082676094025, Final Batch Loss: 0.00014961334818508476\n",
      "Epoch 2554, Loss: 0.00021420526718429755, Final Batch Loss: 1.8187723981100135e-05\n",
      "Epoch 2555, Loss: 0.00036247671232558787, Final Batch Loss: 0.000181066949153319\n",
      "Epoch 2556, Loss: 0.00854212007834576, Final Batch Loss: 0.0002759672643151134\n",
      "Epoch 2557, Loss: 0.008062663891905686, Final Batch Loss: 0.008029057644307613\n",
      "Epoch 2558, Loss: 0.0002883211927837692, Final Batch Loss: 0.00022375868866220117\n",
      "Epoch 2559, Loss: 0.0009083734476007521, Final Batch Loss: 0.00019021827029064298\n",
      "Epoch 2560, Loss: 0.0018447831680532545, Final Batch Loss: 0.0017835511825978756\n",
      "Epoch 2561, Loss: 0.0015111749889911152, Final Batch Loss: 0.0014646518975496292\n",
      "Epoch 2562, Loss: 0.0007969971338752657, Final Batch Loss: 0.0005459549138322473\n",
      "Epoch 2563, Loss: 0.0005950030463282019, Final Batch Loss: 0.000266663555521518\n",
      "Epoch 2564, Loss: 0.0015273403696483001, Final Batch Loss: 0.0013934624148532748\n",
      "Epoch 2565, Loss: 0.004032468888908625, Final Batch Loss: 0.0009172616992145777\n",
      "Epoch 2566, Loss: 0.0006888736388646066, Final Batch Loss: 0.0002520886482670903\n",
      "Epoch 2567, Loss: 0.0003255746851209551, Final Batch Loss: 0.0001407349918736145\n",
      "Epoch 2568, Loss: 0.0002061354389297776, Final Batch Loss: 7.404796633636579e-05\n",
      "Epoch 2569, Loss: 0.00016127740309457295, Final Batch Loss: 0.0001165900393971242\n",
      "Epoch 2570, Loss: 8.381690167880151e-05, Final Batch Loss: 6.408707849914208e-05\n",
      "Epoch 2571, Loss: 0.0001537275966256857, Final Batch Loss: 9.182973735732958e-05\n",
      "Epoch 2572, Loss: 0.0002666780128492974, Final Batch Loss: 9.445036266697571e-05\n",
      "Epoch 2573, Loss: 0.0003794859349000035, Final Batch Loss: 1.746586167428177e-05\n",
      "Epoch 2574, Loss: 0.00010039729386335239, Final Batch Loss: 7.046385871944949e-05\n",
      "Epoch 2575, Loss: 0.0001140849526564125, Final Batch Loss: 7.048167753964663e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2576, Loss: 0.0004081051592947915, Final Batch Loss: 0.00018595883739180863\n",
      "Epoch 2577, Loss: 0.0011489149037515745, Final Batch Loss: 0.001070691621862352\n",
      "Epoch 2578, Loss: 0.00026248316862620413, Final Batch Loss: 4.173901106696576e-05\n",
      "Epoch 2579, Loss: 0.0007369689992628992, Final Batch Loss: 0.00035131166805513203\n",
      "Epoch 2580, Loss: 0.0008947045771492412, Final Batch Loss: 2.864437374228146e-05\n",
      "Epoch 2581, Loss: 0.0010037937099696137, Final Batch Loss: 0.0009338184027001262\n",
      "Epoch 2582, Loss: 0.0003182617438142188, Final Batch Loss: 0.00028333740192465484\n",
      "Epoch 2583, Loss: 0.00046547075362468604, Final Batch Loss: 0.0004508295969571918\n",
      "Epoch 2584, Loss: 0.0024824513275234494, Final Batch Loss: 0.0024474619422107935\n",
      "Epoch 2585, Loss: 9.30468704609666e-05, Final Batch Loss: 4.6476350689772516e-05\n",
      "Epoch 2586, Loss: 0.0002836781713995151, Final Batch Loss: 0.00022182623797561973\n",
      "Epoch 2587, Loss: 0.0004078784113517031, Final Batch Loss: 0.00013935814786236733\n",
      "Epoch 2588, Loss: 0.0005122478360135574, Final Batch Loss: 0.0004858155152760446\n",
      "Epoch 2589, Loss: 0.0002853029045581934, Final Batch Loss: 0.0002722777135204524\n",
      "Epoch 2590, Loss: 0.0004634505894500762, Final Batch Loss: 0.0002965151215903461\n",
      "Epoch 2591, Loss: 0.0009798078681342304, Final Batch Loss: 0.0003034129040315747\n",
      "Epoch 2592, Loss: 0.00014430275405175053, Final Batch Loss: 0.00012290016456972808\n",
      "Epoch 2593, Loss: 0.00036099118915444706, Final Batch Loss: 2.4226284949691035e-05\n",
      "Epoch 2594, Loss: 0.0006617677208851092, Final Batch Loss: 9.824765584198758e-05\n",
      "Epoch 2595, Loss: 0.000310193128825631, Final Batch Loss: 0.00010659425606718287\n",
      "Epoch 2596, Loss: 0.0007186336297309026, Final Batch Loss: 0.00014556692622136325\n",
      "Epoch 2597, Loss: 0.0007056735776131973, Final Batch Loss: 0.00015997949230950326\n",
      "Epoch 2598, Loss: 0.00023862792068030103, Final Batch Loss: 5.959967438684544e-06\n",
      "Epoch 2599, Loss: 0.0011386218247935176, Final Batch Loss: 0.0001574503257870674\n",
      "Epoch 2600, Loss: 0.027614607592113316, Final Batch Loss: 0.02744438499212265\n",
      "Epoch 2601, Loss: 0.00015770825848449022, Final Batch Loss: 0.00011761202767957002\n",
      "Epoch 2602, Loss: 0.00015043634994071908, Final Batch Loss: 0.00012988426897209138\n",
      "Epoch 2603, Loss: 0.0003930230886908248, Final Batch Loss: 0.00023603862791787833\n",
      "Epoch 2604, Loss: 0.00014577010733773932, Final Batch Loss: 9.503532783128321e-05\n",
      "Epoch 2605, Loss: 0.0028968587866984308, Final Batch Loss: 0.002471846528351307\n",
      "Epoch 2606, Loss: 0.0025578434579074383, Final Batch Loss: 0.0006174090085551143\n",
      "Epoch 2607, Loss: 0.0020586656173691154, Final Batch Loss: 0.001777683268301189\n",
      "Epoch 2608, Loss: 0.0007099375143297948, Final Batch Loss: 6.318107625702396e-05\n",
      "Epoch 2609, Loss: 0.001298919287364697, Final Batch Loss: 0.0012445742031559348\n",
      "Epoch 2610, Loss: 0.0022437997395172715, Final Batch Loss: 0.0019774185493588448\n",
      "Epoch 2611, Loss: 0.00043884487877221545, Final Batch Loss: 5.025655809731688e-06\n",
      "Epoch 2612, Loss: 0.004988218424841762, Final Batch Loss: 0.002868571085855365\n",
      "Epoch 2613, Loss: 0.0005463813722599298, Final Batch Loss: 0.0002552313089836389\n",
      "Epoch 2614, Loss: 0.00017806890173233114, Final Batch Loss: 0.00016104978567454964\n",
      "Epoch 2615, Loss: 4.489354796533007e-05, Final Batch Loss: 1.243399856321048e-05\n",
      "Epoch 2616, Loss: 0.00030292066185211297, Final Batch Loss: 0.0002823622489813715\n",
      "Epoch 2617, Loss: 0.0014240294767660089, Final Batch Loss: 0.00010028959513874725\n",
      "Epoch 2618, Loss: 0.0004310585354687646, Final Batch Loss: 0.00021444089361466467\n",
      "Epoch 2619, Loss: 0.0003863316869683331, Final Batch Loss: 0.0003732556651812047\n",
      "Epoch 2620, Loss: 0.00027841223345603794, Final Batch Loss: 0.00010946282418444753\n",
      "Epoch 2621, Loss: 0.0003664672149170656, Final Batch Loss: 0.0003122566267848015\n",
      "Epoch 2622, Loss: 0.00020060152746737003, Final Batch Loss: 0.0001259162527276203\n",
      "Epoch 2623, Loss: 0.0005100194102851674, Final Batch Loss: 0.00038640579441562295\n",
      "Epoch 2624, Loss: 0.0003533070266712457, Final Batch Loss: 0.00030531204538419843\n",
      "Epoch 2625, Loss: 0.008099699625745416, Final Batch Loss: 0.0004669299814850092\n",
      "Epoch 2626, Loss: 8.789579806034453e-05, Final Batch Loss: 7.183902926044539e-05\n",
      "Epoch 2627, Loss: 0.00013931111789133865, Final Batch Loss: 0.0001170527539215982\n",
      "Epoch 2628, Loss: 0.00018867463222704828, Final Batch Loss: 0.00010540389484958723\n",
      "Epoch 2629, Loss: 0.0002344214044569526, Final Batch Loss: 3.218202982679941e-05\n",
      "Epoch 2630, Loss: 0.0011808474137069425, Final Batch Loss: 1.3465882148011588e-05\n",
      "Epoch 2631, Loss: 0.00016338703062501736, Final Batch Loss: 3.444152025622316e-05\n",
      "Epoch 2632, Loss: 0.00034599879018060165, Final Batch Loss: 7.643798198841978e-06\n",
      "Epoch 2633, Loss: 0.00019437199080130085, Final Batch Loss: 3.4127348044421524e-05\n",
      "Epoch 2634, Loss: 8.214148510887753e-05, Final Batch Loss: 1.53235796460649e-05\n",
      "Epoch 2635, Loss: 0.00024147770818672143, Final Batch Loss: 0.00020647443307098\n",
      "Epoch 2636, Loss: 0.00024529934398742625, Final Batch Loss: 1.4770667803531978e-05\n",
      "Epoch 2637, Loss: 0.0019586978160077706, Final Batch Loss: 7.041696517262608e-05\n",
      "Epoch 2638, Loss: 0.0001984884511330165, Final Batch Loss: 5.760997737525031e-05\n",
      "Epoch 2639, Loss: 0.0006052058888599277, Final Batch Loss: 9.094103006646037e-05\n",
      "Epoch 2640, Loss: 0.00016436677833553404, Final Batch Loss: 6.283399125095457e-05\n",
      "Epoch 2641, Loss: 0.001939416310051456, Final Batch Loss: 0.0002996509720105678\n",
      "Epoch 2642, Loss: 0.00022185518355399836, Final Batch Loss: 1.2051286830683239e-05\n",
      "Epoch 2643, Loss: 0.0001925829565152526, Final Batch Loss: 7.292815280379727e-05\n",
      "Epoch 2644, Loss: 0.0002772767074930016, Final Batch Loss: 0.00024454883532598615\n",
      "Epoch 2645, Loss: 0.001049523547408171, Final Batch Loss: 0.0009769059251993895\n",
      "Epoch 2646, Loss: 8.261521043095854e-05, Final Batch Loss: 4.1557000258762855e-06\n",
      "Epoch 2647, Loss: 0.0001216604850924341, Final Batch Loss: 1.2077425708412193e-05\n",
      "Epoch 2648, Loss: 0.0012809874606318772, Final Batch Loss: 0.00018549809465184808\n",
      "Epoch 2649, Loss: 0.0001934152878675377, Final Batch Loss: 5.664018317474984e-06\n",
      "Epoch 2650, Loss: 0.0006947019137442112, Final Batch Loss: 0.0006232751184143126\n",
      "Epoch 2651, Loss: 0.0003327130398247391, Final Batch Loss: 0.00025831026141531765\n",
      "Epoch 2652, Loss: 4.7392082706210203e-05, Final Batch Loss: 1.810128742363304e-05\n",
      "Epoch 2653, Loss: 0.0002877051738323644, Final Batch Loss: 0.0002210563252447173\n",
      "Epoch 2654, Loss: 9.861497528618202e-05, Final Batch Loss: 5.589907232206315e-06\n",
      "Epoch 2655, Loss: 0.00025200562140526017, Final Batch Loss: 1.003326087811729e-05\n",
      "Epoch 2656, Loss: 0.00036598638689611107, Final Batch Loss: 0.00029425977845676243\n",
      "Epoch 2657, Loss: 0.00011319272198306862, Final Batch Loss: 9.418325498700142e-05\n",
      "Epoch 2658, Loss: 0.0006276767962845042, Final Batch Loss: 0.00046836986439302564\n",
      "Epoch 2659, Loss: 0.00010356196708016796, Final Batch Loss: 9.3786393335904e-06\n",
      "Epoch 2660, Loss: 0.00013852187930751825, Final Batch Loss: 0.00012502734898589551\n",
      "Epoch 2661, Loss: 0.00011853928663185798, Final Batch Loss: 5.541413338505663e-05\n",
      "Epoch 2662, Loss: 0.00028154204483143985, Final Batch Loss: 5.386964767239988e-05\n",
      "Epoch 2663, Loss: 0.0003269218868808821, Final Batch Loss: 0.0002244743227493018\n",
      "Epoch 2664, Loss: 0.00010298594679625239, Final Batch Loss: 9.45896863413509e-06\n",
      "Epoch 2665, Loss: 0.0006433559665310895, Final Batch Loss: 1.2546506695798598e-05\n",
      "Epoch 2666, Loss: 0.00041650907041912433, Final Batch Loss: 0.0003997329040430486\n",
      "Epoch 2667, Loss: 0.00046983646461740136, Final Batch Loss: 0.000247950287302956\n",
      "Epoch 2668, Loss: 2.4415424377366435e-05, Final Batch Loss: 5.496837729879189e-06\n",
      "Epoch 2669, Loss: 0.0007909707992439508, Final Batch Loss: 0.0007780129089951515\n",
      "Epoch 2670, Loss: 0.002727098297327757, Final Batch Loss: 0.00254740659147501\n",
      "Epoch 2671, Loss: 0.00035669976023200434, Final Batch Loss: 0.0003407247131690383\n",
      "Epoch 2672, Loss: 0.0001642521019675769, Final Batch Loss: 1.4476558135356754e-05\n",
      "Epoch 2673, Loss: 0.0008063561326707713, Final Batch Loss: 4.058889317093417e-05\n",
      "Epoch 2674, Loss: 0.00022925033408682793, Final Batch Loss: 0.00015929838991723955\n",
      "Epoch 2675, Loss: 0.00016403534391429275, Final Batch Loss: 5.067135498393327e-05\n",
      "Epoch 2676, Loss: 0.0005744534428231418, Final Batch Loss: 0.00026499025989323854\n",
      "Epoch 2677, Loss: 7.792939686623868e-05, Final Batch Loss: 2.0204390239086933e-05\n",
      "Epoch 2678, Loss: 3.726928844116628e-05, Final Batch Loss: 2.9612820071633905e-05\n",
      "Epoch 2679, Loss: 0.0005516740493476391, Final Batch Loss: 0.0003221903170924634\n",
      "Epoch 2680, Loss: 0.00018657079635886475, Final Batch Loss: 0.0001042950534611009\n",
      "Epoch 2681, Loss: 8.173078913387144e-05, Final Batch Loss: 6.854811363155022e-05\n",
      "Epoch 2682, Loss: 2.1948851099296007e-05, Final Batch Loss: 1.1136005923617631e-05\n",
      "Epoch 2683, Loss: 4.9134649088955484e-05, Final Batch Loss: 2.649960333656054e-05\n",
      "Epoch 2684, Loss: 0.0002750345847744029, Final Batch Loss: 1.8948350771097466e-05\n",
      "Epoch 2685, Loss: 0.00029851734871044755, Final Batch Loss: 7.972853200044483e-05\n",
      "Epoch 2686, Loss: 7.671719026802748e-05, Final Batch Loss: 2.1545008621615125e-06\n",
      "Epoch 2687, Loss: 0.0341673911025282, Final Batch Loss: 0.034006066620349884\n",
      "Epoch 2688, Loss: 0.007825408087228425, Final Batch Loss: 0.007743546739220619\n",
      "Epoch 2689, Loss: 0.00028241402469575405, Final Batch Loss: 0.00027123690233565867\n",
      "Epoch 2690, Loss: 7.959672439028509e-05, Final Batch Loss: 4.748817809741013e-05\n",
      "Epoch 2691, Loss: 0.00025261176779167727, Final Batch Loss: 0.0001661349815549329\n",
      "Epoch 2692, Loss: 0.0004686000756919384, Final Batch Loss: 3.471589297987521e-05\n",
      "Epoch 2693, Loss: 0.001043879019562155, Final Batch Loss: 0.0004639629041776061\n",
      "Epoch 2694, Loss: 0.0012826567981392145, Final Batch Loss: 0.0005878058145754039\n",
      "Epoch 2695, Loss: 0.00294123642379418, Final Batch Loss: 0.0006046349299140275\n",
      "Epoch 2696, Loss: 0.0860878266976215, Final Batch Loss: 0.08561088889837265\n",
      "Epoch 2697, Loss: 0.015475249994779006, Final Batch Loss: 0.000383967679226771\n",
      "Epoch 2698, Loss: 0.0008215111156459898, Final Batch Loss: 0.00030568227521143854\n",
      "Epoch 2699, Loss: 0.0006751369219273329, Final Batch Loss: 0.0003145491355098784\n",
      "Epoch 2700, Loss: 0.0003030755615327507, Final Batch Loss: 0.0002275630395160988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2701, Loss: 0.0011610751098487526, Final Batch Loss: 0.0007280533318407834\n",
      "Epoch 2702, Loss: 0.00025174188340315595, Final Batch Loss: 6.59072320559062e-05\n",
      "Epoch 2703, Loss: 0.0005701937334379181, Final Batch Loss: 0.0003840226272586733\n",
      "Epoch 2704, Loss: 0.0006488040671683848, Final Batch Loss: 0.0002743176301009953\n",
      "Epoch 2705, Loss: 0.003194641845766455, Final Batch Loss: 0.0023605527821928263\n",
      "Epoch 2706, Loss: 0.0007811928808223456, Final Batch Loss: 0.0005315904854796827\n",
      "Epoch 2707, Loss: 0.01120612071827054, Final Batch Loss: 0.001527425367385149\n",
      "Epoch 2708, Loss: 0.0004898415645584464, Final Batch Loss: 0.00018944573821499944\n",
      "Epoch 2709, Loss: 0.00016084953676909208, Final Batch Loss: 9.271894668927416e-05\n",
      "Epoch 2710, Loss: 0.0001320665433013346, Final Batch Loss: 8.769567648414522e-05\n",
      "Epoch 2711, Loss: 0.0006590454067918472, Final Batch Loss: 7.734889368293807e-05\n",
      "Epoch 2712, Loss: 0.0005892757617402822, Final Batch Loss: 7.053188164718449e-05\n",
      "Epoch 2713, Loss: 0.0004088603745913133, Final Batch Loss: 0.00017760921036824584\n",
      "Epoch 2714, Loss: 0.025673965457826853, Final Batch Loss: 0.025446612387895584\n",
      "Epoch 2715, Loss: 0.00023206528567243367, Final Batch Loss: 6.415488314814866e-05\n",
      "Epoch 2716, Loss: 0.0006700635130982846, Final Batch Loss: 0.0005515777156688273\n",
      "Epoch 2717, Loss: 6.928148286533542e-05, Final Batch Loss: 2.7407859306549653e-05\n",
      "Epoch 2718, Loss: 0.0018385300936643034, Final Batch Loss: 0.00032046405249275267\n",
      "Epoch 2719, Loss: 0.039531165901280474, Final Batch Loss: 0.039485521614551544\n",
      "Epoch 2720, Loss: 0.00012182522550574504, Final Batch Loss: 9.052743553183973e-05\n",
      "Epoch 2721, Loss: 0.001961300295079127, Final Batch Loss: 0.0018159733153879642\n",
      "Epoch 2722, Loss: 0.0003208263478882145, Final Batch Loss: 0.000266105227638036\n",
      "Epoch 2723, Loss: 0.00040628851274959743, Final Batch Loss: 0.00013681731070391834\n",
      "Epoch 2724, Loss: 0.015651039371732622, Final Batch Loss: 8.670572424307466e-05\n",
      "Epoch 2725, Loss: 0.00028451224989112234, Final Batch Loss: 1.1668961633404251e-05\n",
      "Epoch 2726, Loss: 0.0003720410604728386, Final Batch Loss: 0.0002776971668936312\n",
      "Epoch 2727, Loss: 0.0003164240624755621, Final Batch Loss: 0.00022422053734771907\n",
      "Epoch 2728, Loss: 0.009009654771944042, Final Batch Loss: 7.461397763108835e-05\n",
      "Epoch 2729, Loss: 0.00026071341562783346, Final Batch Loss: 0.0001624088763492182\n",
      "Epoch 2730, Loss: 0.0018453671218594536, Final Batch Loss: 9.735951607581228e-05\n",
      "Epoch 2731, Loss: 0.00028718760586343706, Final Batch Loss: 0.0001420595363015309\n",
      "Epoch 2732, Loss: 0.0003627468686318025, Final Batch Loss: 0.0002157400012947619\n",
      "Epoch 2733, Loss: 0.0019285379094071686, Final Batch Loss: 0.0016259734984487295\n",
      "Epoch 2734, Loss: 0.0010132794559467584, Final Batch Loss: 0.00015911806258372962\n",
      "Epoch 2735, Loss: 0.0010680170089472085, Final Batch Loss: 0.00012965375208295882\n",
      "Epoch 2736, Loss: 0.006186131329741329, Final Batch Loss: 0.0059869661927223206\n",
      "Epoch 2737, Loss: 0.004381951919640414, Final Batch Loss: 0.00024143238260876387\n",
      "Epoch 2738, Loss: 0.0006383972067851573, Final Batch Loss: 0.0005600359872914851\n",
      "Epoch 2739, Loss: 0.0005016275026719086, Final Batch Loss: 6.431587826227769e-05\n",
      "Epoch 2740, Loss: 0.000316236968501471, Final Batch Loss: 0.00021619228937197477\n",
      "Epoch 2741, Loss: 0.0027172790723852813, Final Batch Loss: 0.00038101355312392116\n",
      "Epoch 2742, Loss: 0.001894945278763771, Final Batch Loss: 0.0017222658498212695\n",
      "Epoch 2743, Loss: 0.0003538697783369571, Final Batch Loss: 7.918340270407498e-05\n",
      "Epoch 2744, Loss: 0.0005480288964463398, Final Batch Loss: 0.00017023315012920648\n",
      "Epoch 2745, Loss: 0.0010430385082145222, Final Batch Loss: 0.00011671754327835515\n",
      "Epoch 2746, Loss: 0.00031979537016013637, Final Batch Loss: 3.2313379051629454e-05\n",
      "Epoch 2747, Loss: 0.0003603870136430487, Final Batch Loss: 0.0003123183560092002\n",
      "Epoch 2748, Loss: 0.0005980049027130008, Final Batch Loss: 0.0004656015953514725\n",
      "Epoch 2749, Loss: 0.0005617849310510792, Final Batch Loss: 8.05578674771823e-05\n",
      "Epoch 2750, Loss: 0.00022688038734486327, Final Batch Loss: 0.0001307227066718042\n",
      "Epoch 2751, Loss: 0.004176059796009213, Final Batch Loss: 0.0009316190262325108\n",
      "Epoch 2752, Loss: 0.0007524517131969333, Final Batch Loss: 0.0004544694093056023\n",
      "Epoch 2753, Loss: 0.0002190933155361563, Final Batch Loss: 0.00017628296336624771\n",
      "Epoch 2754, Loss: 0.01233792956918478, Final Batch Loss: 0.011564581654965878\n",
      "Epoch 2755, Loss: 0.0006417095501092263, Final Batch Loss: 0.0005493488279171288\n",
      "Epoch 2756, Loss: 0.0001540060984552838, Final Batch Loss: 6.135451258160174e-05\n",
      "Epoch 2757, Loss: 0.00024213408869400155, Final Batch Loss: 1.9766301193158142e-05\n",
      "Epoch 2758, Loss: 0.0002535611856728792, Final Batch Loss: 0.0001531131420051679\n",
      "Epoch 2759, Loss: 0.0001292322231165599, Final Batch Loss: 2.5738230760907754e-05\n",
      "Epoch 2760, Loss: 0.00015555583922832739, Final Batch Loss: 0.0001302200398640707\n",
      "Epoch 2761, Loss: 0.008154868308338337, Final Batch Loss: 0.007912170141935349\n",
      "Epoch 2762, Loss: 0.00043508640374056995, Final Batch Loss: 0.0002352463052375242\n",
      "Epoch 2763, Loss: 0.00016181317550945096, Final Batch Loss: 0.00013835930440109223\n",
      "Epoch 2764, Loss: 0.004434166505234316, Final Batch Loss: 0.004106035456061363\n",
      "Epoch 2765, Loss: 9.181394489132799e-05, Final Batch Loss: 1.6706249880371615e-05\n",
      "Epoch 2766, Loss: 0.0005076614761492237, Final Batch Loss: 0.0003182431391905993\n",
      "Epoch 2767, Loss: 0.0004493474043556489, Final Batch Loss: 7.944444223539904e-05\n",
      "Epoch 2768, Loss: 0.049842721069580875, Final Batch Loss: 0.00010679870320018381\n",
      "Epoch 2769, Loss: 0.009102906158659607, Final Batch Loss: 0.00884665735065937\n",
      "Epoch 2770, Loss: 0.00045159776345826685, Final Batch Loss: 0.00016901892377063632\n",
      "Epoch 2771, Loss: 0.0005433217374957167, Final Batch Loss: 6.922333705006167e-05\n",
      "Epoch 2772, Loss: 0.00037533833528868854, Final Batch Loss: 0.00011280368198640645\n",
      "Epoch 2773, Loss: 0.00025093966542044654, Final Batch Loss: 0.00020572630455717444\n",
      "Epoch 2774, Loss: 0.00024638004833832383, Final Batch Loss: 8.270342368632555e-05\n",
      "Epoch 2775, Loss: 0.0004268139382475056, Final Batch Loss: 0.00011814735626103356\n",
      "Epoch 2776, Loss: 0.0007778739382047206, Final Batch Loss: 0.00031658943044021726\n",
      "Epoch 2777, Loss: 0.0004629494796972722, Final Batch Loss: 0.00020648195641115308\n",
      "Epoch 2778, Loss: 0.0001708895779302111, Final Batch Loss: 1.683155096543487e-05\n",
      "Epoch 2779, Loss: 0.001833889342378825, Final Batch Loss: 0.00015232706209644675\n",
      "Epoch 2780, Loss: 0.0007261073551489972, Final Batch Loss: 0.0006386804743669927\n",
      "Epoch 2781, Loss: 0.001784718013368547, Final Batch Loss: 0.0008589091012254357\n",
      "Epoch 2782, Loss: 0.0032781085901660845, Final Batch Loss: 0.003097902750596404\n",
      "Epoch 2783, Loss: 0.0004773450637003407, Final Batch Loss: 0.0003224911342840642\n",
      "Epoch 2784, Loss: 0.000149731153214816, Final Batch Loss: 6.164723890833557e-05\n",
      "Epoch 2785, Loss: 0.00023162440265878104, Final Batch Loss: 5.32620724698063e-05\n",
      "Epoch 2786, Loss: 0.0004588948795571923, Final Batch Loss: 0.0001269571657758206\n",
      "Epoch 2787, Loss: 0.0011453853112470824, Final Batch Loss: 0.0011039340170100331\n",
      "Epoch 2788, Loss: 0.0005324195954017341, Final Batch Loss: 6.683895480819046e-05\n",
      "Epoch 2789, Loss: 0.0052548161474987864, Final Batch Loss: 0.0010396920843049884\n",
      "Epoch 2790, Loss: 0.0004655464581446722, Final Batch Loss: 0.00032970868051052094\n",
      "Epoch 2791, Loss: 0.001117185689508915, Final Batch Loss: 0.0003621822106651962\n",
      "Epoch 2792, Loss: 0.0004326350026531145, Final Batch Loss: 3.386240859981626e-05\n",
      "Epoch 2793, Loss: 0.0018863831064663827, Final Batch Loss: 0.001404127455316484\n",
      "Epoch 2794, Loss: 0.0017075421783374622, Final Batch Loss: 0.0015529446536675096\n",
      "Epoch 2795, Loss: 0.0010575793276075274, Final Batch Loss: 0.0009804093278944492\n",
      "Epoch 2796, Loss: 0.00028414357802830637, Final Batch Loss: 0.00015326742141041905\n",
      "Epoch 2797, Loss: 0.0053666036037611775, Final Batch Loss: 5.704699287889525e-05\n",
      "Epoch 2798, Loss: 0.000453084270702675, Final Batch Loss: 0.00014267920050770044\n",
      "Epoch 2799, Loss: 0.0059026305680163205, Final Batch Loss: 0.00018833467038348317\n",
      "Epoch 2800, Loss: 5.844988663739059e-05, Final Batch Loss: 4.0581820940133184e-05\n",
      "Epoch 2801, Loss: 0.00038041827792767435, Final Batch Loss: 5.2894160035066307e-05\n",
      "Epoch 2802, Loss: 0.0005187865608604625, Final Batch Loss: 8.369261922780424e-05\n",
      "Epoch 2803, Loss: 0.009304533537942916, Final Batch Loss: 0.0008370678988285363\n",
      "Epoch 2804, Loss: 7.312817251658998e-05, Final Batch Loss: 3.6054370866622776e-05\n",
      "Epoch 2805, Loss: 0.0031586250697728246, Final Batch Loss: 0.0027858854737132788\n",
      "Epoch 2806, Loss: 0.00023170411986939143, Final Batch Loss: 0.0002210032835137099\n",
      "Epoch 2807, Loss: 0.0003751346084754914, Final Batch Loss: 0.00021819827088620514\n",
      "Epoch 2808, Loss: 0.00013642519843415357, Final Batch Loss: 8.986303873825818e-05\n",
      "Epoch 2809, Loss: 7.851756708987523e-05, Final Batch Loss: 1.7433407265343703e-05\n",
      "Epoch 2810, Loss: 0.003435460908804089, Final Batch Loss: 0.0031119727063924074\n",
      "Epoch 2811, Loss: 6.540745744132437e-05, Final Batch Loss: 3.940755414078012e-05\n",
      "Epoch 2812, Loss: 0.00033084993992815726, Final Batch Loss: 0.0003080023161601275\n",
      "Epoch 2813, Loss: 0.00026347992388764396, Final Batch Loss: 0.00022857979638502002\n",
      "Epoch 2814, Loss: 5.78654398850631e-05, Final Batch Loss: 5.029068415751681e-05\n",
      "Epoch 2815, Loss: 0.0001590191004652297, Final Batch Loss: 0.00013150865561328828\n",
      "Epoch 2816, Loss: 0.00030764801704208367, Final Batch Loss: 0.0002885173598770052\n",
      "Epoch 2817, Loss: 0.0006076267454773188, Final Batch Loss: 0.000558309315238148\n",
      "Epoch 2818, Loss: 0.00021612380533042597, Final Batch Loss: 0.00020676293934229761\n",
      "Epoch 2819, Loss: 0.00023028750729281455, Final Batch Loss: 0.0001358506706310436\n",
      "Epoch 2820, Loss: 0.00028180952358525246, Final Batch Loss: 0.00010682789434213191\n",
      "Epoch 2821, Loss: 0.0008333960140589625, Final Batch Loss: 0.000136950722662732\n",
      "Epoch 2822, Loss: 0.00013177108121453784, Final Batch Loss: 8.027750300243497e-05\n",
      "Epoch 2823, Loss: 0.00039199262391775846, Final Batch Loss: 0.0002671943511813879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2824, Loss: 0.00010792080865940079, Final Batch Loss: 8.832154708215967e-05\n",
      "Epoch 2825, Loss: 0.00025101384017034434, Final Batch Loss: 0.0002056905796052888\n",
      "Epoch 2826, Loss: 0.0003123083515674807, Final Batch Loss: 1.7348713299725205e-05\n",
      "Epoch 2827, Loss: 0.000634564581559971, Final Batch Loss: 0.0003896653652191162\n",
      "Epoch 2828, Loss: 8.0637739301892e-05, Final Batch Loss: 3.30750408465974e-05\n",
      "Epoch 2829, Loss: 0.0003700055385706946, Final Batch Loss: 0.00033021855051629245\n",
      "Epoch 2830, Loss: 0.00013081830911687575, Final Batch Loss: 0.00010317921987734735\n",
      "Epoch 2831, Loss: 0.00414754008033924, Final Batch Loss: 0.004142363090068102\n",
      "Epoch 2832, Loss: 0.00023324762878473848, Final Batch Loss: 0.00010126872803084552\n",
      "Epoch 2833, Loss: 0.0009051847573573468, Final Batch Loss: 0.000886335561517626\n",
      "Epoch 2834, Loss: 0.00021611544798361138, Final Batch Loss: 6.525126082124189e-05\n",
      "Epoch 2835, Loss: 0.0001986066918107099, Final Batch Loss: 1.2824340046790894e-05\n",
      "Epoch 2836, Loss: 7.52150244807126e-05, Final Batch Loss: 6.651443254668266e-05\n",
      "Epoch 2837, Loss: 0.000699577693012543, Final Batch Loss: 0.0001228166074724868\n",
      "Epoch 2838, Loss: 0.0004628315655281767, Final Batch Loss: 3.39412217726931e-05\n",
      "Epoch 2839, Loss: 9.782625056686811e-05, Final Batch Loss: 4.8650468670530245e-05\n",
      "Epoch 2840, Loss: 0.02728911067242734, Final Batch Loss: 0.026965375989675522\n",
      "Epoch 2841, Loss: 0.00010841557013918646, Final Batch Loss: 7.504766108468175e-05\n",
      "Epoch 2842, Loss: 0.0010142517621716252, Final Batch Loss: 0.0009890011278912425\n",
      "Epoch 2843, Loss: 8.372975207748823e-05, Final Batch Loss: 3.454411853454076e-05\n",
      "Epoch 2844, Loss: 0.00013251302880235016, Final Batch Loss: 4.035751044284552e-05\n",
      "Epoch 2845, Loss: 0.00020577241957653314, Final Batch Loss: 0.00016880226030480117\n",
      "Epoch 2846, Loss: 0.0003879320283886045, Final Batch Loss: 0.00018987992370966822\n",
      "Epoch 2847, Loss: 0.0007366678182734177, Final Batch Loss: 0.00013779794971924275\n",
      "Epoch 2848, Loss: 0.009814000863116235, Final Batch Loss: 0.009477449581027031\n",
      "Epoch 2849, Loss: 0.00030271949799498543, Final Batch Loss: 8.63826644490473e-05\n",
      "Epoch 2850, Loss: 0.001151789321738761, Final Batch Loss: 6.409337947843596e-05\n",
      "Epoch 2851, Loss: 0.00021836411178810522, Final Batch Loss: 1.1712305422406644e-05\n",
      "Epoch 2852, Loss: 0.0003714563645189628, Final Batch Loss: 0.0001657217217143625\n",
      "Epoch 2853, Loss: 0.00036288257433625404, Final Batch Loss: 9.895253242575563e-06\n",
      "Epoch 2854, Loss: 0.0030645552396890707, Final Batch Loss: 0.003028695471584797\n",
      "Epoch 2855, Loss: 0.0005994916646159254, Final Batch Loss: 8.80132065503858e-05\n",
      "Epoch 2856, Loss: 0.0008479323514620773, Final Batch Loss: 0.0007335158879868686\n",
      "Epoch 2857, Loss: 0.0012507346691563725, Final Batch Loss: 0.0006286286516115069\n",
      "Epoch 2858, Loss: 0.00031852786560193636, Final Batch Loss: 0.000264741072896868\n",
      "Epoch 2859, Loss: 0.00020058962854818674, Final Batch Loss: 0.0001928052370203659\n",
      "Epoch 2860, Loss: 0.000102701651485404, Final Batch Loss: 4.836252628592774e-05\n",
      "Epoch 2861, Loss: 0.0005254440766293555, Final Batch Loss: 0.00015254277968779206\n",
      "Epoch 2862, Loss: 0.00041306656930828467, Final Batch Loss: 8.466142026009038e-05\n",
      "Epoch 2863, Loss: 0.017662573693087325, Final Batch Loss: 0.00039055952220223844\n",
      "Epoch 2864, Loss: 0.00014594470849260688, Final Batch Loss: 3.509601083351299e-05\n",
      "Epoch 2865, Loss: 0.00017926800501300022, Final Batch Loss: 7.901096978457645e-05\n",
      "Epoch 2866, Loss: 0.0004458467592485249, Final Batch Loss: 0.0003916196583304554\n",
      "Epoch 2867, Loss: 9.977418994822074e-05, Final Batch Loss: 7.323432510020211e-05\n",
      "Epoch 2868, Loss: 0.0037742758286185563, Final Batch Loss: 0.0001425273367203772\n",
      "Epoch 2869, Loss: 0.018324389966437593, Final Batch Loss: 0.017922770231962204\n",
      "Epoch 2870, Loss: 0.0013067803884041496, Final Batch Loss: 2.3339300241786987e-05\n",
      "Epoch 2871, Loss: 0.00022931800049263984, Final Batch Loss: 0.00019580533262342215\n",
      "Epoch 2872, Loss: 0.0014891625178279355, Final Batch Loss: 0.0013631517067551613\n",
      "Epoch 2873, Loss: 0.00032453943276777864, Final Batch Loss: 0.00020155370293650776\n",
      "Epoch 2874, Loss: 0.0005275195799185894, Final Batch Loss: 0.0004209495964460075\n",
      "Epoch 2875, Loss: 7.120936516002985e-05, Final Batch Loss: 1.5251564946083818e-05\n",
      "Epoch 2876, Loss: 0.00026835194876184687, Final Batch Loss: 3.253632894484326e-05\n",
      "Epoch 2877, Loss: 0.0001286218648601789, Final Batch Loss: 8.80899460753426e-05\n",
      "Epoch 2878, Loss: 0.004993332687263319, Final Batch Loss: 9.795322512218263e-06\n",
      "Epoch 2879, Loss: 0.00018056075532513205, Final Batch Loss: 0.00017209337966050953\n",
      "Epoch 2880, Loss: 0.0010948503768304363, Final Batch Loss: 0.0009233155287802219\n",
      "Epoch 2881, Loss: 0.0005193928518565372, Final Batch Loss: 0.00035790621768683195\n",
      "Epoch 2882, Loss: 0.00024588749511167407, Final Batch Loss: 0.0002019031235249713\n",
      "Epoch 2883, Loss: 0.00032784874201752245, Final Batch Loss: 0.00020203918393235654\n",
      "Epoch 2884, Loss: 0.0014361976354848593, Final Batch Loss: 0.00012037469423376024\n",
      "Epoch 2885, Loss: 0.00021408615248219576, Final Batch Loss: 1.9257020539953373e-05\n",
      "Epoch 2886, Loss: 5.682847677235259e-05, Final Batch Loss: 4.312301825848408e-05\n",
      "Epoch 2887, Loss: 0.001032089043292217, Final Batch Loss: 7.470800483133644e-05\n",
      "Epoch 2888, Loss: 0.0006681922532152385, Final Batch Loss: 0.0004003043577540666\n",
      "Epoch 2889, Loss: 0.0023322530032601207, Final Batch Loss: 0.0018457863479852676\n",
      "Epoch 2890, Loss: 0.010811396321514621, Final Batch Loss: 0.00012551099644042552\n",
      "Epoch 2891, Loss: 0.0002671383190318011, Final Batch Loss: 0.00019236086518503726\n",
      "Epoch 2892, Loss: 8.356729154002096e-05, Final Batch Loss: 3.669746320156264e-06\n",
      "Epoch 2893, Loss: 0.00025511714193271473, Final Batch Loss: 3.39108009939082e-05\n",
      "Epoch 2894, Loss: 0.000501903414260596, Final Batch Loss: 0.00021614858997054398\n",
      "Epoch 2895, Loss: 0.00028400768860592507, Final Batch Loss: 3.278502481407486e-05\n",
      "Epoch 2896, Loss: 4.4029529817635193e-05, Final Batch Loss: 2.0119674445595592e-05\n",
      "Epoch 2897, Loss: 0.00013966924416308757, Final Batch Loss: 0.00011628311040112749\n",
      "Epoch 2898, Loss: 0.02455704529711511, Final Batch Loss: 6.843415030743927e-05\n",
      "Epoch 2899, Loss: 0.00021256534819258377, Final Batch Loss: 4.992649337509647e-05\n",
      "Epoch 2900, Loss: 0.009884838596917689, Final Batch Loss: 0.008884457871317863\n",
      "Epoch 2901, Loss: 0.0020311481202952564, Final Batch Loss: 0.0014757642056792974\n",
      "Epoch 2902, Loss: 0.002488060757968924, Final Batch Loss: 0.0024688050616532564\n",
      "Epoch 2903, Loss: 0.000452168911579065, Final Batch Loss: 0.00021538989676628262\n",
      "Epoch 2904, Loss: 0.00023486919053539168, Final Batch Loss: 2.6483101464691572e-05\n",
      "Epoch 2905, Loss: 0.00012480297755246283, Final Batch Loss: 1.2429173693817575e-05\n",
      "Epoch 2906, Loss: 4.809876963918214e-05, Final Batch Loss: 4.1435421735513955e-05\n",
      "Epoch 2907, Loss: 0.00014079116226639599, Final Batch Loss: 8.357509068446234e-05\n",
      "Epoch 2908, Loss: 0.00012538805458461866, Final Batch Loss: 4.8638808948453516e-05\n",
      "Epoch 2909, Loss: 0.0008850377344060689, Final Batch Loss: 0.0005071524647064507\n",
      "Epoch 2910, Loss: 0.0016414888705185149, Final Batch Loss: 4.829618046642281e-05\n",
      "Epoch 2911, Loss: 0.0004413845599628985, Final Batch Loss: 0.0003564402286428958\n",
      "Epoch 2912, Loss: 0.00019535394312697463, Final Batch Loss: 0.00016710383351892233\n",
      "Epoch 2913, Loss: 0.00108235256629996, Final Batch Loss: 0.0001357414002995938\n",
      "Epoch 2914, Loss: 0.0010933005105471238, Final Batch Loss: 5.1676048315130174e-05\n",
      "Epoch 2915, Loss: 0.0003075654512940673, Final Batch Loss: 0.0002809282159432769\n",
      "Epoch 2916, Loss: 0.0005611810920527205, Final Batch Loss: 0.0004543228424154222\n",
      "Epoch 2917, Loss: 0.0009016706899274141, Final Batch Loss: 0.00028536966419778764\n",
      "Epoch 2918, Loss: 0.0010202128032688051, Final Batch Loss: 0.00012923122267238796\n",
      "Epoch 2919, Loss: 0.00043446639392641373, Final Batch Loss: 5.493466233019717e-05\n",
      "Epoch 2920, Loss: 0.0004465182682906743, Final Batch Loss: 3.412318983464502e-05\n",
      "Epoch 2921, Loss: 0.0003224144675186835, Final Batch Loss: 7.814622222213075e-05\n",
      "Epoch 2922, Loss: 0.00011975079905823804, Final Batch Loss: 5.1804516260745004e-05\n",
      "Epoch 2923, Loss: 0.0002639588274178095, Final Batch Loss: 0.00023110948677640408\n",
      "Epoch 2924, Loss: 0.0004934444714308484, Final Batch Loss: 1.6950767530943267e-05\n",
      "Epoch 2925, Loss: 0.000510885423864238, Final Batch Loss: 8.031270408537239e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2926, Loss: 3.80472465622006e-05, Final Batch Loss: 1.994080412259791e-05\n",
      "Epoch 2927, Loss: 0.00029655428079422563, Final Batch Loss: 0.0002338987833354622\n",
      "Epoch 2928, Loss: 0.0010367156137363054, Final Batch Loss: 6.927279900992289e-05\n",
      "Epoch 2929, Loss: 0.0003882463861373253, Final Batch Loss: 0.00028663413831964135\n",
      "Epoch 2930, Loss: 0.0003892891836585477, Final Batch Loss: 0.00015428285405505449\n",
      "Epoch 2931, Loss: 0.0006311878587439423, Final Batch Loss: 0.0006107263616286218\n",
      "Epoch 2932, Loss: 0.00015879478360147914, Final Batch Loss: 1.2773240996466484e-05\n",
      "Epoch 2933, Loss: 0.0005519965634448454, Final Batch Loss: 0.00016182467516046017\n",
      "Epoch 2934, Loss: 0.00040098620593198575, Final Batch Loss: 0.0003662491508293897\n",
      "Epoch 2935, Loss: 0.002085253898258088, Final Batch Loss: 5.3531559387920424e-05\n",
      "Epoch 2936, Loss: 0.0009406800090800971, Final Batch Loss: 0.0008839059737510979\n",
      "Epoch 2937, Loss: 0.0004558526852633804, Final Batch Loss: 0.0002575601974967867\n",
      "Epoch 2938, Loss: 0.0003074337000725791, Final Batch Loss: 0.00018491328228265047\n",
      "Epoch 2939, Loss: 0.00017945895888260566, Final Batch Loss: 0.0001288915955228731\n",
      "Epoch 2940, Loss: 0.004083891195477918, Final Batch Loss: 3.292856854386628e-05\n",
      "Epoch 2941, Loss: 7.503934102714993e-05, Final Batch Loss: 3.0390001484192908e-05\n",
      "Epoch 2942, Loss: 0.0008786306862020865, Final Batch Loss: 0.00013385243073571473\n",
      "Epoch 2943, Loss: 5.635357229039073e-05, Final Batch Loss: 1.28870815387927e-05\n",
      "Epoch 2944, Loss: 0.009755328203027602, Final Batch Loss: 0.009721888229250908\n",
      "Epoch 2945, Loss: 0.0010146359127247706, Final Batch Loss: 0.0009144223877228796\n",
      "Epoch 2946, Loss: 8.637608698336408e-05, Final Batch Loss: 5.3717216360382736e-05\n",
      "Epoch 2947, Loss: 0.0026081164924107725, Final Batch Loss: 0.002597163198515773\n",
      "Epoch 2948, Loss: 0.0015280165935109835, Final Batch Loss: 3.92084002669435e-05\n",
      "Epoch 2949, Loss: 0.0002659006022440735, Final Batch Loss: 4.439487020135857e-05\n",
      "Epoch 2950, Loss: 0.0015771355683682486, Final Batch Loss: 0.0001188612513942644\n",
      "Epoch 2951, Loss: 0.00011989486483798828, Final Batch Loss: 8.983967563835904e-05\n",
      "Epoch 2952, Loss: 0.0005083037394797429, Final Batch Loss: 0.00016546306142117828\n",
      "Epoch 2953, Loss: 0.00016479011901537888, Final Batch Loss: 4.1219765989808366e-05\n",
      "Epoch 2954, Loss: 3.6318088859843556e-05, Final Batch Loss: 2.9567128876806237e-05\n",
      "Epoch 2955, Loss: 4.884267150373489e-05, Final Batch Loss: 4.5897497329860926e-05\n",
      "Epoch 2956, Loss: 0.0002853114515346533, Final Batch Loss: 4.697149506682763e-06\n",
      "Epoch 2957, Loss: 0.00038955196214374155, Final Batch Loss: 3.6081255530007184e-05\n",
      "Epoch 2958, Loss: 0.0002626711702760076, Final Batch Loss: 0.00023550169134978205\n",
      "Epoch 2959, Loss: 0.00022598327132072882, Final Batch Loss: 2.83816416413174e-06\n",
      "Epoch 2960, Loss: 0.025828846883086953, Final Batch Loss: 0.00011944879224756733\n",
      "Epoch 2961, Loss: 3.184703746228479e-05, Final Batch Loss: 1.6866006262716837e-05\n",
      "Epoch 2962, Loss: 0.00032452936466143, Final Batch Loss: 2.32899055845337e-05\n",
      "Epoch 2963, Loss: 0.00011136880857520737, Final Batch Loss: 2.3899239749880508e-05\n",
      "Epoch 2964, Loss: 5.7767098041949794e-05, Final Batch Loss: 1.526416963315569e-05\n",
      "Epoch 2965, Loss: 0.00011621948215179145, Final Batch Loss: 3.502325125737116e-05\n",
      "Epoch 2966, Loss: 0.0002681457990547642, Final Batch Loss: 0.00014461303362622857\n",
      "Epoch 2967, Loss: 9.177743777399883e-05, Final Batch Loss: 4.239243207848631e-05\n",
      "Epoch 2968, Loss: 0.00795359828043729, Final Batch Loss: 0.007139065768569708\n",
      "Epoch 2969, Loss: 0.00011274353164480999, Final Batch Loss: 4.436089511727914e-05\n",
      "Epoch 2970, Loss: 0.00335736564011313, Final Batch Loss: 0.0032746007200330496\n",
      "Epoch 2971, Loss: 0.0002861214816221036, Final Batch Loss: 3.550551627995446e-05\n",
      "Epoch 2972, Loss: 0.00045351131120696664, Final Batch Loss: 0.0002620237646624446\n",
      "Epoch 2973, Loss: 7.692565850447863e-05, Final Batch Loss: 4.5526045141741633e-05\n",
      "Epoch 2974, Loss: 0.004671639584557852, Final Batch Loss: 0.004613115917891264\n",
      "Epoch 2975, Loss: 7.109732723620255e-05, Final Batch Loss: 1.8801029000314884e-05\n",
      "Epoch 2976, Loss: 0.008642624190542847, Final Batch Loss: 0.0004351866082288325\n",
      "Epoch 2977, Loss: 0.0008070694730122341, Final Batch Loss: 0.0007899508345872164\n",
      "Epoch 2978, Loss: 0.004737058678074391, Final Batch Loss: 0.004717923700809479\n",
      "Epoch 2979, Loss: 0.00025187119217662257, Final Batch Loss: 7.4722997851495165e-06\n",
      "Epoch 2980, Loss: 0.004226219785778085, Final Batch Loss: 1.9471106497803703e-05\n",
      "Epoch 2981, Loss: 0.0002469942483003251, Final Batch Loss: 0.00012156715820310637\n",
      "Epoch 2982, Loss: 0.007499650135287084, Final Batch Loss: 0.007428217679262161\n",
      "Epoch 2983, Loss: 0.0005169888136151712, Final Batch Loss: 0.0004773862019646913\n",
      "Epoch 2984, Loss: 0.0007130645099096, Final Batch Loss: 0.0004427884705364704\n",
      "Epoch 2985, Loss: 0.0006351364372676471, Final Batch Loss: 1.6380561646656133e-05\n",
      "Epoch 2986, Loss: 5.2373372454894707e-05, Final Batch Loss: 2.2997584892436862e-05\n",
      "Epoch 2987, Loss: 0.0002533291626605205, Final Batch Loss: 9.14957417990081e-05\n",
      "Epoch 2988, Loss: 7.175970677053556e-05, Final Batch Loss: 2.3554028302896768e-05\n",
      "Epoch 2989, Loss: 0.00020621094154193997, Final Batch Loss: 0.0001552079920656979\n",
      "Epoch 2990, Loss: 0.0006373036885634065, Final Batch Loss: 0.000251561141340062\n",
      "Epoch 2991, Loss: 0.0003053764157812111, Final Batch Loss: 0.0002500657574273646\n",
      "Epoch 2992, Loss: 0.0002711417691898532, Final Batch Loss: 2.983447484439239e-05\n",
      "Epoch 2993, Loss: 0.00016782950478955172, Final Batch Loss: 5.463306661113165e-05\n",
      "Epoch 2994, Loss: 0.0002992292429553345, Final Batch Loss: 0.0002610104565974325\n",
      "Epoch 2995, Loss: 0.0011261696163273882, Final Batch Loss: 0.0010987719288095832\n",
      "Epoch 2996, Loss: 0.0004638292593881488, Final Batch Loss: 0.00024721684167161584\n",
      "Epoch 2997, Loss: 0.0001671870704740286, Final Batch Loss: 6.556353037012741e-05\n",
      "Epoch 2998, Loss: 0.00043848024506587535, Final Batch Loss: 0.0003005408216267824\n",
      "Epoch 2999, Loss: 0.0002020867759711109, Final Batch Loss: 5.5485616030637175e-05\n",
      "Epoch 3000, Loss: 0.0003890695224981755, Final Batch Loss: 9.127464727498591e-05\n",
      "Epoch 3001, Loss: 9.446222793485504e-05, Final Batch Loss: 7.039373303996399e-05\n",
      "Epoch 3002, Loss: 0.0003153064171783626, Final Batch Loss: 0.00011604736209847033\n",
      "Epoch 3003, Loss: 0.0009464680770179257, Final Batch Loss: 0.000868123141117394\n",
      "Epoch 3004, Loss: 0.00018797659140545875, Final Batch Loss: 2.5065033696591854e-05\n",
      "Epoch 3005, Loss: 0.00020504101848928258, Final Batch Loss: 0.00016290874918922782\n",
      "Epoch 3006, Loss: 7.09531559550669e-05, Final Batch Loss: 4.009658732684329e-05\n",
      "Epoch 3007, Loss: 6.760975884390064e-05, Final Batch Loss: 2.0460327505134046e-05\n",
      "Epoch 3008, Loss: 0.0003504250053083524, Final Batch Loss: 0.00016273444634862244\n",
      "Epoch 3009, Loss: 6.431040310417302e-05, Final Batch Loss: 5.625683115795255e-06\n",
      "Epoch 3010, Loss: 0.00030087402410572395, Final Batch Loss: 9.070062515093014e-05\n",
      "Epoch 3011, Loss: 0.00048609671648591757, Final Batch Loss: 0.0002780621580313891\n",
      "Epoch 3012, Loss: 0.0036929335328750312, Final Batch Loss: 0.00012648728443309665\n",
      "Epoch 3013, Loss: 0.00012369168325676583, Final Batch Loss: 5.020997559768148e-05\n",
      "Epoch 3014, Loss: 0.00016192567636608146, Final Batch Loss: 0.00014075729995965958\n",
      "Epoch 3015, Loss: 0.0003346717421663925, Final Batch Loss: 0.00017844025569502264\n",
      "Epoch 3016, Loss: 0.0008535377419320866, Final Batch Loss: 0.0007526320405304432\n",
      "Epoch 3017, Loss: 0.0017175127723021433, Final Batch Loss: 0.0015060700243338943\n",
      "Epoch 3018, Loss: 0.00019228683231631294, Final Batch Loss: 9.561627666698769e-05\n",
      "Epoch 3019, Loss: 0.0005799689970444888, Final Batch Loss: 0.00019331430667079985\n",
      "Epoch 3020, Loss: 0.00011466787691460922, Final Batch Loss: 8.36558174341917e-05\n",
      "Epoch 3021, Loss: 0.004512007944867946, Final Batch Loss: 0.00010856207518372685\n",
      "Epoch 3022, Loss: 9.43757731874939e-05, Final Batch Loss: 3.0406965379370376e-05\n",
      "Epoch 3023, Loss: 0.000952980244619539, Final Batch Loss: 1.468159825890325e-05\n",
      "Epoch 3024, Loss: 0.00036888651811750606, Final Batch Loss: 0.0002900075924117118\n",
      "Epoch 3025, Loss: 0.0009688707068562508, Final Batch Loss: 0.00043415441177785397\n",
      "Epoch 3026, Loss: 0.0008123992438413552, Final Batch Loss: 0.0008011137833818793\n",
      "Epoch 3027, Loss: 0.001072053040843457, Final Batch Loss: 0.0010079931234940886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3028, Loss: 7.361958705587313e-05, Final Batch Loss: 3.3229036489501595e-05\n",
      "Epoch 3029, Loss: 0.00034728962054941803, Final Batch Loss: 0.00013540906365960836\n",
      "Epoch 3030, Loss: 0.00015210454330372158, Final Batch Loss: 2.943621984741185e-05\n",
      "Epoch 3031, Loss: 0.0002532330217945855, Final Batch Loss: 5.331540523911826e-05\n",
      "Epoch 3032, Loss: 0.00017992750508710742, Final Batch Loss: 0.00011200427252333611\n",
      "Epoch 3033, Loss: 0.0005222324662099709, Final Batch Loss: 1.062321553035872e-05\n",
      "Epoch 3034, Loss: 0.0003485831548459828, Final Batch Loss: 0.00021515495609492064\n",
      "Epoch 3035, Loss: 0.0001377915687044151, Final Batch Loss: 8.840259397402406e-05\n",
      "Epoch 3036, Loss: 0.0009071671120182145, Final Batch Loss: 0.000872247270308435\n",
      "Epoch 3037, Loss: 0.00035045981348957866, Final Batch Loss: 0.00020921191025990993\n",
      "Epoch 3038, Loss: 0.0004780046656378545, Final Batch Loss: 6.773536006221548e-05\n",
      "Epoch 3039, Loss: 9.648240302340128e-05, Final Batch Loss: 8.903496200218797e-05\n",
      "Epoch 3040, Loss: 0.0002052095951512456, Final Batch Loss: 0.00013339715951588005\n",
      "Epoch 3041, Loss: 0.0005015075876144692, Final Batch Loss: 0.0001956516207428649\n",
      "Epoch 3042, Loss: 0.0005422161630121991, Final Batch Loss: 0.0004992875037714839\n",
      "Epoch 3043, Loss: 0.00019432752560533118, Final Batch Loss: 9.031542504089884e-06\n",
      "Epoch 3044, Loss: 6.793187276343815e-05, Final Batch Loss: 3.403365190024488e-05\n",
      "Epoch 3045, Loss: 0.005662704672431573, Final Batch Loss: 0.00033456445089541376\n",
      "Epoch 3046, Loss: 0.00019452781816653442, Final Batch Loss: 2.8950466003152542e-05\n",
      "Epoch 3047, Loss: 0.0001927323392010294, Final Batch Loss: 2.999163552885875e-05\n",
      "Epoch 3048, Loss: 0.0003842895414436498, Final Batch Loss: 1.6480655631312402e-06\n",
      "Epoch 3049, Loss: 0.0012843434233218431, Final Batch Loss: 0.0008546911994926631\n",
      "Epoch 3050, Loss: 0.0005429824623206514, Final Batch Loss: 1.0467406355019193e-05\n",
      "Epoch 3051, Loss: 0.0005914736611885019, Final Batch Loss: 0.00011403903044993058\n",
      "Epoch 3052, Loss: 0.00023553555365651846, Final Batch Loss: 0.00011625679326243699\n",
      "Epoch 3053, Loss: 0.008915989979868755, Final Batch Loss: 0.00036651952541433275\n",
      "Epoch 3054, Loss: 9.38094271987211e-05, Final Batch Loss: 4.4716962293023244e-05\n",
      "Epoch 3055, Loss: 0.0008127794526444632, Final Batch Loss: 9.237478479917627e-06\n",
      "Epoch 3056, Loss: 0.0003541743335517822, Final Batch Loss: 1.5832089047762565e-05\n",
      "Epoch 3057, Loss: 0.0004543398681562394, Final Batch Loss: 0.00024314351321663707\n",
      "Epoch 3058, Loss: 0.011270911229075864, Final Batch Loss: 0.01114716473966837\n",
      "Epoch 3059, Loss: 0.0002535275634727441, Final Batch Loss: 9.74209324340336e-05\n",
      "Epoch 3060, Loss: 0.034919854369945824, Final Batch Loss: 0.0006488749058917165\n",
      "Epoch 3061, Loss: 0.0014108245959505439, Final Batch Loss: 0.0007529971189796925\n",
      "Epoch 3062, Loss: 0.034091865964001045, Final Batch Loss: 0.0004243462753947824\n",
      "Epoch 3063, Loss: 0.00026833773540602124, Final Batch Loss: 0.0002649049274623394\n",
      "Epoch 3064, Loss: 0.00021187575839576311, Final Batch Loss: 0.00017078177188523114\n",
      "Epoch 3065, Loss: 0.058834889529862266, Final Batch Loss: 9.877233424049336e-06\n",
      "Epoch 3066, Loss: 0.001482202875195071, Final Batch Loss: 0.001195048214867711\n",
      "Epoch 3067, Loss: 0.0147353793727234, Final Batch Loss: 0.013199551030993462\n",
      "Epoch 3068, Loss: 0.0062395017594099045, Final Batch Loss: 0.0006829714402556419\n",
      "Epoch 3069, Loss: 0.000278547995549161, Final Batch Loss: 7.02648758306168e-05\n",
      "Epoch 3070, Loss: 0.0005565380124608055, Final Batch Loss: 0.0002432071341900155\n",
      "Epoch 3071, Loss: 0.0011172658887517173, Final Batch Loss: 5.1910978072555736e-05\n",
      "Epoch 3072, Loss: 0.0004264977906132117, Final Batch Loss: 0.00018738328071776778\n",
      "Epoch 3073, Loss: 0.0004383400810183957, Final Batch Loss: 0.00011546919995453209\n",
      "Epoch 3074, Loss: 0.00035801116609945893, Final Batch Loss: 0.00021432530775200576\n",
      "Epoch 3075, Loss: 0.0007115127809811383, Final Batch Loss: 0.00024684349773451686\n",
      "Epoch 3076, Loss: 0.0010658547980710864, Final Batch Loss: 0.0003364501753821969\n",
      "Epoch 3077, Loss: 0.001442170119844377, Final Batch Loss: 0.000856471830047667\n",
      "Epoch 3078, Loss: 0.0006369884504238144, Final Batch Loss: 0.0005621047457680106\n",
      "Epoch 3079, Loss: 0.00021111305250087753, Final Batch Loss: 0.00010435256263008341\n",
      "Epoch 3080, Loss: 0.0006336590304272249, Final Batch Loss: 0.00043113104766234756\n",
      "Epoch 3081, Loss: 0.00021977214419166557, Final Batch Loss: 0.00016746576875448227\n",
      "Epoch 3082, Loss: 0.002442504293867387, Final Batch Loss: 0.00012159232574049383\n",
      "Epoch 3083, Loss: 0.0012334100101725198, Final Batch Loss: 7.220722181955352e-05\n",
      "Epoch 3084, Loss: 0.0009757291409187019, Final Batch Loss: 0.0002017826191149652\n",
      "Epoch 3085, Loss: 0.00012300037633394822, Final Batch Loss: 5.5271098972298205e-05\n",
      "Epoch 3086, Loss: 0.00015828713367227465, Final Batch Loss: 5.084018630441278e-05\n",
      "Epoch 3087, Loss: 0.00015543220433755778, Final Batch Loss: 0.00013947630941402167\n",
      "Epoch 3088, Loss: 0.0004516219923971221, Final Batch Loss: 0.00011294624709989876\n",
      "Epoch 3089, Loss: 0.0005457648221636191, Final Batch Loss: 0.00016075240273494273\n",
      "Epoch 3090, Loss: 0.0006009371136315167, Final Batch Loss: 0.0004793051048181951\n",
      "Epoch 3091, Loss: 0.00016033853535191156, Final Batch Loss: 1.1464322597021237e-05\n",
      "Epoch 3092, Loss: 0.0002687039777811151, Final Batch Loss: 0.00024407688761129975\n",
      "Epoch 3093, Loss: 0.0005323736695572734, Final Batch Loss: 0.0003224409301765263\n",
      "Epoch 3094, Loss: 0.0006371046620188281, Final Batch Loss: 0.00022050550614949316\n",
      "Epoch 3095, Loss: 0.00018546672072261572, Final Batch Loss: 0.00010397554433438927\n",
      "Epoch 3096, Loss: 0.000557571358513087, Final Batch Loss: 0.00017288621165789664\n",
      "Epoch 3097, Loss: 0.0002159301202482311, Final Batch Loss: 3.0446562959696166e-05\n",
      "Epoch 3098, Loss: 0.0003533458220772445, Final Batch Loss: 0.00013502816727850586\n",
      "Epoch 3099, Loss: 0.000744407792808488, Final Batch Loss: 0.00020837978809140623\n",
      "Epoch 3100, Loss: 0.0020272075198590755, Final Batch Loss: 0.0005107504548504949\n",
      "Epoch 3101, Loss: 0.0016698622657713713, Final Batch Loss: 2.2495240045827813e-05\n",
      "Epoch 3102, Loss: 0.000586091133300215, Final Batch Loss: 0.00026548365713097155\n",
      "Epoch 3103, Loss: 0.00017073940580303315, Final Batch Loss: 1.5373510905192234e-05\n",
      "Epoch 3104, Loss: 0.0002523656658013351, Final Batch Loss: 0.00010274258238496259\n",
      "Epoch 3105, Loss: 0.0004550634548650123, Final Batch Loss: 7.693816587561741e-05\n",
      "Epoch 3106, Loss: 0.0006673578172922134, Final Batch Loss: 0.000629240064881742\n",
      "Epoch 3107, Loss: 0.00019686439554789104, Final Batch Loss: 0.00015781122783664614\n",
      "Epoch 3108, Loss: 0.001124748945585452, Final Batch Loss: 0.00017959803517442197\n",
      "Epoch 3109, Loss: 0.00022698687098454684, Final Batch Loss: 0.00013023069186601788\n",
      "Epoch 3110, Loss: 0.0007495955433114432, Final Batch Loss: 0.00011773601727327332\n",
      "Epoch 3111, Loss: 0.0007508375856559724, Final Batch Loss: 0.00031565851531922817\n",
      "Epoch 3112, Loss: 0.0010504391830181703, Final Batch Loss: 5.5844298913143575e-05\n",
      "Epoch 3113, Loss: 0.0004522617382463068, Final Batch Loss: 0.0003328931925352663\n",
      "Epoch 3114, Loss: 6.517482324852608e-05, Final Batch Loss: 3.039486546185799e-05\n",
      "Epoch 3115, Loss: 0.00013136860070517287, Final Batch Loss: 3.404868766665459e-05\n",
      "Epoch 3116, Loss: 0.0005628097715089098, Final Batch Loss: 0.00015790517500136048\n",
      "Epoch 3117, Loss: 0.00019690665794769302, Final Batch Loss: 0.00014547689352184534\n",
      "Epoch 3118, Loss: 0.0008266287622973323, Final Batch Loss: 0.0008067918242886662\n",
      "Epoch 3119, Loss: 0.00010407013905933127, Final Batch Loss: 4.251172504154965e-05\n",
      "Epoch 3120, Loss: 0.00037857885763514787, Final Batch Loss: 0.00023944108397699893\n",
      "Epoch 3121, Loss: 0.0001672454072831897, Final Batch Loss: 0.0001488206908106804\n",
      "Epoch 3122, Loss: 0.00023627182963537052, Final Batch Loss: 5.519334081327543e-05\n",
      "Epoch 3123, Loss: 0.00031200236844597384, Final Batch Loss: 0.0002623280161060393\n",
      "Epoch 3124, Loss: 0.00018229993293061852, Final Batch Loss: 0.00013719011622015387\n",
      "Epoch 3125, Loss: 0.00041698343557072803, Final Batch Loss: 0.0003695914929267019\n",
      "Epoch 3126, Loss: 0.0006867106712888926, Final Batch Loss: 0.0003867957566399127\n",
      "Epoch 3127, Loss: 0.00027766039784182794, Final Batch Loss: 0.00023284120834432542\n",
      "Epoch 3128, Loss: 8.170174260158092e-05, Final Batch Loss: 1.8218874174635857e-05\n",
      "Epoch 3129, Loss: 0.006026232342264848, Final Batch Loss: 2.8319849661784247e-05\n",
      "Epoch 3130, Loss: 0.000273011465651507, Final Batch Loss: 1.0778793694043998e-05\n",
      "Epoch 3131, Loss: 0.000171662300999742, Final Batch Loss: 3.2660325814504176e-05\n",
      "Epoch 3132, Loss: 5.8165358495898545e-05, Final Batch Loss: 4.229186743032187e-05\n",
      "Epoch 3133, Loss: 0.00015994221212167758, Final Batch Loss: 2.37665244640084e-05\n",
      "Epoch 3134, Loss: 0.000696483715728391, Final Batch Loss: 5.377468914957717e-05\n",
      "Epoch 3135, Loss: 0.0008844463227433152, Final Batch Loss: 0.0007982646930031478\n",
      "Epoch 3136, Loss: 0.004708555556135252, Final Batch Loss: 0.00015451948274858296\n",
      "Epoch 3137, Loss: 0.0007526855333708227, Final Batch Loss: 0.0006341194384731352\n",
      "Epoch 3138, Loss: 0.00042122557351831347, Final Batch Loss: 4.163548874203116e-05\n",
      "Epoch 3139, Loss: 0.0010513273373362608, Final Batch Loss: 0.0009321021498180926\n",
      "Epoch 3140, Loss: 0.0024415776006208034, Final Batch Loss: 2.9004864700254984e-05\n",
      "Epoch 3141, Loss: 0.00013578011021309067, Final Batch Loss: 1.2777994925272651e-05\n",
      "Epoch 3142, Loss: 3.360360824444797e-05, Final Batch Loss: 1.809863533708267e-05\n",
      "Epoch 3143, Loss: 0.00031998373742680997, Final Batch Loss: 0.00018095150880981237\n",
      "Epoch 3144, Loss: 6.700280391669367e-05, Final Batch Loss: 1.8379259927314706e-05\n",
      "Epoch 3145, Loss: 0.0007236191859192331, Final Batch Loss: 5.317674549587537e-06\n",
      "Epoch 3146, Loss: 0.000744162913179025, Final Batch Loss: 0.0005092043429613113\n",
      "Epoch 3147, Loss: 0.002537079282774357, Final Batch Loss: 5.868928201380186e-05\n",
      "Epoch 3148, Loss: 0.00032857604674063623, Final Batch Loss: 0.0002612340613268316\n",
      "Epoch 3149, Loss: 0.0003418655105633661, Final Batch Loss: 0.0001889582781586796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3150, Loss: 5.554909694183152e-05, Final Batch Loss: 1.7411000953870825e-05\n",
      "Epoch 3151, Loss: 3.4700979085755534e-05, Final Batch Loss: 8.882339898264036e-06\n",
      "Epoch 3152, Loss: 0.0006408124463632703, Final Batch Loss: 5.575391696766019e-05\n",
      "Epoch 3153, Loss: 0.0001559728571010055, Final Batch Loss: 0.00013561906234826893\n",
      "Epoch 3154, Loss: 0.00036092111258767545, Final Batch Loss: 4.107409040443599e-05\n",
      "Epoch 3155, Loss: 9.220429092238192e-05, Final Batch Loss: 8.283026545541361e-05\n",
      "Epoch 3156, Loss: 7.638024908374064e-05, Final Batch Loss: 2.3965538275660947e-05\n",
      "Epoch 3157, Loss: 0.001778979756636545, Final Batch Loss: 0.001712257624603808\n",
      "Epoch 3158, Loss: 0.00022168301802594215, Final Batch Loss: 5.1660797907970846e-05\n",
      "Epoch 3159, Loss: 0.000262748209934216, Final Batch Loss: 0.0001486287801526487\n",
      "Epoch 3160, Loss: 0.001018368755467236, Final Batch Loss: 0.0009239631472155452\n",
      "Epoch 3161, Loss: 0.00024243239386123605, Final Batch Loss: 0.00018767216533888131\n",
      "Epoch 3162, Loss: 0.00010009029028879013, Final Batch Loss: 9.32038456085138e-05\n",
      "Epoch 3163, Loss: 0.00022745724709238857, Final Batch Loss: 3.6585217458195984e-05\n",
      "Epoch 3164, Loss: 0.00010238851427857298, Final Batch Loss: 1.0334393664379604e-05\n",
      "Epoch 3165, Loss: 0.0004929502283630427, Final Batch Loss: 0.0004589481104630977\n",
      "Epoch 3166, Loss: 0.00015938409796945052, Final Batch Loss: 1.1057662959501613e-05\n",
      "Epoch 3167, Loss: 0.003685765472255298, Final Batch Loss: 8.13816768641118e-06\n",
      "Epoch 3168, Loss: 1.6296451576636173e-05, Final Batch Loss: 9.957760994439013e-06\n",
      "Epoch 3169, Loss: 0.00025055051082745194, Final Batch Loss: 0.0002253972488688305\n",
      "Epoch 3170, Loss: 0.00040697429813008057, Final Batch Loss: 6.0876891438965686e-06\n",
      "Epoch 3171, Loss: 0.0003818079858319834, Final Batch Loss: 0.0002902282867580652\n",
      "Epoch 3172, Loss: 0.0014796295727137476, Final Batch Loss: 0.0014652430545538664\n",
      "Epoch 3173, Loss: 0.00010821114301506896, Final Batch Loss: 8.509207691531628e-05\n",
      "Epoch 3174, Loss: 0.000327107758494094, Final Batch Loss: 0.0002505043230485171\n",
      "Epoch 3175, Loss: 0.0010222241980955005, Final Batch Loss: 0.0005812898161821067\n",
      "Epoch 3176, Loss: 0.0004324499604990706, Final Batch Loss: 9.256749763153493e-06\n",
      "Epoch 3177, Loss: 0.0005193034185140277, Final Batch Loss: 1.4029256817593705e-05\n",
      "Epoch 3178, Loss: 0.0001852683435572544, Final Batch Loss: 1.0999248843290843e-05\n",
      "Epoch 3179, Loss: 0.0002814550534822047, Final Batch Loss: 0.00025075083249248564\n",
      "Epoch 3180, Loss: 0.00021936302800895646, Final Batch Loss: 0.00014407113485503942\n",
      "Epoch 3181, Loss: 3.209873193554813e-05, Final Batch Loss: 1.0839187780220527e-05\n",
      "Epoch 3182, Loss: 0.0003053731661566417, Final Batch Loss: 1.0564926014922094e-05\n",
      "Epoch 3183, Loss: 0.0004336924721428659, Final Batch Loss: 3.287323852418922e-05\n",
      "Epoch 3184, Loss: 6.444912014558213e-05, Final Batch Loss: 1.2298180990910623e-05\n",
      "Epoch 3185, Loss: 0.00010414013740955852, Final Batch Loss: 5.50281947653275e-05\n",
      "Epoch 3186, Loss: 0.0001131866315517982, Final Batch Loss: 2.622365627757972e-06\n",
      "Epoch 3187, Loss: 9.851083450485021e-05, Final Batch Loss: 5.806923218187876e-05\n",
      "Epoch 3188, Loss: 2.7546854653337505e-05, Final Batch Loss: 1.7617921912460588e-05\n",
      "Epoch 3189, Loss: 0.00041876628529280424, Final Batch Loss: 0.00012578460155054927\n",
      "Epoch 3190, Loss: 9.167200005322229e-05, Final Batch Loss: 1.2911526937386952e-05\n",
      "Epoch 3191, Loss: 0.006006600731780054, Final Batch Loss: 0.005976145155727863\n",
      "Epoch 3192, Loss: 0.0002227656104878406, Final Batch Loss: 9.602680620446336e-06\n",
      "Epoch 3193, Loss: 8.818391324894037e-05, Final Batch Loss: 6.744189886376262e-05\n",
      "Epoch 3194, Loss: 0.00013909274275647476, Final Batch Loss: 6.249714351724833e-05\n",
      "Epoch 3195, Loss: 8.315214654430747e-05, Final Batch Loss: 5.949123078607954e-05\n",
      "Epoch 3196, Loss: 0.0007766981198074063, Final Batch Loss: 0.0007519777282141149\n",
      "Epoch 3197, Loss: 0.0004593296835082583, Final Batch Loss: 3.107851807726547e-05\n",
      "Epoch 3198, Loss: 0.0006213161686901003, Final Batch Loss: 0.0004342433821875602\n",
      "Epoch 3199, Loss: 4.687151522375643e-05, Final Batch Loss: 8.966759196482599e-06\n",
      "Epoch 3200, Loss: 0.00011659595111268573, Final Batch Loss: 5.9788613725686446e-05\n",
      "Epoch 3201, Loss: 5.4473835916724056e-05, Final Batch Loss: 1.9332917872816324e-05\n",
      "Epoch 3202, Loss: 0.0001578984156367369, Final Batch Loss: 2.1358653611969203e-05\n",
      "Epoch 3203, Loss: 0.00010353836842114106, Final Batch Loss: 7.883628131821752e-05\n",
      "Epoch 3204, Loss: 0.00040879612697608536, Final Batch Loss: 7.708905286563095e-06\n",
      "Epoch 3205, Loss: 0.0001230219022545498, Final Batch Loss: 2.7187586965737864e-05\n",
      "Epoch 3206, Loss: 0.0001515951516921632, Final Batch Loss: 1.1281423212494701e-05\n",
      "Epoch 3207, Loss: 0.0005799996870337054, Final Batch Loss: 0.0003565467777661979\n",
      "Epoch 3208, Loss: 0.0012909438300994225, Final Batch Loss: 0.0012595582520589232\n",
      "Epoch 3209, Loss: 0.00028451825346564874, Final Batch Loss: 7.354745321208611e-05\n",
      "Epoch 3210, Loss: 0.0005040542000642745, Final Batch Loss: 1.8840668417396955e-05\n",
      "Epoch 3211, Loss: 0.0001556146853545215, Final Batch Loss: 9.676847548689693e-05\n",
      "Epoch 3212, Loss: 0.0002807874698191881, Final Batch Loss: 0.00018117927538696676\n",
      "Epoch 3213, Loss: 0.00017209144425578415, Final Batch Loss: 0.00015672548033762723\n",
      "Epoch 3214, Loss: 5.237937739366316e-05, Final Batch Loss: 7.625111265952e-06\n",
      "Epoch 3215, Loss: 0.002340939730856917, Final Batch Loss: 0.0023277581203728914\n",
      "Epoch 3216, Loss: 0.00021491482766577974, Final Batch Loss: 7.953785097924992e-05\n",
      "Epoch 3217, Loss: 0.00031365466566057876, Final Batch Loss: 7.434898725477979e-05\n",
      "Epoch 3218, Loss: 0.0008211259082600009, Final Batch Loss: 2.621880776132457e-05\n",
      "Epoch 3219, Loss: 0.00019144795805914328, Final Batch Loss: 6.954785931156948e-05\n",
      "Epoch 3220, Loss: 0.0001438078106730245, Final Batch Loss: 9.448590571992099e-05\n",
      "Epoch 3221, Loss: 0.00025532278641549055, Final Batch Loss: 3.3672008612484206e-06\n",
      "Epoch 3222, Loss: 0.0001612760461284779, Final Batch Loss: 7.07669896655716e-05\n",
      "Epoch 3223, Loss: 0.005729085691200453, Final Batch Loss: 2.0203571693855338e-05\n",
      "Epoch 3224, Loss: 2.2284538999883807e-05, Final Batch Loss: 2.517788516342989e-06\n",
      "Epoch 3225, Loss: 6.571123412868474e-05, Final Batch Loss: 2.289698204549495e-05\n",
      "Epoch 3226, Loss: 0.00022710896155331284, Final Batch Loss: 0.0001551851601107046\n",
      "Epoch 3227, Loss: 0.00438528272388794, Final Batch Loss: 1.1031954272766598e-05\n",
      "Epoch 3228, Loss: 0.00015258685562002938, Final Batch Loss: 1.8523844119044952e-05\n",
      "Epoch 3229, Loss: 0.00013154219959687907, Final Batch Loss: 0.00010916785686276853\n",
      "Epoch 3230, Loss: 0.0001022457563522039, Final Batch Loss: 7.210580952232704e-05\n",
      "Epoch 3231, Loss: 0.00045836708159185946, Final Batch Loss: 9.829760529100895e-06\n",
      "Epoch 3232, Loss: 0.00019622889521997422, Final Batch Loss: 7.346789061557502e-05\n",
      "Epoch 3233, Loss: 0.0002801169430313166, Final Batch Loss: 0.00021911463409196585\n",
      "Epoch 3234, Loss: 0.008310282053571427, Final Batch Loss: 8.043283742154017e-06\n",
      "Epoch 3235, Loss: 0.00015417379017890198, Final Batch Loss: 0.00014085300790611655\n",
      "Epoch 3236, Loss: 0.000647916313027963, Final Batch Loss: 0.0004342531901784241\n",
      "Epoch 3237, Loss: 3.8570361539314035e-05, Final Batch Loss: 1.0814496818056796e-05\n",
      "Epoch 3238, Loss: 0.00010406257024442311, Final Batch Loss: 7.910971180535853e-05\n",
      "Epoch 3239, Loss: 0.00817589569487609, Final Batch Loss: 0.00773430522531271\n",
      "Epoch 3240, Loss: 0.03192813420901075, Final Batch Loss: 0.00017460534581914544\n",
      "Epoch 3241, Loss: 0.00012386528396746144, Final Batch Loss: 8.531951607437804e-05\n",
      "Epoch 3242, Loss: 0.000639383441011887, Final Batch Loss: 0.0006122381892055273\n",
      "Epoch 3243, Loss: 0.0026291869708074955, Final Batch Loss: 8.17725776869338e-06\n",
      "Epoch 3244, Loss: 0.019007130918907933, Final Batch Loss: 0.018920784816145897\n",
      "Epoch 3245, Loss: 0.0003731726774276467, Final Batch Loss: 2.687327105377335e-05\n",
      "Epoch 3246, Loss: 0.0005569740023929626, Final Batch Loss: 0.0002760940697044134\n",
      "Epoch 3247, Loss: 0.009364468045532703, Final Batch Loss: 0.00667093088850379\n",
      "Epoch 3248, Loss: 0.02961494604824111, Final Batch Loss: 0.029064586386084557\n",
      "Epoch 3249, Loss: 0.00019615933342720382, Final Batch Loss: 4.600589090841822e-05\n",
      "Epoch 3250, Loss: 0.00012516419155872427, Final Batch Loss: 5.460640022647567e-05\n",
      "Epoch 3251, Loss: 0.00011748287215596065, Final Batch Loss: 7.493534940294921e-05\n",
      "Epoch 3252, Loss: 0.0002173061584471725, Final Batch Loss: 2.6470348529983312e-05\n",
      "Epoch 3253, Loss: 0.004331037343945354, Final Batch Loss: 0.00336945871822536\n",
      "Epoch 3254, Loss: 0.0008700604812474921, Final Batch Loss: 0.0007334358524531126\n",
      "Epoch 3255, Loss: 0.016967556279269047, Final Batch Loss: 7.364976045209914e-05\n",
      "Epoch 3256, Loss: 0.00010843394193216227, Final Batch Loss: 6.669932918157429e-05\n",
      "Epoch 3257, Loss: 0.00020462100656004623, Final Batch Loss: 3.510679380269721e-05\n",
      "Epoch 3258, Loss: 0.0013009830836381298, Final Batch Loss: 5.917129965382628e-05\n",
      "Epoch 3259, Loss: 0.0006818984256824479, Final Batch Loss: 0.0006110729882493615\n",
      "Epoch 3260, Loss: 6.26096771156881e-05, Final Batch Loss: 2.2366974008036777e-05\n",
      "Epoch 3261, Loss: 0.0022163475077832118, Final Batch Loss: 0.00015883521700743586\n",
      "Epoch 3262, Loss: 0.0001366643118672073, Final Batch Loss: 9.842970757745206e-05\n",
      "Epoch 3263, Loss: 0.00015679018179071136, Final Batch Loss: 0.0001289062201976776\n",
      "Epoch 3264, Loss: 0.00011142500352434581, Final Batch Loss: 7.22003369446611e-06\n",
      "Epoch 3265, Loss: 0.00027572873477765825, Final Batch Loss: 2.199714617745485e-05\n",
      "Epoch 3266, Loss: 0.0011604605133470614, Final Batch Loss: 0.0011499193497002125\n",
      "Epoch 3267, Loss: 0.0022589550753764343, Final Batch Loss: 0.0022296977695077658\n",
      "Epoch 3268, Loss: 0.0008209705556510016, Final Batch Loss: 0.0006695467745885253\n",
      "Epoch 3269, Loss: 0.0003791148992604576, Final Batch Loss: 0.0003088364319410175\n",
      "Epoch 3270, Loss: 0.00033864847500808537, Final Batch Loss: 9.130951366387308e-05\n",
      "Epoch 3271, Loss: 0.0002681330661289394, Final Batch Loss: 0.000177714042365551\n",
      "Epoch 3272, Loss: 0.00022996025654720142, Final Batch Loss: 0.00010806576028699055\n",
      "Epoch 3273, Loss: 0.0002805405529215932, Final Batch Loss: 0.0002441820688545704\n",
      "Epoch 3274, Loss: 0.002382258273428306, Final Batch Loss: 0.0002784566895570606\n",
      "Epoch 3275, Loss: 0.0023932322146720253, Final Batch Loss: 0.002283004578202963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3276, Loss: 0.00215052452404052, Final Batch Loss: 0.0002545849420130253\n",
      "Epoch 3277, Loss: 0.002077903021017846, Final Batch Loss: 0.002066267654299736\n",
      "Epoch 3278, Loss: 0.0005761346401413903, Final Batch Loss: 0.000191202198038809\n",
      "Epoch 3279, Loss: 0.00027756889176089317, Final Batch Loss: 0.00020106974989175797\n",
      "Epoch 3280, Loss: 0.001337765366770327, Final Batch Loss: 0.00038789957761764526\n",
      "Epoch 3281, Loss: 0.0006770935142412782, Final Batch Loss: 0.0005822198581881821\n",
      "Epoch 3282, Loss: 0.00027737024356611073, Final Batch Loss: 0.00021523745090235025\n",
      "Epoch 3283, Loss: 0.0002947563916677609, Final Batch Loss: 0.0001245447783730924\n",
      "Epoch 3284, Loss: 0.0002752612690528622, Final Batch Loss: 8.61596163304057e-06\n",
      "Epoch 3285, Loss: 0.00014067616939428262, Final Batch Loss: 4.6492215915350243e-05\n",
      "Epoch 3286, Loss: 0.0006724070262862369, Final Batch Loss: 0.0006061114836484194\n",
      "Epoch 3287, Loss: 0.007481721353542525, Final Batch Loss: 0.0074585359543561935\n",
      "Epoch 3288, Loss: 0.00048355216858908534, Final Batch Loss: 0.00017003004904836416\n",
      "Epoch 3289, Loss: 0.0001818155615183059, Final Batch Loss: 5.0433303840691224e-05\n",
      "Epoch 3290, Loss: 0.000120225447062694, Final Batch Loss: 1.3942791156296153e-05\n",
      "Epoch 3291, Loss: 0.0006209362327354029, Final Batch Loss: 0.00012924698239658028\n",
      "Epoch 3292, Loss: 0.0012952895485796034, Final Batch Loss: 0.0003044030745513737\n",
      "Epoch 3293, Loss: 0.0002144410136679653, Final Batch Loss: 0.0001764500339049846\n",
      "Epoch 3294, Loss: 0.003303784760646522, Final Batch Loss: 0.0005364423850551248\n",
      "Epoch 3295, Loss: 0.0004599148487614002, Final Batch Loss: 1.9678813259815797e-05\n",
      "Epoch 3296, Loss: 0.005557809956371784, Final Batch Loss: 0.000666061881929636\n",
      "Epoch 3297, Loss: 0.00012122554835514165, Final Batch Loss: 5.7952591305365786e-05\n",
      "Epoch 3298, Loss: 0.00014031156752025709, Final Batch Loss: 7.692735380260274e-05\n",
      "Epoch 3299, Loss: 0.023444859201845247, Final Batch Loss: 0.02337229996919632\n",
      "Epoch 3300, Loss: 0.0010404063505120575, Final Batch Loss: 0.00041159900138154626\n",
      "Epoch 3301, Loss: 0.0005189177609281614, Final Batch Loss: 2.111181674990803e-05\n",
      "Epoch 3302, Loss: 0.0009517854196019471, Final Batch Loss: 0.0003838330158032477\n",
      "Epoch 3303, Loss: 0.00012985284774913453, Final Batch Loss: 2.2012525732861832e-05\n",
      "Epoch 3304, Loss: 0.0007734588161838474, Final Batch Loss: 0.00075630220817402\n",
      "Epoch 3305, Loss: 0.00027785691781900823, Final Batch Loss: 0.00018518691649660468\n",
      "Epoch 3306, Loss: 0.00527047549985582, Final Batch Loss: 0.00011176706902915612\n",
      "Epoch 3307, Loss: 0.0001676321990089491, Final Batch Loss: 0.00010445697262184694\n",
      "Epoch 3308, Loss: 0.000744050441426225, Final Batch Loss: 0.0005758135812357068\n",
      "Epoch 3309, Loss: 0.001176290912553668, Final Batch Loss: 0.0008940721163526177\n",
      "Epoch 3310, Loss: 0.00015691791486460716, Final Batch Loss: 9.248784044757485e-05\n",
      "Epoch 3311, Loss: 0.0009026170359902608, Final Batch Loss: 0.0008964723092503846\n",
      "Epoch 3312, Loss: 0.007923339950139052, Final Batch Loss: 1.8719108993536793e-05\n",
      "Epoch 3313, Loss: 0.001086485048290342, Final Batch Loss: 0.00018906127661466599\n",
      "Epoch 3314, Loss: 0.0024566306583437836, Final Batch Loss: 1.6837691873661242e-05\n",
      "Epoch 3315, Loss: 0.00021769643808511319, Final Batch Loss: 0.00020430932636372745\n",
      "Epoch 3316, Loss: 0.0010467220781720243, Final Batch Loss: 0.0009786983719095588\n",
      "Epoch 3317, Loss: 0.0001259874588868115, Final Batch Loss: 7.899204501882195e-05\n",
      "Epoch 3318, Loss: 3.684535386128118e-05, Final Batch Loss: 7.718107553955633e-06\n",
      "Epoch 3319, Loss: 0.0013910777779528871, Final Batch Loss: 3.7608915590681136e-05\n",
      "Epoch 3320, Loss: 0.0010863751531360322, Final Batch Loss: 8.199423064070288e-06\n",
      "Epoch 3321, Loss: 0.0001896800531540066, Final Batch Loss: 1.7192796804010868e-05\n",
      "Epoch 3322, Loss: 0.0005314333393471316, Final Batch Loss: 9.11526003619656e-05\n",
      "Epoch 3323, Loss: 0.00020098710228921846, Final Batch Loss: 6.458657298935577e-05\n",
      "Epoch 3324, Loss: 0.0003173871082253754, Final Batch Loss: 0.0002799913636408746\n",
      "Epoch 3325, Loss: 0.00023582598805660382, Final Batch Loss: 8.383453678106889e-05\n",
      "Epoch 3326, Loss: 0.00011923916099476628, Final Batch Loss: 0.00010281448339810595\n",
      "Epoch 3327, Loss: 0.00024527732784918044, Final Batch Loss: 0.00023044714180286974\n",
      "Epoch 3328, Loss: 0.00016677174426149577, Final Batch Loss: 9.148818935500458e-05\n",
      "Epoch 3329, Loss: 0.0008529632395948283, Final Batch Loss: 0.0007650132174603641\n",
      "Epoch 3330, Loss: 0.0004406027655932121, Final Batch Loss: 0.00038189225597307086\n",
      "Epoch 3331, Loss: 0.0010185247883782722, Final Batch Loss: 0.0009315084316767752\n",
      "Epoch 3332, Loss: 0.00016004448843887076, Final Batch Loss: 2.3682958271820098e-05\n",
      "Epoch 3333, Loss: 0.001015406737678859, Final Batch Loss: 5.425589733931702e-06\n",
      "Epoch 3334, Loss: 0.0006635511417698581, Final Batch Loss: 0.000617107842117548\n",
      "Epoch 3335, Loss: 0.004469680001420784, Final Batch Loss: 0.004444194957613945\n",
      "Epoch 3336, Loss: 8.528450052835979e-05, Final Batch Loss: 3.390342681086622e-05\n",
      "Epoch 3337, Loss: 0.00040555495070293546, Final Batch Loss: 9.52228729147464e-05\n",
      "Epoch 3338, Loss: 0.00014152870789985172, Final Batch Loss: 4.9008962378138676e-05\n",
      "Epoch 3339, Loss: 0.0016928777331486344, Final Batch Loss: 0.0003574335714802146\n",
      "Epoch 3340, Loss: 0.001803119735996006, Final Batch Loss: 0.0017552899662405252\n",
      "Epoch 3341, Loss: 0.0014624013201682828, Final Batch Loss: 5.735150625696406e-05\n",
      "Epoch 3342, Loss: 0.00023135322771850042, Final Batch Loss: 0.00021441293938551098\n",
      "Epoch 3343, Loss: 0.0002939941987278871, Final Batch Loss: 4.068601265316829e-05\n",
      "Epoch 3344, Loss: 0.002640091988723725, Final Batch Loss: 0.0007766340277157724\n",
      "Epoch 3345, Loss: 0.002251663225251832, Final Batch Loss: 1.5881823856034316e-05\n",
      "Epoch 3346, Loss: 5.6197180128947366e-05, Final Batch Loss: 4.568662006931845e-06\n",
      "Epoch 3347, Loss: 3.553300064140785e-05, Final Batch Loss: 5.720752369597903e-07\n",
      "Epoch 3348, Loss: 0.0002543484006309882, Final Batch Loss: 7.633939094375819e-05\n",
      "Epoch 3349, Loss: 0.0017322734784102067, Final Batch Loss: 0.00014384287351276726\n",
      "Epoch 3350, Loss: 0.0005943723808741197, Final Batch Loss: 0.00016322666488122195\n",
      "Epoch 3351, Loss: 0.00024798423692118376, Final Batch Loss: 5.657899600919336e-05\n",
      "Epoch 3352, Loss: 0.0002524609635656816, Final Batch Loss: 4.168182385910768e-06\n",
      "Epoch 3353, Loss: 0.00021927258057985455, Final Batch Loss: 0.00010335294791730121\n",
      "Epoch 3354, Loss: 0.013121918425895274, Final Batch Loss: 0.0011633780086413026\n",
      "Epoch 3355, Loss: 7.823004352758289e-05, Final Batch Loss: 4.558986347547034e-06\n",
      "Epoch 3356, Loss: 0.0001686566947682877, Final Batch Loss: 0.0001543168764328584\n",
      "Epoch 3357, Loss: 7.451169221894816e-05, Final Batch Loss: 5.113900624564849e-05\n",
      "Epoch 3358, Loss: 2.8190317607368343e-05, Final Batch Loss: 1.4292829291662201e-05\n",
      "Epoch 3359, Loss: 0.0010993609757861122, Final Batch Loss: 0.00012966680515091866\n",
      "Epoch 3360, Loss: 0.0002670492394827306, Final Batch Loss: 0.00010643579298630357\n",
      "Epoch 3361, Loss: 0.00022865855862619355, Final Batch Loss: 0.00019456783775240183\n",
      "Epoch 3362, Loss: 0.0033345718402415514, Final Batch Loss: 0.0025432114489376545\n",
      "Epoch 3363, Loss: 0.00911311364689027, Final Batch Loss: 3.588504114304669e-05\n",
      "Epoch 3364, Loss: 0.0006173104047775269, Final Batch Loss: 0.0001233708462677896\n",
      "Epoch 3365, Loss: 5.928186328674201e-05, Final Batch Loss: 1.2018203051411547e-05\n",
      "Epoch 3366, Loss: 7.713807644904591e-05, Final Batch Loss: 7.275769166881219e-05\n",
      "Epoch 3367, Loss: 0.00010014966119342716, Final Batch Loss: 1.2963207154825795e-05\n",
      "Epoch 3368, Loss: 0.0003850374940839174, Final Batch Loss: 0.00038326275534927845\n",
      "Epoch 3369, Loss: 0.0005470296746352687, Final Batch Loss: 3.126311639789492e-05\n",
      "Epoch 3370, Loss: 4.048140772283659e-05, Final Batch Loss: 5.403597697295481e-06\n",
      "Epoch 3371, Loss: 3.252471583437e-05, Final Batch Loss: 1.8618841295392485e-06\n",
      "Epoch 3372, Loss: 2.0368065634102095e-05, Final Batch Loss: 9.81003358901944e-06\n",
      "Epoch 3373, Loss: 0.0002849924348993227, Final Batch Loss: 0.00020890242012683302\n",
      "Epoch 3374, Loss: 0.00020759230756084435, Final Batch Loss: 4.7969104343792424e-05\n",
      "Epoch 3375, Loss: 0.004346015426563099, Final Batch Loss: 0.004068396519869566\n",
      "Epoch 3376, Loss: 0.0004828906949114753, Final Batch Loss: 1.9240133042330854e-05\n",
      "Epoch 3377, Loss: 0.0002466908990754746, Final Batch Loss: 0.00011449543671915308\n",
      "Epoch 3378, Loss: 0.0005725560331484303, Final Batch Loss: 0.0002006155700655654\n",
      "Epoch 3379, Loss: 0.0029100825731802615, Final Batch Loss: 1.4559943338099401e-05\n",
      "Epoch 3380, Loss: 0.0007171795004978776, Final Batch Loss: 0.00015302299289032817\n",
      "Epoch 3381, Loss: 0.006039585336111486, Final Batch Loss: 0.005826391279697418\n",
      "Epoch 3382, Loss: 0.0018384541835985146, Final Batch Loss: 6.010047945892438e-05\n",
      "Epoch 3383, Loss: 0.00016542282901355065, Final Batch Loss: 2.8407423087628558e-05\n",
      "Epoch 3384, Loss: 0.002898662962252274, Final Batch Loss: 0.00037163906381465495\n",
      "Epoch 3385, Loss: 0.0005335233036021236, Final Batch Loss: 0.0005224053165875375\n",
      "Epoch 3386, Loss: 0.0001511167865828611, Final Batch Loss: 8.339325722772628e-05\n",
      "Epoch 3387, Loss: 0.00026450062250660267, Final Batch Loss: 1.6880721886991523e-05\n",
      "Epoch 3388, Loss: 0.0006783241842640564, Final Batch Loss: 7.229750917758793e-05\n",
      "Epoch 3389, Loss: 4.019273455924122e-05, Final Batch Loss: 3.0694511224282905e-05\n",
      "Epoch 3390, Loss: 2.0371932805574033e-05, Final Batch Loss: 5.960064299870282e-06\n",
      "Epoch 3391, Loss: 0.0003388988843653351, Final Batch Loss: 0.0001073068124242127\n",
      "Epoch 3392, Loss: 5.952043647994287e-05, Final Batch Loss: 3.979933535447344e-05\n",
      "Epoch 3393, Loss: 8.239571980084293e-05, Final Batch Loss: 3.149614349240437e-05\n",
      "Epoch 3394, Loss: 0.0002156098071282031, Final Batch Loss: 2.2388836441677995e-05\n",
      "Epoch 3395, Loss: 0.00030251569114625454, Final Batch Loss: 9.514224075246602e-05\n",
      "Epoch 3396, Loss: 5.920996773056686e-05, Final Batch Loss: 2.8015529096592218e-06\n",
      "Epoch 3397, Loss: 0.00413888823823072, Final Batch Loss: 0.0004370376991573721\n",
      "Epoch 3398, Loss: 2.837062220351072e-05, Final Batch Loss: 8.835199878376443e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3399, Loss: 9.369045983476099e-05, Final Batch Loss: 1.922859337355476e-05\n",
      "Epoch 3400, Loss: 0.00012793595305993222, Final Batch Loss: 5.831873932038434e-05\n",
      "Epoch 3401, Loss: 0.0008403084466408473, Final Batch Loss: 0.0008334916201420128\n",
      "Epoch 3402, Loss: 0.0037831299341632985, Final Batch Loss: 0.00011078485840698704\n",
      "Epoch 3403, Loss: 0.00029161870770622045, Final Batch Loss: 0.00021899545390624553\n",
      "Epoch 3404, Loss: 0.00023189390049083158, Final Batch Loss: 6.780928379157558e-05\n",
      "Epoch 3405, Loss: 0.0004197754151391564, Final Batch Loss: 1.5699608411523513e-05\n",
      "Epoch 3406, Loss: 0.0001040987808664795, Final Batch Loss: 4.7748908400535583e-05\n",
      "Epoch 3407, Loss: 0.029679322920856066, Final Batch Loss: 0.00010972686868626624\n",
      "Epoch 3408, Loss: 2.3393738047161605e-05, Final Batch Loss: 5.7485713114147075e-06\n",
      "Epoch 3409, Loss: 0.00017998932526097633, Final Batch Loss: 0.00016225528088398278\n",
      "Epoch 3410, Loss: 7.570240450149868e-05, Final Batch Loss: 6.031023804098368e-05\n",
      "Epoch 3411, Loss: 0.00011994734086329117, Final Batch Loss: 0.00011078387615270913\n",
      "Epoch 3412, Loss: 0.0001869701791292755, Final Batch Loss: 1.3247465176391415e-05\n",
      "Epoch 3413, Loss: 0.00030601967227994464, Final Batch Loss: 3.0333405447890982e-05\n",
      "Epoch 3414, Loss: 0.0011251180403633043, Final Batch Loss: 0.0009982273913919926\n",
      "Epoch 3415, Loss: 0.00010766429113573395, Final Batch Loss: 6.361174746416509e-05\n",
      "Epoch 3416, Loss: 1.4418419596040621e-05, Final Batch Loss: 4.6775048758718185e-06\n",
      "Epoch 3417, Loss: 8.038018836487026e-05, Final Batch Loss: 2.4191756438085577e-06\n",
      "Epoch 3418, Loss: 0.0001197693982248893, Final Batch Loss: 1.4531395208905451e-05\n",
      "Epoch 3419, Loss: 2.084990956063848e-05, Final Batch Loss: 1.0523749551794026e-05\n",
      "Epoch 3420, Loss: 0.0002228494322480401, Final Batch Loss: 0.00020166748436167836\n",
      "Epoch 3421, Loss: 2.7113455871585757e-05, Final Batch Loss: 5.556710675591603e-06\n",
      "Epoch 3422, Loss: 0.00046080736501608044, Final Batch Loss: 0.00014506890147458762\n",
      "Epoch 3423, Loss: 0.00048169848378165625, Final Batch Loss: 0.000433197186794132\n",
      "Epoch 3424, Loss: 0.00030200779292499647, Final Batch Loss: 8.187129424186423e-05\n",
      "Epoch 3425, Loss: 0.00032401301723439246, Final Batch Loss: 0.00025303298025391996\n",
      "Epoch 3426, Loss: 0.0003126177289232146, Final Batch Loss: 5.299671829561703e-05\n",
      "Epoch 3427, Loss: 0.0007886247040005401, Final Batch Loss: 6.532717088703066e-05\n",
      "Epoch 3428, Loss: 0.00017560715423314832, Final Batch Loss: 0.0001213385330629535\n",
      "Epoch 3429, Loss: 0.0015391634642583085, Final Batch Loss: 0.0015207792166620493\n",
      "Epoch 3430, Loss: 3.9665245822106954e-05, Final Batch Loss: 1.4956457562220749e-05\n",
      "Epoch 3431, Loss: 0.000321964813338127, Final Batch Loss: 1.7835722246672958e-05\n",
      "Epoch 3432, Loss: 0.000373536461211188, Final Batch Loss: 0.00036930045462213457\n",
      "Epoch 3433, Loss: 1.7843759906099876e-05, Final Batch Loss: 5.68453606319963e-06\n",
      "Epoch 3434, Loss: 0.0009052089299075305, Final Batch Loss: 0.00040532939601689577\n",
      "Epoch 3435, Loss: 0.00012309164412727114, Final Batch Loss: 0.00011506460577948019\n",
      "Epoch 3436, Loss: 0.0033015816588886082, Final Batch Loss: 1.453055301681161e-05\n",
      "Epoch 3437, Loss: 7.069151979521848e-05, Final Batch Loss: 4.2695715819718316e-05\n",
      "Epoch 3438, Loss: 0.00020594726265699137, Final Batch Loss: 0.00018398069369141012\n",
      "Epoch 3439, Loss: 0.0003728443080035504, Final Batch Loss: 3.441230728640221e-05\n",
      "Epoch 3440, Loss: 2.126330355167738e-05, Final Batch Loss: 4.697494205174735e-06\n",
      "Epoch 3441, Loss: 0.0002987671673508885, Final Batch Loss: 4.038875431433553e-06\n",
      "Epoch 3442, Loss: 0.00013811970075039426, Final Batch Loss: 0.00012682484521064907\n",
      "Epoch 3443, Loss: 0.0006446398183470592, Final Batch Loss: 0.00016988824063446373\n",
      "Epoch 3444, Loss: 0.00011569029538804898, Final Batch Loss: 0.00010085542453452945\n",
      "Epoch 3445, Loss: 0.00013710177336179186, Final Batch Loss: 0.00011597426782827824\n",
      "Epoch 3446, Loss: 0.0003947711520595476, Final Batch Loss: 0.0003425109898671508\n",
      "Epoch 3447, Loss: 2.974271137645701e-05, Final Batch Loss: 1.775631244527176e-05\n",
      "Epoch 3448, Loss: 0.0003100327812717296, Final Batch Loss: 0.00027663318905979395\n",
      "Epoch 3449, Loss: 0.0002632230452945805, Final Batch Loss: 1.4646763702330645e-05\n",
      "Epoch 3450, Loss: 0.0001699449640000239, Final Batch Loss: 9.560418402543291e-05\n",
      "Epoch 3451, Loss: 0.00016916071763262153, Final Batch Loss: 5.818163481308147e-05\n",
      "Epoch 3452, Loss: 4.7190771510940976e-05, Final Batch Loss: 2.681313708308153e-05\n",
      "Epoch 3453, Loss: 0.006103406562033342, Final Batch Loss: 1.2501044693635777e-05\n",
      "Epoch 3454, Loss: 7.7087948739063e-05, Final Batch Loss: 1.9447226804913953e-05\n",
      "Epoch 3455, Loss: 0.0003366466480656527, Final Batch Loss: 9.931218664860353e-05\n",
      "Epoch 3456, Loss: 0.00032440499489894137, Final Batch Loss: 0.00021563202608376741\n",
      "Epoch 3457, Loss: 0.0003970561228925362, Final Batch Loss: 0.00025817553978413343\n",
      "Epoch 3458, Loss: 0.00012332110418356024, Final Batch Loss: 6.727017898811027e-05\n",
      "Epoch 3459, Loss: 3.111224168605986e-05, Final Batch Loss: 2.778080124699045e-05\n",
      "Epoch 3460, Loss: 0.0009038438074639998, Final Batch Loss: 0.00011304273357382044\n",
      "Epoch 3461, Loss: 6.105068860051688e-05, Final Batch Loss: 4.2119463614653796e-05\n",
      "Epoch 3462, Loss: 0.0003410970643926703, Final Batch Loss: 3.816294793068664e-06\n",
      "Epoch 3463, Loss: 0.00026235574478050694, Final Batch Loss: 8.636406710138544e-05\n",
      "Epoch 3464, Loss: 0.0003992480542365229, Final Batch Loss: 0.0003724768466781825\n",
      "Epoch 3465, Loss: 5.586993393080775e-05, Final Batch Loss: 4.496051769820042e-05\n",
      "Epoch 3466, Loss: 0.008390188078919891, Final Batch Loss: 0.008303300477564335\n",
      "Epoch 3467, Loss: 4.871928285865579e-05, Final Batch Loss: 1.7141008356702514e-05\n",
      "Epoch 3468, Loss: 0.0006064656390663004, Final Batch Loss: 0.0005950066260993481\n",
      "Epoch 3469, Loss: 0.00017775203014025465, Final Batch Loss: 4.7296191041823477e-05\n",
      "Epoch 3470, Loss: 0.00011360291864548344, Final Batch Loss: 0.000109952969069127\n",
      "Epoch 3471, Loss: 0.00014893947445671074, Final Batch Loss: 0.00011469236778793857\n",
      "Epoch 3472, Loss: 0.00034503832375776256, Final Batch Loss: 0.0003344462311360985\n",
      "Epoch 3473, Loss: 6.426475198395565e-05, Final Batch Loss: 6.93800814133283e-07\n",
      "Epoch 3474, Loss: 0.00035241285513620824, Final Batch Loss: 0.00020596796821337193\n",
      "Epoch 3475, Loss: 6.701071743009379e-05, Final Batch Loss: 1.289377087232424e-05\n",
      "Epoch 3476, Loss: 0.0013842302287230268, Final Batch Loss: 0.00019433478883001953\n",
      "Epoch 3477, Loss: 0.0007037837203824893, Final Batch Loss: 0.0005707063246518373\n",
      "Epoch 3478, Loss: 0.00041075262561207637, Final Batch Loss: 0.0003273456823080778\n",
      "Epoch 3479, Loss: 0.0011121539428131655, Final Batch Loss: 0.00010391611431259662\n",
      "Epoch 3480, Loss: 7.73557330830954e-05, Final Batch Loss: 3.791958442889154e-05\n",
      "Epoch 3481, Loss: 0.002241528730792197, Final Batch Loss: 4.483291832002578e-06\n",
      "Epoch 3482, Loss: 0.00015857537619012874, Final Batch Loss: 0.00015377246018033475\n",
      "Epoch 3483, Loss: 0.0006126944281277247, Final Batch Loss: 2.1643303625751287e-05\n",
      "Epoch 3484, Loss: 4.7942034143488854e-05, Final Batch Loss: 1.362441253149882e-05\n",
      "Epoch 3485, Loss: 0.00020934711210429668, Final Batch Loss: 6.964542262721807e-05\n",
      "Epoch 3486, Loss: 0.00019029100076295435, Final Batch Loss: 0.00012019766290904954\n",
      "Epoch 3487, Loss: 0.0006516640278277919, Final Batch Loss: 0.00044302287278696895\n",
      "Epoch 3488, Loss: 8.36575109133264e-05, Final Batch Loss: 1.763185537129175e-05\n",
      "Epoch 3489, Loss: 0.0027477620424178895, Final Batch Loss: 3.852488225675188e-05\n",
      "Epoch 3490, Loss: 0.0001047847472364083, Final Batch Loss: 3.24654538417235e-05\n",
      "Epoch 3491, Loss: 0.00483388008797192, Final Batch Loss: 4.77258327009622e-05\n",
      "Epoch 3492, Loss: 2.8468769869505195e-05, Final Batch Loss: 4.523926236288389e-06\n",
      "Epoch 3493, Loss: 0.00021735478367190808, Final Batch Loss: 0.00015343255654443055\n",
      "Epoch 3494, Loss: 0.001552589877974242, Final Batch Loss: 0.0014653014950454235\n",
      "Epoch 3495, Loss: 2.4479999410687014e-05, Final Batch Loss: 1.9914034055545926e-05\n",
      "Epoch 3496, Loss: 0.0014071644836803898, Final Batch Loss: 0.0012864520540460944\n",
      "Epoch 3497, Loss: 5.49037431483157e-05, Final Batch Loss: 2.427978688501753e-05\n",
      "Epoch 3498, Loss: 7.61125261306006e-06, Final Batch Loss: 4.317715593060711e-06\n",
      "Epoch 3499, Loss: 0.003307989562927105, Final Batch Loss: 1.0081796972372103e-05\n",
      "Epoch 3500, Loss: 0.000991926048300229, Final Batch Loss: 7.758043648209423e-05\n",
      "Epoch 3501, Loss: 0.0007083478121785447, Final Batch Loss: 6.936710269656032e-05\n",
      "Epoch 3502, Loss: 0.0002371190748817753, Final Batch Loss: 0.00020804266387131065\n",
      "Epoch 3503, Loss: 0.00034798934211721644, Final Batch Loss: 3.582526551326737e-05\n",
      "Epoch 3504, Loss: 0.0005787605277873809, Final Batch Loss: 2.1312336684786715e-05\n",
      "Epoch 3505, Loss: 0.0003275415247117053, Final Batch Loss: 7.016441486484837e-06\n",
      "Epoch 3506, Loss: 0.0010592858088784851, Final Batch Loss: 7.794096745783463e-05\n",
      "Epoch 3507, Loss: 0.00041825397784123197, Final Batch Loss: 2.0690007659140974e-05\n",
      "Epoch 3508, Loss: 0.0009797682323551271, Final Batch Loss: 0.0009553610580042005\n",
      "Epoch 3509, Loss: 0.00024285336985485628, Final Batch Loss: 0.0001794616982806474\n",
      "Epoch 3510, Loss: 7.371918991339044e-05, Final Batch Loss: 7.427212494803825e-06\n",
      "Epoch 3511, Loss: 0.000236089759710012, Final Batch Loss: 0.00021361859398894012\n",
      "Epoch 3512, Loss: 0.0002384465915383771, Final Batch Loss: 0.00011974990047747269\n",
      "Epoch 3513, Loss: 1.4285838005889673e-05, Final Batch Loss: 1.0190013199462555e-05\n",
      "Epoch 3514, Loss: 0.00011005538726749364, Final Batch Loss: 9.848394256550819e-05\n",
      "Epoch 3515, Loss: 2.433095278320252e-05, Final Batch Loss: 4.185210400464712e-06\n",
      "Epoch 3516, Loss: 0.00011482404443086125, Final Batch Loss: 0.00010478057811269537\n",
      "Epoch 3517, Loss: 0.0002870914904633537, Final Batch Loss: 0.00024579590535722673\n",
      "Epoch 3518, Loss: 0.00010850524176930776, Final Batch Loss: 8.11570407677209e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3519, Loss: 0.00013638376287872234, Final Batch Loss: 1.6959940012384322e-06\n",
      "Epoch 3520, Loss: 0.0005344470155250747, Final Batch Loss: 4.794572669197805e-05\n",
      "Epoch 3521, Loss: 0.0005143023299751803, Final Batch Loss: 0.0001514039031462744\n",
      "Epoch 3522, Loss: 0.005182563957532693, Final Batch Loss: 0.005174596793949604\n",
      "Epoch 3523, Loss: 7.791760435793549e-05, Final Batch Loss: 3.494470365694724e-05\n",
      "Epoch 3524, Loss: 0.0002401240635663271, Final Batch Loss: 0.0001590634637977928\n",
      "Epoch 3525, Loss: 0.00033953455204027705, Final Batch Loss: 5.8068362704943866e-06\n",
      "Epoch 3526, Loss: 0.00013625457722810097, Final Batch Loss: 9.13922704057768e-05\n",
      "Epoch 3527, Loss: 0.0011955092413700186, Final Batch Loss: 8.314885053550825e-05\n",
      "Epoch 3528, Loss: 6.310654134722427e-05, Final Batch Loss: 2.9072609322611243e-05\n",
      "Epoch 3529, Loss: 0.0001881224634416867, Final Batch Loss: 2.7405916625866666e-05\n",
      "Epoch 3530, Loss: 0.0002179634502681438, Final Batch Loss: 2.9395687306532636e-05\n",
      "Epoch 3531, Loss: 0.0004371966133476235, Final Batch Loss: 9.050509106600657e-05\n",
      "Epoch 3532, Loss: 0.0007031043132883497, Final Batch Loss: 0.0006586553063243628\n",
      "Epoch 3533, Loss: 0.00020559419499477372, Final Batch Loss: 7.224364526337013e-05\n",
      "Epoch 3534, Loss: 0.00031012031831778586, Final Batch Loss: 0.00012398164835758507\n",
      "Epoch 3535, Loss: 0.0004609540073943208, Final Batch Loss: 0.00044703917228616774\n",
      "Epoch 3536, Loss: 0.0001813812050386332, Final Batch Loss: 7.100728544173762e-05\n",
      "Epoch 3537, Loss: 0.005709660268621519, Final Batch Loss: 0.005609037354588509\n",
      "Epoch 3538, Loss: 0.0011017939532393939, Final Batch Loss: 1.2294970474613365e-05\n",
      "Epoch 3539, Loss: 0.0006216279653017409, Final Batch Loss: 4.332082608016208e-05\n",
      "Epoch 3540, Loss: 0.005544560561702383, Final Batch Loss: 0.005540397483855486\n",
      "Epoch 3541, Loss: 0.011648086830973625, Final Batch Loss: 0.006982358638197184\n",
      "Epoch 3542, Loss: 0.007690799771808088, Final Batch Loss: 0.00032254995312541723\n",
      "Epoch 3543, Loss: 0.00048443507694173604, Final Batch Loss: 5.5720345699228346e-05\n",
      "Epoch 3544, Loss: 0.0003523130726534873, Final Batch Loss: 0.00031090970151126385\n",
      "Epoch 3545, Loss: 0.0011287757552054245, Final Batch Loss: 4.8750302084954455e-05\n",
      "Epoch 3546, Loss: 0.0022516868339153007, Final Batch Loss: 5.684614006895572e-05\n",
      "Epoch 3547, Loss: 0.0004904620291199535, Final Batch Loss: 0.0002460172981955111\n",
      "Epoch 3548, Loss: 0.0012500549055403098, Final Batch Loss: 0.00012788000458385795\n",
      "Epoch 3549, Loss: 6.800062510592397e-05, Final Batch Loss: 5.7739725889405236e-06\n",
      "Epoch 3550, Loss: 0.00018430984346196055, Final Batch Loss: 7.514945173170418e-05\n",
      "Epoch 3551, Loss: 3.9666421798756346e-05, Final Batch Loss: 1.6181313185370527e-05\n",
      "Epoch 3552, Loss: 0.00020104559735045768, Final Batch Loss: 4.43899079982657e-05\n",
      "Epoch 3553, Loss: 5.621250420517754e-05, Final Batch Loss: 4.09144013246987e-05\n",
      "Epoch 3554, Loss: 0.004301703738747165, Final Batch Loss: 3.159019979648292e-05\n",
      "Epoch 3555, Loss: 0.02753101513371803, Final Batch Loss: 0.027138153091073036\n",
      "Epoch 3556, Loss: 0.00016622857219772413, Final Batch Loss: 9.758945816429332e-05\n",
      "Epoch 3557, Loss: 9.149381367024034e-05, Final Batch Loss: 7.476772589143366e-05\n",
      "Epoch 3558, Loss: 3.1054445571498945e-05, Final Batch Loss: 9.907591447699815e-06\n",
      "Epoch 3559, Loss: 0.00022779118080507033, Final Batch Loss: 0.00018979169544763863\n",
      "Epoch 3560, Loss: 0.0002029597308137454, Final Batch Loss: 3.5061319067608565e-05\n",
      "Epoch 3561, Loss: 0.0037681888788938522, Final Batch Loss: 0.00032137916423380375\n",
      "Epoch 3562, Loss: 0.0005934473429078935, Final Batch Loss: 0.0005804069805890322\n",
      "Epoch 3563, Loss: 0.00045078545008436777, Final Batch Loss: 0.00038997892988845706\n",
      "Epoch 3564, Loss: 8.61740318214288e-05, Final Batch Loss: 6.0549926274688914e-05\n",
      "Epoch 3565, Loss: 0.00042274898351024603, Final Batch Loss: 0.00041365044307895005\n",
      "Epoch 3566, Loss: 0.0002915000695793424, Final Batch Loss: 3.501674291328527e-05\n",
      "Epoch 3567, Loss: 0.010260488641506527, Final Batch Loss: 5.278251046547666e-05\n",
      "Epoch 3568, Loss: 0.00019326571009514737, Final Batch Loss: 5.877816420252202e-06\n",
      "Epoch 3569, Loss: 4.748292167278123e-05, Final Batch Loss: 6.30140175417182e-06\n",
      "Epoch 3570, Loss: 0.0003987816016888246, Final Batch Loss: 3.085027856286615e-05\n",
      "Epoch 3571, Loss: 0.00047840913794061635, Final Batch Loss: 0.00045185067574493587\n",
      "Epoch 3572, Loss: 0.0002565709964983398, Final Batch Loss: 2.0523026250884868e-05\n",
      "Epoch 3573, Loss: 0.000873780605616048, Final Batch Loss: 0.0007258452824316919\n",
      "Epoch 3574, Loss: 0.00039386117714457214, Final Batch Loss: 0.00022963984520174563\n",
      "Epoch 3575, Loss: 0.00030602686820202507, Final Batch Loss: 0.00024937166017480195\n",
      "Epoch 3576, Loss: 9.628216866985895e-05, Final Batch Loss: 2.6914643967757e-05\n",
      "Epoch 3577, Loss: 0.00012645476999750827, Final Batch Loss: 0.00010439058678457513\n",
      "Epoch 3578, Loss: 0.0003470006486168131, Final Batch Loss: 0.00022924336371943355\n",
      "Epoch 3579, Loss: 0.0003820998208539095, Final Batch Loss: 0.0003513476112857461\n",
      "Epoch 3580, Loss: 0.00033625926153035834, Final Batch Loss: 0.0002541697467677295\n",
      "Epoch 3581, Loss: 0.00011788033589255065, Final Batch Loss: 3.97280091419816e-05\n",
      "Epoch 3582, Loss: 0.00011795337468356593, Final Batch Loss: 1.0242259122605901e-05\n",
      "Epoch 3583, Loss: 0.0006950416864128783, Final Batch Loss: 0.0006202048389241099\n",
      "Epoch 3584, Loss: 0.0009257949823222589, Final Batch Loss: 0.0009077460272237659\n",
      "Epoch 3585, Loss: 9.842514191404916e-05, Final Batch Loss: 5.163619061931968e-05\n",
      "Epoch 3586, Loss: 8.028138290683273e-05, Final Batch Loss: 2.2087782781454735e-05\n",
      "Epoch 3587, Loss: 0.00061472287052311, Final Batch Loss: 0.0003119839238934219\n",
      "Epoch 3588, Loss: 0.0002953734074253589, Final Batch Loss: 0.00012433771917130798\n",
      "Epoch 3589, Loss: 0.00040302037450601347, Final Batch Loss: 2.4953613319667056e-05\n",
      "Epoch 3590, Loss: 0.004776739340741187, Final Batch Loss: 0.004105488304048777\n",
      "Epoch 3591, Loss: 0.00020748847691720584, Final Batch Loss: 1.2923942449560855e-05\n",
      "Epoch 3592, Loss: 0.00010931781434919685, Final Batch Loss: 6.974163989070803e-05\n",
      "Epoch 3593, Loss: 0.000461733405245468, Final Batch Loss: 0.0002015508944168687\n",
      "Epoch 3594, Loss: 0.00016565844725846546, Final Batch Loss: 1.1741501111828256e-05\n",
      "Epoch 3595, Loss: 0.0009524493289063685, Final Batch Loss: 0.0009286243584938347\n",
      "Epoch 3596, Loss: 0.00011991915016551502, Final Batch Loss: 9.041069279192016e-05\n",
      "Epoch 3597, Loss: 5.089049045636784e-05, Final Batch Loss: 4.088088098797016e-05\n",
      "Epoch 3598, Loss: 0.0001599940787855303, Final Batch Loss: 0.00014424000983126462\n",
      "Epoch 3599, Loss: 3.6253482903703116e-05, Final Batch Loss: 2.7653664801619016e-05\n",
      "Epoch 3600, Loss: 0.00024592817135271616, Final Batch Loss: 3.895037298207171e-05\n",
      "Epoch 3601, Loss: 0.00020567573301377706, Final Batch Loss: 0.00019142469682265073\n",
      "Epoch 3602, Loss: 0.0004682290164055303, Final Batch Loss: 0.0002678837045095861\n",
      "Epoch 3603, Loss: 0.00021563978589256294, Final Batch Loss: 4.550101948552765e-05\n",
      "Epoch 3604, Loss: 6.915805442986311e-05, Final Batch Loss: 1.347662055195542e-05\n",
      "Epoch 3605, Loss: 1.6026240700739436e-05, Final Batch Loss: 7.716568688920233e-06\n",
      "Epoch 3606, Loss: 0.00015629080007784069, Final Batch Loss: 6.870085053378716e-05\n",
      "Epoch 3607, Loss: 0.00010795009484354523, Final Batch Loss: 7.402217761409702e-06\n",
      "Epoch 3608, Loss: 0.00014899935013090726, Final Batch Loss: 0.00012493539543356746\n",
      "Epoch 3609, Loss: 0.00011889107327078818, Final Batch Loss: 0.00011452493345132098\n",
      "Epoch 3610, Loss: 0.00027561542447074316, Final Batch Loss: 5.718606917071156e-05\n",
      "Epoch 3611, Loss: 0.00020588534243870527, Final Batch Loss: 0.00011164105671923608\n",
      "Epoch 3612, Loss: 9.943958275471232e-06, Final Batch Loss: 7.50566641727346e-07\n",
      "Epoch 3613, Loss: 3.8589496398344636e-05, Final Batch Loss: 2.559501626819838e-05\n",
      "Epoch 3614, Loss: 9.080939707928337e-05, Final Batch Loss: 6.309994932962582e-05\n",
      "Epoch 3615, Loss: 0.0002486886296537705, Final Batch Loss: 0.0002169516374124214\n",
      "Epoch 3616, Loss: 5.732272802561056e-05, Final Batch Loss: 1.5558280210825615e-05\n",
      "Epoch 3617, Loss: 0.0003697708289109869, Final Batch Loss: 0.00035253024543635547\n",
      "Epoch 3618, Loss: 0.0010231342312181368, Final Batch Loss: 0.0008776352042332292\n",
      "Epoch 3619, Loss: 4.4145922402094584e-05, Final Batch Loss: 1.2857758520112839e-05\n",
      "Epoch 3620, Loss: 9.32936163735576e-05, Final Batch Loss: 4.796461871592328e-05\n",
      "Epoch 3621, Loss: 6.149563751023379e-05, Final Batch Loss: 5.694556239177473e-05\n",
      "Epoch 3622, Loss: 0.00016927339311223477, Final Batch Loss: 0.00012219740892760456\n",
      "Epoch 3623, Loss: 0.00034817976120393723, Final Batch Loss: 0.0002899842511396855\n",
      "Epoch 3624, Loss: 0.000271867131232284, Final Batch Loss: 0.0001448274269932881\n",
      "Epoch 3625, Loss: 0.00100769284836133, Final Batch Loss: 4.2758725612657145e-05\n",
      "Epoch 3626, Loss: 0.0005518796024261974, Final Batch Loss: 9.662235243013129e-05\n",
      "Epoch 3627, Loss: 0.00016903492723940872, Final Batch Loss: 1.716703627607785e-05\n",
      "Epoch 3628, Loss: 8.488563071296085e-05, Final Batch Loss: 1.6448570022475906e-05\n",
      "Epoch 3629, Loss: 0.00032063733669929206, Final Batch Loss: 6.665487308055162e-05\n",
      "Epoch 3630, Loss: 0.0006973814961384051, Final Batch Loss: 0.000581589003559202\n",
      "Epoch 3631, Loss: 2.3706214960839134e-05, Final Batch Loss: 7.245948836498428e-06\n",
      "Epoch 3632, Loss: 0.00017870032752398401, Final Batch Loss: 0.00017051216855179518\n",
      "Epoch 3633, Loss: 2.0926097931805998e-05, Final Batch Loss: 1.5027775589260273e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3634, Loss: 3.414678394619841e-05, Final Batch Loss: 6.710404704790562e-06\n",
      "Epoch 3635, Loss: 1.925144852066296e-05, Final Batch Loss: 7.034974714770215e-06\n",
      "Epoch 3636, Loss: 0.00036871767952106893, Final Batch Loss: 0.00019644369604066014\n",
      "Epoch 3637, Loss: 0.0005655539061990567, Final Batch Loss: 0.000546314287930727\n",
      "Epoch 3638, Loss: 5.2897627028869465e-05, Final Batch Loss: 2.378971839789301e-05\n",
      "Epoch 3639, Loss: 0.0001015172074403381, Final Batch Loss: 7.403286872431636e-05\n",
      "Epoch 3640, Loss: 0.0002408184454907314, Final Batch Loss: 2.09514928428689e-06\n",
      "Epoch 3641, Loss: 0.0009735720232129097, Final Batch Loss: 0.0002695624716579914\n",
      "Epoch 3642, Loss: 1.1230093832637067e-05, Final Batch Loss: 7.5578736868919805e-06\n",
      "Epoch 3643, Loss: 0.00027642721397569403, Final Batch Loss: 0.0001629959442652762\n",
      "Epoch 3644, Loss: 9.233405398845207e-05, Final Batch Loss: 2.9134293072274886e-05\n",
      "Epoch 3645, Loss: 0.0003808641922660172, Final Batch Loss: 7.54913198761642e-05\n",
      "Epoch 3646, Loss: 5.181753431315883e-05, Final Batch Loss: 3.897626356774708e-06\n",
      "Epoch 3647, Loss: 0.00045691122068092227, Final Batch Loss: 0.000358487362973392\n",
      "Epoch 3648, Loss: 0.009812396856432315, Final Batch Loss: 0.009724459610879421\n",
      "Epoch 3649, Loss: 0.00011674714914988726, Final Batch Loss: 5.138729466125369e-05\n",
      "Epoch 3650, Loss: 5.4778610547145945e-05, Final Batch Loss: 5.132936712470837e-05\n",
      "Epoch 3651, Loss: 0.004939883889164776, Final Batch Loss: 0.0003465357585810125\n",
      "Epoch 3652, Loss: 0.0005184677684155758, Final Batch Loss: 3.380313501111232e-05\n",
      "Epoch 3653, Loss: 0.00026331498429499334, Final Batch Loss: 1.2439150850696024e-05\n",
      "Epoch 3654, Loss: 0.0023641803418286145, Final Batch Loss: 0.001514090457931161\n",
      "Epoch 3655, Loss: 4.570420765048766e-05, Final Batch Loss: 3.562388656064286e-06\n",
      "Epoch 3656, Loss: 0.0003116928073723102, Final Batch Loss: 1.6917949324124493e-05\n",
      "Epoch 3657, Loss: 0.00012186145977466367, Final Batch Loss: 3.6176283174427226e-05\n",
      "Epoch 3658, Loss: 0.0005741819113609381, Final Batch Loss: 0.0005063014687038958\n",
      "Epoch 3659, Loss: 0.00033225803781533614, Final Batch Loss: 8.57206541695632e-05\n",
      "Epoch 3660, Loss: 0.00020388113989611156, Final Batch Loss: 3.1190607842290774e-05\n",
      "Epoch 3661, Loss: 4.332815660745837e-05, Final Batch Loss: 1.565755701449234e-05\n",
      "Epoch 3662, Loss: 0.00010092494630953297, Final Batch Loss: 3.2792158890515566e-05\n",
      "Epoch 3663, Loss: 0.0009403597146047105, Final Batch Loss: 2.61933791989577e-06\n",
      "Epoch 3664, Loss: 0.0004800762640115863, Final Batch Loss: 3.83331871489645e-06\n",
      "Epoch 3665, Loss: 0.00015124511264730245, Final Batch Loss: 0.00011809047282440588\n",
      "Epoch 3666, Loss: 0.00032965825812425464, Final Batch Loss: 0.00013925631355959922\n",
      "Epoch 3667, Loss: 9.132736613537418e-05, Final Batch Loss: 8.020856330404058e-05\n",
      "Epoch 3668, Loss: 4.9050318921217695e-05, Final Batch Loss: 1.3641252735396847e-05\n",
      "Epoch 3669, Loss: 1.6503423466929235e-05, Final Batch Loss: 5.829083420394454e-06\n",
      "Epoch 3670, Loss: 8.014025115699042e-05, Final Batch Loss: 2.1801713955937885e-05\n",
      "Epoch 3671, Loss: 0.0004764874938700814, Final Batch Loss: 0.00044371577678248286\n",
      "Epoch 3672, Loss: 0.0007477426697732881, Final Batch Loss: 0.00019978471391368657\n",
      "Epoch 3673, Loss: 4.7187406380544417e-05, Final Batch Loss: 3.904475306626409e-05\n",
      "Epoch 3674, Loss: 4.16461816712399e-05, Final Batch Loss: 2.7895001039723866e-05\n",
      "Epoch 3675, Loss: 0.00048429026355734095, Final Batch Loss: 8.108218753477558e-05\n",
      "Epoch 3676, Loss: 0.0023031811324472073, Final Batch Loss: 3.7989728298271075e-05\n",
      "Epoch 3677, Loss: 2.7153079827257898e-05, Final Batch Loss: 4.2979891077266075e-06\n",
      "Epoch 3678, Loss: 0.0009522394393570721, Final Batch Loss: 0.0004600750398822129\n",
      "Epoch 3679, Loss: 0.0008480271653752425, Final Batch Loss: 8.248885023931507e-06\n",
      "Epoch 3680, Loss: 0.00018111042390955845, Final Batch Loss: 3.7516956581384875e-06\n",
      "Epoch 3681, Loss: 4.219332731736358e-05, Final Batch Loss: 2.1992409529048018e-05\n",
      "Epoch 3682, Loss: 8.425895111940918e-05, Final Batch Loss: 4.099558736925246e-06\n",
      "Epoch 3683, Loss: 7.976437018442084e-06, Final Batch Loss: 4.2436768126208335e-06\n",
      "Epoch 3684, Loss: 2.2846176761959214e-05, Final Batch Loss: 1.3905067135056015e-05\n",
      "Epoch 3685, Loss: 0.00010673694123397581, Final Batch Loss: 3.715620914590545e-05\n",
      "Epoch 3686, Loss: 0.00010032084446720546, Final Batch Loss: 1.5060809346323367e-05\n",
      "Epoch 3687, Loss: 2.7517009527855407e-05, Final Batch Loss: 6.364061277963629e-07\n",
      "Epoch 3688, Loss: 4.577156414597994e-05, Final Batch Loss: 3.67355823982507e-05\n",
      "Epoch 3689, Loss: 8.658951082907151e-05, Final Batch Loss: 1.4662064131698571e-05\n",
      "Epoch 3690, Loss: 0.0002139573080057744, Final Batch Loss: 5.192179014557041e-05\n",
      "Epoch 3691, Loss: 0.00015218376756820362, Final Batch Loss: 1.796535616449546e-05\n",
      "Epoch 3692, Loss: 0.007446580784744583, Final Batch Loss: 0.007357361260801554\n",
      "Epoch 3693, Loss: 0.0008256382134277374, Final Batch Loss: 0.0006386209861375391\n",
      "Epoch 3694, Loss: 0.00013125929126545088, Final Batch Loss: 0.00012043806054862216\n",
      "Epoch 3695, Loss: 0.0004250351521477569, Final Batch Loss: 5.96681384195108e-05\n",
      "Epoch 3696, Loss: 0.00032064024253486423, Final Batch Loss: 0.0003101806214544922\n",
      "Epoch 3697, Loss: 4.801288014277816e-05, Final Batch Loss: 1.2203559890622273e-05\n",
      "Epoch 3698, Loss: 0.00027444841271062614, Final Batch Loss: 7.734332939435262e-06\n",
      "Epoch 3699, Loss: 1.2930359844176564e-05, Final Batch Loss: 7.781072781654075e-06\n",
      "Epoch 3700, Loss: 0.00018143740453524515, Final Batch Loss: 4.9445654440205544e-05\n",
      "Epoch 3701, Loss: 0.0008654518860566895, Final Batch Loss: 5.917752787354402e-05\n",
      "Epoch 3702, Loss: 8.390771654376294e-05, Final Batch Loss: 1.1820395229733549e-05\n",
      "Epoch 3703, Loss: 3.257044227211736e-05, Final Batch Loss: 8.699424142832868e-06\n",
      "Epoch 3704, Loss: 0.00022917419846635312, Final Batch Loss: 9.298705845139921e-05\n",
      "Epoch 3705, Loss: 0.0028410957020241767, Final Batch Loss: 7.93261278886348e-05\n",
      "Epoch 3706, Loss: 0.00043366120371501893, Final Batch Loss: 0.0002685025683604181\n",
      "Epoch 3707, Loss: 0.00037052168045192957, Final Batch Loss: 0.00022408939548768103\n",
      "Epoch 3708, Loss: 0.0005882746772840619, Final Batch Loss: 0.00015101672033779323\n",
      "Epoch 3709, Loss: 0.009540158928302844, Final Batch Loss: 2.36895766647649e-06\n",
      "Epoch 3710, Loss: 0.0004994909259039559, Final Batch Loss: 5.837923708895687e-06\n",
      "Epoch 3711, Loss: 1.3467918591913985e-05, Final Batch Loss: 1.3046396816207562e-05\n",
      "Epoch 3712, Loss: 3.971372643718496e-05, Final Batch Loss: 2.3557380700367503e-05\n",
      "Epoch 3713, Loss: 9.439954919798765e-05, Final Batch Loss: 2.0377361579448916e-05\n",
      "Epoch 3714, Loss: 6.104140084062237e-05, Final Batch Loss: 9.20230922929477e-06\n",
      "Epoch 3715, Loss: 0.0015068373049871298, Final Batch Loss: 1.1335696399328299e-05\n",
      "Epoch 3716, Loss: 0.0001614537450222997, Final Batch Loss: 2.2025951693649404e-05\n",
      "Epoch 3717, Loss: 0.001703351408650633, Final Batch Loss: 5.569450877374038e-05\n",
      "Epoch 3718, Loss: 0.002492517676728312, Final Batch Loss: 9.348031744593754e-05\n",
      "Epoch 3719, Loss: 0.0004912636723020114, Final Batch Loss: 0.00038125834544189274\n",
      "Epoch 3720, Loss: 0.00023159102420322597, Final Batch Loss: 5.342044460121542e-05\n",
      "Epoch 3721, Loss: 9.710084123071283e-05, Final Batch Loss: 5.336728281690739e-05\n",
      "Epoch 3722, Loss: 4.656248347600922e-05, Final Batch Loss: 1.9111070287181064e-05\n",
      "Epoch 3723, Loss: 0.00017615427532291505, Final Batch Loss: 1.848574356699828e-05\n",
      "Epoch 3724, Loss: 2.605597956062411e-05, Final Batch Loss: 7.56856434236397e-06\n",
      "Epoch 3725, Loss: 8.10145847935928e-05, Final Batch Loss: 6.569815013790503e-05\n",
      "Epoch 3726, Loss: 0.00018778216326609254, Final Batch Loss: 0.00014818708586972207\n",
      "Epoch 3727, Loss: 5.227061046753079e-05, Final Batch Loss: 5.608359060715884e-06\n",
      "Epoch 3728, Loss: 5.295739174471237e-05, Final Batch Loss: 3.241424201405607e-05\n",
      "Epoch 3729, Loss: 0.000834145533190167, Final Batch Loss: 0.0008276908192783594\n",
      "Epoch 3730, Loss: 0.0009444812385481782, Final Batch Loss: 0.0008621936431154609\n",
      "Epoch 3731, Loss: 2.7891770514543168e-05, Final Batch Loss: 7.93003709986806e-06\n",
      "Epoch 3732, Loss: 0.015539661617367528, Final Batch Loss: 1.5253768651746213e-05\n",
      "Epoch 3733, Loss: 2.0357897483336274e-05, Final Batch Loss: 5.866429091838654e-06\n",
      "Epoch 3734, Loss: 2.0279945374568342e-05, Final Batch Loss: 1.9027325834031217e-05\n",
      "Epoch 3735, Loss: 0.00039599866431672126, Final Batch Loss: 8.759692718740553e-05\n",
      "Epoch 3736, Loss: 1.5881906165304827e-05, Final Batch Loss: 6.287413725658553e-06\n",
      "Epoch 3737, Loss: 0.011391320298571372, Final Batch Loss: 4.607814844348468e-05\n",
      "Epoch 3738, Loss: 6.944370761630125e-05, Final Batch Loss: 5.2186525863362476e-05\n",
      "Epoch 3739, Loss: 0.00022081625684222672, Final Batch Loss: 0.00021234634914435446\n",
      "Epoch 3740, Loss: 6.448042404372245e-05, Final Batch Loss: 3.145355367450975e-05\n",
      "Epoch 3741, Loss: 5.636245714413235e-05, Final Batch Loss: 1.2730238267977256e-05\n",
      "Epoch 3742, Loss: 0.0034821422113964218, Final Batch Loss: 0.0034795012325048447\n",
      "Epoch 3743, Loss: 5.398953999247169e-05, Final Batch Loss: 1.3401134310697671e-05\n",
      "Epoch 3744, Loss: 0.00015499604978685966, Final Batch Loss: 1.0287250006513204e-05\n",
      "Epoch 3745, Loss: 0.12441303592640907, Final Batch Loss: 0.0006974564166739583\n",
      "Epoch 3746, Loss: 5.6493133797630435e-05, Final Batch Loss: 4.587823696056148e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3747, Loss: 3.576873859856278e-05, Final Batch Loss: 1.6081296053016558e-05\n",
      "Epoch 3748, Loss: 0.00012255106685188366, Final Batch Loss: 0.00011441655806265771\n",
      "Epoch 3749, Loss: 0.0008853217150317505, Final Batch Loss: 0.0008617808925919235\n",
      "Epoch 3750, Loss: 0.00038742432661820203, Final Batch Loss: 0.00012776094081345946\n",
      "Epoch 3751, Loss: 0.05249553034082055, Final Batch Loss: 0.046608198434114456\n",
      "Epoch 3752, Loss: 0.0005483991262735799, Final Batch Loss: 0.00014848962018731982\n",
      "Epoch 3753, Loss: 0.001997174258576706, Final Batch Loss: 0.00039799886872060597\n",
      "Epoch 3754, Loss: 0.000135094716824824, Final Batch Loss: 4.652095594792627e-05\n",
      "Epoch 3755, Loss: 0.0016280575946439058, Final Batch Loss: 0.0012698918581008911\n",
      "Epoch 3756, Loss: 0.0001000938136712648, Final Batch Loss: 5.8209101553075016e-05\n",
      "Epoch 3757, Loss: 0.00020688392396550626, Final Batch Loss: 6.443087477236986e-05\n",
      "Epoch 3758, Loss: 0.00011883346815011464, Final Batch Loss: 8.030941535253078e-05\n",
      "Epoch 3759, Loss: 0.00016067284013843164, Final Batch Loss: 6.993088027229533e-05\n",
      "Epoch 3760, Loss: 0.00017081887563108467, Final Batch Loss: 2.547754775150679e-05\n",
      "Epoch 3761, Loss: 0.005149062315467745, Final Batch Loss: 0.00035446748370304704\n",
      "Epoch 3762, Loss: 0.0001488523503212491, Final Batch Loss: 0.00013599295925814658\n",
      "Epoch 3763, Loss: 0.00020975990628357977, Final Batch Loss: 0.00015448905469384044\n",
      "Epoch 3764, Loss: 0.0007297483971342444, Final Batch Loss: 0.0006931781535968184\n",
      "Epoch 3765, Loss: 0.0038539066445082426, Final Batch Loss: 0.0033476154785603285\n",
      "Epoch 3766, Loss: 0.0008815602777758613, Final Batch Loss: 9.914157271850854e-05\n",
      "Epoch 3767, Loss: 0.00016210199828492478, Final Batch Loss: 2.4823595595080405e-05\n",
      "Epoch 3768, Loss: 0.0015528421208728105, Final Batch Loss: 0.0012995874276384711\n",
      "Epoch 3769, Loss: 0.0006823705043643713, Final Batch Loss: 0.00017191481310874224\n",
      "Epoch 3770, Loss: 0.0002411082423350308, Final Batch Loss: 5.5686123232590035e-05\n",
      "Epoch 3771, Loss: 0.00010426859444123693, Final Batch Loss: 4.801462637260556e-05\n",
      "Epoch 3772, Loss: 0.0002475284240972542, Final Batch Loss: 6.824146566941636e-06\n",
      "Epoch 3773, Loss: 0.0007983485120348632, Final Batch Loss: 8.89642396941781e-05\n",
      "Epoch 3774, Loss: 7.27347141946666e-05, Final Batch Loss: 4.4847016397397965e-05\n",
      "Epoch 3775, Loss: 0.0011949716426897794, Final Batch Loss: 0.00042117261909879744\n",
      "Epoch 3776, Loss: 4.842163161811186e-05, Final Batch Loss: 1.3043320905126166e-05\n",
      "Epoch 3777, Loss: 0.0003087239783781115, Final Batch Loss: 2.4873679649317637e-05\n",
      "Epoch 3778, Loss: 0.0009105500503210351, Final Batch Loss: 0.00012856196553912014\n",
      "Epoch 3779, Loss: 0.004291468934752629, Final Batch Loss: 1.0879413821385242e-05\n",
      "Epoch 3780, Loss: 0.0008932646924222354, Final Batch Loss: 2.0050709281349555e-05\n",
      "Epoch 3781, Loss: 7.431845006067306e-05, Final Batch Loss: 2.612200114526786e-05\n",
      "Epoch 3782, Loss: 0.000514142848260235, Final Batch Loss: 3.485427441773936e-05\n",
      "Epoch 3783, Loss: 7.050714884826448e-05, Final Batch Loss: 1.7267475413973443e-05\n",
      "Epoch 3784, Loss: 2.8834150725742802e-05, Final Batch Loss: 1.246831743628718e-05\n",
      "Epoch 3785, Loss: 0.0011711256811395288, Final Batch Loss: 0.0009089959785342216\n",
      "Epoch 3786, Loss: 0.00048099845844262745, Final Batch Loss: 0.0004536418418865651\n",
      "Epoch 3787, Loss: 0.00026787890237756073, Final Batch Loss: 0.00021628011018037796\n",
      "Epoch 3788, Loss: 0.0002261449299112428, Final Batch Loss: 1.5864894521655515e-05\n",
      "Epoch 3789, Loss: 5.066248377261218e-05, Final Batch Loss: 3.457847560639493e-05\n",
      "Epoch 3790, Loss: 0.001437138402252458, Final Batch Loss: 0.0013414004351943731\n",
      "Epoch 3791, Loss: 0.00011843102038255893, Final Batch Loss: 8.247992809629068e-05\n",
      "Epoch 3792, Loss: 0.00012904172399430536, Final Batch Loss: 6.898746505612507e-05\n",
      "Epoch 3793, Loss: 0.00019260235967522021, Final Batch Loss: 0.00016916220192797482\n",
      "Epoch 3794, Loss: 0.0005623396500595845, Final Batch Loss: 0.000514380109962076\n",
      "Epoch 3795, Loss: 0.00013006195513298735, Final Batch Loss: 6.26801120233722e-05\n",
      "Epoch 3796, Loss: 7.420830388582544e-05, Final Batch Loss: 1.2075904123776127e-05\n",
      "Epoch 3797, Loss: 0.00020908004535158398, Final Batch Loss: 1.0702065083023626e-05\n",
      "Epoch 3798, Loss: 0.00366241778829135, Final Batch Loss: 0.0032397464383393526\n",
      "Epoch 3799, Loss: 0.00012675727521127556, Final Batch Loss: 1.1447396900621243e-05\n",
      "Epoch 3800, Loss: 0.0004379137244541198, Final Batch Loss: 0.0002183464530389756\n",
      "Epoch 3801, Loss: 0.0003061829920625314, Final Batch Loss: 0.0002224346826551482\n",
      "Epoch 3802, Loss: 0.00036597186590370256, Final Batch Loss: 8.31000397738535e-06\n",
      "Epoch 3803, Loss: 5.1914051255153026e-05, Final Batch Loss: 3.857206320390105e-05\n",
      "Epoch 3804, Loss: 0.0002730728010646999, Final Batch Loss: 0.0001271800574613735\n",
      "Epoch 3805, Loss: 6.228014444786822e-05, Final Batch Loss: 7.824283784430008e-06\n",
      "Epoch 3806, Loss: 0.0036875663136015646, Final Batch Loss: 2.2393352992367e-05\n",
      "Epoch 3807, Loss: 0.0002960843121400103, Final Batch Loss: 7.496512262150645e-05\n",
      "Epoch 3808, Loss: 9.183807560475543e-05, Final Batch Loss: 6.510152161354199e-05\n",
      "Epoch 3809, Loss: 2.068652202069643e-05, Final Batch Loss: 3.680115241877502e-06\n",
      "Epoch 3810, Loss: 0.00020752686396008357, Final Batch Loss: 9.769244934432209e-05\n",
      "Epoch 3811, Loss: 0.00046829347775201313, Final Batch Loss: 1.3972177839605138e-05\n",
      "Epoch 3812, Loss: 0.00045623528421856463, Final Batch Loss: 2.7485803002491593e-05\n",
      "Epoch 3813, Loss: 0.00022809071560914163, Final Batch Loss: 2.3411939764628187e-06\n",
      "Epoch 3814, Loss: 0.00034073987626470625, Final Batch Loss: 0.00021060493600089103\n",
      "Epoch 3815, Loss: 5.506877914740471e-05, Final Batch Loss: 4.847467607760336e-06\n",
      "Epoch 3816, Loss: 0.00201888065203093, Final Batch Loss: 2.575232065282762e-05\n",
      "Epoch 3817, Loss: 9.231553303834517e-05, Final Batch Loss: 7.23159610060975e-05\n",
      "Epoch 3818, Loss: 0.0074356693075969815, Final Batch Loss: 0.006639392115175724\n",
      "Epoch 3819, Loss: 0.00041727631105459295, Final Batch Loss: 0.00039837861550040543\n",
      "Epoch 3820, Loss: 0.002102110011037439, Final Batch Loss: 0.00024783011758700013\n",
      "Epoch 3821, Loss: 8.123633961076848e-05, Final Batch Loss: 1.208401590702124e-05\n",
      "Epoch 3822, Loss: 6.831650534877554e-05, Final Batch Loss: 3.118280801572837e-05\n",
      "Epoch 3823, Loss: 0.000503115399624221, Final Batch Loss: 0.0003603026270866394\n",
      "Epoch 3824, Loss: 4.23814767600561e-05, Final Batch Loss: 2.179133389290655e-06\n",
      "Epoch 3825, Loss: 0.0002857308770671807, Final Batch Loss: 3.5628379464469617e-06\n",
      "Epoch 3826, Loss: 5.7601213484304026e-05, Final Batch Loss: 1.6681620763847604e-05\n",
      "Epoch 3827, Loss: 0.000866576923726825, Final Batch Loss: 0.0008362677763216197\n",
      "Epoch 3828, Loss: 4.190803338133264e-05, Final Batch Loss: 2.3376316676149145e-05\n",
      "Epoch 3829, Loss: 0.00011597693264775444, Final Batch Loss: 2.4219190891017206e-05\n",
      "Epoch 3830, Loss: 5.038485505792778e-05, Final Batch Loss: 2.5031873519765213e-05\n",
      "Epoch 3831, Loss: 7.225777517305687e-05, Final Batch Loss: 3.871646185871214e-06\n",
      "Epoch 3832, Loss: 0.0002912655545515008, Final Batch Loss: 2.648754889378324e-05\n",
      "Epoch 3833, Loss: 0.0007516599434893578, Final Batch Loss: 0.0002640206948854029\n",
      "Epoch 3834, Loss: 0.0014386913098860532, Final Batch Loss: 0.00021409583860076964\n",
      "Epoch 3835, Loss: 0.00031323154689744115, Final Batch Loss: 6.252128514461219e-05\n",
      "Epoch 3836, Loss: 0.0020742164051625878, Final Batch Loss: 0.0004159179807174951\n",
      "Epoch 3837, Loss: 3.944176569348201e-05, Final Batch Loss: 1.3101443983032368e-05\n",
      "Epoch 3838, Loss: 5.7031691540032625e-05, Final Batch Loss: 3.5292596294311807e-05\n",
      "Epoch 3839, Loss: 0.00017458888396504335, Final Batch Loss: 5.149765274836682e-05\n",
      "Epoch 3840, Loss: 0.00014015825217938982, Final Batch Loss: 9.328719897894189e-06\n",
      "Epoch 3841, Loss: 0.00037952505226712674, Final Batch Loss: 0.000153188913827762\n",
      "Epoch 3842, Loss: 6.158632822916843e-05, Final Batch Loss: 4.5032764319330454e-05\n",
      "Epoch 3843, Loss: 6.6042659454979e-05, Final Batch Loss: 1.0279189154971391e-05\n",
      "Epoch 3844, Loss: 6.356213998515159e-05, Final Batch Loss: 2.9431143047986552e-05\n",
      "Epoch 3845, Loss: 0.001024595063427114, Final Batch Loss: 0.0010013007558882236\n",
      "Epoch 3846, Loss: 3.75373856513761e-05, Final Batch Loss: 1.081899790733587e-05\n",
      "Epoch 3847, Loss: 5.32588012447377e-05, Final Batch Loss: 3.346485073052463e-06\n",
      "Epoch 3848, Loss: 3.6442581404116936e-05, Final Batch Loss: 1.703697671473492e-05\n",
      "Epoch 3849, Loss: 2.4111487164191203e-05, Final Batch Loss: 1.7388506421411876e-06\n",
      "Epoch 3850, Loss: 0.0002336125762667507, Final Batch Loss: 0.00011956116213696077\n",
      "Epoch 3851, Loss: 0.00045180946472100914, Final Batch Loss: 0.00017682049656286836\n",
      "Epoch 3852, Loss: 0.00014189217290550005, Final Batch Loss: 1.9815021005342714e-05\n",
      "Epoch 3853, Loss: 4.441702549229376e-05, Final Batch Loss: 2.7965603294433095e-05\n",
      "Epoch 3854, Loss: 0.0002773401101876516, Final Batch Loss: 2.0120107365073636e-05\n",
      "Epoch 3855, Loss: 0.0005433184996945783, Final Batch Loss: 6.957176083233207e-05\n",
      "Epoch 3856, Loss: 0.00014806440776737873, Final Batch Loss: 1.732946293486748e-05\n",
      "Epoch 3857, Loss: 0.00019409422930039, Final Batch Loss: 1.9141951270285062e-05\n",
      "Epoch 3858, Loss: 0.00022305311904347036, Final Batch Loss: 7.939563147374429e-06\n",
      "Epoch 3859, Loss: 0.0002679334538697731, Final Batch Loss: 1.8692382582230493e-05\n",
      "Epoch 3860, Loss: 0.00019598956714617088, Final Batch Loss: 6.0941158153582364e-05\n",
      "Epoch 3861, Loss: 0.000656088137475308, Final Batch Loss: 0.0005900844116695225\n",
      "Epoch 3862, Loss: 0.00012398511535138823, Final Batch Loss: 5.310630876920186e-05\n",
      "Epoch 3863, Loss: 8.335825918948103e-05, Final Batch Loss: 8.055954822339118e-05\n",
      "Epoch 3864, Loss: 0.003949544805436744, Final Batch Loss: 0.003932448569685221\n",
      "Epoch 3865, Loss: 3.581542841857299e-05, Final Batch Loss: 2.88418959826231e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3866, Loss: 6.168773188619525e-05, Final Batch Loss: 7.346212896663928e-06\n",
      "Epoch 3867, Loss: 0.00017586228477739496, Final Batch Loss: 0.00016977108316496015\n",
      "Epoch 3868, Loss: 0.0007902131619630381, Final Batch Loss: 0.00015743255789857358\n",
      "Epoch 3869, Loss: 0.00017259490050491877, Final Batch Loss: 0.00012795717339031398\n",
      "Epoch 3870, Loss: 5.524407242774032e-05, Final Batch Loss: 1.9653271010611206e-06\n",
      "Epoch 3871, Loss: 0.00013709231143366196, Final Batch Loss: 5.2164527915010694e-06\n",
      "Epoch 3872, Loss: 0.0002512872033548774, Final Batch Loss: 2.167372622352559e-05\n",
      "Epoch 3873, Loss: 0.00014892168837832287, Final Batch Loss: 8.286973024951294e-05\n",
      "Epoch 3874, Loss: 4.702365731645841e-05, Final Batch Loss: 2.2835758500150405e-05\n",
      "Epoch 3875, Loss: 0.01598831993760541, Final Batch Loss: 2.618704456835985e-06\n",
      "Epoch 3876, Loss: 2.4460858981001365e-05, Final Batch Loss: 1.0615120800139266e-06\n",
      "Epoch 3877, Loss: 2.2097057808423415e-05, Final Batch Loss: 1.6011199477361515e-05\n",
      "Epoch 3878, Loss: 6.921968770257081e-05, Final Batch Loss: 3.39565622198279e-06\n",
      "Epoch 3879, Loss: 0.0003946722536056768, Final Batch Loss: 0.00037915355642326176\n",
      "Epoch 3880, Loss: 0.0001797426084522158, Final Batch Loss: 0.00013681962445843965\n",
      "Epoch 3881, Loss: 8.975966738944408e-05, Final Batch Loss: 6.847463373560458e-05\n",
      "Epoch 3882, Loss: 0.001495216965849977, Final Batch Loss: 0.00010696611570892856\n",
      "Epoch 3883, Loss: 0.0003098016741205356, Final Batch Loss: 1.4428295799007174e-05\n",
      "Epoch 3884, Loss: 0.0006253943574847654, Final Batch Loss: 0.0005603047902695835\n",
      "Epoch 3885, Loss: 0.00018443083899910562, Final Batch Loss: 3.3269341656705365e-05\n",
      "Epoch 3886, Loss: 0.00021722723613493145, Final Batch Loss: 6.853108061477542e-06\n",
      "Epoch 3887, Loss: 0.0008876585998223163, Final Batch Loss: 6.968985690036789e-05\n",
      "Epoch 3888, Loss: 0.0003253653940191725, Final Batch Loss: 2.564672649896238e-05\n",
      "Epoch 3889, Loss: 0.00014234252012101933, Final Batch Loss: 7.130626181606203e-05\n",
      "Epoch 3890, Loss: 0.0002085627638734877, Final Batch Loss: 8.358176273759454e-05\n",
      "Epoch 3891, Loss: 0.0014652277459390461, Final Batch Loss: 0.0005637099966406822\n",
      "Epoch 3892, Loss: 8.53369365358958e-05, Final Batch Loss: 6.51315858704038e-05\n",
      "Epoch 3893, Loss: 0.0013539194624172524, Final Batch Loss: 0.0001317841961281374\n",
      "Epoch 3894, Loss: 3.9870662476459984e-05, Final Batch Loss: 2.70901364274323e-05\n",
      "Epoch 3895, Loss: 2.2959629859542474e-05, Final Batch Loss: 8.01332134869881e-06\n",
      "Epoch 3896, Loss: 2.4287617179652443e-06, Final Batch Loss: 7.770555612296448e-07\n",
      "Epoch 3897, Loss: 0.0010330448003514903, Final Batch Loss: 0.0010044118389487267\n",
      "Epoch 3898, Loss: 9.127127123065293e-05, Final Batch Loss: 5.891421824344434e-05\n",
      "Epoch 3899, Loss: 0.00010839214155566879, Final Batch Loss: 6.350985495373607e-05\n",
      "Epoch 3900, Loss: 0.0068724927041330375, Final Batch Loss: 0.00010145069245481864\n",
      "Epoch 3901, Loss: 9.380513802170753e-05, Final Batch Loss: 4.163786434219219e-05\n",
      "Epoch 3902, Loss: 9.169544455289724e-05, Final Batch Loss: 6.8486838245007675e-06\n",
      "Epoch 3903, Loss: 0.012972334072401281, Final Batch Loss: 1.5648685803171247e-05\n",
      "Epoch 3904, Loss: 0.0032698552968213335, Final Batch Loss: 3.7764330045320094e-05\n",
      "Epoch 3905, Loss: 5.7210355407733005e-05, Final Batch Loss: 1.5165288459684234e-05\n",
      "Epoch 3906, Loss: 6.928002312633907e-05, Final Batch Loss: 1.4784555787628051e-05\n",
      "Epoch 3907, Loss: 5.014709040551679e-05, Final Batch Loss: 4.650157279684208e-05\n",
      "Epoch 3908, Loss: 0.00043834362713823793, Final Batch Loss: 6.1744167396682315e-06\n",
      "Epoch 3909, Loss: 0.0003768379956454737, Final Batch Loss: 1.3886134183849208e-05\n",
      "Epoch 3910, Loss: 0.00011144517884531524, Final Batch Loss: 9.03481341083534e-05\n",
      "Epoch 3911, Loss: 0.00018955930863739923, Final Batch Loss: 0.0001278755080420524\n",
      "Epoch 3912, Loss: 0.00014545683370670304, Final Batch Loss: 3.5468423448037356e-05\n",
      "Epoch 3913, Loss: 0.00014820442811469547, Final Batch Loss: 5.3112842579139397e-05\n",
      "Epoch 3914, Loss: 0.00010618689475450083, Final Batch Loss: 0.00010095000470755622\n",
      "Epoch 3915, Loss: 0.00014733353827978135, Final Batch Loss: 6.192387900227914e-06\n",
      "Epoch 3916, Loss: 1.020567742671119e-05, Final Batch Loss: 5.913166205573361e-06\n",
      "Epoch 3917, Loss: 0.0028805529873352498, Final Batch Loss: 3.224352258257568e-05\n",
      "Epoch 3918, Loss: 8.115264063235372e-05, Final Batch Loss: 1.7575250240042806e-05\n",
      "Epoch 3919, Loss: 0.0012368507232167758, Final Batch Loss: 0.0012201032368466258\n",
      "Epoch 3920, Loss: 8.300576337205712e-05, Final Batch Loss: 2.2159207219374366e-05\n",
      "Epoch 3921, Loss: 7.099401227605995e-05, Final Batch Loss: 1.837671698012855e-05\n",
      "Epoch 3922, Loss: 9.968975200536079e-05, Final Batch Loss: 5.732219051424181e-06\n",
      "Epoch 3923, Loss: 8.698788587935269e-05, Final Batch Loss: 7.30411265976727e-05\n",
      "Epoch 3924, Loss: 9.30292304701652e-05, Final Batch Loss: 1.013585119835625e-06\n",
      "Epoch 3925, Loss: 2.332589792786166e-05, Final Batch Loss: 8.97066365723731e-06\n",
      "Epoch 3926, Loss: 0.0004718724376289174, Final Batch Loss: 0.0003480300947558135\n",
      "Epoch 3927, Loss: 6.823515832365956e-05, Final Batch Loss: 4.14319547417108e-05\n",
      "Epoch 3928, Loss: 0.0031217511650538654, Final Batch Loss: 0.003118881257250905\n",
      "Epoch 3929, Loss: 0.0020736348451464437, Final Batch Loss: 0.00202661263756454\n",
      "Epoch 3930, Loss: 0.0002324604312207157, Final Batch Loss: 9.978131174648297e-07\n",
      "Epoch 3931, Loss: 0.0011411074856368941, Final Batch Loss: 1.3747097000305075e-05\n",
      "Epoch 3932, Loss: 0.00012820040683436673, Final Batch Loss: 1.997656909225043e-05\n",
      "Epoch 3933, Loss: 0.0007479871710529551, Final Batch Loss: 0.000224980860366486\n",
      "Epoch 3934, Loss: 0.00020190572013234487, Final Batch Loss: 1.0434035175421741e-05\n",
      "Epoch 3935, Loss: 0.00011711238676070934, Final Batch Loss: 9.994705578719731e-06\n",
      "Epoch 3936, Loss: 0.00013439685972116422, Final Batch Loss: 2.085820415231865e-05\n",
      "Epoch 3937, Loss: 0.001087048090994358, Final Batch Loss: 0.00011070823529735208\n",
      "Epoch 3938, Loss: 0.0003389984135537816, Final Batch Loss: 7.37382788429386e-06\n",
      "Epoch 3939, Loss: 4.5579276047647e-05, Final Batch Loss: 3.221907900297083e-05\n",
      "Epoch 3940, Loss: 0.00012227814659127034, Final Batch Loss: 0.00010805423517012969\n",
      "Epoch 3941, Loss: 4.9474464503873605e-05, Final Batch Loss: 4.086854460183531e-05\n",
      "Epoch 3942, Loss: 0.0002225929911219282, Final Batch Loss: 4.0471477404935285e-06\n",
      "Epoch 3943, Loss: 0.00011299005927867256, Final Batch Loss: 9.159974433714524e-05\n",
      "Epoch 3944, Loss: 0.00019872256962116808, Final Batch Loss: 9.984957432607189e-05\n",
      "Epoch 3945, Loss: 0.001693850601441227, Final Batch Loss: 0.00021022137661930174\n",
      "Epoch 3946, Loss: 0.004368153458926827, Final Batch Loss: 0.004272501915693283\n",
      "Epoch 3947, Loss: 0.00023083010455593467, Final Batch Loss: 0.00013445546210277826\n",
      "Epoch 3948, Loss: 0.0002545428469602484, Final Batch Loss: 0.00023014185717329383\n",
      "Epoch 3949, Loss: 8.009292787392042e-05, Final Batch Loss: 7.882839418016374e-05\n",
      "Epoch 3950, Loss: 5.9500594943528995e-05, Final Batch Loss: 2.0720490283565596e-05\n",
      "Epoch 3951, Loss: 2.12947472846281e-05, Final Batch Loss: 1.929234895214904e-05\n",
      "Epoch 3952, Loss: 0.0007854157374822535, Final Batch Loss: 0.000742717063985765\n",
      "Epoch 3953, Loss: 0.000211507584026549, Final Batch Loss: 0.00018094487313646823\n",
      "Epoch 3954, Loss: 7.839646184493176e-05, Final Batch Loss: 1.454352400287462e-06\n",
      "Epoch 3955, Loss: 6.615084021177609e-05, Final Batch Loss: 5.844207771588117e-05\n",
      "Epoch 3956, Loss: 0.0095246675900853, Final Batch Loss: 0.00949772447347641\n",
      "Epoch 3957, Loss: 0.0005481063708430156, Final Batch Loss: 0.0004768759827129543\n",
      "Epoch 3958, Loss: 8.752360372454859e-05, Final Batch Loss: 4.485694444156252e-05\n",
      "Epoch 3959, Loss: 7.68894224165706e-05, Final Batch Loss: 5.1954535592813045e-05\n",
      "Epoch 3960, Loss: 7.824044041626621e-05, Final Batch Loss: 5.58912506676279e-05\n",
      "Epoch 3961, Loss: 0.0007586489591631107, Final Batch Loss: 2.3646563931833953e-05\n",
      "Epoch 3962, Loss: 0.00042299610504414886, Final Batch Loss: 0.0001900003117043525\n",
      "Epoch 3963, Loss: 0.00024850777663232293, Final Batch Loss: 1.7870528608909808e-05\n",
      "Epoch 3964, Loss: 0.0004071949243780182, Final Batch Loss: 6.427018206522916e-07\n",
      "Epoch 3965, Loss: 0.0006534811982419342, Final Batch Loss: 0.00021929587819613516\n",
      "Epoch 3966, Loss: 0.0010411533419301122, Final Batch Loss: 0.001040362287312746\n",
      "Epoch 3967, Loss: 0.000152159597746504, Final Batch Loss: 1.2864590644312557e-05\n",
      "Epoch 3968, Loss: 0.000862674694872112, Final Batch Loss: 8.056429578573443e-06\n",
      "Epoch 3969, Loss: 0.0004683407792072103, Final Batch Loss: 0.00046553771244361997\n",
      "Epoch 3970, Loss: 0.0006496120768133551, Final Batch Loss: 0.0004937109770253301\n",
      "Epoch 3971, Loss: 0.0001297953508583305, Final Batch Loss: 3.874368758260971e-06\n",
      "Epoch 3972, Loss: 2.5050208932952955e-05, Final Batch Loss: 1.1681877367664129e-05\n",
      "Epoch 3973, Loss: 7.4406477779120905e-06, Final Batch Loss: 3.7253778373269597e-06\n",
      "Epoch 3974, Loss: 7.824593194527552e-05, Final Batch Loss: 2.804403629852459e-05\n",
      "Epoch 3975, Loss: 7.85988197549159e-05, Final Batch Loss: 7.685990567551926e-05\n",
      "Epoch 3976, Loss: 0.00011747410644602496, Final Batch Loss: 1.4102715795161203e-06\n",
      "Epoch 3977, Loss: 9.027505893755006e-05, Final Batch Loss: 4.454069312487263e-06\n",
      "Epoch 3978, Loss: 2.81856782748946e-05, Final Batch Loss: 3.1262361517292447e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3979, Loss: 0.00012182302725705085, Final Batch Loss: 1.1974824701610487e-05\n",
      "Epoch 3980, Loss: 2.203493158958736e-05, Final Batch Loss: 1.629856342333369e-05\n",
      "Epoch 3981, Loss: 0.0027691046707332134, Final Batch Loss: 0.0006758507806807756\n",
      "Epoch 3982, Loss: 0.00013712248437514063, Final Batch Loss: 5.4328756959876046e-06\n",
      "Epoch 3983, Loss: 4.605279855240951e-06, Final Batch Loss: 2.762457597782486e-06\n",
      "Epoch 3984, Loss: 3.991832090832759e-05, Final Batch Loss: 1.440633786842227e-05\n",
      "Epoch 3985, Loss: 1.6400739241362317e-05, Final Batch Loss: 2.976184532599291e-06\n",
      "Epoch 3986, Loss: 7.1508032760903e-05, Final Batch Loss: 6.43927269265987e-05\n",
      "Epoch 3987, Loss: 0.00016941364447120577, Final Batch Loss: 0.00012016771506750956\n",
      "Epoch 3988, Loss: 0.00013273784861667082, Final Batch Loss: 3.652557643363252e-05\n",
      "Epoch 3989, Loss: 2.7209192921873182e-05, Final Batch Loss: 4.285526301828213e-06\n",
      "Epoch 3990, Loss: 4.8421024075651076e-05, Final Batch Loss: 7.451561941707041e-06\n",
      "Epoch 3991, Loss: 0.00062455788315674, Final Batch Loss: 0.0006214192253537476\n",
      "Epoch 3992, Loss: 1.186234794658958e-05, Final Batch Loss: 6.980044872761937e-06\n",
      "Epoch 3993, Loss: 7.195295620476827e-05, Final Batch Loss: 4.70678205601871e-05\n",
      "Epoch 3994, Loss: 0.0003376463009772124, Final Batch Loss: 0.0003280503151472658\n",
      "Epoch 3995, Loss: 8.289450852316804e-05, Final Batch Loss: 1.9301241991342977e-05\n",
      "Epoch 3996, Loss: 1.9173835426045116e-05, Final Batch Loss: 1.2703735592367593e-05\n",
      "Epoch 3997, Loss: 0.003143067689961754, Final Batch Loss: 8.519201946910471e-05\n",
      "Epoch 3998, Loss: 0.00010562441843831039, Final Batch Loss: 2.2697388430970022e-06\n",
      "Epoch 3999, Loss: 0.00021903332617512206, Final Batch Loss: 0.00020987579773645848\n",
      "Epoch 4000, Loss: 0.0005768483169958927, Final Batch Loss: 0.00048139257705770433\n",
      "Epoch 4001, Loss: 0.0013144492877472658, Final Batch Loss: 1.9033486751141027e-05\n",
      "Epoch 4002, Loss: 5.765610148955602e-05, Final Batch Loss: 1.668199365667533e-05\n",
      "Epoch 4003, Loss: 0.0006216129258973524, Final Batch Loss: 0.0003881485899910331\n",
      "Epoch 4004, Loss: 7.543908122897847e-05, Final Batch Loss: 1.1847124369523954e-05\n",
      "Epoch 4005, Loss: 9.546594895937233e-06, Final Batch Loss: 9.229978786606807e-06\n",
      "Epoch 4006, Loss: 0.0025110276146733668, Final Batch Loss: 0.0024756903294473886\n",
      "Epoch 4007, Loss: 0.0005392466555349529, Final Batch Loss: 0.0002278689353261143\n",
      "Epoch 4008, Loss: 1.3845592320649303e-05, Final Batch Loss: 1.2134431926824618e-05\n",
      "Epoch 4009, Loss: 0.00021396093507064506, Final Batch Loss: 0.00015079353761393577\n",
      "Epoch 4010, Loss: 8.430917660007253e-05, Final Batch Loss: 6.111222319304943e-05\n",
      "Epoch 4011, Loss: 7.785668640281074e-05, Final Batch Loss: 1.6452318959636614e-05\n",
      "Epoch 4012, Loss: 8.305363371619023e-05, Final Batch Loss: 3.27101479342673e-05\n",
      "Epoch 4013, Loss: 0.0004883021028945222, Final Batch Loss: 0.00019325710309203714\n",
      "Epoch 4014, Loss: 0.0007484163234039443, Final Batch Loss: 0.0007282084552571177\n",
      "Epoch 4015, Loss: 0.0002253454804304056, Final Batch Loss: 0.00014890238526277244\n",
      "Epoch 4016, Loss: 4.12306659427486e-05, Final Batch Loss: 1.3938666825197288e-06\n",
      "Epoch 4017, Loss: 4.414055365487002e-05, Final Batch Loss: 2.6286446882295422e-05\n",
      "Epoch 4018, Loss: 0.0023888295763754286, Final Batch Loss: 0.002371473703533411\n",
      "Epoch 4019, Loss: 1.1972462289122632e-05, Final Batch Loss: 9.727138603921048e-06\n",
      "Epoch 4020, Loss: 9.74666622823861e-05, Final Batch Loss: 9.08414731384255e-05\n",
      "Epoch 4021, Loss: 2.3376526769425254e-05, Final Batch Loss: 7.119192559912335e-06\n",
      "Epoch 4022, Loss: 0.00010921322245849296, Final Batch Loss: 7.32886983314529e-05\n",
      "Epoch 4023, Loss: 0.0038517122229677625, Final Batch Loss: 1.649978366913274e-05\n",
      "Epoch 4024, Loss: 0.00011228946095798165, Final Batch Loss: 7.135271152947098e-05\n",
      "Epoch 4025, Loss: 8.185129263438284e-05, Final Batch Loss: 1.654496736591682e-05\n",
      "Epoch 4026, Loss: 3.260808989580255e-05, Final Batch Loss: 2.534310260671191e-05\n",
      "Epoch 4027, Loss: 8.163996244547889e-05, Final Batch Loss: 3.482529427856207e-05\n",
      "Epoch 4028, Loss: 0.00016395454440498725, Final Batch Loss: 9.048665378941223e-05\n",
      "Epoch 4029, Loss: 0.0002538867065595696, Final Batch Loss: 0.0002367393608437851\n",
      "Epoch 4030, Loss: 0.0004758352545195521, Final Batch Loss: 1.9898827758879634e-06\n",
      "Epoch 4031, Loss: 1.5628242181264795e-05, Final Batch Loss: 1.401567533321213e-05\n",
      "Epoch 4032, Loss: 5.514891199709382e-05, Final Batch Loss: 3.920367089449428e-05\n",
      "Epoch 4033, Loss: 0.00013175800177123165, Final Batch Loss: 4.412692760524806e-06\n",
      "Epoch 4034, Loss: 9.754916027304716e-05, Final Batch Loss: 4.0310875192517415e-05\n",
      "Epoch 4035, Loss: 4.277599509805441e-05, Final Batch Loss: 1.7943499187822454e-05\n",
      "Epoch 4036, Loss: 1.9952841171289037e-05, Final Batch Loss: 1.871740460046567e-05\n",
      "Epoch 4037, Loss: 0.00011381702643120661, Final Batch Loss: 8.846666605677456e-05\n",
      "Epoch 4038, Loss: 3.087474351559649e-05, Final Batch Loss: 4.3480554268171545e-06\n",
      "Epoch 4039, Loss: 1.867347646111739e-05, Final Batch Loss: 1.3338032658793963e-05\n",
      "Epoch 4040, Loss: 1.105016247038293e-05, Final Batch Loss: 1.0595740604912862e-05\n",
      "Epoch 4041, Loss: 0.00011015132599823119, Final Batch Loss: 2.8210413347551366e-06\n",
      "Epoch 4042, Loss: 6.721865429426543e-05, Final Batch Loss: 3.267399733886123e-05\n",
      "Epoch 4043, Loss: 0.0020359723312139977, Final Batch Loss: 1.9581424567149952e-05\n",
      "Epoch 4044, Loss: 1.6049516261773533e-05, Final Batch Loss: 1.820855459300219e-06\n",
      "Epoch 4045, Loss: 0.00047341578465420753, Final Batch Loss: 7.761998858768493e-05\n",
      "Epoch 4046, Loss: 2.219623638666235e-05, Final Batch Loss: 9.261824743589386e-06\n",
      "Epoch 4047, Loss: 0.003162783465540997, Final Batch Loss: 4.133570200792747e-06\n",
      "Epoch 4048, Loss: 0.00010540175480855396, Final Batch Loss: 9.582857273926493e-06\n",
      "Epoch 4049, Loss: 0.0001948260123754153, Final Batch Loss: 1.9560708096832968e-05\n",
      "Epoch 4050, Loss: 0.00013381437747739255, Final Batch Loss: 7.216323137981817e-05\n",
      "Epoch 4051, Loss: 3.343862590554636e-05, Final Batch Loss: 2.348496491322294e-05\n",
      "Epoch 4052, Loss: 0.0005231301366848129, Final Batch Loss: 0.0005219609593041241\n",
      "Epoch 4053, Loss: 9.348606454295805e-06, Final Batch Loss: 4.052545591548551e-06\n",
      "Epoch 4054, Loss: 2.8989799830014817e-05, Final Batch Loss: 2.212481376773212e-05\n",
      "Epoch 4055, Loss: 7.914696811894828e-05, Final Batch Loss: 1.1157424069097033e-06\n",
      "Epoch 4056, Loss: 0.003681878911379499, Final Batch Loss: 0.003680560039356351\n",
      "Epoch 4057, Loss: 0.00030595580756198615, Final Batch Loss: 0.00013776271953247488\n",
      "Epoch 4058, Loss: 5.928864084125962e-06, Final Batch Loss: 4.739216819871217e-06\n",
      "Epoch 4059, Loss: 1.0845578657381338e-06, Final Batch Loss: 1.866977044073792e-07\n",
      "Epoch 4060, Loss: 0.000781331786129158, Final Batch Loss: 0.0007132647442631423\n",
      "Epoch 4061, Loss: 0.004870724136708304, Final Batch Loss: 0.00013027872773818672\n",
      "Epoch 4062, Loss: 2.7241815587331075e-05, Final Batch Loss: 2.482572199369315e-05\n",
      "Epoch 4063, Loss: 9.236434652848402e-05, Final Batch Loss: 1.0097516678797547e-05\n",
      "Epoch 4064, Loss: 4.594663505486096e-05, Final Batch Loss: 4.507546236709459e-06\n",
      "Epoch 4065, Loss: 0.0001619082540855743, Final Batch Loss: 0.00014583198935724795\n",
      "Epoch 4066, Loss: 3.208656448805414e-05, Final Batch Loss: 2.2597675979341147e-06\n",
      "Epoch 4067, Loss: 8.510733323419117e-06, Final Batch Loss: 6.3689108174003195e-06\n",
      "Epoch 4068, Loss: 4.215845137878205e-06, Final Batch Loss: 1.2103103017579997e-06\n",
      "Epoch 4069, Loss: 0.0002245461886332123, Final Batch Loss: 1.798028620214609e-06\n",
      "Epoch 4070, Loss: 0.00114309269702062, Final Batch Loss: 0.0008253384148702025\n",
      "Epoch 4071, Loss: 0.00015274607949322672, Final Batch Loss: 0.00015059567522257566\n",
      "Epoch 4072, Loss: 0.0033499608598503983, Final Batch Loss: 0.0033391909673810005\n",
      "Epoch 4073, Loss: 8.762032393860864e-06, Final Batch Loss: 3.6684500628325623e-06\n",
      "Epoch 4074, Loss: 7.799342529324349e-05, Final Batch Loss: 6.58893259242177e-05\n",
      "Epoch 4075, Loss: 0.005560581560530409, Final Batch Loss: 0.0055537596344947815\n",
      "Epoch 4076, Loss: 3.883189219777705e-05, Final Batch Loss: 3.20157159876544e-05\n",
      "Epoch 4077, Loss: 0.0004700994904851541, Final Batch Loss: 0.00013373089313972741\n",
      "Epoch 4078, Loss: 0.0001622072741156444, Final Batch Loss: 6.847907206974924e-05\n",
      "Epoch 4079, Loss: 0.00013227730232756585, Final Batch Loss: 9.298358781961724e-05\n",
      "Epoch 4080, Loss: 4.4471009914559545e-06, Final Batch Loss: 2.2061647086957237e-06\n",
      "Epoch 4081, Loss: 4.813471150555415e-06, Final Batch Loss: 2.8520109935925575e-06\n",
      "Epoch 4082, Loss: 0.0006703992821712745, Final Batch Loss: 0.0006477066199295223\n",
      "Epoch 4083, Loss: 0.00019622481386250001, Final Batch Loss: 4.794951109943213e-06\n",
      "Epoch 4084, Loss: 1.828483073040843e-05, Final Batch Loss: 1.4021259630681016e-05\n",
      "Epoch 4085, Loss: 5.4835672926856205e-05, Final Batch Loss: 3.6369761801324785e-05\n",
      "Epoch 4086, Loss: 3.274539324138459e-06, Final Batch Loss: 8.691311563779891e-07\n",
      "Epoch 4087, Loss: 1.5599402559018927e-05, Final Batch Loss: 9.167336429527495e-06\n",
      "Epoch 4088, Loss: 3.513683031997061e-05, Final Batch Loss: 7.106050816219067e-06\n",
      "Epoch 4089, Loss: 0.0017065156916942215, Final Batch Loss: 0.001697438769042492\n",
      "Epoch 4090, Loss: 0.00014410132189368596, Final Batch Loss: 0.00013467435201164335\n",
      "Epoch 4091, Loss: 0.0034315349948883522, Final Batch Loss: 3.17742997140158e-05\n",
      "Epoch 4092, Loss: 0.00011796316289292008, Final Batch Loss: 2.419835482214694e-06\n",
      "Epoch 4093, Loss: 0.00011132955478387885, Final Batch Loss: 0.00010258013207931072\n",
      "Epoch 4094, Loss: 4.014459591417108e-05, Final Batch Loss: 2.1965557607472874e-05\n",
      "Epoch 4095, Loss: 5.49602755199885e-05, Final Batch Loss: 1.0615809515002184e-05\n",
      "Epoch 4096, Loss: 5.209745359024964e-05, Final Batch Loss: 3.62407517968677e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4097, Loss: 0.00018303071556147188, Final Batch Loss: 0.00014787542750127614\n",
      "Epoch 4098, Loss: 5.909469109610654e-06, Final Batch Loss: 2.7489600142871495e-06\n",
      "Epoch 4099, Loss: 8.874110426404513e-05, Final Batch Loss: 6.646061956416816e-05\n",
      "Epoch 4100, Loss: 7.207565431599505e-06, Final Batch Loss: 6.592931185878115e-06\n",
      "Epoch 4101, Loss: 0.00011333098433397026, Final Batch Loss: 9.442001669413003e-07\n",
      "Epoch 4102, Loss: 0.0002254126920888666, Final Batch Loss: 4.9317724915454164e-05\n",
      "Epoch 4103, Loss: 8.68564648044412e-05, Final Batch Loss: 5.336744834494311e-06\n",
      "Epoch 4104, Loss: 5.279806782709784e-05, Final Batch Loss: 1.8832520254363772e-06\n",
      "Epoch 4105, Loss: 0.00035966284121968783, Final Batch Loss: 0.00034563656663522124\n",
      "Epoch 4106, Loss: 0.00017543124022267875, Final Batch Loss: 0.00016965906252153218\n",
      "Epoch 4107, Loss: 0.0009537212488339719, Final Batch Loss: 0.0009507261565886438\n",
      "Epoch 4108, Loss: 1.3226615692474297e-05, Final Batch Loss: 3.1606612083123764e-06\n",
      "Epoch 4109, Loss: 0.0008508237165187893, Final Batch Loss: 3.9154051592049655e-06\n",
      "Epoch 4110, Loss: 0.001191856467130492, Final Batch Loss: 3.7114480164746055e-06\n",
      "Epoch 4111, Loss: 1.762728561516269e-05, Final Batch Loss: 1.1253970114921685e-05\n",
      "Epoch 4112, Loss: 3.2697984352125786e-05, Final Batch Loss: 7.421645932481624e-06\n",
      "Epoch 4113, Loss: 0.00022829482213637675, Final Batch Loss: 0.00022128909768071026\n",
      "Epoch 4114, Loss: 2.9530930532928323e-05, Final Batch Loss: 2.4598099116701633e-05\n",
      "Epoch 4115, Loss: 0.0010158626682823524, Final Batch Loss: 7.889616244938225e-05\n",
      "Epoch 4116, Loss: 1.1469744549685856e-05, Final Batch Loss: 4.986113708582707e-06\n",
      "Epoch 4117, Loss: 0.00023896944048829027, Final Batch Loss: 2.7486080398375634e-06\n",
      "Epoch 4118, Loss: 0.00031151622670222423, Final Batch Loss: 5.845913165103411e-06\n",
      "Epoch 4119, Loss: 1.128433734720602e-05, Final Batch Loss: 1.5143106111281668e-06\n",
      "Epoch 4120, Loss: 1.579524905537255e-05, Final Batch Loss: 4.791790161107201e-06\n",
      "Epoch 4121, Loss: 9.059776402864372e-05, Final Batch Loss: 8.957210229709744e-05\n",
      "Epoch 4122, Loss: 2.2142682610137854e-05, Final Batch Loss: 1.36800108521129e-05\n",
      "Epoch 4123, Loss: 0.0001230437754884406, Final Batch Loss: 1.3162624554752256e-06\n",
      "Epoch 4124, Loss: 9.506478545517894e-05, Final Batch Loss: 8.222033102356363e-06\n",
      "Epoch 4125, Loss: 1.5299177903216332e-05, Final Batch Loss: 3.8433454392361455e-06\n",
      "Epoch 4126, Loss: 0.00015471290635105106, Final Batch Loss: 7.417649158014683e-06\n",
      "Epoch 4127, Loss: 0.0002666106302058324, Final Batch Loss: 1.3496479368768632e-05\n",
      "Epoch 4128, Loss: 2.2335725589073263e-05, Final Batch Loss: 1.4336763342726044e-05\n",
      "Epoch 4129, Loss: 0.001252434383786749, Final Batch Loss: 0.0011605785693973303\n",
      "Epoch 4130, Loss: 0.0003889990625793871, Final Batch Loss: 0.0003836119140032679\n",
      "Epoch 4131, Loss: 0.00010681515414034948, Final Batch Loss: 9.134556603385136e-05\n",
      "Epoch 4132, Loss: 3.054268836422125e-05, Final Batch Loss: 9.805228728509974e-06\n",
      "Epoch 4133, Loss: 2.0234763724147342e-05, Final Batch Loss: 1.382776736136293e-05\n",
      "Epoch 4134, Loss: 7.962241215864196e-05, Final Batch Loss: 5.0615708460099995e-06\n",
      "Epoch 4135, Loss: 2.1163754354347475e-05, Final Batch Loss: 1.4494402421405539e-05\n",
      "Epoch 4136, Loss: 1.9807460830634227e-05, Final Batch Loss: 2.9364523470576387e-06\n",
      "Epoch 4137, Loss: 2.7607900392467855e-05, Final Batch Loss: 2.35819516092306e-05\n",
      "Epoch 4138, Loss: 0.00029208137857494876, Final Batch Loss: 3.6944162275176495e-05\n",
      "Epoch 4139, Loss: 4.154012685830821e-06, Final Batch Loss: 2.148130306522944e-06\n",
      "Epoch 4140, Loss: 0.00036334847459329467, Final Batch Loss: 3.377311031727004e-06\n",
      "Epoch 4141, Loss: 0.0022234401330933906, Final Batch Loss: 0.0022106801625341177\n",
      "Epoch 4142, Loss: 2.4767454419816204e-05, Final Batch Loss: 2.300042069691699e-05\n",
      "Epoch 4143, Loss: 0.00015315671839744027, Final Batch Loss: 1.4172189821692882e-06\n",
      "Epoch 4144, Loss: 4.705948322225595e-05, Final Batch Loss: 1.2966070244146977e-05\n",
      "Epoch 4145, Loss: 0.00010893596481764689, Final Batch Loss: 9.379122639074922e-05\n",
      "Epoch 4146, Loss: 0.00011161225484102033, Final Batch Loss: 8.008865552255884e-05\n",
      "Epoch 4147, Loss: 0.00016518875781912357, Final Batch Loss: 0.00012098719162167981\n",
      "Epoch 4148, Loss: 5.8781009101949167e-05, Final Batch Loss: 5.0082599045708776e-05\n",
      "Epoch 4149, Loss: 3.118985614491976e-05, Final Batch Loss: 4.296001407055883e-06\n",
      "Epoch 4150, Loss: 4.592910045175813e-05, Final Batch Loss: 2.115357892762404e-05\n",
      "Epoch 4151, Loss: 0.007092106877280457, Final Batch Loss: 0.007080800831317902\n",
      "Epoch 4152, Loss: 0.00011552433943506912, Final Batch Loss: 0.00011047060252167284\n",
      "Epoch 4153, Loss: 0.0013214055597927654, Final Batch Loss: 0.0013070113491266966\n",
      "Epoch 4154, Loss: 0.0005112840808578767, Final Batch Loss: 1.0200579708907753e-05\n",
      "Epoch 4155, Loss: 0.0003813495823123958, Final Batch Loss: 4.664554580813274e-06\n",
      "Epoch 4156, Loss: 1.784504456736613e-05, Final Batch Loss: 9.076094102056231e-06\n",
      "Epoch 4157, Loss: 0.00011337872820149641, Final Batch Loss: 9.72901179920882e-05\n",
      "Epoch 4158, Loss: 5.358670250643627e-06, Final Batch Loss: 1.2853463431383716e-06\n",
      "Epoch 4159, Loss: 0.00045303388287720736, Final Batch Loss: 3.7019690353190526e-06\n",
      "Epoch 4160, Loss: 0.00020909105023747543, Final Batch Loss: 1.0368698895035777e-05\n",
      "Epoch 4161, Loss: 0.0002393583577031677, Final Batch Loss: 5.883355242985999e-06\n",
      "Epoch 4162, Loss: 3.3753285947568656e-05, Final Batch Loss: 7.984912144820555e-07\n",
      "Epoch 4163, Loss: 0.0006947764040887705, Final Batch Loss: 0.0006840217974968255\n",
      "Epoch 4164, Loss: 0.000843343797896523, Final Batch Loss: 0.0008184722973965108\n",
      "Epoch 4165, Loss: 5.350883111532312e-05, Final Batch Loss: 8.597604391979985e-06\n",
      "Epoch 4166, Loss: 0.00027942350425291806, Final Batch Loss: 0.00018143336637876928\n",
      "Epoch 4167, Loss: 0.00018535753338255745, Final Batch Loss: 0.00018347514560446143\n",
      "Epoch 4168, Loss: 0.00011327385527692968, Final Batch Loss: 8.96766232472146e-06\n",
      "Epoch 4169, Loss: 3.241563035771833e-05, Final Batch Loss: 2.961704012705013e-05\n",
      "Epoch 4170, Loss: 3.193124211975373e-05, Final Batch Loss: 8.379720384255052e-06\n",
      "Epoch 4171, Loss: 0.0001873184037322062, Final Batch Loss: 7.7120885180193e-06\n",
      "Epoch 4172, Loss: 0.0006748821888322709, Final Batch Loss: 1.3628143278765492e-05\n",
      "Epoch 4173, Loss: 2.4194753450501594e-05, Final Batch Loss: 2.709376303755562e-06\n",
      "Epoch 4174, Loss: 2.1262894733808935e-05, Final Batch Loss: 9.540017344988883e-06\n",
      "Epoch 4175, Loss: 1.578690421411011e-05, Final Batch Loss: 1.162421312983497e-06\n",
      "Epoch 4176, Loss: 3.0313137813209323e-05, Final Batch Loss: 2.1097107492096256e-06\n",
      "Epoch 4177, Loss: 0.008759440737776458, Final Batch Loss: 0.000542568857781589\n",
      "Epoch 4178, Loss: 0.00030284046079032123, Final Batch Loss: 0.00012825427984353155\n",
      "Epoch 4179, Loss: 7.19885720172897e-05, Final Batch Loss: 3.558001480996609e-05\n",
      "Epoch 4180, Loss: 3.8561547626159154e-05, Final Batch Loss: 1.9557206542231143e-05\n",
      "Epoch 4181, Loss: 0.0006732561450917274, Final Batch Loss: 9.648627019487321e-05\n",
      "Epoch 4182, Loss: 1.7214408671861747e-05, Final Batch Loss: 4.681263362726895e-06\n",
      "Epoch 4183, Loss: 0.014597446775042044, Final Batch Loss: 7.978757821547333e-06\n",
      "Epoch 4184, Loss: 0.006538771260238718, Final Batch Loss: 0.006454689893871546\n",
      "Epoch 4185, Loss: 0.0003714372287504375, Final Batch Loss: 1.830994733609259e-05\n",
      "Epoch 4186, Loss: 0.00015888739744696068, Final Batch Loss: 7.188396011770237e-06\n",
      "Epoch 4187, Loss: 0.0003106300473518786, Final Batch Loss: 9.38642642722698e-06\n",
      "Epoch 4188, Loss: 3.6295439258537954e-05, Final Batch Loss: 3.832008133031195e-06\n",
      "Epoch 4189, Loss: 9.062345043275855e-06, Final Batch Loss: 1.8303514934814302e-06\n",
      "Epoch 4190, Loss: 0.0001350509119220078, Final Batch Loss: 3.8027028494980186e-05\n",
      "Epoch 4191, Loss: 0.0003945764728996437, Final Batch Loss: 5.3172912885202095e-05\n",
      "Epoch 4192, Loss: 5.643380245601293e-05, Final Batch Loss: 1.75885852513602e-05\n",
      "Epoch 4193, Loss: 0.0003972047234128695, Final Batch Loss: 3.759907485800795e-05\n",
      "Epoch 4194, Loss: 9.810568553803023e-05, Final Batch Loss: 2.307735485373996e-06\n",
      "Epoch 4195, Loss: 0.00014473743976850528, Final Batch Loss: 0.00011566790635697544\n",
      "Epoch 4196, Loss: 0.0002740815098150051, Final Batch Loss: 0.0002615581324789673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4197, Loss: 0.001681369562220425, Final Batch Loss: 2.9333825750654796e-06\n",
      "Epoch 4198, Loss: 5.714896906283684e-05, Final Batch Loss: 3.753517376026139e-05\n",
      "Epoch 4199, Loss: 1.94023132280563e-05, Final Batch Loss: 8.641660315333866e-06\n",
      "Epoch 4200, Loss: 8.620501375844469e-05, Final Batch Loss: 4.03031208406901e-06\n",
      "Epoch 4201, Loss: 4.0545691263105255e-05, Final Batch Loss: 2.7136569769936614e-05\n",
      "Epoch 4202, Loss: 0.00018212836312159197, Final Batch Loss: 8.487692866765428e-06\n",
      "Epoch 4203, Loss: 4.4542104660649784e-05, Final Batch Loss: 5.035539288655855e-06\n",
      "Epoch 4204, Loss: 0.0003015682814293541, Final Batch Loss: 2.824262628564611e-05\n",
      "Epoch 4205, Loss: 0.0005567438429352478, Final Batch Loss: 0.0005545171443372965\n",
      "Epoch 4206, Loss: 9.29715133679565e-06, Final Batch Loss: 6.176338501973078e-06\n",
      "Epoch 4207, Loss: 0.00013922907237429172, Final Batch Loss: 6.97085342835635e-05\n",
      "Epoch 4208, Loss: 0.0005619741350528784, Final Batch Loss: 7.51428960938938e-05\n",
      "Epoch 4209, Loss: 3.609545066751707e-05, Final Batch Loss: 4.503415027556912e-07\n",
      "Epoch 4210, Loss: 0.0003171101748193905, Final Batch Loss: 5.021448032493936e-06\n",
      "Epoch 4211, Loss: 0.00026272706236341037, Final Batch Loss: 1.874234658316709e-05\n",
      "Epoch 4212, Loss: 7.5479442784853745e-06, Final Batch Loss: 6.1652003751078155e-06\n",
      "Epoch 4213, Loss: 0.00011456668926257407, Final Batch Loss: 0.00010717809345806018\n",
      "Epoch 4214, Loss: 2.6542949854047038e-05, Final Batch Loss: 1.7128722902270965e-05\n",
      "Epoch 4215, Loss: 8.4265095210867e-05, Final Batch Loss: 3.601793650886975e-05\n",
      "Epoch 4216, Loss: 9.154190593108069e-06, Final Batch Loss: 5.220106231718091e-06\n",
      "Epoch 4217, Loss: 4.864720904151909e-05, Final Batch Loss: 2.69638385361759e-05\n",
      "Epoch 4218, Loss: 2.147051361589547e-05, Final Batch Loss: 1.6404877669629059e-06\n",
      "Epoch 4219, Loss: 0.00033431785232096445, Final Batch Loss: 0.0003190070856362581\n",
      "Epoch 4220, Loss: 0.00014545811609423254, Final Batch Loss: 2.1397276213974692e-05\n",
      "Epoch 4221, Loss: 0.0014248756997403689, Final Batch Loss: 4.907378752250224e-06\n",
      "Epoch 4222, Loss: 0.00012527042053989135, Final Batch Loss: 3.517670484143309e-05\n",
      "Epoch 4223, Loss: 4.7295231524913106e-05, Final Batch Loss: 3.395384919713251e-05\n",
      "Epoch 4224, Loss: 2.7539034590517986e-06, Final Batch Loss: 9.195973689202219e-07\n",
      "Epoch 4225, Loss: 3.152334898004483e-05, Final Batch Loss: 3.1896622658678098e-06\n",
      "Epoch 4226, Loss: 0.0002911521660280414, Final Batch Loss: 2.7279813366476446e-05\n",
      "Epoch 4227, Loss: 1.39169096655678e-05, Final Batch Loss: 1.1288504538242705e-05\n",
      "Epoch 4228, Loss: 0.00012353338752291165, Final Batch Loss: 8.960529521573335e-05\n",
      "Epoch 4229, Loss: 0.0023696057014603866, Final Batch Loss: 6.579559340025298e-06\n",
      "Epoch 4230, Loss: 0.0026453245955053717, Final Batch Loss: 0.0025448924861848354\n",
      "Epoch 4231, Loss: 2.3790479644958396e-05, Final Batch Loss: 1.5759089365019463e-05\n",
      "Epoch 4232, Loss: 0.00015385567712655757, Final Batch Loss: 0.00013524104724638164\n",
      "Epoch 4233, Loss: 0.00018409880885883467, Final Batch Loss: 5.189312105358113e-06\n",
      "Epoch 4234, Loss: 0.0004557501110866724, Final Batch Loss: 0.00045047796447761357\n",
      "Epoch 4235, Loss: 8.446918036497664e-05, Final Batch Loss: 1.5616422388120554e-05\n",
      "Epoch 4236, Loss: 0.0003845169267151505, Final Batch Loss: 0.00030769791919738054\n",
      "Epoch 4237, Loss: 0.0031727109994790226, Final Batch Loss: 5.450328444567276e-06\n",
      "Epoch 4238, Loss: 8.970531052909791e-05, Final Batch Loss: 6.037825733073987e-05\n",
      "Epoch 4239, Loss: 5.0803944759536535e-05, Final Batch Loss: 3.949886013288051e-05\n",
      "Epoch 4240, Loss: 0.00010295856679931603, Final Batch Loss: 1.6304160226354725e-06\n",
      "Epoch 4241, Loss: 0.0003405991828913102, Final Batch Loss: 0.00032123096752911806\n",
      "Epoch 4242, Loss: 3.0467908914033615e-05, Final Batch Loss: 1.888975134534121e-06\n",
      "Epoch 4243, Loss: 0.00017164807923109038, Final Batch Loss: 3.8905882320250385e-06\n",
      "Epoch 4244, Loss: 0.001203203632030636, Final Batch Loss: 0.00042716471944004297\n",
      "Epoch 4245, Loss: 0.0013942757359473035, Final Batch Loss: 9.601078636478633e-05\n",
      "Epoch 4246, Loss: 0.02161988010288951, Final Batch Loss: 8.451718258584151e-07\n",
      "Epoch 4247, Loss: 1.097247923098621e-05, Final Batch Loss: 6.007390311424388e-06\n",
      "Epoch 4248, Loss: 0.00010355417180107906, Final Batch Loss: 7.292794180102646e-06\n",
      "Epoch 4249, Loss: 8.226243880926631e-05, Final Batch Loss: 5.6402412155875936e-05\n",
      "Epoch 4250, Loss: 0.0001841687444539275, Final Batch Loss: 4.797521614818834e-05\n",
      "Epoch 4251, Loss: 0.00013200013199821115, Final Batch Loss: 3.38996178470552e-05\n",
      "Epoch 4252, Loss: 0.005895551119465381, Final Batch Loss: 6.627553375437856e-05\n",
      "Epoch 4253, Loss: 0.00012148243695264682, Final Batch Loss: 6.799789116485044e-05\n",
      "Epoch 4254, Loss: 0.00020484249125729548, Final Batch Loss: 8.345084097527433e-06\n",
      "Epoch 4255, Loss: 0.0029300771420821548, Final Batch Loss: 0.0017158514820039272\n",
      "Epoch 4256, Loss: 2.6155541945627192e-05, Final Batch Loss: 2.033302553172689e-05\n",
      "Epoch 4257, Loss: 0.015703055962148937, Final Batch Loss: 3.1049839890329167e-06\n",
      "Epoch 4258, Loss: 0.0004890035925200209, Final Batch Loss: 0.0001089905999833718\n",
      "Epoch 4259, Loss: 0.0016803351463750005, Final Batch Loss: 0.0005921288393437862\n",
      "Epoch 4260, Loss: 2.0555862647597678e-05, Final Batch Loss: 9.352336746815126e-06\n",
      "Epoch 4261, Loss: 0.04302756581455469, Final Batch Loss: 0.013645908795297146\n",
      "Epoch 4262, Loss: 0.002747533486399334, Final Batch Loss: 2.420099190203473e-05\n",
      "Epoch 4263, Loss: 4.618889238372503e-05, Final Batch Loss: 3.0563462587451795e-06\n",
      "Epoch 4264, Loss: 0.0003182222935720347, Final Batch Loss: 0.00011053685011574998\n",
      "Epoch 4265, Loss: 0.02944417451726622, Final Batch Loss: 0.029423009604215622\n",
      "Epoch 4266, Loss: 0.013176700231269933, Final Batch Loss: 0.00013027912063989788\n",
      "Epoch 4267, Loss: 0.0013241810665931553, Final Batch Loss: 0.0009544138447381556\n",
      "Epoch 4268, Loss: 0.0004794663755092188, Final Batch Loss: 1.1994451597274747e-05\n",
      "Epoch 4269, Loss: 0.0005319711926858872, Final Batch Loss: 0.000290468247840181\n",
      "Epoch 4270, Loss: 0.0004423466234584339, Final Batch Loss: 0.0003564543731044978\n",
      "Epoch 4271, Loss: 0.014667204333818518, Final Batch Loss: 0.00013176047650631517\n",
      "Epoch 4272, Loss: 0.00011380036085029133, Final Batch Loss: 3.556567753548734e-05\n",
      "Epoch 4273, Loss: 0.0005547759210458025, Final Batch Loss: 0.0005003880942240357\n",
      "Epoch 4274, Loss: 0.003216526342839643, Final Batch Loss: 0.0032098619267344475\n",
      "Epoch 4275, Loss: 0.0004922092512060772, Final Batch Loss: 0.0004810142854694277\n",
      "Epoch 4276, Loss: 3.512340208544629e-05, Final Batch Loss: 1.203171723318519e-05\n",
      "Epoch 4277, Loss: 4.223625910526607e-05, Final Batch Loss: 1.6838872397784144e-05\n",
      "Epoch 4278, Loss: 0.004861445500864647, Final Batch Loss: 0.00010411148832645267\n",
      "Epoch 4279, Loss: 0.0003070298771490343, Final Batch Loss: 0.0001963064423762262\n",
      "Epoch 4280, Loss: 0.0005078095418866724, Final Batch Loss: 0.0004356352146714926\n",
      "Epoch 4281, Loss: 0.00022817208810010925, Final Batch Loss: 0.0002109373890561983\n",
      "Epoch 4282, Loss: 3.377173561602831e-05, Final Batch Loss: 8.96437450137455e-06\n",
      "Epoch 4283, Loss: 0.00025882540830934886, Final Batch Loss: 1.49166244227672e-05\n",
      "Epoch 4284, Loss: 0.00015641281061107293, Final Batch Loss: 3.124512295471504e-05\n",
      "Epoch 4285, Loss: 0.00042216633300995454, Final Batch Loss: 0.0003063804761040956\n",
      "Epoch 4286, Loss: 0.0003633790256571956, Final Batch Loss: 0.0002579783322289586\n",
      "Epoch 4287, Loss: 6.953081265237415e-05, Final Batch Loss: 8.353687917406205e-06\n",
      "Epoch 4288, Loss: 0.0003912014508387074, Final Batch Loss: 0.00030047609470784664\n",
      "Epoch 4289, Loss: 0.008219077466492308, Final Batch Loss: 0.00817888230085373\n",
      "Epoch 4290, Loss: 0.0001878216462500859, Final Batch Loss: 4.770348095917143e-05\n",
      "Epoch 4291, Loss: 2.9011789592914283e-05, Final Batch Loss: 1.1258694939897396e-05\n",
      "Epoch 4292, Loss: 0.0005715978622902185, Final Batch Loss: 0.0001762051833793521\n",
      "Epoch 4293, Loss: 0.0001819468816393055, Final Batch Loss: 0.00010773133544716984\n",
      "Epoch 4294, Loss: 0.0012474975010263734, Final Batch Loss: 0.001231687841936946\n",
      "Epoch 4295, Loss: 0.00015311869901779573, Final Batch Loss: 1.4024537449586205e-05\n",
      "Epoch 4296, Loss: 0.0009530399111099541, Final Batch Loss: 0.0008175480179488659\n",
      "Epoch 4297, Loss: 0.00012817040806112345, Final Batch Loss: 1.6079005945357494e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4298, Loss: 0.0003916091955034062, Final Batch Loss: 0.0001746953057590872\n",
      "Epoch 4299, Loss: 0.0004523131938185543, Final Batch Loss: 4.788261139765382e-05\n",
      "Epoch 4300, Loss: 7.57354027882684e-05, Final Batch Loss: 4.505111792241223e-05\n",
      "Epoch 4301, Loss: 0.0004070317663718015, Final Batch Loss: 0.00027819283423013985\n",
      "Epoch 4302, Loss: 6.0560982092283666e-05, Final Batch Loss: 4.3791369535028934e-05\n",
      "Epoch 4303, Loss: 0.004011194119811989, Final Batch Loss: 3.9946186007000506e-05\n",
      "Epoch 4304, Loss: 0.0001921723196574021, Final Batch Loss: 3.219706195523031e-05\n",
      "Epoch 4305, Loss: 0.00010188297801505541, Final Batch Loss: 1.4176751392369624e-05\n",
      "Epoch 4306, Loss: 0.00011362283839844167, Final Batch Loss: 3.794574149651453e-05\n",
      "Epoch 4307, Loss: 2.427067647658987e-05, Final Batch Loss: 1.6009294995456003e-05\n",
      "Epoch 4308, Loss: 0.0004779308073921129, Final Batch Loss: 0.0003649696009233594\n",
      "Epoch 4309, Loss: 0.0003594732697820291, Final Batch Loss: 0.0001378479355480522\n",
      "Epoch 4310, Loss: 0.0001268266059923917, Final Batch Loss: 3.647060657385737e-05\n",
      "Epoch 4311, Loss: 7.888945219747256e-05, Final Batch Loss: 2.810562182276044e-05\n",
      "Epoch 4312, Loss: 0.002085157495457679, Final Batch Loss: 0.0015897168777883053\n",
      "Epoch 4313, Loss: 4.37112230429193e-05, Final Batch Loss: 3.226389526389539e-05\n",
      "Epoch 4314, Loss: 7.417869528580923e-05, Final Batch Loss: 4.3995540181640536e-05\n",
      "Epoch 4315, Loss: 0.0003255747797084041, Final Batch Loss: 9.555619180900976e-05\n",
      "Epoch 4316, Loss: 0.00031324980227509513, Final Batch Loss: 0.0002728506806306541\n",
      "Epoch 4317, Loss: 8.629959029349266e-05, Final Batch Loss: 8.315316335938405e-06\n",
      "Epoch 4318, Loss: 0.0001770572894201905, Final Batch Loss: 6.7801488512486685e-06\n",
      "Epoch 4319, Loss: 0.0005656806461047381, Final Batch Loss: 6.940020830370486e-05\n",
      "Epoch 4320, Loss: 0.00011311167963867774, Final Batch Loss: 1.0097514859808143e-05\n",
      "Epoch 4321, Loss: 7.654603564333229e-06, Final Batch Loss: 6.398168352461653e-06\n",
      "Epoch 4322, Loss: 6.389651980498456e-05, Final Batch Loss: 6.894561465742299e-06\n",
      "Epoch 4323, Loss: 0.00014125873713055626, Final Batch Loss: 3.175539313815534e-05\n",
      "Epoch 4324, Loss: 0.00014065214145375649, Final Batch Loss: 2.241468791908119e-06\n",
      "Epoch 4325, Loss: 0.00048079209227580577, Final Batch Loss: 5.7803859817795455e-05\n",
      "Epoch 4326, Loss: 0.0002247596530651208, Final Batch Loss: 1.6150512237800285e-05\n",
      "Epoch 4327, Loss: 6.0831567679997534e-05, Final Batch Loss: 4.596833241521381e-05\n",
      "Epoch 4328, Loss: 3.333192489662906e-05, Final Batch Loss: 7.815550816303585e-06\n",
      "Epoch 4329, Loss: 0.0009523564285700559, Final Batch Loss: 4.644963155442383e-06\n",
      "Epoch 4330, Loss: 8.949842253969109e-05, Final Batch Loss: 2.800156153170974e-06\n",
      "Epoch 4331, Loss: 0.00011492988051031716, Final Batch Loss: 4.4621065171668306e-05\n",
      "Epoch 4332, Loss: 0.00010825458957697265, Final Batch Loss: 7.041179924272001e-05\n",
      "Epoch 4333, Loss: 0.00010600280893413583, Final Batch Loss: 0.00010133937030332163\n",
      "Epoch 4334, Loss: 1.5955155618030403e-05, Final Batch Loss: 1.1321454849166912e-06\n",
      "Epoch 4335, Loss: 2.8032328827976016e-05, Final Batch Loss: 2.0658755602198653e-05\n",
      "Epoch 4336, Loss: 0.0004248507466400042, Final Batch Loss: 0.00016902438073884696\n",
      "Epoch 4337, Loss: 0.0005177215803087165, Final Batch Loss: 7.3813148446788546e-06\n",
      "Epoch 4338, Loss: 0.003303177305497229, Final Batch Loss: 0.00301531283184886\n",
      "Epoch 4339, Loss: 5.8326519138063304e-05, Final Batch Loss: 3.3464406442362815e-05\n",
      "Epoch 4340, Loss: 0.00037390864900999077, Final Batch Loss: 0.0003732162876985967\n",
      "Epoch 4341, Loss: 0.0001640852879063459, Final Batch Loss: 0.00014177178672980517\n",
      "Epoch 4342, Loss: 0.00029355785227380693, Final Batch Loss: 0.00027758607757277787\n",
      "Epoch 4343, Loss: 6.036068316461751e-05, Final Batch Loss: 5.0320097216172144e-05\n",
      "Epoch 4344, Loss: 5.973006227577571e-05, Final Batch Loss: 5.648176738759503e-05\n",
      "Epoch 4345, Loss: 8.646909009257797e-05, Final Batch Loss: 1.7639200450503267e-05\n",
      "Epoch 4346, Loss: 6.590669363504276e-05, Final Batch Loss: 4.960759179084562e-05\n",
      "Epoch 4347, Loss: 7.356677451753058e-05, Final Batch Loss: 9.644569217925891e-06\n",
      "Epoch 4348, Loss: 0.0002721809778449824, Final Batch Loss: 0.0002529624616727233\n",
      "Epoch 4349, Loss: 0.0002560732391430065, Final Batch Loss: 0.00020581443095579743\n",
      "Epoch 4350, Loss: 0.00026750643337436486, Final Batch Loss: 1.2250560757820494e-05\n",
      "Epoch 4351, Loss: 0.0003542007216310594, Final Batch Loss: 1.491821967647411e-05\n",
      "Epoch 4352, Loss: 4.5853656047256663e-05, Final Batch Loss: 2.75445945590036e-05\n",
      "Epoch 4353, Loss: 0.00047897066178848036, Final Batch Loss: 0.0004492195148486644\n",
      "Epoch 4354, Loss: 0.0002920571769209346, Final Batch Loss: 0.0002899097162298858\n",
      "Epoch 4355, Loss: 3.603103368732263e-05, Final Batch Loss: 2.84339657810051e-05\n",
      "Epoch 4356, Loss: 0.00037761521934953635, Final Batch Loss: 0.00037375613464973867\n",
      "Epoch 4357, Loss: 6.456257506215479e-05, Final Batch Loss: 1.6841875549289398e-05\n",
      "Epoch 4358, Loss: 0.00014626008487539366, Final Batch Loss: 2.1842912246938795e-05\n",
      "Epoch 4359, Loss: 0.0005001321685540461, Final Batch Loss: 0.0004977104254066944\n",
      "Epoch 4360, Loss: 0.0004996428742742864, Final Batch Loss: 1.8581644326332025e-05\n",
      "Epoch 4361, Loss: 8.343534864252433e-05, Final Batch Loss: 7.184463902376592e-05\n",
      "Epoch 4362, Loss: 0.0012825063677155413, Final Batch Loss: 0.00011366161197656766\n",
      "Epoch 4363, Loss: 8.572872866352554e-05, Final Batch Loss: 6.927840877324343e-05\n",
      "Epoch 4364, Loss: 0.00022322944778352394, Final Batch Loss: 5.297491497913143e-06\n",
      "Epoch 4365, Loss: 5.169888027012348e-05, Final Batch Loss: 3.722097972058691e-05\n",
      "Epoch 4366, Loss: 5.3201681112113874e-05, Final Batch Loss: 1.151769083662657e-05\n",
      "Epoch 4367, Loss: 0.00019530240024323575, Final Batch Loss: 0.0001792794355424121\n",
      "Epoch 4368, Loss: 0.000179859419404238, Final Batch Loss: 0.00017763074720278382\n",
      "Epoch 4369, Loss: 8.341626744368114e-05, Final Batch Loss: 1.530050576548092e-05\n",
      "Epoch 4370, Loss: 0.00014763464241696056, Final Batch Loss: 5.910644176765345e-06\n",
      "Epoch 4371, Loss: 1.3704702041650307e-05, Final Batch Loss: 2.2351689494826132e-06\n",
      "Epoch 4372, Loss: 0.00011753890430554748, Final Batch Loss: 8.498951501678675e-05\n",
      "Epoch 4373, Loss: 4.959904254064895e-05, Final Batch Loss: 4.293961319490336e-05\n",
      "Epoch 4374, Loss: 8.374211893169559e-05, Final Batch Loss: 7.675946108065546e-05\n",
      "Epoch 4375, Loss: 0.0030692888130943174, Final Batch Loss: 0.00305547215975821\n",
      "Epoch 4376, Loss: 5.323236200638348e-05, Final Batch Loss: 5.546896318264771e-06\n",
      "Epoch 4377, Loss: 6.0883170590386726e-05, Final Batch Loss: 2.9315260690054856e-05\n",
      "Epoch 4378, Loss: 0.0005080153914605035, Final Batch Loss: 1.9405559214646928e-05\n",
      "Epoch 4379, Loss: 7.413248931698035e-05, Final Batch Loss: 6.178468174766749e-05\n",
      "Epoch 4380, Loss: 0.0002975086681544781, Final Batch Loss: 0.00026094168424606323\n",
      "Epoch 4381, Loss: 0.00024173384008463472, Final Batch Loss: 0.00017934123752638698\n",
      "Epoch 4382, Loss: 0.0015075393312145025, Final Batch Loss: 0.001475172583013773\n",
      "Epoch 4383, Loss: 7.777858854751685e-05, Final Batch Loss: 7.422694034175947e-05\n",
      "Epoch 4384, Loss: 0.0002091302339977119, Final Batch Loss: 2.6699901354731992e-05\n",
      "Epoch 4385, Loss: 0.0003780951637963881, Final Batch Loss: 7.93684466771083e-06\n",
      "Epoch 4386, Loss: 0.0002636403951328248, Final Batch Loss: 0.0001276537514058873\n",
      "Epoch 4387, Loss: 0.00038689502980560064, Final Batch Loss: 6.901074084453285e-05\n",
      "Epoch 4388, Loss: 0.00019423813864705153, Final Batch Loss: 5.551720460061915e-05\n",
      "Epoch 4389, Loss: 0.0004916368197882548, Final Batch Loss: 0.0003281220851931721\n",
      "Epoch 4390, Loss: 2.18807347209804e-05, Final Batch Loss: 2.0863628833467374e-06\n",
      "Epoch 4391, Loss: 8.374998833460268e-05, Final Batch Loss: 5.3795098210684955e-05\n",
      "Epoch 4392, Loss: 0.0003111593941866886, Final Batch Loss: 0.00027333307662047446\n",
      "Epoch 4393, Loss: 0.0007101031442289241, Final Batch Loss: 0.0006021330482326448\n",
      "Epoch 4394, Loss: 0.0003667319870146457, Final Batch Loss: 5.178354695090093e-05\n",
      "Epoch 4395, Loss: 0.0008609927899669856, Final Batch Loss: 0.00027667926042340696\n",
      "Epoch 4396, Loss: 5.3908340305497404e-05, Final Batch Loss: 1.1206370800209697e-05\n",
      "Epoch 4397, Loss: 0.0004089163412572816, Final Batch Loss: 0.00021489665959961712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4398, Loss: 0.0005779084931418765, Final Batch Loss: 0.0005534128285944462\n",
      "Epoch 4399, Loss: 0.00013207242591306567, Final Batch Loss: 6.848292832728475e-05\n",
      "Epoch 4400, Loss: 0.00011436359636718407, Final Batch Loss: 3.393046063138172e-05\n",
      "Epoch 4401, Loss: 6.477499391621677e-05, Final Batch Loss: 1.0892133104789536e-05\n",
      "Epoch 4402, Loss: 0.00015196148888207972, Final Batch Loss: 0.00010391591786174104\n",
      "Epoch 4403, Loss: 0.000616910284406913, Final Batch Loss: 7.953485692269169e-07\n",
      "Epoch 4404, Loss: 0.00017159308117697947, Final Batch Loss: 0.0001302457822021097\n",
      "Epoch 4405, Loss: 4.6943114739406155e-05, Final Batch Loss: 3.469871899142163e-06\n",
      "Epoch 4406, Loss: 3.371554294062662e-05, Final Batch Loss: 4.796001576323761e-06\n",
      "Epoch 4407, Loss: 1.1696396768456907e-05, Final Batch Loss: 8.648818038636819e-06\n",
      "Epoch 4408, Loss: 3.894940255122492e-05, Final Batch Loss: 6.447572559409309e-06\n",
      "Epoch 4409, Loss: 1.8384075190169824e-05, Final Batch Loss: 9.177114748126769e-07\n",
      "Epoch 4410, Loss: 0.0002059461039607413, Final Batch Loss: 0.00010603207192616537\n",
      "Epoch 4411, Loss: 4.822184450858913e-06, Final Batch Loss: 1.8012696045843768e-06\n",
      "Epoch 4412, Loss: 0.0001359714751743013, Final Batch Loss: 1.17867693916196e-05\n",
      "Epoch 4413, Loss: 0.0003313554875603586, Final Batch Loss: 0.0003261995443608612\n",
      "Epoch 4414, Loss: 0.004834672494325787, Final Batch Loss: 0.004227112513035536\n",
      "Epoch 4415, Loss: 2.6592631911626086e-05, Final Batch Loss: 2.1975378331262618e-05\n",
      "Epoch 4416, Loss: 6.384011794580147e-05, Final Batch Loss: 4.387987792142667e-05\n",
      "Epoch 4417, Loss: 0.00026050703672808595, Final Batch Loss: 0.00021308023133315146\n",
      "Epoch 4418, Loss: 0.015926704356388655, Final Batch Loss: 0.0158567875623703\n",
      "Epoch 4419, Loss: 1.340222161161364e-05, Final Batch Loss: 7.31801446818281e-06\n",
      "Epoch 4420, Loss: 0.0023586688403156586, Final Batch Loss: 0.00010065024980576709\n",
      "Epoch 4421, Loss: 0.0001514166779088555, Final Batch Loss: 0.0001434508740203455\n",
      "Epoch 4422, Loss: 0.0002842084759322461, Final Batch Loss: 0.00024799222592264414\n",
      "Epoch 4423, Loss: 2.801278606057167e-05, Final Batch Loss: 1.8282318706042133e-05\n",
      "Epoch 4424, Loss: 0.0002069917318294756, Final Batch Loss: 9.023679740494117e-05\n",
      "Epoch 4425, Loss: 0.0005595362235908397, Final Batch Loss: 0.0004802935873158276\n",
      "Epoch 4426, Loss: 0.00035527703948901035, Final Batch Loss: 4.383200212032534e-05\n",
      "Epoch 4427, Loss: 0.0021612617128994316, Final Batch Loss: 0.0018957400461658835\n",
      "Epoch 4428, Loss: 4.940575263390201e-05, Final Batch Loss: 7.0574128585576545e-06\n",
      "Epoch 4429, Loss: 0.0005837036878801882, Final Batch Loss: 0.00036293946322984993\n",
      "Epoch 4430, Loss: 9.142031558440067e-05, Final Batch Loss: 3.070479215239175e-05\n",
      "Epoch 4431, Loss: 0.000532900492544286, Final Batch Loss: 0.00042089700582437217\n",
      "Epoch 4432, Loss: 0.007806707639247179, Final Batch Loss: 0.004440197721123695\n",
      "Epoch 4433, Loss: 0.0006515012064483017, Final Batch Loss: 0.0002985334722325206\n",
      "Epoch 4434, Loss: 1.5161769169935724e-05, Final Batch Loss: 5.375207820179639e-06\n",
      "Epoch 4435, Loss: 5.873773716302821e-06, Final Batch Loss: 3.348558038851479e-06\n",
      "Epoch 4436, Loss: 0.00018888874183176085, Final Batch Loss: 0.00011820624786196277\n",
      "Epoch 4437, Loss: 3.1842200542087085e-05, Final Batch Loss: 3.3483026982139563e-06\n",
      "Epoch 4438, Loss: 2.171615051338449e-05, Final Batch Loss: 1.3488305739883799e-05\n",
      "Epoch 4439, Loss: 0.0002373058532612049, Final Batch Loss: 0.00022917016758583486\n",
      "Epoch 4440, Loss: 0.0006952012608962832, Final Batch Loss: 0.0006722160032950342\n",
      "Epoch 4441, Loss: 0.0002925978769781068, Final Batch Loss: 8.021245594136417e-05\n",
      "Epoch 4442, Loss: 5.6569728258182295e-05, Final Batch Loss: 3.497976649668999e-05\n",
      "Epoch 4443, Loss: 0.0003856002804241143, Final Batch Loss: 2.9724898922722787e-05\n",
      "Epoch 4444, Loss: 0.00017214434046763927, Final Batch Loss: 0.00013649009633809328\n",
      "Epoch 4445, Loss: 0.00037619697468471713, Final Batch Loss: 0.00034939698525704443\n",
      "Epoch 4446, Loss: 1.965987837593275e-05, Final Batch Loss: 1.6000911955416086e-06\n",
      "Epoch 4447, Loss: 0.000247451156610623, Final Batch Loss: 7.383531192317605e-05\n",
      "Epoch 4448, Loss: 0.0020485095319600077, Final Batch Loss: 0.0020226426422595978\n",
      "Epoch 4449, Loss: 0.0001185307846753858, Final Batch Loss: 0.0001119481457863003\n",
      "Epoch 4450, Loss: 0.00010827875303220935, Final Batch Loss: 4.5779812353430316e-05\n",
      "Epoch 4451, Loss: 3.7214917938399594e-05, Final Batch Loss: 5.068831342214253e-06\n",
      "Epoch 4452, Loss: 8.693643212609459e-05, Final Batch Loss: 2.913758908107411e-05\n",
      "Epoch 4453, Loss: 0.0003938446989195654, Final Batch Loss: 0.0003858167910948396\n",
      "Epoch 4454, Loss: 0.00014574859596905299, Final Batch Loss: 0.0001160672472906299\n",
      "Epoch 4455, Loss: 0.00015631285350536928, Final Batch Loss: 6.611758726648986e-05\n",
      "Epoch 4456, Loss: 0.001374366427626228, Final Batch Loss: 2.1676500182366e-05\n",
      "Epoch 4457, Loss: 5.5705442264297744e-05, Final Batch Loss: 5.048714956501499e-05\n",
      "Epoch 4458, Loss: 0.00043752470082836226, Final Batch Loss: 0.0003243490064051002\n",
      "Epoch 4459, Loss: 0.0005530581729544792, Final Batch Loss: 1.052674269885756e-05\n",
      "Epoch 4460, Loss: 0.00017679113807389513, Final Batch Loss: 2.5597815692890435e-05\n",
      "Epoch 4461, Loss: 3.654344709502766e-05, Final Batch Loss: 1.4545733392878901e-05\n",
      "Epoch 4462, Loss: 0.00022999729185357864, Final Batch Loss: 0.00022779351274948567\n",
      "Epoch 4463, Loss: 0.00045327522821025923, Final Batch Loss: 0.0004105639236513525\n",
      "Epoch 4464, Loss: 4.338399139669491e-05, Final Batch Loss: 1.4777781871089246e-05\n",
      "Epoch 4465, Loss: 0.0006881873268866912, Final Batch Loss: 0.0005433405167423189\n",
      "Epoch 4466, Loss: 0.003948490892071277, Final Batch Loss: 0.003912034910172224\n",
      "Epoch 4467, Loss: 9.186779425363056e-05, Final Batch Loss: 1.3653527275891975e-05\n",
      "Epoch 4468, Loss: 0.00013730132559430785, Final Batch Loss: 2.0980700355721638e-05\n",
      "Epoch 4469, Loss: 0.0006883199530420825, Final Batch Loss: 3.40670085279271e-05\n",
      "Epoch 4470, Loss: 0.00019228931250836467, Final Batch Loss: 0.00018125954375136644\n",
      "Epoch 4471, Loss: 0.0001156492689915467, Final Batch Loss: 4.147315848967992e-05\n",
      "Epoch 4472, Loss: 0.0002881876673654915, Final Batch Loss: 2.2320557491184445e-06\n",
      "Epoch 4473, Loss: 0.000629823945928365, Final Batch Loss: 0.00013107468839734793\n",
      "Epoch 4474, Loss: 9.06417126316228e-05, Final Batch Loss: 1.2275872904865537e-05\n",
      "Epoch 4475, Loss: 3.2861566069186665e-05, Final Batch Loss: 1.1012645700247958e-05\n",
      "Epoch 4476, Loss: 0.000286032933217939, Final Batch Loss: 0.0001641186245251447\n",
      "Epoch 4477, Loss: 2.0891469375783345e-05, Final Batch Loss: 1.3610560927190818e-05\n",
      "Epoch 4478, Loss: 0.0037072176968422355, Final Batch Loss: 1.4802830037297099e-06\n",
      "Epoch 4479, Loss: 2.5858998924377374e-05, Final Batch Loss: 3.670689693535678e-06\n",
      "Epoch 4480, Loss: 8.167707346729003e-05, Final Batch Loss: 3.928312798961997e-05\n",
      "Epoch 4481, Loss: 0.0001643130999582354, Final Batch Loss: 0.00013325181498657912\n",
      "Epoch 4482, Loss: 0.002719287898798939, Final Batch Loss: 0.002669296460226178\n",
      "Epoch 4483, Loss: 0.000476576344226487, Final Batch Loss: 8.584385795984417e-05\n",
      "Epoch 4484, Loss: 4.594651727529708e-05, Final Batch Loss: 2.7594705898081884e-05\n",
      "Epoch 4485, Loss: 1.984081995942688e-05, Final Batch Loss: 2.652656121426844e-06\n",
      "Epoch 4486, Loss: 6.991800364630762e-05, Final Batch Loss: 4.672447903431021e-05\n",
      "Epoch 4487, Loss: 7.295429213627358e-05, Final Batch Loss: 6.644322274951264e-05\n",
      "Epoch 4488, Loss: 0.0001271333712793421, Final Batch Loss: 0.00010863821808015928\n",
      "Epoch 4489, Loss: 0.00011665288798212714, Final Batch Loss: 0.00011301432823529467\n",
      "Epoch 4490, Loss: 6.445886947403778e-05, Final Batch Loss: 7.012062724243151e-06\n",
      "Epoch 4491, Loss: 0.00012701705236395355, Final Batch Loss: 2.2550206267624162e-05\n",
      "Epoch 4492, Loss: 0.00016837161456351168, Final Batch Loss: 3.1185354600893334e-05\n",
      "Epoch 4493, Loss: 6.3576200773241e-05, Final Batch Loss: 2.0401985239004716e-05\n",
      "Epoch 4494, Loss: 0.00010221799311693758, Final Batch Loss: 3.827214823104441e-05\n",
      "Epoch 4495, Loss: 5.5475213230238296e-05, Final Batch Loss: 8.157183401635848e-06\n",
      "Epoch 4496, Loss: 0.0006276744898059405, Final Batch Loss: 5.412204336607829e-05\n",
      "Epoch 4497, Loss: 4.316396871217876e-05, Final Batch Loss: 2.8739100343955215e-06\n",
      "Epoch 4498, Loss: 4.03911128614709e-05, Final Batch Loss: 2.0813042738154763e-06\n",
      "Epoch 4499, Loss: 7.48391316847119e-05, Final Batch Loss: 7.245628512464464e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4500, Loss: 8.902773151930887e-05, Final Batch Loss: 7.24334386177361e-05\n",
      "Epoch 4501, Loss: 0.0005694666378985858, Final Batch Loss: 2.0287194274715148e-05\n",
      "Epoch 4502, Loss: 0.00018890260435000528, Final Batch Loss: 2.0543129721772857e-05\n",
      "Epoch 4503, Loss: 9.118013622355647e-05, Final Batch Loss: 6.364922592183575e-05\n",
      "Epoch 4504, Loss: 3.82817361241905e-05, Final Batch Loss: 1.4499069948215038e-05\n",
      "Epoch 4505, Loss: 1.2539280987766688e-05, Final Batch Loss: 1.7218656012119027e-06\n",
      "Epoch 4506, Loss: 7.746948540443555e-05, Final Batch Loss: 5.090756530989893e-05\n",
      "Epoch 4507, Loss: 9.36816441026167e-05, Final Batch Loss: 5.155002327228431e-06\n",
      "Epoch 4508, Loss: 6.212228981894441e-05, Final Batch Loss: 8.602954039815813e-06\n",
      "Epoch 4509, Loss: 9.578599565429613e-05, Final Batch Loss: 3.805156302405521e-05\n",
      "Epoch 4510, Loss: 1.7846781247499166e-05, Final Batch Loss: 1.4173228009894956e-05\n",
      "Epoch 4511, Loss: 0.002965089453937253, Final Batch Loss: 5.432433317764662e-05\n",
      "Epoch 4512, Loss: 0.002084271022795292, Final Batch Loss: 1.6744897948228754e-06\n",
      "Epoch 4513, Loss: 1.2805198821297381e-05, Final Batch Loss: 3.549432221916504e-06\n",
      "Epoch 4514, Loss: 0.0007232759999169502, Final Batch Loss: 0.0007063806988298893\n",
      "Epoch 4515, Loss: 0.00012949239317094907, Final Batch Loss: 2.6718764274846762e-05\n",
      "Epoch 4516, Loss: 0.0008414918695507367, Final Batch Loss: 0.0008393157040700316\n",
      "Epoch 4517, Loss: 0.000155903525865142, Final Batch Loss: 0.0001515791518613696\n",
      "Epoch 4518, Loss: 1.3819988339491829e-05, Final Batch Loss: 1.831533040785871e-06\n",
      "Epoch 4519, Loss: 1.198580662276072e-05, Final Batch Loss: 3.0229628009692533e-06\n",
      "Epoch 4520, Loss: 6.767952652353415e-05, Final Batch Loss: 9.97164875116141e-07\n",
      "Epoch 4521, Loss: 7.52363112042076e-05, Final Batch Loss: 6.001654401188716e-05\n",
      "Epoch 4522, Loss: 0.00019737426737265196, Final Batch Loss: 0.00016798214346636087\n",
      "Epoch 4523, Loss: 0.0004785869077750249, Final Batch Loss: 0.0004543883551377803\n",
      "Epoch 4524, Loss: 3.311289810881135e-05, Final Batch Loss: 2.971096182591282e-05\n",
      "Epoch 4525, Loss: 0.0010120394304067304, Final Batch Loss: 0.0010068302508443594\n",
      "Epoch 4526, Loss: 1.361750764772296e-05, Final Batch Loss: 5.951475941401441e-06\n",
      "Epoch 4527, Loss: 7.726501553406706e-05, Final Batch Loss: 6.870503420941532e-05\n",
      "Epoch 4528, Loss: 0.0003750666946871206, Final Batch Loss: 0.00021215048036538064\n",
      "Epoch 4529, Loss: 0.0001654089705880324, Final Batch Loss: 0.00016131819575093687\n",
      "Epoch 4530, Loss: 6.433711405406939e-06, Final Batch Loss: 4.444902515388094e-06\n",
      "Epoch 4531, Loss: 9.88508390946663e-05, Final Batch Loss: 8.810623694444075e-05\n",
      "Epoch 4532, Loss: 7.698585113757872e-05, Final Batch Loss: 7.506588735850528e-05\n",
      "Epoch 4533, Loss: 0.00022554149109055288, Final Batch Loss: 5.527522080228664e-05\n",
      "Epoch 4534, Loss: 9.743197097122902e-06, Final Batch Loss: 5.513658379641129e-06\n",
      "Epoch 4535, Loss: 1.10699684228166e-05, Final Batch Loss: 5.815857548441272e-06\n",
      "Epoch 4536, Loss: 0.0003090795726166107, Final Batch Loss: 0.00022847685613669455\n",
      "Epoch 4537, Loss: 0.004269126118742861, Final Batch Loss: 0.004200340714305639\n",
      "Epoch 4538, Loss: 0.000494574589538388, Final Batch Loss: 0.00020199267601128668\n",
      "Epoch 4539, Loss: 0.00043980124701192835, Final Batch Loss: 1.0056065548269544e-05\n",
      "Epoch 4540, Loss: 0.00019714608424692415, Final Batch Loss: 8.393846655962989e-06\n",
      "Epoch 4541, Loss: 0.0014003050773681025, Final Batch Loss: 8.69948689796729e-06\n",
      "Epoch 4542, Loss: 2.808351752037197e-05, Final Batch Loss: 5.06472190409113e-07\n",
      "Epoch 4543, Loss: 0.0014694316341774538, Final Batch Loss: 0.0013949171407148242\n",
      "Epoch 4544, Loss: 6.948036389076151e-05, Final Batch Loss: 3.2883275707717985e-05\n",
      "Epoch 4545, Loss: 3.0915761044525425e-05, Final Batch Loss: 2.987627340189647e-05\n",
      "Epoch 4546, Loss: 0.00010044319060398266, Final Batch Loss: 6.452262459788471e-05\n",
      "Epoch 4547, Loss: 0.0009751667130331043, Final Batch Loss: 3.3625608921283856e-05\n",
      "Epoch 4548, Loss: 0.00025905512302415445, Final Batch Loss: 0.00018762596300803125\n",
      "Epoch 4549, Loss: 1.3960999694972998e-05, Final Batch Loss: 8.634329788037576e-06\n",
      "Epoch 4550, Loss: 7.759390911132868e-05, Final Batch Loss: 7.675994129385799e-05\n",
      "Epoch 4551, Loss: 6.617319786528242e-05, Final Batch Loss: 9.61852947511943e-07\n",
      "Epoch 4552, Loss: 0.0002636452845763415, Final Batch Loss: 0.0001222580613102764\n",
      "Epoch 4553, Loss: 2.0494308614615875e-06, Final Batch Loss: 4.793502625943802e-07\n",
      "Epoch 4554, Loss: 0.00018533064576331526, Final Batch Loss: 9.016024705488235e-05\n",
      "Epoch 4555, Loss: 0.0016269352972813067, Final Batch Loss: 0.0016138069331645966\n",
      "Epoch 4556, Loss: 0.00019907830210286193, Final Batch Loss: 9.580060577718541e-06\n",
      "Epoch 4557, Loss: 1.8335563254368026e-05, Final Batch Loss: 3.4678514566621743e-06\n",
      "Epoch 4558, Loss: 4.895432539342437e-05, Final Batch Loss: 5.691998012480326e-06\n",
      "Epoch 4559, Loss: 5.201829299039673e-05, Final Batch Loss: 1.8192504285252653e-05\n",
      "Epoch 4560, Loss: 0.00015395888385683065, Final Batch Loss: 4.44428496848559e-06\n",
      "Epoch 4561, Loss: 9.006134678202216e-05, Final Batch Loss: 1.3966595361125655e-05\n",
      "Epoch 4562, Loss: 0.00018913632084149867, Final Batch Loss: 0.00011222445755265653\n",
      "Epoch 4563, Loss: 0.00018004038429353386, Final Batch Loss: 0.00016234531358350068\n",
      "Epoch 4564, Loss: 2.385940206295345e-05, Final Batch Loss: 8.003929906408302e-06\n",
      "Epoch 4565, Loss: 5.9681614402506966e-05, Final Batch Loss: 1.0268450751027558e-05\n",
      "Epoch 4566, Loss: 0.00022001549950800836, Final Batch Loss: 7.108836143743247e-05\n",
      "Epoch 4567, Loss: 1.2119711755076423e-05, Final Batch Loss: 8.524665645381901e-06\n",
      "Epoch 4568, Loss: 7.753741374472156e-05, Final Batch Loss: 2.5118511985056102e-05\n",
      "Epoch 4569, Loss: 1.891201191028813e-05, Final Batch Loss: 1.168299604614731e-05\n",
      "Epoch 4570, Loss: 0.0001974162005353719, Final Batch Loss: 0.0001406268129358068\n",
      "Epoch 4571, Loss: 1.964181024050049e-05, Final Batch Loss: 1.7262074834434316e-05\n",
      "Epoch 4572, Loss: 0.00012469545254134573, Final Batch Loss: 0.00010665594163583592\n",
      "Epoch 4573, Loss: 6.207175897543493e-05, Final Batch Loss: 6.101512917666696e-05\n",
      "Epoch 4574, Loss: 4.036797872686293e-05, Final Batch Loss: 1.862429598986637e-05\n",
      "Epoch 4575, Loss: 0.0005525070555449929, Final Batch Loss: 0.0005053087370470166\n",
      "Epoch 4576, Loss: 0.0022039778050384484, Final Batch Loss: 0.002160885604098439\n",
      "Epoch 4577, Loss: 4.253018232702743e-05, Final Batch Loss: 1.6396586943301372e-05\n",
      "Epoch 4578, Loss: 0.00010414750522613758, Final Batch Loss: 9.126893564825878e-05\n",
      "Epoch 4579, Loss: 0.0011934544309042394, Final Batch Loss: 0.0004561736714094877\n",
      "Epoch 4580, Loss: 0.010043631336884573, Final Batch Loss: 0.010006104595959187\n",
      "Epoch 4581, Loss: 0.0006350260155159049, Final Batch Loss: 0.0005228727823123336\n",
      "Epoch 4582, Loss: 4.001765779548805e-05, Final Batch Loss: 3.9844089769758284e-05\n",
      "Epoch 4583, Loss: 0.0006549751301463402, Final Batch Loss: 6.069083156035049e-06\n",
      "Epoch 4584, Loss: 3.7407397940114606e-05, Final Batch Loss: 2.702354140637908e-05\n",
      "Epoch 4585, Loss: 0.00024363894954149146, Final Batch Loss: 0.0002296859456691891\n",
      "Epoch 4586, Loss: 9.003835293697193e-05, Final Batch Loss: 3.5692009987542406e-05\n",
      "Epoch 4587, Loss: 7.535432359873084e-06, Final Batch Loss: 2.8520321393443737e-06\n",
      "Epoch 4588, Loss: 6.956759494869402e-05, Final Batch Loss: 6.351361321321747e-07\n",
      "Epoch 4589, Loss: 2.9429470487229992e-05, Final Batch Loss: 2.7233296350459568e-05\n",
      "Epoch 4590, Loss: 0.00021014876256231219, Final Batch Loss: 0.00014886909048072994\n",
      "Epoch 4591, Loss: 0.000129222216855851, Final Batch Loss: 1.610382787475828e-05\n",
      "Epoch 4592, Loss: 0.0001687139883870259, Final Batch Loss: 0.0001348936784779653\n",
      "Epoch 4593, Loss: 0.00017471107912570005, Final Batch Loss: 1.445879661332583e-05\n",
      "Epoch 4594, Loss: 1.7530743207316846e-05, Final Batch Loss: 4.530254045675974e-06\n",
      "Epoch 4595, Loss: 0.00010054530230263481, Final Batch Loss: 4.832175363844726e-06\n",
      "Epoch 4596, Loss: 0.0001115812574425945, Final Batch Loss: 1.5764819181640632e-05\n",
      "Epoch 4597, Loss: 0.0011433842009864748, Final Batch Loss: 0.0004913076991215348\n",
      "Epoch 4598, Loss: 5.932206659053918e-05, Final Batch Loss: 1.256892028322909e-05\n",
      "Epoch 4599, Loss: 9.716772365209181e-05, Final Batch Loss: 8.552413783036172e-05\n",
      "Epoch 4600, Loss: 5.8576743185767555e-05, Final Batch Loss: 3.114690343863913e-06\n",
      "Epoch 4601, Loss: 7.43833634260227e-05, Final Batch Loss: 3.053767613891978e-06\n",
      "Epoch 4602, Loss: 1.490601854925444e-05, Final Batch Loss: 1.4440632185142022e-05\n",
      "Epoch 4603, Loss: 8.507119673595298e-06, Final Batch Loss: 5.6745429901639e-06\n",
      "Epoch 4604, Loss: 0.00011216239181521814, Final Batch Loss: 0.00011036149953724816\n",
      "Epoch 4605, Loss: 1.7721235906265065e-05, Final Batch Loss: 9.176882826977817e-07\n",
      "Epoch 4606, Loss: 0.00010177763215324376, Final Batch Loss: 1.5511724996031262e-05\n",
      "Epoch 4607, Loss: 1.6201140624616528e-05, Final Batch Loss: 4.4423563849704806e-06\n",
      "Epoch 4608, Loss: 0.0001077086694749596, Final Batch Loss: 2.9250427360238973e-06\n",
      "Epoch 4609, Loss: 6.581205889233388e-05, Final Batch Loss: 1.916137625812553e-05\n",
      "Epoch 4610, Loss: 6.498606012428354e-06, Final Batch Loss: 1.4404948842638987e-06\n",
      "Epoch 4611, Loss: 2.3256891381606692e-05, Final Batch Loss: 4.249219728080789e-06\n",
      "Epoch 4612, Loss: 8.94618351594545e-05, Final Batch Loss: 8.014246850507334e-05\n",
      "Epoch 4613, Loss: 3.419377298996551e-05, Final Batch Loss: 1.1160097528772894e-05\n",
      "Epoch 4614, Loss: 2.5714590037750895e-05, Final Batch Loss: 2.282894274685532e-05\n",
      "Epoch 4615, Loss: 0.0002797517631734081, Final Batch Loss: 0.000272911274805665\n",
      "Epoch 4616, Loss: 1.5568175513180904e-05, Final Batch Loss: 8.574951607442927e-06\n",
      "Epoch 4617, Loss: 2.2967224822423304e-05, Final Batch Loss: 2.522804379623267e-06\n",
      "Epoch 4618, Loss: 0.00014642858150182292, Final Batch Loss: 0.00010581700189504772\n",
      "Epoch 4619, Loss: 6.874486371089006e-05, Final Batch Loss: 1.1801684195233975e-05\n",
      "Epoch 4620, Loss: 0.0015582261694362387, Final Batch Loss: 0.0013739936985075474\n",
      "Epoch 4621, Loss: 0.00010862039562198333, Final Batch Loss: 8.661950414534658e-05\n",
      "Epoch 4622, Loss: 4.80650904819413e-05, Final Batch Loss: 1.3150328186384286e-06\n",
      "Epoch 4623, Loss: 6.935033684385417e-05, Final Batch Loss: 6.80219309288077e-05\n",
      "Epoch 4624, Loss: 0.001995635687308095, Final Batch Loss: 4.455682756088208e-06\n",
      "Epoch 4625, Loss: 0.00027126393069920596, Final Batch Loss: 4.594729034579359e-06\n",
      "Epoch 4626, Loss: 1.143224949373689e-05, Final Batch Loss: 2.102730149999843e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4627, Loss: 0.000768890736708272, Final Batch Loss: 6.640986157435691e-06\n",
      "Epoch 4628, Loss: 6.268407355491945e-05, Final Batch Loss: 6.019835200277157e-05\n",
      "Epoch 4629, Loss: 0.00015530511518591084, Final Batch Loss: 0.00010887916141655296\n",
      "Epoch 4630, Loss: 0.00012586971024575178, Final Batch Loss: 0.00012492801761254668\n",
      "Epoch 4631, Loss: 5.240341354806333e-05, Final Batch Loss: 5.205866546020843e-05\n",
      "Epoch 4632, Loss: 1.860378836227028e-05, Final Batch Loss: 1.832860675676784e-06\n",
      "Epoch 4633, Loss: 1.279352272831602e-05, Final Batch Loss: 2.0819497876800597e-06\n",
      "Epoch 4634, Loss: 8.327363548232825e-05, Final Batch Loss: 7.842451304895803e-05\n",
      "Epoch 4635, Loss: 1.8280436506756814e-05, Final Batch Loss: 6.842044513177825e-06\n",
      "Epoch 4636, Loss: 2.6045906906801974e-05, Final Batch Loss: 2.1249206838547252e-05\n",
      "Epoch 4637, Loss: 8.902522824882908e-05, Final Batch Loss: 8.790184801910073e-05\n",
      "Epoch 4638, Loss: 3.856421244563535e-05, Final Batch Loss: 2.2192052711034194e-05\n",
      "Epoch 4639, Loss: 1.0209749916612054e-05, Final Batch Loss: 7.873858521634247e-06\n",
      "Epoch 4640, Loss: 0.0009591521148877291, Final Batch Loss: 3.42485805049364e-07\n",
      "Epoch 4641, Loss: 6.210875631040835e-05, Final Batch Loss: 5.846164276590571e-05\n",
      "Epoch 4642, Loss: 0.00012539065210148692, Final Batch Loss: 7.298819400602952e-05\n",
      "Epoch 4643, Loss: 4.967604763805866e-05, Final Batch Loss: 4.545848423731513e-05\n",
      "Epoch 4644, Loss: 0.00014497872143692803, Final Batch Loss: 1.2843838703702204e-05\n",
      "Epoch 4645, Loss: 0.0004976661293767393, Final Batch Loss: 5.6315911933779716e-05\n",
      "Epoch 4646, Loss: 4.196244276499783e-06, Final Batch Loss: 2.5064650799322408e-06\n",
      "Epoch 4647, Loss: 0.00016143018365255557, Final Batch Loss: 0.0001305377227254212\n",
      "Epoch 4648, Loss: 4.736237974611868e-05, Final Batch Loss: 3.144686388623086e-06\n",
      "Epoch 4649, Loss: 9.078804669115925e-05, Final Batch Loss: 8.83320317370817e-05\n",
      "Epoch 4650, Loss: 4.7328593382189865e-06, Final Batch Loss: 4.165431164437905e-06\n",
      "Epoch 4651, Loss: 7.8368345839408e-06, Final Batch Loss: 8.602953585068462e-07\n",
      "Epoch 4652, Loss: 4.2874338305409765e-05, Final Batch Loss: 4.365012046037009e-06\n",
      "Epoch 4653, Loss: 1.2886214136642593e-05, Final Batch Loss: 4.118631125038519e-07\n",
      "Epoch 4654, Loss: 4.918809793252876e-06, Final Batch Loss: 4.963799824508897e-07\n",
      "Epoch 4655, Loss: 0.0005126146588736447, Final Batch Loss: 2.215801396232564e-05\n",
      "Epoch 4656, Loss: 0.00025510841305731446, Final Batch Loss: 2.57508736467571e-06\n",
      "Epoch 4657, Loss: 0.00029533120687119663, Final Batch Loss: 6.069835217203945e-05\n",
      "Epoch 4658, Loss: 1.1912491117982427e-05, Final Batch Loss: 4.610745691024931e-06\n",
      "Epoch 4659, Loss: 0.0001400347100570798, Final Batch Loss: 5.240397877059877e-05\n",
      "Epoch 4660, Loss: 1.8346185584050545e-06, Final Batch Loss: 8.375744187105738e-07\n",
      "Epoch 4661, Loss: 3.8074274925747886e-05, Final Batch Loss: 2.8451939215301536e-05\n",
      "Epoch 4662, Loss: 7.512180266644464e-05, Final Batch Loss: 3.027521700005309e-07\n",
      "Epoch 4663, Loss: 2.6735905521491077e-05, Final Batch Loss: 9.02851843420649e-06\n",
      "Epoch 4664, Loss: 0.00015888417055975879, Final Batch Loss: 5.775175850430969e-06\n",
      "Epoch 4665, Loss: 3.8551509078388335e-06, Final Batch Loss: 3.4078818771376973e-06\n",
      "Epoch 4666, Loss: 3.724272528415895e-05, Final Batch Loss: 3.526831278577447e-05\n",
      "Epoch 4667, Loss: 4.285266186343506e-05, Final Batch Loss: 8.328432159032673e-06\n",
      "Epoch 4668, Loss: 2.1690883841074537e-05, Final Batch Loss: 1.1825524779851548e-05\n",
      "Epoch 4669, Loss: 1.097355698220781e-05, Final Batch Loss: 7.123034720279975e-06\n",
      "Epoch 4670, Loss: 0.0004515343734965427, Final Batch Loss: 0.0004215665103401989\n",
      "Epoch 4671, Loss: 0.0005548932676902041, Final Batch Loss: 0.00019990089640486985\n",
      "Epoch 4672, Loss: 7.296042133475567e-05, Final Batch Loss: 7.178126543294638e-05\n",
      "Epoch 4673, Loss: 2.5629024889894936e-05, Final Batch Loss: 1.8195740949522587e-06\n",
      "Epoch 4674, Loss: 4.071353407653078e-05, Final Batch Loss: 1.284788709199347e-06\n",
      "Epoch 4675, Loss: 3.966521148868196e-06, Final Batch Loss: 2.1494524844456464e-06\n",
      "Epoch 4676, Loss: 5.300648444972467e-05, Final Batch Loss: 5.140206849318929e-05\n",
      "Epoch 4677, Loss: 1.2683140084845945e-05, Final Batch Loss: 6.441977802751353e-06\n",
      "Epoch 4678, Loss: 0.002807764209137531, Final Batch Loss: 0.0028059484902769327\n",
      "Epoch 4679, Loss: 4.480196162148786e-05, Final Batch Loss: 8.798431281320518e-07\n",
      "Epoch 4680, Loss: 0.0001151653659690055, Final Batch Loss: 7.2415814429405145e-06\n",
      "Epoch 4681, Loss: 5.3742063073514146e-05, Final Batch Loss: 5.462090939545305e-07\n",
      "Epoch 4682, Loss: 2.641528863023268e-05, Final Batch Loss: 1.1803668712673243e-05\n",
      "Epoch 4683, Loss: 0.00010328326106900931, Final Batch Loss: 3.4138306546083186e-06\n",
      "Epoch 4684, Loss: 0.0004423095815582201, Final Batch Loss: 0.00042972416849806905\n",
      "Epoch 4685, Loss: 5.320609079717542e-05, Final Batch Loss: 4.960256410413422e-05\n",
      "Epoch 4686, Loss: 0.00018831653505912982, Final Batch Loss: 4.215494482195936e-05\n",
      "Epoch 4687, Loss: 5.5714188420097344e-05, Final Batch Loss: 5.942843927186914e-06\n",
      "Epoch 4688, Loss: 9.551813496955219e-05, Final Batch Loss: 8.073148478615622e-07\n",
      "Epoch 4689, Loss: 1.6692536860318796e-05, Final Batch Loss: 1.397657229063043e-06\n",
      "Epoch 4690, Loss: 2.427222227652237e-05, Final Batch Loss: 4.257386763129034e-07\n",
      "Epoch 4691, Loss: 1.1190766144864028e-05, Final Batch Loss: 5.139353106642375e-06\n",
      "Epoch 4692, Loss: 1.5075781902851304e-05, Final Batch Loss: 6.443103757192148e-06\n",
      "Epoch 4693, Loss: 1.1932703728234628e-05, Final Batch Loss: 1.103676731872838e-05\n",
      "Epoch 4694, Loss: 1.9009328752872534e-05, Final Batch Loss: 7.171292963903397e-07\n",
      "Epoch 4695, Loss: 4.787291231878044e-06, Final Batch Loss: 3.159960897392011e-07\n",
      "Epoch 4696, Loss: 6.1034892496536486e-05, Final Batch Loss: 5.204162880545482e-05\n",
      "Epoch 4697, Loss: 2.2599666408495978e-05, Final Batch Loss: 1.3893059986003209e-05\n",
      "Epoch 4698, Loss: 7.143933800080049e-06, Final Batch Loss: 3.986226886354416e-07\n",
      "Epoch 4699, Loss: 0.006413863243778906, Final Batch Loss: 3.708696567628067e-07\n",
      "Epoch 4700, Loss: 0.00011867991133840405, Final Batch Loss: 0.00011347352847224101\n",
      "Epoch 4701, Loss: 0.0004666986642405391, Final Batch Loss: 0.0002956411335617304\n",
      "Epoch 4702, Loss: 0.00043982903252981487, Final Batch Loss: 0.0004384724597912282\n",
      "Epoch 4703, Loss: 3.5269663385406602e-06, Final Batch Loss: 1.7861895003079553e-06\n",
      "Epoch 4704, Loss: 9.981001539927092e-06, Final Batch Loss: 6.223441232577898e-06\n",
      "Epoch 4705, Loss: 1.1098800143827248e-05, Final Batch Loss: 1.035972309182398e-05\n",
      "Epoch 4706, Loss: 0.0001416024642821867, Final Batch Loss: 4.8403602704638615e-05\n",
      "Epoch 4707, Loss: 0.0009381788258906454, Final Batch Loss: 0.0009143890347331762\n",
      "Epoch 4708, Loss: 0.0034213659037050093, Final Batch Loss: 1.7309715985902585e-05\n",
      "Epoch 4709, Loss: 0.0005638481629830494, Final Batch Loss: 4.9936165851249825e-06\n",
      "Epoch 4710, Loss: 0.00016590108953096205, Final Batch Loss: 9.794851393962745e-06\n",
      "Epoch 4711, Loss: 5.6665710559400395e-06, Final Batch Loss: 1.356081753556282e-07\n",
      "Epoch 4712, Loss: 4.0308900679519866e-05, Final Batch Loss: 1.223590788868023e-05\n",
      "Epoch 4713, Loss: 3.9980289784580236e-05, Final Batch Loss: 3.216174718545517e-06\n",
      "Epoch 4714, Loss: 0.014031327112277836, Final Batch Loss: 1.450690234605645e-07\n",
      "Epoch 4715, Loss: 0.00038208648339832507, Final Batch Loss: 0.0003812863724306226\n",
      "Epoch 4716, Loss: 1.3370586657401873e-05, Final Batch Loss: 1.25218330140342e-05\n",
      "Epoch 4717, Loss: 9.658389006972357e-05, Final Batch Loss: 9.609132393961772e-05\n",
      "Epoch 4718, Loss: 0.00023790424438629998, Final Batch Loss: 0.00022735990933142602\n",
      "Epoch 4719, Loss: 0.00017338575344183482, Final Batch Loss: 0.00016869293176569045\n",
      "Epoch 4720, Loss: 0.00013957627652416704, Final Batch Loss: 1.2506580787885468e-05\n",
      "Epoch 4721, Loss: 4.2358859900559764e-05, Final Batch Loss: 3.216526238247752e-05\n",
      "Epoch 4722, Loss: 2.540853574828361e-05, Final Batch Loss: 4.318143055570545e-06\n",
      "Epoch 4723, Loss: 0.000244777649641037, Final Batch Loss: 7.405297947116196e-05\n",
      "Epoch 4724, Loss: 9.118330035562394e-05, Final Batch Loss: 2.7870946723851375e-06\n",
      "Epoch 4725, Loss: 3.7179342143645044e-05, Final Batch Loss: 3.0903087463229895e-05\n",
      "Epoch 4726, Loss: 0.0006434521419578232, Final Batch Loss: 7.074871246004477e-05\n",
      "Epoch 4727, Loss: 0.00018864614150970738, Final Batch Loss: 1.2443653076843475e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4728, Loss: 0.00018760310194920748, Final Batch Loss: 8.873151818988845e-05\n",
      "Epoch 4729, Loss: 0.00015429521590704098, Final Batch Loss: 0.00013481445785146207\n",
      "Epoch 4730, Loss: 6.0857613334519556e-05, Final Batch Loss: 5.802227678941563e-05\n",
      "Epoch 4731, Loss: 0.0001703473535599187, Final Batch Loss: 4.391609400045127e-05\n",
      "Epoch 4732, Loss: 4.414806335262256e-05, Final Batch Loss: 2.0939269234077074e-06\n",
      "Epoch 4733, Loss: 0.0002410912129562348, Final Batch Loss: 0.00018342252587899566\n",
      "Epoch 4734, Loss: 0.00039652878604101716, Final Batch Loss: 7.161764187912922e-06\n",
      "Epoch 4735, Loss: 0.0007836577497073449, Final Batch Loss: 0.0007400743197649717\n",
      "Epoch 4736, Loss: 0.0002580004402261693, Final Batch Loss: 0.00020366182434372604\n",
      "Epoch 4737, Loss: 2.7377353490010137e-05, Final Batch Loss: 2.2428152078646235e-05\n",
      "Epoch 4738, Loss: 7.220726547529921e-05, Final Batch Loss: 6.0734397266060114e-05\n",
      "Epoch 4739, Loss: 4.563540414892486e-06, Final Batch Loss: 2.99003227155481e-06\n",
      "Epoch 4740, Loss: 0.0001225353407789953, Final Batch Loss: 4.1441002395004034e-05\n",
      "Epoch 4741, Loss: 8.747270612730063e-06, Final Batch Loss: 5.772487384092528e-06\n",
      "Epoch 4742, Loss: 5.445646274893079e-05, Final Batch Loss: 2.342344851058442e-05\n",
      "Epoch 4743, Loss: 0.0029643751990988676, Final Batch Loss: 0.0029570383485406637\n",
      "Epoch 4744, Loss: 0.0001027550006256206, Final Batch Loss: 6.674743417534046e-06\n",
      "Epoch 4745, Loss: 9.941857024386991e-05, Final Batch Loss: 8.130935748340562e-05\n",
      "Epoch 4746, Loss: 2.2420255845645443e-05, Final Batch Loss: 8.568381417717319e-06\n",
      "Epoch 4747, Loss: 0.00016721352494641906, Final Batch Loss: 0.00016308232443407178\n",
      "Epoch 4748, Loss: 2.8105250748922117e-06, Final Batch Loss: 1.2141246088503976e-06\n",
      "Epoch 4749, Loss: 0.00016527210391359404, Final Batch Loss: 3.726433351403102e-05\n",
      "Epoch 4750, Loss: 6.420121508199372e-06, Final Batch Loss: 2.8234060209797462e-06\n",
      "Epoch 4751, Loss: 0.00018172135537497525, Final Batch Loss: 0.00018047734920401126\n",
      "Epoch 4752, Loss: 1.6478565612487728e-05, Final Batch Loss: 2.098242021020269e-06\n",
      "Epoch 4753, Loss: 0.00018892015214078128, Final Batch Loss: 0.00012541621981654316\n",
      "Epoch 4754, Loss: 0.0007731021994459297, Final Batch Loss: 0.0007717838161624968\n",
      "Epoch 4755, Loss: 0.00019738934497581795, Final Batch Loss: 0.00013943100930191576\n",
      "Epoch 4756, Loss: 0.00013965754988021217, Final Batch Loss: 8.12170619610697e-05\n",
      "Epoch 4757, Loss: 0.00010228948212898104, Final Batch Loss: 9.961843898054212e-05\n",
      "Epoch 4758, Loss: 0.00017566738642926794, Final Batch Loss: 1.6834672351251356e-05\n",
      "Epoch 4759, Loss: 2.578906855887908e-05, Final Batch Loss: 2.2018124582245946e-05\n",
      "Epoch 4760, Loss: 1.4900284099894634e-05, Final Batch Loss: 1.3025064617977478e-05\n",
      "Epoch 4761, Loss: 8.100135505628714e-05, Final Batch Loss: 7.897854084149003e-05\n",
      "Epoch 4762, Loss: 0.008768842526478693, Final Batch Loss: 0.0001401062763761729\n",
      "Epoch 4763, Loss: 7.950114195409697e-06, Final Batch Loss: 4.551194706436945e-06\n",
      "Epoch 4764, Loss: 0.005052811233326793, Final Batch Loss: 0.005039290990680456\n",
      "Epoch 4765, Loss: 1.6595920897088945e-05, Final Batch Loss: 6.575303814315703e-06\n",
      "Epoch 4766, Loss: 2.3386816621950857e-05, Final Batch Loss: 2.2884723875904456e-05\n",
      "Epoch 4767, Loss: 0.0005741624554502778, Final Batch Loss: 7.512815500376746e-05\n",
      "Epoch 4768, Loss: 0.0004360940001788549, Final Batch Loss: 2.4407920136582106e-05\n",
      "Epoch 4769, Loss: 0.000355425269845, Final Batch Loss: 3.915870365744922e-06\n",
      "Epoch 4770, Loss: 2.0213497919030488e-05, Final Batch Loss: 6.159555596241262e-06\n",
      "Epoch 4771, Loss: 0.0009089844570553396, Final Batch Loss: 4.196310328552499e-06\n",
      "Epoch 4772, Loss: 0.00017271104297833517, Final Batch Loss: 9.023675374919549e-05\n",
      "Epoch 4773, Loss: 0.0002580342952569481, Final Batch Loss: 4.310955046094023e-05\n",
      "Epoch 4774, Loss: 1.9721030639630044e-05, Final Batch Loss: 6.832408416812541e-06\n",
      "Epoch 4775, Loss: 4.533417836682929e-06, Final Batch Loss: 1.1150760883538169e-06\n",
      "Epoch 4776, Loss: 2.1493739495781483e-05, Final Batch Loss: 2.0560351003950927e-06\n",
      "Epoch 4777, Loss: 3.0095734473434277e-05, Final Batch Loss: 7.821485269232653e-06\n",
      "Epoch 4778, Loss: 8.868503209669143e-05, Final Batch Loss: 3.455632395343855e-05\n",
      "Epoch 4779, Loss: 1.1627009484982409e-05, Final Batch Loss: 1.2185147397758556e-06\n",
      "Epoch 4780, Loss: 2.8977172405575402e-05, Final Batch Loss: 2.3064920242177323e-05\n",
      "Epoch 4781, Loss: 0.00014093369100010023, Final Batch Loss: 6.16209363215603e-05\n",
      "Epoch 4782, Loss: 0.004662638217268977, Final Batch Loss: 0.004565998911857605\n",
      "Epoch 4783, Loss: 3.9169098272395786e-05, Final Batch Loss: 3.397760519874282e-05\n",
      "Epoch 4784, Loss: 0.00016560082440264523, Final Batch Loss: 1.779351441655308e-05\n",
      "Epoch 4785, Loss: 0.00038446290000138106, Final Batch Loss: 0.0003777428646571934\n",
      "Epoch 4786, Loss: 5.694014930668345e-05, Final Batch Loss: 5.5988428357522935e-05\n",
      "Epoch 4787, Loss: 0.00043498693230503704, Final Batch Loss: 1.9327742847963236e-05\n",
      "Epoch 4788, Loss: 5.662068178935442e-05, Final Batch Loss: 3.148630275973119e-05\n",
      "Epoch 4789, Loss: 0.0017795540625229478, Final Batch Loss: 0.0015675581526011229\n",
      "Epoch 4790, Loss: 0.01208471949576051, Final Batch Loss: 0.01204993948340416\n",
      "Epoch 4791, Loss: 0.00011561867631826317, Final Batch Loss: 0.00010520461364649236\n",
      "Epoch 4792, Loss: 2.6079745566676138e-05, Final Batch Loss: 6.8332715272845235e-06\n",
      "Epoch 4793, Loss: 3.051670137210749e-05, Final Batch Loss: 1.5271196389221586e-05\n",
      "Epoch 4794, Loss: 0.0005292165328683041, Final Batch Loss: 3.217591711290879e-06\n",
      "Epoch 4795, Loss: 0.00022699603437104088, Final Batch Loss: 3.3647477266640635e-06\n",
      "Epoch 4796, Loss: 7.982122588146012e-05, Final Batch Loss: 7.7727650932502e-05\n",
      "Epoch 4797, Loss: 8.69834311743034e-05, Final Batch Loss: 1.937417073349934e-05\n",
      "Epoch 4798, Loss: 7.04094526327026e-06, Final Batch Loss: 9.183106044474698e-07\n",
      "Epoch 4799, Loss: 3.71891951544967e-05, Final Batch Loss: 3.1410352676175535e-05\n",
      "Epoch 4800, Loss: 2.7110057999379933e-05, Final Batch Loss: 4.8665478971088305e-06\n",
      "Epoch 4801, Loss: 6.171422000988969e-06, Final Batch Loss: 3.5438847589830402e-06\n",
      "Epoch 4802, Loss: 3.538537703207112e-05, Final Batch Loss: 3.220400685677305e-05\n",
      "Epoch 4803, Loss: 6.431975543819135e-05, Final Batch Loss: 5.999835775583051e-05\n",
      "Epoch 4804, Loss: 0.00142879330451251, Final Batch Loss: 0.0014239739393815398\n",
      "Epoch 4805, Loss: 8.420698463851295e-05, Final Batch Loss: 8.116727258311585e-05\n",
      "Epoch 4806, Loss: 8.390883022002527e-05, Final Batch Loss: 8.045491995289922e-05\n",
      "Epoch 4807, Loss: 9.982824280996283e-06, Final Batch Loss: 8.323098882101476e-06\n",
      "Epoch 4808, Loss: 7.387147343251854e-05, Final Batch Loss: 2.385100378887728e-05\n",
      "Epoch 4809, Loss: 2.4636061453975344e-05, Final Batch Loss: 2.63014982238019e-07\n",
      "Epoch 4810, Loss: 5.600146693041097e-06, Final Batch Loss: 3.2545759154345433e-07\n",
      "Epoch 4811, Loss: 1.6323723230016185e-05, Final Batch Loss: 2.3428879103448708e-06\n",
      "Epoch 4812, Loss: 2.1041941181465518e-05, Final Batch Loss: 8.260103641077876e-06\n",
      "Epoch 4813, Loss: 1.2856346643275174e-05, Final Batch Loss: 1.1320051271468401e-05\n",
      "Epoch 4814, Loss: 0.00019234915089327842, Final Batch Loss: 7.942219235701486e-05\n",
      "Epoch 4815, Loss: 6.454604681493947e-05, Final Batch Loss: 4.944543252349831e-05\n",
      "Epoch 4816, Loss: 2.6743298576548113e-05, Final Batch Loss: 2.5453537091379985e-05\n",
      "Epoch 4817, Loss: 3.751507665583631e-05, Final Batch Loss: 2.3998318283702247e-06\n",
      "Epoch 4818, Loss: 0.006103576150053414, Final Batch Loss: 4.9958460294874385e-05\n",
      "Epoch 4819, Loss: 0.0005047841841587797, Final Batch Loss: 0.00019005512876901776\n",
      "Epoch 4820, Loss: 0.00023222133495437447, Final Batch Loss: 1.3007820598431863e-05\n",
      "Epoch 4821, Loss: 0.0008590288052801043, Final Batch Loss: 0.0006836248794570565\n",
      "Epoch 4822, Loss: 0.00015404920304717962, Final Batch Loss: 2.0520581529126503e-05\n",
      "Epoch 4823, Loss: 7.751244379505806e-05, Final Batch Loss: 9.814041277422803e-07\n",
      "Epoch 4824, Loss: 0.0007903286532382481, Final Batch Loss: 2.1199397451709956e-05\n",
      "Epoch 4825, Loss: 0.0009882589729386382, Final Batch Loss: 0.0009568256209604442\n",
      "Epoch 4826, Loss: 0.0013359657596083707, Final Batch Loss: 7.945985089463647e-06\n",
      "Epoch 4827, Loss: 0.004551016694676946, Final Batch Loss: 1.2190050256322138e-05\n",
      "Epoch 4828, Loss: 9.383334418089362e-05, Final Batch Loss: 7.991214079083875e-05\n",
      "Epoch 4829, Loss: 7.546033543803787e-05, Final Batch Loss: 1.9513793176884064e-06\n",
      "Epoch 4830, Loss: 0.00011420878502121923, Final Batch Loss: 0.00011246507347095758\n",
      "Epoch 4831, Loss: 2.6277839424437843e-05, Final Batch Loss: 1.3943886187917087e-05\n",
      "Epoch 4832, Loss: 9.283460030928836e-06, Final Batch Loss: 2.180305500587565e-06\n",
      "Epoch 4833, Loss: 9.650548599893227e-05, Final Batch Loss: 3.536614531185478e-05\n",
      "Epoch 4834, Loss: 0.00021413944341475144, Final Batch Loss: 0.0001035127424984239\n",
      "Epoch 4835, Loss: 0.00029248134160297923, Final Batch Loss: 0.0002698864263948053\n",
      "Epoch 4836, Loss: 3.9685714909865055e-05, Final Batch Loss: 6.94360369379865e-06\n",
      "Epoch 4837, Loss: 0.00011993708267254988, Final Batch Loss: 1.6707062968635e-06\n",
      "Epoch 4838, Loss: 3.1353466965811094e-05, Final Batch Loss: 2.8127908080932684e-05\n",
      "Epoch 4839, Loss: 8.32525128657835e-06, Final Batch Loss: 3.3113482800217753e-07\n",
      "Epoch 4840, Loss: 1.9479309059988736e-05, Final Batch Loss: 8.167651799340092e-07\n",
      "Epoch 4841, Loss: 2.2809633264841978e-05, Final Batch Loss: 1.2073237485310528e-05\n",
      "Epoch 4842, Loss: 6.86546241013275e-06, Final Batch Loss: 3.4381823752482887e-06\n",
      "Epoch 4843, Loss: 0.0002255724839415052, Final Batch Loss: 8.321731911564711e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4844, Loss: 9.415656222699909e-06, Final Batch Loss: 2.535747626097873e-06\n",
      "Epoch 4845, Loss: 0.0005742817011196166, Final Batch Loss: 0.00027703167870640755\n",
      "Epoch 4846, Loss: 1.1558293067537306e-05, Final Batch Loss: 1.3894401718062e-06\n",
      "Epoch 4847, Loss: 2.6923916266241577e-05, Final Batch Loss: 7.387500772892963e-06\n",
      "Epoch 4848, Loss: 1.1016149528586539e-05, Final Batch Loss: 8.741216333874036e-06\n",
      "Epoch 4849, Loss: 0.0038904047978576273, Final Batch Loss: 0.0038589532487094402\n",
      "Epoch 4850, Loss: 1.1488857353469939e-05, Final Batch Loss: 8.135365533235017e-06\n",
      "Epoch 4851, Loss: 3.978940276283538e-05, Final Batch Loss: 6.163815669424366e-06\n",
      "Epoch 4852, Loss: 3.272541317755895e-05, Final Batch Loss: 6.092816988712002e-07\n",
      "Epoch 4853, Loss: 0.000299573965548916, Final Batch Loss: 2.2705376068188343e-06\n",
      "Epoch 4854, Loss: 0.0003402732995709812, Final Batch Loss: 3.9521414691989776e-06\n",
      "Epoch 4855, Loss: 2.1721593839174602e-05, Final Batch Loss: 5.3873200158705e-06\n",
      "Epoch 4856, Loss: 2.667980606929632e-05, Final Batch Loss: 1.8469861970515922e-05\n",
      "Epoch 4857, Loss: 5.1475835903147527e-05, Final Batch Loss: 5.0171776820207015e-05\n",
      "Epoch 4858, Loss: 8.66236723595648e-06, Final Batch Loss: 6.1621403801837e-07\n",
      "Epoch 4859, Loss: 1.5344104440373485e-05, Final Batch Loss: 3.164027702950989e-06\n",
      "Epoch 4860, Loss: 8.948551291609874e-05, Final Batch Loss: 2.838296211393754e-07\n",
      "Epoch 4861, Loss: 2.4189509986172197e-05, Final Batch Loss: 2.0185543689876795e-05\n",
      "Epoch 4862, Loss: 1.374483485960809e-05, Final Batch Loss: 1.297961489399313e-06\n",
      "Epoch 4863, Loss: 0.00018571831895997093, Final Batch Loss: 5.285502879814885e-07\n",
      "Epoch 4864, Loss: 0.0002878060331568122, Final Batch Loss: 0.0001356554712401703\n",
      "Epoch 4865, Loss: 1.587114041967652e-05, Final Batch Loss: 2.125574951605813e-07\n",
      "Epoch 4866, Loss: 7.404769348795526e-05, Final Batch Loss: 6.190165731823072e-05\n",
      "Epoch 4867, Loss: 1.0105312867381144e-05, Final Batch Loss: 5.687208158633439e-06\n",
      "Epoch 4868, Loss: 0.00022481233872895245, Final Batch Loss: 0.00021721363009419292\n",
      "Epoch 4869, Loss: 0.00015529419215454254, Final Batch Loss: 0.0001301504235016182\n",
      "Epoch 4870, Loss: 0.00013095305985189043, Final Batch Loss: 0.00011964839359279722\n",
      "Epoch 4871, Loss: 0.00023807922343621613, Final Batch Loss: 4.0747204366198275e-06\n",
      "Epoch 4872, Loss: 7.728812590812595e-06, Final Batch Loss: 7.96567121597036e-07\n",
      "Epoch 4873, Loss: 6.656296363871661e-06, Final Batch Loss: 4.856536179431714e-06\n",
      "Epoch 4874, Loss: 0.0003127782431420201, Final Batch Loss: 1.9821047771984013e-06\n",
      "Epoch 4875, Loss: 0.00040748793981038034, Final Batch Loss: 0.00032395918969996274\n",
      "Epoch 4876, Loss: 4.348556831246242e-05, Final Batch Loss: 1.7293778000748716e-05\n",
      "Epoch 4877, Loss: 0.000489300065964926, Final Batch Loss: 0.00040983851067721844\n",
      "Epoch 4878, Loss: 7.70522224229353e-05, Final Batch Loss: 2.7635965125227813e-06\n",
      "Epoch 4879, Loss: 5.286830173645285e-06, Final Batch Loss: 2.0554018647089833e-06\n",
      "Epoch 4880, Loss: 1.3478189544002817e-05, Final Batch Loss: 1.2380943417156232e-06\n",
      "Epoch 4881, Loss: 0.001242524600456818, Final Batch Loss: 6.479100193246268e-06\n",
      "Epoch 4882, Loss: 0.000129489386381465, Final Batch Loss: 1.4550858395523392e-05\n",
      "Epoch 4883, Loss: 3.7580581420115777e-06, Final Batch Loss: 3.1458246212423546e-06\n",
      "Epoch 4884, Loss: 0.0003800516569754109, Final Batch Loss: 0.00027725554537028074\n",
      "Epoch 4885, Loss: 3.373119653815593e-05, Final Batch Loss: 6.231519478205882e-07\n",
      "Epoch 4886, Loss: 8.386117724512587e-05, Final Batch Loss: 5.55663746126811e-06\n",
      "Epoch 4887, Loss: 0.00037949182660668157, Final Batch Loss: 0.00032251887023448944\n",
      "Epoch 4888, Loss: 0.00034728654100035783, Final Batch Loss: 6.613370715058409e-06\n",
      "Epoch 4889, Loss: 1.38259695177112e-05, Final Batch Loss: 1.434214254913968e-06\n",
      "Epoch 4890, Loss: 1.3073189848000766e-05, Final Batch Loss: 1.2452360351744574e-05\n",
      "Epoch 4891, Loss: 3.954770181735512e-05, Final Batch Loss: 3.179747727699578e-05\n",
      "Epoch 4892, Loss: 8.87406276888214e-05, Final Batch Loss: 2.96629877993837e-05\n",
      "Epoch 4893, Loss: 0.0004252899661878473, Final Batch Loss: 0.0004169465973973274\n",
      "Epoch 4894, Loss: 5.9720667195506394e-05, Final Batch Loss: 5.3367966756923124e-05\n",
      "Epoch 4895, Loss: 1.3283639418659732e-05, Final Batch Loss: 1.0410862159915268e-05\n",
      "Epoch 4896, Loss: 0.001450482679047127, Final Batch Loss: 7.502192147512687e-06\n",
      "Epoch 4897, Loss: 0.002568239283391449, Final Batch Loss: 7.201389053079765e-06\n",
      "Epoch 4898, Loss: 1.4336007666315709e-05, Final Batch Loss: 1.787440055522893e-06\n",
      "Epoch 4899, Loss: 0.0002184625482186675, Final Batch Loss: 9.31590620893985e-05\n",
      "Epoch 4900, Loss: 6.746498547727242e-05, Final Batch Loss: 5.199409861234017e-05\n",
      "Epoch 4901, Loss: 0.03151152058671869, Final Batch Loss: 0.03149517625570297\n",
      "Epoch 4902, Loss: 1.88708295354445e-05, Final Batch Loss: 1.392401918565156e-05\n",
      "Epoch 4903, Loss: 7.97853340372967e-06, Final Batch Loss: 3.301040806036326e-06\n",
      "Epoch 4904, Loss: 4.000272974735708e-05, Final Batch Loss: 3.542488411767408e-05\n",
      "Epoch 4905, Loss: 1.0407396302980487e-05, Final Batch Loss: 7.880470548116136e-06\n",
      "Epoch 4906, Loss: 0.00048778003838378936, Final Batch Loss: 0.0002290338306920603\n",
      "Epoch 4907, Loss: 0.000291347510938067, Final Batch Loss: 0.00020757585298269987\n",
      "Epoch 4908, Loss: 0.00010461050442245323, Final Batch Loss: 5.427174983196892e-06\n",
      "Epoch 4909, Loss: 6.542591017932864e-05, Final Batch Loss: 1.1936183909710962e-05\n",
      "Epoch 4910, Loss: 9.662356751505286e-05, Final Batch Loss: 6.775251677026972e-05\n",
      "Epoch 4911, Loss: 0.00023944632812344935, Final Batch Loss: 1.9270626580691896e-05\n",
      "Epoch 4912, Loss: 0.0002659884048625827, Final Batch Loss: 0.00010881241178140044\n",
      "Epoch 4913, Loss: 4.692059769695334e-05, Final Batch Loss: 4.556548083201051e-05\n",
      "Epoch 4914, Loss: 0.0034581596264615655, Final Batch Loss: 0.0012902611633762717\n",
      "Epoch 4915, Loss: 3.061854567931732e-05, Final Batch Loss: 2.0329458493506536e-05\n",
      "Epoch 4916, Loss: 0.00016205343854380772, Final Batch Loss: 4.8326110118068755e-05\n",
      "Epoch 4917, Loss: 0.0002373433053435292, Final Batch Loss: 9.032675734488294e-06\n",
      "Epoch 4918, Loss: 0.0034503316919654026, Final Batch Loss: 1.3029616638959851e-05\n",
      "Epoch 4919, Loss: 0.00019148631417920114, Final Batch Loss: 0.00018001718854065984\n",
      "Epoch 4920, Loss: 0.00019775982400460634, Final Batch Loss: 0.00017906969878822565\n",
      "Epoch 4921, Loss: 3.514562740747351e-05, Final Batch Loss: 1.4575913155567832e-05\n",
      "Epoch 4922, Loss: 3.033907796634594e-05, Final Batch Loss: 9.854783456830774e-06\n",
      "Epoch 4923, Loss: 2.3400412374030566e-05, Final Batch Loss: 2.155226502509322e-05\n",
      "Epoch 4924, Loss: 1.8500726810088963e-05, Final Batch Loss: 3.721308985404903e-07\n",
      "Epoch 4925, Loss: 8.179361611837521e-05, Final Batch Loss: 6.0189879150129855e-05\n",
      "Epoch 4926, Loss: 0.00024777195358183235, Final Batch Loss: 0.0001443258224753663\n",
      "Epoch 4927, Loss: 0.00011351443663443206, Final Batch Loss: 0.00010353235120419413\n",
      "Epoch 4928, Loss: 6.27608801551105e-05, Final Batch Loss: 5.845314444741234e-05\n",
      "Epoch 4929, Loss: 0.00119077815907076, Final Batch Loss: 0.0001976242638193071\n",
      "Epoch 4930, Loss: 7.829232714584577e-06, Final Batch Loss: 2.2832583113086002e-07\n",
      "Epoch 4931, Loss: 3.228277228117804e-05, Final Batch Loss: 5.93215145272552e-06\n",
      "Epoch 4932, Loss: 7.388990343315527e-05, Final Batch Loss: 8.401591912843287e-06\n",
      "Epoch 4933, Loss: 0.0015033385425340384, Final Batch Loss: 8.477884694002569e-05\n",
      "Epoch 4934, Loss: 0.00015685570679124794, Final Batch Loss: 1.980953584279632e-06\n",
      "Epoch 4935, Loss: 2.007746934395982e-05, Final Batch Loss: 5.485017936734948e-06\n",
      "Epoch 4936, Loss: 3.1217510240821866e-05, Final Batch Loss: 5.7282682064396795e-06\n",
      "Epoch 4937, Loss: 0.0014767456959816627, Final Batch Loss: 8.571799116907641e-05\n",
      "Epoch 4938, Loss: 0.0015024328022263944, Final Batch Loss: 0.0007439468754455447\n",
      "Epoch 4939, Loss: 3.586630214158504e-06, Final Batch Loss: 2.9090545012877556e-06\n",
      "Epoch 4940, Loss: 7.547029554189066e-06, Final Batch Loss: 5.375399268814363e-06\n",
      "Epoch 4941, Loss: 6.561161228546553e-06, Final Batch Loss: 6.660430358351732e-07\n",
      "Epoch 4942, Loss: 1.0460691555636004e-05, Final Batch Loss: 7.75832450017333e-06\n",
      "Epoch 4943, Loss: 6.795512263124692e-06, Final Batch Loss: 2.4779099021543516e-06\n",
      "Epoch 4944, Loss: 0.00017387350192166195, Final Batch Loss: 6.937926855243859e-07\n",
      "Epoch 4945, Loss: 8.16995307104662e-05, Final Batch Loss: 2.4463752197334543e-05\n",
      "Epoch 4946, Loss: 0.0003982433570399735, Final Batch Loss: 0.0003951542894355953\n",
      "Epoch 4947, Loss: 4.3382004150771536e-05, Final Batch Loss: 1.3289685739437118e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4948, Loss: 1.959516112037818e-05, Final Batch Loss: 1.4883934454701375e-05\n",
      "Epoch 4949, Loss: 6.9973755216778954e-06, Final Batch Loss: 4.769332008436322e-06\n",
      "Epoch 4950, Loss: 0.0006368725428274047, Final Batch Loss: 3.356426759637543e-06\n",
      "Epoch 4951, Loss: 0.00010268626920151291, Final Batch Loss: 1.2652878467633855e-05\n",
      "Epoch 4952, Loss: 0.0001991934077523183, Final Batch Loss: 3.324319186503999e-05\n",
      "Epoch 4953, Loss: 5.492302625498269e-05, Final Batch Loss: 1.281084587390069e-05\n",
      "Epoch 4954, Loss: 0.00037339064527941446, Final Batch Loss: 0.0003724808630067855\n",
      "Epoch 4955, Loss: 8.303749382321257e-05, Final Batch Loss: 7.236948295030743e-05\n",
      "Epoch 4956, Loss: 0.00027133744356433454, Final Batch Loss: 0.0002683489874470979\n",
      "Epoch 4957, Loss: 2.03126586484359e-06, Final Batch Loss: 3.7023909271738376e-07\n",
      "Epoch 4958, Loss: 0.0003716269562907826, Final Batch Loss: 3.847493346142983e-08\n",
      "Epoch 4959, Loss: 2.31641474783828e-05, Final Batch Loss: 1.742218591971323e-05\n",
      "Epoch 4960, Loss: 0.00024908090563258156, Final Batch Loss: 0.00023611547658219934\n",
      "Epoch 4961, Loss: 6.64399254901582e-05, Final Batch Loss: 6.477178976638243e-05\n",
      "Epoch 4962, Loss: 7.376517987722764e-05, Final Batch Loss: 5.931306804995984e-05\n",
      "Epoch 4963, Loss: 5.0639276793162935e-05, Final Batch Loss: 3.229339711197099e-07\n",
      "Epoch 4964, Loss: 0.023587602186580625, Final Batch Loss: 6.531361123052193e-06\n",
      "Epoch 4965, Loss: 2.1130826553417137e-05, Final Batch Loss: 5.268980658001965e-06\n",
      "Epoch 4966, Loss: 1.3300270893523702e-05, Final Batch Loss: 5.451807282952359e-06\n",
      "Epoch 4967, Loss: 0.0001820216748456005, Final Batch Loss: 0.000141545053338632\n",
      "Epoch 4968, Loss: 3.374596440153255e-05, Final Batch Loss: 1.0003279840020696e-06\n",
      "Epoch 4969, Loss: 0.0031986349104045075, Final Batch Loss: 8.402702405874152e-06\n",
      "Epoch 4970, Loss: 1.3284121905599022e-05, Final Batch Loss: 5.986510586808436e-06\n",
      "Epoch 4971, Loss: 0.00022090874409741446, Final Batch Loss: 3.4374971846773406e-07\n",
      "Epoch 4972, Loss: 0.0004081395193225035, Final Batch Loss: 0.00040474391425959766\n",
      "Epoch 4973, Loss: 3.7656399399566e-05, Final Batch Loss: 5.5321515901596285e-06\n",
      "Epoch 4974, Loss: 5.9143420003238134e-05, Final Batch Loss: 3.742202534340322e-05\n",
      "Epoch 4975, Loss: 0.0004596393082465511, Final Batch Loss: 0.0004184268182143569\n",
      "Epoch 4976, Loss: 4.638719110516831e-05, Final Batch Loss: 3.670896330731921e-05\n",
      "Epoch 4977, Loss: 8.555181011615787e-05, Final Batch Loss: 1.2666963812080212e-05\n",
      "Epoch 4978, Loss: 1.2078767667844659e-05, Final Batch Loss: 7.307716259674635e-06\n",
      "Epoch 4979, Loss: 7.5561417247627105e-06, Final Batch Loss: 6.614407084271079e-06\n",
      "Epoch 4980, Loss: 0.0002587928975117393, Final Batch Loss: 0.00016067670367192477\n",
      "Epoch 4981, Loss: 5.383227862409967e-05, Final Batch Loss: 1.7849770017619448e-07\n",
      "Epoch 4982, Loss: 0.0001509617595729651, Final Batch Loss: 2.7610296456259675e-05\n",
      "Epoch 4983, Loss: 4.6772324822086375e-05, Final Batch Loss: 1.4046904652786907e-05\n",
      "Epoch 4984, Loss: 2.4584643142588902e-05, Final Batch Loss: 3.580177690309938e-06\n",
      "Epoch 4985, Loss: 7.289450695679989e-05, Final Batch Loss: 2.1488738639163785e-05\n",
      "Epoch 4986, Loss: 8.232231812144164e-05, Final Batch Loss: 6.45674517727457e-05\n",
      "Epoch 4987, Loss: 0.001203850596311895, Final Batch Loss: 6.427151220123051e-07\n",
      "Epoch 4988, Loss: 2.0133584257564507e-05, Final Batch Loss: 1.3920745004725177e-05\n",
      "Epoch 4989, Loss: 9.099730732486933e-06, Final Batch Loss: 2.312099468326778e-06\n",
      "Epoch 4990, Loss: 0.00012135211818531388, Final Batch Loss: 0.00011572519724722952\n",
      "Epoch 4991, Loss: 1.8756353711069096e-05, Final Batch Loss: 9.147914170171134e-06\n",
      "Epoch 4992, Loss: 2.3087621684680926e-05, Final Batch Loss: 2.1468208615260664e-06\n",
      "Epoch 4993, Loss: 3.275847438999335e-05, Final Batch Loss: 5.669771326211048e-06\n",
      "Epoch 4994, Loss: 5.372064879338723e-05, Final Batch Loss: 2.12915019801585e-05\n",
      "Epoch 4995, Loss: 9.108520316658542e-06, Final Batch Loss: 2.2705489755026065e-06\n",
      "Epoch 4996, Loss: 8.427196007687598e-05, Final Batch Loss: 7.645448931725696e-05\n",
      "Epoch 4997, Loss: 1.1721967211997253e-05, Final Batch Loss: 1.065197375282878e-05\n",
      "Epoch 4998, Loss: 1.8308606286154827e-05, Final Batch Loss: 2.399090135440929e-06\n",
      "Epoch 4999, Loss: 5.372614032239653e-05, Final Batch Loss: 4.6003860916243866e-05\n",
      "Epoch 5000, Loss: 0.0014945372299735027, Final Batch Loss: 0.0014878354268148541\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  0  0]\n",
      " [ 1 39  0]\n",
      " [ 0  0 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96970   1.00000   0.98462        32\n",
      "           1    1.00000   0.97500   0.98734        40\n",
      "           2    1.00000   1.00000   1.00000        38\n",
      "\n",
      "    accuracy                        0.99091       110\n",
      "   macro avg    0.98990   0.99167   0.99065       110\n",
      "weighted avg    0.99118   0.99091   0.99092       110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (gen): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=106, out_features=80, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=80, out_features=60, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=60, out_features=50, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Linear(in_features=50, out_features=46, bias=True)\n",
       "    (4): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = Generator(z_dim = 106)\n",
    "load_model(gen, \"cGAN_UCI_Group_5_gen.param\")\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(X_test)\n",
    "latent_vectors = get_noise(size, 100)\n",
    "act_vectors = get_act_matrix(size, 3)\n",
    "usr_vectors = get_usr_matrix(size, 3)\n",
    "\n",
    "to_gen = torch.cat((latent_vectors, act_vectors[1], usr_vectors[1]), 1)\n",
    "fake_features = gen(to_gen).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  0  0]\n",
      " [ 0 33  0]\n",
      " [ 0  0 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        35\n",
      "           1    1.00000   1.00000   1.00000        33\n",
      "           2    1.00000   1.00000   1.00000        42\n",
      "\n",
      "    accuracy                        1.00000       110\n",
      "   macro avg    1.00000   1.00000   1.00000       110\n",
      "weighted avg    1.00000   1.00000   1.00000       110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(act_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(act_vectors[0], preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [23, 25, 27]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 23:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 25:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3086363077163696, Final Batch Loss: 1.1559561491012573\n",
      "Epoch 2, Loss: 2.3013386726379395, Final Batch Loss: 1.1542434692382812\n",
      "Epoch 3, Loss: 2.2967309951782227, Final Batch Loss: 1.149670124053955\n",
      "Epoch 4, Loss: 2.292755603790283, Final Batch Loss: 1.1495531797409058\n",
      "Epoch 5, Loss: 2.2890398502349854, Final Batch Loss: 1.1501538753509521\n",
      "Epoch 6, Loss: 2.2806206941604614, Final Batch Loss: 1.1259349584579468\n",
      "Epoch 7, Loss: 2.2806702852249146, Final Batch Loss: 1.140572428703308\n",
      "Epoch 8, Loss: 2.272704243659973, Final Batch Loss: 1.1240222454071045\n",
      "Epoch 9, Loss: 2.269160509109497, Final Batch Loss: 1.1231893301010132\n",
      "Epoch 10, Loss: 2.2675135135650635, Final Batch Loss: 1.1380356550216675\n",
      "Epoch 11, Loss: 2.2658989429473877, Final Batch Loss: 1.1533607244491577\n",
      "Epoch 12, Loss: 2.255954384803772, Final Batch Loss: 1.1186026334762573\n",
      "Epoch 13, Loss: 2.255547285079956, Final Batch Loss: 1.1265558004379272\n",
      "Epoch 14, Loss: 2.249314785003662, Final Batch Loss: 1.123370885848999\n",
      "Epoch 15, Loss: 2.2466689348220825, Final Batch Loss: 1.121555209159851\n",
      "Epoch 16, Loss: 2.2426435947418213, Final Batch Loss: 1.114362120628357\n",
      "Epoch 17, Loss: 2.2405734062194824, Final Batch Loss: 1.1282209157943726\n",
      "Epoch 18, Loss: 2.2331557273864746, Final Batch Loss: 1.115288496017456\n",
      "Epoch 19, Loss: 2.228993773460388, Final Batch Loss: 1.1135855913162231\n",
      "Epoch 20, Loss: 2.2247360944747925, Final Batch Loss: 1.1218901872634888\n",
      "Epoch 21, Loss: 2.2173250913619995, Final Batch Loss: 1.1107456684112549\n",
      "Epoch 22, Loss: 2.209894061088562, Final Batch Loss: 1.0982789993286133\n",
      "Epoch 23, Loss: 2.2019500732421875, Final Batch Loss: 1.0924264192581177\n",
      "Epoch 24, Loss: 2.203035831451416, Final Batch Loss: 1.0979820489883423\n",
      "Epoch 25, Loss: 2.1975845098495483, Final Batch Loss: 1.0987504720687866\n",
      "Epoch 26, Loss: 2.1886600255966187, Final Batch Loss: 1.0967681407928467\n",
      "Epoch 27, Loss: 2.1748381853103638, Final Batch Loss: 1.0885761976242065\n",
      "Epoch 28, Loss: 2.159432888031006, Final Batch Loss: 1.0679808855056763\n",
      "Epoch 29, Loss: 2.157509446144104, Final Batch Loss: 1.075091004371643\n",
      "Epoch 30, Loss: 2.1372718811035156, Final Batch Loss: 1.07063627243042\n",
      "Epoch 31, Loss: 2.136710047721863, Final Batch Loss: 1.0673683881759644\n",
      "Epoch 32, Loss: 2.1218732595443726, Final Batch Loss: 1.0645742416381836\n",
      "Epoch 33, Loss: 2.093395709991455, Final Batch Loss: 1.0318334102630615\n",
      "Epoch 34, Loss: 2.08615779876709, Final Batch Loss: 1.0346890687942505\n",
      "Epoch 35, Loss: 2.0806154012680054, Final Batch Loss: 1.0459789037704468\n",
      "Epoch 36, Loss: 2.0561347007751465, Final Batch Loss: 1.0308932065963745\n",
      "Epoch 37, Loss: 2.0440287590026855, Final Batch Loss: 1.016653299331665\n",
      "Epoch 38, Loss: 2.0439120531082153, Final Batch Loss: 1.0317814350128174\n",
      "Epoch 39, Loss: 1.9800732135772705, Final Batch Loss: 0.9861354827880859\n",
      "Epoch 40, Loss: 1.9771255850791931, Final Batch Loss: 0.9953604936599731\n",
      "Epoch 41, Loss: 1.9700161218643188, Final Batch Loss: 0.9772881269454956\n",
      "Epoch 42, Loss: 1.9057355523109436, Final Batch Loss: 0.9405950903892517\n",
      "Epoch 43, Loss: 1.8851836323738098, Final Batch Loss: 0.9202502965927124\n",
      "Epoch 44, Loss: 1.8704546093940735, Final Batch Loss: 0.9488955140113831\n",
      "Epoch 45, Loss: 1.838268220424652, Final Batch Loss: 0.9144318699836731\n",
      "Epoch 46, Loss: 1.8522658348083496, Final Batch Loss: 0.9587135314941406\n",
      "Epoch 47, Loss: 1.8192745447158813, Final Batch Loss: 0.9082828164100647\n",
      "Epoch 48, Loss: 1.82023423910141, Final Batch Loss: 0.9472569823265076\n",
      "Epoch 49, Loss: 1.7683931589126587, Final Batch Loss: 0.8572861552238464\n",
      "Epoch 50, Loss: 1.7507896423339844, Final Batch Loss: 0.8775042295455933\n",
      "Epoch 51, Loss: 1.7335760593414307, Final Batch Loss: 0.835639238357544\n",
      "Epoch 52, Loss: 1.7653396725654602, Final Batch Loss: 0.9066990613937378\n",
      "Epoch 53, Loss: 1.7187103629112244, Final Batch Loss: 0.8502269387245178\n",
      "Epoch 54, Loss: 1.7210626602172852, Final Batch Loss: 0.8526405692100525\n",
      "Epoch 55, Loss: 1.7048975825309753, Final Batch Loss: 0.8325448036193848\n",
      "Epoch 56, Loss: 1.6869885921478271, Final Batch Loss: 0.8328093886375427\n",
      "Epoch 57, Loss: 1.6852187514305115, Final Batch Loss: 0.8140404224395752\n",
      "Epoch 58, Loss: 1.7052444219589233, Final Batch Loss: 0.8987463712692261\n",
      "Epoch 59, Loss: 1.6265510320663452, Final Batch Loss: 0.8098727464675903\n",
      "Epoch 60, Loss: 1.6419392228126526, Final Batch Loss: 0.8436707258224487\n",
      "Epoch 61, Loss: 1.586864709854126, Final Batch Loss: 0.7718427777290344\n",
      "Epoch 62, Loss: 1.591461956501007, Final Batch Loss: 0.8092924356460571\n",
      "Epoch 63, Loss: 1.610305666923523, Final Batch Loss: 0.8003953695297241\n",
      "Epoch 64, Loss: 1.5887526869773865, Final Batch Loss: 0.8015689849853516\n",
      "Epoch 65, Loss: 1.5399373769760132, Final Batch Loss: 0.7131957411766052\n",
      "Epoch 66, Loss: 1.5430426001548767, Final Batch Loss: 0.7703836560249329\n",
      "Epoch 67, Loss: 1.5020854473114014, Final Batch Loss: 0.7773079872131348\n",
      "Epoch 68, Loss: 1.5429490804672241, Final Batch Loss: 0.7779586911201477\n",
      "Epoch 69, Loss: 1.5157068371772766, Final Batch Loss: 0.7339643836021423\n",
      "Epoch 70, Loss: 1.530647099018097, Final Batch Loss: 0.791057825088501\n",
      "Epoch 71, Loss: 1.5097811818122864, Final Batch Loss: 0.7668677568435669\n",
      "Epoch 72, Loss: 1.5005114078521729, Final Batch Loss: 0.716947615146637\n",
      "Epoch 73, Loss: 1.4505570530891418, Final Batch Loss: 0.7323121428489685\n",
      "Epoch 74, Loss: 1.4572476744651794, Final Batch Loss: 0.7324191927909851\n",
      "Epoch 75, Loss: 1.479473054409027, Final Batch Loss: 0.7691128849983215\n",
      "Epoch 76, Loss: 1.4567055106163025, Final Batch Loss: 0.746535062789917\n",
      "Epoch 77, Loss: 1.4189082980155945, Final Batch Loss: 0.6894914507865906\n",
      "Epoch 78, Loss: 1.4573120474815369, Final Batch Loss: 0.7196376919746399\n",
      "Epoch 79, Loss: 1.4497134685516357, Final Batch Loss: 0.7012186050415039\n",
      "Epoch 80, Loss: 1.3944958448410034, Final Batch Loss: 0.6946923732757568\n",
      "Epoch 81, Loss: 1.3989130854606628, Final Batch Loss: 0.7302220463752747\n",
      "Epoch 82, Loss: 1.379345953464508, Final Batch Loss: 0.7027807235717773\n",
      "Epoch 83, Loss: 1.3825952410697937, Final Batch Loss: 0.6803396940231323\n",
      "Epoch 84, Loss: 1.366378366947174, Final Batch Loss: 0.6685311198234558\n",
      "Epoch 85, Loss: 1.3401389122009277, Final Batch Loss: 0.6459039449691772\n",
      "Epoch 86, Loss: 1.3221746683120728, Final Batch Loss: 0.6715008020401001\n",
      "Epoch 87, Loss: 1.3644628524780273, Final Batch Loss: 0.7064760327339172\n",
      "Epoch 88, Loss: 1.3546958565711975, Final Batch Loss: 0.6770119071006775\n",
      "Epoch 89, Loss: 1.3494622111320496, Final Batch Loss: 0.6609355807304382\n",
      "Epoch 90, Loss: 1.3789405226707458, Final Batch Loss: 0.6964926719665527\n",
      "Epoch 91, Loss: 1.331028401851654, Final Batch Loss: 0.6725857257843018\n",
      "Epoch 92, Loss: 1.3369479179382324, Final Batch Loss: 0.6831907033920288\n",
      "Epoch 93, Loss: 1.2980793118476868, Final Batch Loss: 0.6698456406593323\n",
      "Epoch 94, Loss: 1.3255153894424438, Final Batch Loss: 0.6682483553886414\n",
      "Epoch 95, Loss: 1.2928774952888489, Final Batch Loss: 0.6420917510986328\n",
      "Epoch 96, Loss: 1.3100283741950989, Final Batch Loss: 0.6582382321357727\n",
      "Epoch 97, Loss: 1.2636197805404663, Final Batch Loss: 0.6256425380706787\n",
      "Epoch 98, Loss: 1.2529633045196533, Final Batch Loss: 0.6301063895225525\n",
      "Epoch 99, Loss: 1.2571913003921509, Final Batch Loss: 0.6230275630950928\n",
      "Epoch 100, Loss: 1.223229467868805, Final Batch Loss: 0.5862675905227661\n",
      "Epoch 101, Loss: 1.2227856516838074, Final Batch Loss: 0.6128870844841003\n",
      "Epoch 102, Loss: 1.1895215511322021, Final Batch Loss: 0.5726183652877808\n",
      "Epoch 103, Loss: 1.221835970878601, Final Batch Loss: 0.6339312195777893\n",
      "Epoch 104, Loss: 1.182045578956604, Final Batch Loss: 0.622890293598175\n",
      "Epoch 105, Loss: 1.198490023612976, Final Batch Loss: 0.6134482026100159\n",
      "Epoch 106, Loss: 1.1372894048690796, Final Batch Loss: 0.5855138897895813\n",
      "Epoch 107, Loss: 1.0883956551551819, Final Batch Loss: 0.54521244764328\n",
      "Epoch 108, Loss: 1.1099838614463806, Final Batch Loss: 0.5498819947242737\n",
      "Epoch 109, Loss: 1.1299058198928833, Final Batch Loss: 0.5756950378417969\n",
      "Epoch 110, Loss: 1.10342538356781, Final Batch Loss: 0.5485340356826782\n",
      "Epoch 111, Loss: 1.0753521621227264, Final Batch Loss: 0.48126497864723206\n",
      "Epoch 112, Loss: 1.0098174512386322, Final Batch Loss: 0.5105479955673218\n",
      "Epoch 113, Loss: 1.0837084650993347, Final Batch Loss: 0.5382351279258728\n",
      "Epoch 114, Loss: 1.0452115833759308, Final Batch Loss: 0.5464063882827759\n",
      "Epoch 115, Loss: 1.0347543060779572, Final Batch Loss: 0.5373414754867554\n",
      "Epoch 116, Loss: 1.0240940749645233, Final Batch Loss: 0.5272603631019592\n",
      "Epoch 117, Loss: 1.069145917892456, Final Batch Loss: 0.5105162262916565\n",
      "Epoch 118, Loss: 1.003953069448471, Final Batch Loss: 0.4678507149219513\n",
      "Epoch 119, Loss: 0.9538255035877228, Final Batch Loss: 0.4535556733608246\n",
      "Epoch 120, Loss: 1.0101985335350037, Final Batch Loss: 0.506217360496521\n",
      "Epoch 121, Loss: 0.9754758477210999, Final Batch Loss: 0.491850882768631\n",
      "Epoch 122, Loss: 0.9373200833797455, Final Batch Loss: 0.48065176606178284\n",
      "Epoch 123, Loss: 0.9711341261863708, Final Batch Loss: 0.4499897360801697\n",
      "Epoch 124, Loss: 0.9633004665374756, Final Batch Loss: 0.5086899995803833\n",
      "Epoch 125, Loss: 0.9696522057056427, Final Batch Loss: 0.46421191096305847\n",
      "Epoch 126, Loss: 0.9079692661762238, Final Batch Loss: 0.4730653762817383\n",
      "Epoch 127, Loss: 0.9305044710636139, Final Batch Loss: 0.500376284122467\n",
      "Epoch 128, Loss: 0.929406613111496, Final Batch Loss: 0.4565105140209198\n",
      "Epoch 129, Loss: 0.8970133066177368, Final Batch Loss: 0.46065351366996765\n",
      "Epoch 130, Loss: 0.9773929119110107, Final Batch Loss: 0.4866274893283844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131, Loss: 0.883942723274231, Final Batch Loss: 0.4319545328617096\n",
      "Epoch 132, Loss: 0.910086989402771, Final Batch Loss: 0.45880788564682007\n",
      "Epoch 133, Loss: 0.9022880494594574, Final Batch Loss: 0.4420330822467804\n",
      "Epoch 134, Loss: 0.8596119284629822, Final Batch Loss: 0.4077427387237549\n",
      "Epoch 135, Loss: 0.8388789594173431, Final Batch Loss: 0.3867569863796234\n",
      "Epoch 136, Loss: 0.8405241072177887, Final Batch Loss: 0.4078630208969116\n",
      "Epoch 137, Loss: 0.8370073735713959, Final Batch Loss: 0.3953127861022949\n",
      "Epoch 138, Loss: 0.8176299929618835, Final Batch Loss: 0.41398385167121887\n",
      "Epoch 139, Loss: 0.8498306274414062, Final Batch Loss: 0.38221725821495056\n",
      "Epoch 140, Loss: 0.815652459859848, Final Batch Loss: 0.41660013794898987\n",
      "Epoch 141, Loss: 0.7639546394348145, Final Batch Loss: 0.3342606723308563\n",
      "Epoch 142, Loss: 0.7943935096263885, Final Batch Loss: 0.38227570056915283\n",
      "Epoch 143, Loss: 0.7749638259410858, Final Batch Loss: 0.37422987818717957\n",
      "Epoch 144, Loss: 0.8343122005462646, Final Batch Loss: 0.4405696392059326\n",
      "Epoch 145, Loss: 0.7266561388969421, Final Batch Loss: 0.3709435760974884\n",
      "Epoch 146, Loss: 0.7819221019744873, Final Batch Loss: 0.380961149930954\n",
      "Epoch 147, Loss: 0.7330196797847748, Final Batch Loss: 0.34800347685813904\n",
      "Epoch 148, Loss: 0.703576385974884, Final Batch Loss: 0.3897734582424164\n",
      "Epoch 149, Loss: 0.7995331287384033, Final Batch Loss: 0.419975608587265\n",
      "Epoch 150, Loss: 0.7246835231781006, Final Batch Loss: 0.3148982524871826\n",
      "Epoch 151, Loss: 0.6983664631843567, Final Batch Loss: 0.3433440327644348\n",
      "Epoch 152, Loss: 0.6920344531536102, Final Batch Loss: 0.3409203886985779\n",
      "Epoch 153, Loss: 0.6829359233379364, Final Batch Loss: 0.33764007687568665\n",
      "Epoch 154, Loss: 0.7195552289485931, Final Batch Loss: 0.35057902336120605\n",
      "Epoch 155, Loss: 0.7058236598968506, Final Batch Loss: 0.282577246427536\n",
      "Epoch 156, Loss: 0.6850854754447937, Final Batch Loss: 0.3318065404891968\n",
      "Epoch 157, Loss: 0.6724891364574432, Final Batch Loss: 0.3458057641983032\n",
      "Epoch 158, Loss: 0.6582134962081909, Final Batch Loss: 0.3183954954147339\n",
      "Epoch 159, Loss: 0.6410296559333801, Final Batch Loss: 0.307586133480072\n",
      "Epoch 160, Loss: 0.662678599357605, Final Batch Loss: 0.29903095960617065\n",
      "Epoch 161, Loss: 0.668218731880188, Final Batch Loss: 0.30195942521095276\n",
      "Epoch 162, Loss: 0.6542423665523529, Final Batch Loss: 0.3344517648220062\n",
      "Epoch 163, Loss: 0.6408462524414062, Final Batch Loss: 0.3121741712093353\n",
      "Epoch 164, Loss: 0.6131727993488312, Final Batch Loss: 0.2835814952850342\n",
      "Epoch 165, Loss: 0.6797245740890503, Final Batch Loss: 0.3513709604740143\n",
      "Epoch 166, Loss: 0.65274578332901, Final Batch Loss: 0.28217852115631104\n",
      "Epoch 167, Loss: 0.641847550868988, Final Batch Loss: 0.33985650539398193\n",
      "Epoch 168, Loss: 0.6044577658176422, Final Batch Loss: 0.298530638217926\n",
      "Epoch 169, Loss: 0.6139965951442719, Final Batch Loss: 0.3247174024581909\n",
      "Epoch 170, Loss: 0.6182882189750671, Final Batch Loss: 0.3271799385547638\n",
      "Epoch 171, Loss: 0.6287295520305634, Final Batch Loss: 0.31887876987457275\n",
      "Epoch 172, Loss: 0.6228685677051544, Final Batch Loss: 0.31041231751441956\n",
      "Epoch 173, Loss: 0.5922624170780182, Final Batch Loss: 0.2605384290218353\n",
      "Epoch 174, Loss: 0.6039971709251404, Final Batch Loss: 0.34724265336990356\n",
      "Epoch 175, Loss: 0.6125594973564148, Final Batch Loss: 0.360840767621994\n",
      "Epoch 176, Loss: 0.5970446765422821, Final Batch Loss: 0.2840605676174164\n",
      "Epoch 177, Loss: 0.6158989667892456, Final Batch Loss: 0.29668569564819336\n",
      "Epoch 178, Loss: 0.6139413416385651, Final Batch Loss: 0.33922573924064636\n",
      "Epoch 179, Loss: 0.547511875629425, Final Batch Loss: 0.2621413469314575\n",
      "Epoch 180, Loss: 0.5464097708463669, Final Batch Loss: 0.23869119584560394\n",
      "Epoch 181, Loss: 0.5799243152141571, Final Batch Loss: 0.3217228949069977\n",
      "Epoch 182, Loss: 0.5917608439922333, Final Batch Loss: 0.2906455397605896\n",
      "Epoch 183, Loss: 0.5548741519451141, Final Batch Loss: 0.25416913628578186\n",
      "Epoch 184, Loss: 0.5969357490539551, Final Batch Loss: 0.2893831431865692\n",
      "Epoch 185, Loss: 0.6011243164539337, Final Batch Loss: 0.3186508119106293\n",
      "Epoch 186, Loss: 0.5461984574794769, Final Batch Loss: 0.24817171692848206\n",
      "Epoch 187, Loss: 0.5079818367958069, Final Batch Loss: 0.2440895140171051\n",
      "Epoch 188, Loss: 0.5150186419487, Final Batch Loss: 0.2756577730178833\n",
      "Epoch 189, Loss: 0.534389078617096, Final Batch Loss: 0.26680639386177063\n",
      "Epoch 190, Loss: 0.49743926525115967, Final Batch Loss: 0.25579625368118286\n",
      "Epoch 191, Loss: 0.5360483229160309, Final Batch Loss: 0.24549081921577454\n",
      "Epoch 192, Loss: 0.5118917375802994, Final Batch Loss: 0.23508094251155853\n",
      "Epoch 193, Loss: 0.5169438868761063, Final Batch Loss: 0.24695028364658356\n",
      "Epoch 194, Loss: 0.4986797869205475, Final Batch Loss: 0.26348623633384705\n",
      "Epoch 195, Loss: 0.4419175833463669, Final Batch Loss: 0.2196921706199646\n",
      "Epoch 196, Loss: 0.5036991685628891, Final Batch Loss: 0.24513591825962067\n",
      "Epoch 197, Loss: 0.4726365953683853, Final Batch Loss: 0.2292509377002716\n",
      "Epoch 198, Loss: 0.525510311126709, Final Batch Loss: 0.25476589798927307\n",
      "Epoch 199, Loss: 0.46608270704746246, Final Batch Loss: 0.2202649563550949\n",
      "Epoch 200, Loss: 0.4255076050758362, Final Batch Loss: 0.16435354948043823\n",
      "Epoch 201, Loss: 0.4594973772764206, Final Batch Loss: 0.2168736308813095\n",
      "Epoch 202, Loss: 0.49050140380859375, Final Batch Loss: 0.25039201974868774\n",
      "Epoch 203, Loss: 0.467699334025383, Final Batch Loss: 0.23055094480514526\n",
      "Epoch 204, Loss: 0.44629378616809845, Final Batch Loss: 0.23494675755500793\n",
      "Epoch 205, Loss: 0.47202153503894806, Final Batch Loss: 0.25362953543663025\n",
      "Epoch 206, Loss: 0.4475294053554535, Final Batch Loss: 0.21001525223255157\n",
      "Epoch 207, Loss: 0.4889994263648987, Final Batch Loss: 0.25501957535743713\n",
      "Epoch 208, Loss: 0.4214898943901062, Final Batch Loss: 0.21074654161930084\n",
      "Epoch 209, Loss: 0.5007976740598679, Final Batch Loss: 0.24930183589458466\n",
      "Epoch 210, Loss: 0.48326389491558075, Final Batch Loss: 0.24372108280658722\n",
      "Epoch 211, Loss: 0.4416213780641556, Final Batch Loss: 0.19571241736412048\n",
      "Epoch 212, Loss: 0.4138641804456711, Final Batch Loss: 0.2235899269580841\n",
      "Epoch 213, Loss: 0.4195112884044647, Final Batch Loss: 0.17054635286331177\n",
      "Epoch 214, Loss: 0.4602010101079941, Final Batch Loss: 0.24317023158073425\n",
      "Epoch 215, Loss: 0.4152376800775528, Final Batch Loss: 0.22115497291088104\n",
      "Epoch 216, Loss: 0.45214472711086273, Final Batch Loss: 0.22632862627506256\n",
      "Epoch 217, Loss: 0.40628691017627716, Final Batch Loss: 0.17102228105068207\n",
      "Epoch 218, Loss: 0.40329501032829285, Final Batch Loss: 0.17903080582618713\n",
      "Epoch 219, Loss: 0.4593712389469147, Final Batch Loss: 0.27972841262817383\n",
      "Epoch 220, Loss: 0.4147769510746002, Final Batch Loss: 0.2115800976753235\n",
      "Epoch 221, Loss: 0.40982042253017426, Final Batch Loss: 0.17407415807247162\n",
      "Epoch 222, Loss: 0.41152074933052063, Final Batch Loss: 0.2004902958869934\n",
      "Epoch 223, Loss: 0.3967660665512085, Final Batch Loss: 0.16451002657413483\n",
      "Epoch 224, Loss: 0.3920156955718994, Final Batch Loss: 0.18253041803836823\n",
      "Epoch 225, Loss: 0.37925077974796295, Final Batch Loss: 0.19238704442977905\n",
      "Epoch 226, Loss: 0.40851156413555145, Final Batch Loss: 0.22034944593906403\n",
      "Epoch 227, Loss: 0.3791666179895401, Final Batch Loss: 0.21592645347118378\n",
      "Epoch 228, Loss: 0.4392671585083008, Final Batch Loss: 0.24994789063930511\n",
      "Epoch 229, Loss: 0.3840029686689377, Final Batch Loss: 0.21457155048847198\n",
      "Epoch 230, Loss: 0.3864334672689438, Final Batch Loss: 0.20078805088996887\n",
      "Epoch 231, Loss: 0.42999041080474854, Final Batch Loss: 0.2095118910074234\n",
      "Epoch 232, Loss: 0.3672492504119873, Final Batch Loss: 0.1661497801542282\n",
      "Epoch 233, Loss: 0.3296913802623749, Final Batch Loss: 0.1899455487728119\n",
      "Epoch 234, Loss: 0.3673880845308304, Final Batch Loss: 0.1756199300289154\n",
      "Epoch 235, Loss: 0.3817790597677231, Final Batch Loss: 0.18993310630321503\n",
      "Epoch 236, Loss: 0.34527765214443207, Final Batch Loss: 0.13530869781970978\n",
      "Epoch 237, Loss: 0.34152495861053467, Final Batch Loss: 0.1832251399755478\n",
      "Epoch 238, Loss: 0.3848826289176941, Final Batch Loss: 0.180482879281044\n",
      "Epoch 239, Loss: 0.370681568980217, Final Batch Loss: 0.17108085751533508\n",
      "Epoch 240, Loss: 0.3886411488056183, Final Batch Loss: 0.15478964149951935\n",
      "Epoch 241, Loss: 0.35333941876888275, Final Batch Loss: 0.16921332478523254\n",
      "Epoch 242, Loss: 0.3518880754709244, Final Batch Loss: 0.17540262639522552\n",
      "Epoch 243, Loss: 0.33000048995018005, Final Batch Loss: 0.16480079293251038\n",
      "Epoch 244, Loss: 0.33796529471874237, Final Batch Loss: 0.18026933073997498\n",
      "Epoch 245, Loss: 0.3987147659063339, Final Batch Loss: 0.21777395904064178\n",
      "Epoch 246, Loss: 0.340969517827034, Final Batch Loss: 0.18274343013763428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247, Loss: 0.34961308538913727, Final Batch Loss: 0.16480015218257904\n",
      "Epoch 248, Loss: 0.3218728005886078, Final Batch Loss: 0.1408226490020752\n",
      "Epoch 249, Loss: 0.36421744525432587, Final Batch Loss: 0.16180890798568726\n",
      "Epoch 250, Loss: 0.3544015735387802, Final Batch Loss: 0.18981175124645233\n",
      "Epoch 251, Loss: 0.33909010887145996, Final Batch Loss: 0.12542863190174103\n",
      "Epoch 252, Loss: 0.4142443388700485, Final Batch Loss: 0.23956891894340515\n",
      "Epoch 253, Loss: 0.3465155363082886, Final Batch Loss: 0.1538282036781311\n",
      "Epoch 254, Loss: 0.330171599984169, Final Batch Loss: 0.189218670129776\n",
      "Epoch 255, Loss: 0.3814755231142044, Final Batch Loss: 0.17784714698791504\n",
      "Epoch 256, Loss: 0.33937792479991913, Final Batch Loss: 0.1832485944032669\n",
      "Epoch 257, Loss: 0.2855118662118912, Final Batch Loss: 0.1592671424150467\n",
      "Epoch 258, Loss: 0.38706086575984955, Final Batch Loss: 0.21445602178573608\n",
      "Epoch 259, Loss: 0.32787613570690155, Final Batch Loss: 0.1635766476392746\n",
      "Epoch 260, Loss: 0.33205658197402954, Final Batch Loss: 0.15995550155639648\n",
      "Epoch 261, Loss: 0.36315077543258667, Final Batch Loss: 0.20444515347480774\n",
      "Epoch 262, Loss: 0.3430204540491104, Final Batch Loss: 0.19461190700531006\n",
      "Epoch 263, Loss: 0.31235500425100327, Final Batch Loss: 0.10945313423871994\n",
      "Epoch 264, Loss: 0.3112928420305252, Final Batch Loss: 0.1627601683139801\n",
      "Epoch 265, Loss: 0.34083007276058197, Final Batch Loss: 0.17116288840770721\n",
      "Epoch 266, Loss: 0.2887476831674576, Final Batch Loss: 0.15353311598300934\n",
      "Epoch 267, Loss: 0.40221937000751495, Final Batch Loss: 0.23188099265098572\n",
      "Epoch 268, Loss: 0.36582455039024353, Final Batch Loss: 0.23494915664196014\n",
      "Epoch 269, Loss: 0.36203910410404205, Final Batch Loss: 0.15474791824817657\n",
      "Epoch 270, Loss: 0.2629752978682518, Final Batch Loss: 0.15323102474212646\n",
      "Epoch 271, Loss: 0.3408443182706833, Final Batch Loss: 0.15642496943473816\n",
      "Epoch 272, Loss: 0.32462216913700104, Final Batch Loss: 0.15148960053920746\n",
      "Epoch 273, Loss: 0.29867279529571533, Final Batch Loss: 0.17507719993591309\n",
      "Epoch 274, Loss: 0.3262319266796112, Final Batch Loss: 0.16701824963092804\n",
      "Epoch 275, Loss: 0.28149082511663437, Final Batch Loss: 0.11065828055143356\n",
      "Epoch 276, Loss: 0.3084067553281784, Final Batch Loss: 0.15401622653007507\n",
      "Epoch 277, Loss: 0.3371637314558029, Final Batch Loss: 0.21163125336170197\n",
      "Epoch 278, Loss: 0.3571997731924057, Final Batch Loss: 0.1610933542251587\n",
      "Epoch 279, Loss: 0.293770968914032, Final Batch Loss: 0.16750794649124146\n",
      "Epoch 280, Loss: 0.30290184915065765, Final Batch Loss: 0.17749881744384766\n",
      "Epoch 281, Loss: 0.28973981738090515, Final Batch Loss: 0.13316470384597778\n",
      "Epoch 282, Loss: 0.36958764493465424, Final Batch Loss: 0.15447735786437988\n",
      "Epoch 283, Loss: 0.3572358042001724, Final Batch Loss: 0.15666872262954712\n",
      "Epoch 284, Loss: 0.2970826178789139, Final Batch Loss: 0.14068855345249176\n",
      "Epoch 285, Loss: 0.29114146530628204, Final Batch Loss: 0.1309569925069809\n",
      "Epoch 286, Loss: 0.273524671792984, Final Batch Loss: 0.1375618427991867\n",
      "Epoch 287, Loss: 0.30471867322921753, Final Batch Loss: 0.18339252471923828\n",
      "Epoch 288, Loss: 0.4468987137079239, Final Batch Loss: 0.1889030784368515\n",
      "Epoch 289, Loss: 0.2870718985795975, Final Batch Loss: 0.1438373625278473\n",
      "Epoch 290, Loss: 0.2887001931667328, Final Batch Loss: 0.11506344377994537\n",
      "Epoch 291, Loss: 0.2749747037887573, Final Batch Loss: 0.11600476503372192\n",
      "Epoch 292, Loss: 0.35392822325229645, Final Batch Loss: 0.15145346522331238\n",
      "Epoch 293, Loss: 0.33718307316303253, Final Batch Loss: 0.15952168405056\n",
      "Epoch 294, Loss: 0.32050269842147827, Final Batch Loss: 0.2156536728143692\n",
      "Epoch 295, Loss: 0.2794623523950577, Final Batch Loss: 0.14472486078739166\n",
      "Epoch 296, Loss: 0.32161594927310944, Final Batch Loss: 0.18480077385902405\n",
      "Epoch 297, Loss: 0.27864018082618713, Final Batch Loss: 0.14815467596054077\n",
      "Epoch 298, Loss: 0.28014953434467316, Final Batch Loss: 0.14925502240657806\n",
      "Epoch 299, Loss: 0.33571699261665344, Final Batch Loss: 0.18210697174072266\n",
      "Epoch 300, Loss: 0.27045711874961853, Final Batch Loss: 0.13578100502490997\n",
      "Epoch 301, Loss: 0.3137567937374115, Final Batch Loss: 0.18592001497745514\n",
      "Epoch 302, Loss: 0.3194739520549774, Final Batch Loss: 0.1552429050207138\n",
      "Epoch 303, Loss: 0.29949410259723663, Final Batch Loss: 0.13227839767932892\n",
      "Epoch 304, Loss: 0.2498260661959648, Final Batch Loss: 0.0982770249247551\n",
      "Epoch 305, Loss: 0.2865383103489876, Final Batch Loss: 0.12494038790464401\n",
      "Epoch 306, Loss: 0.289045125246048, Final Batch Loss: 0.13283443450927734\n",
      "Epoch 307, Loss: 0.26536090672016144, Final Batch Loss: 0.12558767199516296\n",
      "Epoch 308, Loss: 0.28245536983013153, Final Batch Loss: 0.11812420189380646\n",
      "Epoch 309, Loss: 0.2965933009982109, Final Batch Loss: 0.17479932308197021\n",
      "Epoch 310, Loss: 0.31874363124370575, Final Batch Loss: 0.1553802192211151\n",
      "Epoch 311, Loss: 0.32059019804000854, Final Batch Loss: 0.1481984406709671\n",
      "Epoch 312, Loss: 0.2946110963821411, Final Batch Loss: 0.16706059873104095\n",
      "Epoch 313, Loss: 0.2496965527534485, Final Batch Loss: 0.09363028407096863\n",
      "Epoch 314, Loss: 0.3116120249032974, Final Batch Loss: 0.17640367150306702\n",
      "Epoch 315, Loss: 0.3156733363866806, Final Batch Loss: 0.18270520865917206\n",
      "Epoch 316, Loss: 0.31652137637138367, Final Batch Loss: 0.1528318077325821\n",
      "Epoch 317, Loss: 0.24925339967012405, Final Batch Loss: 0.13503308594226837\n",
      "Epoch 318, Loss: 0.28244754672050476, Final Batch Loss: 0.14181004464626312\n",
      "Epoch 319, Loss: 0.33562855422496796, Final Batch Loss: 0.2043566256761551\n",
      "Epoch 320, Loss: 0.30434608459472656, Final Batch Loss: 0.15550777316093445\n",
      "Epoch 321, Loss: 0.2929573506116867, Final Batch Loss: 0.13260874152183533\n",
      "Epoch 322, Loss: 0.2839127331972122, Final Batch Loss: 0.1354820877313614\n",
      "Epoch 323, Loss: 0.2589300349354744, Final Batch Loss: 0.10366696864366531\n",
      "Epoch 324, Loss: 0.3244553953409195, Final Batch Loss: 0.16729074716567993\n",
      "Epoch 325, Loss: 0.28628018498420715, Final Batch Loss: 0.10653077065944672\n",
      "Epoch 326, Loss: 0.2775653600692749, Final Batch Loss: 0.1506541669368744\n",
      "Epoch 327, Loss: 0.2676885649561882, Final Batch Loss: 0.11474808305501938\n",
      "Epoch 328, Loss: 0.21902130544185638, Final Batch Loss: 0.10718977451324463\n",
      "Epoch 329, Loss: 0.3102880269289017, Final Batch Loss: 0.1448252946138382\n",
      "Epoch 330, Loss: 0.28127747774124146, Final Batch Loss: 0.13691362738609314\n",
      "Epoch 331, Loss: 0.2738092541694641, Final Batch Loss: 0.13505658507347107\n",
      "Epoch 332, Loss: 0.25930043309926987, Final Batch Loss: 0.12285368889570236\n",
      "Epoch 333, Loss: 0.27996698021888733, Final Batch Loss: 0.14765803515911102\n",
      "Epoch 334, Loss: 0.2691921889781952, Final Batch Loss: 0.14937657117843628\n",
      "Epoch 335, Loss: 0.27217860519886017, Final Batch Loss: 0.13520236313343048\n",
      "Epoch 336, Loss: 0.2653907313942909, Final Batch Loss: 0.1544729322195053\n",
      "Epoch 337, Loss: 0.2685522809624672, Final Batch Loss: 0.15295064449310303\n",
      "Epoch 338, Loss: 0.2187987044453621, Final Batch Loss: 0.12557218968868256\n",
      "Epoch 339, Loss: 0.25792478024959564, Final Batch Loss: 0.12173321843147278\n",
      "Epoch 340, Loss: 0.27133625000715256, Final Batch Loss: 0.1166088804602623\n",
      "Epoch 341, Loss: 0.25586724281311035, Final Batch Loss: 0.15703634917736053\n",
      "Epoch 342, Loss: 0.23595871776342392, Final Batch Loss: 0.13081064820289612\n",
      "Epoch 343, Loss: 0.28179679065942764, Final Batch Loss: 0.08329225331544876\n",
      "Epoch 344, Loss: 0.2677132487297058, Final Batch Loss: 0.11603695154190063\n",
      "Epoch 345, Loss: 0.2473764419555664, Final Batch Loss: 0.1282123476266861\n",
      "Epoch 346, Loss: 0.25611068308353424, Final Batch Loss: 0.12477283179759979\n",
      "Epoch 347, Loss: 0.265075646340847, Final Batch Loss: 0.11927256733179092\n",
      "Epoch 348, Loss: 0.2252100482583046, Final Batch Loss: 0.11046521365642548\n",
      "Epoch 349, Loss: 0.27471567690372467, Final Batch Loss: 0.11607605218887329\n",
      "Epoch 350, Loss: 0.24691630899906158, Final Batch Loss: 0.1219823956489563\n",
      "Epoch 351, Loss: 0.2259623035788536, Final Batch Loss: 0.113062784075737\n",
      "Epoch 352, Loss: 0.30904383957386017, Final Batch Loss: 0.16719089448451996\n",
      "Epoch 353, Loss: 0.21039143204689026, Final Batch Loss: 0.08482791483402252\n",
      "Epoch 354, Loss: 0.21379563957452774, Final Batch Loss: 0.11175762861967087\n",
      "Epoch 355, Loss: 0.27535945177078247, Final Batch Loss: 0.1659250110387802\n",
      "Epoch 356, Loss: 0.2251795157790184, Final Batch Loss: 0.10405190289020538\n",
      "Epoch 357, Loss: 0.27925724536180496, Final Batch Loss: 0.11132239550352097\n",
      "Epoch 358, Loss: 0.28905758261680603, Final Batch Loss: 0.14249111711978912\n",
      "Epoch 359, Loss: 0.2699926048517227, Final Batch Loss: 0.14021074771881104\n",
      "Epoch 360, Loss: 0.23872461169958115, Final Batch Loss: 0.11148460954427719\n",
      "Epoch 361, Loss: 0.24348746985197067, Final Batch Loss: 0.08460385352373123\n",
      "Epoch 362, Loss: 0.342678427696228, Final Batch Loss: 0.18469136953353882\n",
      "Epoch 363, Loss: 0.24450332671403885, Final Batch Loss: 0.14094461500644684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364, Loss: 0.2477797567844391, Final Batch Loss: 0.16083915531635284\n",
      "Epoch 365, Loss: 0.26073676347732544, Final Batch Loss: 0.12189500033855438\n",
      "Epoch 366, Loss: 0.3366616815328598, Final Batch Loss: 0.13154369592666626\n",
      "Epoch 367, Loss: 0.23138292133808136, Final Batch Loss: 0.12063883244991302\n",
      "Epoch 368, Loss: 0.24936895072460175, Final Batch Loss: 0.15228338539600372\n",
      "Epoch 369, Loss: 0.23603935539722443, Final Batch Loss: 0.11188054084777832\n",
      "Epoch 370, Loss: 0.2693890854716301, Final Batch Loss: 0.12496484071016312\n",
      "Epoch 371, Loss: 0.19917602837085724, Final Batch Loss: 0.10790852457284927\n",
      "Epoch 372, Loss: 0.2761834114789963, Final Batch Loss: 0.1529269516468048\n",
      "Epoch 373, Loss: 0.20394328981637955, Final Batch Loss: 0.11632151156663895\n",
      "Epoch 374, Loss: 0.21282906085252762, Final Batch Loss: 0.09961779415607452\n",
      "Epoch 375, Loss: 0.23510070145130157, Final Batch Loss: 0.10419423878192902\n",
      "Epoch 376, Loss: 0.2470843344926834, Final Batch Loss: 0.12165090441703796\n",
      "Epoch 377, Loss: 0.1936313435435295, Final Batch Loss: 0.09080955386161804\n",
      "Epoch 378, Loss: 0.26662585139274597, Final Batch Loss: 0.12662558257579803\n",
      "Epoch 379, Loss: 0.223276786506176, Final Batch Loss: 0.10767250508069992\n",
      "Epoch 380, Loss: 0.22977320104837418, Final Batch Loss: 0.08191973716020584\n",
      "Epoch 381, Loss: 0.23903347551822662, Final Batch Loss: 0.12231414020061493\n",
      "Epoch 382, Loss: 0.3013123422861099, Final Batch Loss: 0.16091054677963257\n",
      "Epoch 383, Loss: 0.30138324201107025, Final Batch Loss: 0.16222693026065826\n",
      "Epoch 384, Loss: 0.2246105596423149, Final Batch Loss: 0.12208271771669388\n",
      "Epoch 385, Loss: 0.21442612260580063, Final Batch Loss: 0.10350034385919571\n",
      "Epoch 386, Loss: 0.2573013976216316, Final Batch Loss: 0.11278035491704941\n",
      "Epoch 387, Loss: 0.2048725038766861, Final Batch Loss: 0.0966382771730423\n",
      "Epoch 388, Loss: 0.26353007555007935, Final Batch Loss: 0.1377277672290802\n",
      "Epoch 389, Loss: 0.19618168473243713, Final Batch Loss: 0.10099826008081436\n",
      "Epoch 390, Loss: 0.24430032819509506, Final Batch Loss: 0.14621102809906006\n",
      "Epoch 391, Loss: 0.2132207304239273, Final Batch Loss: 0.1059161126613617\n",
      "Epoch 392, Loss: 0.22153425961732864, Final Batch Loss: 0.09234201163053513\n",
      "Epoch 393, Loss: 0.3144727796316147, Final Batch Loss: 0.12087103724479675\n",
      "Epoch 394, Loss: 0.22137043625116348, Final Batch Loss: 0.0952577218413353\n",
      "Epoch 395, Loss: 0.23601509630680084, Final Batch Loss: 0.15171849727630615\n",
      "Epoch 396, Loss: 0.21231987327337265, Final Batch Loss: 0.0874565839767456\n",
      "Epoch 397, Loss: 0.2423134744167328, Final Batch Loss: 0.10216513276100159\n",
      "Epoch 398, Loss: 0.21655113995075226, Final Batch Loss: 0.06521683931350708\n",
      "Epoch 399, Loss: 0.21374397724866867, Final Batch Loss: 0.12684676051139832\n",
      "Epoch 400, Loss: 0.2376575991511345, Final Batch Loss: 0.06810256093740463\n",
      "Epoch 401, Loss: 0.2269972711801529, Final Batch Loss: 0.1114819124341011\n",
      "Epoch 402, Loss: 0.2176712080836296, Final Batch Loss: 0.08180081099271774\n",
      "Epoch 403, Loss: 0.19133947044610977, Final Batch Loss: 0.10214048624038696\n",
      "Epoch 404, Loss: 0.20959866791963577, Final Batch Loss: 0.11929862946271896\n",
      "Epoch 405, Loss: 0.1893405020236969, Final Batch Loss: 0.08515682071447372\n",
      "Epoch 406, Loss: 0.2474937066435814, Final Batch Loss: 0.15829859673976898\n",
      "Epoch 407, Loss: 0.20576211810112, Final Batch Loss: 0.14334382116794586\n",
      "Epoch 408, Loss: 0.1910635530948639, Final Batch Loss: 0.08646620064973831\n",
      "Epoch 409, Loss: 0.21747908741235733, Final Batch Loss: 0.12208369374275208\n",
      "Epoch 410, Loss: 0.24510866403579712, Final Batch Loss: 0.15139682590961456\n",
      "Epoch 411, Loss: 0.20190104842185974, Final Batch Loss: 0.11047469079494476\n",
      "Epoch 412, Loss: 0.21519989520311356, Final Batch Loss: 0.10454351454973221\n",
      "Epoch 413, Loss: 0.216843843460083, Final Batch Loss: 0.10162453353404999\n",
      "Epoch 414, Loss: 0.17588718980550766, Final Batch Loss: 0.08307947963476181\n",
      "Epoch 415, Loss: 0.1979212388396263, Final Batch Loss: 0.10880333185195923\n",
      "Epoch 416, Loss: 0.19309736788272858, Final Batch Loss: 0.08155300468206406\n",
      "Epoch 417, Loss: 0.2232879176735878, Final Batch Loss: 0.09014434367418289\n",
      "Epoch 418, Loss: 0.210673950612545, Final Batch Loss: 0.132579505443573\n",
      "Epoch 419, Loss: 0.23211320489645004, Final Batch Loss: 0.09776832908391953\n",
      "Epoch 420, Loss: 0.2508612275123596, Final Batch Loss: 0.13003040850162506\n",
      "Epoch 421, Loss: 0.1877541020512581, Final Batch Loss: 0.09685450792312622\n",
      "Epoch 422, Loss: 0.257254995405674, Final Batch Loss: 0.16843487322330475\n",
      "Epoch 423, Loss: 0.22114448249340057, Final Batch Loss: 0.12369631230831146\n",
      "Epoch 424, Loss: 0.2395523488521576, Final Batch Loss: 0.11046366393566132\n",
      "Epoch 425, Loss: 0.2446441501379013, Final Batch Loss: 0.16141784191131592\n",
      "Epoch 426, Loss: 0.2042814865708351, Final Batch Loss: 0.10682763159275055\n",
      "Epoch 427, Loss: 0.1739097274839878, Final Batch Loss: 0.05894135311245918\n",
      "Epoch 428, Loss: 0.20306150615215302, Final Batch Loss: 0.11911417543888092\n",
      "Epoch 429, Loss: 0.22169800847768784, Final Batch Loss: 0.0840265229344368\n",
      "Epoch 430, Loss: 0.20210542529821396, Final Batch Loss: 0.12070640921592712\n",
      "Epoch 431, Loss: 0.19538664072752, Final Batch Loss: 0.09063228964805603\n",
      "Epoch 432, Loss: 0.23290212452411652, Final Batch Loss: 0.09663937985897064\n",
      "Epoch 433, Loss: 0.22907976806163788, Final Batch Loss: 0.11183887720108032\n",
      "Epoch 434, Loss: 0.22648776322603226, Final Batch Loss: 0.12514325976371765\n",
      "Epoch 435, Loss: 0.30572018027305603, Final Batch Loss: 0.12070149183273315\n",
      "Epoch 436, Loss: 0.22123730927705765, Final Batch Loss: 0.10457975417375565\n",
      "Epoch 437, Loss: 0.20415553450584412, Final Batch Loss: 0.09899581223726273\n",
      "Epoch 438, Loss: 0.2551674544811249, Final Batch Loss: 0.15296217799186707\n",
      "Epoch 439, Loss: 0.2230529710650444, Final Batch Loss: 0.1164339929819107\n",
      "Epoch 440, Loss: 0.18402556329965591, Final Batch Loss: 0.07587765157222748\n",
      "Epoch 441, Loss: 0.19828437268733978, Final Batch Loss: 0.10862580686807632\n",
      "Epoch 442, Loss: 0.2187001183629036, Final Batch Loss: 0.08533497899770737\n",
      "Epoch 443, Loss: 0.2224777415394783, Final Batch Loss: 0.13210129737854004\n",
      "Epoch 444, Loss: 0.2180391252040863, Final Batch Loss: 0.13731108605861664\n",
      "Epoch 445, Loss: 0.22255922108888626, Final Batch Loss: 0.0869029089808464\n",
      "Epoch 446, Loss: 0.23491527885198593, Final Batch Loss: 0.12145355343818665\n",
      "Epoch 447, Loss: 0.21745676547288895, Final Batch Loss: 0.10158589482307434\n",
      "Epoch 448, Loss: 0.19850879162549973, Final Batch Loss: 0.10354568064212799\n",
      "Epoch 449, Loss: 0.2096046879887581, Final Batch Loss: 0.09659487754106522\n",
      "Epoch 450, Loss: 0.18135925382375717, Final Batch Loss: 0.09811128675937653\n",
      "Epoch 451, Loss: 0.2256324663758278, Final Batch Loss: 0.13018600642681122\n",
      "Epoch 452, Loss: 0.20488961786031723, Final Batch Loss: 0.11467746645212173\n",
      "Epoch 453, Loss: 0.23809092491865158, Final Batch Loss: 0.11265971511602402\n",
      "Epoch 454, Loss: 0.21754523366689682, Final Batch Loss: 0.0735163763165474\n",
      "Epoch 455, Loss: 0.3074502795934677, Final Batch Loss: 0.13218756020069122\n",
      "Epoch 456, Loss: 0.25545307248830795, Final Batch Loss: 0.13910557329654694\n",
      "Epoch 457, Loss: 0.23897352069616318, Final Batch Loss: 0.14908824861049652\n",
      "Epoch 458, Loss: 0.2815859317779541, Final Batch Loss: 0.14775234460830688\n",
      "Epoch 459, Loss: 0.28000257164239883, Final Batch Loss: 0.16794593632221222\n",
      "Epoch 460, Loss: 0.23592247813940048, Final Batch Loss: 0.09575692564249039\n",
      "Epoch 461, Loss: 0.20247340202331543, Final Batch Loss: 0.09496805816888809\n",
      "Epoch 462, Loss: 0.1965959519147873, Final Batch Loss: 0.09717056900262833\n",
      "Epoch 463, Loss: 0.1922682672739029, Final Batch Loss: 0.08504892885684967\n",
      "Epoch 464, Loss: 0.27571776509284973, Final Batch Loss: 0.1550024300813675\n",
      "Epoch 465, Loss: 0.23038320988416672, Final Batch Loss: 0.13127906620502472\n",
      "Epoch 466, Loss: 0.18202432990074158, Final Batch Loss: 0.08633581548929214\n",
      "Epoch 467, Loss: 0.20779335498809814, Final Batch Loss: 0.11227505654096603\n",
      "Epoch 468, Loss: 0.22450093179941177, Final Batch Loss: 0.10574289411306381\n",
      "Epoch 469, Loss: 0.20106110721826553, Final Batch Loss: 0.10452424734830856\n",
      "Epoch 470, Loss: 0.19876626133918762, Final Batch Loss: 0.09307873249053955\n",
      "Epoch 471, Loss: 0.1774199679493904, Final Batch Loss: 0.08774378150701523\n",
      "Epoch 472, Loss: 0.2517850324511528, Final Batch Loss: 0.07336124032735825\n",
      "Epoch 473, Loss: 0.22418981790542603, Final Batch Loss: 0.10522469133138657\n",
      "Epoch 474, Loss: 0.21609847992658615, Final Batch Loss: 0.13070258498191833\n",
      "Epoch 475, Loss: 0.19866172969341278, Final Batch Loss: 0.11925749480724335\n",
      "Epoch 476, Loss: 0.2110862359404564, Final Batch Loss: 0.13364405930042267\n",
      "Epoch 477, Loss: 0.2649429738521576, Final Batch Loss: 0.15731361508369446\n",
      "Epoch 478, Loss: 0.18474596738815308, Final Batch Loss: 0.11180569231510162\n",
      "Epoch 479, Loss: 0.21348419040441513, Final Batch Loss: 0.08123067766427994\n",
      "Epoch 480, Loss: 0.21675938367843628, Final Batch Loss: 0.1185968667268753\n",
      "Epoch 481, Loss: 0.1969800442457199, Final Batch Loss: 0.10592315346002579\n",
      "Epoch 482, Loss: 0.1956072896718979, Final Batch Loss: 0.0762530043721199\n",
      "Epoch 483, Loss: 0.22476519644260406, Final Batch Loss: 0.07335840165615082\n",
      "Epoch 484, Loss: 0.20656826347112656, Final Batch Loss: 0.0915924459695816\n",
      "Epoch 485, Loss: 0.2617395594716072, Final Batch Loss: 0.12296482175588608\n",
      "Epoch 486, Loss: 0.19331544637680054, Final Batch Loss: 0.08836614340543747\n",
      "Epoch 487, Loss: 0.2641919404268265, Final Batch Loss: 0.12718336284160614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 488, Loss: 0.19346727430820465, Final Batch Loss: 0.08086694031953812\n",
      "Epoch 489, Loss: 0.18550102412700653, Final Batch Loss: 0.07841479033231735\n",
      "Epoch 490, Loss: 0.2242213785648346, Final Batch Loss: 0.1361234337091446\n",
      "Epoch 491, Loss: 0.19309549033641815, Final Batch Loss: 0.06857980787754059\n",
      "Epoch 492, Loss: 0.18466821312904358, Final Batch Loss: 0.07735401391983032\n",
      "Epoch 493, Loss: 0.21860643476247787, Final Batch Loss: 0.12872900068759918\n",
      "Epoch 494, Loss: 0.19851134717464447, Final Batch Loss: 0.07456520944833755\n",
      "Epoch 495, Loss: 0.1934514418244362, Final Batch Loss: 0.11348912864923477\n",
      "Epoch 496, Loss: 0.2126493975520134, Final Batch Loss: 0.09168587625026703\n",
      "Epoch 497, Loss: 0.15207058191299438, Final Batch Loss: 0.08889327198266983\n",
      "Epoch 498, Loss: 0.14644037187099457, Final Batch Loss: 0.06304334849119186\n",
      "Epoch 499, Loss: 0.20811446756124496, Final Batch Loss: 0.08408410847187042\n",
      "Epoch 500, Loss: 0.2512208893895149, Final Batch Loss: 0.13020217418670654\n",
      "Epoch 501, Loss: 0.1851821392774582, Final Batch Loss: 0.10872507095336914\n",
      "Epoch 502, Loss: 0.1744709312915802, Final Batch Loss: 0.10102827101945877\n",
      "Epoch 503, Loss: 0.2020021229982376, Final Batch Loss: 0.11630146205425262\n",
      "Epoch 504, Loss: 0.18254659324884415, Final Batch Loss: 0.1236984133720398\n",
      "Epoch 505, Loss: 0.22601405531167984, Final Batch Loss: 0.09580720216035843\n",
      "Epoch 506, Loss: 0.20421937108039856, Final Batch Loss: 0.07242763042449951\n",
      "Epoch 507, Loss: 0.14949282258749008, Final Batch Loss: 0.06450042128562927\n",
      "Epoch 508, Loss: 0.1683453768491745, Final Batch Loss: 0.07927192002534866\n",
      "Epoch 509, Loss: 0.20827463269233704, Final Batch Loss: 0.12019971013069153\n",
      "Epoch 510, Loss: 0.1719205528497696, Final Batch Loss: 0.08763831853866577\n",
      "Epoch 511, Loss: 0.1907961145043373, Final Batch Loss: 0.11320899426937103\n",
      "Epoch 512, Loss: 0.18843986093997955, Final Batch Loss: 0.08966027945280075\n",
      "Epoch 513, Loss: 0.18249958753585815, Final Batch Loss: 0.08002236485481262\n",
      "Epoch 514, Loss: 0.17101416736841202, Final Batch Loss: 0.08912143111228943\n",
      "Epoch 515, Loss: 0.22630178928375244, Final Batch Loss: 0.11332594603300095\n",
      "Epoch 516, Loss: 0.15176299959421158, Final Batch Loss: 0.06483800709247589\n",
      "Epoch 517, Loss: 0.20902063697576523, Final Batch Loss: 0.11604363471269608\n",
      "Epoch 518, Loss: 0.25693754851818085, Final Batch Loss: 0.19399085640907288\n",
      "Epoch 519, Loss: 0.17987151816487312, Final Batch Loss: 0.12254990637302399\n",
      "Epoch 520, Loss: 0.154902882874012, Final Batch Loss: 0.0632953941822052\n",
      "Epoch 521, Loss: 0.18689648061990738, Final Batch Loss: 0.0854385644197464\n",
      "Epoch 522, Loss: 0.17190303653478622, Final Batch Loss: 0.08269407600164413\n",
      "Epoch 523, Loss: 0.16326408833265305, Final Batch Loss: 0.06299035996198654\n",
      "Epoch 524, Loss: 0.18379753082990646, Final Batch Loss: 0.1000826433300972\n",
      "Epoch 525, Loss: 0.24548552185297012, Final Batch Loss: 0.098481185734272\n",
      "Epoch 526, Loss: 0.15057656913995743, Final Batch Loss: 0.06762266904115677\n",
      "Epoch 527, Loss: 0.1519932895898819, Final Batch Loss: 0.060364820063114166\n",
      "Epoch 528, Loss: 0.2356264889240265, Final Batch Loss: 0.15252189338207245\n",
      "Epoch 529, Loss: 0.2437816485762596, Final Batch Loss: 0.09807022660970688\n",
      "Epoch 530, Loss: 0.22589796781539917, Final Batch Loss: 0.14384564757347107\n",
      "Epoch 531, Loss: 0.15328913182020187, Final Batch Loss: 0.04997948557138443\n",
      "Epoch 532, Loss: 0.1969250813126564, Final Batch Loss: 0.06576281040906906\n",
      "Epoch 533, Loss: 0.16868001967668533, Final Batch Loss: 0.09929202497005463\n",
      "Epoch 534, Loss: 0.14964284002780914, Final Batch Loss: 0.06624946743249893\n",
      "Epoch 535, Loss: 0.19317743182182312, Final Batch Loss: 0.11560530215501785\n",
      "Epoch 536, Loss: 0.17064765840768814, Final Batch Loss: 0.07201092690229416\n",
      "Epoch 537, Loss: 0.19631529599428177, Final Batch Loss: 0.08883308619260788\n",
      "Epoch 538, Loss: 0.17636505141854286, Final Batch Loss: 0.056939709931612015\n",
      "Epoch 539, Loss: 0.15984907001256943, Final Batch Loss: 0.0887063667178154\n",
      "Epoch 540, Loss: 0.16765572130680084, Final Batch Loss: 0.09567772597074509\n",
      "Epoch 541, Loss: 0.16475097835063934, Final Batch Loss: 0.07917577028274536\n",
      "Epoch 542, Loss: 0.16640713810920715, Final Batch Loss: 0.08673970401287079\n",
      "Epoch 543, Loss: 0.16944843530654907, Final Batch Loss: 0.10354574024677277\n",
      "Epoch 544, Loss: 0.1934860572218895, Final Batch Loss: 0.07656750082969666\n",
      "Epoch 545, Loss: 0.16596699506044388, Final Batch Loss: 0.08360252529382706\n",
      "Epoch 546, Loss: 0.2153833657503128, Final Batch Loss: 0.1256408989429474\n",
      "Epoch 547, Loss: 0.160333514213562, Final Batch Loss: 0.06462017446756363\n",
      "Epoch 548, Loss: 0.15419282019138336, Final Batch Loss: 0.07620894908905029\n",
      "Epoch 549, Loss: 0.14169761911034584, Final Batch Loss: 0.05447304621338844\n",
      "Epoch 550, Loss: 0.17367049306631088, Final Batch Loss: 0.10224699229001999\n",
      "Epoch 551, Loss: 0.20930691808462143, Final Batch Loss: 0.050739385187625885\n",
      "Epoch 552, Loss: 0.17259514331817627, Final Batch Loss: 0.08461371064186096\n",
      "Epoch 553, Loss: 0.15992550551891327, Final Batch Loss: 0.0849519670009613\n",
      "Epoch 554, Loss: 0.2097858488559723, Final Batch Loss: 0.09643631428480148\n",
      "Epoch 555, Loss: 0.13465794175863266, Final Batch Loss: 0.06881923228502274\n",
      "Epoch 556, Loss: 0.14318658411502838, Final Batch Loss: 0.06513907760381699\n",
      "Epoch 557, Loss: 0.18734072148799896, Final Batch Loss: 0.08843225240707397\n",
      "Epoch 558, Loss: 0.15283016115427017, Final Batch Loss: 0.08243381977081299\n",
      "Epoch 559, Loss: 0.18575121462345123, Final Batch Loss: 0.08050595223903656\n",
      "Epoch 560, Loss: 0.21995656192302704, Final Batch Loss: 0.13034488260746002\n",
      "Epoch 561, Loss: 0.16278772801160812, Final Batch Loss: 0.10752652585506439\n",
      "Epoch 562, Loss: 0.2217811718583107, Final Batch Loss: 0.09444240480661392\n",
      "Epoch 563, Loss: 0.15671244263648987, Final Batch Loss: 0.07532977312803268\n",
      "Epoch 564, Loss: 0.19926131516695023, Final Batch Loss: 0.089443638920784\n",
      "Epoch 565, Loss: 0.20761478692293167, Final Batch Loss: 0.11481298506259918\n",
      "Epoch 566, Loss: 0.22366385161876678, Final Batch Loss: 0.09898493438959122\n",
      "Epoch 567, Loss: 0.15191863477230072, Final Batch Loss: 0.07462626695632935\n",
      "Epoch 568, Loss: 0.15841403976082802, Final Batch Loss: 0.05580918863415718\n",
      "Epoch 569, Loss: 0.12027205526828766, Final Batch Loss: 0.06326258927583694\n",
      "Epoch 570, Loss: 0.1576961949467659, Final Batch Loss: 0.09782087802886963\n",
      "Epoch 571, Loss: 0.15829984843730927, Final Batch Loss: 0.09595344215631485\n",
      "Epoch 572, Loss: 0.23615987598896027, Final Batch Loss: 0.12852756679058075\n",
      "Epoch 573, Loss: 0.19059601426124573, Final Batch Loss: 0.10482779890298843\n",
      "Epoch 574, Loss: 0.19540270417928696, Final Batch Loss: 0.12261969596147537\n",
      "Epoch 575, Loss: 0.22238073498010635, Final Batch Loss: 0.05310525745153427\n",
      "Epoch 576, Loss: 0.15538375079631805, Final Batch Loss: 0.09070293605327606\n",
      "Epoch 577, Loss: 0.16059256345033646, Final Batch Loss: 0.07734347879886627\n",
      "Epoch 578, Loss: 0.15859752893447876, Final Batch Loss: 0.056010276079177856\n",
      "Epoch 579, Loss: 0.18388697504997253, Final Batch Loss: 0.12037760764360428\n",
      "Epoch 580, Loss: 0.21338820457458496, Final Batch Loss: 0.07246123254299164\n",
      "Epoch 581, Loss: 0.2271846979856491, Final Batch Loss: 0.11663220822811127\n",
      "Epoch 582, Loss: 0.1819034181535244, Final Batch Loss: 0.062071170657873154\n",
      "Epoch 583, Loss: 0.20128510892391205, Final Batch Loss: 0.08417009562253952\n",
      "Epoch 584, Loss: 0.185637429356575, Final Batch Loss: 0.10311072319746017\n",
      "Epoch 585, Loss: 0.17330197989940643, Final Batch Loss: 0.07915543019771576\n",
      "Epoch 586, Loss: 0.1742696315050125, Final Batch Loss: 0.09123058617115021\n",
      "Epoch 587, Loss: 0.19728254526853561, Final Batch Loss: 0.10727144032716751\n",
      "Epoch 588, Loss: 0.15524012595415115, Final Batch Loss: 0.08460769802331924\n",
      "Epoch 589, Loss: 0.21293560415506363, Final Batch Loss: 0.13386277854442596\n",
      "Epoch 590, Loss: 0.16414246708154678, Final Batch Loss: 0.07483318448066711\n",
      "Epoch 591, Loss: 0.18065658956766129, Final Batch Loss: 0.09471669048070908\n",
      "Epoch 592, Loss: 0.1920020952820778, Final Batch Loss: 0.11496131122112274\n",
      "Epoch 593, Loss: 0.20504699647426605, Final Batch Loss: 0.08457223325967789\n",
      "Epoch 594, Loss: 0.15684585645794868, Final Batch Loss: 0.0546315498650074\n",
      "Epoch 595, Loss: 0.15587906911969185, Final Batch Loss: 0.09363351762294769\n",
      "Epoch 596, Loss: 0.16090771555900574, Final Batch Loss: 0.08424358069896698\n",
      "Epoch 597, Loss: 0.15123877674341202, Final Batch Loss: 0.08028380572795868\n",
      "Epoch 598, Loss: 0.14278215169906616, Final Batch Loss: 0.06891920417547226\n",
      "Epoch 599, Loss: 0.2101910412311554, Final Batch Loss: 0.11379750818014145\n",
      "Epoch 600, Loss: 0.1950756534934044, Final Batch Loss: 0.0835038274526596\n",
      "Epoch 601, Loss: 0.21393421292304993, Final Batch Loss: 0.14216318726539612\n",
      "Epoch 602, Loss: 0.1668114885687828, Final Batch Loss: 0.08554889261722565\n",
      "Epoch 603, Loss: 0.18408924341201782, Final Batch Loss: 0.05910399556159973\n",
      "Epoch 604, Loss: 0.1537531465291977, Final Batch Loss: 0.09188441932201385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 605, Loss: 0.23012547940015793, Final Batch Loss: 0.12345559895038605\n",
      "Epoch 606, Loss: 0.20377615839242935, Final Batch Loss: 0.1062711775302887\n",
      "Epoch 607, Loss: 0.1695145219564438, Final Batch Loss: 0.07250767946243286\n",
      "Epoch 608, Loss: 0.17754918336868286, Final Batch Loss: 0.10705632716417313\n",
      "Epoch 609, Loss: 0.17538383603096008, Final Batch Loss: 0.07893039286136627\n",
      "Epoch 610, Loss: 0.14067815989255905, Final Batch Loss: 0.07513247430324554\n",
      "Epoch 611, Loss: 0.1945071816444397, Final Batch Loss: 0.09520784020423889\n",
      "Epoch 612, Loss: 0.177479088306427, Final Batch Loss: 0.07640186697244644\n",
      "Epoch 613, Loss: 0.23122330754995346, Final Batch Loss: 0.13461847603321075\n",
      "Epoch 614, Loss: 0.2076069936156273, Final Batch Loss: 0.11034081131219864\n",
      "Epoch 615, Loss: 0.14034593105316162, Final Batch Loss: 0.07284973561763763\n",
      "Epoch 616, Loss: 0.23503536731004715, Final Batch Loss: 0.1229269877076149\n",
      "Epoch 617, Loss: 0.16664259880781174, Final Batch Loss: 0.11029477417469025\n",
      "Epoch 618, Loss: 0.19852523133158684, Final Batch Loss: 0.14353469014167786\n",
      "Epoch 619, Loss: 0.24343707412481308, Final Batch Loss: 0.1646381914615631\n",
      "Epoch 620, Loss: 0.22104579955339432, Final Batch Loss: 0.12474691867828369\n",
      "Epoch 621, Loss: 0.1137210763990879, Final Batch Loss: 0.042699430137872696\n",
      "Epoch 622, Loss: 0.15227030962705612, Final Batch Loss: 0.09119372069835663\n",
      "Epoch 623, Loss: 0.19190527498722076, Final Batch Loss: 0.10177549719810486\n",
      "Epoch 624, Loss: 0.1456647925078869, Final Batch Loss: 0.06188857927918434\n",
      "Epoch 625, Loss: 0.1698487624526024, Final Batch Loss: 0.0925818458199501\n",
      "Epoch 626, Loss: 0.20448018610477448, Final Batch Loss: 0.11743520200252533\n",
      "Epoch 627, Loss: 0.2041865810751915, Final Batch Loss: 0.06950291246175766\n",
      "Epoch 628, Loss: 0.17906983196735382, Final Batch Loss: 0.06926346570253372\n",
      "Epoch 629, Loss: 0.20166126638650894, Final Batch Loss: 0.08349238336086273\n",
      "Epoch 630, Loss: 0.1714440956711769, Final Batch Loss: 0.07483323663473129\n",
      "Epoch 631, Loss: 0.15396296977996826, Final Batch Loss: 0.06657145172357559\n",
      "Epoch 632, Loss: 0.15520542114973068, Final Batch Loss: 0.05772054195404053\n",
      "Epoch 633, Loss: 0.20498356223106384, Final Batch Loss: 0.09532791376113892\n",
      "Epoch 634, Loss: 0.19010543823242188, Final Batch Loss: 0.1152353510260582\n",
      "Epoch 635, Loss: 0.1649632379412651, Final Batch Loss: 0.08540008962154388\n",
      "Epoch 636, Loss: 0.1979500874876976, Final Batch Loss: 0.09435741603374481\n",
      "Epoch 637, Loss: 0.13290825858712196, Final Batch Loss: 0.07105743885040283\n",
      "Epoch 638, Loss: 0.13914472237229347, Final Batch Loss: 0.07825212180614471\n",
      "Epoch 639, Loss: 0.2278454452753067, Final Batch Loss: 0.13522067666053772\n",
      "Epoch 640, Loss: 0.1582702174782753, Final Batch Loss: 0.07345762848854065\n",
      "Epoch 641, Loss: 0.15947062894701958, Final Batch Loss: 0.0976942777633667\n",
      "Epoch 642, Loss: 0.1704404130578041, Final Batch Loss: 0.09077432751655579\n",
      "Epoch 643, Loss: 0.15736908465623856, Final Batch Loss: 0.08705051243305206\n",
      "Epoch 644, Loss: 0.1189422719180584, Final Batch Loss: 0.06733819097280502\n",
      "Epoch 645, Loss: 0.18682675063610077, Final Batch Loss: 0.06169760227203369\n",
      "Epoch 646, Loss: 0.12223717197775841, Final Batch Loss: 0.07930324971675873\n",
      "Epoch 647, Loss: 0.20956750959157944, Final Batch Loss: 0.11462436616420746\n",
      "Epoch 648, Loss: 0.16787267476320267, Final Batch Loss: 0.0677880197763443\n",
      "Epoch 649, Loss: 0.19585052877664566, Final Batch Loss: 0.09279803186655045\n",
      "Epoch 650, Loss: 0.1415855437517166, Final Batch Loss: 0.05179627239704132\n",
      "Epoch 651, Loss: 0.15713274478912354, Final Batch Loss: 0.07359767705202103\n",
      "Epoch 652, Loss: 0.18985460698604584, Final Batch Loss: 0.08256592601537704\n",
      "Epoch 653, Loss: 0.20965655893087387, Final Batch Loss: 0.1290290802717209\n",
      "Epoch 654, Loss: 0.20307675004005432, Final Batch Loss: 0.11390139162540436\n",
      "Epoch 655, Loss: 0.16513674706220627, Final Batch Loss: 0.09899714589118958\n",
      "Epoch 656, Loss: 0.1730753779411316, Final Batch Loss: 0.07833407074213028\n",
      "Epoch 657, Loss: 0.15286552906036377, Final Batch Loss: 0.062184564769268036\n",
      "Epoch 658, Loss: 0.2505052909255028, Final Batch Loss: 0.1433054357767105\n",
      "Epoch 659, Loss: 0.14722643047571182, Final Batch Loss: 0.07996553927659988\n",
      "Epoch 660, Loss: 0.15716703608632088, Final Batch Loss: 0.05148589238524437\n",
      "Epoch 661, Loss: 0.13683069124817848, Final Batch Loss: 0.059117842465639114\n",
      "Epoch 662, Loss: 0.2009185254573822, Final Batch Loss: 0.10862413793802261\n",
      "Epoch 663, Loss: 0.16501805931329727, Final Batch Loss: 0.0781373605132103\n",
      "Epoch 664, Loss: 0.13789137825369835, Final Batch Loss: 0.05409608408808708\n",
      "Epoch 665, Loss: 0.135780468583107, Final Batch Loss: 0.0693216621875763\n",
      "Epoch 666, Loss: 0.14998794347047806, Final Batch Loss: 0.07172024995088577\n",
      "Epoch 667, Loss: 0.16356249898672104, Final Batch Loss: 0.07984700798988342\n",
      "Epoch 668, Loss: 0.17119044065475464, Final Batch Loss: 0.08708231151103973\n",
      "Epoch 669, Loss: 0.15204941481351852, Final Batch Loss: 0.08007235080003738\n",
      "Epoch 670, Loss: 0.15806977450847626, Final Batch Loss: 0.0724543109536171\n",
      "Epoch 671, Loss: 0.16158808395266533, Final Batch Loss: 0.050685781985521317\n",
      "Epoch 672, Loss: 0.1707194298505783, Final Batch Loss: 0.08044423162937164\n",
      "Epoch 673, Loss: 0.12871656566858292, Final Batch Loss: 0.07998431473970413\n",
      "Epoch 674, Loss: 0.15954392403364182, Final Batch Loss: 0.07315976917743683\n",
      "Epoch 675, Loss: 0.17738961428403854, Final Batch Loss: 0.07381658256053925\n",
      "Epoch 676, Loss: 0.16129452735185623, Final Batch Loss: 0.06850169599056244\n",
      "Epoch 677, Loss: 0.167594812810421, Final Batch Loss: 0.03451547771692276\n",
      "Epoch 678, Loss: 0.2213393934071064, Final Batch Loss: 0.1607677936553955\n",
      "Epoch 679, Loss: 0.16613015159964561, Final Batch Loss: 0.10444402694702148\n",
      "Epoch 680, Loss: 0.20512736588716507, Final Batch Loss: 0.09390289336442947\n",
      "Epoch 681, Loss: 0.16821345686912537, Final Batch Loss: 0.07072816044092178\n",
      "Epoch 682, Loss: 0.18329200893640518, Final Batch Loss: 0.10979577898979187\n",
      "Epoch 683, Loss: 0.16306719183921814, Final Batch Loss: 0.08646275848150253\n",
      "Epoch 684, Loss: 0.15886308997869492, Final Batch Loss: 0.03830414265394211\n",
      "Epoch 685, Loss: 0.14871158823370934, Final Batch Loss: 0.08894501626491547\n",
      "Epoch 686, Loss: 0.14488671720027924, Final Batch Loss: 0.06989209353923798\n",
      "Epoch 687, Loss: 0.13669798150658607, Final Batch Loss: 0.07457085698843002\n",
      "Epoch 688, Loss: 0.2074793055653572, Final Batch Loss: 0.1054970771074295\n",
      "Epoch 689, Loss: 0.16745920479297638, Final Batch Loss: 0.0980982780456543\n",
      "Epoch 690, Loss: 0.14432596415281296, Final Batch Loss: 0.09002845734357834\n",
      "Epoch 691, Loss: 0.15393437445163727, Final Batch Loss: 0.06900777667760849\n",
      "Epoch 692, Loss: 0.12372202426195145, Final Batch Loss: 0.05181401968002319\n",
      "Epoch 693, Loss: 0.16965356469154358, Final Batch Loss: 0.07546623051166534\n",
      "Epoch 694, Loss: 0.13101650029420853, Final Batch Loss: 0.056486815214157104\n",
      "Epoch 695, Loss: 0.24958278983831406, Final Batch Loss: 0.1145242229104042\n",
      "Epoch 696, Loss: 0.18754755705595016, Final Batch Loss: 0.1164695993065834\n",
      "Epoch 697, Loss: 0.15684767067432404, Final Batch Loss: 0.06514043360948563\n",
      "Epoch 698, Loss: 0.14794333279132843, Final Batch Loss: 0.07032996416091919\n",
      "Epoch 699, Loss: 0.16488035023212433, Final Batch Loss: 0.06575962901115417\n",
      "Epoch 700, Loss: 0.29124876111745834, Final Batch Loss: 0.17697331309318542\n",
      "Epoch 701, Loss: 0.17612792551517487, Final Batch Loss: 0.0932958573102951\n",
      "Epoch 702, Loss: 0.20662204921245575, Final Batch Loss: 0.10590717941522598\n",
      "Epoch 703, Loss: 0.16582170128822327, Final Batch Loss: 0.06537266075611115\n",
      "Epoch 704, Loss: 0.15849030762910843, Final Batch Loss: 0.09924814850091934\n",
      "Epoch 705, Loss: 0.21587392687797546, Final Batch Loss: 0.0787406861782074\n",
      "Epoch 706, Loss: 0.2027612403035164, Final Batch Loss: 0.07121651619672775\n",
      "Epoch 707, Loss: 0.15439777076244354, Final Batch Loss: 0.06724954396486282\n",
      "Epoch 708, Loss: 0.13011259958148003, Final Batch Loss: 0.03743999823927879\n",
      "Epoch 709, Loss: 0.14344115555286407, Final Batch Loss: 0.049157507717609406\n",
      "Epoch 710, Loss: 0.17141611874103546, Final Batch Loss: 0.07511290162801743\n",
      "Epoch 711, Loss: 0.23233917355537415, Final Batch Loss: 0.12804044783115387\n",
      "Epoch 712, Loss: 0.22737444564700127, Final Batch Loss: 0.05677330121397972\n",
      "Epoch 713, Loss: 0.15833886712789536, Final Batch Loss: 0.07010903209447861\n",
      "Epoch 714, Loss: 0.18368937075138092, Final Batch Loss: 0.06803461909294128\n",
      "Epoch 715, Loss: 0.14419469237327576, Final Batch Loss: 0.07507266104221344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 716, Loss: 0.17520850896835327, Final Batch Loss: 0.0668586939573288\n",
      "Epoch 717, Loss: 0.25240447372198105, Final Batch Loss: 0.08571141213178635\n",
      "Epoch 718, Loss: 0.1709790974855423, Final Batch Loss: 0.07898720353841782\n",
      "Epoch 719, Loss: 0.26768601685762405, Final Batch Loss: 0.09564276784658432\n",
      "Epoch 720, Loss: 0.17574594169855118, Final Batch Loss: 0.09144984930753708\n",
      "Epoch 721, Loss: 0.17822609096765518, Final Batch Loss: 0.08335772156715393\n",
      "Epoch 722, Loss: 0.21772997081279755, Final Batch Loss: 0.07545535266399384\n",
      "Epoch 723, Loss: 0.16518646478652954, Final Batch Loss: 0.09278620034456253\n",
      "Epoch 724, Loss: 0.13978563994169235, Final Batch Loss: 0.05691397190093994\n",
      "Epoch 725, Loss: 0.18663479015231133, Final Batch Loss: 0.06135156378149986\n",
      "Epoch 726, Loss: 0.2156132012605667, Final Batch Loss: 0.10082972794771194\n",
      "Epoch 727, Loss: 0.22375094890594482, Final Batch Loss: 0.07646612823009491\n",
      "Epoch 728, Loss: 0.18418265506625175, Final Batch Loss: 0.055634792894124985\n",
      "Epoch 729, Loss: 0.20835783332586288, Final Batch Loss: 0.12640392780303955\n",
      "Epoch 730, Loss: 0.1783638820052147, Final Batch Loss: 0.0813804417848587\n",
      "Epoch 731, Loss: 0.15295755118131638, Final Batch Loss: 0.1004815548658371\n",
      "Epoch 732, Loss: 0.1684362292289734, Final Batch Loss: 0.08805292099714279\n",
      "Epoch 733, Loss: 0.19141067564487457, Final Batch Loss: 0.06235848367214203\n",
      "Epoch 734, Loss: 0.1636519655585289, Final Batch Loss: 0.1300429105758667\n",
      "Epoch 735, Loss: 0.12408062815666199, Final Batch Loss: 0.05177465081214905\n",
      "Epoch 736, Loss: 0.13457554206252098, Final Batch Loss: 0.07292473316192627\n",
      "Epoch 737, Loss: 0.17115408927202225, Final Batch Loss: 0.09459609538316727\n",
      "Epoch 738, Loss: 0.2368740662932396, Final Batch Loss: 0.1590522676706314\n",
      "Epoch 739, Loss: 0.16928084567189217, Final Batch Loss: 0.11493349820375443\n",
      "Epoch 740, Loss: 0.20664025843143463, Final Batch Loss: 0.08139243721961975\n",
      "Epoch 741, Loss: 0.1516871079802513, Final Batch Loss: 0.06283537298440933\n",
      "Epoch 742, Loss: 0.15652405098080635, Final Batch Loss: 0.04633143171668053\n",
      "Epoch 743, Loss: 0.1724300980567932, Final Batch Loss: 0.07318234443664551\n",
      "Epoch 744, Loss: 0.1462787464261055, Final Batch Loss: 0.07626432180404663\n",
      "Epoch 745, Loss: 0.14222770929336548, Final Batch Loss: 0.07921444624662399\n",
      "Epoch 746, Loss: 0.15153919905424118, Final Batch Loss: 0.08638641238212585\n",
      "Epoch 747, Loss: 0.18484969437122345, Final Batch Loss: 0.10816612094640732\n",
      "Epoch 748, Loss: 0.13763420656323433, Final Batch Loss: 0.056684818118810654\n",
      "Epoch 749, Loss: 0.1994759440422058, Final Batch Loss: 0.09164604544639587\n",
      "Epoch 750, Loss: 0.25298159569501877, Final Batch Loss: 0.15912404656410217\n",
      "Epoch 751, Loss: 0.19965150952339172, Final Batch Loss: 0.11027126014232635\n",
      "Epoch 752, Loss: 0.16545285284519196, Final Batch Loss: 0.11238735914230347\n",
      "Epoch 753, Loss: 0.23711254447698593, Final Batch Loss: 0.1226876750588417\n",
      "Epoch 754, Loss: 0.20376453548669815, Final Batch Loss: 0.1308465152978897\n",
      "Epoch 755, Loss: 0.20623838156461716, Final Batch Loss: 0.11083406209945679\n",
      "Epoch 756, Loss: 0.1590990498661995, Final Batch Loss: 0.08411373943090439\n",
      "Epoch 757, Loss: 0.2210461050271988, Final Batch Loss: 0.12948369979858398\n",
      "Epoch 758, Loss: 0.17144422978162766, Final Batch Loss: 0.07069594413042068\n",
      "Epoch 759, Loss: 0.17140785604715347, Final Batch Loss: 0.07892915606498718\n",
      "Epoch 760, Loss: 0.18928369134664536, Final Batch Loss: 0.07154574990272522\n",
      "Epoch 761, Loss: 0.16794460266828537, Final Batch Loss: 0.08978898823261261\n",
      "Epoch 762, Loss: 0.14245294779539108, Final Batch Loss: 0.06529313325881958\n",
      "Epoch 763, Loss: 0.20900298655033112, Final Batch Loss: 0.09688787162303925\n",
      "Epoch 764, Loss: 0.15834363922476768, Final Batch Loss: 0.06214682385325432\n",
      "Epoch 765, Loss: 0.14933809638023376, Final Batch Loss: 0.0813678577542305\n",
      "Epoch 766, Loss: 0.14362917095422745, Final Batch Loss: 0.06082689017057419\n",
      "Epoch 767, Loss: 0.20504959672689438, Final Batch Loss: 0.09391821920871735\n",
      "Epoch 768, Loss: 0.20411783456802368, Final Batch Loss: 0.0842180922627449\n",
      "Epoch 769, Loss: 0.15601269155740738, Final Batch Loss: 0.06951012462377548\n",
      "Epoch 770, Loss: 0.19033345580101013, Final Batch Loss: 0.06889884918928146\n",
      "Epoch 771, Loss: 0.11916246265172958, Final Batch Loss: 0.050450727343559265\n",
      "Epoch 772, Loss: 0.17331218719482422, Final Batch Loss: 0.0982026606798172\n",
      "Epoch 773, Loss: 0.17282455414533615, Final Batch Loss: 0.06615334004163742\n",
      "Epoch 774, Loss: 0.18261303007602692, Final Batch Loss: 0.08838152885437012\n",
      "Epoch 775, Loss: 0.1377047523856163, Final Batch Loss: 0.08105713874101639\n",
      "Epoch 776, Loss: 0.12455632910132408, Final Batch Loss: 0.06302857398986816\n",
      "Epoch 777, Loss: 0.24324268847703934, Final Batch Loss: 0.06959439069032669\n",
      "Epoch 778, Loss: 0.1662888377904892, Final Batch Loss: 0.09638296812772751\n",
      "Epoch 779, Loss: 0.13284114748239517, Final Batch Loss: 0.0724983885884285\n",
      "Epoch 780, Loss: 0.14904817938804626, Final Batch Loss: 0.07281423360109329\n",
      "Epoch 781, Loss: 0.16229373216629028, Final Batch Loss: 0.057878509163856506\n",
      "Epoch 782, Loss: 0.11314881965517998, Final Batch Loss: 0.059140998870134354\n",
      "Epoch 783, Loss: 0.1283242143690586, Final Batch Loss: 0.04003983363509178\n",
      "Epoch 784, Loss: 0.16327572613954544, Final Batch Loss: 0.09742147475481033\n",
      "Epoch 785, Loss: 0.1363753080368042, Final Batch Loss: 0.059477873146533966\n",
      "Epoch 786, Loss: 0.1559242084622383, Final Batch Loss: 0.09733310341835022\n",
      "Epoch 787, Loss: 0.16461193561553955, Final Batch Loss: 0.07652891427278519\n",
      "Epoch 788, Loss: 0.13401000574231148, Final Batch Loss: 0.07604295015335083\n",
      "Epoch 789, Loss: 0.17739791423082352, Final Batch Loss: 0.10547902435064316\n",
      "Epoch 790, Loss: 0.1857011318206787, Final Batch Loss: 0.06980523467063904\n",
      "Epoch 791, Loss: 0.14828889816999435, Final Batch Loss: 0.07885275036096573\n",
      "Epoch 792, Loss: 0.12315313518047333, Final Batch Loss: 0.04651717096567154\n",
      "Epoch 793, Loss: 0.19658174365758896, Final Batch Loss: 0.12105154246091843\n",
      "Epoch 794, Loss: 0.1844206601381302, Final Batch Loss: 0.07780727744102478\n",
      "Epoch 795, Loss: 0.17720729857683182, Final Batch Loss: 0.07705936580896378\n",
      "Epoch 796, Loss: 0.23889252543449402, Final Batch Loss: 0.1498774141073227\n",
      "Epoch 797, Loss: 0.17055565863847733, Final Batch Loss: 0.0870983675122261\n",
      "Epoch 798, Loss: 0.2029486745595932, Final Batch Loss: 0.12637239694595337\n",
      "Epoch 799, Loss: 0.16426282934844494, Final Batch Loss: 0.135110005736351\n",
      "Epoch 800, Loss: 0.1304144263267517, Final Batch Loss: 0.0757715255022049\n",
      "Epoch 801, Loss: 0.14269570633769035, Final Batch Loss: 0.08319196105003357\n",
      "Epoch 802, Loss: 0.1754182055592537, Final Batch Loss: 0.09446997195482254\n",
      "Epoch 803, Loss: 0.12969573214650154, Final Batch Loss: 0.052825216203927994\n",
      "Epoch 804, Loss: 0.1260831654071808, Final Batch Loss: 0.06257690489292145\n",
      "Epoch 805, Loss: 0.14712710678577423, Final Batch Loss: 0.07468345016241074\n",
      "Epoch 806, Loss: 0.22500814497470856, Final Batch Loss: 0.12759830057621002\n",
      "Epoch 807, Loss: 0.1670413687825203, Final Batch Loss: 0.11742225289344788\n",
      "Epoch 808, Loss: 0.1505519300699234, Final Batch Loss: 0.041310153901576996\n",
      "Epoch 809, Loss: 0.17863238602876663, Final Batch Loss: 0.08564650267362595\n",
      "Epoch 810, Loss: 0.14411312714219093, Final Batch Loss: 0.10031066089868546\n",
      "Epoch 811, Loss: 0.15412431955337524, Final Batch Loss: 0.07743490487337112\n",
      "Epoch 812, Loss: 0.16744059324264526, Final Batch Loss: 0.08318249881267548\n",
      "Epoch 813, Loss: 0.12236974760890007, Final Batch Loss: 0.061668165028095245\n",
      "Epoch 814, Loss: 0.14200444519519806, Final Batch Loss: 0.08388232439756393\n",
      "Epoch 815, Loss: 0.17513199895620346, Final Batch Loss: 0.05880523473024368\n",
      "Epoch 816, Loss: 0.17234742641448975, Final Batch Loss: 0.10541824996471405\n",
      "Epoch 817, Loss: 0.12300613895058632, Final Batch Loss: 0.06875790655612946\n",
      "Epoch 818, Loss: 0.14899249374866486, Final Batch Loss: 0.07799671590328217\n",
      "Epoch 819, Loss: 0.14978989213705063, Final Batch Loss: 0.07831466197967529\n",
      "Epoch 820, Loss: 0.11210517957806587, Final Batch Loss: 0.051891714334487915\n",
      "Epoch 821, Loss: 0.12886521592736244, Final Batch Loss: 0.04668528959155083\n",
      "Epoch 822, Loss: 0.13254103437066078, Final Batch Loss: 0.08220911026000977\n",
      "Epoch 823, Loss: 0.11925043538212776, Final Batch Loss: 0.07639826834201813\n",
      "Epoch 824, Loss: 0.10665842518210411, Final Batch Loss: 0.05924159660935402\n",
      "Epoch 825, Loss: 0.1365332491695881, Final Batch Loss: 0.05307113751769066\n",
      "Epoch 826, Loss: 0.16023851931095123, Final Batch Loss: 0.07670664042234421\n",
      "Epoch 827, Loss: 0.11846829950809479, Final Batch Loss: 0.05628494918346405\n",
      "Epoch 828, Loss: 0.23270224779844284, Final Batch Loss: 0.13630200922489166\n",
      "Epoch 829, Loss: 0.15204588323831558, Final Batch Loss: 0.08671430498361588\n",
      "Epoch 830, Loss: 0.1354859471321106, Final Batch Loss: 0.07330123335123062\n",
      "Epoch 831, Loss: 0.14814715087413788, Final Batch Loss: 0.07397275418043137\n",
      "Epoch 832, Loss: 0.15619459003210068, Final Batch Loss: 0.07883875072002411\n",
      "Epoch 833, Loss: 0.1387096829712391, Final Batch Loss: 0.06002343073487282\n",
      "Epoch 834, Loss: 0.17969851195812225, Final Batch Loss: 0.06956976652145386\n",
      "Epoch 835, Loss: 0.1300511285662651, Final Batch Loss: 0.0684528797864914\n",
      "Epoch 836, Loss: 0.16447899490594864, Final Batch Loss: 0.09228034317493439\n",
      "Epoch 837, Loss: 0.1489577740430832, Final Batch Loss: 0.04047374427318573\n",
      "Epoch 838, Loss: 0.13303401321172714, Final Batch Loss: 0.07883550226688385\n",
      "Epoch 839, Loss: 0.13548262417316437, Final Batch Loss: 0.0756637305021286\n",
      "Epoch 840, Loss: 0.20612286031246185, Final Batch Loss: 0.09682232141494751\n",
      "Epoch 841, Loss: 0.1919434517621994, Final Batch Loss: 0.08037882298231125\n",
      "Epoch 842, Loss: 0.14939462393522263, Final Batch Loss: 0.06630434095859528\n",
      "Epoch 843, Loss: 0.14553876966238022, Final Batch Loss: 0.07922074943780899\n",
      "Epoch 844, Loss: 0.1302662044763565, Final Batch Loss: 0.06517426669597626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 845, Loss: 0.14561619237065315, Final Batch Loss: 0.08380743861198425\n",
      "Epoch 846, Loss: 0.16720563918352127, Final Batch Loss: 0.11913112550973892\n",
      "Epoch 847, Loss: 0.18353504687547684, Final Batch Loss: 0.07350333034992218\n",
      "Epoch 848, Loss: 0.12790591269731522, Final Batch Loss: 0.05921676754951477\n",
      "Epoch 849, Loss: 0.14010608568787575, Final Batch Loss: 0.08255466818809509\n",
      "Epoch 850, Loss: 0.15310708433389664, Final Batch Loss: 0.06005415320396423\n",
      "Epoch 851, Loss: 0.1201779656112194, Final Batch Loss: 0.04966748133301735\n",
      "Epoch 852, Loss: 0.15392595157027245, Final Batch Loss: 0.05912480875849724\n",
      "Epoch 853, Loss: 0.11469070985913277, Final Batch Loss: 0.06275764852762222\n",
      "Epoch 854, Loss: 0.11162592843174934, Final Batch Loss: 0.05471479147672653\n",
      "Epoch 855, Loss: 0.10996672511100769, Final Batch Loss: 0.039972685277462006\n",
      "Epoch 856, Loss: 0.16334568709135056, Final Batch Loss: 0.08943446725606918\n",
      "Epoch 857, Loss: 0.15701184421777725, Final Batch Loss: 0.08169667422771454\n",
      "Epoch 858, Loss: 0.1614171341061592, Final Batch Loss: 0.09211336076259613\n",
      "Epoch 859, Loss: 0.2061750441789627, Final Batch Loss: 0.10414935648441315\n",
      "Epoch 860, Loss: 0.14390872046351433, Final Batch Loss: 0.08777031302452087\n",
      "Epoch 861, Loss: 0.15650532394647598, Final Batch Loss: 0.07413938641548157\n",
      "Epoch 862, Loss: 0.1436486914753914, Final Batch Loss: 0.05760408192873001\n",
      "Epoch 863, Loss: 0.15075283497571945, Final Batch Loss: 0.07823028415441513\n",
      "Epoch 864, Loss: 0.11598671972751617, Final Batch Loss: 0.03412746638059616\n",
      "Epoch 865, Loss: 0.11110443994402885, Final Batch Loss: 0.07197833061218262\n",
      "Epoch 866, Loss: 0.11815808713436127, Final Batch Loss: 0.057415205985307693\n",
      "Epoch 867, Loss: 0.13099901750683784, Final Batch Loss: 0.06243225559592247\n",
      "Epoch 868, Loss: 0.12255466356873512, Final Batch Loss: 0.056446995586156845\n",
      "Epoch 869, Loss: 0.11771256104111671, Final Batch Loss: 0.06027630344033241\n",
      "Epoch 870, Loss: 0.1324613094329834, Final Batch Loss: 0.058923132717609406\n",
      "Epoch 871, Loss: 0.125565093010664, Final Batch Loss: 0.04810504987835884\n",
      "Epoch 872, Loss: 0.1502225063741207, Final Batch Loss: 0.09296440333127975\n",
      "Epoch 873, Loss: 0.2172110453248024, Final Batch Loss: 0.13023971021175385\n",
      "Epoch 874, Loss: 0.13707327842712402, Final Batch Loss: 0.06301660090684891\n",
      "Epoch 875, Loss: 0.15798955410718918, Final Batch Loss: 0.10171452164649963\n",
      "Epoch 876, Loss: 0.1305052787065506, Final Batch Loss: 0.06788595020771027\n",
      "Epoch 877, Loss: 0.13876643031835556, Final Batch Loss: 0.06838624179363251\n",
      "Epoch 878, Loss: 0.148666862398386, Final Batch Loss: 0.08627296984195709\n",
      "Epoch 879, Loss: 0.19339074939489365, Final Batch Loss: 0.12279313057661057\n",
      "Epoch 880, Loss: 0.10542197152972221, Final Batch Loss: 0.05193553864955902\n",
      "Epoch 881, Loss: 0.1611551269888878, Final Batch Loss: 0.0756070613861084\n",
      "Epoch 882, Loss: 0.16437727212905884, Final Batch Loss: 0.10011080652475357\n",
      "Epoch 883, Loss: 0.17325617000460625, Final Batch Loss: 0.11526729166507721\n",
      "Epoch 884, Loss: 0.17786181718111038, Final Batch Loss: 0.09174003452062607\n",
      "Epoch 885, Loss: 0.14290326461195946, Final Batch Loss: 0.05343532934784889\n",
      "Epoch 886, Loss: 0.13884295523166656, Final Batch Loss: 0.05903097242116928\n",
      "Epoch 887, Loss: 0.11747826635837555, Final Batch Loss: 0.053760215640068054\n",
      "Epoch 888, Loss: 0.15572600811719894, Final Batch Loss: 0.08705680817365646\n",
      "Epoch 889, Loss: 0.16097964346408844, Final Batch Loss: 0.0759769082069397\n",
      "Epoch 890, Loss: 0.11793703213334084, Final Batch Loss: 0.07853100448846817\n",
      "Epoch 891, Loss: 0.12583578750491142, Final Batch Loss: 0.06125935539603233\n",
      "Epoch 892, Loss: 0.1434103399515152, Final Batch Loss: 0.08814964443445206\n",
      "Epoch 893, Loss: 0.1286132037639618, Final Batch Loss: 0.06347381323575974\n",
      "Epoch 894, Loss: 0.12213551998138428, Final Batch Loss: 0.0506163164973259\n",
      "Epoch 895, Loss: 0.1761731281876564, Final Batch Loss: 0.11197491735219955\n",
      "Epoch 896, Loss: 0.14867182821035385, Final Batch Loss: 0.07341185957193375\n",
      "Epoch 897, Loss: 0.1908598206937313, Final Batch Loss: 0.1304144561290741\n",
      "Epoch 898, Loss: 0.1319780834019184, Final Batch Loss: 0.07325126975774765\n",
      "Epoch 899, Loss: 0.1802956759929657, Final Batch Loss: 0.10232993215322495\n",
      "Epoch 900, Loss: 0.21229413896799088, Final Batch Loss: 0.08549066632986069\n",
      "Epoch 901, Loss: 0.15068012475967407, Final Batch Loss: 0.05430861562490463\n",
      "Epoch 902, Loss: 0.20777688920497894, Final Batch Loss: 0.07329510152339935\n",
      "Epoch 903, Loss: 0.16673356294631958, Final Batch Loss: 0.030647724866867065\n",
      "Epoch 904, Loss: 0.2063296213746071, Final Batch Loss: 0.13442564010620117\n",
      "Epoch 905, Loss: 0.11932419240474701, Final Batch Loss: 0.05932078883051872\n",
      "Epoch 906, Loss: 0.10698138549923897, Final Batch Loss: 0.04934410750865936\n",
      "Epoch 907, Loss: 0.15848595649003983, Final Batch Loss: 0.0676599070429802\n",
      "Epoch 908, Loss: 0.1409379094839096, Final Batch Loss: 0.10409298539161682\n",
      "Epoch 909, Loss: 0.18281982094049454, Final Batch Loss: 0.0991748720407486\n",
      "Epoch 910, Loss: 0.17946764826774597, Final Batch Loss: 0.09648682177066803\n",
      "Epoch 911, Loss: 0.15113870799541473, Final Batch Loss: 0.08794708549976349\n",
      "Epoch 912, Loss: 0.15445350110530853, Final Batch Loss: 0.08498000353574753\n",
      "Epoch 913, Loss: 0.10403797030448914, Final Batch Loss: 0.045008476823568344\n",
      "Epoch 914, Loss: 0.1682904027402401, Final Batch Loss: 0.1139863133430481\n",
      "Epoch 915, Loss: 0.1402546465396881, Final Batch Loss: 0.04965907335281372\n",
      "Epoch 916, Loss: 0.1609187349677086, Final Batch Loss: 0.0884346216917038\n",
      "Epoch 917, Loss: 0.11973549425601959, Final Batch Loss: 0.052411772310733795\n",
      "Epoch 918, Loss: 0.1345890872180462, Final Batch Loss: 0.05808242782950401\n",
      "Epoch 919, Loss: 0.1714765876531601, Final Batch Loss: 0.08544863015413284\n",
      "Epoch 920, Loss: 0.12943892180919647, Final Batch Loss: 0.06370186805725098\n",
      "Epoch 921, Loss: 0.1939791478216648, Final Batch Loss: 0.05155322328209877\n",
      "Epoch 922, Loss: 0.11456547304987907, Final Batch Loss: 0.061466045677661896\n",
      "Epoch 923, Loss: 0.15686792135238647, Final Batch Loss: 0.08182298392057419\n",
      "Epoch 924, Loss: 0.1886378824710846, Final Batch Loss: 0.11621787399053574\n",
      "Epoch 925, Loss: 0.1444268897175789, Final Batch Loss: 0.07475725561380386\n",
      "Epoch 926, Loss: 0.1667577028274536, Final Batch Loss: 0.09215552359819412\n",
      "Epoch 927, Loss: 0.15318992733955383, Final Batch Loss: 0.05232710391283035\n",
      "Epoch 928, Loss: 0.12008392065763474, Final Batch Loss: 0.05697062611579895\n",
      "Epoch 929, Loss: 0.16570723801851273, Final Batch Loss: 0.06882503628730774\n",
      "Epoch 930, Loss: 0.19118967652320862, Final Batch Loss: 0.04966352880001068\n",
      "Epoch 931, Loss: 0.18677064031362534, Final Batch Loss: 0.06846563518047333\n",
      "Epoch 932, Loss: 0.18283166736364365, Final Batch Loss: 0.12784330546855927\n",
      "Epoch 933, Loss: 0.13132980093359947, Final Batch Loss: 0.08816200494766235\n",
      "Epoch 934, Loss: 0.12932121381163597, Final Batch Loss: 0.07107187062501907\n",
      "Epoch 935, Loss: 0.1390908733010292, Final Batch Loss: 0.07084877043962479\n",
      "Epoch 936, Loss: 0.18104863539338112, Final Batch Loss: 0.13098174333572388\n",
      "Epoch 937, Loss: 0.18323878571391106, Final Batch Loss: 0.13921178877353668\n",
      "Epoch 938, Loss: 0.1299830712378025, Final Batch Loss: 0.05937435105443001\n",
      "Epoch 939, Loss: 0.1268898919224739, Final Batch Loss: 0.07571393251419067\n",
      "Epoch 940, Loss: 0.1616557352244854, Final Batch Loss: 0.10339471697807312\n",
      "Epoch 941, Loss: 0.16395068168640137, Final Batch Loss: 0.07582119852304459\n",
      "Epoch 942, Loss: 0.11131874099373817, Final Batch Loss: 0.05780570209026337\n",
      "Epoch 943, Loss: 0.11337198317050934, Final Batch Loss: 0.062310606241226196\n",
      "Epoch 944, Loss: 0.1364601105451584, Final Batch Loss: 0.08679463714361191\n",
      "Epoch 945, Loss: 0.140804685652256, Final Batch Loss: 0.0689648911356926\n",
      "Epoch 946, Loss: 0.1953902468085289, Final Batch Loss: 0.15362781286239624\n",
      "Epoch 947, Loss: 0.17804893851280212, Final Batch Loss: 0.08773352950811386\n",
      "Epoch 948, Loss: 0.14237405732274055, Final Batch Loss: 0.08399047702550888\n",
      "Epoch 949, Loss: 0.134260855615139, Final Batch Loss: 0.055048868060112\n",
      "Epoch 950, Loss: 0.1608482301235199, Final Batch Loss: 0.07750380784273148\n",
      "Epoch 951, Loss: 0.13276755809783936, Final Batch Loss: 0.06309300661087036\n",
      "Epoch 952, Loss: 0.1478232815861702, Final Batch Loss: 0.04655567556619644\n",
      "Epoch 953, Loss: 0.13502322882413864, Final Batch Loss: 0.07685547322034836\n",
      "Epoch 954, Loss: 0.1658134087920189, Final Batch Loss: 0.060884878039360046\n",
      "Epoch 955, Loss: 0.1314697079360485, Final Batch Loss: 0.0598301999270916\n",
      "Epoch 956, Loss: 0.12936509028077126, Final Batch Loss: 0.06937240064144135\n",
      "Epoch 957, Loss: 0.1522582769393921, Final Batch Loss: 0.07319971174001694\n",
      "Epoch 958, Loss: 0.13107405975461006, Final Batch Loss: 0.07949317246675491\n",
      "Epoch 959, Loss: 0.1496047079563141, Final Batch Loss: 0.0654308870434761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 960, Loss: 0.13166063278913498, Final Batch Loss: 0.07876072078943253\n",
      "Epoch 961, Loss: 0.15428974479436874, Final Batch Loss: 0.10800350457429886\n",
      "Epoch 962, Loss: 0.1610560640692711, Final Batch Loss: 0.08724407106637955\n",
      "Epoch 963, Loss: 0.12700505554676056, Final Batch Loss: 0.07174412906169891\n",
      "Epoch 964, Loss: 0.1509271189570427, Final Batch Loss: 0.09848209470510483\n",
      "Epoch 965, Loss: 0.20546315610408783, Final Batch Loss: 0.11854559183120728\n",
      "Epoch 966, Loss: 0.16223221644759178, Final Batch Loss: 0.1011103168129921\n",
      "Epoch 967, Loss: 0.12554362416267395, Final Batch Loss: 0.05941671133041382\n",
      "Epoch 968, Loss: 0.14119135588407516, Final Batch Loss: 0.06772833317518234\n",
      "Epoch 969, Loss: 0.1525089628994465, Final Batch Loss: 0.09263549000024796\n",
      "Epoch 970, Loss: 0.12753095477819443, Final Batch Loss: 0.06181715428829193\n",
      "Epoch 971, Loss: 0.14250405877828598, Final Batch Loss: 0.0550900474190712\n",
      "Epoch 972, Loss: 0.12438562884926796, Final Batch Loss: 0.06930692493915558\n",
      "Epoch 973, Loss: 0.13099146634340286, Final Batch Loss: 0.08562316000461578\n",
      "Epoch 974, Loss: 0.13418834656476974, Final Batch Loss: 0.058030568063259125\n",
      "Epoch 975, Loss: 0.2046308070421219, Final Batch Loss: 0.09240104258060455\n",
      "Epoch 976, Loss: 0.16739196330308914, Final Batch Loss: 0.11573491990566254\n",
      "Epoch 977, Loss: 0.12290987372398376, Final Batch Loss: 0.08413562923669815\n",
      "Epoch 978, Loss: 0.11949201300740242, Final Batch Loss: 0.06609366834163666\n",
      "Epoch 979, Loss: 0.10322419553995132, Final Batch Loss: 0.03741856664419174\n",
      "Epoch 980, Loss: 0.1310017816722393, Final Batch Loss: 0.057539936155080795\n",
      "Epoch 981, Loss: 0.17894741147756577, Final Batch Loss: 0.10663372278213501\n",
      "Epoch 982, Loss: 0.1415669284760952, Final Batch Loss: 0.06150370463728905\n",
      "Epoch 983, Loss: 0.13744479417800903, Final Batch Loss: 0.07036667317152023\n",
      "Epoch 984, Loss: 0.08766717091202736, Final Batch Loss: 0.04813886433839798\n",
      "Epoch 985, Loss: 0.12795686349272728, Final Batch Loss: 0.06731361150741577\n",
      "Epoch 986, Loss: 0.12894444540143013, Final Batch Loss: 0.04245726391673088\n",
      "Epoch 987, Loss: 0.1473832130432129, Final Batch Loss: 0.0711166113615036\n",
      "Epoch 988, Loss: 0.1613115817308426, Final Batch Loss: 0.06580206751823425\n",
      "Epoch 989, Loss: 0.19539929926395416, Final Batch Loss: 0.12188538163900375\n",
      "Epoch 990, Loss: 0.19004523754119873, Final Batch Loss: 0.07571157068014145\n",
      "Epoch 991, Loss: 0.1418885886669159, Final Batch Loss: 0.05447028577327728\n",
      "Epoch 992, Loss: 0.12625988572835922, Final Batch Loss: 0.06370587646961212\n",
      "Epoch 993, Loss: 0.13339919596910477, Final Batch Loss: 0.08469554036855698\n",
      "Epoch 994, Loss: 0.1542268879711628, Final Batch Loss: 0.09292509406805038\n",
      "Epoch 995, Loss: 0.16142522543668747, Final Batch Loss: 0.08855603635311127\n",
      "Epoch 996, Loss: 0.1515117958188057, Final Batch Loss: 0.08894535154104233\n",
      "Epoch 997, Loss: 0.13612814620137215, Final Batch Loss: 0.05170908942818642\n",
      "Epoch 998, Loss: 0.13064737990498543, Final Batch Loss: 0.07851646840572357\n",
      "Epoch 999, Loss: 0.1618516519665718, Final Batch Loss: 0.08944230526685715\n",
      "Epoch 1000, Loss: 0.16901832818984985, Final Batch Loss: 0.10594988614320755\n",
      "Epoch 1001, Loss: 0.1837301105260849, Final Batch Loss: 0.11997519433498383\n",
      "Epoch 1002, Loss: 0.1491880565881729, Final Batch Loss: 0.08001331984996796\n",
      "Epoch 1003, Loss: 0.14088695123791695, Final Batch Loss: 0.08456909656524658\n",
      "Epoch 1004, Loss: 0.12139343842864037, Final Batch Loss: 0.05011272057890892\n",
      "Epoch 1005, Loss: 0.15000664070248604, Final Batch Loss: 0.09363829344511032\n",
      "Epoch 1006, Loss: 0.14768236875534058, Final Batch Loss: 0.07038453966379166\n",
      "Epoch 1007, Loss: 0.11252529546618462, Final Batch Loss: 0.06482122093439102\n",
      "Epoch 1008, Loss: 0.15176446735858917, Final Batch Loss: 0.09637416154146194\n",
      "Epoch 1009, Loss: 0.1588665470480919, Final Batch Loss: 0.07575183361768723\n",
      "Epoch 1010, Loss: 0.1526765152812004, Final Batch Loss: 0.06052637845277786\n",
      "Epoch 1011, Loss: 0.1056356355547905, Final Batch Loss: 0.047579776495695114\n",
      "Epoch 1012, Loss: 0.18034175783395767, Final Batch Loss: 0.08094364404678345\n",
      "Epoch 1013, Loss: 0.16503417491912842, Final Batch Loss: 0.07080965489149094\n",
      "Epoch 1014, Loss: 0.15182707458734512, Final Batch Loss: 0.08159545809030533\n",
      "Epoch 1015, Loss: 0.11589635163545609, Final Batch Loss: 0.06681313365697861\n",
      "Epoch 1016, Loss: 0.14069921150803566, Final Batch Loss: 0.08408475667238235\n",
      "Epoch 1017, Loss: 0.12603263556957245, Final Batch Loss: 0.0648806244134903\n",
      "Epoch 1018, Loss: 0.13490143790841103, Final Batch Loss: 0.07873479276895523\n",
      "Epoch 1019, Loss: 0.14415184408426285, Final Batch Loss: 0.07154262065887451\n",
      "Epoch 1020, Loss: 0.14249752461910248, Final Batch Loss: 0.04889412969350815\n",
      "Epoch 1021, Loss: 0.11454539746046066, Final Batch Loss: 0.05542130023241043\n",
      "Epoch 1022, Loss: 0.1125921793282032, Final Batch Loss: 0.06039252504706383\n",
      "Epoch 1023, Loss: 0.14692389965057373, Final Batch Loss: 0.06400655955076218\n",
      "Epoch 1024, Loss: 0.15921231359243393, Final Batch Loss: 0.08461885899305344\n",
      "Epoch 1025, Loss: 0.1338280774652958, Final Batch Loss: 0.05042100325226784\n",
      "Epoch 1026, Loss: 0.12913063913583755, Final Batch Loss: 0.0737399160861969\n",
      "Epoch 1027, Loss: 0.12536713108420372, Final Batch Loss: 0.042815517634153366\n",
      "Epoch 1028, Loss: 0.1417662538588047, Final Batch Loss: 0.055696044117212296\n",
      "Epoch 1029, Loss: 0.1201372817158699, Final Batch Loss: 0.057974673807621\n",
      "Epoch 1030, Loss: 0.15736619383096695, Final Batch Loss: 0.08277719467878342\n",
      "Epoch 1031, Loss: 0.11533442512154579, Final Batch Loss: 0.06303061544895172\n",
      "Epoch 1032, Loss: 0.13577431440353394, Final Batch Loss: 0.06894425302743912\n",
      "Epoch 1033, Loss: 0.13395104929804802, Final Batch Loss: 0.05104447528719902\n",
      "Epoch 1034, Loss: 0.17989321798086166, Final Batch Loss: 0.06862813234329224\n",
      "Epoch 1035, Loss: 0.1316164769232273, Final Batch Loss: 0.039990101009607315\n",
      "Epoch 1036, Loss: 0.1406998410820961, Final Batch Loss: 0.042503729462623596\n",
      "Epoch 1037, Loss: 0.14875075221061707, Final Batch Loss: 0.07850539684295654\n",
      "Epoch 1038, Loss: 0.1233082115650177, Final Batch Loss: 0.052535317838191986\n",
      "Epoch 1039, Loss: 0.14507538452744484, Final Batch Loss: 0.0949881300330162\n",
      "Epoch 1040, Loss: 0.2529306560754776, Final Batch Loss: 0.11761198937892914\n",
      "Epoch 1041, Loss: 0.1097845658659935, Final Batch Loss: 0.04459825158119202\n",
      "Epoch 1042, Loss: 0.13692361116409302, Final Batch Loss: 0.06846348941326141\n",
      "Epoch 1043, Loss: 0.20136668533086777, Final Batch Loss: 0.07242114096879959\n",
      "Epoch 1044, Loss: 0.1352120339870453, Final Batch Loss: 0.06394675374031067\n",
      "Epoch 1045, Loss: 0.12988430261611938, Final Batch Loss: 0.0630803257226944\n",
      "Epoch 1046, Loss: 0.19666314497590065, Final Batch Loss: 0.1368459165096283\n",
      "Epoch 1047, Loss: 0.12009134888648987, Final Batch Loss: 0.08036930859088898\n",
      "Epoch 1048, Loss: 0.14815588295459747, Final Batch Loss: 0.07712370902299881\n",
      "Epoch 1049, Loss: 0.1437288001179695, Final Batch Loss: 0.11238656938076019\n",
      "Epoch 1050, Loss: 0.17593777924776077, Final Batch Loss: 0.12598124146461487\n",
      "Epoch 1051, Loss: 0.10815045982599258, Final Batch Loss: 0.052731018513441086\n",
      "Epoch 1052, Loss: 0.10645696520805359, Final Batch Loss: 0.06858740746974945\n",
      "Epoch 1053, Loss: 0.24517716467380524, Final Batch Loss: 0.15094730257987976\n",
      "Epoch 1054, Loss: 0.17917034029960632, Final Batch Loss: 0.12210328131914139\n",
      "Epoch 1055, Loss: 0.15011443197727203, Final Batch Loss: 0.079146608710289\n",
      "Epoch 1056, Loss: 0.13295544311404228, Final Batch Loss: 0.04915038123726845\n",
      "Epoch 1057, Loss: 0.17696068435907364, Final Batch Loss: 0.08628600090742111\n",
      "Epoch 1058, Loss: 0.10925960913300514, Final Batch Loss: 0.0477014034986496\n",
      "Epoch 1059, Loss: 0.15839942544698715, Final Batch Loss: 0.07443545758724213\n",
      "Epoch 1060, Loss: 0.11177000403404236, Final Batch Loss: 0.06104765832424164\n",
      "Epoch 1061, Loss: 0.11946199461817741, Final Batch Loss: 0.06073181331157684\n",
      "Epoch 1062, Loss: 0.12855471298098564, Final Batch Loss: 0.07703276723623276\n",
      "Epoch 1063, Loss: 0.10946715250611305, Final Batch Loss: 0.05278439074754715\n",
      "Epoch 1064, Loss: 0.16358695179224014, Final Batch Loss: 0.06754574179649353\n",
      "Epoch 1065, Loss: 0.15351983532309532, Final Batch Loss: 0.05172332003712654\n",
      "Epoch 1066, Loss: 0.1347370408475399, Final Batch Loss: 0.056399960070848465\n",
      "Epoch 1067, Loss: 0.1537131443619728, Final Batch Loss: 0.09213995188474655\n",
      "Epoch 1068, Loss: 0.130321454256773, Final Batch Loss: 0.05700237676501274\n",
      "Epoch 1069, Loss: 0.14355777949094772, Final Batch Loss: 0.09700000286102295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1070, Loss: 0.1182435005903244, Final Batch Loss: 0.041961103677749634\n",
      "Epoch 1071, Loss: 0.15993044525384903, Final Batch Loss: 0.08115342259407043\n",
      "Epoch 1072, Loss: 0.21039701998233795, Final Batch Loss: 0.12942449748516083\n",
      "Epoch 1073, Loss: 0.1924930363893509, Final Batch Loss: 0.11349164694547653\n",
      "Epoch 1074, Loss: 0.12642480432987213, Final Batch Loss: 0.06437625735998154\n",
      "Epoch 1075, Loss: 0.11311932653188705, Final Batch Loss: 0.05130179598927498\n",
      "Epoch 1076, Loss: 0.09201253578066826, Final Batch Loss: 0.047569505870342255\n",
      "Epoch 1077, Loss: 0.1745167076587677, Final Batch Loss: 0.07100564241409302\n",
      "Epoch 1078, Loss: 0.19869334995746613, Final Batch Loss: 0.11067324131727219\n",
      "Epoch 1079, Loss: 0.13164963573217392, Final Batch Loss: 0.06381209194660187\n",
      "Epoch 1080, Loss: 0.13855010271072388, Final Batch Loss: 0.062410078942775726\n",
      "Epoch 1081, Loss: 0.13625527173280716, Final Batch Loss: 0.06453986465930939\n",
      "Epoch 1082, Loss: 0.11873449012637138, Final Batch Loss: 0.03679485246539116\n",
      "Epoch 1083, Loss: 0.19336356967687607, Final Batch Loss: 0.08609019964933395\n",
      "Epoch 1084, Loss: 0.10583995282649994, Final Batch Loss: 0.059139639139175415\n",
      "Epoch 1085, Loss: 0.13849500566720963, Final Batch Loss: 0.06924119591712952\n",
      "Epoch 1086, Loss: 0.1606389284133911, Final Batch Loss: 0.08270058035850525\n",
      "Epoch 1087, Loss: 0.1659887582063675, Final Batch Loss: 0.042553193867206573\n",
      "Epoch 1088, Loss: 0.1725960224866867, Final Batch Loss: 0.1050400584936142\n",
      "Epoch 1089, Loss: 0.13472799211740494, Final Batch Loss: 0.06580598652362823\n",
      "Epoch 1090, Loss: 0.11383126676082611, Final Batch Loss: 0.055266547948122025\n",
      "Epoch 1091, Loss: 0.1379891186952591, Final Batch Loss: 0.07981371134519577\n",
      "Epoch 1092, Loss: 0.16120897233486176, Final Batch Loss: 0.09305157512426376\n",
      "Epoch 1093, Loss: 0.12768486887216568, Final Batch Loss: 0.04539161175489426\n",
      "Epoch 1094, Loss: 0.09878820180892944, Final Batch Loss: 0.0371374674141407\n",
      "Epoch 1095, Loss: 0.12346667051315308, Final Batch Loss: 0.04392101615667343\n",
      "Epoch 1096, Loss: 0.11312055215239525, Final Batch Loss: 0.04448695853352547\n",
      "Epoch 1097, Loss: 0.12958012148737907, Final Batch Loss: 0.05784211680293083\n",
      "Epoch 1098, Loss: 0.12180766463279724, Final Batch Loss: 0.06847924739122391\n",
      "Epoch 1099, Loss: 0.11927993968129158, Final Batch Loss: 0.04893805459141731\n",
      "Epoch 1100, Loss: 0.10995201393961906, Final Batch Loss: 0.06510759890079498\n",
      "Epoch 1101, Loss: 0.13202237710356712, Final Batch Loss: 0.08242542296648026\n",
      "Epoch 1102, Loss: 0.10256146267056465, Final Batch Loss: 0.057056915014982224\n",
      "Epoch 1103, Loss: 0.14131096005439758, Final Batch Loss: 0.05864018201828003\n",
      "Epoch 1104, Loss: 0.11734317243099213, Final Batch Loss: 0.06325282156467438\n",
      "Epoch 1105, Loss: 0.13593104481697083, Final Batch Loss: 0.06499971449375153\n",
      "Epoch 1106, Loss: 0.13556557148694992, Final Batch Loss: 0.0711568221449852\n",
      "Epoch 1107, Loss: 0.11748246103525162, Final Batch Loss: 0.0526328906416893\n",
      "Epoch 1108, Loss: 0.09442988410592079, Final Batch Loss: 0.04224656894803047\n",
      "Epoch 1109, Loss: 0.10472378507256508, Final Batch Loss: 0.03958841785788536\n",
      "Epoch 1110, Loss: 0.16393771022558212, Final Batch Loss: 0.04813981056213379\n",
      "Epoch 1111, Loss: 0.10384703055024147, Final Batch Loss: 0.049368929117918015\n",
      "Epoch 1112, Loss: 0.13293420150876045, Final Batch Loss: 0.04549010470509529\n",
      "Epoch 1113, Loss: 0.14556219428777695, Final Batch Loss: 0.06554510444402695\n",
      "Epoch 1114, Loss: 0.12767987698316574, Final Batch Loss: 0.06710891425609589\n",
      "Epoch 1115, Loss: 0.13792526721954346, Final Batch Loss: 0.07325524091720581\n",
      "Epoch 1116, Loss: 0.14574196934700012, Final Batch Loss: 0.05317431688308716\n",
      "Epoch 1117, Loss: 0.1065366342663765, Final Batch Loss: 0.033236779272556305\n",
      "Epoch 1118, Loss: 0.13885421678423882, Final Batch Loss: 0.08477535098791122\n",
      "Epoch 1119, Loss: 0.11242793500423431, Final Batch Loss: 0.06479079276323318\n",
      "Epoch 1120, Loss: 0.16733955591917038, Final Batch Loss: 0.08935702592134476\n",
      "Epoch 1121, Loss: 0.11511975899338722, Final Batch Loss: 0.05738454312086105\n",
      "Epoch 1122, Loss: 0.08942344039678574, Final Batch Loss: 0.03462929278612137\n",
      "Epoch 1123, Loss: 0.11649059131741524, Final Batch Loss: 0.06962166726589203\n",
      "Epoch 1124, Loss: 0.11457343772053719, Final Batch Loss: 0.047887902706861496\n",
      "Epoch 1125, Loss: 0.11765874922275543, Final Batch Loss: 0.05319332331418991\n",
      "Epoch 1126, Loss: 0.13942915201187134, Final Batch Loss: 0.09602836519479752\n",
      "Epoch 1127, Loss: 0.09165000542998314, Final Batch Loss: 0.045076724141836166\n",
      "Epoch 1128, Loss: 0.1682402789592743, Final Batch Loss: 0.08834247291088104\n",
      "Epoch 1129, Loss: 0.1819145791232586, Final Batch Loss: 0.13222892582416534\n",
      "Epoch 1130, Loss: 0.12045411765575409, Final Batch Loss: 0.05299495905637741\n",
      "Epoch 1131, Loss: 0.1764903888106346, Final Batch Loss: 0.0787753164768219\n",
      "Epoch 1132, Loss: 0.14431536197662354, Final Batch Loss: 0.08590658754110336\n",
      "Epoch 1133, Loss: 0.12003214657306671, Final Batch Loss: 0.034293219447135925\n",
      "Epoch 1134, Loss: 0.17410100996494293, Final Batch Loss: 0.07424730807542801\n",
      "Epoch 1135, Loss: 0.10798895359039307, Final Batch Loss: 0.04896324500441551\n",
      "Epoch 1136, Loss: 0.11724511533975601, Final Batch Loss: 0.0559086836874485\n",
      "Epoch 1137, Loss: 0.12594939395785332, Final Batch Loss: 0.03926931694149971\n",
      "Epoch 1138, Loss: 0.10470080748200417, Final Batch Loss: 0.038743484765291214\n",
      "Epoch 1139, Loss: 0.15612319856882095, Final Batch Loss: 0.08085992932319641\n",
      "Epoch 1140, Loss: 0.13660777732729912, Final Batch Loss: 0.061757732182741165\n",
      "Epoch 1141, Loss: 0.11965145170688629, Final Batch Loss: 0.07651297748088837\n",
      "Epoch 1142, Loss: 0.12534882873296738, Final Batch Loss: 0.05866837501525879\n",
      "Epoch 1143, Loss: 0.14220302179455757, Final Batch Loss: 0.08513599634170532\n",
      "Epoch 1144, Loss: 0.11657494306564331, Final Batch Loss: 0.05673779547214508\n",
      "Epoch 1145, Loss: 0.1508004143834114, Final Batch Loss: 0.08523285388946533\n",
      "Epoch 1146, Loss: 0.16452081501483917, Final Batch Loss: 0.08021258562803268\n",
      "Epoch 1147, Loss: 0.21740688383579254, Final Batch Loss: 0.08885043859481812\n",
      "Epoch 1148, Loss: 0.14663178473711014, Final Batch Loss: 0.07182137668132782\n",
      "Epoch 1149, Loss: 0.12850691750645638, Final Batch Loss: 0.07509105652570724\n",
      "Epoch 1150, Loss: 0.12976057827472687, Final Batch Loss: 0.045697107911109924\n",
      "Epoch 1151, Loss: 0.10541533678770065, Final Batch Loss: 0.044938452541828156\n",
      "Epoch 1152, Loss: 0.09522471576929092, Final Batch Loss: 0.03404233977198601\n",
      "Epoch 1153, Loss: 0.1202693022787571, Final Batch Loss: 0.052589986473321915\n",
      "Epoch 1154, Loss: 0.09449956007301807, Final Batch Loss: 0.030005285516381264\n",
      "Epoch 1155, Loss: 0.1288958638906479, Final Batch Loss: 0.06481270492076874\n",
      "Epoch 1156, Loss: 0.1388501152396202, Final Batch Loss: 0.06931176036596298\n",
      "Epoch 1157, Loss: 0.11451384052634239, Final Batch Loss: 0.04379667714238167\n",
      "Epoch 1158, Loss: 0.12683863192796707, Final Batch Loss: 0.0626012533903122\n",
      "Epoch 1159, Loss: 0.13056165352463722, Final Batch Loss: 0.08618505299091339\n",
      "Epoch 1160, Loss: 0.11550067737698555, Final Batch Loss: 0.03745817765593529\n",
      "Epoch 1161, Loss: 0.10177455469965935, Final Batch Loss: 0.05432608351111412\n",
      "Epoch 1162, Loss: 0.09711909666657448, Final Batch Loss: 0.03718798607587814\n",
      "Epoch 1163, Loss: 0.11731944233179092, Final Batch Loss: 0.06295676529407501\n",
      "Epoch 1164, Loss: 0.13156335055828094, Final Batch Loss: 0.0770343542098999\n",
      "Epoch 1165, Loss: 0.16413379460573196, Final Batch Loss: 0.08802291005849838\n",
      "Epoch 1166, Loss: 0.14950670674443245, Final Batch Loss: 0.04722588136792183\n",
      "Epoch 1167, Loss: 0.0807282105088234, Final Batch Loss: 0.04490318521857262\n",
      "Epoch 1168, Loss: 0.12302966043353081, Final Batch Loss: 0.05467074736952782\n",
      "Epoch 1169, Loss: 0.11451731994748116, Final Batch Loss: 0.050768669694662094\n",
      "Epoch 1170, Loss: 0.12467391043901443, Final Batch Loss: 0.0761023759841919\n",
      "Epoch 1171, Loss: 0.13464772701263428, Final Batch Loss: 0.07916795462369919\n",
      "Epoch 1172, Loss: 0.16629179567098618, Final Batch Loss: 0.10098850727081299\n",
      "Epoch 1173, Loss: 0.12669379636645317, Final Batch Loss: 0.06247877702116966\n",
      "Epoch 1174, Loss: 0.1302884891629219, Final Batch Loss: 0.10351915657520294\n",
      "Epoch 1175, Loss: 0.12263217940926552, Final Batch Loss: 0.06288589537143707\n",
      "Epoch 1176, Loss: 0.12667205929756165, Final Batch Loss: 0.07249179482460022\n",
      "Epoch 1177, Loss: 0.14329886808991432, Final Batch Loss: 0.08739009499549866\n",
      "Epoch 1178, Loss: 0.13503548502922058, Final Batch Loss: 0.07106927037239075\n",
      "Epoch 1179, Loss: 0.1372113823890686, Final Batch Loss: 0.0750390812754631\n",
      "Epoch 1180, Loss: 0.0991872288286686, Final Batch Loss: 0.037514280527830124\n",
      "Epoch 1181, Loss: 0.2145652025938034, Final Batch Loss: 0.16097164154052734\n",
      "Epoch 1182, Loss: 0.13400592654943466, Final Batch Loss: 0.0357627272605896\n",
      "Epoch 1183, Loss: 0.10300875827670097, Final Batch Loss: 0.046230316162109375\n",
      "Epoch 1184, Loss: 0.12233053892850876, Final Batch Loss: 0.08058138936758041\n",
      "Epoch 1185, Loss: 0.100380789488554, Final Batch Loss: 0.056754399091005325\n",
      "Epoch 1186, Loss: 0.17083045840263367, Final Batch Loss: 0.09583444893360138\n",
      "Epoch 1187, Loss: 0.11570335552096367, Final Batch Loss: 0.06787112355232239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1188, Loss: 0.12444760650396347, Final Batch Loss: 0.05659238249063492\n",
      "Epoch 1189, Loss: 0.12483742460608482, Final Batch Loss: 0.06805826723575592\n",
      "Epoch 1190, Loss: 0.12623021379113197, Final Batch Loss: 0.03442826494574547\n",
      "Epoch 1191, Loss: 0.16204460710287094, Final Batch Loss: 0.06978987902402878\n",
      "Epoch 1192, Loss: 0.08915694430470467, Final Batch Loss: 0.03767598792910576\n",
      "Epoch 1193, Loss: 0.13671211898326874, Final Batch Loss: 0.0517377108335495\n",
      "Epoch 1194, Loss: 0.10698214173316956, Final Batch Loss: 0.060519564896821976\n",
      "Epoch 1195, Loss: 0.13926467671990395, Final Batch Loss: 0.056102436035871506\n",
      "Epoch 1196, Loss: 0.09190920740365982, Final Batch Loss: 0.040117133408784866\n",
      "Epoch 1197, Loss: 0.13002966716885567, Final Batch Loss: 0.09349355846643448\n",
      "Epoch 1198, Loss: 0.11882820352911949, Final Batch Loss: 0.0727037787437439\n",
      "Epoch 1199, Loss: 0.1360943205654621, Final Batch Loss: 0.05221274867653847\n",
      "Epoch 1200, Loss: 0.12397011369466782, Final Batch Loss: 0.07733976095914841\n",
      "Epoch 1201, Loss: 0.1050039790570736, Final Batch Loss: 0.04606787487864494\n",
      "Epoch 1202, Loss: 0.15732337534427643, Final Batch Loss: 0.08160926401615143\n",
      "Epoch 1203, Loss: 0.17740100622177124, Final Batch Loss: 0.11381252110004425\n",
      "Epoch 1204, Loss: 0.12704288214445114, Final Batch Loss: 0.06384146213531494\n",
      "Epoch 1205, Loss: 0.11184453219175339, Final Batch Loss: 0.06460931897163391\n",
      "Epoch 1206, Loss: 0.11718032509088516, Final Batch Loss: 0.05671054124832153\n",
      "Epoch 1207, Loss: 0.10836521163582802, Final Batch Loss: 0.06530772149562836\n",
      "Epoch 1208, Loss: 0.12809398770332336, Final Batch Loss: 0.05672337859869003\n",
      "Epoch 1209, Loss: 0.10054836422204971, Final Batch Loss: 0.04152250662446022\n",
      "Epoch 1210, Loss: 0.14152608066797256, Final Batch Loss: 0.06807221472263336\n",
      "Epoch 1211, Loss: 0.10955585166811943, Final Batch Loss: 0.04816363751888275\n",
      "Epoch 1212, Loss: 0.12306874245405197, Final Batch Loss: 0.07573442906141281\n",
      "Epoch 1213, Loss: 0.1273937150835991, Final Batch Loss: 0.055246010422706604\n",
      "Epoch 1214, Loss: 0.18579493463039398, Final Batch Loss: 0.1174384206533432\n",
      "Epoch 1215, Loss: 0.12691068276762962, Final Batch Loss: 0.06895553320646286\n",
      "Epoch 1216, Loss: 0.14386244118213654, Final Batch Loss: 0.06302651762962341\n",
      "Epoch 1217, Loss: 0.10840163379907608, Final Batch Loss: 0.034034475684165955\n",
      "Epoch 1218, Loss: 0.13576889410614967, Final Batch Loss: 0.08883874118328094\n",
      "Epoch 1219, Loss: 0.12563152238726616, Final Batch Loss: 0.04992963746190071\n",
      "Epoch 1220, Loss: 0.11072994023561478, Final Batch Loss: 0.07012904435396194\n",
      "Epoch 1221, Loss: 0.110569316893816, Final Batch Loss: 0.05731280520558357\n",
      "Epoch 1222, Loss: 0.15850578248500824, Final Batch Loss: 0.09578792750835419\n",
      "Epoch 1223, Loss: 0.13683945685625076, Final Batch Loss: 0.08062517642974854\n",
      "Epoch 1224, Loss: 0.12037868052721024, Final Batch Loss: 0.051434777677059174\n",
      "Epoch 1225, Loss: 0.12175615131855011, Final Batch Loss: 0.06333277374505997\n",
      "Epoch 1226, Loss: 0.13453175500035286, Final Batch Loss: 0.05569221451878548\n",
      "Epoch 1227, Loss: 0.10249222069978714, Final Batch Loss: 0.04320530593395233\n",
      "Epoch 1228, Loss: 0.11642353981733322, Final Batch Loss: 0.0668807327747345\n",
      "Epoch 1229, Loss: 0.125896617770195, Final Batch Loss: 0.045859307050704956\n",
      "Epoch 1230, Loss: 0.15688377618789673, Final Batch Loss: 0.06456030160188675\n",
      "Epoch 1231, Loss: 0.13266237825155258, Final Batch Loss: 0.06062041223049164\n",
      "Epoch 1232, Loss: 0.14391951635479927, Final Batch Loss: 0.05389374867081642\n",
      "Epoch 1233, Loss: 0.08332637324929237, Final Batch Loss: 0.04833310842514038\n",
      "Epoch 1234, Loss: 0.09890592843294144, Final Batch Loss: 0.06236841157078743\n",
      "Epoch 1235, Loss: 0.10968462750315666, Final Batch Loss: 0.05352955311536789\n",
      "Epoch 1236, Loss: 0.11714453622698784, Final Batch Loss: 0.068944551050663\n",
      "Epoch 1237, Loss: 0.11175179481506348, Final Batch Loss: 0.04892708361148834\n",
      "Epoch 1238, Loss: 0.11205960065126419, Final Batch Loss: 0.06400109082460403\n",
      "Epoch 1239, Loss: 0.10539016872644424, Final Batch Loss: 0.05645318329334259\n",
      "Epoch 1240, Loss: 0.11240100488066673, Final Batch Loss: 0.03314126655459404\n",
      "Epoch 1241, Loss: 0.10751361399888992, Final Batch Loss: 0.05139685794711113\n",
      "Epoch 1242, Loss: 0.09274912998080254, Final Batch Loss: 0.04205146059393883\n",
      "Epoch 1243, Loss: 0.1286407709121704, Final Batch Loss: 0.07180896401405334\n",
      "Epoch 1244, Loss: 0.1261117234826088, Final Batch Loss: 0.08674439787864685\n",
      "Epoch 1245, Loss: 0.16853315383195877, Final Batch Loss: 0.08401252329349518\n",
      "Epoch 1246, Loss: 0.14619680494070053, Final Batch Loss: 0.08134683221578598\n",
      "Epoch 1247, Loss: 0.13401072844862938, Final Batch Loss: 0.04705411568284035\n",
      "Epoch 1248, Loss: 0.13928620517253876, Final Batch Loss: 0.06169077008962631\n",
      "Epoch 1249, Loss: 0.15552204847335815, Final Batch Loss: 0.07588424533605576\n",
      "Epoch 1250, Loss: 0.1263195276260376, Final Batch Loss: 0.06375932693481445\n",
      "Epoch 1251, Loss: 0.1517358273267746, Final Batch Loss: 0.09019635617733002\n",
      "Epoch 1252, Loss: 0.12049549072980881, Final Batch Loss: 0.08715122193098068\n",
      "Epoch 1253, Loss: 0.14327865466475487, Final Batch Loss: 0.08796893060207367\n",
      "Epoch 1254, Loss: 0.118638776242733, Final Batch Loss: 0.0644410029053688\n",
      "Epoch 1255, Loss: 0.16026605665683746, Final Batch Loss: 0.07647419720888138\n",
      "Epoch 1256, Loss: 0.21732790023088455, Final Batch Loss: 0.13934831321239471\n",
      "Epoch 1257, Loss: 0.14890246093273163, Final Batch Loss: 0.10960134118795395\n",
      "Epoch 1258, Loss: 0.27354368567466736, Final Batch Loss: 0.14315272867679596\n",
      "Epoch 1259, Loss: 0.12115117907524109, Final Batch Loss: 0.056620217859745026\n",
      "Epoch 1260, Loss: 0.18794956803321838, Final Batch Loss: 0.07967809587717056\n",
      "Epoch 1261, Loss: 0.1274312511086464, Final Batch Loss: 0.05351301282644272\n",
      "Epoch 1262, Loss: 0.14201302826404572, Final Batch Loss: 0.06889429688453674\n",
      "Epoch 1263, Loss: 0.11916997656226158, Final Batch Loss: 0.030520793050527573\n",
      "Epoch 1264, Loss: 0.12353796139359474, Final Batch Loss: 0.07143770903348923\n",
      "Epoch 1265, Loss: 0.16936182975769043, Final Batch Loss: 0.06935661286115646\n",
      "Epoch 1266, Loss: 0.17198998481035233, Final Batch Loss: 0.07873599976301193\n",
      "Epoch 1267, Loss: 0.18582846969366074, Final Batch Loss: 0.04291928559541702\n",
      "Epoch 1268, Loss: 0.1814120039343834, Final Batch Loss: 0.1395866870880127\n",
      "Epoch 1269, Loss: 0.11369345337152481, Final Batch Loss: 0.049594394862651825\n",
      "Epoch 1270, Loss: 0.12805696949362755, Final Batch Loss: 0.06948574632406235\n",
      "Epoch 1271, Loss: 0.13301346078515053, Final Batch Loss: 0.08322246372699738\n",
      "Epoch 1272, Loss: 0.14364711195230484, Final Batch Loss: 0.056594327092170715\n",
      "Epoch 1273, Loss: 0.11213551461696625, Final Batch Loss: 0.05502843111753464\n",
      "Epoch 1274, Loss: 0.11876409128308296, Final Batch Loss: 0.06137658655643463\n",
      "Epoch 1275, Loss: 0.15436558052897453, Final Batch Loss: 0.10404845327138901\n",
      "Epoch 1276, Loss: 0.10998968034982681, Final Batch Loss: 0.04806246981024742\n",
      "Epoch 1277, Loss: 0.10946331918239594, Final Batch Loss: 0.04836117848753929\n",
      "Epoch 1278, Loss: 0.13161545246839523, Final Batch Loss: 0.05685379356145859\n",
      "Epoch 1279, Loss: 0.1617511734366417, Final Batch Loss: 0.06678563356399536\n",
      "Epoch 1280, Loss: 0.19487904012203217, Final Batch Loss: 0.09744637459516525\n",
      "Epoch 1281, Loss: 0.11971846967935562, Final Batch Loss: 0.06419678777456284\n",
      "Epoch 1282, Loss: 0.09772619232535362, Final Batch Loss: 0.04099363833665848\n",
      "Epoch 1283, Loss: 0.08778872713446617, Final Batch Loss: 0.04439472034573555\n",
      "Epoch 1284, Loss: 0.10165785625576973, Final Batch Loss: 0.060733940452337265\n",
      "Epoch 1285, Loss: 0.12379857152700424, Final Batch Loss: 0.0445573627948761\n",
      "Epoch 1286, Loss: 0.09849342703819275, Final Batch Loss: 0.046625830233097076\n",
      "Epoch 1287, Loss: 0.1385565586388111, Final Batch Loss: 0.08215878903865814\n",
      "Epoch 1288, Loss: 0.1174803376197815, Final Batch Loss: 0.067718006670475\n",
      "Epoch 1289, Loss: 0.1061202846467495, Final Batch Loss: 0.04864545166492462\n",
      "Epoch 1290, Loss: 0.1267995573580265, Final Batch Loss: 0.04602203145623207\n",
      "Epoch 1291, Loss: 0.11730458959937096, Final Batch Loss: 0.060297999531030655\n",
      "Epoch 1292, Loss: 0.12442487478256226, Final Batch Loss: 0.05596280097961426\n",
      "Epoch 1293, Loss: 0.13347255811095238, Final Batch Loss: 0.0895061120390892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1294, Loss: 0.0916014015674591, Final Batch Loss: 0.04415503516793251\n",
      "Epoch 1295, Loss: 0.1402876228094101, Final Batch Loss: 0.06625115126371384\n",
      "Epoch 1296, Loss: 0.10115070454776287, Final Batch Loss: 0.026650255545973778\n",
      "Epoch 1297, Loss: 0.09193185344338417, Final Batch Loss: 0.05688516050577164\n",
      "Epoch 1298, Loss: 0.09744108095765114, Final Batch Loss: 0.04405903071165085\n",
      "Epoch 1299, Loss: 0.08934183418750763, Final Batch Loss: 0.04790308699011803\n",
      "Epoch 1300, Loss: 0.12568368390202522, Final Batch Loss: 0.05730896070599556\n",
      "Epoch 1301, Loss: 0.10801992937922478, Final Batch Loss: 0.045287903398275375\n",
      "Epoch 1302, Loss: 0.1264588162302971, Final Batch Loss: 0.054889410734176636\n",
      "Epoch 1303, Loss: 0.08757665753364563, Final Batch Loss: 0.055368319153785706\n",
      "Epoch 1304, Loss: 0.10732174292206764, Final Batch Loss: 0.05603755638003349\n",
      "Epoch 1305, Loss: 0.15396005660295486, Final Batch Loss: 0.0444410964846611\n",
      "Epoch 1306, Loss: 0.1123742051422596, Final Batch Loss: 0.051171112805604935\n",
      "Epoch 1307, Loss: 0.13987185433506966, Final Batch Loss: 0.05756423994898796\n",
      "Epoch 1308, Loss: 0.12372446805238724, Final Batch Loss: 0.07242949306964874\n",
      "Epoch 1309, Loss: 0.10785224288702011, Final Batch Loss: 0.04615093767642975\n",
      "Epoch 1310, Loss: 0.1443641483783722, Final Batch Loss: 0.07135959714651108\n",
      "Epoch 1311, Loss: 0.09739432111382484, Final Batch Loss: 0.04321873560547829\n",
      "Epoch 1312, Loss: 0.08806222304701805, Final Batch Loss: 0.04900987818837166\n",
      "Epoch 1313, Loss: 0.10894238576292992, Final Batch Loss: 0.054703645408153534\n",
      "Epoch 1314, Loss: 0.15027647465467453, Final Batch Loss: 0.06463552266359329\n",
      "Epoch 1315, Loss: 0.1068241074681282, Final Batch Loss: 0.06740735471248627\n",
      "Epoch 1316, Loss: 0.08793458342552185, Final Batch Loss: 0.03170834109187126\n",
      "Epoch 1317, Loss: 0.12620200216770172, Final Batch Loss: 0.06756241619586945\n",
      "Epoch 1318, Loss: 0.10789882391691208, Final Batch Loss: 0.034296855330467224\n",
      "Epoch 1319, Loss: 0.12904025986790657, Final Batch Loss: 0.07971055060625076\n",
      "Epoch 1320, Loss: 0.0947451014071703, Final Batch Loss: 0.022470595315098763\n",
      "Epoch 1321, Loss: 0.11030490510165691, Final Batch Loss: 0.0793074518442154\n",
      "Epoch 1322, Loss: 0.10769500210881233, Final Batch Loss: 0.07516084611415863\n",
      "Epoch 1323, Loss: 0.27890346199274063, Final Batch Loss: 0.06409990042448044\n",
      "Epoch 1324, Loss: 0.1521942913532257, Final Batch Loss: 0.08574069291353226\n",
      "Epoch 1325, Loss: 0.12243727222084999, Final Batch Loss: 0.0720667764544487\n",
      "Epoch 1326, Loss: 0.1250024437904358, Final Batch Loss: 0.056773409247398376\n",
      "Epoch 1327, Loss: 0.13474906235933304, Final Batch Loss: 0.06538083404302597\n",
      "Epoch 1328, Loss: 0.15697553381323814, Final Batch Loss: 0.1068655252456665\n",
      "Epoch 1329, Loss: 0.11100278794765472, Final Batch Loss: 0.06812402606010437\n",
      "Epoch 1330, Loss: 0.09479240328073502, Final Batch Loss: 0.04064583033323288\n",
      "Epoch 1331, Loss: 0.11858811601996422, Final Batch Loss: 0.07779043912887573\n",
      "Epoch 1332, Loss: 0.08492841199040413, Final Batch Loss: 0.05124028027057648\n",
      "Epoch 1333, Loss: 0.25022025406360626, Final Batch Loss: 0.18347066640853882\n",
      "Epoch 1334, Loss: 0.11211464554071426, Final Batch Loss: 0.05433434620499611\n",
      "Epoch 1335, Loss: 0.09876540303230286, Final Batch Loss: 0.03978706896305084\n",
      "Epoch 1336, Loss: 0.11545830965042114, Final Batch Loss: 0.06709858775138855\n",
      "Epoch 1337, Loss: 0.10689722374081612, Final Batch Loss: 0.0631411001086235\n",
      "Epoch 1338, Loss: 0.13083868473768234, Final Batch Loss: 0.07399767637252808\n",
      "Epoch 1339, Loss: 0.14716419577598572, Final Batch Loss: 0.06419435888528824\n",
      "Epoch 1340, Loss: 0.09051420167088509, Final Batch Loss: 0.027362551540136337\n",
      "Epoch 1341, Loss: 0.13965700194239616, Final Batch Loss: 0.03706296905875206\n",
      "Epoch 1342, Loss: 0.12429958209395409, Final Batch Loss: 0.07122429460287094\n",
      "Epoch 1343, Loss: 0.11699429526925087, Final Batch Loss: 0.07704833894968033\n",
      "Epoch 1344, Loss: 0.14136140793561935, Final Batch Loss: 0.06966855376958847\n",
      "Epoch 1345, Loss: 0.13164623826742172, Final Batch Loss: 0.05177201330661774\n",
      "Epoch 1346, Loss: 0.10386195033788681, Final Batch Loss: 0.06988091766834259\n",
      "Epoch 1347, Loss: 0.11152463406324387, Final Batch Loss: 0.05499934032559395\n",
      "Epoch 1348, Loss: 0.11159548163414001, Final Batch Loss: 0.046180933713912964\n",
      "Epoch 1349, Loss: 0.12003057822585106, Final Batch Loss: 0.06124182045459747\n",
      "Epoch 1350, Loss: 0.10297287628054619, Final Batch Loss: 0.05336703360080719\n",
      "Epoch 1351, Loss: 0.09578686207532883, Final Batch Loss: 0.047535769641399384\n",
      "Epoch 1352, Loss: 0.16595161333680153, Final Batch Loss: 0.05427858605980873\n",
      "Epoch 1353, Loss: 0.12552842497825623, Final Batch Loss: 0.06943586468696594\n",
      "Epoch 1354, Loss: 0.08579643070697784, Final Batch Loss: 0.045479804277420044\n",
      "Epoch 1355, Loss: 0.10735263302922249, Final Batch Loss: 0.03835717961192131\n",
      "Epoch 1356, Loss: 0.07981496676802635, Final Batch Loss: 0.03219861909747124\n",
      "Epoch 1357, Loss: 0.13494595885276794, Final Batch Loss: 0.057381771504879\n",
      "Epoch 1358, Loss: 0.1100565493106842, Final Batch Loss: 0.03490301966667175\n",
      "Epoch 1359, Loss: 0.11610931158065796, Final Batch Loss: 0.05982031673192978\n",
      "Epoch 1360, Loss: 0.10527380183339119, Final Batch Loss: 0.0708315521478653\n",
      "Epoch 1361, Loss: 0.09701274707913399, Final Batch Loss: 0.03828180581331253\n",
      "Epoch 1362, Loss: 0.07715097069740295, Final Batch Loss: 0.04518158361315727\n",
      "Epoch 1363, Loss: 0.08571742102503777, Final Batch Loss: 0.046799108386039734\n",
      "Epoch 1364, Loss: 0.09535963833332062, Final Batch Loss: 0.04979509115219116\n",
      "Epoch 1365, Loss: 0.07596339285373688, Final Batch Loss: 0.03900451585650444\n",
      "Epoch 1366, Loss: 0.09820215776562691, Final Batch Loss: 0.04654330760240555\n",
      "Epoch 1367, Loss: 0.09458208829164505, Final Batch Loss: 0.05264651030302048\n",
      "Epoch 1368, Loss: 0.09148819372057915, Final Batch Loss: 0.04480857402086258\n",
      "Epoch 1369, Loss: 0.15973836928606033, Final Batch Loss: 0.09290025383234024\n",
      "Epoch 1370, Loss: 0.10902056470513344, Final Batch Loss: 0.07111655920743942\n",
      "Epoch 1371, Loss: 0.11079982295632362, Final Batch Loss: 0.05547136440873146\n",
      "Epoch 1372, Loss: 0.1059177964925766, Final Batch Loss: 0.05526658892631531\n",
      "Epoch 1373, Loss: 0.10419188812375069, Final Batch Loss: 0.05460478737950325\n",
      "Epoch 1374, Loss: 0.10009756311774254, Final Batch Loss: 0.05414019525051117\n",
      "Epoch 1375, Loss: 0.10314993560314178, Final Batch Loss: 0.03048861026763916\n",
      "Epoch 1376, Loss: 0.12109816446900368, Final Batch Loss: 0.05558759346604347\n",
      "Epoch 1377, Loss: 0.07592948153614998, Final Batch Loss: 0.02623932436108589\n",
      "Epoch 1378, Loss: 0.10111896693706512, Final Batch Loss: 0.049916140735149384\n",
      "Epoch 1379, Loss: 0.11656492576003075, Final Batch Loss: 0.051758285611867905\n",
      "Epoch 1380, Loss: 0.09133147075772285, Final Batch Loss: 0.04629048705101013\n",
      "Epoch 1381, Loss: 0.09466416388750076, Final Batch Loss: 0.04319918155670166\n",
      "Epoch 1382, Loss: 0.08353331685066223, Final Batch Loss: 0.032174497842788696\n",
      "Epoch 1383, Loss: 0.06786590814590454, Final Batch Loss: 0.03046225756406784\n",
      "Epoch 1384, Loss: 0.13719631731510162, Final Batch Loss: 0.10109647363424301\n",
      "Epoch 1385, Loss: 0.12497052922844887, Final Batch Loss: 0.06721515208482742\n",
      "Epoch 1386, Loss: 0.09838609024882317, Final Batch Loss: 0.051470376551151276\n",
      "Epoch 1387, Loss: 0.12052232399582863, Final Batch Loss: 0.048879366368055344\n",
      "Epoch 1388, Loss: 0.1063995286822319, Final Batch Loss: 0.038829050958156586\n",
      "Epoch 1389, Loss: 0.13420158997178078, Final Batch Loss: 0.0410296805202961\n",
      "Epoch 1390, Loss: 0.11115212365984917, Final Batch Loss: 0.05977357178926468\n",
      "Epoch 1391, Loss: 0.08782955631613731, Final Batch Loss: 0.04628083109855652\n",
      "Epoch 1392, Loss: 0.10478419065475464, Final Batch Loss: 0.057069119065999985\n",
      "Epoch 1393, Loss: 0.08008153550326824, Final Batch Loss: 0.030358964577317238\n",
      "Epoch 1394, Loss: 0.10689487680792809, Final Batch Loss: 0.04439369961619377\n",
      "Epoch 1395, Loss: 0.11059165745973587, Final Batch Loss: 0.06941578537225723\n",
      "Epoch 1396, Loss: 0.12797174602746964, Final Batch Loss: 0.0728534609079361\n",
      "Epoch 1397, Loss: 0.11111132055521011, Final Batch Loss: 0.07321599125862122\n",
      "Epoch 1398, Loss: 0.10281848534941673, Final Batch Loss: 0.05620715767145157\n",
      "Epoch 1399, Loss: 0.10671992227435112, Final Batch Loss: 0.07127223163843155\n",
      "Epoch 1400, Loss: 0.11846756190061569, Final Batch Loss: 0.06497519463300705\n",
      "Epoch 1401, Loss: 0.0930672287940979, Final Batch Loss: 0.04587865248322487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1402, Loss: 0.09940299391746521, Final Batch Loss: 0.045531660318374634\n",
      "Epoch 1403, Loss: 0.09243949875235558, Final Batch Loss: 0.05270915478467941\n",
      "Epoch 1404, Loss: 0.09934841841459274, Final Batch Loss: 0.05737492814660072\n",
      "Epoch 1405, Loss: 0.11140268296003342, Final Batch Loss: 0.06123149022459984\n",
      "Epoch 1406, Loss: 0.12211819365620613, Final Batch Loss: 0.07882686704397202\n",
      "Epoch 1407, Loss: 0.09928818047046661, Final Batch Loss: 0.03433428704738617\n",
      "Epoch 1408, Loss: 0.09939423203468323, Final Batch Loss: 0.052175123244524\n",
      "Epoch 1409, Loss: 0.10045653954148293, Final Batch Loss: 0.04264630749821663\n",
      "Epoch 1410, Loss: 0.15548770502209663, Final Batch Loss: 0.09827403724193573\n",
      "Epoch 1411, Loss: 0.10302574187517166, Final Batch Loss: 0.06570477038621902\n",
      "Epoch 1412, Loss: 0.13684480264782906, Final Batch Loss: 0.032258372753858566\n",
      "Epoch 1413, Loss: 0.11026698723435402, Final Batch Loss: 0.05181640386581421\n",
      "Epoch 1414, Loss: 0.11348433792591095, Final Batch Loss: 0.045356519520282745\n",
      "Epoch 1415, Loss: 0.10240514203906059, Final Batch Loss: 0.04686065390706062\n",
      "Epoch 1416, Loss: 0.09519495442509651, Final Batch Loss: 0.047361813485622406\n",
      "Epoch 1417, Loss: 0.10132364556193352, Final Batch Loss: 0.037155631929636\n",
      "Epoch 1418, Loss: 0.11987413093447685, Final Batch Loss: 0.048144835978746414\n",
      "Epoch 1419, Loss: 0.20884229242801666, Final Batch Loss: 0.10761076956987381\n",
      "Epoch 1420, Loss: 0.11473711207509041, Final Batch Loss: 0.06495727598667145\n",
      "Epoch 1421, Loss: 0.1153775006532669, Final Batch Loss: 0.048736460506916046\n",
      "Epoch 1422, Loss: 0.10126413032412529, Final Batch Loss: 0.04320229962468147\n",
      "Epoch 1423, Loss: 0.15802080929279327, Final Batch Loss: 0.05318786948919296\n",
      "Epoch 1424, Loss: 0.10506198555231094, Final Batch Loss: 0.0630706250667572\n",
      "Epoch 1425, Loss: 0.10740935802459717, Final Batch Loss: 0.056353550404310226\n",
      "Epoch 1426, Loss: 0.0898488350212574, Final Batch Loss: 0.04398505762219429\n",
      "Epoch 1427, Loss: 0.09038864821195602, Final Batch Loss: 0.04345780238509178\n",
      "Epoch 1428, Loss: 0.12445388361811638, Final Batch Loss: 0.05420112982392311\n",
      "Epoch 1429, Loss: 0.16852637007832527, Final Batch Loss: 0.12549622356891632\n",
      "Epoch 1430, Loss: 0.11129511892795563, Final Batch Loss: 0.07859337329864502\n",
      "Epoch 1431, Loss: 0.12150938808917999, Final Batch Loss: 0.049285635352134705\n",
      "Epoch 1432, Loss: 0.1488126739859581, Final Batch Loss: 0.07817167043685913\n",
      "Epoch 1433, Loss: 0.10686143301427364, Final Batch Loss: 0.030510729178786278\n",
      "Epoch 1434, Loss: 0.11474253982305527, Final Batch Loss: 0.06544461101293564\n",
      "Epoch 1435, Loss: 0.12775317206978798, Final Batch Loss: 0.08868548274040222\n",
      "Epoch 1436, Loss: 0.12234890833497047, Final Batch Loss: 0.0728190466761589\n",
      "Epoch 1437, Loss: 0.12848499417304993, Final Batch Loss: 0.07064444571733475\n",
      "Epoch 1438, Loss: 0.08326021954417229, Final Batch Loss: 0.03705418482422829\n",
      "Epoch 1439, Loss: 0.11958499997854233, Final Batch Loss: 0.055612996220588684\n",
      "Epoch 1440, Loss: 0.11021276190876961, Final Batch Loss: 0.042540665715932846\n",
      "Epoch 1441, Loss: 0.12129418179392815, Final Batch Loss: 0.05328365042805672\n",
      "Epoch 1442, Loss: 0.13124185428023338, Final Batch Loss: 0.06912738084793091\n",
      "Epoch 1443, Loss: 0.12674938887357712, Final Batch Loss: 0.061899229884147644\n",
      "Epoch 1444, Loss: 0.10433018952608109, Final Batch Loss: 0.05197986215353012\n",
      "Epoch 1445, Loss: 0.10558048263192177, Final Batch Loss: 0.04094531014561653\n",
      "Epoch 1446, Loss: 0.15862052887678146, Final Batch Loss: 0.07453847676515579\n",
      "Epoch 1447, Loss: 0.16067585349082947, Final Batch Loss: 0.08973731100559235\n",
      "Epoch 1448, Loss: 0.12475233897566795, Final Batch Loss: 0.06780931353569031\n",
      "Epoch 1449, Loss: 0.1268003135919571, Final Batch Loss: 0.05980312079191208\n",
      "Epoch 1450, Loss: 0.1344728022813797, Final Batch Loss: 0.03210808336734772\n",
      "Epoch 1451, Loss: 0.10612519457936287, Final Batch Loss: 0.053877826780080795\n",
      "Epoch 1452, Loss: 0.11327056586742401, Final Batch Loss: 0.043758027255535126\n",
      "Epoch 1453, Loss: 0.11673828586935997, Final Batch Loss: 0.056202735751867294\n",
      "Epoch 1454, Loss: 0.16132702678442, Final Batch Loss: 0.08167386800050735\n",
      "Epoch 1455, Loss: 0.10067838430404663, Final Batch Loss: 0.056336820125579834\n",
      "Epoch 1456, Loss: 0.10803930461406708, Final Batch Loss: 0.06675124913454056\n",
      "Epoch 1457, Loss: 0.12716057524085045, Final Batch Loss: 0.0679720938205719\n",
      "Epoch 1458, Loss: 0.12949104607105255, Final Batch Loss: 0.08753784745931625\n",
      "Epoch 1459, Loss: 0.1389308199286461, Final Batch Loss: 0.04602924734354019\n",
      "Epoch 1460, Loss: 0.11281906440854073, Final Batch Loss: 0.0519699864089489\n",
      "Epoch 1461, Loss: 0.11379905790090561, Final Batch Loss: 0.07788032293319702\n",
      "Epoch 1462, Loss: 0.10349305346608162, Final Batch Loss: 0.05169900134205818\n",
      "Epoch 1463, Loss: 0.10732611641287804, Final Batch Loss: 0.04973071068525314\n",
      "Epoch 1464, Loss: 0.09832408651709557, Final Batch Loss: 0.05045633018016815\n",
      "Epoch 1465, Loss: 0.10900133475661278, Final Batch Loss: 0.049315765500068665\n",
      "Epoch 1466, Loss: 0.09632192924618721, Final Batch Loss: 0.06273677200078964\n",
      "Epoch 1467, Loss: 0.11287106573581696, Final Batch Loss: 0.0550353042781353\n",
      "Epoch 1468, Loss: 0.10325977951288223, Final Batch Loss: 0.07189543545246124\n",
      "Epoch 1469, Loss: 0.09956333413720131, Final Batch Loss: 0.045258890837430954\n",
      "Epoch 1470, Loss: 0.1466669924557209, Final Batch Loss: 0.10197235643863678\n",
      "Epoch 1471, Loss: 0.08148444443941116, Final Batch Loss: 0.04058447480201721\n",
      "Epoch 1472, Loss: 0.13418131321668625, Final Batch Loss: 0.08857116848230362\n",
      "Epoch 1473, Loss: 0.10032913647592068, Final Batch Loss: 0.016117176041007042\n",
      "Epoch 1474, Loss: 0.11131421476602554, Final Batch Loss: 0.058926016092300415\n",
      "Epoch 1475, Loss: 0.12950392067432404, Final Batch Loss: 0.07696224749088287\n",
      "Epoch 1476, Loss: 0.10108555853366852, Final Batch Loss: 0.03976397216320038\n",
      "Epoch 1477, Loss: 0.16477341949939728, Final Batch Loss: 0.11628876626491547\n",
      "Epoch 1478, Loss: 0.10708408057689667, Final Batch Loss: 0.06693766266107559\n",
      "Epoch 1479, Loss: 0.11091764643788338, Final Batch Loss: 0.04762442782521248\n",
      "Epoch 1480, Loss: 0.09433579817414284, Final Batch Loss: 0.04790177941322327\n",
      "Epoch 1481, Loss: 0.13577799126505852, Final Batch Loss: 0.05701236054301262\n",
      "Epoch 1482, Loss: 0.13283908367156982, Final Batch Loss: 0.06154271215200424\n",
      "Epoch 1483, Loss: 0.08520841598510742, Final Batch Loss: 0.043962378054857254\n",
      "Epoch 1484, Loss: 0.11611609905958176, Final Batch Loss: 0.049456141889095306\n",
      "Epoch 1485, Loss: 0.11697398126125336, Final Batch Loss: 0.06086571514606476\n",
      "Epoch 1486, Loss: 0.14525466784834862, Final Batch Loss: 0.0569075383245945\n",
      "Epoch 1487, Loss: 0.11331906355917454, Final Batch Loss: 0.02870507724583149\n",
      "Epoch 1488, Loss: 0.10107176378369331, Final Batch Loss: 0.057437215000391006\n",
      "Epoch 1489, Loss: 0.09878254309296608, Final Batch Loss: 0.0434381477534771\n",
      "Epoch 1490, Loss: 0.09975439496338367, Final Batch Loss: 0.025323377922177315\n",
      "Epoch 1491, Loss: 0.12831348925828934, Final Batch Loss: 0.061033107340335846\n",
      "Epoch 1492, Loss: 0.10299155861139297, Final Batch Loss: 0.058205943554639816\n",
      "Epoch 1493, Loss: 0.19097992777824402, Final Batch Loss: 0.11743318289518356\n",
      "Epoch 1494, Loss: 0.141008660197258, Final Batch Loss: 0.06910213828086853\n",
      "Epoch 1495, Loss: 0.09300503879785538, Final Batch Loss: 0.045371998101472855\n",
      "Epoch 1496, Loss: 0.09255721047520638, Final Batch Loss: 0.03685421496629715\n",
      "Epoch 1497, Loss: 0.09100106358528137, Final Batch Loss: 0.04234679415822029\n",
      "Epoch 1498, Loss: 0.14160287752747536, Final Batch Loss: 0.1026076152920723\n",
      "Epoch 1499, Loss: 0.10202382132411003, Final Batch Loss: 0.04316921904683113\n",
      "Epoch 1500, Loss: 0.12452731654047966, Final Batch Loss: 0.0840553417801857\n",
      "Epoch 1501, Loss: 0.10266406461596489, Final Batch Loss: 0.06667681783437729\n",
      "Epoch 1502, Loss: 0.10798637196421623, Final Batch Loss: 0.035292644053697586\n",
      "Epoch 1503, Loss: 0.08409479819238186, Final Batch Loss: 0.02233593352138996\n",
      "Epoch 1504, Loss: 0.11646991595625877, Final Batch Loss: 0.06380769610404968\n",
      "Epoch 1505, Loss: 0.09651131182909012, Final Batch Loss: 0.06213149428367615\n",
      "Epoch 1506, Loss: 0.10870132222771645, Final Batch Loss: 0.030832160264253616\n",
      "Epoch 1507, Loss: 0.12072779983282089, Final Batch Loss: 0.07478088140487671\n",
      "Epoch 1508, Loss: 0.10618279129266739, Final Batch Loss: 0.04766390100121498\n",
      "Epoch 1509, Loss: 0.16364222019910812, Final Batch Loss: 0.07788784801959991\n",
      "Epoch 1510, Loss: 0.11288048326969147, Final Batch Loss: 0.05471917986869812\n",
      "Epoch 1511, Loss: 0.1465233638882637, Final Batch Loss: 0.05870143324136734\n",
      "Epoch 1512, Loss: 0.09275397285819054, Final Batch Loss: 0.03329729661345482\n",
      "Epoch 1513, Loss: 0.11750201135873795, Final Batch Loss: 0.059914615005254745\n",
      "Epoch 1514, Loss: 0.09541375935077667, Final Batch Loss: 0.04336745664477348\n",
      "Epoch 1515, Loss: 0.12581682205200195, Final Batch Loss: 0.06221126765012741\n",
      "Epoch 1516, Loss: 0.09369250014424324, Final Batch Loss: 0.03549544885754585\n",
      "Epoch 1517, Loss: 0.12199942022562027, Final Batch Loss: 0.0442800372838974\n",
      "Epoch 1518, Loss: 0.1304764226078987, Final Batch Loss: 0.05819687992334366\n",
      "Epoch 1519, Loss: 0.13449490442872047, Final Batch Loss: 0.047743167728185654\n",
      "Epoch 1520, Loss: 0.19220873713493347, Final Batch Loss: 0.06825185567140579\n",
      "Epoch 1521, Loss: 0.09240538626909256, Final Batch Loss: 0.03590613231062889\n",
      "Epoch 1522, Loss: 0.11329629272222519, Final Batch Loss: 0.04607038199901581\n",
      "Epoch 1523, Loss: 0.12641502916812897, Final Batch Loss: 0.07320192456245422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1524, Loss: 0.10935226455330849, Final Batch Loss: 0.062251560389995575\n",
      "Epoch 1525, Loss: 0.11857258901000023, Final Batch Loss: 0.06446653604507446\n",
      "Epoch 1526, Loss: 0.151222363114357, Final Batch Loss: 0.06761957705020905\n",
      "Epoch 1527, Loss: 0.10838660970330238, Final Batch Loss: 0.03850908204913139\n",
      "Epoch 1528, Loss: 0.1637750267982483, Final Batch Loss: 0.08260945975780487\n",
      "Epoch 1529, Loss: 0.10375458374619484, Final Batch Loss: 0.06517144292593002\n",
      "Epoch 1530, Loss: 0.12563049793243408, Final Batch Loss: 0.0863054096698761\n",
      "Epoch 1531, Loss: 0.14471860229969025, Final Batch Loss: 0.09931538254022598\n",
      "Epoch 1532, Loss: 0.11750388145446777, Final Batch Loss: 0.05722067132592201\n",
      "Epoch 1533, Loss: 0.09425791166722775, Final Batch Loss: 0.029889730736613274\n",
      "Epoch 1534, Loss: 0.21161022037267685, Final Batch Loss: 0.09295392036437988\n",
      "Epoch 1535, Loss: 0.17336728423833847, Final Batch Loss: 0.07229935377836227\n",
      "Epoch 1536, Loss: 0.11897869035601616, Final Batch Loss: 0.07001397758722305\n",
      "Epoch 1537, Loss: 0.18980871886014938, Final Batch Loss: 0.12595432996749878\n",
      "Epoch 1538, Loss: 0.09443410113453865, Final Batch Loss: 0.0460694395005703\n",
      "Epoch 1539, Loss: 0.11673761531710625, Final Batch Loss: 0.06845546513795853\n",
      "Epoch 1540, Loss: 0.10401293262839317, Final Batch Loss: 0.06017226725816727\n",
      "Epoch 1541, Loss: 0.10416638478636742, Final Batch Loss: 0.04805842041969299\n",
      "Epoch 1542, Loss: 0.14004039764404297, Final Batch Loss: 0.09383364766836166\n",
      "Epoch 1543, Loss: 0.2129773497581482, Final Batch Loss: 0.14706319570541382\n",
      "Epoch 1544, Loss: 0.1682794764637947, Final Batch Loss: 0.07325095683336258\n",
      "Epoch 1545, Loss: 0.1167936697602272, Final Batch Loss: 0.06401772797107697\n",
      "Epoch 1546, Loss: 0.13185035809874535, Final Batch Loss: 0.09701984375715256\n",
      "Epoch 1547, Loss: 0.16930481791496277, Final Batch Loss: 0.09595713764429092\n",
      "Epoch 1548, Loss: 0.14187764003872871, Final Batch Loss: 0.10141798853874207\n",
      "Epoch 1549, Loss: 0.10611734539270401, Final Batch Loss: 0.06213611364364624\n",
      "Epoch 1550, Loss: 0.1031336784362793, Final Batch Loss: 0.04822075739502907\n",
      "Epoch 1551, Loss: 0.10497921332716942, Final Batch Loss: 0.03131264075636864\n",
      "Epoch 1552, Loss: 0.12055166810750961, Final Batch Loss: 0.04580935835838318\n",
      "Epoch 1553, Loss: 0.12277813255786896, Final Batch Loss: 0.04194874316453934\n",
      "Epoch 1554, Loss: 0.10405142977833748, Final Batch Loss: 0.06235335022211075\n",
      "Epoch 1555, Loss: 0.09497306495904922, Final Batch Loss: 0.05317811667919159\n",
      "Epoch 1556, Loss: 0.13070109486579895, Final Batch Loss: 0.06589582562446594\n",
      "Epoch 1557, Loss: 0.15874813124537468, Final Batch Loss: 0.0546238012611866\n",
      "Epoch 1558, Loss: 0.07146680727601051, Final Batch Loss: 0.0396881029009819\n",
      "Epoch 1559, Loss: 0.13846355676651, Final Batch Loss: 0.0422012135386467\n",
      "Epoch 1560, Loss: 0.13423274084925652, Final Batch Loss: 0.07990974187850952\n",
      "Epoch 1561, Loss: 0.10951642319560051, Final Batch Loss: 0.05995848774909973\n",
      "Epoch 1562, Loss: 0.13117796555161476, Final Batch Loss: 0.07012665271759033\n",
      "Epoch 1563, Loss: 0.13322626426815987, Final Batch Loss: 0.0748741626739502\n",
      "Epoch 1564, Loss: 0.08888634666800499, Final Batch Loss: 0.03824455663561821\n",
      "Epoch 1565, Loss: 0.11615056917071342, Final Batch Loss: 0.05644364655017853\n",
      "Epoch 1566, Loss: 0.21100879460573196, Final Batch Loss: 0.04988526552915573\n",
      "Epoch 1567, Loss: 0.14710673689842224, Final Batch Loss: 0.07697443664073944\n",
      "Epoch 1568, Loss: 0.13742366805672646, Final Batch Loss: 0.08305952697992325\n",
      "Epoch 1569, Loss: 0.13478245958685875, Final Batch Loss: 0.0878906324505806\n",
      "Epoch 1570, Loss: 0.11521396785974503, Final Batch Loss: 0.04181203246116638\n",
      "Epoch 1571, Loss: 0.09152195230126381, Final Batch Loss: 0.036726728081703186\n",
      "Epoch 1572, Loss: 0.21971971541643143, Final Batch Loss: 0.11082509905099869\n",
      "Epoch 1573, Loss: 0.11700168997049332, Final Batch Loss: 0.06387023627758026\n",
      "Epoch 1574, Loss: 0.3000255934894085, Final Batch Loss: 0.2415691316127777\n",
      "Epoch 1575, Loss: 0.11566071957349777, Final Batch Loss: 0.059106871485710144\n",
      "Epoch 1576, Loss: 0.11170558258891106, Final Batch Loss: 0.050980597734451294\n",
      "Epoch 1577, Loss: 0.12059583142399788, Final Batch Loss: 0.05023333802819252\n",
      "Epoch 1578, Loss: 0.16322705894708633, Final Batch Loss: 0.09906281530857086\n",
      "Epoch 1579, Loss: 0.11215978115797043, Final Batch Loss: 0.045497335493564606\n",
      "Epoch 1580, Loss: 0.12454701587557793, Final Batch Loss: 0.07192659378051758\n",
      "Epoch 1581, Loss: 0.1311117187142372, Final Batch Loss: 0.06494438648223877\n",
      "Epoch 1582, Loss: 0.11045096069574356, Final Batch Loss: 0.034965358674526215\n",
      "Epoch 1583, Loss: 0.161556214094162, Final Batch Loss: 0.11647762358188629\n",
      "Epoch 1584, Loss: 0.1549498215317726, Final Batch Loss: 0.0915200337767601\n",
      "Epoch 1585, Loss: 0.14102236554026604, Final Batch Loss: 0.0818086713552475\n",
      "Epoch 1586, Loss: 0.14241958409547806, Final Batch Loss: 0.06410349160432816\n",
      "Epoch 1587, Loss: 0.09373260289430618, Final Batch Loss: 0.042665205895900726\n",
      "Epoch 1588, Loss: 0.11223026737570763, Final Batch Loss: 0.047818828374147415\n",
      "Epoch 1589, Loss: 0.13252481818199158, Final Batch Loss: 0.07013121247291565\n",
      "Epoch 1590, Loss: 0.08883901871740818, Final Batch Loss: 0.021576160565018654\n",
      "Epoch 1591, Loss: 0.10948234051465988, Final Batch Loss: 0.04928082227706909\n",
      "Epoch 1592, Loss: 0.1240370161831379, Final Batch Loss: 0.041152436286211014\n",
      "Epoch 1593, Loss: 0.0908759143203497, Final Batch Loss: 0.029360955581068993\n",
      "Epoch 1594, Loss: 0.08895775303244591, Final Batch Loss: 0.030185669660568237\n",
      "Epoch 1595, Loss: 0.15665779262781143, Final Batch Loss: 0.06460314244031906\n",
      "Epoch 1596, Loss: 0.09819082170724869, Final Batch Loss: 0.06416173279285431\n",
      "Epoch 1597, Loss: 0.09793325886130333, Final Batch Loss: 0.042219746857881546\n",
      "Epoch 1598, Loss: 0.13105911016464233, Final Batch Loss: 0.06427297741174698\n",
      "Epoch 1599, Loss: 0.1162150651216507, Final Batch Loss: 0.04804706573486328\n",
      "Epoch 1600, Loss: 0.09934920445084572, Final Batch Loss: 0.04682226479053497\n",
      "Epoch 1601, Loss: 0.07455234974622726, Final Batch Loss: 0.03588081896305084\n",
      "Epoch 1602, Loss: 0.13080552592873573, Final Batch Loss: 0.09719982743263245\n",
      "Epoch 1603, Loss: 0.12087517231702805, Final Batch Loss: 0.06318137049674988\n",
      "Epoch 1604, Loss: 0.12412064522504807, Final Batch Loss: 0.06928252428770065\n",
      "Epoch 1605, Loss: 0.10989087447524071, Final Batch Loss: 0.03242601081728935\n",
      "Epoch 1606, Loss: 0.09126106277108192, Final Batch Loss: 0.04619857668876648\n",
      "Epoch 1607, Loss: 0.06828640028834343, Final Batch Loss: 0.019915137439966202\n",
      "Epoch 1608, Loss: 0.1062612347304821, Final Batch Loss: 0.058497510850429535\n",
      "Epoch 1609, Loss: 0.12594932317733765, Final Batch Loss: 0.07699134200811386\n",
      "Epoch 1610, Loss: 0.09044468402862549, Final Batch Loss: 0.0441674143075943\n",
      "Epoch 1611, Loss: 0.12015262246131897, Final Batch Loss: 0.07762257754802704\n",
      "Epoch 1612, Loss: 0.15971124544739723, Final Batch Loss: 0.10864388197660446\n",
      "Epoch 1613, Loss: 0.1055058166384697, Final Batch Loss: 0.046160612255334854\n",
      "Epoch 1614, Loss: 0.09029095619916916, Final Batch Loss: 0.036583300679922104\n",
      "Epoch 1615, Loss: 0.10568537935614586, Final Batch Loss: 0.04725169762969017\n",
      "Epoch 1616, Loss: 0.09519116207957268, Final Batch Loss: 0.04117056354880333\n",
      "Epoch 1617, Loss: 0.28200625628232956, Final Batch Loss: 0.23564571142196655\n",
      "Epoch 1618, Loss: 0.10288794338703156, Final Batch Loss: 0.06194295361638069\n",
      "Epoch 1619, Loss: 0.10951309278607368, Final Batch Loss: 0.06025240197777748\n",
      "Epoch 1620, Loss: 0.09732240065932274, Final Batch Loss: 0.03255001828074455\n",
      "Epoch 1621, Loss: 0.1282796896994114, Final Batch Loss: 0.07029783725738525\n",
      "Epoch 1622, Loss: 0.12392548844218254, Final Batch Loss: 0.0653785690665245\n",
      "Epoch 1623, Loss: 0.10773970931768417, Final Batch Loss: 0.046300940215587616\n",
      "Epoch 1624, Loss: 0.10533063486218452, Final Batch Loss: 0.05711878463625908\n",
      "Epoch 1625, Loss: 0.08117588981986046, Final Batch Loss: 0.03237913176417351\n",
      "Epoch 1626, Loss: 0.13697852566838264, Final Batch Loss: 0.09523671120405197\n",
      "Epoch 1627, Loss: 0.11584853380918503, Final Batch Loss: 0.051999785006046295\n",
      "Epoch 1628, Loss: 0.11685657501220703, Final Batch Loss: 0.04511398822069168\n",
      "Epoch 1629, Loss: 0.11984613165259361, Final Batch Loss: 0.05452025309205055\n",
      "Epoch 1630, Loss: 0.1251779943704605, Final Batch Loss: 0.06728716939687729\n",
      "Epoch 1631, Loss: 0.15631267055869102, Final Batch Loss: 0.09777074307203293\n",
      "Epoch 1632, Loss: 0.1493527702987194, Final Batch Loss: 0.08731911331415176\n",
      "Epoch 1633, Loss: 0.13893356174230576, Final Batch Loss: 0.08829544484615326\n",
      "Epoch 1634, Loss: 0.10309828817844391, Final Batch Loss: 0.04638569802045822\n",
      "Epoch 1635, Loss: 0.10505649074912071, Final Batch Loss: 0.04694090783596039\n",
      "Epoch 1636, Loss: 0.09879947826266289, Final Batch Loss: 0.04602097347378731\n",
      "Epoch 1637, Loss: 0.09167946875095367, Final Batch Loss: 0.04146386682987213\n",
      "Epoch 1638, Loss: 0.11853429675102234, Final Batch Loss: 0.07783812284469604\n",
      "Epoch 1639, Loss: 0.09057052060961723, Final Batch Loss: 0.0330665223300457\n",
      "Epoch 1640, Loss: 0.08960604667663574, Final Batch Loss: 0.04171137884259224\n",
      "Epoch 1641, Loss: 0.1323547475039959, Final Batch Loss: 0.08207522332668304\n",
      "Epoch 1642, Loss: 0.10660754516720772, Final Batch Loss: 0.060379039496183395\n",
      "Epoch 1643, Loss: 0.13948041200637817, Final Batch Loss: 0.04909362643957138\n",
      "Epoch 1644, Loss: 0.08969563990831375, Final Batch Loss: 0.04511166736483574\n",
      "Epoch 1645, Loss: 0.14132185652852058, Final Batch Loss: 0.06069984659552574\n",
      "Epoch 1646, Loss: 0.11129344627261162, Final Batch Loss: 0.0660252645611763\n",
      "Epoch 1647, Loss: 0.15326543897390366, Final Batch Loss: 0.09269779920578003\n",
      "Epoch 1648, Loss: 0.10727262310683727, Final Batch Loss: 0.025110764428973198\n",
      "Epoch 1649, Loss: 0.16337784752249718, Final Batch Loss: 0.04396342113614082\n",
      "Epoch 1650, Loss: 0.13319725170731544, Final Batch Loss: 0.07872448861598969\n",
      "Epoch 1651, Loss: 0.11218806356191635, Final Batch Loss: 0.05318806692957878\n",
      "Epoch 1652, Loss: 0.103190578520298, Final Batch Loss: 0.04481038451194763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1653, Loss: 0.11937926709651947, Final Batch Loss: 0.06744668632745743\n",
      "Epoch 1654, Loss: 0.15192939341068268, Final Batch Loss: 0.09875106811523438\n",
      "Epoch 1655, Loss: 0.09640806913375854, Final Batch Loss: 0.04404044151306152\n",
      "Epoch 1656, Loss: 0.09252190217375755, Final Batch Loss: 0.05345677584409714\n",
      "Epoch 1657, Loss: 0.12377164140343666, Final Batch Loss: 0.061935678124427795\n",
      "Epoch 1658, Loss: 0.11874930001795292, Final Batch Loss: 0.02971549518406391\n",
      "Epoch 1659, Loss: 0.10609039291739464, Final Batch Loss: 0.05811082571744919\n",
      "Epoch 1660, Loss: 0.13767443969845772, Final Batch Loss: 0.05709786340594292\n",
      "Epoch 1661, Loss: 0.1179913766682148, Final Batch Loss: 0.054022300988435745\n",
      "Epoch 1662, Loss: 0.11036987975239754, Final Batch Loss: 0.05352478474378586\n",
      "Epoch 1663, Loss: 0.09516319632530212, Final Batch Loss: 0.0310160294175148\n",
      "Epoch 1664, Loss: 0.17235272005200386, Final Batch Loss: 0.11419877409934998\n",
      "Epoch 1665, Loss: 0.11745700240135193, Final Batch Loss: 0.07075495272874832\n",
      "Epoch 1666, Loss: 0.1274438202381134, Final Batch Loss: 0.029894664883613586\n",
      "Epoch 1667, Loss: 0.09339647367596626, Final Batch Loss: 0.05622132495045662\n",
      "Epoch 1668, Loss: 0.12374784052371979, Final Batch Loss: 0.06902612745761871\n",
      "Epoch 1669, Loss: 0.1147254928946495, Final Batch Loss: 0.06772176921367645\n",
      "Epoch 1670, Loss: 0.10654745623469353, Final Batch Loss: 0.06348918378353119\n",
      "Epoch 1671, Loss: 0.08999687060713768, Final Batch Loss: 0.0473618321120739\n",
      "Epoch 1672, Loss: 0.1313249059021473, Final Batch Loss: 0.07822288572788239\n",
      "Epoch 1673, Loss: 0.12258769571781158, Final Batch Loss: 0.04146189242601395\n",
      "Epoch 1674, Loss: 0.13901057466864586, Final Batch Loss: 0.08412638306617737\n",
      "Epoch 1675, Loss: 0.11470506712794304, Final Batch Loss: 0.05451401695609093\n",
      "Epoch 1676, Loss: 0.13211017474532127, Final Batch Loss: 0.07564742863178253\n",
      "Epoch 1677, Loss: 0.13032687082886696, Final Batch Loss: 0.050563227385282516\n",
      "Epoch 1678, Loss: 0.09464076906442642, Final Batch Loss: 0.05527753010392189\n",
      "Epoch 1679, Loss: 0.11651737987995148, Final Batch Loss: 0.05161543935537338\n",
      "Epoch 1680, Loss: 0.0965861827135086, Final Batch Loss: 0.03634169325232506\n",
      "Epoch 1681, Loss: 0.12024147808551788, Final Batch Loss: 0.07896587997674942\n",
      "Epoch 1682, Loss: 0.14815228432416916, Final Batch Loss: 0.06293335556983948\n",
      "Epoch 1683, Loss: 0.10454168170690536, Final Batch Loss: 0.05599551647901535\n",
      "Epoch 1684, Loss: 0.13309363648295403, Final Batch Loss: 0.05214415118098259\n",
      "Epoch 1685, Loss: 0.1085854023694992, Final Batch Loss: 0.06929436326026917\n",
      "Epoch 1686, Loss: 0.10221393778920174, Final Batch Loss: 0.045946646481752396\n",
      "Epoch 1687, Loss: 0.12721360102295876, Final Batch Loss: 0.04333272948861122\n",
      "Epoch 1688, Loss: 0.09514568746089935, Final Batch Loss: 0.05547400563955307\n",
      "Epoch 1689, Loss: 0.10865161567926407, Final Batch Loss: 0.05413855239748955\n",
      "Epoch 1690, Loss: 0.10496415570378304, Final Batch Loss: 0.06118575483560562\n",
      "Epoch 1691, Loss: 0.2158900834619999, Final Batch Loss: 0.15980781614780426\n",
      "Epoch 1692, Loss: 0.09655262157320976, Final Batch Loss: 0.040615376085042953\n",
      "Epoch 1693, Loss: 0.13685128092765808, Final Batch Loss: 0.07703512161970139\n",
      "Epoch 1694, Loss: 0.08860419690608978, Final Batch Loss: 0.04479314759373665\n",
      "Epoch 1695, Loss: 0.10970133915543556, Final Batch Loss: 0.05770237743854523\n",
      "Epoch 1696, Loss: 0.1161840595304966, Final Batch Loss: 0.07897357642650604\n",
      "Epoch 1697, Loss: 0.09065013751387596, Final Batch Loss: 0.04473216086626053\n",
      "Epoch 1698, Loss: 0.1368778869509697, Final Batch Loss: 0.06484781205654144\n",
      "Epoch 1699, Loss: 0.08760247752070427, Final Batch Loss: 0.047997526824474335\n",
      "Epoch 1700, Loss: 0.08439024537801743, Final Batch Loss: 0.03615691885352135\n",
      "Epoch 1701, Loss: 0.0883939117193222, Final Batch Loss: 0.0421491414308548\n",
      "Epoch 1702, Loss: 0.11936228722333908, Final Batch Loss: 0.0721697211265564\n",
      "Epoch 1703, Loss: 0.0973062701523304, Final Batch Loss: 0.04435976594686508\n",
      "Epoch 1704, Loss: 0.1244240365922451, Final Batch Loss: 0.06896848231554031\n",
      "Epoch 1705, Loss: 0.10485514625906944, Final Batch Loss: 0.06576130539178848\n",
      "Epoch 1706, Loss: 0.11283079534769058, Final Batch Loss: 0.05378428101539612\n",
      "Epoch 1707, Loss: 0.11516550183296204, Final Batch Loss: 0.040999479591846466\n",
      "Epoch 1708, Loss: 0.09057334810495377, Final Batch Loss: 0.04818890988826752\n",
      "Epoch 1709, Loss: 0.0974162295460701, Final Batch Loss: 0.06082847714424133\n",
      "Epoch 1710, Loss: 0.13590117916464806, Final Batch Loss: 0.060633186250925064\n",
      "Epoch 1711, Loss: 0.1355164870619774, Final Batch Loss: 0.05255576968193054\n",
      "Epoch 1712, Loss: 0.1463920846581459, Final Batch Loss: 0.08045530319213867\n",
      "Epoch 1713, Loss: 0.08113666623830795, Final Batch Loss: 0.03527732565999031\n",
      "Epoch 1714, Loss: 0.13545267283916473, Final Batch Loss: 0.0716882199048996\n",
      "Epoch 1715, Loss: 0.10831727460026741, Final Batch Loss: 0.03447210416197777\n",
      "Epoch 1716, Loss: 0.08947788551449776, Final Batch Loss: 0.050385262817144394\n",
      "Epoch 1717, Loss: 0.10583264008164406, Final Batch Loss: 0.05811337009072304\n",
      "Epoch 1718, Loss: 0.11976376548409462, Final Batch Loss: 0.03554505482316017\n",
      "Epoch 1719, Loss: 0.08516104519367218, Final Batch Loss: 0.045373450964689255\n",
      "Epoch 1720, Loss: 0.12084266170859337, Final Batch Loss: 0.06747741997241974\n",
      "Epoch 1721, Loss: 0.13659876585006714, Final Batch Loss: 0.07920258492231369\n",
      "Epoch 1722, Loss: 0.09553949534893036, Final Batch Loss: 0.04179077222943306\n",
      "Epoch 1723, Loss: 0.09231841191649437, Final Batch Loss: 0.03232806175947189\n",
      "Epoch 1724, Loss: 0.11196588724851608, Final Batch Loss: 0.05990010127425194\n",
      "Epoch 1725, Loss: 0.11964255571365356, Final Batch Loss: 0.06012600660324097\n",
      "Epoch 1726, Loss: 0.11349904537200928, Final Batch Loss: 0.03411343693733215\n",
      "Epoch 1727, Loss: 0.12731845676898956, Final Batch Loss: 0.0844080001115799\n",
      "Epoch 1728, Loss: 0.09907358884811401, Final Batch Loss: 0.03951453045010567\n",
      "Epoch 1729, Loss: 0.11953224241733551, Final Batch Loss: 0.042890533804893494\n",
      "Epoch 1730, Loss: 0.14623656496405602, Final Batch Loss: 0.0403398759663105\n",
      "Epoch 1731, Loss: 0.11412127315998077, Final Batch Loss: 0.0659089982509613\n",
      "Epoch 1732, Loss: 0.10497450828552246, Final Batch Loss: 0.062263160943984985\n",
      "Epoch 1733, Loss: 0.12043891102075577, Final Batch Loss: 0.07943438738584518\n",
      "Epoch 1734, Loss: 0.10373234003782272, Final Batch Loss: 0.06470555812120438\n",
      "Epoch 1735, Loss: 0.11475732550024986, Final Batch Loss: 0.04762773588299751\n",
      "Epoch 1736, Loss: 0.09571769088506699, Final Batch Loss: 0.029886901378631592\n",
      "Epoch 1737, Loss: 0.15375617891550064, Final Batch Loss: 0.07723695039749146\n",
      "Epoch 1738, Loss: 0.12937218323349953, Final Batch Loss: 0.0780811607837677\n",
      "Epoch 1739, Loss: 0.1153106801211834, Final Batch Loss: 0.07087956368923187\n",
      "Epoch 1740, Loss: 0.13294440135359764, Final Batch Loss: 0.024641308933496475\n",
      "Epoch 1741, Loss: 0.10488588735461235, Final Batch Loss: 0.051255714148283005\n",
      "Epoch 1742, Loss: 0.1147843711078167, Final Batch Loss: 0.06358135491609573\n",
      "Epoch 1743, Loss: 0.09175781160593033, Final Batch Loss: 0.05338536947965622\n",
      "Epoch 1744, Loss: 0.10186762735247612, Final Batch Loss: 0.03994688764214516\n",
      "Epoch 1745, Loss: 0.09366878867149353, Final Batch Loss: 0.05100596323609352\n",
      "Epoch 1746, Loss: 0.08142342418432236, Final Batch Loss: 0.0332774892449379\n",
      "Epoch 1747, Loss: 0.12771588563919067, Final Batch Loss: 0.08300814777612686\n",
      "Epoch 1748, Loss: 0.14907734841108322, Final Batch Loss: 0.07898090779781342\n",
      "Epoch 1749, Loss: 0.1141994260251522, Final Batch Loss: 0.040586527436971664\n",
      "Epoch 1750, Loss: 0.112788375467062, Final Batch Loss: 0.05971814692020416\n",
      "Epoch 1751, Loss: 0.08609059825539589, Final Batch Loss: 0.03392951563000679\n",
      "Epoch 1752, Loss: 0.11542868241667747, Final Batch Loss: 0.07513786852359772\n",
      "Epoch 1753, Loss: 0.1241571307182312, Final Batch Loss: 0.056983090937137604\n",
      "Epoch 1754, Loss: 0.08246473968029022, Final Batch Loss: 0.04646022617816925\n",
      "Epoch 1755, Loss: 0.09576311707496643, Final Batch Loss: 0.04788722097873688\n",
      "Epoch 1756, Loss: 0.1163557916879654, Final Batch Loss: 0.043510958552360535\n",
      "Epoch 1757, Loss: 0.10000593587756157, Final Batch Loss: 0.053851980715990067\n",
      "Epoch 1758, Loss: 0.13647721335291862, Final Batch Loss: 0.055378612130880356\n",
      "Epoch 1759, Loss: 0.12669126316905022, Final Batch Loss: 0.05244474485516548\n",
      "Epoch 1760, Loss: 0.0913863480091095, Final Batch Loss: 0.06692012399435043\n",
      "Epoch 1761, Loss: 0.0811307542026043, Final Batch Loss: 0.048807576298713684\n",
      "Epoch 1762, Loss: 0.11492737010121346, Final Batch Loss: 0.04887024685740471\n",
      "Epoch 1763, Loss: 0.09961183369159698, Final Batch Loss: 0.0438065305352211\n",
      "Epoch 1764, Loss: 0.12337387353181839, Final Batch Loss: 0.05497715622186661\n",
      "Epoch 1765, Loss: 0.10890134051442146, Final Batch Loss: 0.0807398334145546\n",
      "Epoch 1766, Loss: 0.09192285686731339, Final Batch Loss: 0.05008522793650627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1767, Loss: 0.09386156126856804, Final Batch Loss: 0.04201952740550041\n",
      "Epoch 1768, Loss: 0.09054755419492722, Final Batch Loss: 0.03610577806830406\n",
      "Epoch 1769, Loss: 0.10949811339378357, Final Batch Loss: 0.06891478598117828\n",
      "Epoch 1770, Loss: 0.0968022309243679, Final Batch Loss: 0.059290915727615356\n",
      "Epoch 1771, Loss: 0.10947586968541145, Final Batch Loss: 0.06862213462591171\n",
      "Epoch 1772, Loss: 0.11124374717473984, Final Batch Loss: 0.06176169961690903\n",
      "Epoch 1773, Loss: 0.1070527471601963, Final Batch Loss: 0.05833197385072708\n",
      "Epoch 1774, Loss: 0.14055995643138885, Final Batch Loss: 0.053063906729221344\n",
      "Epoch 1775, Loss: 0.09795227646827698, Final Batch Loss: 0.03143816441297531\n",
      "Epoch 1776, Loss: 0.11275674030184746, Final Batch Loss: 0.04323660954833031\n",
      "Epoch 1777, Loss: 0.1104954332113266, Final Batch Loss: 0.06434649974107742\n",
      "Epoch 1778, Loss: 0.1015903688967228, Final Batch Loss: 0.0404885895550251\n",
      "Epoch 1779, Loss: 0.08005661889910698, Final Batch Loss: 0.049714405089616776\n",
      "Epoch 1780, Loss: 0.096045246347785, Final Batch Loss: 0.06767497211694717\n",
      "Epoch 1781, Loss: 0.1031443364918232, Final Batch Loss: 0.06241462379693985\n",
      "Epoch 1782, Loss: 0.1621050350368023, Final Batch Loss: 0.1290964037179947\n",
      "Epoch 1783, Loss: 0.08684825152158737, Final Batch Loss: 0.0378560833632946\n",
      "Epoch 1784, Loss: 0.08661394566297531, Final Batch Loss: 0.044621970504522324\n",
      "Epoch 1785, Loss: 0.11657746136188507, Final Batch Loss: 0.05873234570026398\n",
      "Epoch 1786, Loss: 0.12344148755073547, Final Batch Loss: 0.06359920650720596\n",
      "Epoch 1787, Loss: 0.10645388625562191, Final Batch Loss: 0.07778845727443695\n",
      "Epoch 1788, Loss: 0.10042653232812881, Final Batch Loss: 0.057079240679740906\n",
      "Epoch 1789, Loss: 0.08781714737415314, Final Batch Loss: 0.04385640472173691\n",
      "Epoch 1790, Loss: 0.11397723853588104, Final Batch Loss: 0.04022051393985748\n",
      "Epoch 1791, Loss: 0.08709496445953846, Final Batch Loss: 0.030647428706288338\n",
      "Epoch 1792, Loss: 0.08621829189360142, Final Batch Loss: 0.05697610601782799\n",
      "Epoch 1793, Loss: 0.08537795394659042, Final Batch Loss: 0.03523030877113342\n",
      "Epoch 1794, Loss: 0.0875438041985035, Final Batch Loss: 0.03452800214290619\n",
      "Epoch 1795, Loss: 0.08607761561870575, Final Batch Loss: 0.04419684037566185\n",
      "Epoch 1796, Loss: 0.09899311885237694, Final Batch Loss: 0.026660341769456863\n",
      "Epoch 1797, Loss: 0.08410908654332161, Final Batch Loss: 0.0336771085858345\n",
      "Epoch 1798, Loss: 0.09717359766364098, Final Batch Loss: 0.06303858011960983\n",
      "Epoch 1799, Loss: 0.08863099291920662, Final Batch Loss: 0.04050872102379799\n",
      "Epoch 1800, Loss: 0.10772883519530296, Final Batch Loss: 0.05698418989777565\n",
      "Epoch 1801, Loss: 0.09049115143716335, Final Batch Loss: 0.030696386471390724\n",
      "Epoch 1802, Loss: 0.12517910078167915, Final Batch Loss: 0.06248217448592186\n",
      "Epoch 1803, Loss: 0.09177962318062782, Final Batch Loss: 0.049226704984903336\n",
      "Epoch 1804, Loss: 0.14158970490098, Final Batch Loss: 0.08795435726642609\n",
      "Epoch 1805, Loss: 0.08954456076025963, Final Batch Loss: 0.055277857929468155\n",
      "Epoch 1806, Loss: 0.09553225338459015, Final Batch Loss: 0.04815555363893509\n",
      "Epoch 1807, Loss: 0.11190775036811829, Final Batch Loss: 0.03899279981851578\n",
      "Epoch 1808, Loss: 0.11147747188806534, Final Batch Loss: 0.044652268290519714\n",
      "Epoch 1809, Loss: 0.10189015418291092, Final Batch Loss: 0.059732262045145035\n",
      "Epoch 1810, Loss: 0.09568901732563972, Final Batch Loss: 0.053311459720134735\n",
      "Epoch 1811, Loss: 0.10566733777523041, Final Batch Loss: 0.03817690908908844\n",
      "Epoch 1812, Loss: 0.12058630213141441, Final Batch Loss: 0.07369150221347809\n",
      "Epoch 1813, Loss: 0.08945318683981895, Final Batch Loss: 0.03718630596995354\n",
      "Epoch 1814, Loss: 0.09460468217730522, Final Batch Loss: 0.047033485025167465\n",
      "Epoch 1815, Loss: 0.12203578650951385, Final Batch Loss: 0.05459125339984894\n",
      "Epoch 1816, Loss: 0.09211055934429169, Final Batch Loss: 0.03804076835513115\n",
      "Epoch 1817, Loss: 0.15285752713680267, Final Batch Loss: 0.08871704339981079\n",
      "Epoch 1818, Loss: 0.11402614787220955, Final Batch Loss: 0.07085064053535461\n",
      "Epoch 1819, Loss: 0.10069582611322403, Final Batch Loss: 0.06804723292589188\n",
      "Epoch 1820, Loss: 0.11372260004281998, Final Batch Loss: 0.04887615144252777\n",
      "Epoch 1821, Loss: 0.09679422900080681, Final Batch Loss: 0.05707796290516853\n",
      "Epoch 1822, Loss: 0.10450239479541779, Final Batch Loss: 0.03462196886539459\n",
      "Epoch 1823, Loss: 0.08639175072312355, Final Batch Loss: 0.050491075962781906\n",
      "Epoch 1824, Loss: 0.0955287292599678, Final Batch Loss: 0.050402432680130005\n",
      "Epoch 1825, Loss: 0.1002659760415554, Final Batch Loss: 0.04197192192077637\n",
      "Epoch 1826, Loss: 0.12763060629367828, Final Batch Loss: 0.07228562980890274\n",
      "Epoch 1827, Loss: 0.10556835308670998, Final Batch Loss: 0.054763369262218475\n",
      "Epoch 1828, Loss: 0.10469913110136986, Final Batch Loss: 0.047646526247262955\n",
      "Epoch 1829, Loss: 0.11994441226124763, Final Batch Loss: 0.04128998890519142\n",
      "Epoch 1830, Loss: 0.1589258797466755, Final Batch Loss: 0.0531327985227108\n",
      "Epoch 1831, Loss: 0.11564735323190689, Final Batch Loss: 0.06861371546983719\n",
      "Epoch 1832, Loss: 0.10134942829608917, Final Batch Loss: 0.047082506120204926\n",
      "Epoch 1833, Loss: 0.09107634052634239, Final Batch Loss: 0.045812781900167465\n",
      "Epoch 1834, Loss: 0.15506300330162048, Final Batch Loss: 0.07500225305557251\n",
      "Epoch 1835, Loss: 0.08515981584787369, Final Batch Loss: 0.03428416699171066\n",
      "Epoch 1836, Loss: 0.14984335750341415, Final Batch Loss: 0.1099385991692543\n",
      "Epoch 1837, Loss: 0.12311341241002083, Final Batch Loss: 0.07602507621049881\n",
      "Epoch 1838, Loss: 0.10575325042009354, Final Batch Loss: 0.06532778590917587\n",
      "Epoch 1839, Loss: 0.09019732102751732, Final Batch Loss: 0.044629551470279694\n",
      "Epoch 1840, Loss: 0.0914706252515316, Final Batch Loss: 0.041826315224170685\n",
      "Epoch 1841, Loss: 0.12719815224409103, Final Batch Loss: 0.07500360161066055\n",
      "Epoch 1842, Loss: 0.12071077525615692, Final Batch Loss: 0.06525587290525436\n",
      "Epoch 1843, Loss: 0.10905490070581436, Final Batch Loss: 0.05857762694358826\n",
      "Epoch 1844, Loss: 0.1053573451936245, Final Batch Loss: 0.057193953543901443\n",
      "Epoch 1845, Loss: 0.13151849433779716, Final Batch Loss: 0.042441438883543015\n",
      "Epoch 1846, Loss: 0.09884554520249367, Final Batch Loss: 0.042441338300704956\n",
      "Epoch 1847, Loss: 0.09620469436049461, Final Batch Loss: 0.03254685178399086\n",
      "Epoch 1848, Loss: 0.07828421518206596, Final Batch Loss: 0.02253022789955139\n",
      "Epoch 1849, Loss: 0.09106577187776566, Final Batch Loss: 0.03425933048129082\n",
      "Epoch 1850, Loss: 0.14038226380944252, Final Batch Loss: 0.08620990067720413\n",
      "Epoch 1851, Loss: 0.08328012935817242, Final Batch Loss: 0.05481313169002533\n",
      "Epoch 1852, Loss: 0.11648526787757874, Final Batch Loss: 0.0492342934012413\n",
      "Epoch 1853, Loss: 0.09442081302404404, Final Batch Loss: 0.037612173706293106\n",
      "Epoch 1854, Loss: 0.12937143817543983, Final Batch Loss: 0.05284678563475609\n",
      "Epoch 1855, Loss: 0.12091175094246864, Final Batch Loss: 0.04157729819417\n",
      "Epoch 1856, Loss: 0.08274240419268608, Final Batch Loss: 0.039501555263996124\n",
      "Epoch 1857, Loss: 0.10817297920584679, Final Batch Loss: 0.0823945626616478\n",
      "Epoch 1858, Loss: 0.08993322774767876, Final Batch Loss: 0.05215253308415413\n",
      "Epoch 1859, Loss: 0.1103615090250969, Final Batch Loss: 0.04663575440645218\n",
      "Epoch 1860, Loss: 0.07682130113244057, Final Batch Loss: 0.03181527182459831\n",
      "Epoch 1861, Loss: 0.11913076043128967, Final Batch Loss: 0.0726572573184967\n",
      "Epoch 1862, Loss: 0.1110551580786705, Final Batch Loss: 0.06030190363526344\n",
      "Epoch 1863, Loss: 0.09316175058484077, Final Batch Loss: 0.028136644512414932\n",
      "Epoch 1864, Loss: 0.19469769299030304, Final Batch Loss: 0.06034894287586212\n",
      "Epoch 1865, Loss: 0.1099219061434269, Final Batch Loss: 0.04723468795418739\n",
      "Epoch 1866, Loss: 0.10893305018544197, Final Batch Loss: 0.054379332810640335\n",
      "Epoch 1867, Loss: 0.10717965289950371, Final Batch Loss: 0.05641429126262665\n",
      "Epoch 1868, Loss: 0.17919734120368958, Final Batch Loss: 0.11414411664009094\n",
      "Epoch 1869, Loss: 0.10099424794316292, Final Batch Loss: 0.06202954053878784\n",
      "Epoch 1870, Loss: 0.10370475798845291, Final Batch Loss: 0.051679495722055435\n",
      "Epoch 1871, Loss: 0.08390756696462631, Final Batch Loss: 0.04379654303193092\n",
      "Epoch 1872, Loss: 0.09978118166327477, Final Batch Loss: 0.05102870985865593\n",
      "Epoch 1873, Loss: 0.1031232438981533, Final Batch Loss: 0.07201465964317322\n",
      "Epoch 1874, Loss: 0.08195673674345016, Final Batch Loss: 0.03561905771493912\n",
      "Epoch 1875, Loss: 0.10557970777153969, Final Batch Loss: 0.051360514014959335\n",
      "Epoch 1876, Loss: 0.10592705756425858, Final Batch Loss: 0.04209931939840317\n",
      "Epoch 1877, Loss: 0.10184329375624657, Final Batch Loss: 0.04778832197189331\n",
      "Epoch 1878, Loss: 0.11541968584060669, Final Batch Loss: 0.06387966126203537\n",
      "Epoch 1879, Loss: 0.10246125236153603, Final Batch Loss: 0.04744238406419754\n",
      "Epoch 1880, Loss: 0.13653694093227386, Final Batch Loss: 0.07221837341785431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1881, Loss: 0.09494724124670029, Final Batch Loss: 0.04037213325500488\n",
      "Epoch 1882, Loss: 0.10164112597703934, Final Batch Loss: 0.05158417299389839\n",
      "Epoch 1883, Loss: 0.11302509717643261, Final Batch Loss: 0.02773733250796795\n",
      "Epoch 1884, Loss: 0.07245116122066975, Final Batch Loss: 0.024933600798249245\n",
      "Epoch 1885, Loss: 0.11015664041042328, Final Batch Loss: 0.07996153086423874\n",
      "Epoch 1886, Loss: 0.08348275348544121, Final Batch Loss: 0.04199298843741417\n",
      "Epoch 1887, Loss: 0.08671921491622925, Final Batch Loss: 0.047952380031347275\n",
      "Epoch 1888, Loss: 0.10023067146539688, Final Batch Loss: 0.05625475198030472\n",
      "Epoch 1889, Loss: 0.08511454239487648, Final Batch Loss: 0.03298860788345337\n",
      "Epoch 1890, Loss: 0.09284863993525505, Final Batch Loss: 0.049630194902420044\n",
      "Epoch 1891, Loss: 0.11690208874642849, Final Batch Loss: 0.027189141139388084\n",
      "Epoch 1892, Loss: 0.08689040318131447, Final Batch Loss: 0.053567975759506226\n",
      "Epoch 1893, Loss: 0.1240258626639843, Final Batch Loss: 0.05600013956427574\n",
      "Epoch 1894, Loss: 0.10059871524572372, Final Batch Loss: 0.04242117330431938\n",
      "Epoch 1895, Loss: 0.09491082280874252, Final Batch Loss: 0.05551614612340927\n",
      "Epoch 1896, Loss: 0.10309918969869614, Final Batch Loss: 0.06869644671678543\n",
      "Epoch 1897, Loss: 0.1171492375433445, Final Batch Loss: 0.061951495707035065\n",
      "Epoch 1898, Loss: 0.10758968815207481, Final Batch Loss: 0.054939430207014084\n",
      "Epoch 1899, Loss: 0.09730809554457664, Final Batch Loss: 0.04277053847908974\n",
      "Epoch 1900, Loss: 0.12869100272655487, Final Batch Loss: 0.08709767460823059\n",
      "Epoch 1901, Loss: 0.13518806919455528, Final Batch Loss: 0.0759434923529625\n",
      "Epoch 1902, Loss: 0.08578293025493622, Final Batch Loss: 0.04263986274600029\n",
      "Epoch 1903, Loss: 0.12639832124114037, Final Batch Loss: 0.07708200067281723\n",
      "Epoch 1904, Loss: 0.09700985997915268, Final Batch Loss: 0.04843747243285179\n",
      "Epoch 1905, Loss: 0.16397413611412048, Final Batch Loss: 0.07774669677019119\n",
      "Epoch 1906, Loss: 0.084871307015419, Final Batch Loss: 0.044556889683008194\n",
      "Epoch 1907, Loss: 0.07210839539766312, Final Batch Loss: 0.03498223051428795\n",
      "Epoch 1908, Loss: 0.1118744183331728, Final Batch Loss: 0.02642023004591465\n",
      "Epoch 1909, Loss: 0.13256638310849667, Final Batch Loss: 0.017369097098708153\n",
      "Epoch 1910, Loss: 0.09177691116929054, Final Batch Loss: 0.05226418003439903\n",
      "Epoch 1911, Loss: 0.10457079485058784, Final Batch Loss: 0.05690527334809303\n",
      "Epoch 1912, Loss: 0.09631883352994919, Final Batch Loss: 0.03940246254205704\n",
      "Epoch 1913, Loss: 0.10644573345780373, Final Batch Loss: 0.0540822297334671\n",
      "Epoch 1914, Loss: 0.10679697059094906, Final Batch Loss: 0.031140802428126335\n",
      "Epoch 1915, Loss: 0.12603576481342316, Final Batch Loss: 0.058287590742111206\n",
      "Epoch 1916, Loss: 0.11288583278656006, Final Batch Loss: 0.04679160565137863\n",
      "Epoch 1917, Loss: 0.08303963392972946, Final Batch Loss: 0.05584258586168289\n",
      "Epoch 1918, Loss: 0.10032361373305321, Final Batch Loss: 0.05007035285234451\n",
      "Epoch 1919, Loss: 0.11376838013529778, Final Batch Loss: 0.04817615821957588\n",
      "Epoch 1920, Loss: 0.08235578425228596, Final Batch Loss: 0.024611109867691994\n",
      "Epoch 1921, Loss: 0.09430905804038048, Final Batch Loss: 0.0592978298664093\n",
      "Epoch 1922, Loss: 0.11719492450356483, Final Batch Loss: 0.05810757353901863\n",
      "Epoch 1923, Loss: 0.10289433412253857, Final Batch Loss: 0.019665895029902458\n",
      "Epoch 1924, Loss: 0.2167394682765007, Final Batch Loss: 0.12876275181770325\n",
      "Epoch 1925, Loss: 0.10983121022582054, Final Batch Loss: 0.03934937343001366\n",
      "Epoch 1926, Loss: 0.11935003846883774, Final Batch Loss: 0.049701906740665436\n",
      "Epoch 1927, Loss: 0.10037299618124962, Final Batch Loss: 0.05374165251851082\n",
      "Epoch 1928, Loss: 0.1270098052918911, Final Batch Loss: 0.03628029301762581\n",
      "Epoch 1929, Loss: 0.11708688363432884, Final Batch Loss: 0.03806191310286522\n",
      "Epoch 1930, Loss: 0.08267202973365784, Final Batch Loss: 0.03477735444903374\n",
      "Epoch 1931, Loss: 0.1226060576736927, Final Batch Loss: 0.07531625032424927\n",
      "Epoch 1932, Loss: 0.11150535196065903, Final Batch Loss: 0.07520078867673874\n",
      "Epoch 1933, Loss: 0.08626299910247326, Final Batch Loss: 0.02650129236280918\n",
      "Epoch 1934, Loss: 0.13673438131809235, Final Batch Loss: 0.08075422048568726\n",
      "Epoch 1935, Loss: 0.10267990455031395, Final Batch Loss: 0.05486280843615532\n",
      "Epoch 1936, Loss: 0.10835373401641846, Final Batch Loss: 0.059108175337314606\n",
      "Epoch 1937, Loss: 0.08812995627522469, Final Batch Loss: 0.05708511173725128\n",
      "Epoch 1938, Loss: 0.1147349551320076, Final Batch Loss: 0.07147295773029327\n",
      "Epoch 1939, Loss: 0.10499563068151474, Final Batch Loss: 0.04155507683753967\n",
      "Epoch 1940, Loss: 0.13781963288784027, Final Batch Loss: 0.06774606555700302\n",
      "Epoch 1941, Loss: 0.0980975441634655, Final Batch Loss: 0.0452955923974514\n",
      "Epoch 1942, Loss: 0.16520386561751366, Final Batch Loss: 0.11787161976099014\n",
      "Epoch 1943, Loss: 0.10448811948299408, Final Batch Loss: 0.03882625699043274\n",
      "Epoch 1944, Loss: 0.14747852832078934, Final Batch Loss: 0.07387234270572662\n",
      "Epoch 1945, Loss: 0.11794828996062279, Final Batch Loss: 0.04599004611372948\n",
      "Epoch 1946, Loss: 0.12880171835422516, Final Batch Loss: 0.05023348331451416\n",
      "Epoch 1947, Loss: 0.13656533509492874, Final Batch Loss: 0.06359172612428665\n",
      "Epoch 1948, Loss: 0.10613539069890976, Final Batch Loss: 0.05111675336956978\n",
      "Epoch 1949, Loss: 0.07813498005270958, Final Batch Loss: 0.02961808070540428\n",
      "Epoch 1950, Loss: 0.1552339270710945, Final Batch Loss: 0.06572043895721436\n",
      "Epoch 1951, Loss: 0.11578990146517754, Final Batch Loss: 0.08366397768259048\n",
      "Epoch 1952, Loss: 0.08816033229231834, Final Batch Loss: 0.03331493213772774\n",
      "Epoch 1953, Loss: 0.10511654242873192, Final Batch Loss: 0.05173749849200249\n",
      "Epoch 1954, Loss: 0.15074166283011436, Final Batch Loss: 0.09679590165615082\n",
      "Epoch 1955, Loss: 0.10573913529515266, Final Batch Loss: 0.055088821798563004\n",
      "Epoch 1956, Loss: 0.11886328458786011, Final Batch Loss: 0.05273272097110748\n",
      "Epoch 1957, Loss: 0.1269499473273754, Final Batch Loss: 0.036477599292993546\n",
      "Epoch 1958, Loss: 0.10321537405252457, Final Batch Loss: 0.06414178013801575\n",
      "Epoch 1959, Loss: 0.09558845683932304, Final Batch Loss: 0.03920188173651695\n",
      "Epoch 1960, Loss: 0.10523932054638863, Final Batch Loss: 0.06926587224006653\n",
      "Epoch 1961, Loss: 0.08359672129154205, Final Batch Loss: 0.03581344708800316\n",
      "Epoch 1962, Loss: 0.12521587684750557, Final Batch Loss: 0.044986527413129807\n",
      "Epoch 1963, Loss: 0.12638524547219276, Final Batch Loss: 0.07584740221500397\n",
      "Epoch 1964, Loss: 0.12332627549767494, Final Batch Loss: 0.056092288345098495\n",
      "Epoch 1965, Loss: 0.09971538186073303, Final Batch Loss: 0.041108034551143646\n",
      "Epoch 1966, Loss: 0.12439129129052162, Final Batch Loss: 0.060684654861688614\n",
      "Epoch 1967, Loss: 0.09799236431717873, Final Batch Loss: 0.05652201175689697\n",
      "Epoch 1968, Loss: 0.10476543009281158, Final Batch Loss: 0.06226406991481781\n",
      "Epoch 1969, Loss: 0.1224481537938118, Final Batch Loss: 0.03950302302837372\n",
      "Epoch 1970, Loss: 0.09269445389509201, Final Batch Loss: 0.05709626525640488\n",
      "Epoch 1971, Loss: 0.15035321936011314, Final Batch Loss: 0.030953843146562576\n",
      "Epoch 1972, Loss: 0.10245908424258232, Final Batch Loss: 0.03603794798254967\n",
      "Epoch 1973, Loss: 0.0874236673116684, Final Batch Loss: 0.04888781160116196\n",
      "Epoch 1974, Loss: 0.18094586580991745, Final Batch Loss: 0.13691259920597076\n",
      "Epoch 1975, Loss: 0.10406151786446571, Final Batch Loss: 0.045455675572156906\n",
      "Epoch 1976, Loss: 0.13790525496006012, Final Batch Loss: 0.06590521335601807\n",
      "Epoch 1977, Loss: 0.11292870715260506, Final Batch Loss: 0.04248329624533653\n",
      "Epoch 1978, Loss: 0.12545889616012573, Final Batch Loss: 0.06982921063899994\n",
      "Epoch 1979, Loss: 0.11368785426020622, Final Batch Loss: 0.04534147307276726\n",
      "Epoch 1980, Loss: 0.10382809862494469, Final Batch Loss: 0.04330337792634964\n",
      "Epoch 1981, Loss: 0.15122906118631363, Final Batch Loss: 0.08397138863801956\n",
      "Epoch 1982, Loss: 0.08855254575610161, Final Batch Loss: 0.03776773810386658\n",
      "Epoch 1983, Loss: 0.09266854077577591, Final Batch Loss: 0.05104702338576317\n",
      "Epoch 1984, Loss: 0.11858353018760681, Final Batch Loss: 0.06147506833076477\n",
      "Epoch 1985, Loss: 0.11513837054371834, Final Batch Loss: 0.0510517917573452\n",
      "Epoch 1986, Loss: 0.14874784648418427, Final Batch Loss: 0.05572950094938278\n",
      "Epoch 1987, Loss: 0.09734293445944786, Final Batch Loss: 0.056470174342393875\n",
      "Epoch 1988, Loss: 0.1012844480574131, Final Batch Loss: 0.04272039234638214\n",
      "Epoch 1989, Loss: 0.09760867431759834, Final Batch Loss: 0.03182524815201759\n",
      "Epoch 1990, Loss: 0.10766515880823135, Final Batch Loss: 0.0346699059009552\n",
      "Epoch 1991, Loss: 0.08809133991599083, Final Batch Loss: 0.04933829605579376\n",
      "Epoch 1992, Loss: 0.11850030720233917, Final Batch Loss: 0.055376119911670685\n",
      "Epoch 1993, Loss: 0.11407632008194923, Final Batch Loss: 0.05383722484111786\n",
      "Epoch 1994, Loss: 0.10600583255290985, Final Batch Loss: 0.06097443774342537\n",
      "Epoch 1995, Loss: 0.09300033375620842, Final Batch Loss: 0.051663827151060104\n",
      "Epoch 1996, Loss: 0.0784536860883236, Final Batch Loss: 0.039632756263017654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1997, Loss: 0.11261115968227386, Final Batch Loss: 0.04806157201528549\n",
      "Epoch 1998, Loss: 0.07374539040029049, Final Batch Loss: 0.02202572114765644\n",
      "Epoch 1999, Loss: 0.09131325781345367, Final Batch Loss: 0.037480439990758896\n",
      "Epoch 2000, Loss: 0.07304328121244907, Final Batch Loss: 0.020282642915844917\n",
      "Epoch 2001, Loss: 0.08723530173301697, Final Batch Loss: 0.02532021701335907\n",
      "Epoch 2002, Loss: 0.07832879573106766, Final Batch Loss: 0.035149507224559784\n",
      "Epoch 2003, Loss: 0.123126070946455, Final Batch Loss: 0.08727473020553589\n",
      "Epoch 2004, Loss: 0.107720285654068, Final Batch Loss: 0.03612221032381058\n",
      "Epoch 2005, Loss: 0.12740816548466682, Final Batch Loss: 0.0351562462747097\n",
      "Epoch 2006, Loss: 0.07550640776753426, Final Batch Loss: 0.022901099175214767\n",
      "Epoch 2007, Loss: 0.10822555050253868, Final Batch Loss: 0.0479055754840374\n",
      "Epoch 2008, Loss: 0.15700486302375793, Final Batch Loss: 0.08185015618801117\n",
      "Epoch 2009, Loss: 0.09174977615475655, Final Batch Loss: 0.035358134657144547\n",
      "Epoch 2010, Loss: 0.11892242357134819, Final Batch Loss: 0.0812491700053215\n",
      "Epoch 2011, Loss: 0.07862691581249237, Final Batch Loss: 0.04679989814758301\n",
      "Epoch 2012, Loss: 0.06979200430214405, Final Batch Loss: 0.029142165556550026\n",
      "Epoch 2013, Loss: 0.09423419833183289, Final Batch Loss: 0.05443369224667549\n",
      "Epoch 2014, Loss: 0.07768375054001808, Final Batch Loss: 0.03345058485865593\n",
      "Epoch 2015, Loss: 0.08958959951996803, Final Batch Loss: 0.03915136680006981\n",
      "Epoch 2016, Loss: 0.08253636956214905, Final Batch Loss: 0.033430445939302444\n",
      "Epoch 2017, Loss: 0.1035255715250969, Final Batch Loss: 0.04711620509624481\n",
      "Epoch 2018, Loss: 0.08448460325598717, Final Batch Loss: 0.04557952284812927\n",
      "Epoch 2019, Loss: 0.09758369997143745, Final Batch Loss: 0.08058956265449524\n",
      "Epoch 2020, Loss: 0.10637195780873299, Final Batch Loss: 0.04308202490210533\n",
      "Epoch 2021, Loss: 0.07641963101923466, Final Batch Loss: 0.03103271685540676\n",
      "Epoch 2022, Loss: 0.12204372137784958, Final Batch Loss: 0.04445734620094299\n",
      "Epoch 2023, Loss: 0.09369931928813457, Final Batch Loss: 0.022118723019957542\n",
      "Epoch 2024, Loss: 0.07049482874572277, Final Batch Loss: 0.027168365195393562\n",
      "Epoch 2025, Loss: 0.08178681880235672, Final Batch Loss: 0.04227565973997116\n",
      "Epoch 2026, Loss: 0.07756831869482994, Final Batch Loss: 0.03525485098361969\n",
      "Epoch 2027, Loss: 0.10431378334760666, Final Batch Loss: 0.06452082842588425\n",
      "Epoch 2028, Loss: 0.08509156480431557, Final Batch Loss: 0.04616647586226463\n",
      "Epoch 2029, Loss: 0.0936087891459465, Final Batch Loss: 0.05429330840706825\n",
      "Epoch 2030, Loss: 0.09572876431047916, Final Batch Loss: 0.02703836001455784\n",
      "Epoch 2031, Loss: 0.09732408076524734, Final Batch Loss: 0.04260789602994919\n",
      "Epoch 2032, Loss: 0.09746063128113747, Final Batch Loss: 0.043057672679424286\n",
      "Epoch 2033, Loss: 0.1099432110786438, Final Batch Loss: 0.05010363087058067\n",
      "Epoch 2034, Loss: 0.11081059090793133, Final Batch Loss: 0.0297026839107275\n",
      "Epoch 2035, Loss: 0.08643369376659393, Final Batch Loss: 0.04902338609099388\n",
      "Epoch 2036, Loss: 0.10214842110872269, Final Batch Loss: 0.04798363894224167\n",
      "Epoch 2037, Loss: 0.12658468261361122, Final Batch Loss: 0.04377974197268486\n",
      "Epoch 2038, Loss: 0.12056264281272888, Final Batch Loss: 0.05885918438434601\n",
      "Epoch 2039, Loss: 0.08320004679262638, Final Batch Loss: 0.054994307458400726\n",
      "Epoch 2040, Loss: 0.11055242270231247, Final Batch Loss: 0.03792554885149002\n",
      "Epoch 2041, Loss: 0.09246044233441353, Final Batch Loss: 0.03869416564702988\n",
      "Epoch 2042, Loss: 0.10130427777767181, Final Batch Loss: 0.054949261248111725\n",
      "Epoch 2043, Loss: 0.0996889378875494, Final Batch Loss: 0.010533614084124565\n",
      "Epoch 2044, Loss: 0.08357758074998856, Final Batch Loss: 0.03600718826055527\n",
      "Epoch 2045, Loss: 0.1134926937520504, Final Batch Loss: 0.061034880578517914\n",
      "Epoch 2046, Loss: 0.1106383353471756, Final Batch Loss: 0.05979517847299576\n",
      "Epoch 2047, Loss: 0.1346057578921318, Final Batch Loss: 0.07128303498029709\n",
      "Epoch 2048, Loss: 0.09218946471810341, Final Batch Loss: 0.03089272230863571\n",
      "Epoch 2049, Loss: 0.13611017912626266, Final Batch Loss: 0.07101879268884659\n",
      "Epoch 2050, Loss: 0.0900825597345829, Final Batch Loss: 0.04260709136724472\n",
      "Epoch 2051, Loss: 0.08012313023209572, Final Batch Loss: 0.04645252600312233\n",
      "Epoch 2052, Loss: 0.09984913840889931, Final Batch Loss: 0.04734395444393158\n",
      "Epoch 2053, Loss: 0.07919071242213249, Final Batch Loss: 0.048975925892591476\n",
      "Epoch 2054, Loss: 0.10231420770287514, Final Batch Loss: 0.06468045711517334\n",
      "Epoch 2055, Loss: 0.10634805634617805, Final Batch Loss: 0.04874051362276077\n",
      "Epoch 2056, Loss: 0.0866057425737381, Final Batch Loss: 0.04820062592625618\n",
      "Epoch 2057, Loss: 0.21192624419927597, Final Batch Loss: 0.1755397766828537\n",
      "Epoch 2058, Loss: 0.10036597028374672, Final Batch Loss: 0.0523674376308918\n",
      "Epoch 2059, Loss: 0.10140298865735531, Final Batch Loss: 0.08000596612691879\n",
      "Epoch 2060, Loss: 0.08648249134421349, Final Batch Loss: 0.03786109387874603\n",
      "Epoch 2061, Loss: 0.0787959136068821, Final Batch Loss: 0.03798624500632286\n",
      "Epoch 2062, Loss: 0.10573212057352066, Final Batch Loss: 0.055972110480070114\n",
      "Epoch 2063, Loss: 0.10843846574425697, Final Batch Loss: 0.05870635807514191\n",
      "Epoch 2064, Loss: 0.0620508287101984, Final Batch Loss: 0.02460845373570919\n",
      "Epoch 2065, Loss: 0.08491387963294983, Final Batch Loss: 0.04697694629430771\n",
      "Epoch 2066, Loss: 0.07441499456763268, Final Batch Loss: 0.03738965839147568\n",
      "Epoch 2067, Loss: 0.07792410254478455, Final Batch Loss: 0.04659557715058327\n",
      "Epoch 2068, Loss: 0.13313471525907516, Final Batch Loss: 0.08040685206651688\n",
      "Epoch 2069, Loss: 0.08015208318829536, Final Batch Loss: 0.04183389991521835\n",
      "Epoch 2070, Loss: 0.09089872613549232, Final Batch Loss: 0.02820080891251564\n",
      "Epoch 2071, Loss: 0.07859470881521702, Final Batch Loss: 0.018940141424536705\n",
      "Epoch 2072, Loss: 0.06741021759808064, Final Batch Loss: 0.038946811109781265\n",
      "Epoch 2073, Loss: 0.08787311241030693, Final Batch Loss: 0.04596979543566704\n",
      "Epoch 2074, Loss: 0.08174294978380203, Final Batch Loss: 0.042802851647138596\n",
      "Epoch 2075, Loss: 0.08357821963727474, Final Batch Loss: 0.027241142466664314\n",
      "Epoch 2076, Loss: 0.0946049802005291, Final Batch Loss: 0.05091209337115288\n",
      "Epoch 2077, Loss: 0.10762733407318592, Final Batch Loss: 0.08047662675380707\n",
      "Epoch 2078, Loss: 0.10505625233054161, Final Batch Loss: 0.04480383172631264\n",
      "Epoch 2079, Loss: 0.13634703308343887, Final Batch Loss: 0.06292359530925751\n",
      "Epoch 2080, Loss: 0.07522381469607353, Final Batch Loss: 0.034715116024017334\n",
      "Epoch 2081, Loss: 0.07945592887699604, Final Batch Loss: 0.030280103906989098\n",
      "Epoch 2082, Loss: 0.10860716551542282, Final Batch Loss: 0.06115727126598358\n",
      "Epoch 2083, Loss: 0.07935051620006561, Final Batch Loss: 0.04624050855636597\n",
      "Epoch 2084, Loss: 0.0918271504342556, Final Batch Loss: 0.037289123982191086\n",
      "Epoch 2085, Loss: 0.08106127940118313, Final Batch Loss: 0.030309999361634254\n",
      "Epoch 2086, Loss: 0.09924038872122765, Final Batch Loss: 0.04595272243022919\n",
      "Epoch 2087, Loss: 0.09305056557059288, Final Batch Loss: 0.04503535106778145\n",
      "Epoch 2088, Loss: 0.13199670985341072, Final Batch Loss: 0.049848053604364395\n",
      "Epoch 2089, Loss: 0.12221953272819519, Final Batch Loss: 0.050683245062828064\n",
      "Epoch 2090, Loss: 0.10369477421045303, Final Batch Loss: 0.05261553078889847\n",
      "Epoch 2091, Loss: 0.0830440055578947, Final Batch Loss: 0.05714985355734825\n",
      "Epoch 2092, Loss: 0.08578654564917088, Final Batch Loss: 0.05585074424743652\n",
      "Epoch 2093, Loss: 0.08229189366102219, Final Batch Loss: 0.018797755241394043\n",
      "Epoch 2094, Loss: 0.0955100804567337, Final Batch Loss: 0.041396819055080414\n",
      "Epoch 2095, Loss: 0.12997299432754517, Final Batch Loss: 0.08088449388742447\n",
      "Epoch 2096, Loss: 0.10117564909160137, Final Batch Loss: 0.07234853506088257\n",
      "Epoch 2097, Loss: 0.10171462595462799, Final Batch Loss: 0.04861767217516899\n",
      "Epoch 2098, Loss: 0.10338057950139046, Final Batch Loss: 0.049625612795352936\n",
      "Epoch 2099, Loss: 0.09650741145014763, Final Batch Loss: 0.046947039663791656\n",
      "Epoch 2100, Loss: 0.09431410953402519, Final Batch Loss: 0.05621258169412613\n",
      "Epoch 2101, Loss: 0.09786917269229889, Final Batch Loss: 0.041830286383628845\n",
      "Epoch 2102, Loss: 0.12008677423000336, Final Batch Loss: 0.08603332191705704\n",
      "Epoch 2103, Loss: 0.11630946770310402, Final Batch Loss: 0.07549005001783371\n",
      "Epoch 2104, Loss: 0.08890467882156372, Final Batch Loss: 0.03905134275555611\n",
      "Epoch 2105, Loss: 0.11500830762088299, Final Batch Loss: 0.016201434656977654\n",
      "Epoch 2106, Loss: 0.09940500929951668, Final Batch Loss: 0.056738123297691345\n",
      "Epoch 2107, Loss: 0.09173567779362202, Final Batch Loss: 0.0678928792476654\n",
      "Epoch 2108, Loss: 0.0875022653490305, Final Batch Loss: 0.06387124955654144\n",
      "Epoch 2109, Loss: 0.08568314090371132, Final Batch Loss: 0.048630375415086746\n",
      "Epoch 2110, Loss: 0.06458292715251446, Final Batch Loss: 0.030273424461483955\n",
      "Epoch 2111, Loss: 0.09566250443458557, Final Batch Loss: 0.046819787472486496\n",
      "Epoch 2112, Loss: 0.07185599580407143, Final Batch Loss: 0.0363200418651104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2113, Loss: 0.09345737844705582, Final Batch Loss: 0.05955323204398155\n",
      "Epoch 2114, Loss: 0.07810905575752258, Final Batch Loss: 0.03586317226290703\n",
      "Epoch 2115, Loss: 0.08626443892717361, Final Batch Loss: 0.03366060554981232\n",
      "Epoch 2116, Loss: 0.07095770537853241, Final Batch Loss: 0.03514318913221359\n",
      "Epoch 2117, Loss: 0.09023587591946125, Final Batch Loss: 0.06690751016139984\n",
      "Epoch 2118, Loss: 0.08599168807268143, Final Batch Loss: 0.04587624967098236\n",
      "Epoch 2119, Loss: 0.10108256340026855, Final Batch Loss: 0.03685219585895538\n",
      "Epoch 2120, Loss: 0.12254371121525764, Final Batch Loss: 0.08364430069923401\n",
      "Epoch 2121, Loss: 0.10284136608242989, Final Batch Loss: 0.0592137835919857\n",
      "Epoch 2122, Loss: 0.09555584192276001, Final Batch Loss: 0.037094637751579285\n",
      "Epoch 2123, Loss: 0.07867376506328583, Final Batch Loss: 0.019996751099824905\n",
      "Epoch 2124, Loss: 0.09217942133545876, Final Batch Loss: 0.03478117287158966\n",
      "Epoch 2125, Loss: 0.10227534174919128, Final Batch Loss: 0.04071967676281929\n",
      "Epoch 2126, Loss: 0.11846157163381577, Final Batch Loss: 0.07690570503473282\n",
      "Epoch 2127, Loss: 0.05784819647669792, Final Batch Loss: 0.024220339953899384\n",
      "Epoch 2128, Loss: 0.11604715511202812, Final Batch Loss: 0.06261841952800751\n",
      "Epoch 2129, Loss: 0.09012308716773987, Final Batch Loss: 0.0419352687895298\n",
      "Epoch 2130, Loss: 0.08961604163050652, Final Batch Loss: 0.024956148117780685\n",
      "Epoch 2131, Loss: 0.09831367433071136, Final Batch Loss: 0.03733295947313309\n",
      "Epoch 2132, Loss: 0.1252073533833027, Final Batch Loss: 0.07814876735210419\n",
      "Epoch 2133, Loss: 0.18504074215888977, Final Batch Loss: 0.12857654690742493\n",
      "Epoch 2134, Loss: 0.11513885483145714, Final Batch Loss: 0.07409893721342087\n",
      "Epoch 2135, Loss: 0.08520857244729996, Final Batch Loss: 0.03477330505847931\n",
      "Epoch 2136, Loss: 0.12004806473851204, Final Batch Loss: 0.07162992656230927\n",
      "Epoch 2137, Loss: 0.10220884904265404, Final Batch Loss: 0.040452808141708374\n",
      "Epoch 2138, Loss: 0.12102809175848961, Final Batch Loss: 0.05977804586291313\n",
      "Epoch 2139, Loss: 0.07798835635185242, Final Batch Loss: 0.048765894025564194\n",
      "Epoch 2140, Loss: 0.12247227504849434, Final Batch Loss: 0.06669300049543381\n",
      "Epoch 2141, Loss: 0.09694349020719528, Final Batch Loss: 0.047095268964767456\n",
      "Epoch 2142, Loss: 0.08278326317667961, Final Batch Loss: 0.037636809051036835\n",
      "Epoch 2143, Loss: 0.10691922158002853, Final Batch Loss: 0.05768933519721031\n",
      "Epoch 2144, Loss: 0.10154756158590317, Final Batch Loss: 0.057900700718164444\n",
      "Epoch 2145, Loss: 0.09370545297861099, Final Batch Loss: 0.04869161918759346\n",
      "Epoch 2146, Loss: 0.08472362160682678, Final Batch Loss: 0.034982725977897644\n",
      "Epoch 2147, Loss: 0.08243711665272713, Final Batch Loss: 0.03920178860425949\n",
      "Epoch 2148, Loss: 0.10941223055124283, Final Batch Loss: 0.04892736300826073\n",
      "Epoch 2149, Loss: 0.1056792214512825, Final Batch Loss: 0.07370307296514511\n",
      "Epoch 2150, Loss: 0.08406301960349083, Final Batch Loss: 0.04717937856912613\n",
      "Epoch 2151, Loss: 0.11545970290899277, Final Batch Loss: 0.06113171577453613\n",
      "Epoch 2152, Loss: 0.13014471903443336, Final Batch Loss: 0.05169754847884178\n",
      "Epoch 2153, Loss: 0.08662158250808716, Final Batch Loss: 0.03274904936552048\n",
      "Epoch 2154, Loss: 0.09433567151427269, Final Batch Loss: 0.048482734709978104\n",
      "Epoch 2155, Loss: 0.08866289258003235, Final Batch Loss: 0.03757371008396149\n",
      "Epoch 2156, Loss: 0.0827544517815113, Final Batch Loss: 0.0345141626894474\n",
      "Epoch 2157, Loss: 0.11052369698882103, Final Batch Loss: 0.07689062505960464\n",
      "Epoch 2158, Loss: 0.09468172118067741, Final Batch Loss: 0.04923788085579872\n",
      "Epoch 2159, Loss: 0.11681947857141495, Final Batch Loss: 0.057711273431777954\n",
      "Epoch 2160, Loss: 0.08538582921028137, Final Batch Loss: 0.04803694412112236\n",
      "Epoch 2161, Loss: 0.07780034840106964, Final Batch Loss: 0.041940074414014816\n",
      "Epoch 2162, Loss: 0.08547830954194069, Final Batch Loss: 0.034877803176641464\n",
      "Epoch 2163, Loss: 0.11200568079948425, Final Batch Loss: 0.050592292100191116\n",
      "Epoch 2164, Loss: 0.09040426835417747, Final Batch Loss: 0.04150714725255966\n",
      "Epoch 2165, Loss: 0.11053011938929558, Final Batch Loss: 0.03929976746439934\n",
      "Epoch 2166, Loss: 0.12928179278969765, Final Batch Loss: 0.04642294719815254\n",
      "Epoch 2167, Loss: 0.0923757515847683, Final Batch Loss: 0.057619623839855194\n",
      "Epoch 2168, Loss: 0.0854048915207386, Final Batch Loss: 0.03542802855372429\n",
      "Epoch 2169, Loss: 0.08460108935832977, Final Batch Loss: 0.04223212972283363\n",
      "Epoch 2170, Loss: 0.09869095496833324, Final Batch Loss: 0.028107574209570885\n",
      "Epoch 2171, Loss: 0.0987335667014122, Final Batch Loss: 0.06965750455856323\n",
      "Epoch 2172, Loss: 0.09426693245768547, Final Batch Loss: 0.050244834274053574\n",
      "Epoch 2173, Loss: 0.07376588135957718, Final Batch Loss: 0.024291422218084335\n",
      "Epoch 2174, Loss: 0.10358745977282524, Final Batch Loss: 0.05638464167714119\n",
      "Epoch 2175, Loss: 0.11265459284186363, Final Batch Loss: 0.06705795973539352\n",
      "Epoch 2176, Loss: 0.06777480244636536, Final Batch Loss: 0.032085444778203964\n",
      "Epoch 2177, Loss: 0.0873291864991188, Final Batch Loss: 0.04237889498472214\n",
      "Epoch 2178, Loss: 0.09122266620397568, Final Batch Loss: 0.05210123211145401\n",
      "Epoch 2179, Loss: 0.10378587618470192, Final Batch Loss: 0.032465141266584396\n",
      "Epoch 2180, Loss: 0.09840847551822662, Final Batch Loss: 0.024981938302516937\n",
      "Epoch 2181, Loss: 0.10583773255348206, Final Batch Loss: 0.056683074682950974\n",
      "Epoch 2182, Loss: 0.07805389910936356, Final Batch Loss: 0.019748851656913757\n",
      "Epoch 2183, Loss: 0.11602045223116875, Final Batch Loss: 0.06767627596855164\n",
      "Epoch 2184, Loss: 0.12209919840097427, Final Batch Loss: 0.059974074363708496\n",
      "Epoch 2185, Loss: 0.12395992130041122, Final Batch Loss: 0.06639029085636139\n",
      "Epoch 2186, Loss: 0.07501757889986038, Final Batch Loss: 0.033055998384952545\n",
      "Epoch 2187, Loss: 0.11781371012330055, Final Batch Loss: 0.07611880451440811\n",
      "Epoch 2188, Loss: 0.10327723994851112, Final Batch Loss: 0.04518823325634003\n",
      "Epoch 2189, Loss: 0.136029664427042, Final Batch Loss: 0.08413208276033401\n",
      "Epoch 2190, Loss: 0.11003103107213974, Final Batch Loss: 0.05779028683900833\n",
      "Epoch 2191, Loss: 0.08994278684258461, Final Batch Loss: 0.0452813096344471\n",
      "Epoch 2192, Loss: 0.07753396593034267, Final Batch Loss: 0.03064172901213169\n",
      "Epoch 2193, Loss: 0.13258739560842514, Final Batch Loss: 0.08700799942016602\n",
      "Epoch 2194, Loss: 0.09349588677287102, Final Batch Loss: 0.03920602798461914\n",
      "Epoch 2195, Loss: 0.12130272015929222, Final Batch Loss: 0.077278733253479\n",
      "Epoch 2196, Loss: 0.09491641819477081, Final Batch Loss: 0.05172954872250557\n",
      "Epoch 2197, Loss: 0.10454780608415604, Final Batch Loss: 0.05411363020539284\n",
      "Epoch 2198, Loss: 0.12477102130651474, Final Batch Loss: 0.07663236558437347\n",
      "Epoch 2199, Loss: 0.06630593538284302, Final Batch Loss: 0.03314901143312454\n",
      "Epoch 2200, Loss: 0.08314450457692146, Final Batch Loss: 0.04333160072565079\n",
      "Epoch 2201, Loss: 0.15349072217941284, Final Batch Loss: 0.062471576035022736\n",
      "Epoch 2202, Loss: 0.10217448323965073, Final Batch Loss: 0.027143284678459167\n",
      "Epoch 2203, Loss: 0.12621016427874565, Final Batch Loss: 0.0678667426109314\n",
      "Epoch 2204, Loss: 0.1225813627243042, Final Batch Loss: 0.0688505470752716\n",
      "Epoch 2205, Loss: 0.08383487537503242, Final Batch Loss: 0.02498316392302513\n",
      "Epoch 2206, Loss: 0.08890413120388985, Final Batch Loss: 0.03921392932534218\n",
      "Epoch 2207, Loss: 0.08634503930807114, Final Batch Loss: 0.044942572712898254\n",
      "Epoch 2208, Loss: 0.11637374758720398, Final Batch Loss: 0.07729960978031158\n",
      "Epoch 2209, Loss: 0.09066002815961838, Final Batch Loss: 0.03131445497274399\n",
      "Epoch 2210, Loss: 0.09473695233464241, Final Batch Loss: 0.05031004548072815\n",
      "Epoch 2211, Loss: 0.17562220990657806, Final Batch Loss: 0.11588235199451447\n",
      "Epoch 2212, Loss: 0.1038680300116539, Final Batch Loss: 0.059594180434942245\n",
      "Epoch 2213, Loss: 0.08785011991858482, Final Batch Loss: 0.051652342081069946\n",
      "Epoch 2214, Loss: 0.1275639683008194, Final Batch Loss: 0.04952066391706467\n",
      "Epoch 2215, Loss: 0.11715499311685562, Final Batch Loss: 0.04355689138174057\n",
      "Epoch 2216, Loss: 0.14984244480729103, Final Batch Loss: 0.04679866507649422\n",
      "Epoch 2217, Loss: 0.15551184490323067, Final Batch Loss: 0.037315499037504196\n",
      "Epoch 2218, Loss: 0.09126145020127296, Final Batch Loss: 0.04329581558704376\n",
      "Epoch 2219, Loss: 0.09632087126374245, Final Batch Loss: 0.04114457219839096\n",
      "Epoch 2220, Loss: 0.09928008913993835, Final Batch Loss: 0.03634510189294815\n",
      "Epoch 2221, Loss: 0.09843247383832932, Final Batch Loss: 0.053128428757190704\n",
      "Epoch 2222, Loss: 0.10247446596622467, Final Batch Loss: 0.06350881606340408\n",
      "Epoch 2223, Loss: 0.10183870047330856, Final Batch Loss: 0.06512465327978134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2224, Loss: 0.1037236787378788, Final Batch Loss: 0.05849777162075043\n",
      "Epoch 2225, Loss: 0.08742836862802505, Final Batch Loss: 0.031219489872455597\n",
      "Epoch 2226, Loss: 0.12340008094906807, Final Batch Loss: 0.06548362970352173\n",
      "Epoch 2227, Loss: 0.08801694214344025, Final Batch Loss: 0.03149700164794922\n",
      "Epoch 2228, Loss: 0.08904775604605675, Final Batch Loss: 0.040168117731809616\n",
      "Epoch 2229, Loss: 0.09964786469936371, Final Batch Loss: 0.07378248870372772\n",
      "Epoch 2230, Loss: 0.11084574460983276, Final Batch Loss: 0.03832603991031647\n",
      "Epoch 2231, Loss: 0.10528327152132988, Final Batch Loss: 0.06194588169455528\n",
      "Epoch 2232, Loss: 0.10858788341283798, Final Batch Loss: 0.045651875436306\n",
      "Epoch 2233, Loss: 0.1182307954877615, Final Batch Loss: 0.08825956284999847\n",
      "Epoch 2234, Loss: 0.11116747185587883, Final Batch Loss: 0.06303390860557556\n",
      "Epoch 2235, Loss: 0.10034930147230625, Final Batch Loss: 0.07542734593153\n",
      "Epoch 2236, Loss: 0.09524585120379925, Final Batch Loss: 0.027549175545573235\n",
      "Epoch 2237, Loss: 0.19503898918628693, Final Batch Loss: 0.15523920953273773\n",
      "Epoch 2238, Loss: 0.10630669072270393, Final Batch Loss: 0.048055823892354965\n",
      "Epoch 2239, Loss: 0.09130304306745529, Final Batch Loss: 0.03957284614443779\n",
      "Epoch 2240, Loss: 0.09172222763299942, Final Batch Loss: 0.04067695885896683\n",
      "Epoch 2241, Loss: 0.1509345807135105, Final Batch Loss: 0.10364291071891785\n",
      "Epoch 2242, Loss: 0.10473174601793289, Final Batch Loss: 0.05138779804110527\n",
      "Epoch 2243, Loss: 0.09289588779211044, Final Batch Loss: 0.05127850919961929\n",
      "Epoch 2244, Loss: 0.08545977994799614, Final Batch Loss: 0.04262278228998184\n",
      "Epoch 2245, Loss: 0.07574685104191303, Final Batch Loss: 0.029361369088292122\n",
      "Epoch 2246, Loss: 0.11325370147824287, Final Batch Loss: 0.053186941891908646\n",
      "Epoch 2247, Loss: 0.09972406178712845, Final Batch Loss: 0.04890488460659981\n",
      "Epoch 2248, Loss: 0.07198784127831459, Final Batch Loss: 0.01860789582133293\n",
      "Epoch 2249, Loss: 0.0957225114107132, Final Batch Loss: 0.053332965821027756\n",
      "Epoch 2250, Loss: 0.08222541585564613, Final Batch Loss: 0.03780653700232506\n",
      "Epoch 2251, Loss: 0.0764109343290329, Final Batch Loss: 0.03577270358800888\n",
      "Epoch 2252, Loss: 0.09582890942692757, Final Batch Loss: 0.04636402800679207\n",
      "Epoch 2253, Loss: 0.09510738030076027, Final Batch Loss: 0.04906785488128662\n",
      "Epoch 2254, Loss: 0.07874413952231407, Final Batch Loss: 0.03618483245372772\n",
      "Epoch 2255, Loss: 0.07805640995502472, Final Batch Loss: 0.03410771116614342\n",
      "Epoch 2256, Loss: 0.10216405987739563, Final Batch Loss: 0.048598527908325195\n",
      "Epoch 2257, Loss: 0.12153004854917526, Final Batch Loss: 0.08862432837486267\n",
      "Epoch 2258, Loss: 0.08469217643141747, Final Batch Loss: 0.04318941384553909\n",
      "Epoch 2259, Loss: 0.11891170963644981, Final Batch Loss: 0.050997111946344376\n",
      "Epoch 2260, Loss: 0.10914415493607521, Final Batch Loss: 0.0354982353746891\n",
      "Epoch 2261, Loss: 0.07641857117414474, Final Batch Loss: 0.03151792287826538\n",
      "Epoch 2262, Loss: 0.07116689905524254, Final Batch Loss: 0.023636091500520706\n",
      "Epoch 2263, Loss: 0.09424515068531036, Final Batch Loss: 0.03307786211371422\n",
      "Epoch 2264, Loss: 0.10441570356488228, Final Batch Loss: 0.05374133214354515\n",
      "Epoch 2265, Loss: 0.08178673312067986, Final Batch Loss: 0.03272290900349617\n",
      "Epoch 2266, Loss: 0.0916801206767559, Final Batch Loss: 0.0361269935965538\n",
      "Epoch 2267, Loss: 0.10275270417332649, Final Batch Loss: 0.06452494114637375\n",
      "Epoch 2268, Loss: 0.1125924102962017, Final Batch Loss: 0.032839540392160416\n",
      "Epoch 2269, Loss: 0.08130969852209091, Final Batch Loss: 0.04027792066335678\n",
      "Epoch 2270, Loss: 0.0933724157512188, Final Batch Loss: 0.054859939962625504\n",
      "Epoch 2271, Loss: 0.10357749089598656, Final Batch Loss: 0.04291483387351036\n",
      "Epoch 2272, Loss: 0.0734027847647667, Final Batch Loss: 0.05341087654232979\n",
      "Epoch 2273, Loss: 0.09793910384178162, Final Batch Loss: 0.061558954417705536\n",
      "Epoch 2274, Loss: 0.10834475606679916, Final Batch Loss: 0.07743120193481445\n",
      "Epoch 2275, Loss: 0.10934175550937653, Final Batch Loss: 0.03183306008577347\n",
      "Epoch 2276, Loss: 0.09756538644433022, Final Batch Loss: 0.036926209926605225\n",
      "Epoch 2277, Loss: 0.13181518763303757, Final Batch Loss: 0.0876379981637001\n",
      "Epoch 2278, Loss: 0.11176091805100441, Final Batch Loss: 0.05850733071565628\n",
      "Epoch 2279, Loss: 0.07801656797528267, Final Batch Loss: 0.042705193161964417\n",
      "Epoch 2280, Loss: 0.07012022100389004, Final Batch Loss: 0.021701576188206673\n",
      "Epoch 2281, Loss: 0.07768607512116432, Final Batch Loss: 0.03556888923048973\n",
      "Epoch 2282, Loss: 0.10880466923117638, Final Batch Loss: 0.06470920890569687\n",
      "Epoch 2283, Loss: 0.11406230181455612, Final Batch Loss: 0.07859788089990616\n",
      "Epoch 2284, Loss: 0.11399354413151741, Final Batch Loss: 0.03767378255724907\n",
      "Epoch 2285, Loss: 0.11349287256598473, Final Batch Loss: 0.04676518961787224\n",
      "Epoch 2286, Loss: 0.0832097977399826, Final Batch Loss: 0.046474114060401917\n",
      "Epoch 2287, Loss: 0.08375462517142296, Final Batch Loss: 0.055705681443214417\n",
      "Epoch 2288, Loss: 0.07717911899089813, Final Batch Loss: 0.029579665511846542\n",
      "Epoch 2289, Loss: 0.11387532204389572, Final Batch Loss: 0.05566239729523659\n",
      "Epoch 2290, Loss: 0.09026755392551422, Final Batch Loss: 0.04480341076850891\n",
      "Epoch 2291, Loss: 0.14196716248989105, Final Batch Loss: 0.06290275603532791\n",
      "Epoch 2292, Loss: 0.08258742466568947, Final Batch Loss: 0.04119066521525383\n",
      "Epoch 2293, Loss: 0.07600802555680275, Final Batch Loss: 0.03517626225948334\n",
      "Epoch 2294, Loss: 0.09282555058598518, Final Batch Loss: 0.03759235516190529\n",
      "Epoch 2295, Loss: 0.08845553547143936, Final Batch Loss: 0.0521756112575531\n",
      "Epoch 2296, Loss: 0.09178956598043442, Final Batch Loss: 0.041024621576070786\n",
      "Epoch 2297, Loss: 0.09404078498482704, Final Batch Loss: 0.0389951728284359\n",
      "Epoch 2298, Loss: 0.08220194652676582, Final Batch Loss: 0.04714661464095116\n",
      "Epoch 2299, Loss: 0.1092660240828991, Final Batch Loss: 0.04222073778510094\n",
      "Epoch 2300, Loss: 0.09512509405612946, Final Batch Loss: 0.02726762741804123\n",
      "Epoch 2301, Loss: 0.10777236893773079, Final Batch Loss: 0.04642069339752197\n",
      "Epoch 2302, Loss: 0.09162086248397827, Final Batch Loss: 0.056895241141319275\n",
      "Epoch 2303, Loss: 0.10203290730714798, Final Batch Loss: 0.05613106116652489\n",
      "Epoch 2304, Loss: 0.09117748029530048, Final Batch Loss: 0.02786039002239704\n",
      "Epoch 2305, Loss: 0.11448121815919876, Final Batch Loss: 0.06538816541433334\n",
      "Epoch 2306, Loss: 0.11528345197439194, Final Batch Loss: 0.028118960559368134\n",
      "Epoch 2307, Loss: 0.08210725337266922, Final Batch Loss: 0.04576578736305237\n",
      "Epoch 2308, Loss: 0.11389055848121643, Final Batch Loss: 0.034898221492767334\n",
      "Epoch 2309, Loss: 0.12396127544343472, Final Batch Loss: 0.09614133089780807\n",
      "Epoch 2310, Loss: 0.09957008436322212, Final Batch Loss: 0.028603632003068924\n",
      "Epoch 2311, Loss: 0.09183311834931374, Final Batch Loss: 0.049607694149017334\n",
      "Epoch 2312, Loss: 0.09696193784475327, Final Batch Loss: 0.05156874656677246\n",
      "Epoch 2313, Loss: 0.1134413480758667, Final Batch Loss: 0.06213562563061714\n",
      "Epoch 2314, Loss: 0.10600845329463482, Final Batch Loss: 0.07669731974601746\n",
      "Epoch 2315, Loss: 0.10230463743209839, Final Batch Loss: 0.036342963576316833\n",
      "Epoch 2316, Loss: 0.07642455585300922, Final Batch Loss: 0.04849577695131302\n",
      "Epoch 2317, Loss: 0.1373177133500576, Final Batch Loss: 0.062427062541246414\n",
      "Epoch 2318, Loss: 0.14297134429216385, Final Batch Loss: 0.07037405669689178\n",
      "Epoch 2319, Loss: 0.11621953174471855, Final Batch Loss: 0.056005921214818954\n",
      "Epoch 2320, Loss: 0.09887434169650078, Final Batch Loss: 0.06467418372631073\n",
      "Epoch 2321, Loss: 0.11547847837209702, Final Batch Loss: 0.06167329475283623\n",
      "Epoch 2322, Loss: 0.12419404834508896, Final Batch Loss: 0.05618499964475632\n",
      "Epoch 2323, Loss: 0.1035812720656395, Final Batch Loss: 0.04354503005743027\n",
      "Epoch 2324, Loss: 0.1342216469347477, Final Batch Loss: 0.07303471863269806\n",
      "Epoch 2325, Loss: 0.13323140144348145, Final Batch Loss: 0.06862881779670715\n",
      "Epoch 2326, Loss: 0.16242939978837967, Final Batch Loss: 0.07856499403715134\n",
      "Epoch 2327, Loss: 0.13405341655015945, Final Batch Loss: 0.042038194835186005\n",
      "Epoch 2328, Loss: 0.2249719277024269, Final Batch Loss: 0.07448314875364304\n",
      "Epoch 2329, Loss: 0.20334338396787643, Final Batch Loss: 0.10942405462265015\n",
      "Epoch 2330, Loss: 0.14270151779055595, Final Batch Loss: 0.08744429796934128\n",
      "Epoch 2331, Loss: 0.10683000460267067, Final Batch Loss: 0.052607323974370956\n",
      "Epoch 2332, Loss: 0.11916805058717728, Final Batch Loss: 0.0814405232667923\n",
      "Epoch 2333, Loss: 0.16136614978313446, Final Batch Loss: 0.06796485930681229\n",
      "Epoch 2334, Loss: 0.13418229296803474, Final Batch Loss: 0.036685701459646225\n",
      "Epoch 2335, Loss: 0.11623914539813995, Final Batch Loss: 0.06409548968076706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2336, Loss: 0.09716565161943436, Final Batch Loss: 0.045729152858257294\n",
      "Epoch 2337, Loss: 0.10464521497488022, Final Batch Loss: 0.04591080918908119\n",
      "Epoch 2338, Loss: 0.12665517255663872, Final Batch Loss: 0.07310599088668823\n",
      "Epoch 2339, Loss: 0.14046601206064224, Final Batch Loss: 0.06906996667385101\n",
      "Epoch 2340, Loss: 0.1061491146683693, Final Batch Loss: 0.06998375058174133\n",
      "Epoch 2341, Loss: 0.07925441116094589, Final Batch Loss: 0.04326554015278816\n",
      "Epoch 2342, Loss: 0.10513221845030785, Final Batch Loss: 0.056871041655540466\n",
      "Epoch 2343, Loss: 0.14988020062446594, Final Batch Loss: 0.0672915056347847\n",
      "Epoch 2344, Loss: 0.14996741712093353, Final Batch Loss: 0.07449466735124588\n",
      "Epoch 2345, Loss: 0.1445944756269455, Final Batch Loss: 0.10958845168352127\n",
      "Epoch 2346, Loss: 0.11233295500278473, Final Batch Loss: 0.04902142286300659\n",
      "Epoch 2347, Loss: 0.18185880780220032, Final Batch Loss: 0.07201322913169861\n",
      "Epoch 2348, Loss: 0.1295878067612648, Final Batch Loss: 0.058170706033706665\n",
      "Epoch 2349, Loss: 0.19096209108829498, Final Batch Loss: 0.10079921036958694\n",
      "Epoch 2350, Loss: 0.12231861054897308, Final Batch Loss: 0.04055716097354889\n",
      "Epoch 2351, Loss: 0.14666113629937172, Final Batch Loss: 0.10136957466602325\n",
      "Epoch 2352, Loss: 0.14112260565161705, Final Batch Loss: 0.09498383104801178\n",
      "Epoch 2353, Loss: 0.16071737557649612, Final Batch Loss: 0.06816212087869644\n",
      "Epoch 2354, Loss: 0.12217544764280319, Final Batch Loss: 0.08313396573066711\n",
      "Epoch 2355, Loss: 0.18194276839494705, Final Batch Loss: 0.06310109049081802\n",
      "Epoch 2356, Loss: 0.1147308349609375, Final Batch Loss: 0.04247205704450607\n",
      "Epoch 2357, Loss: 0.22010721266269684, Final Batch Loss: 0.1604205071926117\n",
      "Epoch 2358, Loss: 0.18637743219733238, Final Batch Loss: 0.12882237136363983\n",
      "Epoch 2359, Loss: 0.08402753621339798, Final Batch Loss: 0.0416802279651165\n",
      "Epoch 2360, Loss: 0.2732296958565712, Final Batch Loss: 0.1895454376935959\n",
      "Epoch 2361, Loss: 0.08513402938842773, Final Batch Loss: 0.051523540169000626\n",
      "Epoch 2362, Loss: 0.10921968519687653, Final Batch Loss: 0.056069113314151764\n",
      "Epoch 2363, Loss: 0.10384530201554298, Final Batch Loss: 0.046100057661533356\n",
      "Epoch 2364, Loss: 0.11510052531957626, Final Batch Loss: 0.04333854466676712\n",
      "Epoch 2365, Loss: 0.11398474499583244, Final Batch Loss: 0.0536600686609745\n",
      "Epoch 2366, Loss: 0.17249290645122528, Final Batch Loss: 0.10689011961221695\n",
      "Epoch 2367, Loss: 0.1051224060356617, Final Batch Loss: 0.05071425065398216\n",
      "Epoch 2368, Loss: 0.28599709272384644, Final Batch Loss: 0.10047240555286407\n",
      "Epoch 2369, Loss: 0.08616277389228344, Final Batch Loss: 0.030890142545104027\n",
      "Epoch 2370, Loss: 0.09728202596306801, Final Batch Loss: 0.02856506034731865\n",
      "Epoch 2371, Loss: 0.13126233220100403, Final Batch Loss: 0.08078288286924362\n",
      "Epoch 2372, Loss: 0.10056857392191887, Final Batch Loss: 0.04663162678480148\n",
      "Epoch 2373, Loss: 0.0800301693379879, Final Batch Loss: 0.04308453947305679\n",
      "Epoch 2374, Loss: 0.14685340598225594, Final Batch Loss: 0.05360110476613045\n",
      "Epoch 2375, Loss: 0.16374145448207855, Final Batch Loss: 0.06463304907083511\n",
      "Epoch 2376, Loss: 0.10813147947192192, Final Batch Loss: 0.05022379010915756\n",
      "Epoch 2377, Loss: 0.09575843438506126, Final Batch Loss: 0.06404276937246323\n",
      "Epoch 2378, Loss: 0.11786949634552002, Final Batch Loss: 0.06249134987592697\n",
      "Epoch 2379, Loss: 0.08839043974876404, Final Batch Loss: 0.04168951138854027\n",
      "Epoch 2380, Loss: 0.10563252121210098, Final Batch Loss: 0.057066675275564194\n",
      "Epoch 2381, Loss: 0.10326208174228668, Final Batch Loss: 0.04749256744980812\n",
      "Epoch 2382, Loss: 0.06818382255733013, Final Batch Loss: 0.022028444334864616\n",
      "Epoch 2383, Loss: 0.09311535023152828, Final Batch Loss: 0.028151607140898705\n",
      "Epoch 2384, Loss: 0.11691095679998398, Final Batch Loss: 0.06740044057369232\n",
      "Epoch 2385, Loss: 0.1389184705913067, Final Batch Loss: 0.09428837895393372\n",
      "Epoch 2386, Loss: 0.09767722338438034, Final Batch Loss: 0.043461162596940994\n",
      "Epoch 2387, Loss: 0.0786009319126606, Final Batch Loss: 0.02921038120985031\n",
      "Epoch 2388, Loss: 0.10937729105353355, Final Batch Loss: 0.05787273123860359\n",
      "Epoch 2389, Loss: 0.13151075318455696, Final Batch Loss: 0.052165087312459946\n",
      "Epoch 2390, Loss: 0.07454264909029007, Final Batch Loss: 0.01940721645951271\n",
      "Epoch 2391, Loss: 0.08238985203206539, Final Batch Loss: 0.029627537354826927\n",
      "Epoch 2392, Loss: 0.09782436117529869, Final Batch Loss: 0.05473514273762703\n",
      "Epoch 2393, Loss: 0.08664209023118019, Final Batch Loss: 0.036375146359205246\n",
      "Epoch 2394, Loss: 0.1860596388578415, Final Batch Loss: 0.10940872877836227\n",
      "Epoch 2395, Loss: 0.11227269843220711, Final Batch Loss: 0.045826081186532974\n",
      "Epoch 2396, Loss: 0.11721140891313553, Final Batch Loss: 0.052070252597332\n",
      "Epoch 2397, Loss: 0.11112929880619049, Final Batch Loss: 0.05292383208870888\n",
      "Epoch 2398, Loss: 0.10981657728552818, Final Batch Loss: 0.06979844719171524\n",
      "Epoch 2399, Loss: 0.09197420999407768, Final Batch Loss: 0.058490026742219925\n",
      "Epoch 2400, Loss: 0.08672478795051575, Final Batch Loss: 0.038577936589717865\n",
      "Epoch 2401, Loss: 0.10005848109722137, Final Batch Loss: 0.04825133830308914\n",
      "Epoch 2402, Loss: 0.11643123999238014, Final Batch Loss: 0.05705740675330162\n",
      "Epoch 2403, Loss: 0.12314564734697342, Final Batch Loss: 0.039321042597293854\n",
      "Epoch 2404, Loss: 0.10438873618841171, Final Batch Loss: 0.05822393670678139\n",
      "Epoch 2405, Loss: 0.10258392058312893, Final Batch Loss: 0.03111202083528042\n",
      "Epoch 2406, Loss: 0.1168220080435276, Final Batch Loss: 0.05272911861538887\n",
      "Epoch 2407, Loss: 0.15863443538546562, Final Batch Loss: 0.11331484466791153\n",
      "Epoch 2408, Loss: 0.1101120114326477, Final Batch Loss: 0.06217171996831894\n",
      "Epoch 2409, Loss: 0.10917476937174797, Final Batch Loss: 0.07990208268165588\n",
      "Epoch 2410, Loss: 0.07291727140545845, Final Batch Loss: 0.034159038215875626\n",
      "Epoch 2411, Loss: 0.1318005435168743, Final Batch Loss: 0.08598131686449051\n",
      "Epoch 2412, Loss: 0.10996899753808975, Final Batch Loss: 0.04812013357877731\n",
      "Epoch 2413, Loss: 0.14939136058092117, Final Batch Loss: 0.09843877702951431\n",
      "Epoch 2414, Loss: 0.12166604027152061, Final Batch Loss: 0.03778793290257454\n",
      "Epoch 2415, Loss: 0.16805019974708557, Final Batch Loss: 0.0844055637717247\n",
      "Epoch 2416, Loss: 0.18927166610956192, Final Batch Loss: 0.08640295267105103\n",
      "Epoch 2417, Loss: 0.14735005050897598, Final Batch Loss: 0.08253645151853561\n",
      "Epoch 2418, Loss: 0.19098979979753494, Final Batch Loss: 0.135796457529068\n",
      "Epoch 2419, Loss: 0.1487116664648056, Final Batch Loss: 0.060480259358882904\n",
      "Epoch 2420, Loss: 0.11811314895749092, Final Batch Loss: 0.06757810711860657\n",
      "Epoch 2421, Loss: 0.10126994177699089, Final Batch Loss: 0.07621116936206818\n",
      "Epoch 2422, Loss: 0.1300659328699112, Final Batch Loss: 0.05900737643241882\n",
      "Epoch 2423, Loss: 0.18825506418943405, Final Batch Loss: 0.0640806034207344\n",
      "Epoch 2424, Loss: 0.09424986690282822, Final Batch Loss: 0.03876719996333122\n",
      "Epoch 2425, Loss: 0.11734235286712646, Final Batch Loss: 0.07518859952688217\n",
      "Epoch 2426, Loss: 0.0953085608780384, Final Batch Loss: 0.028375383466482162\n",
      "Epoch 2427, Loss: 0.10175598412752151, Final Batch Loss: 0.06195246800780296\n",
      "Epoch 2428, Loss: 0.13187534362077713, Final Batch Loss: 0.08411993831396103\n",
      "Epoch 2429, Loss: 0.13086648285388947, Final Batch Loss: 0.0682566836476326\n",
      "Epoch 2430, Loss: 0.10409542173147202, Final Batch Loss: 0.057199664413928986\n",
      "Epoch 2431, Loss: 0.11768389493227005, Final Batch Loss: 0.056220341473817825\n",
      "Epoch 2432, Loss: 0.09058048948645592, Final Batch Loss: 0.04241381213068962\n",
      "Epoch 2433, Loss: 0.1337765008211136, Final Batch Loss: 0.06580889225006104\n",
      "Epoch 2434, Loss: 0.11990204080939293, Final Batch Loss: 0.06754784286022186\n",
      "Epoch 2435, Loss: 0.14248792827129364, Final Batch Loss: 0.07426164299249649\n",
      "Epoch 2436, Loss: 0.09556899592280388, Final Batch Loss: 0.05901332199573517\n",
      "Epoch 2437, Loss: 0.10708869248628616, Final Batch Loss: 0.05530242994427681\n",
      "Epoch 2438, Loss: 0.08221299946308136, Final Batch Loss: 0.03563768044114113\n",
      "Epoch 2439, Loss: 0.1554434522986412, Final Batch Loss: 0.08720824867486954\n",
      "Epoch 2440, Loss: 0.09348487854003906, Final Batch Loss: 0.05242731049656868\n",
      "Epoch 2441, Loss: 0.09812435880303383, Final Batch Loss: 0.059926118701696396\n",
      "Epoch 2442, Loss: 0.08765585348010063, Final Batch Loss: 0.05045849084854126\n",
      "Epoch 2443, Loss: 0.09657436236739159, Final Batch Loss: 0.06259224563837051\n",
      "Epoch 2444, Loss: 0.10401187837123871, Final Batch Loss: 0.035692617297172546\n",
      "Epoch 2445, Loss: 0.08587212860584259, Final Batch Loss: 0.03679407387971878\n",
      "Epoch 2446, Loss: 0.14979413896799088, Final Batch Loss: 0.07242564857006073\n",
      "Epoch 2447, Loss: 0.10212467238306999, Final Batch Loss: 0.06499059498310089\n",
      "Epoch 2448, Loss: 0.11395853757858276, Final Batch Loss: 0.055925171822309494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2449, Loss: 0.10359149053692818, Final Batch Loss: 0.042744867503643036\n",
      "Epoch 2450, Loss: 0.08188032358884811, Final Batch Loss: 0.03874681144952774\n",
      "Epoch 2451, Loss: 0.09367033466696739, Final Batch Loss: 0.053239841014146805\n",
      "Epoch 2452, Loss: 0.09780676662921906, Final Batch Loss: 0.049518048763275146\n",
      "Epoch 2453, Loss: 0.09083417803049088, Final Batch Loss: 0.03262639790773392\n",
      "Epoch 2454, Loss: 0.11020515859127045, Final Batch Loss: 0.03401350975036621\n",
      "Epoch 2455, Loss: 0.11390608549118042, Final Batch Loss: 0.054749276489019394\n",
      "Epoch 2456, Loss: 0.14453844353556633, Final Batch Loss: 0.10143928229808807\n",
      "Epoch 2457, Loss: 0.10102210566401482, Final Batch Loss: 0.03177414461970329\n",
      "Epoch 2458, Loss: 0.09303553029894829, Final Batch Loss: 0.03938763216137886\n",
      "Epoch 2459, Loss: 0.08558015897870064, Final Batch Loss: 0.03593667224049568\n",
      "Epoch 2460, Loss: 0.08082417398691177, Final Batch Loss: 0.04434856399893761\n",
      "Epoch 2461, Loss: 0.14274653047323227, Final Batch Loss: 0.07593928277492523\n",
      "Epoch 2462, Loss: 0.09924444556236267, Final Batch Loss: 0.0441705659031868\n",
      "Epoch 2463, Loss: 0.10932214558124542, Final Batch Loss: 0.047485996037721634\n",
      "Epoch 2464, Loss: 0.08822979032993317, Final Batch Loss: 0.051664337515830994\n",
      "Epoch 2465, Loss: 0.1061103567481041, Final Batch Loss: 0.05365251749753952\n",
      "Epoch 2466, Loss: 0.08981523662805557, Final Batch Loss: 0.043870724737644196\n",
      "Epoch 2467, Loss: 0.09532195329666138, Final Batch Loss: 0.0621369443833828\n",
      "Epoch 2468, Loss: 0.10126067325472832, Final Batch Loss: 0.053323742002248764\n",
      "Epoch 2469, Loss: 0.09120739996433258, Final Batch Loss: 0.04662412777543068\n",
      "Epoch 2470, Loss: 0.11390914395451546, Final Batch Loss: 0.07601966708898544\n",
      "Epoch 2471, Loss: 0.1144038662314415, Final Batch Loss: 0.07302488386631012\n",
      "Epoch 2472, Loss: 0.1028815284371376, Final Batch Loss: 0.061560455709695816\n",
      "Epoch 2473, Loss: 0.10407029837369919, Final Batch Loss: 0.05029614269733429\n",
      "Epoch 2474, Loss: 0.08650937676429749, Final Batch Loss: 0.03893270716071129\n",
      "Epoch 2475, Loss: 0.09765911102294922, Final Batch Loss: 0.0469987653195858\n",
      "Epoch 2476, Loss: 0.15905950590968132, Final Batch Loss: 0.04476621374487877\n",
      "Epoch 2477, Loss: 0.11656517535448074, Final Batch Loss: 0.0758197233080864\n",
      "Epoch 2478, Loss: 0.13602088391780853, Final Batch Loss: 0.0744515135884285\n",
      "Epoch 2479, Loss: 0.07983637601137161, Final Batch Loss: 0.04580744355916977\n",
      "Epoch 2480, Loss: 0.1252022683620453, Final Batch Loss: 0.05657011270523071\n",
      "Epoch 2481, Loss: 0.1352754905819893, Final Batch Loss: 0.09036169946193695\n",
      "Epoch 2482, Loss: 0.10920578241348267, Final Batch Loss: 0.07618819177150726\n",
      "Epoch 2483, Loss: 0.08481999486684799, Final Batch Loss: 0.041607294231653214\n",
      "Epoch 2484, Loss: 0.08210028894245625, Final Batch Loss: 0.06011420488357544\n",
      "Epoch 2485, Loss: 0.09150279313325882, Final Batch Loss: 0.057064592838287354\n",
      "Epoch 2486, Loss: 0.13441253080964088, Final Batch Loss: 0.044574011117219925\n",
      "Epoch 2487, Loss: 0.08611154928803444, Final Batch Loss: 0.042633652687072754\n",
      "Epoch 2488, Loss: 0.11473771184682846, Final Batch Loss: 0.07105793803930283\n",
      "Epoch 2489, Loss: 0.13709642365574837, Final Batch Loss: 0.07993166893720627\n",
      "Epoch 2490, Loss: 0.10775739699602127, Final Batch Loss: 0.051479000598192215\n",
      "Epoch 2491, Loss: 0.09547000005841255, Final Batch Loss: 0.04140790179371834\n",
      "Epoch 2492, Loss: 0.06288209371268749, Final Batch Loss: 0.02640676312148571\n",
      "Epoch 2493, Loss: 0.10837901011109352, Final Batch Loss: 0.05845058709383011\n",
      "Epoch 2494, Loss: 0.12677152827382088, Final Batch Loss: 0.06444606930017471\n",
      "Epoch 2495, Loss: 0.10580650717020035, Final Batch Loss: 0.07325392216444016\n",
      "Epoch 2496, Loss: 0.13372549042105675, Final Batch Loss: 0.052387136965990067\n",
      "Epoch 2497, Loss: 0.10212734341621399, Final Batch Loss: 0.0572909340262413\n",
      "Epoch 2498, Loss: 0.10866641253232956, Final Batch Loss: 0.0515117347240448\n",
      "Epoch 2499, Loss: 0.09179839491844177, Final Batch Loss: 0.03718477487564087\n",
      "Epoch 2500, Loss: 0.14128248393535614, Final Batch Loss: 0.0594596192240715\n",
      "Epoch 2501, Loss: 0.1028544045984745, Final Batch Loss: 0.04997635260224342\n",
      "Epoch 2502, Loss: 0.09944441542029381, Final Batch Loss: 0.03941793739795685\n",
      "Epoch 2503, Loss: 0.09623588621616364, Final Batch Loss: 0.048315051943063736\n",
      "Epoch 2504, Loss: 0.09636993333697319, Final Batch Loss: 0.03673331439495087\n",
      "Epoch 2505, Loss: 0.0838000513613224, Final Batch Loss: 0.04612838849425316\n",
      "Epoch 2506, Loss: 0.10852642357349396, Final Batch Loss: 0.04974084347486496\n",
      "Epoch 2507, Loss: 0.10361651331186295, Final Batch Loss: 0.047031376510858536\n",
      "Epoch 2508, Loss: 0.1016504131257534, Final Batch Loss: 0.036279838532209396\n",
      "Epoch 2509, Loss: 0.12773607671260834, Final Batch Loss: 0.08663895726203918\n",
      "Epoch 2510, Loss: 0.09130581840872765, Final Batch Loss: 0.04912365972995758\n",
      "Epoch 2511, Loss: 0.08892650157213211, Final Batch Loss: 0.03903968632221222\n",
      "Epoch 2512, Loss: 0.08564000949263573, Final Batch Loss: 0.04489440470933914\n",
      "Epoch 2513, Loss: 0.09209594503045082, Final Batch Loss: 0.05286991223692894\n",
      "Epoch 2514, Loss: 0.08297814428806305, Final Batch Loss: 0.03471773862838745\n",
      "Epoch 2515, Loss: 0.1211455725133419, Final Batch Loss: 0.06873787939548492\n",
      "Epoch 2516, Loss: 0.0867397915571928, Final Batch Loss: 0.028243696317076683\n",
      "Epoch 2517, Loss: 0.09722332656383514, Final Batch Loss: 0.04671943560242653\n",
      "Epoch 2518, Loss: 0.08110658824443817, Final Batch Loss: 0.04210290312767029\n",
      "Epoch 2519, Loss: 0.09919312596321106, Final Batch Loss: 0.06318657845258713\n",
      "Epoch 2520, Loss: 0.1146501712501049, Final Batch Loss: 0.05439278483390808\n",
      "Epoch 2521, Loss: 0.07505866512656212, Final Batch Loss: 0.0313020721077919\n",
      "Epoch 2522, Loss: 0.10554473288357258, Final Batch Loss: 0.07842779159545898\n",
      "Epoch 2523, Loss: 0.08236387744545937, Final Batch Loss: 0.037888042628765106\n",
      "Epoch 2524, Loss: 0.1051984578371048, Final Batch Loss: 0.06388142704963684\n",
      "Epoch 2525, Loss: 0.11867387965321541, Final Batch Loss: 0.07898005843162537\n",
      "Epoch 2526, Loss: 0.13082294538617134, Final Batch Loss: 0.058795008808374405\n",
      "Epoch 2527, Loss: 0.1058378629386425, Final Batch Loss: 0.04030562564730644\n",
      "Epoch 2528, Loss: 0.10683808475732803, Final Batch Loss: 0.051467400044202805\n",
      "Epoch 2529, Loss: 0.07772650383412838, Final Batch Loss: 0.022803006693720818\n",
      "Epoch 2530, Loss: 0.1313536800444126, Final Batch Loss: 0.04482102766633034\n",
      "Epoch 2531, Loss: 0.08657833188772202, Final Batch Loss: 0.04167230427265167\n",
      "Epoch 2532, Loss: 0.1198999434709549, Final Batch Loss: 0.05511695146560669\n",
      "Epoch 2533, Loss: 0.11376317590475082, Final Batch Loss: 0.020211204886436462\n",
      "Epoch 2534, Loss: 0.08747602254152298, Final Batch Loss: 0.045564547181129456\n",
      "Epoch 2535, Loss: 0.12742628529667854, Final Batch Loss: 0.04584216699004173\n",
      "Epoch 2536, Loss: 0.09146490320563316, Final Batch Loss: 0.052545685321092606\n",
      "Epoch 2537, Loss: 0.09293807670474052, Final Batch Loss: 0.04756680876016617\n",
      "Epoch 2538, Loss: 0.12854183837771416, Final Batch Loss: 0.07620078325271606\n",
      "Epoch 2539, Loss: 0.1116853579878807, Final Batch Loss: 0.059638846665620804\n",
      "Epoch 2540, Loss: 0.08466998115181923, Final Batch Loss: 0.04167192429304123\n",
      "Epoch 2541, Loss: 0.09552313014864922, Final Batch Loss: 0.038208916783332825\n",
      "Epoch 2542, Loss: 0.06923862919211388, Final Batch Loss: 0.033274028450250626\n",
      "Epoch 2543, Loss: 0.09363411366939545, Final Batch Loss: 0.03196156397461891\n",
      "Epoch 2544, Loss: 0.102033831179142, Final Batch Loss: 0.04494861885905266\n",
      "Epoch 2545, Loss: 0.10567521676421165, Final Batch Loss: 0.04725775122642517\n",
      "Epoch 2546, Loss: 0.07411320693790913, Final Batch Loss: 0.029579048976302147\n",
      "Epoch 2547, Loss: 0.11740261688828468, Final Batch Loss: 0.03980795666575432\n",
      "Epoch 2548, Loss: 0.09133325889706612, Final Batch Loss: 0.051846105605363846\n",
      "Epoch 2549, Loss: 0.09809508919715881, Final Batch Loss: 0.04652383551001549\n",
      "Epoch 2550, Loss: 0.0881788320839405, Final Batch Loss: 0.06389044970273972\n",
      "Epoch 2551, Loss: 0.14786247164011002, Final Batch Loss: 0.06539830565452576\n",
      "Epoch 2552, Loss: 0.11103576421737671, Final Batch Loss: 0.05968465283513069\n",
      "Epoch 2553, Loss: 0.11640017852187157, Final Batch Loss: 0.05631624907255173\n",
      "Epoch 2554, Loss: 0.10280891507863998, Final Batch Loss: 0.05040016025304794\n",
      "Epoch 2555, Loss: 0.18247388303279877, Final Batch Loss: 0.031968384981155396\n",
      "Epoch 2556, Loss: 0.10295389592647552, Final Batch Loss: 0.05316314473748207\n",
      "Epoch 2557, Loss: 0.07962911576032639, Final Batch Loss: 0.040178604423999786\n",
      "Epoch 2558, Loss: 0.08985287323594093, Final Batch Loss: 0.0569627545773983\n",
      "Epoch 2559, Loss: 0.11198234930634499, Final Batch Loss: 0.057116638869047165\n",
      "Epoch 2560, Loss: 0.1013067364692688, Final Batch Loss: 0.06615492701530457\n",
      "Epoch 2561, Loss: 0.10119154304265976, Final Batch Loss: 0.04660693556070328\n",
      "Epoch 2562, Loss: 0.09867941588163376, Final Batch Loss: 0.04204047471284866\n",
      "Epoch 2563, Loss: 0.10249745473265648, Final Batch Loss: 0.05423769727349281\n",
      "Epoch 2564, Loss: 0.08681567013263702, Final Batch Loss: 0.040074750781059265\n",
      "Epoch 2565, Loss: 0.10412697121500969, Final Batch Loss: 0.05590352043509483\n",
      "Epoch 2566, Loss: 0.07930020615458488, Final Batch Loss: 0.029864046722650528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2567, Loss: 0.12500927969813347, Final Batch Loss: 0.058224935084581375\n",
      "Epoch 2568, Loss: 0.11994398012757301, Final Batch Loss: 0.061950214207172394\n",
      "Epoch 2569, Loss: 0.09539296478033066, Final Batch Loss: 0.055391326546669006\n",
      "Epoch 2570, Loss: 0.07934199273586273, Final Batch Loss: 0.04077614098787308\n",
      "Epoch 2571, Loss: 0.06697164103388786, Final Batch Loss: 0.0376315601170063\n",
      "Epoch 2572, Loss: 0.10450467839837074, Final Batch Loss: 0.049301471561193466\n",
      "Epoch 2573, Loss: 0.11643528193235397, Final Batch Loss: 0.09175316989421844\n",
      "Epoch 2574, Loss: 0.10854465141892433, Final Batch Loss: 0.079034723341465\n",
      "Epoch 2575, Loss: 0.1466601062566042, Final Batch Loss: 0.12389041483402252\n",
      "Epoch 2576, Loss: 0.12032606452703476, Final Batch Loss: 0.06153801456093788\n",
      "Epoch 2577, Loss: 0.0803673043847084, Final Batch Loss: 0.04317057505249977\n",
      "Epoch 2578, Loss: 0.1774286851286888, Final Batch Loss: 0.08655232936143875\n",
      "Epoch 2579, Loss: 0.14910545200109482, Final Batch Loss: 0.0833401083946228\n",
      "Epoch 2580, Loss: 0.11375561729073524, Final Batch Loss: 0.03530729189515114\n",
      "Epoch 2581, Loss: 0.1218324564397335, Final Batch Loss: 0.08119990676641464\n",
      "Epoch 2582, Loss: 0.15585212409496307, Final Batch Loss: 0.07095567882061005\n",
      "Epoch 2583, Loss: 0.10832919552922249, Final Batch Loss: 0.05069046467542648\n",
      "Epoch 2584, Loss: 0.10563275776803493, Final Batch Loss: 0.030799558386206627\n",
      "Epoch 2585, Loss: 0.11582285538315773, Final Batch Loss: 0.06820260733366013\n",
      "Epoch 2586, Loss: 0.10758176445960999, Final Batch Loss: 0.04967571049928665\n",
      "Epoch 2587, Loss: 0.09350316599011421, Final Batch Loss: 0.04858386144042015\n",
      "Epoch 2588, Loss: 0.10210169479250908, Final Batch Loss: 0.05665174499154091\n",
      "Epoch 2589, Loss: 0.09774486720561981, Final Batch Loss: 0.05293497443199158\n",
      "Epoch 2590, Loss: 0.10069119557738304, Final Batch Loss: 0.05919446051120758\n",
      "Epoch 2591, Loss: 0.08801442384719849, Final Batch Loss: 0.041445039212703705\n",
      "Epoch 2592, Loss: 0.07357857562601566, Final Batch Loss: 0.024014553055167198\n",
      "Epoch 2593, Loss: 0.10187000781297684, Final Batch Loss: 0.032864779233932495\n",
      "Epoch 2594, Loss: 0.07816636934876442, Final Batch Loss: 0.04646680876612663\n",
      "Epoch 2595, Loss: 0.11257052049040794, Final Batch Loss: 0.036315854638814926\n",
      "Epoch 2596, Loss: 0.09549429081380367, Final Batch Loss: 0.06556250900030136\n",
      "Epoch 2597, Loss: 0.10198685899376869, Final Batch Loss: 0.04880437254905701\n",
      "Epoch 2598, Loss: 0.10086299106478691, Final Batch Loss: 0.04984667897224426\n",
      "Epoch 2599, Loss: 0.10670527443289757, Final Batch Loss: 0.041335027664899826\n",
      "Epoch 2600, Loss: 0.13783865794539452, Final Batch Loss: 0.07975849509239197\n",
      "Epoch 2601, Loss: 0.1330820918083191, Final Batch Loss: 0.04564706236124039\n",
      "Epoch 2602, Loss: 0.14163095131516457, Final Batch Loss: 0.05619748309254646\n",
      "Epoch 2603, Loss: 0.11786032095551491, Final Batch Loss: 0.052703533321619034\n",
      "Epoch 2604, Loss: 0.13456493988633156, Final Batch Loss: 0.04429702088236809\n",
      "Epoch 2605, Loss: 0.10709042474627495, Final Batch Loss: 0.053420525044202805\n",
      "Epoch 2606, Loss: 0.16057435423135757, Final Batch Loss: 0.05774388462305069\n",
      "Epoch 2607, Loss: 0.08075091801583767, Final Batch Loss: 0.02621578983962536\n",
      "Epoch 2608, Loss: 0.09351098909974098, Final Batch Loss: 0.03239131718873978\n",
      "Epoch 2609, Loss: 0.11637812480330467, Final Batch Loss: 0.08340246975421906\n",
      "Epoch 2610, Loss: 0.10217105597257614, Final Batch Loss: 0.054160915315151215\n",
      "Epoch 2611, Loss: 0.11362535133957863, Final Batch Loss: 0.049740422517061234\n",
      "Epoch 2612, Loss: 0.0941118486225605, Final Batch Loss: 0.04728466272354126\n",
      "Epoch 2613, Loss: 0.07382815331220627, Final Batch Loss: 0.03502009063959122\n",
      "Epoch 2614, Loss: 0.12338755279779434, Final Batch Loss: 0.06851176917552948\n",
      "Epoch 2615, Loss: 0.08363604918122292, Final Batch Loss: 0.03135213255882263\n",
      "Epoch 2616, Loss: 0.10801685228943825, Final Batch Loss: 0.04996044561266899\n",
      "Epoch 2617, Loss: 0.10553675517439842, Final Batch Loss: 0.03656087443232536\n",
      "Epoch 2618, Loss: 0.10341962799429893, Final Batch Loss: 0.07422477751970291\n",
      "Epoch 2619, Loss: 0.1242637075483799, Final Batch Loss: 0.05878755822777748\n",
      "Epoch 2620, Loss: 0.0896686501801014, Final Batch Loss: 0.04705856367945671\n",
      "Epoch 2621, Loss: 0.10204014182090759, Final Batch Loss: 0.042432185262441635\n",
      "Epoch 2622, Loss: 0.0951349139213562, Final Batch Loss: 0.036547884345054626\n",
      "Epoch 2623, Loss: 0.10421181470155716, Final Batch Loss: 0.05701081082224846\n",
      "Epoch 2624, Loss: 0.12074528634548187, Final Batch Loss: 0.07520081847906113\n",
      "Epoch 2625, Loss: 0.08177348785102367, Final Batch Loss: 0.028052890673279762\n",
      "Epoch 2626, Loss: 0.08589194715023041, Final Batch Loss: 0.058448757976293564\n",
      "Epoch 2627, Loss: 0.07992688566446304, Final Batch Loss: 0.025197219103574753\n",
      "Epoch 2628, Loss: 0.10358362272381783, Final Batch Loss: 0.0687820166349411\n",
      "Epoch 2629, Loss: 0.12628517299890518, Final Batch Loss: 0.054138459265232086\n",
      "Epoch 2630, Loss: 0.1009008139371872, Final Batch Loss: 0.03733997792005539\n",
      "Epoch 2631, Loss: 0.10209688544273376, Final Batch Loss: 0.04824351146817207\n",
      "Epoch 2632, Loss: 0.08835350349545479, Final Batch Loss: 0.034916676580905914\n",
      "Epoch 2633, Loss: 0.10330909118056297, Final Batch Loss: 0.06960169225931168\n",
      "Epoch 2634, Loss: 0.1015797033905983, Final Batch Loss: 0.04606267064809799\n",
      "Epoch 2635, Loss: 0.11105864122509956, Final Batch Loss: 0.07387960702180862\n",
      "Epoch 2636, Loss: 0.131211519241333, Final Batch Loss: 0.053153395652770996\n",
      "Epoch 2637, Loss: 0.1086479052901268, Final Batch Loss: 0.06601614505052567\n",
      "Epoch 2638, Loss: 0.14394643157720566, Final Batch Loss: 0.08131535351276398\n",
      "Epoch 2639, Loss: 0.15020442754030228, Final Batch Loss: 0.04282831400632858\n",
      "Epoch 2640, Loss: 0.10070107132196426, Final Batch Loss: 0.040201786905527115\n",
      "Epoch 2641, Loss: 0.10036640986800194, Final Batch Loss: 0.061940792948007584\n",
      "Epoch 2642, Loss: 0.09926027059555054, Final Batch Loss: 0.06675806641578674\n",
      "Epoch 2643, Loss: 0.10909390449523926, Final Batch Loss: 0.06419282406568527\n",
      "Epoch 2644, Loss: 0.09929435700178146, Final Batch Loss: 0.03858229145407677\n",
      "Epoch 2645, Loss: 0.08822938799858093, Final Batch Loss: 0.038548313081264496\n",
      "Epoch 2646, Loss: 0.15160416439175606, Final Batch Loss: 0.09296984225511551\n",
      "Epoch 2647, Loss: 0.09110448509454727, Final Batch Loss: 0.044376127421855927\n",
      "Epoch 2648, Loss: 0.09085303172469139, Final Batch Loss: 0.056142304092645645\n",
      "Epoch 2649, Loss: 0.10635080933570862, Final Batch Loss: 0.045154571533203125\n",
      "Epoch 2650, Loss: 0.11136255040764809, Final Batch Loss: 0.040633175522089005\n",
      "Epoch 2651, Loss: 0.09261132217943668, Final Batch Loss: 0.07040711492300034\n",
      "Epoch 2652, Loss: 0.1377348005771637, Final Batch Loss: 0.042521506547927856\n",
      "Epoch 2653, Loss: 0.15375704690814018, Final Batch Loss: 0.12650366127490997\n",
      "Epoch 2654, Loss: 0.13338886946439743, Final Batch Loss: 0.04927550256252289\n",
      "Epoch 2655, Loss: 0.12206446751952171, Final Batch Loss: 0.07196400314569473\n",
      "Epoch 2656, Loss: 0.10738120973110199, Final Batch Loss: 0.049066197127103806\n",
      "Epoch 2657, Loss: 0.08872191980481148, Final Batch Loss: 0.0445704348385334\n",
      "Epoch 2658, Loss: 0.09437974914908409, Final Batch Loss: 0.053002674132585526\n",
      "Epoch 2659, Loss: 0.10735326260328293, Final Batch Loss: 0.04363156855106354\n",
      "Epoch 2660, Loss: 0.09111110866069794, Final Batch Loss: 0.04724891483783722\n",
      "Epoch 2661, Loss: 0.09939858689904213, Final Batch Loss: 0.0588863380253315\n",
      "Epoch 2662, Loss: 0.0985674187541008, Final Batch Loss: 0.042735401540994644\n",
      "Epoch 2663, Loss: 0.10429083928465843, Final Batch Loss: 0.04464176297187805\n",
      "Epoch 2664, Loss: 0.0858168825507164, Final Batch Loss: 0.0465487465262413\n",
      "Epoch 2665, Loss: 0.09377852827310562, Final Batch Loss: 0.04268776252865791\n",
      "Epoch 2666, Loss: 0.10547647252678871, Final Batch Loss: 0.06776303797960281\n",
      "Epoch 2667, Loss: 0.1011902317404747, Final Batch Loss: 0.06105784326791763\n",
      "Epoch 2668, Loss: 0.09884292632341385, Final Batch Loss: 0.04614078626036644\n",
      "Epoch 2669, Loss: 0.084524966776371, Final Batch Loss: 0.05272718518972397\n",
      "Epoch 2670, Loss: 0.11686528474092484, Final Batch Loss: 0.08237484842538834\n",
      "Epoch 2671, Loss: 0.07149475440382957, Final Batch Loss: 0.0392751581966877\n",
      "Epoch 2672, Loss: 0.09035714715719223, Final Batch Loss: 0.03184913098812103\n",
      "Epoch 2673, Loss: 0.08868482708930969, Final Batch Loss: 0.03553538769483566\n",
      "Epoch 2674, Loss: 0.10310565307736397, Final Batch Loss: 0.06646720319986343\n",
      "Epoch 2675, Loss: 0.12378445640206337, Final Batch Loss: 0.03360192850232124\n",
      "Epoch 2676, Loss: 0.08958190307021141, Final Batch Loss: 0.05104168504476547\n",
      "Epoch 2677, Loss: 0.07817560061812401, Final Batch Loss: 0.03659813851118088\n",
      "Epoch 2678, Loss: 0.08851448073983192, Final Batch Loss: 0.0467866025865078\n",
      "Epoch 2679, Loss: 0.11592001467943192, Final Batch Loss: 0.05683782696723938\n",
      "Epoch 2680, Loss: 0.1344064623117447, Final Batch Loss: 0.0824873223900795\n",
      "Epoch 2681, Loss: 0.09378863871097565, Final Batch Loss: 0.05249141901731491\n",
      "Epoch 2682, Loss: 0.06937116384506226, Final Batch Loss: 0.04377538710832596\n",
      "Epoch 2683, Loss: 0.057092079892754555, Final Batch Loss: 0.025955572724342346\n",
      "Epoch 2684, Loss: 0.08379097282886505, Final Batch Loss: 0.04733596369624138\n",
      "Epoch 2685, Loss: 0.09442561492323875, Final Batch Loss: 0.03577658161520958\n",
      "Epoch 2686, Loss: 0.09206543117761612, Final Batch Loss: 0.044956762343645096\n",
      "Epoch 2687, Loss: 0.1029200591146946, Final Batch Loss: 0.04522187262773514\n",
      "Epoch 2688, Loss: 0.12024329602718353, Final Batch Loss: 0.03766410052776337\n",
      "Epoch 2689, Loss: 0.0823051668703556, Final Batch Loss: 0.040097836405038834\n",
      "Epoch 2690, Loss: 0.08741101995110512, Final Batch Loss: 0.04245366156101227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2691, Loss: 0.1577930822968483, Final Batch Loss: 0.10471882671117783\n",
      "Epoch 2692, Loss: 0.11746237799525261, Final Batch Loss: 0.05406837537884712\n",
      "Epoch 2693, Loss: 0.08998369798064232, Final Batch Loss: 0.04605557769536972\n",
      "Epoch 2694, Loss: 0.07247772067785263, Final Batch Loss: 0.035157736390829086\n",
      "Epoch 2695, Loss: 0.08930779621005058, Final Batch Loss: 0.05921171233057976\n",
      "Epoch 2696, Loss: 0.0869094654917717, Final Batch Loss: 0.03613998368382454\n",
      "Epoch 2697, Loss: 0.11771795153617859, Final Batch Loss: 0.06202147156000137\n",
      "Epoch 2698, Loss: 0.139102004468441, Final Batch Loss: 0.04255986213684082\n",
      "Epoch 2699, Loss: 0.0757066011428833, Final Batch Loss: 0.03318164870142937\n",
      "Epoch 2700, Loss: 0.11891003511846066, Final Batch Loss: 0.08834795653820038\n",
      "Epoch 2701, Loss: 0.10622269287705421, Final Batch Loss: 0.07351378351449966\n",
      "Epoch 2702, Loss: 0.09267772361636162, Final Batch Loss: 0.059509288519620895\n",
      "Epoch 2703, Loss: 0.11786960810422897, Final Batch Loss: 0.0325448140501976\n",
      "Epoch 2704, Loss: 0.08334553241729736, Final Batch Loss: 0.04321002587676048\n",
      "Epoch 2705, Loss: 0.0925474539399147, Final Batch Loss: 0.04582517221570015\n",
      "Epoch 2706, Loss: 0.08807835355401039, Final Batch Loss: 0.04941974952816963\n",
      "Epoch 2707, Loss: 0.1248837411403656, Final Batch Loss: 0.07469980418682098\n",
      "Epoch 2708, Loss: 0.08722345530986786, Final Batch Loss: 0.03164014220237732\n",
      "Epoch 2709, Loss: 0.19297323003411293, Final Batch Loss: 0.15826132893562317\n",
      "Epoch 2710, Loss: 0.07479313388466835, Final Batch Loss: 0.034501802176237106\n",
      "Epoch 2711, Loss: 0.0853055827319622, Final Batch Loss: 0.04589764401316643\n",
      "Epoch 2712, Loss: 0.13854738138616085, Final Batch Loss: 0.10797639936208725\n",
      "Epoch 2713, Loss: 0.10276958346366882, Final Batch Loss: 0.051116812974214554\n",
      "Epoch 2714, Loss: 0.11160163953900337, Final Batch Loss: 0.05091346427798271\n",
      "Epoch 2715, Loss: 0.11544948071241379, Final Batch Loss: 0.07403366267681122\n",
      "Epoch 2716, Loss: 0.10057831183075905, Final Batch Loss: 0.04808371514081955\n",
      "Epoch 2717, Loss: 0.13560759276151657, Final Batch Loss: 0.04760359227657318\n",
      "Epoch 2718, Loss: 0.09344890341162682, Final Batch Loss: 0.03294984623789787\n",
      "Epoch 2719, Loss: 0.09787442721426487, Final Batch Loss: 0.0689161941409111\n",
      "Epoch 2720, Loss: 0.09352202340960503, Final Batch Loss: 0.04046110436320305\n",
      "Epoch 2721, Loss: 0.09756190702319145, Final Batch Loss: 0.06174997240304947\n",
      "Epoch 2722, Loss: 0.13454489409923553, Final Batch Loss: 0.092464379966259\n",
      "Epoch 2723, Loss: 0.0844411589205265, Final Batch Loss: 0.051668569445610046\n",
      "Epoch 2724, Loss: 0.10455182939767838, Final Batch Loss: 0.05804170295596123\n",
      "Epoch 2725, Loss: 0.11337876692414284, Final Batch Loss: 0.07076982408761978\n",
      "Epoch 2726, Loss: 0.08749301359057426, Final Batch Loss: 0.0485994890332222\n",
      "Epoch 2727, Loss: 0.17925263196229935, Final Batch Loss: 0.1127026379108429\n",
      "Epoch 2728, Loss: 0.07722661644220352, Final Batch Loss: 0.03142562136054039\n",
      "Epoch 2729, Loss: 0.10642701387405396, Final Batch Loss: 0.050181642174720764\n",
      "Epoch 2730, Loss: 0.10505133680999279, Final Batch Loss: 0.02864461950957775\n",
      "Epoch 2731, Loss: 0.10952625796198845, Final Batch Loss: 0.056551434099674225\n",
      "Epoch 2732, Loss: 0.12690449506044388, Final Batch Loss: 0.07639848440885544\n",
      "Epoch 2733, Loss: 0.09560280665755272, Final Batch Loss: 0.041322723031044006\n",
      "Epoch 2734, Loss: 0.15360300987958908, Final Batch Loss: 0.07374011725187302\n",
      "Epoch 2735, Loss: 0.13446863740682602, Final Batch Loss: 0.07451657205820084\n",
      "Epoch 2736, Loss: 0.09881655126810074, Final Batch Loss: 0.020096510648727417\n",
      "Epoch 2737, Loss: 0.08265349268913269, Final Batch Loss: 0.026819314807653427\n",
      "Epoch 2738, Loss: 0.092515479773283, Final Batch Loss: 0.0436975434422493\n",
      "Epoch 2739, Loss: 0.0752946138381958, Final Batch Loss: 0.042625296860933304\n",
      "Epoch 2740, Loss: 0.09666657075285912, Final Batch Loss: 0.04869334027171135\n",
      "Epoch 2741, Loss: 0.07889039628207684, Final Batch Loss: 0.02247214876115322\n",
      "Epoch 2742, Loss: 0.07358530350029469, Final Batch Loss: 0.051550839096307755\n",
      "Epoch 2743, Loss: 0.09288983419537544, Final Batch Loss: 0.03700634092092514\n",
      "Epoch 2744, Loss: 0.1253923363983631, Final Batch Loss: 0.0784679502248764\n",
      "Epoch 2745, Loss: 0.10419614240527153, Final Batch Loss: 0.060946326702833176\n",
      "Epoch 2746, Loss: 0.12036261707544327, Final Batch Loss: 0.07355047017335892\n",
      "Epoch 2747, Loss: 0.11519705131649971, Final Batch Loss: 0.04483075067400932\n",
      "Epoch 2748, Loss: 0.15065867453813553, Final Batch Loss: 0.09373024106025696\n",
      "Epoch 2749, Loss: 0.08888975717127323, Final Batch Loss: 0.03099253587424755\n",
      "Epoch 2750, Loss: 0.0999736599624157, Final Batch Loss: 0.05367342010140419\n",
      "Epoch 2751, Loss: 0.08543002232909203, Final Batch Loss: 0.04629402607679367\n",
      "Epoch 2752, Loss: 0.11531830951571465, Final Batch Loss: 0.03207625076174736\n",
      "Epoch 2753, Loss: 0.10298054292798042, Final Batch Loss: 0.06072904169559479\n",
      "Epoch 2754, Loss: 0.07928599789738655, Final Batch Loss: 0.04318251833319664\n",
      "Epoch 2755, Loss: 0.1197371706366539, Final Batch Loss: 0.07560074329376221\n",
      "Epoch 2756, Loss: 0.10043884441256523, Final Batch Loss: 0.056198716163635254\n",
      "Epoch 2757, Loss: 0.10664445906877518, Final Batch Loss: 0.06962493807077408\n",
      "Epoch 2758, Loss: 0.1048039011657238, Final Batch Loss: 0.04323633015155792\n",
      "Epoch 2759, Loss: 0.06967201828956604, Final Batch Loss: 0.0371161624789238\n",
      "Epoch 2760, Loss: 0.07386944442987442, Final Batch Loss: 0.043371569365262985\n",
      "Epoch 2761, Loss: 0.07779180258512497, Final Batch Loss: 0.030138134956359863\n",
      "Epoch 2762, Loss: 0.08893011137843132, Final Batch Loss: 0.021017063409090042\n",
      "Epoch 2763, Loss: 0.09133106470108032, Final Batch Loss: 0.043036047369241714\n",
      "Epoch 2764, Loss: 0.06468373723328114, Final Batch Loss: 0.019538497552275658\n",
      "Epoch 2765, Loss: 0.07725225575268269, Final Batch Loss: 0.024527350440621376\n",
      "Epoch 2766, Loss: 0.07303066365420818, Final Batch Loss: 0.023588793352246284\n",
      "Epoch 2767, Loss: 0.07406448572874069, Final Batch Loss: 0.03313693404197693\n",
      "Epoch 2768, Loss: 0.08468446880578995, Final Batch Loss: 0.03720073401927948\n",
      "Epoch 2769, Loss: 0.08346048556268215, Final Batch Loss: 0.026728851720690727\n",
      "Epoch 2770, Loss: 0.09700004011392593, Final Batch Loss: 0.03192552924156189\n",
      "Epoch 2771, Loss: 0.11463650688529015, Final Batch Loss: 0.049501288682222366\n",
      "Epoch 2772, Loss: 0.08611129224300385, Final Batch Loss: 0.03844620659947395\n",
      "Epoch 2773, Loss: 0.08355218172073364, Final Batch Loss: 0.033433619886636734\n",
      "Epoch 2774, Loss: 0.08291367813944817, Final Batch Loss: 0.04347095265984535\n",
      "Epoch 2775, Loss: 0.13274506852030754, Final Batch Loss: 0.03578323498368263\n",
      "Epoch 2776, Loss: 0.0650671236217022, Final Batch Loss: 0.03559231385588646\n",
      "Epoch 2777, Loss: 0.06858808733522892, Final Batch Loss: 0.02666301839053631\n",
      "Epoch 2778, Loss: 0.09549926966428757, Final Batch Loss: 0.04419304430484772\n",
      "Epoch 2779, Loss: 0.08440100960433483, Final Batch Loss: 0.030593620613217354\n",
      "Epoch 2780, Loss: 0.07761226408183575, Final Batch Loss: 0.021225372329354286\n",
      "Epoch 2781, Loss: 0.1269846335053444, Final Batch Loss: 0.09203136712312698\n",
      "Epoch 2782, Loss: 0.08467122539877892, Final Batch Loss: 0.04432542622089386\n",
      "Epoch 2783, Loss: 0.11381490156054497, Final Batch Loss: 0.05480877310037613\n",
      "Epoch 2784, Loss: 0.09031393378973007, Final Batch Loss: 0.04446597769856453\n",
      "Epoch 2785, Loss: 0.0794869028031826, Final Batch Loss: 0.04407813027501106\n",
      "Epoch 2786, Loss: 0.0915238969027996, Final Batch Loss: 0.04492419585585594\n",
      "Epoch 2787, Loss: 0.0804830864071846, Final Batch Loss: 0.04971592128276825\n",
      "Epoch 2788, Loss: 0.0967859411612153, Final Batch Loss: 0.08280220627784729\n",
      "Epoch 2789, Loss: 0.08804484084248543, Final Batch Loss: 0.039769887924194336\n",
      "Epoch 2790, Loss: 0.09923514723777771, Final Batch Loss: 0.04662321135401726\n",
      "Epoch 2791, Loss: 0.07648923620581627, Final Batch Loss: 0.042430199682712555\n",
      "Epoch 2792, Loss: 0.09097713977098465, Final Batch Loss: 0.05004977062344551\n",
      "Epoch 2793, Loss: 0.07395701110363007, Final Batch Loss: 0.031738605350255966\n",
      "Epoch 2794, Loss: 0.062055014073848724, Final Batch Loss: 0.033756572753190994\n",
      "Epoch 2795, Loss: 0.08347326889634132, Final Batch Loss: 0.02080930396914482\n",
      "Epoch 2796, Loss: 0.10638641193509102, Final Batch Loss: 0.03439191356301308\n",
      "Epoch 2797, Loss: 0.07476779818534851, Final Batch Loss: 0.042457353323698044\n",
      "Epoch 2798, Loss: 0.11002729460597038, Final Batch Loss: 0.05577262118458748\n",
      "Epoch 2799, Loss: 0.10826738551259041, Final Batch Loss: 0.03922130540013313\n",
      "Epoch 2800, Loss: 0.08430441841483116, Final Batch Loss: 0.0428745336830616\n",
      "Epoch 2801, Loss: 0.11084089055657387, Final Batch Loss: 0.05278819426894188\n",
      "Epoch 2802, Loss: 0.08273287862539291, Final Batch Loss: 0.04008099436759949\n",
      "Epoch 2803, Loss: 0.0927312895655632, Final Batch Loss: 0.05131998658180237\n",
      "Epoch 2804, Loss: 0.08973906561732292, Final Batch Loss: 0.03572516515851021\n",
      "Epoch 2805, Loss: 0.10466241650283337, Final Batch Loss: 0.023306196555495262\n",
      "Epoch 2806, Loss: 0.07278671115636826, Final Batch Loss: 0.031105630099773407\n",
      "Epoch 2807, Loss: 0.06725934520363808, Final Batch Loss: 0.028277691453695297\n",
      "Epoch 2808, Loss: 0.08110962063074112, Final Batch Loss: 0.030741240829229355\n",
      "Epoch 2809, Loss: 0.09923499822616577, Final Batch Loss: 0.06662637740373611\n",
      "Epoch 2810, Loss: 0.0670541450381279, Final Batch Loss: 0.046736110001802444\n",
      "Epoch 2811, Loss: 0.10169478505849838, Final Batch Loss: 0.03848449885845184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2812, Loss: 0.059549881145358086, Final Batch Loss: 0.02220945991575718\n",
      "Epoch 2813, Loss: 0.1218218170106411, Final Batch Loss: 0.051170263439416885\n",
      "Epoch 2814, Loss: 0.10983513295650482, Final Batch Loss: 0.06255695223808289\n",
      "Epoch 2815, Loss: 0.08577007800340652, Final Batch Loss: 0.03577447310090065\n",
      "Epoch 2816, Loss: 0.08246368169784546, Final Batch Loss: 0.05426992103457451\n",
      "Epoch 2817, Loss: 0.10832270234823227, Final Batch Loss: 0.06991494446992874\n",
      "Epoch 2818, Loss: 0.09745734184980392, Final Batch Loss: 0.0467592254281044\n",
      "Epoch 2819, Loss: 0.07806752994656563, Final Batch Loss: 0.03622385859489441\n",
      "Epoch 2820, Loss: 0.09140988066792488, Final Batch Loss: 0.046190712600946426\n",
      "Epoch 2821, Loss: 0.11205470561981201, Final Batch Loss: 0.07955040782690048\n",
      "Epoch 2822, Loss: 0.09020060673356056, Final Batch Loss: 0.03622424229979515\n",
      "Epoch 2823, Loss: 0.07181688584387302, Final Batch Loss: 0.041756898164749146\n",
      "Epoch 2824, Loss: 0.07256448641419411, Final Batch Loss: 0.04178251698613167\n",
      "Epoch 2825, Loss: 0.09681010618805885, Final Batch Loss: 0.022374119609594345\n",
      "Epoch 2826, Loss: 0.09955933690071106, Final Batch Loss: 0.043407995253801346\n",
      "Epoch 2827, Loss: 0.08382660150527954, Final Batch Loss: 0.04924839735031128\n",
      "Epoch 2828, Loss: 0.07721503265202045, Final Batch Loss: 0.022642681375145912\n",
      "Epoch 2829, Loss: 0.0901644341647625, Final Batch Loss: 0.05556987598538399\n",
      "Epoch 2830, Loss: 0.10533416643738747, Final Batch Loss: 0.063425213098526\n",
      "Epoch 2831, Loss: 0.1137777641415596, Final Batch Loss: 0.06805729866027832\n",
      "Epoch 2832, Loss: 0.14071012660861015, Final Batch Loss: 0.057231586426496506\n",
      "Epoch 2833, Loss: 0.07828529924154282, Final Batch Loss: 0.049452099949121475\n",
      "Epoch 2834, Loss: 0.11884519457817078, Final Batch Loss: 0.046478912234306335\n",
      "Epoch 2835, Loss: 0.09506160765886307, Final Batch Loss: 0.036189813166856766\n",
      "Epoch 2836, Loss: 0.08717569336295128, Final Batch Loss: 0.04038998857140541\n",
      "Epoch 2837, Loss: 0.07747307792305946, Final Batch Loss: 0.03426133096218109\n",
      "Epoch 2838, Loss: 0.07787885889410973, Final Batch Loss: 0.03689960017800331\n",
      "Epoch 2839, Loss: 0.12020790204405785, Final Batch Loss: 0.05152922496199608\n",
      "Epoch 2840, Loss: 0.14776020869612694, Final Batch Loss: 0.05181228742003441\n",
      "Epoch 2841, Loss: 0.13950351253151894, Final Batch Loss: 0.09918403625488281\n",
      "Epoch 2842, Loss: 0.08294432237744331, Final Batch Loss: 0.031077206134796143\n",
      "Epoch 2843, Loss: 0.0828404426574707, Final Batch Loss: 0.040830835700035095\n",
      "Epoch 2844, Loss: 0.10919983312487602, Final Batch Loss: 0.07571907341480255\n",
      "Epoch 2845, Loss: 0.10402407497167587, Final Batch Loss: 0.040436357259750366\n",
      "Epoch 2846, Loss: 0.08019554428756237, Final Batch Loss: 0.020487597212195396\n",
      "Epoch 2847, Loss: 0.10831745713949203, Final Batch Loss: 0.03986138105392456\n",
      "Epoch 2848, Loss: 0.09866797551512718, Final Batch Loss: 0.058169908821582794\n",
      "Epoch 2849, Loss: 0.10412026941776276, Final Batch Loss: 0.05024271085858345\n",
      "Epoch 2850, Loss: 0.11342218518257141, Final Batch Loss: 0.05989440530538559\n",
      "Epoch 2851, Loss: 0.0729830451309681, Final Batch Loss: 0.04171980544924736\n",
      "Epoch 2852, Loss: 0.13725287839770317, Final Batch Loss: 0.03756586089730263\n",
      "Epoch 2853, Loss: 0.10157069191336632, Final Batch Loss: 0.03993615508079529\n",
      "Epoch 2854, Loss: 0.09017127379775047, Final Batch Loss: 0.03802569955587387\n",
      "Epoch 2855, Loss: 0.08106083050370216, Final Batch Loss: 0.04654297977685928\n",
      "Epoch 2856, Loss: 0.07903943583369255, Final Batch Loss: 0.046118710190057755\n",
      "Epoch 2857, Loss: 0.09382117167115211, Final Batch Loss: 0.056718409061431885\n",
      "Epoch 2858, Loss: 0.08134782314300537, Final Batch Loss: 0.02899356186389923\n",
      "Epoch 2859, Loss: 0.07157652080059052, Final Batch Loss: 0.041297104209661484\n",
      "Epoch 2860, Loss: 0.10009097680449486, Final Batch Loss: 0.0447801798582077\n",
      "Epoch 2861, Loss: 0.0999705083668232, Final Batch Loss: 0.046708546578884125\n",
      "Epoch 2862, Loss: 0.12089802697300911, Final Batch Loss: 0.04625502601265907\n",
      "Epoch 2863, Loss: 0.13097638078033924, Final Batch Loss: 0.02922702021896839\n",
      "Epoch 2864, Loss: 0.1065700463950634, Final Batch Loss: 0.06349708139896393\n",
      "Epoch 2865, Loss: 0.08988114073872566, Final Batch Loss: 0.043111834675073624\n",
      "Epoch 2866, Loss: 0.07730568572878838, Final Batch Loss: 0.03352775052189827\n",
      "Epoch 2867, Loss: 0.09247573092579842, Final Batch Loss: 0.036640990525484085\n",
      "Epoch 2868, Loss: 0.09173727594316006, Final Batch Loss: 0.031040797010064125\n",
      "Epoch 2869, Loss: 0.0908893309533596, Final Batch Loss: 0.05013206601142883\n",
      "Epoch 2870, Loss: 0.08441509678959846, Final Batch Loss: 0.06014755740761757\n",
      "Epoch 2871, Loss: 0.08456742577254772, Final Batch Loss: 0.05530557781457901\n",
      "Epoch 2872, Loss: 0.08369165286421776, Final Batch Loss: 0.04146844521164894\n",
      "Epoch 2873, Loss: 0.07432946190237999, Final Batch Loss: 0.030569497495889664\n",
      "Epoch 2874, Loss: 0.09929849579930305, Final Batch Loss: 0.05696769431233406\n",
      "Epoch 2875, Loss: 0.08550999313592911, Final Batch Loss: 0.02456580474972725\n",
      "Epoch 2876, Loss: 0.07513920590281487, Final Batch Loss: 0.04908763989806175\n",
      "Epoch 2877, Loss: 0.11461525037884712, Final Batch Loss: 0.0733383521437645\n",
      "Epoch 2878, Loss: 0.07518680393695831, Final Batch Loss: 0.04037062078714371\n",
      "Epoch 2879, Loss: 0.09084785729646683, Final Batch Loss: 0.05124304071068764\n",
      "Epoch 2880, Loss: 0.12870549596846104, Final Batch Loss: 0.030941011384129524\n",
      "Epoch 2881, Loss: 0.09233736619353294, Final Batch Loss: 0.040657784789800644\n",
      "Epoch 2882, Loss: 0.08980653807520866, Final Batch Loss: 0.04313848540186882\n",
      "Epoch 2883, Loss: 0.14247851073741913, Final Batch Loss: 0.09288535267114639\n",
      "Epoch 2884, Loss: 0.09651142731308937, Final Batch Loss: 0.029093865305185318\n",
      "Epoch 2885, Loss: 0.11230390518903732, Final Batch Loss: 0.04722468554973602\n",
      "Epoch 2886, Loss: 0.09389852359890938, Final Batch Loss: 0.03725002706050873\n",
      "Epoch 2887, Loss: 0.07919837348163128, Final Batch Loss: 0.030520623549818993\n",
      "Epoch 2888, Loss: 0.14545625820755959, Final Batch Loss: 0.09448620676994324\n",
      "Epoch 2889, Loss: 0.09133057668805122, Final Batch Loss: 0.05148229002952576\n",
      "Epoch 2890, Loss: 0.14135200902819633, Final Batch Loss: 0.050040435045957565\n",
      "Epoch 2891, Loss: 0.11750152707099915, Final Batch Loss: 0.044697947800159454\n",
      "Epoch 2892, Loss: 0.11332350224256516, Final Batch Loss: 0.04513498395681381\n",
      "Epoch 2893, Loss: 0.07174600660800934, Final Batch Loss: 0.03145671263337135\n",
      "Epoch 2894, Loss: 0.09483419358730316, Final Batch Loss: 0.047092195600271225\n",
      "Epoch 2895, Loss: 0.0611959807574749, Final Batch Loss: 0.01940777152776718\n",
      "Epoch 2896, Loss: 0.10450323298573494, Final Batch Loss: 0.06581227481365204\n",
      "Epoch 2897, Loss: 0.11229577660560608, Final Batch Loss: 0.0505162812769413\n",
      "Epoch 2898, Loss: 0.0948714055120945, Final Batch Loss: 0.03542514145374298\n",
      "Epoch 2899, Loss: 0.07946107536554337, Final Batch Loss: 0.03767763450741768\n",
      "Epoch 2900, Loss: 0.12067156657576561, Final Batch Loss: 0.07171791046857834\n",
      "Epoch 2901, Loss: 0.07744058407843113, Final Batch Loss: 0.025246093049645424\n",
      "Epoch 2902, Loss: 0.07911328040063381, Final Batch Loss: 0.024855898693203926\n",
      "Epoch 2903, Loss: 0.09692756086587906, Final Batch Loss: 0.03402141481637955\n",
      "Epoch 2904, Loss: 0.08759910240769386, Final Batch Loss: 0.052850931882858276\n",
      "Epoch 2905, Loss: 0.08162080496549606, Final Batch Loss: 0.045465826988220215\n",
      "Epoch 2906, Loss: 0.18877458572387695, Final Batch Loss: 0.10094805806875229\n",
      "Epoch 2907, Loss: 0.18824918568134308, Final Batch Loss: 0.12415572255849838\n",
      "Epoch 2908, Loss: 0.1644037775695324, Final Batch Loss: 0.027627374976873398\n",
      "Epoch 2909, Loss: 0.09650621190667152, Final Batch Loss: 0.057977546006441116\n",
      "Epoch 2910, Loss: 0.07906518690288067, Final Batch Loss: 0.05130083113908768\n",
      "Epoch 2911, Loss: 0.0711316168308258, Final Batch Loss: 0.033130936324596405\n",
      "Epoch 2912, Loss: 0.08184120059013367, Final Batch Loss: 0.03513076528906822\n",
      "Epoch 2913, Loss: 0.08594832941889763, Final Batch Loss: 0.04960724711418152\n",
      "Epoch 2914, Loss: 0.0859672911465168, Final Batch Loss: 0.030590254813432693\n",
      "Epoch 2915, Loss: 0.08013279736042023, Final Batch Loss: 0.04262783005833626\n",
      "Epoch 2916, Loss: 0.07901239395141602, Final Batch Loss: 0.04255696013569832\n",
      "Epoch 2917, Loss: 0.1347651183605194, Final Batch Loss: 0.06930102407932281\n",
      "Epoch 2918, Loss: 0.06951302103698254, Final Batch Loss: 0.027729520574212074\n",
      "Epoch 2919, Loss: 0.10601084679365158, Final Batch Loss: 0.05948392301797867\n",
      "Epoch 2920, Loss: 0.07715064659714699, Final Batch Loss: 0.03504064306616783\n",
      "Epoch 2921, Loss: 0.10037888213992119, Final Batch Loss: 0.033882539719343185\n",
      "Epoch 2922, Loss: 0.11402299627661705, Final Batch Loss: 0.03704245015978813\n",
      "Epoch 2923, Loss: 0.08453807234764099, Final Batch Loss: 0.04008738324046135\n",
      "Epoch 2924, Loss: 0.10008596628904343, Final Batch Loss: 0.0342683345079422\n",
      "Epoch 2925, Loss: 0.07904622703790665, Final Batch Loss: 0.04652249440550804\n",
      "Epoch 2926, Loss: 0.13487546145915985, Final Batch Loss: 0.0899069681763649\n",
      "Epoch 2927, Loss: 0.08296094834804535, Final Batch Loss: 0.047251176089048386\n",
      "Epoch 2928, Loss: 0.07270361669361591, Final Batch Loss: 0.019656898453831673\n",
      "Epoch 2929, Loss: 0.07978583686053753, Final Batch Loss: 0.05333760008215904\n",
      "Epoch 2930, Loss: 0.09774491935968399, Final Batch Loss: 0.07365874201059341\n",
      "Epoch 2931, Loss: 0.07600797712802887, Final Batch Loss: 0.03960706293582916\n",
      "Epoch 2932, Loss: 0.10457082465291023, Final Batch Loss: 0.04378081485629082\n",
      "Epoch 2933, Loss: 0.08658964559435844, Final Batch Loss: 0.04803217947483063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2934, Loss: 0.11951665580272675, Final Batch Loss: 0.057847633957862854\n",
      "Epoch 2935, Loss: 0.11402076110243797, Final Batch Loss: 0.05051838979125023\n",
      "Epoch 2936, Loss: 0.08520719036459923, Final Batch Loss: 0.04767463356256485\n",
      "Epoch 2937, Loss: 0.08852223120629787, Final Batch Loss: 0.028484730049967766\n",
      "Epoch 2938, Loss: 0.08745291084051132, Final Batch Loss: 0.042227670550346375\n",
      "Epoch 2939, Loss: 0.13039379194378853, Final Batch Loss: 0.08628270030021667\n",
      "Epoch 2940, Loss: 0.09462920390069485, Final Batch Loss: 0.020958079025149345\n",
      "Epoch 2941, Loss: 0.12123529985547066, Final Batch Loss: 0.08356145024299622\n",
      "Epoch 2942, Loss: 0.06752962060272694, Final Batch Loss: 0.044390663504600525\n",
      "Epoch 2943, Loss: 0.1105608269572258, Final Batch Loss: 0.0681171640753746\n",
      "Epoch 2944, Loss: 0.10748013481497765, Final Batch Loss: 0.025208067148923874\n",
      "Epoch 2945, Loss: 0.07964100688695908, Final Batch Loss: 0.04499724879860878\n",
      "Epoch 2946, Loss: 0.08414430543780327, Final Batch Loss: 0.04259411245584488\n",
      "Epoch 2947, Loss: 0.08917311951518059, Final Batch Loss: 0.04706083983182907\n",
      "Epoch 2948, Loss: 0.2339499369263649, Final Batch Loss: 0.1266254484653473\n",
      "Epoch 2949, Loss: 0.11769658699631691, Final Batch Loss: 0.08340826630592346\n",
      "Epoch 2950, Loss: 0.09859900362789631, Final Batch Loss: 0.06763117015361786\n",
      "Epoch 2951, Loss: 0.06424508988857269, Final Batch Loss: 0.0315297469496727\n",
      "Epoch 2952, Loss: 0.1020720973610878, Final Batch Loss: 0.06384985893964767\n",
      "Epoch 2953, Loss: 0.07320536673069, Final Batch Loss: 0.02730896696448326\n",
      "Epoch 2954, Loss: 0.08753305859863758, Final Batch Loss: 0.031238598749041557\n",
      "Epoch 2955, Loss: 0.09427520632743835, Final Batch Loss: 0.047950588166713715\n",
      "Epoch 2956, Loss: 0.09795187041163445, Final Batch Loss: 0.035332780331373215\n",
      "Epoch 2957, Loss: 0.08114952594041824, Final Batch Loss: 0.023873507976531982\n",
      "Epoch 2958, Loss: 0.09854219108819962, Final Batch Loss: 0.04452949017286301\n",
      "Epoch 2959, Loss: 0.07987627759575844, Final Batch Loss: 0.04732026532292366\n",
      "Epoch 2960, Loss: 0.10435985028743744, Final Batch Loss: 0.056726522743701935\n",
      "Epoch 2961, Loss: 0.08002296276390553, Final Batch Loss: 0.030380597338080406\n",
      "Epoch 2962, Loss: 0.05226845666766167, Final Batch Loss: 0.023852568119764328\n",
      "Epoch 2963, Loss: 0.08197564259171486, Final Batch Loss: 0.04498344659805298\n",
      "Epoch 2964, Loss: 0.06288667023181915, Final Batch Loss: 0.020092356950044632\n",
      "Epoch 2965, Loss: 0.08719108998775482, Final Batch Loss: 0.04828045517206192\n",
      "Epoch 2966, Loss: 0.09247485920786858, Final Batch Loss: 0.05877061188220978\n",
      "Epoch 2967, Loss: 0.1249212697148323, Final Batch Loss: 0.08130553364753723\n",
      "Epoch 2968, Loss: 0.08196292817592621, Final Batch Loss: 0.04563445970416069\n",
      "Epoch 2969, Loss: 0.07735056430101395, Final Batch Loss: 0.038980625569820404\n",
      "Epoch 2970, Loss: 0.08462641015648842, Final Batch Loss: 0.04024667665362358\n",
      "Epoch 2971, Loss: 0.08504711091518402, Final Batch Loss: 0.038889575749635696\n",
      "Epoch 2972, Loss: 0.10484654083848, Final Batch Loss: 0.06419464945793152\n",
      "Epoch 2973, Loss: 0.07255078479647636, Final Batch Loss: 0.04728494957089424\n",
      "Epoch 2974, Loss: 0.10875485092401505, Final Batch Loss: 0.04060295224189758\n",
      "Epoch 2975, Loss: 0.08067374303936958, Final Batch Loss: 0.029040571302175522\n",
      "Epoch 2976, Loss: 0.08914443105459213, Final Batch Loss: 0.05166539177298546\n",
      "Epoch 2977, Loss: 0.11409629508852959, Final Batch Loss: 0.06060774251818657\n",
      "Epoch 2978, Loss: 0.08888457715511322, Final Batch Loss: 0.03321859985589981\n",
      "Epoch 2979, Loss: 0.06109604239463806, Final Batch Loss: 0.033035025000572205\n",
      "Epoch 2980, Loss: 0.09876568056643009, Final Batch Loss: 0.07843808084726334\n",
      "Epoch 2981, Loss: 0.08695231936872005, Final Batch Loss: 0.05815088748931885\n",
      "Epoch 2982, Loss: 0.10112908110022545, Final Batch Loss: 0.04645831137895584\n",
      "Epoch 2983, Loss: 0.09865815937519073, Final Batch Loss: 0.05018429458141327\n",
      "Epoch 2984, Loss: 0.09447889775037766, Final Batch Loss: 0.053938910365104675\n",
      "Epoch 2985, Loss: 0.07552345842123032, Final Batch Loss: 0.03978193551301956\n",
      "Epoch 2986, Loss: 0.14697294309735298, Final Batch Loss: 0.05607365444302559\n",
      "Epoch 2987, Loss: 0.12049943581223488, Final Batch Loss: 0.04697418585419655\n",
      "Epoch 2988, Loss: 0.14759105071425438, Final Batch Loss: 0.09819067269563675\n",
      "Epoch 2989, Loss: 0.10263670608401299, Final Batch Loss: 0.038010891526937485\n",
      "Epoch 2990, Loss: 0.13088803365826607, Final Batch Loss: 0.07319290190935135\n",
      "Epoch 2991, Loss: 0.11634084582328796, Final Batch Loss: 0.04507933557033539\n",
      "Epoch 2992, Loss: 0.09583819657564163, Final Batch Loss: 0.04634609445929527\n",
      "Epoch 2993, Loss: 0.11525853350758553, Final Batch Loss: 0.07459303736686707\n",
      "Epoch 2994, Loss: 0.0964067243039608, Final Batch Loss: 0.033614981919527054\n",
      "Epoch 2995, Loss: 0.07899693213403225, Final Batch Loss: 0.04798553138971329\n",
      "Epoch 2996, Loss: 0.09126272797584534, Final Batch Loss: 0.037093617022037506\n",
      "Epoch 2997, Loss: 0.09396054968237877, Final Batch Loss: 0.05921745300292969\n",
      "Epoch 2998, Loss: 0.08284720778465271, Final Batch Loss: 0.04142313823103905\n",
      "Epoch 2999, Loss: 0.09519683755934238, Final Batch Loss: 0.06866339594125748\n",
      "Epoch 3000, Loss: 0.0823862012475729, Final Batch Loss: 0.052883949130773544\n",
      "Epoch 3001, Loss: 0.10931465774774551, Final Batch Loss: 0.07610081136226654\n",
      "Epoch 3002, Loss: 0.11282075569033623, Final Batch Loss: 0.052695002406835556\n",
      "Epoch 3003, Loss: 0.0961964800953865, Final Batch Loss: 0.056608896702528\n",
      "Epoch 3004, Loss: 0.08265344798564911, Final Batch Loss: 0.05230603739619255\n",
      "Epoch 3005, Loss: 0.08549157530069351, Final Batch Loss: 0.05182614549994469\n",
      "Epoch 3006, Loss: 0.10125729814171791, Final Batch Loss: 0.05919713154435158\n",
      "Epoch 3007, Loss: 0.0835115909576416, Final Batch Loss: 0.037511102855205536\n",
      "Epoch 3008, Loss: 0.08892469853162766, Final Batch Loss: 0.047157254070043564\n",
      "Epoch 3009, Loss: 0.09726053476333618, Final Batch Loss: 0.03963036835193634\n",
      "Epoch 3010, Loss: 0.12739139422774315, Final Batch Loss: 0.03748294338583946\n",
      "Epoch 3011, Loss: 0.0886765904724598, Final Batch Loss: 0.050014227628707886\n",
      "Epoch 3012, Loss: 0.1071290485560894, Final Batch Loss: 0.06432302296161652\n",
      "Epoch 3013, Loss: 0.06962100975215435, Final Batch Loss: 0.02636338211596012\n",
      "Epoch 3014, Loss: 0.09535441175103188, Final Batch Loss: 0.04906954616308212\n",
      "Epoch 3015, Loss: 0.0784028172492981, Final Batch Loss: 0.03872322291135788\n",
      "Epoch 3016, Loss: 0.08239189721643925, Final Batch Loss: 0.028857940807938576\n",
      "Epoch 3017, Loss: 0.08973247930407524, Final Batch Loss: 0.04790571331977844\n",
      "Epoch 3018, Loss: 0.10058924183249474, Final Batch Loss: 0.051861781626939774\n",
      "Epoch 3019, Loss: 0.09796442463994026, Final Batch Loss: 0.05409673601388931\n",
      "Epoch 3020, Loss: 0.06545479968190193, Final Batch Loss: 0.03375733271241188\n",
      "Epoch 3021, Loss: 0.09264107421040535, Final Batch Loss: 0.04258529096841812\n",
      "Epoch 3022, Loss: 0.09372297488152981, Final Batch Loss: 0.025743385776877403\n",
      "Epoch 3023, Loss: 0.08599738776683807, Final Batch Loss: 0.04895177483558655\n",
      "Epoch 3024, Loss: 0.09324634075164795, Final Batch Loss: 0.04666191712021828\n",
      "Epoch 3025, Loss: 0.09322670847177505, Final Batch Loss: 0.05879499018192291\n",
      "Epoch 3026, Loss: 0.08346155285835266, Final Batch Loss: 0.04629988223314285\n",
      "Epoch 3027, Loss: 0.14223241433501244, Final Batch Loss: 0.10389453172683716\n",
      "Epoch 3028, Loss: 0.08068671077489853, Final Batch Loss: 0.04017467796802521\n",
      "Epoch 3029, Loss: 0.08102407678961754, Final Batch Loss: 0.04076175019145012\n",
      "Epoch 3030, Loss: 0.10058104246854782, Final Batch Loss: 0.07649752497673035\n",
      "Epoch 3031, Loss: 0.07352327927947044, Final Batch Loss: 0.035004306584596634\n",
      "Epoch 3032, Loss: 0.07962323725223541, Final Batch Loss: 0.03537498414516449\n",
      "Epoch 3033, Loss: 0.13200807943940163, Final Batch Loss: 0.031746525317430496\n",
      "Epoch 3034, Loss: 0.09176339954137802, Final Batch Loss: 0.05302334204316139\n",
      "Epoch 3035, Loss: 0.09894540160894394, Final Batch Loss: 0.03381863236427307\n",
      "Epoch 3036, Loss: 0.07964029908180237, Final Batch Loss: 0.03483060374855995\n",
      "Epoch 3037, Loss: 0.11316719651222229, Final Batch Loss: 0.051933400332927704\n",
      "Epoch 3038, Loss: 0.09631114825606346, Final Batch Loss: 0.04875276982784271\n",
      "Epoch 3039, Loss: 0.08883035555481911, Final Batch Loss: 0.04579157009720802\n",
      "Epoch 3040, Loss: 0.10498589649796486, Final Batch Loss: 0.05405409261584282\n",
      "Epoch 3041, Loss: 0.09309893101453781, Final Batch Loss: 0.0642779991030693\n",
      "Epoch 3042, Loss: 0.06788375787436962, Final Batch Loss: 0.028958996757864952\n",
      "Epoch 3043, Loss: 0.11355378851294518, Final Batch Loss: 0.07274316996335983\n",
      "Epoch 3044, Loss: 0.066911106929183, Final Batch Loss: 0.022893356159329414\n",
      "Epoch 3045, Loss: 0.12400900013744831, Final Batch Loss: 0.0991203784942627\n",
      "Epoch 3046, Loss: 0.10964151844382286, Final Batch Loss: 0.06382808089256287\n",
      "Epoch 3047, Loss: 0.11894743889570236, Final Batch Loss: 0.05562080442905426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3048, Loss: 0.1064266636967659, Final Batch Loss: 0.051316600292921066\n",
      "Epoch 3049, Loss: 0.09447566419839859, Final Batch Loss: 0.05032274127006531\n",
      "Epoch 3050, Loss: 0.11619736067950726, Final Batch Loss: 0.02655925415456295\n",
      "Epoch 3051, Loss: 0.12430980429053307, Final Batch Loss: 0.06516529619693756\n",
      "Epoch 3052, Loss: 0.08712280914187431, Final Batch Loss: 0.03394339233636856\n",
      "Epoch 3053, Loss: 0.09289507567882538, Final Batch Loss: 0.047119785100221634\n",
      "Epoch 3054, Loss: 0.12942279875278473, Final Batch Loss: 0.06599898636341095\n",
      "Epoch 3055, Loss: 0.08248457498848438, Final Batch Loss: 0.05577683821320534\n",
      "Epoch 3056, Loss: 0.08058054372668266, Final Batch Loss: 0.03825667127966881\n",
      "Epoch 3057, Loss: 0.09012075886130333, Final Batch Loss: 0.05317848548293114\n",
      "Epoch 3058, Loss: 0.08683989569544792, Final Batch Loss: 0.022909600287675858\n",
      "Epoch 3059, Loss: 0.08501171320676804, Final Batch Loss: 0.03886847943067551\n",
      "Epoch 3060, Loss: 0.09701137244701385, Final Batch Loss: 0.04194500669836998\n",
      "Epoch 3061, Loss: 0.1278129145503044, Final Batch Loss: 0.0924762636423111\n",
      "Epoch 3062, Loss: 0.10571373626589775, Final Batch Loss: 0.04340901970863342\n",
      "Epoch 3063, Loss: 0.09225574135780334, Final Batch Loss: 0.03772405534982681\n",
      "Epoch 3064, Loss: 0.1251743845641613, Final Batch Loss: 0.03885066136717796\n",
      "Epoch 3065, Loss: 0.09693653881549835, Final Batch Loss: 0.0373300276696682\n",
      "Epoch 3066, Loss: 0.07204621843993664, Final Batch Loss: 0.02667037956416607\n",
      "Epoch 3067, Loss: 0.08773799240589142, Final Batch Loss: 0.05290401354432106\n",
      "Epoch 3068, Loss: 0.08802507817745209, Final Batch Loss: 0.0259111188352108\n",
      "Epoch 3069, Loss: 0.10315606743097305, Final Batch Loss: 0.04449144005775452\n",
      "Epoch 3070, Loss: 0.09601939842104912, Final Batch Loss: 0.05878939479589462\n",
      "Epoch 3071, Loss: 0.08563366159796715, Final Batch Loss: 0.035800546407699585\n",
      "Epoch 3072, Loss: 0.08797905966639519, Final Batch Loss: 0.04084407910704613\n",
      "Epoch 3073, Loss: 0.08808668702840805, Final Batch Loss: 0.05890867859125137\n",
      "Epoch 3074, Loss: 0.11136701330542564, Final Batch Loss: 0.06907012313604355\n",
      "Epoch 3075, Loss: 0.07175596989691257, Final Batch Loss: 0.041143856942653656\n",
      "Epoch 3076, Loss: 0.07658356800675392, Final Batch Loss: 0.03844447433948517\n",
      "Epoch 3077, Loss: 0.0735747218132019, Final Batch Loss: 0.038330622017383575\n",
      "Epoch 3078, Loss: 0.08809956908226013, Final Batch Loss: 0.04826882854104042\n",
      "Epoch 3079, Loss: 0.12111872807145119, Final Batch Loss: 0.07705612480640411\n",
      "Epoch 3080, Loss: 0.08461573719978333, Final Batch Loss: 0.05163523182272911\n",
      "Epoch 3081, Loss: 0.08661407604813576, Final Batch Loss: 0.04453688859939575\n",
      "Epoch 3082, Loss: 0.09663558378815651, Final Batch Loss: 0.057833291590213776\n",
      "Epoch 3083, Loss: 0.10868686810135841, Final Batch Loss: 0.05111929401755333\n",
      "Epoch 3084, Loss: 0.1247316300868988, Final Batch Loss: 0.044692277908325195\n",
      "Epoch 3085, Loss: 0.07416434958577156, Final Batch Loss: 0.038387998938560486\n",
      "Epoch 3086, Loss: 0.11573008820414543, Final Batch Loss: 0.07494934648275375\n",
      "Epoch 3087, Loss: 0.1063859686255455, Final Batch Loss: 0.04043571650981903\n",
      "Epoch 3088, Loss: 0.12624968588352203, Final Batch Loss: 0.07397512346506119\n",
      "Epoch 3089, Loss: 0.08325262740254402, Final Batch Loss: 0.02849426493048668\n",
      "Epoch 3090, Loss: 0.08041302487254143, Final Batch Loss: 0.03294725716114044\n",
      "Epoch 3091, Loss: 0.15868910402059555, Final Batch Loss: 0.09693609178066254\n",
      "Epoch 3092, Loss: 0.07825608178973198, Final Batch Loss: 0.03922952711582184\n",
      "Epoch 3093, Loss: 0.16666150093078613, Final Batch Loss: 0.0721449926495552\n",
      "Epoch 3094, Loss: 0.1125069335103035, Final Batch Loss: 0.05249817296862602\n",
      "Epoch 3095, Loss: 0.09339646995067596, Final Batch Loss: 0.04912308603525162\n",
      "Epoch 3096, Loss: 0.12411191314458847, Final Batch Loss: 0.0856068953871727\n",
      "Epoch 3097, Loss: 0.13134770095348358, Final Batch Loss: 0.06160196661949158\n",
      "Epoch 3098, Loss: 0.17228321358561516, Final Batch Loss: 0.05457236245274544\n",
      "Epoch 3099, Loss: 0.14910046011209488, Final Batch Loss: 0.09721813350915909\n",
      "Epoch 3100, Loss: 0.15977316722273827, Final Batch Loss: 0.04805607721209526\n",
      "Epoch 3101, Loss: 0.11423372104763985, Final Batch Loss: 0.06125727295875549\n",
      "Epoch 3102, Loss: 0.12075170129537582, Final Batch Loss: 0.07461675256490707\n",
      "Epoch 3103, Loss: 0.11665866523981094, Final Batch Loss: 0.05926099047064781\n",
      "Epoch 3104, Loss: 0.11921851709485054, Final Batch Loss: 0.0761333554983139\n",
      "Epoch 3105, Loss: 0.16630788892507553, Final Batch Loss: 0.08992818742990494\n",
      "Epoch 3106, Loss: 0.18232472240924835, Final Batch Loss: 0.09074285626411438\n",
      "Epoch 3107, Loss: 0.09739500284194946, Final Batch Loss: 0.06498628854751587\n",
      "Epoch 3108, Loss: 0.23520619049668312, Final Batch Loss: 0.17432408034801483\n",
      "Epoch 3109, Loss: 0.1418812144547701, Final Batch Loss: 0.02508905716240406\n",
      "Epoch 3110, Loss: 0.12535573914647102, Final Batch Loss: 0.08609145134687424\n",
      "Epoch 3111, Loss: 0.15693926066160202, Final Batch Loss: 0.0656576082110405\n",
      "Epoch 3112, Loss: 0.16275127977132797, Final Batch Loss: 0.08416952937841415\n",
      "Epoch 3113, Loss: 0.1317535936832428, Final Batch Loss: 0.07066886872053146\n",
      "Epoch 3114, Loss: 0.1838894486427307, Final Batch Loss: 0.10645394772291183\n",
      "Epoch 3115, Loss: 0.08604611083865166, Final Batch Loss: 0.046395570039749146\n",
      "Epoch 3116, Loss: 0.21075450628995895, Final Batch Loss: 0.07215464860200882\n",
      "Epoch 3117, Loss: 0.2187623754143715, Final Batch Loss: 0.09344581514596939\n",
      "Epoch 3118, Loss: 0.11608340218663216, Final Batch Loss: 0.03863062337040901\n",
      "Epoch 3119, Loss: 0.15365581214427948, Final Batch Loss: 0.07521813362836838\n",
      "Epoch 3120, Loss: 0.12269636988639832, Final Batch Loss: 0.08586227893829346\n",
      "Epoch 3121, Loss: 0.12283990904688835, Final Batch Loss: 0.08456096053123474\n",
      "Epoch 3122, Loss: 0.12467407807707787, Final Batch Loss: 0.041187141090631485\n",
      "Epoch 3123, Loss: 0.11033342033624649, Final Batch Loss: 0.04753074795007706\n",
      "Epoch 3124, Loss: 0.1441219262778759, Final Batch Loss: 0.09348887205123901\n",
      "Epoch 3125, Loss: 0.11369268596172333, Final Batch Loss: 0.033978089690208435\n",
      "Epoch 3126, Loss: 0.17292896658182144, Final Batch Loss: 0.07734400033950806\n",
      "Epoch 3127, Loss: 0.13569672033190727, Final Batch Loss: 0.05359947308897972\n",
      "Epoch 3128, Loss: 0.1840868853032589, Final Batch Loss: 0.05209336802363396\n",
      "Epoch 3129, Loss: 0.12080482393503189, Final Batch Loss: 0.0623546727001667\n",
      "Epoch 3130, Loss: 0.1008199118077755, Final Batch Loss: 0.039106015115976334\n",
      "Epoch 3131, Loss: 0.1273304894566536, Final Batch Loss: 0.04663265496492386\n",
      "Epoch 3132, Loss: 0.10468053072690964, Final Batch Loss: 0.03637026250362396\n",
      "Epoch 3133, Loss: 0.10133937746286392, Final Batch Loss: 0.06207457184791565\n",
      "Epoch 3134, Loss: 0.12023843079805374, Final Batch Loss: 0.052751995623111725\n",
      "Epoch 3135, Loss: 0.14953022450208664, Final Batch Loss: 0.08056000620126724\n",
      "Epoch 3136, Loss: 0.11864109337329865, Final Batch Loss: 0.05683019384741783\n",
      "Epoch 3137, Loss: 0.0796477273106575, Final Batch Loss: 0.025682926177978516\n",
      "Epoch 3138, Loss: 0.1271488331258297, Final Batch Loss: 0.08100847154855728\n",
      "Epoch 3139, Loss: 0.13304099813103676, Final Batch Loss: 0.08932255208492279\n",
      "Epoch 3140, Loss: 0.16737881675362587, Final Batch Loss: 0.11933720111846924\n",
      "Epoch 3141, Loss: 0.1191350594162941, Final Batch Loss: 0.07902270555496216\n",
      "Epoch 3142, Loss: 0.12453565746545792, Final Batch Loss: 0.06419964879751205\n",
      "Epoch 3143, Loss: 0.1082693412899971, Final Batch Loss: 0.04210144281387329\n",
      "Epoch 3144, Loss: 0.13832193985581398, Final Batch Loss: 0.05192432180047035\n",
      "Epoch 3145, Loss: 0.13649851083755493, Final Batch Loss: 0.06555822491645813\n",
      "Epoch 3146, Loss: 0.10497971624135971, Final Batch Loss: 0.06635218113660812\n",
      "Epoch 3147, Loss: 0.16073141247034073, Final Batch Loss: 0.0714610293507576\n",
      "Epoch 3148, Loss: 0.135643370449543, Final Batch Loss: 0.06400366127490997\n",
      "Epoch 3149, Loss: 0.15373515710234642, Final Batch Loss: 0.05808047577738762\n",
      "Epoch 3150, Loss: 0.12694712728261948, Final Batch Loss: 0.049169450998306274\n",
      "Epoch 3151, Loss: 0.08617659658193588, Final Batch Loss: 0.051627155393362045\n",
      "Epoch 3152, Loss: 0.0967198982834816, Final Batch Loss: 0.059532538056373596\n",
      "Epoch 3153, Loss: 0.10766949132084846, Final Batch Loss: 0.06038311496376991\n",
      "Epoch 3154, Loss: 0.0885181687772274, Final Batch Loss: 0.03721082955598831\n",
      "Epoch 3155, Loss: 0.12973754853010178, Final Batch Loss: 0.04739849269390106\n",
      "Epoch 3156, Loss: 0.07551440224051476, Final Batch Loss: 0.018004722893238068\n",
      "Epoch 3157, Loss: 0.07583177089691162, Final Batch Loss: 0.026663772761821747\n",
      "Epoch 3158, Loss: 0.17765527218580246, Final Batch Loss: 0.09239000082015991\n",
      "Epoch 3159, Loss: 0.10439131408929825, Final Batch Loss: 0.07379323244094849\n",
      "Epoch 3160, Loss: 0.10018749535083771, Final Batch Loss: 0.045141514390707016\n",
      "Epoch 3161, Loss: 0.07614365592598915, Final Batch Loss: 0.0409989096224308\n",
      "Epoch 3162, Loss: 0.11046049743890762, Final Batch Loss: 0.056005436927080154\n",
      "Epoch 3163, Loss: 0.06899384036660194, Final Batch Loss: 0.025377172976732254\n",
      "Epoch 3164, Loss: 0.1616027131676674, Final Batch Loss: 0.0925065279006958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3165, Loss: 0.08886191248893738, Final Batch Loss: 0.0537567101418972\n",
      "Epoch 3166, Loss: 0.11915122345089912, Final Batch Loss: 0.07029534131288528\n",
      "Epoch 3167, Loss: 0.13187486678361893, Final Batch Loss: 0.06992790102958679\n",
      "Epoch 3168, Loss: 0.12006625905632973, Final Batch Loss: 0.06733640283346176\n",
      "Epoch 3169, Loss: 0.1037244088947773, Final Batch Loss: 0.03310840204358101\n",
      "Epoch 3170, Loss: 0.09552642703056335, Final Batch Loss: 0.04314303398132324\n",
      "Epoch 3171, Loss: 0.10618067532777786, Final Batch Loss: 0.0641227513551712\n",
      "Epoch 3172, Loss: 0.10941577702760696, Final Batch Loss: 0.042818084359169006\n",
      "Epoch 3173, Loss: 0.1648261621594429, Final Batch Loss: 0.044237278401851654\n",
      "Epoch 3174, Loss: 0.1170332320034504, Final Batch Loss: 0.04117589071393013\n",
      "Epoch 3175, Loss: 0.09584993869066238, Final Batch Loss: 0.03867972642183304\n",
      "Epoch 3176, Loss: 0.0992446169257164, Final Batch Loss: 0.05271817371249199\n",
      "Epoch 3177, Loss: 0.09570686519145966, Final Batch Loss: 0.04773743078112602\n",
      "Epoch 3178, Loss: 0.1473764143884182, Final Batch Loss: 0.08708732575178146\n",
      "Epoch 3179, Loss: 0.12023515999317169, Final Batch Loss: 0.056038133800029755\n",
      "Epoch 3180, Loss: 0.10281896963715553, Final Batch Loss: 0.06529702246189117\n",
      "Epoch 3181, Loss: 0.13938448578119278, Final Batch Loss: 0.0595453605055809\n",
      "Epoch 3182, Loss: 0.11203261464834213, Final Batch Loss: 0.051719121634960175\n",
      "Epoch 3183, Loss: 0.12388954311609268, Final Batch Loss: 0.05211862921714783\n",
      "Epoch 3184, Loss: 0.10063138976693153, Final Batch Loss: 0.045251693576574326\n",
      "Epoch 3185, Loss: 0.09902069717645645, Final Batch Loss: 0.035061582922935486\n",
      "Epoch 3186, Loss: 0.08630625531077385, Final Batch Loss: 0.03187565132975578\n",
      "Epoch 3187, Loss: 0.10432054847478867, Final Batch Loss: 0.047116126865148544\n",
      "Epoch 3188, Loss: 0.08368949219584465, Final Batch Loss: 0.0501096248626709\n",
      "Epoch 3189, Loss: 0.10469198226928711, Final Batch Loss: 0.05602290481328964\n",
      "Epoch 3190, Loss: 0.08698304370045662, Final Batch Loss: 0.04550314322113991\n",
      "Epoch 3191, Loss: 0.0972965843975544, Final Batch Loss: 0.035216670483350754\n",
      "Epoch 3192, Loss: 0.07549544796347618, Final Batch Loss: 0.03630949556827545\n",
      "Epoch 3193, Loss: 0.0839339829981327, Final Batch Loss: 0.04183129966259003\n",
      "Epoch 3194, Loss: 0.09695220366120338, Final Batch Loss: 0.06031167134642601\n",
      "Epoch 3195, Loss: 0.09410148113965988, Final Batch Loss: 0.04308339208364487\n",
      "Epoch 3196, Loss: 0.0767437070608139, Final Batch Loss: 0.036167845129966736\n",
      "Epoch 3197, Loss: 0.09451151266694069, Final Batch Loss: 0.03821749985218048\n",
      "Epoch 3198, Loss: 0.10937895253300667, Final Batch Loss: 0.057441167533397675\n",
      "Epoch 3199, Loss: 0.08325496315956116, Final Batch Loss: 0.049441780894994736\n",
      "Epoch 3200, Loss: 0.10419933870434761, Final Batch Loss: 0.05605814605951309\n",
      "Epoch 3201, Loss: 0.10557949542999268, Final Batch Loss: 0.04399285838007927\n",
      "Epoch 3202, Loss: 0.08383355662226677, Final Batch Loss: 0.045191895216703415\n",
      "Epoch 3203, Loss: 0.11276328936219215, Final Batch Loss: 0.04961356893181801\n",
      "Epoch 3204, Loss: 0.07180873677134514, Final Batch Loss: 0.034193191677331924\n",
      "Epoch 3205, Loss: 0.09704052656888962, Final Batch Loss: 0.055711932480335236\n",
      "Epoch 3206, Loss: 0.08100805804133415, Final Batch Loss: 0.05540991201996803\n",
      "Epoch 3207, Loss: 0.09571037068963051, Final Batch Loss: 0.059703484177589417\n",
      "Epoch 3208, Loss: 0.08982719853520393, Final Batch Loss: 0.043356623500585556\n",
      "Epoch 3209, Loss: 0.1221829243004322, Final Batch Loss: 0.055006224662065506\n",
      "Epoch 3210, Loss: 0.0985236894339323, Final Batch Loss: 0.02250043861567974\n",
      "Epoch 3211, Loss: 0.11563927680253983, Final Batch Loss: 0.03536292910575867\n",
      "Epoch 3212, Loss: 0.129684716463089, Final Batch Loss: 0.07826089859008789\n",
      "Epoch 3213, Loss: 0.10196619108319283, Final Batch Loss: 0.04537895321846008\n",
      "Epoch 3214, Loss: 0.0988396629691124, Final Batch Loss: 0.040912557393312454\n",
      "Epoch 3215, Loss: 0.1314443238079548, Final Batch Loss: 0.08033299446105957\n",
      "Epoch 3216, Loss: 0.12536782771348953, Final Batch Loss: 0.0694604441523552\n",
      "Epoch 3217, Loss: 0.16916930675506592, Final Batch Loss: 0.04999944567680359\n",
      "Epoch 3218, Loss: 0.09285819157958031, Final Batch Loss: 0.05586451664566994\n",
      "Epoch 3219, Loss: 0.08717221394181252, Final Batch Loss: 0.05396008864045143\n",
      "Epoch 3220, Loss: 0.1031283512711525, Final Batch Loss: 0.058530110865831375\n",
      "Epoch 3221, Loss: 0.10152038931846619, Final Batch Loss: 0.0593358613550663\n",
      "Epoch 3222, Loss: 0.09165734052658081, Final Batch Loss: 0.05754393711686134\n",
      "Epoch 3223, Loss: 0.08482242003083229, Final Batch Loss: 0.04707323759794235\n",
      "Epoch 3224, Loss: 0.1599615104496479, Final Batch Loss: 0.10972298681735992\n",
      "Epoch 3225, Loss: 0.12755215540528297, Final Batch Loss: 0.04052748158574104\n",
      "Epoch 3226, Loss: 0.10523848235607147, Final Batch Loss: 0.06053074449300766\n",
      "Epoch 3227, Loss: 0.09364299476146698, Final Batch Loss: 0.053061556071043015\n",
      "Epoch 3228, Loss: 0.08726835995912552, Final Batch Loss: 0.039354924112558365\n",
      "Epoch 3229, Loss: 0.06979072839021683, Final Batch Loss: 0.033953167498111725\n",
      "Epoch 3230, Loss: 0.09733277186751366, Final Batch Loss: 0.0520450696349144\n",
      "Epoch 3231, Loss: 0.09483825415372849, Final Batch Loss: 0.03625499829649925\n",
      "Epoch 3232, Loss: 0.10380156710743904, Final Batch Loss: 0.055866971611976624\n",
      "Epoch 3233, Loss: 0.10984515771269798, Final Batch Loss: 0.056013111025094986\n",
      "Epoch 3234, Loss: 0.08427362889051437, Final Batch Loss: 0.03586012125015259\n",
      "Epoch 3235, Loss: 0.0974351279437542, Final Batch Loss: 0.06074308976531029\n",
      "Epoch 3236, Loss: 0.14743328094482422, Final Batch Loss: 0.07229790091514587\n",
      "Epoch 3237, Loss: 0.08159759640693665, Final Batch Loss: 0.03788227587938309\n",
      "Epoch 3238, Loss: 0.10033032670617104, Final Batch Loss: 0.04383561387658119\n",
      "Epoch 3239, Loss: 0.09218204766511917, Final Batch Loss: 0.04002846032381058\n",
      "Epoch 3240, Loss: 0.12118937633931637, Final Batch Loss: 0.028502998873591423\n",
      "Epoch 3241, Loss: 0.10596030950546265, Final Batch Loss: 0.04319307208061218\n",
      "Epoch 3242, Loss: 0.09590669721364975, Final Batch Loss: 0.046254467219114304\n",
      "Epoch 3243, Loss: 0.16515133529901505, Final Batch Loss: 0.07690802216529846\n",
      "Epoch 3244, Loss: 0.11770767346024513, Final Batch Loss: 0.06258594244718552\n",
      "Epoch 3245, Loss: 0.09488961845636368, Final Batch Loss: 0.06210624799132347\n",
      "Epoch 3246, Loss: 0.08298053592443466, Final Batch Loss: 0.043560128659009933\n",
      "Epoch 3247, Loss: 0.11722570657730103, Final Batch Loss: 0.0733628123998642\n",
      "Epoch 3248, Loss: 0.08067994005978107, Final Batch Loss: 0.027942152693867683\n",
      "Epoch 3249, Loss: 0.07867078483104706, Final Batch Loss: 0.03761948645114899\n",
      "Epoch 3250, Loss: 0.10513736307621002, Final Batch Loss: 0.05759575217962265\n",
      "Epoch 3251, Loss: 0.1021997258067131, Final Batch Loss: 0.0689486563205719\n",
      "Epoch 3252, Loss: 0.07513107359409332, Final Batch Loss: 0.027776367962360382\n",
      "Epoch 3253, Loss: 0.0862966775894165, Final Batch Loss: 0.036311808973550797\n",
      "Epoch 3254, Loss: 0.10390723496675491, Final Batch Loss: 0.035074345767498016\n",
      "Epoch 3255, Loss: 0.09999088570475578, Final Batch Loss: 0.04450175538659096\n",
      "Epoch 3256, Loss: 0.09478593245148659, Final Batch Loss: 0.05495568364858627\n",
      "Epoch 3257, Loss: 0.11445622146129608, Final Batch Loss: 0.05739882215857506\n",
      "Epoch 3258, Loss: 0.09064662829041481, Final Batch Loss: 0.040447209030389786\n",
      "Epoch 3259, Loss: 0.0829668939113617, Final Batch Loss: 0.03326757624745369\n",
      "Epoch 3260, Loss: 0.09835696965456009, Final Batch Loss: 0.04025194048881531\n",
      "Epoch 3261, Loss: 0.07758612558245659, Final Batch Loss: 0.04585013911128044\n",
      "Epoch 3262, Loss: 0.09861359000205994, Final Batch Loss: 0.06231013312935829\n",
      "Epoch 3263, Loss: 0.08872850239276886, Final Batch Loss: 0.049231190234422684\n",
      "Epoch 3264, Loss: 0.0930667594075203, Final Batch Loss: 0.04862720146775246\n",
      "Epoch 3265, Loss: 0.07954444363713264, Final Batch Loss: 0.02050543576478958\n",
      "Epoch 3266, Loss: 0.14958982169628143, Final Batch Loss: 0.07951854169368744\n",
      "Epoch 3267, Loss: 0.08728210255503654, Final Batch Loss: 0.046626437455415726\n",
      "Epoch 3268, Loss: 0.15472405403852463, Final Batch Loss: 0.07897073775529861\n",
      "Epoch 3269, Loss: 0.08137732744216919, Final Batch Loss: 0.03916075453162193\n",
      "Epoch 3270, Loss: 0.198592908680439, Final Batch Loss: 0.13369402289390564\n",
      "Epoch 3271, Loss: 0.12254389002919197, Final Batch Loss: 0.038618575781583786\n",
      "Epoch 3272, Loss: 0.08320757746696472, Final Batch Loss: 0.05764321982860565\n",
      "Epoch 3273, Loss: 0.11659182608127594, Final Batch Loss: 0.04282744973897934\n",
      "Epoch 3274, Loss: 0.07891607284545898, Final Batch Loss: 0.03810178115963936\n",
      "Epoch 3275, Loss: 0.11863837763667107, Final Batch Loss: 0.03805520012974739\n",
      "Epoch 3276, Loss: 0.10594325885176659, Final Batch Loss: 0.05500055104494095\n",
      "Epoch 3277, Loss: 0.09249494038522243, Final Batch Loss: 0.06347702443599701\n",
      "Epoch 3278, Loss: 0.10023071989417076, Final Batch Loss: 0.04764104634523392\n",
      "Epoch 3279, Loss: 0.0806209072470665, Final Batch Loss: 0.039221860468387604\n",
      "Epoch 3280, Loss: 0.10468326136469841, Final Batch Loss: 0.054785262793302536\n",
      "Epoch 3281, Loss: 0.08975649997591972, Final Batch Loss: 0.051537781953811646\n",
      "Epoch 3282, Loss: 0.08159985020756721, Final Batch Loss: 0.03658061474561691\n",
      "Epoch 3283, Loss: 0.07841230928897858, Final Batch Loss: 0.02798069268465042\n",
      "Epoch 3284, Loss: 0.10268062725663185, Final Batch Loss: 0.06151212006807327\n",
      "Epoch 3285, Loss: 0.091487355530262, Final Batch Loss: 0.04560793191194534\n",
      "Epoch 3286, Loss: 0.08576665818691254, Final Batch Loss: 0.04645974189043045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3287, Loss: 0.0803462490439415, Final Batch Loss: 0.03093898296356201\n",
      "Epoch 3288, Loss: 0.11402412131428719, Final Batch Loss: 0.05509026721119881\n",
      "Epoch 3289, Loss: 0.07893907278776169, Final Batch Loss: 0.03919694200158119\n",
      "Epoch 3290, Loss: 0.08012640476226807, Final Batch Loss: 0.029961850494146347\n",
      "Epoch 3291, Loss: 0.12644468992948532, Final Batch Loss: 0.09598322957754135\n",
      "Epoch 3292, Loss: 0.12354830279946327, Final Batch Loss: 0.03634526953101158\n",
      "Epoch 3293, Loss: 0.1274016723036766, Final Batch Loss: 0.03486914932727814\n",
      "Epoch 3294, Loss: 0.1394439898431301, Final Batch Loss: 0.06232450529932976\n",
      "Epoch 3295, Loss: 0.09255237877368927, Final Batch Loss: 0.07052025198936462\n",
      "Epoch 3296, Loss: 0.09434390440583229, Final Batch Loss: 0.03727157786488533\n",
      "Epoch 3297, Loss: 0.12181413173675537, Final Batch Loss: 0.0479864701628685\n",
      "Epoch 3298, Loss: 0.14550279080867767, Final Batch Loss: 0.07015573233366013\n",
      "Epoch 3299, Loss: 0.08590468391776085, Final Batch Loss: 0.04980967938899994\n",
      "Epoch 3300, Loss: 0.09987681359052658, Final Batch Loss: 0.05159998685121536\n",
      "Epoch 3301, Loss: 0.14251487329602242, Final Batch Loss: 0.044063862413167953\n",
      "Epoch 3302, Loss: 0.10230331867933273, Final Batch Loss: 0.04259907826781273\n",
      "Epoch 3303, Loss: 0.12533174082636833, Final Batch Loss: 0.05956130102276802\n",
      "Epoch 3304, Loss: 0.15154094621539116, Final Batch Loss: 0.0915394201874733\n",
      "Epoch 3305, Loss: 0.14528308436274529, Final Batch Loss: 0.09048447757959366\n",
      "Epoch 3306, Loss: 0.12387435510754585, Final Batch Loss: 0.033732350915670395\n",
      "Epoch 3307, Loss: 0.13363002985715866, Final Batch Loss: 0.05303367227315903\n",
      "Epoch 3308, Loss: 0.12304292619228363, Final Batch Loss: 0.06624279171228409\n",
      "Epoch 3309, Loss: 0.09925104677677155, Final Batch Loss: 0.0564834289252758\n",
      "Epoch 3310, Loss: 0.1211981549859047, Final Batch Loss: 0.08431696146726608\n",
      "Epoch 3311, Loss: 0.08417940139770508, Final Batch Loss: 0.05085542052984238\n",
      "Epoch 3312, Loss: 0.07372600585222244, Final Batch Loss: 0.02150079235434532\n",
      "Epoch 3313, Loss: 0.08633029833436012, Final Batch Loss: 0.047844115644693375\n",
      "Epoch 3314, Loss: 0.12071873992681503, Final Batch Loss: 0.03530877083539963\n",
      "Epoch 3315, Loss: 0.08902622759342194, Final Batch Loss: 0.04539890214800835\n",
      "Epoch 3316, Loss: 0.06967059522867203, Final Batch Loss: 0.030586697161197662\n",
      "Epoch 3317, Loss: 0.10794634185731411, Final Batch Loss: 0.030337033793330193\n",
      "Epoch 3318, Loss: 0.12027349323034286, Final Batch Loss: 0.07235437631607056\n",
      "Epoch 3319, Loss: 0.24856331571936607, Final Batch Loss: 0.2027927041053772\n",
      "Epoch 3320, Loss: 0.09411768242716789, Final Batch Loss: 0.04516780003905296\n",
      "Epoch 3321, Loss: 0.07539064809679985, Final Batch Loss: 0.042160000652074814\n",
      "Epoch 3322, Loss: 0.08016345463693142, Final Batch Loss: 0.021692512556910515\n",
      "Epoch 3323, Loss: 0.06910085491836071, Final Batch Loss: 0.02879803068935871\n",
      "Epoch 3324, Loss: 0.1217346154153347, Final Batch Loss: 0.06130871921777725\n",
      "Epoch 3325, Loss: 0.09308161959052086, Final Batch Loss: 0.04831122234463692\n",
      "Epoch 3326, Loss: 0.09278270229697227, Final Batch Loss: 0.03520170971751213\n",
      "Epoch 3327, Loss: 0.09728306531906128, Final Batch Loss: 0.0802367702126503\n",
      "Epoch 3328, Loss: 0.11390181444585323, Final Batch Loss: 0.0274688508361578\n",
      "Epoch 3329, Loss: 0.10485570877790451, Final Batch Loss: 0.059038784354925156\n",
      "Epoch 3330, Loss: 0.1164218857884407, Final Batch Loss: 0.07141885161399841\n",
      "Epoch 3331, Loss: 0.08510984480381012, Final Batch Loss: 0.04742932319641113\n",
      "Epoch 3332, Loss: 0.07422133721411228, Final Batch Loss: 0.014705123379826546\n",
      "Epoch 3333, Loss: 0.09655178338289261, Final Batch Loss: 0.03475922718644142\n",
      "Epoch 3334, Loss: 0.08126876130700111, Final Batch Loss: 0.05175907537341118\n",
      "Epoch 3335, Loss: 0.0978267453610897, Final Batch Loss: 0.03233589604496956\n",
      "Epoch 3336, Loss: 0.09215645119547844, Final Batch Loss: 0.03720148652791977\n",
      "Epoch 3337, Loss: 0.07380002923309803, Final Batch Loss: 0.02322530187666416\n",
      "Epoch 3338, Loss: 0.09375036135315895, Final Batch Loss: 0.050141800194978714\n",
      "Epoch 3339, Loss: 0.1404961720108986, Final Batch Loss: 0.03378347307443619\n",
      "Epoch 3340, Loss: 0.12257987633347511, Final Batch Loss: 0.09598279744386673\n",
      "Epoch 3341, Loss: 0.17241403833031654, Final Batch Loss: 0.12133283168077469\n",
      "Epoch 3342, Loss: 0.08513971045613289, Final Batch Loss: 0.04787817597389221\n",
      "Epoch 3343, Loss: 0.09189258143305779, Final Batch Loss: 0.03607684001326561\n",
      "Epoch 3344, Loss: 0.14066315442323685, Final Batch Loss: 0.09166967868804932\n",
      "Epoch 3345, Loss: 0.12914766371250153, Final Batch Loss: 0.06951580941677094\n",
      "Epoch 3346, Loss: 0.09790914133191109, Final Batch Loss: 0.04387758672237396\n",
      "Epoch 3347, Loss: 0.08984034135937691, Final Batch Loss: 0.05444323271512985\n",
      "Epoch 3348, Loss: 0.0793961975723505, Final Batch Loss: 0.02744649164378643\n",
      "Epoch 3349, Loss: 0.07256845757365227, Final Batch Loss: 0.03547017276287079\n",
      "Epoch 3350, Loss: 0.09308744966983795, Final Batch Loss: 0.04201860353350639\n",
      "Epoch 3351, Loss: 0.11317813396453857, Final Batch Loss: 0.04743760824203491\n",
      "Epoch 3352, Loss: 0.09248391166329384, Final Batch Loss: 0.036377739161252975\n",
      "Epoch 3353, Loss: 0.09650928527116776, Final Batch Loss: 0.03986604884266853\n",
      "Epoch 3354, Loss: 0.11020220257341862, Final Batch Loss: 0.01763749308884144\n",
      "Epoch 3355, Loss: 0.08197484537959099, Final Batch Loss: 0.049500055611133575\n",
      "Epoch 3356, Loss: 0.08655567467212677, Final Batch Loss: 0.04787179082632065\n",
      "Epoch 3357, Loss: 0.0991431437432766, Final Batch Loss: 0.049949947744607925\n",
      "Epoch 3358, Loss: 0.09251435473561287, Final Batch Loss: 0.05507991090416908\n",
      "Epoch 3359, Loss: 0.09823175147175789, Final Batch Loss: 0.06455708295106888\n",
      "Epoch 3360, Loss: 0.08785384520888329, Final Batch Loss: 0.04605579748749733\n",
      "Epoch 3361, Loss: 0.11383768916130066, Final Batch Loss: 0.06514393538236618\n",
      "Epoch 3362, Loss: 0.08422090858221054, Final Batch Loss: 0.02663123980164528\n",
      "Epoch 3363, Loss: 0.10213914886116982, Final Batch Loss: 0.06636305153369904\n",
      "Epoch 3364, Loss: 0.14780938252806664, Final Batch Loss: 0.0503547303378582\n",
      "Epoch 3365, Loss: 0.18631933629512787, Final Batch Loss: 0.07020031660795212\n",
      "Epoch 3366, Loss: 0.07889169454574585, Final Batch Loss: 0.017874520272016525\n",
      "Epoch 3367, Loss: 0.1309865228831768, Final Batch Loss: 0.05658137425780296\n",
      "Epoch 3368, Loss: 0.10249703377485275, Final Batch Loss: 0.025366470217704773\n",
      "Epoch 3369, Loss: 0.09137357771396637, Final Batch Loss: 0.03743315860629082\n",
      "Epoch 3370, Loss: 0.09913521260023117, Final Batch Loss: 0.04878819361329079\n",
      "Epoch 3371, Loss: 0.08558614552021027, Final Batch Loss: 0.04583626613020897\n",
      "Epoch 3372, Loss: 0.11976107954978943, Final Batch Loss: 0.052182793617248535\n",
      "Epoch 3373, Loss: 0.11110135912895203, Final Batch Loss: 0.07792522013187408\n",
      "Epoch 3374, Loss: 0.15068533644080162, Final Batch Loss: 0.06167426332831383\n",
      "Epoch 3375, Loss: 0.10510098189115524, Final Batch Loss: 0.048238545656204224\n",
      "Epoch 3376, Loss: 0.08425472676753998, Final Batch Loss: 0.0367576964199543\n",
      "Epoch 3377, Loss: 0.10729298740625381, Final Batch Loss: 0.06717066466808319\n",
      "Epoch 3378, Loss: 0.09294000267982483, Final Batch Loss: 0.04291119799017906\n",
      "Epoch 3379, Loss: 0.1523914858698845, Final Batch Loss: 0.05768240988254547\n",
      "Epoch 3380, Loss: 0.07379409484565258, Final Batch Loss: 0.02728557400405407\n",
      "Epoch 3381, Loss: 0.1270938366651535, Final Batch Loss: 0.08132068067789078\n",
      "Epoch 3382, Loss: 0.10156632587313652, Final Batch Loss: 0.06440668553113937\n",
      "Epoch 3383, Loss: 0.07221941277384758, Final Batch Loss: 0.036097217351198196\n",
      "Epoch 3384, Loss: 0.09718169271945953, Final Batch Loss: 0.05619052052497864\n",
      "Epoch 3385, Loss: 0.07992473617196083, Final Batch Loss: 0.038794420659542084\n",
      "Epoch 3386, Loss: 0.08552534505724907, Final Batch Loss: 0.06460098177194595\n",
      "Epoch 3387, Loss: 0.07796723023056984, Final Batch Loss: 0.0400078222155571\n",
      "Epoch 3388, Loss: 0.05825388245284557, Final Batch Loss: 0.016885606572031975\n",
      "Epoch 3389, Loss: 0.07775614224374294, Final Batch Loss: 0.025941597297787666\n",
      "Epoch 3390, Loss: 0.08421606570482254, Final Batch Loss: 0.051714938133955\n",
      "Epoch 3391, Loss: 0.0822032056748867, Final Batch Loss: 0.03145240247249603\n",
      "Epoch 3392, Loss: 0.09489762037992477, Final Batch Loss: 0.02844974398612976\n",
      "Epoch 3393, Loss: 0.07072984427213669, Final Batch Loss: 0.0382760651409626\n",
      "Epoch 3394, Loss: 0.07700624316930771, Final Batch Loss: 0.027533814311027527\n",
      "Epoch 3395, Loss: 0.20255063101649284, Final Batch Loss: 0.035745661705732346\n",
      "Epoch 3396, Loss: 0.08897668868303299, Final Batch Loss: 0.0402769073843956\n",
      "Epoch 3397, Loss: 0.09538435563445091, Final Batch Loss: 0.031562160700559616\n",
      "Epoch 3398, Loss: 0.07750635221600533, Final Batch Loss: 0.0427984744310379\n",
      "Epoch 3399, Loss: 0.09955659881234169, Final Batch Loss: 0.07073531299829483\n",
      "Epoch 3400, Loss: 0.08382204361259937, Final Batch Loss: 0.02689432166516781\n",
      "Epoch 3401, Loss: 0.07687203213572502, Final Batch Loss: 0.045038122683763504\n",
      "Epoch 3402, Loss: 0.08476391062140465, Final Batch Loss: 0.031728047877550125\n",
      "Epoch 3403, Loss: 0.07923318073153496, Final Batch Loss: 0.04275474697351456\n",
      "Epoch 3404, Loss: 0.08873135223984718, Final Batch Loss: 0.05685178562998772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3405, Loss: 0.10410545021295547, Final Batch Loss: 0.02467186748981476\n",
      "Epoch 3406, Loss: 0.10662124678492546, Final Batch Loss: 0.036505650728940964\n",
      "Epoch 3407, Loss: 0.06587187945842743, Final Batch Loss: 0.030451662838459015\n",
      "Epoch 3408, Loss: 0.09519359469413757, Final Batch Loss: 0.06577892601490021\n",
      "Epoch 3409, Loss: 0.08818172663450241, Final Batch Loss: 0.060897909104824066\n",
      "Epoch 3410, Loss: 0.13860453106462955, Final Batch Loss: 0.030480453744530678\n",
      "Epoch 3411, Loss: 0.08739741146564484, Final Batch Loss: 0.03996431455016136\n",
      "Epoch 3412, Loss: 0.09159380942583084, Final Batch Loss: 0.05010482296347618\n",
      "Epoch 3413, Loss: 0.09557696804404259, Final Batch Loss: 0.04519017040729523\n",
      "Epoch 3414, Loss: 0.11983795091509819, Final Batch Loss: 0.031741995364427567\n",
      "Epoch 3415, Loss: 0.12098373472690582, Final Batch Loss: 0.0607641376554966\n",
      "Epoch 3416, Loss: 0.07452315464615822, Final Batch Loss: 0.04829734191298485\n",
      "Epoch 3417, Loss: 0.10451914370059967, Final Batch Loss: 0.06478052586317062\n",
      "Epoch 3418, Loss: 0.08659072034060955, Final Batch Loss: 0.05989844724535942\n",
      "Epoch 3419, Loss: 0.12642178311944008, Final Batch Loss: 0.08431791514158249\n",
      "Epoch 3420, Loss: 0.10985546186566353, Final Batch Loss: 0.046165015548467636\n",
      "Epoch 3421, Loss: 0.12228577956557274, Final Batch Loss: 0.0657186433672905\n",
      "Epoch 3422, Loss: 0.1364869475364685, Final Batch Loss: 0.03848434239625931\n",
      "Epoch 3423, Loss: 0.143881693482399, Final Batch Loss: 0.09121718257665634\n",
      "Epoch 3424, Loss: 0.08343983814120293, Final Batch Loss: 0.038314446806907654\n",
      "Epoch 3425, Loss: 0.08135024458169937, Final Batch Loss: 0.05331045389175415\n",
      "Epoch 3426, Loss: 0.14623340219259262, Final Batch Loss: 0.1039477288722992\n",
      "Epoch 3427, Loss: 0.08722654357552528, Final Batch Loss: 0.03837030753493309\n",
      "Epoch 3428, Loss: 0.08668063022196293, Final Batch Loss: 0.02982337959110737\n",
      "Epoch 3429, Loss: 0.0736815333366394, Final Batch Loss: 0.0472550205886364\n",
      "Epoch 3430, Loss: 0.09749205410480499, Final Batch Loss: 0.05325285717844963\n",
      "Epoch 3431, Loss: 0.08680278435349464, Final Batch Loss: 0.05281878635287285\n",
      "Epoch 3432, Loss: 0.08531277254223824, Final Batch Loss: 0.05402853712439537\n",
      "Epoch 3433, Loss: 0.07967869378626347, Final Batch Loss: 0.05052470043301582\n",
      "Epoch 3434, Loss: 0.07600630447268486, Final Batch Loss: 0.042548079043626785\n",
      "Epoch 3435, Loss: 0.10359438508749008, Final Batch Loss: 0.05670834705233574\n",
      "Epoch 3436, Loss: 0.07625163346529007, Final Batch Loss: 0.048401858657598495\n",
      "Epoch 3437, Loss: 0.12799426168203354, Final Batch Loss: 0.09436751902103424\n",
      "Epoch 3438, Loss: 0.08428692631423473, Final Batch Loss: 0.028172800317406654\n",
      "Epoch 3439, Loss: 0.09735006466507912, Final Batch Loss: 0.03244197741150856\n",
      "Epoch 3440, Loss: 0.10775795578956604, Final Batch Loss: 0.04488790035247803\n",
      "Epoch 3441, Loss: 0.09272859618067741, Final Batch Loss: 0.02600817009806633\n",
      "Epoch 3442, Loss: 0.07156572304666042, Final Batch Loss: 0.04340635985136032\n",
      "Epoch 3443, Loss: 0.09688844159245491, Final Batch Loss: 0.06059470400214195\n",
      "Epoch 3444, Loss: 0.0720018558204174, Final Batch Loss: 0.0322340689599514\n",
      "Epoch 3445, Loss: 0.08729379996657372, Final Batch Loss: 0.035244058817625046\n",
      "Epoch 3446, Loss: 0.09162933379411697, Final Batch Loss: 0.04968896135687828\n",
      "Epoch 3447, Loss: 0.09612477570772171, Final Batch Loss: 0.034203726798295975\n",
      "Epoch 3448, Loss: 0.0837956927716732, Final Batch Loss: 0.05218152701854706\n",
      "Epoch 3449, Loss: 0.08272768557071686, Final Batch Loss: 0.04134833440184593\n",
      "Epoch 3450, Loss: 0.06884893029928207, Final Batch Loss: 0.016493216156959534\n",
      "Epoch 3451, Loss: 0.11640777625143528, Final Batch Loss: 0.09388627856969833\n",
      "Epoch 3452, Loss: 0.06488763727247715, Final Batch Loss: 0.04054086282849312\n",
      "Epoch 3453, Loss: 0.08306480571627617, Final Batch Loss: 0.04741334542632103\n",
      "Epoch 3454, Loss: 0.05618098936975002, Final Batch Loss: 0.023653490468859673\n",
      "Epoch 3455, Loss: 0.07129756733775139, Final Batch Loss: 0.0369260311126709\n",
      "Epoch 3456, Loss: 0.08860233053565025, Final Batch Loss: 0.045792609453201294\n",
      "Epoch 3457, Loss: 0.08284921199083328, Final Batch Loss: 0.0521865151822567\n",
      "Epoch 3458, Loss: 0.07639321871101856, Final Batch Loss: 0.060098353773355484\n",
      "Epoch 3459, Loss: 0.1487884782254696, Final Batch Loss: 0.11295165121555328\n",
      "Epoch 3460, Loss: 0.09555858373641968, Final Batch Loss: 0.07325451821088791\n",
      "Epoch 3461, Loss: 0.13764378800988197, Final Batch Loss: 0.0925663560628891\n",
      "Epoch 3462, Loss: 0.11190236359834671, Final Batch Loss: 0.07915280759334564\n",
      "Epoch 3463, Loss: 0.09237398579716682, Final Batch Loss: 0.02220839634537697\n",
      "Epoch 3464, Loss: 0.07142342999577522, Final Batch Loss: 0.03412938490509987\n",
      "Epoch 3465, Loss: 0.0625601839274168, Final Batch Loss: 0.02363487519323826\n",
      "Epoch 3466, Loss: 0.05738956481218338, Final Batch Loss: 0.031200777739286423\n",
      "Epoch 3467, Loss: 0.08934824168682098, Final Batch Loss: 0.0465129129588604\n",
      "Epoch 3468, Loss: 0.09021306037902832, Final Batch Loss: 0.03999636694788933\n",
      "Epoch 3469, Loss: 0.09719172865152359, Final Batch Loss: 0.050208691507577896\n",
      "Epoch 3470, Loss: 0.10179793834686279, Final Batch Loss: 0.06643697619438171\n",
      "Epoch 3471, Loss: 0.07540938258171082, Final Batch Loss: 0.022535357624292374\n",
      "Epoch 3472, Loss: 0.08288273587822914, Final Batch Loss: 0.042308829724788666\n",
      "Epoch 3473, Loss: 0.06954536214470863, Final Batch Loss: 0.03721955418586731\n",
      "Epoch 3474, Loss: 0.07709814980626106, Final Batch Loss: 0.03381017595529556\n",
      "Epoch 3475, Loss: 0.11986863240599632, Final Batch Loss: 0.07065442204475403\n",
      "Epoch 3476, Loss: 0.12950582429766655, Final Batch Loss: 0.040523793548345566\n",
      "Epoch 3477, Loss: 0.08365534618496895, Final Batch Loss: 0.04307882487773895\n",
      "Epoch 3478, Loss: 0.07994864508509636, Final Batch Loss: 0.04451971873641014\n",
      "Epoch 3479, Loss: 0.057226838544011116, Final Batch Loss: 0.02940715104341507\n",
      "Epoch 3480, Loss: 0.09053047373890877, Final Batch Loss: 0.03346765413880348\n",
      "Epoch 3481, Loss: 0.08536936715245247, Final Batch Loss: 0.04298646003007889\n",
      "Epoch 3482, Loss: 0.08330810442566872, Final Batch Loss: 0.03785672038793564\n",
      "Epoch 3483, Loss: 0.07279345020651817, Final Batch Loss: 0.036027342081069946\n",
      "Epoch 3484, Loss: 0.06865310482680798, Final Batch Loss: 0.04224323481321335\n",
      "Epoch 3485, Loss: 0.08798767253756523, Final Batch Loss: 0.054269466549158096\n",
      "Epoch 3486, Loss: 0.09089438989758492, Final Batch Loss: 0.046680424362421036\n",
      "Epoch 3487, Loss: 0.08613795787096024, Final Batch Loss: 0.04963209852576256\n",
      "Epoch 3488, Loss: 0.14449983835220337, Final Batch Loss: 0.10238240659236908\n",
      "Epoch 3489, Loss: 0.10963990166783333, Final Batch Loss: 0.06614525616168976\n",
      "Epoch 3490, Loss: 0.08127733878791332, Final Batch Loss: 0.05945805087685585\n",
      "Epoch 3491, Loss: 0.08848479017615318, Final Batch Loss: 0.04253643751144409\n",
      "Epoch 3492, Loss: 0.09357063472270966, Final Batch Loss: 0.044499095529317856\n",
      "Epoch 3493, Loss: 0.08058401569724083, Final Batch Loss: 0.028389986604452133\n",
      "Epoch 3494, Loss: 0.08202307485044003, Final Batch Loss: 0.029651975259184837\n",
      "Epoch 3495, Loss: 0.0982397310435772, Final Batch Loss: 0.03446664288640022\n",
      "Epoch 3496, Loss: 0.089382104575634, Final Batch Loss: 0.04566456377506256\n",
      "Epoch 3497, Loss: 0.13175199925899506, Final Batch Loss: 0.06390471011400223\n",
      "Epoch 3498, Loss: 0.11513671278953552, Final Batch Loss: 0.06436124444007874\n",
      "Epoch 3499, Loss: 0.08314092084765434, Final Batch Loss: 0.02842310070991516\n",
      "Epoch 3500, Loss: 0.09994642436504364, Final Batch Loss: 0.06630148738622665\n",
      "Epoch 3501, Loss: 0.07664546743035316, Final Batch Loss: 0.030024591833353043\n",
      "Epoch 3502, Loss: 0.09654250368475914, Final Batch Loss: 0.051242854446172714\n",
      "Epoch 3503, Loss: 0.08182014152407646, Final Batch Loss: 0.04024222120642662\n",
      "Epoch 3504, Loss: 0.08644498512148857, Final Batch Loss: 0.04766828939318657\n",
      "Epoch 3505, Loss: 0.12692441418766975, Final Batch Loss: 0.04270661249756813\n",
      "Epoch 3506, Loss: 0.09173787012696266, Final Batch Loss: 0.03910057991743088\n",
      "Epoch 3507, Loss: 0.0814220979809761, Final Batch Loss: 0.04337746649980545\n",
      "Epoch 3508, Loss: 0.09088344871997833, Final Batch Loss: 0.04832754284143448\n",
      "Epoch 3509, Loss: 0.06762172281742096, Final Batch Loss: 0.028094392269849777\n",
      "Epoch 3510, Loss: 0.07935313507914543, Final Batch Loss: 0.05036335811018944\n",
      "Epoch 3511, Loss: 0.09034531563520432, Final Batch Loss: 0.04097435623407364\n",
      "Epoch 3512, Loss: 0.09218715876340866, Final Batch Loss: 0.05077548325061798\n",
      "Epoch 3513, Loss: 0.07498237863183022, Final Batch Loss: 0.037642113864421844\n",
      "Epoch 3514, Loss: 0.07532375678420067, Final Batch Loss: 0.03256047144532204\n",
      "Epoch 3515, Loss: 0.08204547688364983, Final Batch Loss: 0.04052199795842171\n",
      "Epoch 3516, Loss: 0.09244068711996078, Final Batch Loss: 0.05361074581742287\n",
      "Epoch 3517, Loss: 0.08261964842677116, Final Batch Loss: 0.0444055050611496\n",
      "Epoch 3518, Loss: 0.07943851128220558, Final Batch Loss: 0.03976891562342644\n",
      "Epoch 3519, Loss: 0.06910436786711216, Final Batch Loss: 0.02959027700126171\n",
      "Epoch 3520, Loss: 0.09088799357414246, Final Batch Loss: 0.049982521682977676\n",
      "Epoch 3521, Loss: 0.12194671481847763, Final Batch Loss: 0.08654063940048218\n",
      "Epoch 3522, Loss: 0.07218587212264538, Final Batch Loss: 0.05449783429503441\n",
      "Epoch 3523, Loss: 0.06798406317830086, Final Batch Loss: 0.020823929458856583\n",
      "Epoch 3524, Loss: 0.07860457897186279, Final Batch Loss: 0.0449804924428463\n",
      "Epoch 3525, Loss: 0.08506543934345245, Final Batch Loss: 0.04023066163063049\n",
      "Epoch 3526, Loss: 0.11482563242316246, Final Batch Loss: 0.0717754140496254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3527, Loss: 0.07672304101288319, Final Batch Loss: 0.04992487654089928\n",
      "Epoch 3528, Loss: 0.07210583239793777, Final Batch Loss: 0.023967232555150986\n",
      "Epoch 3529, Loss: 0.09876366332173347, Final Batch Loss: 0.04834454506635666\n",
      "Epoch 3530, Loss: 0.06798706203699112, Final Batch Loss: 0.03235795348882675\n",
      "Epoch 3531, Loss: 0.08656487241387367, Final Batch Loss: 0.05483711510896683\n",
      "Epoch 3532, Loss: 0.08104726672172546, Final Batch Loss: 0.03337877616286278\n",
      "Epoch 3533, Loss: 0.10123706236481667, Final Batch Loss: 0.06465158611536026\n",
      "Epoch 3534, Loss: 0.08385896682739258, Final Batch Loss: 0.04291333630681038\n",
      "Epoch 3535, Loss: 0.06595377624034882, Final Batch Loss: 0.04157029092311859\n",
      "Epoch 3536, Loss: 0.12045811116695404, Final Batch Loss: 0.08215980231761932\n",
      "Epoch 3537, Loss: 0.08701985701918602, Final Batch Loss: 0.021340887993574142\n",
      "Epoch 3538, Loss: 0.07279642671346664, Final Batch Loss: 0.04204806312918663\n",
      "Epoch 3539, Loss: 0.0709996409714222, Final Batch Loss: 0.0381820984184742\n",
      "Epoch 3540, Loss: 0.09152775071561337, Final Batch Loss: 0.03073434717953205\n",
      "Epoch 3541, Loss: 0.1215692013502121, Final Batch Loss: 0.0786973387002945\n",
      "Epoch 3542, Loss: 0.06681334041059017, Final Batch Loss: 0.030667630955576897\n",
      "Epoch 3543, Loss: 0.098918616771698, Final Batch Loss: 0.0522681325674057\n",
      "Epoch 3544, Loss: 0.11537864804267883, Final Batch Loss: 0.06513862311840057\n",
      "Epoch 3545, Loss: 0.07818717509508133, Final Batch Loss: 0.03692254796624184\n",
      "Epoch 3546, Loss: 0.0797494575381279, Final Batch Loss: 0.03874623402953148\n",
      "Epoch 3547, Loss: 0.07939395308494568, Final Batch Loss: 0.05190644785761833\n",
      "Epoch 3548, Loss: 0.07790561020374298, Final Batch Loss: 0.04514049366116524\n",
      "Epoch 3549, Loss: 0.08965934813022614, Final Batch Loss: 0.0601077526807785\n",
      "Epoch 3550, Loss: 0.08175154589116573, Final Batch Loss: 0.02419375814497471\n",
      "Epoch 3551, Loss: 0.07284087594598532, Final Batch Loss: 0.05869315564632416\n",
      "Epoch 3552, Loss: 0.15946070104837418, Final Batch Loss: 0.031671904027462006\n",
      "Epoch 3553, Loss: 0.07656938955187798, Final Batch Loss: 0.04709601402282715\n",
      "Epoch 3554, Loss: 0.07700653187930584, Final Batch Loss: 0.04794670268893242\n",
      "Epoch 3555, Loss: 0.11438608169555664, Final Batch Loss: 0.04982445389032364\n",
      "Epoch 3556, Loss: 0.07295054383575916, Final Batch Loss: 0.02959749661386013\n",
      "Epoch 3557, Loss: 0.09043685719370842, Final Batch Loss: 0.04133434221148491\n",
      "Epoch 3558, Loss: 0.11209885030984879, Final Batch Loss: 0.04996532201766968\n",
      "Epoch 3559, Loss: 0.05256185494363308, Final Batch Loss: 0.008143911138176918\n",
      "Epoch 3560, Loss: 0.09247217699885368, Final Batch Loss: 0.04621989279985428\n",
      "Epoch 3561, Loss: 0.11620338633656502, Final Batch Loss: 0.07332833111286163\n",
      "Epoch 3562, Loss: 0.07871939241886139, Final Batch Loss: 0.047550857067108154\n",
      "Epoch 3563, Loss: 0.1234154924750328, Final Batch Loss: 0.056026898324489594\n",
      "Epoch 3564, Loss: 0.07449784129858017, Final Batch Loss: 0.042843133211135864\n",
      "Epoch 3565, Loss: 0.08692631870508194, Final Batch Loss: 0.04377343878149986\n",
      "Epoch 3566, Loss: 0.10170641168951988, Final Batch Loss: 0.054391030222177505\n",
      "Epoch 3567, Loss: 0.09674946218729019, Final Batch Loss: 0.056767240166664124\n",
      "Epoch 3568, Loss: 0.07725999131798744, Final Batch Loss: 0.025555353611707687\n",
      "Epoch 3569, Loss: 0.08549554087221622, Final Batch Loss: 0.02661793865263462\n",
      "Epoch 3570, Loss: 0.096250981092453, Final Batch Loss: 0.0540970079600811\n",
      "Epoch 3571, Loss: 0.0851648561656475, Final Batch Loss: 0.0441509485244751\n",
      "Epoch 3572, Loss: 0.1073211021721363, Final Batch Loss: 0.05913316458463669\n",
      "Epoch 3573, Loss: 0.0787615068256855, Final Batch Loss: 0.03908899426460266\n",
      "Epoch 3574, Loss: 0.08906076475977898, Final Batch Loss: 0.023936565965414047\n",
      "Epoch 3575, Loss: 0.1039519663900137, Final Batch Loss: 0.025779640302062035\n",
      "Epoch 3576, Loss: 0.07479844614863396, Final Batch Loss: 0.0400238074362278\n",
      "Epoch 3577, Loss: 0.08953525498509407, Final Batch Loss: 0.057521067559719086\n",
      "Epoch 3578, Loss: 0.13783275708556175, Final Batch Loss: 0.09497994929552078\n",
      "Epoch 3579, Loss: 0.07449059933423996, Final Batch Loss: 0.04148406535387039\n",
      "Epoch 3580, Loss: 0.16225962713360786, Final Batch Loss: 0.1274031549692154\n",
      "Epoch 3581, Loss: 0.11024297401309013, Final Batch Loss: 0.05697369575500488\n",
      "Epoch 3582, Loss: 0.07055741176009178, Final Batch Loss: 0.04537419229745865\n",
      "Epoch 3583, Loss: 0.09249276667833328, Final Batch Loss: 0.04304639622569084\n",
      "Epoch 3584, Loss: 0.0762556754052639, Final Batch Loss: 0.038896091282367706\n",
      "Epoch 3585, Loss: 0.08346300944685936, Final Batch Loss: 0.057065196335315704\n",
      "Epoch 3586, Loss: 0.10486476868391037, Final Batch Loss: 0.05898657441139221\n",
      "Epoch 3587, Loss: 0.08548334985971451, Final Batch Loss: 0.03385287895798683\n",
      "Epoch 3588, Loss: 0.11659792438149452, Final Batch Loss: 0.03934302553534508\n",
      "Epoch 3589, Loss: 0.07854446023702621, Final Batch Loss: 0.0413476899266243\n",
      "Epoch 3590, Loss: 0.0995996929705143, Final Batch Loss: 0.0625704675912857\n",
      "Epoch 3591, Loss: 0.07211989909410477, Final Batch Loss: 0.015990644693374634\n",
      "Epoch 3592, Loss: 0.09441143274307251, Final Batch Loss: 0.04403941333293915\n",
      "Epoch 3593, Loss: 0.08856353908777237, Final Batch Loss: 0.047924600541591644\n",
      "Epoch 3594, Loss: 0.09538684599101543, Final Batch Loss: 0.026495499536395073\n",
      "Epoch 3595, Loss: 0.07035044766962528, Final Batch Loss: 0.02869105525314808\n",
      "Epoch 3596, Loss: 0.06980100087821484, Final Batch Loss: 0.04084985330700874\n",
      "Epoch 3597, Loss: 0.07760986872017384, Final Batch Loss: 0.029431821778416634\n",
      "Epoch 3598, Loss: 0.09767735376954079, Final Batch Loss: 0.04160955920815468\n",
      "Epoch 3599, Loss: 0.09710122272372246, Final Batch Loss: 0.05616314709186554\n",
      "Epoch 3600, Loss: 0.08490103855729103, Final Batch Loss: 0.03659053146839142\n",
      "Epoch 3601, Loss: 0.07315173000097275, Final Batch Loss: 0.038870058953762054\n",
      "Epoch 3602, Loss: 0.0884152501821518, Final Batch Loss: 0.05227562412619591\n",
      "Epoch 3603, Loss: 0.12361081317067146, Final Batch Loss: 0.06392835825681686\n",
      "Epoch 3604, Loss: 0.1237085647881031, Final Batch Loss: 0.06135446950793266\n",
      "Epoch 3605, Loss: 0.06707356125116348, Final Batch Loss: 0.026353750377893448\n",
      "Epoch 3606, Loss: 0.10564200207591057, Final Batch Loss: 0.05390864983201027\n",
      "Epoch 3607, Loss: 0.09382975473999977, Final Batch Loss: 0.05861537531018257\n",
      "Epoch 3608, Loss: 0.0710789505392313, Final Batch Loss: 0.030820319429039955\n",
      "Epoch 3609, Loss: 0.08812053129076958, Final Batch Loss: 0.047074560075998306\n",
      "Epoch 3610, Loss: 0.08016524091362953, Final Batch Loss: 0.032752275466918945\n",
      "Epoch 3611, Loss: 0.10068013519048691, Final Batch Loss: 0.035517796874046326\n",
      "Epoch 3612, Loss: 0.08767729997634888, Final Batch Loss: 0.04104360565543175\n",
      "Epoch 3613, Loss: 0.08307889848947525, Final Batch Loss: 0.0338444709777832\n",
      "Epoch 3614, Loss: 0.10011332295835018, Final Batch Loss: 0.07168431580066681\n",
      "Epoch 3615, Loss: 0.0927378349006176, Final Batch Loss: 0.04823392629623413\n",
      "Epoch 3616, Loss: 0.11252748221158981, Final Batch Loss: 0.05560581758618355\n",
      "Epoch 3617, Loss: 0.09170296229422092, Final Batch Loss: 0.06196574121713638\n",
      "Epoch 3618, Loss: 0.11887223646044731, Final Batch Loss: 0.05778178945183754\n",
      "Epoch 3619, Loss: 0.0843205638229847, Final Batch Loss: 0.04239954799413681\n",
      "Epoch 3620, Loss: 0.1625201292335987, Final Batch Loss: 0.05127805843949318\n",
      "Epoch 3621, Loss: 0.07622409425675869, Final Batch Loss: 0.030417805537581444\n",
      "Epoch 3622, Loss: 0.08678020536899567, Final Batch Loss: 0.04119202494621277\n",
      "Epoch 3623, Loss: 0.08948015421628952, Final Batch Loss: 0.05106191709637642\n",
      "Epoch 3624, Loss: 0.10561336763203144, Final Batch Loss: 0.0770411267876625\n",
      "Epoch 3625, Loss: 0.09264065325260162, Final Batch Loss: 0.040508564561605453\n",
      "Epoch 3626, Loss: 0.07972618192434311, Final Batch Loss: 0.03674938157200813\n",
      "Epoch 3627, Loss: 0.06236844323575497, Final Batch Loss: 0.025850938633084297\n",
      "Epoch 3628, Loss: 0.07974471524357796, Final Batch Loss: 0.03826144337654114\n",
      "Epoch 3629, Loss: 0.06864088587462902, Final Batch Loss: 0.04184940829873085\n",
      "Epoch 3630, Loss: 0.09161734953522682, Final Batch Loss: 0.040362097322940826\n",
      "Epoch 3631, Loss: 0.09696009755134583, Final Batch Loss: 0.05393671244382858\n",
      "Epoch 3632, Loss: 0.0923418402671814, Final Batch Loss: 0.03672078624367714\n",
      "Epoch 3633, Loss: 0.10741252079606056, Final Batch Loss: 0.04216689243912697\n",
      "Epoch 3634, Loss: 0.0820249505341053, Final Batch Loss: 0.035404887050390244\n",
      "Epoch 3635, Loss: 0.08606024831533432, Final Batch Loss: 0.043326251208782196\n",
      "Epoch 3636, Loss: 0.09860295429825783, Final Batch Loss: 0.052725277841091156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3637, Loss: 0.07336439751088619, Final Batch Loss: 0.04248730465769768\n",
      "Epoch 3638, Loss: 0.08345895633101463, Final Batch Loss: 0.04900021106004715\n",
      "Epoch 3639, Loss: 0.0760866031050682, Final Batch Loss: 0.03566202148795128\n",
      "Epoch 3640, Loss: 0.09979825839400291, Final Batch Loss: 0.04279908537864685\n",
      "Epoch 3641, Loss: 0.07849925756454468, Final Batch Loss: 0.03454413264989853\n",
      "Epoch 3642, Loss: 0.08878404647111893, Final Batch Loss: 0.05971796438097954\n",
      "Epoch 3643, Loss: 0.11389029026031494, Final Batch Loss: 0.06522130966186523\n",
      "Epoch 3644, Loss: 0.0869878027588129, Final Batch Loss: 0.0582699179649353\n",
      "Epoch 3645, Loss: 0.10818061232566833, Final Batch Loss: 0.03883085399866104\n",
      "Epoch 3646, Loss: 0.11140844970941544, Final Batch Loss: 0.07085487246513367\n",
      "Epoch 3647, Loss: 0.10436857119202614, Final Batch Loss: 0.031821172684431076\n",
      "Epoch 3648, Loss: 0.09299805015325546, Final Batch Loss: 0.04482128843665123\n",
      "Epoch 3649, Loss: 0.15975842624902725, Final Batch Loss: 0.05373748391866684\n",
      "Epoch 3650, Loss: 0.0795351006090641, Final Batch Loss: 0.026299361139535904\n",
      "Epoch 3651, Loss: 0.0977388396859169, Final Batch Loss: 0.046734753996133804\n",
      "Epoch 3652, Loss: 0.08809404820203781, Final Batch Loss: 0.03772960230708122\n",
      "Epoch 3653, Loss: 0.12005724012851715, Final Batch Loss: 0.04540582001209259\n",
      "Epoch 3654, Loss: 0.0794866532087326, Final Batch Loss: 0.037506215274333954\n",
      "Epoch 3655, Loss: 0.1519979164004326, Final Batch Loss: 0.05287925899028778\n",
      "Epoch 3656, Loss: 0.09572364389896393, Final Batch Loss: 0.057199690490961075\n",
      "Epoch 3657, Loss: 0.07117948867380619, Final Batch Loss: 0.03072085790336132\n",
      "Epoch 3658, Loss: 0.07610769383609295, Final Batch Loss: 0.028693268075585365\n",
      "Epoch 3659, Loss: 0.07522158697247505, Final Batch Loss: 0.021561887115240097\n",
      "Epoch 3660, Loss: 0.10677916556596756, Final Batch Loss: 0.031106755137443542\n",
      "Epoch 3661, Loss: 0.08530063554644585, Final Batch Loss: 0.03477763012051582\n",
      "Epoch 3662, Loss: 0.08338985219597816, Final Batch Loss: 0.05033878609538078\n",
      "Epoch 3663, Loss: 0.0850960798561573, Final Batch Loss: 0.03597468510270119\n",
      "Epoch 3664, Loss: 0.07936830073595047, Final Batch Loss: 0.030165016651153564\n",
      "Epoch 3665, Loss: 0.11506417393684387, Final Batch Loss: 0.04445604234933853\n",
      "Epoch 3666, Loss: 0.13302995264530182, Final Batch Loss: 0.09460810571908951\n",
      "Epoch 3667, Loss: 0.09731128439307213, Final Batch Loss: 0.05526663362979889\n",
      "Epoch 3668, Loss: 0.12210831418633461, Final Batch Loss: 0.06273198872804642\n",
      "Epoch 3669, Loss: 0.0865330882370472, Final Batch Loss: 0.052622366696596146\n",
      "Epoch 3670, Loss: 0.07046662643551826, Final Batch Loss: 0.030193455517292023\n",
      "Epoch 3671, Loss: 0.09873202815651894, Final Batch Loss: 0.06091547757387161\n",
      "Epoch 3672, Loss: 0.11112342029809952, Final Batch Loss: 0.07570633292198181\n",
      "Epoch 3673, Loss: 0.12116658315062523, Final Batch Loss: 0.08550500869750977\n",
      "Epoch 3674, Loss: 0.1616438552737236, Final Batch Loss: 0.11441086232662201\n",
      "Epoch 3675, Loss: 0.09196096658706665, Final Batch Loss: 0.04579263553023338\n",
      "Epoch 3676, Loss: 0.09103674069046974, Final Batch Loss: 0.04762247949838638\n",
      "Epoch 3677, Loss: 0.13520970195531845, Final Batch Loss: 0.09263003617525101\n",
      "Epoch 3678, Loss: 0.11053327471017838, Final Batch Loss: 0.06567902117967606\n",
      "Epoch 3679, Loss: 0.09892383217811584, Final Batch Loss: 0.03839937224984169\n",
      "Epoch 3680, Loss: 0.08870257809758186, Final Batch Loss: 0.031976375728845596\n",
      "Epoch 3681, Loss: 0.0991058424115181, Final Batch Loss: 0.04929724708199501\n",
      "Epoch 3682, Loss: 0.09149705246090889, Final Batch Loss: 0.041396237909793854\n",
      "Epoch 3683, Loss: 0.0838760994374752, Final Batch Loss: 0.05843875929713249\n",
      "Epoch 3684, Loss: 0.13098440319299698, Final Batch Loss: 0.038609541952610016\n",
      "Epoch 3685, Loss: 0.09721402823925018, Final Batch Loss: 0.04970969259738922\n",
      "Epoch 3686, Loss: 0.08628825098276138, Final Batch Loss: 0.03567344695329666\n",
      "Epoch 3687, Loss: 0.08680946007370949, Final Batch Loss: 0.051379911601543427\n",
      "Epoch 3688, Loss: 0.09122402593493462, Final Batch Loss: 0.026478055864572525\n",
      "Epoch 3689, Loss: 0.10708556696772575, Final Batch Loss: 0.04891938343644142\n",
      "Epoch 3690, Loss: 0.0879207942634821, Final Batch Loss: 0.06414906680583954\n",
      "Epoch 3691, Loss: 0.11031786352396011, Final Batch Loss: 0.054740406572818756\n",
      "Epoch 3692, Loss: 0.11011086031794548, Final Batch Loss: 0.05414454638957977\n",
      "Epoch 3693, Loss: 0.0879940316081047, Final Batch Loss: 0.051183559000492096\n",
      "Epoch 3694, Loss: 0.09859028458595276, Final Batch Loss: 0.0657278522849083\n",
      "Epoch 3695, Loss: 0.09874112904071808, Final Batch Loss: 0.0485321544110775\n",
      "Epoch 3696, Loss: 0.09354202821850777, Final Batch Loss: 0.0332636758685112\n",
      "Epoch 3697, Loss: 0.11070550233125687, Final Batch Loss: 0.05948479473590851\n",
      "Epoch 3698, Loss: 0.09010860696434975, Final Batch Loss: 0.04995989799499512\n",
      "Epoch 3699, Loss: 0.1186508797109127, Final Batch Loss: 0.05966578423976898\n",
      "Epoch 3700, Loss: 0.08456571400165558, Final Batch Loss: 0.03224250674247742\n",
      "Epoch 3701, Loss: 0.08970530331134796, Final Batch Loss: 0.03210318461060524\n",
      "Epoch 3702, Loss: 0.11942784488201141, Final Batch Loss: 0.0866456925868988\n",
      "Epoch 3703, Loss: 0.07756183668971062, Final Batch Loss: 0.04030938819050789\n",
      "Epoch 3704, Loss: 0.0772579237818718, Final Batch Loss: 0.028720393776893616\n",
      "Epoch 3705, Loss: 0.08627539500594139, Final Batch Loss: 0.04623257741332054\n",
      "Epoch 3706, Loss: 0.0830538421869278, Final Batch Loss: 0.020447060465812683\n",
      "Epoch 3707, Loss: 0.08238709717988968, Final Batch Loss: 0.051101770251989365\n",
      "Epoch 3708, Loss: 0.1201050914824009, Final Batch Loss: 0.06103779375553131\n",
      "Epoch 3709, Loss: 0.07473437115550041, Final Batch Loss: 0.040869876742362976\n",
      "Epoch 3710, Loss: 0.09348127990961075, Final Batch Loss: 0.03061734139919281\n",
      "Epoch 3711, Loss: 0.149724081158638, Final Batch Loss: 0.03838527947664261\n",
      "Epoch 3712, Loss: 0.0770404152572155, Final Batch Loss: 0.03302041441202164\n",
      "Epoch 3713, Loss: 0.09322897717356682, Final Batch Loss: 0.05296345800161362\n",
      "Epoch 3714, Loss: 0.09742256626486778, Final Batch Loss: 0.04775504022836685\n",
      "Epoch 3715, Loss: 0.0853884369134903, Final Batch Loss: 0.04400506988167763\n",
      "Epoch 3716, Loss: 0.10550342127680779, Final Batch Loss: 0.06288211792707443\n",
      "Epoch 3717, Loss: 0.0893014669418335, Final Batch Loss: 0.04986495152115822\n",
      "Epoch 3718, Loss: 0.08702890947461128, Final Batch Loss: 0.04291340336203575\n",
      "Epoch 3719, Loss: 0.0976250059902668, Final Batch Loss: 0.05437074229121208\n",
      "Epoch 3720, Loss: 0.08948001265525818, Final Batch Loss: 0.03504088521003723\n",
      "Epoch 3721, Loss: 0.0583580806851387, Final Batch Loss: 0.01435861736536026\n",
      "Epoch 3722, Loss: 0.08055328205227852, Final Batch Loss: 0.03325337544083595\n",
      "Epoch 3723, Loss: 0.09415461122989655, Final Batch Loss: 0.042021140456199646\n",
      "Epoch 3724, Loss: 0.08243370428681374, Final Batch Loss: 0.03652269020676613\n",
      "Epoch 3725, Loss: 0.10979650542140007, Final Batch Loss: 0.04478223994374275\n",
      "Epoch 3726, Loss: 0.07591797225177288, Final Batch Loss: 0.02751648612320423\n",
      "Epoch 3727, Loss: 0.13486547023057938, Final Batch Loss: 0.08810339868068695\n",
      "Epoch 3728, Loss: 0.06057038716971874, Final Batch Loss: 0.031662993133068085\n",
      "Epoch 3729, Loss: 0.05376470647752285, Final Batch Loss: 0.017378373071551323\n",
      "Epoch 3730, Loss: 0.0794808380305767, Final Batch Loss: 0.04622887820005417\n",
      "Epoch 3731, Loss: 0.08298951759934425, Final Batch Loss: 0.04919738322496414\n",
      "Epoch 3732, Loss: 0.09630607068538666, Final Batch Loss: 0.06017424538731575\n",
      "Epoch 3733, Loss: 0.1082516647875309, Final Batch Loss: 0.06433017551898956\n",
      "Epoch 3734, Loss: 0.07556707039475441, Final Batch Loss: 0.03279938921332359\n",
      "Epoch 3735, Loss: 0.08256630226969719, Final Batch Loss: 0.03282201662659645\n",
      "Epoch 3736, Loss: 0.0781836025416851, Final Batch Loss: 0.042741380631923676\n",
      "Epoch 3737, Loss: 0.06667211651802063, Final Batch Loss: 0.027315475046634674\n",
      "Epoch 3738, Loss: 0.08744752034544945, Final Batch Loss: 0.0483839213848114\n",
      "Epoch 3739, Loss: 0.08463042788207531, Final Batch Loss: 0.020746557042002678\n",
      "Epoch 3740, Loss: 0.12375262379646301, Final Batch Loss: 0.06285147368907928\n",
      "Epoch 3741, Loss: 0.08293839916586876, Final Batch Loss: 0.03192957863211632\n",
      "Epoch 3742, Loss: 0.07102946005761623, Final Batch Loss: 0.029587773606181145\n",
      "Epoch 3743, Loss: 0.09286493062973022, Final Batch Loss: 0.046158649027347565\n",
      "Epoch 3744, Loss: 0.08408253639936447, Final Batch Loss: 0.03445928171277046\n",
      "Epoch 3745, Loss: 0.07761724293231964, Final Batch Loss: 0.045301638543605804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3746, Loss: 0.13200915046036243, Final Batch Loss: 0.1090531051158905\n",
      "Epoch 3747, Loss: 0.10471418127417564, Final Batch Loss: 0.038962651044130325\n",
      "Epoch 3748, Loss: 0.11627718433737755, Final Batch Loss: 0.05908925086259842\n",
      "Epoch 3749, Loss: 0.14583561569452286, Final Batch Loss: 0.07137180119752884\n",
      "Epoch 3750, Loss: 0.06985852867364883, Final Batch Loss: 0.03629773110151291\n",
      "Epoch 3751, Loss: 0.11289391666650772, Final Batch Loss: 0.07924460619688034\n",
      "Epoch 3752, Loss: 0.11084414646029472, Final Batch Loss: 0.051995858550071716\n",
      "Epoch 3753, Loss: 0.09920002147555351, Final Batch Loss: 0.059253379702568054\n",
      "Epoch 3754, Loss: 0.09674481675028801, Final Batch Loss: 0.05231212452054024\n",
      "Epoch 3755, Loss: 0.10414274409413338, Final Batch Loss: 0.052018266171216965\n",
      "Epoch 3756, Loss: 0.09434802830219269, Final Batch Loss: 0.03988206014037132\n",
      "Epoch 3757, Loss: 0.08795585855841637, Final Batch Loss: 0.05634191632270813\n",
      "Epoch 3758, Loss: 0.08063094317913055, Final Batch Loss: 0.04707064479589462\n",
      "Epoch 3759, Loss: 0.07135961204767227, Final Batch Loss: 0.018508408218622208\n",
      "Epoch 3760, Loss: 0.0854814201593399, Final Batch Loss: 0.04920831322669983\n",
      "Epoch 3761, Loss: 0.07789123803377151, Final Batch Loss: 0.03509116545319557\n",
      "Epoch 3762, Loss: 0.14078227803111076, Final Batch Loss: 0.08833801746368408\n",
      "Epoch 3763, Loss: 0.0760137215256691, Final Batch Loss: 0.04085024446249008\n",
      "Epoch 3764, Loss: 0.11354481801390648, Final Batch Loss: 0.04588654264807701\n",
      "Epoch 3765, Loss: 0.07952456548810005, Final Batch Loss: 0.035232797265052795\n",
      "Epoch 3766, Loss: 0.09115548804402351, Final Batch Loss: 0.054643742740154266\n",
      "Epoch 3767, Loss: 0.07412767596542835, Final Batch Loss: 0.030367715284228325\n",
      "Epoch 3768, Loss: 0.29044458270072937, Final Batch Loss: 0.23924733698368073\n",
      "Epoch 3769, Loss: 0.0845923013985157, Final Batch Loss: 0.03674449399113655\n",
      "Epoch 3770, Loss: 0.1189998909831047, Final Batch Loss: 0.04198846220970154\n",
      "Epoch 3771, Loss: 0.08240108378231525, Final Batch Loss: 0.021192939952015877\n",
      "Epoch 3772, Loss: 0.08134940639138222, Final Batch Loss: 0.03891141340136528\n",
      "Epoch 3773, Loss: 0.08155199512839317, Final Batch Loss: 0.03395393490791321\n",
      "Epoch 3774, Loss: 0.0780605636537075, Final Batch Loss: 0.04348195344209671\n",
      "Epoch 3775, Loss: 0.21713735908269882, Final Batch Loss: 0.17762447893619537\n",
      "Epoch 3776, Loss: 0.10293456166982651, Final Batch Loss: 0.05365745723247528\n",
      "Epoch 3777, Loss: 0.15413964167237282, Final Batch Loss: 0.10124662518501282\n",
      "Epoch 3778, Loss: 0.10954822227358818, Final Batch Loss: 0.04407086595892906\n",
      "Epoch 3779, Loss: 0.10341917350888252, Final Batch Loss: 0.04965456202626228\n",
      "Epoch 3780, Loss: 0.09510327130556107, Final Batch Loss: 0.05433845520019531\n",
      "Epoch 3781, Loss: 0.11153167113661766, Final Batch Loss: 0.06565696001052856\n",
      "Epoch 3782, Loss: 0.09188731014728546, Final Batch Loss: 0.044518500566482544\n",
      "Epoch 3783, Loss: 0.12303193286061287, Final Batch Loss: 0.08107863366603851\n",
      "Epoch 3784, Loss: 0.10652755945920944, Final Batch Loss: 0.07137148082256317\n",
      "Epoch 3785, Loss: 0.1089581698179245, Final Batch Loss: 0.03533019870519638\n",
      "Epoch 3786, Loss: 0.08053848519921303, Final Batch Loss: 0.04676724970340729\n",
      "Epoch 3787, Loss: 0.11448080837726593, Final Batch Loss: 0.05431380122900009\n",
      "Epoch 3788, Loss: 0.11398771032691002, Final Batch Loss: 0.06648649275302887\n",
      "Epoch 3789, Loss: 0.10253872722387314, Final Batch Loss: 0.048968419432640076\n",
      "Epoch 3790, Loss: 0.10897769406437874, Final Batch Loss: 0.0483950600028038\n",
      "Epoch 3791, Loss: 0.09870518371462822, Final Batch Loss: 0.050240084528923035\n",
      "Epoch 3792, Loss: 0.1259855516254902, Final Batch Loss: 0.06624988466501236\n",
      "Epoch 3793, Loss: 0.09363647550344467, Final Batch Loss: 0.0510614737868309\n",
      "Epoch 3794, Loss: 0.1564587652683258, Final Batch Loss: 0.09481557458639145\n",
      "Epoch 3795, Loss: 0.10898543521761894, Final Batch Loss: 0.04820350185036659\n",
      "Epoch 3796, Loss: 0.0931277833878994, Final Batch Loss: 0.04311274364590645\n",
      "Epoch 3797, Loss: 0.08981743454933167, Final Batch Loss: 0.039767246693372726\n",
      "Epoch 3798, Loss: 0.08485250920057297, Final Batch Loss: 0.04694649204611778\n",
      "Epoch 3799, Loss: 0.08589606359601021, Final Batch Loss: 0.018883448094129562\n",
      "Epoch 3800, Loss: 0.11065954342484474, Final Batch Loss: 0.041598979383707047\n",
      "Epoch 3801, Loss: 0.08133655041456223, Final Batch Loss: 0.03140288218855858\n",
      "Epoch 3802, Loss: 0.0915917456150055, Final Batch Loss: 0.03064899891614914\n",
      "Epoch 3803, Loss: 0.11537124961614609, Final Batch Loss: 0.08709841221570969\n",
      "Epoch 3804, Loss: 0.08241495117545128, Final Batch Loss: 0.04692625254392624\n",
      "Epoch 3805, Loss: 0.08787263557314873, Final Batch Loss: 0.04644772782921791\n",
      "Epoch 3806, Loss: 0.07820793986320496, Final Batch Loss: 0.03598923608660698\n",
      "Epoch 3807, Loss: 0.08130354061722755, Final Batch Loss: 0.022419296205043793\n",
      "Epoch 3808, Loss: 0.0926365777850151, Final Batch Loss: 0.04947404935956001\n",
      "Epoch 3809, Loss: 0.0725097693502903, Final Batch Loss: 0.034405093640089035\n",
      "Epoch 3810, Loss: 0.06938532739877701, Final Batch Loss: 0.03954518213868141\n",
      "Epoch 3811, Loss: 0.07667132839560509, Final Batch Loss: 0.040839776396751404\n",
      "Epoch 3812, Loss: 0.07297795079648495, Final Batch Loss: 0.02992076240479946\n",
      "Epoch 3813, Loss: 0.07746976986527443, Final Batch Loss: 0.030286431312561035\n",
      "Epoch 3814, Loss: 0.08019165135920048, Final Batch Loss: 0.05408306047320366\n",
      "Epoch 3815, Loss: 0.08545052260160446, Final Batch Loss: 0.0604662261903286\n",
      "Epoch 3816, Loss: 0.0952276811003685, Final Batch Loss: 0.03136243671178818\n",
      "Epoch 3817, Loss: 0.07736916467547417, Final Batch Loss: 0.044807352125644684\n",
      "Epoch 3818, Loss: 0.08052836917340755, Final Batch Loss: 0.027620801702141762\n",
      "Epoch 3819, Loss: 0.09700508043169975, Final Batch Loss: 0.015887994319200516\n",
      "Epoch 3820, Loss: 0.07012691162526608, Final Batch Loss: 0.027870235964655876\n",
      "Epoch 3821, Loss: 0.0984816662967205, Final Batch Loss: 0.03418911620974541\n",
      "Epoch 3822, Loss: 0.0880734845995903, Final Batch Loss: 0.04450153186917305\n",
      "Epoch 3823, Loss: 0.07642745971679688, Final Batch Loss: 0.04015129432082176\n",
      "Epoch 3824, Loss: 0.1275860108435154, Final Batch Loss: 0.09040439128875732\n",
      "Epoch 3825, Loss: 0.07464434951543808, Final Batch Loss: 0.037219829857349396\n",
      "Epoch 3826, Loss: 0.09703056514263153, Final Batch Loss: 0.06574951857328415\n",
      "Epoch 3827, Loss: 0.09211678057909012, Final Batch Loss: 0.0527176596224308\n",
      "Epoch 3828, Loss: 0.07147502712905407, Final Batch Loss: 0.044800128787755966\n",
      "Epoch 3829, Loss: 0.14152561128139496, Final Batch Loss: 0.10153485089540482\n",
      "Epoch 3830, Loss: 0.07017525844275951, Final Batch Loss: 0.044564634561538696\n",
      "Epoch 3831, Loss: 0.07608268409967422, Final Batch Loss: 0.04312047362327576\n",
      "Epoch 3832, Loss: 0.09181182272732258, Final Batch Loss: 0.06300922483205795\n",
      "Epoch 3833, Loss: 0.12920060753822327, Final Batch Loss: 0.09464704245328903\n",
      "Epoch 3834, Loss: 0.08748331665992737, Final Batch Loss: 0.035691890865564346\n",
      "Epoch 3835, Loss: 0.08479303494095802, Final Batch Loss: 0.0360775887966156\n",
      "Epoch 3836, Loss: 0.13819314539432526, Final Batch Loss: 0.09398999065160751\n",
      "Epoch 3837, Loss: 0.09813247248530388, Final Batch Loss: 0.037139371037483215\n",
      "Epoch 3838, Loss: 0.12339833006262779, Final Batch Loss: 0.059840235859155655\n",
      "Epoch 3839, Loss: 0.09656344726681709, Final Batch Loss: 0.054574400186538696\n",
      "Epoch 3840, Loss: 0.08536393567919731, Final Batch Loss: 0.046712446957826614\n",
      "Epoch 3841, Loss: 0.09850757196545601, Final Batch Loss: 0.06552077829837799\n",
      "Epoch 3842, Loss: 0.07499329373240471, Final Batch Loss: 0.02241024374961853\n",
      "Epoch 3843, Loss: 0.08007587306201458, Final Batch Loss: 0.049670927226543427\n",
      "Epoch 3844, Loss: 0.08803445473313332, Final Batch Loss: 0.0378270223736763\n",
      "Epoch 3845, Loss: 0.07699524238705635, Final Batch Loss: 0.04062839597463608\n",
      "Epoch 3846, Loss: 0.08766677603125572, Final Batch Loss: 0.0443306565284729\n",
      "Epoch 3847, Loss: 0.08889514580368996, Final Batch Loss: 0.05615480989217758\n",
      "Epoch 3848, Loss: 0.06945741921663284, Final Batch Loss: 0.03183655068278313\n",
      "Epoch 3849, Loss: 0.09513705037534237, Final Batch Loss: 0.029883122071623802\n",
      "Epoch 3850, Loss: 0.10506360605359077, Final Batch Loss: 0.04817803576588631\n",
      "Epoch 3851, Loss: 0.07654834911227226, Final Batch Loss: 0.038259923458099365\n",
      "Epoch 3852, Loss: 0.12385000288486481, Final Batch Loss: 0.08558346331119537\n",
      "Epoch 3853, Loss: 0.12515414506196976, Final Batch Loss: 0.07539234310388565\n",
      "Epoch 3854, Loss: 0.09543704241514206, Final Batch Loss: 0.04939974471926689\n",
      "Epoch 3855, Loss: 0.08974302187561989, Final Batch Loss: 0.04061194509267807\n",
      "Epoch 3856, Loss: 0.10236473754048347, Final Batch Loss: 0.04799439013004303\n",
      "Epoch 3857, Loss: 0.14183611422777176, Final Batch Loss: 0.07644175738096237\n",
      "Epoch 3858, Loss: 0.06181107647716999, Final Batch Loss: 0.03581090271472931\n",
      "Epoch 3859, Loss: 0.0884513407945633, Final Batch Loss: 0.06718700379133224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3860, Loss: 0.1796933114528656, Final Batch Loss: 0.10631223022937775\n",
      "Epoch 3861, Loss: 0.07102014869451523, Final Batch Loss: 0.04207063466310501\n",
      "Epoch 3862, Loss: 0.1984129399061203, Final Batch Loss: 0.1515401303768158\n",
      "Epoch 3863, Loss: 0.1797766536474228, Final Batch Loss: 0.12510401010513306\n",
      "Epoch 3864, Loss: 0.10169326141476631, Final Batch Loss: 0.04379856958985329\n",
      "Epoch 3865, Loss: 0.0843459852039814, Final Batch Loss: 0.047101546078920364\n",
      "Epoch 3866, Loss: 0.09800475090742111, Final Batch Loss: 0.048723917454481125\n",
      "Epoch 3867, Loss: 0.10669222474098206, Final Batch Loss: 0.039500296115875244\n",
      "Epoch 3868, Loss: 0.1043158657848835, Final Batch Loss: 0.05168561637401581\n",
      "Epoch 3869, Loss: 0.13238602131605148, Final Batch Loss: 0.09772325307130814\n",
      "Epoch 3870, Loss: 0.09451813250780106, Final Batch Loss: 0.0427093543112278\n",
      "Epoch 3871, Loss: 0.07469206675887108, Final Batch Loss: 0.04333186149597168\n",
      "Epoch 3872, Loss: 0.09586227312684059, Final Batch Loss: 0.05667620897293091\n",
      "Epoch 3873, Loss: 0.09945914149284363, Final Batch Loss: 0.04373834654688835\n",
      "Epoch 3874, Loss: 0.09424113854765892, Final Batch Loss: 0.0344155915081501\n",
      "Epoch 3875, Loss: 0.11662245914340019, Final Batch Loss: 0.06510750949382782\n",
      "Epoch 3876, Loss: 0.11973004415631294, Final Batch Loss: 0.04263508692383766\n",
      "Epoch 3877, Loss: 0.13833454623818398, Final Batch Loss: 0.10693175345659256\n",
      "Epoch 3878, Loss: 0.13646557927131653, Final Batch Loss: 0.09483564645051956\n",
      "Epoch 3879, Loss: 0.07336480170488358, Final Batch Loss: 0.04487360268831253\n",
      "Epoch 3880, Loss: 0.09862445294857025, Final Batch Loss: 0.03645244613289833\n",
      "Epoch 3881, Loss: 0.08181175217032433, Final Batch Loss: 0.051259301602840424\n",
      "Epoch 3882, Loss: 0.08386793360114098, Final Batch Loss: 0.050659578293561935\n",
      "Epoch 3883, Loss: 0.09529129602015018, Final Batch Loss: 0.0721161812543869\n",
      "Epoch 3884, Loss: 0.10133763030171394, Final Batch Loss: 0.061909399926662445\n",
      "Epoch 3885, Loss: 0.08588758483529091, Final Batch Loss: 0.04511452093720436\n",
      "Epoch 3886, Loss: 0.07668101973831654, Final Batch Loss: 0.028886737301945686\n",
      "Epoch 3887, Loss: 0.07590413838624954, Final Batch Loss: 0.03555307537317276\n",
      "Epoch 3888, Loss: 0.08297142758965492, Final Batch Loss: 0.033754751086235046\n",
      "Epoch 3889, Loss: 0.11939392238855362, Final Batch Loss: 0.03965764492750168\n",
      "Epoch 3890, Loss: 0.08802005276083946, Final Batch Loss: 0.039968062192201614\n",
      "Epoch 3891, Loss: 0.12958919629454613, Final Batch Loss: 0.09699026495218277\n",
      "Epoch 3892, Loss: 0.08875418826937675, Final Batch Loss: 0.03969785198569298\n",
      "Epoch 3893, Loss: 0.06249368004500866, Final Batch Loss: 0.028230657801032066\n",
      "Epoch 3894, Loss: 0.09962091594934464, Final Batch Loss: 0.04658518731594086\n",
      "Epoch 3895, Loss: 0.07532718032598495, Final Batch Loss: 0.031030282378196716\n",
      "Epoch 3896, Loss: 0.0872812569141388, Final Batch Loss: 0.036819297820329666\n",
      "Epoch 3897, Loss: 0.0971554908901453, Final Batch Loss: 0.06909245252609253\n",
      "Epoch 3898, Loss: 0.07654426619410515, Final Batch Loss: 0.03731846809387207\n",
      "Epoch 3899, Loss: 0.08739454671740532, Final Batch Loss: 0.03920356184244156\n",
      "Epoch 3900, Loss: 0.08329038694500923, Final Batch Loss: 0.04809022694826126\n",
      "Epoch 3901, Loss: 0.09157327190041542, Final Batch Loss: 0.06691251695156097\n",
      "Epoch 3902, Loss: 0.0671665146946907, Final Batch Loss: 0.029967807233333588\n",
      "Epoch 3903, Loss: 0.08042156882584095, Final Batch Loss: 0.021284880116581917\n",
      "Epoch 3904, Loss: 0.12321510910987854, Final Batch Loss: 0.05069226026535034\n",
      "Epoch 3905, Loss: 0.0977507121860981, Final Batch Loss: 0.036309387534856796\n",
      "Epoch 3906, Loss: 0.08369184285402298, Final Batch Loss: 0.042467229068279266\n",
      "Epoch 3907, Loss: 0.10880135744810104, Final Batch Loss: 0.06381046772003174\n",
      "Epoch 3908, Loss: 0.056093718856573105, Final Batch Loss: 0.029137149453163147\n",
      "Epoch 3909, Loss: 0.0648379735648632, Final Batch Loss: 0.031738944351673126\n",
      "Epoch 3910, Loss: 0.09688126295804977, Final Batch Loss: 0.05877348408102989\n",
      "Epoch 3911, Loss: 0.07486353069543839, Final Batch Loss: 0.0419614315032959\n",
      "Epoch 3912, Loss: 0.08234212920069695, Final Batch Loss: 0.02423439547419548\n",
      "Epoch 3913, Loss: 0.07592928409576416, Final Batch Loss: 0.037828002125024796\n",
      "Epoch 3914, Loss: 0.09634270519018173, Final Batch Loss: 0.03602918982505798\n",
      "Epoch 3915, Loss: 0.08672648295760155, Final Batch Loss: 0.04587197303771973\n",
      "Epoch 3916, Loss: 0.06739361025393009, Final Batch Loss: 0.02546142227947712\n",
      "Epoch 3917, Loss: 0.088401660323143, Final Batch Loss: 0.05659809336066246\n",
      "Epoch 3918, Loss: 0.09275192767381668, Final Batch Loss: 0.05292476341128349\n",
      "Epoch 3919, Loss: 0.10502219200134277, Final Batch Loss: 0.04776071757078171\n",
      "Epoch 3920, Loss: 0.057451991364359856, Final Batch Loss: 0.03428960219025612\n",
      "Epoch 3921, Loss: 0.0987035445868969, Final Batch Loss: 0.040834590792655945\n",
      "Epoch 3922, Loss: 0.06739460676908493, Final Batch Loss: 0.041035886853933334\n",
      "Epoch 3923, Loss: 0.1087791658937931, Final Batch Loss: 0.05532515048980713\n",
      "Epoch 3924, Loss: 0.0944778136909008, Final Batch Loss: 0.056070681661367416\n",
      "Epoch 3925, Loss: 0.07744088396430016, Final Batch Loss: 0.04774089157581329\n",
      "Epoch 3926, Loss: 0.131706815212965, Final Batch Loss: 0.09035152941942215\n",
      "Epoch 3927, Loss: 0.06849635764956474, Final Batch Loss: 0.031904447823762894\n",
      "Epoch 3928, Loss: 0.07790211029350758, Final Batch Loss: 0.02505536563694477\n",
      "Epoch 3929, Loss: 0.11340789124369621, Final Batch Loss: 0.049338165670633316\n",
      "Epoch 3930, Loss: 0.09449604526162148, Final Batch Loss: 0.05892319977283478\n",
      "Epoch 3931, Loss: 0.1024077907204628, Final Batch Loss: 0.0401960052549839\n",
      "Epoch 3932, Loss: 0.08706017769873142, Final Batch Loss: 0.02183772809803486\n",
      "Epoch 3933, Loss: 0.08142621256411076, Final Batch Loss: 0.028924545273184776\n",
      "Epoch 3934, Loss: 0.07517876848578453, Final Batch Loss: 0.039611298590898514\n",
      "Epoch 3935, Loss: 0.083159189671278, Final Batch Loss: 0.03527679294347763\n",
      "Epoch 3936, Loss: 0.09481528401374817, Final Batch Loss: 0.04945116117596626\n",
      "Epoch 3937, Loss: 0.09111864492297173, Final Batch Loss: 0.054082173854112625\n",
      "Epoch 3938, Loss: 0.11042611673474312, Final Batch Loss: 0.059878308326005936\n",
      "Epoch 3939, Loss: 0.0948069728910923, Final Batch Loss: 0.05573408305644989\n",
      "Epoch 3940, Loss: 0.09067026898264885, Final Batch Loss: 0.060090962797403336\n",
      "Epoch 3941, Loss: 0.0769097562879324, Final Batch Loss: 0.04733411967754364\n",
      "Epoch 3942, Loss: 0.11673199012875557, Final Batch Loss: 0.047848086804151535\n",
      "Epoch 3943, Loss: 0.11713907867670059, Final Batch Loss: 0.08456433564424515\n",
      "Epoch 3944, Loss: 0.09774332866072655, Final Batch Loss: 0.060911525040864944\n",
      "Epoch 3945, Loss: 0.0997236929833889, Final Batch Loss: 0.058574408292770386\n",
      "Epoch 3946, Loss: 0.08994372934103012, Final Batch Loss: 0.04865606501698494\n",
      "Epoch 3947, Loss: 0.08201806619763374, Final Batch Loss: 0.04448217153549194\n",
      "Epoch 3948, Loss: 0.09412162005901337, Final Batch Loss: 0.05236450210213661\n",
      "Epoch 3949, Loss: 0.11449329741299152, Final Batch Loss: 0.025829965248703957\n",
      "Epoch 3950, Loss: 0.14299888536334038, Final Batch Loss: 0.08470407128334045\n",
      "Epoch 3951, Loss: 0.09662662819027901, Final Batch Loss: 0.0431736595928669\n",
      "Epoch 3952, Loss: 0.08594491519033909, Final Batch Loss: 0.05495411902666092\n",
      "Epoch 3953, Loss: 0.09485133923590183, Final Batch Loss: 0.030139239504933357\n",
      "Epoch 3954, Loss: 0.0793621800839901, Final Batch Loss: 0.0394442193210125\n",
      "Epoch 3955, Loss: 0.09615299105644226, Final Batch Loss: 0.04155351221561432\n",
      "Epoch 3956, Loss: 0.08928950503468513, Final Batch Loss: 0.046391844749450684\n",
      "Epoch 3957, Loss: 0.08991137146949768, Final Batch Loss: 0.05116602033376694\n",
      "Epoch 3958, Loss: 0.09210026264190674, Final Batch Loss: 0.0494670607149601\n",
      "Epoch 3959, Loss: 0.11566821485757828, Final Batch Loss: 0.04728212207555771\n",
      "Epoch 3960, Loss: 0.09249812364578247, Final Batch Loss: 0.047850534319877625\n",
      "Epoch 3961, Loss: 0.07247165404260159, Final Batch Loss: 0.04444834962487221\n",
      "Epoch 3962, Loss: 0.09324995800852776, Final Batch Loss: 0.04360876604914665\n",
      "Epoch 3963, Loss: 0.10177474841475487, Final Batch Loss: 0.050414808094501495\n",
      "Epoch 3964, Loss: 0.07708001136779785, Final Batch Loss: 0.03733275085687637\n",
      "Epoch 3965, Loss: 0.1484505534172058, Final Batch Loss: 0.08451775461435318\n",
      "Epoch 3966, Loss: 0.0817943587899208, Final Batch Loss: 0.03377464413642883\n",
      "Epoch 3967, Loss: 0.10310220718383789, Final Batch Loss: 0.03147722780704498\n",
      "Epoch 3968, Loss: 0.13341942057013512, Final Batch Loss: 0.030177336186170578\n",
      "Epoch 3969, Loss: 0.14853303506970406, Final Batch Loss: 0.039012130349874496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3970, Loss: 0.08268719911575317, Final Batch Loss: 0.02867775782942772\n",
      "Epoch 3971, Loss: 0.07514330372214317, Final Batch Loss: 0.026453454047441483\n",
      "Epoch 3972, Loss: 0.16334955021739006, Final Batch Loss: 0.05234338715672493\n",
      "Epoch 3973, Loss: 0.09630610421299934, Final Batch Loss: 0.06689305603504181\n",
      "Epoch 3974, Loss: 0.09939304739236832, Final Batch Loss: 0.03982769697904587\n",
      "Epoch 3975, Loss: 0.10187681391835213, Final Batch Loss: 0.05991588532924652\n",
      "Epoch 3976, Loss: 0.05804113484919071, Final Batch Loss: 0.022109145298600197\n",
      "Epoch 3977, Loss: 0.0788678228855133, Final Batch Loss: 0.04691309109330177\n",
      "Epoch 3978, Loss: 0.14641014114022255, Final Batch Loss: 0.05558159574866295\n",
      "Epoch 3979, Loss: 0.14266594499349594, Final Batch Loss: 0.09969446808099747\n",
      "Epoch 3980, Loss: 0.08682051673531532, Final Batch Loss: 0.05211286246776581\n",
      "Epoch 3981, Loss: 0.11866911873221397, Final Batch Loss: 0.0654582604765892\n",
      "Epoch 3982, Loss: 0.11383124813437462, Final Batch Loss: 0.08040077984333038\n",
      "Epoch 3983, Loss: 0.08000757172703743, Final Batch Loss: 0.0587388351559639\n",
      "Epoch 3984, Loss: 0.1372939720749855, Final Batch Loss: 0.07795640081167221\n",
      "Epoch 3985, Loss: 0.07442334480583668, Final Batch Loss: 0.04454789310693741\n",
      "Epoch 3986, Loss: 0.07637937366962433, Final Batch Loss: 0.027501676231622696\n",
      "Epoch 3987, Loss: 0.07620161026716232, Final Batch Loss: 0.026962317526340485\n",
      "Epoch 3988, Loss: 0.0813478771597147, Final Batch Loss: 0.024821998551487923\n",
      "Epoch 3989, Loss: 0.07281227223575115, Final Batch Loss: 0.03081958182156086\n",
      "Epoch 3990, Loss: 0.08279809355735779, Final Batch Loss: 0.042219094932079315\n",
      "Epoch 3991, Loss: 0.07954403012990952, Final Batch Loss: 0.03154580667614937\n",
      "Epoch 3992, Loss: 0.08950579538941383, Final Batch Loss: 0.04147670045495033\n",
      "Epoch 3993, Loss: 0.06282622553408146, Final Batch Loss: 0.02617134340107441\n",
      "Epoch 3994, Loss: 0.0770480465143919, Final Batch Loss: 0.04805367439985275\n",
      "Epoch 3995, Loss: 0.102774977684021, Final Batch Loss: 0.07094980031251907\n",
      "Epoch 3996, Loss: 0.07294828072190285, Final Batch Loss: 0.032677631825208664\n",
      "Epoch 3997, Loss: 0.07018008828163147, Final Batch Loss: 0.0346536859869957\n",
      "Epoch 3998, Loss: 0.068789167329669, Final Batch Loss: 0.04289993271231651\n",
      "Epoch 3999, Loss: 0.06690645776689053, Final Batch Loss: 0.04090278223156929\n",
      "Epoch 4000, Loss: 0.1083080805838108, Final Batch Loss: 0.03572768345475197\n",
      "Epoch 4001, Loss: 0.07841360941529274, Final Batch Loss: 0.04463688284158707\n",
      "Epoch 4002, Loss: 0.14890354871749878, Final Batch Loss: 0.1077357605099678\n",
      "Epoch 4003, Loss: 0.07310319878160954, Final Batch Loss: 0.025450611487030983\n",
      "Epoch 4004, Loss: 0.06541458331048489, Final Batch Loss: 0.04289614036679268\n",
      "Epoch 4005, Loss: 0.07718641683459282, Final Batch Loss: 0.03580162674188614\n",
      "Epoch 4006, Loss: 0.06559795700013638, Final Batch Loss: 0.03474321961402893\n",
      "Epoch 4007, Loss: 0.1027199923992157, Final Batch Loss: 0.04146742448210716\n",
      "Epoch 4008, Loss: 0.05617720074951649, Final Batch Loss: 0.01787497289478779\n",
      "Epoch 4009, Loss: 0.07911057583987713, Final Batch Loss: 0.05099337920546532\n",
      "Epoch 4010, Loss: 0.06644453667104244, Final Batch Loss: 0.03068883903324604\n",
      "Epoch 4011, Loss: 0.08233729004859924, Final Batch Loss: 0.04043663665652275\n",
      "Epoch 4012, Loss: 0.12306276336312294, Final Batch Loss: 0.07447083294391632\n",
      "Epoch 4013, Loss: 0.08318249508738518, Final Batch Loss: 0.039391230791807175\n",
      "Epoch 4014, Loss: 0.06975040212273598, Final Batch Loss: 0.025344014167785645\n",
      "Epoch 4015, Loss: 0.08254072070121765, Final Batch Loss: 0.05000239610671997\n",
      "Epoch 4016, Loss: 0.1120445765554905, Final Batch Loss: 0.06985080242156982\n",
      "Epoch 4017, Loss: 0.08727884665131569, Final Batch Loss: 0.04428528621792793\n",
      "Epoch 4018, Loss: 0.06826794520020485, Final Batch Loss: 0.028196044266223907\n",
      "Epoch 4019, Loss: 0.07526431605219841, Final Batch Loss: 0.03173412010073662\n",
      "Epoch 4020, Loss: 0.08943518251180649, Final Batch Loss: 0.047526292502880096\n",
      "Epoch 4021, Loss: 0.11442873626947403, Final Batch Loss: 0.03766892850399017\n",
      "Epoch 4022, Loss: 0.07697056233882904, Final Batch Loss: 0.03318048268556595\n",
      "Epoch 4023, Loss: 0.06778981536626816, Final Batch Loss: 0.04009028524160385\n",
      "Epoch 4024, Loss: 0.08406627550721169, Final Batch Loss: 0.015122827142477036\n",
      "Epoch 4025, Loss: 0.09269373491406441, Final Batch Loss: 0.04037529602646828\n",
      "Epoch 4026, Loss: 0.09138607978820801, Final Batch Loss: 0.048281479626894\n",
      "Epoch 4027, Loss: 0.07212925516068935, Final Batch Loss: 0.046713974326848984\n",
      "Epoch 4028, Loss: 0.10353441163897514, Final Batch Loss: 0.06926722824573517\n",
      "Epoch 4029, Loss: 0.10417941585183144, Final Batch Loss: 0.0401461161673069\n",
      "Epoch 4030, Loss: 0.07376327738165855, Final Batch Loss: 0.02550218254327774\n",
      "Epoch 4031, Loss: 0.19683057069778442, Final Batch Loss: 0.10232598334550858\n",
      "Epoch 4032, Loss: 0.11058617010712624, Final Batch Loss: 0.07715287059545517\n",
      "Epoch 4033, Loss: 0.09914705157279968, Final Batch Loss: 0.043656688183546066\n",
      "Epoch 4034, Loss: 0.1945415586233139, Final Batch Loss: 0.07541349530220032\n",
      "Epoch 4035, Loss: 0.15586788579821587, Final Batch Loss: 0.09359590709209442\n",
      "Epoch 4036, Loss: 0.11874210834503174, Final Batch Loss: 0.060352638363838196\n",
      "Epoch 4037, Loss: 0.09305023029446602, Final Batch Loss: 0.04459412768483162\n",
      "Epoch 4038, Loss: 0.10148866847157478, Final Batch Loss: 0.04617833346128464\n",
      "Epoch 4039, Loss: 0.09950069710612297, Final Batch Loss: 0.03947165980935097\n",
      "Epoch 4040, Loss: 0.13443369418382645, Final Batch Loss: 0.0849214494228363\n",
      "Epoch 4041, Loss: 0.06483147479593754, Final Batch Loss: 0.02524779923260212\n",
      "Epoch 4042, Loss: 0.12635913491249084, Final Batch Loss: 0.07534285634756088\n",
      "Epoch 4043, Loss: 0.11974431201815605, Final Batch Loss: 0.06887149810791016\n",
      "Epoch 4044, Loss: 0.14527206867933273, Final Batch Loss: 0.10839256644248962\n",
      "Epoch 4045, Loss: 0.07244590297341347, Final Batch Loss: 0.02635141834616661\n",
      "Epoch 4046, Loss: 0.0645343828946352, Final Batch Loss: 0.02316862903535366\n",
      "Epoch 4047, Loss: 0.07988196797668934, Final Batch Loss: 0.05651189014315605\n",
      "Epoch 4048, Loss: 0.07449755817651749, Final Batch Loss: 0.04750516265630722\n",
      "Epoch 4049, Loss: 0.12879199162125587, Final Batch Loss: 0.06931079179048538\n",
      "Epoch 4050, Loss: 0.1019404586404562, Final Batch Loss: 0.029910093173384666\n",
      "Epoch 4051, Loss: 0.08556313440203667, Final Batch Loss: 0.046602874994277954\n",
      "Epoch 4052, Loss: 0.09996571019291878, Final Batch Loss: 0.05749564245343208\n",
      "Epoch 4053, Loss: 0.10912271589040756, Final Batch Loss: 0.036207154393196106\n",
      "Epoch 4054, Loss: 0.0805552713572979, Final Batch Loss: 0.04187871143221855\n",
      "Epoch 4055, Loss: 0.0720259752124548, Final Batch Loss: 0.0303377453237772\n",
      "Epoch 4056, Loss: 0.11361093446612358, Final Batch Loss: 0.06846015900373459\n",
      "Epoch 4057, Loss: 0.08804238587617874, Final Batch Loss: 0.049696169793605804\n",
      "Epoch 4058, Loss: 0.0787565391510725, Final Batch Loss: 0.027860896661877632\n",
      "Epoch 4059, Loss: 0.0657520703971386, Final Batch Loss: 0.03171658143401146\n",
      "Epoch 4060, Loss: 0.08367228135466576, Final Batch Loss: 0.03722352162003517\n",
      "Epoch 4061, Loss: 0.11244616284966469, Final Batch Loss: 0.06981503218412399\n",
      "Epoch 4062, Loss: 0.07992365956306458, Final Batch Loss: 0.03045157715678215\n",
      "Epoch 4063, Loss: 0.11026609316468239, Final Batch Loss: 0.042583342641592026\n",
      "Epoch 4064, Loss: 0.08689511567354202, Final Batch Loss: 0.018376938998699188\n",
      "Epoch 4065, Loss: 0.11274426430463791, Final Batch Loss: 0.05019621551036835\n",
      "Epoch 4066, Loss: 0.08232956379652023, Final Batch Loss: 0.03452550247311592\n",
      "Epoch 4067, Loss: 0.0835266001522541, Final Batch Loss: 0.03427786007523537\n",
      "Epoch 4068, Loss: 0.08630968257784843, Final Batch Loss: 0.05030004680156708\n",
      "Epoch 4069, Loss: 0.09125961735844612, Final Batch Loss: 0.04526011645793915\n",
      "Epoch 4070, Loss: 0.06828633695840836, Final Batch Loss: 0.046950045973062515\n",
      "Epoch 4071, Loss: 0.11237866804003716, Final Batch Loss: 0.0688195452094078\n",
      "Epoch 4072, Loss: 0.07707091420888901, Final Batch Loss: 0.030302494764328003\n",
      "Epoch 4073, Loss: 0.18754858523607254, Final Batch Loss: 0.14210793375968933\n",
      "Epoch 4074, Loss: 0.10418575629591942, Final Batch Loss: 0.02644990012049675\n",
      "Epoch 4075, Loss: 0.13710331916809082, Final Batch Loss: 0.08912750333547592\n",
      "Epoch 4076, Loss: 0.2226850911974907, Final Batch Loss: 0.12158575654029846\n",
      "Epoch 4077, Loss: 0.14262567460536957, Final Batch Loss: 0.06872562319040298\n",
      "Epoch 4078, Loss: 0.1309092454612255, Final Batch Loss: 0.08797115087509155\n",
      "Epoch 4079, Loss: 0.1211724728345871, Final Batch Loss: 0.059217434376478195\n",
      "Epoch 4080, Loss: 0.09959781169891357, Final Batch Loss: 0.06065685674548149\n",
      "Epoch 4081, Loss: 0.09088309109210968, Final Batch Loss: 0.04006590694189072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4082, Loss: 0.09004307352006435, Final Batch Loss: 0.02691364847123623\n",
      "Epoch 4083, Loss: 0.11747893318533897, Final Batch Loss: 0.0264594666659832\n",
      "Epoch 4084, Loss: 0.12237003445625305, Final Batch Loss: 0.047307342290878296\n",
      "Epoch 4085, Loss: 0.10537891834974289, Final Batch Loss: 0.04737516865134239\n",
      "Epoch 4086, Loss: 0.10380933061242104, Final Batch Loss: 0.0319543220102787\n",
      "Epoch 4087, Loss: 0.0785459466278553, Final Batch Loss: 0.041904278099536896\n",
      "Epoch 4088, Loss: 0.08070449903607368, Final Batch Loss: 0.04125341400504112\n",
      "Epoch 4089, Loss: 0.1228165365755558, Final Batch Loss: 0.0505814291536808\n",
      "Epoch 4090, Loss: 0.08003582432866096, Final Batch Loss: 0.05885164439678192\n",
      "Epoch 4091, Loss: 0.08659160137176514, Final Batch Loss: 0.06132159009575844\n",
      "Epoch 4092, Loss: 0.09201669320464134, Final Batch Loss: 0.05556539446115494\n",
      "Epoch 4093, Loss: 0.07986306771636009, Final Batch Loss: 0.036811091005802155\n",
      "Epoch 4094, Loss: 0.0907442755997181, Final Batch Loss: 0.04959600791335106\n",
      "Epoch 4095, Loss: 0.08429257571697235, Final Batch Loss: 0.04814959317445755\n",
      "Epoch 4096, Loss: 0.08184092864394188, Final Batch Loss: 0.04855814948678017\n",
      "Epoch 4097, Loss: 0.07869784161448479, Final Batch Loss: 0.042388830333948135\n",
      "Epoch 4098, Loss: 0.07209769636392593, Final Batch Loss: 0.031707312911748886\n",
      "Epoch 4099, Loss: 0.10464198514819145, Final Batch Loss: 0.06837505102157593\n",
      "Epoch 4100, Loss: 0.08386045321822166, Final Batch Loss: 0.04473671689629555\n",
      "Epoch 4101, Loss: 0.07359549775719643, Final Batch Loss: 0.03566262871026993\n",
      "Epoch 4102, Loss: 0.08305206522345543, Final Batch Loss: 0.018029656261205673\n",
      "Epoch 4103, Loss: 0.07134419120848179, Final Batch Loss: 0.04779893532395363\n",
      "Epoch 4104, Loss: 0.074701689183712, Final Batch Loss: 0.042705390602350235\n",
      "Epoch 4105, Loss: 0.08777865394949913, Final Batch Loss: 0.038246966898441315\n",
      "Epoch 4106, Loss: 0.08012629300355911, Final Batch Loss: 0.03744529187679291\n",
      "Epoch 4107, Loss: 0.11531610414385796, Final Batch Loss: 0.07980173826217651\n",
      "Epoch 4108, Loss: 0.08798094838857651, Final Batch Loss: 0.040768180042505264\n",
      "Epoch 4109, Loss: 0.08489333465695381, Final Batch Loss: 0.04223906621336937\n",
      "Epoch 4110, Loss: 0.0751857478171587, Final Batch Loss: 0.024675646796822548\n",
      "Epoch 4111, Loss: 0.10639605671167374, Final Batch Loss: 0.06761449575424194\n",
      "Epoch 4112, Loss: 0.11185330897569656, Final Batch Loss: 0.0388975590467453\n",
      "Epoch 4113, Loss: 0.09490616619586945, Final Batch Loss: 0.0546022392809391\n",
      "Epoch 4114, Loss: 0.08296201378107071, Final Batch Loss: 0.048128530383110046\n",
      "Epoch 4115, Loss: 0.07326053641736507, Final Batch Loss: 0.04473666101694107\n",
      "Epoch 4116, Loss: 0.10019306093454361, Final Batch Loss: 0.06806192547082901\n",
      "Epoch 4117, Loss: 0.15771590918302536, Final Batch Loss: 0.09349054098129272\n",
      "Epoch 4118, Loss: 0.09705992043018341, Final Batch Loss: 0.031632982194423676\n",
      "Epoch 4119, Loss: 0.09328902140259743, Final Batch Loss: 0.047180429100990295\n",
      "Epoch 4120, Loss: 0.09065457060933113, Final Batch Loss: 0.03409171476960182\n",
      "Epoch 4121, Loss: 0.08968910202383995, Final Batch Loss: 0.048535846173763275\n",
      "Epoch 4122, Loss: 0.08861581236124039, Final Batch Loss: 0.03716900944709778\n",
      "Epoch 4123, Loss: 0.0786074623465538, Final Batch Loss: 0.034869201481342316\n",
      "Epoch 4124, Loss: 0.09596332348883152, Final Batch Loss: 0.06575822830200195\n",
      "Epoch 4125, Loss: 0.0735780093818903, Final Batch Loss: 0.024626588448882103\n",
      "Epoch 4126, Loss: 0.07928777486085892, Final Batch Loss: 0.028328709304332733\n",
      "Epoch 4127, Loss: 0.08057422190904617, Final Batch Loss: 0.041256245225667953\n",
      "Epoch 4128, Loss: 0.07447659596800804, Final Batch Loss: 0.03223586082458496\n",
      "Epoch 4129, Loss: 0.12192926183342934, Final Batch Loss: 0.03412550315260887\n",
      "Epoch 4130, Loss: 0.11370902881026268, Final Batch Loss: 0.056830909103155136\n",
      "Epoch 4131, Loss: 0.09171908348798752, Final Batch Loss: 0.03519958257675171\n",
      "Epoch 4132, Loss: 0.13786692917346954, Final Batch Loss: 0.05089385807514191\n",
      "Epoch 4133, Loss: 0.07179916650056839, Final Batch Loss: 0.03559854254126549\n",
      "Epoch 4134, Loss: 0.08150224387645721, Final Batch Loss: 0.040660228580236435\n",
      "Epoch 4135, Loss: 0.10678629577159882, Final Batch Loss: 0.05186516046524048\n",
      "Epoch 4136, Loss: 0.07441530004143715, Final Batch Loss: 0.03945088014006615\n",
      "Epoch 4137, Loss: 0.06398472376167774, Final Batch Loss: 0.040302492678165436\n",
      "Epoch 4138, Loss: 0.08267952501773834, Final Batch Loss: 0.05422184616327286\n",
      "Epoch 4139, Loss: 0.08737911097705364, Final Batch Loss: 0.06346333026885986\n",
      "Epoch 4140, Loss: 0.08634510077536106, Final Batch Loss: 0.028847886249423027\n",
      "Epoch 4141, Loss: 0.09758792072534561, Final Batch Loss: 0.04063158854842186\n",
      "Epoch 4142, Loss: 0.07384851202368736, Final Batch Loss: 0.03619752451777458\n",
      "Epoch 4143, Loss: 0.07197187654674053, Final Batch Loss: 0.030429938808083534\n",
      "Epoch 4144, Loss: 0.07937415689229965, Final Batch Loss: 0.04501546546816826\n",
      "Epoch 4145, Loss: 0.06597321107983589, Final Batch Loss: 0.035238586366176605\n",
      "Epoch 4146, Loss: 0.09392127394676208, Final Batch Loss: 0.055452555418014526\n",
      "Epoch 4147, Loss: 0.10252564772963524, Final Batch Loss: 0.04983855038881302\n",
      "Epoch 4148, Loss: 0.099533811211586, Final Batch Loss: 0.04309985414147377\n",
      "Epoch 4149, Loss: 0.07381589896976948, Final Batch Loss: 0.022711819037795067\n",
      "Epoch 4150, Loss: 0.14298375695943832, Final Batch Loss: 0.07655921578407288\n",
      "Epoch 4151, Loss: 0.08517008274793625, Final Batch Loss: 0.04715637490153313\n",
      "Epoch 4152, Loss: 0.09329671785235405, Final Batch Loss: 0.04371889308094978\n",
      "Epoch 4153, Loss: 0.10739351436495781, Final Batch Loss: 0.04476962611079216\n",
      "Epoch 4154, Loss: 0.15143686532974243, Final Batch Loss: 0.06975752860307693\n",
      "Epoch 4155, Loss: 0.0976843424141407, Final Batch Loss: 0.018621359020471573\n",
      "Epoch 4156, Loss: 0.15141063928604126, Final Batch Loss: 0.05747056007385254\n",
      "Epoch 4157, Loss: 0.09427615255117416, Final Batch Loss: 0.03197955712676048\n",
      "Epoch 4158, Loss: 0.07559417933225632, Final Batch Loss: 0.041708480566740036\n",
      "Epoch 4159, Loss: 0.16096871718764305, Final Batch Loss: 0.12456617504358292\n",
      "Epoch 4160, Loss: 0.12122558057308197, Final Batch Loss: 0.043351687490940094\n",
      "Epoch 4161, Loss: 0.0989002026617527, Final Batch Loss: 0.06123460456728935\n",
      "Epoch 4162, Loss: 0.059592194855213165, Final Batch Loss: 0.029094340279698372\n",
      "Epoch 4163, Loss: 0.1629963368177414, Final Batch Loss: 0.10400042682886124\n",
      "Epoch 4164, Loss: 0.07935141772031784, Final Batch Loss: 0.024416707456111908\n",
      "Epoch 4165, Loss: 0.1015908308327198, Final Batch Loss: 0.05697839334607124\n",
      "Epoch 4166, Loss: 0.14177439361810684, Final Batch Loss: 0.09486489742994308\n",
      "Epoch 4167, Loss: 0.07510925643146038, Final Batch Loss: 0.0488814078271389\n",
      "Epoch 4168, Loss: 0.109365563839674, Final Batch Loss: 0.047826580703258514\n",
      "Epoch 4169, Loss: 0.09776332974433899, Final Batch Loss: 0.04125002399086952\n",
      "Epoch 4170, Loss: 0.13201867789030075, Final Batch Loss: 0.09258250147104263\n",
      "Epoch 4171, Loss: 0.1017599031329155, Final Batch Loss: 0.05405373498797417\n",
      "Epoch 4172, Loss: 0.13328582793474197, Final Batch Loss: 0.054296478629112244\n",
      "Epoch 4173, Loss: 0.0895366445183754, Final Batch Loss: 0.05966630578041077\n",
      "Epoch 4174, Loss: 0.09063624776899815, Final Batch Loss: 0.017419101670384407\n",
      "Epoch 4175, Loss: 0.14336008206009865, Final Batch Loss: 0.027181994169950485\n",
      "Epoch 4176, Loss: 0.15186116844415665, Final Batch Loss: 0.09409164637327194\n",
      "Epoch 4177, Loss: 0.09751162678003311, Final Batch Loss: 0.034744203090667725\n",
      "Epoch 4178, Loss: 0.09953391551971436, Final Batch Loss: 0.05529628321528435\n",
      "Epoch 4179, Loss: 0.12124816328287125, Final Batch Loss: 0.05654657632112503\n",
      "Epoch 4180, Loss: 0.10723191872239113, Final Batch Loss: 0.05032902583479881\n",
      "Epoch 4181, Loss: 0.10260949283838272, Final Batch Loss: 0.054025307297706604\n",
      "Epoch 4182, Loss: 0.18133802711963654, Final Batch Loss: 0.07791613787412643\n",
      "Epoch 4183, Loss: 0.08728550374507904, Final Batch Loss: 0.053110651671886444\n",
      "Epoch 4184, Loss: 0.12395304068922997, Final Batch Loss: 0.06830702722072601\n",
      "Epoch 4185, Loss: 0.11936283111572266, Final Batch Loss: 0.05567546188831329\n",
      "Epoch 4186, Loss: 0.10820520296692848, Final Batch Loss: 0.044251274317502975\n",
      "Epoch 4187, Loss: 0.09293153509497643, Final Batch Loss: 0.02715844288468361\n",
      "Epoch 4188, Loss: 0.14660849794745445, Final Batch Loss: 0.1161855086684227\n",
      "Epoch 4189, Loss: 0.08813842013478279, Final Batch Loss: 0.042606111615896225\n",
      "Epoch 4190, Loss: 0.07584619522094727, Final Batch Loss: 0.03160037100315094\n",
      "Epoch 4191, Loss: 0.09351153671741486, Final Batch Loss: 0.04484965652227402\n",
      "Epoch 4192, Loss: 0.08257819712162018, Final Batch Loss: 0.04489881917834282\n",
      "Epoch 4193, Loss: 0.10827871039509773, Final Batch Loss: 0.044252920895814896\n",
      "Epoch 4194, Loss: 0.10433942824602127, Final Batch Loss: 0.047351084649562836\n",
      "Epoch 4195, Loss: 0.11326208338141441, Final Batch Loss: 0.07049661129713058\n",
      "Epoch 4196, Loss: 0.08893925696611404, Final Batch Loss: 0.04707281291484833\n",
      "Epoch 4197, Loss: 0.10687807947397232, Final Batch Loss: 0.0652843490242958\n",
      "Epoch 4198, Loss: 0.07947483658790588, Final Batch Loss: 0.04562956094741821\n",
      "Epoch 4199, Loss: 0.09629448130726814, Final Batch Loss: 0.04515314847230911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4200, Loss: 0.07953010499477386, Final Batch Loss: 0.05036263167858124\n",
      "Epoch 4201, Loss: 0.08012555167078972, Final Batch Loss: 0.03491587936878204\n",
      "Epoch 4202, Loss: 0.0930769070982933, Final Batch Loss: 0.05554768815636635\n",
      "Epoch 4203, Loss: 0.0839642658829689, Final Batch Loss: 0.040771692991256714\n",
      "Epoch 4204, Loss: 0.07393443398177624, Final Batch Loss: 0.044895682483911514\n",
      "Epoch 4205, Loss: 0.0842023529112339, Final Batch Loss: 0.04911431670188904\n",
      "Epoch 4206, Loss: 0.08762944117188454, Final Batch Loss: 0.044535450637340546\n",
      "Epoch 4207, Loss: 0.08431174419820309, Final Batch Loss: 0.019125474616885185\n",
      "Epoch 4208, Loss: 0.08553079888224602, Final Batch Loss: 0.03813137486577034\n",
      "Epoch 4209, Loss: 0.10590298473834991, Final Batch Loss: 0.053467363119125366\n",
      "Epoch 4210, Loss: 0.10284675657749176, Final Batch Loss: 0.04404659941792488\n",
      "Epoch 4211, Loss: 0.09974213875830173, Final Batch Loss: 0.07079391181468964\n",
      "Epoch 4212, Loss: 0.09477220848202705, Final Batch Loss: 0.04685837775468826\n",
      "Epoch 4213, Loss: 0.10287651419639587, Final Batch Loss: 0.02727571874856949\n",
      "Epoch 4214, Loss: 0.0828716978430748, Final Batch Loss: 0.03960799425840378\n",
      "Epoch 4215, Loss: 0.09056419879198074, Final Batch Loss: 0.04945923388004303\n",
      "Epoch 4216, Loss: 0.14454135671257973, Final Batch Loss: 0.10425924509763718\n",
      "Epoch 4217, Loss: 0.09774090349674225, Final Batch Loss: 0.0576513297855854\n",
      "Epoch 4218, Loss: 0.08948787301778793, Final Batch Loss: 0.04303644597530365\n",
      "Epoch 4219, Loss: 0.09928339347243309, Final Batch Loss: 0.06668056547641754\n",
      "Epoch 4220, Loss: 0.10032374039292336, Final Batch Loss: 0.0646519809961319\n",
      "Epoch 4221, Loss: 0.08371277526021004, Final Batch Loss: 0.03479896858334541\n",
      "Epoch 4222, Loss: 0.07247753441333771, Final Batch Loss: 0.01914789155125618\n",
      "Epoch 4223, Loss: 0.109211266040802, Final Batch Loss: 0.07134372740983963\n",
      "Epoch 4224, Loss: 0.09407854825258255, Final Batch Loss: 0.05863279476761818\n",
      "Epoch 4225, Loss: 0.08950819820165634, Final Batch Loss: 0.03350520133972168\n",
      "Epoch 4226, Loss: 0.09073073789477348, Final Batch Loss: 0.04818055033683777\n",
      "Epoch 4227, Loss: 0.08149705454707146, Final Batch Loss: 0.04271627962589264\n",
      "Epoch 4228, Loss: 0.10606757551431656, Final Batch Loss: 0.04654877632856369\n",
      "Epoch 4229, Loss: 0.08620643988251686, Final Batch Loss: 0.03830858692526817\n",
      "Epoch 4230, Loss: 0.14960334077477455, Final Batch Loss: 0.106385737657547\n",
      "Epoch 4231, Loss: 0.08947044610977173, Final Batch Loss: 0.054410334676504135\n",
      "Epoch 4232, Loss: 0.08547928556799889, Final Batch Loss: 0.06461700797080994\n",
      "Epoch 4233, Loss: 0.08380237966775894, Final Batch Loss: 0.050477225333452225\n",
      "Epoch 4234, Loss: 0.10080242156982422, Final Batch Loss: 0.062442198395729065\n",
      "Epoch 4235, Loss: 0.06903726048767567, Final Batch Loss: 0.03024285100400448\n",
      "Epoch 4236, Loss: 0.07097171992063522, Final Batch Loss: 0.01817183941602707\n",
      "Epoch 4237, Loss: 0.07035259529948235, Final Batch Loss: 0.03352964669466019\n",
      "Epoch 4238, Loss: 0.12265127897262573, Final Batch Loss: 0.09089560061693192\n",
      "Epoch 4239, Loss: 0.08283498883247375, Final Batch Loss: 0.040748242288827896\n",
      "Epoch 4240, Loss: 0.09461977891623974, Final Batch Loss: 0.06690461933612823\n",
      "Epoch 4241, Loss: 0.11958626750856638, Final Batch Loss: 0.104135662317276\n",
      "Epoch 4242, Loss: 0.06602714583277702, Final Batch Loss: 0.03234082832932472\n",
      "Epoch 4243, Loss: 0.09211106225848198, Final Batch Loss: 0.02737177535891533\n",
      "Epoch 4244, Loss: 0.12542024813592434, Final Batch Loss: 0.09626317769289017\n",
      "Epoch 4245, Loss: 0.09159978106617928, Final Batch Loss: 0.048257071524858475\n",
      "Epoch 4246, Loss: 0.10819125175476074, Final Batch Loss: 0.0529591403901577\n",
      "Epoch 4247, Loss: 0.08441536128520966, Final Batch Loss: 0.040312666445970535\n",
      "Epoch 4248, Loss: 0.0739855021238327, Final Batch Loss: 0.03141084313392639\n",
      "Epoch 4249, Loss: 0.07085695117712021, Final Batch Loss: 0.02834329381585121\n",
      "Epoch 4250, Loss: 0.1120847761631012, Final Batch Loss: 0.022442296147346497\n",
      "Epoch 4251, Loss: 0.07711334154009819, Final Batch Loss: 0.04629773274064064\n",
      "Epoch 4252, Loss: 0.0892176441848278, Final Batch Loss: 0.04505869373679161\n",
      "Epoch 4253, Loss: 0.09590990468859673, Final Batch Loss: 0.0545632503926754\n",
      "Epoch 4254, Loss: 0.09097787737846375, Final Batch Loss: 0.03557174280285835\n",
      "Epoch 4255, Loss: 0.08064815774559975, Final Batch Loss: 0.032833945006132126\n",
      "Epoch 4256, Loss: 0.1115727648139, Final Batch Loss: 0.054512690752744675\n",
      "Epoch 4257, Loss: 0.08078851737082005, Final Batch Loss: 0.05597143992781639\n",
      "Epoch 4258, Loss: 0.09350733831524849, Final Batch Loss: 0.05772986263036728\n",
      "Epoch 4259, Loss: 0.09634849801659584, Final Batch Loss: 0.04256439208984375\n",
      "Epoch 4260, Loss: 0.08090290799736977, Final Batch Loss: 0.021774567663669586\n",
      "Epoch 4261, Loss: 0.12620780989527702, Final Batch Loss: 0.06512205302715302\n",
      "Epoch 4262, Loss: 0.10520811378955841, Final Batch Loss: 0.06420935690402985\n",
      "Epoch 4263, Loss: 0.11002382636070251, Final Batch Loss: 0.06048085540533066\n",
      "Epoch 4264, Loss: 0.09859652072191238, Final Batch Loss: 0.05760982632637024\n",
      "Epoch 4265, Loss: 0.1082116849720478, Final Batch Loss: 0.06043272092938423\n",
      "Epoch 4266, Loss: 0.09988175332546234, Final Batch Loss: 0.05471954122185707\n",
      "Epoch 4267, Loss: 0.11786153167486191, Final Batch Loss: 0.08086533844470978\n",
      "Epoch 4268, Loss: 0.06732235290110111, Final Batch Loss: 0.025123177096247673\n",
      "Epoch 4269, Loss: 0.10166893154382706, Final Batch Loss: 0.049551721662282944\n",
      "Epoch 4270, Loss: 0.07889841683208942, Final Batch Loss: 0.05101805925369263\n",
      "Epoch 4271, Loss: 0.09409045800566673, Final Batch Loss: 0.047507259994745255\n",
      "Epoch 4272, Loss: 0.1423046663403511, Final Batch Loss: 0.09363570809364319\n",
      "Epoch 4273, Loss: 0.06961542181670666, Final Batch Loss: 0.028670312836766243\n",
      "Epoch 4274, Loss: 0.10424772650003433, Final Batch Loss: 0.05402638018131256\n",
      "Epoch 4275, Loss: 0.0727466456592083, Final Batch Loss: 0.033490873873233795\n",
      "Epoch 4276, Loss: 0.08284816145896912, Final Batch Loss: 0.0391557402908802\n",
      "Epoch 4277, Loss: 0.0913997869938612, Final Batch Loss: 0.06382947415113449\n",
      "Epoch 4278, Loss: 0.0823907870799303, Final Batch Loss: 0.028725119307637215\n",
      "Epoch 4279, Loss: 0.07540157809853554, Final Batch Loss: 0.042246196419000626\n",
      "Epoch 4280, Loss: 0.07481892220675945, Final Batch Loss: 0.026942184194922447\n",
      "Epoch 4281, Loss: 0.08122254721820354, Final Batch Loss: 0.02759028784930706\n",
      "Epoch 4282, Loss: 0.16369718313217163, Final Batch Loss: 0.12352626770734787\n",
      "Epoch 4283, Loss: 0.09581644833087921, Final Batch Loss: 0.05048656091094017\n",
      "Epoch 4284, Loss: 0.1335597187280655, Final Batch Loss: 0.03655003756284714\n",
      "Epoch 4285, Loss: 0.09810822829604149, Final Batch Loss: 0.04919784143567085\n",
      "Epoch 4286, Loss: 0.1269465573132038, Final Batch Loss: 0.06886360049247742\n",
      "Epoch 4287, Loss: 0.08595346659421921, Final Batch Loss: 0.05116032436490059\n",
      "Epoch 4288, Loss: 0.09407197684049606, Final Batch Loss: 0.05069153383374214\n",
      "Epoch 4289, Loss: 0.09847955033183098, Final Batch Loss: 0.042485445737838745\n",
      "Epoch 4290, Loss: 0.07752297073602676, Final Batch Loss: 0.027784209698438644\n",
      "Epoch 4291, Loss: 0.09763094782829285, Final Batch Loss: 0.04417130723595619\n",
      "Epoch 4292, Loss: 0.07923882827162743, Final Batch Loss: 0.03221319243311882\n",
      "Epoch 4293, Loss: 0.0773417316377163, Final Batch Loss: 0.038288746029138565\n",
      "Epoch 4294, Loss: 0.08621717058122158, Final Batch Loss: 0.06097019091248512\n",
      "Epoch 4295, Loss: 0.10556022077798843, Final Batch Loss: 0.0769016444683075\n",
      "Epoch 4296, Loss: 0.07167239300906658, Final Batch Loss: 0.04208272323012352\n",
      "Epoch 4297, Loss: 0.07976903393864632, Final Batch Loss: 0.03033110871911049\n",
      "Epoch 4298, Loss: 0.08059893921017647, Final Batch Loss: 0.03795332834124565\n",
      "Epoch 4299, Loss: 0.08845480158925056, Final Batch Loss: 0.05489460751414299\n",
      "Epoch 4300, Loss: 0.08375341072678566, Final Batch Loss: 0.05808441340923309\n",
      "Epoch 4301, Loss: 0.1079123467206955, Final Batch Loss: 0.05555956810712814\n",
      "Epoch 4302, Loss: 0.07834582030773163, Final Batch Loss: 0.03550499677658081\n",
      "Epoch 4303, Loss: 0.08937372267246246, Final Batch Loss: 0.04203955456614494\n",
      "Epoch 4304, Loss: 0.10868491604924202, Final Batch Loss: 0.06603825837373734\n",
      "Epoch 4305, Loss: 0.12347583472728729, Final Batch Loss: 0.09155483543872833\n",
      "Epoch 4306, Loss: 0.1059756949543953, Final Batch Loss: 0.07761580497026443\n",
      "Epoch 4307, Loss: 0.08403100073337555, Final Batch Loss: 0.04171578958630562\n",
      "Epoch 4308, Loss: 0.1272873617708683, Final Batch Loss: 0.08582340180873871\n",
      "Epoch 4309, Loss: 0.08451563119888306, Final Batch Loss: 0.04314018040895462\n",
      "Epoch 4310, Loss: 0.10321352258324623, Final Batch Loss: 0.05331337824463844\n",
      "Epoch 4311, Loss: 0.06602772884070873, Final Batch Loss: 0.019435709342360497\n",
      "Epoch 4312, Loss: 0.08703207969665527, Final Batch Loss: 0.03643094748258591\n",
      "Epoch 4313, Loss: 0.0761768463999033, Final Batch Loss: 0.019423386082053185\n",
      "Epoch 4314, Loss: 0.07900643162429333, Final Batch Loss: 0.031003182753920555\n",
      "Epoch 4315, Loss: 0.08413330838084221, Final Batch Loss: 0.035239748656749725\n",
      "Epoch 4316, Loss: 0.08961528912186623, Final Batch Loss: 0.04453688859939575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4317, Loss: 0.14090446382761002, Final Batch Loss: 0.06621264666318893\n",
      "Epoch 4318, Loss: 0.07719330862164497, Final Batch Loss: 0.04865677282214165\n",
      "Epoch 4319, Loss: 0.07282568328082561, Final Batch Loss: 0.045493513345718384\n",
      "Epoch 4320, Loss: 0.09326720982789993, Final Batch Loss: 0.03605715557932854\n",
      "Epoch 4321, Loss: 0.07814265787601471, Final Batch Loss: 0.03211827576160431\n",
      "Epoch 4322, Loss: 0.34215977042913437, Final Batch Loss: 0.27788564562797546\n",
      "Epoch 4323, Loss: 0.07727920264005661, Final Batch Loss: 0.03671504929661751\n",
      "Epoch 4324, Loss: 0.07893519848585129, Final Batch Loss: 0.0390365831553936\n",
      "Epoch 4325, Loss: 0.07284936867654324, Final Batch Loss: 0.027173461392521858\n",
      "Epoch 4326, Loss: 0.13739654794335365, Final Batch Loss: 0.0859091728925705\n",
      "Epoch 4327, Loss: 0.12842194363474846, Final Batch Loss: 0.06682849675416946\n",
      "Epoch 4328, Loss: 0.07930287346243858, Final Batch Loss: 0.0476461686193943\n",
      "Epoch 4329, Loss: 0.09830734133720398, Final Batch Loss: 0.05252012610435486\n",
      "Epoch 4330, Loss: 0.09845561906695366, Final Batch Loss: 0.042132120579481125\n",
      "Epoch 4331, Loss: 0.07394896633923054, Final Batch Loss: 0.04615779221057892\n",
      "Epoch 4332, Loss: 0.08869843371212482, Final Batch Loss: 0.030708232894539833\n",
      "Epoch 4333, Loss: 0.0992203839123249, Final Batch Loss: 0.06483640521764755\n",
      "Epoch 4334, Loss: 0.0823983158916235, Final Batch Loss: 0.0268151443451643\n",
      "Epoch 4335, Loss: 0.09482736885547638, Final Batch Loss: 0.037453461438417435\n",
      "Epoch 4336, Loss: 0.07842701114714146, Final Batch Loss: 0.02877863310277462\n",
      "Epoch 4337, Loss: 0.07969122752547264, Final Batch Loss: 0.03594315052032471\n",
      "Epoch 4338, Loss: 0.09487264603376389, Final Batch Loss: 0.05814985930919647\n",
      "Epoch 4339, Loss: 0.08639893680810928, Final Batch Loss: 0.04355978965759277\n",
      "Epoch 4340, Loss: 0.10892095044255257, Final Batch Loss: 0.07294883579015732\n",
      "Epoch 4341, Loss: 0.10100695118308067, Final Batch Loss: 0.05572041496634483\n",
      "Epoch 4342, Loss: 0.08003847673535347, Final Batch Loss: 0.037295151501894\n",
      "Epoch 4343, Loss: 0.09596291184425354, Final Batch Loss: 0.056802473962306976\n",
      "Epoch 4344, Loss: 0.08439353108406067, Final Batch Loss: 0.05072455480694771\n",
      "Epoch 4345, Loss: 0.0892704650759697, Final Batch Loss: 0.061876870691776276\n",
      "Epoch 4346, Loss: 0.10493021458387375, Final Batch Loss: 0.051861055195331573\n",
      "Epoch 4347, Loss: 0.06453023105859756, Final Batch Loss: 0.03302774578332901\n",
      "Epoch 4348, Loss: 0.07554599642753601, Final Batch Loss: 0.03652162104845047\n",
      "Epoch 4349, Loss: 0.09617358818650246, Final Batch Loss: 0.0613597147166729\n",
      "Epoch 4350, Loss: 0.10249322652816772, Final Batch Loss: 0.05283935368061066\n",
      "Epoch 4351, Loss: 0.08221123367547989, Final Batch Loss: 0.03560817986726761\n",
      "Epoch 4352, Loss: 0.07624970562756062, Final Batch Loss: 0.04665270820260048\n",
      "Epoch 4353, Loss: 0.06444880180060863, Final Batch Loss: 0.037203580141067505\n",
      "Epoch 4354, Loss: 0.07079696282744408, Final Batch Loss: 0.029176142066717148\n",
      "Epoch 4355, Loss: 0.07417034730315208, Final Batch Loss: 0.030480198562145233\n",
      "Epoch 4356, Loss: 0.10124687664210796, Final Batch Loss: 0.02761705033481121\n",
      "Epoch 4357, Loss: 0.06974740885198116, Final Batch Loss: 0.04597317799925804\n",
      "Epoch 4358, Loss: 0.09990909695625305, Final Batch Loss: 0.05109715461730957\n",
      "Epoch 4359, Loss: 0.08236649259924889, Final Batch Loss: 0.03973971679806709\n",
      "Epoch 4360, Loss: 0.08725379966199398, Final Batch Loss: 0.026931850239634514\n",
      "Epoch 4361, Loss: 0.09185495972633362, Final Batch Loss: 0.058493372052907944\n",
      "Epoch 4362, Loss: 0.07693654298782349, Final Batch Loss: 0.04380843788385391\n",
      "Epoch 4363, Loss: 0.08104493096470833, Final Batch Loss: 0.049139946699142456\n",
      "Epoch 4364, Loss: 0.10493491590023041, Final Batch Loss: 0.056949157267808914\n",
      "Epoch 4365, Loss: 0.06585332937538624, Final Batch Loss: 0.03585042059421539\n",
      "Epoch 4366, Loss: 0.12397985905408859, Final Batch Loss: 0.09945512562990189\n",
      "Epoch 4367, Loss: 0.09216000512242317, Final Batch Loss: 0.05840389430522919\n",
      "Epoch 4368, Loss: 0.08650968968868256, Final Batch Loss: 0.0495944619178772\n",
      "Epoch 4369, Loss: 0.06603237241506577, Final Batch Loss: 0.03647187724709511\n",
      "Epoch 4370, Loss: 0.10173297673463821, Final Batch Loss: 0.03345292806625366\n",
      "Epoch 4371, Loss: 0.09841369278728962, Final Batch Loss: 0.021116191521286964\n",
      "Epoch 4372, Loss: 0.06721590086817741, Final Batch Loss: 0.029007498174905777\n",
      "Epoch 4373, Loss: 0.18743811547756195, Final Batch Loss: 0.04936033487319946\n",
      "Epoch 4374, Loss: 0.06593073531985283, Final Batch Loss: 0.031124450266361237\n",
      "Epoch 4375, Loss: 0.09459301084280014, Final Batch Loss: 0.05812731757760048\n",
      "Epoch 4376, Loss: 0.07679125666618347, Final Batch Loss: 0.02636606991291046\n",
      "Epoch 4377, Loss: 0.09986843541264534, Final Batch Loss: 0.038033634424209595\n",
      "Epoch 4378, Loss: 0.07156870327889919, Final Batch Loss: 0.04464469477534294\n",
      "Epoch 4379, Loss: 0.1035175696015358, Final Batch Loss: 0.05685608088970184\n",
      "Epoch 4380, Loss: 0.07283291965723038, Final Batch Loss: 0.036096248775720596\n",
      "Epoch 4381, Loss: 0.07808781415224075, Final Batch Loss: 0.042989905923604965\n",
      "Epoch 4382, Loss: 0.0590604217723012, Final Batch Loss: 0.01546125952154398\n",
      "Epoch 4383, Loss: 0.09450862184166908, Final Batch Loss: 0.05016240105032921\n",
      "Epoch 4384, Loss: 0.08225572854280472, Final Batch Loss: 0.04042524844408035\n",
      "Epoch 4385, Loss: 0.07732145488262177, Final Batch Loss: 0.03286342695355415\n",
      "Epoch 4386, Loss: 0.08548040874302387, Final Batch Loss: 0.06452370434999466\n",
      "Epoch 4387, Loss: 0.06834982894361019, Final Batch Loss: 0.026148086413741112\n",
      "Epoch 4388, Loss: 0.09523014351725578, Final Batch Loss: 0.03791380301117897\n",
      "Epoch 4389, Loss: 0.07209708914160728, Final Batch Loss: 0.03694988787174225\n",
      "Epoch 4390, Loss: 0.08243304304778576, Final Batch Loss: 0.03062671236693859\n",
      "Epoch 4391, Loss: 0.10264762490987778, Final Batch Loss: 0.03491101413965225\n",
      "Epoch 4392, Loss: 0.06344514340162277, Final Batch Loss: 0.02829105406999588\n",
      "Epoch 4393, Loss: 0.08402035012841225, Final Batch Loss: 0.027244113385677338\n",
      "Epoch 4394, Loss: 0.08557304181158543, Final Batch Loss: 0.06333321332931519\n",
      "Epoch 4395, Loss: 0.06642693653702736, Final Batch Loss: 0.029324721544981003\n",
      "Epoch 4396, Loss: 0.09216839447617531, Final Batch Loss: 0.05894392356276512\n",
      "Epoch 4397, Loss: 0.08625409938395023, Final Batch Loss: 0.02449696697294712\n",
      "Epoch 4398, Loss: 0.08668429777026176, Final Batch Loss: 0.04768197983503342\n",
      "Epoch 4399, Loss: 0.09171402640640736, Final Batch Loss: 0.06292895972728729\n",
      "Epoch 4400, Loss: 0.06914100237190723, Final Batch Loss: 0.02031843550503254\n",
      "Epoch 4401, Loss: 0.09212305769324303, Final Batch Loss: 0.05509733781218529\n",
      "Epoch 4402, Loss: 0.08650457486510277, Final Batch Loss: 0.035839710384607315\n",
      "Epoch 4403, Loss: 0.06971769966185093, Final Batch Loss: 0.030011584982275963\n",
      "Epoch 4404, Loss: 0.08936108648777008, Final Batch Loss: 0.057035259902477264\n",
      "Epoch 4405, Loss: 0.07860122993588448, Final Batch Loss: 0.047105204313993454\n",
      "Epoch 4406, Loss: 0.08325016126036644, Final Batch Loss: 0.03326205164194107\n",
      "Epoch 4407, Loss: 0.1058086808770895, Final Batch Loss: 0.030691852793097496\n",
      "Epoch 4408, Loss: 0.08440239541232586, Final Batch Loss: 0.056385960429906845\n",
      "Epoch 4409, Loss: 0.09182510897517204, Final Batch Loss: 0.04845711216330528\n",
      "Epoch 4410, Loss: 0.09862025082111359, Final Batch Loss: 0.05985810607671738\n",
      "Epoch 4411, Loss: 0.08972595259547234, Final Batch Loss: 0.04861578345298767\n",
      "Epoch 4412, Loss: 0.08376913517713547, Final Batch Loss: 0.039610546082258224\n",
      "Epoch 4413, Loss: 0.07444944977760315, Final Batch Loss: 0.03119005635380745\n",
      "Epoch 4414, Loss: 0.07980577647686005, Final Batch Loss: 0.0399269163608551\n",
      "Epoch 4415, Loss: 0.1493561714887619, Final Batch Loss: 0.05279291421175003\n",
      "Epoch 4416, Loss: 0.08484452031552792, Final Batch Loss: 0.028585342690348625\n",
      "Epoch 4417, Loss: 0.07713712751865387, Final Batch Loss: 0.04017206281423569\n",
      "Epoch 4418, Loss: 0.1088484637439251, Final Batch Loss: 0.06916772574186325\n",
      "Epoch 4419, Loss: 0.08479917794466019, Final Batch Loss: 0.04941689968109131\n",
      "Epoch 4420, Loss: 0.08602827042341232, Final Batch Loss: 0.0490260049700737\n",
      "Epoch 4421, Loss: 0.08580886945128441, Final Batch Loss: 0.05277952551841736\n",
      "Epoch 4422, Loss: 0.08731643855571747, Final Batch Loss: 0.03213968500494957\n",
      "Epoch 4423, Loss: 0.0758297760039568, Final Batch Loss: 0.027431907132267952\n",
      "Epoch 4424, Loss: 0.07091419957578182, Final Batch Loss: 0.029238952323794365\n",
      "Epoch 4425, Loss: 0.06965471431612968, Final Batch Loss: 0.034496504813432693\n",
      "Epoch 4426, Loss: 0.12050896883010864, Final Batch Loss: 0.043534211814403534\n",
      "Epoch 4427, Loss: 0.06674429588019848, Final Batch Loss: 0.018270710483193398\n",
      "Epoch 4428, Loss: 0.09942970983684063, Final Batch Loss: 0.07044859975576401\n",
      "Epoch 4429, Loss: 0.10796518810093403, Final Batch Loss: 0.07842379063367844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4430, Loss: 0.09810440614819527, Final Batch Loss: 0.04515647888183594\n",
      "Epoch 4431, Loss: 0.12482190504670143, Final Batch Loss: 0.08408983051776886\n",
      "Epoch 4432, Loss: 0.08158440515398979, Final Batch Loss: 0.04420182481408119\n",
      "Epoch 4433, Loss: 0.07511194795370102, Final Batch Loss: 0.034141905605793\n",
      "Epoch 4434, Loss: 0.08444449678063393, Final Batch Loss: 0.038043245673179626\n",
      "Epoch 4435, Loss: 0.10995877161622047, Final Batch Loss: 0.0856214240193367\n",
      "Epoch 4436, Loss: 0.08077893033623695, Final Batch Loss: 0.03571850061416626\n",
      "Epoch 4437, Loss: 0.0752466693520546, Final Batch Loss: 0.017343640327453613\n",
      "Epoch 4438, Loss: 0.061830466613173485, Final Batch Loss: 0.03391016647219658\n",
      "Epoch 4439, Loss: 0.07500125467777252, Final Batch Loss: 0.03705384582281113\n",
      "Epoch 4440, Loss: 0.0644195806235075, Final Batch Loss: 0.034766875207424164\n",
      "Epoch 4441, Loss: 0.06513172015547752, Final Batch Loss: 0.034754037857055664\n",
      "Epoch 4442, Loss: 0.08190420642495155, Final Batch Loss: 0.044413842260837555\n",
      "Epoch 4443, Loss: 0.0872146487236023, Final Batch Loss: 0.05794479325413704\n",
      "Epoch 4444, Loss: 0.06789311021566391, Final Batch Loss: 0.03410119190812111\n",
      "Epoch 4445, Loss: 0.09745768457651138, Final Batch Loss: 0.06552302837371826\n",
      "Epoch 4446, Loss: 0.09672924317419529, Final Batch Loss: 0.07281482219696045\n",
      "Epoch 4447, Loss: 0.06949416734278202, Final Batch Loss: 0.03048601932823658\n",
      "Epoch 4448, Loss: 0.07429418712854385, Final Batch Loss: 0.03732693940401077\n",
      "Epoch 4449, Loss: 0.0896074790507555, Final Batch Loss: 0.030091674998402596\n",
      "Epoch 4450, Loss: 0.09368724003434181, Final Batch Loss: 0.05395055189728737\n",
      "Epoch 4451, Loss: 0.0865259226411581, Final Batch Loss: 0.056467343121767044\n",
      "Epoch 4452, Loss: 0.10632187873125076, Final Batch Loss: 0.035750553011894226\n",
      "Epoch 4453, Loss: 0.10894563049077988, Final Batch Loss: 0.04392058402299881\n",
      "Epoch 4454, Loss: 0.08759722486138344, Final Batch Loss: 0.05073145031929016\n",
      "Epoch 4455, Loss: 0.1054568849503994, Final Batch Loss: 0.050217404961586\n",
      "Epoch 4456, Loss: 0.08110846765339375, Final Batch Loss: 0.05110993981361389\n",
      "Epoch 4457, Loss: 0.08414345234632492, Final Batch Loss: 0.047531258314847946\n",
      "Epoch 4458, Loss: 0.11213457584381104, Final Batch Loss: 0.040011219680309296\n",
      "Epoch 4459, Loss: 0.07743177562952042, Final Batch Loss: 0.041606154292821884\n",
      "Epoch 4460, Loss: 0.09125608578324318, Final Batch Loss: 0.05693880841135979\n",
      "Epoch 4461, Loss: 0.07123639062047005, Final Batch Loss: 0.035599660128355026\n",
      "Epoch 4462, Loss: 0.08184517920017242, Final Batch Loss: 0.05029674991965294\n",
      "Epoch 4463, Loss: 0.08740473538637161, Final Batch Loss: 0.048898398876190186\n",
      "Epoch 4464, Loss: 0.08073028177022934, Final Batch Loss: 0.03348642587661743\n",
      "Epoch 4465, Loss: 0.12233918905258179, Final Batch Loss: 0.06054870784282684\n",
      "Epoch 4466, Loss: 0.09418942779302597, Final Batch Loss: 0.04623677581548691\n",
      "Epoch 4467, Loss: 0.10566856525838375, Final Batch Loss: 0.020702285692095757\n",
      "Epoch 4468, Loss: 0.12008126080036163, Final Batch Loss: 0.0959060937166214\n",
      "Epoch 4469, Loss: 0.12571004778146744, Final Batch Loss: 0.038685038685798645\n",
      "Epoch 4470, Loss: 0.08202001824975014, Final Batch Loss: 0.03506005182862282\n",
      "Epoch 4471, Loss: 0.0865895114839077, Final Batch Loss: 0.04933834448456764\n",
      "Epoch 4472, Loss: 0.07136729918420315, Final Batch Loss: 0.04788266122341156\n",
      "Epoch 4473, Loss: 0.07764753513038158, Final Batch Loss: 0.028725938871502876\n",
      "Epoch 4474, Loss: 0.10103107988834381, Final Batch Loss: 0.06432484835386276\n",
      "Epoch 4475, Loss: 0.08423735201358795, Final Batch Loss: 0.03556565195322037\n",
      "Epoch 4476, Loss: 0.10241787880659103, Final Batch Loss: 0.046376246958971024\n",
      "Epoch 4477, Loss: 0.08673543110489845, Final Batch Loss: 0.052086587995290756\n",
      "Epoch 4478, Loss: 0.0650535337626934, Final Batch Loss: 0.028677839785814285\n",
      "Epoch 4479, Loss: 0.09977618604898453, Final Batch Loss: 0.04156703129410744\n",
      "Epoch 4480, Loss: 0.0944446437060833, Final Batch Loss: 0.05148853734135628\n",
      "Epoch 4481, Loss: 0.08487743884325027, Final Batch Loss: 0.058407172560691833\n",
      "Epoch 4482, Loss: 0.14779912680387497, Final Batch Loss: 0.10083543509244919\n",
      "Epoch 4483, Loss: 0.12290813401341438, Final Batch Loss: 0.04913102462887764\n",
      "Epoch 4484, Loss: 0.07892698794603348, Final Batch Loss: 0.03724338486790657\n",
      "Epoch 4485, Loss: 0.08060001954436302, Final Batch Loss: 0.037194233387708664\n",
      "Epoch 4486, Loss: 0.11399965733289719, Final Batch Loss: 0.07463009655475616\n",
      "Epoch 4487, Loss: 0.07588701322674751, Final Batch Loss: 0.0365724079310894\n",
      "Epoch 4488, Loss: 0.09294440597295761, Final Batch Loss: 0.02511879801750183\n",
      "Epoch 4489, Loss: 0.0724814347922802, Final Batch Loss: 0.03649292513728142\n",
      "Epoch 4490, Loss: 0.07945273071527481, Final Batch Loss: 0.037834953516721725\n",
      "Epoch 4491, Loss: 0.1310008019208908, Final Batch Loss: 0.05848158895969391\n",
      "Epoch 4492, Loss: 0.10258989781141281, Final Batch Loss: 0.04901009425520897\n",
      "Epoch 4493, Loss: 0.1419815793633461, Final Batch Loss: 0.08079208433628082\n",
      "Epoch 4494, Loss: 0.16479172557592392, Final Batch Loss: 0.09560669958591461\n",
      "Epoch 4495, Loss: 0.10668222606182098, Final Batch Loss: 0.07408036291599274\n",
      "Epoch 4496, Loss: 0.05996249057352543, Final Batch Loss: 0.029846960678696632\n",
      "Epoch 4497, Loss: 0.08117888495326042, Final Batch Loss: 0.04232374206185341\n",
      "Epoch 4498, Loss: 0.11106452345848083, Final Batch Loss: 0.02284856140613556\n",
      "Epoch 4499, Loss: 0.09150937013328075, Final Batch Loss: 0.06262779980897903\n",
      "Epoch 4500, Loss: 0.11354043334722519, Final Batch Loss: 0.08932309597730637\n",
      "Epoch 4501, Loss: 0.13964592665433884, Final Batch Loss: 0.0698014497756958\n",
      "Epoch 4502, Loss: 0.08624184876680374, Final Batch Loss: 0.049906328320503235\n",
      "Epoch 4503, Loss: 0.09619439765810966, Final Batch Loss: 0.042944733053445816\n",
      "Epoch 4504, Loss: 0.17209837958216667, Final Batch Loss: 0.1307234764099121\n",
      "Epoch 4505, Loss: 0.09817751497030258, Final Batch Loss: 0.06584491580724716\n",
      "Epoch 4506, Loss: 0.13769728690385818, Final Batch Loss: 0.0700976550579071\n",
      "Epoch 4507, Loss: 0.09961671382188797, Final Batch Loss: 0.03182051330804825\n",
      "Epoch 4508, Loss: 0.10622310638427734, Final Batch Loss: 0.03513932228088379\n",
      "Epoch 4509, Loss: 0.11372579634189606, Final Batch Loss: 0.05478427931666374\n",
      "Epoch 4510, Loss: 0.1527969241142273, Final Batch Loss: 0.04480122774839401\n",
      "Epoch 4511, Loss: 0.08548606187105179, Final Batch Loss: 0.043262582272291183\n",
      "Epoch 4512, Loss: 0.10542786121368408, Final Batch Loss: 0.06672493368387222\n",
      "Epoch 4513, Loss: 0.06859572790563107, Final Batch Loss: 0.044676534831523895\n",
      "Epoch 4514, Loss: 0.1078086607158184, Final Batch Loss: 0.056892991065979004\n",
      "Epoch 4515, Loss: 0.10320968925952911, Final Batch Loss: 0.06278513371944427\n",
      "Epoch 4516, Loss: 0.11635711044073105, Final Batch Loss: 0.04390165954828262\n",
      "Epoch 4517, Loss: 0.14053415693342686, Final Batch Loss: 0.016624825075268745\n",
      "Epoch 4518, Loss: 0.16289038583636284, Final Batch Loss: 0.11789850890636444\n",
      "Epoch 4519, Loss: 0.07866289466619492, Final Batch Loss: 0.04528988152742386\n",
      "Epoch 4520, Loss: 0.1120697595179081, Final Batch Loss: 0.0411699078977108\n",
      "Epoch 4521, Loss: 0.08662830293178558, Final Batch Loss: 0.0482148677110672\n",
      "Epoch 4522, Loss: 0.10735709220170975, Final Batch Loss: 0.054140716791152954\n",
      "Epoch 4523, Loss: 0.1494254544377327, Final Batch Loss: 0.05897749215364456\n",
      "Epoch 4524, Loss: 0.09615200012922287, Final Batch Loss: 0.047538112848997116\n",
      "Epoch 4525, Loss: 0.08758538588881493, Final Batch Loss: 0.04428735375404358\n",
      "Epoch 4526, Loss: 0.07053699158132076, Final Batch Loss: 0.02578987367451191\n",
      "Epoch 4527, Loss: 0.0973554216325283, Final Batch Loss: 0.0650951936841011\n",
      "Epoch 4528, Loss: 0.09955761581659317, Final Batch Loss: 0.051816631108522415\n",
      "Epoch 4529, Loss: 0.08185294643044472, Final Batch Loss: 0.04242267832159996\n",
      "Epoch 4530, Loss: 0.1512884460389614, Final Batch Loss: 0.11185458302497864\n",
      "Epoch 4531, Loss: 0.13902117684483528, Final Batch Loss: 0.11708768457174301\n",
      "Epoch 4532, Loss: 0.10653156787157059, Final Batch Loss: 0.07459446787834167\n",
      "Epoch 4533, Loss: 0.1878272481262684, Final Batch Loss: 0.1312704086303711\n",
      "Epoch 4534, Loss: 0.09520397335290909, Final Batch Loss: 0.04077036306262016\n",
      "Epoch 4535, Loss: 0.08291314356029034, Final Batch Loss: 0.026378629729151726\n",
      "Epoch 4536, Loss: 0.18025440350174904, Final Batch Loss: 0.1297023743391037\n",
      "Epoch 4537, Loss: 0.12062463164329529, Final Batch Loss: 0.053684599697589874\n",
      "Epoch 4538, Loss: 0.07617507874965668, Final Batch Loss: 0.03315282240509987\n",
      "Epoch 4539, Loss: 0.08554777503013611, Final Batch Loss: 0.05654076486825943\n",
      "Epoch 4540, Loss: 0.07644346170127392, Final Batch Loss: 0.028085166588425636\n",
      "Epoch 4541, Loss: 0.06422369740903378, Final Batch Loss: 0.01922737993299961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4542, Loss: 0.0902150496840477, Final Batch Loss: 0.03705102205276489\n",
      "Epoch 4543, Loss: 0.08936554193496704, Final Batch Loss: 0.055725663900375366\n",
      "Epoch 4544, Loss: 0.09568949416279793, Final Batch Loss: 0.04728781431913376\n",
      "Epoch 4545, Loss: 0.09759333916008472, Final Batch Loss: 0.03046363778412342\n",
      "Epoch 4546, Loss: 0.11945271119475365, Final Batch Loss: 0.03770764544606209\n",
      "Epoch 4547, Loss: 0.09659566357731819, Final Batch Loss: 0.04280709847807884\n",
      "Epoch 4548, Loss: 0.060398077592253685, Final Batch Loss: 0.02466401644051075\n",
      "Epoch 4549, Loss: 0.07322771847248077, Final Batch Loss: 0.03185039013624191\n",
      "Epoch 4550, Loss: 0.07403062656521797, Final Batch Loss: 0.032986901700496674\n",
      "Epoch 4551, Loss: 0.09677747264504433, Final Batch Loss: 0.05195952579379082\n",
      "Epoch 4552, Loss: 0.09083596244454384, Final Batch Loss: 0.050977617502212524\n",
      "Epoch 4553, Loss: 0.08433158695697784, Final Batch Loss: 0.05309443548321724\n",
      "Epoch 4554, Loss: 0.0872626043856144, Final Batch Loss: 0.04823005944490433\n",
      "Epoch 4555, Loss: 0.13061785697937012, Final Batch Loss: 0.07323680073022842\n",
      "Epoch 4556, Loss: 0.13297409936785698, Final Batch Loss: 0.08156260848045349\n",
      "Epoch 4557, Loss: 0.09617567621171474, Final Batch Loss: 0.06730891019105911\n",
      "Epoch 4558, Loss: 0.16127081587910652, Final Batch Loss: 0.12246771901845932\n",
      "Epoch 4559, Loss: 0.07541785389184952, Final Batch Loss: 0.037332914769649506\n",
      "Epoch 4560, Loss: 0.07381259463727474, Final Batch Loss: 0.04662097617983818\n",
      "Epoch 4561, Loss: 0.0996549054980278, Final Batch Loss: 0.03940099477767944\n",
      "Epoch 4562, Loss: 0.15311548486351967, Final Batch Loss: 0.053697619587183\n",
      "Epoch 4563, Loss: 0.09013199806213379, Final Batch Loss: 0.04539745673537254\n",
      "Epoch 4564, Loss: 0.12472213432192802, Final Batch Loss: 0.05499488487839699\n",
      "Epoch 4565, Loss: 0.07951346412301064, Final Batch Loss: 0.035824570804834366\n",
      "Epoch 4566, Loss: 0.09330009296536446, Final Batch Loss: 0.04939524456858635\n",
      "Epoch 4567, Loss: 0.0876135565340519, Final Batch Loss: 0.05410291627049446\n",
      "Epoch 4568, Loss: 0.1384492665529251, Final Batch Loss: 0.08862990140914917\n",
      "Epoch 4569, Loss: 0.08194134384393692, Final Batch Loss: 0.04097384586930275\n",
      "Epoch 4570, Loss: 0.08062643557786942, Final Batch Loss: 0.04357818886637688\n",
      "Epoch 4571, Loss: 0.11399206146597862, Final Batch Loss: 0.04556402191519737\n",
      "Epoch 4572, Loss: 0.11991330981254578, Final Batch Loss: 0.052718713879585266\n",
      "Epoch 4573, Loss: 0.11572040244936943, Final Batch Loss: 0.04519271478056908\n",
      "Epoch 4574, Loss: 0.11623647436499596, Final Batch Loss: 0.08193036168813705\n",
      "Epoch 4575, Loss: 0.11845773831009865, Final Batch Loss: 0.06842730939388275\n",
      "Epoch 4576, Loss: 0.07596495002508163, Final Batch Loss: 0.03511880338191986\n",
      "Epoch 4577, Loss: 0.12310750037431717, Final Batch Loss: 0.06835123151540756\n",
      "Epoch 4578, Loss: 0.09368294104933739, Final Batch Loss: 0.049849364906549454\n",
      "Epoch 4579, Loss: 0.10777051001787186, Final Batch Loss: 0.06522118300199509\n",
      "Epoch 4580, Loss: 0.1665353998541832, Final Batch Loss: 0.09275095164775848\n",
      "Epoch 4581, Loss: 0.10300561226904392, Final Batch Loss: 0.07235687226057053\n",
      "Epoch 4582, Loss: 0.15800471603870392, Final Batch Loss: 0.08398950845003128\n",
      "Epoch 4583, Loss: 0.10917516052722931, Final Batch Loss: 0.061862729489803314\n",
      "Epoch 4584, Loss: 0.07343462482094765, Final Batch Loss: 0.03729911521077156\n",
      "Epoch 4585, Loss: 0.08221733570098877, Final Batch Loss: 0.037668824195861816\n",
      "Epoch 4586, Loss: 0.07537308894097805, Final Batch Loss: 0.01607404835522175\n",
      "Epoch 4587, Loss: 0.11435682699084282, Final Batch Loss: 0.06555835902690887\n",
      "Epoch 4588, Loss: 0.1484057866036892, Final Batch Loss: 0.04435001686215401\n",
      "Epoch 4589, Loss: 0.18772904202342033, Final Batch Loss: 0.13634827733039856\n",
      "Epoch 4590, Loss: 0.07896500453352928, Final Batch Loss: 0.045719001442193985\n",
      "Epoch 4591, Loss: 0.1332603096961975, Final Batch Loss: 0.06314194947481155\n",
      "Epoch 4592, Loss: 0.10577815398573875, Final Batch Loss: 0.03421400114893913\n",
      "Epoch 4593, Loss: 0.14843857288360596, Final Batch Loss: 0.11015269160270691\n",
      "Epoch 4594, Loss: 0.11426214873790741, Final Batch Loss: 0.03927632421255112\n",
      "Epoch 4595, Loss: 0.09641679376363754, Final Batch Loss: 0.056911367923021317\n",
      "Epoch 4596, Loss: 0.06886657327413559, Final Batch Loss: 0.020550336688756943\n",
      "Epoch 4597, Loss: 0.14933005347847939, Final Batch Loss: 0.10180948674678802\n",
      "Epoch 4598, Loss: 0.07840108685195446, Final Batch Loss: 0.025698179379105568\n",
      "Epoch 4599, Loss: 0.1377612240612507, Final Batch Loss: 0.047148387879133224\n",
      "Epoch 4600, Loss: 0.08276280388236046, Final Batch Loss: 0.049773331731557846\n",
      "Epoch 4601, Loss: 0.10305657982826233, Final Batch Loss: 0.02493254840373993\n",
      "Epoch 4602, Loss: 0.09180628880858421, Final Batch Loss: 0.035882413387298584\n",
      "Epoch 4603, Loss: 0.1842673346400261, Final Batch Loss: 0.07314752787351608\n",
      "Epoch 4604, Loss: 0.10025877878069878, Final Batch Loss: 0.037988871335983276\n",
      "Epoch 4605, Loss: 0.11399583891034126, Final Batch Loss: 0.05021338537335396\n",
      "Epoch 4606, Loss: 0.20757810771465302, Final Batch Loss: 0.06958535313606262\n",
      "Epoch 4607, Loss: 0.12350311502814293, Final Batch Loss: 0.05905182287096977\n",
      "Epoch 4608, Loss: 0.10777704790234566, Final Batch Loss: 0.06457644701004028\n",
      "Epoch 4609, Loss: 0.07599735260009766, Final Batch Loss: 0.04245392233133316\n",
      "Epoch 4610, Loss: 0.10785950720310211, Final Batch Loss: 0.06487390398979187\n",
      "Epoch 4611, Loss: 0.08248269557952881, Final Batch Loss: 0.03751056268811226\n",
      "Epoch 4612, Loss: 0.08982370421290398, Final Batch Loss: 0.04446319863200188\n",
      "Epoch 4613, Loss: 0.07823771610856056, Final Batch Loss: 0.045714110136032104\n",
      "Epoch 4614, Loss: 0.07488371059298515, Final Batch Loss: 0.036066390573978424\n",
      "Epoch 4615, Loss: 0.08511257916688919, Final Batch Loss: 0.020992808043956757\n",
      "Epoch 4616, Loss: 0.08326577581465244, Final Batch Loss: 0.05682174861431122\n",
      "Epoch 4617, Loss: 0.1178336851298809, Final Batch Loss: 0.08185181021690369\n",
      "Epoch 4618, Loss: 0.10845456644892693, Final Batch Loss: 0.0618390217423439\n",
      "Epoch 4619, Loss: 0.07538409531116486, Final Batch Loss: 0.035493556410074234\n",
      "Epoch 4620, Loss: 0.06948556005954742, Final Batch Loss: 0.03191707655787468\n",
      "Epoch 4621, Loss: 0.07664339244365692, Final Batch Loss: 0.030793484300374985\n",
      "Epoch 4622, Loss: 0.08111095800995827, Final Batch Loss: 0.040899597108364105\n",
      "Epoch 4623, Loss: 0.07704618573188782, Final Batch Loss: 0.03394433856010437\n",
      "Epoch 4624, Loss: 0.0773543007671833, Final Batch Loss: 0.03749160096049309\n",
      "Epoch 4625, Loss: 0.09078706800937653, Final Batch Loss: 0.03589054197072983\n",
      "Epoch 4626, Loss: 0.09134195744991302, Final Batch Loss: 0.047615520656108856\n",
      "Epoch 4627, Loss: 0.09231778606772423, Final Batch Loss: 0.055035609751939774\n",
      "Epoch 4628, Loss: 0.10254082456231117, Final Batch Loss: 0.06821878254413605\n",
      "Epoch 4629, Loss: 0.09974589943885803, Final Batch Loss: 0.06335926800966263\n",
      "Epoch 4630, Loss: 0.098736971616745, Final Batch Loss: 0.03201910853385925\n",
      "Epoch 4631, Loss: 0.07526892982423306, Final Batch Loss: 0.02949252910912037\n",
      "Epoch 4632, Loss: 0.07438299432396889, Final Batch Loss: 0.03139014169573784\n",
      "Epoch 4633, Loss: 0.08483901992440224, Final Batch Loss: 0.0516207218170166\n",
      "Epoch 4634, Loss: 0.12489787861704826, Final Batch Loss: 0.06585004925727844\n",
      "Epoch 4635, Loss: 0.1572461985051632, Final Batch Loss: 0.036170605570077896\n",
      "Epoch 4636, Loss: 0.14835453033447266, Final Batch Loss: 0.055040761828422546\n",
      "Epoch 4637, Loss: 0.09760881960391998, Final Batch Loss: 0.04026507958769798\n",
      "Epoch 4638, Loss: 0.07399214617908001, Final Batch Loss: 0.02192424051463604\n",
      "Epoch 4639, Loss: 0.10263043269515038, Final Batch Loss: 0.03715353086590767\n",
      "Epoch 4640, Loss: 0.09996780753135681, Final Batch Loss: 0.062477849423885345\n",
      "Epoch 4641, Loss: 0.07215938344597816, Final Batch Loss: 0.03438762202858925\n",
      "Epoch 4642, Loss: 0.11359979212284088, Final Batch Loss: 0.06740310788154602\n",
      "Epoch 4643, Loss: 0.09881898760795593, Final Batch Loss: 0.03226575255393982\n",
      "Epoch 4644, Loss: 0.065587492659688, Final Batch Loss: 0.021045131608843803\n",
      "Epoch 4645, Loss: 0.09980174712836742, Final Batch Loss: 0.029646476730704308\n",
      "Epoch 4646, Loss: 0.09128613024950027, Final Batch Loss: 0.037995412945747375\n",
      "Epoch 4647, Loss: 0.10175521299242973, Final Batch Loss: 0.030440066009759903\n",
      "Epoch 4648, Loss: 0.09411366283893585, Final Batch Loss: 0.049627646803855896\n",
      "Epoch 4649, Loss: 0.08187876269221306, Final Batch Loss: 0.03776099160313606\n",
      "Epoch 4650, Loss: 0.10770471394062042, Final Batch Loss: 0.061712395399808884\n",
      "Epoch 4651, Loss: 0.08592064306139946, Final Batch Loss: 0.04764235392212868\n",
      "Epoch 4652, Loss: 0.0934855155646801, Final Batch Loss: 0.046642277389764786\n",
      "Epoch 4653, Loss: 0.07099302858114243, Final Batch Loss: 0.03382350876927376\n",
      "Epoch 4654, Loss: 0.07187636941671371, Final Batch Loss: 0.03584979102015495\n",
      "Epoch 4655, Loss: 0.07615241222083569, Final Batch Loss: 0.026584332808852196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4656, Loss: 0.13560800813138485, Final Batch Loss: 0.021599529311060905\n",
      "Epoch 4657, Loss: 0.06403588503599167, Final Batch Loss: 0.032964836806058884\n",
      "Epoch 4658, Loss: 0.07729456201195717, Final Batch Loss: 0.04352713003754616\n",
      "Epoch 4659, Loss: 0.08032851479947567, Final Batch Loss: 0.05406048521399498\n",
      "Epoch 4660, Loss: 0.143990408629179, Final Batch Loss: 0.09523195028305054\n",
      "Epoch 4661, Loss: 0.0809735357761383, Final Batch Loss: 0.026216834783554077\n",
      "Epoch 4662, Loss: 0.08444879949092865, Final Batch Loss: 0.023748990148305893\n",
      "Epoch 4663, Loss: 0.11618665605783463, Final Batch Loss: 0.07108257710933685\n",
      "Epoch 4664, Loss: 0.1242901012301445, Final Batch Loss: 0.06766227632761002\n",
      "Epoch 4665, Loss: 0.06420821137726307, Final Batch Loss: 0.025782691314816475\n",
      "Epoch 4666, Loss: 0.13653556630015373, Final Batch Loss: 0.09447871893644333\n",
      "Epoch 4667, Loss: 0.0693109855055809, Final Batch Loss: 0.04221910983324051\n",
      "Epoch 4668, Loss: 0.09239742532372475, Final Batch Loss: 0.03666151314973831\n",
      "Epoch 4669, Loss: 0.07417786866426468, Final Batch Loss: 0.02646550163626671\n",
      "Epoch 4670, Loss: 0.06566662713885307, Final Batch Loss: 0.04189154878258705\n",
      "Epoch 4671, Loss: 0.07003205083310604, Final Batch Loss: 0.04296816140413284\n",
      "Epoch 4672, Loss: 0.09657930582761765, Final Batch Loss: 0.048431284725666046\n",
      "Epoch 4673, Loss: 0.0867573507130146, Final Batch Loss: 0.054349638521671295\n",
      "Epoch 4674, Loss: 0.08401387557387352, Final Batch Loss: 0.052238352596759796\n",
      "Epoch 4675, Loss: 0.07205824181437492, Final Batch Loss: 0.03484246879816055\n",
      "Epoch 4676, Loss: 0.08465393632650375, Final Batch Loss: 0.04985871911048889\n",
      "Epoch 4677, Loss: 0.06786291673779488, Final Batch Loss: 0.019829142838716507\n",
      "Epoch 4678, Loss: 0.0617369320243597, Final Batch Loss: 0.022207675501704216\n",
      "Epoch 4679, Loss: 0.09008844941854477, Final Batch Loss: 0.03893132880330086\n",
      "Epoch 4680, Loss: 0.08007615059614182, Final Batch Loss: 0.02124665305018425\n",
      "Epoch 4681, Loss: 0.0902043767273426, Final Batch Loss: 0.04539935663342476\n",
      "Epoch 4682, Loss: 0.09073955938220024, Final Batch Loss: 0.049219317734241486\n",
      "Epoch 4683, Loss: 0.08254151046276093, Final Batch Loss: 0.04717963933944702\n",
      "Epoch 4684, Loss: 0.10001543536782265, Final Batch Loss: 0.04365972429513931\n",
      "Epoch 4685, Loss: 0.08451027050614357, Final Batch Loss: 0.04203544929623604\n",
      "Epoch 4686, Loss: 0.07304010912775993, Final Batch Loss: 0.03513655811548233\n",
      "Epoch 4687, Loss: 0.07523289322853088, Final Batch Loss: 0.03183993697166443\n",
      "Epoch 4688, Loss: 0.0989183597266674, Final Batch Loss: 0.027279462665319443\n",
      "Epoch 4689, Loss: 0.08878377825021744, Final Batch Loss: 0.03915797173976898\n",
      "Epoch 4690, Loss: 0.07772466540336609, Final Batch Loss: 0.05141335353255272\n",
      "Epoch 4691, Loss: 0.11579162999987602, Final Batch Loss: 0.0424775667488575\n",
      "Epoch 4692, Loss: 0.07916769571602345, Final Batch Loss: 0.030332231894135475\n",
      "Epoch 4693, Loss: 0.08711270987987518, Final Batch Loss: 0.03582996875047684\n",
      "Epoch 4694, Loss: 0.1804647222161293, Final Batch Loss: 0.1038377583026886\n",
      "Epoch 4695, Loss: 0.0702172089368105, Final Batch Loss: 0.02822980098426342\n",
      "Epoch 4696, Loss: 0.09266559034585953, Final Batch Loss: 0.03743892163038254\n",
      "Epoch 4697, Loss: 0.07193115539848804, Final Batch Loss: 0.020293569192290306\n",
      "Epoch 4698, Loss: 0.09546947479248047, Final Batch Loss: 0.042927682399749756\n",
      "Epoch 4699, Loss: 0.08345065638422966, Final Batch Loss: 0.046382781118154526\n",
      "Epoch 4700, Loss: 0.09008098766207695, Final Batch Loss: 0.042157795280218124\n",
      "Epoch 4701, Loss: 0.06470995768904686, Final Batch Loss: 0.02757522463798523\n",
      "Epoch 4702, Loss: 0.06645239889621735, Final Batch Loss: 0.031772736459970474\n",
      "Epoch 4703, Loss: 0.1087607741355896, Final Batch Loss: 0.06498315930366516\n",
      "Epoch 4704, Loss: 0.11344519630074501, Final Batch Loss: 0.06027515232563019\n",
      "Epoch 4705, Loss: 0.1197640672326088, Final Batch Loss: 0.03566876798868179\n",
      "Epoch 4706, Loss: 0.07925951853394508, Final Batch Loss: 0.03668738529086113\n",
      "Epoch 4707, Loss: 0.09522650018334389, Final Batch Loss: 0.0647488683462143\n",
      "Epoch 4708, Loss: 0.09806766733527184, Final Batch Loss: 0.056252989917993546\n",
      "Epoch 4709, Loss: 0.10062821954488754, Final Batch Loss: 0.04001758620142937\n",
      "Epoch 4710, Loss: 0.14347878098487854, Final Batch Loss: 0.06936214864253998\n",
      "Epoch 4711, Loss: 0.11268634349107742, Final Batch Loss: 0.09325557947158813\n",
      "Epoch 4712, Loss: 0.07094165310263634, Final Batch Loss: 0.03298870101571083\n",
      "Epoch 4713, Loss: 0.07769124209880829, Final Batch Loss: 0.03781810402870178\n",
      "Epoch 4714, Loss: 0.07451999187469482, Final Batch Loss: 0.016948997974395752\n",
      "Epoch 4715, Loss: 0.07208838313817978, Final Batch Loss: 0.047043658792972565\n",
      "Epoch 4716, Loss: 0.11594386026263237, Final Batch Loss: 0.07237976044416428\n",
      "Epoch 4717, Loss: 0.07583814673125744, Final Batch Loss: 0.051821451634168625\n",
      "Epoch 4718, Loss: 0.06779235228896141, Final Batch Loss: 0.038947366178035736\n",
      "Epoch 4719, Loss: 0.083071980625391, Final Batch Loss: 0.04129042476415634\n",
      "Epoch 4720, Loss: 0.06780901551246643, Final Batch Loss: 0.026634588837623596\n",
      "Epoch 4721, Loss: 0.0844423733651638, Final Batch Loss: 0.035095833241939545\n",
      "Epoch 4722, Loss: 0.10979362577199936, Final Batch Loss: 0.05817682668566704\n",
      "Epoch 4723, Loss: 0.09734035655856133, Final Batch Loss: 0.057726431638002396\n",
      "Epoch 4724, Loss: 0.1005200631916523, Final Batch Loss: 0.05823676288127899\n",
      "Epoch 4725, Loss: 0.07147477567195892, Final Batch Loss: 0.03132829815149307\n",
      "Epoch 4726, Loss: 0.0711302999407053, Final Batch Loss: 0.028422201052308083\n",
      "Epoch 4727, Loss: 0.0994110256433487, Final Batch Loss: 0.03336958587169647\n",
      "Epoch 4728, Loss: 0.0713796578347683, Final Batch Loss: 0.03288524970412254\n",
      "Epoch 4729, Loss: 0.06989517249166965, Final Batch Loss: 0.027107970789074898\n",
      "Epoch 4730, Loss: 0.08675253763794899, Final Batch Loss: 0.04916570708155632\n",
      "Epoch 4731, Loss: 0.07847235165536404, Final Batch Loss: 0.05090811848640442\n",
      "Epoch 4732, Loss: 0.12514621019363403, Final Batch Loss: 0.039512038230895996\n",
      "Epoch 4733, Loss: 0.09526177681982517, Final Batch Loss: 0.030179569497704506\n",
      "Epoch 4734, Loss: 0.06508115120232105, Final Batch Loss: 0.02820012904703617\n",
      "Epoch 4735, Loss: 0.061914678663015366, Final Batch Loss: 0.0178602896630764\n",
      "Epoch 4736, Loss: 0.1166345551609993, Final Batch Loss: 0.06342578679323196\n",
      "Epoch 4737, Loss: 0.0812399759888649, Final Batch Loss: 0.045650094747543335\n",
      "Epoch 4738, Loss: 0.0913071371614933, Final Batch Loss: 0.03939688950777054\n",
      "Epoch 4739, Loss: 0.09270775318145752, Final Batch Loss: 0.08029293268918991\n",
      "Epoch 4740, Loss: 0.1561114713549614, Final Batch Loss: 0.12113574147224426\n",
      "Epoch 4741, Loss: 0.10033615306019783, Final Batch Loss: 0.046113695949316025\n",
      "Epoch 4742, Loss: 0.07170996628701687, Final Batch Loss: 0.020895102992653847\n",
      "Epoch 4743, Loss: 0.1052035540342331, Final Batch Loss: 0.06037041172385216\n",
      "Epoch 4744, Loss: 0.09541188180446625, Final Batch Loss: 0.017000965774059296\n",
      "Epoch 4745, Loss: 0.07056919857859612, Final Batch Loss: 0.031860340386629105\n",
      "Epoch 4746, Loss: 0.09042152017354965, Final Batch Loss: 0.0492250993847847\n",
      "Epoch 4747, Loss: 0.07553093880414963, Final Batch Loss: 0.035336121916770935\n",
      "Epoch 4748, Loss: 0.07968959212303162, Final Batch Loss: 0.04201086238026619\n",
      "Epoch 4749, Loss: 0.10460588708519936, Final Batch Loss: 0.03747148439288139\n",
      "Epoch 4750, Loss: 0.09626228362321854, Final Batch Loss: 0.03781532496213913\n",
      "Epoch 4751, Loss: 0.07689051330089569, Final Batch Loss: 0.0337994322180748\n",
      "Epoch 4752, Loss: 0.0723633598536253, Final Batch Loss: 0.03068883903324604\n",
      "Epoch 4753, Loss: 0.0864562951028347, Final Batch Loss: 0.038095567375421524\n",
      "Epoch 4754, Loss: 0.07714935578405857, Final Batch Loss: 0.022435201331973076\n",
      "Epoch 4755, Loss: 0.08593842014670372, Final Batch Loss: 0.029958639293909073\n",
      "Epoch 4756, Loss: 0.10261373221874237, Final Batch Loss: 0.04278305917978287\n",
      "Epoch 4757, Loss: 0.15271102264523506, Final Batch Loss: 0.1214217022061348\n",
      "Epoch 4758, Loss: 0.08689269050955772, Final Batch Loss: 0.04504717141389847\n",
      "Epoch 4759, Loss: 0.08362669497728348, Final Batch Loss: 0.04015742242336273\n",
      "Epoch 4760, Loss: 0.08057228848338127, Final Batch Loss: 0.029525253921747208\n",
      "Epoch 4761, Loss: 0.0762372650206089, Final Batch Loss: 0.034943945705890656\n",
      "Epoch 4762, Loss: 0.1400550827383995, Final Batch Loss: 0.11985735595226288\n",
      "Epoch 4763, Loss: 0.07691750302910805, Final Batch Loss: 0.0349511057138443\n",
      "Epoch 4764, Loss: 0.09633558616042137, Final Batch Loss: 0.048182662576436996\n",
      "Epoch 4765, Loss: 0.16130542755126953, Final Batch Loss: 0.11764838546514511\n",
      "Epoch 4766, Loss: 0.07357702031731606, Final Batch Loss: 0.03504832834005356\n",
      "Epoch 4767, Loss: 0.09652525931596756, Final Batch Loss: 0.04660896956920624\n",
      "Epoch 4768, Loss: 0.13238001987338066, Final Batch Loss: 0.07886849343776703\n",
      "Epoch 4769, Loss: 0.07028579711914062, Final Batch Loss: 0.04587620124220848\n",
      "Epoch 4770, Loss: 0.07824446260929108, Final Batch Loss: 0.0405004620552063\n",
      "Epoch 4771, Loss: 0.11076599732041359, Final Batch Loss: 0.06628776341676712\n",
      "Epoch 4772, Loss: 0.08966292254626751, Final Batch Loss: 0.02284763567149639\n",
      "Epoch 4773, Loss: 0.07928607054054737, Final Batch Loss: 0.04903705418109894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4774, Loss: 0.06263037025928497, Final Batch Loss: 0.021789751946926117\n",
      "Epoch 4775, Loss: 0.06619792059063911, Final Batch Loss: 0.031162269413471222\n",
      "Epoch 4776, Loss: 0.07320603169500828, Final Batch Loss: 0.02126876823604107\n",
      "Epoch 4777, Loss: 0.07692956738173962, Final Batch Loss: 0.030475763604044914\n",
      "Epoch 4778, Loss: 0.09063076972961426, Final Batch Loss: 0.03612188622355461\n",
      "Epoch 4779, Loss: 0.08791397139430046, Final Batch Loss: 0.02851647138595581\n",
      "Epoch 4780, Loss: 0.07168367877602577, Final Batch Loss: 0.038825623691082\n",
      "Epoch 4781, Loss: 0.07146849296987057, Final Batch Loss: 0.04274468868970871\n",
      "Epoch 4782, Loss: 0.08572696894407272, Final Batch Loss: 0.043314095586538315\n",
      "Epoch 4783, Loss: 0.06379630044102669, Final Batch Loss: 0.040975283831357956\n",
      "Epoch 4784, Loss: 0.11943469196557999, Final Batch Loss: 0.03196951001882553\n",
      "Epoch 4785, Loss: 0.07722742110490799, Final Batch Loss: 0.051417794078588486\n",
      "Epoch 4786, Loss: 0.08120905980467796, Final Batch Loss: 0.028600521385669708\n",
      "Epoch 4787, Loss: 0.06825319863855839, Final Batch Loss: 0.053122930228710175\n",
      "Epoch 4788, Loss: 0.08775405213236809, Final Batch Loss: 0.023263994604349136\n",
      "Epoch 4789, Loss: 0.11901718005537987, Final Batch Loss: 0.07422862201929092\n",
      "Epoch 4790, Loss: 0.09014829248189926, Final Batch Loss: 0.03690981864929199\n",
      "Epoch 4791, Loss: 0.06847187876701355, Final Batch Loss: 0.022332407534122467\n",
      "Epoch 4792, Loss: 0.09417545422911644, Final Batch Loss: 0.06797178089618683\n",
      "Epoch 4793, Loss: 0.07448825985193253, Final Batch Loss: 0.027816295623779297\n",
      "Epoch 4794, Loss: 0.13668711110949516, Final Batch Loss: 0.08705486357212067\n",
      "Epoch 4795, Loss: 0.09046272560954094, Final Batch Loss: 0.05664139240980148\n",
      "Epoch 4796, Loss: 0.08756405487656593, Final Batch Loss: 0.040458206087350845\n",
      "Epoch 4797, Loss: 0.10356951877474785, Final Batch Loss: 0.0523526668548584\n",
      "Epoch 4798, Loss: 0.08035873621702194, Final Batch Loss: 0.035588063299655914\n",
      "Epoch 4799, Loss: 0.07512624189257622, Final Batch Loss: 0.029428858309984207\n",
      "Epoch 4800, Loss: 0.0852731391787529, Final Batch Loss: 0.04542664438486099\n",
      "Epoch 4801, Loss: 0.0928626973181963, Final Batch Loss: 0.06836992502212524\n",
      "Epoch 4802, Loss: 0.08253209106624126, Final Batch Loss: 0.02891855128109455\n",
      "Epoch 4803, Loss: 0.08319084718823433, Final Batch Loss: 0.037273112684488297\n",
      "Epoch 4804, Loss: 0.08588477969169617, Final Batch Loss: 0.02791091427206993\n",
      "Epoch 4805, Loss: 0.08986439183354378, Final Batch Loss: 0.050881169736385345\n",
      "Epoch 4806, Loss: 0.07754267007112503, Final Batch Loss: 0.03948463872075081\n",
      "Epoch 4807, Loss: 0.08912643045186996, Final Batch Loss: 0.041145481169223785\n",
      "Epoch 4808, Loss: 0.05478675477206707, Final Batch Loss: 0.022229021415114403\n",
      "Epoch 4809, Loss: 0.09253395907580853, Final Batch Loss: 0.06600956618785858\n",
      "Epoch 4810, Loss: 0.12015695869922638, Final Batch Loss: 0.055841103196144104\n",
      "Epoch 4811, Loss: 0.0674106515944004, Final Batch Loss: 0.03820156678557396\n",
      "Epoch 4812, Loss: 0.08512450009584427, Final Batch Loss: 0.04743610695004463\n",
      "Epoch 4813, Loss: 0.07427359744906425, Final Batch Loss: 0.03239377960562706\n",
      "Epoch 4814, Loss: 0.09216535836458206, Final Batch Loss: 0.04412958025932312\n",
      "Epoch 4815, Loss: 0.06746598705649376, Final Batch Loss: 0.036545928567647934\n",
      "Epoch 4816, Loss: 0.07435894757509232, Final Batch Loss: 0.03514348715543747\n",
      "Epoch 4817, Loss: 0.1074349470436573, Final Batch Loss: 0.05610440671443939\n",
      "Epoch 4818, Loss: 0.07726767100393772, Final Batch Loss: 0.026703977957367897\n",
      "Epoch 4819, Loss: 0.08904055505990982, Final Batch Loss: 0.044039685279130936\n",
      "Epoch 4820, Loss: 0.09768197312951088, Final Batch Loss: 0.051701415330171585\n",
      "Epoch 4821, Loss: 0.08715630322694778, Final Batch Loss: 0.050104472786188126\n",
      "Epoch 4822, Loss: 0.06650557368993759, Final Batch Loss: 0.03455721586942673\n",
      "Epoch 4823, Loss: 0.11381914094090462, Final Batch Loss: 0.06715361028909683\n",
      "Epoch 4824, Loss: 0.2093236967921257, Final Batch Loss: 0.15372741222381592\n",
      "Epoch 4825, Loss: 0.12512201070785522, Final Batch Loss: 0.07530795782804489\n",
      "Epoch 4826, Loss: 0.12841623276472092, Final Batch Loss: 0.08175194263458252\n",
      "Epoch 4827, Loss: 0.0844310000538826, Final Batch Loss: 0.047520965337753296\n",
      "Epoch 4828, Loss: 0.07898001372814178, Final Batch Loss: 0.043672237545251846\n",
      "Epoch 4829, Loss: 0.08488574624061584, Final Batch Loss: 0.03721458837389946\n",
      "Epoch 4830, Loss: 0.09562873467803001, Final Batch Loss: 0.047193218022584915\n",
      "Epoch 4831, Loss: 0.08498395793139935, Final Batch Loss: 0.059487972408533096\n",
      "Epoch 4832, Loss: 0.10677354037761688, Final Batch Loss: 0.03577335178852081\n",
      "Epoch 4833, Loss: 0.07359593734145164, Final Batch Loss: 0.03202749043703079\n",
      "Epoch 4834, Loss: 0.10013352707028389, Final Batch Loss: 0.05093053728342056\n",
      "Epoch 4835, Loss: 0.06757188402116299, Final Batch Loss: 0.037922728806734085\n",
      "Epoch 4836, Loss: 0.0763402134180069, Final Batch Loss: 0.04048829525709152\n",
      "Epoch 4837, Loss: 0.09111396968364716, Final Batch Loss: 0.04509777948260307\n",
      "Epoch 4838, Loss: 0.09929481334984303, Final Batch Loss: 0.07200754433870316\n",
      "Epoch 4839, Loss: 0.08540302887558937, Final Batch Loss: 0.03915507346391678\n",
      "Epoch 4840, Loss: 0.06365922093391418, Final Batch Loss: 0.03771570324897766\n",
      "Epoch 4841, Loss: 0.0606593731790781, Final Batch Loss: 0.01885921321809292\n",
      "Epoch 4842, Loss: 0.08658313751220703, Final Batch Loss: 0.03807888552546501\n",
      "Epoch 4843, Loss: 0.08026710525155067, Final Batch Loss: 0.04685184359550476\n",
      "Epoch 4844, Loss: 0.07825415581464767, Final Batch Loss: 0.02809443324804306\n",
      "Epoch 4845, Loss: 0.10123745910823345, Final Batch Loss: 0.030146678909659386\n",
      "Epoch 4846, Loss: 0.06177258025854826, Final Batch Loss: 0.011996458284556866\n",
      "Epoch 4847, Loss: 0.07728039287030697, Final Batch Loss: 0.04646066203713417\n",
      "Epoch 4848, Loss: 0.07266388647258282, Final Batch Loss: 0.028377367183566093\n",
      "Epoch 4849, Loss: 0.09993992373347282, Final Batch Loss: 0.03039347007870674\n",
      "Epoch 4850, Loss: 0.06251430325210094, Final Batch Loss: 0.025677481666207314\n",
      "Epoch 4851, Loss: 0.07699881121516228, Final Batch Loss: 0.03752952814102173\n",
      "Epoch 4852, Loss: 0.07779142633080482, Final Batch Loss: 0.04323932155966759\n",
      "Epoch 4853, Loss: 0.14805372804403305, Final Batch Loss: 0.10819930583238602\n",
      "Epoch 4854, Loss: 0.12856163084506989, Final Batch Loss: 0.0958823561668396\n",
      "Epoch 4855, Loss: 0.11020932346582413, Final Batch Loss: 0.06862926483154297\n",
      "Epoch 4856, Loss: 0.11466747522354126, Final Batch Loss: 0.07470114529132843\n",
      "Epoch 4857, Loss: 0.12660260498523712, Final Batch Loss: 0.054153650999069214\n",
      "Epoch 4858, Loss: 0.16580206155776978, Final Batch Loss: 0.0989452674984932\n",
      "Epoch 4859, Loss: 0.08969688788056374, Final Batch Loss: 0.04855778068304062\n",
      "Epoch 4860, Loss: 0.15593594312667847, Final Batch Loss: 0.12643739581108093\n",
      "Epoch 4861, Loss: 0.09619129449129105, Final Batch Loss: 0.025072909891605377\n",
      "Epoch 4862, Loss: 0.07818995788693428, Final Batch Loss: 0.036782268434762955\n",
      "Epoch 4863, Loss: 0.07106316648423672, Final Batch Loss: 0.04283338785171509\n",
      "Epoch 4864, Loss: 0.08468976616859436, Final Batch Loss: 0.0327376089990139\n",
      "Epoch 4865, Loss: 0.13951724767684937, Final Batch Loss: 0.055189184844493866\n",
      "Epoch 4866, Loss: 0.0645649004727602, Final Batch Loss: 0.03472369536757469\n",
      "Epoch 4867, Loss: 0.12515963427722454, Final Batch Loss: 0.029970800504088402\n",
      "Epoch 4868, Loss: 0.1323031298816204, Final Batch Loss: 0.09552981704473495\n",
      "Epoch 4869, Loss: 0.0722435861825943, Final Batch Loss: 0.028339583426713943\n",
      "Epoch 4870, Loss: 0.09261217340826988, Final Batch Loss: 0.04750610142946243\n",
      "Epoch 4871, Loss: 0.06795903481543064, Final Batch Loss: 0.026866136118769646\n",
      "Epoch 4872, Loss: 0.10107612609863281, Final Batch Loss: 0.05604692921042442\n",
      "Epoch 4873, Loss: 0.08906356617808342, Final Batch Loss: 0.050314974039793015\n",
      "Epoch 4874, Loss: 0.08832153305411339, Final Batch Loss: 0.03325062617659569\n",
      "Epoch 4875, Loss: 0.07661858573555946, Final Batch Loss: 0.05650344118475914\n",
      "Epoch 4876, Loss: 0.062401628121733665, Final Batch Loss: 0.019982894882559776\n",
      "Epoch 4877, Loss: 0.07732550241053104, Final Batch Loss: 0.02504855953156948\n",
      "Epoch 4878, Loss: 0.07841482385993004, Final Batch Loss: 0.03873689845204353\n",
      "Epoch 4879, Loss: 0.08701413869857788, Final Batch Loss: 0.03868720307946205\n",
      "Epoch 4880, Loss: 0.07929138839244843, Final Batch Loss: 0.033715829253196716\n",
      "Epoch 4881, Loss: 0.07706517726182938, Final Batch Loss: 0.03657519817352295\n",
      "Epoch 4882, Loss: 0.06140458025038242, Final Batch Loss: 0.03692193701863289\n",
      "Epoch 4883, Loss: 0.08329436928033829, Final Batch Loss: 0.03361964970827103\n",
      "Epoch 4884, Loss: 0.06529327668249607, Final Batch Loss: 0.022505437955260277\n",
      "Epoch 4885, Loss: 0.0806226059794426, Final Batch Loss: 0.053917333483695984\n",
      "Epoch 4886, Loss: 0.06229597330093384, Final Batch Loss: 0.029763419181108475\n",
      "Epoch 4887, Loss: 0.09265556186437607, Final Batch Loss: 0.040655579417943954\n",
      "Epoch 4888, Loss: 0.08888034895062447, Final Batch Loss: 0.039540305733680725\n",
      "Epoch 4889, Loss: 0.09181724861264229, Final Batch Loss: 0.04302414879202843\n",
      "Epoch 4890, Loss: 0.0987725555896759, Final Batch Loss: 0.05797021836042404\n",
      "Epoch 4891, Loss: 0.11804019659757614, Final Batch Loss: 0.033881448209285736\n",
      "Epoch 4892, Loss: 0.09848546981811523, Final Batch Loss: 0.04727742075920105\n",
      "Epoch 4893, Loss: 0.08021420799195766, Final Batch Loss: 0.027699721977114677\n",
      "Epoch 4894, Loss: 0.07636564783751965, Final Batch Loss: 0.02752804569900036\n",
      "Epoch 4895, Loss: 0.06492641381919384, Final Batch Loss: 0.01863892190158367\n",
      "Epoch 4896, Loss: 0.09576589986681938, Final Batch Loss: 0.05905923247337341\n",
      "Epoch 4897, Loss: 0.15096233785152435, Final Batch Loss: 0.10707160830497742\n",
      "Epoch 4898, Loss: 0.12920140475034714, Final Batch Loss: 0.06598810851573944\n",
      "Epoch 4899, Loss: 0.08869931846857071, Final Batch Loss: 0.030424993485212326\n",
      "Epoch 4900, Loss: 0.09930693358182907, Final Batch Loss: 0.02163759618997574\n",
      "Epoch 4901, Loss: 0.0957249253988266, Final Batch Loss: 0.07296539843082428\n",
      "Epoch 4902, Loss: 0.12965958565473557, Final Batch Loss: 0.07663282752037048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4903, Loss: 0.07800963893532753, Final Batch Loss: 0.03488348051905632\n",
      "Epoch 4904, Loss: 0.11720189452171326, Final Batch Loss: 0.060910455882549286\n",
      "Epoch 4905, Loss: 0.10188327729701996, Final Batch Loss: 0.04927203804254532\n",
      "Epoch 4906, Loss: 0.11300739273428917, Final Batch Loss: 0.041119735687971115\n",
      "Epoch 4907, Loss: 0.09167656116187572, Final Batch Loss: 0.029775256291031837\n",
      "Epoch 4908, Loss: 0.12045059353113174, Final Batch Loss: 0.07559816539287567\n",
      "Epoch 4909, Loss: 0.12708278745412827, Final Batch Loss: 0.05700545758008957\n",
      "Epoch 4910, Loss: 0.10459793731570244, Final Batch Loss: 0.03836965933442116\n",
      "Epoch 4911, Loss: 0.10952742397785187, Final Batch Loss: 0.07665973901748657\n",
      "Epoch 4912, Loss: 0.08046027086675167, Final Batch Loss: 0.02786836586892605\n",
      "Epoch 4913, Loss: 0.11261813715100288, Final Batch Loss: 0.05207470431923866\n",
      "Epoch 4914, Loss: 0.09670998901128769, Final Batch Loss: 0.049401577562093735\n",
      "Epoch 4915, Loss: 0.09036281332373619, Final Batch Loss: 0.055084411054849625\n",
      "Epoch 4916, Loss: 0.08582280576229095, Final Batch Loss: 0.05326252803206444\n",
      "Epoch 4917, Loss: 0.08305662497878075, Final Batch Loss: 0.04583850875496864\n",
      "Epoch 4918, Loss: 0.08745849505066872, Final Batch Loss: 0.03698286786675453\n",
      "Epoch 4919, Loss: 0.06981190294027328, Final Batch Loss: 0.03778909146785736\n",
      "Epoch 4920, Loss: 0.07192153111100197, Final Batch Loss: 0.03704163432121277\n",
      "Epoch 4921, Loss: 0.06688082311302423, Final Batch Loss: 0.014583495445549488\n",
      "Epoch 4922, Loss: 0.07953842729330063, Final Batch Loss: 0.047009099274873734\n",
      "Epoch 4923, Loss: 0.07165016420185566, Final Batch Loss: 0.05166495218873024\n",
      "Epoch 4924, Loss: 0.07912987843155861, Final Batch Loss: 0.036764901131391525\n",
      "Epoch 4925, Loss: 0.08890366926789284, Final Batch Loss: 0.04955513775348663\n",
      "Epoch 4926, Loss: 0.06863568723201752, Final Batch Loss: 0.028748225420713425\n",
      "Epoch 4927, Loss: 0.08736572042107582, Final Batch Loss: 0.03396597504615784\n",
      "Epoch 4928, Loss: 0.0729011781513691, Final Batch Loss: 0.01776573807001114\n",
      "Epoch 4929, Loss: 0.09004729241132736, Final Batch Loss: 0.036455318331718445\n",
      "Epoch 4930, Loss: 0.0972964409738779, Final Batch Loss: 0.029669830575585365\n",
      "Epoch 4931, Loss: 0.07860267907381058, Final Batch Loss: 0.04743143543601036\n",
      "Epoch 4932, Loss: 0.1206119991838932, Final Batch Loss: 0.022190053015947342\n",
      "Epoch 4933, Loss: 0.1339733749628067, Final Batch Loss: 0.06681530177593231\n",
      "Epoch 4934, Loss: 0.09341438114643097, Final Batch Loss: 0.04339994117617607\n",
      "Epoch 4935, Loss: 0.09862491488456726, Final Batch Loss: 0.05430719256401062\n",
      "Epoch 4936, Loss: 0.09522725641727448, Final Batch Loss: 0.05406532436609268\n",
      "Epoch 4937, Loss: 0.08081080950796604, Final Batch Loss: 0.051097571849823\n",
      "Epoch 4938, Loss: 0.0936366617679596, Final Batch Loss: 0.03633156046271324\n",
      "Epoch 4939, Loss: 0.06738564558327198, Final Batch Loss: 0.03851137310266495\n",
      "Epoch 4940, Loss: 0.07958026602864265, Final Batch Loss: 0.040080808103084564\n",
      "Epoch 4941, Loss: 0.08195594698190689, Final Batch Loss: 0.04759112745523453\n",
      "Epoch 4942, Loss: 0.07506280764937401, Final Batch Loss: 0.0365140326321125\n",
      "Epoch 4943, Loss: 0.06576795503497124, Final Batch Loss: 0.02622964233160019\n",
      "Epoch 4944, Loss: 0.07108907215297222, Final Batch Loss: 0.04636293277144432\n",
      "Epoch 4945, Loss: 0.09565466828644276, Final Batch Loss: 0.06479375064373016\n",
      "Epoch 4946, Loss: 0.08045292273163795, Final Batch Loss: 0.029980454593896866\n",
      "Epoch 4947, Loss: 0.08685122430324554, Final Batch Loss: 0.05100056901574135\n",
      "Epoch 4948, Loss: 0.09163615480065346, Final Batch Loss: 0.04596708342432976\n",
      "Epoch 4949, Loss: 0.06657542660832405, Final Batch Loss: 0.03442520648241043\n",
      "Epoch 4950, Loss: 0.08360280655324459, Final Batch Loss: 0.028707405552268028\n",
      "Epoch 4951, Loss: 0.08858317509293556, Final Batch Loss: 0.041476570069789886\n",
      "Epoch 4952, Loss: 0.0710226520895958, Final Batch Loss: 0.04046187549829483\n",
      "Epoch 4953, Loss: 0.07244981825351715, Final Batch Loss: 0.05237007141113281\n",
      "Epoch 4954, Loss: 0.08699748665094376, Final Batch Loss: 0.05497727543115616\n",
      "Epoch 4955, Loss: 0.0688944011926651, Final Batch Loss: 0.035231851041316986\n",
      "Epoch 4956, Loss: 0.06983747333288193, Final Batch Loss: 0.027378849685192108\n",
      "Epoch 4957, Loss: 0.074467483907938, Final Batch Loss: 0.034206803888082504\n",
      "Epoch 4958, Loss: 0.06494553200900555, Final Batch Loss: 0.035762447863817215\n",
      "Epoch 4959, Loss: 0.08554651960730553, Final Batch Loss: 0.023412972688674927\n",
      "Epoch 4960, Loss: 0.06078817881643772, Final Batch Loss: 0.017939971759915352\n",
      "Epoch 4961, Loss: 0.0675754090771079, Final Batch Loss: 0.015436011366546154\n",
      "Epoch 4962, Loss: 0.06365145929157734, Final Batch Loss: 0.022979898378252983\n",
      "Epoch 4963, Loss: 0.07860667817294598, Final Batch Loss: 0.028050294145941734\n",
      "Epoch 4964, Loss: 0.07846050336956978, Final Batch Loss: 0.03994542732834816\n",
      "Epoch 4965, Loss: 0.07421137392520905, Final Batch Loss: 0.041610050946474075\n",
      "Epoch 4966, Loss: 0.06585298106074333, Final Batch Loss: 0.023555904626846313\n",
      "Epoch 4967, Loss: 0.060391997918486595, Final Batch Loss: 0.024769796058535576\n",
      "Epoch 4968, Loss: 0.10219187662005424, Final Batch Loss: 0.06065370514988899\n",
      "Epoch 4969, Loss: 0.10443144291639328, Final Batch Loss: 0.05981294810771942\n",
      "Epoch 4970, Loss: 0.0894204881042242, Final Batch Loss: 0.031059669330716133\n",
      "Epoch 4971, Loss: 0.1524723768234253, Final Batch Loss: 0.10248782485723495\n",
      "Epoch 4972, Loss: 0.08692405745387077, Final Batch Loss: 0.03644057735800743\n",
      "Epoch 4973, Loss: 0.09595596790313721, Final Batch Loss: 0.042589277029037476\n",
      "Epoch 4974, Loss: 0.06575840711593628, Final Batch Loss: 0.028281480073928833\n",
      "Epoch 4975, Loss: 0.1115398146212101, Final Batch Loss: 0.05783316120505333\n",
      "Epoch 4976, Loss: 0.12613724172115326, Final Batch Loss: 0.09165111929178238\n",
      "Epoch 4977, Loss: 0.09744739159941673, Final Batch Loss: 0.04306343197822571\n",
      "Epoch 4978, Loss: 0.09340771660208702, Final Batch Loss: 0.05860619992017746\n",
      "Epoch 4979, Loss: 0.10230288282036781, Final Batch Loss: 0.032101716846227646\n",
      "Epoch 4980, Loss: 0.1077623963356018, Final Batch Loss: 0.06229652464389801\n",
      "Epoch 4981, Loss: 0.07881032302975655, Final Batch Loss: 0.041019193828105927\n",
      "Epoch 4982, Loss: 0.07175656966865063, Final Batch Loss: 0.02416517399251461\n",
      "Epoch 4983, Loss: 0.09322744607925415, Final Batch Loss: 0.054915931075811386\n",
      "Epoch 4984, Loss: 0.09655167907476425, Final Batch Loss: 0.05756846442818642\n",
      "Epoch 4985, Loss: 0.0941508561372757, Final Batch Loss: 0.04642069339752197\n",
      "Epoch 4986, Loss: 0.09023024141788483, Final Batch Loss: 0.04230733588337898\n",
      "Epoch 4987, Loss: 0.07618187367916107, Final Batch Loss: 0.028150394558906555\n",
      "Epoch 4988, Loss: 0.0840042233467102, Final Batch Loss: 0.05392655357718468\n",
      "Epoch 4989, Loss: 0.09817977994680405, Final Batch Loss: 0.0625229924917221\n",
      "Epoch 4990, Loss: 0.0960816740989685, Final Batch Loss: 0.04936446249485016\n",
      "Epoch 4991, Loss: 0.06720704957842827, Final Batch Loss: 0.019001200795173645\n",
      "Epoch 4992, Loss: 0.07370450347661972, Final Batch Loss: 0.041120804846286774\n",
      "Epoch 4993, Loss: 0.08064857311546803, Final Batch Loss: 0.052632156759500504\n",
      "Epoch 4994, Loss: 0.06820014864206314, Final Batch Loss: 0.03464334458112717\n",
      "Epoch 4995, Loss: 0.08662748523056507, Final Batch Loss: 0.024231264367699623\n",
      "Epoch 4996, Loss: 0.07358228974044323, Final Batch Loss: 0.043633900582790375\n",
      "Epoch 4997, Loss: 0.07523670792579651, Final Batch Loss: 0.032643873244524\n",
      "Epoch 4998, Loss: 0.09211226552724838, Final Batch Loss: 0.06003112345933914\n",
      "Epoch 4999, Loss: 0.0921044573187828, Final Batch Loss: 0.05104358121752739\n",
      "Epoch 5000, Loss: 0.0803641602396965, Final Batch Loss: 0.0442313589155674\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  2  0]\n",
      " [ 1 42  0]\n",
      " [ 0  0 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96000   0.92308   0.94118        26\n",
      "           1    0.95455   0.97674   0.96552        43\n",
      "           2    1.00000   1.00000   1.00000        41\n",
      "\n",
      "    accuracy                        0.97273       110\n",
      "   macro avg    0.97152   0.96661   0.96890       110\n",
      "weighted avg    0.97278   0.97273   0.97262       110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38  0  0]\n",
      " [ 0 38  0]\n",
      " [ 0  0 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        38\n",
      "           1    1.00000   1.00000   1.00000        38\n",
      "           2    1.00000   1.00000   1.00000        34\n",
      "\n",
      "    accuracy                        1.00000       110\n",
      "   macro avg    1.00000   1.00000   1.00000       110\n",
      "weighted avg    1.00000   1.00000   1.00000       110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(usr_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(usr_vectors[0], preds.cpu(), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
