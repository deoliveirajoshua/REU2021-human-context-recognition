{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '125 tBodyGyro-std()-Y',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '138 tBodyGyro-energy()-Y',\n",
    " '165 tBodyGyroJerk-std()-Y',\n",
    " '168 tBodyGyroJerk-mad()-Y',\n",
    " '178 tBodyGyroJerk-energy()-Y',\n",
    " '181 tBodyGyroJerk-iqr()-Y',\n",
    " '425 fBodyGyro-mean()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '431 fBodyGyro-mad()-Y',\n",
    " '441 fBodyGyro-energy()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '478 fBodyGyro-bandsEnergy()-25,32',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '204 tBodyAccMag-max()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '217 tGravityAccMag-max()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '275 fBodyAcc-max()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '506 fBodyAccMag-max()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>42 tGravityAcc-mean()-Y</th>\n",
       "      <th>43 tGravityAcc-mean()-Z</th>\n",
       "      <th>51 tGravityAcc-max()-Y</th>\n",
       "      <th>52 tGravityAcc-max()-Z</th>\n",
       "      <th>54 tGravityAcc-min()-Y</th>\n",
       "      <th>55 tGravityAcc-min()-Z</th>\n",
       "      <th>56 tGravityAcc-sma()</th>\n",
       "      <th>59 tGravityAcc-energy()-Z</th>\n",
       "      <th>125 tBodyGyro-std()-Y</th>\n",
       "      <th>128 tBodyGyro-mad()-Y</th>\n",
       "      <th>...</th>\n",
       "      <th>282 fBodyAcc-energy()-X</th>\n",
       "      <th>303 fBodyAcc-bandsEnergy()-1,8</th>\n",
       "      <th>311 fBodyAcc-bandsEnergy()-1,16</th>\n",
       "      <th>315 fBodyAcc-bandsEnergy()-1,24</th>\n",
       "      <th>504 fBodyAccMag-std()</th>\n",
       "      <th>505 fBodyAccMag-mad()</th>\n",
       "      <th>506 fBodyAccMag-max()</th>\n",
       "      <th>509 fBodyAccMag-energy()</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.140840</td>\n",
       "      <td>0.115375</td>\n",
       "      <td>-0.161265</td>\n",
       "      <td>0.124660</td>\n",
       "      <td>-0.123213</td>\n",
       "      <td>0.056483</td>\n",
       "      <td>-0.375426</td>\n",
       "      <td>-0.975510</td>\n",
       "      <td>-0.976623</td>\n",
       "      <td>-0.976353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999968</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>-0.956134</td>\n",
       "      <td>-0.948870</td>\n",
       "      <td>-0.974321</td>\n",
       "      <td>-0.998285</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.141551</td>\n",
       "      <td>0.109379</td>\n",
       "      <td>-0.161343</td>\n",
       "      <td>0.122586</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.383430</td>\n",
       "      <td>-0.978500</td>\n",
       "      <td>-0.989046</td>\n",
       "      <td>-0.989038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.975866</td>\n",
       "      <td>-0.975777</td>\n",
       "      <td>-0.978226</td>\n",
       "      <td>-0.999472</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.142010</td>\n",
       "      <td>0.101884</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.094566</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.401602</td>\n",
       "      <td>-0.981672</td>\n",
       "      <td>-0.993552</td>\n",
       "      <td>-0.994122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-0.999972</td>\n",
       "      <td>-0.989015</td>\n",
       "      <td>-0.985594</td>\n",
       "      <td>-0.993062</td>\n",
       "      <td>-0.999807</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.143976</td>\n",
       "      <td>0.099850</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.093425</td>\n",
       "      <td>-0.121336</td>\n",
       "      <td>0.095753</td>\n",
       "      <td>-0.400278</td>\n",
       "      <td>-0.982420</td>\n",
       "      <td>-0.992407</td>\n",
       "      <td>-0.993142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999975</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-0.986742</td>\n",
       "      <td>-0.983524</td>\n",
       "      <td>-0.990230</td>\n",
       "      <td>-0.999770</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.148750</td>\n",
       "      <td>0.094486</td>\n",
       "      <td>-0.166786</td>\n",
       "      <td>0.091682</td>\n",
       "      <td>-0.121834</td>\n",
       "      <td>0.094059</td>\n",
       "      <td>-0.400477</td>\n",
       "      <td>-0.984363</td>\n",
       "      <td>-0.992378</td>\n",
       "      <td>-0.992542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.990063</td>\n",
       "      <td>-0.992324</td>\n",
       "      <td>-0.990506</td>\n",
       "      <td>-0.999873</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>-0.222004</td>\n",
       "      <td>-0.039492</td>\n",
       "      <td>-0.214233</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.071977</td>\n",
       "      <td>-0.405132</td>\n",
       "      <td>-0.995193</td>\n",
       "      <td>0.084878</td>\n",
       "      <td>0.065142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674230</td>\n",
       "      <td>-0.684177</td>\n",
       "      <td>-0.666429</td>\n",
       "      <td>-0.668164</td>\n",
       "      <td>-0.232600</td>\n",
       "      <td>-0.007392</td>\n",
       "      <td>-0.401674</td>\n",
       "      <td>-0.584282</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>-0.242054</td>\n",
       "      <td>-0.039863</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.358934</td>\n",
       "      <td>-0.995151</td>\n",
       "      <td>0.098249</td>\n",
       "      <td>0.091791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.705580</td>\n",
       "      <td>-0.726986</td>\n",
       "      <td>-0.704444</td>\n",
       "      <td>-0.705435</td>\n",
       "      <td>-0.275373</td>\n",
       "      <td>-0.172448</td>\n",
       "      <td>-0.410577</td>\n",
       "      <td>-0.632536</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>-0.236950</td>\n",
       "      <td>-0.026805</td>\n",
       "      <td>-0.249134</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.216004</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.377025</td>\n",
       "      <td>-0.995450</td>\n",
       "      <td>0.185902</td>\n",
       "      <td>0.170686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.692379</td>\n",
       "      <td>-0.655263</td>\n",
       "      <td>-0.674515</td>\n",
       "      <td>-0.684729</td>\n",
       "      <td>-0.220288</td>\n",
       "      <td>-0.216074</td>\n",
       "      <td>-0.362904</td>\n",
       "      <td>-0.641170</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>-0.233230</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.244267</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.210542</td>\n",
       "      <td>-0.040009</td>\n",
       "      <td>-0.440050</td>\n",
       "      <td>-0.998824</td>\n",
       "      <td>0.190360</td>\n",
       "      <td>0.178939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693098</td>\n",
       "      <td>-0.643425</td>\n",
       "      <td>-0.677215</td>\n",
       "      <td>-0.685088</td>\n",
       "      <td>-0.234539</td>\n",
       "      <td>-0.220443</td>\n",
       "      <td>-0.397687</td>\n",
       "      <td>-0.663579</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>-0.233292</td>\n",
       "      <td>-0.020954</td>\n",
       "      <td>-0.240956</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>-0.212149</td>\n",
       "      <td>-0.047491</td>\n",
       "      <td>-0.432003</td>\n",
       "      <td>-0.998144</td>\n",
       "      <td>0.022216</td>\n",
       "      <td>-0.073681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.731037</td>\n",
       "      <td>-0.709495</td>\n",
       "      <td>-0.728519</td>\n",
       "      <td>-0.727441</td>\n",
       "      <td>-0.342670</td>\n",
       "      <td>-0.146649</td>\n",
       "      <td>-0.620014</td>\n",
       "      <td>-0.698087</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      42 tGravityAcc-mean()-Y  43 tGravityAcc-mean()-Z  \\\n",
       "0                   -0.140840                 0.115375   \n",
       "1                   -0.141551                 0.109379   \n",
       "2                   -0.142010                 0.101884   \n",
       "3                   -0.143976                 0.099850   \n",
       "4                   -0.148750                 0.094486   \n",
       "...                       ...                      ...   \n",
       "7347                -0.222004                -0.039492   \n",
       "7348                -0.242054                -0.039863   \n",
       "7349                -0.236950                -0.026805   \n",
       "7350                -0.233230                -0.004984   \n",
       "7351                -0.233292                -0.020954   \n",
       "\n",
       "      51 tGravityAcc-max()-Y  52 tGravityAcc-max()-Z  54 tGravityAcc-min()-Y  \\\n",
       "0                  -0.161265                0.124660               -0.123213   \n",
       "1                  -0.161343                0.122586               -0.114893   \n",
       "2                  -0.163711                0.094566               -0.114893   \n",
       "3                  -0.163711                0.093425               -0.121336   \n",
       "4                  -0.166786                0.091682               -0.121834   \n",
       "...                      ...                     ...                     ...   \n",
       "7347               -0.214233               -0.016391               -0.234998   \n",
       "7348               -0.231477               -0.016391               -0.234998   \n",
       "7349               -0.249134                0.024684               -0.216004   \n",
       "7350               -0.244267                0.024684               -0.210542   \n",
       "7351               -0.240956                0.003031               -0.212149   \n",
       "\n",
       "      55 tGravityAcc-min()-Z  56 tGravityAcc-sma()  59 tGravityAcc-energy()-Z  \\\n",
       "0                   0.056483             -0.375426                  -0.975510   \n",
       "1                   0.102764             -0.383430                  -0.978500   \n",
       "2                   0.102764             -0.401602                  -0.981672   \n",
       "3                   0.095753             -0.400278                  -0.982420   \n",
       "4                   0.094059             -0.400477                  -0.984363   \n",
       "...                      ...                   ...                        ...   \n",
       "7347               -0.071977             -0.405132                  -0.995193   \n",
       "7348               -0.068919             -0.358934                  -0.995151   \n",
       "7349               -0.068919             -0.377025                  -0.995450   \n",
       "7350               -0.040009             -0.440050                  -0.998824   \n",
       "7351               -0.047491             -0.432003                  -0.998144   \n",
       "\n",
       "      125 tBodyGyro-std()-Y  128 tBodyGyro-mad()-Y  ...  \\\n",
       "0                 -0.976623              -0.976353  ...   \n",
       "1                 -0.989046              -0.989038  ...   \n",
       "2                 -0.993552              -0.994122  ...   \n",
       "3                 -0.992407              -0.993142  ...   \n",
       "4                 -0.992378              -0.992542  ...   \n",
       "...                     ...                    ...  ...   \n",
       "7347               0.084878               0.065142  ...   \n",
       "7348               0.098249               0.091791  ...   \n",
       "7349               0.185902               0.170686  ...   \n",
       "7350               0.190360               0.178939  ...   \n",
       "7351               0.022216              -0.073681  ...   \n",
       "\n",
       "      282 fBodyAcc-energy()-X  303 fBodyAcc-bandsEnergy()-1,8  \\\n",
       "0                   -0.999968                       -0.999963   \n",
       "1                   -0.999991                       -0.999996   \n",
       "2                   -0.999969                       -0.999989   \n",
       "3                   -0.999975                       -0.999989   \n",
       "4                   -0.999990                       -0.999994   \n",
       "...                       ...                             ...   \n",
       "7347                -0.674230                       -0.684177   \n",
       "7348                -0.705580                       -0.726986   \n",
       "7349                -0.692379                       -0.655263   \n",
       "7350                -0.693098                       -0.643425   \n",
       "7351                -0.731037                       -0.709495   \n",
       "\n",
       "      311 fBodyAcc-bandsEnergy()-1,16  315 fBodyAcc-bandsEnergy()-1,24  \\\n",
       "0                           -0.999969                        -0.999971   \n",
       "1                           -0.999994                        -0.999992   \n",
       "2                           -0.999983                        -0.999972   \n",
       "3                           -0.999986                        -0.999977   \n",
       "4                           -0.999993                        -0.999991   \n",
       "...                               ...                              ...   \n",
       "7347                        -0.666429                        -0.668164   \n",
       "7348                        -0.704444                        -0.705435   \n",
       "7349                        -0.674515                        -0.684729   \n",
       "7350                        -0.677215                        -0.685088   \n",
       "7351                        -0.728519                        -0.727441   \n",
       "\n",
       "      504 fBodyAccMag-std()  505 fBodyAccMag-mad()  506 fBodyAccMag-max()  \\\n",
       "0                 -0.956134              -0.948870              -0.974321   \n",
       "1                 -0.975866              -0.975777              -0.978226   \n",
       "2                 -0.989015              -0.985594              -0.993062   \n",
       "3                 -0.986742              -0.983524              -0.990230   \n",
       "4                 -0.990063              -0.992324              -0.990506   \n",
       "...                     ...                    ...                    ...   \n",
       "7347              -0.232600              -0.007392              -0.401674   \n",
       "7348              -0.275373              -0.172448              -0.410577   \n",
       "7349              -0.220288              -0.216074              -0.362904   \n",
       "7350              -0.234539              -0.220443              -0.397687   \n",
       "7351              -0.342670              -0.146649              -0.620014   \n",
       "\n",
       "      509 fBodyAccMag-energy()  Activity  Subject  \n",
       "0                    -0.998285         5        1  \n",
       "1                    -0.999472         5        1  \n",
       "2                    -0.999807         5        1  \n",
       "3                    -0.999770         5        1  \n",
       "4                    -0.999873         5        1  \n",
       "...                        ...       ...      ...  \n",
       "7347                 -0.584282         2       30  \n",
       "7348                 -0.632536         2       30  \n",
       "7349                 -0.641170         2       30  \n",
       "7350                 -0.663579         2       30  \n",
       "7351                 -0.698087         2       30  \n",
       "\n",
       "[7352 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names = pd.read_csv('../../data/features.txt', delimiter = '\\n', header = None)\n",
    "train_column_names = train_names.values.tolist()\n",
    "train_column_names = [k for row in train_column_names for k in row]\n",
    "\n",
    "train_data = pd.read_csv('../../data/X_train.txt', delim_whitespace = True, header = None)\n",
    "train_data.columns = train_column_names\n",
    "\n",
    "### Single dataframe column\n",
    "y_train = pd.read_csv('../../data/y_train.txt', header = None)\n",
    "y_train.columns = ['Activity']\n",
    "\n",
    "y_train_subject = pd.read_csv('../../data/subject_train.txt', header = None)\n",
    "y_train_subject.columns = ['Subject']\n",
    "\n",
    "X_train_1 = train_data[sub_features]\n",
    "X_train_2 = train_data[act_features]\n",
    "X_train_data = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "\n",
    "X_train_data = pd.concat([X_train_data, y_train, y_train_subject], axis = 1)\n",
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_data[(X_train_data['Subject'].isin([23, 25, 27])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,:-2].values\n",
    "y_train = X_train_data[(X_train_data['Subject'].isin([23, 25, 27])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,-2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y_train)):\n",
    "    if y_train[k] == 1:\n",
    "        y_train[k] = 0\n",
    "    elif y_train[k] == 3:\n",
    "        y_train[k] = 1\n",
    "    else:\n",
    "        y_train[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.15, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 30),\n",
    "            classifier_block(30, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2798492908477783, Final Batch Loss: 1.12424898147583\n",
      "Epoch 2, Loss: 2.2675838470458984, Final Batch Loss: 1.1163382530212402\n",
      "Epoch 3, Loss: 2.2644495964050293, Final Batch Loss: 1.1403100490570068\n",
      "Epoch 4, Loss: 2.2573609352111816, Final Batch Loss: 1.1244179010391235\n",
      "Epoch 5, Loss: 2.2558274269104004, Final Batch Loss: 1.1370238065719604\n",
      "Epoch 6, Loss: 2.2566198110580444, Final Batch Loss: 1.126944899559021\n",
      "Epoch 7, Loss: 2.2447688579559326, Final Batch Loss: 1.1112414598464966\n",
      "Epoch 8, Loss: 2.2440497875213623, Final Batch Loss: 1.1234130859375\n",
      "Epoch 9, Loss: 2.2389479875564575, Final Batch Loss: 1.1155328750610352\n",
      "Epoch 10, Loss: 2.2372355461120605, Final Batch Loss: 1.1233962774276733\n",
      "Epoch 11, Loss: 2.230385184288025, Final Batch Loss: 1.1084474325180054\n",
      "Epoch 12, Loss: 2.222010374069214, Final Batch Loss: 1.1047154664993286\n",
      "Epoch 13, Loss: 2.218112349510193, Final Batch Loss: 1.1029027700424194\n",
      "Epoch 14, Loss: 2.206552028656006, Final Batch Loss: 1.1069051027297974\n",
      "Epoch 15, Loss: 2.202816963195801, Final Batch Loss: 1.0999269485473633\n",
      "Epoch 16, Loss: 2.189920663833618, Final Batch Loss: 1.0982052087783813\n",
      "Epoch 17, Loss: 2.1785603761672974, Final Batch Loss: 1.0864779949188232\n",
      "Epoch 18, Loss: 2.160501718521118, Final Batch Loss: 1.0774189233779907\n",
      "Epoch 19, Loss: 2.147617220878601, Final Batch Loss: 1.0699416399002075\n",
      "Epoch 20, Loss: 2.1334469318389893, Final Batch Loss: 1.0643162727355957\n",
      "Epoch 21, Loss: 2.1119524240493774, Final Batch Loss: 1.0524158477783203\n",
      "Epoch 22, Loss: 2.099898338317871, Final Batch Loss: 1.0511384010314941\n",
      "Epoch 23, Loss: 2.0603277683258057, Final Batch Loss: 1.0264451503753662\n",
      "Epoch 24, Loss: 2.0397439002990723, Final Batch Loss: 1.015966773033142\n",
      "Epoch 25, Loss: 2.003135561943054, Final Batch Loss: 1.0040656328201294\n",
      "Epoch 26, Loss: 1.9616491794586182, Final Batch Loss: 0.9815874695777893\n",
      "Epoch 27, Loss: 1.934704065322876, Final Batch Loss: 0.9670292139053345\n",
      "Epoch 28, Loss: 1.8759938478469849, Final Batch Loss: 0.9187027215957642\n",
      "Epoch 29, Loss: 1.8123317956924438, Final Batch Loss: 0.9014415144920349\n",
      "Epoch 30, Loss: 1.7706636190414429, Final Batch Loss: 0.8909568190574646\n",
      "Epoch 31, Loss: 1.703227937221527, Final Batch Loss: 0.8315522074699402\n",
      "Epoch 32, Loss: 1.6524230241775513, Final Batch Loss: 0.8466901183128357\n",
      "Epoch 33, Loss: 1.554551362991333, Final Batch Loss: 0.7869105339050293\n",
      "Epoch 34, Loss: 1.4857705235481262, Final Batch Loss: 0.7389668822288513\n",
      "Epoch 35, Loss: 1.3788219690322876, Final Batch Loss: 0.6670752763748169\n",
      "Epoch 36, Loss: 1.335813283920288, Final Batch Loss: 0.6459512114524841\n",
      "Epoch 37, Loss: 1.2641764879226685, Final Batch Loss: 0.6277661323547363\n",
      "Epoch 38, Loss: 1.145500361919403, Final Batch Loss: 0.5530824065208435\n",
      "Epoch 39, Loss: 1.0870870351791382, Final Batch Loss: 0.5117268562316895\n",
      "Epoch 40, Loss: 1.0148466229438782, Final Batch Loss: 0.5120938420295715\n",
      "Epoch 41, Loss: 0.9574317932128906, Final Batch Loss: 0.4472707509994507\n",
      "Epoch 42, Loss: 0.8893535137176514, Final Batch Loss: 0.43515926599502563\n",
      "Epoch 43, Loss: 0.8346006572246552, Final Batch Loss: 0.40034469962120056\n",
      "Epoch 44, Loss: 0.7642397284507751, Final Batch Loss: 0.3948168158531189\n",
      "Epoch 45, Loss: 0.7436489462852478, Final Batch Loss: 0.36148324608802795\n",
      "Epoch 46, Loss: 0.6877202689647675, Final Batch Loss: 0.3570769727230072\n",
      "Epoch 47, Loss: 0.5673707723617554, Final Batch Loss: 0.2727005183696747\n",
      "Epoch 48, Loss: 0.5884399116039276, Final Batch Loss: 0.3085387647151947\n",
      "Epoch 49, Loss: 0.544581800699234, Final Batch Loss: 0.2751240134239197\n",
      "Epoch 50, Loss: 0.5737771093845367, Final Batch Loss: 0.2951871454715729\n",
      "Epoch 51, Loss: 0.5270660221576691, Final Batch Loss: 0.2576368749141693\n",
      "Epoch 52, Loss: 0.4524858444929123, Final Batch Loss: 0.24370819330215454\n",
      "Epoch 53, Loss: 0.4358803778886795, Final Batch Loss: 0.2004900872707367\n",
      "Epoch 54, Loss: 0.46705374121665955, Final Batch Loss: 0.21955938637256622\n",
      "Epoch 55, Loss: 0.3710669279098511, Final Batch Loss: 0.19262546300888062\n",
      "Epoch 56, Loss: 0.4375196844339371, Final Batch Loss: 0.2240113466978073\n",
      "Epoch 57, Loss: 0.36989860236644745, Final Batch Loss: 0.20156431198120117\n",
      "Epoch 58, Loss: 0.3653109669685364, Final Batch Loss: 0.18099214136600494\n",
      "Epoch 59, Loss: 0.3500308692455292, Final Batch Loss: 0.15787138044834137\n",
      "Epoch 60, Loss: 0.3527522385120392, Final Batch Loss: 0.18990188837051392\n",
      "Epoch 61, Loss: 0.3604300022125244, Final Batch Loss: 0.20116189122200012\n",
      "Epoch 62, Loss: 0.31260041892528534, Final Batch Loss: 0.16465270519256592\n",
      "Epoch 63, Loss: 0.28741370141506195, Final Batch Loss: 0.1391962319612503\n",
      "Epoch 64, Loss: 0.3169805407524109, Final Batch Loss: 0.1459018737077713\n",
      "Epoch 65, Loss: 0.2571161389350891, Final Batch Loss: 0.1100647896528244\n",
      "Epoch 66, Loss: 0.3093409985303879, Final Batch Loss: 0.12755799293518066\n",
      "Epoch 67, Loss: 0.29574091732501984, Final Batch Loss: 0.14974285662174225\n",
      "Epoch 68, Loss: 0.28412244468927383, Final Batch Loss: 0.12419518083333969\n",
      "Epoch 69, Loss: 0.2255268692970276, Final Batch Loss: 0.08657310903072357\n",
      "Epoch 70, Loss: 0.2511596381664276, Final Batch Loss: 0.1368829905986786\n",
      "Epoch 71, Loss: 0.2754695862531662, Final Batch Loss: 0.1416391134262085\n",
      "Epoch 72, Loss: 0.21675660461187363, Final Batch Loss: 0.11433330923318863\n",
      "Epoch 73, Loss: 0.2102024108171463, Final Batch Loss: 0.10289377719163895\n",
      "Epoch 74, Loss: 0.21694064885377884, Final Batch Loss: 0.08752221614122391\n",
      "Epoch 75, Loss: 0.2127380669116974, Final Batch Loss: 0.1314752697944641\n",
      "Epoch 76, Loss: 0.24969355016946793, Final Batch Loss: 0.11173395067453384\n",
      "Epoch 77, Loss: 0.224794439971447, Final Batch Loss: 0.09898634999990463\n",
      "Epoch 78, Loss: 0.21330352872610092, Final Batch Loss: 0.10530083626508713\n",
      "Epoch 79, Loss: 0.14658847823739052, Final Batch Loss: 0.06223704293370247\n",
      "Epoch 80, Loss: 0.18977613002061844, Final Batch Loss: 0.08356331288814545\n",
      "Epoch 81, Loss: 0.21554163098335266, Final Batch Loss: 0.09617391973733902\n",
      "Epoch 82, Loss: 0.18810921162366867, Final Batch Loss: 0.07841292768716812\n",
      "Epoch 83, Loss: 0.2414359375834465, Final Batch Loss: 0.17828601598739624\n",
      "Epoch 84, Loss: 0.137648306787014, Final Batch Loss: 0.05610673129558563\n",
      "Epoch 85, Loss: 0.1649506390094757, Final Batch Loss: 0.08707403391599655\n",
      "Epoch 86, Loss: 0.19035149365663528, Final Batch Loss: 0.0897178053855896\n",
      "Epoch 87, Loss: 0.142426960170269, Final Batch Loss: 0.06414631009101868\n",
      "Epoch 88, Loss: 0.20032639801502228, Final Batch Loss: 0.09992664307355881\n",
      "Epoch 89, Loss: 0.14384040236473083, Final Batch Loss: 0.07959262281656265\n",
      "Epoch 90, Loss: 0.17190928012132645, Final Batch Loss: 0.09225936233997345\n",
      "Epoch 91, Loss: 0.17188376188278198, Final Batch Loss: 0.10578818619251251\n",
      "Epoch 92, Loss: 0.15749118477106094, Final Batch Loss: 0.10133825242519379\n",
      "Epoch 93, Loss: 0.1514715999364853, Final Batch Loss: 0.09050870686769485\n",
      "Epoch 94, Loss: 0.12881944701075554, Final Batch Loss: 0.05982581153512001\n",
      "Epoch 95, Loss: 0.14422855526208878, Final Batch Loss: 0.06539858877658844\n",
      "Epoch 96, Loss: 0.15990997105836868, Final Batch Loss: 0.07447835803031921\n",
      "Epoch 97, Loss: 0.18325459957122803, Final Batch Loss: 0.1024477407336235\n",
      "Epoch 98, Loss: 0.157961867749691, Final Batch Loss: 0.06549417227506638\n",
      "Epoch 99, Loss: 0.15476119145751, Final Batch Loss: 0.09241720288991928\n",
      "Epoch 100, Loss: 0.14454665035009384, Final Batch Loss: 0.06542012095451355\n",
      "Epoch 101, Loss: 0.10334018990397453, Final Batch Loss: 0.05419827997684479\n",
      "Epoch 102, Loss: 0.11173345893621445, Final Batch Loss: 0.07217638939619064\n",
      "Epoch 103, Loss: 0.10606304183602333, Final Batch Loss: 0.04362872242927551\n",
      "Epoch 104, Loss: 0.12484215572476387, Final Batch Loss: 0.0741608589887619\n",
      "Epoch 105, Loss: 0.142752006649971, Final Batch Loss: 0.06354806572198868\n",
      "Epoch 106, Loss: 0.08076855540275574, Final Batch Loss: 0.045918550342321396\n",
      "Epoch 107, Loss: 0.0990268923342228, Final Batch Loss: 0.05583075061440468\n",
      "Epoch 108, Loss: 0.10441655293107033, Final Batch Loss: 0.049141548573970795\n",
      "Epoch 109, Loss: 0.09316505119204521, Final Batch Loss: 0.052963580936193466\n",
      "Epoch 110, Loss: 0.11715952679514885, Final Batch Loss: 0.07878047972917557\n",
      "Epoch 111, Loss: 0.11335522681474686, Final Batch Loss: 0.05806497856974602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112, Loss: 0.11283533647656441, Final Batch Loss: 0.053661055862903595\n",
      "Epoch 113, Loss: 0.09292160719633102, Final Batch Loss: 0.04632100835442543\n",
      "Epoch 114, Loss: 0.09412185102701187, Final Batch Loss: 0.05083083361387253\n",
      "Epoch 115, Loss: 0.1144651249051094, Final Batch Loss: 0.06876036524772644\n",
      "Epoch 116, Loss: 0.12220751494169235, Final Batch Loss: 0.06547845900058746\n",
      "Epoch 117, Loss: 0.08976477012038231, Final Batch Loss: 0.043345194309949875\n",
      "Epoch 118, Loss: 0.08999314159154892, Final Batch Loss: 0.03687211498618126\n",
      "Epoch 119, Loss: 0.11074494943022728, Final Batch Loss: 0.07461341470479965\n",
      "Epoch 120, Loss: 0.09210348129272461, Final Batch Loss: 0.04919411614537239\n",
      "Epoch 121, Loss: 0.09918525069952011, Final Batch Loss: 0.06067726016044617\n",
      "Epoch 122, Loss: 0.08069897070527077, Final Batch Loss: 0.038692548871040344\n",
      "Epoch 123, Loss: 0.09114183485507965, Final Batch Loss: 0.02749823033809662\n",
      "Epoch 124, Loss: 0.0860290601849556, Final Batch Loss: 0.03276233375072479\n",
      "Epoch 125, Loss: 0.08009283058345318, Final Batch Loss: 0.019591117277741432\n",
      "Epoch 126, Loss: 0.0867171511054039, Final Batch Loss: 0.03539014235138893\n",
      "Epoch 127, Loss: 0.08666561171412468, Final Batch Loss: 0.05081295967102051\n",
      "Epoch 128, Loss: 0.16417210549116135, Final Batch Loss: 0.09900693595409393\n",
      "Epoch 129, Loss: 0.07856886088848114, Final Batch Loss: 0.03732690215110779\n",
      "Epoch 130, Loss: 0.10162988677620888, Final Batch Loss: 0.049335792660713196\n",
      "Epoch 131, Loss: 0.10201326757669449, Final Batch Loss: 0.04018097370862961\n",
      "Epoch 132, Loss: 0.054879676550626755, Final Batch Loss: 0.02730906754732132\n",
      "Epoch 133, Loss: 0.0731489323079586, Final Batch Loss: 0.04166219383478165\n",
      "Epoch 134, Loss: 0.05964719131588936, Final Batch Loss: 0.03469404950737953\n",
      "Epoch 135, Loss: 0.08826953172683716, Final Batch Loss: 0.04373442754149437\n",
      "Epoch 136, Loss: 0.07336224615573883, Final Batch Loss: 0.03160052374005318\n",
      "Epoch 137, Loss: 0.06589365750551224, Final Batch Loss: 0.03613394871354103\n",
      "Epoch 138, Loss: 0.07014470547437668, Final Batch Loss: 0.03631525859236717\n",
      "Epoch 139, Loss: 0.07777370885014534, Final Batch Loss: 0.03924756869673729\n",
      "Epoch 140, Loss: 0.09188012778759003, Final Batch Loss: 0.03863191232085228\n",
      "Epoch 141, Loss: 0.07586389780044556, Final Batch Loss: 0.02862124890089035\n",
      "Epoch 142, Loss: 0.048742715269327164, Final Batch Loss: 0.023442760109901428\n",
      "Epoch 143, Loss: 0.07811593264341354, Final Batch Loss: 0.0445437952876091\n",
      "Epoch 144, Loss: 0.0700557678937912, Final Batch Loss: 0.040538813918828964\n",
      "Epoch 145, Loss: 0.0882117860019207, Final Batch Loss: 0.051503486931324005\n",
      "Epoch 146, Loss: 0.07998394779860973, Final Batch Loss: 0.027327382937073708\n",
      "Epoch 147, Loss: 0.09420430660247803, Final Batch Loss: 0.05386050418019295\n",
      "Epoch 148, Loss: 0.05415518768131733, Final Batch Loss: 0.031719136983156204\n",
      "Epoch 149, Loss: 0.08335226960480213, Final Batch Loss: 0.030421080067753792\n",
      "Epoch 150, Loss: 0.0908861756324768, Final Batch Loss: 0.05302676931023598\n",
      "Epoch 151, Loss: 0.08370393514633179, Final Batch Loss: 0.02335420623421669\n",
      "Epoch 152, Loss: 0.04944421164691448, Final Batch Loss: 0.010944580659270287\n",
      "Epoch 153, Loss: 0.055470651015639305, Final Batch Loss: 0.014248890802264214\n",
      "Epoch 154, Loss: 0.044739666394889355, Final Batch Loss: 0.013784934766590595\n",
      "Epoch 155, Loss: 0.03996660094708204, Final Batch Loss: 0.012121112085878849\n",
      "Epoch 156, Loss: 0.05673479102551937, Final Batch Loss: 0.021026989445090294\n",
      "Epoch 157, Loss: 0.06542149186134338, Final Batch Loss: 0.018251992762088776\n",
      "Epoch 158, Loss: 0.053983330726623535, Final Batch Loss: 0.023730983957648277\n",
      "Epoch 159, Loss: 0.04908146895468235, Final Batch Loss: 0.024895591661334038\n",
      "Epoch 160, Loss: 0.04144104849547148, Final Batch Loss: 0.027100348845124245\n",
      "Epoch 161, Loss: 0.03939874563366175, Final Batch Loss: 0.014875696040689945\n",
      "Epoch 162, Loss: 0.040759794414043427, Final Batch Loss: 0.01823616959154606\n",
      "Epoch 163, Loss: 0.08093913272023201, Final Batch Loss: 0.04231064021587372\n",
      "Epoch 164, Loss: 0.054368915036320686, Final Batch Loss: 0.02435627393424511\n",
      "Epoch 165, Loss: 0.047438643872737885, Final Batch Loss: 0.015868499875068665\n",
      "Epoch 166, Loss: 0.06175839342176914, Final Batch Loss: 0.042208246886730194\n",
      "Epoch 167, Loss: 0.04463306441903114, Final Batch Loss: 0.022548507899045944\n",
      "Epoch 168, Loss: 0.04601013660430908, Final Batch Loss: 0.016794277355074883\n",
      "Epoch 169, Loss: 0.05290408246219158, Final Batch Loss: 0.03995389863848686\n",
      "Epoch 170, Loss: 0.06599452719092369, Final Batch Loss: 0.03849246725440025\n",
      "Epoch 171, Loss: 0.03302432969212532, Final Batch Loss: 0.01846691593527794\n",
      "Epoch 172, Loss: 0.04303073510527611, Final Batch Loss: 0.021274147555232048\n",
      "Epoch 173, Loss: 0.08583822846412659, Final Batch Loss: 0.04572311416268349\n",
      "Epoch 174, Loss: 0.03947824612259865, Final Batch Loss: 0.00995979830622673\n",
      "Epoch 175, Loss: 0.055541012436151505, Final Batch Loss: 0.02790188416838646\n",
      "Epoch 176, Loss: 0.04556557536125183, Final Batch Loss: 0.03692395240068436\n",
      "Epoch 177, Loss: 0.03575634025037289, Final Batch Loss: 0.015651896595954895\n",
      "Epoch 178, Loss: 0.05567683465778828, Final Batch Loss: 0.03571533411741257\n",
      "Epoch 179, Loss: 0.04367638938128948, Final Batch Loss: 0.018373511731624603\n",
      "Epoch 180, Loss: 0.05517212674021721, Final Batch Loss: 0.01702306792140007\n",
      "Epoch 181, Loss: 0.044473509304225445, Final Batch Loss: 0.01194716151803732\n",
      "Epoch 182, Loss: 0.04282012768089771, Final Batch Loss: 0.018523791804909706\n",
      "Epoch 183, Loss: 0.04988776706159115, Final Batch Loss: 0.016272610053420067\n",
      "Epoch 184, Loss: 0.037537576630711555, Final Batch Loss: 0.017846740782260895\n",
      "Epoch 185, Loss: 0.06708081066608429, Final Batch Loss: 0.03774062916636467\n",
      "Epoch 186, Loss: 0.032426122575998306, Final Batch Loss: 0.02216583676636219\n",
      "Epoch 187, Loss: 0.06415477208793163, Final Batch Loss: 0.036900825798511505\n",
      "Epoch 188, Loss: 0.033915056847035885, Final Batch Loss: 0.024938078597187996\n",
      "Epoch 189, Loss: 0.05023863725364208, Final Batch Loss: 0.026350680738687515\n",
      "Epoch 190, Loss: 0.05578010156750679, Final Batch Loss: 0.04007209092378616\n",
      "Epoch 191, Loss: 0.06801370345056057, Final Batch Loss: 0.05353882536292076\n",
      "Epoch 192, Loss: 0.05213189497590065, Final Batch Loss: 0.026671966537833214\n",
      "Epoch 193, Loss: 0.043552180752158165, Final Batch Loss: 0.015966540202498436\n",
      "Epoch 194, Loss: 0.04304365161806345, Final Batch Loss: 0.029386671259999275\n",
      "Epoch 195, Loss: 0.03250369429588318, Final Batch Loss: 0.016839632764458656\n",
      "Epoch 196, Loss: 0.049199800938367844, Final Batch Loss: 0.030345825478434563\n",
      "Epoch 197, Loss: 0.0317770685069263, Final Batch Loss: 0.007345892023295164\n",
      "Epoch 198, Loss: 0.047558603808283806, Final Batch Loss: 0.02317194826900959\n",
      "Epoch 199, Loss: 0.039103930816054344, Final Batch Loss: 0.02297666296362877\n",
      "Epoch 200, Loss: 0.04260916355997324, Final Batch Loss: 0.03469814360141754\n",
      "Epoch 201, Loss: 0.04262216854840517, Final Batch Loss: 0.028099726885557175\n",
      "Epoch 202, Loss: 0.030010965652763844, Final Batch Loss: 0.00894124899059534\n",
      "Epoch 203, Loss: 0.020668206736445427, Final Batch Loss: 0.012358207255601883\n",
      "Epoch 204, Loss: 0.08267803303897381, Final Batch Loss: 0.028069866821169853\n",
      "Epoch 205, Loss: 0.038700975477695465, Final Batch Loss: 0.0202017854899168\n",
      "Epoch 206, Loss: 0.0429638372734189, Final Batch Loss: 0.012321804650127888\n",
      "Epoch 207, Loss: 0.03632731921970844, Final Batch Loss: 0.01616007648408413\n",
      "Epoch 208, Loss: 0.03568519465625286, Final Batch Loss: 0.02270159311592579\n",
      "Epoch 209, Loss: 0.03432988282293081, Final Batch Loss: 0.010936743579804897\n",
      "Epoch 210, Loss: 0.024874670431017876, Final Batch Loss: 0.013649183325469494\n",
      "Epoch 211, Loss: 0.049996779300272465, Final Batch Loss: 0.04124109074473381\n",
      "Epoch 212, Loss: 0.02063889242708683, Final Batch Loss: 0.012133000418543816\n",
      "Epoch 213, Loss: 0.028927342034876347, Final Batch Loss: 0.017072506248950958\n",
      "Epoch 214, Loss: 0.04433407448232174, Final Batch Loss: 0.02473938837647438\n",
      "Epoch 215, Loss: 0.03960364358499646, Final Batch Loss: 0.03246860206127167\n",
      "Epoch 216, Loss: 0.0334057342261076, Final Batch Loss: 0.010431144386529922\n",
      "Epoch 217, Loss: 0.030067231506109238, Final Batch Loss: 0.015880612656474113\n",
      "Epoch 218, Loss: 0.05011284351348877, Final Batch Loss: 0.031358085572719574\n",
      "Epoch 219, Loss: 0.031212951987981796, Final Batch Loss: 0.018312660977244377\n",
      "Epoch 220, Loss: 0.019644010346382856, Final Batch Loss: 0.007206165697425604\n",
      "Epoch 221, Loss: 0.0527875404804945, Final Batch Loss: 0.01135311834514141\n",
      "Epoch 222, Loss: 0.035106171388179064, Final Batch Loss: 0.02793099172413349\n",
      "Epoch 223, Loss: 0.03753128461539745, Final Batch Loss: 0.011526582762598991\n",
      "Epoch 224, Loss: 0.032535867765545845, Final Batch Loss: 0.0170340146869421\n",
      "Epoch 225, Loss: 0.02558300318196416, Final Batch Loss: 0.007391641382128\n",
      "Epoch 226, Loss: 0.03963226638734341, Final Batch Loss: 0.019425339996814728\n",
      "Epoch 227, Loss: 0.03411171678453684, Final Batch Loss: 0.02120843715965748\n",
      "Epoch 228, Loss: 0.03239494934678078, Final Batch Loss: 0.02183302864432335\n",
      "Epoch 229, Loss: 0.04623093595728278, Final Batch Loss: 0.039874155074357986\n",
      "Epoch 230, Loss: 0.0191253200173378, Final Batch Loss: 0.007869941182434559\n",
      "Epoch 231, Loss: 0.023768344894051552, Final Batch Loss: 0.012595530599355698\n",
      "Epoch 232, Loss: 0.021877081133425236, Final Batch Loss: 0.012006624601781368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233, Loss: 0.023144392762333155, Final Batch Loss: 0.017864402383565903\n",
      "Epoch 234, Loss: 0.043458023108541965, Final Batch Loss: 0.03482387214899063\n",
      "Epoch 235, Loss: 0.03802546113729477, Final Batch Loss: 0.024772806093096733\n",
      "Epoch 236, Loss: 0.024892928544431925, Final Batch Loss: 0.0065732416696846485\n",
      "Epoch 237, Loss: 0.028476913459599018, Final Batch Loss: 0.005786198191344738\n",
      "Epoch 238, Loss: 0.03460385370999575, Final Batch Loss: 0.025204885751008987\n",
      "Epoch 239, Loss: 0.023164164274930954, Final Batch Loss: 0.010455800220370293\n",
      "Epoch 240, Loss: 0.015677464194595814, Final Batch Loss: 0.004821234382688999\n",
      "Epoch 241, Loss: 0.030115352012217045, Final Batch Loss: 0.023068919777870178\n",
      "Epoch 242, Loss: 0.03820635471493006, Final Batch Loss: 0.013092889450490475\n",
      "Epoch 243, Loss: 0.05796841345727444, Final Batch Loss: 0.028705241158604622\n",
      "Epoch 244, Loss: 0.03431027987971902, Final Batch Loss: 0.0061621335335075855\n",
      "Epoch 245, Loss: 0.023566711228340864, Final Batch Loss: 0.004595325794070959\n",
      "Epoch 246, Loss: 0.021658023819327354, Final Batch Loss: 0.01596233807504177\n",
      "Epoch 247, Loss: 0.013823507353663445, Final Batch Loss: 0.00504489429295063\n",
      "Epoch 248, Loss: 0.0279280380345881, Final Batch Loss: 0.02035098895430565\n",
      "Epoch 249, Loss: 0.028417576104402542, Final Batch Loss: 0.01331411674618721\n",
      "Epoch 250, Loss: 0.031090501695871353, Final Batch Loss: 0.019025707617402077\n",
      "Epoch 251, Loss: 0.02027077693492174, Final Batch Loss: 0.012957809492945671\n",
      "Epoch 252, Loss: 0.02857823111116886, Final Batch Loss: 0.018488384783267975\n",
      "Epoch 253, Loss: 0.03546425141394138, Final Batch Loss: 0.02099565975368023\n",
      "Epoch 254, Loss: 0.01754334755241871, Final Batch Loss: 0.010237785056233406\n",
      "Epoch 255, Loss: 0.03422430530190468, Final Batch Loss: 0.024563811719417572\n",
      "Epoch 256, Loss: 0.022481045685708523, Final Batch Loss: 0.012301075272262096\n",
      "Epoch 257, Loss: 0.021051772870123386, Final Batch Loss: 0.006231850013136864\n",
      "Epoch 258, Loss: 0.027248414466157556, Final Batch Loss: 0.024013744667172432\n",
      "Epoch 259, Loss: 0.03702340694144368, Final Batch Loss: 0.005902873817831278\n",
      "Epoch 260, Loss: 0.01461872085928917, Final Batch Loss: 0.007309926673769951\n",
      "Epoch 261, Loss: 0.02685578539967537, Final Batch Loss: 0.006999028846621513\n",
      "Epoch 262, Loss: 0.009292090311646461, Final Batch Loss: 0.0029815007001161575\n",
      "Epoch 263, Loss: 0.015922876074910164, Final Batch Loss: 0.006769413128495216\n",
      "Epoch 264, Loss: 0.0707575622946024, Final Batch Loss: 0.045387428253889084\n",
      "Epoch 265, Loss: 0.01532761799171567, Final Batch Loss: 0.008759835734963417\n",
      "Epoch 266, Loss: 0.030030693858861923, Final Batch Loss: 0.020699940621852875\n",
      "Epoch 267, Loss: 0.023909340612590313, Final Batch Loss: 0.01566515862941742\n",
      "Epoch 268, Loss: 0.015321075450628996, Final Batch Loss: 0.006848487537354231\n",
      "Epoch 269, Loss: 0.022365889977663755, Final Batch Loss: 0.017934488132596016\n",
      "Epoch 270, Loss: 0.028969881124794483, Final Batch Loss: 0.013833481818437576\n",
      "Epoch 271, Loss: 0.024078408256173134, Final Batch Loss: 0.019185783341526985\n",
      "Epoch 272, Loss: 0.017422206234186888, Final Batch Loss: 0.0032706349156796932\n",
      "Epoch 273, Loss: 0.01782974135130644, Final Batch Loss: 0.005654618144035339\n",
      "Epoch 274, Loss: 0.05541227385401726, Final Batch Loss: 0.04461444914340973\n",
      "Epoch 275, Loss: 0.03866436704993248, Final Batch Loss: 0.017902450636029243\n",
      "Epoch 276, Loss: 0.02726810984313488, Final Batch Loss: 0.0179306473582983\n",
      "Epoch 277, Loss: 0.041783797554671764, Final Batch Loss: 0.007813396863639355\n",
      "Epoch 278, Loss: 0.014602608513087034, Final Batch Loss: 0.008954891003668308\n",
      "Epoch 279, Loss: 0.044426669366657734, Final Batch Loss: 0.036017000675201416\n",
      "Epoch 280, Loss: 0.03978732135146856, Final Batch Loss: 0.027535919100046158\n",
      "Epoch 281, Loss: 0.022111852187663317, Final Batch Loss: 0.016126452013850212\n",
      "Epoch 282, Loss: 0.01951201632618904, Final Batch Loss: 0.01087347511202097\n",
      "Epoch 283, Loss: 0.014713083859533072, Final Batch Loss: 0.004460721742361784\n",
      "Epoch 284, Loss: 0.026706226635724306, Final Batch Loss: 0.018924232572317123\n",
      "Epoch 285, Loss: 0.009978021495044231, Final Batch Loss: 0.005950195249170065\n",
      "Epoch 286, Loss: 0.018115374259650707, Final Batch Loss: 0.010073249228298664\n",
      "Epoch 287, Loss: 0.020984024740755558, Final Batch Loss: 0.003775845281779766\n",
      "Epoch 288, Loss: 0.022421694360673428, Final Batch Loss: 0.009076862595975399\n",
      "Epoch 289, Loss: 0.009607338346540928, Final Batch Loss: 0.005409885663539171\n",
      "Epoch 290, Loss: 0.03308428777381778, Final Batch Loss: 0.025488004088401794\n",
      "Epoch 291, Loss: 0.01082382700406015, Final Batch Loss: 0.0025492978747934103\n",
      "Epoch 292, Loss: 0.06535986810922623, Final Batch Loss: 0.04609404131770134\n",
      "Epoch 293, Loss: 0.017392845824360847, Final Batch Loss: 0.007953083142638206\n",
      "Epoch 294, Loss: 0.015983624383807182, Final Batch Loss: 0.010375787504017353\n",
      "Epoch 295, Loss: 0.03459380194544792, Final Batch Loss: 0.019735269248485565\n",
      "Epoch 296, Loss: 0.026797558180987835, Final Batch Loss: 0.011529496870934963\n",
      "Epoch 297, Loss: 0.01840029377490282, Final Batch Loss: 0.005579650402069092\n",
      "Epoch 298, Loss: 0.017287684371694922, Final Batch Loss: 0.014626596122980118\n",
      "Epoch 299, Loss: 0.013419375754892826, Final Batch Loss: 0.008730226196348667\n",
      "Epoch 300, Loss: 0.01123017305508256, Final Batch Loss: 0.004345185123383999\n",
      "Epoch 301, Loss: 0.03555803466588259, Final Batch Loss: 0.004505804739892483\n",
      "Epoch 302, Loss: 0.013345611980184913, Final Batch Loss: 0.011189811863005161\n",
      "Epoch 303, Loss: 0.01069817109964788, Final Batch Loss: 0.007496621459722519\n",
      "Epoch 304, Loss: 0.0139707550406456, Final Batch Loss: 0.006539967376738787\n",
      "Epoch 305, Loss: 0.007551203249022365, Final Batch Loss: 0.00332137499935925\n",
      "Epoch 306, Loss: 0.0075306647922843695, Final Batch Loss: 0.003498974023386836\n",
      "Epoch 307, Loss: 0.012188095599412918, Final Batch Loss: 0.005670616403222084\n",
      "Epoch 308, Loss: 0.012121740728616714, Final Batch Loss: 0.00432265130802989\n",
      "Epoch 309, Loss: 0.013055723626166582, Final Batch Loss: 0.009527282789349556\n",
      "Epoch 310, Loss: 0.02011043019592762, Final Batch Loss: 0.011673808097839355\n",
      "Epoch 311, Loss: 0.01354937069118023, Final Batch Loss: 0.003977772779762745\n",
      "Epoch 312, Loss: 0.016513321548700333, Final Batch Loss: 0.008854632265865803\n",
      "Epoch 313, Loss: 0.01841716282069683, Final Batch Loss: 0.007404357194900513\n",
      "Epoch 314, Loss: 0.010982210515066981, Final Batch Loss: 0.0026700932066887617\n",
      "Epoch 315, Loss: 0.010645540431141853, Final Batch Loss: 0.004142353311181068\n",
      "Epoch 316, Loss: 0.02154270838946104, Final Batch Loss: 0.013087409548461437\n",
      "Epoch 317, Loss: 0.012257697060704231, Final Batch Loss: 0.0037302738055586815\n",
      "Epoch 318, Loss: 0.011561909690499306, Final Batch Loss: 0.005946738179773092\n",
      "Epoch 319, Loss: 0.005683331284672022, Final Batch Loss: 0.0033064265735447407\n",
      "Epoch 320, Loss: 0.026349864900112152, Final Batch Loss: 0.01141230296343565\n",
      "Epoch 321, Loss: 0.032698459923267365, Final Batch Loss: 0.012524958699941635\n",
      "Epoch 322, Loss: 0.03774096630513668, Final Batch Loss: 0.008292041718959808\n",
      "Epoch 323, Loss: 0.017779034562408924, Final Batch Loss: 0.01592891477048397\n",
      "Epoch 324, Loss: 0.006563953356817365, Final Batch Loss: 0.0031203788239508867\n",
      "Epoch 325, Loss: 0.02112188283354044, Final Batch Loss: 0.005953310057520866\n",
      "Epoch 326, Loss: 0.017525460571050644, Final Batch Loss: 0.009607060812413692\n",
      "Epoch 327, Loss: 0.013101865537464619, Final Batch Loss: 0.009368328377604485\n",
      "Epoch 328, Loss: 0.011831411626189947, Final Batch Loss: 0.004281236790120602\n",
      "Epoch 329, Loss: 0.017102621030062437, Final Batch Loss: 0.005398085806518793\n",
      "Epoch 330, Loss: 0.03698383737355471, Final Batch Loss: 0.008784529753029346\n",
      "Epoch 331, Loss: 0.011417636880651116, Final Batch Loss: 0.007616140879690647\n",
      "Epoch 332, Loss: 0.008162889629602432, Final Batch Loss: 0.0034907194785773754\n",
      "Epoch 333, Loss: 0.015291801653802395, Final Batch Loss: 0.003664277493953705\n",
      "Epoch 334, Loss: 0.02739020250737667, Final Batch Loss: 0.014517871662974358\n",
      "Epoch 335, Loss: 0.012098999926820397, Final Batch Loss: 0.0027606638614088297\n",
      "Epoch 336, Loss: 0.00989663996733725, Final Batch Loss: 0.002550462493672967\n",
      "Epoch 337, Loss: 0.013480594847351313, Final Batch Loss: 0.005602085497230291\n",
      "Epoch 338, Loss: 0.012485229526646435, Final Batch Loss: 0.001231439528055489\n",
      "Epoch 339, Loss: 0.01128791319206357, Final Batch Loss: 0.00529481889680028\n",
      "Epoch 340, Loss: 0.041634855209849775, Final Batch Loss: 0.00154799351003021\n",
      "Epoch 341, Loss: 0.010684219188988209, Final Batch Loss: 0.005320004187524319\n",
      "Epoch 342, Loss: 0.02682359702885151, Final Batch Loss: 0.005780002102255821\n",
      "Epoch 343, Loss: 0.013829322066158056, Final Batch Loss: 0.009320281445980072\n",
      "Epoch 344, Loss: 0.011640370823442936, Final Batch Loss: 0.006839466281235218\n",
      "Epoch 345, Loss: 0.044766782550141215, Final Batch Loss: 0.0415588840842247\n",
      "Epoch 346, Loss: 0.018799943616613746, Final Batch Loss: 0.003597187576815486\n",
      "Epoch 347, Loss: 0.00560928275808692, Final Batch Loss: 0.0017292799893766642\n",
      "Epoch 348, Loss: 0.007917285431176424, Final Batch Loss: 0.0058382353745400906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349, Loss: 0.012985749635845423, Final Batch Loss: 0.006381451617926359\n",
      "Epoch 350, Loss: 0.04080528952181339, Final Batch Loss: 0.021716365590691566\n",
      "Epoch 351, Loss: 0.015657689422369003, Final Batch Loss: 0.010902964510023594\n",
      "Epoch 352, Loss: 0.010503984987735748, Final Batch Loss: 0.0027156230062246323\n",
      "Epoch 353, Loss: 0.037382862996309996, Final Batch Loss: 0.03450470790266991\n",
      "Epoch 354, Loss: 0.011120799696072936, Final Batch Loss: 0.003251922084018588\n",
      "Epoch 355, Loss: 0.02943610679358244, Final Batch Loss: 0.010389433242380619\n",
      "Epoch 356, Loss: 0.02118649729527533, Final Batch Loss: 0.018961206078529358\n",
      "Epoch 357, Loss: 0.030597659293562174, Final Batch Loss: 0.005207369569689035\n",
      "Epoch 358, Loss: 0.006620797561481595, Final Batch Loss: 0.002935531549155712\n",
      "Epoch 359, Loss: 0.019152902998030186, Final Batch Loss: 0.010656827129423618\n",
      "Epoch 360, Loss: 0.014458563644438982, Final Batch Loss: 0.007677216082811356\n",
      "Epoch 361, Loss: 0.013527993578463793, Final Batch Loss: 0.00449582701548934\n",
      "Epoch 362, Loss: 0.016896833200007677, Final Batch Loss: 0.01169829536229372\n",
      "Epoch 363, Loss: 0.02567238942719996, Final Batch Loss: 0.022253453731536865\n",
      "Epoch 364, Loss: 0.012488707434386015, Final Batch Loss: 0.004486036952584982\n",
      "Epoch 365, Loss: 0.03026488795876503, Final Batch Loss: 0.020916232839226723\n",
      "Epoch 366, Loss: 0.020172271877527237, Final Batch Loss: 0.011961575597524643\n",
      "Epoch 367, Loss: 0.008048818912357092, Final Batch Loss: 0.002828342840075493\n",
      "Epoch 368, Loss: 0.01843101833947003, Final Batch Loss: 0.002277293475344777\n",
      "Epoch 369, Loss: 0.010603702161461115, Final Batch Loss: 0.007062048185616732\n",
      "Epoch 370, Loss: 0.015990871004760265, Final Batch Loss: 0.008394702337682247\n",
      "Epoch 371, Loss: 0.037106665782630444, Final Batch Loss: 0.008198118768632412\n",
      "Epoch 372, Loss: 0.006197160109877586, Final Batch Loss: 0.004021372180432081\n",
      "Epoch 373, Loss: 0.01535126008093357, Final Batch Loss: 0.010608784854412079\n",
      "Epoch 374, Loss: 0.012133962009102106, Final Batch Loss: 0.00606427900493145\n",
      "Epoch 375, Loss: 0.011252399650402367, Final Batch Loss: 0.0016057660104706883\n",
      "Epoch 376, Loss: 0.004484196309931576, Final Batch Loss: 0.0031181005761027336\n",
      "Epoch 377, Loss: 0.012935459613800049, Final Batch Loss: 0.0041431402787566185\n",
      "Epoch 378, Loss: 0.014163696905598044, Final Batch Loss: 0.003300774609670043\n",
      "Epoch 379, Loss: 0.0037673936458304524, Final Batch Loss: 0.0021606264635920525\n",
      "Epoch 380, Loss: 0.005415987689048052, Final Batch Loss: 0.0015548830851912498\n",
      "Epoch 381, Loss: 0.02227982971817255, Final Batch Loss: 0.014128672890365124\n",
      "Epoch 382, Loss: 0.003351554390974343, Final Batch Loss: 0.0012683357344940305\n",
      "Epoch 383, Loss: 0.0171799729578197, Final Batch Loss: 0.007137305568903685\n",
      "Epoch 384, Loss: 0.006002811132930219, Final Batch Loss: 0.0017312722047790885\n",
      "Epoch 385, Loss: 0.007072358392179012, Final Batch Loss: 0.003555527189746499\n",
      "Epoch 386, Loss: 0.009937759721651673, Final Batch Loss: 0.0022535917814821005\n",
      "Epoch 387, Loss: 0.0034251412143930793, Final Batch Loss: 0.0012978619197383523\n",
      "Epoch 388, Loss: 0.008283547242172062, Final Batch Loss: 0.006557222455739975\n",
      "Epoch 389, Loss: 0.009667117148637772, Final Batch Loss: 0.0019647423177957535\n",
      "Epoch 390, Loss: 0.013942169956862926, Final Batch Loss: 0.008630866184830666\n",
      "Epoch 391, Loss: 0.009297323878854513, Final Batch Loss: 0.005225576926022768\n",
      "Epoch 392, Loss: 0.029873847030103207, Final Batch Loss: 0.02126537263393402\n",
      "Epoch 393, Loss: 0.009922518278472126, Final Batch Loss: 0.0017611224902793765\n",
      "Epoch 394, Loss: 0.008423409890383482, Final Batch Loss: 0.00333571108058095\n",
      "Epoch 395, Loss: 0.008655772311612964, Final Batch Loss: 0.002319736173376441\n",
      "Epoch 396, Loss: 0.009843550156801939, Final Batch Loss: 0.006065321154892445\n",
      "Epoch 397, Loss: 0.0044365685898810625, Final Batch Loss: 0.0019350552465766668\n",
      "Epoch 398, Loss: 0.02740105614066124, Final Batch Loss: 0.023418888449668884\n",
      "Epoch 399, Loss: 0.010456627700477839, Final Batch Loss: 0.007267307955771685\n",
      "Epoch 400, Loss: 0.009285518317483366, Final Batch Loss: 0.0018071754602715373\n",
      "Epoch 401, Loss: 0.017669381108134985, Final Batch Loss: 0.012125326320528984\n",
      "Epoch 402, Loss: 0.007467494811862707, Final Batch Loss: 0.005497605539858341\n",
      "Epoch 403, Loss: 0.012250755447894335, Final Batch Loss: 0.01089463010430336\n",
      "Epoch 404, Loss: 0.0052252005552873015, Final Batch Loss: 0.0013502397341653705\n",
      "Epoch 405, Loss: 0.007469488424248993, Final Batch Loss: 0.005734062287956476\n",
      "Epoch 406, Loss: 0.005694914609193802, Final Batch Loss: 0.002075175754725933\n",
      "Epoch 407, Loss: 0.04373543558176607, Final Batch Loss: 0.0013255536323413253\n",
      "Epoch 408, Loss: 0.014474851079285145, Final Batch Loss: 0.006206798367202282\n",
      "Epoch 409, Loss: 0.004446613602340221, Final Batch Loss: 0.001872616820037365\n",
      "Epoch 410, Loss: 0.01227881945669651, Final Batch Loss: 0.00681073684245348\n",
      "Epoch 411, Loss: 0.003332087420858443, Final Batch Loss: 0.0014016894856467843\n",
      "Epoch 412, Loss: 0.004209556616842747, Final Batch Loss: 0.0017716661095619202\n",
      "Epoch 413, Loss: 0.023845332441851497, Final Batch Loss: 0.02220781147480011\n",
      "Epoch 414, Loss: 0.00802002428099513, Final Batch Loss: 0.004284827038645744\n",
      "Epoch 415, Loss: 0.01271233893930912, Final Batch Loss: 0.008073793724179268\n",
      "Epoch 416, Loss: 0.009345377795398235, Final Batch Loss: 0.00444223964586854\n",
      "Epoch 417, Loss: 0.008766877581365407, Final Batch Loss: 0.001783012063242495\n",
      "Epoch 418, Loss: 0.008261650800704956, Final Batch Loss: 0.005611423868685961\n",
      "Epoch 419, Loss: 0.032224976108409464, Final Batch Loss: 0.00106096884701401\n",
      "Epoch 420, Loss: 0.01738053187727928, Final Batch Loss: 0.009421170689165592\n",
      "Epoch 421, Loss: 0.003087478340603411, Final Batch Loss: 0.0018577121663838625\n",
      "Epoch 422, Loss: 0.004880496533587575, Final Batch Loss: 0.0032181809656322002\n",
      "Epoch 423, Loss: 0.012555010849609971, Final Batch Loss: 0.0010747036430984735\n",
      "Epoch 424, Loss: 0.011934338137507439, Final Batch Loss: 0.003680950030684471\n",
      "Epoch 425, Loss: 0.01836847048252821, Final Batch Loss: 0.0023089488968253136\n",
      "Epoch 426, Loss: 0.003520443453453481, Final Batch Loss: 0.0020699352025985718\n",
      "Epoch 427, Loss: 0.01824854756705463, Final Batch Loss: 0.0030901681166142225\n",
      "Epoch 428, Loss: 0.011337416246533394, Final Batch Loss: 0.0017929375171661377\n",
      "Epoch 429, Loss: 0.0073169320821762085, Final Batch Loss: 0.0025105495005846024\n",
      "Epoch 430, Loss: 0.02551621850579977, Final Batch Loss: 0.008787802420556545\n",
      "Epoch 431, Loss: 0.00802840874530375, Final Batch Loss: 0.0055700442753732204\n",
      "Epoch 432, Loss: 0.020632078871130943, Final Batch Loss: 0.01349880825728178\n",
      "Epoch 433, Loss: 0.010165848769247532, Final Batch Loss: 0.007942335680127144\n",
      "Epoch 434, Loss: 0.012911821715533733, Final Batch Loss: 0.004602361470460892\n",
      "Epoch 435, Loss: 0.008116262499243021, Final Batch Loss: 0.0038568852469325066\n",
      "Epoch 436, Loss: 0.009670844301581383, Final Batch Loss: 0.005015313159674406\n",
      "Epoch 437, Loss: 0.01812606817111373, Final Batch Loss: 0.0142797427251935\n",
      "Epoch 438, Loss: 0.014090321492403746, Final Batch Loss: 0.004518483299762011\n",
      "Epoch 439, Loss: 0.020426347851753235, Final Batch Loss: 0.006543443538248539\n",
      "Epoch 440, Loss: 0.01759555982425809, Final Batch Loss: 0.012085352092981339\n",
      "Epoch 441, Loss: 0.01688506151549518, Final Batch Loss: 0.003436810104176402\n",
      "Epoch 442, Loss: 0.023253144696354866, Final Batch Loss: 0.008184774778783321\n",
      "Epoch 443, Loss: 0.01551608880981803, Final Batch Loss: 0.010018100030720234\n",
      "Epoch 444, Loss: 0.021070449613034725, Final Batch Loss: 0.010007721371948719\n",
      "Epoch 445, Loss: 0.009348698193207383, Final Batch Loss: 0.0022188301663845778\n",
      "Epoch 446, Loss: 0.0073729881551116705, Final Batch Loss: 0.0017398365307599306\n",
      "Epoch 447, Loss: 0.01635363046079874, Final Batch Loss: 0.007999897934496403\n",
      "Epoch 448, Loss: 0.023647702182643116, Final Batch Loss: 0.021855108439922333\n",
      "Epoch 449, Loss: 0.02343149669468403, Final Batch Loss: 0.020515069365501404\n",
      "Epoch 450, Loss: 0.00944875436834991, Final Batch Loss: 0.0023541764821857214\n",
      "Epoch 451, Loss: 0.010148595552891493, Final Batch Loss: 0.002155069727450609\n",
      "Epoch 452, Loss: 0.01409765426069498, Final Batch Loss: 0.0051823267713189125\n",
      "Epoch 453, Loss: 0.006923036649823189, Final Batch Loss: 0.0036538485437631607\n",
      "Epoch 454, Loss: 0.005110459867864847, Final Batch Loss: 0.0027349372394382954\n",
      "Epoch 455, Loss: 0.009903543163090944, Final Batch Loss: 0.002911025658249855\n",
      "Epoch 456, Loss: 0.004788905149325728, Final Batch Loss: 0.0025349382776767015\n",
      "Epoch 457, Loss: 0.007735385268460959, Final Batch Loss: 0.0005299678887240589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458, Loss: 0.0077837028075009584, Final Batch Loss: 0.005743164569139481\n",
      "Epoch 459, Loss: 0.004457657691091299, Final Batch Loss: 0.0016002021729946136\n",
      "Epoch 460, Loss: 0.0043904457706958055, Final Batch Loss: 0.002242896007373929\n",
      "Epoch 461, Loss: 0.009311788249760866, Final Batch Loss: 0.0076811048202216625\n",
      "Epoch 462, Loss: 0.005885816062800586, Final Batch Loss: 0.0042815860360860825\n",
      "Epoch 463, Loss: 0.002643635729327798, Final Batch Loss: 0.0012280222726985812\n",
      "Epoch 464, Loss: 0.009842421626672149, Final Batch Loss: 0.0034218241926282644\n",
      "Epoch 465, Loss: 0.005024021957069635, Final Batch Loss: 0.0016158828511834145\n",
      "Epoch 466, Loss: 0.0053833131096325815, Final Batch Loss: 0.0006586475647054613\n",
      "Epoch 467, Loss: 0.009368312312290072, Final Batch Loss: 0.001932145794853568\n",
      "Epoch 468, Loss: 0.011585925240069628, Final Batch Loss: 0.0077440980821847916\n",
      "Epoch 469, Loss: 0.013662753626704216, Final Batch Loss: 0.0015303241088986397\n",
      "Epoch 470, Loss: 0.0052029965445399284, Final Batch Loss: 0.002579893684014678\n",
      "Epoch 471, Loss: 0.005650827777571976, Final Batch Loss: 0.00386050995439291\n",
      "Epoch 472, Loss: 0.00781688408460468, Final Batch Loss: 0.0006275534396991134\n",
      "Epoch 473, Loss: 0.005108093377202749, Final Batch Loss: 0.0018066810443997383\n",
      "Epoch 474, Loss: 0.007361088879406452, Final Batch Loss: 0.0064775375649333\n",
      "Epoch 475, Loss: 0.008257440757006407, Final Batch Loss: 0.006931002717465162\n",
      "Epoch 476, Loss: 0.016304584220051765, Final Batch Loss: 0.01436181552708149\n",
      "Epoch 477, Loss: 0.005892833636607975, Final Batch Loss: 0.005224708002060652\n",
      "Epoch 478, Loss: 0.004236586042679846, Final Batch Loss: 0.002796953311190009\n",
      "Epoch 479, Loss: 0.01568689988926053, Final Batch Loss: 0.0051170638762414455\n",
      "Epoch 480, Loss: 0.011262597283348441, Final Batch Loss: 0.0026739330496639013\n",
      "Epoch 481, Loss: 0.009808157570660114, Final Batch Loss: 0.004728213883936405\n",
      "Epoch 482, Loss: 0.003199674771167338, Final Batch Loss: 0.001526113599538803\n",
      "Epoch 483, Loss: 0.02671888656914234, Final Batch Loss: 0.016685543581843376\n",
      "Epoch 484, Loss: 0.0032531978795304894, Final Batch Loss: 0.001200946164317429\n",
      "Epoch 485, Loss: 0.002829787670634687, Final Batch Loss: 0.0010030281264334917\n",
      "Epoch 486, Loss: 0.01313107181340456, Final Batch Loss: 0.009007321670651436\n",
      "Epoch 487, Loss: 0.00968444428872317, Final Batch Loss: 0.009350109845399857\n",
      "Epoch 488, Loss: 0.009625006699934602, Final Batch Loss: 0.0070799109525978565\n",
      "Epoch 489, Loss: 0.008521165233105421, Final Batch Loss: 0.0061125922948122025\n",
      "Epoch 490, Loss: 0.005742047680541873, Final Batch Loss: 0.0024170251563191414\n",
      "Epoch 491, Loss: 0.003802335704676807, Final Batch Loss: 0.0013914756709709764\n",
      "Epoch 492, Loss: 0.0062231034971773624, Final Batch Loss: 0.0024815055076032877\n",
      "Epoch 493, Loss: 0.006588540971279144, Final Batch Loss: 0.004463219083845615\n",
      "Epoch 494, Loss: 0.007398284040391445, Final Batch Loss: 0.00619799317792058\n",
      "Epoch 495, Loss: 0.01054670033045113, Final Batch Loss: 0.0021234520245343447\n",
      "Epoch 496, Loss: 0.007856715936213732, Final Batch Loss: 0.005662671755999327\n",
      "Epoch 497, Loss: 0.009096257854253054, Final Batch Loss: 0.005324072670191526\n",
      "Epoch 498, Loss: 0.023845967836678028, Final Batch Loss: 0.019069191068410873\n",
      "Epoch 499, Loss: 0.020155927632004023, Final Batch Loss: 0.007784170564264059\n",
      "Epoch 500, Loss: 0.0027280637295916677, Final Batch Loss: 0.0015416055684909225\n",
      "Epoch 501, Loss: 0.007486513233743608, Final Batch Loss: 0.0007149492157623172\n",
      "Epoch 502, Loss: 0.0022911811829544604, Final Batch Loss: 0.0014242376200854778\n",
      "Epoch 503, Loss: 0.010134208016097546, Final Batch Loss: 0.0018487125635147095\n",
      "Epoch 504, Loss: 0.002619451843202114, Final Batch Loss: 0.0016072080470621586\n",
      "Epoch 505, Loss: 0.03007274493575096, Final Batch Loss: 0.026996005326509476\n",
      "Epoch 506, Loss: 0.013809737632982433, Final Batch Loss: 0.0006458525313064456\n",
      "Epoch 507, Loss: 0.0035737514263018966, Final Batch Loss: 0.00225775851868093\n",
      "Epoch 508, Loss: 0.0058382569113746285, Final Batch Loss: 0.001296927803196013\n",
      "Epoch 509, Loss: 0.0038422526558861136, Final Batch Loss: 0.0015608438989147544\n",
      "Epoch 510, Loss: 0.015897054108791053, Final Batch Loss: 0.014808517880737782\n",
      "Epoch 511, Loss: 0.003914489061571658, Final Batch Loss: 0.0022730405908077955\n",
      "Epoch 512, Loss: 0.017590562347322702, Final Batch Loss: 0.009995019994676113\n",
      "Epoch 513, Loss: 0.0118897789507173, Final Batch Loss: 0.0008354605524800718\n",
      "Epoch 514, Loss: 0.003798975027166307, Final Batch Loss: 0.0025281189009547234\n",
      "Epoch 515, Loss: 0.008919520885683596, Final Batch Loss: 0.0014542179415002465\n",
      "Epoch 516, Loss: 0.0032860093051567674, Final Batch Loss: 0.0021458619739860296\n",
      "Epoch 517, Loss: 0.020130076445639133, Final Batch Loss: 0.003904045559465885\n",
      "Epoch 518, Loss: 0.016750310780480504, Final Batch Loss: 0.015817536041140556\n",
      "Epoch 519, Loss: 0.011152873514220119, Final Batch Loss: 0.008645059540867805\n",
      "Epoch 520, Loss: 0.0045286440290510654, Final Batch Loss: 0.0011673129629343748\n",
      "Epoch 521, Loss: 0.005749815376475453, Final Batch Loss: 0.004228098317980766\n",
      "Epoch 522, Loss: 0.004758048919029534, Final Batch Loss: 0.001149458927102387\n",
      "Epoch 523, Loss: 0.0037873080000281334, Final Batch Loss: 0.0008393076714128256\n",
      "Epoch 524, Loss: 0.0044494683388620615, Final Batch Loss: 0.002150898100808263\n",
      "Epoch 525, Loss: 0.003085444332100451, Final Batch Loss: 0.0016264832811430097\n",
      "Epoch 526, Loss: 0.00525240576826036, Final Batch Loss: 0.0033124666661024094\n",
      "Epoch 527, Loss: 0.009745837189257145, Final Batch Loss: 0.005383206065744162\n",
      "Epoch 528, Loss: 0.01006972324103117, Final Batch Loss: 0.0017160391435027122\n",
      "Epoch 529, Loss: 0.008472208515740931, Final Batch Loss: 0.007353465538471937\n",
      "Epoch 530, Loss: 0.00982836470939219, Final Batch Loss: 0.0019326305482536554\n",
      "Epoch 531, Loss: 0.007248160894960165, Final Batch Loss: 0.0018258397467434406\n",
      "Epoch 532, Loss: 0.006041884073056281, Final Batch Loss: 0.0018564300844445825\n",
      "Epoch 533, Loss: 0.004826131975278258, Final Batch Loss: 0.0019913583528250456\n",
      "Epoch 534, Loss: 0.021052543073892593, Final Batch Loss: 0.006085703149437904\n",
      "Epoch 535, Loss: 0.0021426867460832, Final Batch Loss: 0.001231894362717867\n",
      "Epoch 536, Loss: 0.0031569640850648284, Final Batch Loss: 0.0009857219411060214\n",
      "Epoch 537, Loss: 0.014318559784442186, Final Batch Loss: 0.007581425830721855\n",
      "Epoch 538, Loss: 0.01545447768876329, Final Batch Loss: 0.0009156149462796748\n",
      "Epoch 539, Loss: 0.006249046215089038, Final Batch Loss: 0.005794574972242117\n",
      "Epoch 540, Loss: 0.009171395562589169, Final Batch Loss: 0.006419728044420481\n",
      "Epoch 541, Loss: 0.013889872236177325, Final Batch Loss: 0.013132095336914062\n",
      "Epoch 542, Loss: 0.03920875885523856, Final Batch Loss: 0.0033784436527639627\n",
      "Epoch 543, Loss: 0.0014036398206371814, Final Batch Loss: 0.0010385995265096426\n",
      "Epoch 544, Loss: 0.0019205056596547365, Final Batch Loss: 0.0003956181462854147\n",
      "Epoch 545, Loss: 0.027387703594285995, Final Batch Loss: 0.02675405703485012\n",
      "Epoch 546, Loss: 0.0016892232815735042, Final Batch Loss: 0.0011656531132757664\n",
      "Epoch 547, Loss: 0.0066910977475345135, Final Batch Loss: 0.004117095842957497\n",
      "Epoch 548, Loss: 0.002577489649411291, Final Batch Loss: 0.0021163728088140488\n",
      "Epoch 549, Loss: 0.009650710504502058, Final Batch Loss: 0.008568987250328064\n",
      "Epoch 550, Loss: 0.004509497783146799, Final Batch Loss: 0.0008107881294563413\n",
      "Epoch 551, Loss: 0.004184163641184568, Final Batch Loss: 0.0015720592346042395\n",
      "Epoch 552, Loss: 0.003868950647301972, Final Batch Loss: 0.003009277628734708\n",
      "Epoch 553, Loss: 0.004102371982298791, Final Batch Loss: 0.0023622403386980295\n",
      "Epoch 554, Loss: 0.0056583903497084975, Final Batch Loss: 0.005330292508006096\n",
      "Epoch 555, Loss: 0.002491561812348664, Final Batch Loss: 0.0012654857710003853\n",
      "Epoch 556, Loss: 0.010697959281969815, Final Batch Loss: 0.0006273456965573132\n",
      "Epoch 557, Loss: 0.008886115625500679, Final Batch Loss: 0.004676144104450941\n",
      "Epoch 558, Loss: 0.001233777729794383, Final Batch Loss: 0.0005102780996821821\n",
      "Epoch 559, Loss: 0.006126430467702448, Final Batch Loss: 0.00483757583424449\n",
      "Epoch 560, Loss: 0.009219333995133638, Final Batch Loss: 0.00464588450267911\n",
      "Epoch 561, Loss: 0.02020771033130586, Final Batch Loss: 0.0005911828484386206\n",
      "Epoch 562, Loss: 0.004341669264249504, Final Batch Loss: 0.0012034784303978086\n",
      "Epoch 563, Loss: 0.007646971149370074, Final Batch Loss: 0.0020924352575093508\n",
      "Epoch 564, Loss: 0.010790849104523659, Final Batch Loss: 0.0039953491650521755\n",
      "Epoch 565, Loss: 0.015122374752536416, Final Batch Loss: 0.01219203695654869\n",
      "Epoch 566, Loss: 0.011703196447342634, Final Batch Loss: 0.007396895904093981\n",
      "Epoch 567, Loss: 0.01699585933238268, Final Batch Loss: 0.008623233996331692\n",
      "Epoch 568, Loss: 0.008363213390111923, Final Batch Loss: 0.0047206091694533825\n",
      "Epoch 569, Loss: 0.028562461957335472, Final Batch Loss: 0.024922605603933334\n",
      "Epoch 570, Loss: 0.0104213897138834, Final Batch Loss: 0.008423121646046638\n",
      "Epoch 571, Loss: 0.004796302266186103, Final Batch Loss: 0.004403884056955576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 572, Loss: 0.006848372868262231, Final Batch Loss: 0.0015730465529486537\n",
      "Epoch 573, Loss: 0.0022953026345930994, Final Batch Loss: 0.001555868424475193\n",
      "Epoch 574, Loss: 0.003081409609876573, Final Batch Loss: 0.0013371759559959173\n",
      "Epoch 575, Loss: 0.0029868670972064137, Final Batch Loss: 0.002114356029778719\n",
      "Epoch 576, Loss: 0.002270281547680497, Final Batch Loss: 0.0006744705606251955\n",
      "Epoch 577, Loss: 0.0069694421254098415, Final Batch Loss: 0.004280482418835163\n",
      "Epoch 578, Loss: 0.00825074315071106, Final Batch Loss: 0.0038969432935118675\n",
      "Epoch 579, Loss: 0.0029154166113585234, Final Batch Loss: 0.001316896639764309\n",
      "Epoch 580, Loss: 0.0067834879737347364, Final Batch Loss: 0.004418742377310991\n",
      "Epoch 581, Loss: 0.008928802446462214, Final Batch Loss: 0.001468400121666491\n",
      "Epoch 582, Loss: 0.007623078767210245, Final Batch Loss: 0.003340453375130892\n",
      "Epoch 583, Loss: 0.011716005275957286, Final Batch Loss: 0.010334396734833717\n",
      "Epoch 584, Loss: 0.0209061021450907, Final Batch Loss: 0.017122235149145126\n",
      "Epoch 585, Loss: 0.0027075271354988217, Final Batch Loss: 0.0018078931607306004\n",
      "Epoch 586, Loss: 0.020312734181061387, Final Batch Loss: 0.01933116652071476\n",
      "Epoch 587, Loss: 0.001709784904960543, Final Batch Loss: 0.0006475474801845849\n",
      "Epoch 588, Loss: 0.009144060080870986, Final Batch Loss: 0.0007000367622822523\n",
      "Epoch 589, Loss: 0.004184885881841183, Final Batch Loss: 0.0036143383476883173\n",
      "Epoch 590, Loss: 0.009009875473566353, Final Batch Loss: 0.0008602953748777509\n",
      "Epoch 591, Loss: 0.006071604089811444, Final Batch Loss: 0.0038689528591930866\n",
      "Epoch 592, Loss: 0.028686617268249393, Final Batch Loss: 0.026256050914525986\n",
      "Epoch 593, Loss: 0.0029522619443014264, Final Batch Loss: 0.0019439196912571788\n",
      "Epoch 594, Loss: 0.003003689576871693, Final Batch Loss: 0.0015507797943428159\n",
      "Epoch 595, Loss: 0.019026526249945164, Final Batch Loss: 0.01612439937889576\n",
      "Epoch 596, Loss: 0.006559909204952419, Final Batch Loss: 0.004833274520933628\n",
      "Epoch 597, Loss: 0.009681984316557646, Final Batch Loss: 0.007958115078508854\n",
      "Epoch 598, Loss: 0.007366188336163759, Final Batch Loss: 0.002335767261683941\n",
      "Epoch 599, Loss: 0.0031004243064671755, Final Batch Loss: 0.0017342991195619106\n",
      "Epoch 600, Loss: 0.004825698910281062, Final Batch Loss: 0.0015343916602432728\n",
      "Epoch 601, Loss: 0.0026069897576235235, Final Batch Loss: 0.001819887780584395\n",
      "Epoch 602, Loss: 0.012869032099843025, Final Batch Loss: 0.008093582466244698\n",
      "Epoch 603, Loss: 0.007615594135131687, Final Batch Loss: 0.0008310097618959844\n",
      "Epoch 604, Loss: 0.016889306716620922, Final Batch Loss: 0.01070966012775898\n",
      "Epoch 605, Loss: 0.010227376129478216, Final Batch Loss: 0.008136519230902195\n",
      "Epoch 606, Loss: 0.009012624272145331, Final Batch Loss: 0.00790455099195242\n",
      "Epoch 607, Loss: 0.007306879560928792, Final Batch Loss: 0.0009624442900530994\n",
      "Epoch 608, Loss: 0.0053520334186032414, Final Batch Loss: 0.003790272632613778\n",
      "Epoch 609, Loss: 0.00914723810274154, Final Batch Loss: 0.007297748699784279\n",
      "Epoch 610, Loss: 0.007157625397667289, Final Batch Loss: 0.006602775771170855\n",
      "Epoch 611, Loss: 0.00481264409609139, Final Batch Loss: 0.0028018434531986713\n",
      "Epoch 612, Loss: 0.0017349660629406571, Final Batch Loss: 0.0011479895329102874\n",
      "Epoch 613, Loss: 0.013332748610991985, Final Batch Loss: 0.012408198788762093\n",
      "Epoch 614, Loss: 0.01951154274865985, Final Batch Loss: 0.018055109307169914\n",
      "Epoch 615, Loss: 0.015501267509534955, Final Batch Loss: 0.0017781539354473352\n",
      "Epoch 616, Loss: 0.002963827399071306, Final Batch Loss: 0.002109686378389597\n",
      "Epoch 617, Loss: 0.025951744057238102, Final Batch Loss: 0.015114198438823223\n",
      "Epoch 618, Loss: 0.015994977904483676, Final Batch Loss: 0.003249655244871974\n",
      "Epoch 619, Loss: 0.005387148237787187, Final Batch Loss: 0.0012257950147613883\n",
      "Epoch 620, Loss: 0.0076198275201022625, Final Batch Loss: 0.004565199371427298\n",
      "Epoch 621, Loss: 0.023885583388619125, Final Batch Loss: 0.022255077958106995\n",
      "Epoch 622, Loss: 0.013037676457315683, Final Batch Loss: 0.006512558087706566\n",
      "Epoch 623, Loss: 0.007514063734561205, Final Batch Loss: 0.004272270482033491\n",
      "Epoch 624, Loss: 0.0028495118021965027, Final Batch Loss: 0.001605886034667492\n",
      "Epoch 625, Loss: 0.0058166394010186195, Final Batch Loss: 0.0022586158011108637\n",
      "Epoch 626, Loss: 0.00788202544208616, Final Batch Loss: 0.006438726093620062\n",
      "Epoch 627, Loss: 0.006410879781469703, Final Batch Loss: 0.0034447999205440283\n",
      "Epoch 628, Loss: 0.0017485714924987406, Final Batch Loss: 0.0003558753232937306\n",
      "Epoch 629, Loss: 0.002224659314379096, Final Batch Loss: 0.000867971102707088\n",
      "Epoch 630, Loss: 0.02265340683516115, Final Batch Loss: 0.0014525934820994735\n",
      "Epoch 631, Loss: 0.007723481277935207, Final Batch Loss: 0.006235198117792606\n",
      "Epoch 632, Loss: 0.0017754971340764314, Final Batch Loss: 0.0003933441184926778\n",
      "Epoch 633, Loss: 0.007146263378672302, Final Batch Loss: 0.00571499252691865\n",
      "Epoch 634, Loss: 0.0025267311139032245, Final Batch Loss: 0.0019802819006145\n",
      "Epoch 635, Loss: 0.00284026563167572, Final Batch Loss: 0.0007230232004076242\n",
      "Epoch 636, Loss: 0.001868767401902005, Final Batch Loss: 0.0003763253043871373\n",
      "Epoch 637, Loss: 0.0011327315587550402, Final Batch Loss: 0.0008200340089388192\n",
      "Epoch 638, Loss: 0.005035664886236191, Final Batch Loss: 0.001718487124890089\n",
      "Epoch 639, Loss: 0.008225175668485463, Final Batch Loss: 0.0010159026132896543\n",
      "Epoch 640, Loss: 0.0025424406630918384, Final Batch Loss: 0.0016301072901114821\n",
      "Epoch 641, Loss: 0.00454995158361271, Final Batch Loss: 0.0009255917393602431\n",
      "Epoch 642, Loss: 0.004608270828612149, Final Batch Loss: 0.003183913417160511\n",
      "Epoch 643, Loss: 0.015711764339357615, Final Batch Loss: 0.0148922149091959\n",
      "Epoch 644, Loss: 0.0026974318316206336, Final Batch Loss: 0.0016112690791487694\n",
      "Epoch 645, Loss: 0.003624113742262125, Final Batch Loss: 0.0014123977161943913\n",
      "Epoch 646, Loss: 0.005904220859520137, Final Batch Loss: 0.0004610576434060931\n",
      "Epoch 647, Loss: 0.010634991573169827, Final Batch Loss: 0.002382490085437894\n",
      "Epoch 648, Loss: 0.004174608213361353, Final Batch Loss: 0.0005153174861334264\n",
      "Epoch 649, Loss: 0.004681770224124193, Final Batch Loss: 0.0019211545586585999\n",
      "Epoch 650, Loss: 0.003952769562602043, Final Batch Loss: 0.0019664946012198925\n",
      "Epoch 651, Loss: 0.0035620020935311913, Final Batch Loss: 0.002419778611510992\n",
      "Epoch 652, Loss: 0.005836400901898742, Final Batch Loss: 0.0026449477300047874\n",
      "Epoch 653, Loss: 0.003608869621530175, Final Batch Loss: 0.001202072948217392\n",
      "Epoch 654, Loss: 0.002995191141963005, Final Batch Loss: 0.0007228481117635965\n",
      "Epoch 655, Loss: 0.012843674863688648, Final Batch Loss: 0.0010446197120472789\n",
      "Epoch 656, Loss: 0.009013623581267893, Final Batch Loss: 0.00746538583189249\n",
      "Epoch 657, Loss: 0.0013263325090520084, Final Batch Loss: 0.0005773899029009044\n",
      "Epoch 658, Loss: 0.0030327292915899307, Final Batch Loss: 0.00038208210025914013\n",
      "Epoch 659, Loss: 0.001261054421775043, Final Batch Loss: 0.0007618092931807041\n",
      "Epoch 660, Loss: 0.0016959640197455883, Final Batch Loss: 0.0007537958445027471\n",
      "Epoch 661, Loss: 0.007748419651761651, Final Batch Loss: 0.005018028896301985\n",
      "Epoch 662, Loss: 0.0012377987732179463, Final Batch Loss: 0.0007358590955846012\n",
      "Epoch 663, Loss: 0.0021585848880931735, Final Batch Loss: 0.00043998577166348696\n",
      "Epoch 664, Loss: 0.001526610809378326, Final Batch Loss: 0.0009885842446237803\n",
      "Epoch 665, Loss: 0.005177032056963071, Final Batch Loss: 0.0004854876024182886\n",
      "Epoch 666, Loss: 0.015662006102502346, Final Batch Loss: 0.0018748687580227852\n",
      "Epoch 667, Loss: 0.0016938609187491238, Final Batch Loss: 0.0010901003843173385\n",
      "Epoch 668, Loss: 0.004473709384910762, Final Batch Loss: 0.0034989025443792343\n",
      "Epoch 669, Loss: 0.0015508415235672146, Final Batch Loss: 0.0012162165949121118\n",
      "Epoch 670, Loss: 0.000640328653389588, Final Batch Loss: 0.00041056357440538704\n",
      "Epoch 671, Loss: 0.003035392437595874, Final Batch Loss: 0.0008026778814382851\n",
      "Epoch 672, Loss: 0.0023441719822585583, Final Batch Loss: 0.0011962433345615864\n",
      "Epoch 673, Loss: 0.0008822248200885952, Final Batch Loss: 0.0003987686650361866\n",
      "Epoch 674, Loss: 0.0034305757144466043, Final Batch Loss: 0.00222784630022943\n",
      "Epoch 675, Loss: 0.008767934865318239, Final Batch Loss: 0.0002729039406403899\n",
      "Epoch 676, Loss: 0.0019527195836417377, Final Batch Loss: 0.0008008498116396368\n",
      "Epoch 677, Loss: 0.001707685412839055, Final Batch Loss: 0.001027443096973002\n",
      "Epoch 678, Loss: 0.007052744273096323, Final Batch Loss: 0.0005713845603168011\n",
      "Epoch 679, Loss: 0.014700668165460229, Final Batch Loss: 0.011873318813741207\n",
      "Epoch 680, Loss: 0.0007536697958130389, Final Batch Loss: 0.0004337514110375196\n",
      "Epoch 681, Loss: 0.0011224150948692113, Final Batch Loss: 0.0007289451896212995\n",
      "Epoch 682, Loss: 0.010918058454990387, Final Batch Loss: 0.010588180273771286\n",
      "Epoch 683, Loss: 0.002052337396889925, Final Batch Loss: 0.0007173885824158788\n",
      "Epoch 684, Loss: 0.005815383279696107, Final Batch Loss: 0.0009405172895640135\n",
      "Epoch 685, Loss: 0.006527023448143154, Final Batch Loss: 0.0005804603570140898\n",
      "Epoch 686, Loss: 0.00883177388459444, Final Batch Loss: 0.0013988488353788853\n",
      "Epoch 687, Loss: 0.02462029826710932, Final Batch Loss: 0.024159105494618416\n",
      "Epoch 688, Loss: 0.0013658039388246834, Final Batch Loss: 0.0008851583697833121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 689, Loss: 0.0045160900335758924, Final Batch Loss: 0.0016951949801295996\n",
      "Epoch 690, Loss: 0.0008430430898442864, Final Batch Loss: 0.0004587422590702772\n",
      "Epoch 691, Loss: 0.0030176020227372646, Final Batch Loss: 0.0012212356086820364\n",
      "Epoch 692, Loss: 0.003985794028267264, Final Batch Loss: 0.002802475355565548\n",
      "Epoch 693, Loss: 0.018522912170737982, Final Batch Loss: 0.012706964276731014\n",
      "Epoch 694, Loss: 0.007146252610255033, Final Batch Loss: 0.006642929743975401\n",
      "Epoch 695, Loss: 0.0028423747571650892, Final Batch Loss: 0.0024658660404384136\n",
      "Epoch 696, Loss: 0.012178456876426935, Final Batch Loss: 0.007226220332086086\n",
      "Epoch 697, Loss: 0.00269711937289685, Final Batch Loss: 0.0016273141372948885\n",
      "Epoch 698, Loss: 0.0023299906169995666, Final Batch Loss: 0.000915602664463222\n",
      "Epoch 699, Loss: 0.0050909839337691665, Final Batch Loss: 0.0016004190547391772\n",
      "Epoch 700, Loss: 0.00835775036830455, Final Batch Loss: 0.007266336586326361\n",
      "Epoch 701, Loss: 0.010707641369663179, Final Batch Loss: 0.009882242418825626\n",
      "Epoch 702, Loss: 0.0017939780373126268, Final Batch Loss: 0.0009845109889283776\n",
      "Epoch 703, Loss: 0.006416973250452429, Final Batch Loss: 0.0007498846971429884\n",
      "Epoch 704, Loss: 0.001780330901965499, Final Batch Loss: 0.0005232484545558691\n",
      "Epoch 705, Loss: 0.0005158733401913196, Final Batch Loss: 0.00024258455960080028\n",
      "Epoch 706, Loss: 0.0012938283616676927, Final Batch Loss: 0.0006742737605236471\n",
      "Epoch 707, Loss: 0.003858630283502862, Final Batch Loss: 0.00048163344035856426\n",
      "Epoch 708, Loss: 0.0034523545764386654, Final Batch Loss: 0.002246264601126313\n",
      "Epoch 709, Loss: 0.0043834816897287965, Final Batch Loss: 0.0005190178053453565\n",
      "Epoch 710, Loss: 0.008414258947595954, Final Batch Loss: 0.005008792970329523\n",
      "Epoch 711, Loss: 0.006255867192521691, Final Batch Loss: 0.005678161978721619\n",
      "Epoch 712, Loss: 0.014710457995533943, Final Batch Loss: 0.005986347794532776\n",
      "Epoch 713, Loss: 0.001024372351821512, Final Batch Loss: 0.0002573705860413611\n",
      "Epoch 714, Loss: 0.006703503197059035, Final Batch Loss: 0.00048716249875724316\n",
      "Epoch 715, Loss: 0.001670359750278294, Final Batch Loss: 0.0008002667455002666\n",
      "Epoch 716, Loss: 0.003315264650154859, Final Batch Loss: 0.0024095638655126095\n",
      "Epoch 717, Loss: 0.0007363116310443729, Final Batch Loss: 0.000457281043054536\n",
      "Epoch 718, Loss: 0.005634055472910404, Final Batch Loss: 0.005370482336729765\n",
      "Epoch 719, Loss: 0.0013582824321929365, Final Batch Loss: 0.0009021895821206272\n",
      "Epoch 720, Loss: 0.010553787578828633, Final Batch Loss: 0.0005333806620910764\n",
      "Epoch 721, Loss: 0.003461727872490883, Final Batch Loss: 0.0021066763438284397\n",
      "Epoch 722, Loss: 0.004998816177248955, Final Batch Loss: 0.0021856827661395073\n",
      "Epoch 723, Loss: 0.011308991233818233, Final Batch Loss: 0.0012176464078947902\n",
      "Epoch 724, Loss: 0.0016583274118602276, Final Batch Loss: 0.0005806457484140992\n",
      "Epoch 725, Loss: 0.006051523552741855, Final Batch Loss: 0.0006371433264575899\n",
      "Epoch 726, Loss: 0.0011157763947267085, Final Batch Loss: 0.0007158849039115012\n",
      "Epoch 727, Loss: 0.005829791596625, Final Batch Loss: 0.00037706788862124085\n",
      "Epoch 728, Loss: 0.004216135886963457, Final Batch Loss: 0.003753635101020336\n",
      "Epoch 729, Loss: 0.00945708667859435, Final Batch Loss: 0.0022535244934260845\n",
      "Epoch 730, Loss: 0.0035161738051101565, Final Batch Loss: 0.0007851816480979323\n",
      "Epoch 731, Loss: 0.005898188101127744, Final Batch Loss: 0.005286126863211393\n",
      "Epoch 732, Loss: 0.008932956901844591, Final Batch Loss: 0.000606775691267103\n",
      "Epoch 733, Loss: 0.006843640236184001, Final Batch Loss: 0.0020137338433414698\n",
      "Epoch 734, Loss: 0.0031262361735571176, Final Batch Loss: 0.0026989574544131756\n",
      "Epoch 735, Loss: 0.0063337794272229075, Final Batch Loss: 0.0011158202541992068\n",
      "Epoch 736, Loss: 0.0033828375162556767, Final Batch Loss: 0.002171874977648258\n",
      "Epoch 737, Loss: 0.012113159289583564, Final Batch Loss: 0.0036451711785048246\n",
      "Epoch 738, Loss: 0.0033381624380126595, Final Batch Loss: 0.0013729551574215293\n",
      "Epoch 739, Loss: 0.00196937465807423, Final Batch Loss: 0.0009576681186445057\n",
      "Epoch 740, Loss: 0.006643862230703235, Final Batch Loss: 0.0004249673802405596\n",
      "Epoch 741, Loss: 0.0016202836413867772, Final Batch Loss: 0.0012419046834111214\n",
      "Epoch 742, Loss: 0.004492926527746022, Final Batch Loss: 0.003511227900162339\n",
      "Epoch 743, Loss: 0.00336797209456563, Final Batch Loss: 0.0022055150475353003\n",
      "Epoch 744, Loss: 0.010394608485512435, Final Batch Loss: 0.0012171369744464755\n",
      "Epoch 745, Loss: 0.004013964207842946, Final Batch Loss: 0.0034345481544733047\n",
      "Epoch 746, Loss: 0.005575527669861913, Final Batch Loss: 0.0003337047528475523\n",
      "Epoch 747, Loss: 0.0011796914041042328, Final Batch Loss: 0.0007193346973508596\n",
      "Epoch 748, Loss: 0.0013401831383816898, Final Batch Loss: 0.0004067636327818036\n",
      "Epoch 749, Loss: 0.012137664656620473, Final Batch Loss: 0.0008225023630075157\n",
      "Epoch 750, Loss: 0.0010134782060049474, Final Batch Loss: 0.0007142430986277759\n",
      "Epoch 751, Loss: 0.0010431266273371875, Final Batch Loss: 0.0006929711671546102\n",
      "Epoch 752, Loss: 0.00159943918697536, Final Batch Loss: 0.0008233911939896643\n",
      "Epoch 753, Loss: 0.003676714259199798, Final Batch Loss: 0.0006582963978871703\n",
      "Epoch 754, Loss: 0.006788142374716699, Final Batch Loss: 0.005128401797264814\n",
      "Epoch 755, Loss: 0.005050382460467517, Final Batch Loss: 0.0039926208555698395\n",
      "Epoch 756, Loss: 0.00839875140809454, Final Batch Loss: 0.00047838842147029936\n",
      "Epoch 757, Loss: 0.002923336811363697, Final Batch Loss: 0.0012462253216654062\n",
      "Epoch 758, Loss: 0.006169888249132782, Final Batch Loss: 0.005785695277154446\n",
      "Epoch 759, Loss: 0.0019935686141252518, Final Batch Loss: 0.0010055300081148744\n",
      "Epoch 760, Loss: 0.0012782848643837497, Final Batch Loss: 0.00024372553161811084\n",
      "Epoch 761, Loss: 0.002115093113388866, Final Batch Loss: 0.0007666368619538844\n",
      "Epoch 762, Loss: 0.0035559110110625625, Final Batch Loss: 0.0010873075807467103\n",
      "Epoch 763, Loss: 0.00106148881604895, Final Batch Loss: 0.0007086608093231916\n",
      "Epoch 764, Loss: 0.015858587808907032, Final Batch Loss: 0.011283676140010357\n",
      "Epoch 765, Loss: 0.012018715031445026, Final Batch Loss: 0.005709809251129627\n",
      "Epoch 766, Loss: 0.0058252974558854476, Final Batch Loss: 0.005653221160173416\n",
      "Epoch 767, Loss: 0.008259048277977854, Final Batch Loss: 0.0005243239575065672\n",
      "Epoch 768, Loss: 0.004036796744912863, Final Batch Loss: 0.0009533227421343327\n",
      "Epoch 769, Loss: 0.005728229763917625, Final Batch Loss: 0.0009621273493394256\n",
      "Epoch 770, Loss: 0.0021356394863687456, Final Batch Loss: 0.0015253997407853603\n",
      "Epoch 771, Loss: 0.006038532475940883, Final Batch Loss: 0.004425676539540291\n",
      "Epoch 772, Loss: 0.001821013807784766, Final Batch Loss: 0.001275767688639462\n",
      "Epoch 773, Loss: 0.004975671006832272, Final Batch Loss: 0.0008245236822403967\n",
      "Epoch 774, Loss: 0.002683520142454654, Final Batch Loss: 0.0007453816360794008\n",
      "Epoch 775, Loss: 0.0015358079108409584, Final Batch Loss: 0.0008517195819877088\n",
      "Epoch 776, Loss: 0.0020666754571720958, Final Batch Loss: 0.0012535742716863751\n",
      "Epoch 777, Loss: 0.00853144028224051, Final Batch Loss: 0.001609539845958352\n",
      "Epoch 778, Loss: 0.004309829790145159, Final Batch Loss: 0.0010644025169312954\n",
      "Epoch 779, Loss: 0.0019597859354689717, Final Batch Loss: 0.0007872098358348012\n",
      "Epoch 780, Loss: 0.013218679465353489, Final Batch Loss: 0.006103083956986666\n",
      "Epoch 781, Loss: 0.004297495004720986, Final Batch Loss: 0.0012699911603704095\n",
      "Epoch 782, Loss: 0.004804155323654413, Final Batch Loss: 0.003047263016924262\n",
      "Epoch 783, Loss: 0.0015615414595231414, Final Batch Loss: 0.0010694051161408424\n",
      "Epoch 784, Loss: 0.0011811353033408523, Final Batch Loss: 0.0006171088898554444\n",
      "Epoch 785, Loss: 0.004570588149363175, Final Batch Loss: 0.00033150488161481917\n",
      "Epoch 786, Loss: 0.0013408021768555045, Final Batch Loss: 0.0011315555311739445\n",
      "Epoch 787, Loss: 0.006399264384526759, Final Batch Loss: 0.005525006912648678\n",
      "Epoch 788, Loss: 0.0007430641853716224, Final Batch Loss: 0.0004393278213683516\n",
      "Epoch 789, Loss: 0.0004980605299351737, Final Batch Loss: 0.00011967589671257883\n",
      "Epoch 790, Loss: 0.0012789517058990896, Final Batch Loss: 0.000996846822090447\n",
      "Epoch 791, Loss: 0.002933777985163033, Final Batch Loss: 0.0009761370019987226\n",
      "Epoch 792, Loss: 0.000876016216352582, Final Batch Loss: 0.0004178336530458182\n",
      "Epoch 793, Loss: 0.005506750210770406, Final Batch Loss: 0.005379397422075272\n",
      "Epoch 794, Loss: 0.01201523827330675, Final Batch Loss: 0.00016569426225032657\n",
      "Epoch 795, Loss: 0.0015119623276405036, Final Batch Loss: 0.0005541411228477955\n",
      "Epoch 796, Loss: 0.001253346068551764, Final Batch Loss: 0.0004556025087367743\n",
      "Epoch 797, Loss: 0.003998320025857538, Final Batch Loss: 0.0008732147398404777\n",
      "Epoch 798, Loss: 0.001097524189390242, Final Batch Loss: 0.00031111150747165084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799, Loss: 0.0043426877819001675, Final Batch Loss: 0.003784437198191881\n",
      "Epoch 800, Loss: 0.0014578485279344022, Final Batch Loss: 0.0007896090392023325\n",
      "Epoch 801, Loss: 0.0006314954080153257, Final Batch Loss: 0.000319319951813668\n",
      "Epoch 802, Loss: 0.006851698301034048, Final Batch Loss: 0.0003713700280059129\n",
      "Epoch 803, Loss: 0.003040161158423871, Final Batch Loss: 0.0008944558794610202\n",
      "Epoch 804, Loss: 0.0008203612233046442, Final Batch Loss: 0.0003193659067619592\n",
      "Epoch 805, Loss: 0.005369462771341205, Final Batch Loss: 0.004497686866670847\n",
      "Epoch 806, Loss: 0.0037282361299730837, Final Batch Loss: 0.002985756378620863\n",
      "Epoch 807, Loss: 0.0056343041360378265, Final Batch Loss: 0.0032362891361117363\n",
      "Epoch 808, Loss: 0.007438985630869865, Final Batch Loss: 0.0025380109436810017\n",
      "Epoch 809, Loss: 0.0009711267193779349, Final Batch Loss: 0.00024171348195523024\n",
      "Epoch 810, Loss: 0.0016506578540429473, Final Batch Loss: 0.0006494601257145405\n",
      "Epoch 811, Loss: 0.004830495628993958, Final Batch Loss: 0.004608694929629564\n",
      "Epoch 812, Loss: 0.002848650445230305, Final Batch Loss: 0.0019450841937214136\n",
      "Epoch 813, Loss: 0.005687380617018789, Final Batch Loss: 0.0005789398564957082\n",
      "Epoch 814, Loss: 0.004180899006314576, Final Batch Loss: 0.0014099263353273273\n",
      "Epoch 815, Loss: 0.010289861951605417, Final Batch Loss: 0.00020578702969942242\n",
      "Epoch 816, Loss: 0.0018297937931492925, Final Batch Loss: 0.001176673686131835\n",
      "Epoch 817, Loss: 0.006353859993396327, Final Batch Loss: 0.00029378451290540397\n",
      "Epoch 818, Loss: 0.01050591841340065, Final Batch Loss: 0.005460153799504042\n",
      "Epoch 819, Loss: 0.0010280657443217933, Final Batch Loss: 0.0006053395918570459\n",
      "Epoch 820, Loss: 0.002081202226690948, Final Batch Loss: 0.0008770858403295279\n",
      "Epoch 821, Loss: 0.005238508339971304, Final Batch Loss: 0.000994009431451559\n",
      "Epoch 822, Loss: 0.0069523530546575785, Final Batch Loss: 0.003348627360537648\n",
      "Epoch 823, Loss: 0.0062970222206786275, Final Batch Loss: 0.005724603310227394\n",
      "Epoch 824, Loss: 0.005215652112383395, Final Batch Loss: 0.00023291195975616574\n",
      "Epoch 825, Loss: 0.004882746463408694, Final Batch Loss: 0.0002646014036145061\n",
      "Epoch 826, Loss: 0.0010594361810944974, Final Batch Loss: 0.0007161347893998027\n",
      "Epoch 827, Loss: 0.0020775160228367895, Final Batch Loss: 0.0015949771041050553\n",
      "Epoch 828, Loss: 0.0027910041389986873, Final Batch Loss: 0.0022384393960237503\n",
      "Epoch 829, Loss: 0.006572644168045372, Final Batch Loss: 0.0057001556269824505\n",
      "Epoch 830, Loss: 0.0022268249886110425, Final Batch Loss: 0.0008297841995954514\n",
      "Epoch 831, Loss: 0.00981514761224389, Final Batch Loss: 0.005445599555969238\n",
      "Epoch 832, Loss: 0.005612769047729671, Final Batch Loss: 0.0014148064656183124\n",
      "Epoch 833, Loss: 0.0013345552142709494, Final Batch Loss: 0.0008379991631954908\n",
      "Epoch 834, Loss: 0.0008506333106197417, Final Batch Loss: 0.0004599528620019555\n",
      "Epoch 835, Loss: 0.005655825603753328, Final Batch Loss: 0.003704332048073411\n",
      "Epoch 836, Loss: 0.0035704820693354122, Final Batch Loss: 0.0034720401745289564\n",
      "Epoch 837, Loss: 0.0012741076643578708, Final Batch Loss: 0.00017069134628400207\n",
      "Epoch 838, Loss: 0.0007488687115255743, Final Batch Loss: 0.0003346493758726865\n",
      "Epoch 839, Loss: 0.0015992476837709546, Final Batch Loss: 0.0006522330222651362\n",
      "Epoch 840, Loss: 0.003240786259993911, Final Batch Loss: 0.0028086553793400526\n",
      "Epoch 841, Loss: 0.0013764781469944865, Final Batch Loss: 0.0003525376378092915\n",
      "Epoch 842, Loss: 0.00026657227135729045, Final Batch Loss: 0.00019120966317132115\n",
      "Epoch 843, Loss: 0.004227804747642949, Final Batch Loss: 0.00390965910628438\n",
      "Epoch 844, Loss: 0.0014026424614712596, Final Batch Loss: 0.0010395115241408348\n",
      "Epoch 845, Loss: 0.0008107810863293707, Final Batch Loss: 0.00011918722884729505\n",
      "Epoch 846, Loss: 0.0007146624266169965, Final Batch Loss: 0.0002291234559379518\n",
      "Epoch 847, Loss: 0.0006729813612764701, Final Batch Loss: 0.00020836594922002405\n",
      "Epoch 848, Loss: 0.0034131729626096785, Final Batch Loss: 0.0029965396970510483\n",
      "Epoch 849, Loss: 0.0056162611581385136, Final Batch Loss: 0.0024333170149475336\n",
      "Epoch 850, Loss: 0.0006434418901335448, Final Batch Loss: 0.0002582169836387038\n",
      "Epoch 851, Loss: 0.007955012610182166, Final Batch Loss: 0.0027304633986204863\n",
      "Epoch 852, Loss: 0.00022611716121900827, Final Batch Loss: 0.00016175064956769347\n",
      "Epoch 853, Loss: 0.001358780893497169, Final Batch Loss: 0.0007187809678725898\n",
      "Epoch 854, Loss: 0.0006579907931154594, Final Batch Loss: 0.00012052907550241798\n",
      "Epoch 855, Loss: 0.0010810175735969096, Final Batch Loss: 0.0004400738689582795\n",
      "Epoch 856, Loss: 0.00487928677466698, Final Batch Loss: 0.00034338541445322335\n",
      "Epoch 857, Loss: 0.01183560723438859, Final Batch Loss: 0.011522107757627964\n",
      "Epoch 858, Loss: 0.013524299720302224, Final Batch Loss: 0.009653167799115181\n",
      "Epoch 859, Loss: 0.01723932521417737, Final Batch Loss: 0.014557863585650921\n",
      "Epoch 860, Loss: 0.0017955619259737432, Final Batch Loss: 0.0007133972248993814\n",
      "Epoch 861, Loss: 0.00745682732667774, Final Batch Loss: 0.006342210806906223\n",
      "Epoch 862, Loss: 0.006459299591369927, Final Batch Loss: 0.006106036715209484\n",
      "Epoch 863, Loss: 0.004340821644291282, Final Batch Loss: 0.0015301364473998547\n",
      "Epoch 864, Loss: 0.008857757085934281, Final Batch Loss: 0.0027458711992949247\n",
      "Epoch 865, Loss: 0.004642800893634558, Final Batch Loss: 0.003555349772796035\n",
      "Epoch 866, Loss: 0.000739203009288758, Final Batch Loss: 0.00032846059184521437\n",
      "Epoch 867, Loss: 0.0035765100037679076, Final Batch Loss: 0.0012721797684207559\n",
      "Epoch 868, Loss: 0.0046179324854165316, Final Batch Loss: 0.000750810606405139\n",
      "Epoch 869, Loss: 0.004873757075984031, Final Batch Loss: 0.00037245062412694097\n",
      "Epoch 870, Loss: 0.0012519579904619604, Final Batch Loss: 0.000998843228444457\n",
      "Epoch 871, Loss: 0.0015246814000420272, Final Batch Loss: 0.0007308242493309081\n",
      "Epoch 872, Loss: 0.002786371624097228, Final Batch Loss: 0.0015577778685837984\n",
      "Epoch 873, Loss: 0.0025263723800890148, Final Batch Loss: 0.0022090726997703314\n",
      "Epoch 874, Loss: 0.0006543962226714939, Final Batch Loss: 0.0003316377114970237\n",
      "Epoch 875, Loss: 0.002699734875932336, Final Batch Loss: 0.0007220450788736343\n",
      "Epoch 876, Loss: 0.0061662049847655, Final Batch Loss: 0.0005500453407876194\n",
      "Epoch 877, Loss: 0.002961271209642291, Final Batch Loss: 0.0006700863596051931\n",
      "Epoch 878, Loss: 0.0020780988852493465, Final Batch Loss: 0.0005610365769825876\n",
      "Epoch 879, Loss: 0.004877982253674418, Final Batch Loss: 0.0006485325866378844\n",
      "Epoch 880, Loss: 0.0009947683283826336, Final Batch Loss: 0.0007717095431871712\n",
      "Epoch 881, Loss: 0.0018329103768337518, Final Batch Loss: 0.001505704945884645\n",
      "Epoch 882, Loss: 0.0009905116457957774, Final Batch Loss: 0.0007789469673298299\n",
      "Epoch 883, Loss: 0.0008056017977651209, Final Batch Loss: 0.00046863610623404384\n",
      "Epoch 884, Loss: 0.0063605401664972305, Final Batch Loss: 0.005766736343502998\n",
      "Epoch 885, Loss: 0.0076995231211185455, Final Batch Loss: 0.0005859122611582279\n",
      "Epoch 886, Loss: 0.0012269931903574616, Final Batch Loss: 0.00026464814436621964\n",
      "Epoch 887, Loss: 0.0063594316598027945, Final Batch Loss: 0.0015893655363470316\n",
      "Epoch 888, Loss: 0.0006853000377304852, Final Batch Loss: 0.00041425845120102167\n",
      "Epoch 889, Loss: 0.00032631879730615765, Final Batch Loss: 0.00020057614892721176\n",
      "Epoch 890, Loss: 0.0010626494840835221, Final Batch Loss: 0.0009973065461963415\n",
      "Epoch 891, Loss: 0.002716680755838752, Final Batch Loss: 0.0002724591176956892\n",
      "Epoch 892, Loss: 0.01320581417530775, Final Batch Loss: 0.0106997424736619\n",
      "Epoch 893, Loss: 0.0014442711835727096, Final Batch Loss: 0.0008503757417201996\n",
      "Epoch 894, Loss: 0.0044390053080860525, Final Batch Loss: 0.0003225972468499094\n",
      "Epoch 895, Loss: 0.0019497572793625295, Final Batch Loss: 0.0010515134781599045\n",
      "Epoch 896, Loss: 0.005987962184008211, Final Batch Loss: 0.005397051107138395\n",
      "Epoch 897, Loss: 0.007515472825616598, Final Batch Loss: 0.0023318971507251263\n",
      "Epoch 898, Loss: 0.0011958316899836063, Final Batch Loss: 0.0010442420607432723\n",
      "Epoch 899, Loss: 0.003976063861045986, Final Batch Loss: 0.0034840796142816544\n",
      "Epoch 900, Loss: 0.0028526112873805687, Final Batch Loss: 0.0001912976586027071\n",
      "Epoch 901, Loss: 0.004205356759484857, Final Batch Loss: 0.0005487952730618417\n",
      "Epoch 902, Loss: 0.0014963330759201199, Final Batch Loss: 0.0011320986086502671\n",
      "Epoch 903, Loss: 0.00046388484770432115, Final Batch Loss: 7.734537939541042e-05\n",
      "Epoch 904, Loss: 0.0037516950396820903, Final Batch Loss: 0.00047824636567384005\n",
      "Epoch 905, Loss: 0.001789580739568919, Final Batch Loss: 0.0007885671802796423\n",
      "Epoch 906, Loss: 0.0011743842769647017, Final Batch Loss: 0.00021706150437239558\n",
      "Epoch 907, Loss: 0.009498873463599011, Final Batch Loss: 0.00013021912309341133\n",
      "Epoch 908, Loss: 0.004717122879810631, Final Batch Loss: 0.0002620207378640771\n",
      "Epoch 909, Loss: 0.01106212753802538, Final Batch Loss: 0.0008136089891195297\n",
      "Epoch 910, Loss: 0.0007089249993441626, Final Batch Loss: 0.00017569020565133542\n",
      "Epoch 911, Loss: 0.002056223471299745, Final Batch Loss: 0.00010196062794420868\n",
      "Epoch 912, Loss: 0.0010756972478702664, Final Batch Loss: 0.0005640490562655032\n",
      "Epoch 913, Loss: 0.0008156283583957702, Final Batch Loss: 0.0003914489643648267\n",
      "Epoch 914, Loss: 0.00138675062044058, Final Batch Loss: 0.0002083702856907621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 915, Loss: 0.005560387682635337, Final Batch Loss: 0.0006158769247122109\n",
      "Epoch 916, Loss: 0.002900446765124798, Final Batch Loss: 0.0021496303379535675\n",
      "Epoch 917, Loss: 0.0004872107820119709, Final Batch Loss: 0.0001824595674406737\n",
      "Epoch 918, Loss: 0.0011855831544380635, Final Batch Loss: 0.0007691375794820487\n",
      "Epoch 919, Loss: 0.002125939296092838, Final Batch Loss: 0.0007620150572620332\n",
      "Epoch 920, Loss: 0.00017860060324892402, Final Batch Loss: 8.146929030772299e-05\n",
      "Epoch 921, Loss: 0.0028271495539229363, Final Batch Loss: 0.002513520186766982\n",
      "Epoch 922, Loss: 0.0003376546810613945, Final Batch Loss: 0.00016465467342641205\n",
      "Epoch 923, Loss: 0.0005981139547657222, Final Batch Loss: 0.0001700563298072666\n",
      "Epoch 924, Loss: 0.003521974547766149, Final Batch Loss: 0.003285710234194994\n",
      "Epoch 925, Loss: 0.0004001124616479501, Final Batch Loss: 0.00014480053505394608\n",
      "Epoch 926, Loss: 0.00017326885790680535, Final Batch Loss: 4.434786751517095e-05\n",
      "Epoch 927, Loss: 0.0006399822887033224, Final Batch Loss: 0.0003175686579197645\n",
      "Epoch 928, Loss: 0.0006581572233699262, Final Batch Loss: 0.0003387493488844484\n",
      "Epoch 929, Loss: 0.0006235981418285519, Final Batch Loss: 0.0001267228799406439\n",
      "Epoch 930, Loss: 0.0225314823910594, Final Batch Loss: 0.018211081624031067\n",
      "Epoch 931, Loss: 0.0007165890419855714, Final Batch Loss: 0.00034593732561916113\n",
      "Epoch 932, Loss: 0.0014562151045538485, Final Batch Loss: 0.00013547000708058476\n",
      "Epoch 933, Loss: 0.019921645522117615, Final Batch Loss: 0.008782751858234406\n",
      "Epoch 934, Loss: 0.0012266319536138326, Final Batch Loss: 0.0009268121211789548\n",
      "Epoch 935, Loss: 0.0008613530662842095, Final Batch Loss: 0.0003706052666530013\n",
      "Epoch 936, Loss: 0.001879178686067462, Final Batch Loss: 0.0014952673809602857\n",
      "Epoch 937, Loss: 0.002289186173584312, Final Batch Loss: 0.0013259155675768852\n",
      "Epoch 938, Loss: 0.0047620394034311175, Final Batch Loss: 0.0015821399865671992\n",
      "Epoch 939, Loss: 0.04895848978776485, Final Batch Loss: 0.0007490572752431035\n",
      "Epoch 940, Loss: 0.0030698445916641504, Final Batch Loss: 0.0026613345835357904\n",
      "Epoch 941, Loss: 0.0011119726696051657, Final Batch Loss: 0.0007926955004222691\n",
      "Epoch 942, Loss: 0.008138050849083811, Final Batch Loss: 0.007428524550050497\n",
      "Epoch 943, Loss: 0.0022148671268951148, Final Batch Loss: 0.0003819418780039996\n",
      "Epoch 944, Loss: 0.004087190143764019, Final Batch Loss: 0.0017641745507717133\n",
      "Epoch 945, Loss: 0.0011342108191456646, Final Batch Loss: 0.00048083506408147514\n",
      "Epoch 946, Loss: 0.0018951395177282393, Final Batch Loss: 0.0009965960634872317\n",
      "Epoch 947, Loss: 0.0025630051968619227, Final Batch Loss: 0.0009007080225273967\n",
      "Epoch 948, Loss: 0.0008749904518481344, Final Batch Loss: 0.0004922743537463248\n",
      "Epoch 949, Loss: 0.001822965161409229, Final Batch Loss: 0.0008020131499506533\n",
      "Epoch 950, Loss: 0.004744409641716629, Final Batch Loss: 0.004491483327001333\n",
      "Epoch 951, Loss: 0.0010678095859475434, Final Batch Loss: 0.0006506576319225132\n",
      "Epoch 952, Loss: 0.01810075549292378, Final Batch Loss: 0.017792347818613052\n",
      "Epoch 953, Loss: 0.001078253029845655, Final Batch Loss: 0.0005517503595910966\n",
      "Epoch 954, Loss: 0.0017817594925872982, Final Batch Loss: 0.00019817863358184695\n",
      "Epoch 955, Loss: 0.0021082466701045632, Final Batch Loss: 0.0008055820362642407\n",
      "Epoch 956, Loss: 0.001545845763757825, Final Batch Loss: 0.0004313811659812927\n",
      "Epoch 957, Loss: 0.001484969223383814, Final Batch Loss: 0.00017764681251719594\n",
      "Epoch 958, Loss: 0.0013141234230715781, Final Batch Loss: 0.0004278353007975966\n",
      "Epoch 959, Loss: 0.003945872449548915, Final Batch Loss: 0.003593078348785639\n",
      "Epoch 960, Loss: 0.0005486498703248799, Final Batch Loss: 0.0003550314577296376\n",
      "Epoch 961, Loss: 0.0006751433247700334, Final Batch Loss: 0.00014483259292319417\n",
      "Epoch 962, Loss: 0.000979802425717935, Final Batch Loss: 0.0006643810193054378\n",
      "Epoch 963, Loss: 0.0022797532146796584, Final Batch Loss: 0.0014035409549251199\n",
      "Epoch 964, Loss: 0.0034283527347724885, Final Batch Loss: 0.0033583147451281548\n",
      "Epoch 965, Loss: 0.004998154530767351, Final Batch Loss: 0.00023162743309512734\n",
      "Epoch 966, Loss: 0.0006507844809675589, Final Batch Loss: 0.00023586257884744555\n",
      "Epoch 967, Loss: 0.005325646197889, Final Batch Loss: 0.0007117144414223731\n",
      "Epoch 968, Loss: 0.0009740539244376123, Final Batch Loss: 0.0007746054325252771\n",
      "Epoch 969, Loss: 0.0018745712586678565, Final Batch Loss: 0.0014724947977811098\n",
      "Epoch 970, Loss: 0.004379363905172795, Final Batch Loss: 0.003955344203859568\n",
      "Epoch 971, Loss: 0.0009482328459853306, Final Batch Loss: 0.0007540839142166078\n",
      "Epoch 972, Loss: 0.0008389875292778015, Final Batch Loss: 0.000510353478603065\n",
      "Epoch 973, Loss: 0.002370419737417251, Final Batch Loss: 0.0008811676525510848\n",
      "Epoch 974, Loss: 0.007505063782446086, Final Batch Loss: 0.0004426984814926982\n",
      "Epoch 975, Loss: 0.00511384685523808, Final Batch Loss: 0.0033951285295188427\n",
      "Epoch 976, Loss: 0.0050265023892279714, Final Batch Loss: 0.00042877657688222826\n",
      "Epoch 977, Loss: 0.006071283540222794, Final Batch Loss: 0.005305463448166847\n",
      "Epoch 978, Loss: 0.005123464099597186, Final Batch Loss: 0.004769342951476574\n",
      "Epoch 979, Loss: 0.00954147195443511, Final Batch Loss: 0.0009285104461014271\n",
      "Epoch 980, Loss: 0.0009708531579235569, Final Batch Loss: 0.0008322740322910249\n",
      "Epoch 981, Loss: 0.00397193874232471, Final Batch Loss: 0.0011011823080480099\n",
      "Epoch 982, Loss: 0.0005676098371623084, Final Batch Loss: 0.00014926250150892884\n",
      "Epoch 983, Loss: 0.0022001695178914815, Final Batch Loss: 0.001888624276034534\n",
      "Epoch 984, Loss: 0.000498675333801657, Final Batch Loss: 0.00013539334759116173\n",
      "Epoch 985, Loss: 0.002987662563100457, Final Batch Loss: 0.00039446051232516766\n",
      "Epoch 986, Loss: 0.005074926069937646, Final Batch Loss: 0.0043917251750826836\n",
      "Epoch 987, Loss: 0.005926859215833247, Final Batch Loss: 0.0006161165656521916\n",
      "Epoch 988, Loss: 0.0007553264149464667, Final Batch Loss: 0.0004601947439368814\n",
      "Epoch 989, Loss: 0.0061015968094579875, Final Batch Loss: 0.0052231959998607635\n",
      "Epoch 990, Loss: 0.0011571990326046944, Final Batch Loss: 0.0005250617978163064\n",
      "Epoch 991, Loss: 0.0016970583092188463, Final Batch Loss: 0.00012523970508482307\n",
      "Epoch 992, Loss: 0.0037637242930941284, Final Batch Loss: 0.003262632992118597\n",
      "Epoch 993, Loss: 0.0011262486805208027, Final Batch Loss: 0.000601898122113198\n",
      "Epoch 994, Loss: 0.011476242449134588, Final Batch Loss: 9.961938485503197e-05\n",
      "Epoch 995, Loss: 0.0008151919755619019, Final Batch Loss: 0.0003951966646127403\n",
      "Epoch 996, Loss: 0.0027195100410608575, Final Batch Loss: 0.0001881710923044011\n",
      "Epoch 997, Loss: 0.0006540493632201105, Final Batch Loss: 0.00046738010132685304\n",
      "Epoch 998, Loss: 0.0047510971198789775, Final Batch Loss: 0.0038698946591466665\n",
      "Epoch 999, Loss: 0.0013943478697910905, Final Batch Loss: 0.0006040093721821904\n",
      "Epoch 1000, Loss: 0.012680967804044485, Final Batch Loss: 0.005933312699198723\n",
      "Epoch 1001, Loss: 0.0008011552854441106, Final Batch Loss: 0.0005475591751746833\n",
      "Epoch 1002, Loss: 0.002914457203587517, Final Batch Loss: 0.00038254851824603975\n",
      "Epoch 1003, Loss: 0.0007287234475370497, Final Batch Loss: 0.0004567457071971148\n",
      "Epoch 1004, Loss: 0.0007733896200079471, Final Batch Loss: 0.0005777913029305637\n",
      "Epoch 1005, Loss: 0.0047182287817122415, Final Batch Loss: 0.00013538131315726787\n",
      "Epoch 1006, Loss: 0.0004376292781671509, Final Batch Loss: 0.00022149634605739266\n",
      "Epoch 1007, Loss: 0.018584368168376386, Final Batch Loss: 0.0002294195583090186\n",
      "Epoch 1008, Loss: 0.0006054614132153802, Final Batch Loss: 6.43969324300997e-05\n",
      "Epoch 1009, Loss: 0.0010713773663155735, Final Batch Loss: 0.00013532215962186456\n",
      "Epoch 1010, Loss: 0.00047121025272645056, Final Batch Loss: 0.00013130251318216324\n",
      "Epoch 1011, Loss: 0.008700803969986737, Final Batch Loss: 0.006890630815178156\n",
      "Epoch 1012, Loss: 0.0003087419463554397, Final Batch Loss: 0.0001379465829813853\n",
      "Epoch 1013, Loss: 0.025177799601806328, Final Batch Loss: 0.024718578904867172\n",
      "Epoch 1014, Loss: 0.016407267656177282, Final Batch Loss: 0.0111014349386096\n",
      "Epoch 1015, Loss: 0.0012684399844147265, Final Batch Loss: 0.000958414631895721\n",
      "Epoch 1016, Loss: 0.0005869094020454213, Final Batch Loss: 0.00013161673268768936\n",
      "Epoch 1017, Loss: 0.0005089383339509368, Final Batch Loss: 0.00037541030906140804\n",
      "Epoch 1018, Loss: 0.0014596427790820599, Final Batch Loss: 0.0007572369067929685\n",
      "Epoch 1019, Loss: 0.011671766929794103, Final Batch Loss: 0.010721077211201191\n",
      "Epoch 1020, Loss: 0.00036150592495687306, Final Batch Loss: 0.0002021206746576354\n",
      "Epoch 1021, Loss: 0.0028311119531281292, Final Batch Loss: 0.00040550396079197526\n",
      "Epoch 1022, Loss: 0.007637993563548662, Final Batch Loss: 0.00015609957335982472\n",
      "Epoch 1023, Loss: 0.0009848125919234008, Final Batch Loss: 0.0002926123852375895\n",
      "Epoch 1024, Loss: 0.006587031210074201, Final Batch Loss: 0.0062441108748316765\n",
      "Epoch 1025, Loss: 0.006291734986007214, Final Batch Loss: 0.0023761913180351257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1026, Loss: 0.0003589732150430791, Final Batch Loss: 0.0001135791462729685\n",
      "Epoch 1027, Loss: 0.0032081514946185052, Final Batch Loss: 0.0002162586315535009\n",
      "Epoch 1028, Loss: 0.0012603289796970785, Final Batch Loss: 0.000918748090043664\n",
      "Epoch 1029, Loss: 0.0017922908009495586, Final Batch Loss: 0.0014176114927977324\n",
      "Epoch 1030, Loss: 0.0006302614056039602, Final Batch Loss: 0.0003038270224351436\n",
      "Epoch 1031, Loss: 0.011167834047228098, Final Batch Loss: 0.006725683808326721\n",
      "Epoch 1032, Loss: 0.006292280508205295, Final Batch Loss: 0.003512009745463729\n",
      "Epoch 1033, Loss: 0.0025666251312941313, Final Batch Loss: 0.002231645630672574\n",
      "Epoch 1034, Loss: 0.006797409849241376, Final Batch Loss: 0.002578707179054618\n",
      "Epoch 1035, Loss: 0.0007290182402357459, Final Batch Loss: 0.00019837258150801063\n",
      "Epoch 1036, Loss: 0.0008895463251974434, Final Batch Loss: 0.00015186003292910755\n",
      "Epoch 1037, Loss: 0.0018858352850656956, Final Batch Loss: 0.0016058753244578838\n",
      "Epoch 1038, Loss: 0.0009818538383115083, Final Batch Loss: 0.00028301161364652216\n",
      "Epoch 1039, Loss: 0.011259161605266854, Final Batch Loss: 0.00018975205603055656\n",
      "Epoch 1040, Loss: 0.005408593715401366, Final Batch Loss: 0.00027460584533400834\n",
      "Epoch 1041, Loss: 0.0010710029455367476, Final Batch Loss: 0.0008200098527595401\n",
      "Epoch 1042, Loss: 0.0042068913171533495, Final Batch Loss: 0.0039625875651836395\n",
      "Epoch 1043, Loss: 0.0007313962560147047, Final Batch Loss: 0.00020039547234773636\n",
      "Epoch 1044, Loss: 0.0004013623038190417, Final Batch Loss: 0.00031597763882018626\n",
      "Epoch 1045, Loss: 0.0011381058429833502, Final Batch Loss: 0.000247776071773842\n",
      "Epoch 1046, Loss: 0.007911026710644364, Final Batch Loss: 0.0076137688010931015\n",
      "Epoch 1047, Loss: 0.0038968423614278436, Final Batch Loss: 0.003684182418510318\n",
      "Epoch 1048, Loss: 0.0019185800629202276, Final Batch Loss: 0.001555192400701344\n",
      "Epoch 1049, Loss: 0.0008760464552324265, Final Batch Loss: 0.0004158120427746326\n",
      "Epoch 1050, Loss: 0.0029467788990586996, Final Batch Loss: 0.0010614474304020405\n",
      "Epoch 1051, Loss: 0.0010687457979656756, Final Batch Loss: 0.0006487739738076925\n",
      "Epoch 1052, Loss: 0.0005686285949195735, Final Batch Loss: 9.460100409341976e-05\n",
      "Epoch 1053, Loss: 0.000563936511753127, Final Batch Loss: 0.00038017917540855706\n",
      "Epoch 1054, Loss: 0.0005776536054327153, Final Batch Loss: 0.00012097637954866514\n",
      "Epoch 1055, Loss: 0.0009717479988466948, Final Batch Loss: 0.000760560913477093\n",
      "Epoch 1056, Loss: 0.0028778415944543667, Final Batch Loss: 0.0027584140188992023\n",
      "Epoch 1057, Loss: 0.0003914526241715066, Final Batch Loss: 0.00011762102803913876\n",
      "Epoch 1058, Loss: 0.0005413791222963482, Final Batch Loss: 0.000255758932325989\n",
      "Epoch 1059, Loss: 0.005477338039781898, Final Batch Loss: 0.0004186713485978544\n",
      "Epoch 1060, Loss: 0.0023489397135563195, Final Batch Loss: 0.00017644494073465466\n",
      "Epoch 1061, Loss: 0.0007996713975444436, Final Batch Loss: 0.0004197368980385363\n",
      "Epoch 1062, Loss: 0.010829831968294457, Final Batch Loss: 0.010383921675384045\n",
      "Epoch 1063, Loss: 0.00047740635636728257, Final Batch Loss: 0.00021712052694056183\n",
      "Epoch 1064, Loss: 0.005429865908809006, Final Batch Loss: 0.0050918408669531345\n",
      "Epoch 1065, Loss: 0.0005154885584488511, Final Batch Loss: 0.00014153518714010715\n",
      "Epoch 1066, Loss: 0.000672140609822236, Final Batch Loss: 0.00016357934509869665\n",
      "Epoch 1067, Loss: 0.00032855862082215026, Final Batch Loss: 9.814849909162149e-05\n",
      "Epoch 1068, Loss: 0.000706428472767584, Final Batch Loss: 0.00020136810780968517\n",
      "Epoch 1069, Loss: 0.012170129964943044, Final Batch Loss: 0.011990594677627087\n",
      "Epoch 1070, Loss: 0.0006133672432042658, Final Batch Loss: 0.0002698606112971902\n",
      "Epoch 1071, Loss: 0.00025089833070524037, Final Batch Loss: 9.218351624440402e-05\n",
      "Epoch 1072, Loss: 0.001072518789442256, Final Batch Loss: 0.00039972938247956336\n",
      "Epoch 1073, Loss: 0.0002645364438649267, Final Batch Loss: 4.7071705921553075e-05\n",
      "Epoch 1074, Loss: 0.00494757853448391, Final Batch Loss: 0.004421608056873083\n",
      "Epoch 1075, Loss: 0.0004227934405207634, Final Batch Loss: 0.00026176130631938577\n",
      "Epoch 1076, Loss: 0.0029428609705064446, Final Batch Loss: 0.0027665705420076847\n",
      "Epoch 1077, Loss: 0.0009398979891557246, Final Batch Loss: 0.0005769981071352959\n",
      "Epoch 1078, Loss: 0.0010059359483420849, Final Batch Loss: 0.0006903089815750718\n",
      "Epoch 1079, Loss: 0.017286752350628376, Final Batch Loss: 0.005068179219961166\n",
      "Epoch 1080, Loss: 0.004406221298268065, Final Batch Loss: 0.0040641347877681255\n",
      "Epoch 1081, Loss: 0.0004951755690854043, Final Batch Loss: 0.0004069842689204961\n",
      "Epoch 1082, Loss: 0.0024526052875444293, Final Batch Loss: 0.0021100291050970554\n",
      "Epoch 1083, Loss: 0.0004054539749631658, Final Batch Loss: 0.0002599393483251333\n",
      "Epoch 1084, Loss: 0.024648879189044237, Final Batch Loss: 0.0238902997225523\n",
      "Epoch 1085, Loss: 0.008861239635734819, Final Batch Loss: 0.000148262464790605\n",
      "Epoch 1086, Loss: 0.004596728816977702, Final Batch Loss: 0.00011767445539589971\n",
      "Epoch 1087, Loss: 0.0011749548721127212, Final Batch Loss: 0.0005281260819174349\n",
      "Epoch 1088, Loss: 0.01561802823562175, Final Batch Loss: 0.0018943987088277936\n",
      "Epoch 1089, Loss: 0.007380195893347263, Final Batch Loss: 0.00041730795055627823\n",
      "Epoch 1090, Loss: 0.0007628226303495467, Final Batch Loss: 0.00040910637471824884\n",
      "Epoch 1091, Loss: 0.006537673791171983, Final Batch Loss: 0.006155163981020451\n",
      "Epoch 1092, Loss: 0.0005761400097981095, Final Batch Loss: 0.00017325804219581187\n",
      "Epoch 1093, Loss: 0.003243625382310711, Final Batch Loss: 0.003081301925703883\n",
      "Epoch 1094, Loss: 0.0016641047550365329, Final Batch Loss: 0.0007872242713347077\n",
      "Epoch 1095, Loss: 0.0005283123828121461, Final Batch Loss: 0.0004481218638829887\n",
      "Epoch 1096, Loss: 0.000981851073447615, Final Batch Loss: 0.00058002769947052\n",
      "Epoch 1097, Loss: 0.0011086744780186564, Final Batch Loss: 0.000844779540784657\n",
      "Epoch 1098, Loss: 0.0057425610575592145, Final Batch Loss: 0.00019648995657917112\n",
      "Epoch 1099, Loss: 0.0019860687607433647, Final Batch Loss: 0.0004578852967824787\n",
      "Epoch 1100, Loss: 0.0005327470862539485, Final Batch Loss: 0.00036792014725506306\n",
      "Epoch 1101, Loss: 0.00020117561871302314, Final Batch Loss: 0.00015829948824830353\n",
      "Epoch 1102, Loss: 0.0043209686991758645, Final Batch Loss: 0.0003724413109011948\n",
      "Epoch 1103, Loss: 0.003513396717607975, Final Batch Loss: 0.002848483854904771\n",
      "Epoch 1104, Loss: 0.0005543288862099871, Final Batch Loss: 0.00023300819157157093\n",
      "Epoch 1105, Loss: 0.00043254176853224635, Final Batch Loss: 0.00013915039016865194\n",
      "Epoch 1106, Loss: 0.00045345165563048795, Final Batch Loss: 0.00041212973883375525\n",
      "Epoch 1107, Loss: 0.0002435465830785688, Final Batch Loss: 3.10870491375681e-05\n",
      "Epoch 1108, Loss: 0.006641558458795771, Final Batch Loss: 0.0001928723359014839\n",
      "Epoch 1109, Loss: 0.0009617233299650252, Final Batch Loss: 0.0005772587610408664\n",
      "Epoch 1110, Loss: 0.007505552319344133, Final Batch Loss: 0.0001724990434013307\n",
      "Epoch 1111, Loss: 0.0007745841285213828, Final Batch Loss: 0.0005907102604396641\n",
      "Epoch 1112, Loss: 0.00552569271530956, Final Batch Loss: 0.0013911043060943484\n",
      "Epoch 1113, Loss: 0.0005054415669292212, Final Batch Loss: 0.00027317318017594516\n",
      "Epoch 1114, Loss: 0.003606219368521124, Final Batch Loss: 0.0029209156055003405\n",
      "Epoch 1115, Loss: 0.0003533313029038254, Final Batch Loss: 0.00030000947299413383\n",
      "Epoch 1116, Loss: 0.0006018165149725974, Final Batch Loss: 0.00039930109051056206\n",
      "Epoch 1117, Loss: 0.001013092347420752, Final Batch Loss: 0.0008110324270091951\n",
      "Epoch 1118, Loss: 0.005463995679747313, Final Batch Loss: 0.0008958216640166938\n",
      "Epoch 1119, Loss: 0.0020601718715624884, Final Batch Loss: 0.00014583028678316623\n",
      "Epoch 1120, Loss: 0.0006049620369594777, Final Batch Loss: 2.2673668354400434e-05\n",
      "Epoch 1121, Loss: 0.0005002023681299761, Final Batch Loss: 0.00046283280244097114\n",
      "Epoch 1122, Loss: 0.00045827125723008066, Final Batch Loss: 0.00035032795858569443\n",
      "Epoch 1123, Loss: 0.0013842750922776759, Final Batch Loss: 0.0005824045510962605\n",
      "Epoch 1124, Loss: 0.0015663246304029599, Final Batch Loss: 7.17102229828015e-05\n",
      "Epoch 1125, Loss: 0.011117636342532933, Final Batch Loss: 0.010128785856068134\n",
      "Epoch 1126, Loss: 0.000585752037295606, Final Batch Loss: 0.0005258306628093123\n",
      "Epoch 1127, Loss: 0.0006728536973241717, Final Batch Loss: 0.00013879084144718945\n",
      "Epoch 1128, Loss: 0.0002768171107163653, Final Batch Loss: 0.00015910834190435708\n",
      "Epoch 1129, Loss: 0.0005093580693937838, Final Batch Loss: 0.0003631954314187169\n",
      "Epoch 1130, Loss: 0.0012829166371375322, Final Batch Loss: 0.0007585373823530972\n",
      "Epoch 1131, Loss: 0.00044695939868688583, Final Batch Loss: 0.00013166049029678106\n",
      "Epoch 1132, Loss: 0.021044100867584348, Final Batch Loss: 0.0002462242264300585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1133, Loss: 0.04064310641842894, Final Batch Loss: 0.0001749165530782193\n",
      "Epoch 1134, Loss: 0.008874892257153988, Final Batch Loss: 0.0048520914278924465\n",
      "Epoch 1135, Loss: 0.002794687112327665, Final Batch Loss: 0.001982655143365264\n",
      "Epoch 1136, Loss: 0.0038486815756186843, Final Batch Loss: 0.0006355632795020938\n",
      "Epoch 1137, Loss: 0.012963281929842196, Final Batch Loss: 0.012725580483675003\n",
      "Epoch 1138, Loss: 0.01286212750710547, Final Batch Loss: 0.0031483203638345003\n",
      "Epoch 1139, Loss: 0.006223284872248769, Final Batch Loss: 0.0012871830258518457\n",
      "Epoch 1140, Loss: 0.0003904617769876495, Final Batch Loss: 0.00022853445261716843\n",
      "Epoch 1141, Loss: 0.00519381754565984, Final Batch Loss: 0.0007048394763842225\n",
      "Epoch 1142, Loss: 0.0021527516655623913, Final Batch Loss: 0.0012547633377835155\n",
      "Epoch 1143, Loss: 0.0003946493088733405, Final Batch Loss: 0.00021236379689071327\n",
      "Epoch 1144, Loss: 0.0011760669585783035, Final Batch Loss: 0.0008348411647602916\n",
      "Epoch 1145, Loss: 0.0006532739571412094, Final Batch Loss: 0.0005590916844084859\n",
      "Epoch 1146, Loss: 0.006496816349681467, Final Batch Loss: 0.00035711744567379355\n",
      "Epoch 1147, Loss: 0.026663649128749967, Final Batch Loss: 0.024347031489014626\n",
      "Epoch 1148, Loss: 0.001010025618597865, Final Batch Loss: 0.00043964164797216654\n",
      "Epoch 1149, Loss: 0.0013702437281608582, Final Batch Loss: 0.00032080954406410456\n",
      "Epoch 1150, Loss: 0.0011279585887677968, Final Batch Loss: 0.0006181739154271781\n",
      "Epoch 1151, Loss: 0.004784985911101103, Final Batch Loss: 0.003313724184408784\n",
      "Epoch 1152, Loss: 0.004457009024918079, Final Batch Loss: 0.0003968924283981323\n",
      "Epoch 1153, Loss: 0.0005072606290923432, Final Batch Loss: 0.00015912258822936565\n",
      "Epoch 1154, Loss: 0.004588444397086278, Final Batch Loss: 0.00028239018865861\n",
      "Epoch 1155, Loss: 0.004917422600556165, Final Batch Loss: 0.004262394271790981\n",
      "Epoch 1156, Loss: 0.002097957913065329, Final Batch Loss: 0.0017486887518316507\n",
      "Epoch 1157, Loss: 0.0015302522224374115, Final Batch Loss: 0.0010209603933617473\n",
      "Epoch 1158, Loss: 0.00506628310540691, Final Batch Loss: 0.0006862944574095309\n",
      "Epoch 1159, Loss: 0.002140179625712335, Final Batch Loss: 0.0009323970880359411\n",
      "Epoch 1160, Loss: 0.0009939576557371765, Final Batch Loss: 0.0007735039689578116\n",
      "Epoch 1161, Loss: 0.001045009383233264, Final Batch Loss: 0.0004349933296907693\n",
      "Epoch 1162, Loss: 0.003488436690531671, Final Batch Loss: 0.0006552228005602956\n",
      "Epoch 1163, Loss: 0.0007573958719149232, Final Batch Loss: 0.00020763574866577983\n",
      "Epoch 1164, Loss: 0.0004045345413032919, Final Batch Loss: 0.00019705129670910537\n",
      "Epoch 1165, Loss: 0.004769113889778964, Final Batch Loss: 0.004581055138260126\n",
      "Epoch 1166, Loss: 0.00024108927391353063, Final Batch Loss: 4.502197771216743e-05\n",
      "Epoch 1167, Loss: 0.0006065145425964147, Final Batch Loss: 0.0003485055058263242\n",
      "Epoch 1168, Loss: 0.00037897040601819754, Final Batch Loss: 0.00016708999464754015\n",
      "Epoch 1169, Loss: 0.006975306081585586, Final Batch Loss: 0.0006102569168433547\n",
      "Epoch 1170, Loss: 0.00013340737496037036, Final Batch Loss: 7.261252903845161e-05\n",
      "Epoch 1171, Loss: 0.0001509724861534778, Final Batch Loss: 9.168620454147458e-05\n",
      "Epoch 1172, Loss: 0.00031762782600708306, Final Batch Loss: 0.0001386844669468701\n",
      "Epoch 1173, Loss: 0.00033608998637646437, Final Batch Loss: 0.0002467823796905577\n",
      "Epoch 1174, Loss: 0.0004973083414370194, Final Batch Loss: 0.00023919752857182175\n",
      "Epoch 1175, Loss: 0.0013963850360596552, Final Batch Loss: 0.0012416302924975753\n",
      "Epoch 1176, Loss: 0.005271900678053498, Final Batch Loss: 0.0041588242165744305\n",
      "Epoch 1177, Loss: 0.000846326642204076, Final Batch Loss: 0.0005722735659219325\n",
      "Epoch 1178, Loss: 0.0027888514450751245, Final Batch Loss: 0.0003490927047096193\n",
      "Epoch 1179, Loss: 0.001379435183480382, Final Batch Loss: 0.0007905264501459897\n",
      "Epoch 1180, Loss: 0.0038395625015255064, Final Batch Loss: 0.0002218625450041145\n",
      "Epoch 1181, Loss: 0.001308844643062912, Final Batch Loss: 0.0011788352858275175\n",
      "Epoch 1182, Loss: 0.0009984153148252517, Final Batch Loss: 0.0003522279148455709\n",
      "Epoch 1183, Loss: 0.0011143765150336549, Final Batch Loss: 9.352648339699954e-05\n",
      "Epoch 1184, Loss: 0.0009702633833512664, Final Batch Loss: 0.00027527293423190713\n",
      "Epoch 1185, Loss: 0.00033777762291720137, Final Batch Loss: 5.4726631788071245e-05\n",
      "Epoch 1186, Loss: 0.00274799537146464, Final Batch Loss: 0.00259030400775373\n",
      "Epoch 1187, Loss: 0.0010006650409195572, Final Batch Loss: 0.0008369360584765673\n",
      "Epoch 1188, Loss: 0.0035378057655179873, Final Batch Loss: 0.00011747168900910765\n",
      "Epoch 1189, Loss: 0.0007589585438836366, Final Batch Loss: 0.0004987525171600282\n",
      "Epoch 1190, Loss: 0.0025500796909909695, Final Batch Loss: 0.00039037151145748794\n",
      "Epoch 1191, Loss: 0.0021410292538348585, Final Batch Loss: 0.0017820830689743161\n",
      "Epoch 1192, Loss: 0.0009206377435475588, Final Batch Loss: 0.00040903128683567047\n",
      "Epoch 1193, Loss: 0.0008789704588707536, Final Batch Loss: 0.0004503409727476537\n",
      "Epoch 1194, Loss: 0.003765212371945381, Final Batch Loss: 0.0008383523672819138\n",
      "Epoch 1195, Loss: 0.0003178487968398258, Final Batch Loss: 0.00016054129810072482\n",
      "Epoch 1196, Loss: 0.0007773973047733307, Final Batch Loss: 0.0006187353865243495\n",
      "Epoch 1197, Loss: 0.0025067346286959946, Final Batch Loss: 0.0001919498317874968\n",
      "Epoch 1198, Loss: 0.0008463044359814376, Final Batch Loss: 0.00024926834157668054\n",
      "Epoch 1199, Loss: 0.0035219913988839835, Final Batch Loss: 0.00038242616574279964\n",
      "Epoch 1200, Loss: 0.00020566592866089195, Final Batch Loss: 0.00012208952102810144\n",
      "Epoch 1201, Loss: 0.0003101637375948485, Final Batch Loss: 0.00028472047415561974\n",
      "Epoch 1202, Loss: 0.0031527186511084437, Final Batch Loss: 0.0005196566926315427\n",
      "Epoch 1203, Loss: 0.000505555890413234, Final Batch Loss: 0.00045068786130286753\n",
      "Epoch 1204, Loss: 0.00788884935900569, Final Batch Loss: 0.004515615291893482\n",
      "Epoch 1205, Loss: 0.00129727617604658, Final Batch Loss: 0.0010044088121503592\n",
      "Epoch 1206, Loss: 0.0003191254781995667, Final Batch Loss: 2.3614060410181992e-05\n",
      "Epoch 1207, Loss: 0.0005550165369641036, Final Batch Loss: 0.0003151223063468933\n",
      "Epoch 1208, Loss: 0.0006388536203303374, Final Batch Loss: 0.0005209957016631961\n",
      "Epoch 1209, Loss: 0.002799527777824551, Final Batch Loss: 0.0002310255658812821\n",
      "Epoch 1210, Loss: 0.00021951326925773174, Final Batch Loss: 0.00013738052803091705\n",
      "Epoch 1211, Loss: 0.002912778058089316, Final Batch Loss: 5.1778857596218586e-05\n",
      "Epoch 1212, Loss: 0.0006334744539344683, Final Batch Loss: 0.00019777686975430697\n",
      "Epoch 1213, Loss: 0.003108462638920173, Final Batch Loss: 0.0003772607014980167\n",
      "Epoch 1214, Loss: 0.008885982795618474, Final Batch Loss: 0.007417305838316679\n",
      "Epoch 1215, Loss: 0.00502087821951136, Final Batch Loss: 0.004658255260437727\n",
      "Epoch 1216, Loss: 0.01178942873957567, Final Batch Loss: 0.00025366779300384223\n",
      "Epoch 1217, Loss: 0.002189205086324364, Final Batch Loss: 9.582244092598557e-05\n",
      "Epoch 1218, Loss: 0.0017335131124127656, Final Batch Loss: 0.00038764733471907675\n",
      "Epoch 1219, Loss: 0.007170183816924691, Final Batch Loss: 0.0030422776471823454\n",
      "Epoch 1220, Loss: 0.003196509809640702, Final Batch Loss: 0.0031287188176065683\n",
      "Epoch 1221, Loss: 0.001658899971516803, Final Batch Loss: 0.00040515654836781323\n",
      "Epoch 1222, Loss: 0.0005256068689050153, Final Batch Loss: 0.00014521872799377888\n",
      "Epoch 1223, Loss: 0.0006580792251043022, Final Batch Loss: 0.00022537342738360167\n",
      "Epoch 1224, Loss: 0.0007143621587601956, Final Batch Loss: 0.000660568242892623\n",
      "Epoch 1225, Loss: 0.002874687059374992, Final Batch Loss: 0.0028099885676056147\n",
      "Epoch 1226, Loss: 0.004348855960415676, Final Batch Loss: 0.0004466101818252355\n",
      "Epoch 1227, Loss: 0.011720057285856456, Final Batch Loss: 0.01109378132969141\n",
      "Epoch 1228, Loss: 0.0012238246272318065, Final Batch Loss: 0.000520121946465224\n",
      "Epoch 1229, Loss: 0.0015825737500563264, Final Batch Loss: 0.0008041025139391422\n",
      "Epoch 1230, Loss: 0.006402687082299963, Final Batch Loss: 0.006260900758206844\n",
      "Epoch 1231, Loss: 0.0008371163858100772, Final Batch Loss: 0.000425550970248878\n",
      "Epoch 1232, Loss: 0.00992185901850462, Final Batch Loss: 0.004161270335316658\n",
      "Epoch 1233, Loss: 0.0005787703557871282, Final Batch Loss: 0.00010939946514554322\n",
      "Epoch 1234, Loss: 0.003552251491782954, Final Batch Loss: 5.976110332994722e-05\n",
      "Epoch 1235, Loss: 0.000731019681552425, Final Batch Loss: 0.00023622336448170245\n",
      "Epoch 1236, Loss: 0.002918071928434074, Final Batch Loss: 0.00031679391395300627\n",
      "Epoch 1237, Loss: 0.0026870524416153785, Final Batch Loss: 5.550434798351489e-05\n",
      "Epoch 1238, Loss: 0.00019387765496503562, Final Batch Loss: 7.06724968040362e-05\n",
      "Epoch 1239, Loss: 0.00031598475470673293, Final Batch Loss: 0.00019131573208142072\n",
      "Epoch 1240, Loss: 0.004410908615682274, Final Batch Loss: 0.00017328752437606454\n",
      "Epoch 1241, Loss: 0.0016660080873407423, Final Batch Loss: 0.0006253853789530694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1242, Loss: 0.0023541945847682655, Final Batch Loss: 0.00018109072698280215\n",
      "Epoch 1243, Loss: 0.00017278766608797014, Final Batch Loss: 4.987091233488172e-05\n",
      "Epoch 1244, Loss: 0.008209591556806117, Final Batch Loss: 0.0007270693895407021\n",
      "Epoch 1245, Loss: 0.006043423636583611, Final Batch Loss: 0.005823514889925718\n",
      "Epoch 1246, Loss: 0.012307031080126762, Final Batch Loss: 0.005726072005927563\n",
      "Epoch 1247, Loss: 0.002553175771026872, Final Batch Loss: 0.0001134244812419638\n",
      "Epoch 1248, Loss: 0.0005471399963425938, Final Batch Loss: 3.402334186830558e-05\n",
      "Epoch 1249, Loss: 0.0009813525539357215, Final Batch Loss: 0.0005441694520413876\n",
      "Epoch 1250, Loss: 0.004025438713142648, Final Batch Loss: 0.0039905970916152\n",
      "Epoch 1251, Loss: 0.004713655303930864, Final Batch Loss: 0.00032417834154330194\n",
      "Epoch 1252, Loss: 0.001848105195676908, Final Batch Loss: 0.0004612774064298719\n",
      "Epoch 1253, Loss: 0.0005215323981246911, Final Batch Loss: 0.0004480814386624843\n",
      "Epoch 1254, Loss: 0.004159630771027878, Final Batch Loss: 0.003823180217295885\n",
      "Epoch 1255, Loss: 0.0006715956260450184, Final Batch Loss: 0.0005731325945816934\n",
      "Epoch 1256, Loss: 0.0003402749280212447, Final Batch Loss: 0.000122983125038445\n",
      "Epoch 1257, Loss: 0.0004195281653665006, Final Batch Loss: 0.0001823616330511868\n",
      "Epoch 1258, Loss: 0.0031244731799233705, Final Batch Loss: 0.00022919548791833222\n",
      "Epoch 1259, Loss: 0.00023273489205166698, Final Batch Loss: 0.00013599032536149025\n",
      "Epoch 1260, Loss: 0.004954018149874173, Final Batch Loss: 0.004728185944259167\n",
      "Epoch 1261, Loss: 0.00042407809087308124, Final Batch Loss: 8.761947538005188e-05\n",
      "Epoch 1262, Loss: 0.004840726716793142, Final Batch Loss: 0.0001319425500696525\n",
      "Epoch 1263, Loss: 0.005530681170057505, Final Batch Loss: 0.005064644385129213\n",
      "Epoch 1264, Loss: 0.0017675406561465934, Final Batch Loss: 0.0016268596518784761\n",
      "Epoch 1265, Loss: 0.0008778077899478376, Final Batch Loss: 0.0003413177328184247\n",
      "Epoch 1266, Loss: 0.0006631413707509637, Final Batch Loss: 0.00010768912034109235\n",
      "Epoch 1267, Loss: 0.0002459498791722581, Final Batch Loss: 3.53445066139102e-05\n",
      "Epoch 1268, Loss: 0.00030463060102192685, Final Batch Loss: 0.00011006001295754686\n",
      "Epoch 1269, Loss: 0.0005082911666249856, Final Batch Loss: 0.00039505274617113173\n",
      "Epoch 1270, Loss: 0.0004644477157853544, Final Batch Loss: 0.000311547628371045\n",
      "Epoch 1271, Loss: 0.00011618787902989425, Final Batch Loss: 6.419765850296244e-05\n",
      "Epoch 1272, Loss: 0.003674603569379542, Final Batch Loss: 9.406780736753717e-05\n",
      "Epoch 1273, Loss: 0.001452569558750838, Final Batch Loss: 0.00019737199181690812\n",
      "Epoch 1274, Loss: 0.0004466065911401529, Final Batch Loss: 4.6307006414281204e-05\n",
      "Epoch 1275, Loss: 0.00034688519372139126, Final Batch Loss: 0.000208369514439255\n",
      "Epoch 1276, Loss: 0.0005971737700747326, Final Batch Loss: 0.00015435107343364507\n",
      "Epoch 1277, Loss: 0.0006219216447789222, Final Batch Loss: 0.0004725069447886199\n",
      "Epoch 1278, Loss: 0.001025962847052142, Final Batch Loss: 0.0006922198808752\n",
      "Epoch 1279, Loss: 0.015655991301173344, Final Batch Loss: 0.000327717192703858\n",
      "Epoch 1280, Loss: 0.0004933251038892195, Final Batch Loss: 0.00016051971761044115\n",
      "Epoch 1281, Loss: 0.0006167017709231004, Final Batch Loss: 0.0005759401828981936\n",
      "Epoch 1282, Loss: 0.002656205906532705, Final Batch Loss: 0.00054477050434798\n",
      "Epoch 1283, Loss: 0.00048483679711353034, Final Batch Loss: 0.0001621986011741683\n",
      "Epoch 1284, Loss: 0.00117881106416462, Final Batch Loss: 0.00107632577419281\n",
      "Epoch 1285, Loss: 0.0005988994234940037, Final Batch Loss: 0.0003935856802854687\n",
      "Epoch 1286, Loss: 0.00018755705968942493, Final Batch Loss: 0.00011767730757128447\n",
      "Epoch 1287, Loss: 0.00031537208997178823, Final Batch Loss: 0.00014373163867276162\n",
      "Epoch 1288, Loss: 0.0003022911769221537, Final Batch Loss: 7.200250547612086e-05\n",
      "Epoch 1289, Loss: 0.0038275918050203472, Final Batch Loss: 0.00024011023924686015\n",
      "Epoch 1290, Loss: 0.007378580732620321, Final Batch Loss: 0.00014479247329290956\n",
      "Epoch 1291, Loss: 0.0005644862467306666, Final Batch Loss: 0.00011735068255802616\n",
      "Epoch 1292, Loss: 0.000507231401570607, Final Batch Loss: 5.1901683036703616e-05\n",
      "Epoch 1293, Loss: 0.004031005693832412, Final Batch Loss: 0.00015522949979640543\n",
      "Epoch 1294, Loss: 0.004526877019088715, Final Batch Loss: 0.0006898734136484563\n",
      "Epoch 1295, Loss: 0.0003856880430248566, Final Batch Loss: 9.991584374802187e-05\n",
      "Epoch 1296, Loss: 0.0009462609305046499, Final Batch Loss: 0.0005221024039201438\n",
      "Epoch 1297, Loss: 0.00024858442338882014, Final Batch Loss: 8.017669460969046e-05\n",
      "Epoch 1298, Loss: 0.0004158135416219011, Final Batch Loss: 0.0002382495440542698\n",
      "Epoch 1299, Loss: 0.0019407041399972513, Final Batch Loss: 0.0017174870008602738\n",
      "Epoch 1300, Loss: 0.0007703036826569587, Final Batch Loss: 0.00018989908858202398\n",
      "Epoch 1301, Loss: 0.002470580402587075, Final Batch Loss: 0.0023958475794643164\n",
      "Epoch 1302, Loss: 0.0004660815902752802, Final Batch Loss: 0.0002931253402493894\n",
      "Epoch 1303, Loss: 0.0006767944869352505, Final Batch Loss: 0.00045628301450051367\n",
      "Epoch 1304, Loss: 0.0004977555654477328, Final Batch Loss: 0.0001956616761162877\n",
      "Epoch 1305, Loss: 0.00032354921859223396, Final Batch Loss: 0.00016180593229364604\n",
      "Epoch 1306, Loss: 0.0009565136861056089, Final Batch Loss: 0.0001971307792700827\n",
      "Epoch 1307, Loss: 0.0004887868853984401, Final Batch Loss: 0.0003310100582893938\n",
      "Epoch 1308, Loss: 0.002939716214314103, Final Batch Loss: 0.0019600908271968365\n",
      "Epoch 1309, Loss: 0.0007173336780397221, Final Batch Loss: 0.00015442392032127827\n",
      "Epoch 1310, Loss: 0.00035585103614721447, Final Batch Loss: 0.000165115314302966\n",
      "Epoch 1311, Loss: 0.005280389144900255, Final Batch Loss: 0.00016506777319591492\n",
      "Epoch 1312, Loss: 0.0002735041416599415, Final Batch Loss: 0.00016931058780755848\n",
      "Epoch 1313, Loss: 0.0003095415740972385, Final Batch Loss: 0.00011312609422020614\n",
      "Epoch 1314, Loss: 0.00040829421777743846, Final Batch Loss: 0.0001391462137689814\n",
      "Epoch 1315, Loss: 0.000591323827393353, Final Batch Loss: 0.00027722143568098545\n",
      "Epoch 1316, Loss: 0.006076297955587506, Final Batch Loss: 0.002563376212492585\n",
      "Epoch 1317, Loss: 0.0029216590337455273, Final Batch Loss: 0.002355539705604315\n",
      "Epoch 1318, Loss: 0.00038424394733738154, Final Batch Loss: 0.0002477626840118319\n",
      "Epoch 1319, Loss: 0.001151699645561166, Final Batch Loss: 0.0009517539292573929\n",
      "Epoch 1320, Loss: 0.00017878283688332886, Final Batch Loss: 0.0001323527394561097\n",
      "Epoch 1321, Loss: 0.033586694073164836, Final Batch Loss: 0.03327411785721779\n",
      "Epoch 1322, Loss: 0.0002094731680699624, Final Batch Loss: 6.624901288887486e-05\n",
      "Epoch 1323, Loss: 0.001985394788789563, Final Batch Loss: 0.0019057601457461715\n",
      "Epoch 1324, Loss: 0.000787891709478572, Final Batch Loss: 0.0005640656454488635\n",
      "Epoch 1325, Loss: 0.00032635757088428363, Final Batch Loss: 0.00025067885871976614\n",
      "Epoch 1326, Loss: 0.000512306927703321, Final Batch Loss: 0.00012528261868283153\n",
      "Epoch 1327, Loss: 0.01385938748717308, Final Batch Loss: 0.0127342464402318\n",
      "Epoch 1328, Loss: 0.00044467377301771194, Final Batch Loss: 0.0002102469006786123\n",
      "Epoch 1329, Loss: 0.0005941193085163832, Final Batch Loss: 0.0002328659174963832\n",
      "Epoch 1330, Loss: 0.0001870909472927451, Final Batch Loss: 4.6508765080943704e-05\n",
      "Epoch 1331, Loss: 0.0008702768245711923, Final Batch Loss: 0.0005579999997280538\n",
      "Epoch 1332, Loss: 0.0036590148229151964, Final Batch Loss: 0.0014677783474326134\n",
      "Epoch 1333, Loss: 0.0006395763193722814, Final Batch Loss: 6.957826553843915e-05\n",
      "Epoch 1334, Loss: 0.0009004381154227303, Final Batch Loss: 2.800853872031439e-05\n",
      "Epoch 1335, Loss: 0.000411138913477771, Final Batch Loss: 0.00021564702910836786\n",
      "Epoch 1336, Loss: 0.0007014256989350542, Final Batch Loss: 0.0005237075965851545\n",
      "Epoch 1337, Loss: 0.005227292669587769, Final Batch Loss: 0.004988413769751787\n",
      "Epoch 1338, Loss: 0.0061352864613581914, Final Batch Loss: 0.006086267996579409\n",
      "Epoch 1339, Loss: 0.002073184776236303, Final Batch Loss: 6.358973041642457e-05\n",
      "Epoch 1340, Loss: 0.0011535138473846018, Final Batch Loss: 0.0004929474671371281\n",
      "Epoch 1341, Loss: 0.00023023220273898914, Final Batch Loss: 8.727399836061522e-05\n",
      "Epoch 1342, Loss: 0.0467595674272161, Final Batch Loss: 0.0001970894809346646\n",
      "Epoch 1343, Loss: 0.0012075951090082526, Final Batch Loss: 0.0005971936043351889\n",
      "Epoch 1344, Loss: 0.0004957383935106918, Final Batch Loss: 0.00012513673573266715\n",
      "Epoch 1345, Loss: 0.0038645770837320015, Final Batch Loss: 4.399991303216666e-05\n",
      "Epoch 1346, Loss: 0.0003025584592251107, Final Batch Loss: 0.0001227049360750243\n",
      "Epoch 1347, Loss: 0.0002559980348451063, Final Batch Loss: 6.215967005118728e-05\n",
      "Epoch 1348, Loss: 0.003243122366257012, Final Batch Loss: 0.001150991884060204\n",
      "Epoch 1349, Loss: 0.0011688597151078284, Final Batch Loss: 0.0005175621481612325\n",
      "Epoch 1350, Loss: 0.003927202516933903, Final Batch Loss: 0.003797220066189766\n",
      "Epoch 1351, Loss: 0.0008937041857279837, Final Batch Loss: 0.00017138017574325204\n",
      "Epoch 1352, Loss: 0.00033409459138056263, Final Batch Loss: 0.00026807814720086753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1353, Loss: 0.0061401642014971, Final Batch Loss: 0.00012657429033424705\n",
      "Epoch 1354, Loss: 0.00036088505294173956, Final Batch Loss: 0.00012903157039545476\n",
      "Epoch 1355, Loss: 0.00045735217281617224, Final Batch Loss: 0.00021700507204513997\n",
      "Epoch 1356, Loss: 0.00032581391860730946, Final Batch Loss: 0.0001656248205108568\n",
      "Epoch 1357, Loss: 0.00032616463431622833, Final Batch Loss: 0.00023692676040809602\n",
      "Epoch 1358, Loss: 0.0005669844103977084, Final Batch Loss: 0.00018524614279158413\n",
      "Epoch 1359, Loss: 0.0026799231563927606, Final Batch Loss: 0.0002303750516148284\n",
      "Epoch 1360, Loss: 0.002528469660319388, Final Batch Loss: 0.00037519086617976427\n",
      "Epoch 1361, Loss: 0.00021930356888333336, Final Batch Loss: 0.00013430631952360272\n",
      "Epoch 1362, Loss: 0.009496724378550425, Final Batch Loss: 0.009337319992482662\n",
      "Epoch 1363, Loss: 0.00031352707446785644, Final Batch Loss: 0.00020554009824991226\n",
      "Epoch 1364, Loss: 0.00020193211821606383, Final Batch Loss: 0.0001582335971761495\n",
      "Epoch 1365, Loss: 0.003871339315082878, Final Batch Loss: 0.0005988084594719112\n",
      "Epoch 1366, Loss: 0.000642370869172737, Final Batch Loss: 0.00029710395028814673\n",
      "Epoch 1367, Loss: 0.0029933208716101944, Final Batch Loss: 8.735625306144357e-05\n",
      "Epoch 1368, Loss: 0.0013745004762313329, Final Batch Loss: 9.322180267190561e-05\n",
      "Epoch 1369, Loss: 0.0001413028730894439, Final Batch Loss: 7.917703624116257e-05\n",
      "Epoch 1370, Loss: 0.0016404605630668812, Final Batch Loss: 9.292386675952002e-05\n",
      "Epoch 1371, Loss: 0.003740105588803999, Final Batch Loss: 0.00013994127220939845\n",
      "Epoch 1372, Loss: 0.00013491473873727955, Final Batch Loss: 5.695675281458534e-05\n",
      "Epoch 1373, Loss: 0.0058115336651098914, Final Batch Loss: 6.413530354620889e-05\n",
      "Epoch 1374, Loss: 0.0032432370353490114, Final Batch Loss: 2.4077482521533966e-05\n",
      "Epoch 1375, Loss: 0.004598009254550561, Final Batch Loss: 0.004208859521895647\n",
      "Epoch 1376, Loss: 0.0022421049943659455, Final Batch Loss: 0.00017199516878463328\n",
      "Epoch 1377, Loss: 0.01575281300029019, Final Batch Loss: 0.00010342166206100956\n",
      "Epoch 1378, Loss: 0.0006983253188082017, Final Batch Loss: 0.0006227652775123715\n",
      "Epoch 1379, Loss: 0.0008448030130239204, Final Batch Loss: 0.00016654569481033832\n",
      "Epoch 1380, Loss: 0.0005244110652711242, Final Batch Loss: 0.00039845705032348633\n",
      "Epoch 1381, Loss: 0.0002608963259262964, Final Batch Loss: 0.0002050446200883016\n",
      "Epoch 1382, Loss: 0.004337691352702677, Final Batch Loss: 0.00029651832301169634\n",
      "Epoch 1383, Loss: 0.0020101079426240176, Final Batch Loss: 0.0004206858284305781\n",
      "Epoch 1384, Loss: 0.0002483988537278492, Final Batch Loss: 2.1357835066737607e-05\n",
      "Epoch 1385, Loss: 0.0008572397782700136, Final Batch Loss: 8.688286470714957e-05\n",
      "Epoch 1386, Loss: 0.0010502277218620293, Final Batch Loss: 0.0009745939751155674\n",
      "Epoch 1387, Loss: 0.008272172883152962, Final Batch Loss: 0.004296238999813795\n",
      "Epoch 1388, Loss: 0.0019052954448852688, Final Batch Loss: 0.00024257684708572924\n",
      "Epoch 1389, Loss: 0.00024050697538768873, Final Batch Loss: 0.00013004070206079632\n",
      "Epoch 1390, Loss: 0.004373271091026254, Final Batch Loss: 0.00012630091805476695\n",
      "Epoch 1391, Loss: 0.0022489362308988348, Final Batch Loss: 0.002094687195494771\n",
      "Epoch 1392, Loss: 0.0032850311981746927, Final Batch Loss: 0.00011365524551365525\n",
      "Epoch 1393, Loss: 0.00033775139309000224, Final Batch Loss: 0.00027725251857191324\n",
      "Epoch 1394, Loss: 0.00034233419864904135, Final Batch Loss: 0.00010137265780940652\n",
      "Epoch 1395, Loss: 0.00029063284455332905, Final Batch Loss: 0.00015701784286648035\n",
      "Epoch 1396, Loss: 0.0003997157509729732, Final Batch Loss: 0.0003544268838595599\n",
      "Epoch 1397, Loss: 0.00038648228655802086, Final Batch Loss: 0.00029989503673277795\n",
      "Epoch 1398, Loss: 0.00242283362604212, Final Batch Loss: 0.00023561371199321002\n",
      "Epoch 1399, Loss: 0.005846729269251227, Final Batch Loss: 0.005391435697674751\n",
      "Epoch 1400, Loss: 0.0036660733312601224, Final Batch Loss: 0.0036003580316901207\n",
      "Epoch 1401, Loss: 0.003150557226035744, Final Batch Loss: 0.00034952611895278096\n",
      "Epoch 1402, Loss: 0.003598221308493521, Final Batch Loss: 9.675017645349726e-05\n",
      "Epoch 1403, Loss: 0.0004265751485945657, Final Batch Loss: 0.00020479199883993715\n",
      "Epoch 1404, Loss: 0.000184487049409654, Final Batch Loss: 0.00010083871165988967\n",
      "Epoch 1405, Loss: 0.0002959112316602841, Final Batch Loss: 0.0001157766382675618\n",
      "Epoch 1406, Loss: 0.0022185094785527326, Final Batch Loss: 7.563285907963291e-05\n",
      "Epoch 1407, Loss: 0.0003905205230694264, Final Batch Loss: 0.00012040202273055911\n",
      "Epoch 1408, Loss: 0.007856307551264763, Final Batch Loss: 0.0031403061002492905\n",
      "Epoch 1409, Loss: 0.0034926640801131725, Final Batch Loss: 0.00033974996767938137\n",
      "Epoch 1410, Loss: 0.00032229807402472943, Final Batch Loss: 0.00020912439504172653\n",
      "Epoch 1411, Loss: 0.006891051452839747, Final Batch Loss: 0.00042447043233551085\n",
      "Epoch 1412, Loss: 0.00410052266670391, Final Batch Loss: 0.0003256652853451669\n",
      "Epoch 1413, Loss: 0.00039981622103368863, Final Batch Loss: 0.00012082087778253481\n",
      "Epoch 1414, Loss: 0.0002444982819724828, Final Batch Loss: 6.865574687253684e-05\n",
      "Epoch 1415, Loss: 0.005675962907844223, Final Batch Loss: 0.00017787494289223105\n",
      "Epoch 1416, Loss: 0.0036158124275971204, Final Batch Loss: 0.00033745079417712986\n",
      "Epoch 1417, Loss: 0.00019776079716393724, Final Batch Loss: 0.00011893074406543747\n",
      "Epoch 1418, Loss: 0.0015416751230077352, Final Batch Loss: 1.7127891624113545e-05\n",
      "Epoch 1419, Loss: 0.0032410271815024316, Final Batch Loss: 0.0026189852505922318\n",
      "Epoch 1420, Loss: 0.00016919300196605036, Final Batch Loss: 1.1755176274164114e-05\n",
      "Epoch 1421, Loss: 0.007029659289401025, Final Batch Loss: 0.0005820590886287391\n",
      "Epoch 1422, Loss: 0.00029862517112633213, Final Batch Loss: 0.00018503562023397535\n",
      "Epoch 1423, Loss: 0.0002838834698195569, Final Batch Loss: 0.00016641091497149318\n",
      "Epoch 1424, Loss: 0.0010148729343200102, Final Batch Loss: 0.0008873601909726858\n",
      "Epoch 1425, Loss: 0.004101810973224929, Final Batch Loss: 1.6611997125437483e-05\n",
      "Epoch 1426, Loss: 0.0038427229737862945, Final Batch Loss: 0.0026488678995519876\n",
      "Epoch 1427, Loss: 0.00022431597972172312, Final Batch Loss: 3.5671571822604164e-05\n",
      "Epoch 1428, Loss: 0.005444896130939014, Final Batch Loss: 0.005205703899264336\n",
      "Epoch 1429, Loss: 0.0003078807203564793, Final Batch Loss: 0.00016770491492934525\n",
      "Epoch 1430, Loss: 0.0024538699217373505, Final Batch Loss: 0.00021767245198134333\n",
      "Epoch 1431, Loss: 0.00044974822958465666, Final Batch Loss: 0.00012211968714836985\n",
      "Epoch 1432, Loss: 0.0002223862029495649, Final Batch Loss: 0.00010542474046815187\n",
      "Epoch 1433, Loss: 0.0027368993178242818, Final Batch Loss: 0.00018588641250971705\n",
      "Epoch 1434, Loss: 0.0005727534589823335, Final Batch Loss: 7.93075596448034e-05\n",
      "Epoch 1435, Loss: 0.00026108590100193396, Final Batch Loss: 0.0001763627806212753\n",
      "Epoch 1436, Loss: 0.00023208331185742281, Final Batch Loss: 4.5767894334858283e-05\n",
      "Epoch 1437, Loss: 0.00019206805154681206, Final Batch Loss: 6.901603774167597e-05\n",
      "Epoch 1438, Loss: 0.0018079955989378504, Final Batch Loss: 7.857794116716832e-06\n",
      "Epoch 1439, Loss: 0.005506523375515826, Final Batch Loss: 0.005350317340344191\n",
      "Epoch 1440, Loss: 0.0040775094530545175, Final Batch Loss: 0.0007019312470220029\n",
      "Epoch 1441, Loss: 0.00424183887662366, Final Batch Loss: 0.00036092713708058\n",
      "Epoch 1442, Loss: 0.02515004202723503, Final Batch Loss: 0.00780421681702137\n",
      "Epoch 1443, Loss: 0.0005744392110500485, Final Batch Loss: 0.0002475569781381637\n",
      "Epoch 1444, Loss: 0.002201711860834621, Final Batch Loss: 0.002003804314881563\n",
      "Epoch 1445, Loss: 0.0002794234169414267, Final Batch Loss: 5.518044054042548e-05\n",
      "Epoch 1446, Loss: 0.0012090974196325988, Final Batch Loss: 0.0008659143932163715\n",
      "Epoch 1447, Loss: 0.003461119660641998, Final Batch Loss: 0.00044118001824244857\n",
      "Epoch 1448, Loss: 0.0018143571505788714, Final Batch Loss: 0.0002698713506106287\n",
      "Epoch 1449, Loss: 0.0038011387368896976, Final Batch Loss: 4.554692714009434e-05\n",
      "Epoch 1450, Loss: 0.024058037146460265, Final Batch Loss: 0.0001145104761235416\n",
      "Epoch 1451, Loss: 0.0024983775801956654, Final Batch Loss: 0.0019243852002546191\n",
      "Epoch 1452, Loss: 0.00047835717850830406, Final Batch Loss: 0.00012843661534134299\n",
      "Epoch 1453, Loss: 0.0019007583032362163, Final Batch Loss: 0.000400350836571306\n",
      "Epoch 1454, Loss: 0.00040526669181417674, Final Batch Loss: 0.00017327771638520062\n",
      "Epoch 1455, Loss: 0.006799208356824238, Final Batch Loss: 7.584447303088382e-05\n",
      "Epoch 1456, Loss: 0.0005051864718552679, Final Batch Loss: 0.0002519101253710687\n",
      "Epoch 1457, Loss: 0.00010667272363207303, Final Batch Loss: 4.415453804540448e-05\n",
      "Epoch 1458, Loss: 0.0001778472687874455, Final Batch Loss: 4.938518759445287e-05\n",
      "Epoch 1459, Loss: 0.0033523782185511664, Final Batch Loss: 0.00021046325855422765\n",
      "Epoch 1460, Loss: 0.0001543678117741365, Final Batch Loss: 9.541217150399461e-05\n",
      "Epoch 1461, Loss: 0.000626584398560226, Final Batch Loss: 0.00047902550431899726\n",
      "Epoch 1462, Loss: 0.005241269187536091, Final Batch Loss: 0.004888271912932396\n",
      "Epoch 1463, Loss: 0.0001298220595344901, Final Batch Loss: 1.4600729628000408e-05\n",
      "Epoch 1464, Loss: 0.001398339751176536, Final Batch Loss: 0.00014980172272771597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1465, Loss: 0.0029218013514764607, Final Batch Loss: 0.002625764347612858\n",
      "Epoch 1466, Loss: 0.00034676991344895214, Final Batch Loss: 0.00018472981173545122\n",
      "Epoch 1467, Loss: 0.0007834024436306208, Final Batch Loss: 0.00033610581886023283\n",
      "Epoch 1468, Loss: 0.0005852986359968781, Final Batch Loss: 0.00033202083432115614\n",
      "Epoch 1469, Loss: 0.01629898442843114, Final Batch Loss: 0.016271408647298813\n",
      "Epoch 1470, Loss: 0.0003760444524232298, Final Batch Loss: 0.0001323804899584502\n",
      "Epoch 1471, Loss: 0.00043252325849607587, Final Batch Loss: 0.0003854520618915558\n",
      "Epoch 1472, Loss: 0.004767455036926549, Final Batch Loss: 0.004716718569397926\n",
      "Epoch 1473, Loss: 0.000298848855891265, Final Batch Loss: 9.022981976158917e-05\n",
      "Epoch 1474, Loss: 0.013210594246629626, Final Batch Loss: 0.012712710537016392\n",
      "Epoch 1475, Loss: 0.0050642178975977, Final Batch Loss: 0.004838378168642521\n",
      "Epoch 1476, Loss: 0.00028331083740340546, Final Batch Loss: 0.00010126693086931482\n",
      "Epoch 1477, Loss: 0.003634606604464352, Final Batch Loss: 0.0033052852377295494\n",
      "Epoch 1478, Loss: 0.030881654238328338, Final Batch Loss: 0.029884420335292816\n",
      "Epoch 1479, Loss: 0.0008201455057132989, Final Batch Loss: 0.0005095078959129751\n",
      "Epoch 1480, Loss: 0.0009614433292881586, Final Batch Loss: 0.0008538812398910522\n",
      "Epoch 1481, Loss: 0.007234583608806133, Final Batch Loss: 0.003924849443137646\n",
      "Epoch 1482, Loss: 0.0034827655472327024, Final Batch Loss: 0.003280850825831294\n",
      "Epoch 1483, Loss: 0.0009147837408818305, Final Batch Loss: 0.0003673844621516764\n",
      "Epoch 1484, Loss: 0.0009054455440491438, Final Batch Loss: 0.0004830586549360305\n",
      "Epoch 1485, Loss: 0.0008809547289274633, Final Batch Loss: 0.0006522573530673981\n",
      "Epoch 1486, Loss: 0.007027996820397675, Final Batch Loss: 0.0012480738805606961\n",
      "Epoch 1487, Loss: 0.0004600066240527667, Final Batch Loss: 0.00011852954776259139\n",
      "Epoch 1488, Loss: 0.0025825996708590537, Final Batch Loss: 0.002372440882027149\n",
      "Epoch 1489, Loss: 0.0003744126734090969, Final Batch Loss: 0.00016966859402600676\n",
      "Epoch 1490, Loss: 0.00031421166386280674, Final Batch Loss: 2.696308547456283e-05\n",
      "Epoch 1491, Loss: 0.002731784785282798, Final Batch Loss: 0.00015073160466272384\n",
      "Epoch 1492, Loss: 0.0005529923219000921, Final Batch Loss: 0.00046125578228384256\n",
      "Epoch 1493, Loss: 0.0003076015964325052, Final Batch Loss: 4.9784586735768244e-05\n",
      "Epoch 1494, Loss: 0.004457863629795611, Final Batch Loss: 0.0006494809640571475\n",
      "Epoch 1495, Loss: 0.002509347687009722, Final Batch Loss: 0.0002958931145258248\n",
      "Epoch 1496, Loss: 0.003297514711448457, Final Batch Loss: 7.71167324273847e-05\n",
      "Epoch 1497, Loss: 0.002588780494988896, Final Batch Loss: 0.00017475955246482044\n",
      "Epoch 1498, Loss: 0.000882209169503767, Final Batch Loss: 9.627384861232713e-05\n",
      "Epoch 1499, Loss: 0.00341247793767252, Final Batch Loss: 4.349628943600692e-05\n",
      "Epoch 1500, Loss: 0.001119506843679119, Final Batch Loss: 0.0009978578891605139\n",
      "Epoch 1501, Loss: 0.0025875982246361673, Final Batch Loss: 0.0002828970900736749\n",
      "Epoch 1502, Loss: 0.0002904122229665518, Final Batch Loss: 9.647099068388343e-05\n",
      "Epoch 1503, Loss: 0.010651002172380686, Final Batch Loss: 0.005674830637872219\n",
      "Epoch 1504, Loss: 0.00571814326394815, Final Batch Loss: 0.00012743387196678668\n",
      "Epoch 1505, Loss: 0.0007918357878224924, Final Batch Loss: 0.0002039962710114196\n",
      "Epoch 1506, Loss: 0.003995698556536809, Final Batch Loss: 0.0004010383563581854\n",
      "Epoch 1507, Loss: 0.006012507947161794, Final Batch Loss: 0.0034150751307606697\n",
      "Epoch 1508, Loss: 0.000489912272314541, Final Batch Loss: 0.00033315899781882763\n",
      "Epoch 1509, Loss: 0.0003359171241754666, Final Batch Loss: 4.984829865861684e-05\n",
      "Epoch 1510, Loss: 0.00040414690010948107, Final Batch Loss: 0.0003099714231211692\n",
      "Epoch 1511, Loss: 0.0010592603066470474, Final Batch Loss: 0.0002639754384290427\n",
      "Epoch 1512, Loss: 0.0019007194932783023, Final Batch Loss: 0.0001997766230488196\n",
      "Epoch 1513, Loss: 0.0019591660166042857, Final Batch Loss: 0.00010769697109935805\n",
      "Epoch 1514, Loss: 0.04094216039084131, Final Batch Loss: 0.04085473343729973\n",
      "Epoch 1515, Loss: 0.0018362638038524892, Final Batch Loss: 4.4498239731183276e-05\n",
      "Epoch 1516, Loss: 0.0024836174125084653, Final Batch Loss: 0.00012900600268039852\n",
      "Epoch 1517, Loss: 0.005806196015328169, Final Batch Loss: 0.00363072264008224\n",
      "Epoch 1518, Loss: 0.0002876500366255641, Final Batch Loss: 0.0001272307417821139\n",
      "Epoch 1519, Loss: 0.0005586434781434946, Final Batch Loss: 8.909648022381589e-05\n",
      "Epoch 1520, Loss: 0.00013462673086905852, Final Batch Loss: 8.79322542459704e-05\n",
      "Epoch 1521, Loss: 0.0028312501963227987, Final Batch Loss: 0.00027112802490592003\n",
      "Epoch 1522, Loss: 0.007622871715284418, Final Batch Loss: 8.375493780476972e-05\n",
      "Epoch 1523, Loss: 0.00016070299170678481, Final Batch Loss: 6.904215115355328e-05\n",
      "Epoch 1524, Loss: 0.0003253018076065928, Final Batch Loss: 0.00014435412595048547\n",
      "Epoch 1525, Loss: 0.0004686129104811698, Final Batch Loss: 0.0003287721483502537\n",
      "Epoch 1526, Loss: 0.0009690507140476257, Final Batch Loss: 0.0005337651236914098\n",
      "Epoch 1527, Loss: 0.003942264011129737, Final Batch Loss: 0.00374307157471776\n",
      "Epoch 1528, Loss: 0.0004419592551130336, Final Batch Loss: 4.280775829101913e-05\n",
      "Epoch 1529, Loss: 0.004310782882384956, Final Batch Loss: 0.003133018733933568\n",
      "Epoch 1530, Loss: 0.0006379962142091244, Final Batch Loss: 0.0005545321037061512\n",
      "Epoch 1531, Loss: 0.003966053773183376, Final Batch Loss: 0.003672335995361209\n",
      "Epoch 1532, Loss: 0.0005439346768980613, Final Batch Loss: 0.0005199239822104573\n",
      "Epoch 1533, Loss: 0.0001117455649364274, Final Batch Loss: 5.3053365263622254e-05\n",
      "Epoch 1534, Loss: 0.002405603154329583, Final Batch Loss: 0.00034210176090709865\n",
      "Epoch 1535, Loss: 0.0008034953498281538, Final Batch Loss: 0.0006650927243754268\n",
      "Epoch 1536, Loss: 0.0001986864663194865, Final Batch Loss: 5.294082802720368e-05\n",
      "Epoch 1537, Loss: 0.0014104220317676663, Final Batch Loss: 0.0012615410378202796\n",
      "Epoch 1538, Loss: 0.003700923844007775, Final Batch Loss: 0.00037171549047343433\n",
      "Epoch 1539, Loss: 0.00314417445770232, Final Batch Loss: 0.00011810578143922612\n",
      "Epoch 1540, Loss: 0.0031504094367846847, Final Batch Loss: 0.000336320954374969\n",
      "Epoch 1541, Loss: 0.0005594920148723759, Final Batch Loss: 8.981026621768251e-05\n",
      "Epoch 1542, Loss: 0.003055438050068915, Final Batch Loss: 0.0028635491617023945\n",
      "Epoch 1543, Loss: 0.00021535508858505636, Final Batch Loss: 9.976058208849281e-05\n",
      "Epoch 1544, Loss: 0.004021364846266806, Final Batch Loss: 0.003845991799607873\n",
      "Epoch 1545, Loss: 0.0003628034901339561, Final Batch Loss: 0.00023297658481169492\n",
      "Epoch 1546, Loss: 0.0004628174065146595, Final Batch Loss: 0.00017189292702823877\n",
      "Epoch 1547, Loss: 0.0015993660781532526, Final Batch Loss: 0.0006300837267190218\n",
      "Epoch 1548, Loss: 0.0002549731907492969, Final Batch Loss: 3.167811155435629e-05\n",
      "Epoch 1549, Loss: 0.006354595068842173, Final Batch Loss: 9.458046406507492e-05\n",
      "Epoch 1550, Loss: 0.00022239082682062872, Final Batch Loss: 0.00017068932356778532\n",
      "Epoch 1551, Loss: 0.0004923592059640214, Final Batch Loss: 0.00035918413777835667\n",
      "Epoch 1552, Loss: 0.0001913155647343956, Final Batch Loss: 0.00013506883988156915\n",
      "Epoch 1553, Loss: 0.011032431852072477, Final Batch Loss: 0.010854541324079037\n",
      "Epoch 1554, Loss: 0.0004305624752305448, Final Batch Loss: 0.00016044118092395365\n",
      "Epoch 1555, Loss: 0.001005142978101503, Final Batch Loss: 0.0008890466415323317\n",
      "Epoch 1556, Loss: 0.0039399926899932325, Final Batch Loss: 0.00030223181238397956\n",
      "Epoch 1557, Loss: 0.0009033742499013897, Final Batch Loss: 4.7571342292940244e-05\n",
      "Epoch 1558, Loss: 0.00031988394766813144, Final Batch Loss: 0.0002580869768280536\n",
      "Epoch 1559, Loss: 0.0007243589061545208, Final Batch Loss: 0.00016001945186872035\n",
      "Epoch 1560, Loss: 0.0028586440967046656, Final Batch Loss: 4.0584222006145865e-05\n",
      "Epoch 1561, Loss: 0.0004337345089879818, Final Batch Loss: 0.0003529782989062369\n",
      "Epoch 1562, Loss: 0.0002706742816371843, Final Batch Loss: 0.0001424988586222753\n",
      "Epoch 1563, Loss: 0.0021183509670663625, Final Batch Loss: 0.00021399374236352742\n",
      "Epoch 1564, Loss: 0.00031516115996055305, Final Batch Loss: 0.0001369746751151979\n",
      "Epoch 1565, Loss: 0.0002848725416697562, Final Batch Loss: 4.7231515054591e-05\n",
      "Epoch 1566, Loss: 0.014121677726507187, Final Batch Loss: 0.008466986939311028\n",
      "Epoch 1567, Loss: 0.004779362621775363, Final Batch Loss: 8.584143506595865e-05\n",
      "Epoch 1568, Loss: 0.00038855774619150907, Final Batch Loss: 0.00020778736507054418\n",
      "Epoch 1569, Loss: 0.004556552041321993, Final Batch Loss: 0.0021541519090533257\n",
      "Epoch 1570, Loss: 0.0007689135891268961, Final Batch Loss: 6.920017040101811e-05\n",
      "Epoch 1571, Loss: 0.00012654644160647877, Final Batch Loss: 8.211229578591883e-05\n",
      "Epoch 1572, Loss: 0.00013681204654858448, Final Batch Loss: 9.826164750847965e-05\n",
      "Epoch 1573, Loss: 0.00020188790949760005, Final Batch Loss: 0.00012854966917075217\n",
      "Epoch 1574, Loss: 0.008304844828671776, Final Batch Loss: 0.008209333755075932\n",
      "Epoch 1575, Loss: 0.00258427483640844, Final Batch Loss: 4.441242344910279e-05\n",
      "Epoch 1576, Loss: 0.0028470084071159363, Final Batch Loss: 0.00036943331360816956\n",
      "Epoch 1577, Loss: 0.0031663614172430243, Final Batch Loss: 0.003118949243798852\n",
      "Epoch 1578, Loss: 0.0019501539372868137, Final Batch Loss: 2.8429525627871044e-05\n",
      "Epoch 1579, Loss: 0.00021535887935897335, Final Batch Loss: 0.00012388931645546108\n",
      "Epoch 1580, Loss: 0.00020985828450648114, Final Batch Loss: 0.00014765273954253644\n",
      "Epoch 1581, Loss: 0.0007252782888826914, Final Batch Loss: 0.0006633861339651048\n",
      "Epoch 1582, Loss: 0.0019731027459783945, Final Batch Loss: 0.0019529742421582341\n",
      "Epoch 1583, Loss: 0.0003986128867836669, Final Batch Loss: 0.00014301536430139095\n",
      "Epoch 1584, Loss: 0.010885846568271518, Final Batch Loss: 0.008133471943438053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1585, Loss: 0.000322069252433721, Final Batch Loss: 0.0002415607013972476\n",
      "Epoch 1586, Loss: 0.0008535191009286791, Final Batch Loss: 0.0007262332946993411\n",
      "Epoch 1587, Loss: 0.0007215150253614411, Final Batch Loss: 0.0001912457955768332\n",
      "Epoch 1588, Loss: 0.0003971693804487586, Final Batch Loss: 0.0002562980225775391\n",
      "Epoch 1589, Loss: 0.0007541295199189335, Final Batch Loss: 0.000210827769478783\n",
      "Epoch 1590, Loss: 0.0007273956434801221, Final Batch Loss: 0.0003632169682532549\n",
      "Epoch 1591, Loss: 0.0016098791384138167, Final Batch Loss: 0.0003849014756269753\n",
      "Epoch 1592, Loss: 0.005025594058679417, Final Batch Loss: 0.0002471264742780477\n",
      "Epoch 1593, Loss: 0.0012428739573806524, Final Batch Loss: 0.0008556246757507324\n",
      "Epoch 1594, Loss: 0.0005106489115860313, Final Batch Loss: 0.0002760961069725454\n",
      "Epoch 1595, Loss: 0.006194070156197995, Final Batch Loss: 0.0007079780916683376\n",
      "Epoch 1596, Loss: 0.0009017842821776867, Final Batch Loss: 0.0006224432145245373\n",
      "Epoch 1597, Loss: 0.0039626895159017295, Final Batch Loss: 0.00010069084237329662\n",
      "Epoch 1598, Loss: 0.0053704580932389945, Final Batch Loss: 0.00048696339945308864\n",
      "Epoch 1599, Loss: 0.0060583282029256225, Final Batch Loss: 0.0044515966437757015\n",
      "Epoch 1600, Loss: 0.0019155317568220198, Final Batch Loss: 0.0007459173793904483\n",
      "Epoch 1601, Loss: 0.0005346196849131957, Final Batch Loss: 0.00018718909996096045\n",
      "Epoch 1602, Loss: 0.00437335399328731, Final Batch Loss: 0.0040655434131622314\n",
      "Epoch 1603, Loss: 0.000896830897545442, Final Batch Loss: 0.00014006099081598222\n",
      "Epoch 1604, Loss: 0.00021786503566545434, Final Batch Loss: 3.685406773001887e-05\n",
      "Epoch 1605, Loss: 0.007733102887868881, Final Batch Loss: 0.002803906798362732\n",
      "Epoch 1606, Loss: 0.00028649223531829193, Final Batch Loss: 0.00019017809245269746\n",
      "Epoch 1607, Loss: 0.007404384494293481, Final Batch Loss: 0.007128963712602854\n",
      "Epoch 1608, Loss: 0.003103209164692089, Final Batch Loss: 0.002896219491958618\n",
      "Epoch 1609, Loss: 0.003545800078427419, Final Batch Loss: 0.003297438845038414\n",
      "Epoch 1610, Loss: 0.0008584522292949259, Final Batch Loss: 0.0002683484344743192\n",
      "Epoch 1611, Loss: 0.00030025760861462913, Final Batch Loss: 0.00027213036082684994\n",
      "Epoch 1612, Loss: 0.00033058313420042396, Final Batch Loss: 0.0002111739304382354\n",
      "Epoch 1613, Loss: 0.0001749730326991994, Final Batch Loss: 5.168952702661045e-05\n",
      "Epoch 1614, Loss: 0.000607549533015117, Final Batch Loss: 0.00020631973166018724\n",
      "Epoch 1615, Loss: 0.003034085790204699, Final Batch Loss: 0.0030145691707730293\n",
      "Epoch 1616, Loss: 8.154312126862351e-05, Final Batch Loss: 6.140469486126676e-05\n",
      "Epoch 1617, Loss: 0.0006600802662433125, Final Batch Loss: 6.74450202495791e-05\n",
      "Epoch 1618, Loss: 0.00020606190446414985, Final Batch Loss: 2.8036072762915865e-05\n",
      "Epoch 1619, Loss: 0.00041728241194505244, Final Batch Loss: 0.0001910821592900902\n",
      "Epoch 1620, Loss: 0.0030090408290561754, Final Batch Loss: 0.0029495719354599714\n",
      "Epoch 1621, Loss: 0.003181691103236517, Final Batch Loss: 0.0031301919370889664\n",
      "Epoch 1622, Loss: 0.002183109478210099, Final Batch Loss: 0.0020922815892845392\n",
      "Epoch 1623, Loss: 0.006862587109935703, Final Batch Loss: 0.006802087649703026\n",
      "Epoch 1624, Loss: 8.41665496409405e-05, Final Batch Loss: 3.5423068766249344e-05\n",
      "Epoch 1625, Loss: 0.0006369904440362006, Final Batch Loss: 0.000319804617902264\n",
      "Epoch 1626, Loss: 0.00021873291916563176, Final Batch Loss: 0.00015795313811395317\n",
      "Epoch 1627, Loss: 0.0007993043655005749, Final Batch Loss: 0.0007462195935659111\n",
      "Epoch 1628, Loss: 0.00027184509963262826, Final Batch Loss: 0.00022288772743195295\n",
      "Epoch 1629, Loss: 0.0005728433316107839, Final Batch Loss: 0.00023669336223974824\n",
      "Epoch 1630, Loss: 0.003332750995468814, Final Batch Loss: 0.00010236085654469207\n",
      "Epoch 1631, Loss: 0.00013921925710747018, Final Batch Loss: 9.4712340796832e-05\n",
      "Epoch 1632, Loss: 0.0005444492562673986, Final Batch Loss: 0.0003457568818703294\n",
      "Epoch 1633, Loss: 0.0001736924532451667, Final Batch Loss: 8.131788490572944e-05\n",
      "Epoch 1634, Loss: 0.0004184377321507782, Final Batch Loss: 0.00029372848803177476\n",
      "Epoch 1635, Loss: 7.783826004015282e-05, Final Batch Loss: 3.402897345949896e-05\n",
      "Epoch 1636, Loss: 7.995805026439484e-05, Final Batch Loss: 1.6338131899829023e-05\n",
      "Epoch 1637, Loss: 0.002558403240982443, Final Batch Loss: 0.00200540735386312\n",
      "Epoch 1638, Loss: 0.0009181915411318187, Final Batch Loss: 3.601613934733905e-05\n",
      "Epoch 1639, Loss: 0.00023613149824086577, Final Batch Loss: 7.777097926009446e-05\n",
      "Epoch 1640, Loss: 0.0007992712744453456, Final Batch Loss: 3.646436016424559e-05\n",
      "Epoch 1641, Loss: 0.0057208610596717335, Final Batch Loss: 7.080127397784963e-05\n",
      "Epoch 1642, Loss: 0.0008222528558690101, Final Batch Loss: 0.000785909709520638\n",
      "Epoch 1643, Loss: 8.631347736809403e-05, Final Batch Loss: 3.609387931646779e-05\n",
      "Epoch 1644, Loss: 0.006292693084105849, Final Batch Loss: 0.0026745672803372145\n",
      "Epoch 1645, Loss: 0.0002597578422864899, Final Batch Loss: 0.00017453792679589242\n",
      "Epoch 1646, Loss: 0.0003669110592454672, Final Batch Loss: 8.411117596551776e-05\n",
      "Epoch 1647, Loss: 0.00027810884785139933, Final Batch Loss: 0.00017727121303323656\n",
      "Epoch 1648, Loss: 0.00022522376457345672, Final Batch Loss: 3.640774593804963e-05\n",
      "Epoch 1649, Loss: 0.00023208693710330408, Final Batch Loss: 2.462467637087684e-05\n",
      "Epoch 1650, Loss: 0.00050664606897044, Final Batch Loss: 0.00045462697744369507\n",
      "Epoch 1651, Loss: 0.0004876247840002179, Final Batch Loss: 5.552938091568649e-05\n",
      "Epoch 1652, Loss: 0.005501760530023603, Final Batch Loss: 0.005461833905428648\n",
      "Epoch 1653, Loss: 0.0002337588266527746, Final Batch Loss: 3.088616722379811e-05\n",
      "Epoch 1654, Loss: 0.00024385741562582552, Final Batch Loss: 2.1726475097239017e-05\n",
      "Epoch 1655, Loss: 0.0002107256732415408, Final Batch Loss: 0.00012883245653938502\n",
      "Epoch 1656, Loss: 0.0002132394874934107, Final Batch Loss: 9.3439819465857e-05\n",
      "Epoch 1657, Loss: 0.00019699249241966754, Final Batch Loss: 6.553964340128005e-05\n",
      "Epoch 1658, Loss: 0.004328070266637951, Final Batch Loss: 0.004052326548844576\n",
      "Epoch 1659, Loss: 0.006505991961603286, Final Batch Loss: 6.002809459459968e-05\n",
      "Epoch 1660, Loss: 0.007395575754344463, Final Batch Loss: 0.0037400564178824425\n",
      "Epoch 1661, Loss: 0.00019065024389419705, Final Batch Loss: 0.0001048864287440665\n",
      "Epoch 1662, Loss: 0.005943422089330852, Final Batch Loss: 0.0013950885040685534\n",
      "Epoch 1663, Loss: 0.0034245456408825703, Final Batch Loss: 5.283545033307746e-05\n",
      "Epoch 1664, Loss: 0.0004229572368785739, Final Batch Loss: 0.00021629997354466468\n",
      "Epoch 1665, Loss: 0.005141699992236681, Final Batch Loss: 0.00020422863599378616\n",
      "Epoch 1666, Loss: 0.0005410211506386986, Final Batch Loss: 1.3230112017481588e-05\n",
      "Epoch 1667, Loss: 0.0046437032615358476, Final Batch Loss: 2.065897933789529e-05\n",
      "Epoch 1668, Loss: 0.0006558567401953042, Final Batch Loss: 0.00016612827312201262\n",
      "Epoch 1669, Loss: 0.0009347531558887567, Final Batch Loss: 1.736636841087602e-05\n",
      "Epoch 1670, Loss: 0.00011741253365471493, Final Batch Loss: 2.270765799039509e-05\n",
      "Epoch 1671, Loss: 9.500840678811073e-05, Final Batch Loss: 2.2291511413641274e-05\n",
      "Epoch 1672, Loss: 0.00012193156180728693, Final Batch Loss: 0.0001003544675768353\n",
      "Epoch 1673, Loss: 0.00016467687737531378, Final Batch Loss: 4.95901394970133e-06\n",
      "Epoch 1674, Loss: 0.0003703836555359885, Final Batch Loss: 0.0002679786121007055\n",
      "Epoch 1675, Loss: 0.0003949635356548242, Final Batch Loss: 2.0231753296684474e-05\n",
      "Epoch 1676, Loss: 0.0002869853124138899, Final Batch Loss: 3.75960735254921e-05\n",
      "Epoch 1677, Loss: 0.00015719642033218406, Final Batch Loss: 5.6484346714569256e-05\n",
      "Epoch 1678, Loss: 6.216975816641934e-05, Final Batch Loss: 2.6226691261399537e-05\n",
      "Epoch 1679, Loss: 5.130801037012134e-05, Final Batch Loss: 2.9003860618104227e-05\n",
      "Epoch 1680, Loss: 0.00021650541020790115, Final Batch Loss: 0.00012799286923836917\n",
      "Epoch 1681, Loss: 0.00042274908264516853, Final Batch Loss: 3.695836858241819e-05\n",
      "Epoch 1682, Loss: 0.00011201846791664138, Final Batch Loss: 6.614626909140497e-05\n",
      "Epoch 1683, Loss: 8.496262626067619e-05, Final Batch Loss: 7.901179196778685e-05\n",
      "Epoch 1684, Loss: 0.00014570522967005672, Final Batch Loss: 2.975141114802682e-06\n",
      "Epoch 1685, Loss: 0.00020710810349555686, Final Batch Loss: 2.907493762904778e-05\n",
      "Epoch 1686, Loss: 0.00333629622036824, Final Batch Loss: 0.0032538329251110554\n",
      "Epoch 1687, Loss: 0.00025686640674393857, Final Batch Loss: 1.1474200618977193e-05\n",
      "Epoch 1688, Loss: 0.0013478542387019843, Final Batch Loss: 8.81730520632118e-05\n",
      "Epoch 1689, Loss: 0.0001137368872150546, Final Batch Loss: 9.085816418519244e-05\n",
      "Epoch 1690, Loss: 0.0010615355058689602, Final Batch Loss: 0.0009880689904093742\n",
      "Epoch 1691, Loss: 4.378258927317802e-05, Final Batch Loss: 3.1933755963109434e-05\n",
      "Epoch 1692, Loss: 0.002547872281866148, Final Batch Loss: 0.0022592206951230764\n",
      "Epoch 1693, Loss: 0.005552140068175504, Final Batch Loss: 3.643660238594748e-05\n",
      "Epoch 1694, Loss: 0.002440622500216705, Final Batch Loss: 0.002417610026896\n",
      "Epoch 1695, Loss: 0.000508817181980703, Final Batch Loss: 7.494242890970781e-05\n",
      "Epoch 1696, Loss: 0.0029110337018209975, Final Batch Loss: 7.772014214424416e-06\n",
      "Epoch 1697, Loss: 0.0011657206669042353, Final Batch Loss: 0.0011378481285646558\n",
      "Epoch 1698, Loss: 4.660364174924325e-05, Final Batch Loss: 1.6854550267453305e-05\n",
      "Epoch 1699, Loss: 0.0001295897673116997, Final Batch Loss: 3.4199161746073514e-05\n",
      "Epoch 1700, Loss: 8.058149978751317e-05, Final Batch Loss: 5.3983632824383676e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1701, Loss: 0.0003134640719508752, Final Batch Loss: 0.0001002719218377024\n",
      "Epoch 1702, Loss: 0.00045881958067184314, Final Batch Loss: 0.0003870082728099078\n",
      "Epoch 1703, Loss: 0.0017081618861993775, Final Batch Loss: 7.520346844103187e-05\n",
      "Epoch 1704, Loss: 0.00014820975775364786, Final Batch Loss: 2.0086721633560956e-05\n",
      "Epoch 1705, Loss: 9.983277959690895e-05, Final Batch Loss: 8.125259773805737e-05\n",
      "Epoch 1706, Loss: 2.2799124963057693e-05, Final Batch Loss: 9.855505595623981e-06\n",
      "Epoch 1707, Loss: 0.0002692109119379893, Final Batch Loss: 0.00023542583221569657\n",
      "Epoch 1708, Loss: 0.00030688371225551236, Final Batch Loss: 2.3257309294422157e-05\n",
      "Epoch 1709, Loss: 0.0003720932363648899, Final Batch Loss: 0.0003268683794885874\n",
      "Epoch 1710, Loss: 0.002542239901231369, Final Batch Loss: 1.6465604858240113e-05\n",
      "Epoch 1711, Loss: 0.00040241047827294096, Final Batch Loss: 7.018050382612273e-05\n",
      "Epoch 1712, Loss: 7.806551730027422e-05, Final Batch Loss: 4.154716225457378e-05\n",
      "Epoch 1713, Loss: 0.00014773829161640606, Final Batch Loss: 0.00014265740173868835\n",
      "Epoch 1714, Loss: 0.004676410391766694, Final Batch Loss: 0.0046595302410423756\n",
      "Epoch 1715, Loss: 0.0025261114205932245, Final Batch Loss: 0.0024926182813942432\n",
      "Epoch 1716, Loss: 0.0021806410659337416, Final Batch Loss: 9.609853441361338e-05\n",
      "Epoch 1717, Loss: 0.0023247451117640594, Final Batch Loss: 0.0023170814383774996\n",
      "Epoch 1718, Loss: 0.004338499682489783, Final Batch Loss: 0.004181251395493746\n",
      "Epoch 1719, Loss: 0.0026709304547694046, Final Batch Loss: 1.975520353880711e-05\n",
      "Epoch 1720, Loss: 0.00023262847389560193, Final Batch Loss: 3.346208541188389e-05\n",
      "Epoch 1721, Loss: 0.0031022595248941798, Final Batch Loss: 0.0030797480139881372\n",
      "Epoch 1722, Loss: 0.00020993868747609667, Final Batch Loss: 2.7744736144086346e-05\n",
      "Epoch 1723, Loss: 0.0022129169665277004, Final Batch Loss: 3.788899630308151e-05\n",
      "Epoch 1724, Loss: 0.000251250578003237, Final Batch Loss: 0.0002150841901311651\n",
      "Epoch 1725, Loss: 0.0029271199309732765, Final Batch Loss: 0.00012773004709742963\n",
      "Epoch 1726, Loss: 0.0025560378780937754, Final Batch Loss: 0.0025366139598190784\n",
      "Epoch 1727, Loss: 0.00030346600397024304, Final Batch Loss: 0.00019298010738566518\n",
      "Epoch 1728, Loss: 0.0001358172703476157, Final Batch Loss: 3.89767847082112e-05\n",
      "Epoch 1729, Loss: 0.0021203998767305166, Final Batch Loss: 9.93293069768697e-05\n",
      "Epoch 1730, Loss: 0.0002602033782750368, Final Batch Loss: 0.00023244366457220167\n",
      "Epoch 1731, Loss: 0.0022868899031891488, Final Batch Loss: 9.379800030728802e-05\n",
      "Epoch 1732, Loss: 0.0006612977376789786, Final Batch Loss: 2.0180224964860827e-05\n",
      "Epoch 1733, Loss: 0.0003790942319028545, Final Batch Loss: 0.0003329585015308112\n",
      "Epoch 1734, Loss: 0.0002773705491563305, Final Batch Loss: 4.398616147227585e-05\n",
      "Epoch 1735, Loss: 0.0006195147143444046, Final Batch Loss: 0.0004794326378032565\n",
      "Epoch 1736, Loss: 0.00017341454076813534, Final Batch Loss: 0.00010007101082010195\n",
      "Epoch 1737, Loss: 0.03037194861099124, Final Batch Loss: 0.006070717703551054\n",
      "Epoch 1738, Loss: 0.0024402027138421545, Final Batch Loss: 2.961416066682432e-05\n",
      "Epoch 1739, Loss: 0.00028801156440749764, Final Batch Loss: 0.00014512102643493563\n",
      "Epoch 1740, Loss: 0.0004079669015482068, Final Batch Loss: 0.00012812059139832854\n",
      "Epoch 1741, Loss: 0.00012146609697083477, Final Batch Loss: 0.00010374058183515444\n",
      "Epoch 1742, Loss: 0.00012355657236184925, Final Batch Loss: 5.009346205042675e-05\n",
      "Epoch 1743, Loss: 0.0002078876059385948, Final Batch Loss: 8.420693484367803e-05\n",
      "Epoch 1744, Loss: 0.013318950361281168, Final Batch Loss: 4.6282126277219504e-05\n",
      "Epoch 1745, Loss: 0.00016635310021229088, Final Batch Loss: 3.1789313652552664e-05\n",
      "Epoch 1746, Loss: 0.00038626196328550577, Final Batch Loss: 0.00017346862296108156\n",
      "Epoch 1747, Loss: 0.0043774902587756515, Final Batch Loss: 0.002579047344624996\n",
      "Epoch 1748, Loss: 0.004560596164083108, Final Batch Loss: 8.526569581590593e-05\n",
      "Epoch 1749, Loss: 0.00021034626115579158, Final Batch Loss: 0.0001654110092204064\n",
      "Epoch 1750, Loss: 0.004991752735804766, Final Batch Loss: 0.004415352363139391\n",
      "Epoch 1751, Loss: 0.002079969799524406, Final Batch Loss: 3.0061059078434482e-05\n",
      "Epoch 1752, Loss: 0.0007049747509881854, Final Batch Loss: 0.00034452907857485116\n",
      "Epoch 1753, Loss: 0.0008652424439787865, Final Batch Loss: 0.00040920928586274385\n",
      "Epoch 1754, Loss: 0.001247736334335059, Final Batch Loss: 0.0005775903700850904\n",
      "Epoch 1755, Loss: 0.0007631305779796094, Final Batch Loss: 0.0005028413725085557\n",
      "Epoch 1756, Loss: 0.01086035935441032, Final Batch Loss: 0.0003480679006315768\n",
      "Epoch 1757, Loss: 0.00022287081083049998, Final Batch Loss: 8.063218410825357e-05\n",
      "Epoch 1758, Loss: 0.0019985997132607736, Final Batch Loss: 8.300398621940985e-05\n",
      "Epoch 1759, Loss: 0.00016498718105140142, Final Batch Loss: 3.229501817259006e-05\n",
      "Epoch 1760, Loss: 0.0003734656929736957, Final Batch Loss: 7.432805432472378e-05\n",
      "Epoch 1761, Loss: 0.0003627053229138255, Final Batch Loss: 7.038557669147849e-05\n",
      "Epoch 1762, Loss: 0.0033220715558854863, Final Batch Loss: 0.0001748529466567561\n",
      "Epoch 1763, Loss: 0.0001232067425007699, Final Batch Loss: 0.00010199299140367657\n",
      "Epoch 1764, Loss: 0.0013803999754600227, Final Batch Loss: 0.0009204221423715353\n",
      "Epoch 1765, Loss: 0.000432433338573901, Final Batch Loss: 0.0004013442958239466\n",
      "Epoch 1766, Loss: 0.0052928433287888765, Final Batch Loss: 0.004802765790373087\n",
      "Epoch 1767, Loss: 0.004515894492215011, Final Batch Loss: 7.130092853913084e-05\n",
      "Epoch 1768, Loss: 0.0002585733454907313, Final Batch Loss: 9.206878894474357e-05\n",
      "Epoch 1769, Loss: 0.00014990149065852165, Final Batch Loss: 3.6399556847754866e-05\n",
      "Epoch 1770, Loss: 0.02285973314428702, Final Batch Loss: 0.022257480770349503\n",
      "Epoch 1771, Loss: 0.0021672170551028103, Final Batch Loss: 0.0003026005288120359\n",
      "Epoch 1772, Loss: 0.0037421745364554226, Final Batch Loss: 0.00012939918087795377\n",
      "Epoch 1773, Loss: 0.004094376148714218, Final Batch Loss: 6.440506695071235e-05\n",
      "Epoch 1774, Loss: 0.0043376962712500244, Final Batch Loss: 0.003995019011199474\n",
      "Epoch 1775, Loss: 0.0004518308414844796, Final Batch Loss: 0.00019944905943702906\n",
      "Epoch 1776, Loss: 0.000352931790985167, Final Batch Loss: 0.0003039992006961256\n",
      "Epoch 1777, Loss: 0.01589607127243653, Final Batch Loss: 0.01552825327962637\n",
      "Epoch 1778, Loss: 0.00041669134225230664, Final Batch Loss: 0.00019723543664440513\n",
      "Epoch 1779, Loss: 8.793705092102755e-05, Final Batch Loss: 7.38167145755142e-05\n",
      "Epoch 1780, Loss: 0.0005895025824429467, Final Batch Loss: 0.00021440042473841459\n",
      "Epoch 1781, Loss: 0.0001353297211608151, Final Batch Loss: 2.8679229217232205e-05\n",
      "Epoch 1782, Loss: 0.008424109313637018, Final Batch Loss: 0.004123372491449118\n",
      "Epoch 1783, Loss: 4.647731270779332e-05, Final Batch Loss: 4.277923653717153e-05\n",
      "Epoch 1784, Loss: 0.0008256489818450063, Final Batch Loss: 0.0006098452722653747\n",
      "Epoch 1785, Loss: 0.029603638904518448, Final Batch Loss: 0.029454998672008514\n",
      "Epoch 1786, Loss: 0.00013896098244003952, Final Batch Loss: 4.0022052417043597e-05\n",
      "Epoch 1787, Loss: 0.0029540106479544193, Final Batch Loss: 0.0027905458118766546\n",
      "Epoch 1788, Loss: 0.004363383472082205, Final Batch Loss: 0.0002010244206758216\n",
      "Epoch 1789, Loss: 0.00025772740627871826, Final Batch Loss: 0.00010790974920382723\n",
      "Epoch 1790, Loss: 0.0019985277322120965, Final Batch Loss: 0.0017281814943999052\n",
      "Epoch 1791, Loss: 0.0009910281951306388, Final Batch Loss: 0.0001748283248161897\n",
      "Epoch 1792, Loss: 0.0022803942074460792, Final Batch Loss: 1.2307088582019787e-05\n",
      "Epoch 1793, Loss: 0.00018634237494552508, Final Batch Loss: 9.844242595136166e-05\n",
      "Epoch 1794, Loss: 0.00016992466771625914, Final Batch Loss: 5.779467392130755e-05\n",
      "Epoch 1795, Loss: 0.0001146992108260747, Final Batch Loss: 1.9466726371319965e-05\n",
      "Epoch 1796, Loss: 0.0003623578777478542, Final Batch Loss: 4.55795343441423e-05\n",
      "Epoch 1797, Loss: 0.00014829137217020616, Final Batch Loss: 6.521473551401868e-05\n",
      "Epoch 1798, Loss: 0.0002220444002887234, Final Batch Loss: 4.73900290671736e-05\n",
      "Epoch 1799, Loss: 0.003331398984300904, Final Batch Loss: 0.0032439236529171467\n",
      "Epoch 1800, Loss: 0.00013007674351683818, Final Batch Loss: 8.327831164933741e-05\n",
      "Epoch 1801, Loss: 5.2911329476046376e-05, Final Batch Loss: 3.448802817729302e-05\n",
      "Epoch 1802, Loss: 0.00017729297178448178, Final Batch Loss: 0.0001413686404703185\n",
      "Epoch 1803, Loss: 0.000356714570443728, Final Batch Loss: 1.6073327060439624e-05\n",
      "Epoch 1804, Loss: 0.00022733987134415656, Final Batch Loss: 0.0001891192077891901\n",
      "Epoch 1805, Loss: 0.00017686003047856502, Final Batch Loss: 5.10334903083276e-05\n",
      "Epoch 1806, Loss: 0.0027497367264004424, Final Batch Loss: 0.0026875725015997887\n",
      "Epoch 1807, Loss: 0.00018997413280885667, Final Batch Loss: 8.701607293915004e-05\n",
      "Epoch 1808, Loss: 0.004547283484498621, Final Batch Loss: 1.1212157914997078e-05\n",
      "Epoch 1809, Loss: 0.0009882052399916574, Final Batch Loss: 0.00019779933791141957\n",
      "Epoch 1810, Loss: 0.00011732750499504618, Final Batch Loss: 5.571782457991503e-05\n",
      "Epoch 1811, Loss: 0.00010957045742543414, Final Batch Loss: 3.316377114970237e-05\n",
      "Epoch 1812, Loss: 0.00032547293812967837, Final Batch Loss: 0.00021394510986283422\n",
      "Epoch 1813, Loss: 0.00043727455340558663, Final Batch Loss: 9.868419874692336e-05\n",
      "Epoch 1814, Loss: 0.0003482654137769714, Final Batch Loss: 0.0002786552649922669\n",
      "Epoch 1815, Loss: 0.00013366644270718098, Final Batch Loss: 6.342573033180088e-05\n",
      "Epoch 1816, Loss: 0.00012082990906492341, Final Batch Loss: 2.5941191779565997e-05\n",
      "Epoch 1817, Loss: 0.0026538356105447747, Final Batch Loss: 0.0026373490691184998\n",
      "Epoch 1818, Loss: 0.0035637347464216873, Final Batch Loss: 0.0034361130092293024\n",
      "Epoch 1819, Loss: 0.002122730322298594, Final Batch Loss: 0.0020270594395697117\n",
      "Epoch 1820, Loss: 0.006154151404189179, Final Batch Loss: 0.006097016390413046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1821, Loss: 0.00014346895113703795, Final Batch Loss: 4.374137279228307e-05\n",
      "Epoch 1822, Loss: 0.00021275923791108653, Final Batch Loss: 0.00010496425238670781\n",
      "Epoch 1823, Loss: 0.000330466493323911, Final Batch Loss: 0.0002643133047968149\n",
      "Epoch 1824, Loss: 0.006765129044651985, Final Batch Loss: 0.0031099203042685986\n",
      "Epoch 1825, Loss: 0.008186923529137857, Final Batch Loss: 0.008122741244733334\n",
      "Epoch 1826, Loss: 0.00236657184723299, Final Batch Loss: 0.00018366675067227334\n",
      "Epoch 1827, Loss: 0.00012875239735876676, Final Batch Loss: 2.5130224457825534e-05\n",
      "Epoch 1828, Loss: 0.005618931259959936, Final Batch Loss: 0.003131947945803404\n",
      "Epoch 1829, Loss: 0.0013887198501834064, Final Batch Loss: 1.4470037967839744e-05\n",
      "Epoch 1830, Loss: 0.003952943383410457, Final Batch Loss: 2.0945108190062456e-05\n",
      "Epoch 1831, Loss: 4.705088736045582e-05, Final Batch Loss: 4.4352622353471816e-05\n",
      "Epoch 1832, Loss: 0.00024252622461062856, Final Batch Loss: 0.00021791021572425961\n",
      "Epoch 1833, Loss: 8.802046613709535e-05, Final Batch Loss: 6.140095501905307e-05\n",
      "Epoch 1834, Loss: 0.00018688730051508173, Final Batch Loss: 0.00013575259072240442\n",
      "Epoch 1835, Loss: 0.0029669749055756256, Final Batch Loss: 3.921710595022887e-05\n",
      "Epoch 1836, Loss: 0.005366440862417221, Final Batch Loss: 0.002549294847995043\n",
      "Epoch 1837, Loss: 0.01681803540850524, Final Batch Loss: 0.00020337665046099573\n",
      "Epoch 1838, Loss: 0.002421435601718258, Final Batch Loss: 4.2764404497575015e-05\n",
      "Epoch 1839, Loss: 0.00010695807577576488, Final Batch Loss: 3.302512050140649e-05\n",
      "Epoch 1840, Loss: 0.00029755174182355404, Final Batch Loss: 0.00016747058543842286\n",
      "Epoch 1841, Loss: 0.002325340930838138, Final Batch Loss: 0.00015187409007921815\n",
      "Epoch 1842, Loss: 0.00028934841975569725, Final Batch Loss: 6.944249616935849e-05\n",
      "Epoch 1843, Loss: 0.0146956249482173, Final Batch Loss: 0.014672810211777687\n",
      "Epoch 1844, Loss: 0.000992675300949486, Final Batch Loss: 0.0009561204351484776\n",
      "Epoch 1845, Loss: 0.001961983120054356, Final Batch Loss: 2.947597204183694e-05\n",
      "Epoch 1846, Loss: 0.00019254991639172658, Final Batch Loss: 9.536118159303442e-05\n",
      "Epoch 1847, Loss: 0.003603942575864494, Final Batch Loss: 0.0002063446445390582\n",
      "Epoch 1848, Loss: 0.008778042858466506, Final Batch Loss: 0.0038720385637134314\n",
      "Epoch 1849, Loss: 0.00010830007886397652, Final Batch Loss: 4.571181852952577e-05\n",
      "Epoch 1850, Loss: 0.007357849506661296, Final Batch Loss: 0.0034284356515854597\n",
      "Epoch 1851, Loss: 0.0026136299566132948, Final Batch Loss: 0.002438695402815938\n",
      "Epoch 1852, Loss: 0.003013874404132366, Final Batch Loss: 0.0002629389055073261\n",
      "Epoch 1853, Loss: 0.0006299357919488102, Final Batch Loss: 0.0002428677980788052\n",
      "Epoch 1854, Loss: 0.0026982886702171527, Final Batch Loss: 7.678116526221856e-05\n",
      "Epoch 1855, Loss: 0.00011467348667792976, Final Batch Loss: 4.1677783883642405e-05\n",
      "Epoch 1856, Loss: 0.00032452086088596843, Final Batch Loss: 0.00030832309857942164\n",
      "Epoch 1857, Loss: 0.0004822390474146232, Final Batch Loss: 5.174257967155427e-05\n",
      "Epoch 1858, Loss: 0.0006676008488284424, Final Batch Loss: 0.0005320469499565661\n",
      "Epoch 1859, Loss: 0.017981853801757097, Final Batch Loss: 0.001529949251562357\n",
      "Epoch 1860, Loss: 0.00023553267237730324, Final Batch Loss: 6.559869507327676e-05\n",
      "Epoch 1861, Loss: 0.00507960791583173, Final Batch Loss: 0.0004363585903774947\n",
      "Epoch 1862, Loss: 0.0018652648504939862, Final Batch Loss: 7.809384987922385e-05\n",
      "Epoch 1863, Loss: 0.0005071386112831533, Final Batch Loss: 0.00016931351274251938\n",
      "Epoch 1864, Loss: 0.0008506968297297135, Final Batch Loss: 0.00014490711328107864\n",
      "Epoch 1865, Loss: 0.003106580552412197, Final Batch Loss: 0.00031239070813171566\n",
      "Epoch 1866, Loss: 0.0012931212258990854, Final Batch Loss: 5.365462857298553e-05\n",
      "Epoch 1867, Loss: 0.0024253424089693, Final Batch Loss: 1.729683208395727e-05\n",
      "Epoch 1868, Loss: 0.0018093381368089467, Final Batch Loss: 0.0014840702060610056\n",
      "Epoch 1869, Loss: 0.00025286721938755363, Final Batch Loss: 5.6766351917758584e-05\n",
      "Epoch 1870, Loss: 0.00013435399887384847, Final Batch Loss: 0.00011847618588944897\n",
      "Epoch 1871, Loss: 0.0011294386931695044, Final Batch Loss: 0.0009999993490055203\n",
      "Epoch 1872, Loss: 0.002022864471655339, Final Batch Loss: 0.00013790634693577886\n",
      "Epoch 1873, Loss: 0.00029165163141442463, Final Batch Loss: 8.98364742170088e-05\n",
      "Epoch 1874, Loss: 0.004832490318221971, Final Batch Loss: 0.00013008105452172458\n",
      "Epoch 1875, Loss: 0.0020368536934256554, Final Batch Loss: 0.0018732494208961725\n",
      "Epoch 1876, Loss: 0.000556131184566766, Final Batch Loss: 0.00023252054234035313\n",
      "Epoch 1877, Loss: 0.003817351935140323, Final Batch Loss: 0.0037572572473436594\n",
      "Epoch 1878, Loss: 0.00032104571073432453, Final Batch Loss: 5.4495776566909626e-05\n",
      "Epoch 1879, Loss: 0.0006497631256934255, Final Batch Loss: 0.0004361275350674987\n",
      "Epoch 1880, Loss: 0.001657308512221789, Final Batch Loss: 3.6769397411262617e-05\n",
      "Epoch 1881, Loss: 0.002663939267222304, Final Batch Loss: 0.002551047829911113\n",
      "Epoch 1882, Loss: 0.0014866278506815434, Final Batch Loss: 0.0006897578714415431\n",
      "Epoch 1883, Loss: 0.0002400277771812398, Final Batch Loss: 0.00019432547560427338\n",
      "Epoch 1884, Loss: 0.0011503192799864337, Final Batch Loss: 0.00013238952669780701\n",
      "Epoch 1885, Loss: 0.003156823840981815, Final Batch Loss: 9.52340560615994e-05\n",
      "Epoch 1886, Loss: 0.002780124392302241, Final Batch Loss: 9.509742812952027e-05\n",
      "Epoch 1887, Loss: 0.0004984030092600733, Final Batch Loss: 0.00024782505352050066\n",
      "Epoch 1888, Loss: 0.0005778583727078512, Final Batch Loss: 3.949385427404195e-05\n",
      "Epoch 1889, Loss: 0.0002854445410775952, Final Batch Loss: 4.109093424631283e-05\n",
      "Epoch 1890, Loss: 0.0001517259661341086, Final Batch Loss: 6.648431735811755e-05\n",
      "Epoch 1891, Loss: 0.0006606264796573669, Final Batch Loss: 0.00014810115681029856\n",
      "Epoch 1892, Loss: 0.008118434576317668, Final Batch Loss: 0.0055333394557237625\n",
      "Epoch 1893, Loss: 0.0002509201040084008, Final Batch Loss: 0.00019395943672861904\n",
      "Epoch 1894, Loss: 0.002322852218640037, Final Batch Loss: 0.00012448460620362312\n",
      "Epoch 1895, Loss: 0.0021674697345588356, Final Batch Loss: 9.870334179140627e-05\n",
      "Epoch 1896, Loss: 0.0003311016407678835, Final Batch Loss: 4.9043439503293484e-05\n",
      "Epoch 1897, Loss: 0.0005686443910235539, Final Batch Loss: 0.000479433307191357\n",
      "Epoch 1898, Loss: 0.003721124114235863, Final Batch Loss: 0.0035527546424418688\n",
      "Epoch 1899, Loss: 0.0002902860433096066, Final Batch Loss: 0.00012691359734162688\n",
      "Epoch 1900, Loss: 0.00035292944085085765, Final Batch Loss: 0.0002400238299742341\n",
      "Epoch 1901, Loss: 7.337475108215585e-05, Final Batch Loss: 6.095854769228026e-05\n",
      "Epoch 1902, Loss: 0.007313722555409186, Final Batch Loss: 0.007069820072501898\n",
      "Epoch 1903, Loss: 7.714948515058495e-05, Final Batch Loss: 4.4340766180539504e-05\n",
      "Epoch 1904, Loss: 0.00016480530757689849, Final Batch Loss: 0.00012976236757822335\n",
      "Epoch 1905, Loss: 6.276707063079812e-05, Final Batch Loss: 2.7146008505951613e-05\n",
      "Epoch 1906, Loss: 0.0005517537961168273, Final Batch Loss: 0.0005451198085211217\n",
      "Epoch 1907, Loss: 0.00020879661769868108, Final Batch Loss: 1.045308181346627e-05\n",
      "Epoch 1908, Loss: 0.00419160071760416, Final Batch Loss: 0.002130266511812806\n",
      "Epoch 1909, Loss: 0.0003579532203730196, Final Batch Loss: 0.00012334542407188565\n",
      "Epoch 1910, Loss: 0.00025847586221061647, Final Batch Loss: 8.447442087344825e-05\n",
      "Epoch 1911, Loss: 0.0028555603785207495, Final Batch Loss: 5.291202978696674e-05\n",
      "Epoch 1912, Loss: 0.004054702731082216, Final Batch Loss: 6.067697540856898e-05\n",
      "Epoch 1913, Loss: 0.002571583754615858, Final Batch Loss: 0.00010220569674856961\n",
      "Epoch 1914, Loss: 6.855619903944898e-05, Final Batch Loss: 5.719559339922853e-06\n",
      "Epoch 1915, Loss: 0.00020097618107683957, Final Batch Loss: 0.000115699898742605\n",
      "Epoch 1916, Loss: 2.5726796593517065e-05, Final Batch Loss: 1.3992124877404422e-05\n",
      "Epoch 1917, Loss: 0.002293798577738926, Final Batch Loss: 0.00012105421046726406\n",
      "Epoch 1918, Loss: 0.0036147004429949448, Final Batch Loss: 4.0242026443593204e-05\n",
      "Epoch 1919, Loss: 0.0002692758171178866, Final Batch Loss: 0.00021816228399984539\n",
      "Epoch 1920, Loss: 0.000299880382954143, Final Batch Loss: 6.269122241064906e-05\n",
      "Epoch 1921, Loss: 0.0029995527784194564, Final Batch Loss: 0.0029787132516503334\n",
      "Epoch 1922, Loss: 0.0016241265384451253, Final Batch Loss: 2.295159902132582e-05\n",
      "Epoch 1923, Loss: 0.000443598153651692, Final Batch Loss: 0.00014078141248319298\n",
      "Epoch 1924, Loss: 0.00024223113723564893, Final Batch Loss: 0.000124954545754008\n",
      "Epoch 1925, Loss: 0.002647217479534447, Final Batch Loss: 0.002428671345114708\n",
      "Epoch 1926, Loss: 0.00030080906981311273, Final Batch Loss: 0.00027691549621522427\n",
      "Epoch 1927, Loss: 0.0026344209327362478, Final Batch Loss: 0.002399410819634795\n",
      "Epoch 1928, Loss: 0.000247157018748112, Final Batch Loss: 0.0001300779840676114\n",
      "Epoch 1929, Loss: 0.0009443033486604691, Final Batch Loss: 0.0006001100991852582\n",
      "Epoch 1930, Loss: 0.00023429776774719357, Final Batch Loss: 0.00012356134539004415\n",
      "Epoch 1931, Loss: 0.00012900118235847913, Final Batch Loss: 0.00012023425369989127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1932, Loss: 0.00020288203086238354, Final Batch Loss: 0.00011045471183024347\n",
      "Epoch 1933, Loss: 0.0008041025212150998, Final Batch Loss: 4.9322501581627876e-05\n",
      "Epoch 1934, Loss: 0.0001544964688946493, Final Batch Loss: 4.481980431592092e-05\n",
      "Epoch 1935, Loss: 0.00029544340213760734, Final Batch Loss: 0.00014412410382647067\n",
      "Epoch 1936, Loss: 6.496401692857035e-05, Final Batch Loss: 2.4402404960710555e-05\n",
      "Epoch 1937, Loss: 0.0024737407875363715, Final Batch Loss: 0.00010878145258175209\n",
      "Epoch 1938, Loss: 0.0018538514414103702, Final Batch Loss: 4.9320820835419e-05\n",
      "Epoch 1939, Loss: 0.00022789907961850986, Final Batch Loss: 0.00017925350402947515\n",
      "Epoch 1940, Loss: 0.00027575684725889005, Final Batch Loss: 5.5333806812996045e-05\n",
      "Epoch 1941, Loss: 4.459101273823762e-05, Final Batch Loss: 3.12234005832579e-05\n",
      "Epoch 1942, Loss: 0.00012686304762610234, Final Batch Loss: 0.00010256734094582498\n",
      "Epoch 1943, Loss: 0.007943795470055193, Final Batch Loss: 0.007657149340957403\n",
      "Epoch 1944, Loss: 0.002452711527439533, Final Batch Loss: 0.0024191318079829216\n",
      "Epoch 1945, Loss: 0.00017008307622745633, Final Batch Loss: 9.498055442236364e-05\n",
      "Epoch 1946, Loss: 0.008965277345851064, Final Batch Loss: 0.003206192282959819\n",
      "Epoch 1947, Loss: 0.0002627163048600778, Final Batch Loss: 0.0001330416853306815\n",
      "Epoch 1948, Loss: 0.004318253835663199, Final Batch Loss: 0.0007011971902102232\n",
      "Epoch 1949, Loss: 0.004394108953420073, Final Batch Loss: 0.0042289127595722675\n",
      "Epoch 1950, Loss: 0.00031688393210060894, Final Batch Loss: 0.00013847611262463033\n",
      "Epoch 1951, Loss: 0.0002422259858576581, Final Batch Loss: 0.00013179636152926832\n",
      "Epoch 1952, Loss: 0.0032539025851292536, Final Batch Loss: 3.023938916157931e-05\n",
      "Epoch 1953, Loss: 0.0008712169001228176, Final Batch Loss: 0.0008316060993820429\n",
      "Epoch 1954, Loss: 0.0006423887425626162, Final Batch Loss: 3.2887128327274695e-05\n",
      "Epoch 1955, Loss: 0.004087442946911324, Final Batch Loss: 0.004044016357511282\n",
      "Epoch 1956, Loss: 0.0033811911025622976, Final Batch Loss: 1.222551964019658e-05\n",
      "Epoch 1957, Loss: 0.00017963202117243782, Final Batch Loss: 9.079136361833662e-05\n",
      "Epoch 1958, Loss: 0.000182661933649797, Final Batch Loss: 0.00012261619849596173\n",
      "Epoch 1959, Loss: 0.003298789513792144, Final Batch Loss: 0.0032727201469242573\n",
      "Epoch 1960, Loss: 0.006725411338265985, Final Batch Loss: 0.005823124200105667\n",
      "Epoch 1961, Loss: 0.00030956636328483, Final Batch Loss: 0.00020055368077009916\n",
      "Epoch 1962, Loss: 8.30891185614746e-05, Final Batch Loss: 6.949221278773621e-05\n",
      "Epoch 1963, Loss: 0.023510787839768454, Final Batch Loss: 0.02324427105486393\n",
      "Epoch 1964, Loss: 3.320463702038978e-05, Final Batch Loss: 3.10227187583223e-05\n",
      "Epoch 1965, Loss: 9.803111606743187e-05, Final Batch Loss: 4.931707007926889e-05\n",
      "Epoch 1966, Loss: 0.000557771920284722, Final Batch Loss: 0.0004596211656462401\n",
      "Epoch 1967, Loss: 0.0004761047166539356, Final Batch Loss: 0.0002408747241133824\n",
      "Epoch 1968, Loss: 0.022520507525769062, Final Batch Loss: 0.022365329787135124\n",
      "Epoch 1969, Loss: 0.0050314892214373685, Final Batch Loss: 7.407312659779564e-05\n",
      "Epoch 1970, Loss: 0.00029456152697093785, Final Batch Loss: 0.00012389592302497476\n",
      "Epoch 1971, Loss: 0.005269489949569106, Final Batch Loss: 0.0021813223138451576\n",
      "Epoch 1972, Loss: 0.0007496467442251742, Final Batch Loss: 0.0006170019623823464\n",
      "Epoch 1973, Loss: 0.00031345793831860647, Final Batch Loss: 0.0001105587653000839\n",
      "Epoch 1974, Loss: 0.0015934013936202973, Final Batch Loss: 0.001191485789604485\n",
      "Epoch 1975, Loss: 0.0005066109733888879, Final Batch Loss: 0.00022203275875654072\n",
      "Epoch 1976, Loss: 0.00027991929891868494, Final Batch Loss: 2.0608884369721636e-05\n",
      "Epoch 1977, Loss: 0.0003782078711083159, Final Batch Loss: 0.00013061474601272494\n",
      "Epoch 1978, Loss: 0.0004038034239783883, Final Batch Loss: 0.00015523747424595058\n",
      "Epoch 1979, Loss: 0.0004991898313164711, Final Batch Loss: 0.00026356836315244436\n",
      "Epoch 1980, Loss: 0.0031620601075701416, Final Batch Loss: 0.002792994724586606\n",
      "Epoch 1981, Loss: 0.002814954761561239, Final Batch Loss: 0.002765088342130184\n",
      "Epoch 1982, Loss: 0.006582299123692792, Final Batch Loss: 0.006502874661237001\n",
      "Epoch 1983, Loss: 0.0015027745084807975, Final Batch Loss: 0.0014859505463391542\n",
      "Epoch 1984, Loss: 0.00569530762732029, Final Batch Loss: 0.003098334651440382\n",
      "Epoch 1985, Loss: 0.0007926929974928498, Final Batch Loss: 0.00039711411227472126\n",
      "Epoch 1986, Loss: 8.209736188291572e-05, Final Batch Loss: 3.4859622246585786e-05\n",
      "Epoch 1987, Loss: 0.0011234647390665486, Final Batch Loss: 0.0009847045876085758\n",
      "Epoch 1988, Loss: 0.0002674364441190846, Final Batch Loss: 0.0002161951852031052\n",
      "Epoch 1989, Loss: 0.0001839035321609117, Final Batch Loss: 8.015836647246033e-05\n",
      "Epoch 1990, Loss: 0.004491753948968835, Final Batch Loss: 6.72485475661233e-05\n",
      "Epoch 1991, Loss: 0.0003378959372639656, Final Batch Loss: 0.0003083320625592023\n",
      "Epoch 1992, Loss: 6.284435403358657e-05, Final Batch Loss: 2.6559036996331997e-05\n",
      "Epoch 1993, Loss: 0.008195645030355081, Final Batch Loss: 0.007951606996357441\n",
      "Epoch 1994, Loss: 7.86711952969199e-05, Final Batch Loss: 2.2586356863030232e-05\n",
      "Epoch 1995, Loss: 0.0008207517385017127, Final Batch Loss: 0.0007137641659937799\n",
      "Epoch 1996, Loss: 0.005155175116669852, Final Batch Loss: 0.005068715661764145\n",
      "Epoch 1997, Loss: 0.002874812431400642, Final Batch Loss: 0.00013365861377678812\n",
      "Epoch 1998, Loss: 0.00016673288337187842, Final Batch Loss: 0.00010235558147542179\n",
      "Epoch 1999, Loss: 0.0015936373092699796, Final Batch Loss: 8.719033212400973e-05\n",
      "Epoch 2000, Loss: 0.012055146435159259, Final Batch Loss: 0.01182522065937519\n",
      "Epoch 2001, Loss: 0.003193033756360819, Final Batch Loss: 1.377555508952355e-05\n",
      "Epoch 2002, Loss: 0.002973660477437079, Final Batch Loss: 0.0028278520330786705\n",
      "Epoch 2003, Loss: 0.0005343853554222733, Final Batch Loss: 0.0003907637146767229\n",
      "Epoch 2004, Loss: 0.0005859543962287717, Final Batch Loss: 9.447748743696138e-05\n",
      "Epoch 2005, Loss: 0.001867644698904769, Final Batch Loss: 0.0018544337945058942\n",
      "Epoch 2006, Loss: 0.00012311600585235283, Final Batch Loss: 5.795538891106844e-05\n",
      "Epoch 2007, Loss: 0.00015573130804114044, Final Batch Loss: 0.00011904974962817505\n",
      "Epoch 2008, Loss: 2.6295845600543544e-05, Final Batch Loss: 1.744155269989278e-05\n",
      "Epoch 2009, Loss: 0.0002233650848211255, Final Batch Loss: 0.00016796973068267107\n",
      "Epoch 2010, Loss: 0.0002605787158245221, Final Batch Loss: 0.00010388670489192009\n",
      "Epoch 2011, Loss: 0.0019213318346373853, Final Batch Loss: 1.3351415873330552e-05\n",
      "Epoch 2012, Loss: 0.0022738543775631115, Final Batch Loss: 0.002262857975438237\n",
      "Epoch 2013, Loss: 0.0002480894145264756, Final Batch Loss: 4.089130015927367e-05\n",
      "Epoch 2014, Loss: 7.598200863867532e-05, Final Batch Loss: 5.567140397033654e-05\n",
      "Epoch 2015, Loss: 0.0012067448296875227, Final Batch Loss: 5.901059557800181e-05\n",
      "Epoch 2016, Loss: 0.002138757994543994, Final Batch Loss: 5.2678082283819094e-05\n",
      "Epoch 2017, Loss: 4.2876872612396255e-05, Final Batch Loss: 2.5592977181077003e-05\n",
      "Epoch 2018, Loss: 0.0003634423774201423, Final Batch Loss: 0.00018061762966681272\n",
      "Epoch 2019, Loss: 0.0002109655533786281, Final Batch Loss: 1.249090473720571e-05\n",
      "Epoch 2020, Loss: 0.00024215847224695608, Final Batch Loss: 0.0001460832718294114\n",
      "Epoch 2021, Loss: 0.00039838576049078256, Final Batch Loss: 0.00010515553003642708\n",
      "Epoch 2022, Loss: 0.002446637317916611, Final Batch Loss: 0.002413053996860981\n",
      "Epoch 2023, Loss: 0.0022559519384230953, Final Batch Loss: 2.70693089987617e-05\n",
      "Epoch 2024, Loss: 0.007217277750896756, Final Batch Loss: 0.0071359421126544476\n",
      "Epoch 2025, Loss: 0.0021998548472765833, Final Batch Loss: 0.002151366788893938\n",
      "Epoch 2026, Loss: 0.00516828871332109, Final Batch Loss: 0.0026604351587593555\n",
      "Epoch 2027, Loss: 0.001955926614755299, Final Batch Loss: 0.0001139095620601438\n",
      "Epoch 2028, Loss: 8.291048652608879e-05, Final Batch Loss: 6.359861436067149e-05\n",
      "Epoch 2029, Loss: 0.00022419452579924837, Final Batch Loss: 3.853264934150502e-05\n",
      "Epoch 2030, Loss: 0.00021883712179260328, Final Batch Loss: 0.00011379296483937651\n",
      "Epoch 2031, Loss: 0.00019820124725811183, Final Batch Loss: 8.537537360098213e-05\n",
      "Epoch 2032, Loss: 0.00017523615679237992, Final Batch Loss: 8.513325883541256e-05\n",
      "Epoch 2033, Loss: 0.00018203982472186908, Final Batch Loss: 0.00014733252464793622\n",
      "Epoch 2034, Loss: 0.0032013823511078954, Final Batch Loss: 0.0016159864608198404\n",
      "Epoch 2035, Loss: 0.005071700794360368, Final Batch Loss: 2.3457465431420133e-05\n",
      "Epoch 2036, Loss: 0.0033252177527174354, Final Batch Loss: 0.0017454858170822263\n",
      "Epoch 2037, Loss: 0.002711999939492671, Final Batch Loss: 2.1751748136011884e-05\n",
      "Epoch 2038, Loss: 0.002021064548898721, Final Batch Loss: 4.131466630497016e-05\n",
      "Epoch 2039, Loss: 0.00017215985644725151, Final Batch Loss: 4.7420882765436545e-05\n",
      "Epoch 2040, Loss: 0.0025741023127920926, Final Batch Loss: 0.0022897974122315645\n",
      "Epoch 2041, Loss: 0.0003747197042685002, Final Batch Loss: 0.0003305267309769988\n",
      "Epoch 2042, Loss: 0.00028008586377836764, Final Batch Loss: 5.229635280556977e-05\n",
      "Epoch 2043, Loss: 0.0014666132285583444, Final Batch Loss: 3.4335191685386235e-06\n",
      "Epoch 2044, Loss: 0.0035248918138677254, Final Batch Loss: 5.1445342251099646e-05\n",
      "Epoch 2045, Loss: 0.0003018278389390616, Final Batch Loss: 0.00029794510919600725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2046, Loss: 0.001993353151192423, Final Batch Loss: 0.0019037035526707768\n",
      "Epoch 2047, Loss: 0.0015531073031525011, Final Batch Loss: 1.1308368812024128e-05\n",
      "Epoch 2048, Loss: 0.0023829961573937908, Final Batch Loss: 0.0021653911098837852\n",
      "Epoch 2049, Loss: 0.00013279194536153227, Final Batch Loss: 7.102597010089085e-05\n",
      "Epoch 2050, Loss: 0.004158449783062679, Final Batch Loss: 0.004138210788369179\n",
      "Epoch 2051, Loss: 0.001009739498840645, Final Batch Loss: 7.211350020952523e-05\n",
      "Epoch 2052, Loss: 0.00016159298684215173, Final Batch Loss: 1.0874740837607533e-05\n",
      "Epoch 2053, Loss: 0.0020345629236544482, Final Batch Loss: 4.9016256525646895e-05\n",
      "Epoch 2054, Loss: 0.0059879863110836595, Final Batch Loss: 0.005778361577540636\n",
      "Epoch 2055, Loss: 0.00010434012619953137, Final Batch Loss: 1.70603070728248e-05\n",
      "Epoch 2056, Loss: 4.4079526560381055e-05, Final Batch Loss: 1.0809519153553993e-05\n",
      "Epoch 2057, Loss: 0.003251017798902467, Final Batch Loss: 0.003061722731217742\n",
      "Epoch 2058, Loss: 0.0012527705657703336, Final Batch Loss: 3.544360151863657e-05\n",
      "Epoch 2059, Loss: 0.000174558028447791, Final Batch Loss: 2.6690109734772705e-05\n",
      "Epoch 2060, Loss: 0.004239146206600708, Final Batch Loss: 0.004227671772241592\n",
      "Epoch 2061, Loss: 5.392206094256835e-05, Final Batch Loss: 1.0130869668500964e-05\n",
      "Epoch 2062, Loss: 0.0026342257333453745, Final Batch Loss: 0.0025690165348351\n",
      "Epoch 2063, Loss: 4.437988536665216e-05, Final Batch Loss: 3.412780642975122e-05\n",
      "Epoch 2064, Loss: 8.430912748735864e-05, Final Batch Loss: 2.94112123810919e-05\n",
      "Epoch 2065, Loss: 0.0019967545740655623, Final Batch Loss: 9.772847261046991e-05\n",
      "Epoch 2066, Loss: 0.00019670836445584428, Final Batch Loss: 0.00017007160931825638\n",
      "Epoch 2067, Loss: 0.0024741976521909237, Final Batch Loss: 0.0018031856743618846\n",
      "Epoch 2068, Loss: 0.00021455741807585582, Final Batch Loss: 2.8440124879125506e-05\n",
      "Epoch 2069, Loss: 0.0002601442138256971, Final Batch Loss: 5.2684747060993686e-05\n",
      "Epoch 2070, Loss: 0.004279670654796064, Final Batch Loss: 0.003004129510372877\n",
      "Epoch 2071, Loss: 0.00019475290173431858, Final Batch Loss: 0.0001749257935443893\n",
      "Epoch 2072, Loss: 7.833494419173803e-05, Final Batch Loss: 5.187440547160804e-05\n",
      "Epoch 2073, Loss: 7.835892301955028e-05, Final Batch Loss: 6.365446461131796e-05\n",
      "Epoch 2074, Loss: 0.008236694149672985, Final Batch Loss: 0.0041593266651034355\n",
      "Epoch 2075, Loss: 8.885446368367411e-05, Final Batch Loss: 1.3330460205907002e-05\n",
      "Epoch 2076, Loss: 0.0020412376179592684, Final Batch Loss: 5.6443692301400006e-05\n",
      "Epoch 2077, Loss: 0.0013946170693088789, Final Batch Loss: 0.0013769201468676329\n",
      "Epoch 2078, Loss: 0.0009707012977742124, Final Batch Loss: 4.078251731698401e-05\n",
      "Epoch 2079, Loss: 0.0015658250486012548, Final Batch Loss: 0.00012780373799614608\n",
      "Epoch 2080, Loss: 0.003026332320587244, Final Batch Loss: 0.003009179374203086\n",
      "Epoch 2081, Loss: 0.00011607155101955868, Final Batch Loss: 6.814060907345265e-05\n",
      "Epoch 2082, Loss: 0.00010250658851873595, Final Batch Loss: 9.375981608172879e-05\n",
      "Epoch 2083, Loss: 0.0016479428159072995, Final Batch Loss: 0.00023215555120259523\n",
      "Epoch 2084, Loss: 0.00021891257529205177, Final Batch Loss: 2.0110086552449502e-05\n",
      "Epoch 2085, Loss: 0.0001922680385177955, Final Batch Loss: 8.190620428649709e-05\n",
      "Epoch 2086, Loss: 5.7162191296811216e-05, Final Batch Loss: 3.978543099947274e-05\n",
      "Epoch 2087, Loss: 5.011686334910337e-05, Final Batch Loss: 1.6770953152445145e-05\n",
      "Epoch 2088, Loss: 6.39646914351033e-05, Final Batch Loss: 4.9938709707930684e-05\n",
      "Epoch 2089, Loss: 0.00013975937326904386, Final Batch Loss: 6.344992289086804e-05\n",
      "Epoch 2090, Loss: 0.0014457008510362357, Final Batch Loss: 0.0013638755772262812\n",
      "Epoch 2091, Loss: 0.00010865982039831579, Final Batch Loss: 8.370037539862096e-05\n",
      "Epoch 2092, Loss: 0.010887392796576023, Final Batch Loss: 0.009096643887460232\n",
      "Epoch 2093, Loss: 0.00010604852286633104, Final Batch Loss: 6.569169636350125e-05\n",
      "Epoch 2094, Loss: 9.409262111148564e-05, Final Batch Loss: 8.301701745949686e-05\n",
      "Epoch 2095, Loss: 0.0016933126607909799, Final Batch Loss: 0.00018695369362831116\n",
      "Epoch 2096, Loss: 0.002534134197048843, Final Batch Loss: 0.0001939794747158885\n",
      "Epoch 2097, Loss: 0.0023452598347830644, Final Batch Loss: 6.811761068092892e-06\n",
      "Epoch 2098, Loss: 0.00021021287830080837, Final Batch Loss: 6.651641160715371e-05\n",
      "Epoch 2099, Loss: 9.323356425738893e-05, Final Batch Loss: 6.0157180996611714e-05\n",
      "Epoch 2100, Loss: 5.222427853368572e-05, Final Batch Loss: 6.559077064594021e-06\n",
      "Epoch 2101, Loss: 0.0001308626208356145, Final Batch Loss: 3.671736749311094e-06\n",
      "Epoch 2102, Loss: 5.6013452194747515e-05, Final Batch Loss: 3.122889393125661e-05\n",
      "Epoch 2103, Loss: 2.7739570668927627e-05, Final Batch Loss: 5.48689104107325e-06\n",
      "Epoch 2104, Loss: 7.920246355297422e-05, Final Batch Loss: 1.4878002048135386e-06\n",
      "Epoch 2105, Loss: 5.557387339649722e-05, Final Batch Loss: 2.4720247893128544e-05\n",
      "Epoch 2106, Loss: 5.1105567763443105e-05, Final Batch Loss: 3.330808613100089e-05\n",
      "Epoch 2107, Loss: 2.742863853200106e-05, Final Batch Loss: 1.1953282410104293e-05\n",
      "Epoch 2108, Loss: 0.000316314508609139, Final Batch Loss: 1.369211759083555e-06\n",
      "Epoch 2109, Loss: 0.003720976645126939, Final Batch Loss: 0.001876825001090765\n",
      "Epoch 2110, Loss: 0.0021220773851382546, Final Batch Loss: 8.945748413680121e-05\n",
      "Epoch 2111, Loss: 4.666776021622354e-05, Final Batch Loss: 9.209587915393058e-06\n",
      "Epoch 2112, Loss: 5.511816971193184e-05, Final Batch Loss: 4.54773953606491e-06\n",
      "Epoch 2113, Loss: 0.0007610831817146391, Final Batch Loss: 0.00035768660018220544\n",
      "Epoch 2114, Loss: 2.1067117813799996e-05, Final Batch Loss: 1.8102715330314822e-05\n",
      "Epoch 2115, Loss: 1.913028472699807e-05, Final Batch Loss: 6.9527418418147136e-06\n",
      "Epoch 2116, Loss: 2.4477629267494194e-05, Final Batch Loss: 1.7376980395056307e-05\n",
      "Epoch 2117, Loss: 0.0004845867370022461, Final Batch Loss: 0.00023838535707909614\n",
      "Epoch 2118, Loss: 7.383324737020303e-05, Final Batch Loss: 4.591011384036392e-05\n",
      "Epoch 2119, Loss: 0.0011243229364481522, Final Batch Loss: 2.3963684725458734e-05\n",
      "Epoch 2120, Loss: 1.9946061001974158e-05, Final Batch Loss: 1.016855730995303e-05\n",
      "Epoch 2121, Loss: 0.001809667912311852, Final Batch Loss: 0.001561601529829204\n",
      "Epoch 2122, Loss: 0.0005005503044230863, Final Batch Loss: 0.00032647629268467426\n",
      "Epoch 2123, Loss: 0.0003306361359136645, Final Batch Loss: 0.00029127002926543355\n",
      "Epoch 2124, Loss: 0.00014448896399699152, Final Batch Loss: 1.8473787349648774e-05\n",
      "Epoch 2125, Loss: 1.5912270555418218e-05, Final Batch Loss: 6.884230515424861e-06\n",
      "Epoch 2126, Loss: 1.026907739287708e-05, Final Batch Loss: 5.810261882288614e-06\n",
      "Epoch 2127, Loss: 8.250139990195748e-05, Final Batch Loss: 7.588005973957479e-05\n",
      "Epoch 2128, Loss: 7.024464775895467e-05, Final Batch Loss: 9.56263374973787e-06\n",
      "Epoch 2129, Loss: 9.849298658082262e-05, Final Batch Loss: 6.140641926322132e-05\n",
      "Epoch 2130, Loss: 0.0002627398872618869, Final Batch Loss: 1.2566098348543164e-06\n",
      "Epoch 2131, Loss: 0.00012042225716868415, Final Batch Loss: 8.285976946353912e-05\n",
      "Epoch 2132, Loss: 8.149003406288102e-05, Final Batch Loss: 1.1123600415885448e-05\n",
      "Epoch 2133, Loss: 0.0019446008191152941, Final Batch Loss: 0.001898217131383717\n",
      "Epoch 2134, Loss: 6.946602934476687e-05, Final Batch Loss: 5.961637361906469e-05\n",
      "Epoch 2135, Loss: 0.0003357656933076214, Final Batch Loss: 0.0003202382067684084\n",
      "Epoch 2136, Loss: 0.002224673153250478, Final Batch Loss: 0.000126938903122209\n",
      "Epoch 2137, Loss: 4.727206305688014e-05, Final Batch Loss: 1.0252019819745328e-05\n",
      "Epoch 2138, Loss: 2.4406294869550038e-05, Final Batch Loss: 1.650293961574789e-05\n",
      "Epoch 2139, Loss: 0.0016585942428264389, Final Batch Loss: 0.0016554254107177258\n",
      "Epoch 2140, Loss: 0.0016526791005162522, Final Batch Loss: 0.0015093694673851132\n",
      "Epoch 2141, Loss: 7.055117021081969e-05, Final Batch Loss: 3.574347647372633e-05\n",
      "Epoch 2142, Loss: 5.9314937971066684e-05, Final Batch Loss: 2.43210160988383e-05\n",
      "Epoch 2143, Loss: 0.00010834614295163192, Final Batch Loss: 7.70635815570131e-05\n",
      "Epoch 2144, Loss: 0.0012499945951276459, Final Batch Loss: 0.0012434973614290357\n",
      "Epoch 2145, Loss: 0.006177491508424282, Final Batch Loss: 0.0033018600661307573\n",
      "Epoch 2146, Loss: 0.0030704394041549676, Final Batch Loss: 3.7790334772580536e-06\n",
      "Epoch 2147, Loss: 4.0360735283684335e-05, Final Batch Loss: 3.513183173708967e-06\n",
      "Epoch 2148, Loss: 0.002415989656583406, Final Batch Loss: 0.00013047004176769406\n",
      "Epoch 2149, Loss: 2.0057361098224646e-05, Final Batch Loss: 1.6376416169805452e-05\n",
      "Epoch 2150, Loss: 0.0004907920247205766, Final Batch Loss: 0.00048578003770671785\n",
      "Epoch 2151, Loss: 7.942369802549365e-05, Final Batch Loss: 5.75357944399002e-06\n",
      "Epoch 2152, Loss: 0.00014495727737084962, Final Batch Loss: 1.2133143172832206e-05\n",
      "Epoch 2153, Loss: 0.0024365703866351396, Final Batch Loss: 0.002355020958930254\n",
      "Epoch 2154, Loss: 0.0003088358207605779, Final Batch Loss: 0.00024784664856269956\n",
      "Epoch 2155, Loss: 1.767119147189078e-05, Final Batch Loss: 6.535177362820832e-06\n",
      "Epoch 2156, Loss: 0.0007189372054199339, Final Batch Loss: 7.321309567487333e-06\n",
      "Epoch 2157, Loss: 0.0001235557268728371, Final Batch Loss: 6.633621296714409e-07\n",
      "Epoch 2158, Loss: 2.883911020035157e-05, Final Batch Loss: 1.585300560691394e-05\n",
      "Epoch 2159, Loss: 2.311638763785595e-05, Final Batch Loss: 1.2114876881241798e-05\n",
      "Epoch 2160, Loss: 2.2241621735474837e-05, Final Batch Loss: 3.9846028698775626e-07\n",
      "Epoch 2161, Loss: 0.0004885023517999798, Final Batch Loss: 0.00015137670561671257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2162, Loss: 1.678875150901149e-05, Final Batch Loss: 1.1587022527237423e-05\n",
      "Epoch 2163, Loss: 0.0017324117325188126, Final Batch Loss: 3.338948226883076e-05\n",
      "Epoch 2164, Loss: 0.00018842725330614485, Final Batch Loss: 0.0001616841327631846\n",
      "Epoch 2165, Loss: 0.0017106347977460246, Final Batch Loss: 0.0016985556576400995\n",
      "Epoch 2166, Loss: 3.334126995468978e-05, Final Batch Loss: 2.5062170607270673e-05\n",
      "Epoch 2167, Loss: 4.3927886508754455e-05, Final Batch Loss: 2.413478614471387e-05\n",
      "Epoch 2168, Loss: 5.528055771719664e-05, Final Batch Loss: 3.847603875328787e-05\n",
      "Epoch 2169, Loss: 9.465141010878142e-05, Final Batch Loss: 7.763584289932624e-05\n",
      "Epoch 2170, Loss: 2.0547436179185752e-05, Final Batch Loss: 1.534968578198459e-05\n",
      "Epoch 2171, Loss: 7.601651486766059e-05, Final Batch Loss: 2.417425457679201e-05\n",
      "Epoch 2172, Loss: 0.0031305867596529424, Final Batch Loss: 0.0022610321175307035\n",
      "Epoch 2173, Loss: 0.00012025585238006897, Final Batch Loss: 5.5841421271907166e-05\n",
      "Epoch 2174, Loss: 0.0001325581870332826, Final Batch Loss: 0.00011286184599157423\n",
      "Epoch 2175, Loss: 0.0030771608994655253, Final Batch Loss: 7.538690169894835e-06\n",
      "Epoch 2176, Loss: 0.0015743952171760611, Final Batch Loss: 0.00149874750059098\n",
      "Epoch 2177, Loss: 0.00017141223315775278, Final Batch Loss: 0.000165125064086169\n",
      "Epoch 2178, Loss: 4.3632029701257125e-05, Final Batch Loss: 2.4370512619498186e-05\n",
      "Epoch 2179, Loss: 8.289078687084839e-05, Final Batch Loss: 5.025161226512864e-05\n",
      "Epoch 2180, Loss: 0.002521614836950903, Final Batch Loss: 0.0024974921252578497\n",
      "Epoch 2181, Loss: 2.0706426084871055e-06, Final Batch Loss: 2.439365971440566e-07\n",
      "Epoch 2182, Loss: 0.000694011971972941, Final Batch Loss: 1.3710167877434287e-05\n",
      "Epoch 2183, Loss: 6.446178485930432e-05, Final Batch Loss: 5.536347453016788e-05\n",
      "Epoch 2184, Loss: 0.0077749565498379525, Final Batch Loss: 5.149378193891607e-05\n",
      "Epoch 2185, Loss: 0.00039682805800111964, Final Batch Loss: 6.504086923087016e-05\n",
      "Epoch 2186, Loss: 0.00044685557077173144, Final Batch Loss: 0.0003013396344613284\n",
      "Epoch 2187, Loss: 0.005613605433609337, Final Batch Loss: 0.004655370023101568\n",
      "Epoch 2188, Loss: 0.0006601978675462306, Final Batch Loss: 0.0002735028392635286\n",
      "Epoch 2189, Loss: 0.008485763624776155, Final Batch Loss: 0.008170941844582558\n",
      "Epoch 2190, Loss: 0.00036068980625714175, Final Batch Loss: 0.00032533478224650025\n",
      "Epoch 2191, Loss: 6.477046736108605e-05, Final Batch Loss: 3.959274181397632e-05\n",
      "Epoch 2192, Loss: 0.00011434356929385103, Final Batch Loss: 3.837859185296111e-05\n",
      "Epoch 2193, Loss: 2.966854844999034e-05, Final Batch Loss: 1.9195149434381165e-05\n",
      "Epoch 2194, Loss: 8.958006219472736e-05, Final Batch Loss: 3.432744779274799e-05\n",
      "Epoch 2195, Loss: 2.4623107947263634e-05, Final Batch Loss: 1.7127460523624904e-05\n",
      "Epoch 2196, Loss: 0.0010692375080907368, Final Batch Loss: 7.055613423290197e-06\n",
      "Epoch 2197, Loss: 1.5777754015289247e-05, Final Batch Loss: 5.085576958663296e-06\n",
      "Epoch 2198, Loss: 0.001980672719582799, Final Batch Loss: 0.001964350463822484\n",
      "Epoch 2199, Loss: 0.00025277684835600667, Final Batch Loss: 3.2237072446150705e-05\n",
      "Epoch 2200, Loss: 0.0018724388246482704, Final Batch Loss: 4.217960304231383e-05\n",
      "Epoch 2201, Loss: 0.00017782903523766436, Final Batch Loss: 1.1242740583838895e-05\n",
      "Epoch 2202, Loss: 0.0017571243733982556, Final Batch Loss: 6.680742808384821e-05\n",
      "Epoch 2203, Loss: 0.0010052703910332639, Final Batch Loss: 0.0009587379754520953\n",
      "Epoch 2204, Loss: 0.0034251194447278976, Final Batch Loss: 0.0020867090206593275\n",
      "Epoch 2205, Loss: 0.00011374541372788372, Final Batch Loss: 0.00010711506911320612\n",
      "Epoch 2206, Loss: 8.344679918081965e-05, Final Batch Loss: 2.0349971237010323e-05\n",
      "Epoch 2207, Loss: 2.351034390812856e-05, Final Batch Loss: 4.481519226828823e-06\n",
      "Epoch 2208, Loss: 0.022968617504375288, Final Batch Loss: 0.022952809929847717\n",
      "Epoch 2209, Loss: 3.844510774797527e-05, Final Batch Loss: 1.4351036043080967e-05\n",
      "Epoch 2210, Loss: 9.510436211712658e-05, Final Batch Loss: 7.147584983613342e-05\n",
      "Epoch 2211, Loss: 0.00013591560127679259, Final Batch Loss: 9.98126997728832e-05\n",
      "Epoch 2212, Loss: 7.243834625114687e-05, Final Batch Loss: 6.445337930927053e-05\n",
      "Epoch 2213, Loss: 0.005101572955027223, Final Batch Loss: 0.0029862362425774336\n",
      "Epoch 2214, Loss: 0.00016791098823887296, Final Batch Loss: 0.0001305204350501299\n",
      "Epoch 2215, Loss: 0.010238296592433471, Final Batch Loss: 3.0889415938872844e-05\n",
      "Epoch 2216, Loss: 0.005672411527484655, Final Batch Loss: 6.080698221921921e-05\n",
      "Epoch 2217, Loss: 0.00670259416801855, Final Batch Loss: 0.0006084858323447406\n",
      "Epoch 2218, Loss: 0.0001587646547704935, Final Batch Loss: 1.803443592507392e-05\n",
      "Epoch 2219, Loss: 0.003944486677937675, Final Batch Loss: 0.003928805701434612\n",
      "Epoch 2220, Loss: 0.0018788559245876968, Final Batch Loss: 0.000254591868724674\n",
      "Epoch 2221, Loss: 7.868062630222994e-05, Final Batch Loss: 7.417787855956703e-05\n",
      "Epoch 2222, Loss: 3.758220191230066e-05, Final Batch Loss: 1.5900490325293504e-05\n",
      "Epoch 2223, Loss: 3.83571968995966e-05, Final Batch Loss: 1.861057353380602e-05\n",
      "Epoch 2224, Loss: 1.1936232112930156e-05, Final Batch Loss: 4.570176315610297e-06\n",
      "Epoch 2225, Loss: 0.00013302171828399878, Final Batch Loss: 2.7143008992425166e-05\n",
      "Epoch 2226, Loss: 0.0008180146978702396, Final Batch Loss: 0.00037997699109837413\n",
      "Epoch 2227, Loss: 0.001985830400371924, Final Batch Loss: 8.872841135598719e-05\n",
      "Epoch 2228, Loss: 0.0009253562384401448, Final Batch Loss: 9.822415449889377e-05\n",
      "Epoch 2229, Loss: 0.0008034459624468582, Final Batch Loss: 2.341080289625097e-05\n",
      "Epoch 2230, Loss: 0.001112826976168435, Final Batch Loss: 0.001025645644403994\n",
      "Epoch 2231, Loss: 0.0016755735377955716, Final Batch Loss: 1.6583373508183286e-05\n",
      "Epoch 2232, Loss: 6.786373523937073e-05, Final Batch Loss: 4.133651964366436e-05\n",
      "Epoch 2233, Loss: 0.004831865890082554, Final Batch Loss: 0.004814735613763332\n",
      "Epoch 2234, Loss: 7.479152009182144e-05, Final Batch Loss: 5.360820432542823e-05\n",
      "Epoch 2235, Loss: 0.0010225080941381748, Final Batch Loss: 3.6172159525449388e-06\n",
      "Epoch 2236, Loss: 0.0018126508957720944, Final Batch Loss: 0.001798277604393661\n",
      "Epoch 2237, Loss: 0.0008891787292668596, Final Batch Loss: 0.00013383298937696964\n",
      "Epoch 2238, Loss: 0.0005347047140276118, Final Batch Loss: 0.0005281721241772175\n",
      "Epoch 2239, Loss: 0.00017833547804002592, Final Batch Loss: 3.8040996059862664e-06\n",
      "Epoch 2240, Loss: 0.0038552443293156102, Final Batch Loss: 0.0038170497864484787\n",
      "Epoch 2241, Loss: 0.019386163972740178, Final Batch Loss: 8.323289875988849e-06\n",
      "Epoch 2242, Loss: 0.0014981375425122678, Final Batch Loss: 0.0013973773457109928\n",
      "Epoch 2243, Loss: 0.002596955731860362, Final Batch Loss: 0.0001614370703464374\n",
      "Epoch 2244, Loss: 0.0001764293665473815, Final Batch Loss: 0.00013276153185870498\n",
      "Epoch 2245, Loss: 0.00010282726589139202, Final Batch Loss: 9.687282727099955e-05\n",
      "Epoch 2246, Loss: 4.482608255784726e-05, Final Batch Loss: 1.2914874787384178e-05\n",
      "Epoch 2247, Loss: 0.00015521004843321862, Final Batch Loss: 0.0001477496698498726\n",
      "Epoch 2248, Loss: 0.012198188866022974, Final Batch Loss: 0.00017780583584681153\n",
      "Epoch 2249, Loss: 0.00016291236534016207, Final Batch Loss: 8.238771988544613e-05\n",
      "Epoch 2250, Loss: 0.005501144580193795, Final Batch Loss: 0.005311121698468924\n",
      "Epoch 2251, Loss: 0.029789218671794515, Final Batch Loss: 7.42971824365668e-05\n",
      "Epoch 2252, Loss: 0.002797330729663372, Final Batch Loss: 0.0004212392959743738\n",
      "Epoch 2253, Loss: 0.001078013883670792, Final Batch Loss: 0.0007148449076339602\n",
      "Epoch 2254, Loss: 0.0022384029362001456, Final Batch Loss: 7.909848500275984e-05\n",
      "Epoch 2255, Loss: 0.0030249001283664256, Final Batch Loss: 0.00040771791827864945\n",
      "Epoch 2256, Loss: 0.0010526655823923647, Final Batch Loss: 0.00020708440570160747\n",
      "Epoch 2257, Loss: 0.011442616232670844, Final Batch Loss: 0.010317333973944187\n",
      "Epoch 2258, Loss: 0.0009629377655073768, Final Batch Loss: 2.9702137908316217e-05\n",
      "Epoch 2259, Loss: 0.002044819528236985, Final Batch Loss: 0.0015364731661975384\n",
      "Epoch 2260, Loss: 0.007707558921538293, Final Batch Loss: 0.0064680431969463825\n",
      "Epoch 2261, Loss: 0.002004679510719143, Final Batch Loss: 0.0018263645470142365\n",
      "Epoch 2262, Loss: 0.018689812161028385, Final Batch Loss: 0.012841702438890934\n",
      "Epoch 2263, Loss: 0.00013558218051912263, Final Batch Loss: 3.160073538310826e-05\n",
      "Epoch 2264, Loss: 0.0034899300671895617, Final Batch Loss: 9.487500392424408e-06\n",
      "Epoch 2265, Loss: 0.0013767623204330448, Final Batch Loss: 2.0929179299855605e-05\n",
      "Epoch 2266, Loss: 0.0004880196793237701, Final Batch Loss: 0.00044950880692340434\n",
      "Epoch 2267, Loss: 0.006105114160163794, Final Batch Loss: 0.006017323117703199\n",
      "Epoch 2268, Loss: 0.0022080760754761286, Final Batch Loss: 0.0021838927641510963\n",
      "Epoch 2269, Loss: 0.00012113871343899518, Final Batch Loss: 4.617252852767706e-05\n",
      "Epoch 2270, Loss: 0.00010473056681803428, Final Batch Loss: 5.722175774280913e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2271, Loss: 1.998515745071927e-05, Final Batch Loss: 8.477845767629333e-06\n",
      "Epoch 2272, Loss: 5.485190195031464e-05, Final Batch Loss: 3.532071423251182e-05\n",
      "Epoch 2273, Loss: 8.403449101024307e-05, Final Batch Loss: 7.026409730315208e-05\n",
      "Epoch 2274, Loss: 0.003056685771298362, Final Batch Loss: 0.0030295115429908037\n",
      "Epoch 2275, Loss: 0.00014658275176770985, Final Batch Loss: 9.856196265900508e-05\n",
      "Epoch 2276, Loss: 0.0020455849007703364, Final Batch Loss: 0.0005452120094560087\n",
      "Epoch 2277, Loss: 0.003526138883898966, Final Batch Loss: 0.0034496465232223272\n",
      "Epoch 2278, Loss: 6.175071939651389e-05, Final Batch Loss: 5.122541915625334e-05\n",
      "Epoch 2279, Loss: 2.1301127162587363e-05, Final Batch Loss: 3.825703061011154e-06\n",
      "Epoch 2280, Loss: 0.00013467819007928483, Final Batch Loss: 9.181560017168522e-05\n",
      "Epoch 2281, Loss: 5.167925337445922e-05, Final Batch Loss: 1.2729196896543726e-05\n",
      "Epoch 2282, Loss: 0.00021226504031801596, Final Batch Loss: 0.00012201456411276013\n",
      "Epoch 2283, Loss: 0.0018894924141932279, Final Batch Loss: 7.277962868101895e-05\n",
      "Epoch 2284, Loss: 0.01392729248618707, Final Batch Loss: 0.00011187739437445998\n",
      "Epoch 2285, Loss: 0.0023453211979358457, Final Batch Loss: 0.002310422947630286\n",
      "Epoch 2286, Loss: 0.0005851206738043402, Final Batch Loss: 0.0005791771691292524\n",
      "Epoch 2287, Loss: 0.0016845916252350435, Final Batch Loss: 0.00011224577610846609\n",
      "Epoch 2288, Loss: 0.00511593755800277, Final Batch Loss: 0.0038609427865594625\n",
      "Epoch 2289, Loss: 0.0018110143719241023, Final Batch Loss: 0.0010474356822669506\n",
      "Epoch 2290, Loss: 0.005715810693800449, Final Batch Loss: 0.0032560902182012796\n",
      "Epoch 2291, Loss: 0.00011257683581789024, Final Batch Loss: 7.231911877170205e-05\n",
      "Epoch 2292, Loss: 0.0003951966864406131, Final Batch Loss: 0.0003059747104998678\n",
      "Epoch 2293, Loss: 0.003226482425816357, Final Batch Loss: 0.0017354636220261455\n",
      "Epoch 2294, Loss: 0.0001307089696638286, Final Batch Loss: 9.466321353102103e-05\n",
      "Epoch 2295, Loss: 4.0507258745492436e-05, Final Batch Loss: 2.700391451071482e-05\n",
      "Epoch 2296, Loss: 0.032954495633021, Final Batch Loss: 0.002755327383056283\n",
      "Epoch 2297, Loss: 7.558680954389274e-05, Final Batch Loss: 1.8030252249445766e-05\n",
      "Epoch 2298, Loss: 4.175661888439208e-05, Final Batch Loss: 1.6140564184752293e-05\n",
      "Epoch 2299, Loss: 0.004134738866923726, Final Batch Loss: 1.6694471923983656e-05\n",
      "Epoch 2300, Loss: 0.0003066005519940518, Final Batch Loss: 0.00020760437473654747\n",
      "Epoch 2301, Loss: 0.0001937621709657833, Final Batch Loss: 6.52456219540909e-05\n",
      "Epoch 2302, Loss: 0.00014559026749338955, Final Batch Loss: 5.5386895837727934e-05\n",
      "Epoch 2303, Loss: 0.001292870394536294, Final Batch Loss: 0.0012285200646147132\n",
      "Epoch 2304, Loss: 0.00013436302106129006, Final Batch Loss: 7.200826075859368e-05\n",
      "Epoch 2305, Loss: 0.00040289468597620726, Final Batch Loss: 0.00019089215493295342\n",
      "Epoch 2306, Loss: 0.0004254158920957707, Final Batch Loss: 8.961150160757825e-05\n",
      "Epoch 2307, Loss: 0.00011153391460538842, Final Batch Loss: 6.793465581722558e-05\n",
      "Epoch 2308, Loss: 0.0002368285713600926, Final Batch Loss: 0.00015692248416598886\n",
      "Epoch 2309, Loss: 1.7758894500730094e-05, Final Batch Loss: 6.593115358555224e-06\n",
      "Epoch 2310, Loss: 0.00019990520195278805, Final Batch Loss: 0.0001724787289276719\n",
      "Epoch 2311, Loss: 0.00011418120993766934, Final Batch Loss: 7.408031524391845e-05\n",
      "Epoch 2312, Loss: 0.0001653785366215743, Final Batch Loss: 9.281771053792909e-05\n",
      "Epoch 2313, Loss: 8.954649820225313e-05, Final Batch Loss: 4.155671194894239e-05\n",
      "Epoch 2314, Loss: 0.002597925951704383, Final Batch Loss: 0.0002956285607069731\n",
      "Epoch 2315, Loss: 0.0017056200704246294, Final Batch Loss: 3.620933784986846e-05\n",
      "Epoch 2316, Loss: 0.0017138936382252723, Final Batch Loss: 0.0015868579503148794\n",
      "Epoch 2317, Loss: 0.0002047202542598825, Final Batch Loss: 0.00019555713515728712\n",
      "Epoch 2318, Loss: 0.0002209146914537996, Final Batch Loss: 8.730596164241433e-05\n",
      "Epoch 2319, Loss: 0.028680846095085144, Final Batch Loss: 0.026094699278473854\n",
      "Epoch 2320, Loss: 0.0003889267700287746, Final Batch Loss: 0.0003608777769841254\n",
      "Epoch 2321, Loss: 0.00022311820066533983, Final Batch Loss: 0.000111014858703129\n",
      "Epoch 2322, Loss: 0.00035023687087232247, Final Batch Loss: 3.997184830950573e-05\n",
      "Epoch 2323, Loss: 0.0020039361916133203, Final Batch Loss: 0.0019385357154533267\n",
      "Epoch 2324, Loss: 0.0027250076600466855, Final Batch Loss: 0.0026126434095203876\n",
      "Epoch 2325, Loss: 7.933602319099009e-05, Final Batch Loss: 5.125704046804458e-05\n",
      "Epoch 2326, Loss: 0.00014800230201217346, Final Batch Loss: 9.276227501686662e-05\n",
      "Epoch 2327, Loss: 0.003941159811802208, Final Batch Loss: 0.0017815845785662532\n",
      "Epoch 2328, Loss: 0.00013155751730664633, Final Batch Loss: 5.975771273369901e-05\n",
      "Epoch 2329, Loss: 0.004456266411580145, Final Batch Loss: 0.004239532630890608\n",
      "Epoch 2330, Loss: 0.00048782481462694705, Final Batch Loss: 0.00014163969899527729\n",
      "Epoch 2331, Loss: 0.0003645710712589789, Final Batch Loss: 5.3909392590867355e-05\n",
      "Epoch 2332, Loss: 0.0007099892754922621, Final Batch Loss: 8.448043809039518e-05\n",
      "Epoch 2333, Loss: 0.00034622793828020804, Final Batch Loss: 1.4140281564323232e-05\n",
      "Epoch 2334, Loss: 0.0005550191854126751, Final Batch Loss: 0.0003042636380996555\n",
      "Epoch 2335, Loss: 0.001354911713860929, Final Batch Loss: 0.0009588146931491792\n",
      "Epoch 2336, Loss: 0.00021733113680966198, Final Batch Loss: 7.09789601387456e-05\n",
      "Epoch 2337, Loss: 0.009072875138372183, Final Batch Loss: 0.006811655592173338\n",
      "Epoch 2338, Loss: 0.00140918797114864, Final Batch Loss: 0.0005320061463862658\n",
      "Epoch 2339, Loss: 0.0016202022015932016, Final Batch Loss: 0.00010391021351097152\n",
      "Epoch 2340, Loss: 0.002324114539078437, Final Batch Loss: 0.00012923286703880876\n",
      "Epoch 2341, Loss: 0.00011524705769261345, Final Batch Loss: 4.7086730774026364e-05\n",
      "Epoch 2342, Loss: 0.002343073982046917, Final Batch Loss: 0.00030960774165578187\n",
      "Epoch 2343, Loss: 0.00018299531438970007, Final Batch Loss: 4.70705890620593e-05\n",
      "Epoch 2344, Loss: 0.0005533526855288073, Final Batch Loss: 0.00032055284827947617\n",
      "Epoch 2345, Loss: 0.002484190641553141, Final Batch Loss: 0.00018687536066863686\n",
      "Epoch 2346, Loss: 0.0008052609045989811, Final Batch Loss: 0.0007273121154867113\n",
      "Epoch 2347, Loss: 0.0007806847788742743, Final Batch Loss: 9.143040369963273e-05\n",
      "Epoch 2348, Loss: 0.00034787316690199077, Final Batch Loss: 0.00023192225489765406\n",
      "Epoch 2349, Loss: 0.002476089197443798, Final Batch Loss: 4.6370114432647824e-05\n",
      "Epoch 2350, Loss: 6.646676956734154e-05, Final Batch Loss: 2.0702611436718144e-05\n",
      "Epoch 2351, Loss: 0.0005788498165202327, Final Batch Loss: 6.130804104031995e-05\n",
      "Epoch 2352, Loss: 0.0005362211813917384, Final Batch Loss: 0.00032322556944563985\n",
      "Epoch 2353, Loss: 0.0024815043725539, Final Batch Loss: 0.0020304720383137465\n",
      "Epoch 2354, Loss: 0.0003198359627276659, Final Batch Loss: 4.9643684178590775e-05\n",
      "Epoch 2355, Loss: 0.0014875094639137387, Final Batch Loss: 0.0009044125908985734\n",
      "Epoch 2356, Loss: 0.00032620829006191343, Final Batch Loss: 0.00013163972471375018\n",
      "Epoch 2357, Loss: 0.0012723460822599009, Final Batch Loss: 0.00014147577167022973\n",
      "Epoch 2358, Loss: 0.002096345866448246, Final Batch Loss: 0.0002267053205287084\n",
      "Epoch 2359, Loss: 0.00011295520471321652, Final Batch Loss: 1.418898409610847e-05\n",
      "Epoch 2360, Loss: 0.0021814100618939847, Final Batch Loss: 0.0002385545230936259\n",
      "Epoch 2361, Loss: 0.0009056211274582893, Final Batch Loss: 0.0007569614099338651\n",
      "Epoch 2362, Loss: 0.000155655872731586, Final Batch Loss: 9.982688425225206e-06\n",
      "Epoch 2363, Loss: 0.00034662839607335627, Final Batch Loss: 0.00022403401089832187\n",
      "Epoch 2364, Loss: 0.001334440175924101, Final Batch Loss: 2.8500662665464915e-05\n",
      "Epoch 2365, Loss: 0.0039886810118332505, Final Batch Loss: 0.003862361889332533\n",
      "Epoch 2366, Loss: 0.0008363568995264359, Final Batch Loss: 0.0007270775968208909\n",
      "Epoch 2367, Loss: 0.00283477250195574, Final Batch Loss: 0.00011471430480014533\n",
      "Epoch 2368, Loss: 0.002476884335919749, Final Batch Loss: 0.0023968154564499855\n",
      "Epoch 2369, Loss: 0.0013271413190523162, Final Batch Loss: 0.000109484200947918\n",
      "Epoch 2370, Loss: 0.00010430644306325121, Final Batch Loss: 8.952240750659257e-05\n",
      "Epoch 2371, Loss: 0.000240612993366085, Final Batch Loss: 8.452092879451811e-05\n",
      "Epoch 2372, Loss: 5.4631014791084453e-05, Final Batch Loss: 2.4692182705621235e-05\n",
      "Epoch 2373, Loss: 0.000357013130269479, Final Batch Loss: 7.034063310129568e-05\n",
      "Epoch 2374, Loss: 0.00016699123079888523, Final Batch Loss: 6.763933197362348e-05\n",
      "Epoch 2375, Loss: 0.004203358297672821, Final Batch Loss: 5.132947626407258e-05\n",
      "Epoch 2376, Loss: 7.498731247324031e-05, Final Batch Loss: 4.975734555046074e-05\n",
      "Epoch 2377, Loss: 0.0005372664745664224, Final Batch Loss: 0.00038669430068694055\n",
      "Epoch 2378, Loss: 0.001622082680114545, Final Batch Loss: 0.0015235526952892542\n",
      "Epoch 2379, Loss: 0.0012199359553051181, Final Batch Loss: 0.00011565397289814427\n",
      "Epoch 2380, Loss: 0.0001948851568158716, Final Batch Loss: 7.453199214069173e-05\n",
      "Epoch 2381, Loss: 0.00028437794389901683, Final Batch Loss: 7.165461283875629e-05\n",
      "Epoch 2382, Loss: 0.0001299341206504323, Final Batch Loss: 6.2145377341948915e-06\n",
      "Epoch 2383, Loss: 0.0022942571085877717, Final Batch Loss: 0.0001393017009831965\n",
      "Epoch 2384, Loss: 5.294459333526902e-05, Final Batch Loss: 1.4982560969656333e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2385, Loss: 8.65335896378383e-05, Final Batch Loss: 1.7440455849282444e-05\n",
      "Epoch 2386, Loss: 0.005991554293359513, Final Batch Loss: 2.495053740858566e-05\n",
      "Epoch 2387, Loss: 3.1341643534688046e-05, Final Batch Loss: 2.5845358322840184e-05\n",
      "Epoch 2388, Loss: 0.022652472019217385, Final Batch Loss: 0.022644400596618652\n",
      "Epoch 2389, Loss: 0.0001875245143310167, Final Batch Loss: 3.80025667254813e-05\n",
      "Epoch 2390, Loss: 0.0005522505089174956, Final Batch Loss: 0.0001400972541887313\n",
      "Epoch 2391, Loss: 0.00015218902444757987, Final Batch Loss: 8.300457920995541e-06\n",
      "Epoch 2392, Loss: 0.006725730374455452, Final Batch Loss: 0.001413098070770502\n",
      "Epoch 2393, Loss: 6.400778693205211e-05, Final Batch Loss: 2.4878363547031768e-05\n",
      "Epoch 2394, Loss: 0.00016661783047311474, Final Batch Loss: 0.00015799466928001493\n",
      "Epoch 2395, Loss: 0.00011893914052052423, Final Batch Loss: 4.20176875195466e-05\n",
      "Epoch 2396, Loss: 0.0005107275719637983, Final Batch Loss: 6.530258542625234e-05\n",
      "Epoch 2397, Loss: 0.00013236973973107524, Final Batch Loss: 3.100879621342756e-05\n",
      "Epoch 2398, Loss: 0.0028009084926452488, Final Batch Loss: 0.00258810562081635\n",
      "Epoch 2399, Loss: 0.00034560020321805496, Final Batch Loss: 0.00031553558073937893\n",
      "Epoch 2400, Loss: 0.0005301994242472574, Final Batch Loss: 7.17104267096147e-05\n",
      "Epoch 2401, Loss: 0.002102416613524838, Final Batch Loss: 8.4495632108883e-06\n",
      "Epoch 2402, Loss: 0.0010589171142783016, Final Batch Loss: 0.0009834090014919639\n",
      "Epoch 2403, Loss: 9.941226744558662e-05, Final Batch Loss: 7.560945232398808e-05\n",
      "Epoch 2404, Loss: 0.0012970347233931534, Final Batch Loss: 0.001227918197400868\n",
      "Epoch 2405, Loss: 8.858385899657151e-05, Final Batch Loss: 8.441630598099437e-06\n",
      "Epoch 2406, Loss: 0.00010921787179540843, Final Batch Loss: 8.579373388784006e-05\n",
      "Epoch 2407, Loss: 0.0004895090860372875, Final Batch Loss: 4.140384044148959e-05\n",
      "Epoch 2408, Loss: 0.00042302353540435433, Final Batch Loss: 0.00017295396537519991\n",
      "Epoch 2409, Loss: 0.0007586700266983826, Final Batch Loss: 2.8518134058685973e-05\n",
      "Epoch 2410, Loss: 0.00023358132602879778, Final Batch Loss: 3.9351281884592026e-05\n",
      "Epoch 2411, Loss: 0.00011168120545335114, Final Batch Loss: 6.671447772532701e-05\n",
      "Epoch 2412, Loss: 0.0009921281598508358, Final Batch Loss: 0.0008155725663527846\n",
      "Epoch 2413, Loss: 5.8399476529302774e-05, Final Batch Loss: 4.388165962154744e-06\n",
      "Epoch 2414, Loss: 0.0002458316994307097, Final Batch Loss: 0.00020651174418162555\n",
      "Epoch 2415, Loss: 0.0001013154978863895, Final Batch Loss: 5.441622852231376e-05\n",
      "Epoch 2416, Loss: 0.0013695144734811038, Final Batch Loss: 0.0012668533017858863\n",
      "Epoch 2417, Loss: 0.0007500438077840954, Final Batch Loss: 0.00010817134170792997\n",
      "Epoch 2418, Loss: 0.0002944631560239941, Final Batch Loss: 6.889818178024143e-05\n",
      "Epoch 2419, Loss: 0.00028603071405086666, Final Batch Loss: 0.00020135671366006136\n",
      "Epoch 2420, Loss: 0.0002816522210196126, Final Batch Loss: 3.9427603041986004e-05\n",
      "Epoch 2421, Loss: 0.020032624481245875, Final Batch Loss: 0.019482187926769257\n",
      "Epoch 2422, Loss: 0.00029064679984003305, Final Batch Loss: 6.760084943380207e-05\n",
      "Epoch 2423, Loss: 0.0002522160721127875, Final Batch Loss: 0.00012074020196450874\n",
      "Epoch 2424, Loss: 0.00047400861876667477, Final Batch Loss: 4.7425975935766473e-05\n",
      "Epoch 2425, Loss: 0.0014553286164300516, Final Batch Loss: 0.00021159563038963825\n",
      "Epoch 2426, Loss: 0.009130963357165456, Final Batch Loss: 0.005514270626008511\n",
      "Epoch 2427, Loss: 0.0031620837980881333, Final Batch Loss: 0.0005939706461504102\n",
      "Epoch 2428, Loss: 0.004501081944908947, Final Batch Loss: 0.00017595005920156837\n",
      "Epoch 2429, Loss: 0.0029248319697217084, Final Batch Loss: 0.0028861260507255793\n",
      "Epoch 2430, Loss: 0.000239800319832284, Final Batch Loss: 0.0001538922224426642\n",
      "Epoch 2431, Loss: 0.0002254523933515884, Final Batch Loss: 0.00010698215191951022\n",
      "Epoch 2432, Loss: 0.00027190443870495073, Final Batch Loss: 0.00022534832532983273\n",
      "Epoch 2433, Loss: 0.0018923030511359684, Final Batch Loss: 0.00011414713662816212\n",
      "Epoch 2434, Loss: 0.0012152488197898492, Final Batch Loss: 0.0011259230086579919\n",
      "Epoch 2435, Loss: 0.00011829464710899629, Final Batch Loss: 4.8728212277637795e-05\n",
      "Epoch 2436, Loss: 0.0003837272815871984, Final Batch Loss: 0.00022153595637064427\n",
      "Epoch 2437, Loss: 0.0027212020286242478, Final Batch Loss: 5.868908920092508e-05\n",
      "Epoch 2438, Loss: 0.007054952438920736, Final Batch Loss: 0.004967536777257919\n",
      "Epoch 2439, Loss: 0.004939723992720246, Final Batch Loss: 0.0024083692114800215\n",
      "Epoch 2440, Loss: 0.0011517006569192745, Final Batch Loss: 0.00010393586853751913\n",
      "Epoch 2441, Loss: 0.0010419219761388376, Final Batch Loss: 0.0008865476702339947\n",
      "Epoch 2442, Loss: 0.0002790662183542736, Final Batch Loss: 0.00024562643375247717\n",
      "Epoch 2443, Loss: 6.28977213636972e-05, Final Batch Loss: 3.1479503377340734e-05\n",
      "Epoch 2444, Loss: 0.00040804874151945114, Final Batch Loss: 0.00015166157390922308\n",
      "Epoch 2445, Loss: 0.0004213782667648047, Final Batch Loss: 0.00011132462532259524\n",
      "Epoch 2446, Loss: 0.0013292076764628291, Final Batch Loss: 8.699251338839531e-05\n",
      "Epoch 2447, Loss: 0.0030324835097417235, Final Batch Loss: 0.001274103531613946\n",
      "Epoch 2448, Loss: 0.00010548759382800199, Final Batch Loss: 3.511728937155567e-05\n",
      "Epoch 2449, Loss: 0.0018677629122976214, Final Batch Loss: 0.00027226636302657425\n",
      "Epoch 2450, Loss: 0.00027238177426625043, Final Batch Loss: 0.0001560920209158212\n",
      "Epoch 2451, Loss: 0.005131876096129417, Final Batch Loss: 0.0024880433920770884\n",
      "Epoch 2452, Loss: 0.0028498234023572877, Final Batch Loss: 0.002729627536609769\n",
      "Epoch 2453, Loss: 0.0002358513738727197, Final Batch Loss: 9.018625132739544e-05\n",
      "Epoch 2454, Loss: 0.0002937385706900386, Final Batch Loss: 2.963498809549492e-05\n",
      "Epoch 2455, Loss: 0.00029435149917844683, Final Batch Loss: 5.138188134878874e-05\n",
      "Epoch 2456, Loss: 0.00019442097982391715, Final Batch Loss: 0.0001117256106226705\n",
      "Epoch 2457, Loss: 0.00013198962551541626, Final Batch Loss: 1.5686106053180993e-05\n",
      "Epoch 2458, Loss: 0.002836367057170719, Final Batch Loss: 0.002469464670866728\n",
      "Epoch 2459, Loss: 0.002684826682525454, Final Batch Loss: 0.002629063557833433\n",
      "Epoch 2460, Loss: 0.0009022548620123416, Final Batch Loss: 0.0006549005047418177\n",
      "Epoch 2461, Loss: 5.424361734185368e-05, Final Batch Loss: 1.2650492863031104e-05\n",
      "Epoch 2462, Loss: 0.0003213690433767624, Final Batch Loss: 0.00011695935245370492\n",
      "Epoch 2463, Loss: 0.0002945371306850575, Final Batch Loss: 7.379272574326023e-05\n",
      "Epoch 2464, Loss: 0.00042644447239581496, Final Batch Loss: 0.00021607957023661584\n",
      "Epoch 2465, Loss: 0.00055111208348535, Final Batch Loss: 0.0004938169149681926\n",
      "Epoch 2466, Loss: 0.002253524013212882, Final Batch Loss: 0.0001613744389032945\n",
      "Epoch 2467, Loss: 0.0008541453571524471, Final Batch Loss: 0.0005691862315870821\n",
      "Epoch 2468, Loss: 0.00019751502259168774, Final Batch Loss: 5.1345909014344215e-05\n",
      "Epoch 2469, Loss: 0.00011660812015179545, Final Batch Loss: 5.0119888328481466e-05\n",
      "Epoch 2470, Loss: 0.00042816858331207186, Final Batch Loss: 0.00021781536634080112\n",
      "Epoch 2471, Loss: 0.00011475464998511598, Final Batch Loss: 3.394331724848598e-05\n",
      "Epoch 2472, Loss: 0.0016505525090906303, Final Batch Loss: 0.0016275695525109768\n",
      "Epoch 2473, Loss: 0.0007917412622191478, Final Batch Loss: 0.0007547720451839268\n",
      "Epoch 2474, Loss: 0.00037550271372310817, Final Batch Loss: 0.00012991856783628464\n",
      "Epoch 2475, Loss: 0.004304843721911311, Final Batch Loss: 0.0017570951022207737\n",
      "Epoch 2476, Loss: 0.003413934900891036, Final Batch Loss: 0.0032789777033030987\n",
      "Epoch 2477, Loss: 0.00014352450671140105, Final Batch Loss: 0.00010682995343813673\n",
      "Epoch 2478, Loss: 0.0049829790004878305, Final Batch Loss: 0.004891133867204189\n",
      "Epoch 2479, Loss: 0.00012941926979692653, Final Batch Loss: 3.93824593629688e-05\n",
      "Epoch 2480, Loss: 2.8174202270747628e-05, Final Batch Loss: 1.7357078831992112e-05\n",
      "Epoch 2481, Loss: 0.0014456479148066137, Final Batch Loss: 3.0391154723474756e-05\n",
      "Epoch 2482, Loss: 0.00024031461362028494, Final Batch Loss: 0.00011312458809698\n",
      "Epoch 2483, Loss: 4.50537172582699e-05, Final Batch Loss: 3.124321665382013e-05\n",
      "Epoch 2484, Loss: 4.571853332890896e-05, Final Batch Loss: 5.273329406918492e-06\n",
      "Epoch 2485, Loss: 5.647032503475202e-05, Final Batch Loss: 4.168946543359198e-05\n",
      "Epoch 2486, Loss: 0.002488025113052572, Final Batch Loss: 0.002463066950440407\n",
      "Epoch 2487, Loss: 0.00020887893333565444, Final Batch Loss: 0.00011838665523100644\n",
      "Epoch 2488, Loss: 0.008461622979666572, Final Batch Loss: 4.064803215442225e-05\n",
      "Epoch 2489, Loss: 0.0005377269553719088, Final Batch Loss: 0.0004883427172899246\n",
      "Epoch 2490, Loss: 0.0024955452608992346, Final Batch Loss: 0.0024725543335080147\n",
      "Epoch 2491, Loss: 0.009447898744838312, Final Batch Loss: 0.00017238504369743168\n",
      "Epoch 2492, Loss: 0.00011542514766915701, Final Batch Loss: 4.39935211034026e-05\n",
      "Epoch 2493, Loss: 0.0015766751057526562, Final Batch Loss: 3.48418288922403e-05\n",
      "Epoch 2494, Loss: 0.0005638646325678565, Final Batch Loss: 0.0005028238520026207\n",
      "Epoch 2495, Loss: 0.0020375682252051774, Final Batch Loss: 1.879848787211813e-05\n",
      "Epoch 2496, Loss: 0.0008062465785769746, Final Batch Loss: 0.00011268029629718512\n",
      "Epoch 2497, Loss: 0.0015511591554968618, Final Batch Loss: 0.00011931449262192473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2498, Loss: 0.0006396234675776213, Final Batch Loss: 8.1604317529127e-05\n",
      "Epoch 2499, Loss: 0.00011879706653417088, Final Batch Loss: 0.00010865196236409247\n",
      "Epoch 2500, Loss: 0.0005259804747765884, Final Batch Loss: 0.0003892089589498937\n",
      "Epoch 2501, Loss: 0.00013739535643253475, Final Batch Loss: 3.3022901334334165e-05\n",
      "Epoch 2502, Loss: 0.00010285474490956403, Final Batch Loss: 2.6349178369855508e-05\n",
      "Epoch 2503, Loss: 0.00012834371227654628, Final Batch Loss: 2.7344238333171234e-05\n",
      "Epoch 2504, Loss: 0.0018933376704808325, Final Batch Loss: 0.0018258673371747136\n",
      "Epoch 2505, Loss: 0.00011482910122140311, Final Batch Loss: 7.335260306717828e-05\n",
      "Epoch 2506, Loss: 5.32120566276717e-05, Final Batch Loss: 3.993562495452352e-05\n",
      "Epoch 2507, Loss: 0.0018081838206853718, Final Batch Loss: 4.5023480197414756e-05\n",
      "Epoch 2508, Loss: 0.0027057830011472106, Final Batch Loss: 0.000987701816484332\n",
      "Epoch 2509, Loss: 0.001440222291421378, Final Batch Loss: 3.58283614332322e-05\n",
      "Epoch 2510, Loss: 2.1323975488485303e-05, Final Batch Loss: 7.691617611271795e-06\n",
      "Epoch 2511, Loss: 0.0012168115063104779, Final Batch Loss: 0.001155820325948298\n",
      "Epoch 2512, Loss: 0.0016230744950007647, Final Batch Loss: 0.0015737360808998346\n",
      "Epoch 2513, Loss: 8.43306042952463e-05, Final Batch Loss: 9.969669918064028e-06\n",
      "Epoch 2514, Loss: 0.0013122550863045035, Final Batch Loss: 1.5832874851184897e-05\n",
      "Epoch 2515, Loss: 0.004095590744327637, Final Batch Loss: 0.004080105572938919\n",
      "Epoch 2516, Loss: 0.0030351861205417663, Final Batch Loss: 0.00295909377746284\n",
      "Epoch 2517, Loss: 9.028750491779647e-05, Final Batch Loss: 7.341537184402114e-06\n",
      "Epoch 2518, Loss: 0.0027079577776021324, Final Batch Loss: 0.002692638197913766\n",
      "Epoch 2519, Loss: 0.0007217850870802067, Final Batch Loss: 8.568655175622553e-06\n",
      "Epoch 2520, Loss: 0.0002113668513175071, Final Batch Loss: 3.491578127068351e-06\n",
      "Epoch 2521, Loss: 4.681704558606725e-05, Final Batch Loss: 2.7817981390398927e-05\n",
      "Epoch 2522, Loss: 4.5748816773993894e-05, Final Batch Loss: 6.412858056137338e-06\n",
      "Epoch 2523, Loss: 0.0023845001305744518, Final Batch Loss: 5.39934444532264e-05\n",
      "Epoch 2524, Loss: 0.0023093867775969557, Final Batch Loss: 9.377180504088756e-06\n",
      "Epoch 2525, Loss: 0.00024073157692328095, Final Batch Loss: 2.0392515580169857e-05\n",
      "Epoch 2526, Loss: 0.0018523724615988613, Final Batch Loss: 4.292964604246663e-06\n",
      "Epoch 2527, Loss: 5.427636642707512e-05, Final Batch Loss: 1.9548962882254273e-05\n",
      "Epoch 2528, Loss: 0.0019967750304203946, Final Batch Loss: 0.001975483261048794\n",
      "Epoch 2529, Loss: 0.0011838508362416178, Final Batch Loss: 0.00016887791571207345\n",
      "Epoch 2530, Loss: 7.69694997870829e-05, Final Batch Loss: 4.473126318771392e-05\n",
      "Epoch 2531, Loss: 6.899534309923183e-05, Final Batch Loss: 2.737110662565101e-05\n",
      "Epoch 2532, Loss: 0.00012286160927033052, Final Batch Loss: 4.8953625082504004e-05\n",
      "Epoch 2533, Loss: 0.0007517359626945108, Final Batch Loss: 8.163574966602027e-05\n",
      "Epoch 2534, Loss: 4.6048814056121046e-05, Final Batch Loss: 3.7466293179022614e-06\n",
      "Epoch 2535, Loss: 0.00010300942358298926, Final Batch Loss: 9.22203907975927e-05\n",
      "Epoch 2536, Loss: 5.31973346369341e-05, Final Batch Loss: 1.6973870515357703e-05\n",
      "Epoch 2537, Loss: 1.7001476408040617e-05, Final Batch Loss: 7.998127330210991e-06\n",
      "Epoch 2538, Loss: 9.489697731623892e-05, Final Batch Loss: 2.9726734283030964e-05\n",
      "Epoch 2539, Loss: 8.095878729363903e-05, Final Batch Loss: 7.559200457762927e-05\n",
      "Epoch 2540, Loss: 4.5173149828769965e-05, Final Batch Loss: 5.241479357209755e-06\n",
      "Epoch 2541, Loss: 0.0012198747572256252, Final Batch Loss: 4.8068861360661685e-05\n",
      "Epoch 2542, Loss: 0.00015952681133057922, Final Batch Loss: 7.416986773023382e-05\n",
      "Epoch 2543, Loss: 0.006702330196276307, Final Batch Loss: 0.00468050641939044\n",
      "Epoch 2544, Loss: 0.002397819212092145, Final Batch Loss: 8.593336133344565e-06\n",
      "Epoch 2545, Loss: 7.760000698908698e-05, Final Batch Loss: 2.2476937374449335e-05\n",
      "Epoch 2546, Loss: 0.0024301389985339483, Final Batch Loss: 0.0024079999420791864\n",
      "Epoch 2547, Loss: 0.001385522453347221, Final Batch Loss: 0.00014777787146158516\n",
      "Epoch 2548, Loss: 0.0006283665279624984, Final Batch Loss: 0.00024201137421187013\n",
      "Epoch 2549, Loss: 5.0755349548126105e-05, Final Batch Loss: 1.3791240235150326e-05\n",
      "Epoch 2550, Loss: 0.00018843765428755432, Final Batch Loss: 8.502732816850767e-05\n",
      "Epoch 2551, Loss: 9.405010678165127e-05, Final Batch Loss: 7.05372222000733e-05\n",
      "Epoch 2552, Loss: 7.556051969004329e-05, Final Batch Loss: 2.4614086214569397e-05\n",
      "Epoch 2553, Loss: 0.00020644643518608063, Final Batch Loss: 0.00019753503147512674\n",
      "Epoch 2554, Loss: 4.9244577894569375e-05, Final Batch Loss: 2.8510854463092983e-05\n",
      "Epoch 2555, Loss: 5.6372027756879106e-05, Final Batch Loss: 3.42951352649834e-05\n",
      "Epoch 2556, Loss: 4.6125609515002e-05, Final Batch Loss: 1.8822853235178627e-05\n",
      "Epoch 2557, Loss: 0.000379211429390125, Final Batch Loss: 0.00014864912373013794\n",
      "Epoch 2558, Loss: 0.00048503983998671174, Final Batch Loss: 0.0003590536944102496\n",
      "Epoch 2559, Loss: 0.00010900443339778576, Final Batch Loss: 8.703221828909591e-05\n",
      "Epoch 2560, Loss: 8.310221437568543e-05, Final Batch Loss: 7.322911551455036e-05\n",
      "Epoch 2561, Loss: 7.807370138834813e-05, Final Batch Loss: 3.341460342198843e-06\n",
      "Epoch 2562, Loss: 0.00022825051928521134, Final Batch Loss: 0.000167699865414761\n",
      "Epoch 2563, Loss: 4.513488329394022e-05, Final Batch Loss: 3.551048939698376e-05\n",
      "Epoch 2564, Loss: 0.0001740648949635215, Final Batch Loss: 0.00014057179214432836\n",
      "Epoch 2565, Loss: 0.0003359894180903211, Final Batch Loss: 0.0002327395777683705\n",
      "Epoch 2566, Loss: 0.00045499370025936514, Final Batch Loss: 0.0004009692056570202\n",
      "Epoch 2567, Loss: 7.371208630502224e-05, Final Batch Loss: 2.3104774300009012e-05\n",
      "Epoch 2568, Loss: 0.0010997220892932091, Final Batch Loss: 0.001094449427910149\n",
      "Epoch 2569, Loss: 7.366604040726088e-05, Final Batch Loss: 1.2928980140713975e-05\n",
      "Epoch 2570, Loss: 0.0010885340670938604, Final Batch Loss: 0.0010354926344007254\n",
      "Epoch 2571, Loss: 0.0002526460593799129, Final Batch Loss: 0.00013827085786033422\n",
      "Epoch 2572, Loss: 0.00011480347166070715, Final Batch Loss: 6.130296969786286e-05\n",
      "Epoch 2573, Loss: 0.0005109189878567122, Final Batch Loss: 6.303792906692252e-05\n",
      "Epoch 2574, Loss: 1.9629048438218888e-05, Final Batch Loss: 7.1773401941754855e-06\n",
      "Epoch 2575, Loss: 0.00025585693219909444, Final Batch Loss: 6.248022691579536e-05\n",
      "Epoch 2576, Loss: 9.006071923067793e-05, Final Batch Loss: 4.6559362090192735e-05\n",
      "Epoch 2577, Loss: 0.00020880146985291503, Final Batch Loss: 0.00015077038551680744\n",
      "Epoch 2578, Loss: 0.002150815213099122, Final Batch Loss: 0.0020153771620243788\n",
      "Epoch 2579, Loss: 0.0012877655717602465, Final Batch Loss: 3.000209471792914e-05\n",
      "Epoch 2580, Loss: 2.1636009250869392e-05, Final Batch Loss: 2.0677741758845514e-06\n",
      "Epoch 2581, Loss: 0.0003471377121968544, Final Batch Loss: 2.1444857338792644e-06\n",
      "Epoch 2582, Loss: 0.0005451238539535552, Final Batch Loss: 0.00020005283295176923\n",
      "Epoch 2583, Loss: 0.0016078475018730387, Final Batch Loss: 0.0015973033150658011\n",
      "Epoch 2584, Loss: 0.00077425120434782, Final Batch Loss: 1.4127488611848094e-05\n",
      "Epoch 2585, Loss: 0.001981694963433256, Final Batch Loss: 0.001969161443412304\n",
      "Epoch 2586, Loss: 6.246610973903444e-05, Final Batch Loss: 2.5891198674798943e-05\n",
      "Epoch 2587, Loss: 0.001099978355341591, Final Batch Loss: 0.00014257350994739681\n",
      "Epoch 2588, Loss: 1.8823982486537716e-05, Final Batch Loss: 1.0441359563628794e-06\n",
      "Epoch 2589, Loss: 0.0004999936791136861, Final Batch Loss: 0.00024061676231212914\n",
      "Epoch 2590, Loss: 8.889471837392193e-05, Final Batch Loss: 8.220392919611186e-05\n",
      "Epoch 2591, Loss: 0.00017277398728765547, Final Batch Loss: 0.00015015428652986884\n",
      "Epoch 2592, Loss: 7.39983142921119e-05, Final Batch Loss: 6.193404988152906e-05\n",
      "Epoch 2593, Loss: 8.395666509386501e-05, Final Batch Loss: 7.806974463164806e-05\n",
      "Epoch 2594, Loss: 0.0035510740053723566, Final Batch Loss: 7.214157812995836e-05\n",
      "Epoch 2595, Loss: 0.0019591145623962802, Final Batch Loss: 0.0019550789147615433\n",
      "Epoch 2596, Loss: 0.0002281760180267156, Final Batch Loss: 0.00021596488659270108\n",
      "Epoch 2597, Loss: 3.142009200018947e-05, Final Batch Loss: 1.6037433852034155e-06\n",
      "Epoch 2598, Loss: 9.192421975967591e-05, Final Batch Loss: 6.243241386982845e-06\n",
      "Epoch 2599, Loss: 0.00019551904551917687, Final Batch Loss: 0.00011033713963115588\n",
      "Epoch 2600, Loss: 0.002157753217034042, Final Batch Loss: 0.002149947453290224\n",
      "Epoch 2601, Loss: 0.0002308405310031958, Final Batch Loss: 0.00015098082076292485\n",
      "Epoch 2602, Loss: 1.178515020683335e-05, Final Batch Loss: 1.1086591257480904e-05\n",
      "Epoch 2603, Loss: 0.0002235287320218049, Final Batch Loss: 2.9277092835400254e-05\n",
      "Epoch 2604, Loss: 0.0011571476742346931, Final Batch Loss: 1.0744942073870334e-06\n",
      "Epoch 2605, Loss: 3.150891598124872e-05, Final Batch Loss: 6.730944278388051e-06\n",
      "Epoch 2606, Loss: 0.00027523384778760374, Final Batch Loss: 0.00019881936896126717\n",
      "Epoch 2607, Loss: 3.7590367583106854e-05, Final Batch Loss: 2.0264799331926042e-06\n",
      "Epoch 2608, Loss: 2.0974399376427755e-05, Final Batch Loss: 1.4647849639004562e-05\n",
      "Epoch 2609, Loss: 0.0010368129842390772, Final Batch Loss: 3.549779285094701e-05\n",
      "Epoch 2610, Loss: 9.955905716196867e-05, Final Batch Loss: 8.863794391800184e-06\n",
      "Epoch 2611, Loss: 4.4647386857832316e-05, Final Batch Loss: 4.2680163460318e-05\n",
      "Epoch 2612, Loss: 0.00018602939462653012, Final Batch Loss: 5.776494163001189e-06\n",
      "Epoch 2613, Loss: 0.00013925648818258196, Final Batch Loss: 9.155877341981977e-05\n",
      "Epoch 2614, Loss: 7.028813706710935e-05, Final Batch Loss: 5.333249282557517e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2615, Loss: 1.7212523289344972e-05, Final Batch Loss: 6.5163826548086945e-06\n",
      "Epoch 2616, Loss: 0.00012492096175265033, Final Batch Loss: 2.7829113605548628e-05\n",
      "Epoch 2617, Loss: 3.819497055701504e-05, Final Batch Loss: 3.5765602660831064e-05\n",
      "Epoch 2618, Loss: 8.436692678515101e-05, Final Batch Loss: 7.98907276475802e-05\n",
      "Epoch 2619, Loss: 0.00021557223226409405, Final Batch Loss: 3.116365405730903e-05\n",
      "Epoch 2620, Loss: 4.374835771159269e-05, Final Batch Loss: 1.4773395378142595e-05\n",
      "Epoch 2621, Loss: 7.680629187234445e-05, Final Batch Loss: 1.9536410036380403e-06\n",
      "Epoch 2622, Loss: 0.0013322697204785072, Final Batch Loss: 8.535892447980586e-06\n",
      "Epoch 2623, Loss: 8.697095154275303e-06, Final Batch Loss: 3.6927142446074868e-06\n",
      "Epoch 2624, Loss: 0.00043658530739776324, Final Batch Loss: 1.711415643512737e-05\n",
      "Epoch 2625, Loss: 4.867490133619867e-05, Final Batch Loss: 2.4275843315990642e-05\n",
      "Epoch 2626, Loss: 8.678581980348099e-05, Final Batch Loss: 1.7878950529848225e-05\n",
      "Epoch 2627, Loss: 0.00010708996478570043, Final Batch Loss: 5.043917099101236e-06\n",
      "Epoch 2628, Loss: 7.264601208589738e-05, Final Batch Loss: 6.549306817760225e-06\n",
      "Epoch 2629, Loss: 4.8925179726211354e-05, Final Batch Loss: 3.602724245865829e-05\n",
      "Epoch 2630, Loss: 0.0012305032114454661, Final Batch Loss: 0.0012157768942415714\n",
      "Epoch 2631, Loss: 0.00027099220460513607, Final Batch Loss: 8.227754005929455e-05\n",
      "Epoch 2632, Loss: 0.000410048768571869, Final Batch Loss: 6.1497676142607816e-06\n",
      "Epoch 2633, Loss: 1.3937207313574618e-05, Final Batch Loss: 7.455975264747394e-06\n",
      "Epoch 2634, Loss: 0.00027785051861428656, Final Batch Loss: 3.979404937126674e-05\n",
      "Epoch 2635, Loss: 0.0015649579145247117, Final Batch Loss: 0.0014990671770647168\n",
      "Epoch 2636, Loss: 0.0008374102440029674, Final Batch Loss: 0.0008329568081535399\n",
      "Epoch 2637, Loss: 2.0228377479725168e-05, Final Batch Loss: 1.7111065972130746e-05\n",
      "Epoch 2638, Loss: 0.00036226791053195484, Final Batch Loss: 0.00032674893736839294\n",
      "Epoch 2639, Loss: 4.900557451037457e-05, Final Batch Loss: 1.2985028661205433e-06\n",
      "Epoch 2640, Loss: 9.363561684949673e-05, Final Batch Loss: 5.598450570687419e-06\n",
      "Epoch 2641, Loss: 7.065015961416066e-05, Final Batch Loss: 3.6038887628819793e-05\n",
      "Epoch 2642, Loss: 0.0010083142697112635, Final Batch Loss: 6.482427124865353e-06\n",
      "Epoch 2643, Loss: 3.191977111782762e-05, Final Batch Loss: 2.5298644686699845e-05\n",
      "Epoch 2644, Loss: 0.0010728601500886725, Final Batch Loss: 0.0010648912284523249\n",
      "Epoch 2645, Loss: 4.787288708030246e-05, Final Batch Loss: 3.6931640352122486e-05\n",
      "Epoch 2646, Loss: 2.2294119503385446e-05, Final Batch Loss: 1.465248374188377e-06\n",
      "Epoch 2647, Loss: 0.0006395992058969568, Final Batch Loss: 3.16176847263705e-05\n",
      "Epoch 2648, Loss: 0.00014653924790763995, Final Batch Loss: 0.0001325587509199977\n",
      "Epoch 2649, Loss: 8.141484431689605e-05, Final Batch Loss: 3.9323163946392015e-05\n",
      "Epoch 2650, Loss: 0.00010315415056538768, Final Batch Loss: 1.1779924534494057e-05\n",
      "Epoch 2651, Loss: 0.0016175031687453156, Final Batch Loss: 0.001604864839464426\n",
      "Epoch 2652, Loss: 0.00013476069216267206, Final Batch Loss: 4.589270247379318e-06\n",
      "Epoch 2653, Loss: 4.5457526539394166e-05, Final Batch Loss: 3.353458669153042e-05\n",
      "Epoch 2654, Loss: 0.0005667688237736002, Final Batch Loss: 0.00046594819286838174\n",
      "Epoch 2655, Loss: 0.003222545461539994, Final Batch Loss: 0.0032020886428654194\n",
      "Epoch 2656, Loss: 0.00014208518177838414, Final Batch Loss: 0.00013452583516482264\n",
      "Epoch 2657, Loss: 0.0001154524325102102, Final Batch Loss: 4.4642965804087e-05\n",
      "Epoch 2658, Loss: 2.1518835637834854e-05, Final Batch Loss: 1.1193618774996139e-05\n",
      "Epoch 2659, Loss: 8.305156825372251e-05, Final Batch Loss: 1.2225890714034904e-05\n",
      "Epoch 2660, Loss: 0.00012863646770711057, Final Batch Loss: 3.929511512978934e-05\n",
      "Epoch 2661, Loss: 0.00012374423386063427, Final Batch Loss: 2.5307221221737564e-05\n",
      "Epoch 2662, Loss: 7.346764004978468e-05, Final Batch Loss: 6.665137789241271e-06\n",
      "Epoch 2663, Loss: 0.0003079891830566339, Final Batch Loss: 0.0002453492197673768\n",
      "Epoch 2664, Loss: 0.0019755550310947, Final Batch Loss: 0.0006730727036483586\n",
      "Epoch 2665, Loss: 0.0002540548375691287, Final Batch Loss: 3.8553022022824734e-05\n",
      "Epoch 2666, Loss: 0.0013514461588783888, Final Batch Loss: 0.0013319329591467977\n",
      "Epoch 2667, Loss: 0.0018039411354493495, Final Batch Loss: 0.0018009222112596035\n",
      "Epoch 2668, Loss: 0.00035526036845112685, Final Batch Loss: 2.3631417207070626e-05\n",
      "Epoch 2669, Loss: 2.321703141205944e-05, Final Batch Loss: 9.802029126149137e-06\n",
      "Epoch 2670, Loss: 6.025118454999756e-05, Final Batch Loss: 4.918095874018036e-05\n",
      "Epoch 2671, Loss: 3.823169754468836e-05, Final Batch Loss: 2.035279067058582e-05\n",
      "Epoch 2672, Loss: 2.4564146769989748e-05, Final Batch Loss: 9.069725820154417e-06\n",
      "Epoch 2673, Loss: 9.317015792476013e-05, Final Batch Loss: 3.0419199902098626e-05\n",
      "Epoch 2674, Loss: 0.00023189054627437145, Final Batch Loss: 0.00018709173309616745\n",
      "Epoch 2675, Loss: 2.8285709504416445e-05, Final Batch Loss: 1.0479857337486465e-06\n",
      "Epoch 2676, Loss: 0.00022831656133348588, Final Batch Loss: 4.1529801819706336e-06\n",
      "Epoch 2677, Loss: 0.0018009813502430916, Final Batch Loss: 0.0013047403190284967\n",
      "Epoch 2678, Loss: 8.920484469854273e-05, Final Batch Loss: 6.439725984819233e-05\n",
      "Epoch 2679, Loss: 0.001069456634013477, Final Batch Loss: 7.591505436721491e-06\n",
      "Epoch 2680, Loss: 7.03398745827144e-06, Final Batch Loss: 2.3002157831797376e-06\n",
      "Epoch 2681, Loss: 4.862141940975562e-05, Final Batch Loss: 4.206316589261405e-05\n",
      "Epoch 2682, Loss: 4.948377136315685e-05, Final Batch Loss: 2.4906192265916616e-05\n",
      "Epoch 2683, Loss: 4.419140122990939e-05, Final Batch Loss: 4.099458601558581e-05\n",
      "Epoch 2684, Loss: 1.8203566469310317e-05, Final Batch Loss: 1.5044699466670863e-05\n",
      "Epoch 2685, Loss: 0.0010916881233242748, Final Batch Loss: 7.285686933755642e-06\n",
      "Epoch 2686, Loss: 0.0025658570443738427, Final Batch Loss: 2.5474214453424793e-06\n",
      "Epoch 2687, Loss: 4.94728728881455e-05, Final Batch Loss: 4.0628292481414974e-05\n",
      "Epoch 2688, Loss: 0.00011507759563755826, Final Batch Loss: 0.00011198361607966945\n",
      "Epoch 2689, Loss: 0.0014702193111588713, Final Batch Loss: 5.330677595338784e-05\n",
      "Epoch 2690, Loss: 0.001137278888563742, Final Batch Loss: 1.2554375643958338e-05\n",
      "Epoch 2691, Loss: 1.6408590227001696e-05, Final Batch Loss: 1.3949241292721126e-05\n",
      "Epoch 2692, Loss: 6.457943163695745e-05, Final Batch Loss: 6.048464638297446e-05\n",
      "Epoch 2693, Loss: 8.523297765350435e-06, Final Batch Loss: 3.1173058232525364e-06\n",
      "Epoch 2694, Loss: 0.0021958933648420498, Final Batch Loss: 0.0020733720157295465\n",
      "Epoch 2695, Loss: 0.0005754462836193852, Final Batch Loss: 0.00010283136361977085\n",
      "Epoch 2696, Loss: 3.305091127003834e-05, Final Batch Loss: 3.07003574562259e-05\n",
      "Epoch 2697, Loss: 0.000515569859999232, Final Batch Loss: 5.05859061377123e-05\n",
      "Epoch 2698, Loss: 0.0003101283818978118, Final Batch Loss: 4.1330076783197e-06\n",
      "Epoch 2699, Loss: 0.0024071503430604935, Final Batch Loss: 0.001462999964132905\n",
      "Epoch 2700, Loss: 0.0036338077625259757, Final Batch Loss: 0.0023872111923992634\n",
      "Epoch 2701, Loss: 2.539315482863458e-05, Final Batch Loss: 1.2808320207113866e-05\n",
      "Epoch 2702, Loss: 2.842181856976822e-05, Final Batch Loss: 2.314475023013074e-05\n",
      "Epoch 2703, Loss: 1.3366460407837621e-05, Final Batch Loss: 1.3195276551414281e-05\n",
      "Epoch 2704, Loss: 0.0016038447738537798, Final Batch Loss: 0.001583235221914947\n",
      "Epoch 2705, Loss: 3.341111369081773e-05, Final Batch Loss: 3.272257526987232e-05\n",
      "Epoch 2706, Loss: 3.0453939871222246e-05, Final Batch Loss: 4.022941539005842e-06\n",
      "Epoch 2707, Loss: 0.001650026528068338, Final Batch Loss: 0.0016473393188789487\n",
      "Epoch 2708, Loss: 0.0008999058809422422, Final Batch Loss: 1.312759195570834e-05\n",
      "Epoch 2709, Loss: 0.001070307443569618, Final Batch Loss: 0.001064673881046474\n",
      "Epoch 2710, Loss: 1.4685682344861561e-05, Final Batch Loss: 6.93130232320982e-06\n",
      "Epoch 2711, Loss: 0.0025833111358224414, Final Batch Loss: 0.0025550073478370905\n",
      "Epoch 2712, Loss: 1.7695008409646107e-06, Final Batch Loss: 5.231740942690521e-07\n",
      "Epoch 2713, Loss: 0.0014532843324559508, Final Batch Loss: 1.622857053007465e-05\n",
      "Epoch 2714, Loss: 4.076248023920925e-05, Final Batch Loss: 4.8086631068144925e-06\n",
      "Epoch 2715, Loss: 4.690734976975364e-05, Final Batch Loss: 4.67524341729586e-06\n",
      "Epoch 2716, Loss: 0.0007007097401583451, Final Batch Loss: 0.0006927163922227919\n",
      "Epoch 2717, Loss: 0.0021766933787148446, Final Batch Loss: 0.00039202391053549945\n",
      "Epoch 2718, Loss: 0.0011966238234890625, Final Batch Loss: 2.0536870579235256e-05\n",
      "Epoch 2719, Loss: 1.4562186152033973e-05, Final Batch Loss: 6.746177859895397e-06\n",
      "Epoch 2720, Loss: 3.8325545347106527e-05, Final Batch Loss: 3.6018369428347796e-05\n",
      "Epoch 2721, Loss: 0.001670723439019639, Final Batch Loss: 8.209527732105926e-05\n",
      "Epoch 2722, Loss: 2.595065188870649e-05, Final Batch Loss: 5.094412244943669e-06\n",
      "Epoch 2723, Loss: 0.002516066717362264, Final Batch Loss: 3.596820533857681e-05\n",
      "Epoch 2724, Loss: 0.0001128605981648434, Final Batch Loss: 3.3350723242620006e-05\n",
      "Epoch 2725, Loss: 0.000832693718621158, Final Batch Loss: 0.0008223517797887325\n",
      "Epoch 2726, Loss: 0.007007892973433627, Final Batch Loss: 0.0070027452893555164\n",
      "Epoch 2727, Loss: 0.001994607417145744, Final Batch Loss: 0.0001060774375218898\n",
      "Epoch 2728, Loss: 7.532927656939137e-05, Final Batch Loss: 1.7323395695711952e-06\n",
      "Epoch 2729, Loss: 2.046988629444968e-05, Final Batch Loss: 4.821815309696831e-06\n",
      "Epoch 2730, Loss: 1.0428533641970716e-05, Final Batch Loss: 4.719495791505324e-06\n",
      "Epoch 2731, Loss: 0.0012220347771290108, Final Batch Loss: 0.0012124830391258001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2732, Loss: 1.9464562683424447e-05, Final Batch Loss: 6.416817996068858e-06\n",
      "Epoch 2733, Loss: 0.0009272498409700347, Final Batch Loss: 0.0009198614279739559\n",
      "Epoch 2734, Loss: 0.00041948402213165537, Final Batch Loss: 3.5994053178001195e-05\n",
      "Epoch 2735, Loss: 0.0016409285562986042, Final Batch Loss: 4.024124791612849e-06\n",
      "Epoch 2736, Loss: 1.915283610287588e-05, Final Batch Loss: 4.21542972617317e-06\n",
      "Epoch 2737, Loss: 2.2411385316445376e-05, Final Batch Loss: 1.8792492483044043e-05\n",
      "Epoch 2738, Loss: 0.000186664896318689, Final Batch Loss: 0.00011199904838576913\n",
      "Epoch 2739, Loss: 1.5552662716800114e-05, Final Batch Loss: 1.0568087418505456e-06\n",
      "Epoch 2740, Loss: 0.004448933926141763, Final Batch Loss: 1.4112264580035117e-05\n",
      "Epoch 2741, Loss: 1.9467428955977084e-05, Final Batch Loss: 1.6148147551575676e-05\n",
      "Epoch 2742, Loss: 0.00022110382144546747, Final Batch Loss: 0.00021968249347992241\n",
      "Epoch 2743, Loss: 0.0012308512377785519, Final Batch Loss: 0.001167408307082951\n",
      "Epoch 2744, Loss: 7.82118640927365e-05, Final Batch Loss: 2.1497935449588113e-05\n",
      "Epoch 2745, Loss: 7.965297118062153e-05, Final Batch Loss: 4.853811697103083e-05\n",
      "Epoch 2746, Loss: 3.7565972888842225e-05, Final Batch Loss: 1.2968115697731264e-05\n",
      "Epoch 2747, Loss: 0.00024668250969739347, Final Batch Loss: 4.238534359046753e-07\n",
      "Epoch 2748, Loss: 5.277342279441655e-05, Final Batch Loss: 2.813775063259527e-05\n",
      "Epoch 2749, Loss: 0.00015855708613798924, Final Batch Loss: 1.2356612160147051e-06\n",
      "Epoch 2750, Loss: 4.844463001063559e-05, Final Batch Loss: 4.276032268535346e-05\n",
      "Epoch 2751, Loss: 0.0011109158513136208, Final Batch Loss: 0.0006055186968296766\n",
      "Epoch 2752, Loss: 0.0018912765353888972, Final Batch Loss: 1.699974927760195e-05\n",
      "Epoch 2753, Loss: 0.00023579731714562513, Final Batch Loss: 0.00019952558795921504\n",
      "Epoch 2754, Loss: 0.00011173175153089687, Final Batch Loss: 6.006222974974662e-05\n",
      "Epoch 2755, Loss: 9.140018391917692e-06, Final Batch Loss: 5.303366378939245e-06\n",
      "Epoch 2756, Loss: 0.0011495890357764438, Final Batch Loss: 0.0011417956557124853\n",
      "Epoch 2757, Loss: 9.711531254197325e-05, Final Batch Loss: 1.1622390729826293e-06\n",
      "Epoch 2758, Loss: 3.696256499097217e-05, Final Batch Loss: 3.1639981898479164e-05\n",
      "Epoch 2759, Loss: 0.0020631848310586065, Final Batch Loss: 0.001999977743253112\n",
      "Epoch 2760, Loss: 0.0005804282664030325, Final Batch Loss: 1.2491462257457897e-05\n",
      "Epoch 2761, Loss: 0.0008571940124966204, Final Batch Loss: 0.0008032582700252533\n",
      "Epoch 2762, Loss: 4.8208553835138446e-05, Final Batch Loss: 5.758157840318745e-06\n",
      "Epoch 2763, Loss: 0.001448175009500119, Final Batch Loss: 2.878189661714714e-05\n",
      "Epoch 2764, Loss: 2.3652484742342494e-05, Final Batch Loss: 2.24837931455113e-05\n",
      "Epoch 2765, Loss: 0.00010795887283165939, Final Batch Loss: 5.7335637393407524e-05\n",
      "Epoch 2766, Loss: 3.489559640001971e-05, Final Batch Loss: 1.0234723959001713e-05\n",
      "Epoch 2767, Loss: 0.00026144057665078435, Final Batch Loss: 2.4382223273278214e-05\n",
      "Epoch 2768, Loss: 1.029264967655763e-05, Final Batch Loss: 5.56995973965968e-06\n",
      "Epoch 2769, Loss: 0.0017320570404990576, Final Batch Loss: 0.0016664646100252867\n",
      "Epoch 2770, Loss: 0.00011645160338957794, Final Batch Loss: 4.12599511037115e-05\n",
      "Epoch 2771, Loss: 0.0002654238560353406, Final Batch Loss: 1.2985699868295342e-05\n",
      "Epoch 2772, Loss: 0.00010393369075245573, Final Batch Loss: 9.775957732927054e-05\n",
      "Epoch 2773, Loss: 5.821296213071037e-06, Final Batch Loss: 4.6192758418328594e-06\n",
      "Epoch 2774, Loss: 0.00978080977438367, Final Batch Loss: 2.6256337150698528e-05\n",
      "Epoch 2775, Loss: 0.0001600755012987065, Final Batch Loss: 8.056139449763577e-06\n",
      "Epoch 2776, Loss: 0.0007530745269832551, Final Batch Loss: 1.2388502909743693e-05\n",
      "Epoch 2777, Loss: 0.0010039378539659083, Final Batch Loss: 0.0005419903318397701\n",
      "Epoch 2778, Loss: 0.000846243419800885, Final Batch Loss: 0.00020501077233348042\n",
      "Epoch 2779, Loss: 0.0030101706706204823, Final Batch Loss: 2.720825591495668e-07\n",
      "Epoch 2780, Loss: 0.04381986826774664, Final Batch Loss: 0.04344656318426132\n",
      "Epoch 2781, Loss: 0.0007854195137042552, Final Batch Loss: 0.0007711941725574434\n",
      "Epoch 2782, Loss: 0.001402881584908755, Final Batch Loss: 6.015302460582461e-06\n",
      "Epoch 2783, Loss: 6.106841465225443e-05, Final Batch Loss: 2.1228370314929634e-05\n",
      "Epoch 2784, Loss: 0.00024241069331765175, Final Batch Loss: 6.410441710613668e-05\n",
      "Epoch 2785, Loss: 0.021928802350885235, Final Batch Loss: 0.00016743339074309915\n",
      "Epoch 2786, Loss: 0.0028786154580302536, Final Batch Loss: 0.002045075874775648\n",
      "Epoch 2787, Loss: 0.0002997476876771543, Final Batch Loss: 0.00025033100973814726\n",
      "Epoch 2788, Loss: 0.00022417932996177115, Final Batch Loss: 1.9618706573965028e-05\n",
      "Epoch 2789, Loss: 0.0003173072182107717, Final Batch Loss: 0.00015471338701900095\n",
      "Epoch 2790, Loss: 0.00030848140158923343, Final Batch Loss: 0.0002544392191339284\n",
      "Epoch 2791, Loss: 0.0003391599311726168, Final Batch Loss: 0.00021876150276511908\n",
      "Epoch 2792, Loss: 0.00018120231106877327, Final Batch Loss: 7.860976620577276e-05\n",
      "Epoch 2793, Loss: 0.0015491460799239576, Final Batch Loss: 0.000987015780992806\n",
      "Epoch 2794, Loss: 0.0011571920758797205, Final Batch Loss: 1.1348775842634495e-05\n",
      "Epoch 2795, Loss: 0.0024695175379747525, Final Batch Loss: 0.002244511153548956\n",
      "Epoch 2796, Loss: 0.0001843532700149808, Final Batch Loss: 4.196318695903756e-05\n",
      "Epoch 2797, Loss: 0.00020446144480956718, Final Batch Loss: 0.00012166419764980674\n",
      "Epoch 2798, Loss: 4.072740921401419e-05, Final Batch Loss: 3.176182144670747e-05\n",
      "Epoch 2799, Loss: 0.001794197945855558, Final Batch Loss: 0.0016662927810102701\n",
      "Epoch 2800, Loss: 0.0003715558705152944, Final Batch Loss: 8.500924741383642e-05\n",
      "Epoch 2801, Loss: 0.0033028898906195536, Final Batch Loss: 0.00016952377336565405\n",
      "Epoch 2802, Loss: 4.872911813436076e-05, Final Batch Loss: 2.9282597097335383e-05\n",
      "Epoch 2803, Loss: 5.942334018982365e-05, Final Batch Loss: 5.2488983783405274e-05\n",
      "Epoch 2804, Loss: 0.0002742065553320572, Final Batch Loss: 6.763382407370955e-05\n",
      "Epoch 2805, Loss: 0.00010662710883480031, Final Batch Loss: 8.695149153936654e-05\n",
      "Epoch 2806, Loss: 0.0012963653880433412, Final Batch Loss: 0.0012677423655986786\n",
      "Epoch 2807, Loss: 0.0002694875802262686, Final Batch Loss: 9.067632345249876e-05\n",
      "Epoch 2808, Loss: 9.152705297310604e-05, Final Batch Loss: 8.353860175702721e-05\n",
      "Epoch 2809, Loss: 2.8033824492013082e-05, Final Batch Loss: 9.215196769218892e-06\n",
      "Epoch 2810, Loss: 0.0035697850726137403, Final Batch Loss: 5.948622856521979e-06\n",
      "Epoch 2811, Loss: 0.00016935768508119509, Final Batch Loss: 0.0001547310675960034\n",
      "Epoch 2812, Loss: 0.0001053845917340368, Final Batch Loss: 3.2844298402778804e-05\n",
      "Epoch 2813, Loss: 0.003020980046130717, Final Batch Loss: 0.0010792206740006804\n",
      "Epoch 2814, Loss: 0.00013089556159684435, Final Batch Loss: 6.778653187211603e-05\n",
      "Epoch 2815, Loss: 0.0001227546927111689, Final Batch Loss: 4.984184124623425e-05\n",
      "Epoch 2816, Loss: 5.555908501264639e-05, Final Batch Loss: 3.0003899155417457e-05\n",
      "Epoch 2817, Loss: 5.65774771530414e-05, Final Batch Loss: 2.340263563382905e-05\n",
      "Epoch 2818, Loss: 0.001721809385344386, Final Batch Loss: 0.0009628263651393354\n",
      "Epoch 2819, Loss: 0.000971874498645775, Final Batch Loss: 0.00013723729352932423\n",
      "Epoch 2820, Loss: 0.0009841786541073816, Final Batch Loss: 1.6389387383242138e-05\n",
      "Epoch 2821, Loss: 0.0003003102719958406, Final Batch Loss: 3.0679377232445404e-05\n",
      "Epoch 2822, Loss: 0.0005792861848021857, Final Batch Loss: 8.463113772450015e-05\n",
      "Epoch 2823, Loss: 5.196814345254097e-05, Final Batch Loss: 4.2369920265628025e-05\n",
      "Epoch 2824, Loss: 0.0003668771969387308, Final Batch Loss: 0.0001867039391072467\n",
      "Epoch 2825, Loss: 0.004440905679075513, Final Batch Loss: 7.595602801302448e-05\n",
      "Epoch 2826, Loss: 0.00018833969079423696, Final Batch Loss: 0.00015432813961524516\n",
      "Epoch 2827, Loss: 0.009967174904886633, Final Batch Loss: 0.00017366703832522035\n",
      "Epoch 2828, Loss: 0.0010292301594745368, Final Batch Loss: 0.00017528791795484722\n",
      "Epoch 2829, Loss: 0.00018929902762465645, Final Batch Loss: 1.8618842659634538e-05\n",
      "Epoch 2830, Loss: 0.03612495632842183, Final Batch Loss: 0.0005787205882370472\n",
      "Epoch 2831, Loss: 0.05477116964539164, Final Batch Loss: 0.05472136288881302\n",
      "Epoch 2832, Loss: 0.0003710594519361621, Final Batch Loss: 0.0003417005355004221\n",
      "Epoch 2833, Loss: 0.004616514983354136, Final Batch Loss: 0.0043710628524422646\n",
      "Epoch 2834, Loss: 0.015685488237068057, Final Batch Loss: 0.0020579311531037092\n",
      "Epoch 2835, Loss: 0.0177303075324744, Final Batch Loss: 0.0021656330209225416\n",
      "Epoch 2836, Loss: 0.0024284686951432377, Final Batch Loss: 0.0020575278904289007\n",
      "Epoch 2837, Loss: 0.0022700699628330767, Final Batch Loss: 0.0009674504981376231\n",
      "Epoch 2838, Loss: 0.0012932436002301984, Final Batch Loss: 0.0012036674888804555\n",
      "Epoch 2839, Loss: 0.00020675155656135757, Final Batch Loss: 0.00020055517961736768\n",
      "Epoch 2840, Loss: 0.00047424058902834076, Final Batch Loss: 2.1545232812059112e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2841, Loss: 0.011958392104133964, Final Batch Loss: 0.0012313572224229574\n",
      "Epoch 2842, Loss: 3.6105377148487605e-05, Final Batch Loss: 1.0337937055737711e-05\n",
      "Epoch 2843, Loss: 0.00013738462075707503, Final Batch Loss: 3.247295171604492e-05\n",
      "Epoch 2844, Loss: 2.9326625963221886e-05, Final Batch Loss: 3.670218802653835e-06\n",
      "Epoch 2845, Loss: 2.914706783485599e-05, Final Batch Loss: 1.9799785150098614e-05\n",
      "Epoch 2846, Loss: 9.29467369132908e-05, Final Batch Loss: 8.657883881824091e-05\n",
      "Epoch 2847, Loss: 8.946046511937311e-05, Final Batch Loss: 8.795857866061851e-05\n",
      "Epoch 2848, Loss: 0.0019571229931898415, Final Batch Loss: 0.0007935970206744969\n",
      "Epoch 2849, Loss: 4.60127530459431e-05, Final Batch Loss: 4.064336826559156e-05\n",
      "Epoch 2850, Loss: 0.0013206655021349434, Final Batch Loss: 0.0013143518008291721\n",
      "Epoch 2851, Loss: 4.168761415712652e-05, Final Batch Loss: 4.772297415911453e-06\n",
      "Epoch 2852, Loss: 0.0019476424204185605, Final Batch Loss: 0.0013792248209938407\n",
      "Epoch 2853, Loss: 5.530962789634941e-05, Final Batch Loss: 4.798024019692093e-05\n",
      "Epoch 2854, Loss: 4.49650724476669e-05, Final Batch Loss: 2.824045623128768e-05\n",
      "Epoch 2855, Loss: 7.976636879902799e-05, Final Batch Loss: 7.402774645015597e-05\n",
      "Epoch 2856, Loss: 0.0021997556505084503, Final Batch Loss: 4.113898103241809e-05\n",
      "Epoch 2857, Loss: 3.649823793239193e-05, Final Batch Loss: 8.939226063375827e-06\n",
      "Epoch 2858, Loss: 0.00031267432859749533, Final Batch Loss: 1.0191030014539137e-05\n",
      "Epoch 2859, Loss: 5.3146996833675075e-05, Final Batch Loss: 4.7070316213648766e-05\n",
      "Epoch 2860, Loss: 0.00012392799180815928, Final Batch Loss: 0.00010007384116761386\n",
      "Epoch 2861, Loss: 0.00017440214833186474, Final Batch Loss: 0.00014515628572553396\n",
      "Epoch 2862, Loss: 0.00017486229990026914, Final Batch Loss: 4.8249868996208534e-05\n",
      "Epoch 2863, Loss: 0.00034594276803545654, Final Batch Loss: 0.0002561500878073275\n",
      "Epoch 2864, Loss: 0.005905381207867322, Final Batch Loss: 4.057576461491408e-06\n",
      "Epoch 2865, Loss: 0.002087943248625379, Final Batch Loss: 0.0020449517760425806\n",
      "Epoch 2866, Loss: 0.00018879882827604888, Final Batch Loss: 0.00018296240887138993\n",
      "Epoch 2867, Loss: 7.10285603418015e-05, Final Batch Loss: 5.6959877838380635e-05\n",
      "Epoch 2868, Loss: 6.575927272933768e-05, Final Batch Loss: 4.555372470349539e-06\n",
      "Epoch 2869, Loss: 9.008567212731577e-05, Final Batch Loss: 2.4128243239829317e-05\n",
      "Epoch 2870, Loss: 0.00010762896636151709, Final Batch Loss: 6.41449514660053e-05\n",
      "Epoch 2871, Loss: 0.0002259775383208762, Final Batch Loss: 8.3268560047145e-06\n",
      "Epoch 2872, Loss: 0.0005915760702919215, Final Batch Loss: 0.00018340349197387695\n",
      "Epoch 2873, Loss: 7.429194010910578e-05, Final Batch Loss: 5.269288521958515e-06\n",
      "Epoch 2874, Loss: 0.0016315309803758282, Final Batch Loss: 0.001578026101924479\n",
      "Epoch 2875, Loss: 0.0009310499299317598, Final Batch Loss: 6.378570105880499e-06\n",
      "Epoch 2876, Loss: 0.00013647932519234018, Final Batch Loss: 0.00012625813542399555\n",
      "Epoch 2877, Loss: 2.355978949708515e-05, Final Batch Loss: 4.5841811697755475e-06\n",
      "Epoch 2878, Loss: 7.992525297595421e-06, Final Batch Loss: 4.263632035872433e-06\n",
      "Epoch 2879, Loss: 0.0007637253220309503, Final Batch Loss: 9.458035492571071e-05\n",
      "Epoch 2880, Loss: 2.491090890544001e-05, Final Batch Loss: 8.04442424851004e-06\n",
      "Epoch 2881, Loss: 8.878782955434872e-05, Final Batch Loss: 1.0200538781646173e-05\n",
      "Epoch 2882, Loss: 0.0006687809654977173, Final Batch Loss: 4.6160101192072034e-05\n",
      "Epoch 2883, Loss: 4.7921581426635385e-05, Final Batch Loss: 2.661634971445892e-05\n",
      "Epoch 2884, Loss: 0.0020779192527697887, Final Batch Loss: 0.002024672692641616\n",
      "Epoch 2885, Loss: 5.115769454278052e-05, Final Batch Loss: 4.9450205551693216e-05\n",
      "Epoch 2886, Loss: 0.000282955625152681, Final Batch Loss: 0.00024295887851621956\n",
      "Epoch 2887, Loss: 0.00011705221004376654, Final Batch Loss: 9.426843462279066e-05\n",
      "Epoch 2888, Loss: 7.970955039127148e-06, Final Batch Loss: 4.838839686271967e-06\n",
      "Epoch 2889, Loss: 0.0002871195029001683, Final Batch Loss: 0.00024884086451493204\n",
      "Epoch 2890, Loss: 5.608316496363841e-05, Final Batch Loss: 2.955813761218451e-05\n",
      "Epoch 2891, Loss: 0.0002603440989332739, Final Batch Loss: 3.2302606996381655e-05\n",
      "Epoch 2892, Loss: 4.157443527219584e-05, Final Batch Loss: 8.401383638556581e-06\n",
      "Epoch 2893, Loss: 0.00012583842180902138, Final Batch Loss: 1.7842896340880543e-05\n",
      "Epoch 2894, Loss: 0.0015877972764428705, Final Batch Loss: 0.001523012644611299\n",
      "Epoch 2895, Loss: 0.00022316480317385867, Final Batch Loss: 0.00010768388892756775\n",
      "Epoch 2896, Loss: 0.0002634694137668703, Final Batch Loss: 0.00024077096895780414\n",
      "Epoch 2897, Loss: 0.00013156234490452334, Final Batch Loss: 1.1184056347701699e-05\n",
      "Epoch 2898, Loss: 4.9584697762838914e-05, Final Batch Loss: 1.2256530226295581e-06\n",
      "Epoch 2899, Loss: 0.0011555103842511016, Final Batch Loss: 1.3515377759176772e-06\n",
      "Epoch 2900, Loss: 0.0020499967504292727, Final Batch Loss: 0.0005013897316530347\n",
      "Epoch 2901, Loss: 0.00046682536412845366, Final Batch Loss: 4.4662458094535396e-05\n",
      "Epoch 2902, Loss: 4.2986950575141236e-05, Final Batch Loss: 1.6766105545684695e-05\n",
      "Epoch 2903, Loss: 0.0008106223176582716, Final Batch Loss: 6.901550659677014e-05\n",
      "Epoch 2904, Loss: 3.63870058208704e-05, Final Batch Loss: 3.1788436899660155e-05\n",
      "Epoch 2905, Loss: 0.001363936909797303, Final Batch Loss: 2.770501623672317e-07\n",
      "Epoch 2906, Loss: 0.0001707015144347679, Final Batch Loss: 1.726265691104345e-05\n",
      "Epoch 2907, Loss: 3.083001411141595e-05, Final Batch Loss: 1.2874444109911565e-05\n",
      "Epoch 2908, Loss: 1.5249347939061408e-05, Final Batch Loss: 1.3417901755019557e-05\n",
      "Epoch 2909, Loss: 0.00011545226061571157, Final Batch Loss: 1.0765120350697543e-05\n",
      "Epoch 2910, Loss: 0.00021215571177890524, Final Batch Loss: 0.00014919204113539308\n",
      "Epoch 2911, Loss: 0.00020911638421239331, Final Batch Loss: 0.00014090815966483206\n",
      "Epoch 2912, Loss: 1.4149818753139698e-05, Final Batch Loss: 1.9606025034590857e-06\n",
      "Epoch 2913, Loss: 0.00022930326497316855, Final Batch Loss: 1.3631416777570848e-06\n",
      "Epoch 2914, Loss: 0.0006561992777278647, Final Batch Loss: 0.0001411815610481426\n",
      "Epoch 2915, Loss: 0.0013997764726809692, Final Batch Loss: 0.0013782382011413574\n",
      "Epoch 2916, Loss: 0.00012145245636929758, Final Batch Loss: 9.177914762403816e-05\n",
      "Epoch 2917, Loss: 7.073660708556417e-05, Final Batch Loss: 2.227766344731208e-05\n",
      "Epoch 2918, Loss: 0.004447657690661799, Final Batch Loss: 1.2880948361271294e-06\n",
      "Epoch 2919, Loss: 9.590510217094561e-06, Final Batch Loss: 4.8086631068144925e-06\n",
      "Epoch 2920, Loss: 4.3166116483916994e-05, Final Batch Loss: 4.094886207894888e-06\n",
      "Epoch 2921, Loss: 1.3800088709103875e-05, Final Batch Loss: 5.393509127316065e-06\n",
      "Epoch 2922, Loss: 0.00025135343730653403, Final Batch Loss: 1.470876577513991e-05\n",
      "Epoch 2923, Loss: 0.000985439335636329, Final Batch Loss: 1.9971215806435794e-05\n",
      "Epoch 2924, Loss: 0.00019118061209155712, Final Batch Loss: 0.00016074209997896105\n",
      "Epoch 2925, Loss: 1.710976539470721e-05, Final Batch Loss: 4.0681998143554665e-06\n",
      "Epoch 2926, Loss: 0.003722259876667522, Final Batch Loss: 0.003526868997141719\n",
      "Epoch 2927, Loss: 6.546734084622585e-06, Final Batch Loss: 2.619580072860117e-06\n",
      "Epoch 2928, Loss: 0.00012552423504530452, Final Batch Loss: 7.61217379476875e-05\n",
      "Epoch 2929, Loss: 4.912912663712632e-05, Final Batch Loss: 3.310138708911836e-05\n",
      "Epoch 2930, Loss: 4.6553581341868266e-05, Final Batch Loss: 5.707890522899106e-06\n",
      "Epoch 2931, Loss: 2.358076562813949e-05, Final Batch Loss: 1.726990558381658e-05\n",
      "Epoch 2932, Loss: 5.646039357998234e-05, Final Batch Loss: 5.68997393202153e-07\n",
      "Epoch 2933, Loss: 7.091584711815813e-05, Final Batch Loss: 6.495048728538677e-05\n",
      "Epoch 2934, Loss: 0.005353733757146983, Final Batch Loss: 0.005342746619135141\n",
      "Epoch 2935, Loss: 4.8862502808333375e-05, Final Batch Loss: 2.7037451218347996e-05\n",
      "Epoch 2936, Loss: 0.00024517918973288033, Final Batch Loss: 3.0582978070015088e-06\n",
      "Epoch 2937, Loss: 0.00010105973524332512, Final Batch Loss: 8.039763633860275e-05\n",
      "Epoch 2938, Loss: 0.00013761946956947213, Final Batch Loss: 4.082116902281996e-06\n",
      "Epoch 2939, Loss: 0.00010156836287933402, Final Batch Loss: 7.008890679571778e-05\n",
      "Epoch 2940, Loss: 0.00015599751714034937, Final Batch Loss: 0.00013592575851362199\n",
      "Epoch 2941, Loss: 0.0002981139987241477, Final Batch Loss: 0.00027894435334019363\n",
      "Epoch 2942, Loss: 0.0014566781756002456, Final Batch Loss: 0.001432941877283156\n",
      "Epoch 2943, Loss: 0.0012929534865406822, Final Batch Loss: 1.7742719364832737e-06\n",
      "Epoch 2944, Loss: 1.909976617753273e-05, Final Batch Loss: 1.1098682080046274e-05\n",
      "Epoch 2945, Loss: 7.804725976257032e-05, Final Batch Loss: 1.1727366882041679e-06\n",
      "Epoch 2946, Loss: 2.5153260821753065e-05, Final Batch Loss: 2.6443547085364116e-06\n",
      "Epoch 2947, Loss: 7.626543174410472e-05, Final Batch Loss: 6.799554830649868e-05\n",
      "Epoch 2948, Loss: 0.0002971824287669733, Final Batch Loss: 0.0002375929761910811\n",
      "Epoch 2949, Loss: 3.72419035556959e-05, Final Batch Loss: 1.200645237986464e-05\n",
      "Epoch 2950, Loss: 0.0010543622775003314, Final Batch Loss: 0.0006803955766372383\n",
      "Epoch 2951, Loss: 3.188219352523447e-05, Final Batch Loss: 2.4772412871243432e-05\n",
      "Epoch 2952, Loss: 5.757673943662667e-05, Final Batch Loss: 5.187064380152151e-05\n",
      "Epoch 2953, Loss: 2.406127441645367e-05, Final Batch Loss: 1.028633960231673e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2954, Loss: 6.365512854245026e-05, Final Batch Loss: 6.079434751882218e-05\n",
      "Epoch 2955, Loss: 0.002340999315492809, Final Batch Loss: 0.0006733648478984833\n",
      "Epoch 2956, Loss: 8.008184522623196e-05, Final Batch Loss: 4.381678081699647e-05\n",
      "Epoch 2957, Loss: 2.0295474541853764e-05, Final Batch Loss: 2.616263600430102e-06\n",
      "Epoch 2958, Loss: 3.177346661686897e-05, Final Batch Loss: 1.2539123417809606e-05\n",
      "Epoch 2959, Loss: 0.0007410983562294859, Final Batch Loss: 0.0007198502426035702\n",
      "Epoch 2960, Loss: 2.845647577487398e-05, Final Batch Loss: 1.233851071447134e-05\n",
      "Epoch 2961, Loss: 0.0008619616110081552, Final Batch Loss: 2.8236287107574753e-05\n",
      "Epoch 2962, Loss: 0.00025789945902943145, Final Batch Loss: 2.0628776837838814e-06\n",
      "Epoch 2963, Loss: 4.675648648344577e-05, Final Batch Loss: 6.83234759435436e-07\n",
      "Epoch 2964, Loss: 5.537183142223512e-06, Final Batch Loss: 3.4897664136224193e-06\n",
      "Epoch 2965, Loss: 2.5112342882493977e-05, Final Batch Loss: 2.1111383830429986e-05\n",
      "Epoch 2966, Loss: 7.093906106092618e-06, Final Batch Loss: 5.228183454164537e-06\n",
      "Epoch 2967, Loss: 0.00021316937454685103, Final Batch Loss: 0.00018272773013450205\n",
      "Epoch 2968, Loss: 8.843952673487365e-05, Final Batch Loss: 7.187805749708787e-05\n",
      "Epoch 2969, Loss: 0.0034782279981300235, Final Batch Loss: 0.0018384965369477868\n",
      "Epoch 2970, Loss: 0.00026444982995599275, Final Batch Loss: 8.695845281181391e-06\n",
      "Epoch 2971, Loss: 3.310625379526755e-05, Final Batch Loss: 3.1929330361890607e-06\n",
      "Epoch 2972, Loss: 0.0004906653075522627, Final Batch Loss: 0.0004818679881282151\n",
      "Epoch 2973, Loss: 1.2162973234808305e-05, Final Batch Loss: 2.64228901869501e-06\n",
      "Epoch 2974, Loss: 6.729566484864336e-05, Final Batch Loss: 5.169420182937756e-05\n",
      "Epoch 2975, Loss: 7.922192253317917e-05, Final Batch Loss: 7.466744864359498e-05\n",
      "Epoch 2976, Loss: 2.116898394888267e-05, Final Batch Loss: 1.820142279029824e-05\n",
      "Epoch 2977, Loss: 0.00045594397670356557, Final Batch Loss: 0.0004382918414194137\n",
      "Epoch 2978, Loss: 6.383759773598285e-05, Final Batch Loss: 1.4043959708942566e-05\n",
      "Epoch 2979, Loss: 1.62211072165519e-05, Final Batch Loss: 4.1563998820493e-06\n",
      "Epoch 2980, Loss: 8.37245079310378e-06, Final Batch Loss: 6.107110039010877e-06\n",
      "Epoch 2981, Loss: 9.807216520130169e-05, Final Batch Loss: 8.067924500210211e-05\n",
      "Epoch 2982, Loss: 2.2082067516748793e-05, Final Batch Loss: 1.9594128389144316e-05\n",
      "Epoch 2983, Loss: 6.362880321830744e-05, Final Batch Loss: 5.900479663978331e-05\n",
      "Epoch 2984, Loss: 2.385147126915399e-05, Final Batch Loss: 1.3330006368050817e-05\n",
      "Epoch 2985, Loss: 2.124401055425551e-05, Final Batch Loss: 1.9379716832190752e-05\n",
      "Epoch 2986, Loss: 0.0007880471930548083, Final Batch Loss: 6.227968697203323e-06\n",
      "Epoch 2987, Loss: 9.047915682458552e-06, Final Batch Loss: 2.962902271974599e-06\n",
      "Epoch 2988, Loss: 0.00018174140677729156, Final Batch Loss: 0.0001535875489935279\n",
      "Epoch 2989, Loss: 1.6185257777578954e-05, Final Batch Loss: 1.4721431398356799e-05\n",
      "Epoch 2990, Loss: 6.403991847037105e-05, Final Batch Loss: 5.131270518177189e-05\n",
      "Epoch 2991, Loss: 8.663096741656773e-05, Final Batch Loss: 1.158369195763953e-05\n",
      "Epoch 2992, Loss: 0.0006238349596969783, Final Batch Loss: 0.0004119510995224118\n",
      "Epoch 2993, Loss: 0.0009860353166004643, Final Batch Loss: 0.00019479721959214658\n",
      "Epoch 2994, Loss: 2.1486256173375295e-05, Final Batch Loss: 6.57203463561018e-06\n",
      "Epoch 2995, Loss: 3.599212141125463e-05, Final Batch Loss: 7.325015758397058e-06\n",
      "Epoch 2996, Loss: 0.000663188633552636, Final Batch Loss: 2.8674663553829305e-05\n",
      "Epoch 2997, Loss: 6.937057958111836e-05, Final Batch Loss: 6.804835720686242e-05\n",
      "Epoch 2998, Loss: 4.163697667536326e-05, Final Batch Loss: 2.4784065317362547e-05\n",
      "Epoch 2999, Loss: 2.1426136186164513e-05, Final Batch Loss: 1.4381874962055008e-06\n",
      "Epoch 3000, Loss: 8.892587402442587e-06, Final Batch Loss: 3.78635718334408e-06\n",
      "Epoch 3001, Loss: 1.4711743460793514e-05, Final Batch Loss: 1.3095362191961613e-05\n",
      "Epoch 3002, Loss: 8.196118983505585e-06, Final Batch Loss: 6.809532806073548e-06\n",
      "Epoch 3003, Loss: 8.85536030637013e-06, Final Batch Loss: 4.87314196107036e-07\n",
      "Epoch 3004, Loss: 4.283491398382466e-05, Final Batch Loss: 1.5271847587428056e-05\n",
      "Epoch 3005, Loss: 0.0015283854922927276, Final Batch Loss: 5.118596618558513e-06\n",
      "Epoch 3006, Loss: 9.438342112844111e-05, Final Batch Loss: 8.382006490137428e-05\n",
      "Epoch 3007, Loss: 2.718541418289533e-05, Final Batch Loss: 1.0133203431905713e-05\n",
      "Epoch 3008, Loss: 1.796590413505328e-05, Final Batch Loss: 5.2579193834390026e-06\n",
      "Epoch 3009, Loss: 9.763403340912191e-06, Final Batch Loss: 2.744941411947366e-06\n",
      "Epoch 3010, Loss: 0.00012336117100630872, Final Batch Loss: 7.93590459124971e-07\n",
      "Epoch 3011, Loss: 1.9710572360054357e-05, Final Batch Loss: 7.180712145782309e-06\n",
      "Epoch 3012, Loss: 0.0016797142543509835, Final Batch Loss: 0.0016572065651416779\n",
      "Epoch 3013, Loss: 4.943492706388497e-05, Final Batch Loss: 1.0121522109329817e-06\n",
      "Epoch 3014, Loss: 3.953470741180354e-05, Final Batch Loss: 5.451411652757088e-06\n",
      "Epoch 3015, Loss: 0.00019844221969833598, Final Batch Loss: 0.00019569459254853427\n",
      "Epoch 3016, Loss: 0.0004528484096226748, Final Batch Loss: 3.483119871816598e-05\n",
      "Epoch 3017, Loss: 0.0015116002286958974, Final Batch Loss: 2.185139965149574e-05\n",
      "Epoch 3018, Loss: 2.1175738766032737e-05, Final Batch Loss: 1.1655753951345105e-05\n",
      "Epoch 3019, Loss: 3.345971526869107e-05, Final Batch Loss: 1.2440783393685706e-05\n",
      "Epoch 3020, Loss: 0.001509382261247083, Final Batch Loss: 8.380960025533568e-06\n",
      "Epoch 3021, Loss: 5.542292251448089e-05, Final Batch Loss: 5.347183832782321e-05\n",
      "Epoch 3022, Loss: 0.00044593197890208103, Final Batch Loss: 2.5216842914232984e-05\n",
      "Epoch 3023, Loss: 0.00019288206567580346, Final Batch Loss: 0.0001664766314206645\n",
      "Epoch 3024, Loss: 0.00015428069673362188, Final Batch Loss: 0.0001368273515254259\n",
      "Epoch 3025, Loss: 2.9037229978712276e-05, Final Batch Loss: 2.1303889297996648e-05\n",
      "Epoch 3026, Loss: 0.0008437236811005278, Final Batch Loss: 5.444480848382227e-06\n",
      "Epoch 3027, Loss: 9.656657312007155e-05, Final Batch Loss: 7.800357707310468e-05\n",
      "Epoch 3028, Loss: 6.654791195614962e-05, Final Batch Loss: 5.880542448721826e-05\n",
      "Epoch 3029, Loss: 6.390743578776892e-06, Final Batch Loss: 4.761925538332434e-06\n",
      "Epoch 3030, Loss: 1.2388672416818736e-05, Final Batch Loss: 1.1301520316919778e-05\n",
      "Epoch 3031, Loss: 1.9863914531015325e-05, Final Batch Loss: 8.709957910468802e-06\n",
      "Epoch 3032, Loss: 2.3306643925025128e-05, Final Batch Loss: 6.998812750680372e-06\n",
      "Epoch 3033, Loss: 0.0003026491540367715, Final Batch Loss: 0.00022074225125834346\n",
      "Epoch 3034, Loss: 1.94615212762983e-05, Final Batch Loss: 1.916684050229378e-05\n",
      "Epoch 3035, Loss: 2.5873136110021733e-05, Final Batch Loss: 1.5699049981776625e-05\n",
      "Epoch 3036, Loss: 1.227864504471654e-05, Final Batch Loss: 1.0109612958331127e-05\n",
      "Epoch 3037, Loss: 0.0001084705836547073, Final Batch Loss: 5.5611581046832725e-05\n",
      "Epoch 3038, Loss: 0.0038425250522777787, Final Batch Loss: 0.0038320927415043116\n",
      "Epoch 3039, Loss: 3.23257145282696e-05, Final Batch Loss: 2.695519469853025e-05\n",
      "Epoch 3040, Loss: 4.371484124021663e-05, Final Batch Loss: 4.135211565881036e-05\n",
      "Epoch 3041, Loss: 0.0014227034407667816, Final Batch Loss: 0.0014041727408766747\n",
      "Epoch 3042, Loss: 2.9275477572809905e-05, Final Batch Loss: 1.649228397582192e-05\n",
      "Epoch 3043, Loss: 0.0015210262859000068, Final Batch Loss: 1.2350860743026715e-06\n",
      "Epoch 3044, Loss: 6.666942294941691e-05, Final Batch Loss: 3.394341320017702e-06\n",
      "Epoch 3045, Loss: 7.889915650594048e-06, Final Batch Loss: 5.051554126112023e-06\n",
      "Epoch 3046, Loss: 0.0014625132171204314, Final Batch Loss: 0.0013389191590249538\n",
      "Epoch 3047, Loss: 2.4369062089135696e-05, Final Batch Loss: 1.231758801623073e-06\n",
      "Epoch 3048, Loss: 0.0011125091659778263, Final Batch Loss: 1.4510002074530348e-05\n",
      "Epoch 3049, Loss: 0.0005355233462296383, Final Batch Loss: 1.410548179592297e-06\n",
      "Epoch 3050, Loss: 4.891637308901409e-05, Final Batch Loss: 8.622909263067413e-06\n",
      "Epoch 3051, Loss: 8.835772223392269e-05, Final Batch Loss: 8.420254744123667e-05\n",
      "Epoch 3052, Loss: 1.4396021583706897e-06, Final Batch Loss: 8.245007165896823e-07\n",
      "Epoch 3053, Loss: 3.131377320642059e-05, Final Batch Loss: 2.099857510984293e-06\n",
      "Epoch 3054, Loss: 0.0008005419583696494, Final Batch Loss: 3.1991000923881074e-06\n",
      "Epoch 3055, Loss: 1.4369682503456715e-05, Final Batch Loss: 9.393012078362517e-06\n",
      "Epoch 3056, Loss: 3.293164172646357e-05, Final Batch Loss: 1.1438412002462428e-05\n",
      "Epoch 3057, Loss: 3.4158040307374904e-05, Final Batch Loss: 5.934820819675224e-06\n",
      "Epoch 3058, Loss: 1.2716622677544365e-05, Final Batch Loss: 6.19376078248024e-06\n",
      "Epoch 3059, Loss: 3.5331187973497435e-05, Final Batch Loss: 1.750767114572227e-05\n",
      "Epoch 3060, Loss: 0.00025459061362198554, Final Batch Loss: 5.3642052080249414e-05\n",
      "Epoch 3061, Loss: 0.0008023967602639459, Final Batch Loss: 0.0006906818016432226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3062, Loss: 2.2283086082097725e-05, Final Batch Loss: 2.7494463665789226e-06\n",
      "Epoch 3063, Loss: 0.0005626907995974761, Final Batch Loss: 0.0005475315847434103\n",
      "Epoch 3064, Loss: 0.0013385929087235127, Final Batch Loss: 4.34225112257991e-05\n",
      "Epoch 3065, Loss: 2.3071713826539053e-05, Final Batch Loss: 2.1403808204922825e-05\n",
      "Epoch 3066, Loss: 0.00034872100650318316, Final Batch Loss: 0.0003434119571465999\n",
      "Epoch 3067, Loss: 0.0012594254494615598, Final Batch Loss: 1.1172638551215641e-05\n",
      "Epoch 3068, Loss: 0.0001004948735499056, Final Batch Loss: 7.533186362707056e-06\n",
      "Epoch 3069, Loss: 2.264408408336749e-05, Final Batch Loss: 3.502905883578933e-06\n",
      "Epoch 3070, Loss: 4.0636901758261956e-05, Final Batch Loss: 2.0907706129946746e-05\n",
      "Epoch 3071, Loss: 4.920534138364019e-05, Final Batch Loss: 4.2982373997801915e-05\n",
      "Epoch 3072, Loss: 1.3326517091627466e-05, Final Batch Loss: 4.636300673155347e-06\n",
      "Epoch 3073, Loss: 0.00011898977754754014, Final Batch Loss: 8.116277604131028e-05\n",
      "Epoch 3074, Loss: 0.004864572954829782, Final Batch Loss: 0.0047347270883619785\n",
      "Epoch 3075, Loss: 6.292907983151963e-05, Final Batch Loss: 3.988675416621845e-06\n",
      "Epoch 3076, Loss: 0.00021264998940750957, Final Batch Loss: 3.269150329288095e-05\n",
      "Epoch 3077, Loss: 3.242493028210447e-05, Final Batch Loss: 3.19514365401119e-05\n",
      "Epoch 3078, Loss: 0.01770968410050955, Final Batch Loss: 1.9767401226999937e-06\n",
      "Epoch 3079, Loss: 2.9628823313032626e-05, Final Batch Loss: 2.376236579948454e-06\n",
      "Epoch 3080, Loss: 9.954613460649853e-06, Final Batch Loss: 1.1164631814608583e-06\n",
      "Epoch 3081, Loss: 6.545145333802793e-05, Final Batch Loss: 4.1780669562285766e-05\n",
      "Epoch 3082, Loss: 0.0008786727266851813, Final Batch Loss: 0.00016838268493302166\n",
      "Epoch 3083, Loss: 0.0007918606861494482, Final Batch Loss: 0.00044832241837866604\n",
      "Epoch 3084, Loss: 0.02057149656684487, Final Batch Loss: 3.12312004098203e-05\n",
      "Epoch 3085, Loss: 0.0004727509367512539, Final Batch Loss: 9.843120642472059e-05\n",
      "Epoch 3086, Loss: 0.00038227683944569435, Final Batch Loss: 1.0243826181977056e-05\n",
      "Epoch 3087, Loss: 0.0019154054461978376, Final Batch Loss: 0.0006462354795075953\n",
      "Epoch 3088, Loss: 0.005835828312228841, Final Batch Loss: 0.005820583552122116\n",
      "Epoch 3089, Loss: 5.558932389249094e-05, Final Batch Loss: 1.5373316273326054e-05\n",
      "Epoch 3090, Loss: 5.2931982281734236e-05, Final Batch Loss: 2.677719203347806e-05\n",
      "Epoch 3091, Loss: 0.0005931558480369858, Final Batch Loss: 0.00054420210653916\n",
      "Epoch 3092, Loss: 7.962182507981197e-05, Final Batch Loss: 7.441145862685516e-05\n",
      "Epoch 3093, Loss: 0.0006780762137168495, Final Batch Loss: 0.0006719182129018009\n",
      "Epoch 3094, Loss: 0.00015489682846236974, Final Batch Loss: 0.00010542889503994957\n",
      "Epoch 3095, Loss: 6.957155528652947e-05, Final Batch Loss: 4.067600821144879e-05\n",
      "Epoch 3096, Loss: 0.0023381307546515018, Final Batch Loss: 0.0002481595438439399\n",
      "Epoch 3097, Loss: 0.010037154093879508, Final Batch Loss: 0.010011659935116768\n",
      "Epoch 3098, Loss: 0.00018083110990119167, Final Batch Loss: 5.264470019028522e-05\n",
      "Epoch 3099, Loss: 0.00022379882921086391, Final Batch Loss: 0.00021966357599012554\n",
      "Epoch 3100, Loss: 2.6881077928919694e-05, Final Batch Loss: 2.3114880605135113e-05\n",
      "Epoch 3101, Loss: 4.474113302421756e-05, Final Batch Loss: 1.8411952623864636e-05\n",
      "Epoch 3102, Loss: 4.794928463525139e-05, Final Batch Loss: 3.0829694878775626e-05\n",
      "Epoch 3103, Loss: 0.00010083702363772318, Final Batch Loss: 4.1002935176948085e-05\n",
      "Epoch 3104, Loss: 0.0005240605205472093, Final Batch Loss: 1.950289515662007e-05\n",
      "Epoch 3105, Loss: 0.00036664413346443325, Final Batch Loss: 0.00029839263879694045\n",
      "Epoch 3106, Loss: 1.536540412416798e-05, Final Batch Loss: 1.2559089554997627e-05\n",
      "Epoch 3107, Loss: 7.420491965604015e-05, Final Batch Loss: 5.287619569571689e-05\n",
      "Epoch 3108, Loss: 1.8100797660736134e-05, Final Batch Loss: 1.2460165635275189e-05\n",
      "Epoch 3109, Loss: 0.0007398107627523132, Final Batch Loss: 5.750649870606139e-05\n",
      "Epoch 3110, Loss: 2.0330611732788384e-05, Final Batch Loss: 6.075204510125332e-06\n",
      "Epoch 3111, Loss: 0.00018696888582780957, Final Batch Loss: 6.001439760439098e-05\n",
      "Epoch 3112, Loss: 3.205209441148327e-05, Final Batch Loss: 3.7871436688874383e-06\n",
      "Epoch 3113, Loss: 0.0012237856881256448, Final Batch Loss: 0.0012130215764045715\n",
      "Epoch 3114, Loss: 8.432745107711526e-05, Final Batch Loss: 8.268199053418357e-06\n",
      "Epoch 3115, Loss: 0.00022319035588225233, Final Batch Loss: 3.196567831764696e-06\n",
      "Epoch 3116, Loss: 3.4747871268336894e-05, Final Batch Loss: 5.097070697956951e-06\n",
      "Epoch 3117, Loss: 0.000513506348397641, Final Batch Loss: 2.5893032216117717e-06\n",
      "Epoch 3118, Loss: 0.0010235469453618862, Final Batch Loss: 0.00010640003165462986\n",
      "Epoch 3119, Loss: 0.0016789355431683362, Final Batch Loss: 0.0002697492600418627\n",
      "Epoch 3120, Loss: 4.876859293290181e-05, Final Batch Loss: 3.687180287670344e-05\n",
      "Epoch 3121, Loss: 6.639717867074069e-05, Final Batch Loss: 2.0813162336708046e-05\n",
      "Epoch 3122, Loss: 0.0006784143163258705, Final Batch Loss: 3.387756123629515e-06\n",
      "Epoch 3123, Loss: 8.681952465394716e-06, Final Batch Loss: 6.584029392797675e-07\n",
      "Epoch 3124, Loss: 8.354804958798923e-05, Final Batch Loss: 7.417667075060308e-05\n",
      "Epoch 3125, Loss: 4.021004770038417e-06, Final Batch Loss: 2.3282768779608887e-06\n",
      "Epoch 3126, Loss: 3.852603595078108e-05, Final Batch Loss: 7.576840744150104e-06\n",
      "Epoch 3127, Loss: 0.0001558222866151482, Final Batch Loss: 0.0001443560468032956\n",
      "Epoch 3128, Loss: 0.00010057880353997461, Final Batch Loss: 4.9486319767311215e-05\n",
      "Epoch 3129, Loss: 3.511200520733837e-05, Final Batch Loss: 1.309541221417021e-05\n",
      "Epoch 3130, Loss: 2.809834018080437e-05, Final Batch Loss: 2.8139090773038333e-06\n",
      "Epoch 3131, Loss: 0.00012820559095416684, Final Batch Loss: 3.0132659958326258e-05\n",
      "Epoch 3132, Loss: 9.856898213911336e-05, Final Batch Loss: 2.0370096535771154e-05\n",
      "Epoch 3133, Loss: 4.4067641283618286e-05, Final Batch Loss: 1.730849726300221e-05\n",
      "Epoch 3134, Loss: 0.00010811247466335772, Final Batch Loss: 1.1380262549209874e-05\n",
      "Epoch 3135, Loss: 0.0007227976821013726, Final Batch Loss: 2.4171873519662768e-05\n",
      "Epoch 3136, Loss: 0.0014438200159929693, Final Batch Loss: 0.0010290754726156592\n",
      "Epoch 3137, Loss: 0.00020972629135940224, Final Batch Loss: 4.403082130011171e-05\n",
      "Epoch 3138, Loss: 0.00011240083767916076, Final Batch Loss: 5.333363878889941e-05\n",
      "Epoch 3139, Loss: 0.0022056763045839034, Final Batch Loss: 1.9401217286940664e-05\n",
      "Epoch 3140, Loss: 3.683614522742573e-05, Final Batch Loss: 2.7790223612100817e-05\n",
      "Epoch 3141, Loss: 0.0015460309223271906, Final Batch Loss: 0.0005129556520842016\n",
      "Epoch 3142, Loss: 3.18206998599635e-05, Final Batch Loss: 4.093722509423969e-06\n",
      "Epoch 3143, Loss: 1.786491304756055e-05, Final Batch Loss: 1.0474610689925612e-06\n",
      "Epoch 3144, Loss: 1.4738333447894547e-05, Final Batch Loss: 2.877372935472522e-06\n",
      "Epoch 3145, Loss: 0.0017488707089796662, Final Batch Loss: 0.0006552484119310975\n",
      "Epoch 3146, Loss: 7.605531573062763e-05, Final Batch Loss: 2.2148105927044526e-05\n",
      "Epoch 3147, Loss: 1.167415760505719e-06, Final Batch Loss: 1.90403241617787e-07\n",
      "Epoch 3148, Loss: 2.0872756067547016e-05, Final Batch Loss: 1.1776450264733285e-05\n",
      "Epoch 3149, Loss: 0.00019911874005629215, Final Batch Loss: 1.2484082617447712e-05\n",
      "Epoch 3150, Loss: 0.0023923854751046747, Final Batch Loss: 0.0020734232384711504\n",
      "Epoch 3151, Loss: 4.7182843275095365e-05, Final Batch Loss: 5.452646405501582e-07\n",
      "Epoch 3152, Loss: 0.0005484095147494372, Final Batch Loss: 0.0005464154528453946\n",
      "Epoch 3153, Loss: 0.0010168779292598629, Final Batch Loss: 0.0010152587201446295\n",
      "Epoch 3154, Loss: 1.6100963421195047e-05, Final Batch Loss: 1.1462916518212296e-05\n",
      "Epoch 3155, Loss: 0.00015578037687191681, Final Batch Loss: 2.10644770959334e-06\n",
      "Epoch 3156, Loss: 8.751135737838922e-06, Final Batch Loss: 1.1312913557048887e-06\n",
      "Epoch 3157, Loss: 1.6566269096074393e-05, Final Batch Loss: 1.0649917385308072e-05\n",
      "Epoch 3158, Loss: 9.936560672940686e-06, Final Batch Loss: 2.3492893888032995e-06\n",
      "Epoch 3159, Loss: 2.1507963992917212e-05, Final Batch Loss: 1.5605111912009306e-05\n",
      "Epoch 3160, Loss: 1.3279984159453306e-05, Final Batch Loss: 4.008850737591274e-06\n",
      "Epoch 3161, Loss: 3.39324005835806e-05, Final Batch Loss: 5.643453732773196e-06\n",
      "Epoch 3162, Loss: 4.4814979446528014e-05, Final Batch Loss: 3.637837653513998e-05\n",
      "Epoch 3163, Loss: 8.371235253434861e-06, Final Batch Loss: 6.528361154778395e-06\n",
      "Epoch 3164, Loss: 0.00014878189540468156, Final Batch Loss: 7.460558845195919e-05\n",
      "Epoch 3165, Loss: 1.5128233712857764e-05, Final Batch Loss: 1.1302453231110121e-06\n",
      "Epoch 3166, Loss: 1.2083853107469622e-05, Final Batch Loss: 5.4010974963603076e-06\n",
      "Epoch 3167, Loss: 4.5131505885365186e-05, Final Batch Loss: 4.583750978781609e-06\n",
      "Epoch 3168, Loss: 7.835073665773962e-05, Final Batch Loss: 1.5626532331225462e-05\n",
      "Epoch 3169, Loss: 4.950861784891458e-05, Final Batch Loss: 7.89885325502837e-06\n",
      "Epoch 3170, Loss: 3.2454472034260107e-06, Final Batch Loss: 4.845575745093811e-07\n",
      "Epoch 3171, Loss: 8.387466914427932e-05, Final Batch Loss: 5.355412940843962e-05\n",
      "Epoch 3172, Loss: 2.595452042442048e-05, Final Batch Loss: 5.238837729848456e-06\n",
      "Epoch 3173, Loss: 5.784794439023244e-06, Final Batch Loss: 4.710097982751904e-06\n",
      "Epoch 3174, Loss: 5.3389248762414354e-05, Final Batch Loss: 5.09942594817403e-07\n",
      "Epoch 3175, Loss: 7.575003837700933e-05, Final Batch Loss: 6.805556768085808e-05\n",
      "Epoch 3176, Loss: 0.00024131699319696054, Final Batch Loss: 2.308318653376773e-05\n",
      "Epoch 3177, Loss: 1.179127866635099e-05, Final Batch Loss: 4.943018666381249e-06\n",
      "Epoch 3178, Loss: 1.2427343335730257e-05, Final Batch Loss: 7.427477157762041e-06\n",
      "Epoch 3179, Loss: 4.813293458028056e-06, Final Batch Loss: 4.5243336899147835e-06\n",
      "Epoch 3180, Loss: 1.6137240891112015e-05, Final Batch Loss: 6.887224117235746e-06\n",
      "Epoch 3181, Loss: 0.0015171172017289791, Final Batch Loss: 0.0015112727414816618\n",
      "Epoch 3182, Loss: 0.000815674735349603, Final Batch Loss: 0.0007974908803589642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3183, Loss: 8.153710041369777e-06, Final Batch Loss: 4.516150056588231e-06\n",
      "Epoch 3184, Loss: 9.306652827945072e-06, Final Batch Loss: 8.321580025949515e-06\n",
      "Epoch 3185, Loss: 1.8549445485405158e-05, Final Batch Loss: 6.503426448034588e-06\n",
      "Epoch 3186, Loss: 0.0008449886845482979, Final Batch Loss: 0.0008326914976350963\n",
      "Epoch 3187, Loss: 0.0012359861084405566, Final Batch Loss: 0.001226704684086144\n",
      "Epoch 3188, Loss: 0.00014524253083436633, Final Batch Loss: 3.028336777788354e-06\n",
      "Epoch 3189, Loss: 2.790656822071469e-06, Final Batch Loss: 2.1412170099210925e-06\n",
      "Epoch 3190, Loss: 0.0006947186711840914, Final Batch Loss: 1.4620826732425485e-05\n",
      "Epoch 3191, Loss: 2.3768528080836404e-05, Final Batch Loss: 1.04817227111198e-05\n",
      "Epoch 3192, Loss: 0.0006777873522878508, Final Batch Loss: 0.0006690166774205863\n",
      "Epoch 3193, Loss: 2.878586110455217e-05, Final Batch Loss: 1.5292966054403223e-05\n",
      "Epoch 3194, Loss: 2.5123788987002627e-06, Final Batch Loss: 6.10935728673212e-07\n",
      "Epoch 3195, Loss: 0.0016582878730844186, Final Batch Loss: 0.001657967921346426\n",
      "Epoch 3196, Loss: 0.00042052922253787983, Final Batch Loss: 4.47168895334471e-06\n",
      "Epoch 3197, Loss: 7.483893386961427e-05, Final Batch Loss: 4.5700995542574674e-05\n",
      "Epoch 3198, Loss: 3.010656917012966e-05, Final Batch Loss: 1.391260298078123e-06\n",
      "Epoch 3199, Loss: 1.5835335943847895e-05, Final Batch Loss: 1.2005619282717817e-05\n",
      "Epoch 3200, Loss: 8.971290156978284e-06, Final Batch Loss: 8.585538125771564e-06\n",
      "Epoch 3201, Loss: 0.0008045934682741063, Final Batch Loss: 2.4824317733873613e-05\n",
      "Epoch 3202, Loss: 0.0012350099568720907, Final Batch Loss: 0.001215374213643372\n",
      "Epoch 3203, Loss: 0.0002583821303687728, Final Batch Loss: 1.8354446638113586e-06\n",
      "Epoch 3204, Loss: 1.676418071383523e-05, Final Batch Loss: 1.8348088133279816e-06\n",
      "Epoch 3205, Loss: 2.316303925908869e-05, Final Batch Loss: 1.174287262983853e-05\n",
      "Epoch 3206, Loss: 0.00016852268345246557, Final Batch Loss: 2.2640315364697017e-05\n",
      "Epoch 3207, Loss: 3.30573420797009e-05, Final Batch Loss: 1.4506898878607899e-05\n",
      "Epoch 3208, Loss: 0.0001052312714477921, Final Batch Loss: 4.6303335921038524e-07\n",
      "Epoch 3209, Loss: 0.0006361476680467604, Final Batch Loss: 2.9485889172065072e-05\n",
      "Epoch 3210, Loss: 5.267606229608646e-05, Final Batch Loss: 4.030913987662643e-05\n",
      "Epoch 3211, Loss: 0.00030373656045412645, Final Batch Loss: 8.362194785149768e-05\n",
      "Epoch 3212, Loss: 3.875939455610933e-05, Final Batch Loss: 7.328123501793016e-06\n",
      "Epoch 3213, Loss: 8.592047151978477e-06, Final Batch Loss: 3.4342326671321644e-06\n",
      "Epoch 3214, Loss: 0.0036484963164866713, Final Batch Loss: 0.0036475579254329205\n",
      "Epoch 3215, Loss: 0.0002303030778421089, Final Batch Loss: 9.42056649364531e-05\n",
      "Epoch 3216, Loss: 6.150892227196891e-05, Final Batch Loss: 5.858130316482857e-05\n",
      "Epoch 3217, Loss: 3.684667194647773e-05, Final Batch Loss: 1.941451273523853e-06\n",
      "Epoch 3218, Loss: 0.0013539049582504958, Final Batch Loss: 0.001349524944089353\n",
      "Epoch 3219, Loss: 0.0009966303721853365, Final Batch Loss: 3.432749622334086e-07\n",
      "Epoch 3220, Loss: 0.0001404188415108365, Final Batch Loss: 4.179794814263005e-06\n",
      "Epoch 3221, Loss: 0.0008898259347915882, Final Batch Loss: 1.6353218597942032e-05\n",
      "Epoch 3222, Loss: 3.0506632811011514e-05, Final Batch Loss: 2.651367503858637e-05\n",
      "Epoch 3223, Loss: 2.4293665774166584e-05, Final Batch Loss: 1.4542728422384243e-05\n",
      "Epoch 3224, Loss: 2.4132396447384963e-05, Final Batch Loss: 1.8896105757448822e-05\n",
      "Epoch 3225, Loss: 8.115945178133188e-07, Final Batch Loss: 2.3510607150001306e-07\n",
      "Epoch 3226, Loss: 3.625274973728665e-05, Final Batch Loss: 3.540304896887392e-05\n",
      "Epoch 3227, Loss: 0.0014399080027942546, Final Batch Loss: 0.0013980240328237414\n",
      "Epoch 3228, Loss: 3.019753080479859e-06, Final Batch Loss: 7.411764499920537e-07\n",
      "Epoch 3229, Loss: 0.0004141241020079178, Final Batch Loss: 0.00041070819133892655\n",
      "Epoch 3230, Loss: 4.395247003685654e-06, Final Batch Loss: 3.500769253150793e-06\n",
      "Epoch 3231, Loss: 0.0013404700951014092, Final Batch Loss: 1.947912323885248e-06\n",
      "Epoch 3232, Loss: 0.00034520955978223355, Final Batch Loss: 3.0433338906732388e-06\n",
      "Epoch 3233, Loss: 1.3223247833593632e-05, Final Batch Loss: 3.364260692251264e-06\n",
      "Epoch 3234, Loss: 8.136049655149691e-05, Final Batch Loss: 3.289810410933569e-05\n",
      "Epoch 3235, Loss: 0.0008875728053681087, Final Batch Loss: 0.0008794583263806999\n",
      "Epoch 3236, Loss: 4.95442782266764e-06, Final Batch Loss: 1.5667387742723804e-06\n",
      "Epoch 3237, Loss: 0.0009622050638427027, Final Batch Loss: 1.1764939699787647e-05\n",
      "Epoch 3238, Loss: 0.0003979441034971387, Final Batch Loss: 0.0003954437852371484\n",
      "Epoch 3239, Loss: 1.791969509667979e-05, Final Batch Loss: 1.3150703352948767e-06\n",
      "Epoch 3240, Loss: 0.001164758639106367, Final Batch Loss: 1.4491990896203788e-06\n",
      "Epoch 3241, Loss: 0.0001725349939079024, Final Batch Loss: 0.00011046072177123278\n",
      "Epoch 3242, Loss: 0.0001945547865034314, Final Batch Loss: 2.8826385459979065e-05\n",
      "Epoch 3243, Loss: 1.575821579535841e-05, Final Batch Loss: 1.279794469155604e-05\n",
      "Epoch 3244, Loss: 4.648702406484517e-05, Final Batch Loss: 4.2458555071789306e-06\n",
      "Epoch 3245, Loss: 8.483956150939775e-07, Final Batch Loss: 5.022162099521665e-07\n",
      "Epoch 3246, Loss: 3.351353370817378e-05, Final Batch Loss: 2.690581459319219e-05\n",
      "Epoch 3247, Loss: 2.97987382964493e-05, Final Batch Loss: 2.6885698389378376e-05\n",
      "Epoch 3248, Loss: 1.220564051607198e-05, Final Batch Loss: 1.5453012736088567e-07\n",
      "Epoch 3249, Loss: 7.476522114302497e-06, Final Batch Loss: 4.736937626148574e-06\n",
      "Epoch 3250, Loss: 1.5230797316689859e-05, Final Batch Loss: 1.34365454869112e-05\n",
      "Epoch 3251, Loss: 0.05239578212786, Final Batch Loss: 0.05228130519390106\n",
      "Epoch 3252, Loss: 0.0005946652381680906, Final Batch Loss: 0.00012952505494467914\n",
      "Epoch 3253, Loss: 0.0009680306429800112, Final Batch Loss: 0.0009351460612379014\n",
      "Epoch 3254, Loss: 0.02237880703069095, Final Batch Loss: 0.022358408197760582\n",
      "Epoch 3255, Loss: 0.00904026311764028, Final Batch Loss: 0.00016055592277552933\n",
      "Epoch 3256, Loss: 0.0003846662184514571, Final Batch Loss: 0.00036241841735318303\n",
      "Epoch 3257, Loss: 6.426244908652734e-05, Final Batch Loss: 1.7927764929481782e-05\n",
      "Epoch 3258, Loss: 0.0002318453261977993, Final Batch Loss: 0.00010051098797703162\n",
      "Epoch 3259, Loss: 0.0018992859404534101, Final Batch Loss: 0.0010021013440564275\n",
      "Epoch 3260, Loss: 0.01370795164257288, Final Batch Loss: 0.007694408763200045\n",
      "Epoch 3261, Loss: 0.020664298121118918, Final Batch Loss: 0.00010632644989527762\n",
      "Epoch 3262, Loss: 0.03418925011646934, Final Batch Loss: 9.178911568596959e-06\n",
      "Epoch 3263, Loss: 0.00033839360366982874, Final Batch Loss: 0.0003175949677824974\n",
      "Epoch 3264, Loss: 0.0004943377643940039, Final Batch Loss: 0.0004103441024199128\n",
      "Epoch 3265, Loss: 0.00011111026833532378, Final Batch Loss: 8.046990842558444e-05\n",
      "Epoch 3266, Loss: 0.0005772844742750749, Final Batch Loss: 0.00016182642139028758\n",
      "Epoch 3267, Loss: 0.0014127846843621228, Final Batch Loss: 0.0013715701643377542\n",
      "Epoch 3268, Loss: 7.59292634029407e-05, Final Batch Loss: 5.2386898460099474e-05\n",
      "Epoch 3269, Loss: 0.003551863448592485, Final Batch Loss: 1.4423940228880383e-05\n",
      "Epoch 3270, Loss: 0.0017324850014119875, Final Batch Loss: 4.674289812101051e-06\n",
      "Epoch 3271, Loss: 0.001335316919721663, Final Batch Loss: 0.000340286991558969\n",
      "Epoch 3272, Loss: 9.303953993367031e-05, Final Batch Loss: 4.475762398215011e-05\n",
      "Epoch 3273, Loss: 9.11537845240673e-05, Final Batch Loss: 2.7468680855236016e-05\n",
      "Epoch 3274, Loss: 4.4883033297082875e-05, Final Batch Loss: 4.1675120883155614e-05\n",
      "Epoch 3275, Loss: 0.00012072549361619167, Final Batch Loss: 5.718886313843541e-05\n",
      "Epoch 3276, Loss: 0.0006604095633520046, Final Batch Loss: 4.0286631701746956e-06\n",
      "Epoch 3277, Loss: 0.0008077699631030555, Final Batch Loss: 0.0007983894320204854\n",
      "Epoch 3278, Loss: 0.0007218507489596959, Final Batch Loss: 0.0007101739174686372\n",
      "Epoch 3279, Loss: 0.00017533719801576808, Final Batch Loss: 7.16975555405952e-05\n",
      "Epoch 3280, Loss: 0.0009871087677311152, Final Batch Loss: 0.0006799681577831507\n",
      "Epoch 3281, Loss: 0.000706533101038076, Final Batch Loss: 0.0005949030164629221\n",
      "Epoch 3282, Loss: 3.9369707337755244e-05, Final Batch Loss: 2.558289997978136e-05\n",
      "Epoch 3283, Loss: 7.117146560631227e-05, Final Batch Loss: 2.842814319592435e-05\n",
      "Epoch 3284, Loss: 0.00011739470937754959, Final Batch Loss: 4.076888581039384e-05\n",
      "Epoch 3285, Loss: 0.00011890741370734759, Final Batch Loss: 7.607918814755976e-05\n",
      "Epoch 3286, Loss: 0.00022350655854097567, Final Batch Loss: 0.00020205431792419404\n",
      "Epoch 3287, Loss: 0.00013715512068301905, Final Batch Loss: 0.00011183341848663986\n",
      "Epoch 3288, Loss: 2.8396334982971894e-05, Final Batch Loss: 2.1130370441824198e-05\n",
      "Epoch 3289, Loss: 0.0038078888901509345, Final Batch Loss: 0.0008713040151633322\n",
      "Epoch 3290, Loss: 0.00020477398356888443, Final Batch Loss: 4.9677095375955105e-05\n",
      "Epoch 3291, Loss: 0.0033367632277077064, Final Batch Loss: 0.0001884437951957807\n",
      "Epoch 3292, Loss: 0.0011956860034842975, Final Batch Loss: 0.0011377574410289526\n",
      "Epoch 3293, Loss: 0.0028962051728740335, Final Batch Loss: 0.001392784179188311\n",
      "Epoch 3294, Loss: 0.00036249651111575076, Final Batch Loss: 1.133891873905668e-05\n",
      "Epoch 3295, Loss: 5.889448345897108e-06, Final Batch Loss: 2.7980826189377694e-07\n",
      "Epoch 3296, Loss: 2.517667667234491e-05, Final Batch Loss: 2.224261697847396e-05\n",
      "Epoch 3297, Loss: 1.967903062904952e-05, Final Batch Loss: 1.4774299415876158e-05\n",
      "Epoch 3298, Loss: 0.05740266986686038, Final Batch Loss: 0.057341188192367554\n",
      "Epoch 3299, Loss: 0.000885598794411635, Final Batch Loss: 2.3318771127378568e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3300, Loss: 9.330898319603875e-05, Final Batch Loss: 4.5652708649868146e-05\n",
      "Epoch 3301, Loss: 0.013842082931660116, Final Batch Loss: 0.013249616138637066\n",
      "Epoch 3302, Loss: 0.000194860944247921, Final Batch Loss: 0.00017609760107006878\n",
      "Epoch 3303, Loss: 0.00035026814293814823, Final Batch Loss: 0.00028168002609163523\n",
      "Epoch 3304, Loss: 8.524787517671939e-05, Final Batch Loss: 5.8158864703727886e-05\n",
      "Epoch 3305, Loss: 0.000150740823301021, Final Batch Loss: 8.003326365724206e-05\n",
      "Epoch 3306, Loss: 0.0001242189682670869, Final Batch Loss: 1.7349004338029772e-05\n",
      "Epoch 3307, Loss: 0.0007543726242147386, Final Batch Loss: 0.0006584788206964731\n",
      "Epoch 3308, Loss: 0.00014455776999966474, Final Batch Loss: 0.0001311412052018568\n",
      "Epoch 3309, Loss: 0.0014872556930640712, Final Batch Loss: 0.0013697408139705658\n",
      "Epoch 3310, Loss: 0.00042981260048691183, Final Batch Loss: 0.0001365905482089147\n",
      "Epoch 3311, Loss: 0.00305442234093789, Final Batch Loss: 1.5995246940292418e-05\n",
      "Epoch 3312, Loss: 0.0003721327448147349, Final Batch Loss: 0.00010852366540348157\n",
      "Epoch 3313, Loss: 0.0004471002393984236, Final Batch Loss: 8.888234879123047e-05\n",
      "Epoch 3314, Loss: 0.0005469956231536344, Final Batch Loss: 0.0003855624527204782\n",
      "Epoch 3315, Loss: 0.0031246330618159845, Final Batch Loss: 0.0001309958315687254\n",
      "Epoch 3316, Loss: 0.0005165822221897542, Final Batch Loss: 0.0003019124851562083\n",
      "Epoch 3317, Loss: 9.332805348094553e-05, Final Batch Loss: 7.007359818089753e-05\n",
      "Epoch 3318, Loss: 0.00014100829685048666, Final Batch Loss: 3.032230415556114e-05\n",
      "Epoch 3319, Loss: 0.00022242771228775382, Final Batch Loss: 0.0001265684695681557\n",
      "Epoch 3320, Loss: 8.963632171798963e-05, Final Batch Loss: 1.3602360922959633e-05\n",
      "Epoch 3321, Loss: 0.00036782222014153376, Final Batch Loss: 0.00031032372498884797\n",
      "Epoch 3322, Loss: 0.0002102538783219643, Final Batch Loss: 4.018464096589014e-05\n",
      "Epoch 3323, Loss: 0.0007487711227440741, Final Batch Loss: 0.0007279767305590212\n",
      "Epoch 3324, Loss: 0.001040829869452864, Final Batch Loss: 0.0002481103874742985\n",
      "Epoch 3325, Loss: 0.0009914349211612716, Final Batch Loss: 0.0001108205906348303\n",
      "Epoch 3326, Loss: 3.399358047317946e-05, Final Batch Loss: 1.9155659174430184e-05\n",
      "Epoch 3327, Loss: 0.00023642654923605733, Final Batch Loss: 1.1119027476524934e-05\n",
      "Epoch 3328, Loss: 0.0013815876154694706, Final Batch Loss: 0.001063651405274868\n",
      "Epoch 3329, Loss: 0.00030480244822683744, Final Batch Loss: 3.3069034543586895e-05\n",
      "Epoch 3330, Loss: 0.0018020703719230369, Final Batch Loss: 2.915733784902841e-05\n",
      "Epoch 3331, Loss: 0.0011338058684486896, Final Batch Loss: 0.00011474211351014674\n",
      "Epoch 3332, Loss: 6.59203087707283e-05, Final Batch Loss: 2.609229886729736e-05\n",
      "Epoch 3333, Loss: 7.967261080921162e-05, Final Batch Loss: 2.1037985789007507e-05\n",
      "Epoch 3334, Loss: 0.0002950635680463165, Final Batch Loss: 5.486360169015825e-05\n",
      "Epoch 3335, Loss: 0.0005792621195723768, Final Batch Loss: 4.213358261040412e-05\n",
      "Epoch 3336, Loss: 2.8404913791746367e-05, Final Batch Loss: 1.4747556633665226e-05\n",
      "Epoch 3337, Loss: 0.004616949060618936, Final Batch Loss: 0.004610511939972639\n",
      "Epoch 3338, Loss: 1.829152301979775e-05, Final Batch Loss: 1.162821945399628e-06\n",
      "Epoch 3339, Loss: 0.0060318117302813334, Final Batch Loss: 2.1285650291247293e-06\n",
      "Epoch 3340, Loss: 2.8633609417738626e-05, Final Batch Loss: 2.1676389224012382e-05\n",
      "Epoch 3341, Loss: 1.0834617114596767e-05, Final Batch Loss: 2.249310909974156e-06\n",
      "Epoch 3342, Loss: 0.0005240325215254416, Final Batch Loss: 2.7499143016029848e-06\n",
      "Epoch 3343, Loss: 0.001180448838567827, Final Batch Loss: 0.0011515759397298098\n",
      "Epoch 3344, Loss: 1.681071262282785e-05, Final Batch Loss: 3.4654949558898807e-06\n",
      "Epoch 3345, Loss: 0.0002923216416093055, Final Batch Loss: 0.00024132023099809885\n",
      "Epoch 3346, Loss: 2.6824842279893346e-05, Final Batch Loss: 1.0278703484800644e-05\n",
      "Epoch 3347, Loss: 4.8762592996354215e-05, Final Batch Loss: 2.0133373254793696e-05\n",
      "Epoch 3348, Loss: 9.528950249659829e-05, Final Batch Loss: 6.438054697355255e-05\n",
      "Epoch 3349, Loss: 0.00014691589240101166, Final Batch Loss: 4.311216980568133e-05\n",
      "Epoch 3350, Loss: 0.00012345126378932036, Final Batch Loss: 0.00010429876419948414\n",
      "Epoch 3351, Loss: 7.222838030429557e-05, Final Batch Loss: 1.2453139788703993e-05\n",
      "Epoch 3352, Loss: 9.701193039290956e-05, Final Batch Loss: 9.105568460654467e-05\n",
      "Epoch 3353, Loss: 0.00034700762364536786, Final Batch Loss: 1.2053106956955162e-06\n",
      "Epoch 3354, Loss: 0.00015876733959885314, Final Batch Loss: 4.389016248751432e-05\n",
      "Epoch 3355, Loss: 0.00023140411940403283, Final Batch Loss: 4.8492380301468074e-05\n",
      "Epoch 3356, Loss: 1.405833563694614e-05, Final Batch Loss: 6.12899066254613e-06\n",
      "Epoch 3357, Loss: 0.0021450369104059064, Final Batch Loss: 9.45673764363164e-06\n",
      "Epoch 3358, Loss: 0.00015885425091255456, Final Batch Loss: 6.773797940695658e-05\n",
      "Epoch 3359, Loss: 7.925576574052684e-05, Final Batch Loss: 1.4868473954265937e-05\n",
      "Epoch 3360, Loss: 2.1683239538106136e-05, Final Batch Loss: 1.1535774319781922e-05\n",
      "Epoch 3361, Loss: 0.0001783732368494384, Final Batch Loss: 0.0001458263723179698\n",
      "Epoch 3362, Loss: 0.00012696889461949468, Final Batch Loss: 6.93675028742291e-05\n",
      "Epoch 3363, Loss: 9.072151624422986e-05, Final Batch Loss: 7.205498695839196e-05\n",
      "Epoch 3364, Loss: 3.2188127534027444e-05, Final Batch Loss: 2.6790301490109414e-05\n",
      "Epoch 3365, Loss: 0.0005049041064921767, Final Batch Loss: 0.00040799396811053157\n",
      "Epoch 3366, Loss: 3.83281612812425e-05, Final Batch Loss: 9.599122677173e-06\n",
      "Epoch 3367, Loss: 4.016879029222764e-05, Final Batch Loss: 3.0452603823505342e-05\n",
      "Epoch 3368, Loss: 0.006471492612035945, Final Batch Loss: 0.00032527491566725075\n",
      "Epoch 3369, Loss: 0.00033531526423757896, Final Batch Loss: 0.0002830363519024104\n",
      "Epoch 3370, Loss: 0.0005904529862164054, Final Batch Loss: 3.180955900461413e-05\n",
      "Epoch 3371, Loss: 0.0008400950418945285, Final Batch Loss: 0.0008343189838342369\n",
      "Epoch 3372, Loss: 0.001512937480583787, Final Batch Loss: 1.5085563063621521e-05\n",
      "Epoch 3373, Loss: 0.0005987754420857527, Final Batch Loss: 4.803806405107025e-06\n",
      "Epoch 3374, Loss: 6.823172589065507e-05, Final Batch Loss: 3.285886123194359e-05\n",
      "Epoch 3375, Loss: 6.164761521176843e-05, Final Batch Loss: 2.842463572960696e-06\n",
      "Epoch 3376, Loss: 0.0003448619390837848, Final Batch Loss: 0.000195225584320724\n",
      "Epoch 3377, Loss: 0.001460342327845865, Final Batch Loss: 1.833891474234406e-05\n",
      "Epoch 3378, Loss: 0.0014585376484319568, Final Batch Loss: 0.0009617601754143834\n",
      "Epoch 3379, Loss: 0.0009911193897096382, Final Batch Loss: 7.070220362948021e-06\n",
      "Epoch 3380, Loss: 6.9592899080817e-05, Final Batch Loss: 2.016547796301893e-06\n",
      "Epoch 3381, Loss: 1.411268158335588e-05, Final Batch Loss: 1.1582397746678907e-05\n",
      "Epoch 3382, Loss: 0.001325304328929633, Final Batch Loss: 0.00013343506725504994\n",
      "Epoch 3383, Loss: 4.1350054743816145e-05, Final Batch Loss: 1.1022604667232372e-05\n",
      "Epoch 3384, Loss: 0.0003788183748838492, Final Batch Loss: 0.0003197617188561708\n",
      "Epoch 3385, Loss: 2.498908315828885e-05, Final Batch Loss: 1.9345634427736513e-05\n",
      "Epoch 3386, Loss: 2.6219369829050265e-05, Final Batch Loss: 1.3379962183535099e-05\n",
      "Epoch 3387, Loss: 0.00011600827588154061, Final Batch Loss: 8.421413895121077e-07\n",
      "Epoch 3388, Loss: 0.0011611056615947746, Final Batch Loss: 0.0010807528160512447\n",
      "Epoch 3389, Loss: 3.502880281303078e-05, Final Batch Loss: 1.7868444047053345e-05\n",
      "Epoch 3390, Loss: 1.6313755622832105e-05, Final Batch Loss: 1.2512061402958352e-05\n",
      "Epoch 3391, Loss: 0.0010207462282778579, Final Batch Loss: 0.0010126180713996291\n",
      "Epoch 3392, Loss: 0.0001620180410100147, Final Batch Loss: 7.788179209455848e-05\n",
      "Epoch 3393, Loss: 4.509894779403112e-05, Final Batch Loss: 1.98547195395804e-06\n",
      "Epoch 3394, Loss: 2.3065906134434044e-05, Final Batch Loss: 1.1314447874610778e-05\n",
      "Epoch 3395, Loss: 8.37481677535834e-05, Final Batch Loss: 8.145389438141137e-05\n",
      "Epoch 3396, Loss: 9.304614195571048e-06, Final Batch Loss: 7.05978573023458e-06\n",
      "Epoch 3397, Loss: 0.0009149441175395623, Final Batch Loss: 0.00018148317758459598\n",
      "Epoch 3398, Loss: 6.941826177353505e-05, Final Batch Loss: 5.7459037634544075e-05\n",
      "Epoch 3399, Loss: 8.597256965003908e-06, Final Batch Loss: 4.521948540059384e-06\n",
      "Epoch 3400, Loss: 0.0007568218616142985, Final Batch Loss: 0.0007491650758311152\n",
      "Epoch 3401, Loss: 0.00508783071563812, Final Batch Loss: 0.005004717968404293\n",
      "Epoch 3402, Loss: 3.507682924919209e-05, Final Batch Loss: 3.3462842111475766e-05\n",
      "Epoch 3403, Loss: 0.0002583356661034486, Final Batch Loss: 3.013931518580648e-06\n",
      "Epoch 3404, Loss: 0.00010054569793283008, Final Batch Loss: 1.9648530724225566e-05\n",
      "Epoch 3405, Loss: 0.00023910302843432873, Final Batch Loss: 9.428834891878068e-05\n",
      "Epoch 3406, Loss: 4.515104410529602e-05, Final Batch Loss: 3.125081639154814e-05\n",
      "Epoch 3407, Loss: 0.00017055647256825068, Final Batch Loss: 3.300308719644818e-07\n",
      "Epoch 3408, Loss: 0.00046771078268648125, Final Batch Loss: 5.0528007704997435e-05\n",
      "Epoch 3409, Loss: 0.0006684310834543794, Final Batch Loss: 1.6213494973271736e-06\n",
      "Epoch 3410, Loss: 2.0385029984026914e-05, Final Batch Loss: 6.259594101720722e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3411, Loss: 7.574148412459181e-05, Final Batch Loss: 7.14759953552857e-05\n",
      "Epoch 3412, Loss: 0.00017556191926360043, Final Batch Loss: 0.00017401705554220825\n",
      "Epoch 3413, Loss: 0.0022927914978936315, Final Batch Loss: 0.001413833349943161\n",
      "Epoch 3414, Loss: 0.0001472147232561838, Final Batch Loss: 0.00010059668420581147\n",
      "Epoch 3415, Loss: 0.00025646498761489056, Final Batch Loss: 0.00023516865621786565\n",
      "Epoch 3416, Loss: 0.001339650247246027, Final Batch Loss: 0.0013217614032328129\n",
      "Epoch 3417, Loss: 0.0005761733559666027, Final Batch Loss: 4.977737717126729e-06\n",
      "Epoch 3418, Loss: 7.522691521444358e-05, Final Batch Loss: 1.1241743777645752e-05\n",
      "Epoch 3419, Loss: 1.8919319586530037e-05, Final Batch Loss: 1.7949005268746987e-05\n",
      "Epoch 3420, Loss: 0.02692089340507664, Final Batch Loss: 0.026914600282907486\n",
      "Epoch 3421, Loss: 2.3906147362140473e-05, Final Batch Loss: 1.2376818631310016e-05\n",
      "Epoch 3422, Loss: 0.0008145681913447333, Final Batch Loss: 0.0007883700309321284\n",
      "Epoch 3423, Loss: 0.0002529564662836492, Final Batch Loss: 0.0002092351351166144\n",
      "Epoch 3424, Loss: 0.005788150985608809, Final Batch Loss: 0.0055959224700927734\n",
      "Epoch 3425, Loss: 0.0019220919275539927, Final Batch Loss: 7.878801989136264e-05\n",
      "Epoch 3426, Loss: 0.00014172523515298963, Final Batch Loss: 6.369088077917695e-05\n",
      "Epoch 3427, Loss: 0.0005198472499614581, Final Batch Loss: 0.000219294146518223\n",
      "Epoch 3428, Loss: 8.578854613006115e-05, Final Batch Loss: 3.872735032928176e-05\n",
      "Epoch 3429, Loss: 0.0009030030487338081, Final Batch Loss: 0.00023292454716283828\n",
      "Epoch 3430, Loss: 0.0002047841699095443, Final Batch Loss: 0.00010890810517594218\n",
      "Epoch 3431, Loss: 0.00013019991274632048, Final Batch Loss: 0.00010550722072366625\n",
      "Epoch 3432, Loss: 4.958188719683676e-05, Final Batch Loss: 4.241570786689408e-05\n",
      "Epoch 3433, Loss: 0.0001193382777273655, Final Batch Loss: 7.475440361304209e-05\n",
      "Epoch 3434, Loss: 0.0005367103731259704, Final Batch Loss: 0.00029090140014886856\n",
      "Epoch 3435, Loss: 0.00011110208833997604, Final Batch Loss: 9.512399265076965e-05\n",
      "Epoch 3436, Loss: 0.0006391678452928318, Final Batch Loss: 2.7544852855498902e-05\n",
      "Epoch 3437, Loss: 0.0025876091167447157, Final Batch Loss: 5.283195787342265e-05\n",
      "Epoch 3438, Loss: 6.220478871910018e-05, Final Batch Loss: 6.307047897280427e-06\n",
      "Epoch 3439, Loss: 5.29236021975521e-05, Final Batch Loss: 8.048555173445493e-06\n",
      "Epoch 3440, Loss: 0.00018936688320536632, Final Batch Loss: 7.83828909334261e-06\n",
      "Epoch 3441, Loss: 0.007794071578246076, Final Batch Loss: 0.007773227524012327\n",
      "Epoch 3442, Loss: 0.0008340722929460753, Final Batch Loss: 5.63647381568444e-06\n",
      "Epoch 3443, Loss: 7.768857130940887e-06, Final Batch Loss: 2.4187759208871284e-06\n",
      "Epoch 3444, Loss: 2.5967538022086956e-05, Final Batch Loss: 7.628974344697781e-06\n",
      "Epoch 3445, Loss: 2.0342585230537225e-05, Final Batch Loss: 1.644370422582142e-05\n",
      "Epoch 3446, Loss: 0.000606696866270795, Final Batch Loss: 0.0006048382492735982\n",
      "Epoch 3447, Loss: 1.3142042462277459e-05, Final Batch Loss: 1.2963641893293243e-06\n",
      "Epoch 3448, Loss: 0.00028707626324830926, Final Batch Loss: 0.0002804092946462333\n",
      "Epoch 3449, Loss: 0.003468227770554222, Final Batch Loss: 0.003464320208877325\n",
      "Epoch 3450, Loss: 0.034594144020957174, Final Batch Loss: 3.646994082373567e-05\n",
      "Epoch 3451, Loss: 4.9850105824589264e-05, Final Batch Loss: 4.2733394366223365e-05\n",
      "Epoch 3452, Loss: 1.861837648675646e-05, Final Batch Loss: 8.206492907447682e-07\n",
      "Epoch 3453, Loss: 2.493742272235977e-05, Final Batch Loss: 2.792021632558317e-06\n",
      "Epoch 3454, Loss: 8.003996845218353e-05, Final Batch Loss: 3.852145164273679e-05\n",
      "Epoch 3455, Loss: 0.000192083101865137, Final Batch Loss: 0.00017585033492650837\n",
      "Epoch 3456, Loss: 0.0012620069037438952, Final Batch Loss: 0.0012491516536101699\n",
      "Epoch 3457, Loss: 8.97692689250107e-06, Final Batch Loss: 7.264834948728094e-06\n",
      "Epoch 3458, Loss: 0.007825949366633722, Final Batch Loss: 1.1813032870122697e-05\n",
      "Epoch 3459, Loss: 9.529378439765424e-05, Final Batch Loss: 5.357813279260881e-05\n",
      "Epoch 3460, Loss: 4.532871571427677e-05, Final Batch Loss: 2.3200855139293708e-05\n",
      "Epoch 3461, Loss: 6.5392049606316505e-06, Final Batch Loss: 2.3344809108039044e-07\n",
      "Epoch 3462, Loss: 0.0020245056939529604, Final Batch Loss: 1.1984432603640016e-05\n",
      "Epoch 3463, Loss: 0.0007549500951427035, Final Batch Loss: 8.038046507863328e-05\n",
      "Epoch 3464, Loss: 1.7574240246176487e-05, Final Batch Loss: 1.0777369425341021e-05\n",
      "Epoch 3465, Loss: 2.470673774723764e-05, Final Batch Loss: 8.300352760670648e-07\n",
      "Epoch 3466, Loss: 2.0932933693984523e-05, Final Batch Loss: 1.2121153304178733e-05\n",
      "Epoch 3467, Loss: 0.00024382355877605733, Final Batch Loss: 2.0519399186014198e-05\n",
      "Epoch 3468, Loss: 2.1754132831119932e-05, Final Batch Loss: 1.3388900697464123e-05\n",
      "Epoch 3469, Loss: 9.025199096868164e-05, Final Batch Loss: 6.558513177878922e-06\n",
      "Epoch 3470, Loss: 0.0001971363590200781, Final Batch Loss: 2.358551682846155e-06\n",
      "Epoch 3471, Loss: 2.3066449102771003e-05, Final Batch Loss: 8.04975934443064e-06\n",
      "Epoch 3472, Loss: 0.0009700692344267736, Final Batch Loss: 0.0009602293139323592\n",
      "Epoch 3473, Loss: 1.8360946341999806e-05, Final Batch Loss: 6.048612704034895e-07\n",
      "Epoch 3474, Loss: 0.00016349613542843144, Final Batch Loss: 1.4919116438250057e-05\n",
      "Epoch 3475, Loss: 8.758117201068671e-05, Final Batch Loss: 7.871063280617818e-05\n",
      "Epoch 3476, Loss: 0.00011000647356240734, Final Batch Loss: 6.352245804919221e-07\n",
      "Epoch 3477, Loss: 2.290128577442374e-05, Final Batch Loss: 7.857056516513694e-06\n",
      "Epoch 3478, Loss: 0.0002579510983196087, Final Batch Loss: 9.741567919263616e-05\n",
      "Epoch 3479, Loss: 3.6341068948786415e-05, Final Batch Loss: 3.5385990486247465e-05\n",
      "Epoch 3480, Loss: 0.014877849665936083, Final Batch Loss: 0.014205888845026493\n",
      "Epoch 3481, Loss: 1.3228657280706102e-05, Final Batch Loss: 8.356740181625355e-06\n",
      "Epoch 3482, Loss: 0.00020913041953463107, Final Batch Loss: 9.169889381155372e-06\n",
      "Epoch 3483, Loss: 0.0027594393905019388, Final Batch Loss: 0.0026539170648902655\n",
      "Epoch 3484, Loss: 0.0024588147934991866, Final Batch Loss: 0.0022662279661744833\n",
      "Epoch 3485, Loss: 0.0002933062132797204, Final Batch Loss: 8.157621050486341e-05\n",
      "Epoch 3486, Loss: 0.034913574723759666, Final Batch Loss: 0.03449565917253494\n",
      "Epoch 3487, Loss: 0.0003650018770713359, Final Batch Loss: 0.00015272150631062686\n",
      "Epoch 3488, Loss: 0.0014697081787744537, Final Batch Loss: 6.772963388357311e-05\n",
      "Epoch 3489, Loss: 0.000885068657339616, Final Batch Loss: 1.8427236909701605e-06\n",
      "Epoch 3490, Loss: 3.522494444041513e-05, Final Batch Loss: 1.8025702956947498e-05\n",
      "Epoch 3491, Loss: 0.0001140757212851895, Final Batch Loss: 1.699265521892812e-05\n",
      "Epoch 3492, Loss: 3.169661795254797e-05, Final Batch Loss: 5.244175554253161e-06\n",
      "Epoch 3493, Loss: 0.0008203179713746067, Final Batch Loss: 4.322742097429e-05\n",
      "Epoch 3494, Loss: 4.256409056324628e-05, Final Batch Loss: 3.7075919863127638e-06\n",
      "Epoch 3495, Loss: 2.08692090382101e-05, Final Batch Loss: 1.8100885426974855e-05\n",
      "Epoch 3496, Loss: 0.00013154074986232445, Final Batch Loss: 3.24929496855475e-05\n",
      "Epoch 3497, Loss: 0.0006256422057049349, Final Batch Loss: 8.732145943213254e-05\n",
      "Epoch 3498, Loss: 3.291781649750192e-05, Final Batch Loss: 6.4308969740523025e-06\n",
      "Epoch 3499, Loss: 0.003333470202051103, Final Batch Loss: 0.0023966478183865547\n",
      "Epoch 3500, Loss: 0.001039491566189099, Final Batch Loss: 3.7483237974811345e-05\n",
      "Epoch 3501, Loss: 0.0021495469227374997, Final Batch Loss: 0.002103684702888131\n",
      "Epoch 3502, Loss: 0.00010416590157547034, Final Batch Loss: 7.051360444165766e-05\n",
      "Epoch 3503, Loss: 8.164295377355302e-05, Final Batch Loss: 7.366079807979986e-05\n",
      "Epoch 3504, Loss: 0.00027983459403913, Final Batch Loss: 1.4148286936688237e-05\n",
      "Epoch 3505, Loss: 0.0006515950874472765, Final Batch Loss: 0.0006495768902823329\n",
      "Epoch 3506, Loss: 5.883102676307317e-05, Final Batch Loss: 3.806059976341203e-05\n",
      "Epoch 3507, Loss: 0.00019471019913908094, Final Batch Loss: 7.35810463083908e-05\n",
      "Epoch 3508, Loss: 0.00011926408433282631, Final Batch Loss: 0.00011583421292016283\n",
      "Epoch 3509, Loss: 0.0006055820085748564, Final Batch Loss: 4.186776277492754e-05\n",
      "Epoch 3510, Loss: 0.0012030750372105103, Final Batch Loss: 0.00119828584138304\n",
      "Epoch 3511, Loss: 6.533980558742769e-05, Final Batch Loss: 6.271449819905683e-06\n",
      "Epoch 3512, Loss: 1.2018904044452938e-05, Final Batch Loss: 8.314879778481554e-06\n",
      "Epoch 3513, Loss: 0.00015909682770143263, Final Batch Loss: 1.7753944121068344e-05\n",
      "Epoch 3514, Loss: 2.052688569165184e-05, Final Batch Loss: 6.702823611703934e-06\n",
      "Epoch 3515, Loss: 2.514984953450039e-05, Final Batch Loss: 9.178760592476465e-06\n",
      "Epoch 3516, Loss: 0.00021867706163902767, Final Batch Loss: 7.4044255597982556e-06\n",
      "Epoch 3517, Loss: 6.0989244900611084e-05, Final Batch Loss: 5.336732442629e-07\n",
      "Epoch 3518, Loss: 6.761307349734125e-05, Final Batch Loss: 3.996414761786582e-06\n",
      "Epoch 3519, Loss: 0.0003841062371066073, Final Batch Loss: 0.0003693131438922137\n",
      "Epoch 3520, Loss: 2.8144062525825575e-05, Final Batch Loss: 2.0523946659523062e-05\n",
      "Epoch 3521, Loss: 0.00038465009129140526, Final Batch Loss: 3.954944259021431e-05\n",
      "Epoch 3522, Loss: 1.1154819276271155e-05, Final Batch Loss: 3.2468410608998965e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3523, Loss: 0.001063082961991313, Final Batch Loss: 0.0010544846300035715\n",
      "Epoch 3524, Loss: 4.1334100387757644e-05, Final Batch Loss: 3.1459250749321654e-05\n",
      "Epoch 3525, Loss: 0.00014695245590701234, Final Batch Loss: 1.7471304090577178e-05\n",
      "Epoch 3526, Loss: 0.000822468831529477, Final Batch Loss: 3.313001570859342e-06\n",
      "Epoch 3527, Loss: 6.236988338059746e-05, Final Batch Loss: 5.903903365833685e-05\n",
      "Epoch 3528, Loss: 4.5916312956251204e-05, Final Batch Loss: 2.11344249692047e-05\n",
      "Epoch 3529, Loss: 0.0029760476827505045, Final Batch Loss: 0.002913384698331356\n",
      "Epoch 3530, Loss: 4.7106933379836846e-05, Final Batch Loss: 1.2228928426338825e-05\n",
      "Epoch 3531, Loss: 0.0010664954788808245, Final Batch Loss: 2.178379872930236e-05\n",
      "Epoch 3532, Loss: 2.784184653137345e-05, Final Batch Loss: 1.8710568838287145e-05\n",
      "Epoch 3533, Loss: 4.054836517752847e-05, Final Batch Loss: 3.135321821901016e-05\n",
      "Epoch 3534, Loss: 2.919557005043316e-06, Final Batch Loss: 6.302576593952836e-07\n",
      "Epoch 3535, Loss: 1.0472716439835494e-05, Final Batch Loss: 3.6951369111193344e-06\n",
      "Epoch 3536, Loss: 2.3099354621081147e-05, Final Batch Loss: 4.006454219052102e-06\n",
      "Epoch 3537, Loss: 1.079657477021101e-05, Final Batch Loss: 2.1862883841095027e-06\n",
      "Epoch 3538, Loss: 0.025073655997402966, Final Batch Loss: 0.0008739895420148969\n",
      "Epoch 3539, Loss: 2.405788882242632e-05, Final Batch Loss: 1.8650416677701287e-05\n",
      "Epoch 3540, Loss: 0.0009245820037904195, Final Batch Loss: 0.0009137262823060155\n",
      "Epoch 3541, Loss: 0.0021200603532633977, Final Batch Loss: 0.0021070847287774086\n",
      "Epoch 3542, Loss: 1.0479323464096524e-05, Final Batch Loss: 5.038180916017154e-06\n",
      "Epoch 3543, Loss: 0.0010520696995399703, Final Batch Loss: 9.55293103288568e-07\n",
      "Epoch 3544, Loss: 0.0004796770299435593, Final Batch Loss: 0.0003974912397097796\n",
      "Epoch 3545, Loss: 4.7119817054408486e-05, Final Batch Loss: 4.488120976020582e-05\n",
      "Epoch 3546, Loss: 0.0011437759217187704, Final Batch Loss: 0.0011417812202125788\n",
      "Epoch 3547, Loss: 4.107990571355913e-05, Final Batch Loss: 2.5677045414340682e-05\n",
      "Epoch 3548, Loss: 0.0018914843385573477, Final Batch Loss: 0.0014052415499463677\n",
      "Epoch 3549, Loss: 0.00014974465966588468, Final Batch Loss: 5.726290055463323e-06\n",
      "Epoch 3550, Loss: 3.670370551844826e-05, Final Batch Loss: 3.2199870474869385e-05\n",
      "Epoch 3551, Loss: 5.419861008704174e-05, Final Batch Loss: 3.1309293262893334e-05\n",
      "Epoch 3552, Loss: 0.03862402730010217, Final Batch Loss: 1.4384764654096216e-05\n",
      "Epoch 3553, Loss: 2.175645350632749e-05, Final Batch Loss: 1.975764547523795e-07\n",
      "Epoch 3554, Loss: 0.0005191857162571978, Final Batch Loss: 0.0004702832957264036\n",
      "Epoch 3555, Loss: 6.692164606647566e-05, Final Batch Loss: 4.636656740331091e-05\n",
      "Epoch 3556, Loss: 4.688971421273891e-05, Final Batch Loss: 3.6252800782676786e-05\n",
      "Epoch 3557, Loss: 3.905719677277375e-05, Final Batch Loss: 3.212610317859799e-05\n",
      "Epoch 3558, Loss: 1.1000595350196818e-05, Final Batch Loss: 7.044105586828664e-06\n",
      "Epoch 3559, Loss: 0.0005837587395944865, Final Batch Loss: 2.3770482584950514e-05\n",
      "Epoch 3560, Loss: 5.6232072893180884e-05, Final Batch Loss: 4.785943383467384e-05\n",
      "Epoch 3561, Loss: 1.614645725567243e-05, Final Batch Loss: 1.0655653568392154e-05\n",
      "Epoch 3562, Loss: 2.1563953396253055e-05, Final Batch Loss: 1.9176472960680258e-06\n",
      "Epoch 3563, Loss: 0.00010699549420678522, Final Batch Loss: 1.7187374396598898e-05\n",
      "Epoch 3564, Loss: 0.0008309018703585025, Final Batch Loss: 3.504592677927576e-05\n",
      "Epoch 3565, Loss: 0.00032616696262266487, Final Batch Loss: 0.00019963931117672473\n",
      "Epoch 3566, Loss: 0.00062305606843438, Final Batch Loss: 0.0004628717724699527\n",
      "Epoch 3567, Loss: 1.7058063349395525e-05, Final Batch Loss: 1.594993045728188e-05\n",
      "Epoch 3568, Loss: 7.273164283105871e-05, Final Batch Loss: 9.713169674796518e-06\n",
      "Epoch 3569, Loss: 6.956296874705004e-05, Final Batch Loss: 5.7290439144708216e-05\n",
      "Epoch 3570, Loss: 0.00016020480688894168, Final Batch Loss: 1.617633824935183e-05\n",
      "Epoch 3571, Loss: 1.80742836164427e-05, Final Batch Loss: 1.1631415873125661e-05\n",
      "Epoch 3572, Loss: 0.000286620623228373, Final Batch Loss: 0.00027524554752744734\n",
      "Epoch 3573, Loss: 3.9998412830755115e-05, Final Batch Loss: 2.872530785680283e-05\n",
      "Epoch 3574, Loss: 0.0014734254436916672, Final Batch Loss: 0.001374795800074935\n",
      "Epoch 3575, Loss: 7.130997528292937e-05, Final Batch Loss: 6.199302879394963e-05\n",
      "Epoch 3576, Loss: 1.9871659787895624e-05, Final Batch Loss: 1.596252513991203e-05\n",
      "Epoch 3577, Loss: 2.2390366893887403e-05, Final Batch Loss: 1.9214372514397837e-05\n",
      "Epoch 3578, Loss: 7.551452767984301e-06, Final Batch Loss: 1.5717524775027414e-06\n",
      "Epoch 3579, Loss: 0.006115624215453863, Final Batch Loss: 0.004400170408189297\n",
      "Epoch 3580, Loss: 1.61859610443571e-05, Final Batch Loss: 1.6302341236951179e-06\n",
      "Epoch 3581, Loss: 2.7445134037407115e-05, Final Batch Loss: 1.0357149221817963e-05\n",
      "Epoch 3582, Loss: 1.9238646927988157e-05, Final Batch Loss: 1.2742541002808139e-05\n",
      "Epoch 3583, Loss: 0.0008738101159906364, Final Batch Loss: 9.842070539889392e-06\n",
      "Epoch 3584, Loss: 6.105737804773526e-05, Final Batch Loss: 1.7323046677120146e-06\n",
      "Epoch 3585, Loss: 6.635174759139773e-05, Final Batch Loss: 2.041549851128366e-05\n",
      "Epoch 3586, Loss: 2.9792479836032726e-05, Final Batch Loss: 1.4441555322264321e-05\n",
      "Epoch 3587, Loss: 1.3942503301223041e-05, Final Batch Loss: 7.3029668783419766e-06\n",
      "Epoch 3588, Loss: 2.6503016215428943e-05, Final Batch Loss: 2.146805309166666e-05\n",
      "Epoch 3589, Loss: 7.846217158657964e-06, Final Batch Loss: 3.958069100917783e-06\n",
      "Epoch 3590, Loss: 0.00136644311442069, Final Batch Loss: 1.7118845789809711e-06\n",
      "Epoch 3591, Loss: 0.0001664527826505946, Final Batch Loss: 6.501812094938941e-06\n",
      "Epoch 3592, Loss: 0.00129387371816847, Final Batch Loss: 0.001282526645809412\n",
      "Epoch 3593, Loss: 0.0004997805608581984, Final Batch Loss: 1.7477121218689717e-05\n",
      "Epoch 3594, Loss: 0.0011095904128524126, Final Batch Loss: 0.0011046495055779815\n",
      "Epoch 3595, Loss: 0.0003109879812654981, Final Batch Loss: 5.561092166317394e-06\n",
      "Epoch 3596, Loss: 0.0003577053030312527, Final Batch Loss: 3.5330700484337285e-05\n",
      "Epoch 3597, Loss: 7.905739494162844e-05, Final Batch Loss: 7.41074254619889e-05\n",
      "Epoch 3598, Loss: 7.914254524621356e-06, Final Batch Loss: 1.2478170674512512e-06\n",
      "Epoch 3599, Loss: 1.0251347930534394e-05, Final Batch Loss: 1.0811202173499623e-06\n",
      "Epoch 3600, Loss: 2.421701356070116e-05, Final Batch Loss: 3.903962351614609e-06\n",
      "Epoch 3601, Loss: 0.00026033796439151047, Final Batch Loss: 0.0002537750406190753\n",
      "Epoch 3602, Loss: 1.833674468798563e-05, Final Batch Loss: 1.088330645870883e-05\n",
      "Epoch 3603, Loss: 0.0005647401085298043, Final Batch Loss: 3.112539343419485e-05\n",
      "Epoch 3604, Loss: 4.324177325543133e-06, Final Batch Loss: 1.2665666417888133e-06\n",
      "Epoch 3605, Loss: 8.742297723074444e-05, Final Batch Loss: 3.568704050849192e-05\n",
      "Epoch 3606, Loss: 5.00101787110907e-05, Final Batch Loss: 4.4823655116488226e-06\n",
      "Epoch 3607, Loss: 9.951101856131572e-05, Final Batch Loss: 9.53494236455299e-05\n",
      "Epoch 3608, Loss: 7.29227327838089e-05, Final Batch Loss: 7.109654688974842e-05\n",
      "Epoch 3609, Loss: 0.0018204069274361245, Final Batch Loss: 3.787007153732702e-05\n",
      "Epoch 3610, Loss: 3.690837615977216e-05, Final Batch Loss: 3.5784148622042267e-06\n",
      "Epoch 3611, Loss: 0.0006186089449329302, Final Batch Loss: 0.0005716228624805808\n",
      "Epoch 3612, Loss: 0.00011506251212267671, Final Batch Loss: 9.558975580148399e-05\n",
      "Epoch 3613, Loss: 3.764318489629659e-05, Final Batch Loss: 3.0464059818768874e-05\n",
      "Epoch 3614, Loss: 6.956919332878897e-05, Final Batch Loss: 5.912799315410666e-05\n",
      "Epoch 3615, Loss: 9.582949132891372e-06, Final Batch Loss: 5.668010999215767e-06\n",
      "Epoch 3616, Loss: 0.009573163257300621, Final Batch Loss: 3.746876245713793e-05\n",
      "Epoch 3617, Loss: 0.00037365736898209434, Final Batch Loss: 2.4449529519188218e-05\n",
      "Epoch 3618, Loss: 2.20569095290557e-05, Final Batch Loss: 1.4507398191199172e-05\n",
      "Epoch 3619, Loss: 7.282913998096774e-05, Final Batch Loss: 2.0401696474436903e-06\n",
      "Epoch 3620, Loss: 3.1800609576748684e-05, Final Batch Loss: 1.928341771417763e-05\n",
      "Epoch 3621, Loss: 0.007380900934549572, Final Batch Loss: 5.738839718105737e-06\n",
      "Epoch 3622, Loss: 0.0008226074314734433, Final Batch Loss: 4.612526754499413e-05\n",
      "Epoch 3623, Loss: 0.0007857510677240498, Final Batch Loss: 0.0007806061184965074\n",
      "Epoch 3624, Loss: 0.0003666389238787815, Final Batch Loss: 0.00029658718267455697\n",
      "Epoch 3625, Loss: 0.004573160404106602, Final Batch Loss: 0.0044954512268304825\n",
      "Epoch 3626, Loss: 0.00010957734411931597, Final Batch Loss: 1.4614652172895148e-05\n",
      "Epoch 3627, Loss: 0.0026568001267150976, Final Batch Loss: 0.002629036083817482\n",
      "Epoch 3628, Loss: 5.443345980893355e-05, Final Batch Loss: 2.9722306862822734e-05\n",
      "Epoch 3629, Loss: 0.0003380983598617604, Final Batch Loss: 8.454173439531587e-06\n",
      "Epoch 3630, Loss: 0.00020365356613183394, Final Batch Loss: 3.329676837893203e-05\n",
      "Epoch 3631, Loss: 0.00025999425633926876, Final Batch Loss: 0.0002177427231799811\n",
      "Epoch 3632, Loss: 7.0880152634345e-05, Final Batch Loss: 4.606072616297752e-05\n",
      "Epoch 3633, Loss: 0.00013119829236529768, Final Batch Loss: 6.286776624619961e-05\n",
      "Epoch 3634, Loss: 7.893236033851281e-05, Final Batch Loss: 3.171293064951897e-05\n",
      "Epoch 3635, Loss: 7.227652167784981e-05, Final Batch Loss: 5.6159162340918556e-05\n",
      "Epoch 3636, Loss: 0.0013117863672960084, Final Batch Loss: 9.876570402411744e-06\n",
      "Epoch 3637, Loss: 0.0004466758036869578, Final Batch Loss: 9.148913522949442e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3638, Loss: 0.0009591849347998505, Final Batch Loss: 0.0009450314100831747\n",
      "Epoch 3639, Loss: 9.591845991963055e-05, Final Batch Loss: 7.814516720827669e-05\n",
      "Epoch 3640, Loss: 0.000417498558817897, Final Batch Loss: 0.0001215500888065435\n",
      "Epoch 3641, Loss: 7.953574549901532e-05, Final Batch Loss: 7.010152330622077e-05\n",
      "Epoch 3642, Loss: 1.8300403098692186e-05, Final Batch Loss: 6.958179255889263e-06\n",
      "Epoch 3643, Loss: 5.502559906744864e-05, Final Batch Loss: 1.717441227810923e-05\n",
      "Epoch 3644, Loss: 0.00011596989088502596, Final Batch Loss: 6.741789093211992e-06\n",
      "Epoch 3645, Loss: 0.00023485840938519686, Final Batch Loss: 3.756904334295541e-05\n",
      "Epoch 3646, Loss: 0.0017328171888948418, Final Batch Loss: 0.001662874361500144\n",
      "Epoch 3647, Loss: 7.972413914103527e-05, Final Batch Loss: 5.7764744269661605e-05\n",
      "Epoch 3648, Loss: 2.4135849798767595e-05, Final Batch Loss: 6.613808636757312e-06\n",
      "Epoch 3649, Loss: 0.0008306260933750309, Final Batch Loss: 0.0001161288600997068\n",
      "Epoch 3650, Loss: 5.53069539819262e-05, Final Batch Loss: 1.0346621820644941e-05\n",
      "Epoch 3651, Loss: 0.00024287643100251444, Final Batch Loss: 4.2706076783360913e-05\n",
      "Epoch 3652, Loss: 0.00019283389337942936, Final Batch Loss: 0.00017771919374354184\n",
      "Epoch 3653, Loss: 1.712365701678209e-05, Final Batch Loss: 5.822488674311899e-06\n",
      "Epoch 3654, Loss: 0.0003317999671708094, Final Batch Loss: 1.704783244349528e-05\n",
      "Epoch 3655, Loss: 3.191055748175131e-05, Final Batch Loss: 1.2332630831224378e-05\n",
      "Epoch 3656, Loss: 0.0016660016281093704, Final Batch Loss: 1.917500230774749e-05\n",
      "Epoch 3657, Loss: 0.0009076433489099145, Final Batch Loss: 2.573529491201043e-05\n",
      "Epoch 3658, Loss: 7.728521632088814e-05, Final Batch Loss: 5.596331538981758e-05\n",
      "Epoch 3659, Loss: 0.000177007656020578, Final Batch Loss: 0.00013056976604275405\n",
      "Epoch 3660, Loss: 0.0013884342552046292, Final Batch Loss: 6.103066698415205e-05\n",
      "Epoch 3661, Loss: 0.0001597497939656023, Final Batch Loss: 6.079316881368868e-05\n",
      "Epoch 3662, Loss: 0.0012889073586848099, Final Batch Loss: 0.0012718968791887164\n",
      "Epoch 3663, Loss: 0.00010245839621347841, Final Batch Loss: 8.060654363362119e-05\n",
      "Epoch 3664, Loss: 0.0007065302852424793, Final Batch Loss: 3.406102041481063e-05\n",
      "Epoch 3665, Loss: 7.302929043362383e-05, Final Batch Loss: 5.6123448302969337e-05\n",
      "Epoch 3666, Loss: 0.0012905012990813702, Final Batch Loss: 0.00028069710242561996\n",
      "Epoch 3667, Loss: 3.6412012832443e-05, Final Batch Loss: 6.682455477857729e-06\n",
      "Epoch 3668, Loss: 0.00010237988135486376, Final Batch Loss: 9.206096001435071e-05\n",
      "Epoch 3669, Loss: 4.7721203372930177e-05, Final Batch Loss: 2.4120337911881506e-05\n",
      "Epoch 3670, Loss: 0.00072143974739447, Final Batch Loss: 0.0007188860327005386\n",
      "Epoch 3671, Loss: 4.117020216654055e-05, Final Batch Loss: 1.755389166646637e-05\n",
      "Epoch 3672, Loss: 4.464456333153066e-05, Final Batch Loss: 3.723716508829966e-05\n",
      "Epoch 3673, Loss: 2.6258194338879548e-05, Final Batch Loss: 1.2399523257045075e-05\n",
      "Epoch 3674, Loss: 0.00038784761545684887, Final Batch Loss: 0.0003857862902805209\n",
      "Epoch 3675, Loss: 0.0014440493177971803, Final Batch Loss: 4.171465843683109e-05\n",
      "Epoch 3676, Loss: 6.873983875266276e-05, Final Batch Loss: 2.036650403169915e-05\n",
      "Epoch 3677, Loss: 0.00023861791351009742, Final Batch Loss: 4.828706096304813e-06\n",
      "Epoch 3678, Loss: 5.404439252743032e-05, Final Batch Loss: 1.9466579033178277e-05\n",
      "Epoch 3679, Loss: 0.0010138082434423268, Final Batch Loss: 1.6838836017996073e-05\n",
      "Epoch 3680, Loss: 3.830016794381663e-05, Final Batch Loss: 1.5919305951683782e-05\n",
      "Epoch 3681, Loss: 0.00037031658212072216, Final Batch Loss: 0.00036503770388662815\n",
      "Epoch 3682, Loss: 7.960111815918935e-06, Final Batch Loss: 4.388157321955077e-06\n",
      "Epoch 3683, Loss: 0.00010660552288754843, Final Batch Loss: 5.5145908845588565e-05\n",
      "Epoch 3684, Loss: 8.765380016484414e-06, Final Batch Loss: 6.1379000726446975e-06\n",
      "Epoch 3685, Loss: 0.0012146779044996947, Final Batch Loss: 0.0010673711076378822\n",
      "Epoch 3686, Loss: 0.0006386629320331849, Final Batch Loss: 0.000554676866158843\n",
      "Epoch 3687, Loss: 0.0007117573404684663, Final Batch Loss: 0.00021815107902511954\n",
      "Epoch 3688, Loss: 6.246031171031063e-05, Final Batch Loss: 4.849610922974534e-05\n",
      "Epoch 3689, Loss: 6.667304660368245e-05, Final Batch Loss: 1.5107971194083802e-05\n",
      "Epoch 3690, Loss: 0.00011635017563094152, Final Batch Loss: 0.00010442453640280291\n",
      "Epoch 3691, Loss: 6.53150198104413e-06, Final Batch Loss: 1.389073872815061e-06\n",
      "Epoch 3692, Loss: 1.1474593520688359e-05, Final Batch Loss: 7.1655608735454734e-06\n",
      "Epoch 3693, Loss: 9.698157953152986e-06, Final Batch Loss: 6.501208531517477e-07\n",
      "Epoch 3694, Loss: 3.615900823206175e-05, Final Batch Loss: 1.1091322448919527e-05\n",
      "Epoch 3695, Loss: 7.714227103861049e-05, Final Batch Loss: 4.25557627750095e-05\n",
      "Epoch 3696, Loss: 5.177998104954895e-06, Final Batch Loss: 4.220054961479036e-06\n",
      "Epoch 3697, Loss: 3.822227063210448e-05, Final Batch Loss: 5.080425580672454e-06\n",
      "Epoch 3698, Loss: 3.4622379644133616e-05, Final Batch Loss: 3.8050175135140307e-06\n",
      "Epoch 3699, Loss: 0.00015144292410695925, Final Batch Loss: 0.00011043777340091765\n",
      "Epoch 3700, Loss: 0.0007290588182513602, Final Batch Loss: 7.632451161043718e-05\n",
      "Epoch 3701, Loss: 7.229906532302266e-05, Final Batch Loss: 1.4563344848284032e-05\n",
      "Epoch 3702, Loss: 0.00011244154848100152, Final Batch Loss: 3.0332053938764147e-05\n",
      "Epoch 3703, Loss: 1.2691620213445276e-05, Final Batch Loss: 7.728507625870407e-06\n",
      "Epoch 3704, Loss: 0.00025771232321858406, Final Batch Loss: 0.00021009355259593576\n",
      "Epoch 3705, Loss: 0.0007143303701013792, Final Batch Loss: 8.500373951392248e-06\n",
      "Epoch 3706, Loss: 8.99129599929438e-06, Final Batch Loss: 2.5037111299752723e-06\n",
      "Epoch 3707, Loss: 0.0006365130827816756, Final Batch Loss: 0.0006341873086057603\n",
      "Epoch 3708, Loss: 0.00012569248656291165, Final Batch Loss: 2.6947368496621493e-06\n",
      "Epoch 3709, Loss: 3.60727351562673e-05, Final Batch Loss: 3.382727300049737e-05\n",
      "Epoch 3710, Loss: 0.0006834522355347872, Final Batch Loss: 0.0005924004362896085\n",
      "Epoch 3711, Loss: 1.5178886087596766e-05, Final Batch Loss: 1.2846147910750005e-05\n",
      "Epoch 3712, Loss: 0.00018504911440686556, Final Batch Loss: 9.991626029659528e-06\n",
      "Epoch 3713, Loss: 7.951975476316875e-06, Final Batch Loss: 2.4370547180296853e-06\n",
      "Epoch 3714, Loss: 0.00012647921539610252, Final Batch Loss: 5.0063521484844387e-05\n",
      "Epoch 3715, Loss: 0.00041145007708109915, Final Batch Loss: 0.00025300230481661856\n",
      "Epoch 3716, Loss: 3.928491787519306e-05, Final Batch Loss: 6.384278094628826e-06\n",
      "Epoch 3717, Loss: 0.00039358020126201154, Final Batch Loss: 2.3594691356265685e-06\n",
      "Epoch 3718, Loss: 0.001044598793669138, Final Batch Loss: 1.961054658750072e-05\n",
      "Epoch 3719, Loss: 0.0003239436503008619, Final Batch Loss: 3.718540256159031e-06\n",
      "Epoch 3720, Loss: 0.0003747660321096191, Final Batch Loss: 1.8130778698832728e-05\n",
      "Epoch 3721, Loss: 9.437190215066948e-05, Final Batch Loss: 9.092571417568251e-05\n",
      "Epoch 3722, Loss: 0.0001594225668668514, Final Batch Loss: 0.00014979088155087084\n",
      "Epoch 3723, Loss: 8.768815973780875e-06, Final Batch Loss: 7.527174147980986e-06\n",
      "Epoch 3724, Loss: 5.571115571001428e-05, Final Batch Loss: 1.8956702660943847e-06\n",
      "Epoch 3725, Loss: 0.001742651395034045, Final Batch Loss: 0.0007542140665464103\n",
      "Epoch 3726, Loss: 0.00021716237824875861, Final Batch Loss: 0.0001767590583767742\n",
      "Epoch 3727, Loss: 3.800037484325003e-05, Final Batch Loss: 8.275399522972293e-06\n",
      "Epoch 3728, Loss: 3.1438179348697304e-06, Final Batch Loss: 2.4137871150742285e-06\n",
      "Epoch 3729, Loss: 0.00040347579124500044, Final Batch Loss: 0.0004012844292446971\n",
      "Epoch 3730, Loss: 4.189513799701672e-05, Final Batch Loss: 1.6086190726127825e-06\n",
      "Epoch 3731, Loss: 0.0016990777676255675, Final Batch Loss: 4.739371433970518e-06\n",
      "Epoch 3732, Loss: 3.229400545023964e-05, Final Batch Loss: 2.6391446226625703e-05\n",
      "Epoch 3733, Loss: 1.0961073712678626e-05, Final Batch Loss: 5.2060827329114545e-06\n",
      "Epoch 3734, Loss: 1.6902857623790624e-05, Final Batch Loss: 4.216769866616232e-06\n",
      "Epoch 3735, Loss: 4.659717069444014e-05, Final Batch Loss: 3.2559393730480224e-05\n",
      "Epoch 3736, Loss: 1.5951998079799523e-05, Final Batch Loss: 1.4378068044607062e-05\n",
      "Epoch 3737, Loss: 0.0001068753372237552, Final Batch Loss: 5.109770427225158e-06\n",
      "Epoch 3738, Loss: 2.6408078156237025e-05, Final Batch Loss: 1.0421658771520015e-05\n",
      "Epoch 3739, Loss: 4.7189874976538704e-05, Final Batch Loss: 1.97063877749315e-06\n",
      "Epoch 3740, Loss: 1.4163226524033234e-05, Final Batch Loss: 1.1947567145398352e-05\n",
      "Epoch 3741, Loss: 3.721973780557164e-05, Final Batch Loss: 7.190409178292612e-06\n",
      "Epoch 3742, Loss: 5.2118687563051935e-05, Final Batch Loss: 7.77111836214317e-06\n",
      "Epoch 3743, Loss: 0.001388653698086273, Final Batch Loss: 0.0012801125412806869\n",
      "Epoch 3744, Loss: 0.00018777564764604904, Final Batch Loss: 2.0716852304758504e-05\n",
      "Epoch 3745, Loss: 8.85453596310981e-06, Final Batch Loss: 2.6587074444250902e-06\n",
      "Epoch 3746, Loss: 5.910014124310692e-06, Final Batch Loss: 2.841454488589079e-06\n",
      "Epoch 3747, Loss: 3.415810533624608e-05, Final Batch Loss: 3.287688014097512e-05\n",
      "Epoch 3748, Loss: 1.2249825886101462e-05, Final Batch Loss: 6.757310075045098e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3749, Loss: 0.00010661088708729949, Final Batch Loss: 1.5501265806960873e-05\n",
      "Epoch 3750, Loss: 0.0013371097738854587, Final Batch Loss: 0.00117931654676795\n",
      "Epoch 3751, Loss: 0.000154820729221683, Final Batch Loss: 5.578917625825852e-05\n",
      "Epoch 3752, Loss: 3.5073981507594e-05, Final Batch Loss: 3.072861363762058e-05\n",
      "Epoch 3753, Loss: 0.00032032296439865604, Final Batch Loss: 1.874296140158549e-05\n",
      "Epoch 3754, Loss: 2.4423170543741435e-05, Final Batch Loss: 1.1043751328543294e-05\n",
      "Epoch 3755, Loss: 1.0394465334684355e-05, Final Batch Loss: 2.5616677703510504e-06\n",
      "Epoch 3756, Loss: 2.9339329557842575e-05, Final Batch Loss: 1.540717676107306e-05\n",
      "Epoch 3757, Loss: 7.557799790447461e-05, Final Batch Loss: 7.266973261721432e-05\n",
      "Epoch 3758, Loss: 0.0011977819567619008, Final Batch Loss: 1.148561295849504e-05\n",
      "Epoch 3759, Loss: 0.0005115038447911502, Final Batch Loss: 7.481497050321195e-06\n",
      "Epoch 3760, Loss: 1.1841141031254665e-05, Final Batch Loss: 1.036442199620069e-06\n",
      "Epoch 3761, Loss: 0.0018421367309429115, Final Batch Loss: 0.001840359647758305\n",
      "Epoch 3762, Loss: 0.001737348356982693, Final Batch Loss: 0.0014724417123943567\n",
      "Epoch 3763, Loss: 0.00011676028498186497, Final Batch Loss: 0.00011187488416908309\n",
      "Epoch 3764, Loss: 0.0005793359378003515, Final Batch Loss: 0.0005465610302053392\n",
      "Epoch 3765, Loss: 1.4992014712333912e-05, Final Batch Loss: 4.0829031604516786e-06\n",
      "Epoch 3766, Loss: 0.0003707925416165381, Final Batch Loss: 1.421674733137479e-05\n",
      "Epoch 3767, Loss: 0.00027596070481195056, Final Batch Loss: 2.24159498429799e-06\n",
      "Epoch 3768, Loss: 1.9193954358343035e-05, Final Batch Loss: 1.0876737178477924e-05\n",
      "Epoch 3769, Loss: 6.525057688122615e-05, Final Batch Loss: 4.308634379412979e-05\n",
      "Epoch 3770, Loss: 0.00012690429139183834, Final Batch Loss: 4.746238118968904e-05\n",
      "Epoch 3771, Loss: 4.9817234412330436e-05, Final Batch Loss: 7.3090272962872405e-06\n",
      "Epoch 3772, Loss: 7.825317140941479e-06, Final Batch Loss: 3.945980893149681e-07\n",
      "Epoch 3773, Loss: 1.3292522453411948e-05, Final Batch Loss: 5.945815701124957e-06\n",
      "Epoch 3774, Loss: 7.280788850039244e-06, Final Batch Loss: 3.940624537790427e-06\n",
      "Epoch 3775, Loss: 1.179185301225516e-05, Final Batch Loss: 6.052065600670176e-06\n",
      "Epoch 3776, Loss: 0.006017720643285429, Final Batch Loss: 3.672143429866992e-05\n",
      "Epoch 3777, Loss: 3.61310230800882e-05, Final Batch Loss: 2.2060585251892917e-05\n",
      "Epoch 3778, Loss: 3.991746234532911e-05, Final Batch Loss: 3.604984885896556e-05\n",
      "Epoch 3779, Loss: 6.073780241422355e-06, Final Batch Loss: 3.2407765502284747e-06\n",
      "Epoch 3780, Loss: 0.0013487888318195473, Final Batch Loss: 0.001336085144430399\n",
      "Epoch 3781, Loss: 2.9338376862142468e-05, Final Batch Loss: 2.3117416276363656e-05\n",
      "Epoch 3782, Loss: 5.757965368502482e-05, Final Batch Loss: 5.56953891646117e-05\n",
      "Epoch 3783, Loss: 4.775513843924273e-05, Final Batch Loss: 2.5665875000413507e-05\n",
      "Epoch 3784, Loss: 0.0009076618748622423, Final Batch Loss: 0.0009027290507219732\n",
      "Epoch 3785, Loss: 2.791533177060046e-06, Final Batch Loss: 4.939417408422742e-07\n",
      "Epoch 3786, Loss: 5.851828859704256e-06, Final Batch Loss: 4.147702384216245e-06\n",
      "Epoch 3787, Loss: 0.0007463912736511702, Final Batch Loss: 2.214070491390885e-06\n",
      "Epoch 3788, Loss: 2.4303699319716543e-05, Final Batch Loss: 1.6551013686694205e-05\n",
      "Epoch 3789, Loss: 0.00012857267142862838, Final Batch Loss: 0.00012611910642590374\n",
      "Epoch 3790, Loss: 5.133011291036382e-05, Final Batch Loss: 1.7193542589666322e-05\n",
      "Epoch 3791, Loss: 0.0001364187347689949, Final Batch Loss: 1.3355175951801357e-06\n",
      "Epoch 3792, Loss: 3.287606205049087e-05, Final Batch Loss: 1.369710389553802e-06\n",
      "Epoch 3793, Loss: 2.7239218979957514e-05, Final Batch Loss: 1.5473584426217712e-05\n",
      "Epoch 3794, Loss: 4.076550487752684e-05, Final Batch Loss: 1.4458915984505438e-06\n",
      "Epoch 3795, Loss: 5.47058334632311e-06, Final Batch Loss: 4.8559541028225794e-06\n",
      "Epoch 3796, Loss: 3.1852684969635447e-06, Final Batch Loss: 4.790394996234681e-07\n",
      "Epoch 3797, Loss: 5.0161485887656454e-05, Final Batch Loss: 4.7553428885294124e-05\n",
      "Epoch 3798, Loss: 5.9938709455309436e-05, Final Batch Loss: 5.72318458580412e-06\n",
      "Epoch 3799, Loss: 0.001032351215599192, Final Batch Loss: 4.771447038365295e-06\n",
      "Epoch 3800, Loss: 2.761388395811082e-05, Final Batch Loss: 4.389987680042395e-06\n",
      "Epoch 3801, Loss: 0.0003081463655689731, Final Batch Loss: 0.00026984731084667146\n",
      "Epoch 3802, Loss: 3.297046214356669e-05, Final Batch Loss: 3.1055184081196785e-05\n",
      "Epoch 3803, Loss: 4.303924652049318e-05, Final Batch Loss: 1.6584577679168433e-05\n",
      "Epoch 3804, Loss: 7.896255510786432e-06, Final Batch Loss: 4.221474682708504e-06\n",
      "Epoch 3805, Loss: 2.5586096626284416e-05, Final Batch Loss: 2.233226723546977e-06\n",
      "Epoch 3806, Loss: 5.274547766020987e-05, Final Batch Loss: 3.359067704877816e-05\n",
      "Epoch 3807, Loss: 0.0006362228459693142, Final Batch Loss: 0.0006306102150119841\n",
      "Epoch 3808, Loss: 0.0011949473700951785, Final Batch Loss: 0.0003329988394398242\n",
      "Epoch 3809, Loss: 1.1863617601193255e-05, Final Batch Loss: 2.5962885956687387e-06\n",
      "Epoch 3810, Loss: 2.2086721855885116e-05, Final Batch Loss: 1.819408316805493e-05\n",
      "Epoch 3811, Loss: 0.00025088505503845226, Final Batch Loss: 1.2687480648310157e-06\n",
      "Epoch 3812, Loss: 6.047879651305266e-05, Final Batch Loss: 4.904158049612306e-05\n",
      "Epoch 3813, Loss: 0.0004423069131007651, Final Batch Loss: 0.0004332134558353573\n",
      "Epoch 3814, Loss: 0.000806885904239607, Final Batch Loss: 0.0007847982924431562\n",
      "Epoch 3815, Loss: 0.002789458962070057, Final Batch Loss: 2.007978400797583e-05\n",
      "Epoch 3816, Loss: 0.0002976400796796952, Final Batch Loss: 0.0002902721462305635\n",
      "Epoch 3817, Loss: 5.768194978372776e-05, Final Batch Loss: 1.2141194929427002e-06\n",
      "Epoch 3818, Loss: 4.0712120608077385e-05, Final Batch Loss: 3.847201878670603e-05\n",
      "Epoch 3819, Loss: 0.00010855002619791776, Final Batch Loss: 4.359378363005817e-05\n",
      "Epoch 3820, Loss: 0.002364495351230289, Final Batch Loss: 3.6196329347149003e-06\n",
      "Epoch 3821, Loss: 2.8181704692542553e-05, Final Batch Loss: 2.2895301299286075e-05\n",
      "Epoch 3822, Loss: 6.622506077746948e-06, Final Batch Loss: 5.686499662260758e-06\n",
      "Epoch 3823, Loss: 3.7757969039375894e-05, Final Batch Loss: 1.426648123015184e-05\n",
      "Epoch 3824, Loss: 2.2273603462963365e-05, Final Batch Loss: 2.007465809583664e-05\n",
      "Epoch 3825, Loss: 4.521171490523557e-06, Final Batch Loss: 2.700242703213007e-06\n",
      "Epoch 3826, Loss: 0.0004961628010278218, Final Batch Loss: 0.0004870005650445819\n",
      "Epoch 3827, Loss: 1.487957263179851e-05, Final Batch Loss: 9.497363180344109e-07\n",
      "Epoch 3828, Loss: 4.361485662229825e-05, Final Batch Loss: 2.518568180676084e-05\n",
      "Epoch 3829, Loss: 0.00047153512150543975, Final Batch Loss: 6.216298970684875e-06\n",
      "Epoch 3830, Loss: 4.5489679450838594e-05, Final Batch Loss: 3.2744860618549865e-06\n",
      "Epoch 3831, Loss: 0.0002387405515946739, Final Batch Loss: 0.00023314234567806125\n",
      "Epoch 3832, Loss: 1.0721293165261159e-05, Final Batch Loss: 7.869593900977634e-06\n",
      "Epoch 3833, Loss: 2.464618341946334e-05, Final Batch Loss: 3.0872990919306176e-06\n",
      "Epoch 3834, Loss: 2.7843563657370396e-05, Final Batch Loss: 1.2594885447470006e-05\n",
      "Epoch 3835, Loss: 0.0010636650272317638, Final Batch Loss: 0.0010624086717143655\n",
      "Epoch 3836, Loss: 4.9143405703944154e-05, Final Batch Loss: 2.07867196877487e-05\n",
      "Epoch 3837, Loss: 0.00017990716878557578, Final Batch Loss: 9.158159809885547e-05\n",
      "Epoch 3838, Loss: 2.6276348989995313e-06, Final Batch Loss: 1.0441114000059315e-06\n",
      "Epoch 3839, Loss: 0.0012069720833096653, Final Batch Loss: 0.000934705778490752\n",
      "Epoch 3840, Loss: 0.0003130113295810588, Final Batch Loss: 0.00030991522362455726\n",
      "Epoch 3841, Loss: 2.208327614994232e-06, Final Batch Loss: 1.567372152067037e-07\n",
      "Epoch 3842, Loss: 6.00408784521278e-05, Final Batch Loss: 4.209429243928753e-05\n",
      "Epoch 3843, Loss: 0.0002738178077379416, Final Batch Loss: 4.6893323997210246e-06\n",
      "Epoch 3844, Loss: 0.0005694269652281037, Final Batch Loss: 1.2583171837832197e-07\n",
      "Epoch 3845, Loss: 1.0357310941344622e-05, Final Batch Loss: 3.9790648997950484e-07\n",
      "Epoch 3846, Loss: 9.220922402164433e-05, Final Batch Loss: 7.423237548209727e-05\n",
      "Epoch 3847, Loss: 0.0004831939822906861, Final Batch Loss: 5.772390068159439e-06\n",
      "Epoch 3848, Loss: 3.720067934409599e-05, Final Batch Loss: 5.0265766731172334e-06\n",
      "Epoch 3849, Loss: 2.199886125708872e-05, Final Batch Loss: 1.866961429186631e-05\n",
      "Epoch 3850, Loss: 7.558260915629944e-05, Final Batch Loss: 1.2268188811503933e-06\n",
      "Epoch 3851, Loss: 0.00030626377724729537, Final Batch Loss: 0.0003029348445124924\n",
      "Epoch 3852, Loss: 3.571433865090512e-05, Final Batch Loss: 1.5612446304658079e-06\n",
      "Epoch 3853, Loss: 3.4675666711336817e-06, Final Batch Loss: 2.341328581678681e-06\n",
      "Epoch 3854, Loss: 0.00011041708921766258, Final Batch Loss: 5.007366326026386e-06\n",
      "Epoch 3855, Loss: 0.00033045150485122576, Final Batch Loss: 1.9365405023563653e-05\n",
      "Epoch 3856, Loss: 4.487537808017805e-05, Final Batch Loss: 2.613676042528823e-05\n",
      "Epoch 3857, Loss: 6.966331625335442e-06, Final Batch Loss: 5.3238627515384e-06\n",
      "Epoch 3858, Loss: 0.00013176157881389372, Final Batch Loss: 9.899486758513376e-05\n",
      "Epoch 3859, Loss: 4.547510343400063e-06, Final Batch Loss: 1.302433702221606e-06\n",
      "Epoch 3860, Loss: 0.006702367356410832, Final Batch Loss: 0.00667300121858716\n",
      "Epoch 3861, Loss: 1.9652589628549322e-05, Final Batch Loss: 1.8944996554637328e-05\n",
      "Epoch 3862, Loss: 0.0008238458362939127, Final Batch Loss: 0.0008193685207515955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3863, Loss: 2.5244191363071877e-05, Final Batch Loss: 5.36432651188079e-07\n",
      "Epoch 3864, Loss: 0.001320742736425018, Final Batch Loss: 0.0013018392492085695\n",
      "Epoch 3865, Loss: 0.00017559199443439866, Final Batch Loss: 5.209727760302485e-07\n",
      "Epoch 3866, Loss: 6.698697688989341e-05, Final Batch Loss: 4.956466727890074e-05\n",
      "Epoch 3867, Loss: 0.00045765116146867513, Final Batch Loss: 0.00045694023719988763\n",
      "Epoch 3868, Loss: 0.0001958852808456868, Final Batch Loss: 7.140317757148296e-05\n",
      "Epoch 3869, Loss: 4.145719799453218e-06, Final Batch Loss: 4.0508382426196476e-07\n",
      "Epoch 3870, Loss: 9.022905487654498e-06, Final Batch Loss: 4.959115813107928e-06\n",
      "Epoch 3871, Loss: 1.7127966884800117e-05, Final Batch Loss: 1.3355412193050142e-05\n",
      "Epoch 3872, Loss: 0.0007191049717221176, Final Batch Loss: 0.0006977557204663754\n",
      "Epoch 3873, Loss: 1.4743333849764895e-05, Final Batch Loss: 8.460108801955357e-06\n",
      "Epoch 3874, Loss: 3.024760985681496e-06, Final Batch Loss: 3.007806981258909e-07\n",
      "Epoch 3875, Loss: 0.00034595007809912204, Final Batch Loss: 0.0003405284369364381\n",
      "Epoch 3876, Loss: 3.738530904229265e-05, Final Batch Loss: 1.666817297518719e-05\n",
      "Epoch 3877, Loss: 0.005181283020647243, Final Batch Loss: 0.00036890970659442246\n",
      "Epoch 3878, Loss: 9.486634667155158e-06, Final Batch Loss: 8.120571692415979e-06\n",
      "Epoch 3879, Loss: 9.37774416343018e-06, Final Batch Loss: 7.636951522727031e-06\n",
      "Epoch 3880, Loss: 9.737312757351901e-05, Final Batch Loss: 8.828841237118468e-05\n",
      "Epoch 3881, Loss: 0.03304675925755873, Final Batch Loss: 0.032205305993556976\n",
      "Epoch 3882, Loss: 1.0321896183995705e-05, Final Batch Loss: 8.621294000477064e-06\n",
      "Epoch 3883, Loss: 3.4977135669578274e-05, Final Batch Loss: 1.1208607020307682e-06\n",
      "Epoch 3884, Loss: 1.1262329167038843e-06, Final Batch Loss: 4.310186341172084e-07\n",
      "Epoch 3885, Loss: 0.0005395773405325599, Final Batch Loss: 0.0005045550060458481\n",
      "Epoch 3886, Loss: 0.0009684160759206861, Final Batch Loss: 0.00035474871401675045\n",
      "Epoch 3887, Loss: 0.0027596453473961446, Final Batch Loss: 0.0027470518834888935\n",
      "Epoch 3888, Loss: 0.014327716468528706, Final Batch Loss: 1.7075004734579124e-06\n",
      "Epoch 3889, Loss: 8.418717698077671e-05, Final Batch Loss: 5.8607678511179984e-05\n",
      "Epoch 3890, Loss: 0.0007369707491307054, Final Batch Loss: 0.0006983167841099203\n",
      "Epoch 3891, Loss: 0.0016455028089694679, Final Batch Loss: 0.0008071127813309431\n",
      "Epoch 3892, Loss: 1.7604411823413102e-05, Final Batch Loss: 1.4009918231749907e-05\n",
      "Epoch 3893, Loss: 0.0008415960801357869, Final Batch Loss: 0.0008042629342526197\n",
      "Epoch 3894, Loss: 4.015235003862472e-05, Final Batch Loss: 3.819171979557723e-05\n",
      "Epoch 3895, Loss: 5.2137157808829215e-06, Final Batch Loss: 1.2880306030638167e-06\n",
      "Epoch 3896, Loss: 0.0002684740416043496, Final Batch Loss: 0.00026360119227319956\n",
      "Epoch 3897, Loss: 0.00041073645570577355, Final Batch Loss: 9.75549210124882e-06\n",
      "Epoch 3898, Loss: 0.009931309847161174, Final Batch Loss: 8.927821181714535e-05\n",
      "Epoch 3899, Loss: 0.000133179004478734, Final Batch Loss: 0.00010573797771940008\n",
      "Epoch 3900, Loss: 2.881541718124936e-05, Final Batch Loss: 2.737777549555176e-06\n",
      "Epoch 3901, Loss: 0.0007628724097230588, Final Batch Loss: 1.049170987243997e-05\n",
      "Epoch 3902, Loss: 0.0016345904732588679, Final Batch Loss: 0.0016031680861487985\n",
      "Epoch 3903, Loss: 0.00012482361125876196, Final Batch Loss: 1.3900487829232588e-05\n",
      "Epoch 3904, Loss: 5.4321257266565226e-05, Final Batch Loss: 1.4970226402510889e-05\n",
      "Epoch 3905, Loss: 2.398189462837763e-05, Final Batch Loss: 4.176386937615462e-06\n",
      "Epoch 3906, Loss: 0.00011794201236625668, Final Batch Loss: 1.8025280951405875e-05\n",
      "Epoch 3907, Loss: 4.2640527681214735e-05, Final Batch Loss: 3.16124533128459e-05\n",
      "Epoch 3908, Loss: 2.185395896958653e-05, Final Batch Loss: 1.2153452189522795e-05\n",
      "Epoch 3909, Loss: 1.1461593430794892e-05, Final Batch Loss: 3.5881614621757763e-06\n",
      "Epoch 3910, Loss: 0.00023425123072229326, Final Batch Loss: 6.256421329453588e-05\n",
      "Epoch 3911, Loss: 0.0006430996927520027, Final Batch Loss: 1.9442868506303057e-06\n",
      "Epoch 3912, Loss: 0.00016310427054122556, Final Batch Loss: 0.00013446924276649952\n",
      "Epoch 3913, Loss: 4.57468186141341e-05, Final Batch Loss: 1.5181262824626174e-05\n",
      "Epoch 3914, Loss: 5.148296622792259e-05, Final Batch Loss: 2.4372046027565375e-05\n",
      "Epoch 3915, Loss: 0.002790163707686588, Final Batch Loss: 0.00039691870915703475\n",
      "Epoch 3916, Loss: 0.0020096116932109, Final Batch Loss: 0.0006307517178356647\n",
      "Epoch 3917, Loss: 0.0003379548902557872, Final Batch Loss: 6.939302238606615e-06\n",
      "Epoch 3918, Loss: 0.0007453077087120619, Final Batch Loss: 0.0007112439488992095\n",
      "Epoch 3919, Loss: 5.731782039219979e-05, Final Batch Loss: 2.581573608040344e-05\n",
      "Epoch 3920, Loss: 5.21646722972946e-06, Final Batch Loss: 3.960496087529464e-06\n",
      "Epoch 3921, Loss: 1.4758819361304631e-05, Final Batch Loss: 6.920492978679249e-06\n",
      "Epoch 3922, Loss: 0.005488685880663979, Final Batch Loss: 8.64927551447181e-06\n",
      "Epoch 3923, Loss: 3.43145015904156e-05, Final Batch Loss: 2.9537419322878122e-05\n",
      "Epoch 3924, Loss: 2.280888475070242e-05, Final Batch Loss: 1.4160617865854874e-05\n",
      "Epoch 3925, Loss: 7.179804197221529e-05, Final Batch Loss: 4.429304681252688e-05\n",
      "Epoch 3926, Loss: 0.0007527833904532599, Final Batch Loss: 0.0007494266028515995\n",
      "Epoch 3927, Loss: 0.0001471144332754193, Final Batch Loss: 0.00012797469389624894\n",
      "Epoch 3928, Loss: 9.250174298358615e-05, Final Batch Loss: 8.367197006009519e-05\n",
      "Epoch 3929, Loss: 4.941272982250666e-05, Final Batch Loss: 1.4276635738497134e-05\n",
      "Epoch 3930, Loss: 0.00016993407552945428, Final Batch Loss: 0.00013644422870129347\n",
      "Epoch 3931, Loss: 3.417866173549555e-05, Final Batch Loss: 1.7140362615464255e-05\n",
      "Epoch 3932, Loss: 7.848126369935926e-05, Final Batch Loss: 5.828549910802394e-05\n",
      "Epoch 3933, Loss: 0.0015068104503370705, Final Batch Loss: 1.2860425158578437e-05\n",
      "Epoch 3934, Loss: 4.364637425169349e-05, Final Batch Loss: 3.3869971957756206e-05\n",
      "Epoch 3935, Loss: 2.614353115859558e-05, Final Batch Loss: 6.6676952883426566e-06\n",
      "Epoch 3936, Loss: 0.00044992936091148295, Final Batch Loss: 0.0004053270386066288\n",
      "Epoch 3937, Loss: 3.244262961743516e-05, Final Batch Loss: 2.696518822631333e-05\n",
      "Epoch 3938, Loss: 8.999920100905001e-05, Final Batch Loss: 5.704077921109274e-05\n",
      "Epoch 3939, Loss: 3.718040079547791e-05, Final Batch Loss: 2.2600834199693054e-05\n",
      "Epoch 3940, Loss: 7.356014975812286e-05, Final Batch Loss: 2.973980372189544e-05\n",
      "Epoch 3941, Loss: 3.941683871744317e-05, Final Batch Loss: 4.2124233914364595e-06\n",
      "Epoch 3942, Loss: 2.236214322692831e-05, Final Batch Loss: 6.675265922240214e-06\n",
      "Epoch 3943, Loss: 5.2344064897624776e-05, Final Batch Loss: 2.9395814635790884e-05\n",
      "Epoch 3944, Loss: 0.0003210991417290643, Final Batch Loss: 6.34645257377997e-05\n",
      "Epoch 3945, Loss: 6.853616287116893e-05, Final Batch Loss: 4.3726846342906356e-05\n",
      "Epoch 3946, Loss: 2.0047632460773457e-05, Final Batch Loss: 8.125951353576966e-06\n",
      "Epoch 3947, Loss: 2.398896367594716e-05, Final Batch Loss: 2.0446892449399456e-05\n",
      "Epoch 3948, Loss: 1.991356339203776e-05, Final Batch Loss: 6.065743491490139e-06\n",
      "Epoch 3949, Loss: 0.00011427760910009965, Final Batch Loss: 6.52774324407801e-05\n",
      "Epoch 3950, Loss: 0.0013113645582052413, Final Batch Loss: 0.00128135085105896\n",
      "Epoch 3951, Loss: 4.8968019200401613e-05, Final Batch Loss: 4.170077954768203e-05\n",
      "Epoch 3952, Loss: 0.0002662097576831002, Final Batch Loss: 0.00022669325699098408\n",
      "Epoch 3953, Loss: 0.0008494788344250992, Final Batch Loss: 3.5391320125199854e-05\n",
      "Epoch 3954, Loss: 7.578879376524128e-06, Final Batch Loss: 3.5210741771152243e-06\n",
      "Epoch 3955, Loss: 0.001600466828676872, Final Batch Loss: 2.7293033781461418e-05\n",
      "Epoch 3956, Loss: 3.9917853428050876e-05, Final Batch Loss: 1.914447420858778e-05\n",
      "Epoch 3957, Loss: 1.4940093478799099e-05, Final Batch Loss: 1.0381265383330174e-05\n",
      "Epoch 3958, Loss: 8.609590804553591e-05, Final Batch Loss: 6.207913247635588e-05\n",
      "Epoch 3959, Loss: 2.662876431713812e-05, Final Batch Loss: 1.5315030395868234e-05\n",
      "Epoch 3960, Loss: 8.152675945893861e-05, Final Batch Loss: 4.0336304664378986e-05\n",
      "Epoch 3961, Loss: 7.917695802461822e-05, Final Batch Loss: 2.0457448044908233e-05\n",
      "Epoch 3962, Loss: 1.8053841586151975e-05, Final Batch Loss: 1.4851837477181107e-05\n",
      "Epoch 3963, Loss: 0.000896020867912739, Final Batch Loss: 5.7232855397160165e-06\n",
      "Epoch 3964, Loss: 0.0006838901608716697, Final Batch Loss: 1.4699966413900256e-05\n",
      "Epoch 3965, Loss: 0.0004407640017234371, Final Batch Loss: 1.1557241123227868e-05\n",
      "Epoch 3966, Loss: 1.998407373093869e-05, Final Batch Loss: 1.9289334886707366e-05\n",
      "Epoch 3967, Loss: 3.4437283602528623e-06, Final Batch Loss: 1.9613548829511274e-06\n",
      "Epoch 3968, Loss: 3.4727337606454967e-05, Final Batch Loss: 3.0014394724275917e-05\n",
      "Epoch 3969, Loss: 4.1014101952896453e-05, Final Batch Loss: 1.861509372247383e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3970, Loss: 2.8856989047199022e-05, Final Batch Loss: 2.3017941202851944e-05\n",
      "Epoch 3971, Loss: 0.00029703674954362214, Final Batch Loss: 7.405849464703351e-05\n",
      "Epoch 3972, Loss: 0.00011018726218026131, Final Batch Loss: 1.5204983355943114e-05\n",
      "Epoch 3973, Loss: 1.3281462997838389e-05, Final Batch Loss: 5.23606468050275e-06\n",
      "Epoch 3974, Loss: 0.001128746305766981, Final Batch Loss: 2.658040466485545e-05\n",
      "Epoch 3975, Loss: 0.0005124958015585435, Final Batch Loss: 9.139174835581798e-06\n",
      "Epoch 3976, Loss: 0.00011457603432063479, Final Batch Loss: 5.555275492952205e-06\n",
      "Epoch 3977, Loss: 0.00014432601619773777, Final Batch Loss: 0.00013020462938584387\n",
      "Epoch 3978, Loss: 0.00048130019240488764, Final Batch Loss: 0.00047182911657728255\n",
      "Epoch 3979, Loss: 3.4893935662694275e-05, Final Batch Loss: 1.2513946785475127e-05\n",
      "Epoch 3980, Loss: 1.791139902707073e-05, Final Batch Loss: 1.3062915058981162e-05\n",
      "Epoch 3981, Loss: 3.2860145438462496e-05, Final Batch Loss: 1.5375162547570653e-05\n",
      "Epoch 3982, Loss: 0.0002381299163971562, Final Batch Loss: 0.00018485859618522227\n",
      "Epoch 3983, Loss: 4.969840551893867e-05, Final Batch Loss: 2.585423089840333e-06\n",
      "Epoch 3984, Loss: 0.0007286962863872759, Final Batch Loss: 0.0006368497852236032\n",
      "Epoch 3985, Loss: 1.4658524378319271e-05, Final Batch Loss: 3.994112375949044e-06\n",
      "Epoch 3986, Loss: 0.0006347945163724944, Final Batch Loss: 0.0005148850032128394\n",
      "Epoch 3987, Loss: 0.00013273894182930235, Final Batch Loss: 0.0001203762658406049\n",
      "Epoch 3988, Loss: 0.00021358812227845192, Final Batch Loss: 3.3319825888611376e-05\n",
      "Epoch 3989, Loss: 0.0018441509309923276, Final Batch Loss: 0.0017975864466279745\n",
      "Epoch 3990, Loss: 1.696111121418653e-05, Final Batch Loss: 1.4829261090198997e-05\n",
      "Epoch 3991, Loss: 7.716713116678875e-05, Final Batch Loss: 1.0788096915348433e-05\n",
      "Epoch 3992, Loss: 7.492864415326039e-05, Final Batch Loss: 6.273930466704769e-06\n",
      "Epoch 3993, Loss: 0.0004185910156593309, Final Batch Loss: 0.0004107058048248291\n",
      "Epoch 3994, Loss: 9.100700299313758e-05, Final Batch Loss: 6.154472066555172e-05\n",
      "Epoch 3995, Loss: 2.398739343334455e-05, Final Batch Loss: 1.9523602531990036e-05\n",
      "Epoch 3996, Loss: 7.150517012632918e-05, Final Batch Loss: 2.2569465727428906e-05\n",
      "Epoch 3997, Loss: 2.7830246835947037e-05, Final Batch Loss: 2.495956141501665e-05\n",
      "Epoch 3998, Loss: 3.968210512539372e-05, Final Batch Loss: 1.1320542398607358e-05\n",
      "Epoch 3999, Loss: 0.0008146843611029908, Final Batch Loss: 3.6932280636392534e-05\n",
      "Epoch 4000, Loss: 3.0474617233267054e-05, Final Batch Loss: 1.4948051102692261e-05\n",
      "Epoch 4001, Loss: 6.004870783726801e-06, Final Batch Loss: 1.9408801108511398e-06\n",
      "Epoch 4002, Loss: 5.063297794549726e-05, Final Batch Loss: 1.6896396118681878e-05\n",
      "Epoch 4003, Loss: 1.7120005850301823e-05, Final Batch Loss: 6.210294941411121e-06\n",
      "Epoch 4004, Loss: 6.043055009286036e-06, Final Batch Loss: 3.1398785722558387e-06\n",
      "Epoch 4005, Loss: 0.00014696940070280107, Final Batch Loss: 9.159241926681716e-06\n",
      "Epoch 4006, Loss: 5.9151012465008534e-05, Final Batch Loss: 4.1081468225456774e-05\n",
      "Epoch 4007, Loss: 3.0372235414688475e-05, Final Batch Loss: 1.798995799617842e-05\n",
      "Epoch 4008, Loss: 5.7236153224948794e-05, Final Batch Loss: 4.7921967052388936e-05\n",
      "Epoch 4009, Loss: 9.638345545681659e-05, Final Batch Loss: 1.7141284843091853e-05\n",
      "Epoch 4010, Loss: 0.01607220464211423, Final Batch Loss: 3.83521692128852e-05\n",
      "Epoch 4011, Loss: 2.8497564869667258e-05, Final Batch Loss: 2.762783333309926e-05\n",
      "Epoch 4012, Loss: 0.0012517761533672456, Final Batch Loss: 0.00122059287969023\n",
      "Epoch 4013, Loss: 1.4393963738257298e-05, Final Batch Loss: 5.130140834808117e-06\n",
      "Epoch 4014, Loss: 5.882821278646588e-05, Final Batch Loss: 4.158560113864951e-05\n",
      "Epoch 4015, Loss: 0.0030549472430720925, Final Batch Loss: 0.002636136021465063\n",
      "Epoch 4016, Loss: 0.021246125190373277, Final Batch Loss: 2.4794800992822275e-05\n",
      "Epoch 4017, Loss: 0.0006231291044969112, Final Batch Loss: 0.0004805567441508174\n",
      "Epoch 4018, Loss: 7.387961159111e-05, Final Batch Loss: 3.067098441533744e-05\n",
      "Epoch 4019, Loss: 0.00023562392289022682, Final Batch Loss: 1.2848958249378484e-05\n",
      "Epoch 4020, Loss: 0.001793460327462526, Final Batch Loss: 0.0017596414545550942\n",
      "Epoch 4021, Loss: 0.00037766649620607495, Final Batch Loss: 1.682326546870172e-05\n",
      "Epoch 4022, Loss: 3.724627958945348e-05, Final Batch Loss: 3.088685843977146e-05\n",
      "Epoch 4023, Loss: 6.646298197665601e-05, Final Batch Loss: 3.903709057340166e-06\n",
      "Epoch 4024, Loss: 0.00013453722385747824, Final Batch Loss: 0.00010566606215434149\n",
      "Epoch 4025, Loss: 0.000630444468697533, Final Batch Loss: 0.00032212361111305654\n",
      "Epoch 4026, Loss: 7.262486360559706e-05, Final Batch Loss: 6.0537604440469295e-05\n",
      "Epoch 4027, Loss: 0.0007020994889899157, Final Batch Loss: 0.0005801208317279816\n",
      "Epoch 4028, Loss: 5.277410218695877e-05, Final Batch Loss: 4.449869447853416e-05\n",
      "Epoch 4029, Loss: 0.00016809104636195116, Final Batch Loss: 2.306987516931258e-05\n",
      "Epoch 4030, Loss: 7.131061101972591e-05, Final Batch Loss: 6.454444519476965e-05\n",
      "Epoch 4031, Loss: 0.00026597792748361826, Final Batch Loss: 6.999883044045419e-05\n",
      "Epoch 4032, Loss: 0.0013615750099233992, Final Batch Loss: 6.719873908878071e-06\n",
      "Epoch 4033, Loss: 6.225783636182314e-06, Final Batch Loss: 5.1524516493373085e-06\n",
      "Epoch 4034, Loss: 0.013103561979733058, Final Batch Loss: 0.013093768619000912\n",
      "Epoch 4035, Loss: 0.00013328859859029762, Final Batch Loss: 2.796823173412122e-05\n",
      "Epoch 4036, Loss: 0.00016467094246763736, Final Batch Loss: 0.00011465800344012678\n",
      "Epoch 4037, Loss: 0.00010801952339534182, Final Batch Loss: 8.328765397891402e-05\n",
      "Epoch 4038, Loss: 0.005771154698777536, Final Batch Loss: 0.005757463630288839\n",
      "Epoch 4039, Loss: 0.007680391594476532, Final Batch Loss: 6.0570127971004695e-05\n",
      "Epoch 4040, Loss: 0.0009909970976877958, Final Batch Loss: 0.000867470633238554\n",
      "Epoch 4041, Loss: 0.0004869592230534181, Final Batch Loss: 0.0003789935726672411\n",
      "Epoch 4042, Loss: 0.020687520154751837, Final Batch Loss: 3.697874490171671e-05\n",
      "Epoch 4043, Loss: 0.00010045574936157209, Final Batch Loss: 2.858680545614334e-06\n",
      "Epoch 4044, Loss: 0.0001417173225490842, Final Batch Loss: 0.00010773575922939926\n",
      "Epoch 4045, Loss: 0.0002792900340864435, Final Batch Loss: 0.00015599826292600483\n",
      "Epoch 4046, Loss: 0.00011334028022247367, Final Batch Loss: 3.9704911614535376e-05\n",
      "Epoch 4047, Loss: 0.00020086633594473824, Final Batch Loss: 0.00013128927093930542\n",
      "Epoch 4048, Loss: 0.00040466884820489213, Final Batch Loss: 0.00036334170727059245\n",
      "Epoch 4049, Loss: 0.00012359465108602308, Final Batch Loss: 5.390245860326104e-05\n",
      "Epoch 4050, Loss: 0.00046786006714683026, Final Batch Loss: 0.00017806958931032568\n",
      "Epoch 4051, Loss: 0.0008911207551136613, Final Batch Loss: 0.0002979128039442003\n",
      "Epoch 4052, Loss: 0.002554263803176582, Final Batch Loss: 0.0021629873663187027\n",
      "Epoch 4053, Loss: 0.0011243061890127137, Final Batch Loss: 0.00017392421432305127\n",
      "Epoch 4054, Loss: 0.0002863572517526336, Final Batch Loss: 9.180545021081343e-05\n",
      "Epoch 4055, Loss: 0.008086424320936203, Final Batch Loss: 0.0008088517934083939\n",
      "Epoch 4056, Loss: 0.00013673376815859228, Final Batch Loss: 5.9162237448617816e-05\n",
      "Epoch 4057, Loss: 0.00010607163130771369, Final Batch Loss: 6.142775237094611e-05\n",
      "Epoch 4058, Loss: 0.00033126689959317446, Final Batch Loss: 0.00011561675637494773\n",
      "Epoch 4059, Loss: 0.0001382366790494416, Final Batch Loss: 3.833984737866558e-05\n",
      "Epoch 4060, Loss: 0.00017517088053864427, Final Batch Loss: 2.033642158494331e-05\n",
      "Epoch 4061, Loss: 1.656805261518457e-05, Final Batch Loss: 7.419540906994371e-06\n",
      "Epoch 4062, Loss: 0.0006732169713359326, Final Batch Loss: 0.0006291791796684265\n",
      "Epoch 4063, Loss: 0.0039087836048565805, Final Batch Loss: 0.00021721393568441272\n",
      "Epoch 4064, Loss: 0.00011667255603242666, Final Batch Loss: 1.2023199815303087e-05\n",
      "Epoch 4065, Loss: 0.01394305429130327, Final Batch Loss: 0.00012923921167384833\n",
      "Epoch 4066, Loss: 5.869772030564491e-05, Final Batch Loss: 1.852591049100738e-05\n",
      "Epoch 4067, Loss: 0.0006126513835624792, Final Batch Loss: 0.0005715661100111902\n",
      "Epoch 4068, Loss: 0.00030819342828181107, Final Batch Loss: 2.3865535695222206e-05\n",
      "Epoch 4069, Loss: 0.00015212449216051027, Final Batch Loss: 8.950357732828707e-05\n",
      "Epoch 4070, Loss: 0.003631817271525506, Final Batch Loss: 7.815854769432917e-05\n",
      "Epoch 4071, Loss: 0.0018416905077174306, Final Batch Loss: 0.0007525854744017124\n",
      "Epoch 4072, Loss: 0.0008049564276007004, Final Batch Loss: 0.0007273393566720188\n",
      "Epoch 4073, Loss: 0.00021408683096524328, Final Batch Loss: 0.00011579821148188785\n",
      "Epoch 4074, Loss: 0.0023574664373882115, Final Batch Loss: 0.001712333527393639\n",
      "Epoch 4075, Loss: 0.00031615159969078377, Final Batch Loss: 3.5642711736727506e-05\n",
      "Epoch 4076, Loss: 0.00020819486235268414, Final Batch Loss: 6.692795432172716e-05\n",
      "Epoch 4077, Loss: 0.00010841193216037937, Final Batch Loss: 2.9274913686094806e-05\n",
      "Epoch 4078, Loss: 0.008897239806174184, Final Batch Loss: 1.9468830942059867e-05\n",
      "Epoch 4079, Loss: 0.001358133158646524, Final Batch Loss: 0.0005866308347322047\n",
      "Epoch 4080, Loss: 0.0010949468669423368, Final Batch Loss: 1.885858000605367e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4081, Loss: 0.0003818591321760323, Final Batch Loss: 0.000365770683856681\n",
      "Epoch 4082, Loss: 0.0005009654851164669, Final Batch Loss: 0.0003650398284662515\n",
      "Epoch 4083, Loss: 0.00023207050981000066, Final Batch Loss: 0.00013522863446269184\n",
      "Epoch 4084, Loss: 0.00011359722884662915, Final Batch Loss: 2.233901795989368e-05\n",
      "Epoch 4085, Loss: 0.0012184269580757245, Final Batch Loss: 0.0010292348451912403\n",
      "Epoch 4086, Loss: 0.0004645318622351624, Final Batch Loss: 7.220687257358804e-05\n",
      "Epoch 4087, Loss: 0.0002319624472875148, Final Batch Loss: 7.013486174400896e-05\n",
      "Epoch 4088, Loss: 0.00023813660664018244, Final Batch Loss: 7.298971468117088e-05\n",
      "Epoch 4089, Loss: 0.00024911517539294437, Final Batch Loss: 0.00014629375073127449\n",
      "Epoch 4090, Loss: 0.0008818575570330722, Final Batch Loss: 1.7217678760061972e-05\n",
      "Epoch 4091, Loss: 0.0002082536811940372, Final Batch Loss: 5.67274255445227e-05\n",
      "Epoch 4092, Loss: 0.00025195672969857696, Final Batch Loss: 0.00022774942044634372\n",
      "Epoch 4093, Loss: 0.0002574181016825605, Final Batch Loss: 4.8510530177736655e-05\n",
      "Epoch 4094, Loss: 6.410541209334042e-05, Final Batch Loss: 3.751920667127706e-05\n",
      "Epoch 4095, Loss: 6.755687718396075e-05, Final Batch Loss: 1.04106729850173e-05\n",
      "Epoch 4096, Loss: 0.00020026681886520237, Final Batch Loss: 8.978224650491029e-05\n",
      "Epoch 4097, Loss: 0.0011999795169685967, Final Batch Loss: 0.0010819548042491078\n",
      "Epoch 4098, Loss: 0.0003335220899316482, Final Batch Loss: 9.393148502567783e-05\n",
      "Epoch 4099, Loss: 9.57554566412e-05, Final Batch Loss: 1.6123913155752234e-05\n",
      "Epoch 4100, Loss: 5.1118679948558565e-05, Final Batch Loss: 1.3449650396069046e-05\n",
      "Epoch 4101, Loss: 0.0001477008408983238, Final Batch Loss: 6.476009002653882e-05\n",
      "Epoch 4102, Loss: 5.6808751651260536e-05, Final Batch Loss: 5.144945680513047e-05\n",
      "Epoch 4103, Loss: 0.00015080722005222924, Final Batch Loss: 4.7648998588556424e-05\n",
      "Epoch 4104, Loss: 8.288327626360115e-05, Final Batch Loss: 2.4766412025201134e-05\n",
      "Epoch 4105, Loss: 9.681915616965853e-05, Final Batch Loss: 4.601061300490983e-05\n",
      "Epoch 4106, Loss: 5.768017672380665e-05, Final Batch Loss: 9.252155905414838e-06\n",
      "Epoch 4107, Loss: 4.2658656639105175e-05, Final Batch Loss: 1.1286553672107402e-05\n",
      "Epoch 4108, Loss: 0.00019415279439272126, Final Batch Loss: 2.475097971910145e-06\n",
      "Epoch 4109, Loss: 4.441541932465043e-05, Final Batch Loss: 2.182059506594669e-05\n",
      "Epoch 4110, Loss: 6.364569617289817e-05, Final Batch Loss: 1.114916358346818e-05\n",
      "Epoch 4111, Loss: 8.683746864335262e-05, Final Batch Loss: 8.23790323920548e-05\n",
      "Epoch 4112, Loss: 3.099616606050404e-05, Final Batch Loss: 1.2196532225061674e-05\n",
      "Epoch 4113, Loss: 0.00019483639698592015, Final Batch Loss: 0.00018433918012306094\n",
      "Epoch 4114, Loss: 1.426872063348128e-05, Final Batch Loss: 2.8233728244231315e-06\n",
      "Epoch 4115, Loss: 0.0005382136696425732, Final Batch Loss: 2.4274366296594962e-05\n",
      "Epoch 4116, Loss: 0.0002947999819298275, Final Batch Loss: 0.00022770663781557232\n",
      "Epoch 4117, Loss: 0.00023326701921178028, Final Batch Loss: 8.657365833641961e-05\n",
      "Epoch 4118, Loss: 0.00010013417704612948, Final Batch Loss: 6.892903184052557e-05\n",
      "Epoch 4119, Loss: 5.4620822083961684e-05, Final Batch Loss: 1.5108530533325393e-05\n",
      "Epoch 4120, Loss: 3.421326618990861e-05, Final Batch Loss: 6.917634891578928e-06\n",
      "Epoch 4121, Loss: 0.0007741771260043606, Final Batch Loss: 0.0006921254680491984\n",
      "Epoch 4122, Loss: 0.00023327429516939446, Final Batch Loss: 0.00013280210259836167\n",
      "Epoch 4123, Loss: 0.00048040472029242665, Final Batch Loss: 0.00039987757918424904\n",
      "Epoch 4124, Loss: 0.00021126900628587464, Final Batch Loss: 0.0002017572260228917\n",
      "Epoch 4125, Loss: 4.8207404688582756e-05, Final Batch Loss: 3.174043013132177e-05\n",
      "Epoch 4126, Loss: 3.518369067023741e-05, Final Batch Loss: 2.606701855256688e-05\n",
      "Epoch 4127, Loss: 2.8627400752156973e-05, Final Batch Loss: 1.4855489098408725e-05\n",
      "Epoch 4128, Loss: 0.0006119177778600715, Final Batch Loss: 4.892076685791835e-05\n",
      "Epoch 4129, Loss: 4.8412128307973035e-05, Final Batch Loss: 2.2691783669870347e-05\n",
      "Epoch 4130, Loss: 4.4732439619110664e-05, Final Batch Loss: 3.8624610169790685e-05\n",
      "Epoch 4131, Loss: 0.0009140404436038807, Final Batch Loss: 8.225861529354006e-05\n",
      "Epoch 4132, Loss: 5.639097616949584e-05, Final Batch Loss: 2.909961222030688e-05\n",
      "Epoch 4133, Loss: 8.042836998356506e-05, Final Batch Loss: 5.787550253444351e-05\n",
      "Epoch 4134, Loss: 0.0002738136172411032, Final Batch Loss: 7.10170206730254e-05\n",
      "Epoch 4135, Loss: 0.0009163783215626609, Final Batch Loss: 4.9774691433412954e-05\n",
      "Epoch 4136, Loss: 0.00024313967946909543, Final Batch Loss: 1.974062570297974e-06\n",
      "Epoch 4137, Loss: 8.112319119391032e-05, Final Batch Loss: 6.277750071603805e-05\n",
      "Epoch 4138, Loss: 6.219613919711264e-05, Final Batch Loss: 2.2720798824593658e-06\n",
      "Epoch 4139, Loss: 0.00014615706459153444, Final Batch Loss: 6.910722004249692e-05\n",
      "Epoch 4140, Loss: 6.561834379681386e-05, Final Batch Loss: 3.8575548387598246e-05\n",
      "Epoch 4141, Loss: 4.3556210584938526e-05, Final Batch Loss: 1.755381890689023e-05\n",
      "Epoch 4142, Loss: 1.2243282299095881e-05, Final Batch Loss: 8.893264748621732e-06\n",
      "Epoch 4143, Loss: 5.281694575387519e-05, Final Batch Loss: 1.1492867997731082e-05\n",
      "Epoch 4144, Loss: 5.599061114480719e-05, Final Batch Loss: 3.0534796678693965e-05\n",
      "Epoch 4145, Loss: 0.0007976618071552366, Final Batch Loss: 0.00010146884596906602\n",
      "Epoch 4146, Loss: 0.00012999818659409357, Final Batch Loss: 0.00012687244452536106\n",
      "Epoch 4147, Loss: 5.391441300162114e-05, Final Batch Loss: 3.5760011087404564e-05\n",
      "Epoch 4148, Loss: 7.746831397525966e-05, Final Batch Loss: 6.565609510289505e-05\n",
      "Epoch 4149, Loss: 4.2583954837027704e-05, Final Batch Loss: 3.5755179851548746e-05\n",
      "Epoch 4150, Loss: 0.000626011944405036, Final Batch Loss: 5.361515286494978e-05\n",
      "Epoch 4151, Loss: 0.00011011900369339855, Final Batch Loss: 8.194799193006475e-06\n",
      "Epoch 4152, Loss: 0.0018780549771690858, Final Batch Loss: 1.2275461813260335e-05\n",
      "Epoch 4153, Loss: 6.373079031618545e-06, Final Batch Loss: 2.6351376618549693e-06\n",
      "Epoch 4154, Loss: 6.237824345589615e-05, Final Batch Loss: 3.324708450236358e-05\n",
      "Epoch 4155, Loss: 0.00013385260535869747, Final Batch Loss: 0.00010660312545951456\n",
      "Epoch 4156, Loss: 9.373444936500164e-05, Final Batch Loss: 8.368688577320427e-05\n",
      "Epoch 4157, Loss: 2.3709384549874812e-05, Final Batch Loss: 2.1500787624972872e-05\n",
      "Epoch 4158, Loss: 3.7306322155927774e-05, Final Batch Loss: 2.3507258447352797e-05\n",
      "Epoch 4159, Loss: 6.259887595660985e-05, Final Batch Loss: 5.079375841887668e-05\n",
      "Epoch 4160, Loss: 0.0007979428191902116, Final Batch Loss: 0.0006979875615797937\n",
      "Epoch 4161, Loss: 3.5093714359391015e-05, Final Batch Loss: 2.4892004148568958e-05\n",
      "Epoch 4162, Loss: 2.860024596884614e-05, Final Batch Loss: 2.006883551075589e-05\n",
      "Epoch 4163, Loss: 3.897484748449642e-05, Final Batch Loss: 2.3461330783902667e-05\n",
      "Epoch 4164, Loss: 7.451753663190175e-05, Final Batch Loss: 6.245163967832923e-05\n",
      "Epoch 4165, Loss: 1.554958271299256e-05, Final Batch Loss: 6.1264408941497095e-06\n",
      "Epoch 4166, Loss: 7.537303099525161e-05, Final Batch Loss: 5.243142004474066e-05\n",
      "Epoch 4167, Loss: 9.924016239892808e-06, Final Batch Loss: 3.74804199054779e-06\n",
      "Epoch 4168, Loss: 0.0009154614781436976, Final Batch Loss: 2.5117678887909278e-05\n",
      "Epoch 4169, Loss: 0.00046215972542995587, Final Batch Loss: 0.0004004174843430519\n",
      "Epoch 4170, Loss: 0.000868431737217179, Final Batch Loss: 0.0008555219974368811\n",
      "Epoch 4171, Loss: 3.254492185078561e-05, Final Batch Loss: 1.3543320164899342e-05\n",
      "Epoch 4172, Loss: 1.7391172605130123e-05, Final Batch Loss: 1.1442893082858063e-05\n",
      "Epoch 4173, Loss: 0.00019330213763169013, Final Batch Loss: 0.00015508972865063697\n",
      "Epoch 4174, Loss: 0.001231991016993561, Final Batch Loss: 4.208792688586982e-06\n",
      "Epoch 4175, Loss: 0.0021902748267166317, Final Batch Loss: 0.0009049667860381305\n",
      "Epoch 4176, Loss: 3.471884838290862e-05, Final Batch Loss: 3.0611139663960785e-05\n",
      "Epoch 4177, Loss: 1.0584768233456998e-05, Final Batch Loss: 9.073258297576103e-06\n",
      "Epoch 4178, Loss: 6.384752464327903e-05, Final Batch Loss: 1.3840979136148235e-06\n",
      "Epoch 4179, Loss: 2.5285024094046094e-05, Final Batch Loss: 1.2465164218156133e-05\n",
      "Epoch 4180, Loss: 0.0009449714852962643, Final Batch Loss: 4.38009446952492e-05\n",
      "Epoch 4181, Loss: 6.0250607020861935e-05, Final Batch Loss: 5.088900798000395e-05\n",
      "Epoch 4182, Loss: 0.00011088252904301044, Final Batch Loss: 9.114867134485394e-05\n",
      "Epoch 4183, Loss: 7.40444820621633e-05, Final Batch Loss: 6.881316949147731e-05\n",
      "Epoch 4184, Loss: 0.0010283180454280227, Final Batch Loss: 3.7674413761124015e-05\n",
      "Epoch 4185, Loss: 2.4041060896706767e-05, Final Batch Loss: 1.149480067397235e-05\n",
      "Epoch 4186, Loss: 9.237584708898794e-05, Final Batch Loss: 8.952947609941475e-06\n",
      "Epoch 4187, Loss: 0.00016959731874521822, Final Batch Loss: 2.6519890525378287e-05\n",
      "Epoch 4188, Loss: 1.2704011851383257e-05, Final Batch Loss: 1.0543136340857018e-05\n",
      "Epoch 4189, Loss: 0.00023429502743965713, Final Batch Loss: 1.0991304407070857e-05\n",
      "Epoch 4190, Loss: 1.1691293366311584e-05, Final Batch Loss: 6.228573056432651e-06\n",
      "Epoch 4191, Loss: 0.00010366921878812718, Final Batch Loss: 3.5741827559832018e-06\n",
      "Epoch 4192, Loss: 3.7265342371028964e-05, Final Batch Loss: 3.00481156045862e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4193, Loss: 0.00013054582359472988, Final Batch Loss: 1.1358543815731537e-05\n",
      "Epoch 4194, Loss: 0.00078559050189142, Final Batch Loss: 3.7928143683529925e-06\n",
      "Epoch 4195, Loss: 0.00027019878734790836, Final Batch Loss: 0.0002632753166835755\n",
      "Epoch 4196, Loss: 5.653160496876808e-05, Final Batch Loss: 5.0375922000966966e-05\n",
      "Epoch 4197, Loss: 0.0006191659358592005, Final Batch Loss: 1.5963147234288044e-05\n",
      "Epoch 4198, Loss: 0.0016537158535356866, Final Batch Loss: 1.1006022759829648e-05\n",
      "Epoch 4199, Loss: 6.311585366347572e-05, Final Batch Loss: 4.994629853172228e-05\n",
      "Epoch 4200, Loss: 0.031195171643048525, Final Batch Loss: 0.027939610183238983\n",
      "Epoch 4201, Loss: 8.044431001508201e-05, Final Batch Loss: 3.590072310544201e-06\n",
      "Epoch 4202, Loss: 0.00020480176317505538, Final Batch Loss: 0.0001429990225005895\n",
      "Epoch 4203, Loss: 5.4157259000930935e-05, Final Batch Loss: 2.1887768525630236e-05\n",
      "Epoch 4204, Loss: 2.4736021714488743e-05, Final Batch Loss: 1.8529268345446326e-05\n",
      "Epoch 4205, Loss: 0.0029493151523638517, Final Batch Loss: 4.917688784189522e-05\n",
      "Epoch 4206, Loss: 8.78298651514342e-05, Final Batch Loss: 1.886099016701337e-05\n",
      "Epoch 4207, Loss: 0.0004532531629592995, Final Batch Loss: 0.0004463490331545472\n",
      "Epoch 4208, Loss: 0.00038188630969671067, Final Batch Loss: 1.532536953163799e-05\n",
      "Epoch 4209, Loss: 0.00036555540282279253, Final Batch Loss: 0.0003096003201790154\n",
      "Epoch 4210, Loss: 0.000329198082908988, Final Batch Loss: 3.554290742613375e-05\n",
      "Epoch 4211, Loss: 0.01277045574533986, Final Batch Loss: 0.01270253211259842\n",
      "Epoch 4212, Loss: 0.00013479563131113537, Final Batch Loss: 0.00010130950249731541\n",
      "Epoch 4213, Loss: 0.0011479253880679607, Final Batch Loss: 0.001068598940037191\n",
      "Epoch 4214, Loss: 8.246645847975742e-06, Final Batch Loss: 6.485748599516228e-06\n",
      "Epoch 4215, Loss: 0.00026023991813417524, Final Batch Loss: 3.3745571272447705e-05\n",
      "Epoch 4216, Loss: 0.00017138761359092314, Final Batch Loss: 0.00014390017895493656\n",
      "Epoch 4217, Loss: 1.2185882951598614e-05, Final Batch Loss: 6.273538474488305e-06\n",
      "Epoch 4218, Loss: 2.0965155727026286e-05, Final Batch Loss: 6.105846750870114e-06\n",
      "Epoch 4219, Loss: 0.0005052941241956432, Final Batch Loss: 0.0004976764903403819\n",
      "Epoch 4220, Loss: 1.5036923286970705e-05, Final Batch Loss: 4.757544047606643e-06\n",
      "Epoch 4221, Loss: 9.905847400659695e-05, Final Batch Loss: 6.023718378855847e-05\n",
      "Epoch 4222, Loss: 0.007065772661007941, Final Batch Loss: 0.0068176304921507835\n",
      "Epoch 4223, Loss: 7.15537626092555e-05, Final Batch Loss: 2.0180546925985254e-05\n",
      "Epoch 4224, Loss: 7.40335581213003e-05, Final Batch Loss: 5.743569272453897e-05\n",
      "Epoch 4225, Loss: 9.178174150292762e-05, Final Batch Loss: 5.920263356529176e-05\n",
      "Epoch 4226, Loss: 2.113311529683415e-05, Final Batch Loss: 5.684227289748378e-06\n",
      "Epoch 4227, Loss: 0.0008144776966219069, Final Batch Loss: 8.630117008578964e-06\n",
      "Epoch 4228, Loss: 0.00020968612261640374, Final Batch Loss: 0.0001874296722235158\n",
      "Epoch 4229, Loss: 0.0005995179672027007, Final Batch Loss: 0.00014642921451013535\n",
      "Epoch 4230, Loss: 0.00014205721527105197, Final Batch Loss: 7.898174226284027e-05\n",
      "Epoch 4231, Loss: 0.0009659248516982188, Final Batch Loss: 0.0009380914270877838\n",
      "Epoch 4232, Loss: 0.0001181394977720629, Final Batch Loss: 0.00011291717237327248\n",
      "Epoch 4233, Loss: 0.0008419354271609336, Final Batch Loss: 0.00023922653053887188\n",
      "Epoch 4234, Loss: 0.0002943619492725702, Final Batch Loss: 2.159604810003657e-05\n",
      "Epoch 4235, Loss: 0.00019875876387231983, Final Batch Loss: 0.0001907094701891765\n",
      "Epoch 4236, Loss: 0.0001622737563593546, Final Batch Loss: 0.00014181953156366944\n",
      "Epoch 4237, Loss: 5.048174443800235e-05, Final Batch Loss: 1.2113018783566076e-05\n",
      "Epoch 4238, Loss: 6.532599127240246e-05, Final Batch Loss: 5.463074558065273e-05\n",
      "Epoch 4239, Loss: 0.00037412594429042656, Final Batch Loss: 0.00035787964588962495\n",
      "Epoch 4240, Loss: 9.949395825969987e-05, Final Batch Loss: 4.4970794988330454e-05\n",
      "Epoch 4241, Loss: 0.00019698901951414882, Final Batch Loss: 0.00019294396042823792\n",
      "Epoch 4242, Loss: 3.4649988265300635e-05, Final Batch Loss: 1.1546545465535019e-05\n",
      "Epoch 4243, Loss: 0.0003323232267575804, Final Batch Loss: 0.00031873659463599324\n",
      "Epoch 4244, Loss: 0.00042640470655896934, Final Batch Loss: 9.734799277794082e-06\n",
      "Epoch 4245, Loss: 1.2721999610221246e-05, Final Batch Loss: 8.227781108871568e-06\n",
      "Epoch 4246, Loss: 0.0035056918750342447, Final Batch Loss: 1.4096254744799808e-05\n",
      "Epoch 4247, Loss: 3.2880669095902704e-05, Final Batch Loss: 4.313817044021562e-06\n",
      "Epoch 4248, Loss: 4.1636047171778046e-05, Final Batch Loss: 2.5764731617528014e-05\n",
      "Epoch 4249, Loss: 1.663169950916199e-05, Final Batch Loss: 1.2881647307949606e-05\n",
      "Epoch 4250, Loss: 0.000955138704739511, Final Batch Loss: 0.0005024538841098547\n",
      "Epoch 4251, Loss: 0.0001275504291697871, Final Batch Loss: 0.00011599497520364821\n",
      "Epoch 4252, Loss: 0.00015343306222348474, Final Batch Loss: 0.00014176862896420062\n",
      "Epoch 4253, Loss: 0.0005122915936226491, Final Batch Loss: 0.0004984507686458528\n",
      "Epoch 4254, Loss: 2.6002334379882086e-05, Final Batch Loss: 1.438164235878503e-05\n",
      "Epoch 4255, Loss: 6.850991985629662e-05, Final Batch Loss: 6.10177157795988e-05\n",
      "Epoch 4256, Loss: 0.0008045570575632155, Final Batch Loss: 0.0002845904091373086\n",
      "Epoch 4257, Loss: 0.0018813270144164562, Final Batch Loss: 0.0012170752743259072\n",
      "Epoch 4258, Loss: 0.00014814349606240285, Final Batch Loss: 4.680704023485305e-06\n",
      "Epoch 4259, Loss: 0.00011975164807154215, Final Batch Loss: 3.6201977309247013e-06\n",
      "Epoch 4260, Loss: 0.00010229340114165097, Final Batch Loss: 6.549007230205461e-05\n",
      "Epoch 4261, Loss: 4.3698006265913136e-05, Final Batch Loss: 1.2880960639449768e-05\n",
      "Epoch 4262, Loss: 0.00017473509433330037, Final Batch Loss: 3.274574191891588e-05\n",
      "Epoch 4263, Loss: 5.877255716768559e-05, Final Batch Loss: 6.062678949092515e-06\n",
      "Epoch 4264, Loss: 8.818616697681136e-05, Final Batch Loss: 6.135675357654691e-05\n",
      "Epoch 4265, Loss: 2.1768386432086118e-05, Final Batch Loss: 4.487923433771357e-06\n",
      "Epoch 4266, Loss: 0.00011714742333879258, Final Batch Loss: 1.3939953760200297e-06\n",
      "Epoch 4267, Loss: 6.221186140464852e-05, Final Batch Loss: 9.939715710061137e-06\n",
      "Epoch 4268, Loss: 0.0004402690137794707, Final Batch Loss: 2.0450945157790557e-05\n",
      "Epoch 4269, Loss: 4.555986924970057e-05, Final Batch Loss: 2.6094614440808073e-05\n",
      "Epoch 4270, Loss: 4.2480628508201335e-05, Final Batch Loss: 3.3637457818258554e-05\n",
      "Epoch 4271, Loss: 6.721289628330851e-05, Final Batch Loss: 5.410315134213306e-05\n",
      "Epoch 4272, Loss: 0.00013882992061553523, Final Batch Loss: 0.00012978279846720397\n",
      "Epoch 4273, Loss: 2.6813449039764237e-05, Final Batch Loss: 1.967752723430749e-05\n",
      "Epoch 4274, Loss: 0.00016566238718951354, Final Batch Loss: 3.4022314139292575e-06\n",
      "Epoch 4275, Loss: 0.00047847633868514095, Final Batch Loss: 0.0004600511456374079\n",
      "Epoch 4276, Loss: 4.015251670352882e-05, Final Batch Loss: 3.795256634475663e-05\n",
      "Epoch 4277, Loss: 1.852881905506365e-05, Final Batch Loss: 1.0186641702603083e-05\n",
      "Epoch 4278, Loss: 0.00014615509689974715, Final Batch Loss: 2.396173385932343e-06\n",
      "Epoch 4279, Loss: 0.00014721576371812262, Final Batch Loss: 0.00014214673137757927\n",
      "Epoch 4280, Loss: 3.654756164905848e-05, Final Batch Loss: 2.5900619220919907e-05\n",
      "Epoch 4281, Loss: 6.059561201254837e-06, Final Batch Loss: 4.138923486607382e-06\n",
      "Epoch 4282, Loss: 3.125513921986567e-05, Final Batch Loss: 1.795399293769151e-05\n",
      "Epoch 4283, Loss: 3.7702305235143285e-05, Final Batch Loss: 7.197942068160046e-06\n",
      "Epoch 4284, Loss: 0.00011346075461915461, Final Batch Loss: 1.4690641364722978e-05\n",
      "Epoch 4285, Loss: 0.000136137728986796, Final Batch Loss: 8.971919305622578e-05\n",
      "Epoch 4286, Loss: 0.0011809192292275839, Final Batch Loss: 0.0010681819403544068\n",
      "Epoch 4287, Loss: 6.805696443734632e-06, Final Batch Loss: 5.34663467988139e-06\n",
      "Epoch 4288, Loss: 8.883756163413636e-05, Final Batch Loss: 8.1192898505833e-05\n",
      "Epoch 4289, Loss: 2.562205099820858e-05, Final Batch Loss: 3.4942504498758353e-06\n",
      "Epoch 4290, Loss: 2.8984500204387587e-05, Final Batch Loss: 1.5656805771868676e-05\n",
      "Epoch 4291, Loss: 4.569297561829444e-05, Final Batch Loss: 3.938986628782004e-05\n",
      "Epoch 4292, Loss: 1.5900822745607002e-05, Final Batch Loss: 3.5080970519629773e-06\n",
      "Epoch 4293, Loss: 0.00013288977697811788, Final Batch Loss: 0.00012436218094080687\n",
      "Epoch 4294, Loss: 2.2720003016729606e-05, Final Batch Loss: 3.2255861697194632e-06\n",
      "Epoch 4295, Loss: 3.7165871617617086e-05, Final Batch Loss: 2.5332439690828323e-05\n",
      "Epoch 4296, Loss: 6.302848760242341e-05, Final Batch Loss: 1.3891646631236654e-05\n",
      "Epoch 4297, Loss: 0.0014980843152443413, Final Batch Loss: 0.0014680420281365514\n",
      "Epoch 4298, Loss: 1.6824488739075605e-05, Final Batch Loss: 9.438498636882287e-06\n",
      "Epoch 4299, Loss: 5.522525725609739e-05, Final Batch Loss: 5.1205610361648723e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4300, Loss: 8.579447603551671e-05, Final Batch Loss: 5.005754792364314e-05\n",
      "Epoch 4301, Loss: 0.00024553454204578884, Final Batch Loss: 0.00018554116832092404\n",
      "Epoch 4302, Loss: 3.489615755825071e-05, Final Batch Loss: 2.4771414246060885e-05\n",
      "Epoch 4303, Loss: 0.0002166512749681715, Final Batch Loss: 1.689451528363861e-05\n",
      "Epoch 4304, Loss: 3.6683927646663506e-05, Final Batch Loss: 2.6001316655310802e-05\n",
      "Epoch 4305, Loss: 6.153848403300799e-05, Final Batch Loss: 5.845762643730268e-05\n",
      "Epoch 4306, Loss: 0.0001427286324542365, Final Batch Loss: 0.0001331409439444542\n",
      "Epoch 4307, Loss: 1.1722626368282363e-05, Final Batch Loss: 2.6350726329837926e-06\n",
      "Epoch 4308, Loss: 4.6790659325779416e-05, Final Batch Loss: 1.8716826161835343e-05\n",
      "Epoch 4309, Loss: 3.244662184442859e-05, Final Batch Loss: 2.091568967443891e-05\n",
      "Epoch 4310, Loss: 7.252288924064487e-05, Final Batch Loss: 2.273642166983336e-06\n",
      "Epoch 4311, Loss: 1.9955097286583623e-05, Final Batch Loss: 6.343543191178469e-06\n",
      "Epoch 4312, Loss: 4.98628219247621e-06, Final Batch Loss: 2.52974155046104e-06\n",
      "Epoch 4313, Loss: 3.5752542316913605e-05, Final Batch Loss: 2.642359868332278e-05\n",
      "Epoch 4314, Loss: 1.6031302948249504e-05, Final Batch Loss: 1.0621554793033283e-05\n",
      "Epoch 4315, Loss: 1.7927920453075785e-05, Final Batch Loss: 8.143369086610619e-06\n",
      "Epoch 4316, Loss: 3.32090330630308e-05, Final Batch Loss: 2.408798536635004e-05\n",
      "Epoch 4317, Loss: 2.267508261866169e-05, Final Batch Loss: 1.1649050975393038e-05\n",
      "Epoch 4318, Loss: 0.0009107016564371406, Final Batch Loss: 5.507797027348715e-07\n",
      "Epoch 4319, Loss: 0.00040086600529321004, Final Batch Loss: 2.677587508514989e-05\n",
      "Epoch 4320, Loss: 1.905987119243946e-05, Final Batch Loss: 1.1526553862495348e-05\n",
      "Epoch 4321, Loss: 3.810717134911101e-05, Final Batch Loss: 1.884048106148839e-05\n",
      "Epoch 4322, Loss: 4.924423387819843e-05, Final Batch Loss: 4.557668944471516e-05\n",
      "Epoch 4323, Loss: 0.005997550428702425, Final Batch Loss: 4.6634752948193636e-07\n",
      "Epoch 4324, Loss: 0.00017466368808527477, Final Batch Loss: 0.0001532858586870134\n",
      "Epoch 4325, Loss: 0.0006755834474461153, Final Batch Loss: 0.00023711870016995817\n",
      "Epoch 4326, Loss: 6.523088995891158e-05, Final Batch Loss: 4.8332665755879134e-05\n",
      "Epoch 4327, Loss: 1.4185036434355425e-05, Final Batch Loss: 7.548067515017465e-06\n",
      "Epoch 4328, Loss: 0.00019517742657626513, Final Batch Loss: 0.00017910171300172806\n",
      "Epoch 4329, Loss: 0.000712371835106751, Final Batch Loss: 0.0006600316264666617\n",
      "Epoch 4330, Loss: 9.885231520456728e-06, Final Batch Loss: 4.781548796017887e-06\n",
      "Epoch 4331, Loss: 0.004337875236160471, Final Batch Loss: 9.524699635221623e-06\n",
      "Epoch 4332, Loss: 8.735259689274244e-05, Final Batch Loss: 4.015704689663835e-05\n",
      "Epoch 4333, Loss: 9.2913080152357e-05, Final Batch Loss: 3.107536394963972e-05\n",
      "Epoch 4334, Loss: 0.0003593928141754077, Final Batch Loss: 1.788024860616133e-06\n",
      "Epoch 4335, Loss: 0.0003213055861124303, Final Batch Loss: 0.0003108469827566296\n",
      "Epoch 4336, Loss: 1.1573435358513962e-05, Final Batch Loss: 8.016483661776874e-06\n",
      "Epoch 4337, Loss: 2.1333619770302903e-05, Final Batch Loss: 1.2593347491929308e-05\n",
      "Epoch 4338, Loss: 0.00959831167710945, Final Batch Loss: 9.559438331052661e-05\n",
      "Epoch 4339, Loss: 5.163808964425698e-05, Final Batch Loss: 2.703525751712732e-05\n",
      "Epoch 4340, Loss: 4.360668572189752e-05, Final Batch Loss: 1.6188669178518467e-05\n",
      "Epoch 4341, Loss: 9.588722423359286e-05, Final Batch Loss: 1.2649163181777112e-05\n",
      "Epoch 4342, Loss: 4.372945932118455e-05, Final Batch Loss: 3.3779884688556194e-05\n",
      "Epoch 4343, Loss: 0.0001966034760698676, Final Batch Loss: 5.033028719481081e-05\n",
      "Epoch 4344, Loss: 2.610209821796161e-05, Final Batch Loss: 6.824077445344301e-06\n",
      "Epoch 4345, Loss: 0.00044882437396154273, Final Batch Loss: 0.00042274961015209556\n",
      "Epoch 4346, Loss: 0.0007052465016386122, Final Batch Loss: 0.0006946490611881018\n",
      "Epoch 4347, Loss: 3.943827687180601e-05, Final Batch Loss: 2.4174700229195878e-05\n",
      "Epoch 4348, Loss: 0.00018625521261128597, Final Batch Loss: 0.0001397585729137063\n",
      "Epoch 4349, Loss: 0.0001435292087990092, Final Batch Loss: 2.8180906156194396e-05\n",
      "Epoch 4350, Loss: 0.0003380905118319788, Final Batch Loss: 0.00032865346292965114\n",
      "Epoch 4351, Loss: 5.182847598916851e-05, Final Batch Loss: 1.1780179193010554e-05\n",
      "Epoch 4352, Loss: 0.0005432225775621191, Final Batch Loss: 6.375358225341188e-06\n",
      "Epoch 4353, Loss: 0.0008587589636590565, Final Batch Loss: 0.0008403747924603522\n",
      "Epoch 4354, Loss: 6.995315015956294e-05, Final Batch Loss: 4.7966001147869974e-05\n",
      "Epoch 4355, Loss: 0.0010715181670093443, Final Batch Loss: 0.0010690005728974938\n",
      "Epoch 4356, Loss: 0.0002750122803263366, Final Batch Loss: 9.744448470883071e-05\n",
      "Epoch 4357, Loss: 0.002037035417743027, Final Batch Loss: 9.479443542659283e-05\n",
      "Epoch 4358, Loss: 0.0005539264966500923, Final Batch Loss: 7.46164150768891e-05\n",
      "Epoch 4359, Loss: 0.0005922842210566159, Final Batch Loss: 0.0005669624079018831\n",
      "Epoch 4360, Loss: 0.0018548310581536498, Final Batch Loss: 4.55520894320216e-05\n",
      "Epoch 4361, Loss: 0.0047224710033333395, Final Batch Loss: 0.004708669614046812\n",
      "Epoch 4362, Loss: 2.725877720877179e-05, Final Batch Loss: 6.352713626256445e-06\n",
      "Epoch 4363, Loss: 4.300195723772049e-05, Final Batch Loss: 3.7736044760094956e-05\n",
      "Epoch 4364, Loss: 8.707183496881044e-05, Final Batch Loss: 7.918286428321153e-05\n",
      "Epoch 4365, Loss: 0.00021135791030246764, Final Batch Loss: 0.00010401030885986984\n",
      "Epoch 4366, Loss: 0.00021440123964566737, Final Batch Loss: 9.37834192882292e-05\n",
      "Epoch 4367, Loss: 7.095572982507292e-05, Final Batch Loss: 2.7782783945440315e-05\n",
      "Epoch 4368, Loss: 0.00014512517373077571, Final Batch Loss: 0.00013231532648205757\n",
      "Epoch 4369, Loss: 0.00012740968304569833, Final Batch Loss: 8.2350306911394e-05\n",
      "Epoch 4370, Loss: 0.00037969028744555544, Final Batch Loss: 2.0947101802448742e-05\n",
      "Epoch 4371, Loss: 0.0002008192677749321, Final Batch Loss: 0.00016044244694057852\n",
      "Epoch 4372, Loss: 0.0032317963195964694, Final Batch Loss: 0.0029539510142058134\n",
      "Epoch 4373, Loss: 2.6946283469442278e-05, Final Batch Loss: 1.9243227143306285e-05\n",
      "Epoch 4374, Loss: 1.6266965303657344e-05, Final Batch Loss: 1.3442610907077324e-05\n",
      "Epoch 4375, Loss: 0.00012506454277172452, Final Batch Loss: 6.882836714794394e-06\n",
      "Epoch 4376, Loss: 1.6440171179965546e-05, Final Batch Loss: 1.4771770111110527e-05\n",
      "Epoch 4377, Loss: 0.00023255472478922457, Final Batch Loss: 8.284753130283207e-05\n",
      "Epoch 4378, Loss: 1.9526527694324614e-05, Final Batch Loss: 3.443898322075256e-06\n",
      "Epoch 4379, Loss: 2.135617432941217e-05, Final Batch Loss: 1.0402674888609909e-05\n",
      "Epoch 4380, Loss: 3.920223298337078e-05, Final Batch Loss: 3.342342461110093e-05\n",
      "Epoch 4381, Loss: 0.00023512926418334246, Final Batch Loss: 0.0001890785206342116\n",
      "Epoch 4382, Loss: 6.0043953908461845e-05, Final Batch Loss: 5.5445525504183024e-05\n",
      "Epoch 4383, Loss: 5.661536215484375e-05, Final Batch Loss: 1.3732228580920491e-05\n",
      "Epoch 4384, Loss: 0.0005795025790575892, Final Batch Loss: 0.0005123409209772944\n",
      "Epoch 4385, Loss: 0.0005292741043376736, Final Batch Loss: 0.0004198566311970353\n",
      "Epoch 4386, Loss: 0.0001886465315692476, Final Batch Loss: 7.63186744734412e-06\n",
      "Epoch 4387, Loss: 0.0050258885021321476, Final Batch Loss: 2.541783032938838e-05\n",
      "Epoch 4388, Loss: 0.00012866058204963338, Final Batch Loss: 1.0085930625791661e-05\n",
      "Epoch 4389, Loss: 0.006405185031781002, Final Batch Loss: 0.006400184705853462\n",
      "Epoch 4390, Loss: 2.5132836526609026e-05, Final Batch Loss: 8.456549039692618e-06\n",
      "Epoch 4391, Loss: 7.942160300444812e-05, Final Batch Loss: 6.192623550305143e-05\n",
      "Epoch 4392, Loss: 2.043480253632879e-05, Final Batch Loss: 1.3007252164243255e-05\n",
      "Epoch 4393, Loss: 4.069528768013697e-05, Final Batch Loss: 2.1837931853951886e-05\n",
      "Epoch 4394, Loss: 0.0007616526527272072, Final Batch Loss: 5.2918618166586384e-05\n",
      "Epoch 4395, Loss: 0.00010039794415206416, Final Batch Loss: 9.164461516775191e-05\n",
      "Epoch 4396, Loss: 5.931522173341364e-05, Final Batch Loss: 2.3553820938104764e-05\n",
      "Epoch 4397, Loss: 0.00032957884468487464, Final Batch Loss: 0.00030476931715384126\n",
      "Epoch 4398, Loss: 0.001919226735481061, Final Batch Loss: 3.3518081181682646e-05\n",
      "Epoch 4399, Loss: 9.579858306096867e-05, Final Batch Loss: 4.262570655555464e-05\n",
      "Epoch 4400, Loss: 4.5523265725933015e-05, Final Batch Loss: 1.930721009557601e-05\n",
      "Epoch 4401, Loss: 0.0003686654927150812, Final Batch Loss: 0.00033425891888327897\n",
      "Epoch 4402, Loss: 0.00010224866855423898, Final Batch Loss: 2.692277485039085e-05\n",
      "Epoch 4403, Loss: 5.109778794576414e-05, Final Batch Loss: 1.377376975142397e-05\n",
      "Epoch 4404, Loss: 0.00012246806454641046, Final Batch Loss: 0.00010727007611421868\n",
      "Epoch 4405, Loss: 0.0003627768764999928, Final Batch Loss: 0.00034336920361965895\n",
      "Epoch 4406, Loss: 0.0005238304393060389, Final Batch Loss: 0.000518610468134284\n",
      "Epoch 4407, Loss: 0.0004475440364331007, Final Batch Loss: 3.590653068386018e-05\n",
      "Epoch 4408, Loss: 0.00022749709751224145, Final Batch Loss: 0.00013915471208747476\n",
      "Epoch 4409, Loss: 3.9744390051055234e-05, Final Batch Loss: 2.8021862817695364e-05\n",
      "Epoch 4410, Loss: 0.0015643370716134086, Final Batch Loss: 7.859909965191036e-05\n",
      "Epoch 4411, Loss: 4.389729474496562e-05, Final Batch Loss: 1.4908338926034048e-05\n",
      "Epoch 4412, Loss: 4.5067165956425015e-05, Final Batch Loss: 3.257359639974311e-05\n",
      "Epoch 4413, Loss: 9.777943705557846e-05, Final Batch Loss: 6.455374386860058e-05\n",
      "Epoch 4414, Loss: 1.4851359765089e-05, Final Batch Loss: 3.1584456792188575e-06\n",
      "Epoch 4415, Loss: 0.00022206125822776812, Final Batch Loss: 6.63370110487449e-06\n",
      "Epoch 4416, Loss: 4.283694397599902e-05, Final Batch Loss: 1.7443984688725322e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4417, Loss: 0.00010601296344248112, Final Batch Loss: 4.776627974933945e-06\n",
      "Epoch 4418, Loss: 0.0002726153252297081, Final Batch Loss: 0.00021675645257346332\n",
      "Epoch 4419, Loss: 0.00020983802096452564, Final Batch Loss: 0.00013885070802643895\n",
      "Epoch 4420, Loss: 0.0013826368412992451, Final Batch Loss: 0.001378135522827506\n",
      "Epoch 4421, Loss: 0.005445238045012957, Final Batch Loss: 0.005438241176307201\n",
      "Epoch 4422, Loss: 0.0006839540919827414, Final Batch Loss: 1.2231631444592495e-05\n",
      "Epoch 4423, Loss: 4.86653207190102e-05, Final Batch Loss: 2.732564644247759e-05\n",
      "Epoch 4424, Loss: 7.96502881712513e-05, Final Batch Loss: 5.4520696721738204e-05\n",
      "Epoch 4425, Loss: 8.861366859491682e-05, Final Batch Loss: 7.865545194363222e-05\n",
      "Epoch 4426, Loss: 1.9703143550486857e-05, Final Batch Loss: 1.8852964785764925e-05\n",
      "Epoch 4427, Loss: 2.093179818984936e-05, Final Batch Loss: 1.5045168765936978e-05\n",
      "Epoch 4428, Loss: 4.0480838833900634e-05, Final Batch Loss: 3.064696284127422e-05\n",
      "Epoch 4429, Loss: 0.0006744881761733268, Final Batch Loss: 5.711896392313065e-06\n",
      "Epoch 4430, Loss: 4.327709530116408e-05, Final Batch Loss: 4.7477492444159e-06\n",
      "Epoch 4431, Loss: 1.8184838296519956e-05, Final Batch Loss: 1.7771431885194033e-05\n",
      "Epoch 4432, Loss: 0.00028524839376586897, Final Batch Loss: 0.00028205622220411897\n",
      "Epoch 4433, Loss: 2.599298181849008e-05, Final Batch Loss: 2.3565593437524512e-05\n",
      "Epoch 4434, Loss: 5.0894021569547476e-05, Final Batch Loss: 4.443067518877797e-05\n",
      "Epoch 4435, Loss: 3.2499684152753616e-06, Final Batch Loss: 2.9071252356516197e-06\n",
      "Epoch 4436, Loss: 6.524887612613384e-05, Final Batch Loss: 4.7841109335422516e-05\n",
      "Epoch 4437, Loss: 4.999978045816533e-06, Final Batch Loss: 3.353653482918162e-06\n",
      "Epoch 4438, Loss: 0.0011870361422552378, Final Batch Loss: 0.0011775406310334802\n",
      "Epoch 4439, Loss: 1.3476149888447253e-05, Final Batch Loss: 1.1534115401445888e-05\n",
      "Epoch 4440, Loss: 3.583529633033322e-05, Final Batch Loss: 2.1551111785811372e-05\n",
      "Epoch 4441, Loss: 1.1833201938316051e-05, Final Batch Loss: 1.9044147165914183e-06\n",
      "Epoch 4442, Loss: 2.347029840166215e-05, Final Batch Loss: 2.085390042338986e-05\n",
      "Epoch 4443, Loss: 3.0510225769830868e-05, Final Batch Loss: 5.1975512178614736e-06\n",
      "Epoch 4444, Loss: 0.0010002986819017678, Final Batch Loss: 0.00018863045261241496\n",
      "Epoch 4445, Loss: 0.005537597819056828, Final Batch Loss: 3.47060922649689e-05\n",
      "Epoch 4446, Loss: 6.748744931428519e-05, Final Batch Loss: 6.433047383325174e-05\n",
      "Epoch 4447, Loss: 9.41666257858742e-05, Final Batch Loss: 4.4177682866575196e-05\n",
      "Epoch 4448, Loss: 1.1650635087789851e-05, Final Batch Loss: 1.0093933724419912e-06\n",
      "Epoch 4449, Loss: 2.1485717297764495e-05, Final Batch Loss: 3.273598849773407e-06\n",
      "Epoch 4450, Loss: 3.632068637671182e-05, Final Batch Loss: 9.105161552724894e-06\n",
      "Epoch 4451, Loss: 1.6376922530980664e-05, Final Batch Loss: 3.5626187582238344e-06\n",
      "Epoch 4452, Loss: 0.0003216310133211664, Final Batch Loss: 5.517139470612165e-06\n",
      "Epoch 4453, Loss: 4.600881402438972e-05, Final Batch Loss: 8.171855370164849e-06\n",
      "Epoch 4454, Loss: 0.0002700913046282949, Final Batch Loss: 2.3295478968066163e-05\n",
      "Epoch 4455, Loss: 6.464652142312843e-05, Final Batch Loss: 2.0997167666791938e-05\n",
      "Epoch 4456, Loss: 0.000499267394616254, Final Batch Loss: 2.3942864117998397e-06\n",
      "Epoch 4457, Loss: 6.087926749387407e-05, Final Batch Loss: 5.637898721033707e-05\n",
      "Epoch 4458, Loss: 0.00015316585086111445, Final Batch Loss: 0.00013333909737411886\n",
      "Epoch 4459, Loss: 0.00011326021194690838, Final Batch Loss: 8.143134618876502e-05\n",
      "Epoch 4460, Loss: 9.497665701019287e-06, Final Batch Loss: 1.0612683354338515e-06\n",
      "Epoch 4461, Loss: 1.570660833749571e-05, Final Batch Loss: 7.340022875723662e-06\n",
      "Epoch 4462, Loss: 1.3372820149015752e-05, Final Batch Loss: 3.299214995422517e-06\n",
      "Epoch 4463, Loss: 4.558930413622875e-05, Final Batch Loss: 8.126751708914526e-06\n",
      "Epoch 4464, Loss: 0.00037787825385748874, Final Batch Loss: 2.0498524463619106e-05\n",
      "Epoch 4465, Loss: 4.762281787407119e-05, Final Batch Loss: 5.471478289109655e-06\n",
      "Epoch 4466, Loss: 0.00041645193903150357, Final Batch Loss: 0.00041555886855348945\n",
      "Epoch 4467, Loss: 0.00019248689204687253, Final Batch Loss: 8.20669301901944e-05\n",
      "Epoch 4468, Loss: 1.906622674141545e-05, Final Batch Loss: 1.1113666005257983e-05\n",
      "Epoch 4469, Loss: 5.115771159580618e-06, Final Batch Loss: 4.570758846966783e-06\n",
      "Epoch 4470, Loss: 5.132088881509844e-05, Final Batch Loss: 2.4742332243476994e-05\n",
      "Epoch 4471, Loss: 0.00023649245616752523, Final Batch Loss: 0.000235580766457133\n",
      "Epoch 4472, Loss: 0.004459591247723438, Final Batch Loss: 0.004402207676321268\n",
      "Epoch 4473, Loss: 2.908460191974882e-05, Final Batch Loss: 1.3121503798174672e-05\n",
      "Epoch 4474, Loss: 3.95736237805977e-05, Final Batch Loss: 1.977361080207629e-06\n",
      "Epoch 4475, Loss: 0.0009063133620657027, Final Batch Loss: 0.0002663835184648633\n",
      "Epoch 4476, Loss: 2.9990394295964506e-05, Final Batch Loss: 2.87339626083849e-05\n",
      "Epoch 4477, Loss: 0.0012081006238986447, Final Batch Loss: 4.601820819516433e-06\n",
      "Epoch 4478, Loss: 0.0006488554463430773, Final Batch Loss: 0.0006218783091753721\n",
      "Epoch 4479, Loss: 7.135585974538117e-06, Final Batch Loss: 2.560040456955903e-06\n",
      "Epoch 4480, Loss: 1.6497939213877544e-05, Final Batch Loss: 1.1586211257963441e-05\n",
      "Epoch 4481, Loss: 0.00012202343532408122, Final Batch Loss: 0.00011543151777004823\n",
      "Epoch 4482, Loss: 1.877527540727897e-05, Final Batch Loss: 1.831611029956548e-06\n",
      "Epoch 4483, Loss: 1.4655258951279393e-05, Final Batch Loss: 1.1368416608092957e-06\n",
      "Epoch 4484, Loss: 1.2082424746040488e-05, Final Batch Loss: 5.1176411943743005e-06\n",
      "Epoch 4485, Loss: 8.535250708519015e-05, Final Batch Loss: 8.170618457370438e-06\n",
      "Epoch 4486, Loss: 5.070711040389142e-06, Final Batch Loss: 2.1174712401261786e-06\n",
      "Epoch 4487, Loss: 4.809698430108256e-05, Final Batch Loss: 6.33120134807541e-06\n",
      "Epoch 4488, Loss: 0.0009134829599588556, Final Batch Loss: 0.0009126799996010959\n",
      "Epoch 4489, Loss: 2.8391775231284555e-05, Final Batch Loss: 1.4454993106483016e-05\n",
      "Epoch 4490, Loss: 0.0024591899127699435, Final Batch Loss: 0.0008839701185934246\n",
      "Epoch 4491, Loss: 1.8567543293102062e-05, Final Batch Loss: 1.951946387634962e-06\n",
      "Epoch 4492, Loss: 2.2971850739850197e-05, Final Batch Loss: 9.765587492438499e-06\n",
      "Epoch 4493, Loss: 0.0031596088015248824, Final Batch Loss: 1.2571622391988058e-06\n",
      "Epoch 4494, Loss: 9.802882959775161e-05, Final Batch Loss: 6.53138522466179e-06\n",
      "Epoch 4495, Loss: 1.776856845481234e-05, Final Batch Loss: 1.600148061697837e-05\n",
      "Epoch 4496, Loss: 5.383873940445483e-05, Final Batch Loss: 2.534430313971825e-05\n",
      "Epoch 4497, Loss: 3.81833165192802e-05, Final Batch Loss: 7.071350864862325e-06\n",
      "Epoch 4498, Loss: 0.0004017969058622839, Final Batch Loss: 2.9435688702506013e-05\n",
      "Epoch 4499, Loss: 7.79255133238621e-05, Final Batch Loss: 2.363960084039718e-05\n",
      "Epoch 4500, Loss: 3.136584928142838e-05, Final Batch Loss: 1.4108205505181104e-05\n",
      "Epoch 4501, Loss: 0.0001655420774113736, Final Batch Loss: 0.00015695166075602174\n",
      "Epoch 4502, Loss: 6.154882794362493e-05, Final Batch Loss: 3.172671495121904e-05\n",
      "Epoch 4503, Loss: 0.00020729176185341203, Final Batch Loss: 0.00020135455997660756\n",
      "Epoch 4504, Loss: 4.879711923422292e-05, Final Batch Loss: 4.072481897310354e-05\n",
      "Epoch 4505, Loss: 2.4669071081007132e-05, Final Batch Loss: 1.8985476344823837e-05\n",
      "Epoch 4506, Loss: 7.562479549960699e-05, Final Batch Loss: 2.7818770831800066e-05\n",
      "Epoch 4507, Loss: 0.00033375276370861684, Final Batch Loss: 0.000331515067955479\n",
      "Epoch 4508, Loss: 1.9663310922624078e-05, Final Batch Loss: 1.0765705155790783e-05\n",
      "Epoch 4509, Loss: 3.612576529121725e-05, Final Batch Loss: 3.308282975922339e-05\n",
      "Epoch 4510, Loss: 0.00030109194267424755, Final Batch Loss: 0.00026972402702085674\n",
      "Epoch 4511, Loss: 3.8114514779863384e-05, Final Batch Loss: 4.7517477241854067e-07\n",
      "Epoch 4512, Loss: 0.0021919621794950217, Final Batch Loss: 0.0021576269064098597\n",
      "Epoch 4513, Loss: 0.004103097391634947, Final Batch Loss: 5.966637036181055e-05\n",
      "Epoch 4514, Loss: 4.915234967484139e-05, Final Batch Loss: 1.568076913827099e-05\n",
      "Epoch 4515, Loss: 1.2077753581252182e-05, Final Batch Loss: 1.0717903933255002e-05\n",
      "Epoch 4516, Loss: 0.0011431072925915942, Final Batch Loss: 5.5976081057451665e-05\n",
      "Epoch 4517, Loss: 5.81883678023587e-05, Final Batch Loss: 1.3264433619042393e-05\n",
      "Epoch 4518, Loss: 3.159732932545012e-05, Final Batch Loss: 2.39302207774017e-05\n",
      "Epoch 4519, Loss: 0.004801743631105637, Final Batch Loss: 5.188208524486981e-05\n",
      "Epoch 4520, Loss: 0.000463925880012539, Final Batch Loss: 5.313715064403368e-06\n",
      "Epoch 4521, Loss: 6.111252514529042e-05, Final Batch Loss: 4.4457086914917454e-05\n",
      "Epoch 4522, Loss: 2.232866063422989e-05, Final Batch Loss: 8.879198503564112e-06\n",
      "Epoch 4523, Loss: 0.0006913551967500098, Final Batch Loss: 3.6681792607851094e-06\n",
      "Epoch 4524, Loss: 0.002305256656200072, Final Batch Loss: 0.0023000389337539673\n",
      "Epoch 4525, Loss: 4.374681520857848e-05, Final Batch Loss: 2.7436642994871363e-05\n",
      "Epoch 4526, Loss: 0.03353498221440532, Final Batch Loss: 2.3861388399382122e-05\n",
      "Epoch 4527, Loss: 7.353278101618343e-05, Final Batch Loss: 7.091648149071261e-05\n",
      "Epoch 4528, Loss: 8.574694402341265e-05, Final Batch Loss: 7.761459710309282e-05\n",
      "Epoch 4529, Loss: 0.000356985003236332, Final Batch Loss: 1.9570734366425313e-05\n",
      "Epoch 4530, Loss: 0.00011251237083342858, Final Batch Loss: 5.445269198389724e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4531, Loss: 0.00015984774654498324, Final Batch Loss: 8.646796050015837e-05\n",
      "Epoch 4532, Loss: 0.00036607985384762287, Final Batch Loss: 0.0002611801610328257\n",
      "Epoch 4533, Loss: 0.001038956128013524, Final Batch Loss: 5.61845763513702e-06\n",
      "Epoch 4534, Loss: 0.0004417816071509151, Final Batch Loss: 2.394929288129788e-05\n",
      "Epoch 4535, Loss: 0.0013793113030260429, Final Batch Loss: 0.00011771904246415943\n",
      "Epoch 4536, Loss: 0.0006823789735790342, Final Batch Loss: 0.00017868538270704448\n",
      "Epoch 4537, Loss: 0.0018376631378487218, Final Batch Loss: 7.978425855981186e-06\n",
      "Epoch 4538, Loss: 0.00017788798140827566, Final Batch Loss: 3.2722411560826004e-05\n",
      "Epoch 4539, Loss: 0.00011996722400908766, Final Batch Loss: 3.2515215480088955e-06\n",
      "Epoch 4540, Loss: 8.168379645212553e-05, Final Batch Loss: 2.5576435291441157e-05\n",
      "Epoch 4541, Loss: 0.0001881250282167457, Final Batch Loss: 7.28766608517617e-05\n",
      "Epoch 4542, Loss: 4.1181863025485654e-05, Final Batch Loss: 3.4832166875276016e-06\n",
      "Epoch 4543, Loss: 0.0002895888246712275, Final Batch Loss: 4.385825741337612e-05\n",
      "Epoch 4544, Loss: 3.582158478820929e-05, Final Batch Loss: 1.3416653928288724e-05\n",
      "Epoch 4545, Loss: 4.781143343279837e-05, Final Batch Loss: 9.111269719142001e-06\n",
      "Epoch 4546, Loss: 8.672409785503987e-05, Final Batch Loss: 1.786633401934523e-05\n",
      "Epoch 4547, Loss: 9.75870602815121e-06, Final Batch Loss: 6.191978627612116e-06\n",
      "Epoch 4548, Loss: 3.7735484966106014e-05, Final Batch Loss: 4.382284259918379e-06\n",
      "Epoch 4549, Loss: 5.4553394875256345e-05, Final Batch Loss: 4.546719355857931e-05\n",
      "Epoch 4550, Loss: 1.3185052694097976e-05, Final Batch Loss: 2.258147787870257e-06\n",
      "Epoch 4551, Loss: 0.0015539502746833023, Final Batch Loss: 0.0015480761649087071\n",
      "Epoch 4552, Loss: 4.541853559203446e-05, Final Batch Loss: 1.6062296708696522e-05\n",
      "Epoch 4553, Loss: 5.648475962516386e-05, Final Batch Loss: 1.5803156202309765e-05\n",
      "Epoch 4554, Loss: 6.491883777925977e-05, Final Batch Loss: 5.2495113777695224e-05\n",
      "Epoch 4555, Loss: 0.001102539722523943, Final Batch Loss: 0.0010923327645286918\n",
      "Epoch 4556, Loss: 4.7303821247624e-05, Final Batch Loss: 4.2992582166334614e-05\n",
      "Epoch 4557, Loss: 0.0009231803232978564, Final Batch Loss: 4.20994583691936e-05\n",
      "Epoch 4558, Loss: 1.518716044301982e-05, Final Batch Loss: 9.617386240279302e-06\n",
      "Epoch 4559, Loss: 0.0005134852485753072, Final Batch Loss: 7.010379249550169e-06\n",
      "Epoch 4560, Loss: 0.0007640490043741011, Final Batch Loss: 7.263556199177401e-06\n",
      "Epoch 4561, Loss: 0.00037905931640125345, Final Batch Loss: 3.0053603040869348e-05\n",
      "Epoch 4562, Loss: 3.7807376429555006e-05, Final Batch Loss: 1.1678586815833114e-05\n",
      "Epoch 4563, Loss: 7.80291338742245e-06, Final Batch Loss: 2.9062821340630762e-06\n",
      "Epoch 4564, Loss: 5.2548177791322814e-06, Final Batch Loss: 4.502854153543012e-06\n",
      "Epoch 4565, Loss: 0.00023278443222807255, Final Batch Loss: 0.00021006789756938815\n",
      "Epoch 4566, Loss: 0.00023511375729867723, Final Batch Loss: 0.00022083919611759484\n",
      "Epoch 4567, Loss: 7.64306412293081e-06, Final Batch Loss: 1.8553668041931815e-06\n",
      "Epoch 4568, Loss: 0.0004595649288603454, Final Batch Loss: 4.32965225627413e-06\n",
      "Epoch 4569, Loss: 3.644698381322087e-05, Final Batch Loss: 4.332645858085016e-06\n",
      "Epoch 4570, Loss: 1.2634870927286102e-05, Final Batch Loss: 5.475249508890556e-06\n",
      "Epoch 4571, Loss: 5.2366707677720115e-05, Final Batch Loss: 2.911735646193847e-05\n",
      "Epoch 4572, Loss: 3.3103004170698114e-05, Final Batch Loss: 8.652539690956473e-06\n",
      "Epoch 4573, Loss: 3.214987737010233e-05, Final Batch Loss: 4.890538548352197e-06\n",
      "Epoch 4574, Loss: 0.0003455557016422972, Final Batch Loss: 0.0001077602501027286\n",
      "Epoch 4575, Loss: 5.109240589717956e-06, Final Batch Loss: 4.241434453433612e-06\n",
      "Epoch 4576, Loss: 7.030438428046182e-05, Final Batch Loss: 4.4256230466999114e-05\n",
      "Epoch 4577, Loss: 1.8186803686148778e-05, Final Batch Loss: 1.7935545884029125e-06\n",
      "Epoch 4578, Loss: 0.0005223444750299677, Final Batch Loss: 0.0001350823586108163\n",
      "Epoch 4579, Loss: 0.00043189105053897947, Final Batch Loss: 0.0003507318324409425\n",
      "Epoch 4580, Loss: 2.5436100258957595e-05, Final Batch Loss: 5.477091690408997e-06\n",
      "Epoch 4581, Loss: 1.3201155525166541e-05, Final Batch Loss: 9.359755495097488e-07\n",
      "Epoch 4582, Loss: 0.0001264430435412578, Final Batch Loss: 0.00012481471640057862\n",
      "Epoch 4583, Loss: 1.1258579661443946e-05, Final Batch Loss: 2.9888080916862236e-06\n",
      "Epoch 4584, Loss: 2.540042942200671e-05, Final Batch Loss: 2.0304576537455432e-05\n",
      "Epoch 4585, Loss: 2.072242568829097e-05, Final Batch Loss: 5.184072506381199e-06\n",
      "Epoch 4586, Loss: 0.0038187084483070066, Final Batch Loss: 9.10388735064771e-06\n",
      "Epoch 4587, Loss: 1.701208111626329e-05, Final Batch Loss: 1.4475597708951682e-05\n",
      "Epoch 4588, Loss: 0.00017902995205076877, Final Batch Loss: 0.00015757781511638314\n",
      "Epoch 4589, Loss: 0.0003716200162671157, Final Batch Loss: 0.00036222359631210566\n",
      "Epoch 4590, Loss: 9.84783546300605e-05, Final Batch Loss: 3.55750453309156e-05\n",
      "Epoch 4591, Loss: 0.00013743137242272496, Final Batch Loss: 0.00010507401748327538\n",
      "Epoch 4592, Loss: 6.300459426711313e-05, Final Batch Loss: 2.021536056417972e-05\n",
      "Epoch 4593, Loss: 5.9454487200127915e-05, Final Batch Loss: 1.8662536604097113e-05\n",
      "Epoch 4594, Loss: 0.0007648353202966973, Final Batch Loss: 0.0006121069309301674\n",
      "Epoch 4595, Loss: 0.0010508950545045082, Final Batch Loss: 1.7533868231112137e-05\n",
      "Epoch 4596, Loss: 0.00018613417250890052, Final Batch Loss: 0.00017165245662909\n",
      "Epoch 4597, Loss: 2.451808722980786e-05, Final Batch Loss: 1.2739955309370998e-05\n",
      "Epoch 4598, Loss: 0.00018353393534198403, Final Batch Loss: 0.00011417752830311656\n",
      "Epoch 4599, Loss: 8.979913582152221e-05, Final Batch Loss: 1.8163076674682088e-05\n",
      "Epoch 4600, Loss: 0.00012302977575018303, Final Batch Loss: 1.2622546819329727e-05\n",
      "Epoch 4601, Loss: 0.0017506062431493774, Final Batch Loss: 9.759901149664074e-05\n",
      "Epoch 4602, Loss: 2.7300689907860942e-05, Final Batch Loss: 1.334067292191321e-05\n",
      "Epoch 4603, Loss: 0.00010295041647623293, Final Batch Loss: 4.80905182485003e-05\n",
      "Epoch 4604, Loss: 0.0003790255796047859, Final Batch Loss: 0.0003296098147984594\n",
      "Epoch 4605, Loss: 0.00035474964170134626, Final Batch Loss: 0.00030933666857890785\n",
      "Epoch 4606, Loss: 5.499549297383055e-05, Final Batch Loss: 2.2792108211433515e-05\n",
      "Epoch 4607, Loss: 0.00018221181653643725, Final Batch Loss: 8.2201540863025e-06\n",
      "Epoch 4608, Loss: 0.00038298775143630337, Final Batch Loss: 2.9386077585513704e-05\n",
      "Epoch 4609, Loss: 0.00024387262601521797, Final Batch Loss: 2.868747469619848e-05\n",
      "Epoch 4610, Loss: 6.466980630648322e-05, Final Batch Loss: 2.3795881133992225e-05\n",
      "Epoch 4611, Loss: 0.00012236599286552519, Final Batch Loss: 5.684776260750368e-05\n",
      "Epoch 4612, Loss: 0.00021376141376094893, Final Batch Loss: 0.00015485900803469121\n",
      "Epoch 4613, Loss: 3.7057650843053125e-05, Final Batch Loss: 6.170756023493595e-06\n",
      "Epoch 4614, Loss: 0.00033316792632831493, Final Batch Loss: 1.3163947187422309e-05\n",
      "Epoch 4615, Loss: 0.00011679315866786055, Final Batch Loss: 0.00011042020923923701\n",
      "Epoch 4616, Loss: 0.00015430852363351732, Final Batch Loss: 0.0001338467700406909\n",
      "Epoch 4617, Loss: 9.74959830273292e-05, Final Batch Loss: 1.046706074703252e-05\n",
      "Epoch 4618, Loss: 0.00018383058977633482, Final Batch Loss: 5.650129423884209e-06\n",
      "Epoch 4619, Loss: 3.740806550922571e-05, Final Batch Loss: 1.285331654798938e-05\n",
      "Epoch 4620, Loss: 2.3510561732109636e-05, Final Batch Loss: 8.428803994320333e-06\n",
      "Epoch 4621, Loss: 3.679548353829887e-05, Final Batch Loss: 2.1672496586688794e-05\n",
      "Epoch 4622, Loss: 2.9759750304947374e-05, Final Batch Loss: 2.5360453946632333e-05\n",
      "Epoch 4623, Loss: 7.212443233584054e-05, Final Batch Loss: 5.611690357909538e-05\n",
      "Epoch 4624, Loss: 3.41366212524008e-05, Final Batch Loss: 8.934193829190917e-06\n",
      "Epoch 4625, Loss: 0.00013495566236088052, Final Batch Loss: 9.43835184443742e-05\n",
      "Epoch 4626, Loss: 0.00022467274357040878, Final Batch Loss: 0.00019650344620458782\n",
      "Epoch 4627, Loss: 5.4166318477655295e-05, Final Batch Loss: 4.147614527028054e-05\n",
      "Epoch 4628, Loss: 0.0013487315427482827, Final Batch Loss: 0.0013216458028182387\n",
      "Epoch 4629, Loss: 0.00010904671580647118, Final Batch Loss: 0.00010077392653329298\n",
      "Epoch 4630, Loss: 6.42595014141989e-05, Final Batch Loss: 5.994344610371627e-05\n",
      "Epoch 4631, Loss: 0.00012136032455600798, Final Batch Loss: 7.606888539157808e-05\n",
      "Epoch 4632, Loss: 4.8793823225423694e-05, Final Batch Loss: 3.41462146025151e-05\n",
      "Epoch 4633, Loss: 6.682106823063805e-05, Final Batch Loss: 5.446997874969384e-06\n",
      "Epoch 4634, Loss: 0.0010093538621731568, Final Batch Loss: 0.0009739601518958807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4635, Loss: 1.2991514267923776e-05, Final Batch Loss: 8.420264748565387e-06\n",
      "Epoch 4636, Loss: 4.1968182358687045e-05, Final Batch Loss: 3.684317198349163e-05\n",
      "Epoch 4637, Loss: 4.295621965866303e-05, Final Batch Loss: 1.2156545381003525e-05\n",
      "Epoch 4638, Loss: 3.5052591101703e-05, Final Batch Loss: 2.8356269467622042e-05\n",
      "Epoch 4639, Loss: 4.687809996539727e-05, Final Batch Loss: 1.0190648026764393e-05\n",
      "Epoch 4640, Loss: 6.41520828139619e-05, Final Batch Loss: 5.402422902989201e-05\n",
      "Epoch 4641, Loss: 9.559380305290688e-05, Final Batch Loss: 4.619354513124563e-06\n",
      "Epoch 4642, Loss: 4.6661205487907864e-05, Final Batch Loss: 4.3108266254421324e-05\n",
      "Epoch 4643, Loss: 0.00020234322846590658, Final Batch Loss: 4.630518105841475e-06\n",
      "Epoch 4644, Loss: 9.243577096640365e-06, Final Batch Loss: 5.74324258195702e-06\n",
      "Epoch 4645, Loss: 0.00015288597865037445, Final Batch Loss: 0.00014978433318901807\n",
      "Epoch 4646, Loss: 1.3007775578444125e-05, Final Batch Loss: 1.1480537978059147e-05\n",
      "Epoch 4647, Loss: 9.120730737777194e-06, Final Batch Loss: 5.942647931078682e-06\n",
      "Epoch 4648, Loss: 0.000923127886835573, Final Batch Loss: 6.662410214630654e-06\n",
      "Epoch 4649, Loss: 2.060553060800885e-05, Final Batch Loss: 4.038377028336981e-06\n",
      "Epoch 4650, Loss: 3.9431764889741316e-05, Final Batch Loss: 3.4500815672799945e-05\n",
      "Epoch 4651, Loss: 4.93421862302057e-05, Final Batch Loss: 7.017169536993606e-06\n",
      "Epoch 4652, Loss: 0.0002806278364460013, Final Batch Loss: 0.00027964464970864356\n",
      "Epoch 4653, Loss: 2.633485746628139e-05, Final Batch Loss: 1.9795998014160432e-05\n",
      "Epoch 4654, Loss: 1.1012182767444756e-05, Final Batch Loss: 2.2748135961592197e-06\n",
      "Epoch 4655, Loss: 5.434260356196319e-05, Final Batch Loss: 5.892387434869306e-06\n",
      "Epoch 4656, Loss: 3.7765890283480985e-05, Final Batch Loss: 3.130581899313256e-05\n",
      "Epoch 4657, Loss: 1.729737005007337e-05, Final Batch Loss: 1.2912770216644276e-05\n",
      "Epoch 4658, Loss: 6.159516715342761e-06, Final Batch Loss: 2.4838784611347364e-06\n",
      "Epoch 4659, Loss: 1.9187262523701065e-05, Final Batch Loss: 1.799854544515256e-05\n",
      "Epoch 4660, Loss: 7.894332611613208e-06, Final Batch Loss: 3.893997472914634e-06\n",
      "Epoch 4661, Loss: 0.00021594369900412858, Final Batch Loss: 5.2297982620075345e-05\n",
      "Epoch 4662, Loss: 0.00682694825809449, Final Batch Loss: 0.005788502749055624\n",
      "Epoch 4663, Loss: 9.956404710464994e-06, Final Batch Loss: 1.2339748991507804e-06\n",
      "Epoch 4664, Loss: 2.357263110752683e-05, Final Batch Loss: 6.010921424604021e-06\n",
      "Epoch 4665, Loss: 3.0300200251076603e-06, Final Batch Loss: 1.0055223356175702e-06\n",
      "Epoch 4666, Loss: 0.0007778897740990942, Final Batch Loss: 3.6909802929585567e-06\n",
      "Epoch 4667, Loss: 7.172597861426766e-06, Final Batch Loss: 1.9144461020914605e-06\n",
      "Epoch 4668, Loss: 4.080286998942029e-05, Final Batch Loss: 2.334422606509179e-05\n",
      "Epoch 4669, Loss: 2.3311920358537463e-05, Final Batch Loss: 4.376608103484614e-06\n",
      "Epoch 4670, Loss: 5.670668997481698e-05, Final Batch Loss: 1.1155761058034841e-05\n",
      "Epoch 4671, Loss: 0.0010019331020885147, Final Batch Loss: 0.0009277867502532899\n",
      "Epoch 4672, Loss: 3.373738491063705e-05, Final Batch Loss: 3.076175562455319e-05\n",
      "Epoch 4673, Loss: 9.250553716810828e-06, Final Batch Loss: 7.77629975345917e-06\n",
      "Epoch 4674, Loss: 0.0002283425237692427, Final Batch Loss: 0.0001963100366992876\n",
      "Epoch 4675, Loss: 4.284971146262251e-05, Final Batch Loss: 2.3758018869557418e-05\n",
      "Epoch 4676, Loss: 0.00013778600077785086, Final Batch Loss: 1.2043177775922231e-05\n",
      "Epoch 4677, Loss: 0.0002346472829231061, Final Batch Loss: 0.00020938033412676305\n",
      "Epoch 4678, Loss: 5.6328017763007665e-05, Final Batch Loss: 5.270407200441696e-05\n",
      "Epoch 4679, Loss: 1.61044276865141e-05, Final Batch Loss: 1.3774925719189923e-05\n",
      "Epoch 4680, Loss: 6.206409489095677e-05, Final Batch Loss: 3.6335750337457284e-05\n",
      "Epoch 4681, Loss: 8.049157543155161e-06, Final Batch Loss: 7.305773578991648e-06\n",
      "Epoch 4682, Loss: 1.6364372186217224e-05, Final Batch Loss: 1.2448638699424919e-05\n",
      "Epoch 4683, Loss: 2.333944030397106e-05, Final Batch Loss: 1.4399770407180768e-05\n",
      "Epoch 4684, Loss: 2.831307697093166e-05, Final Batch Loss: 5.518936418980047e-08\n",
      "Epoch 4685, Loss: 0.0001414854486938566, Final Batch Loss: 7.576132338726893e-05\n",
      "Epoch 4686, Loss: 4.323067560108029e-05, Final Batch Loss: 4.216500019538216e-05\n",
      "Epoch 4687, Loss: 0.00019404807289902237, Final Batch Loss: 5.948081252427073e-06\n",
      "Epoch 4688, Loss: 6.223933269211557e-06, Final Batch Loss: 4.540794179774821e-06\n",
      "Epoch 4689, Loss: 3.2214933298746473e-06, Final Batch Loss: 1.4597045492337202e-06\n",
      "Epoch 4690, Loss: 2.9669938612642e-06, Final Batch Loss: 1.8951009224110749e-06\n",
      "Epoch 4691, Loss: 1.789422208275937e-05, Final Batch Loss: 2.812284265019116e-06\n",
      "Epoch 4692, Loss: 6.955818753340282e-05, Final Batch Loss: 2.295277954544872e-05\n",
      "Epoch 4693, Loss: 4.9927434702112805e-05, Final Batch Loss: 2.863626832549926e-06\n",
      "Epoch 4694, Loss: 0.0004193822705929051, Final Batch Loss: 0.0004136583593208343\n",
      "Epoch 4695, Loss: 7.920461439425708e-05, Final Batch Loss: 7.824478234397247e-05\n",
      "Epoch 4696, Loss: 0.002638763424329227, Final Batch Loss: 2.5428042135899886e-05\n",
      "Epoch 4697, Loss: 4.863999629378668e-05, Final Batch Loss: 5.8832060858549085e-06\n",
      "Epoch 4698, Loss: 6.490835801287176e-05, Final Batch Loss: 1.7570695263202651e-06\n",
      "Epoch 4699, Loss: 1.2483292266551871e-05, Final Batch Loss: 7.733216989436187e-06\n",
      "Epoch 4700, Loss: 0.00015019530525250957, Final Batch Loss: 0.00014940474648028612\n",
      "Epoch 4701, Loss: 3.3702956898196135e-05, Final Batch Loss: 1.8894941604230553e-05\n",
      "Epoch 4702, Loss: 6.010774654896522e-06, Final Batch Loss: 5.652673735312419e-06\n",
      "Epoch 4703, Loss: 2.421250883344328e-05, Final Batch Loss: 1.1061870281992014e-05\n",
      "Epoch 4704, Loss: 3.739738531294279e-05, Final Batch Loss: 2.92403346975334e-05\n",
      "Epoch 4705, Loss: 1.0252960464640637e-05, Final Batch Loss: 9.216822945745662e-06\n",
      "Epoch 4706, Loss: 1.7079794815799687e-05, Final Batch Loss: 7.70323913457105e-06\n",
      "Epoch 4707, Loss: 8.288966228064965e-06, Final Batch Loss: 5.080060873297043e-06\n",
      "Epoch 4708, Loss: 1.2934193364344537e-05, Final Batch Loss: 7.360698418779066e-06\n",
      "Epoch 4709, Loss: 0.0001521224057796644, Final Batch Loss: 9.79040123638697e-07\n",
      "Epoch 4710, Loss: 3.0892076892996556e-05, Final Batch Loss: 1.2069338026776677e-06\n",
      "Epoch 4711, Loss: 6.537046260746138e-06, Final Batch Loss: 1.7802511820264044e-06\n",
      "Epoch 4712, Loss: 3.408071597732487e-05, Final Batch Loss: 7.180387456173776e-06\n",
      "Epoch 4713, Loss: 8.734847256164358e-06, Final Batch Loss: 7.734010978310835e-06\n",
      "Epoch 4714, Loss: 1.406138790116529e-05, Final Batch Loss: 4.682233793573687e-06\n",
      "Epoch 4715, Loss: 1.3236194718047045e-05, Final Batch Loss: 9.4007491497905e-06\n",
      "Epoch 4716, Loss: 1.2979025825643475e-05, Final Batch Loss: 1.2188447726657614e-05\n",
      "Epoch 4717, Loss: 3.1756502721691504e-05, Final Batch Loss: 2.8764739909092896e-05\n",
      "Epoch 4718, Loss: 8.302100013679592e-06, Final Batch Loss: 4.34063031207188e-06\n",
      "Epoch 4719, Loss: 1.0911785466305446e-05, Final Batch Loss: 5.0189100875286385e-06\n",
      "Epoch 4720, Loss: 1.306429385294905e-05, Final Batch Loss: 7.131718120945152e-06\n",
      "Epoch 4721, Loss: 0.00015261463522620033, Final Batch Loss: 7.992302926140837e-06\n",
      "Epoch 4722, Loss: 2.375342864979757e-05, Final Batch Loss: 1.1553592230484355e-05\n",
      "Epoch 4723, Loss: 2.233899249404203e-05, Final Batch Loss: 1.2510384294728283e-05\n",
      "Epoch 4724, Loss: 1.7405157905159285e-05, Final Batch Loss: 6.993483566475334e-06\n",
      "Epoch 4725, Loss: 1.832795510381402e-05, Final Batch Loss: 1.5461022485396825e-05\n",
      "Epoch 4726, Loss: 8.626609542261576e-06, Final Batch Loss: 4.88176283397479e-06\n",
      "Epoch 4727, Loss: 3.2623122933728155e-05, Final Batch Loss: 3.073496918659657e-05\n",
      "Epoch 4728, Loss: 4.164410341900293e-06, Final Batch Loss: 3.5927527619605826e-07\n",
      "Epoch 4729, Loss: 0.0004357993730081944, Final Batch Loss: 0.0004345739434938878\n",
      "Epoch 4730, Loss: 2.4630426423755125e-05, Final Batch Loss: 2.0573590973071987e-06\n",
      "Epoch 4731, Loss: 4.646498132387933e-05, Final Batch Loss: 9.16675389817101e-07\n",
      "Epoch 4732, Loss: 7.906665871360019e-05, Final Batch Loss: 5.39190864401462e-07\n",
      "Epoch 4733, Loss: 0.0011927089071832597, Final Batch Loss: 0.001037215581163764\n",
      "Epoch 4734, Loss: 0.000954631935769612, Final Batch Loss: 5.800262670163647e-07\n",
      "Epoch 4735, Loss: 8.018246717256261e-06, Final Batch Loss: 5.836947821080685e-06\n",
      "Epoch 4736, Loss: 7.185434560597059e-05, Final Batch Loss: 6.740498065482825e-05\n",
      "Epoch 4737, Loss: 0.0005634461194858886, Final Batch Loss: 0.0005304143414832652\n",
      "Epoch 4738, Loss: 6.897238989722609e-06, Final Batch Loss: 4.100515695881768e-07\n",
      "Epoch 4739, Loss: 1.9797774257312994e-05, Final Batch Loss: 9.651587788539473e-06\n",
      "Epoch 4740, Loss: 2.8322420348558808e-05, Final Batch Loss: 2.3352205971605144e-05\n",
      "Epoch 4741, Loss: 5.411645361164119e-06, Final Batch Loss: 2.913252501457464e-06\n",
      "Epoch 4742, Loss: 9.484152997174533e-06, Final Batch Loss: 4.948955393047072e-06\n",
      "Epoch 4743, Loss: 8.367659580699183e-05, Final Batch Loss: 8.28226184239611e-05\n",
      "Epoch 4744, Loss: 3.5543866943044122e-06, Final Batch Loss: 1.170526502392022e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4745, Loss: 9.233317172174793e-06, Final Batch Loss: 3.4216972721878847e-07\n",
      "Epoch 4746, Loss: 5.788171802123543e-05, Final Batch Loss: 3.8763297197874635e-05\n",
      "Epoch 4747, Loss: 3.8254092942224815e-05, Final Batch Loss: 1.6328447600244544e-05\n",
      "Epoch 4748, Loss: 2.3620921751899004e-06, Final Batch Loss: 1.4651831179435248e-06\n",
      "Epoch 4749, Loss: 7.59142312745098e-06, Final Batch Loss: 1.7581951397005469e-06\n",
      "Epoch 4750, Loss: 2.5847397665756944e-05, Final Batch Loss: 1.986811923870846e-07\n",
      "Epoch 4751, Loss: 8.806037897102215e-06, Final Batch Loss: 8.317286301462445e-06\n",
      "Epoch 4752, Loss: 3.471078173333808e-06, Final Batch Loss: 2.2296404722510488e-07\n",
      "Epoch 4753, Loss: 8.202845037885709e-06, Final Batch Loss: 4.783861186297145e-06\n",
      "Epoch 4754, Loss: 0.00408963220870362, Final Batch Loss: 1.826763735834902e-07\n",
      "Epoch 4755, Loss: 0.004046048489499299, Final Batch Loss: 6.705383839289425e-07\n",
      "Epoch 4756, Loss: 0.008606344490772244, Final Batch Loss: 0.00860584620386362\n",
      "Epoch 4757, Loss: 0.00016270782725769095, Final Batch Loss: 4.161916876910254e-06\n",
      "Epoch 4758, Loss: 0.0003863637502945494, Final Batch Loss: 4.369821908767335e-05\n",
      "Epoch 4759, Loss: 1.5436699527526798e-05, Final Batch Loss: 9.757337693372392e-07\n",
      "Epoch 4760, Loss: 0.0005533170915441588, Final Batch Loss: 1.9247367163188756e-05\n",
      "Epoch 4761, Loss: 0.0022329037310555577, Final Batch Loss: 0.0008510297629982233\n",
      "Epoch 4762, Loss: 0.0009130134394581546, Final Batch Loss: 0.0009018672280944884\n",
      "Epoch 4763, Loss: 5.060290436631476e-05, Final Batch Loss: 4.759765215567313e-05\n",
      "Epoch 4764, Loss: 0.0004586567883961834, Final Batch Loss: 2.728342224145308e-05\n",
      "Epoch 4765, Loss: 2.3399546080327127e-05, Final Batch Loss: 1.0888952601817437e-05\n",
      "Epoch 4766, Loss: 2.0658853372879094e-05, Final Batch Loss: 2.6167194846493658e-06\n",
      "Epoch 4767, Loss: 6.071189000067534e-05, Final Batch Loss: 4.6748173190280795e-05\n",
      "Epoch 4768, Loss: 0.00031171950558928074, Final Batch Loss: 1.2811932720069308e-05\n",
      "Epoch 4769, Loss: 6.580071203643456e-05, Final Batch Loss: 2.622157262521796e-05\n",
      "Epoch 4770, Loss: 2.1159207790333312e-05, Final Batch Loss: 1.519688157713972e-05\n",
      "Epoch 4771, Loss: 0.0004990732113583363, Final Batch Loss: 0.0004906249232590199\n",
      "Epoch 4772, Loss: 0.0005298684955050703, Final Batch Loss: 1.7523965652799234e-05\n",
      "Epoch 4773, Loss: 2.0732238681375748e-05, Final Batch Loss: 4.35694846601109e-06\n",
      "Epoch 4774, Loss: 8.067970384217915e-05, Final Batch Loss: 1.45359854286653e-06\n",
      "Epoch 4775, Loss: 4.102367211089586e-05, Final Batch Loss: 3.646956247393973e-05\n",
      "Epoch 4776, Loss: 0.0003206200422027905, Final Batch Loss: 1.1280285434622783e-06\n",
      "Epoch 4777, Loss: 1.7155034129245905e-05, Final Batch Loss: 4.157779130764538e-06\n",
      "Epoch 4778, Loss: 4.057668866153108e-05, Final Batch Loss: 8.098494618025143e-06\n",
      "Epoch 4779, Loss: 0.0003375951200723648, Final Batch Loss: 0.0003064000920858234\n",
      "Epoch 4780, Loss: 3.586064303817693e-05, Final Batch Loss: 3.03381348203402e-05\n",
      "Epoch 4781, Loss: 1.775336750142742e-05, Final Batch Loss: 1.2704412256425712e-05\n",
      "Epoch 4782, Loss: 3.711572026077192e-05, Final Batch Loss: 1.916656401590444e-06\n",
      "Epoch 4783, Loss: 0.00021627776141031063, Final Batch Loss: 0.00021113033290021122\n",
      "Epoch 4784, Loss: 2.5947229005396366e-05, Final Batch Loss: 7.871696652728133e-06\n",
      "Epoch 4785, Loss: 2.0634309066736023e-05, Final Batch Loss: 2.0886607217107667e-06\n",
      "Epoch 4786, Loss: 0.00011466648493296816, Final Batch Loss: 0.00011058947711717337\n",
      "Epoch 4787, Loss: 1.7586411104275612e-05, Final Batch Loss: 6.630304142163368e-06\n",
      "Epoch 4788, Loss: 3.2343309243287877e-05, Final Batch Loss: 3.190033385180868e-05\n",
      "Epoch 4789, Loss: 1.5355382856796496e-05, Final Batch Loss: 1.2306246389925946e-05\n",
      "Epoch 4790, Loss: 5.9736175899161026e-05, Final Batch Loss: 1.7905422282638028e-05\n",
      "Epoch 4791, Loss: 2.0537584532576147e-05, Final Batch Loss: 1.2028367564198561e-05\n",
      "Epoch 4792, Loss: 0.0001640323332594562, Final Batch Loss: 0.0001619763352209702\n",
      "Epoch 4793, Loss: 1.709545119865652e-05, Final Batch Loss: 1.0088273256769753e-06\n",
      "Epoch 4794, Loss: 0.00066414746052601, Final Batch Loss: 0.0006637164042331278\n",
      "Epoch 4795, Loss: 0.00027812964435725007, Final Batch Loss: 4.196912414045073e-06\n",
      "Epoch 4796, Loss: 7.709407896072662e-06, Final Batch Loss: 5.953345862508286e-06\n",
      "Epoch 4797, Loss: 0.00017290607047470985, Final Batch Loss: 0.0001681100548012182\n",
      "Epoch 4798, Loss: 2.1745617232227232e-05, Final Batch Loss: 5.714288818126079e-06\n",
      "Epoch 4799, Loss: 0.005908972641918808, Final Batch Loss: 0.00587649829685688\n",
      "Epoch 4800, Loss: 1.9808743218163727e-05, Final Batch Loss: 1.7092264897655696e-05\n",
      "Epoch 4801, Loss: 2.433344809560367e-05, Final Batch Loss: 2.3627277187188156e-05\n",
      "Epoch 4802, Loss: 7.259210178744979e-06, Final Batch Loss: 2.9605162126244977e-06\n",
      "Epoch 4803, Loss: 0.0009347771847387776, Final Batch Loss: 5.070566840004176e-05\n",
      "Epoch 4804, Loss: 2.808309545798693e-05, Final Batch Loss: 1.2628561307792552e-05\n",
      "Epoch 4805, Loss: 7.132493777817217e-06, Final Batch Loss: 6.665674391115317e-06\n",
      "Epoch 4806, Loss: 0.0008242866024374962, Final Batch Loss: 0.0002996966359205544\n",
      "Epoch 4807, Loss: 8.692101800988894e-06, Final Batch Loss: 5.919168415857712e-06\n",
      "Epoch 4808, Loss: 2.8225474011378537e-05, Final Batch Loss: 2.6846530090551823e-05\n",
      "Epoch 4809, Loss: 0.00045216440958029125, Final Batch Loss: 0.00045103917364031076\n",
      "Epoch 4810, Loss: 4.3728286414079776e-06, Final Batch Loss: 8.35541811738949e-07\n",
      "Epoch 4811, Loss: 3.36969878844684e-05, Final Batch Loss: 1.5117633665795438e-05\n",
      "Epoch 4812, Loss: 2.262030108113322e-06, Final Batch Loss: 1.4128423231341003e-07\n",
      "Epoch 4813, Loss: 9.509858995215836e-05, Final Batch Loss: 2.792561986098008e-07\n",
      "Epoch 4814, Loss: 1.178439174509549e-05, Final Batch Loss: 1.4779222965444205e-06\n",
      "Epoch 4815, Loss: 0.00020679537919932045, Final Batch Loss: 0.00017818268679548055\n",
      "Epoch 4816, Loss: 0.000327345428559056, Final Batch Loss: 9.08433230506489e-06\n",
      "Epoch 4817, Loss: 0.033631880350185384, Final Batch Loss: 0.03361683711409569\n",
      "Epoch 4818, Loss: 6.2070537296676775e-06, Final Batch Loss: 4.998818440071773e-06\n",
      "Epoch 4819, Loss: 0.0004631154565686302, Final Batch Loss: 0.00046101887710392475\n",
      "Epoch 4820, Loss: 0.000707507373590488, Final Batch Loss: 2.8281363483984023e-05\n",
      "Epoch 4821, Loss: 0.008100005856249481, Final Batch Loss: 0.00018164707580581307\n",
      "Epoch 4822, Loss: 0.00011755095692933537, Final Batch Loss: 5.8768706367118284e-05\n",
      "Epoch 4823, Loss: 6.307673265837366e-05, Final Batch Loss: 4.973983595846221e-05\n",
      "Epoch 4824, Loss: 0.0025971310315071605, Final Batch Loss: 2.2974061721470207e-05\n",
      "Epoch 4825, Loss: 0.0001306261110585183, Final Batch Loss: 3.829727211268619e-05\n",
      "Epoch 4826, Loss: 0.008071300107985735, Final Batch Loss: 0.0011366447433829308\n",
      "Epoch 4827, Loss: 0.0017215639672940597, Final Batch Loss: 0.0015919329598546028\n",
      "Epoch 4828, Loss: 0.0002940470130852191, Final Batch Loss: 2.165559089917224e-05\n",
      "Epoch 4829, Loss: 0.00034434911503922194, Final Batch Loss: 0.00012463325401768088\n",
      "Epoch 4830, Loss: 6.821854003646877e-05, Final Batch Loss: 4.7725225158501416e-05\n",
      "Epoch 4831, Loss: 9.100252827920485e-05, Final Batch Loss: 1.914650965773035e-05\n",
      "Epoch 4832, Loss: 9.74597132881172e-05, Final Batch Loss: 2.278892497997731e-05\n",
      "Epoch 4833, Loss: 5.1683856327144895e-05, Final Batch Loss: 4.252481085131876e-05\n",
      "Epoch 4834, Loss: 0.0002572157245595008, Final Batch Loss: 0.00014542938151862472\n",
      "Epoch 4835, Loss: 0.00014648849901277572, Final Batch Loss: 9.904130274662748e-05\n",
      "Epoch 4836, Loss: 0.00014501920668408275, Final Batch Loss: 9.890847286442295e-05\n",
      "Epoch 4837, Loss: 0.00018387401360087097, Final Batch Loss: 3.7387682823464274e-05\n",
      "Epoch 4838, Loss: 0.0001689396613073768, Final Batch Loss: 2.0973953724023886e-05\n",
      "Epoch 4839, Loss: 0.00013799488806398585, Final Batch Loss: 0.00012043697643093765\n",
      "Epoch 4840, Loss: 0.0011712673094734782, Final Batch Loss: 2.380246041866485e-05\n",
      "Epoch 4841, Loss: 0.00016311007584590698, Final Batch Loss: 0.00015011995856184512\n",
      "Epoch 4842, Loss: 0.0011829542418126948, Final Batch Loss: 6.683037645416334e-05\n",
      "Epoch 4843, Loss: 9.090203457162715e-05, Final Batch Loss: 3.215818287571892e-05\n",
      "Epoch 4844, Loss: 0.00011927155537705403, Final Batch Loss: 1.8793600247590803e-05\n",
      "Epoch 4845, Loss: 5.923983280808898e-05, Final Batch Loss: 1.1460034329502378e-05\n",
      "Epoch 4846, Loss: 0.0008688912785146385, Final Batch Loss: 0.0007444902439601719\n",
      "Epoch 4847, Loss: 0.002462510601617396, Final Batch Loss: 0.0011433070758357644\n",
      "Epoch 4848, Loss: 0.0002560483990237117, Final Batch Loss: 6.447351188398898e-05\n",
      "Epoch 4849, Loss: 2.8038301024935208e-05, Final Batch Loss: 2.207387296948582e-05\n",
      "Epoch 4850, Loss: 0.00022556967451237142, Final Batch Loss: 4.217479727230966e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4851, Loss: 9.358231727674138e-05, Final Batch Loss: 2.9505912607419305e-05\n",
      "Epoch 4852, Loss: 0.00045845397107768804, Final Batch Loss: 0.0002609361836221069\n",
      "Epoch 4853, Loss: 0.00013464794938045088, Final Batch Loss: 0.0001092003658413887\n",
      "Epoch 4854, Loss: 0.0003357750829309225, Final Batch Loss: 0.00014714154531247914\n",
      "Epoch 4855, Loss: 4.198529768473236e-05, Final Batch Loss: 2.8115564418840222e-05\n",
      "Epoch 4856, Loss: 0.00017922899496625178, Final Batch Loss: 0.00016248214524239302\n",
      "Epoch 4857, Loss: 0.000514879078764352, Final Batch Loss: 1.6704680092516355e-05\n",
      "Epoch 4858, Loss: 0.0008843875984894112, Final Batch Loss: 0.0008576619438827038\n",
      "Epoch 4859, Loss: 0.00013317703633219935, Final Batch Loss: 8.222415635827929e-05\n",
      "Epoch 4860, Loss: 0.0006347568851197138, Final Batch Loss: 0.00019782652088906616\n",
      "Epoch 4861, Loss: 3.360456139489543e-05, Final Batch Loss: 1.0548656064202078e-05\n",
      "Epoch 4862, Loss: 6.731533176207449e-05, Final Batch Loss: 4.905321839032695e-05\n",
      "Epoch 4863, Loss: 0.0006027748895576224, Final Batch Loss: 0.0003996213781647384\n",
      "Epoch 4864, Loss: 2.955086438305443e-05, Final Batch Loss: 8.485531907354016e-06\n",
      "Epoch 4865, Loss: 0.0004367486217233818, Final Batch Loss: 0.00041529739974066615\n",
      "Epoch 4866, Loss: 0.0036569751164279296, Final Batch Loss: 0.0036423851270228624\n",
      "Epoch 4867, Loss: 2.065296166620101e-05, Final Batch Loss: 4.118953711440554e-06\n",
      "Epoch 4868, Loss: 9.07259964151308e-05, Final Batch Loss: 6.372496136464179e-05\n",
      "Epoch 4869, Loss: 6.838934859842993e-05, Final Batch Loss: 5.0314029067521915e-05\n",
      "Epoch 4870, Loss: 6.352274431264959e-05, Final Batch Loss: 1.7477446817792952e-05\n",
      "Epoch 4871, Loss: 6.556948846991872e-05, Final Batch Loss: 1.1465853276604321e-05\n",
      "Epoch 4872, Loss: 0.00040342761803913163, Final Batch Loss: 0.00038982482510618865\n",
      "Epoch 4873, Loss: 2.773199798866699e-05, Final Batch Loss: 2.9706009172514314e-06\n",
      "Epoch 4874, Loss: 5.707466334570199e-05, Final Batch Loss: 2.796408807625994e-05\n",
      "Epoch 4875, Loss: 1.329394945059903e-05, Final Batch Loss: 7.486375125154154e-06\n",
      "Epoch 4876, Loss: 9.22756880754605e-05, Final Batch Loss: 4.9285827117273584e-05\n",
      "Epoch 4877, Loss: 4.838302993448451e-05, Final Batch Loss: 2.427106664981693e-06\n",
      "Epoch 4878, Loss: 4.008714768133359e-05, Final Batch Loss: 1.1518929568410385e-05\n",
      "Epoch 4879, Loss: 6.499311894003768e-05, Final Batch Loss: 5.735459126299247e-05\n",
      "Epoch 4880, Loss: 7.871365517075901e-05, Final Batch Loss: 7.699857087573037e-05\n",
      "Epoch 4881, Loss: 1.54160975398554e-05, Final Batch Loss: 9.356712325825356e-06\n",
      "Epoch 4882, Loss: 7.806878420524299e-05, Final Batch Loss: 6.74452749080956e-05\n",
      "Epoch 4883, Loss: 3.837232543446589e-05, Final Batch Loss: 9.524217603029683e-06\n",
      "Epoch 4884, Loss: 4.613143937604036e-05, Final Batch Loss: 1.5984262063284405e-05\n",
      "Epoch 4885, Loss: 2.351443708903389e-05, Final Batch Loss: 5.746348506363574e-06\n",
      "Epoch 4886, Loss: 4.0193474660554784e-05, Final Batch Loss: 3.777761548917624e-06\n",
      "Epoch 4887, Loss: 1.7393191001247033e-05, Final Batch Loss: 1.4004982404003385e-05\n",
      "Epoch 4888, Loss: 9.287269790547725e-06, Final Batch Loss: 1.509939579591446e-06\n",
      "Epoch 4889, Loss: 7.548143912572414e-05, Final Batch Loss: 2.8652368200710043e-05\n",
      "Epoch 4890, Loss: 1.9129937754769344e-05, Final Batch Loss: 1.0076123544422444e-05\n",
      "Epoch 4891, Loss: 0.0001310095285589341, Final Batch Loss: 5.642246833303943e-06\n",
      "Epoch 4892, Loss: 4.952915514877532e-05, Final Batch Loss: 1.6524163584108464e-05\n",
      "Epoch 4893, Loss: 0.007099841957597164, Final Batch Loss: 0.007098299916833639\n",
      "Epoch 4894, Loss: 3.7973229609633563e-06, Final Batch Loss: 1.161674390459666e-06\n",
      "Epoch 4895, Loss: 3.730907974386355e-05, Final Batch Loss: 3.339135946589522e-05\n",
      "Epoch 4896, Loss: 0.001040171301610826, Final Batch Loss: 0.0010316336993128061\n",
      "Epoch 4897, Loss: 0.001183909182145726, Final Batch Loss: 8.944636647356674e-05\n",
      "Epoch 4898, Loss: 8.446462913980213e-05, Final Batch Loss: 1.9072484747084673e-06\n",
      "Epoch 4899, Loss: 0.00016787422418929054, Final Batch Loss: 0.00016164465341717005\n",
      "Epoch 4900, Loss: 0.00011954673846048536, Final Batch Loss: 1.1099805306002963e-05\n",
      "Epoch 4901, Loss: 1.748026215864229e-05, Final Batch Loss: 1.2286817764106672e-05\n",
      "Epoch 4902, Loss: 0.0003462160157141625, Final Batch Loss: 0.00033596475259400904\n",
      "Epoch 4903, Loss: 4.058876191948002e-05, Final Batch Loss: 7.969244393279951e-07\n",
      "Epoch 4904, Loss: 0.00048735543896327727, Final Batch Loss: 9.504739864496514e-06\n",
      "Epoch 4905, Loss: 7.024060460025794e-05, Final Batch Loss: 5.902934844925767e-06\n",
      "Epoch 4906, Loss: 8.447832078672945e-05, Final Batch Loss: 2.6083966076839715e-05\n",
      "Epoch 4907, Loss: 2.301366907886404e-05, Final Batch Loss: 1.9904737200704403e-05\n",
      "Epoch 4908, Loss: 6.007908382343885e-06, Final Batch Loss: 1.341075972050021e-06\n",
      "Epoch 4909, Loss: 6.113785502748215e-06, Final Batch Loss: 2.7267717541690217e-06\n",
      "Epoch 4910, Loss: 3.207369104529789e-06, Final Batch Loss: 6.401875225492404e-07\n",
      "Epoch 4911, Loss: 0.0007315029361052439, Final Batch Loss: 0.0006687261047773063\n",
      "Epoch 4912, Loss: 4.2629083054634975e-06, Final Batch Loss: 2.066231445496669e-06\n",
      "Epoch 4913, Loss: 5.7127513173327316e-06, Final Batch Loss: 1.5606742636009585e-06\n",
      "Epoch 4914, Loss: 7.60235961934086e-05, Final Batch Loss: 5.578796844929457e-05\n",
      "Epoch 4915, Loss: 3.6817048567172606e-05, Final Batch Loss: 3.381531496415846e-05\n",
      "Epoch 4916, Loss: 0.0036050928283657413, Final Batch Loss: 2.827700154739432e-05\n",
      "Epoch 4917, Loss: 2.3645965939067537e-05, Final Batch Loss: 2.0643110474338755e-05\n",
      "Epoch 4918, Loss: 6.456464143411722e-05, Final Batch Loss: 1.7513839338789694e-05\n",
      "Epoch 4919, Loss: 8.045311471960304e-05, Final Batch Loss: 1.7091580275518936e-06\n",
      "Epoch 4920, Loss: 1.531232817342243e-05, Final Batch Loss: 1.5110325648493017e-06\n",
      "Epoch 4921, Loss: 8.626524959254311e-06, Final Batch Loss: 4.7160242502286565e-06\n",
      "Epoch 4922, Loss: 6.570418167939351e-05, Final Batch Loss: 6.269932055147365e-05\n",
      "Epoch 4923, Loss: 8.091500944829022e-06, Final Batch Loss: 1.8073454839395708e-06\n",
      "Epoch 4924, Loss: 6.239660979190376e-05, Final Batch Loss: 4.901674037682824e-05\n",
      "Epoch 4925, Loss: 0.0009247663474525325, Final Batch Loss: 0.0009039984433911741\n",
      "Epoch 4926, Loss: 0.005331162014044821, Final Batch Loss: 0.0005310518899932504\n",
      "Epoch 4927, Loss: 4.0249491576105356e-05, Final Batch Loss: 2.9689326765947044e-06\n",
      "Epoch 4928, Loss: 0.00013972894885228015, Final Batch Loss: 0.00011661108874250203\n",
      "Epoch 4929, Loss: 2.9243791686894838e-05, Final Batch Loss: 1.639800757402554e-05\n",
      "Epoch 4930, Loss: 2.793632643260935e-05, Final Batch Loss: 3.172459173583775e-06\n",
      "Epoch 4931, Loss: 0.0007086401974447654, Final Batch Loss: 0.0006965112988837063\n",
      "Epoch 4932, Loss: 2.1042912180746498e-05, Final Batch Loss: 2.038965430983808e-05\n",
      "Epoch 4933, Loss: 0.0009161055058939382, Final Batch Loss: 0.0008752621943131089\n",
      "Epoch 4934, Loss: 2.444545316393487e-05, Final Batch Loss: 1.4805767023062799e-05\n",
      "Epoch 4935, Loss: 9.002909337141318e-06, Final Batch Loss: 6.795299668738153e-06\n",
      "Epoch 4936, Loss: 0.0001314146375079872, Final Batch Loss: 1.9047483874601312e-05\n",
      "Epoch 4937, Loss: 0.0002576868890287187, Final Batch Loss: 0.00025686531444080174\n",
      "Epoch 4938, Loss: 0.0006442707490350585, Final Batch Loss: 1.2194923328934237e-05\n",
      "Epoch 4939, Loss: 1.3518198016981842e-05, Final Batch Loss: 1.3102399861963931e-05\n",
      "Epoch 4940, Loss: 6.2260153299575904e-06, Final Batch Loss: 2.2902083856024547e-06\n",
      "Epoch 4941, Loss: 5.6676537496969104e-05, Final Batch Loss: 3.465919871814549e-05\n",
      "Epoch 4942, Loss: 3.190620282111922e-05, Final Batch Loss: 1.9214872736483812e-05\n",
      "Epoch 4943, Loss: 1.871163794930908e-05, Final Batch Loss: 5.130816589371534e-06\n",
      "Epoch 4944, Loss: 6.623360786761623e-05, Final Batch Loss: 5.352057996788062e-05\n",
      "Epoch 4945, Loss: 0.005003191588912159, Final Batch Loss: 0.00013127882266417146\n",
      "Epoch 4946, Loss: 9.615925137040904e-06, Final Batch Loss: 1.5860919120314065e-06\n",
      "Epoch 4947, Loss: 7.271945491993392e-06, Final Batch Loss: 5.678007710230304e-06\n",
      "Epoch 4948, Loss: 1.1358260280758259e-05, Final Batch Loss: 2.5253004878322827e-06\n",
      "Epoch 4949, Loss: 4.65121502202237e-05, Final Batch Loss: 1.8106589777744375e-05\n",
      "Epoch 4950, Loss: 0.00011663460099953227, Final Batch Loss: 6.477528222603723e-05\n",
      "Epoch 4951, Loss: 0.00030047064115024114, Final Batch Loss: 4.343344244261971e-07\n",
      "Epoch 4952, Loss: 3.854544866044307e-05, Final Batch Loss: 9.033353308041114e-06\n",
      "Epoch 4953, Loss: 3.170483250869438e-05, Final Batch Loss: 1.6226382285822183e-05\n",
      "Epoch 4954, Loss: 2.7650488902963843e-06, Final Batch Loss: 2.457968093949603e-06\n",
      "Epoch 4955, Loss: 1.0433809620735701e-05, Final Batch Loss: 5.7600905165600125e-06\n",
      "Epoch 4956, Loss: 0.0047124802904363605, Final Batch Loss: 1.1429028745624237e-06\n",
      "Epoch 4957, Loss: 8.666621397424024e-06, Final Batch Loss: 2.66761026068707e-06\n",
      "Epoch 4958, Loss: 1.4772749182156986e-05, Final Batch Loss: 8.588303899159655e-06\n",
      "Epoch 4959, Loss: 1.7725150186720384e-05, Final Batch Loss: 1.3355814587612258e-07\n",
      "Epoch 4960, Loss: 1.7456268892601656e-05, Final Batch Loss: 1.649116529733874e-05\n",
      "Epoch 4961, Loss: 7.589911422201112e-05, Final Batch Loss: 7.458980689989403e-05\n",
      "Epoch 4962, Loss: 1.870768301159842e-05, Final Batch Loss: 8.52524954098044e-06\n",
      "Epoch 4963, Loss: 7.298701689251175e-06, Final Batch Loss: 1.3966827054900932e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4964, Loss: 4.956071256856376e-05, Final Batch Loss: 9.420471087651094e-07\n",
      "Epoch 4965, Loss: 3.037952728845994e-05, Final Batch Loss: 5.900630185351474e-06\n",
      "Epoch 4966, Loss: 5.443618306344433e-06, Final Batch Loss: 1.5474266774617718e-06\n",
      "Epoch 4967, Loss: 1.3746197424779893e-06, Final Batch Loss: 1.2583167574575782e-07\n",
      "Epoch 4968, Loss: 3.1675071113568265e-05, Final Batch Loss: 9.172073077934328e-06\n",
      "Epoch 4969, Loss: 0.0004213147858536104, Final Batch Loss: 0.000399205629946664\n",
      "Epoch 4970, Loss: 7.009469527474721e-06, Final Batch Loss: 2.019251724050264e-06\n",
      "Epoch 4971, Loss: 0.00015131039481275366, Final Batch Loss: 5.786673227703432e-06\n",
      "Epoch 4972, Loss: 0.003389029743402716, Final Batch Loss: 2.0661188955273246e-06\n",
      "Epoch 4973, Loss: 0.0003927755700487978, Final Batch Loss: 0.0003915448905900121\n",
      "Epoch 4974, Loss: 3.2076633942779154e-05, Final Batch Loss: 5.652183972415514e-06\n",
      "Epoch 4975, Loss: 3.179031227773521e-05, Final Batch Loss: 8.473019988741726e-06\n",
      "Epoch 4976, Loss: 1.6282804836009745e-05, Final Batch Loss: 1.3036909876973368e-05\n",
      "Epoch 4977, Loss: 2.5606304916436784e-05, Final Batch Loss: 2.094098636007402e-05\n",
      "Epoch 4978, Loss: 9.519162858850905e-06, Final Batch Loss: 3.1836273137741955e-06\n",
      "Epoch 4979, Loss: 0.0003560025264732758, Final Batch Loss: 0.0003551022964529693\n",
      "Epoch 4980, Loss: 8.739893496567674e-05, Final Batch Loss: 3.616755975599517e-06\n",
      "Epoch 4981, Loss: 3.8779343412898015e-05, Final Batch Loss: 3.139830369036645e-05\n",
      "Epoch 4982, Loss: 1.0160887768506655e-05, Final Batch Loss: 8.379517566936556e-06\n",
      "Epoch 4983, Loss: 1.4352727475852589e-05, Final Batch Loss: 5.276012871036073e-07\n",
      "Epoch 4984, Loss: 2.2119492086858372e-06, Final Batch Loss: 6.799239145038882e-07\n",
      "Epoch 4985, Loss: 1.6518443317181664e-05, Final Batch Loss: 9.319016498920973e-06\n",
      "Epoch 4986, Loss: 1.7966068355690368e-05, Final Batch Loss: 5.066204380455019e-07\n",
      "Epoch 4987, Loss: 1.8739490769803524e-05, Final Batch Loss: 6.173200745251961e-06\n",
      "Epoch 4988, Loss: 8.772532328293892e-05, Final Batch Loss: 9.125110409513582e-06\n",
      "Epoch 4989, Loss: 2.7117945364807383e-06, Final Batch Loss: 1.6070206356744166e-06\n",
      "Epoch 4990, Loss: 7.455423610736034e-05, Final Batch Loss: 7.005500083323568e-05\n",
      "Epoch 4991, Loss: 2.505916836526012e-05, Final Batch Loss: 1.5945166524033993e-05\n",
      "Epoch 4992, Loss: 1.2538715736809536e-06, Final Batch Loss: 7.665624366381962e-07\n",
      "Epoch 4993, Loss: 7.506342171836877e-06, Final Batch Loss: 3.2028624445956666e-06\n",
      "Epoch 4994, Loss: 0.00016865280122146942, Final Batch Loss: 0.00016692487406544387\n",
      "Epoch 4995, Loss: 1.1151579201396089e-05, Final Batch Loss: 4.864702077611582e-06\n",
      "Epoch 4996, Loss: 4.915757244816632e-06, Final Batch Loss: 1.43375359584752e-06\n",
      "Epoch 4997, Loss: 3.66921710792667e-06, Final Batch Loss: 2.007585408136947e-06\n",
      "Epoch 4998, Loss: 6.616316477447981e-05, Final Batch Loss: 5.781048093922436e-05\n",
      "Epoch 4999, Loss: 0.0002709341442823643, Final Batch Loss: 2.256374318676535e-05\n",
      "Epoch 5000, Loss: 1.6221375062741572e-05, Final Batch Loss: 1.231983242178103e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  0  0]\n",
      " [ 0 25  0]\n",
      " [ 0  0 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000        29\n",
      "           1      1.000     1.000     1.000        25\n",
      "           2      1.000     1.000     1.000        29\n",
      "\n",
      "    accuracy                          1.000        83\n",
      "   macro avg      1.000     1.000     1.000        83\n",
      "weighted avg      1.000     1.000     1.000        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../../saved_models/UCI 3 Label Classifier Group 5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
