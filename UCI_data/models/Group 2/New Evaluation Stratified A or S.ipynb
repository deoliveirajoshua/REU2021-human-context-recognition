{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '125 tBodyGyro-std()-Y',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '138 tBodyGyro-energy()-Y',\n",
    " '165 tBodyGyroJerk-std()-Y',\n",
    " '168 tBodyGyroJerk-mad()-Y',\n",
    " '178 tBodyGyroJerk-energy()-Y',\n",
    " '181 tBodyGyroJerk-iqr()-Y',\n",
    " '425 fBodyGyro-mean()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '431 fBodyGyro-mad()-Y',\n",
    " '441 fBodyGyro-energy()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '478 fBodyGyro-bandsEnergy()-25,32',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '204 tBodyAccMag-max()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '217 tGravityAccMag-max()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '275 fBodyAcc-max()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '506 fBodyAccMag-max()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 9)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.648474931716919, Final Batch Loss: 2.3196909427642822\n",
      "Epoch 2, Loss: 4.623358488082886, Final Batch Loss: 2.307652473449707\n",
      "Epoch 3, Loss: 4.5970988273620605, Final Batch Loss: 2.2963767051696777\n",
      "Epoch 4, Loss: 4.576807498931885, Final Batch Loss: 2.282341480255127\n",
      "Epoch 5, Loss: 4.567737102508545, Final Batch Loss: 2.2840986251831055\n",
      "Epoch 6, Loss: 4.5502753257751465, Final Batch Loss: 2.271935224533081\n",
      "Epoch 7, Loss: 4.533130884170532, Final Batch Loss: 2.2686078548431396\n",
      "Epoch 8, Loss: 4.5102198123931885, Final Batch Loss: 2.2504889965057373\n",
      "Epoch 9, Loss: 4.499437570571899, Final Batch Loss: 2.251394271850586\n",
      "Epoch 10, Loss: 4.465226888656616, Final Batch Loss: 2.22273325920105\n",
      "Epoch 11, Loss: 4.462246656417847, Final Batch Loss: 2.2244443893432617\n",
      "Epoch 12, Loss: 4.436897039413452, Final Batch Loss: 2.210871696472168\n",
      "Epoch 13, Loss: 4.4104626178741455, Final Batch Loss: 2.192931652069092\n",
      "Epoch 14, Loss: 4.388186693191528, Final Batch Loss: 2.1845695972442627\n",
      "Epoch 15, Loss: 4.344754695892334, Final Batch Loss: 2.1548638343811035\n",
      "Epoch 16, Loss: 4.325878620147705, Final Batch Loss: 2.150491714477539\n",
      "Epoch 17, Loss: 4.303721904754639, Final Batch Loss: 2.1487605571746826\n",
      "Epoch 18, Loss: 4.264769792556763, Final Batch Loss: 2.124993085861206\n",
      "Epoch 19, Loss: 4.211842775344849, Final Batch Loss: 2.113600015640259\n",
      "Epoch 20, Loss: 4.149286985397339, Final Batch Loss: 2.0728800296783447\n",
      "Epoch 21, Loss: 4.123898267745972, Final Batch Loss: 2.084365129470825\n",
      "Epoch 22, Loss: 4.064322233200073, Final Batch Loss: 2.026430130004883\n",
      "Epoch 23, Loss: 4.00471305847168, Final Batch Loss: 1.9758591651916504\n",
      "Epoch 24, Loss: 3.9439224004745483, Final Batch Loss: 1.958945393562317\n",
      "Epoch 25, Loss: 3.882066488265991, Final Batch Loss: 1.9730477333068848\n",
      "Epoch 26, Loss: 3.7754513025283813, Final Batch Loss: 1.8768973350524902\n",
      "Epoch 27, Loss: 3.7177823781967163, Final Batch Loss: 1.8368600606918335\n",
      "Epoch 28, Loss: 3.64375376701355, Final Batch Loss: 1.7815266847610474\n",
      "Epoch 29, Loss: 3.583388090133667, Final Batch Loss: 1.7793747186660767\n",
      "Epoch 30, Loss: 3.4398531913757324, Final Batch Loss: 1.72959303855896\n",
      "Epoch 31, Loss: 3.337446689605713, Final Batch Loss: 1.6119072437286377\n",
      "Epoch 32, Loss: 3.3406656980514526, Final Batch Loss: 1.7325998544692993\n",
      "Epoch 33, Loss: 3.2312787771224976, Final Batch Loss: 1.6535354852676392\n",
      "Epoch 34, Loss: 3.185747981071472, Final Batch Loss: 1.601214051246643\n",
      "Epoch 35, Loss: 3.084968328475952, Final Batch Loss: 1.5580408573150635\n",
      "Epoch 36, Loss: 2.974614977836609, Final Batch Loss: 1.4687139987945557\n",
      "Epoch 37, Loss: 2.961316466331482, Final Batch Loss: 1.3867846727371216\n",
      "Epoch 38, Loss: 2.876671552658081, Final Batch Loss: 1.3757045269012451\n",
      "Epoch 39, Loss: 2.8025577068328857, Final Batch Loss: 1.3557637929916382\n",
      "Epoch 40, Loss: 2.7767807245254517, Final Batch Loss: 1.3776865005493164\n",
      "Epoch 41, Loss: 2.7727129459381104, Final Batch Loss: 1.3894882202148438\n",
      "Epoch 42, Loss: 2.6760921478271484, Final Batch Loss: 1.280561923980713\n",
      "Epoch 43, Loss: 2.692322850227356, Final Batch Loss: 1.3390750885009766\n",
      "Epoch 44, Loss: 2.4991815090179443, Final Batch Loss: 1.2386462688446045\n",
      "Epoch 45, Loss: 2.637367606163025, Final Batch Loss: 1.3725662231445312\n",
      "Epoch 46, Loss: 2.5277146100997925, Final Batch Loss: 1.283053994178772\n",
      "Epoch 47, Loss: 2.5120444297790527, Final Batch Loss: 1.251417636871338\n",
      "Epoch 48, Loss: 2.4649661779403687, Final Batch Loss: 1.2528536319732666\n",
      "Epoch 49, Loss: 2.415031909942627, Final Batch Loss: 1.1802690029144287\n",
      "Epoch 50, Loss: 2.4402624368667603, Final Batch Loss: 1.2783817052841187\n",
      "Epoch 51, Loss: 2.4061022996902466, Final Batch Loss: 1.2234903573989868\n",
      "Epoch 52, Loss: 2.4163589477539062, Final Batch Loss: 1.1850862503051758\n",
      "Epoch 53, Loss: 2.3508665561676025, Final Batch Loss: 1.1564037799835205\n",
      "Epoch 54, Loss: 2.263725519180298, Final Batch Loss: 1.1620664596557617\n",
      "Epoch 55, Loss: 2.3023775815963745, Final Batch Loss: 1.1198339462280273\n",
      "Epoch 56, Loss: 2.1769092082977295, Final Batch Loss: 1.0066511631011963\n",
      "Epoch 57, Loss: 2.408380150794983, Final Batch Loss: 1.2500454187393188\n",
      "Epoch 58, Loss: 2.19537353515625, Final Batch Loss: 1.0814182758331299\n",
      "Epoch 59, Loss: 2.086790680885315, Final Batch Loss: 1.050104022026062\n",
      "Epoch 60, Loss: 2.0891870260238647, Final Batch Loss: 1.0798825025558472\n",
      "Epoch 61, Loss: 2.017358124256134, Final Batch Loss: 0.9740988612174988\n",
      "Epoch 62, Loss: 2.031140923500061, Final Batch Loss: 0.9945292472839355\n",
      "Epoch 63, Loss: 1.994710385799408, Final Batch Loss: 0.9745329022407532\n",
      "Epoch 64, Loss: 1.9707064628601074, Final Batch Loss: 1.0435370206832886\n",
      "Epoch 65, Loss: 1.9250320792198181, Final Batch Loss: 0.9549950957298279\n",
      "Epoch 66, Loss: 1.8263148069381714, Final Batch Loss: 0.8808435201644897\n",
      "Epoch 67, Loss: 1.8584770560264587, Final Batch Loss: 0.9035417437553406\n",
      "Epoch 68, Loss: 1.777993083000183, Final Batch Loss: 0.868833601474762\n",
      "Epoch 69, Loss: 1.7846034169197083, Final Batch Loss: 0.8524918556213379\n",
      "Epoch 70, Loss: 1.730367362499237, Final Batch Loss: 0.8739917874336243\n",
      "Epoch 71, Loss: 1.6787842512130737, Final Batch Loss: 0.8264936804771423\n",
      "Epoch 72, Loss: 1.558323860168457, Final Batch Loss: 0.7322741746902466\n",
      "Epoch 73, Loss: 1.604327142238617, Final Batch Loss: 0.7461406588554382\n",
      "Epoch 74, Loss: 1.5461536049842834, Final Batch Loss: 0.7785044312477112\n",
      "Epoch 75, Loss: 1.5302804112434387, Final Batch Loss: 0.7612762451171875\n",
      "Epoch 76, Loss: 1.4490718245506287, Final Batch Loss: 0.6540141701698303\n",
      "Epoch 77, Loss: 1.3996326923370361, Final Batch Loss: 0.6581881642341614\n",
      "Epoch 78, Loss: 1.4637752175331116, Final Batch Loss: 0.7327500581741333\n",
      "Epoch 79, Loss: 1.4579888582229614, Final Batch Loss: 0.7415890693664551\n",
      "Epoch 80, Loss: 1.3671075701713562, Final Batch Loss: 0.6446680426597595\n",
      "Epoch 81, Loss: 1.3278521299362183, Final Batch Loss: 0.6638827919960022\n",
      "Epoch 82, Loss: 1.2561204433441162, Final Batch Loss: 0.6541141271591187\n",
      "Epoch 83, Loss: 1.3283287286758423, Final Batch Loss: 0.6931784749031067\n",
      "Epoch 84, Loss: 1.130441129207611, Final Batch Loss: 0.5392141342163086\n",
      "Epoch 85, Loss: 1.1889536380767822, Final Batch Loss: 0.5961297750473022\n",
      "Epoch 86, Loss: 1.1337857246398926, Final Batch Loss: 0.5415814518928528\n",
      "Epoch 87, Loss: 1.1386979222297668, Final Batch Loss: 0.5191323161125183\n",
      "Epoch 88, Loss: 1.2019060850143433, Final Batch Loss: 0.5752529501914978\n",
      "Epoch 89, Loss: 1.0760858952999115, Final Batch Loss: 0.4916580021381378\n",
      "Epoch 90, Loss: 1.067552387714386, Final Batch Loss: 0.5295858979225159\n",
      "Epoch 91, Loss: 1.1191625595092773, Final Batch Loss: 0.5269326567649841\n",
      "Epoch 92, Loss: 1.0841453969478607, Final Batch Loss: 0.5890921354293823\n",
      "Epoch 93, Loss: 1.0304095447063446, Final Batch Loss: 0.4998081624507904\n",
      "Epoch 94, Loss: 1.0314797163009644, Final Batch Loss: 0.513267457485199\n",
      "Epoch 95, Loss: 1.0085342824459076, Final Batch Loss: 0.4983575642108917\n",
      "Epoch 96, Loss: 0.9548467397689819, Final Batch Loss: 0.4709371030330658\n",
      "Epoch 97, Loss: 0.8998992443084717, Final Batch Loss: 0.446794718503952\n",
      "Epoch 98, Loss: 0.901897519826889, Final Batch Loss: 0.438040554523468\n",
      "Epoch 99, Loss: 0.9015515446662903, Final Batch Loss: 0.43873435258865356\n",
      "Epoch 100, Loss: 0.8565609753131866, Final Batch Loss: 0.46902403235435486\n",
      "Epoch 101, Loss: 0.8798046410083771, Final Batch Loss: 0.4593846797943115\n",
      "Epoch 102, Loss: 0.8483292460441589, Final Batch Loss: 0.45152807235717773\n",
      "Epoch 103, Loss: 0.8583351075649261, Final Batch Loss: 0.40212124586105347\n",
      "Epoch 104, Loss: 0.7323148846626282, Final Batch Loss: 0.3589376211166382\n",
      "Epoch 105, Loss: 0.7826217710971832, Final Batch Loss: 0.41033560037612915\n",
      "Epoch 106, Loss: 0.616195559501648, Final Batch Loss: 0.2977921664714813\n",
      "Epoch 107, Loss: 0.7649224698543549, Final Batch Loss: 0.3719041645526886\n",
      "Epoch 108, Loss: 0.6823159158229828, Final Batch Loss: 0.3739413321018219\n",
      "Epoch 109, Loss: 0.689490020275116, Final Batch Loss: 0.3278147280216217\n",
      "Epoch 110, Loss: 0.647130012512207, Final Batch Loss: 0.3248702585697174\n",
      "Epoch 111, Loss: 0.6351985335350037, Final Batch Loss: 0.32596421241760254\n",
      "Epoch 112, Loss: 0.6554851233959198, Final Batch Loss: 0.3404977023601532\n",
      "Epoch 113, Loss: 0.6542139649391174, Final Batch Loss: 0.3354455530643463\n",
      "Epoch 114, Loss: 0.5651749670505524, Final Batch Loss: 0.27936306595802307\n",
      "Epoch 115, Loss: 0.5285801589488983, Final Batch Loss: 0.2704528570175171\n",
      "Epoch 116, Loss: 0.5977321565151215, Final Batch Loss: 0.29327723383903503\n",
      "Epoch 117, Loss: 0.565136194229126, Final Batch Loss: 0.3014548718929291\n",
      "Epoch 118, Loss: 0.5661527216434479, Final Batch Loss: 0.2866293787956238\n",
      "Epoch 119, Loss: 0.6257487237453461, Final Batch Loss: 0.2934878468513489\n",
      "Epoch 120, Loss: 0.5860337615013123, Final Batch Loss: 0.3198331296443939\n",
      "Epoch 121, Loss: 0.46066345274448395, Final Batch Loss: 0.2119182050228119\n",
      "Epoch 122, Loss: 0.5254559814929962, Final Batch Loss: 0.2532157003879547\n",
      "Epoch 123, Loss: 0.5188309997320175, Final Batch Loss: 0.2712574005126953\n",
      "Epoch 124, Loss: 0.4520804136991501, Final Batch Loss: 0.21468690037727356\n",
      "Epoch 125, Loss: 0.489304319024086, Final Batch Loss: 0.2644001841545105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126, Loss: 0.4864729344844818, Final Batch Loss: 0.24793638288974762\n",
      "Epoch 127, Loss: 0.4893082231283188, Final Batch Loss: 0.2616182565689087\n",
      "Epoch 128, Loss: 0.4288881868124008, Final Batch Loss: 0.2158467173576355\n",
      "Epoch 129, Loss: 0.46614232659339905, Final Batch Loss: 0.23878240585327148\n",
      "Epoch 130, Loss: 0.5134861171245575, Final Batch Loss: 0.2819426357746124\n",
      "Epoch 131, Loss: 0.4315120428800583, Final Batch Loss: 0.22077064216136932\n",
      "Epoch 132, Loss: 0.33971795439720154, Final Batch Loss: 0.17709988355636597\n",
      "Epoch 133, Loss: 0.41290001571178436, Final Batch Loss: 0.20059797167778015\n",
      "Epoch 134, Loss: 0.36272308230400085, Final Batch Loss: 0.1631377786397934\n",
      "Epoch 135, Loss: 0.33174146711826324, Final Batch Loss: 0.1414182335138321\n",
      "Epoch 136, Loss: 0.35808880627155304, Final Batch Loss: 0.1647946983575821\n",
      "Epoch 137, Loss: 0.44676582515239716, Final Batch Loss: 0.23249658942222595\n",
      "Epoch 138, Loss: 0.38004089891910553, Final Batch Loss: 0.22184085845947266\n",
      "Epoch 139, Loss: 0.37021709978580475, Final Batch Loss: 0.18439973890781403\n",
      "Epoch 140, Loss: 0.3634125590324402, Final Batch Loss: 0.20033712685108185\n",
      "Epoch 141, Loss: 0.3415788263082504, Final Batch Loss: 0.18027441203594208\n",
      "Epoch 142, Loss: 0.32379962503910065, Final Batch Loss: 0.14310701191425323\n",
      "Epoch 143, Loss: 0.33440497517585754, Final Batch Loss: 0.1738521307706833\n",
      "Epoch 144, Loss: 0.33012109249830246, Final Batch Loss: 0.12410261482000351\n",
      "Epoch 145, Loss: 0.4044761061668396, Final Batch Loss: 0.22803686559200287\n",
      "Epoch 146, Loss: 0.31664472073316574, Final Batch Loss: 0.1955656260251999\n",
      "Epoch 147, Loss: 0.371000275015831, Final Batch Loss: 0.14334392547607422\n",
      "Epoch 148, Loss: 0.3293525278568268, Final Batch Loss: 0.15139827132225037\n",
      "Epoch 149, Loss: 0.32014550268650055, Final Batch Loss: 0.1621229499578476\n",
      "Epoch 150, Loss: 0.28224630653858185, Final Batch Loss: 0.1504766047000885\n",
      "Epoch 151, Loss: 0.27720747888088226, Final Batch Loss: 0.1390327364206314\n",
      "Epoch 152, Loss: 0.3570250868797302, Final Batch Loss: 0.1833367943763733\n",
      "Epoch 153, Loss: 0.39693254232406616, Final Batch Loss: 0.21725155413150787\n",
      "Epoch 154, Loss: 0.25203125178813934, Final Batch Loss: 0.13296791911125183\n",
      "Epoch 155, Loss: 0.3383273780345917, Final Batch Loss: 0.1558775007724762\n",
      "Epoch 156, Loss: 0.303286075592041, Final Batch Loss: 0.13957557082176208\n",
      "Epoch 157, Loss: 0.2712841182947159, Final Batch Loss: 0.10113382339477539\n",
      "Epoch 158, Loss: 0.2444808930158615, Final Batch Loss: 0.14373226463794708\n",
      "Epoch 159, Loss: 0.2787211090326309, Final Batch Loss: 0.13423456251621246\n",
      "Epoch 160, Loss: 0.2700922340154648, Final Batch Loss: 0.1310235857963562\n",
      "Epoch 161, Loss: 0.2683088779449463, Final Batch Loss: 0.13186389207839966\n",
      "Epoch 162, Loss: 0.21941593289375305, Final Batch Loss: 0.11094486713409424\n",
      "Epoch 163, Loss: 0.2642471566796303, Final Batch Loss: 0.17221608757972717\n",
      "Epoch 164, Loss: 0.24727680534124374, Final Batch Loss: 0.1154589131474495\n",
      "Epoch 165, Loss: 0.2268693745136261, Final Batch Loss: 0.09696140885353088\n",
      "Epoch 166, Loss: 0.1925705224275589, Final Batch Loss: 0.08765538781881332\n",
      "Epoch 167, Loss: 0.2234027236700058, Final Batch Loss: 0.08864505589008331\n",
      "Epoch 168, Loss: 0.2509816363453865, Final Batch Loss: 0.10826893895864487\n",
      "Epoch 169, Loss: 0.2722902372479439, Final Batch Loss: 0.10829662531614304\n",
      "Epoch 170, Loss: 0.26028820872306824, Final Batch Loss: 0.1557580828666687\n",
      "Epoch 171, Loss: 0.29190340638160706, Final Batch Loss: 0.1486935168504715\n",
      "Epoch 172, Loss: 0.2946908697485924, Final Batch Loss: 0.17001402378082275\n",
      "Epoch 173, Loss: 0.2614799737930298, Final Batch Loss: 0.12608282268047333\n",
      "Epoch 174, Loss: 0.1994081363081932, Final Batch Loss: 0.0694025382399559\n",
      "Epoch 175, Loss: 0.20121855288743973, Final Batch Loss: 0.1074611023068428\n",
      "Epoch 176, Loss: 0.2195444330573082, Final Batch Loss: 0.10806522518396378\n",
      "Epoch 177, Loss: 0.25764286518096924, Final Batch Loss: 0.12706096470355988\n",
      "Epoch 178, Loss: 0.24036572873592377, Final Batch Loss: 0.0962083488702774\n",
      "Epoch 179, Loss: 0.20481786876916885, Final Batch Loss: 0.11116982996463776\n",
      "Epoch 180, Loss: 0.18358638882637024, Final Batch Loss: 0.09047718346118927\n",
      "Epoch 181, Loss: 0.20401157438755035, Final Batch Loss: 0.09580998122692108\n",
      "Epoch 182, Loss: 0.2732180207967758, Final Batch Loss: 0.13846439123153687\n",
      "Epoch 183, Loss: 0.23694296181201935, Final Batch Loss: 0.1287538707256317\n",
      "Epoch 184, Loss: 0.23192209750413895, Final Batch Loss: 0.14318576455116272\n",
      "Epoch 185, Loss: 0.18358343094587326, Final Batch Loss: 0.07481424510478973\n",
      "Epoch 186, Loss: 0.22572463005781174, Final Batch Loss: 0.11972437798976898\n",
      "Epoch 187, Loss: 0.20336631685495377, Final Batch Loss: 0.07642906159162521\n",
      "Epoch 188, Loss: 0.18656117469072342, Final Batch Loss: 0.08739165961742401\n",
      "Epoch 189, Loss: 0.16292617470026016, Final Batch Loss: 0.06731268018484116\n",
      "Epoch 190, Loss: 0.17983025312423706, Final Batch Loss: 0.08650939166545868\n",
      "Epoch 191, Loss: 0.21386273950338364, Final Batch Loss: 0.12930449843406677\n",
      "Epoch 192, Loss: 0.1979457475244999, Final Batch Loss: 0.05874018743634224\n",
      "Epoch 193, Loss: 0.19724401831626892, Final Batch Loss: 0.09533654898405075\n",
      "Epoch 194, Loss: 0.22981593012809753, Final Batch Loss: 0.10159620642662048\n",
      "Epoch 195, Loss: 0.21702183783054352, Final Batch Loss: 0.09193412959575653\n",
      "Epoch 196, Loss: 0.19398556649684906, Final Batch Loss: 0.10706306993961334\n",
      "Epoch 197, Loss: 0.18009557574987411, Final Batch Loss: 0.135517418384552\n",
      "Epoch 198, Loss: 0.18794213980436325, Final Batch Loss: 0.09565579146146774\n",
      "Epoch 199, Loss: 0.15362825989723206, Final Batch Loss: 0.05307288467884064\n",
      "Epoch 200, Loss: 0.2109800949692726, Final Batch Loss: 0.07177913933992386\n",
      "Epoch 201, Loss: 0.20368358492851257, Final Batch Loss: 0.0924711599946022\n",
      "Epoch 202, Loss: 0.156240314245224, Final Batch Loss: 0.06888605654239655\n",
      "Epoch 203, Loss: 0.22145721316337585, Final Batch Loss: 0.1255076378583908\n",
      "Epoch 204, Loss: 0.1578255370259285, Final Batch Loss: 0.03634686768054962\n",
      "Epoch 205, Loss: 0.20606224238872528, Final Batch Loss: 0.114529550075531\n",
      "Epoch 206, Loss: 0.15895913168787956, Final Batch Loss: 0.05778532102704048\n",
      "Epoch 207, Loss: 0.1950140967965126, Final Batch Loss: 0.10619354993104935\n",
      "Epoch 208, Loss: 0.18693767488002777, Final Batch Loss: 0.10749784111976624\n",
      "Epoch 209, Loss: 0.1512029655277729, Final Batch Loss: 0.058689188212156296\n",
      "Epoch 210, Loss: 0.19359157234430313, Final Batch Loss: 0.12298249453306198\n",
      "Epoch 211, Loss: 0.20203040540218353, Final Batch Loss: 0.12166740745306015\n",
      "Epoch 212, Loss: 0.19997470825910568, Final Batch Loss: 0.09703721106052399\n",
      "Epoch 213, Loss: 0.2914183437824249, Final Batch Loss: 0.20585930347442627\n",
      "Epoch 214, Loss: 0.14341220632195473, Final Batch Loss: 0.04408204182982445\n",
      "Epoch 215, Loss: 0.16619140654802322, Final Batch Loss: 0.10315307974815369\n",
      "Epoch 216, Loss: 0.1725643202662468, Final Batch Loss: 0.11429701000452042\n",
      "Epoch 217, Loss: 0.17220966517925262, Final Batch Loss: 0.07221920788288116\n",
      "Epoch 218, Loss: 0.17268428951501846, Final Batch Loss: 0.0910174697637558\n",
      "Epoch 219, Loss: 0.18487548828125, Final Batch Loss: 0.10684609413146973\n",
      "Epoch 220, Loss: 0.15102599561214447, Final Batch Loss: 0.06283564120531082\n",
      "Epoch 221, Loss: 0.11437766253948212, Final Batch Loss: 0.038560278713703156\n",
      "Epoch 222, Loss: 0.1671581044793129, Final Batch Loss: 0.09420908987522125\n",
      "Epoch 223, Loss: 0.2000521495938301, Final Batch Loss: 0.13359814882278442\n",
      "Epoch 224, Loss: 0.15075363218784332, Final Batch Loss: 0.06809812784194946\n",
      "Epoch 225, Loss: 0.13799227960407734, Final Batch Loss: 0.025051208212971687\n",
      "Epoch 226, Loss: 0.14098426699638367, Final Batch Loss: 0.05734322965145111\n",
      "Epoch 227, Loss: 0.12528151273727417, Final Batch Loss: 0.07379182428121567\n",
      "Epoch 228, Loss: 0.20029959827661514, Final Batch Loss: 0.07990820705890656\n",
      "Epoch 229, Loss: 0.17153484374284744, Final Batch Loss: 0.09106609225273132\n",
      "Epoch 230, Loss: 0.17406436800956726, Final Batch Loss: 0.04848955571651459\n",
      "Epoch 231, Loss: 0.16595575958490372, Final Batch Loss: 0.07517750561237335\n",
      "Epoch 232, Loss: 0.15679633989930153, Final Batch Loss: 0.0995161160826683\n",
      "Epoch 233, Loss: 0.15007473528385162, Final Batch Loss: 0.07313114404678345\n",
      "Epoch 234, Loss: 0.16250617057085037, Final Batch Loss: 0.06210501492023468\n",
      "Epoch 235, Loss: 0.15540985018014908, Final Batch Loss: 0.08570114523172379\n",
      "Epoch 236, Loss: 0.18711792677640915, Final Batch Loss: 0.12183041125535965\n",
      "Epoch 237, Loss: 0.14394626021385193, Final Batch Loss: 0.07907576858997345\n",
      "Epoch 238, Loss: 0.1471702679991722, Final Batch Loss: 0.06907089054584503\n",
      "Epoch 239, Loss: 0.1488959938287735, Final Batch Loss: 0.07850583642721176\n",
      "Epoch 240, Loss: 0.17519357800483704, Final Batch Loss: 0.102900929749012\n",
      "Epoch 241, Loss: 0.16675101965665817, Final Batch Loss: 0.12006912380456924\n",
      "Epoch 242, Loss: 0.15648964419960976, Final Batch Loss: 0.05634108558297157\n",
      "Epoch 243, Loss: 0.15462425723671913, Final Batch Loss: 0.05410288646817207\n",
      "Epoch 244, Loss: 0.15285606309771538, Final Batch Loss: 0.05097142234444618\n",
      "Epoch 245, Loss: 0.1881340965628624, Final Batch Loss: 0.1147649958729744\n",
      "Epoch 246, Loss: 0.16021305322647095, Final Batch Loss: 0.10124870389699936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247, Loss: 0.12004340812563896, Final Batch Loss: 0.07239237427711487\n",
      "Epoch 248, Loss: 0.16316915675997734, Final Batch Loss: 0.10284240543842316\n",
      "Epoch 249, Loss: 0.22576454281806946, Final Batch Loss: 0.1565331667661667\n",
      "Epoch 250, Loss: 0.16041389852762222, Final Batch Loss: 0.09881991147994995\n",
      "Epoch 251, Loss: 0.17883402481675148, Final Batch Loss: 0.1201702132821083\n",
      "Epoch 252, Loss: 0.15341492742300034, Final Batch Loss: 0.06273236870765686\n",
      "Epoch 253, Loss: 0.19720254093408585, Final Batch Loss: 0.06556610018014908\n",
      "Epoch 254, Loss: 0.16605251654982567, Final Batch Loss: 0.10614322125911713\n",
      "Epoch 255, Loss: 0.17652291059494019, Final Batch Loss: 0.06298456341028214\n",
      "Epoch 256, Loss: 0.22017325460910797, Final Batch Loss: 0.14905241131782532\n",
      "Epoch 257, Loss: 0.1613793820142746, Final Batch Loss: 0.09042596817016602\n",
      "Epoch 258, Loss: 0.1259823963046074, Final Batch Loss: 0.05318401753902435\n",
      "Epoch 259, Loss: 0.13370738178491592, Final Batch Loss: 0.043306365609169006\n",
      "Epoch 260, Loss: 0.17643092572689056, Final Batch Loss: 0.06746485829353333\n",
      "Epoch 261, Loss: 0.16767823696136475, Final Batch Loss: 0.06837201863527298\n",
      "Epoch 262, Loss: 0.12167665362358093, Final Batch Loss: 0.05452175438404083\n",
      "Epoch 263, Loss: 0.1629948690533638, Final Batch Loss: 0.09399577975273132\n",
      "Epoch 264, Loss: 0.17811894416809082, Final Batch Loss: 0.11777125298976898\n",
      "Epoch 265, Loss: 0.14665642380714417, Final Batch Loss: 0.06760592013597488\n",
      "Epoch 266, Loss: 0.10611911863088608, Final Batch Loss: 0.06592445820569992\n",
      "Epoch 267, Loss: 0.11911796033382416, Final Batch Loss: 0.055633336305618286\n",
      "Epoch 268, Loss: 0.1919313296675682, Final Batch Loss: 0.08232428133487701\n",
      "Epoch 269, Loss: 0.19211654365062714, Final Batch Loss: 0.11869241297245026\n",
      "Epoch 270, Loss: 0.17020926624536514, Final Batch Loss: 0.1316094845533371\n",
      "Epoch 271, Loss: 0.10832288861274719, Final Batch Loss: 0.03359261155128479\n",
      "Epoch 272, Loss: 0.1343747228384018, Final Batch Loss: 0.06273820996284485\n",
      "Epoch 273, Loss: 0.11304493993520737, Final Batch Loss: 0.055087894201278687\n",
      "Epoch 274, Loss: 0.13850543275475502, Final Batch Loss: 0.05917666479945183\n",
      "Epoch 275, Loss: 0.14490340650081635, Final Batch Loss: 0.07217120379209518\n",
      "Epoch 276, Loss: 0.11377587914466858, Final Batch Loss: 0.04157944768667221\n",
      "Epoch 277, Loss: 0.1673184484243393, Final Batch Loss: 0.08740563690662384\n",
      "Epoch 278, Loss: 0.10816112533211708, Final Batch Loss: 0.05927274748682976\n",
      "Epoch 279, Loss: 0.14977959915995598, Final Batch Loss: 0.06111152842640877\n",
      "Epoch 280, Loss: 0.12872028350830078, Final Batch Loss: 0.053780995309352875\n",
      "Epoch 281, Loss: 0.12366879358887672, Final Batch Loss: 0.06401267647743225\n",
      "Epoch 282, Loss: 0.1324716918170452, Final Batch Loss: 0.0790577158331871\n",
      "Epoch 283, Loss: 0.10015824623405933, Final Batch Loss: 0.025668995454907417\n",
      "Epoch 284, Loss: 0.12636969983577728, Final Batch Loss: 0.04456671327352524\n",
      "Epoch 285, Loss: 0.12379810586571693, Final Batch Loss: 0.05482671782374382\n",
      "Epoch 286, Loss: 0.14499318599700928, Final Batch Loss: 0.06513916701078415\n",
      "Epoch 287, Loss: 0.14871298521757126, Final Batch Loss: 0.07863382250070572\n",
      "Epoch 288, Loss: 0.12561537325382233, Final Batch Loss: 0.08411234617233276\n",
      "Epoch 289, Loss: 0.13040944188833237, Final Batch Loss: 0.058175228536129\n",
      "Epoch 290, Loss: 0.13414177671074867, Final Batch Loss: 0.05602778121829033\n",
      "Epoch 291, Loss: 0.1579672023653984, Final Batch Loss: 0.0920628160238266\n",
      "Epoch 292, Loss: 0.18248256295919418, Final Batch Loss: 0.1023918017745018\n",
      "Epoch 293, Loss: 0.10478869453072548, Final Batch Loss: 0.04754524305462837\n",
      "Epoch 294, Loss: 0.14616572111845016, Final Batch Loss: 0.08117517828941345\n",
      "Epoch 295, Loss: 0.11063330247998238, Final Batch Loss: 0.05949246138334274\n",
      "Epoch 296, Loss: 0.08844538778066635, Final Batch Loss: 0.03786362335085869\n",
      "Epoch 297, Loss: 0.09483877196907997, Final Batch Loss: 0.03065146878361702\n",
      "Epoch 298, Loss: 0.08681894093751907, Final Batch Loss: 0.03360988199710846\n",
      "Epoch 299, Loss: 0.09229955449700356, Final Batch Loss: 0.030443135648965836\n",
      "Epoch 300, Loss: 0.10734736919403076, Final Batch Loss: 0.06443406641483307\n",
      "Epoch 301, Loss: 0.14087477326393127, Final Batch Loss: 0.07470790296792984\n",
      "Epoch 302, Loss: 0.11082235351204872, Final Batch Loss: 0.047372858971357346\n",
      "Epoch 303, Loss: 0.07063100300729275, Final Batch Loss: 0.026016535237431526\n",
      "Epoch 304, Loss: 0.11295462027192116, Final Batch Loss: 0.07709760218858719\n",
      "Epoch 305, Loss: 0.11296319961547852, Final Batch Loss: 0.03161538392305374\n",
      "Epoch 306, Loss: 0.12523458525538445, Final Batch Loss: 0.049607690423727036\n",
      "Epoch 307, Loss: 0.13158831745386124, Final Batch Loss: 0.06279290467500687\n",
      "Epoch 308, Loss: 0.10814499855041504, Final Batch Loss: 0.043617695569992065\n",
      "Epoch 309, Loss: 0.1401205211877823, Final Batch Loss: 0.04594194144010544\n",
      "Epoch 310, Loss: 0.12135276570916176, Final Batch Loss: 0.05638768896460533\n",
      "Epoch 311, Loss: 0.09929637238383293, Final Batch Loss: 0.043887533247470856\n",
      "Epoch 312, Loss: 0.08045201189815998, Final Batch Loss: 0.027526943013072014\n",
      "Epoch 313, Loss: 0.08217749558389187, Final Batch Loss: 0.02307032234966755\n",
      "Epoch 314, Loss: 0.1330493912100792, Final Batch Loss: 0.06441846489906311\n",
      "Epoch 315, Loss: 0.09261219203472137, Final Batch Loss: 0.06103074550628662\n",
      "Epoch 316, Loss: 0.14119454473257065, Final Batch Loss: 0.0867963433265686\n",
      "Epoch 317, Loss: 0.09859303012490273, Final Batch Loss: 0.04254147410392761\n",
      "Epoch 318, Loss: 0.08997146412730217, Final Batch Loss: 0.04363405704498291\n",
      "Epoch 319, Loss: 0.15273812413215637, Final Batch Loss: 0.09816265106201172\n",
      "Epoch 320, Loss: 0.09097413904964924, Final Batch Loss: 0.025430792942643166\n",
      "Epoch 321, Loss: 0.09243815019726753, Final Batch Loss: 0.03936387225985527\n",
      "Epoch 322, Loss: 0.12374774366617203, Final Batch Loss: 0.0736021026968956\n",
      "Epoch 323, Loss: 0.0916997566819191, Final Batch Loss: 0.06253688782453537\n",
      "Epoch 324, Loss: 0.11429261416196823, Final Batch Loss: 0.06852753460407257\n",
      "Epoch 325, Loss: 0.09698566235601902, Final Batch Loss: 0.026886293664574623\n",
      "Epoch 326, Loss: 0.13835687562823296, Final Batch Loss: 0.08973560482263565\n",
      "Epoch 327, Loss: 0.12708219699561596, Final Batch Loss: 0.09736162424087524\n",
      "Epoch 328, Loss: 0.11598294600844383, Final Batch Loss: 0.050470564514398575\n",
      "Epoch 329, Loss: 0.09109309315681458, Final Batch Loss: 0.032327763736248016\n",
      "Epoch 330, Loss: 0.08689054101705551, Final Batch Loss: 0.04329806566238403\n",
      "Epoch 331, Loss: 0.09602104499936104, Final Batch Loss: 0.05108913406729698\n",
      "Epoch 332, Loss: 0.08024383708834648, Final Batch Loss: 0.03730624541640282\n",
      "Epoch 333, Loss: 0.08804173581302166, Final Batch Loss: 0.030005669221282005\n",
      "Epoch 334, Loss: 0.09182873368263245, Final Batch Loss: 0.02148480713367462\n",
      "Epoch 335, Loss: 0.08905988931655884, Final Batch Loss: 0.04620510712265968\n",
      "Epoch 336, Loss: 0.11453879252076149, Final Batch Loss: 0.044271085411310196\n",
      "Epoch 337, Loss: 0.12659252807497978, Final Batch Loss: 0.07892461866140366\n",
      "Epoch 338, Loss: 0.1138865239918232, Final Batch Loss: 0.053634192794561386\n",
      "Epoch 339, Loss: 0.1292603723704815, Final Batch Loss: 0.06909690797328949\n",
      "Epoch 340, Loss: 0.10536464303731918, Final Batch Loss: 0.02636510133743286\n",
      "Epoch 341, Loss: 0.12080370634794235, Final Batch Loss: 0.05608895421028137\n",
      "Epoch 342, Loss: 0.09536256641149521, Final Batch Loss: 0.03297039493918419\n",
      "Epoch 343, Loss: 0.1172826774418354, Final Batch Loss: 0.05645410716533661\n",
      "Epoch 344, Loss: 0.08344751596450806, Final Batch Loss: 0.02141304314136505\n",
      "Epoch 345, Loss: 0.10210490599274635, Final Batch Loss: 0.049288686364889145\n",
      "Epoch 346, Loss: 0.09634765610098839, Final Batch Loss: 0.04163810983300209\n",
      "Epoch 347, Loss: 0.0935734435915947, Final Batch Loss: 0.028348341584205627\n",
      "Epoch 348, Loss: 0.09202557429671288, Final Batch Loss: 0.051325082778930664\n",
      "Epoch 349, Loss: 0.1126212626695633, Final Batch Loss: 0.05519881844520569\n",
      "Epoch 350, Loss: 0.09653830900788307, Final Batch Loss: 0.052441950887441635\n",
      "Epoch 351, Loss: 0.1022450365126133, Final Batch Loss: 0.057160552591085434\n",
      "Epoch 352, Loss: 0.10330387204885483, Final Batch Loss: 0.045885372906923294\n",
      "Epoch 353, Loss: 0.1340213418006897, Final Batch Loss: 0.08379637449979782\n",
      "Epoch 354, Loss: 0.09304820001125336, Final Batch Loss: 0.046941161155700684\n",
      "Epoch 355, Loss: 0.1361902691423893, Final Batch Loss: 0.08784700185060501\n",
      "Epoch 356, Loss: 0.08995621651411057, Final Batch Loss: 0.031206510961055756\n",
      "Epoch 357, Loss: 0.09195175021886826, Final Batch Loss: 0.05509951338171959\n",
      "Epoch 358, Loss: 0.08988883346319199, Final Batch Loss: 0.04786306247115135\n",
      "Epoch 359, Loss: 0.13065017387270927, Final Batch Loss: 0.08682448416948318\n",
      "Epoch 360, Loss: 0.1356354095041752, Final Batch Loss: 0.09656697511672974\n",
      "Epoch 361, Loss: 0.09993107989430428, Final Batch Loss: 0.04210392385721207\n",
      "Epoch 362, Loss: 0.09073552675545216, Final Batch Loss: 0.02212085761129856\n",
      "Epoch 363, Loss: 0.13351779989898205, Final Batch Loss: 0.11294424533843994\n",
      "Epoch 364, Loss: 0.07909975573420525, Final Batch Loss: 0.05414703115820885\n",
      "Epoch 365, Loss: 0.07739208824932575, Final Batch Loss: 0.025287168100476265\n",
      "Epoch 366, Loss: 0.09895569831132889, Final Batch Loss: 0.05971724912524223\n",
      "Epoch 367, Loss: 0.1116974949836731, Final Batch Loss: 0.058772437274456024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368, Loss: 0.10020487383008003, Final Batch Loss: 0.053345367312431335\n",
      "Epoch 369, Loss: 0.09479885175824165, Final Batch Loss: 0.06359683722257614\n",
      "Epoch 370, Loss: 0.08013887703418732, Final Batch Loss: 0.03587422892451286\n",
      "Epoch 371, Loss: 0.10785745084285736, Final Batch Loss: 0.04804714024066925\n",
      "Epoch 372, Loss: 0.09509821608662605, Final Batch Loss: 0.023323874920606613\n",
      "Epoch 373, Loss: 0.06272061727941036, Final Batch Loss: 0.046783894300460815\n",
      "Epoch 374, Loss: 0.07934439927339554, Final Batch Loss: 0.03987250477075577\n",
      "Epoch 375, Loss: 0.0875556692481041, Final Batch Loss: 0.029867321252822876\n",
      "Epoch 376, Loss: 0.13045365177094936, Final Batch Loss: 0.10805971175432205\n",
      "Epoch 377, Loss: 0.06369110569357872, Final Batch Loss: 0.015738286077976227\n",
      "Epoch 378, Loss: 0.05603618547320366, Final Batch Loss: 0.02274627611041069\n",
      "Epoch 379, Loss: 0.08155519515275955, Final Batch Loss: 0.05313856899738312\n",
      "Epoch 380, Loss: 0.09957064315676689, Final Batch Loss: 0.032558586448431015\n",
      "Epoch 381, Loss: 0.0649457685649395, Final Batch Loss: 0.017646506428718567\n",
      "Epoch 382, Loss: 0.10461542010307312, Final Batch Loss: 0.07179902493953705\n",
      "Epoch 383, Loss: 0.061269584111869335, Final Batch Loss: 0.015349912457168102\n",
      "Epoch 384, Loss: 0.09040672704577446, Final Batch Loss: 0.050254855304956436\n",
      "Epoch 385, Loss: 0.09010924585163593, Final Batch Loss: 0.06714554131031036\n",
      "Epoch 386, Loss: 0.1076904945075512, Final Batch Loss: 0.06188874691724777\n",
      "Epoch 387, Loss: 0.09028886258602142, Final Batch Loss: 0.033035390079021454\n",
      "Epoch 388, Loss: 0.07799229398369789, Final Batch Loss: 0.0345500223338604\n",
      "Epoch 389, Loss: 0.06694902759045362, Final Batch Loss: 0.012771396897733212\n",
      "Epoch 390, Loss: 0.10838926210999489, Final Batch Loss: 0.032812993973493576\n",
      "Epoch 391, Loss: 0.07806806452572346, Final Batch Loss: 0.060988374054431915\n",
      "Epoch 392, Loss: 0.05523822456598282, Final Batch Loss: 0.021224312484264374\n",
      "Epoch 393, Loss: 0.05209011770784855, Final Batch Loss: 0.02042265795171261\n",
      "Epoch 394, Loss: 0.05069479439407587, Final Batch Loss: 0.015357513912022114\n",
      "Epoch 395, Loss: 0.09384091943502426, Final Batch Loss: 0.06909476220607758\n",
      "Epoch 396, Loss: 0.10952841117978096, Final Batch Loss: 0.05502903088927269\n",
      "Epoch 397, Loss: 0.08059603720903397, Final Batch Loss: 0.036911044269800186\n",
      "Epoch 398, Loss: 0.0893064271658659, Final Batch Loss: 0.07027482986450195\n",
      "Epoch 399, Loss: 0.09036241844296455, Final Batch Loss: 0.03763078898191452\n",
      "Epoch 400, Loss: 0.0791892446577549, Final Batch Loss: 0.03454416245222092\n",
      "Epoch 401, Loss: 0.07355177961289883, Final Batch Loss: 0.054535653442144394\n",
      "Epoch 402, Loss: 0.07401239313185215, Final Batch Loss: 0.051514316350221634\n",
      "Epoch 403, Loss: 0.0718384962528944, Final Batch Loss: 0.04369323328137398\n",
      "Epoch 404, Loss: 0.0665085669606924, Final Batch Loss: 0.029596639797091484\n",
      "Epoch 405, Loss: 0.06691625900566578, Final Batch Loss: 0.022293129935860634\n",
      "Epoch 406, Loss: 0.06323716323822737, Final Batch Loss: 0.015410265885293484\n",
      "Epoch 407, Loss: 0.06709297560155392, Final Batch Loss: 0.0174409206956625\n",
      "Epoch 408, Loss: 0.08109046518802643, Final Batch Loss: 0.033467814326286316\n",
      "Epoch 409, Loss: 0.06496590375900269, Final Batch Loss: 0.04455919936299324\n",
      "Epoch 410, Loss: 0.09396287798881531, Final Batch Loss: 0.06506573408842087\n",
      "Epoch 411, Loss: 0.08102351799607277, Final Batch Loss: 0.06472677737474442\n",
      "Epoch 412, Loss: 0.06010928004980087, Final Batch Loss: 0.02288922667503357\n",
      "Epoch 413, Loss: 0.12979557365179062, Final Batch Loss: 0.05449933558702469\n",
      "Epoch 414, Loss: 0.08181123062968254, Final Batch Loss: 0.05131760612130165\n",
      "Epoch 415, Loss: 0.08687140047550201, Final Batch Loss: 0.026173502206802368\n",
      "Epoch 416, Loss: 0.10944319143891335, Final Batch Loss: 0.07713140547275543\n",
      "Epoch 417, Loss: 0.09886417910456657, Final Batch Loss: 0.04997481033205986\n",
      "Epoch 418, Loss: 0.075015963986516, Final Batch Loss: 0.049664661288261414\n",
      "Epoch 419, Loss: 0.06694629788398743, Final Batch Loss: 0.014885976910591125\n",
      "Epoch 420, Loss: 0.09517249651253223, Final Batch Loss: 0.028998645022511482\n",
      "Epoch 421, Loss: 0.07013632170855999, Final Batch Loss: 0.022905314341187477\n",
      "Epoch 422, Loss: 0.06529545411467552, Final Batch Loss: 0.02942049875855446\n",
      "Epoch 423, Loss: 0.06760861165821552, Final Batch Loss: 0.017417652532458305\n",
      "Epoch 424, Loss: 0.08094971999526024, Final Batch Loss: 0.030335683375597\n",
      "Epoch 425, Loss: 0.08481785655021667, Final Batch Loss: 0.04691064730286598\n",
      "Epoch 426, Loss: 0.06778931804001331, Final Batch Loss: 0.05064926669001579\n",
      "Epoch 427, Loss: 0.07402482256293297, Final Batch Loss: 0.04443267360329628\n",
      "Epoch 428, Loss: 0.06704876385629177, Final Batch Loss: 0.03985428810119629\n",
      "Epoch 429, Loss: 0.05364702269434929, Final Batch Loss: 0.019460801035165787\n",
      "Epoch 430, Loss: 0.05525321699678898, Final Batch Loss: 0.018337873741984367\n",
      "Epoch 431, Loss: 0.0751848891377449, Final Batch Loss: 0.05267510190606117\n",
      "Epoch 432, Loss: 0.08646387234330177, Final Batch Loss: 0.02746812254190445\n",
      "Epoch 433, Loss: 0.0566900335252285, Final Batch Loss: 0.021804194897413254\n",
      "Epoch 434, Loss: 0.09872772544622421, Final Batch Loss: 0.03527231514453888\n",
      "Epoch 435, Loss: 0.07059687189757824, Final Batch Loss: 0.028602836653590202\n",
      "Epoch 436, Loss: 0.08284575864672661, Final Batch Loss: 0.0469600111246109\n",
      "Epoch 437, Loss: 0.07597417198121548, Final Batch Loss: 0.05432111769914627\n",
      "Epoch 438, Loss: 0.0876597985625267, Final Batch Loss: 0.054130490869283676\n",
      "Epoch 439, Loss: 0.056719956919550896, Final Batch Loss: 0.01701260916888714\n",
      "Epoch 440, Loss: 0.07580926641821861, Final Batch Loss: 0.05521436408162117\n",
      "Epoch 441, Loss: 0.05404516588896513, Final Batch Loss: 0.015088851563632488\n",
      "Epoch 442, Loss: 0.11617741361260414, Final Batch Loss: 0.05060053989291191\n",
      "Epoch 443, Loss: 0.07510031573474407, Final Batch Loss: 0.060797516256570816\n",
      "Epoch 444, Loss: 0.06081520766019821, Final Batch Loss: 0.013253547251224518\n",
      "Epoch 445, Loss: 0.09416068717837334, Final Batch Loss: 0.04133015498518944\n",
      "Epoch 446, Loss: 0.08626454509794712, Final Batch Loss: 0.01642465777695179\n",
      "Epoch 447, Loss: 0.07154475711286068, Final Batch Loss: 0.0526304692029953\n",
      "Epoch 448, Loss: 0.06219976581633091, Final Batch Loss: 0.028913604095578194\n",
      "Epoch 449, Loss: 0.08369343541562557, Final Batch Loss: 0.05513754487037659\n",
      "Epoch 450, Loss: 0.08413044735789299, Final Batch Loss: 0.028674781322479248\n",
      "Epoch 451, Loss: 0.0810405258089304, Final Batch Loss: 0.015926765277981758\n",
      "Epoch 452, Loss: 0.09742432087659836, Final Batch Loss: 0.03723146766424179\n",
      "Epoch 453, Loss: 0.07197357714176178, Final Batch Loss: 0.0211484357714653\n",
      "Epoch 454, Loss: 0.04245861433446407, Final Batch Loss: 0.00981300137937069\n",
      "Epoch 455, Loss: 0.04760151915252209, Final Batch Loss: 0.017775345593690872\n",
      "Epoch 456, Loss: 0.08807333186268806, Final Batch Loss: 0.049943890422582626\n",
      "Epoch 457, Loss: 0.06799841485917568, Final Batch Loss: 0.022152168676257133\n",
      "Epoch 458, Loss: 0.05722876265645027, Final Batch Loss: 0.025524169206619263\n",
      "Epoch 459, Loss: 0.05712991952896118, Final Batch Loss: 0.023793917149305344\n",
      "Epoch 460, Loss: 0.06346603855490685, Final Batch Loss: 0.0370381698012352\n",
      "Epoch 461, Loss: 0.06626755371689796, Final Batch Loss: 0.028212398290634155\n",
      "Epoch 462, Loss: 0.10536080598831177, Final Batch Loss: 0.06800955533981323\n",
      "Epoch 463, Loss: 0.09272179193794727, Final Batch Loss: 0.02821030654013157\n",
      "Epoch 464, Loss: 0.10460719466209412, Final Batch Loss: 0.07541867345571518\n",
      "Epoch 465, Loss: 0.07904106378555298, Final Batch Loss: 0.04334073141217232\n",
      "Epoch 466, Loss: 0.09561427682638168, Final Batch Loss: 0.05568983033299446\n",
      "Epoch 467, Loss: 0.0702694347128272, Final Batch Loss: 0.00943602155894041\n",
      "Epoch 468, Loss: 0.058362383395433426, Final Batch Loss: 0.02286708354949951\n",
      "Epoch 469, Loss: 0.057016413658857346, Final Batch Loss: 0.03862473741173744\n",
      "Epoch 470, Loss: 0.07620387338101864, Final Batch Loss: 0.06349276006221771\n",
      "Epoch 471, Loss: 0.09661498852074146, Final Batch Loss: 0.0734257847070694\n",
      "Epoch 472, Loss: 0.06821487192064524, Final Batch Loss: 0.0075383493676781654\n",
      "Epoch 473, Loss: 0.10200071148574352, Final Batch Loss: 0.0723343938589096\n",
      "Epoch 474, Loss: 0.06449882313609123, Final Batch Loss: 0.030074216425418854\n",
      "Epoch 475, Loss: 0.10411465726792812, Final Batch Loss: 0.07651443779468536\n",
      "Epoch 476, Loss: 0.05818524956703186, Final Batch Loss: 0.044600002467632294\n",
      "Epoch 477, Loss: 0.06527059711515903, Final Batch Loss: 0.02114657126367092\n",
      "Epoch 478, Loss: 0.05002103932201862, Final Batch Loss: 0.017389854416251183\n",
      "Epoch 479, Loss: 0.07205659337341785, Final Batch Loss: 0.04616174101829529\n",
      "Epoch 480, Loss: 0.07567673176527023, Final Batch Loss: 0.026502560824155807\n",
      "Epoch 481, Loss: 0.05118130054324865, Final Batch Loss: 0.013359415344893932\n",
      "Epoch 482, Loss: 0.07466816529631615, Final Batch Loss: 0.03721114620566368\n",
      "Epoch 483, Loss: 0.08111853525042534, Final Batch Loss: 0.05397193133831024\n",
      "Epoch 484, Loss: 0.07363542541861534, Final Batch Loss: 0.0504266731441021\n",
      "Epoch 485, Loss: 0.05264046788215637, Final Batch Loss: 0.02821575477719307\n",
      "Epoch 486, Loss: 0.0919660609215498, Final Batch Loss: 0.0666438415646553\n",
      "Epoch 487, Loss: 0.06290725991129875, Final Batch Loss: 0.030003070831298828\n",
      "Epoch 488, Loss: 0.061605220660567284, Final Batch Loss: 0.045767441391944885\n",
      "Epoch 489, Loss: 0.08204137161374092, Final Batch Loss: 0.0465063750743866\n",
      "Epoch 490, Loss: 0.07353467494249344, Final Batch Loss: 0.05159125477075577\n",
      "Epoch 491, Loss: 0.053839387372136116, Final Batch Loss: 0.018096791580319405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492, Loss: 0.08257126808166504, Final Batch Loss: 0.041352737694978714\n",
      "Epoch 493, Loss: 0.07686110958456993, Final Batch Loss: 0.031948529183864594\n",
      "Epoch 494, Loss: 0.08410773053765297, Final Batch Loss: 0.0563068762421608\n",
      "Epoch 495, Loss: 0.055105216801166534, Final Batch Loss: 0.0249064601957798\n",
      "Epoch 496, Loss: 0.05474236235022545, Final Batch Loss: 0.016632702201604843\n",
      "Epoch 497, Loss: 0.04013371840119362, Final Batch Loss: 0.014959702268242836\n",
      "Epoch 498, Loss: 0.06276905164122581, Final Batch Loss: 0.03872980177402496\n",
      "Epoch 499, Loss: 0.09667671658098698, Final Batch Loss: 0.07094991952180862\n",
      "Epoch 500, Loss: 0.06409794837236404, Final Batch Loss: 0.020695481449365616\n",
      "Epoch 501, Loss: 0.06751013919711113, Final Batch Loss: 0.031506430357694626\n",
      "Epoch 502, Loss: 0.09196069836616516, Final Batch Loss: 0.04866904392838478\n",
      "Epoch 503, Loss: 0.08641378208994865, Final Batch Loss: 0.05728285759687424\n",
      "Epoch 504, Loss: 0.07782241702079773, Final Batch Loss: 0.04381241276860237\n",
      "Epoch 505, Loss: 0.082823870703578, Final Batch Loss: 0.022787300869822502\n",
      "Epoch 506, Loss: 0.0638608280569315, Final Batch Loss: 0.03390469402074814\n",
      "Epoch 507, Loss: 0.06357785686850548, Final Batch Loss: 0.009467393159866333\n",
      "Epoch 508, Loss: 0.06938822008669376, Final Batch Loss: 0.04652058705687523\n",
      "Epoch 509, Loss: 0.06722685880959034, Final Batch Loss: 0.02512435056269169\n",
      "Epoch 510, Loss: 0.07773256488144398, Final Batch Loss: 0.057276077568531036\n",
      "Epoch 511, Loss: 0.08257989026606083, Final Batch Loss: 0.057681720703840256\n",
      "Epoch 512, Loss: 0.06863235682249069, Final Batch Loss: 0.023127932101488113\n",
      "Epoch 513, Loss: 0.07928192988038063, Final Batch Loss: 0.034793246537446976\n",
      "Epoch 514, Loss: 0.051652826368808746, Final Batch Loss: 0.014457982033491135\n",
      "Epoch 515, Loss: 0.06523173116147518, Final Batch Loss: 0.03773251175880432\n",
      "Epoch 516, Loss: 0.0808277353644371, Final Batch Loss: 0.035728536546230316\n",
      "Epoch 517, Loss: 0.07668154314160347, Final Batch Loss: 0.03739764913916588\n",
      "Epoch 518, Loss: 0.040541188791394234, Final Batch Loss: 0.012399537488818169\n",
      "Epoch 519, Loss: 0.06741197034716606, Final Batch Loss: 0.035303231328725815\n",
      "Epoch 520, Loss: 0.046636639162898064, Final Batch Loss: 0.023120159283280373\n",
      "Epoch 521, Loss: 0.06502006482332945, Final Batch Loss: 0.011272001080214977\n",
      "Epoch 522, Loss: 0.062179356813430786, Final Batch Loss: 0.022393561899662018\n",
      "Epoch 523, Loss: 0.08671604935079813, Final Batch Loss: 0.07383999973535538\n",
      "Epoch 524, Loss: 0.06835963577032089, Final Batch Loss: 0.027926843613386154\n",
      "Epoch 525, Loss: 0.06284055858850479, Final Batch Loss: 0.021628081798553467\n",
      "Epoch 526, Loss: 0.0668448880314827, Final Batch Loss: 0.034905027598142624\n",
      "Epoch 527, Loss: 0.039993686601519585, Final Batch Loss: 0.01867399550974369\n",
      "Epoch 528, Loss: 0.05971406772732735, Final Batch Loss: 0.014491844922304153\n",
      "Epoch 529, Loss: 0.0668442901223898, Final Batch Loss: 0.02625219337642193\n",
      "Epoch 530, Loss: 0.12162267789244652, Final Batch Loss: 0.08106961101293564\n",
      "Epoch 531, Loss: 0.06547502987086773, Final Batch Loss: 0.03854042664170265\n",
      "Epoch 532, Loss: 0.07877718657255173, Final Batch Loss: 0.03910691663622856\n",
      "Epoch 533, Loss: 0.05683020129799843, Final Batch Loss: 0.013649523258209229\n",
      "Epoch 534, Loss: 0.05119730485603213, Final Batch Loss: 0.00500614894554019\n",
      "Epoch 535, Loss: 0.053652310743927956, Final Batch Loss: 0.02132743038237095\n",
      "Epoch 536, Loss: 0.11208618432283401, Final Batch Loss: 0.058753032237291336\n",
      "Epoch 537, Loss: 0.054993886500597, Final Batch Loss: 0.014681827276945114\n",
      "Epoch 538, Loss: 0.09728781878948212, Final Batch Loss: 0.04766072705388069\n",
      "Epoch 539, Loss: 0.08178403042256832, Final Batch Loss: 0.06543300300836563\n",
      "Epoch 540, Loss: 0.08286119066178799, Final Batch Loss: 0.0197784211486578\n",
      "Epoch 541, Loss: 0.06806282140314579, Final Batch Loss: 0.06012457236647606\n",
      "Epoch 542, Loss: 0.04181606415659189, Final Batch Loss: 0.012105523608624935\n",
      "Epoch 543, Loss: 0.07164964266121387, Final Batch Loss: 0.04811979457736015\n",
      "Epoch 544, Loss: 0.059961190447211266, Final Batch Loss: 0.035034578293561935\n",
      "Epoch 545, Loss: 0.04700677841901779, Final Batch Loss: 0.016324903815984726\n",
      "Epoch 546, Loss: 0.06117815896868706, Final Batch Loss: 0.02727733924984932\n",
      "Epoch 547, Loss: 0.04687148332595825, Final Batch Loss: 0.012293606996536255\n",
      "Epoch 548, Loss: 0.06724858656525612, Final Batch Loss: 0.024783175438642502\n",
      "Epoch 549, Loss: 0.049621496349573135, Final Batch Loss: 0.01906234212219715\n",
      "Epoch 550, Loss: 0.060281792655587196, Final Batch Loss: 0.04377014935016632\n",
      "Epoch 551, Loss: 0.06817223504185677, Final Batch Loss: 0.05170460045337677\n",
      "Epoch 552, Loss: 0.0455496609210968, Final Batch Loss: 0.02131127007305622\n",
      "Epoch 553, Loss: 0.05938213039189577, Final Batch Loss: 0.010448270477354527\n",
      "Epoch 554, Loss: 0.03696494083851576, Final Batch Loss: 0.012115434743463993\n",
      "Epoch 555, Loss: 0.060711296275258064, Final Batch Loss: 0.03584783151745796\n",
      "Epoch 556, Loss: 0.05433241091668606, Final Batch Loss: 0.03819297254085541\n",
      "Epoch 557, Loss: 0.035819320008158684, Final Batch Loss: 0.01409604586660862\n",
      "Epoch 558, Loss: 0.07817629538476467, Final Batch Loss: 0.05833253264427185\n",
      "Epoch 559, Loss: 0.048694402910768986, Final Batch Loss: 0.014315609820187092\n",
      "Epoch 560, Loss: 0.1044391430914402, Final Batch Loss: 0.06672730296850204\n",
      "Epoch 561, Loss: 0.03948996029794216, Final Batch Loss: 0.01747014932334423\n",
      "Epoch 562, Loss: 0.028584624640643597, Final Batch Loss: 0.009542196057736874\n",
      "Epoch 563, Loss: 0.03173731919378042, Final Batch Loss: 0.012398981489241123\n",
      "Epoch 564, Loss: 0.048576257191598415, Final Batch Loss: 0.040360383689403534\n",
      "Epoch 565, Loss: 0.07683139480650425, Final Batch Loss: 0.05858950689435005\n",
      "Epoch 566, Loss: 0.0971934087574482, Final Batch Loss: 0.07932860404253006\n",
      "Epoch 567, Loss: 0.03599254135042429, Final Batch Loss: 0.014461022801697254\n",
      "Epoch 568, Loss: 0.04262286424636841, Final Batch Loss: 0.008417308330535889\n",
      "Epoch 569, Loss: 0.1201351247727871, Final Batch Loss: 0.08884664624929428\n",
      "Epoch 570, Loss: 0.04819518234580755, Final Batch Loss: 0.01292001735419035\n",
      "Epoch 571, Loss: 0.08532776311039925, Final Batch Loss: 0.06912898272275925\n",
      "Epoch 572, Loss: 0.043025435879826546, Final Batch Loss: 0.012135345488786697\n",
      "Epoch 573, Loss: 0.03433162812143564, Final Batch Loss: 0.010890263132750988\n",
      "Epoch 574, Loss: 0.029180319979786873, Final Batch Loss: 0.011504558846354485\n",
      "Epoch 575, Loss: 0.07228089682757854, Final Batch Loss: 0.04886467382311821\n",
      "Epoch 576, Loss: 0.04375455528497696, Final Batch Loss: 0.02619464509189129\n",
      "Epoch 577, Loss: 0.054178521037101746, Final Batch Loss: 0.036556143313646317\n",
      "Epoch 578, Loss: 0.0660604564473033, Final Batch Loss: 0.013265463523566723\n",
      "Epoch 579, Loss: 0.04324049036949873, Final Batch Loss: 0.010505753569304943\n",
      "Epoch 580, Loss: 0.056076904758811, Final Batch Loss: 0.03798148036003113\n",
      "Epoch 581, Loss: 0.0643517654389143, Final Batch Loss: 0.02703763358294964\n",
      "Epoch 582, Loss: 0.05955068580806255, Final Batch Loss: 0.01378646306693554\n",
      "Epoch 583, Loss: 0.059766873717308044, Final Batch Loss: 0.03708801791071892\n",
      "Epoch 584, Loss: 0.06403408758342266, Final Batch Loss: 0.025614267215132713\n",
      "Epoch 585, Loss: 0.0788181871175766, Final Batch Loss: 0.027651183307170868\n",
      "Epoch 586, Loss: 0.0650293342769146, Final Batch Loss: 0.04313160851597786\n",
      "Epoch 587, Loss: 0.05685697961598635, Final Batch Loss: 0.05007888376712799\n",
      "Epoch 588, Loss: 0.056843819096684456, Final Batch Loss: 0.03963485732674599\n",
      "Epoch 589, Loss: 0.049551378935575485, Final Batch Loss: 0.008768711239099503\n",
      "Epoch 590, Loss: 0.06009281799197197, Final Batch Loss: 0.0477939248085022\n",
      "Epoch 591, Loss: 0.05246693454682827, Final Batch Loss: 0.024760965257883072\n",
      "Epoch 592, Loss: 0.06628818809986115, Final Batch Loss: 0.04294208064675331\n",
      "Epoch 593, Loss: 0.040140499360859394, Final Batch Loss: 0.015039251185953617\n",
      "Epoch 594, Loss: 0.03743494488298893, Final Batch Loss: 0.016051020473241806\n",
      "Epoch 595, Loss: 0.042788246646523476, Final Batch Loss: 0.020814990624785423\n",
      "Epoch 596, Loss: 0.05329336225986481, Final Batch Loss: 0.015207931399345398\n",
      "Epoch 597, Loss: 0.03405126929283142, Final Batch Loss: 0.008996490389108658\n",
      "Epoch 598, Loss: 0.05167233757674694, Final Batch Loss: 0.014108369126915932\n",
      "Epoch 599, Loss: 0.06393272429704666, Final Batch Loss: 0.05047769472002983\n",
      "Epoch 600, Loss: 0.06629905570298433, Final Batch Loss: 0.05561739578843117\n",
      "Epoch 601, Loss: 0.07281976006925106, Final Batch Loss: 0.05022652819752693\n",
      "Epoch 602, Loss: 0.029141675680875778, Final Batch Loss: 0.01282217912375927\n",
      "Epoch 603, Loss: 0.04875254398211837, Final Batch Loss: 0.0063659935258328915\n",
      "Epoch 604, Loss: 0.04827733524143696, Final Batch Loss: 0.017269466072320938\n",
      "Epoch 605, Loss: 0.05789675936102867, Final Batch Loss: 0.01329498365521431\n",
      "Epoch 606, Loss: 0.03967390023171902, Final Batch Loss: 0.014177035540342331\n",
      "Epoch 607, Loss: 0.04150916286744177, Final Batch Loss: 0.003409397089853883\n",
      "Epoch 608, Loss: 0.05012892186641693, Final Batch Loss: 0.021873528137803078\n",
      "Epoch 609, Loss: 0.06931439321488142, Final Batch Loss: 0.058624267578125\n",
      "Epoch 610, Loss: 0.060575343668460846, Final Batch Loss: 0.03881068527698517\n",
      "Epoch 611, Loss: 0.05014969687908888, Final Batch Loss: 0.01532717328518629\n",
      "Epoch 612, Loss: 0.07606993056833744, Final Batch Loss: 0.05143548920750618\n",
      "Epoch 613, Loss: 0.049571121111512184, Final Batch Loss: 0.005187897011637688\n",
      "Epoch 614, Loss: 0.04555550590157509, Final Batch Loss: 0.019145721569657326\n",
      "Epoch 615, Loss: 0.04480846133083105, Final Batch Loss: 0.009651320986449718\n",
      "Epoch 616, Loss: 0.046695008873939514, Final Batch Loss: 0.020160336047410965\n",
      "Epoch 617, Loss: 0.0442971782758832, Final Batch Loss: 0.007406310178339481\n",
      "Epoch 618, Loss: 0.0627709161490202, Final Batch Loss: 0.0430966317653656\n",
      "Epoch 619, Loss: 0.056971676647663116, Final Batch Loss: 0.01625882089138031\n",
      "Epoch 620, Loss: 0.042922754772007465, Final Batch Loss: 0.013983848504722118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 621, Loss: 0.06377341412007809, Final Batch Loss: 0.03885051980614662\n",
      "Epoch 622, Loss: 0.043730766512453556, Final Batch Loss: 0.01024660188704729\n",
      "Epoch 623, Loss: 0.048103672452270985, Final Batch Loss: 0.014922992326319218\n",
      "Epoch 624, Loss: 0.04590490832924843, Final Batch Loss: 0.016936147585511208\n",
      "Epoch 625, Loss: 0.036891563795506954, Final Batch Loss: 0.023738449439406395\n",
      "Epoch 626, Loss: 0.044314428232610226, Final Batch Loss: 0.005285653285682201\n",
      "Epoch 627, Loss: 0.05155517905950546, Final Batch Loss: 0.04273057356476784\n",
      "Epoch 628, Loss: 0.0322277694940567, Final Batch Loss: 0.017242245376110077\n",
      "Epoch 629, Loss: 0.031473116017878056, Final Batch Loss: 0.01156716886907816\n",
      "Epoch 630, Loss: 0.05004739761352539, Final Batch Loss: 0.021626388654112816\n",
      "Epoch 631, Loss: 0.03626331500709057, Final Batch Loss: 0.006066471338272095\n",
      "Epoch 632, Loss: 0.06255084462463856, Final Batch Loss: 0.04444557800889015\n",
      "Epoch 633, Loss: 0.045056965202093124, Final Batch Loss: 0.017855150625109673\n",
      "Epoch 634, Loss: 0.03891361225396395, Final Batch Loss: 0.008404097519814968\n",
      "Epoch 635, Loss: 0.02987374272197485, Final Batch Loss: 0.008167163468897343\n",
      "Epoch 636, Loss: 0.03775828843936324, Final Batch Loss: 0.006866983603686094\n",
      "Epoch 637, Loss: 0.06805118173360825, Final Batch Loss: 0.04787136986851692\n",
      "Epoch 638, Loss: 0.04262395761907101, Final Batch Loss: 0.016799110919237137\n",
      "Epoch 639, Loss: 0.028672341257333755, Final Batch Loss: 0.008047794923186302\n",
      "Epoch 640, Loss: 0.03442218527197838, Final Batch Loss: 0.013697005808353424\n",
      "Epoch 641, Loss: 0.036282253451645374, Final Batch Loss: 0.011932187713682652\n",
      "Epoch 642, Loss: 0.0700078122317791, Final Batch Loss: 0.04808935150504112\n",
      "Epoch 643, Loss: 0.04190867207944393, Final Batch Loss: 0.0071947891265153885\n",
      "Epoch 644, Loss: 0.05558285769075155, Final Batch Loss: 0.0446225069463253\n",
      "Epoch 645, Loss: 0.048299144953489304, Final Batch Loss: 0.03420625254511833\n",
      "Epoch 646, Loss: 0.03293477650731802, Final Batch Loss: 0.019612208008766174\n",
      "Epoch 647, Loss: 0.03853916469961405, Final Batch Loss: 0.028886638581752777\n",
      "Epoch 648, Loss: 0.033353729639202356, Final Batch Loss: 0.0073990789242088795\n",
      "Epoch 649, Loss: 0.06600099429488182, Final Batch Loss: 0.04519244283437729\n",
      "Epoch 650, Loss: 0.05129538103938103, Final Batch Loss: 0.012951735407114029\n",
      "Epoch 651, Loss: 0.05189683474600315, Final Batch Loss: 0.038126058876514435\n",
      "Epoch 652, Loss: 0.029104136861860752, Final Batch Loss: 0.009832496754825115\n",
      "Epoch 653, Loss: 0.04261520691215992, Final Batch Loss: 0.007466128095984459\n",
      "Epoch 654, Loss: 0.052146775647997856, Final Batch Loss: 0.03537233546376228\n",
      "Epoch 655, Loss: 0.036243814043700695, Final Batch Loss: 0.02528558112680912\n",
      "Epoch 656, Loss: 0.06694133207201958, Final Batch Loss: 0.032408297061920166\n",
      "Epoch 657, Loss: 0.0334256486967206, Final Batch Loss: 0.01240795198827982\n",
      "Epoch 658, Loss: 0.07239510491490364, Final Batch Loss: 0.05391824617981911\n",
      "Epoch 659, Loss: 0.02537824446335435, Final Batch Loss: 0.003951557446271181\n",
      "Epoch 660, Loss: 0.05310770310461521, Final Batch Loss: 0.04600059613585472\n",
      "Epoch 661, Loss: 0.04268720559775829, Final Batch Loss: 0.016234762966632843\n",
      "Epoch 662, Loss: 0.03356795944273472, Final Batch Loss: 0.015628358349204063\n",
      "Epoch 663, Loss: 0.04000039864331484, Final Batch Loss: 0.024612145498394966\n",
      "Epoch 664, Loss: 0.03554762154817581, Final Batch Loss: 0.005215797573328018\n",
      "Epoch 665, Loss: 0.047218287363648415, Final Batch Loss: 0.033792056143283844\n",
      "Epoch 666, Loss: 0.04265979956835508, Final Batch Loss: 0.013314074836671352\n",
      "Epoch 667, Loss: 0.07094332575798035, Final Batch Loss: 0.026265833526849747\n",
      "Epoch 668, Loss: 0.04267076123505831, Final Batch Loss: 0.010588307864964008\n",
      "Epoch 669, Loss: 0.05502530187368393, Final Batch Loss: 0.009256899356842041\n",
      "Epoch 670, Loss: 0.03545698709785938, Final Batch Loss: 0.00953499972820282\n",
      "Epoch 671, Loss: 0.025503464974462986, Final Batch Loss: 0.008291753940284252\n",
      "Epoch 672, Loss: 0.0659740399569273, Final Batch Loss: 0.042570166289806366\n",
      "Epoch 673, Loss: 0.05897226929664612, Final Batch Loss: 0.03691571205854416\n",
      "Epoch 674, Loss: 0.03932703845202923, Final Batch Loss: 0.009849309921264648\n",
      "Epoch 675, Loss: 0.047101802192628384, Final Batch Loss: 0.011189538054168224\n",
      "Epoch 676, Loss: 0.05751608684659004, Final Batch Loss: 0.027419352903962135\n",
      "Epoch 677, Loss: 0.03207234852015972, Final Batch Loss: 0.008402172476053238\n",
      "Epoch 678, Loss: 0.0776483304798603, Final Batch Loss: 0.061491888016462326\n",
      "Epoch 679, Loss: 0.04342854116111994, Final Batch Loss: 0.008179818280041218\n",
      "Epoch 680, Loss: 0.03613949194550514, Final Batch Loss: 0.020343778654932976\n",
      "Epoch 681, Loss: 0.03412964101880789, Final Batch Loss: 0.00555067416280508\n",
      "Epoch 682, Loss: 0.037080023903399706, Final Batch Loss: 0.005501855630427599\n",
      "Epoch 683, Loss: 0.041834971867501736, Final Batch Loss: 0.010387840680778027\n",
      "Epoch 684, Loss: 0.03491263464093208, Final Batch Loss: 0.01260560192167759\n",
      "Epoch 685, Loss: 0.0634465697221458, Final Batch Loss: 0.05733225867152214\n",
      "Epoch 686, Loss: 0.03129467833787203, Final Batch Loss: 0.012594458647072315\n",
      "Epoch 687, Loss: 0.06565453112125397, Final Batch Loss: 0.03517453372478485\n",
      "Epoch 688, Loss: 0.07235648483037949, Final Batch Loss: 0.06316113471984863\n",
      "Epoch 689, Loss: 0.02848742064088583, Final Batch Loss: 0.010397753678262234\n",
      "Epoch 690, Loss: 0.07153217680752277, Final Batch Loss: 0.05547419562935829\n",
      "Epoch 691, Loss: 0.04724961332976818, Final Batch Loss: 0.02405449002981186\n",
      "Epoch 692, Loss: 0.027472098357975483, Final Batch Loss: 0.007900836877524853\n",
      "Epoch 693, Loss: 0.04275434743613005, Final Batch Loss: 0.032236672937870026\n",
      "Epoch 694, Loss: 0.03293820470571518, Final Batch Loss: 0.01306459866464138\n",
      "Epoch 695, Loss: 0.046027397736907005, Final Batch Loss: 0.03606785833835602\n",
      "Epoch 696, Loss: 0.03360166773200035, Final Batch Loss: 0.023344045504927635\n",
      "Epoch 697, Loss: 0.04490202013403177, Final Batch Loss: 0.00963569525629282\n",
      "Epoch 698, Loss: 0.0338300047442317, Final Batch Loss: 0.008815490640699863\n",
      "Epoch 699, Loss: 0.05619600974023342, Final Batch Loss: 0.014455905184149742\n",
      "Epoch 700, Loss: 0.05078738369047642, Final Batch Loss: 0.016474755480885506\n",
      "Epoch 701, Loss: 0.04954896541312337, Final Batch Loss: 0.006654613185673952\n",
      "Epoch 702, Loss: 0.04802051931619644, Final Batch Loss: 0.009301412850618362\n",
      "Epoch 703, Loss: 0.02494184486567974, Final Batch Loss: 0.007859351113438606\n",
      "Epoch 704, Loss: 0.05493308790028095, Final Batch Loss: 0.02888028509914875\n",
      "Epoch 705, Loss: 0.04045325564220548, Final Batch Loss: 0.032669004052877426\n",
      "Epoch 706, Loss: 0.03300240729004145, Final Batch Loss: 0.009815500117838383\n",
      "Epoch 707, Loss: 0.04184228740632534, Final Batch Loss: 0.022364472970366478\n",
      "Epoch 708, Loss: 0.040411340072751045, Final Batch Loss: 0.02083880640566349\n",
      "Epoch 709, Loss: 0.04503080993890762, Final Batch Loss: 0.008831430226564407\n",
      "Epoch 710, Loss: 0.04494530148804188, Final Batch Loss: 0.019313955679535866\n",
      "Epoch 711, Loss: 0.03550785407423973, Final Batch Loss: 0.015125729143619537\n",
      "Epoch 712, Loss: 0.045880489982664585, Final Batch Loss: 0.03332381695508957\n",
      "Epoch 713, Loss: 0.043223584070801735, Final Batch Loss: 0.01598018780350685\n",
      "Epoch 714, Loss: 0.031875952146947384, Final Batch Loss: 0.01269665826112032\n",
      "Epoch 715, Loss: 0.04499732097610831, Final Batch Loss: 0.03759237378835678\n",
      "Epoch 716, Loss: 0.027584609109908342, Final Batch Loss: 0.0052873012609779835\n",
      "Epoch 717, Loss: 0.018934488063678145, Final Batch Loss: 0.0035699622239917517\n",
      "Epoch 718, Loss: 0.03507688455283642, Final Batch Loss: 0.009160580113530159\n",
      "Epoch 719, Loss: 0.03069053217768669, Final Batch Loss: 0.005688736215233803\n",
      "Epoch 720, Loss: 0.03139110142365098, Final Batch Loss: 0.007158482912927866\n",
      "Epoch 721, Loss: 0.05407965648919344, Final Batch Loss: 0.040968041867017746\n",
      "Epoch 722, Loss: 0.029742606449872255, Final Batch Loss: 0.005353445652872324\n",
      "Epoch 723, Loss: 0.03736209683120251, Final Batch Loss: 0.0145212821662426\n",
      "Epoch 724, Loss: 0.054204780608415604, Final Batch Loss: 0.02980620600283146\n",
      "Epoch 725, Loss: 0.050065504387021065, Final Batch Loss: 0.04047619551420212\n",
      "Epoch 726, Loss: 0.05072188936173916, Final Batch Loss: 0.031285397708415985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 727, Loss: 0.03337423596531153, Final Batch Loss: 0.007339972071349621\n",
      "Epoch 728, Loss: 0.029910031706094742, Final Batch Loss: 0.005281737074255943\n",
      "Epoch 729, Loss: 0.02212199568748474, Final Batch Loss: 0.0067177023738622665\n",
      "Epoch 730, Loss: 0.03548924159258604, Final Batch Loss: 0.021658847108483315\n",
      "Epoch 731, Loss: 0.047727735713124275, Final Batch Loss: 0.03895792365074158\n",
      "Epoch 732, Loss: 0.05391976237297058, Final Batch Loss: 0.03545096889138222\n",
      "Epoch 733, Loss: 0.029960524290800095, Final Batch Loss: 0.00723235122859478\n",
      "Epoch 734, Loss: 0.02666944544762373, Final Batch Loss: 0.006788336671888828\n",
      "Epoch 735, Loss: 0.05428329762071371, Final Batch Loss: 0.042555972933769226\n",
      "Epoch 736, Loss: 0.04297143220901489, Final Batch Loss: 0.02088797651231289\n",
      "Epoch 737, Loss: 0.04152729827910662, Final Batch Loss: 0.00824608001857996\n",
      "Epoch 738, Loss: 0.056352902203798294, Final Batch Loss: 0.05054173991084099\n",
      "Epoch 739, Loss: 0.049283331260085106, Final Batch Loss: 0.030167322605848312\n",
      "Epoch 740, Loss: 0.05062267044559121, Final Batch Loss: 0.0034554102458059788\n",
      "Epoch 741, Loss: 0.03208036767318845, Final Batch Loss: 0.025144094601273537\n",
      "Epoch 742, Loss: 0.06843906082212925, Final Batch Loss: 0.054442938417196274\n",
      "Epoch 743, Loss: 0.02734508248977363, Final Batch Loss: 0.003262326819822192\n",
      "Epoch 744, Loss: 0.03781242948025465, Final Batch Loss: 0.011817957274615765\n",
      "Epoch 745, Loss: 0.041423218324780464, Final Batch Loss: 0.02248516120016575\n",
      "Epoch 746, Loss: 0.048336694948375225, Final Batch Loss: 0.03378835693001747\n",
      "Epoch 747, Loss: 0.040294695645570755, Final Batch Loss: 0.012784132733941078\n",
      "Epoch 748, Loss: 0.07062814012169838, Final Batch Loss: 0.04013587906956673\n",
      "Epoch 749, Loss: 0.031036888249218464, Final Batch Loss: 0.007282202132046223\n",
      "Epoch 750, Loss: 0.07693534065037966, Final Batch Loss: 0.06337712705135345\n",
      "Epoch 751, Loss: 0.0295837614685297, Final Batch Loss: 0.0037972740828990936\n",
      "Epoch 752, Loss: 0.031539504416286945, Final Batch Loss: 0.02454613707959652\n",
      "Epoch 753, Loss: 0.03611587733030319, Final Batch Loss: 0.01733962446451187\n",
      "Epoch 754, Loss: 0.04206904862076044, Final Batch Loss: 0.010358144529163837\n",
      "Epoch 755, Loss: 0.02638752944767475, Final Batch Loss: 0.0082857646048069\n",
      "Epoch 756, Loss: 0.033094759564846754, Final Batch Loss: 0.006728684064000845\n",
      "Epoch 757, Loss: 0.044118739664554596, Final Batch Loss: 0.03371526300907135\n",
      "Epoch 758, Loss: 0.03077814308926463, Final Batch Loss: 0.006418944802135229\n",
      "Epoch 759, Loss: 0.03535955026745796, Final Batch Loss: 0.009727802127599716\n",
      "Epoch 760, Loss: 0.040376633405685425, Final Batch Loss: 0.029919510707259178\n",
      "Epoch 761, Loss: 0.03524819668382406, Final Batch Loss: 0.006108296103775501\n",
      "Epoch 762, Loss: 0.05051510035991669, Final Batch Loss: 0.040493350476026535\n",
      "Epoch 763, Loss: 0.023710259702056646, Final Batch Loss: 0.0076719108037650585\n",
      "Epoch 764, Loss: 0.04188259085640311, Final Batch Loss: 0.004167267587035894\n",
      "Epoch 765, Loss: 0.027188795153051615, Final Batch Loss: 0.007209267932921648\n",
      "Epoch 766, Loss: 0.015871374867856503, Final Batch Loss: 0.004371043294668198\n",
      "Epoch 767, Loss: 0.030376650393009186, Final Batch Loss: 0.009131703525781631\n",
      "Epoch 768, Loss: 0.023284544236958027, Final Batch Loss: 0.007406591437757015\n",
      "Epoch 769, Loss: 0.02410172182135284, Final Batch Loss: 0.0025033827405422926\n",
      "Epoch 770, Loss: 0.021068592555820942, Final Batch Loss: 0.012007440440356731\n",
      "Epoch 771, Loss: 0.0713165644556284, Final Batch Loss: 0.04504717141389847\n",
      "Epoch 772, Loss: 0.045805743895471096, Final Batch Loss: 0.03534374758601189\n",
      "Epoch 773, Loss: 0.03807272296398878, Final Batch Loss: 0.00546137522906065\n",
      "Epoch 774, Loss: 0.04337347764521837, Final Batch Loss: 0.01294469740241766\n",
      "Epoch 775, Loss: 0.034320353996008635, Final Batch Loss: 0.0050222682766616344\n",
      "Epoch 776, Loss: 0.0629999041557312, Final Batch Loss: 0.03796117752790451\n",
      "Epoch 777, Loss: 0.03195567801594734, Final Batch Loss: 0.023460015654563904\n",
      "Epoch 778, Loss: 0.025601528584957123, Final Batch Loss: 0.0054790787398815155\n",
      "Epoch 779, Loss: 0.040287228766828775, Final Batch Loss: 0.006642250809818506\n",
      "Epoch 780, Loss: 0.03626114968210459, Final Batch Loss: 0.026066027581691742\n",
      "Epoch 781, Loss: 0.04357891250401735, Final Batch Loss: 0.03339168429374695\n",
      "Epoch 782, Loss: 0.030857733450829983, Final Batch Loss: 0.010374599136412144\n",
      "Epoch 783, Loss: 0.021243950352072716, Final Batch Loss: 0.006001761183142662\n",
      "Epoch 784, Loss: 0.026316008530557156, Final Batch Loss: 0.01017377432435751\n",
      "Epoch 785, Loss: 0.049968112260103226, Final Batch Loss: 0.029732558876276016\n",
      "Epoch 786, Loss: 0.017398895230144262, Final Batch Loss: 0.012472218833863735\n",
      "Epoch 787, Loss: 0.047972140833735466, Final Batch Loss: 0.024695102125406265\n",
      "Epoch 788, Loss: 0.01846199296414852, Final Batch Loss: 0.012440145015716553\n",
      "Epoch 789, Loss: 0.055437033995985985, Final Batch Loss: 0.04234051704406738\n",
      "Epoch 790, Loss: 0.02534347539767623, Final Batch Loss: 0.004732401575893164\n",
      "Epoch 791, Loss: 0.04333299491554499, Final Batch Loss: 0.03084719553589821\n",
      "Epoch 792, Loss: 0.034922586753964424, Final Batch Loss: 0.009359098970890045\n",
      "Epoch 793, Loss: 0.04709938634186983, Final Batch Loss: 0.03619721531867981\n",
      "Epoch 794, Loss: 0.029800329823046923, Final Batch Loss: 0.004789190832525492\n",
      "Epoch 795, Loss: 0.0640855971723795, Final Batch Loss: 0.04093896597623825\n",
      "Epoch 796, Loss: 0.05318537214770913, Final Batch Loss: 0.04725699499249458\n",
      "Epoch 797, Loss: 0.02003044355660677, Final Batch Loss: 0.003480643965303898\n",
      "Epoch 798, Loss: 0.036004078574478626, Final Batch Loss: 0.012923021800816059\n",
      "Epoch 799, Loss: 0.0378179382532835, Final Batch Loss: 0.01743980124592781\n",
      "Epoch 800, Loss: 0.052338000386953354, Final Batch Loss: 0.04320134222507477\n",
      "Epoch 801, Loss: 0.039913248270750046, Final Batch Loss: 0.011492855846881866\n",
      "Epoch 802, Loss: 0.046320407185703516, Final Batch Loss: 0.004766477737575769\n",
      "Epoch 803, Loss: 0.03425302915275097, Final Batch Loss: 0.014458507299423218\n",
      "Epoch 804, Loss: 0.03736576717346907, Final Batch Loss: 0.007513341493904591\n",
      "Epoch 805, Loss: 0.05053263623267412, Final Batch Loss: 0.04124170169234276\n",
      "Epoch 806, Loss: 0.03492350038141012, Final Batch Loss: 0.006843053735792637\n",
      "Epoch 807, Loss: 0.03607702208682895, Final Batch Loss: 0.006028750445693731\n",
      "Epoch 808, Loss: 0.02660590084269643, Final Batch Loss: 0.006275613326579332\n",
      "Epoch 809, Loss: 0.03502329043112695, Final Batch Loss: 0.0036338677164167166\n",
      "Epoch 810, Loss: 0.03212842717766762, Final Batch Loss: 0.008703112602233887\n",
      "Epoch 811, Loss: 0.03725197724997997, Final Batch Loss: 0.03167648985981941\n",
      "Epoch 812, Loss: 0.02423620643094182, Final Batch Loss: 0.005802961532026529\n",
      "Epoch 813, Loss: 0.058723362162709236, Final Batch Loss: 0.02716674841940403\n",
      "Epoch 814, Loss: 0.029365885071456432, Final Batch Loss: 0.015344551764428616\n",
      "Epoch 815, Loss: 0.04895680071786046, Final Batch Loss: 0.04320083558559418\n",
      "Epoch 816, Loss: 0.04143470525741577, Final Batch Loss: 0.02399832382798195\n",
      "Epoch 817, Loss: 0.035175726749002934, Final Batch Loss: 0.020103558897972107\n",
      "Epoch 818, Loss: 0.04675077088177204, Final Batch Loss: 0.02623867243528366\n",
      "Epoch 819, Loss: 0.03757599974051118, Final Batch Loss: 0.007206548471003771\n",
      "Epoch 820, Loss: 0.060394853353500366, Final Batch Loss: 0.03057117573916912\n",
      "Epoch 821, Loss: 0.04284313879907131, Final Batch Loss: 0.0340191051363945\n",
      "Epoch 822, Loss: 0.05102228652685881, Final Batch Loss: 0.041242871433496475\n",
      "Epoch 823, Loss: 0.027421717531979084, Final Batch Loss: 0.008028817363083363\n",
      "Epoch 824, Loss: 0.031356245279312134, Final Batch Loss: 0.0056236498057842255\n",
      "Epoch 825, Loss: 0.031619217712432146, Final Batch Loss: 0.004532622639089823\n",
      "Epoch 826, Loss: 0.02681411080993712, Final Batch Loss: 0.003287706756964326\n",
      "Epoch 827, Loss: 0.06407172605395317, Final Batch Loss: 0.03346513211727142\n",
      "Epoch 828, Loss: 0.025656156707555056, Final Batch Loss: 0.005370632279664278\n",
      "Epoch 829, Loss: 0.02559315599501133, Final Batch Loss: 0.01908223144710064\n",
      "Epoch 830, Loss: 0.04453491419553757, Final Batch Loss: 0.027770327404141426\n",
      "Epoch 831, Loss: 0.0505119888111949, Final Batch Loss: 0.03925158828496933\n",
      "Epoch 832, Loss: 0.029432436916977167, Final Batch Loss: 0.006841566879302263\n",
      "Epoch 833, Loss: 0.03906107833608985, Final Batch Loss: 0.034220244735479355\n",
      "Epoch 834, Loss: 0.037315962836146355, Final Batch Loss: 0.025468772277235985\n",
      "Epoch 835, Loss: 0.035365765914320946, Final Batch Loss: 0.017640236765146255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 836, Loss: 0.02391970343887806, Final Batch Loss: 0.010936995968222618\n",
      "Epoch 837, Loss: 0.0467718280851841, Final Batch Loss: 0.03362034261226654\n",
      "Epoch 838, Loss: 0.03019590675830841, Final Batch Loss: 0.018270578235387802\n",
      "Epoch 839, Loss: 0.03473223466426134, Final Batch Loss: 0.008925738744437695\n",
      "Epoch 840, Loss: 0.025132209062576294, Final Batch Loss: 0.0070678479969501495\n",
      "Epoch 841, Loss: 0.06405464559793472, Final Batch Loss: 0.05658251419663429\n",
      "Epoch 842, Loss: 0.03809833573177457, Final Batch Loss: 0.007762203458696604\n",
      "Epoch 843, Loss: 0.039240483194589615, Final Batch Loss: 0.028766347095370293\n",
      "Epoch 844, Loss: 0.05020724330097437, Final Batch Loss: 0.03815772011876106\n",
      "Epoch 845, Loss: 0.027206046041101217, Final Batch Loss: 0.022714409977197647\n",
      "Epoch 846, Loss: 0.026630838634446263, Final Batch Loss: 0.0035447620321065187\n",
      "Epoch 847, Loss: 0.02978154830634594, Final Batch Loss: 0.020434096455574036\n",
      "Epoch 848, Loss: 0.02789406105875969, Final Batch Loss: 0.007882930338382721\n",
      "Epoch 849, Loss: 0.0308382548391819, Final Batch Loss: 0.003723813220858574\n",
      "Epoch 850, Loss: 0.0322770019993186, Final Batch Loss: 0.006794204004108906\n",
      "Epoch 851, Loss: 0.024734804406762123, Final Batch Loss: 0.016371820122003555\n",
      "Epoch 852, Loss: 0.037456946447491646, Final Batch Loss: 0.01666955277323723\n",
      "Epoch 853, Loss: 0.029254264198243618, Final Batch Loss: 0.015775475651025772\n",
      "Epoch 854, Loss: 0.03183633182197809, Final Batch Loss: 0.01723303087055683\n",
      "Epoch 855, Loss: 0.03693689312785864, Final Batch Loss: 0.022804811596870422\n",
      "Epoch 856, Loss: 0.036135985516011715, Final Batch Loss: 0.009557669050991535\n",
      "Epoch 857, Loss: 0.05318813771009445, Final Batch Loss: 0.03397354856133461\n",
      "Epoch 858, Loss: 0.021618823520839214, Final Batch Loss: 0.008413881063461304\n",
      "Epoch 859, Loss: 0.011843925807625055, Final Batch Loss: 0.002629836555570364\n",
      "Epoch 860, Loss: 0.026131746359169483, Final Batch Loss: 0.0023367544636130333\n",
      "Epoch 861, Loss: 0.0345674529671669, Final Batch Loss: 0.018174896016716957\n",
      "Epoch 862, Loss: 0.026749643962830305, Final Batch Loss: 0.005645520519465208\n",
      "Epoch 863, Loss: 0.02178607229143381, Final Batch Loss: 0.015238739550113678\n",
      "Epoch 864, Loss: 0.03267853055149317, Final Batch Loss: 0.022800009697675705\n",
      "Epoch 865, Loss: 0.03345504682511091, Final Batch Loss: 0.027801470831036568\n",
      "Epoch 866, Loss: 0.0695327166467905, Final Batch Loss: 0.04151153936982155\n",
      "Epoch 867, Loss: 0.030444401316344738, Final Batch Loss: 0.022055326029658318\n",
      "Epoch 868, Loss: 0.030512157827615738, Final Batch Loss: 0.008651865646243095\n",
      "Epoch 869, Loss: 0.026555594988167286, Final Batch Loss: 0.007114003412425518\n",
      "Epoch 870, Loss: 0.02474900335073471, Final Batch Loss: 0.005579035729169846\n",
      "Epoch 871, Loss: 0.03395748510956764, Final Batch Loss: 0.02663675881922245\n",
      "Epoch 872, Loss: 0.028287775814533234, Final Batch Loss: 0.00860334001481533\n",
      "Epoch 873, Loss: 0.03968661464750767, Final Batch Loss: 0.03243256360292435\n",
      "Epoch 874, Loss: 0.047133089043200016, Final Batch Loss: 0.03525971248745918\n",
      "Epoch 875, Loss: 0.024488458409905434, Final Batch Loss: 0.00859469547867775\n",
      "Epoch 876, Loss: 0.03895220998674631, Final Batch Loss: 0.015376436524093151\n",
      "Epoch 877, Loss: 0.028534819837659597, Final Batch Loss: 0.023665014654397964\n",
      "Epoch 878, Loss: 0.040184644516557455, Final Batch Loss: 0.03387584537267685\n",
      "Epoch 879, Loss: 0.04138794634491205, Final Batch Loss: 0.02778077870607376\n",
      "Epoch 880, Loss: 0.01560685969889164, Final Batch Loss: 0.0034538256004452705\n",
      "Epoch 881, Loss: 0.04975277557969093, Final Batch Loss: 0.010483678430318832\n",
      "Epoch 882, Loss: 0.03651738911867142, Final Batch Loss: 0.02227756567299366\n",
      "Epoch 883, Loss: 0.0403233552351594, Final Batch Loss: 0.030346136540174484\n",
      "Epoch 884, Loss: 0.01694761263206601, Final Batch Loss: 0.01102864183485508\n",
      "Epoch 885, Loss: 0.034120704513043165, Final Batch Loss: 0.002678974997252226\n",
      "Epoch 886, Loss: 0.04079439444467425, Final Batch Loss: 0.0044259908609092236\n",
      "Epoch 887, Loss: 0.048046501353383064, Final Batch Loss: 0.032410841435194016\n",
      "Epoch 888, Loss: 0.03874322958290577, Final Batch Loss: 0.02077040635049343\n",
      "Epoch 889, Loss: 0.027346222661435604, Final Batch Loss: 0.016246922314167023\n",
      "Epoch 890, Loss: 0.05591272562742233, Final Batch Loss: 0.029146810993552208\n",
      "Epoch 891, Loss: 0.04241279186680913, Final Batch Loss: 0.03623476251959801\n",
      "Epoch 892, Loss: 0.03644569031894207, Final Batch Loss: 0.01122320257127285\n",
      "Epoch 893, Loss: 0.031963872723281384, Final Batch Loss: 0.01735777035355568\n",
      "Epoch 894, Loss: 0.04273584531620145, Final Batch Loss: 0.035716790705919266\n",
      "Epoch 895, Loss: 0.04344647005200386, Final Batch Loss: 0.024579662829637527\n",
      "Epoch 896, Loss: 0.02828091336414218, Final Batch Loss: 0.006298465188592672\n",
      "Epoch 897, Loss: 0.047285296022892, Final Batch Loss: 0.03761165961623192\n",
      "Epoch 898, Loss: 0.029818829149007797, Final Batch Loss: 0.021469786763191223\n",
      "Epoch 899, Loss: 0.03658559639006853, Final Batch Loss: 0.012906196527183056\n",
      "Epoch 900, Loss: 0.012926701921969652, Final Batch Loss: 0.003642741125077009\n",
      "Epoch 901, Loss: 0.04040207527577877, Final Batch Loss: 0.022002531215548515\n",
      "Epoch 902, Loss: 0.049230773001909256, Final Batch Loss: 0.02326878160238266\n",
      "Epoch 903, Loss: 0.028067419305443764, Final Batch Loss: 0.01723092421889305\n",
      "Epoch 904, Loss: 0.028651295229792595, Final Batch Loss: 0.010250499472022057\n",
      "Epoch 905, Loss: 0.02935108821839094, Final Batch Loss: 0.0050666434690356255\n",
      "Epoch 906, Loss: 0.026684517040848732, Final Batch Loss: 0.00705549493432045\n",
      "Epoch 907, Loss: 0.030958685092628002, Final Batch Loss: 0.009480488486588001\n",
      "Epoch 908, Loss: 0.04132522363215685, Final Batch Loss: 0.027329156175255775\n",
      "Epoch 909, Loss: 0.021791073959320784, Final Batch Loss: 0.0036433688364923\n",
      "Epoch 910, Loss: 0.041235472075641155, Final Batch Loss: 0.03459252789616585\n",
      "Epoch 911, Loss: 0.022701069712638855, Final Batch Loss: 0.003116574138402939\n",
      "Epoch 912, Loss: 0.034054925199598074, Final Batch Loss: 0.005035845097154379\n",
      "Epoch 913, Loss: 0.025267701596021652, Final Batch Loss: 0.013636047020554543\n",
      "Epoch 914, Loss: 0.03873991034924984, Final Batch Loss: 0.021184688434004784\n",
      "Epoch 915, Loss: 0.053912107832729816, Final Batch Loss: 0.04340418428182602\n",
      "Epoch 916, Loss: 0.0377136766910553, Final Batch Loss: 0.029374608770012856\n",
      "Epoch 917, Loss: 0.027782465796917677, Final Batch Loss: 0.007335867267102003\n",
      "Epoch 918, Loss: 0.017866021022200584, Final Batch Loss: 0.008363538421690464\n",
      "Epoch 919, Loss: 0.026866680942475796, Final Batch Loss: 0.012267435900866985\n",
      "Epoch 920, Loss: 0.0501807127147913, Final Batch Loss: 0.02494960092008114\n",
      "Epoch 921, Loss: 0.029270420782268047, Final Batch Loss: 0.010956360958516598\n",
      "Epoch 922, Loss: 0.035248925909399986, Final Batch Loss: 0.016669150441884995\n",
      "Epoch 923, Loss: 0.022525028325617313, Final Batch Loss: 0.01444952841848135\n",
      "Epoch 924, Loss: 0.031444125808775425, Final Batch Loss: 0.02674688957631588\n",
      "Epoch 925, Loss: 0.04902006313204765, Final Batch Loss: 0.031574491411447525\n",
      "Epoch 926, Loss: 0.04813528433442116, Final Batch Loss: 0.03804033622145653\n",
      "Epoch 927, Loss: 0.027254891116172075, Final Batch Loss: 0.02030005492269993\n",
      "Epoch 928, Loss: 0.04109328240156174, Final Batch Loss: 0.033837929368019104\n",
      "Epoch 929, Loss: 0.03539516311138868, Final Batch Loss: 0.027303962036967278\n",
      "Epoch 930, Loss: 0.02221290674060583, Final Batch Loss: 0.005032536573708057\n",
      "Epoch 931, Loss: 0.04435333423316479, Final Batch Loss: 0.036749906837940216\n",
      "Epoch 932, Loss: 0.032889374531805515, Final Batch Loss: 0.010609987191855907\n",
      "Epoch 933, Loss: 0.024848137982189655, Final Batch Loss: 0.010852573439478874\n",
      "Epoch 934, Loss: 0.02705548843368888, Final Batch Loss: 0.006962220650166273\n",
      "Epoch 935, Loss: 0.016912451945245266, Final Batch Loss: 0.006385634653270245\n",
      "Epoch 936, Loss: 0.03838598122820258, Final Batch Loss: 0.0309938732534647\n",
      "Epoch 937, Loss: 0.03984163049608469, Final Batch Loss: 0.030509984120726585\n",
      "Epoch 938, Loss: 0.04070681892335415, Final Batch Loss: 0.02490227110683918\n",
      "Epoch 939, Loss: 0.016930866986513138, Final Batch Loss: 0.0046935006976127625\n",
      "Epoch 940, Loss: 0.022028261795639992, Final Batch Loss: 0.007256324402987957\n",
      "Epoch 941, Loss: 0.03291302174329758, Final Batch Loss: 0.01612415909767151\n",
      "Epoch 942, Loss: 0.027648432413116097, Final Batch Loss: 0.0020731559488922358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 943, Loss: 0.02175798173993826, Final Batch Loss: 0.009774591773748398\n",
      "Epoch 944, Loss: 0.02662526722997427, Final Batch Loss: 0.02244597300887108\n",
      "Epoch 945, Loss: 0.028864136897027493, Final Batch Loss: 0.008934556506574154\n",
      "Epoch 946, Loss: 0.026014194823801517, Final Batch Loss: 0.0022181617096066475\n",
      "Epoch 947, Loss: 0.03610049933195114, Final Batch Loss: 0.009053466841578484\n",
      "Epoch 948, Loss: 0.030383584089577198, Final Batch Loss: 0.01700938120484352\n",
      "Epoch 949, Loss: 0.024308943189680576, Final Batch Loss: 0.0034673111513257027\n",
      "Epoch 950, Loss: 0.02556353248655796, Final Batch Loss: 0.01013938244432211\n",
      "Epoch 951, Loss: 0.029277276247739792, Final Batch Loss: 0.0212528258562088\n",
      "Epoch 952, Loss: 0.02832537703216076, Final Batch Loss: 0.007933491840958595\n",
      "Epoch 953, Loss: 0.0097144590690732, Final Batch Loss: 0.004135016351938248\n",
      "Epoch 954, Loss: 0.023519779555499554, Final Batch Loss: 0.0072816358879208565\n",
      "Epoch 955, Loss: 0.032436856999993324, Final Batch Loss: 0.016725488007068634\n",
      "Epoch 956, Loss: 0.018310896353796124, Final Batch Loss: 0.015639862045645714\n",
      "Epoch 957, Loss: 0.02448035404086113, Final Batch Loss: 0.016255728900432587\n",
      "Epoch 958, Loss: 0.02319443505257368, Final Batch Loss: 0.003609408624470234\n",
      "Epoch 959, Loss: 0.038488155230879784, Final Batch Loss: 0.017195554450154305\n",
      "Epoch 960, Loss: 0.022901971358805895, Final Batch Loss: 0.005615855101495981\n",
      "Epoch 961, Loss: 0.02693522023037076, Final Batch Loss: 0.020676029846072197\n",
      "Epoch 962, Loss: 0.05847359914332628, Final Batch Loss: 0.04849664121866226\n",
      "Epoch 963, Loss: 0.025736899580806494, Final Batch Loss: 0.006880793254822493\n",
      "Epoch 964, Loss: 0.02554346714168787, Final Batch Loss: 0.015855278819799423\n",
      "Epoch 965, Loss: 0.0308453980833292, Final Batch Loss: 0.024099860340356827\n",
      "Epoch 966, Loss: 0.023638617247343063, Final Batch Loss: 0.01035304181277752\n",
      "Epoch 967, Loss: 0.020877580158412457, Final Batch Loss: 0.0065317945554852486\n",
      "Epoch 968, Loss: 0.04719685763120651, Final Batch Loss: 0.030517835170030594\n",
      "Epoch 969, Loss: 0.014425755012780428, Final Batch Loss: 0.0034988154657185078\n",
      "Epoch 970, Loss: 0.031839498318731785, Final Batch Loss: 0.024871276691555977\n",
      "Epoch 971, Loss: 0.024924864526838064, Final Batch Loss: 0.0044710165821015835\n",
      "Epoch 972, Loss: 0.01812427374534309, Final Batch Loss: 0.0038973556365817785\n",
      "Epoch 973, Loss: 0.030109857209026814, Final Batch Loss: 0.01727036014199257\n",
      "Epoch 974, Loss: 0.026737293344922364, Final Batch Loss: 0.0017742441268637776\n",
      "Epoch 975, Loss: 0.023792377207428217, Final Batch Loss: 0.005527733359485865\n",
      "Epoch 976, Loss: 0.024559317156672478, Final Batch Loss: 0.00535726360976696\n",
      "Epoch 977, Loss: 0.025583228562027216, Final Batch Loss: 0.018722226843237877\n",
      "Epoch 978, Loss: 0.030011732131242752, Final Batch Loss: 0.011735647916793823\n",
      "Epoch 979, Loss: 0.01985159865580499, Final Batch Loss: 0.0027155836578458548\n",
      "Epoch 980, Loss: 0.029887151438742876, Final Batch Loss: 0.023833466693758965\n",
      "Epoch 981, Loss: 0.014042573515325785, Final Batch Loss: 0.003955812659114599\n",
      "Epoch 982, Loss: 0.030919685028493404, Final Batch Loss: 0.021284816786646843\n",
      "Epoch 983, Loss: 0.02572789415717125, Final Batch Loss: 0.004565298557281494\n",
      "Epoch 984, Loss: 0.04092198656871915, Final Batch Loss: 0.0365394726395607\n",
      "Epoch 985, Loss: 0.024494169279932976, Final Batch Loss: 0.017148083075881004\n",
      "Epoch 986, Loss: 0.04096705932170153, Final Batch Loss: 0.026696762070059776\n",
      "Epoch 987, Loss: 0.030948228668421507, Final Batch Loss: 0.024436764419078827\n",
      "Epoch 988, Loss: 0.04873614199459553, Final Batch Loss: 0.03423314914107323\n",
      "Epoch 989, Loss: 0.028111662715673447, Final Batch Loss: 0.016609828919172287\n",
      "Epoch 990, Loss: 0.016280519077554345, Final Batch Loss: 0.00276471977122128\n",
      "Epoch 991, Loss: 0.01628515962511301, Final Batch Loss: 0.0021523674950003624\n",
      "Epoch 992, Loss: 0.04807126056402922, Final Batch Loss: 0.01288160216063261\n",
      "Epoch 993, Loss: 0.03211362240836024, Final Batch Loss: 0.005530293565243483\n",
      "Epoch 994, Loss: 0.03778268024325371, Final Batch Loss: 0.0148735661059618\n",
      "Epoch 995, Loss: 0.027435249648988247, Final Batch Loss: 0.003502638079226017\n",
      "Epoch 996, Loss: 0.021736217429861426, Final Batch Loss: 0.0038916633930057287\n",
      "Epoch 997, Loss: 0.014656696934252977, Final Batch Loss: 0.0076675149612128735\n",
      "Epoch 998, Loss: 0.03231247141957283, Final Batch Loss: 0.005674978718161583\n",
      "Epoch 999, Loss: 0.03369494900107384, Final Batch Loss: 0.01918325200676918\n",
      "Epoch 1000, Loss: 0.04091131780296564, Final Batch Loss: 0.008043655194342136\n",
      "Epoch 1001, Loss: 0.020682462491095066, Final Batch Loss: 0.00194453913718462\n",
      "Epoch 1002, Loss: 0.03590226452797651, Final Batch Loss: 0.031248783692717552\n",
      "Epoch 1003, Loss: 0.03262398950755596, Final Batch Loss: 0.007290638983249664\n",
      "Epoch 1004, Loss: 0.022815783973783255, Final Batch Loss: 0.00562190031632781\n",
      "Epoch 1005, Loss: 0.041083503514528275, Final Batch Loss: 0.027619436383247375\n",
      "Epoch 1006, Loss: 0.04713683156296611, Final Batch Loss: 0.041654910892248154\n",
      "Epoch 1007, Loss: 0.03220491483807564, Final Batch Loss: 0.01602344587445259\n",
      "Epoch 1008, Loss: 0.022335529327392578, Final Batch Loss: 0.016281643882393837\n",
      "Epoch 1009, Loss: 0.03154687175992876, Final Batch Loss: 0.001648194738663733\n",
      "Epoch 1010, Loss: 0.03688001446425915, Final Batch Loss: 0.020937612280249596\n",
      "Epoch 1011, Loss: 0.018730984069406986, Final Batch Loss: 0.004977299831807613\n",
      "Epoch 1012, Loss: 0.046441154554486275, Final Batch Loss: 0.025601528584957123\n",
      "Epoch 1013, Loss: 0.03602911718189716, Final Batch Loss: 0.016275066882371902\n",
      "Epoch 1014, Loss: 0.02393980510532856, Final Batch Loss: 0.010387800633907318\n",
      "Epoch 1015, Loss: 0.01695955405011773, Final Batch Loss: 0.004513456020504236\n",
      "Epoch 1016, Loss: 0.025299059227108955, Final Batch Loss: 0.004686364904046059\n",
      "Epoch 1017, Loss: 0.009656688896939158, Final Batch Loss: 0.0031325381714850664\n",
      "Epoch 1018, Loss: 0.022198529914021492, Final Batch Loss: 0.00820699892938137\n",
      "Epoch 1019, Loss: 0.02964406181126833, Final Batch Loss: 0.01993105746805668\n",
      "Epoch 1020, Loss: 0.025035894475877285, Final Batch Loss: 0.005079840309917927\n",
      "Epoch 1021, Loss: 0.027530496008694172, Final Batch Loss: 0.009696214459836483\n",
      "Epoch 1022, Loss: 0.03833331819623709, Final Batch Loss: 0.03530899062752724\n",
      "Epoch 1023, Loss: 0.02551908604800701, Final Batch Loss: 0.008671490475535393\n",
      "Epoch 1024, Loss: 0.01798148499801755, Final Batch Loss: 0.0042675272561609745\n",
      "Epoch 1025, Loss: 0.025111681316047907, Final Batch Loss: 0.005528226960450411\n",
      "Epoch 1026, Loss: 0.03085476905107498, Final Batch Loss: 0.013909012079238892\n",
      "Epoch 1027, Loss: 0.031157358083873987, Final Batch Loss: 0.02463786117732525\n",
      "Epoch 1028, Loss: 0.01623359485529363, Final Batch Loss: 0.0021578900050371885\n",
      "Epoch 1029, Loss: 0.01868355693295598, Final Batch Loss: 0.006013030651956797\n",
      "Epoch 1030, Loss: 0.026123134419322014, Final Batch Loss: 0.012155314907431602\n",
      "Epoch 1031, Loss: 0.028244623914361, Final Batch Loss: 0.006485234946012497\n",
      "Epoch 1032, Loss: 0.02227202127687633, Final Batch Loss: 0.020192138850688934\n",
      "Epoch 1033, Loss: 0.025710577610880136, Final Batch Loss: 0.019239695742726326\n",
      "Epoch 1034, Loss: 0.022936753928661346, Final Batch Loss: 0.014862793497741222\n",
      "Epoch 1035, Loss: 0.014545916579663754, Final Batch Loss: 0.006599669344723225\n",
      "Epoch 1036, Loss: 0.019327225862070918, Final Batch Loss: 0.0034547026734799147\n",
      "Epoch 1037, Loss: 0.027122684754431248, Final Batch Loss: 0.018708502873778343\n",
      "Epoch 1038, Loss: 0.01664882618933916, Final Batch Loss: 0.0025792857632040977\n",
      "Epoch 1039, Loss: 0.03159889439120889, Final Batch Loss: 0.02740955725312233\n",
      "Epoch 1040, Loss: 0.030664341058582067, Final Batch Loss: 0.004531714599579573\n",
      "Epoch 1041, Loss: 0.027478114468976855, Final Batch Loss: 0.0029098622035235167\n",
      "Epoch 1042, Loss: 0.027032536454498768, Final Batch Loss: 0.009287846274673939\n",
      "Epoch 1043, Loss: 0.016715990379452705, Final Batch Loss: 0.0071704573929309845\n",
      "Epoch 1044, Loss: 0.034487378783524036, Final Batch Loss: 0.007093007676303387\n",
      "Epoch 1045, Loss: 0.05464221863076091, Final Batch Loss: 0.04893811047077179\n",
      "Epoch 1046, Loss: 0.034362378530204296, Final Batch Loss: 0.02374097891151905\n",
      "Epoch 1047, Loss: 0.023225937504321337, Final Batch Loss: 0.0049428814090788364\n",
      "Epoch 1048, Loss: 0.0230130385607481, Final Batch Loss: 0.01592644676566124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1049, Loss: 0.017207671888172626, Final Batch Loss: 0.008357291109859943\n",
      "Epoch 1050, Loss: 0.03018773440271616, Final Batch Loss: 0.023428793996572495\n",
      "Epoch 1051, Loss: 0.02606169879436493, Final Batch Loss: 0.021842246875166893\n",
      "Epoch 1052, Loss: 0.013971410924568772, Final Batch Loss: 0.003711695084348321\n",
      "Epoch 1053, Loss: 0.03302124794572592, Final Batch Loss: 0.026134416460990906\n",
      "Epoch 1054, Loss: 0.030941378325223923, Final Batch Loss: 0.00848185084760189\n",
      "Epoch 1055, Loss: 0.012442085891962051, Final Batch Loss: 0.005560355726629496\n",
      "Epoch 1056, Loss: 0.028416329994797707, Final Batch Loss: 0.01120319776237011\n",
      "Epoch 1057, Loss: 0.03493599779903889, Final Batch Loss: 0.017787469550967216\n",
      "Epoch 1058, Loss: 0.02630719542503357, Final Batch Loss: 0.010471435263752937\n",
      "Epoch 1059, Loss: 0.02274509286507964, Final Batch Loss: 0.00685781380161643\n",
      "Epoch 1060, Loss: 0.043398997746407986, Final Batch Loss: 0.033519115298986435\n",
      "Epoch 1061, Loss: 0.04277010168880224, Final Batch Loss: 0.033828794956207275\n",
      "Epoch 1062, Loss: 0.027743879705667496, Final Batch Loss: 0.023740941658616066\n",
      "Epoch 1063, Loss: 0.0778256431221962, Final Batch Loss: 0.04258819669485092\n",
      "Epoch 1064, Loss: 0.022189146373420954, Final Batch Loss: 0.016665523871779442\n",
      "Epoch 1065, Loss: 0.03027196042239666, Final Batch Loss: 0.0252804197371006\n",
      "Epoch 1066, Loss: 0.024483365938067436, Final Batch Loss: 0.015968477353453636\n",
      "Epoch 1067, Loss: 0.017584667541086674, Final Batch Loss: 0.0028510037809610367\n",
      "Epoch 1068, Loss: 0.021275280509144068, Final Batch Loss: 0.005040603224188089\n",
      "Epoch 1069, Loss: 0.02440718188881874, Final Batch Loss: 0.010134954936802387\n",
      "Epoch 1070, Loss: 0.023892230354249477, Final Batch Loss: 0.016683287918567657\n",
      "Epoch 1071, Loss: 0.032484134659171104, Final Batch Loss: 0.014896504580974579\n",
      "Epoch 1072, Loss: 0.013959337258711457, Final Batch Loss: 0.0022156464401632547\n",
      "Epoch 1073, Loss: 0.0507131302729249, Final Batch Loss: 0.03928156942129135\n",
      "Epoch 1074, Loss: 0.042635200545191765, Final Batch Loss: 0.02951970137655735\n",
      "Epoch 1075, Loss: 0.037149335257709026, Final Batch Loss: 0.02171424776315689\n",
      "Epoch 1076, Loss: 0.022714855149388313, Final Batch Loss: 0.01929343119263649\n",
      "Epoch 1077, Loss: 0.022728459909558296, Final Batch Loss: 0.00899143610149622\n",
      "Epoch 1078, Loss: 0.02643521735444665, Final Batch Loss: 0.006311193574219942\n",
      "Epoch 1079, Loss: 0.025524966418743134, Final Batch Loss: 0.008906424045562744\n",
      "Epoch 1080, Loss: 0.010850884951651096, Final Batch Loss: 0.002445329912006855\n",
      "Epoch 1081, Loss: 0.01823097071610391, Final Batch Loss: 0.003776199882850051\n",
      "Epoch 1082, Loss: 0.024296291172504425, Final Batch Loss: 0.015559478662908077\n",
      "Epoch 1083, Loss: 0.04776836559176445, Final Batch Loss: 0.03354273736476898\n",
      "Epoch 1084, Loss: 0.036393183283507824, Final Batch Loss: 0.026756079867482185\n",
      "Epoch 1085, Loss: 0.042477451264858246, Final Batch Loss: 0.028468867763876915\n",
      "Epoch 1086, Loss: 0.02001585764810443, Final Batch Loss: 0.013851846568286419\n",
      "Epoch 1087, Loss: 0.02629925822839141, Final Batch Loss: 0.004593051504343748\n",
      "Epoch 1088, Loss: 0.020354092121124268, Final Batch Loss: 0.01326537411659956\n",
      "Epoch 1089, Loss: 0.014115892816334963, Final Batch Loss: 0.005601799581199884\n",
      "Epoch 1090, Loss: 0.022872667759656906, Final Batch Loss: 0.014223473146557808\n",
      "Epoch 1091, Loss: 0.019127940759062767, Final Batch Loss: 0.007983068935573101\n",
      "Epoch 1092, Loss: 0.014487993903458118, Final Batch Loss: 0.005282571539282799\n",
      "Epoch 1093, Loss: 0.022312036715447903, Final Batch Loss: 0.017071377485990524\n",
      "Epoch 1094, Loss: 0.027738715056329966, Final Batch Loss: 0.02367464080452919\n",
      "Epoch 1095, Loss: 0.020275470335036516, Final Batch Loss: 0.01626729406416416\n",
      "Epoch 1096, Loss: 0.05043587228283286, Final Batch Loss: 0.04469843953847885\n",
      "Epoch 1097, Loss: 0.03621249832212925, Final Batch Loss: 0.02441509999334812\n",
      "Epoch 1098, Loss: 0.012064578477293253, Final Batch Loss: 0.003277126234024763\n",
      "Epoch 1099, Loss: 0.02288280986249447, Final Batch Loss: 0.0016398057341575623\n",
      "Epoch 1100, Loss: 0.016734968638047576, Final Batch Loss: 0.0038299725856631994\n",
      "Epoch 1101, Loss: 0.014875913504511118, Final Batch Loss: 0.010608982294797897\n",
      "Epoch 1102, Loss: 0.029722243081778288, Final Batch Loss: 0.025386866182088852\n",
      "Epoch 1103, Loss: 0.01727663865312934, Final Batch Loss: 0.0033077471889555454\n",
      "Epoch 1104, Loss: 0.02068030834197998, Final Batch Loss: 0.003825422376394272\n",
      "Epoch 1105, Loss: 0.03029485046863556, Final Batch Loss: 0.02076323702931404\n",
      "Epoch 1106, Loss: 0.015014730859547853, Final Batch Loss: 0.008077651262283325\n",
      "Epoch 1107, Loss: 0.01151757501065731, Final Batch Loss: 0.007608805317431688\n",
      "Epoch 1108, Loss: 0.02835886785760522, Final Batch Loss: 0.021054482087492943\n",
      "Epoch 1109, Loss: 0.019136266317218542, Final Batch Loss: 0.014328792691230774\n",
      "Epoch 1110, Loss: 0.015059121418744326, Final Batch Loss: 0.0077658407390117645\n",
      "Epoch 1111, Loss: 0.017696215771138668, Final Batch Loss: 0.011329783126711845\n",
      "Epoch 1112, Loss: 0.011976211564615369, Final Batch Loss: 0.0017519465181976557\n",
      "Epoch 1113, Loss: 0.02338570263236761, Final Batch Loss: 0.016388431191444397\n",
      "Epoch 1114, Loss: 0.014684170950204134, Final Batch Loss: 0.009287634864449501\n",
      "Epoch 1115, Loss: 0.03736868593841791, Final Batch Loss: 0.01400184165686369\n",
      "Epoch 1116, Loss: 0.0371235366910696, Final Batch Loss: 0.017556099221110344\n",
      "Epoch 1117, Loss: 0.018295704387128353, Final Batch Loss: 0.010031783021986485\n",
      "Epoch 1118, Loss: 0.010798901319503784, Final Batch Loss: 0.006653366144746542\n",
      "Epoch 1119, Loss: 0.02784956619143486, Final Batch Loss: 0.015836462378501892\n",
      "Epoch 1120, Loss: 0.015374994371086359, Final Batch Loss: 0.007769609801471233\n",
      "Epoch 1121, Loss: 0.016603656113147736, Final Batch Loss: 0.0035440046340227127\n",
      "Epoch 1122, Loss: 0.013991307467222214, Final Batch Loss: 0.003940211609005928\n",
      "Epoch 1123, Loss: 0.02691393857821822, Final Batch Loss: 0.021800681948661804\n",
      "Epoch 1124, Loss: 0.02561931498348713, Final Batch Loss: 0.008562752977013588\n",
      "Epoch 1125, Loss: 0.020442588720470667, Final Batch Loss: 0.014332064427435398\n",
      "Epoch 1126, Loss: 0.021412760019302368, Final Batch Loss: 0.0055110156536102295\n",
      "Epoch 1127, Loss: 0.01491624116897583, Final Batch Loss: 0.006710179150104523\n",
      "Epoch 1128, Loss: 0.01898242998868227, Final Batch Loss: 0.004910108633339405\n",
      "Epoch 1129, Loss: 0.03634243784472346, Final Batch Loss: 0.03083776868879795\n",
      "Epoch 1130, Loss: 0.012531570857390761, Final Batch Loss: 0.0024679878260940313\n",
      "Epoch 1131, Loss: 0.016389623750001192, Final Batch Loss: 0.0114849042147398\n",
      "Epoch 1132, Loss: 0.013347439467906952, Final Batch Loss: 0.010623193345963955\n",
      "Epoch 1133, Loss: 0.012468567583709955, Final Batch Loss: 0.010849198326468468\n",
      "Epoch 1134, Loss: 0.02180713228881359, Final Batch Loss: 0.01219764444977045\n",
      "Epoch 1135, Loss: 0.007409888319671154, Final Batch Loss: 0.0016525527462363243\n",
      "Epoch 1136, Loss: 0.027473825961351395, Final Batch Loss: 0.01765231043100357\n",
      "Epoch 1137, Loss: 0.027483465149998665, Final Batch Loss: 0.019266849383711815\n",
      "Epoch 1138, Loss: 0.02174915699288249, Final Batch Loss: 0.01886615715920925\n",
      "Epoch 1139, Loss: 0.008315704471897334, Final Batch Loss: 0.000826414383482188\n",
      "Epoch 1140, Loss: 0.020184775348752737, Final Batch Loss: 0.005606975872069597\n",
      "Epoch 1141, Loss: 0.005529056186787784, Final Batch Loss: 0.0016586381243541837\n",
      "Epoch 1142, Loss: 0.010123349260538816, Final Batch Loss: 0.0028527281247079372\n",
      "Epoch 1143, Loss: 0.01719517121091485, Final Batch Loss: 0.010145766660571098\n",
      "Epoch 1144, Loss: 0.019004329456947744, Final Batch Loss: 0.001149692921899259\n",
      "Epoch 1145, Loss: 0.030108917504549026, Final Batch Loss: 0.014862045645713806\n",
      "Epoch 1146, Loss: 0.007876206655055285, Final Batch Loss: 0.003048742190003395\n",
      "Epoch 1147, Loss: 0.012570052407681942, Final Batch Loss: 0.004144256003201008\n",
      "Epoch 1148, Loss: 0.01577344536781311, Final Batch Loss: 0.01041692215949297\n",
      "Epoch 1149, Loss: 0.007779331644997001, Final Batch Loss: 0.001930133206769824\n",
      "Epoch 1150, Loss: 0.014213747577741742, Final Batch Loss: 0.011314433068037033\n",
      "Epoch 1151, Loss: 0.058392589911818504, Final Batch Loss: 0.05619998276233673\n",
      "Epoch 1152, Loss: 0.014931810554116964, Final Batch Loss: 0.004691930953413248\n",
      "Epoch 1153, Loss: 0.02337903529405594, Final Batch Loss: 0.009491159580647945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1154, Loss: 0.03559445682913065, Final Batch Loss: 0.010373842902481556\n",
      "Epoch 1155, Loss: 0.021256543695926666, Final Batch Loss: 0.012336024083197117\n",
      "Epoch 1156, Loss: 0.018172239884734154, Final Batch Loss: 0.01416384894400835\n",
      "Epoch 1157, Loss: 0.011092457105405629, Final Batch Loss: 0.0006991067202761769\n",
      "Epoch 1158, Loss: 0.007693309104070067, Final Batch Loss: 0.003562584286555648\n",
      "Epoch 1159, Loss: 0.009260105900466442, Final Batch Loss: 0.00690136244520545\n",
      "Epoch 1160, Loss: 0.021196576417423785, Final Batch Loss: 0.0010418525198474526\n",
      "Epoch 1161, Loss: 0.016566559206694365, Final Batch Loss: 0.013646339997649193\n",
      "Epoch 1162, Loss: 0.005817780387587845, Final Batch Loss: 0.0018363614799454808\n",
      "Epoch 1163, Loss: 0.00920106889680028, Final Batch Loss: 0.004473674111068249\n",
      "Epoch 1164, Loss: 0.022139431908726692, Final Batch Loss: 0.015918560326099396\n",
      "Epoch 1165, Loss: 0.0255502387881279, Final Batch Loss: 0.01563694141805172\n",
      "Epoch 1166, Loss: 0.006768052699044347, Final Batch Loss: 0.0033255410380661488\n",
      "Epoch 1167, Loss: 0.04262570012360811, Final Batch Loss: 0.040480826050043106\n",
      "Epoch 1168, Loss: 0.008985572727397084, Final Batch Loss: 0.0029312658589333296\n",
      "Epoch 1169, Loss: 0.00974320713430643, Final Batch Loss: 0.008267638273537159\n",
      "Epoch 1170, Loss: 0.005861835554242134, Final Batch Loss: 0.0039023670833557844\n",
      "Epoch 1171, Loss: 0.018498283112421632, Final Batch Loss: 0.0023789985571056604\n",
      "Epoch 1172, Loss: 0.013504378497600555, Final Batch Loss: 0.009956451132893562\n",
      "Epoch 1173, Loss: 0.008657634258270264, Final Batch Loss: 0.006898421794176102\n",
      "Epoch 1174, Loss: 0.006965473061427474, Final Batch Loss: 0.0022931715939193964\n",
      "Epoch 1175, Loss: 0.009585653431713581, Final Batch Loss: 0.006206577643752098\n",
      "Epoch 1176, Loss: 0.039164306595921516, Final Batch Loss: 0.01748461276292801\n",
      "Epoch 1177, Loss: 0.009805011213757098, Final Batch Loss: 0.0014489177847281098\n",
      "Epoch 1178, Loss: 0.02847867924720049, Final Batch Loss: 0.01505476888269186\n",
      "Epoch 1179, Loss: 0.0025671852054074407, Final Batch Loss: 0.0011652226094156504\n",
      "Epoch 1180, Loss: 0.009807791095227003, Final Batch Loss: 0.00695122592151165\n",
      "Epoch 1181, Loss: 0.016244912520051003, Final Batch Loss: 0.0061714062467217445\n",
      "Epoch 1182, Loss: 0.025745694059878588, Final Batch Loss: 0.00460843788459897\n",
      "Epoch 1183, Loss: 0.029591199476271868, Final Batch Loss: 0.0031634275801479816\n",
      "Epoch 1184, Loss: 0.007479366613551974, Final Batch Loss: 0.002399068558588624\n",
      "Epoch 1185, Loss: 0.008279653266072273, Final Batch Loss: 0.00432569021359086\n",
      "Epoch 1186, Loss: 0.009914226597175002, Final Batch Loss: 0.0027003579307347536\n",
      "Epoch 1187, Loss: 0.014027551747858524, Final Batch Loss: 0.007498045451939106\n",
      "Epoch 1188, Loss: 0.008904839865863323, Final Batch Loss: 0.0033346153795719147\n",
      "Epoch 1189, Loss: 0.011042854748666286, Final Batch Loss: 0.006944494321942329\n",
      "Epoch 1190, Loss: 0.01932306308299303, Final Batch Loss: 0.008694248273968697\n",
      "Epoch 1191, Loss: 0.01208884478546679, Final Batch Loss: 0.01002721767872572\n",
      "Epoch 1192, Loss: 0.029522607568651438, Final Batch Loss: 0.00633900286629796\n",
      "Epoch 1193, Loss: 0.005592082510702312, Final Batch Loss: 0.001777128898538649\n",
      "Epoch 1194, Loss: 0.01047193817794323, Final Batch Loss: 0.004961630795150995\n",
      "Epoch 1195, Loss: 0.005961604882031679, Final Batch Loss: 0.003506426000967622\n",
      "Epoch 1196, Loss: 0.0037730741314589977, Final Batch Loss: 0.0004939136561006308\n",
      "Epoch 1197, Loss: 0.026272431248798966, Final Batch Loss: 0.023337671533226967\n",
      "Epoch 1198, Loss: 0.01031337445601821, Final Batch Loss: 0.006190776359289885\n",
      "Epoch 1199, Loss: 0.009266437264159322, Final Batch Loss: 0.007212046068161726\n",
      "Epoch 1200, Loss: 0.007906459271907806, Final Batch Loss: 0.003152085468173027\n",
      "Epoch 1201, Loss: 0.0056909461272880435, Final Batch Loss: 0.0016487742541357875\n",
      "Epoch 1202, Loss: 0.0057409286964684725, Final Batch Loss: 0.002081710146740079\n",
      "Epoch 1203, Loss: 0.007623081561177969, Final Batch Loss: 0.0019376026466488838\n",
      "Epoch 1204, Loss: 0.008891253266483545, Final Batch Loss: 0.0009675710462033749\n",
      "Epoch 1205, Loss: 0.00777821964584291, Final Batch Loss: 0.0027327651623636484\n",
      "Epoch 1206, Loss: 0.008773402776569128, Final Batch Loss: 0.004315354395657778\n",
      "Epoch 1207, Loss: 0.034790292382240295, Final Batch Loss: 0.009477702900767326\n",
      "Epoch 1208, Loss: 0.008290210680570453, Final Batch Loss: 0.0006797336391173303\n",
      "Epoch 1209, Loss: 0.006584865273907781, Final Batch Loss: 0.0031119787599891424\n",
      "Epoch 1210, Loss: 0.017482299357652664, Final Batch Loss: 0.00950027909129858\n",
      "Epoch 1211, Loss: 0.004980503232218325, Final Batch Loss: 0.001628854894079268\n",
      "Epoch 1212, Loss: 0.04554808815009892, Final Batch Loss: 0.04175828769803047\n",
      "Epoch 1213, Loss: 0.0037800816353410482, Final Batch Loss: 0.0021945745684206486\n",
      "Epoch 1214, Loss: 0.009612259920686483, Final Batch Loss: 0.0047887172549963\n",
      "Epoch 1215, Loss: 0.0036588479997590184, Final Batch Loss: 0.0013655935181304812\n",
      "Epoch 1216, Loss: 0.007759417407214642, Final Batch Loss: 0.0042950669303536415\n",
      "Epoch 1217, Loss: 0.00559110171161592, Final Batch Loss: 0.004141666926443577\n",
      "Epoch 1218, Loss: 0.006329948315396905, Final Batch Loss: 0.0014063229318708181\n",
      "Epoch 1219, Loss: 0.008063598070293665, Final Batch Loss: 0.003446148708462715\n",
      "Epoch 1220, Loss: 0.007187304552644491, Final Batch Loss: 0.002326639834791422\n",
      "Epoch 1221, Loss: 0.016145811299793422, Final Batch Loss: 0.014763932675123215\n",
      "Epoch 1222, Loss: 0.005726320203393698, Final Batch Loss: 0.004209122620522976\n",
      "Epoch 1223, Loss: 0.004203763557597995, Final Batch Loss: 0.0015077979769557714\n",
      "Epoch 1224, Loss: 0.01000420656055212, Final Batch Loss: 0.008044318296015263\n",
      "Epoch 1225, Loss: 0.011428602039813995, Final Batch Loss: 0.0054212999530136585\n",
      "Epoch 1226, Loss: 0.017989527201279998, Final Batch Loss: 0.01585877127945423\n",
      "Epoch 1227, Loss: 0.012959084007889032, Final Batch Loss: 0.003094180952757597\n",
      "Epoch 1228, Loss: 0.005960231181234121, Final Batch Loss: 0.003153406083583832\n",
      "Epoch 1229, Loss: 0.002141527715139091, Final Batch Loss: 0.0012079394655302167\n",
      "Epoch 1230, Loss: 0.005324290134012699, Final Batch Loss: 0.001166698057204485\n",
      "Epoch 1231, Loss: 0.028315904084593058, Final Batch Loss: 0.023275036364793777\n",
      "Epoch 1232, Loss: 0.009492325596511364, Final Batch Loss: 0.0066799200139939785\n",
      "Epoch 1233, Loss: 0.0037255773786455393, Final Batch Loss: 0.0019440028117969632\n",
      "Epoch 1234, Loss: 0.005640689516440034, Final Batch Loss: 0.004282071720808744\n",
      "Epoch 1235, Loss: 0.020834016613662243, Final Batch Loss: 0.01109076477587223\n",
      "Epoch 1236, Loss: 0.04415435530245304, Final Batch Loss: 0.026367725804448128\n",
      "Epoch 1237, Loss: 0.018209488363936543, Final Batch Loss: 0.0156822819262743\n",
      "Epoch 1238, Loss: 0.05278545059263706, Final Batch Loss: 0.04093841463327408\n",
      "Epoch 1239, Loss: 0.007502129301428795, Final Batch Loss: 0.004152498207986355\n",
      "Epoch 1240, Loss: 0.0058627225225791335, Final Batch Loss: 0.0013627050211653113\n",
      "Epoch 1241, Loss: 0.010253502056002617, Final Batch Loss: 0.006617516279220581\n",
      "Epoch 1242, Loss: 0.007477312698028982, Final Batch Loss: 0.0005321464268490672\n",
      "Epoch 1243, Loss: 0.013704291312023997, Final Batch Loss: 0.0004917436745017767\n",
      "Epoch 1244, Loss: 0.015056281350553036, Final Batch Loss: 0.005170435644686222\n",
      "Epoch 1245, Loss: 0.008708013454452157, Final Batch Loss: 0.0060294256545603275\n",
      "Epoch 1246, Loss: 0.02942945435643196, Final Batch Loss: 0.013082271441817284\n",
      "Epoch 1247, Loss: 0.029738516779616475, Final Batch Loss: 0.026510976254940033\n",
      "Epoch 1248, Loss: 0.02082123956643045, Final Batch Loss: 0.016949573531746864\n",
      "Epoch 1249, Loss: 0.02404103917069733, Final Batch Loss: 0.003819090547040105\n",
      "Epoch 1250, Loss: 0.015794862993061543, Final Batch Loss: 0.0032367417588829994\n",
      "Epoch 1251, Loss: 0.017808121629059315, Final Batch Loss: 0.012707349844276905\n",
      "Epoch 1252, Loss: 0.0061648208647966385, Final Batch Loss: 0.0036317259073257446\n",
      "Epoch 1253, Loss: 0.010408068541437387, Final Batch Loss: 0.0049254754558205605\n",
      "Epoch 1254, Loss: 0.01566920755431056, Final Batch Loss: 0.011340846307575703\n",
      "Epoch 1255, Loss: 0.005521250714082271, Final Batch Loss: 0.0005191586096771061\n",
      "Epoch 1256, Loss: 0.019608695642091334, Final Batch Loss: 0.0180153027176857\n",
      "Epoch 1257, Loss: 0.004533660132437944, Final Batch Loss: 0.0021084006875753403\n",
      "Epoch 1258, Loss: 0.007695619249716401, Final Batch Loss: 0.0059426696971058846\n",
      "Epoch 1259, Loss: 0.004269429948180914, Final Batch Loss: 0.001521579921245575\n",
      "Epoch 1260, Loss: 0.005827911081723869, Final Batch Loss: 0.0017393612070009112\n",
      "Epoch 1261, Loss: 0.03526565572246909, Final Batch Loss: 0.005454260390251875\n",
      "Epoch 1262, Loss: 0.006044935202226043, Final Batch Loss: 0.0033434899523854256\n",
      "Epoch 1263, Loss: 0.00667361100204289, Final Batch Loss: 0.0036949077621102333\n",
      "Epoch 1264, Loss: 0.017156360554508865, Final Batch Loss: 0.001057073357515037\n",
      "Epoch 1265, Loss: 0.014355063904076815, Final Batch Loss: 0.012405798770487309\n",
      "Epoch 1266, Loss: 0.002654601470567286, Final Batch Loss: 0.001114579732529819\n",
      "Epoch 1267, Loss: 0.01385399090941064, Final Batch Loss: 0.00041803947533480823\n",
      "Epoch 1268, Loss: 0.004319142026361078, Final Batch Loss: 0.003577566472813487\n",
      "Epoch 1269, Loss: 0.024310444248840213, Final Batch Loss: 0.02175917662680149\n",
      "Epoch 1270, Loss: 0.03697025217115879, Final Batch Loss: 0.032254841178655624\n",
      "Epoch 1271, Loss: 0.018111488316208124, Final Batch Loss: 0.002530792262405157\n",
      "Epoch 1272, Loss: 0.007175840670242906, Final Batch Loss: 0.002243380295112729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1273, Loss: 0.01704843924380839, Final Batch Loss: 0.0023958750534802675\n",
      "Epoch 1274, Loss: 0.017858912469819188, Final Batch Loss: 0.0017117888201028109\n",
      "Epoch 1275, Loss: 0.01460533612407744, Final Batch Loss: 0.011429551988840103\n",
      "Epoch 1276, Loss: 0.00326897093327716, Final Batch Loss: 0.0004155629430897534\n",
      "Epoch 1277, Loss: 0.010792505461722612, Final Batch Loss: 0.009664003737270832\n",
      "Epoch 1278, Loss: 0.025735725997947156, Final Batch Loss: 0.02467178925871849\n",
      "Epoch 1279, Loss: 0.01163857290521264, Final Batch Loss: 0.007214898243546486\n",
      "Epoch 1280, Loss: 0.005091318394988775, Final Batch Loss: 0.0010559321381151676\n",
      "Epoch 1281, Loss: 0.016989510040730238, Final Batch Loss: 0.002595637459307909\n",
      "Epoch 1282, Loss: 0.006817559013143182, Final Batch Loss: 0.00313384085893631\n",
      "Epoch 1283, Loss: 0.009349308675155044, Final Batch Loss: 0.0028991757426410913\n",
      "Epoch 1284, Loss: 0.0042055819649249315, Final Batch Loss: 0.0012254309840500355\n",
      "Epoch 1285, Loss: 0.01292176591232419, Final Batch Loss: 0.003975472878664732\n",
      "Epoch 1286, Loss: 0.022680746391415596, Final Batch Loss: 0.006418855860829353\n",
      "Epoch 1287, Loss: 0.0047319220611825585, Final Batch Loss: 0.0028296182863414288\n",
      "Epoch 1288, Loss: 0.013435557950288057, Final Batch Loss: 0.009936275891959667\n",
      "Epoch 1289, Loss: 0.018486659042537212, Final Batch Loss: 0.01025276631116867\n",
      "Epoch 1290, Loss: 0.03026933316141367, Final Batch Loss: 0.028628725558519363\n",
      "Epoch 1291, Loss: 0.011213561287149787, Final Batch Loss: 0.0014919580426067114\n",
      "Epoch 1292, Loss: 0.00506279559340328, Final Batch Loss: 0.0012166207889094949\n",
      "Epoch 1293, Loss: 0.01123574294615537, Final Batch Loss: 0.0017163670854642987\n",
      "Epoch 1294, Loss: 0.007393504027277231, Final Batch Loss: 0.0024571670219302177\n",
      "Epoch 1295, Loss: 0.0055590152041986585, Final Batch Loss: 0.004233689978718758\n",
      "Epoch 1296, Loss: 0.012405966641381383, Final Batch Loss: 0.00949671771377325\n",
      "Epoch 1297, Loss: 0.011842063628137112, Final Batch Loss: 0.0033327750861644745\n",
      "Epoch 1298, Loss: 0.011321976315230131, Final Batch Loss: 0.006983660627156496\n",
      "Epoch 1299, Loss: 0.006598808919079602, Final Batch Loss: 0.004697440192103386\n",
      "Epoch 1300, Loss: 0.0030976865673437715, Final Batch Loss: 0.001752141979523003\n",
      "Epoch 1301, Loss: 0.00461241917219013, Final Batch Loss: 0.0010485308011993766\n",
      "Epoch 1302, Loss: 0.006395253585651517, Final Batch Loss: 0.002477627946063876\n",
      "Epoch 1303, Loss: 0.01705755409784615, Final Batch Loss: 0.01510685496032238\n",
      "Epoch 1304, Loss: 0.004460014752112329, Final Batch Loss: 0.000878911348991096\n",
      "Epoch 1305, Loss: 0.003794288611970842, Final Batch Loss: 0.0013278842670843005\n",
      "Epoch 1306, Loss: 0.002671837981324643, Final Batch Loss: 0.0006919598090462387\n",
      "Epoch 1307, Loss: 0.009813169948756695, Final Batch Loss: 0.005412652622908354\n",
      "Epoch 1308, Loss: 0.0063637003768235445, Final Batch Loss: 0.0024448672775179148\n",
      "Epoch 1309, Loss: 0.006831108883488923, Final Batch Loss: 0.0005244932253845036\n",
      "Epoch 1310, Loss: 0.0007713786617387086, Final Batch Loss: 0.00031914300052449107\n",
      "Epoch 1311, Loss: 0.005829475005157292, Final Batch Loss: 0.0014304855139926076\n",
      "Epoch 1312, Loss: 0.02195439243223518, Final Batch Loss: 0.02066539041697979\n",
      "Epoch 1313, Loss: 0.02889489009976387, Final Batch Loss: 0.015549072995781898\n",
      "Epoch 1314, Loss: 0.0070205588126555085, Final Batch Loss: 0.005279066506773233\n",
      "Epoch 1315, Loss: 0.003997283987700939, Final Batch Loss: 0.001463920809328556\n",
      "Epoch 1316, Loss: 0.0037951068370603025, Final Batch Loss: 0.0007358395378105342\n",
      "Epoch 1317, Loss: 0.005977352615445852, Final Batch Loss: 0.004392798990011215\n",
      "Epoch 1318, Loss: 0.03957284800708294, Final Batch Loss: 0.005011329427361488\n",
      "Epoch 1319, Loss: 0.005569358938373625, Final Batch Loss: 0.004758500959724188\n",
      "Epoch 1320, Loss: 0.007025279337540269, Final Batch Loss: 0.0037651886232197285\n",
      "Epoch 1321, Loss: 0.0046970287803560495, Final Batch Loss: 0.00231538200750947\n",
      "Epoch 1322, Loss: 0.02899150608573109, Final Batch Loss: 0.0005737288156524301\n",
      "Epoch 1323, Loss: 0.011051411624066532, Final Batch Loss: 0.009710744954645634\n",
      "Epoch 1324, Loss: 0.005253774696029723, Final Batch Loss: 0.000600778148509562\n",
      "Epoch 1325, Loss: 0.004479213850572705, Final Batch Loss: 0.0017376462928950787\n",
      "Epoch 1326, Loss: 0.046886398922652006, Final Batch Loss: 0.04010539874434471\n",
      "Epoch 1327, Loss: 0.005360405193641782, Final Batch Loss: 0.003668263554573059\n",
      "Epoch 1328, Loss: 0.0018350658938288689, Final Batch Loss: 0.000609144801273942\n",
      "Epoch 1329, Loss: 0.0033954784739762545, Final Batch Loss: 0.000683206832036376\n",
      "Epoch 1330, Loss: 0.006011355435475707, Final Batch Loss: 0.005198720842599869\n",
      "Epoch 1331, Loss: 0.004554378800094128, Final Batch Loss: 0.0021870769560337067\n",
      "Epoch 1332, Loss: 0.017481574090197682, Final Batch Loss: 0.015212275087833405\n",
      "Epoch 1333, Loss: 0.009150507627055049, Final Batch Loss: 0.0011254732962697744\n",
      "Epoch 1334, Loss: 0.002770584891550243, Final Batch Loss: 0.0005075355293229222\n",
      "Epoch 1335, Loss: 0.012275955639779568, Final Batch Loss: 0.0027586650103330612\n",
      "Epoch 1336, Loss: 0.008086013374850154, Final Batch Loss: 0.003297672374173999\n",
      "Epoch 1337, Loss: 0.012576671550050378, Final Batch Loss: 0.001425579423084855\n",
      "Epoch 1338, Loss: 0.006680868566036224, Final Batch Loss: 0.003278123214840889\n",
      "Epoch 1339, Loss: 0.0016348985955119133, Final Batch Loss: 0.0008829720318317413\n",
      "Epoch 1340, Loss: 0.008062342065386474, Final Batch Loss: 0.00676488783210516\n",
      "Epoch 1341, Loss: 0.005518791382201016, Final Batch Loss: 0.0014978937106207013\n",
      "Epoch 1342, Loss: 0.01239865436218679, Final Batch Loss: 0.011286227963864803\n",
      "Epoch 1343, Loss: 0.0027457213727757335, Final Batch Loss: 0.0017326859524473548\n",
      "Epoch 1344, Loss: 0.004290310374926776, Final Batch Loss: 0.0034301860723644495\n",
      "Epoch 1345, Loss: 0.023204811848700047, Final Batch Loss: 0.015590768307447433\n",
      "Epoch 1346, Loss: 0.0031742078717797995, Final Batch Loss: 0.0014939579414203763\n",
      "Epoch 1347, Loss: 0.0031837327987886965, Final Batch Loss: 0.0009697122150100768\n",
      "Epoch 1348, Loss: 0.0033359841909259558, Final Batch Loss: 0.002206838224083185\n",
      "Epoch 1349, Loss: 0.002550062257796526, Final Batch Loss: 0.0015659050550311804\n",
      "Epoch 1350, Loss: 0.0026040547527372837, Final Batch Loss: 0.0015201438218355179\n",
      "Epoch 1351, Loss: 0.0023236842826008797, Final Batch Loss: 0.0012369895121082664\n",
      "Epoch 1352, Loss: 0.0035702764289453626, Final Batch Loss: 0.0018040832364931703\n",
      "Epoch 1353, Loss: 0.014165674452669919, Final Batch Loss: 0.0129878930747509\n",
      "Epoch 1354, Loss: 0.005713265156373382, Final Batch Loss: 0.0005758891347795725\n",
      "Epoch 1355, Loss: 0.003065437194891274, Final Batch Loss: 0.0013738184934481978\n",
      "Epoch 1356, Loss: 0.0023949191090650856, Final Batch Loss: 0.0008772131404839456\n",
      "Epoch 1357, Loss: 0.0024382704286836088, Final Batch Loss: 0.0016547595150768757\n",
      "Epoch 1358, Loss: 0.003187292139045894, Final Batch Loss: 0.002966715022921562\n",
      "Epoch 1359, Loss: 0.007977639441378415, Final Batch Loss: 0.006573700811713934\n",
      "Epoch 1360, Loss: 0.007300367811694741, Final Batch Loss: 0.005833158269524574\n",
      "Epoch 1361, Loss: 0.0083931190893054, Final Batch Loss: 0.007213232573121786\n",
      "Epoch 1362, Loss: 0.006708381348289549, Final Batch Loss: 0.0015735692577436566\n",
      "Epoch 1363, Loss: 0.0019511517020873725, Final Batch Loss: 0.0011670193634927273\n",
      "Epoch 1364, Loss: 0.028162582777440548, Final Batch Loss: 0.018976420164108276\n",
      "Epoch 1365, Loss: 0.006401007296517491, Final Batch Loss: 0.004592851269990206\n",
      "Epoch 1366, Loss: 0.0021292202873155475, Final Batch Loss: 0.0013176285428926349\n",
      "Epoch 1367, Loss: 0.008669802453368902, Final Batch Loss: 0.006875279825180769\n",
      "Epoch 1368, Loss: 0.005518097605090588, Final Batch Loss: 0.004810417536646128\n",
      "Epoch 1369, Loss: 0.006946891197003424, Final Batch Loss: 0.005733061116188765\n",
      "Epoch 1370, Loss: 0.0048829864244908094, Final Batch Loss: 0.0019592358730733395\n",
      "Epoch 1371, Loss: 0.014734464697539806, Final Batch Loss: 0.00890578143298626\n",
      "Epoch 1372, Loss: 0.006319687585346401, Final Batch Loss: 0.005224056076258421\n",
      "Epoch 1373, Loss: 0.004076611716300249, Final Batch Loss: 0.001044596079736948\n",
      "Epoch 1374, Loss: 0.005305491271428764, Final Batch Loss: 0.0018967901123687625\n",
      "Epoch 1375, Loss: 0.019455193600151688, Final Batch Loss: 0.019145719707012177\n",
      "Epoch 1376, Loss: 0.014720937702804804, Final Batch Loss: 0.005154414568096399\n",
      "Epoch 1377, Loss: 0.0034970620181411505, Final Batch Loss: 0.0009420074056833982\n",
      "Epoch 1378, Loss: 0.03197182645089924, Final Batch Loss: 0.02873365581035614\n",
      "Epoch 1379, Loss: 0.02600463293492794, Final Batch Loss: 0.0128588592633605\n",
      "Epoch 1380, Loss: 0.004391360242152587, Final Batch Loss: 0.00041910322033800185\n",
      "Epoch 1381, Loss: 0.0017948384629562497, Final Batch Loss: 0.001026512123644352\n",
      "Epoch 1382, Loss: 0.01673212117748335, Final Batch Loss: 0.016420826315879822\n",
      "Epoch 1383, Loss: 0.008807656355202198, Final Batch Loss: 0.004758389666676521\n",
      "Epoch 1384, Loss: 0.010112322284840047, Final Batch Loss: 0.0007367640500888228\n",
      "Epoch 1385, Loss: 0.012306491029448807, Final Batch Loss: 0.01053848210722208\n",
      "Epoch 1386, Loss: 0.00452463561668992, Final Batch Loss: 0.0038946194108575583\n",
      "Epoch 1387, Loss: 0.011435193242505193, Final Batch Loss: 0.009806760586798191\n",
      "Epoch 1388, Loss: 0.004905438516288996, Final Batch Loss: 0.003295506350696087\n",
      "Epoch 1389, Loss: 0.018327226396650076, Final Batch Loss: 0.01726977713406086\n",
      "Epoch 1390, Loss: 0.002570384996943176, Final Batch Loss: 0.0012030057841911912\n",
      "Epoch 1391, Loss: 0.004466888960450888, Final Batch Loss: 0.0016890864353626966\n",
      "Epoch 1392, Loss: 0.0020763176726177335, Final Batch Loss: 0.0013680969132110476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1393, Loss: 0.0038837760221213102, Final Batch Loss: 0.0010547919664531946\n",
      "Epoch 1394, Loss: 0.004163441015407443, Final Batch Loss: 0.003518987214192748\n",
      "Epoch 1395, Loss: 0.003770697512663901, Final Batch Loss: 0.0013254621298983693\n",
      "Epoch 1396, Loss: 0.007296469062566757, Final Batch Loss: 0.0011377902701497078\n",
      "Epoch 1397, Loss: 0.03405904857208952, Final Batch Loss: 0.0009000831632874906\n",
      "Epoch 1398, Loss: 0.0016466876259073615, Final Batch Loss: 0.000650200410746038\n",
      "Epoch 1399, Loss: 0.002261625020764768, Final Batch Loss: 0.0013059981865808368\n",
      "Epoch 1400, Loss: 0.004022186680231243, Final Batch Loss: 0.0009519463055767119\n",
      "Epoch 1401, Loss: 0.006832773797214031, Final Batch Loss: 0.0014635068364441395\n",
      "Epoch 1402, Loss: 0.005156047060154378, Final Batch Loss: 0.0009675616165623069\n",
      "Epoch 1403, Loss: 0.013835180550813675, Final Batch Loss: 0.001100161112844944\n",
      "Epoch 1404, Loss: 0.004080374143086374, Final Batch Loss: 0.0014557758113369346\n",
      "Epoch 1405, Loss: 0.002154240559320897, Final Batch Loss: 0.0014494414208456874\n",
      "Epoch 1406, Loss: 0.0015656022587791085, Final Batch Loss: 0.0008122588624246418\n",
      "Epoch 1407, Loss: 0.00899426604155451, Final Batch Loss: 0.000864144996739924\n",
      "Epoch 1408, Loss: 0.005170166492462158, Final Batch Loss: 0.0015068918000906706\n",
      "Epoch 1409, Loss: 0.012226639781147242, Final Batch Loss: 0.003945622127503157\n",
      "Epoch 1410, Loss: 0.005146683382918127, Final Batch Loss: 0.00021347003348637372\n",
      "Epoch 1411, Loss: 0.005055059096775949, Final Batch Loss: 0.003220674581825733\n",
      "Epoch 1412, Loss: 0.0021284538670443, Final Batch Loss: 0.0001914090826176107\n",
      "Epoch 1413, Loss: 0.0033101265435107052, Final Batch Loss: 0.0002995795221067965\n",
      "Epoch 1414, Loss: 0.003955018444685265, Final Batch Loss: 0.0037048994563519955\n",
      "Epoch 1415, Loss: 0.003403062408324331, Final Batch Loss: 0.0028624359983950853\n",
      "Epoch 1416, Loss: 0.0032211424550041556, Final Batch Loss: 0.0017298776656389236\n",
      "Epoch 1417, Loss: 0.0024066720507107675, Final Batch Loss: 0.0015876165125519037\n",
      "Epoch 1418, Loss: 0.001504850690253079, Final Batch Loss: 0.0006305263377726078\n",
      "Epoch 1419, Loss: 0.021399944089353085, Final Batch Loss: 0.009693922474980354\n",
      "Epoch 1420, Loss: 0.003175656544044614, Final Batch Loss: 0.0019153007306158543\n",
      "Epoch 1421, Loss: 0.006534741958603263, Final Batch Loss: 0.005199699196964502\n",
      "Epoch 1422, Loss: 0.002020921849180013, Final Batch Loss: 0.001465433742851019\n",
      "Epoch 1423, Loss: 0.0010356763959862292, Final Batch Loss: 0.0004533093306235969\n",
      "Epoch 1424, Loss: 0.01195573399309069, Final Batch Loss: 0.01110747642815113\n",
      "Epoch 1425, Loss: 0.002248109201900661, Final Batch Loss: 0.0010184149723500013\n",
      "Epoch 1426, Loss: 0.002078242221614346, Final Batch Loss: 0.00028536011814139783\n",
      "Epoch 1427, Loss: 0.009916226146742702, Final Batch Loss: 0.0005103105213493109\n",
      "Epoch 1428, Loss: 0.0033917315886355937, Final Batch Loss: 0.0005279395845718682\n",
      "Epoch 1429, Loss: 0.007419173663947731, Final Batch Loss: 0.0006494755507446826\n",
      "Epoch 1430, Loss: 0.005530891939997673, Final Batch Loss: 0.004101959988474846\n",
      "Epoch 1431, Loss: 0.004665196524001658, Final Batch Loss: 0.0010470085544511676\n",
      "Epoch 1432, Loss: 0.0032277557183988392, Final Batch Loss: 0.0024352730251848698\n",
      "Epoch 1433, Loss: 0.0008926503360271454, Final Batch Loss: 0.0004662183637265116\n",
      "Epoch 1434, Loss: 0.006631557829678059, Final Batch Loss: 0.0011971984058618546\n",
      "Epoch 1435, Loss: 0.01045907277148217, Final Batch Loss: 0.009065507911145687\n",
      "Epoch 1436, Loss: 0.004982977174222469, Final Batch Loss: 0.004126989282667637\n",
      "Epoch 1437, Loss: 0.0020042870310135186, Final Batch Loss: 0.0008418041397817433\n",
      "Epoch 1438, Loss: 0.0026268999790772796, Final Batch Loss: 0.002196356886997819\n",
      "Epoch 1439, Loss: 0.01819797232747078, Final Batch Loss: 0.013963250443339348\n",
      "Epoch 1440, Loss: 0.0026045131380669773, Final Batch Loss: 0.0007746471674181521\n",
      "Epoch 1441, Loss: 0.0011326046660542488, Final Batch Loss: 0.0005672129918821156\n",
      "Epoch 1442, Loss: 0.0036487618926912546, Final Batch Loss: 0.0014958260580897331\n",
      "Epoch 1443, Loss: 0.0029386067180894315, Final Batch Loss: 0.002172314329072833\n",
      "Epoch 1444, Loss: 0.018675494473427534, Final Batch Loss: 0.014200982637703419\n",
      "Epoch 1445, Loss: 0.007446204544976354, Final Batch Loss: 0.004670312628149986\n",
      "Epoch 1446, Loss: 0.0017521199770271778, Final Batch Loss: 0.000347810797393322\n",
      "Epoch 1447, Loss: 0.0027210687985643744, Final Batch Loss: 0.001125345123000443\n",
      "Epoch 1448, Loss: 0.0023190693464130163, Final Batch Loss: 0.001607508398592472\n",
      "Epoch 1449, Loss: 0.012747940141707659, Final Batch Loss: 0.00766974501311779\n",
      "Epoch 1450, Loss: 0.0038819439942017198, Final Batch Loss: 0.0012483192840591073\n",
      "Epoch 1451, Loss: 0.003768999478779733, Final Batch Loss: 0.0020686343777924776\n",
      "Epoch 1452, Loss: 0.024252877105027437, Final Batch Loss: 0.0061751180328428745\n",
      "Epoch 1453, Loss: 0.002956615760922432, Final Batch Loss: 0.0006129611283540726\n",
      "Epoch 1454, Loss: 0.0021915044053457677, Final Batch Loss: 0.0015742830000817776\n",
      "Epoch 1455, Loss: 0.0021515880653169006, Final Batch Loss: 0.0019453755812719464\n",
      "Epoch 1456, Loss: 0.005152541270945221, Final Batch Loss: 0.004503810312598944\n",
      "Epoch 1457, Loss: 0.025493291846942157, Final Batch Loss: 0.024929678067564964\n",
      "Epoch 1458, Loss: 0.0028647379076573998, Final Batch Loss: 0.0023813650477677584\n",
      "Epoch 1459, Loss: 0.002010819793213159, Final Batch Loss: 0.0005621212185360491\n",
      "Epoch 1460, Loss: 0.015347476350143552, Final Batch Loss: 0.012568105943500996\n",
      "Epoch 1461, Loss: 0.0226122522726655, Final Batch Loss: 0.011522755026817322\n",
      "Epoch 1462, Loss: 0.005360834999009967, Final Batch Loss: 0.0025021578185260296\n",
      "Epoch 1463, Loss: 0.0035378989996388555, Final Batch Loss: 0.0006448758067563176\n",
      "Epoch 1464, Loss: 0.0017279241001233459, Final Batch Loss: 0.001156582497060299\n",
      "Epoch 1465, Loss: 0.002332830394152552, Final Batch Loss: 0.0006691333255730569\n",
      "Epoch 1466, Loss: 0.011395719484426081, Final Batch Loss: 0.01069796271622181\n",
      "Epoch 1467, Loss: 0.0011273994896328077, Final Batch Loss: 0.0008905419381335378\n",
      "Epoch 1468, Loss: 0.00204712973209098, Final Batch Loss: 0.0004969237488694489\n",
      "Epoch 1469, Loss: 0.007263607578352094, Final Batch Loss: 0.0010434144642204046\n",
      "Epoch 1470, Loss: 0.0004716796684078872, Final Batch Loss: 0.00011827345588244498\n",
      "Epoch 1471, Loss: 0.012193754082545638, Final Batch Loss: 0.0011707113590091467\n",
      "Epoch 1472, Loss: 0.00232772744493559, Final Batch Loss: 0.0009648575796745718\n",
      "Epoch 1473, Loss: 0.030947129242122173, Final Batch Loss: 0.0044583166018128395\n",
      "Epoch 1474, Loss: 0.006570557277882472, Final Batch Loss: 0.006175811402499676\n",
      "Epoch 1475, Loss: 0.006266930780839175, Final Batch Loss: 0.005414916202425957\n",
      "Epoch 1476, Loss: 0.003675911109894514, Final Batch Loss: 0.0009780789259821177\n",
      "Epoch 1477, Loss: 0.00047296030970755965, Final Batch Loss: 9.175193554256111e-05\n",
      "Epoch 1478, Loss: 0.0030752295861020684, Final Batch Loss: 0.002038206672295928\n",
      "Epoch 1479, Loss: 0.017412718385457993, Final Batch Loss: 0.009186056442558765\n",
      "Epoch 1480, Loss: 0.008703294559381902, Final Batch Loss: 0.00015724857803434134\n",
      "Epoch 1481, Loss: 0.009212126024067402, Final Batch Loss: 0.0034942878410220146\n",
      "Epoch 1482, Loss: 0.009949677507393062, Final Batch Loss: 0.008103744126856327\n",
      "Epoch 1483, Loss: 0.003089842648478225, Final Batch Loss: 0.00018152085249312222\n",
      "Epoch 1484, Loss: 0.009603556478396058, Final Batch Loss: 0.007473545148968697\n",
      "Epoch 1485, Loss: 0.010219440344371833, Final Batch Loss: 0.00016386668721679598\n",
      "Epoch 1486, Loss: 0.0039761112711858, Final Batch Loss: 0.003659759648144245\n",
      "Epoch 1487, Loss: 0.003628958249464631, Final Batch Loss: 0.0019493263680487871\n",
      "Epoch 1488, Loss: 0.0025680920225568116, Final Batch Loss: 0.0015918874414637685\n",
      "Epoch 1489, Loss: 0.016110950615257025, Final Batch Loss: 0.01272683683782816\n",
      "Epoch 1490, Loss: 0.0021110352827236056, Final Batch Loss: 0.0007156309438869357\n",
      "Epoch 1491, Loss: 0.0028332825750112534, Final Batch Loss: 0.0012582311173900962\n",
      "Epoch 1492, Loss: 0.0031134807504713535, Final Batch Loss: 0.0013586119748651981\n",
      "Epoch 1493, Loss: 0.011560935992747545, Final Batch Loss: 0.005842351354658604\n",
      "Epoch 1494, Loss: 0.003508202382363379, Final Batch Loss: 0.0023827089462429285\n",
      "Epoch 1495, Loss: 0.0023767822713125497, Final Batch Loss: 0.00018464637105353177\n",
      "Epoch 1496, Loss: 0.030324200924951583, Final Batch Loss: 0.029837893322110176\n",
      "Epoch 1497, Loss: 0.03782226983457804, Final Batch Loss: 0.037425894290208817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1498, Loss: 0.0060297119198367, Final Batch Loss: 0.004118453711271286\n",
      "Epoch 1499, Loss: 0.012626239913515747, Final Batch Loss: 0.0014326608506962657\n",
      "Epoch 1500, Loss: 0.008563391165807843, Final Batch Loss: 0.0023798008915036917\n",
      "Epoch 1501, Loss: 0.042407851899042726, Final Batch Loss: 0.04062214866280556\n",
      "Epoch 1502, Loss: 0.0020901133539155126, Final Batch Loss: 0.0004822822520509362\n",
      "Epoch 1503, Loss: 0.007633476692717522, Final Batch Loss: 0.006965680047869682\n",
      "Epoch 1504, Loss: 0.0030919779965188354, Final Batch Loss: 0.00028478316380642354\n",
      "Epoch 1505, Loss: 0.014303885109256953, Final Batch Loss: 0.0008042740519158542\n",
      "Epoch 1506, Loss: 0.01318495359737426, Final Batch Loss: 0.011357555165886879\n",
      "Epoch 1507, Loss: 0.008035588078200817, Final Batch Loss: 0.006910920143127441\n",
      "Epoch 1508, Loss: 0.0013422388001345098, Final Batch Loss: 0.00010879436740651727\n",
      "Epoch 1509, Loss: 0.005906063597649336, Final Batch Loss: 0.0031499494798481464\n",
      "Epoch 1510, Loss: 0.009833458694629371, Final Batch Loss: 0.0014477287186309695\n",
      "Epoch 1511, Loss: 0.002308592083863914, Final Batch Loss: 0.0017915214411914349\n",
      "Epoch 1512, Loss: 0.0038127650041133165, Final Batch Loss: 0.0021130754612386227\n",
      "Epoch 1513, Loss: 0.03958501515444368, Final Batch Loss: 0.0388394333422184\n",
      "Epoch 1514, Loss: 0.006003668066114187, Final Batch Loss: 0.004940989892929792\n",
      "Epoch 1515, Loss: 0.009381362120620906, Final Batch Loss: 0.008044145070016384\n",
      "Epoch 1516, Loss: 0.002548196178395301, Final Batch Loss: 0.0018353973282501101\n",
      "Epoch 1517, Loss: 0.019775678869336843, Final Batch Loss: 0.004413094837218523\n",
      "Epoch 1518, Loss: 0.004884720328846015, Final Batch Loss: 0.00019985206017736346\n",
      "Epoch 1519, Loss: 0.001203809370053932, Final Batch Loss: 0.0008480452816002071\n",
      "Epoch 1520, Loss: 0.010462693695444614, Final Batch Loss: 0.0004921777290292084\n",
      "Epoch 1521, Loss: 0.01630602905061096, Final Batch Loss: 0.015348154120147228\n",
      "Epoch 1522, Loss: 0.005533550283871591, Final Batch Loss: 0.0009850383503362536\n",
      "Epoch 1523, Loss: 0.001454819634091109, Final Batch Loss: 0.0009387307800352573\n",
      "Epoch 1524, Loss: 0.003204118344001472, Final Batch Loss: 0.0016558219213038683\n",
      "Epoch 1525, Loss: 0.006254039006307721, Final Batch Loss: 0.002825559349730611\n",
      "Epoch 1526, Loss: 0.0044653833610937, Final Batch Loss: 0.0013388242805376649\n",
      "Epoch 1527, Loss: 0.009058512514457107, Final Batch Loss: 0.006921508815139532\n",
      "Epoch 1528, Loss: 0.0023415187606588006, Final Batch Loss: 0.0012396328384056687\n",
      "Epoch 1529, Loss: 0.009139245841652155, Final Batch Loss: 0.006173593457788229\n",
      "Epoch 1530, Loss: 0.01091730350162834, Final Batch Loss: 0.001556545845232904\n",
      "Epoch 1531, Loss: 0.0026274261181242764, Final Batch Loss: 0.0005520026315934956\n",
      "Epoch 1532, Loss: 0.0011110965278930962, Final Batch Loss: 0.0003203097730875015\n",
      "Epoch 1533, Loss: 0.008266786928288639, Final Batch Loss: 0.0013566728448495269\n",
      "Epoch 1534, Loss: 0.004292808938771486, Final Batch Loss: 0.002159971510991454\n",
      "Epoch 1535, Loss: 0.009062201133929193, Final Batch Loss: 0.00785134918987751\n",
      "Epoch 1536, Loss: 0.002201227529440075, Final Batch Loss: 0.0014576367102563381\n",
      "Epoch 1537, Loss: 0.0022685564472340047, Final Batch Loss: 0.0013914111768826842\n",
      "Epoch 1538, Loss: 0.011093599256128073, Final Batch Loss: 0.0026657874695956707\n",
      "Epoch 1539, Loss: 0.004603225504979491, Final Batch Loss: 0.002779873088002205\n",
      "Epoch 1540, Loss: 0.004675964824855328, Final Batch Loss: 0.0029406507965177298\n",
      "Epoch 1541, Loss: 0.0056198342790594324, Final Batch Loss: 0.00017603217565920204\n",
      "Epoch 1542, Loss: 0.0021978834411129355, Final Batch Loss: 0.0014218917349353433\n",
      "Epoch 1543, Loss: 0.002171142608858645, Final Batch Loss: 0.0015367186861112714\n",
      "Epoch 1544, Loss: 0.008742045058170334, Final Batch Loss: 0.0003387540637049824\n",
      "Epoch 1545, Loss: 0.0015984556230250746, Final Batch Loss: 0.0004872822028119117\n",
      "Epoch 1546, Loss: 0.002507176366634667, Final Batch Loss: 0.001132465898990631\n",
      "Epoch 1547, Loss: 0.0016929845442064106, Final Batch Loss: 0.0005219050799496472\n",
      "Epoch 1548, Loss: 0.0026022763922810555, Final Batch Loss: 0.0016646358417347074\n",
      "Epoch 1549, Loss: 0.0017858613282442093, Final Batch Loss: 0.0010227145394310355\n",
      "Epoch 1550, Loss: 0.0019511001592036337, Final Batch Loss: 0.0002902036940213293\n",
      "Epoch 1551, Loss: 0.002738191236858256, Final Batch Loss: 0.0002247290249215439\n",
      "Epoch 1552, Loss: 0.002257772721350193, Final Batch Loss: 0.00011447258293628693\n",
      "Epoch 1553, Loss: 0.0062232931377366185, Final Batch Loss: 0.0011362727964296937\n",
      "Epoch 1554, Loss: 0.003991100005805492, Final Batch Loss: 0.0028509192634373903\n",
      "Epoch 1555, Loss: 0.0024920717696659267, Final Batch Loss: 0.0017636785050854087\n",
      "Epoch 1556, Loss: 0.0008462249825242907, Final Batch Loss: 0.0006296285428106785\n",
      "Epoch 1557, Loss: 0.0021038072591181844, Final Batch Loss: 0.0016685744049027562\n",
      "Epoch 1558, Loss: 0.011783552123233676, Final Batch Loss: 0.010768525302410126\n",
      "Epoch 1559, Loss: 0.013889948604628444, Final Batch Loss: 0.0024980211164802313\n",
      "Epoch 1560, Loss: 0.025831090548308566, Final Batch Loss: 0.025365039706230164\n",
      "Epoch 1561, Loss: 0.019255972234532237, Final Batch Loss: 0.00296626309864223\n",
      "Epoch 1562, Loss: 0.0018441514112055302, Final Batch Loss: 0.0007953183958306909\n",
      "Epoch 1563, Loss: 0.004138469346798956, Final Batch Loss: 0.0012830625055357814\n",
      "Epoch 1564, Loss: 0.0028688531019724905, Final Batch Loss: 0.0006131830741651356\n",
      "Epoch 1565, Loss: 0.002035127079579979, Final Batch Loss: 0.0009696009219624102\n",
      "Epoch 1566, Loss: 0.00907844677567482, Final Batch Loss: 0.0015190592966973782\n",
      "Epoch 1567, Loss: 0.002378087374381721, Final Batch Loss: 0.00030536705162376165\n",
      "Epoch 1568, Loss: 0.0017174590902868658, Final Batch Loss: 0.00047601122059859335\n",
      "Epoch 1569, Loss: 0.000929115922190249, Final Batch Loss: 0.0004342715837992728\n",
      "Epoch 1570, Loss: 0.0036852628691121936, Final Batch Loss: 0.0013695067027583718\n",
      "Epoch 1571, Loss: 0.002442248456645757, Final Batch Loss: 0.0008817890775389969\n",
      "Epoch 1572, Loss: 0.005754635203629732, Final Batch Loss: 0.005470522213727236\n",
      "Epoch 1573, Loss: 0.022989447927102447, Final Batch Loss: 0.0032450517173856497\n",
      "Epoch 1574, Loss: 0.005321039818227291, Final Batch Loss: 0.0018030954524874687\n",
      "Epoch 1575, Loss: 0.0019826521165668964, Final Batch Loss: 0.0005426134448498487\n",
      "Epoch 1576, Loss: 0.0030972150852903724, Final Batch Loss: 0.0013204480055719614\n",
      "Epoch 1577, Loss: 0.003934332984499633, Final Batch Loss: 0.0019940270576626062\n",
      "Epoch 1578, Loss: 0.003038744442164898, Final Batch Loss: 0.0007623624987900257\n",
      "Epoch 1579, Loss: 0.0072891737800091505, Final Batch Loss: 0.0038693842943757772\n",
      "Epoch 1580, Loss: 0.00871950201690197, Final Batch Loss: 0.007150260731577873\n",
      "Epoch 1581, Loss: 0.0012052259407937527, Final Batch Loss: 0.000638853176496923\n",
      "Epoch 1582, Loss: 0.0016893578576855361, Final Batch Loss: 0.00016434065764769912\n",
      "Epoch 1583, Loss: 0.002249398559797555, Final Batch Loss: 0.0018155189463868737\n",
      "Epoch 1584, Loss: 0.023337258317042142, Final Batch Loss: 0.022901780903339386\n",
      "Epoch 1585, Loss: 0.001303146535065025, Final Batch Loss: 0.0003455922706052661\n",
      "Epoch 1586, Loss: 0.008148156572133303, Final Batch Loss: 0.005096722394227982\n",
      "Epoch 1587, Loss: 0.004675256786867976, Final Batch Loss: 0.0037691632751375437\n",
      "Epoch 1588, Loss: 0.012439818427083082, Final Batch Loss: 0.00018427551549393684\n",
      "Epoch 1589, Loss: 0.021660734142642468, Final Batch Loss: 0.02080242522060871\n",
      "Epoch 1590, Loss: 0.00925244006793946, Final Batch Loss: 0.00772882392629981\n",
      "Epoch 1591, Loss: 0.005505363456904888, Final Batch Loss: 0.0023916722275316715\n",
      "Epoch 1592, Loss: 0.012951720040291548, Final Batch Loss: 0.011249285191297531\n",
      "Epoch 1593, Loss: 0.006569166318513453, Final Batch Loss: 0.005583686754107475\n",
      "Epoch 1594, Loss: 0.004162174882367253, Final Batch Loss: 0.0004952871240675449\n",
      "Epoch 1595, Loss: 0.0036694258742500097, Final Batch Loss: 0.00041637037065811455\n",
      "Epoch 1596, Loss: 0.0023486341815441847, Final Batch Loss: 0.0010032212594524026\n",
      "Epoch 1597, Loss: 0.003630777122452855, Final Batch Loss: 0.0027749829459935427\n",
      "Epoch 1598, Loss: 0.004318122344557196, Final Batch Loss: 0.0006353923236019909\n",
      "Epoch 1599, Loss: 0.00541392934974283, Final Batch Loss: 0.003651150269433856\n",
      "Epoch 1600, Loss: 0.0027938038110733032, Final Batch Loss: 0.0011091901687905192\n",
      "Epoch 1601, Loss: 0.017241010384168476, Final Batch Loss: 0.0004064887179993093\n",
      "Epoch 1602, Loss: 0.002093443530611694, Final Batch Loss: 0.0007160246605053544\n",
      "Epoch 1603, Loss: 0.0021748607396148145, Final Batch Loss: 0.001466992311179638\n",
      "Epoch 1604, Loss: 0.002803088937071152, Final Batch Loss: 0.00011453621846158057\n",
      "Epoch 1605, Loss: 0.05254637566395104, Final Batch Loss: 0.0005103100556880236\n",
      "Epoch 1606, Loss: 0.009134450927376747, Final Batch Loss: 0.005990718025714159\n",
      "Epoch 1607, Loss: 0.0015294294280465692, Final Batch Loss: 0.0003147731476929039\n",
      "Epoch 1608, Loss: 0.003821705700829625, Final Batch Loss: 0.0013253455981612206\n",
      "Epoch 1609, Loss: 0.0032102999975904822, Final Batch Loss: 0.002062070881947875\n",
      "Epoch 1610, Loss: 0.003623630211222917, Final Batch Loss: 0.003376421984285116\n",
      "Epoch 1611, Loss: 0.003031208470929414, Final Batch Loss: 0.002302871784195304\n",
      "Epoch 1612, Loss: 0.0022648255398962647, Final Batch Loss: 0.00043914958951063454\n",
      "Epoch 1613, Loss: 0.0021253491286188364, Final Batch Loss: 0.001204894157126546\n",
      "Epoch 1614, Loss: 0.0009103150223381817, Final Batch Loss: 0.0006434804527089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1615, Loss: 0.006922403583303094, Final Batch Loss: 0.0007699860725551844\n",
      "Epoch 1616, Loss: 0.003663594019599259, Final Batch Loss: 0.0026237170677632093\n",
      "Epoch 1617, Loss: 0.004271476995199919, Final Batch Loss: 0.003768318798393011\n",
      "Epoch 1618, Loss: 0.0023355564335361123, Final Batch Loss: 0.0008985046297311783\n",
      "Epoch 1619, Loss: 0.01014592222054489, Final Batch Loss: 0.00038193169166333973\n",
      "Epoch 1620, Loss: 0.006309936987236142, Final Batch Loss: 0.005002724006772041\n",
      "Epoch 1621, Loss: 0.0015460750146303326, Final Batch Loss: 0.0012179078767076135\n",
      "Epoch 1622, Loss: 0.0018899039714597166, Final Batch Loss: 0.000609139387961477\n",
      "Epoch 1623, Loss: 0.0014597029075957835, Final Batch Loss: 0.0004930024733766913\n",
      "Epoch 1624, Loss: 0.0016386487404815853, Final Batch Loss: 0.0009621730423532426\n",
      "Epoch 1625, Loss: 0.0006890090589877218, Final Batch Loss: 0.00029834042652510107\n",
      "Epoch 1626, Loss: 0.00137393269687891, Final Batch Loss: 0.0005585142062045634\n",
      "Epoch 1627, Loss: 0.001900558519992046, Final Batch Loss: 0.0002302563952980563\n",
      "Epoch 1628, Loss: 0.0014511364861391485, Final Batch Loss: 0.0007098805508576334\n",
      "Epoch 1629, Loss: 0.010791760927531868, Final Batch Loss: 0.010158282704651356\n",
      "Epoch 1630, Loss: 0.00771225499920547, Final Batch Loss: 0.004428463522344828\n",
      "Epoch 1631, Loss: 0.003270358021836728, Final Batch Loss: 0.0004653671639971435\n",
      "Epoch 1632, Loss: 0.00379524496383965, Final Batch Loss: 0.0006131075788289309\n",
      "Epoch 1633, Loss: 0.017383784987032413, Final Batch Loss: 0.0010352423414587975\n",
      "Epoch 1634, Loss: 0.004409490851685405, Final Batch Loss: 0.0030116357374936342\n",
      "Epoch 1635, Loss: 0.004698997945524752, Final Batch Loss: 0.00338753336109221\n",
      "Epoch 1636, Loss: 0.002355850476305932, Final Batch Loss: 0.0013815825805068016\n",
      "Epoch 1637, Loss: 0.001746406895108521, Final Batch Loss: 0.0011899194214493036\n",
      "Epoch 1638, Loss: 0.0028045326907886192, Final Batch Loss: 0.0001823548664106056\n",
      "Epoch 1639, Loss: 0.004153612331720069, Final Batch Loss: 0.003813420422375202\n",
      "Epoch 1640, Loss: 0.002099357661791146, Final Batch Loss: 0.0008408119902014732\n",
      "Epoch 1641, Loss: 0.0011643540346994996, Final Batch Loss: 0.0006204615929163992\n",
      "Epoch 1642, Loss: 0.002787911333143711, Final Batch Loss: 0.00228476757183671\n",
      "Epoch 1643, Loss: 0.0006720938981743529, Final Batch Loss: 0.00018859402916859835\n",
      "Epoch 1644, Loss: 0.004828337579965591, Final Batch Loss: 0.002389852423220873\n",
      "Epoch 1645, Loss: 0.0015359270619228482, Final Batch Loss: 0.000654820236377418\n",
      "Epoch 1646, Loss: 0.007358201313763857, Final Batch Loss: 0.002103249542415142\n",
      "Epoch 1647, Loss: 0.0034252012555953115, Final Batch Loss: 0.002940729260444641\n",
      "Epoch 1648, Loss: 0.014109263764112256, Final Batch Loss: 0.00014217161515261978\n",
      "Epoch 1649, Loss: 0.002306121459696442, Final Batch Loss: 0.0006553542916662991\n",
      "Epoch 1650, Loss: 0.002099618664942682, Final Batch Loss: 0.0012159468606114388\n",
      "Epoch 1651, Loss: 0.0016281789285130799, Final Batch Loss: 0.0005913109635002911\n",
      "Epoch 1652, Loss: 0.003168353490764275, Final Batch Loss: 0.00269042095169425\n",
      "Epoch 1653, Loss: 0.0009041351586347446, Final Batch Loss: 0.00022273835202213377\n",
      "Epoch 1654, Loss: 0.002585806418210268, Final Batch Loss: 0.00145457882899791\n",
      "Epoch 1655, Loss: 0.0006016303086653352, Final Batch Loss: 0.00040399786666966975\n",
      "Epoch 1656, Loss: 0.003394710714928806, Final Batch Loss: 0.0011379501083865762\n",
      "Epoch 1657, Loss: 0.00045603133912663907, Final Batch Loss: 0.00024137122090905905\n",
      "Epoch 1658, Loss: 0.0019976439652964473, Final Batch Loss: 0.0009245213586837053\n",
      "Epoch 1659, Loss: 0.0007582702673971653, Final Batch Loss: 0.00038122443947941065\n",
      "Epoch 1660, Loss: 0.001493543473770842, Final Batch Loss: 0.0010543422540649772\n",
      "Epoch 1661, Loss: 0.0018880768911913037, Final Batch Loss: 0.0007689142366871238\n",
      "Epoch 1662, Loss: 0.001536347932415083, Final Batch Loss: 0.00033308289130218327\n",
      "Epoch 1663, Loss: 0.0014819214411545545, Final Batch Loss: 0.001293292618356645\n",
      "Epoch 1664, Loss: 0.0019513951265253127, Final Batch Loss: 0.000492371094878763\n",
      "Epoch 1665, Loss: 0.009230127223418094, Final Batch Loss: 0.0001234269147971645\n",
      "Epoch 1666, Loss: 0.00834775116527453, Final Batch Loss: 0.00019312609219923615\n",
      "Epoch 1667, Loss: 0.005449515418149531, Final Batch Loss: 0.0018376513617113233\n",
      "Epoch 1668, Loss: 0.00041782314656302333, Final Batch Loss: 0.0001588856684975326\n",
      "Epoch 1669, Loss: 0.001520590129075572, Final Batch Loss: 0.00026747348601929843\n",
      "Epoch 1670, Loss: 0.0019876084697898477, Final Batch Loss: 0.0016977123450487852\n",
      "Epoch 1671, Loss: 0.001641339622437954, Final Batch Loss: 0.0008217435097321868\n",
      "Epoch 1672, Loss: 0.018187549081631005, Final Batch Loss: 0.0014249031664803624\n",
      "Epoch 1673, Loss: 0.0019746776088140905, Final Batch Loss: 0.0005298370379023254\n",
      "Epoch 1674, Loss: 0.0011443092807894573, Final Batch Loss: 0.0009812999051064253\n",
      "Epoch 1675, Loss: 0.0016125826514326036, Final Batch Loss: 0.0006077968864701688\n",
      "Epoch 1676, Loss: 0.0033901052083820105, Final Batch Loss: 0.0018644450465217233\n",
      "Epoch 1677, Loss: 0.0007512567972298712, Final Batch Loss: 0.0003496878198347986\n",
      "Epoch 1678, Loss: 0.00257763615809381, Final Batch Loss: 0.0013255049707368016\n",
      "Epoch 1679, Loss: 0.003228467656299472, Final Batch Loss: 0.0015983254415914416\n",
      "Epoch 1680, Loss: 0.0025124840176431462, Final Batch Loss: 0.00013790039520245045\n",
      "Epoch 1681, Loss: 0.004351106705144048, Final Batch Loss: 0.002095089992508292\n",
      "Epoch 1682, Loss: 0.0014383224479388446, Final Batch Loss: 0.00042392450268380344\n",
      "Epoch 1683, Loss: 0.0034314232761971653, Final Batch Loss: 0.002970888279378414\n",
      "Epoch 1684, Loss: 0.0012664443056564778, Final Batch Loss: 0.00025209467275999486\n",
      "Epoch 1685, Loss: 0.0014257612056098878, Final Batch Loss: 0.000521007168572396\n",
      "Epoch 1686, Loss: 0.001652271836064756, Final Batch Loss: 0.0008169632055796683\n",
      "Epoch 1687, Loss: 0.0017784782103262842, Final Batch Loss: 0.0014176929835230112\n",
      "Epoch 1688, Loss: 0.05746940989047289, Final Batch Loss: 0.04935133829712868\n",
      "Epoch 1689, Loss: 0.0131631747353822, Final Batch Loss: 0.0027229285333305597\n",
      "Epoch 1690, Loss: 0.001970604236703366, Final Batch Loss: 0.0005335158784873784\n",
      "Epoch 1691, Loss: 0.0020466690184548497, Final Batch Loss: 0.0009511731332167983\n",
      "Epoch 1692, Loss: 0.0020023674587719142, Final Batch Loss: 0.001683644950389862\n",
      "Epoch 1693, Loss: 0.005359362461604178, Final Batch Loss: 0.0034133093431591988\n",
      "Epoch 1694, Loss: 0.0011567192850634456, Final Batch Loss: 0.0003944264608435333\n",
      "Epoch 1695, Loss: 0.010265103541314602, Final Batch Loss: 0.0025460878387093544\n",
      "Epoch 1696, Loss: 0.018842863850295544, Final Batch Loss: 0.015292303636670113\n",
      "Epoch 1697, Loss: 0.004639952094294131, Final Batch Loss: 0.0012704819673672318\n",
      "Epoch 1698, Loss: 0.0013739223504671827, Final Batch Loss: 0.00023345243243966252\n",
      "Epoch 1699, Loss: 0.024103830917738378, Final Batch Loss: 0.001107867225073278\n",
      "Epoch 1700, Loss: 0.0015426789759658277, Final Batch Loss: 0.0005650428938679397\n",
      "Epoch 1701, Loss: 0.0016350686200894415, Final Batch Loss: 0.0011209347285330296\n",
      "Epoch 1702, Loss: 0.0033473281655460596, Final Batch Loss: 0.00046346569433808327\n",
      "Epoch 1703, Loss: 0.022564634738955647, Final Batch Loss: 0.022003909572958946\n",
      "Epoch 1704, Loss: 0.0016563924436923116, Final Batch Loss: 0.0004254945961292833\n",
      "Epoch 1705, Loss: 0.00849262357223779, Final Batch Loss: 0.0008911482291296124\n",
      "Epoch 1706, Loss: 0.0037894505076110363, Final Batch Loss: 0.001423451118171215\n",
      "Epoch 1707, Loss: 0.002141955657862127, Final Batch Loss: 0.001777388621121645\n",
      "Epoch 1708, Loss: 0.010689963703043759, Final Batch Loss: 0.0013453607680276036\n",
      "Epoch 1709, Loss: 0.0006586232630070299, Final Batch Loss: 0.00038836002931930125\n",
      "Epoch 1710, Loss: 0.005737141007557511, Final Batch Loss: 0.002039998071268201\n",
      "Epoch 1711, Loss: 0.0060013801557943225, Final Batch Loss: 0.005936313420534134\n",
      "Epoch 1712, Loss: 0.00298898306209594, Final Batch Loss: 0.0014311562990769744\n",
      "Epoch 1713, Loss: 0.0016432992415502667, Final Batch Loss: 0.0008691751281730831\n",
      "Epoch 1714, Loss: 0.005585061822785065, Final Batch Loss: 0.005185853224247694\n",
      "Epoch 1715, Loss: 0.004312276840209961, Final Batch Loss: 0.001971170771867037\n",
      "Epoch 1716, Loss: 0.0023344867659034207, Final Batch Loss: 0.0001944392715813592\n",
      "Epoch 1717, Loss: 0.0012521305761765689, Final Batch Loss: 0.00032606811146251857\n",
      "Epoch 1718, Loss: 0.003858085081446916, Final Batch Loss: 0.0029303068295121193\n",
      "Epoch 1719, Loss: 0.0033595962449908257, Final Batch Loss: 0.00013322848826646805\n",
      "Epoch 1720, Loss: 0.003304328245576471, Final Batch Loss: 0.00040201557567343116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1721, Loss: 0.00236384040908888, Final Batch Loss: 0.0008204237674362957\n",
      "Epoch 1722, Loss: 0.006837259905296378, Final Batch Loss: 0.00017865972768049687\n",
      "Epoch 1723, Loss: 0.002222168470325414, Final Batch Loss: 8.423065446550027e-05\n",
      "Epoch 1724, Loss: 0.0057985594612546265, Final Batch Loss: 0.0002770501305349171\n",
      "Epoch 1725, Loss: 0.004641190287657082, Final Batch Loss: 0.001716057420708239\n",
      "Epoch 1726, Loss: 0.0003368751786183566, Final Batch Loss: 0.00014546654711011797\n",
      "Epoch 1727, Loss: 0.0016678156971465796, Final Batch Loss: 0.0003020234580617398\n",
      "Epoch 1728, Loss: 0.0020052404433954507, Final Batch Loss: 0.00027157182921655476\n",
      "Epoch 1729, Loss: 0.009454020706471056, Final Batch Loss: 0.0009564621723257005\n",
      "Epoch 1730, Loss: 0.007247689180076122, Final Batch Loss: 0.002561355009675026\n",
      "Epoch 1731, Loss: 0.001993689453229308, Final Batch Loss: 0.0010745362378656864\n",
      "Epoch 1732, Loss: 0.003159485408104956, Final Batch Loss: 0.0019282317953184247\n",
      "Epoch 1733, Loss: 0.008726933971047401, Final Batch Loss: 0.007609988562762737\n",
      "Epoch 1734, Loss: 0.0019420087337493896, Final Batch Loss: 0.0010127963032573462\n",
      "Epoch 1735, Loss: 0.002205747237894684, Final Batch Loss: 0.001385653973557055\n",
      "Epoch 1736, Loss: 0.0022465912043116987, Final Batch Loss: 0.0005154490354470909\n",
      "Epoch 1737, Loss: 0.002787202422041446, Final Batch Loss: 0.0005049079773016274\n",
      "Epoch 1738, Loss: 0.011387742008082569, Final Batch Loss: 0.0012666432885453105\n",
      "Epoch 1739, Loss: 0.0004056194593431428, Final Batch Loss: 0.0001890712301246822\n",
      "Epoch 1740, Loss: 0.00077139658969827, Final Batch Loss: 0.0005049488390795887\n",
      "Epoch 1741, Loss: 0.00204826972912997, Final Batch Loss: 0.0010051236022263765\n",
      "Epoch 1742, Loss: 0.0017436418565921485, Final Batch Loss: 0.0001930998987518251\n",
      "Epoch 1743, Loss: 0.006178404553793371, Final Batch Loss: 0.0010623069247230887\n",
      "Epoch 1744, Loss: 0.003145963419228792, Final Batch Loss: 0.0017843960085883737\n",
      "Epoch 1745, Loss: 0.008273089275462553, Final Batch Loss: 0.0004852106503676623\n",
      "Epoch 1746, Loss: 0.0025173263857141137, Final Batch Loss: 0.0012983824126422405\n",
      "Epoch 1747, Loss: 0.0010492636647541076, Final Batch Loss: 0.0006767611484974623\n",
      "Epoch 1748, Loss: 0.0006786788289900869, Final Batch Loss: 0.00012634749873541296\n",
      "Epoch 1749, Loss: 0.003797010926064104, Final Batch Loss: 0.0031229958403855562\n",
      "Epoch 1750, Loss: 0.0008876968058757484, Final Batch Loss: 0.0002328762784600258\n",
      "Epoch 1751, Loss: 0.005000089586246759, Final Batch Loss: 0.004229554440826178\n",
      "Epoch 1752, Loss: 0.002596674836240709, Final Batch Loss: 0.0010761249577626586\n",
      "Epoch 1753, Loss: 0.005804136395454407, Final Batch Loss: 0.0009606448002159595\n",
      "Epoch 1754, Loss: 0.011140148038975894, Final Batch Loss: 0.010109415277838707\n",
      "Epoch 1755, Loss: 0.002677525975741446, Final Batch Loss: 0.0011830355506390333\n",
      "Epoch 1756, Loss: 0.0008443408296443522, Final Batch Loss: 0.00013074884191155434\n",
      "Epoch 1757, Loss: 0.00316816900158301, Final Batch Loss: 0.002799906302243471\n",
      "Epoch 1758, Loss: 0.002654187032021582, Final Batch Loss: 0.0014930403558537364\n",
      "Epoch 1759, Loss: 0.0007586512801935896, Final Batch Loss: 0.0001893359440146014\n",
      "Epoch 1760, Loss: 0.0012090163654647768, Final Batch Loss: 0.000656028394587338\n",
      "Epoch 1761, Loss: 0.0157547959825024, Final Batch Loss: 0.0006699872901663184\n",
      "Epoch 1762, Loss: 0.0015303713153116405, Final Batch Loss: 0.0007927130209282041\n",
      "Epoch 1763, Loss: 0.0019420677272137254, Final Batch Loss: 0.00048442799015901983\n",
      "Epoch 1764, Loss: 0.0012601327034644783, Final Batch Loss: 0.0007015008595772088\n",
      "Epoch 1765, Loss: 0.001267059938982129, Final Batch Loss: 0.0001701179426163435\n",
      "Epoch 1766, Loss: 0.001453708900953643, Final Batch Loss: 0.00015894653915893286\n",
      "Epoch 1767, Loss: 0.0022723998117726296, Final Batch Loss: 0.0020118476822972298\n",
      "Epoch 1768, Loss: 0.019029403803870082, Final Batch Loss: 0.0024496137630194426\n",
      "Epoch 1769, Loss: 0.0014892519102431834, Final Batch Loss: 0.0006876730476506054\n",
      "Epoch 1770, Loss: 0.009918887910316698, Final Batch Loss: 0.00020257644064258784\n",
      "Epoch 1771, Loss: 0.017961054749321193, Final Batch Loss: 0.000803332484792918\n",
      "Epoch 1772, Loss: 0.0009058581636054441, Final Batch Loss: 0.0001770658855093643\n",
      "Epoch 1773, Loss: 0.0009645208192523569, Final Batch Loss: 0.0005718193133361638\n",
      "Epoch 1774, Loss: 0.0007437245512846857, Final Batch Loss: 0.0002748004626482725\n",
      "Epoch 1775, Loss: 0.001119726657634601, Final Batch Loss: 0.000771803199313581\n",
      "Epoch 1776, Loss: 0.002426545019261539, Final Batch Loss: 0.0013686037855222821\n",
      "Epoch 1777, Loss: 0.002510222722776234, Final Batch Loss: 0.0019091685535386205\n",
      "Epoch 1778, Loss: 0.013393070839811116, Final Batch Loss: 0.000350052781868726\n",
      "Epoch 1779, Loss: 0.03042016550898552, Final Batch Loss: 0.02260318584740162\n",
      "Epoch 1780, Loss: 0.0013053608126938343, Final Batch Loss: 0.0008917754166759551\n",
      "Epoch 1781, Loss: 0.0034472160623408854, Final Batch Loss: 0.0025354328099638224\n",
      "Epoch 1782, Loss: 0.002025573921855539, Final Batch Loss: 0.0016333471285179257\n",
      "Epoch 1783, Loss: 0.002139285788871348, Final Batch Loss: 0.0006091184914112091\n",
      "Epoch 1784, Loss: 0.002022238215431571, Final Batch Loss: 0.001163317821919918\n",
      "Epoch 1785, Loss: 0.0012339171662461013, Final Batch Loss: 0.00042697330354712903\n",
      "Epoch 1786, Loss: 0.002117059862939641, Final Batch Loss: 0.00031167789711616933\n",
      "Epoch 1787, Loss: 0.0045860306126996875, Final Batch Loss: 0.003391950624063611\n",
      "Epoch 1788, Loss: 0.007012236164882779, Final Batch Loss: 0.0010220843832939863\n",
      "Epoch 1789, Loss: 0.026983696210663766, Final Batch Loss: 0.0008632700773887336\n",
      "Epoch 1790, Loss: 0.001114574755774811, Final Batch Loss: 3.736760118044913e-05\n",
      "Epoch 1791, Loss: 0.002370131202042103, Final Batch Loss: 0.001517476630397141\n",
      "Epoch 1792, Loss: 0.013844345230609179, Final Batch Loss: 0.0062088253907859325\n",
      "Epoch 1793, Loss: 0.004702166304923594, Final Batch Loss: 0.001871338696219027\n",
      "Epoch 1794, Loss: 0.011549501563422382, Final Batch Loss: 0.01098453626036644\n",
      "Epoch 1795, Loss: 0.0008070585026871413, Final Batch Loss: 0.00026475542108528316\n",
      "Epoch 1796, Loss: 0.018747052643448114, Final Batch Loss: 0.00505121098831296\n",
      "Epoch 1797, Loss: 0.008378960425034165, Final Batch Loss: 0.007736254017800093\n",
      "Epoch 1798, Loss: 0.007567266002297401, Final Batch Loss: 0.002484044060111046\n",
      "Epoch 1799, Loss: 0.04799061839003116, Final Batch Loss: 0.04675022512674332\n",
      "Epoch 1800, Loss: 0.0018498629797250032, Final Batch Loss: 0.0007798534352332354\n",
      "Epoch 1801, Loss: 0.0011888747685588896, Final Batch Loss: 0.0005805092514492571\n",
      "Epoch 1802, Loss: 0.014374478836543858, Final Batch Loss: 0.013902128674089909\n",
      "Epoch 1803, Loss: 0.005941611714661121, Final Batch Loss: 0.004924992099404335\n",
      "Epoch 1804, Loss: 0.0019454643479548395, Final Batch Loss: 0.0008647156064398587\n",
      "Epoch 1805, Loss: 0.006539033609442413, Final Batch Loss: 0.0017303222557529807\n",
      "Epoch 1806, Loss: 0.0077405464835464954, Final Batch Loss: 0.004580199718475342\n",
      "Epoch 1807, Loss: 0.004491731175221503, Final Batch Loss: 0.003192245028913021\n",
      "Epoch 1808, Loss: 0.01656923850532621, Final Batch Loss: 0.014624587260186672\n",
      "Epoch 1809, Loss: 0.0014158744816086255, Final Batch Loss: 9.414707164978608e-05\n",
      "Epoch 1810, Loss: 0.004449112573638558, Final Batch Loss: 0.0022938933689147234\n",
      "Epoch 1811, Loss: 0.0007255465898197144, Final Batch Loss: 0.0002459734969306737\n",
      "Epoch 1812, Loss: 0.0024958436843007803, Final Batch Loss: 0.0017567216418683529\n",
      "Epoch 1813, Loss: 0.0069479255471378565, Final Batch Loss: 0.004992188420146704\n",
      "Epoch 1814, Loss: 0.0062217137310653925, Final Batch Loss: 0.004402034915983677\n",
      "Epoch 1815, Loss: 0.0026327550876885653, Final Batch Loss: 0.0016286565223708749\n",
      "Epoch 1816, Loss: 0.003045112593099475, Final Batch Loss: 0.0017673408146947622\n",
      "Epoch 1817, Loss: 0.004295933627872728, Final Batch Loss: 0.0001898744230857119\n",
      "Epoch 1818, Loss: 0.006851912650745362, Final Batch Loss: 0.0008348330738954246\n",
      "Epoch 1819, Loss: 0.0024275831528939307, Final Batch Loss: 0.0003697975189425051\n",
      "Epoch 1820, Loss: 0.0008760103664826602, Final Batch Loss: 0.0003122827911283821\n",
      "Epoch 1821, Loss: 0.0012283375835977495, Final Batch Loss: 0.0009446071344427764\n",
      "Epoch 1822, Loss: 0.009041456272825599, Final Batch Loss: 0.0008080925326794386\n",
      "Epoch 1823, Loss: 0.002735736547037959, Final Batch Loss: 0.00039721885696053505\n",
      "Epoch 1824, Loss: 0.014375820537679829, Final Batch Loss: 0.01429417822510004\n",
      "Epoch 1825, Loss: 0.002622100349981338, Final Batch Loss: 0.0009481700253672898\n",
      "Epoch 1826, Loss: 0.0005784321983810514, Final Batch Loss: 0.0001741785672493279\n",
      "Epoch 1827, Loss: 0.005351878586225212, Final Batch Loss: 0.0010569131700322032\n",
      "Epoch 1828, Loss: 0.0029071939061395824, Final Batch Loss: 0.00012493663234636188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1829, Loss: 0.0025658156373538077, Final Batch Loss: 0.0023255562409758568\n",
      "Epoch 1830, Loss: 0.006499997194623575, Final Batch Loss: 0.006248553283512592\n",
      "Epoch 1831, Loss: 0.0016509970737388358, Final Batch Loss: 0.001440123887732625\n",
      "Epoch 1832, Loss: 0.010342739813495427, Final Batch Loss: 0.0009567358647473156\n",
      "Epoch 1833, Loss: 0.002746971440501511, Final Batch Loss: 0.0017038012156262994\n",
      "Epoch 1834, Loss: 0.0012866397737525403, Final Batch Loss: 0.0006206586258485913\n",
      "Epoch 1835, Loss: 0.0013514814781956375, Final Batch Loss: 0.0011518009705469012\n",
      "Epoch 1836, Loss: 0.002999967080540955, Final Batch Loss: 0.001304035191424191\n",
      "Epoch 1837, Loss: 0.0013380354212131351, Final Batch Loss: 0.000276287755696103\n",
      "Epoch 1838, Loss: 0.0024341271491721272, Final Batch Loss: 0.0010547236306592822\n",
      "Epoch 1839, Loss: 0.0013102853554300964, Final Batch Loss: 7.898017065599561e-05\n",
      "Epoch 1840, Loss: 0.00041019151103682816, Final Batch Loss: 0.00017688149819150567\n",
      "Epoch 1841, Loss: 0.004826518284971826, Final Batch Loss: 0.0001796288852347061\n",
      "Epoch 1842, Loss: 0.0020788342808373272, Final Batch Loss: 0.001529707107692957\n",
      "Epoch 1843, Loss: 0.012280547816772014, Final Batch Loss: 0.0007567096618004143\n",
      "Epoch 1844, Loss: 0.0021329926094040275, Final Batch Loss: 0.0006567500531673431\n",
      "Epoch 1845, Loss: 0.0006419214478228241, Final Batch Loss: 0.0002603257307782769\n",
      "Epoch 1846, Loss: 0.0036699269840028137, Final Batch Loss: 0.003253763308748603\n",
      "Epoch 1847, Loss: 0.014800389588344842, Final Batch Loss: 0.00046800385462120175\n",
      "Epoch 1848, Loss: 0.007121612783521414, Final Batch Loss: 0.0006951112300157547\n",
      "Epoch 1849, Loss: 0.00223532976815477, Final Batch Loss: 0.001603966928087175\n",
      "Epoch 1850, Loss: 0.002609764866065234, Final Batch Loss: 0.002260448643937707\n",
      "Epoch 1851, Loss: 0.0021443755831569433, Final Batch Loss: 0.001787432818673551\n",
      "Epoch 1852, Loss: 0.00048476073425263166, Final Batch Loss: 0.0002930547052528709\n",
      "Epoch 1853, Loss: 0.014236072776839137, Final Batch Loss: 0.013092949986457825\n",
      "Epoch 1854, Loss: 0.0024812210322124884, Final Batch Loss: 0.00016467673412989825\n",
      "Epoch 1855, Loss: 0.001929484133142978, Final Batch Loss: 0.0015232095029205084\n",
      "Epoch 1856, Loss: 0.004644718952476978, Final Batch Loss: 0.004064283799380064\n",
      "Epoch 1857, Loss: 0.0056861661723814905, Final Batch Loss: 0.000880014558788389\n",
      "Epoch 1858, Loss: 0.0016584389086347073, Final Batch Loss: 0.0011815920006483793\n",
      "Epoch 1859, Loss: 0.001325393583101686, Final Batch Loss: 0.0001024136072373949\n",
      "Epoch 1860, Loss: 0.0029081474931444973, Final Batch Loss: 0.00026772203273139894\n",
      "Epoch 1861, Loss: 0.002156388363800943, Final Batch Loss: 0.0010135973570868373\n",
      "Epoch 1862, Loss: 0.000576380843995139, Final Batch Loss: 7.452411227859557e-05\n",
      "Epoch 1863, Loss: 0.0007340696756727993, Final Batch Loss: 0.0003433810779824853\n",
      "Epoch 1864, Loss: 0.0027134910196764395, Final Batch Loss: 0.0024937030393630266\n",
      "Epoch 1865, Loss: 0.002818109351210296, Final Batch Loss: 0.000489617814309895\n",
      "Epoch 1866, Loss: 0.00756932505464647, Final Batch Loss: 3.045787161681801e-05\n",
      "Epoch 1867, Loss: 0.0013859068421879783, Final Batch Loss: 0.0002318903716513887\n",
      "Epoch 1868, Loss: 0.09832237474620342, Final Batch Loss: 0.08878008276224136\n",
      "Epoch 1869, Loss: 0.0014029585290700197, Final Batch Loss: 0.0009472513338550925\n",
      "Epoch 1870, Loss: 0.007227642112411559, Final Batch Loss: 0.0011850037844851613\n",
      "Epoch 1871, Loss: 0.0019086046959273517, Final Batch Loss: 0.00027554092230275273\n",
      "Epoch 1872, Loss: 0.0013419060851447284, Final Batch Loss: 0.0006359373801387846\n",
      "Epoch 1873, Loss: 0.001730341522488743, Final Batch Loss: 0.0008718139142729342\n",
      "Epoch 1874, Loss: 0.0021954368567094207, Final Batch Loss: 0.000737630994990468\n",
      "Epoch 1875, Loss: 0.0003310634565423243, Final Batch Loss: 4.18856434407644e-05\n",
      "Epoch 1876, Loss: 0.0019187096040695906, Final Batch Loss: 0.0006499721202999353\n",
      "Epoch 1877, Loss: 0.0008335050079040229, Final Batch Loss: 0.00022778287529945374\n",
      "Epoch 1878, Loss: 0.0007696919492445886, Final Batch Loss: 0.00044226954923942685\n",
      "Epoch 1879, Loss: 0.0018037274712696671, Final Batch Loss: 0.0006548321107402444\n",
      "Epoch 1880, Loss: 0.00116755670751445, Final Batch Loss: 0.00026653220993466675\n",
      "Epoch 1881, Loss: 0.009185859700664878, Final Batch Loss: 0.007048213388770819\n",
      "Epoch 1882, Loss: 0.004071674658916891, Final Batch Loss: 0.0023055796045809984\n",
      "Epoch 1883, Loss: 0.01656417001504451, Final Batch Loss: 0.00022462208289653063\n",
      "Epoch 1884, Loss: 0.0071558484341949224, Final Batch Loss: 0.0010200936812907457\n",
      "Epoch 1885, Loss: 0.0023377154720947146, Final Batch Loss: 0.0019319497514516115\n",
      "Epoch 1886, Loss: 0.014875442546326667, Final Batch Loss: 0.014326230622828007\n",
      "Epoch 1887, Loss: 0.008582793729146942, Final Batch Loss: 0.008181258104741573\n",
      "Epoch 1888, Loss: 0.0015408112085424364, Final Batch Loss: 0.001255985931493342\n",
      "Epoch 1889, Loss: 0.0012880449939984828, Final Batch Loss: 0.00013010742259211838\n",
      "Epoch 1890, Loss: 0.0011886430147569627, Final Batch Loss: 0.0004025527450721711\n",
      "Epoch 1891, Loss: 0.0013752205413766205, Final Batch Loss: 0.0007416380103677511\n",
      "Epoch 1892, Loss: 0.015270946867531165, Final Batch Loss: 0.0004099703801330179\n",
      "Epoch 1893, Loss: 0.003103432070929557, Final Batch Loss: 0.0028873784467577934\n",
      "Epoch 1894, Loss: 0.01654844277072698, Final Batch Loss: 0.016053758561611176\n",
      "Epoch 1895, Loss: 0.007368976250290871, Final Batch Loss: 0.006127342116087675\n",
      "Epoch 1896, Loss: 0.002088134759105742, Final Batch Loss: 0.001231565373018384\n",
      "Epoch 1897, Loss: 0.0025129964342340827, Final Batch Loss: 0.0016642443370074034\n",
      "Epoch 1898, Loss: 0.0005070326151326299, Final Batch Loss: 0.0002502554270904511\n",
      "Epoch 1899, Loss: 0.002317888895049691, Final Batch Loss: 0.0015116964932531118\n",
      "Epoch 1900, Loss: 0.0013049098197370768, Final Batch Loss: 0.0010780923767015338\n",
      "Epoch 1901, Loss: 0.0017603965243324637, Final Batch Loss: 0.0010640188120305538\n",
      "Epoch 1902, Loss: 0.004723700927570462, Final Batch Loss: 0.002391186775639653\n",
      "Epoch 1903, Loss: 0.001997884246520698, Final Batch Loss: 0.0013992433669045568\n",
      "Epoch 1904, Loss: 0.004294492653571069, Final Batch Loss: 0.0035357093438506126\n",
      "Epoch 1905, Loss: 0.0018499006400816143, Final Batch Loss: 0.0011126011377200484\n",
      "Epoch 1906, Loss: 0.01088623030227609, Final Batch Loss: 0.00043599845957942307\n",
      "Epoch 1907, Loss: 0.0022127667907625437, Final Batch Loss: 0.0017035583732649684\n",
      "Epoch 1908, Loss: 0.0015972394467098638, Final Batch Loss: 0.001358289853669703\n",
      "Epoch 1909, Loss: 0.002373239622102119, Final Batch Loss: 4.922914376948029e-05\n",
      "Epoch 1910, Loss: 0.001032956613926217, Final Batch Loss: 0.0004795426211785525\n",
      "Epoch 1911, Loss: 0.00040211145824287087, Final Batch Loss: 0.00021585130889434367\n",
      "Epoch 1912, Loss: 0.0004198678070679307, Final Batch Loss: 0.00015598899335600436\n",
      "Epoch 1913, Loss: 0.0017621882143430412, Final Batch Loss: 0.0005088032339699566\n",
      "Epoch 1914, Loss: 0.0016451275441795588, Final Batch Loss: 0.00018577557057142258\n",
      "Epoch 1915, Loss: 0.004108578083105385, Final Batch Loss: 0.002694346010684967\n",
      "Epoch 1916, Loss: 0.0006062718748580664, Final Batch Loss: 0.0002140494470950216\n",
      "Epoch 1917, Loss: 0.0019573093159124255, Final Batch Loss: 0.0006461801240220666\n",
      "Epoch 1918, Loss: 0.0015320504026021808, Final Batch Loss: 0.0013168464647606015\n",
      "Epoch 1919, Loss: 0.002762744843494147, Final Batch Loss: 0.0005023683770559728\n",
      "Epoch 1920, Loss: 0.003222814353648573, Final Batch Loss: 0.0009496089187450707\n",
      "Epoch 1921, Loss: 0.0017892928372020833, Final Batch Loss: 2.034316275967285e-05\n",
      "Epoch 1922, Loss: 0.0009862110691756243, Final Batch Loss: 2.3085924112820067e-05\n",
      "Epoch 1923, Loss: 0.001971509016584605, Final Batch Loss: 0.0008503812714479864\n",
      "Epoch 1924, Loss: 0.0015927650238154456, Final Batch Loss: 0.00014024872507434338\n",
      "Epoch 1925, Loss: 0.002007070288527757, Final Batch Loss: 0.0014321905327960849\n",
      "Epoch 1926, Loss: 0.0017962740967050195, Final Batch Loss: 0.0011104465229436755\n",
      "Epoch 1927, Loss: 0.0041187661699950695, Final Batch Loss: 0.0031772020738571882\n",
      "Epoch 1928, Loss: 0.0011512154014781117, Final Batch Loss: 0.0005248278030194342\n",
      "Epoch 1929, Loss: 0.0053131079621380195, Final Batch Loss: 0.000228356322622858\n",
      "Epoch 1930, Loss: 0.0006200694770086557, Final Batch Loss: 0.00035563198616728187\n",
      "Epoch 1931, Loss: 0.01435752713587135, Final Batch Loss: 0.000759290880523622\n",
      "Epoch 1932, Loss: 0.008778860639722552, Final Batch Loss: 0.00012126177171012387\n",
      "Epoch 1933, Loss: 0.000518020402523689, Final Batch Loss: 0.00034878402948379517\n",
      "Epoch 1934, Loss: 0.006187460909131914, Final Batch Loss: 0.0057490007020533085\n",
      "Epoch 1935, Loss: 0.0006142902711872011, Final Batch Loss: 0.0001918810303322971\n",
      "Epoch 1936, Loss: 0.0008883664122549817, Final Batch Loss: 0.00011283216008450836\n",
      "Epoch 1937, Loss: 0.023212533444166183, Final Batch Loss: 0.01295605767518282\n",
      "Epoch 1938, Loss: 0.0014252590481191874, Final Batch Loss: 0.0006150466506369412\n",
      "Epoch 1939, Loss: 0.0011322255595587194, Final Batch Loss: 0.00023028510622680187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1940, Loss: 0.004539439803920686, Final Batch Loss: 0.0008546876488253474\n",
      "Epoch 1941, Loss: 0.03227958013303578, Final Batch Loss: 0.03161793574690819\n",
      "Epoch 1942, Loss: 0.008391469935304485, Final Batch Loss: 9.743425471242517e-05\n",
      "Epoch 1943, Loss: 0.002699486445635557, Final Batch Loss: 0.0014709732495248318\n",
      "Epoch 1944, Loss: 0.0024068262428045273, Final Batch Loss: 0.0007664219010621309\n",
      "Epoch 1945, Loss: 0.002122614474501461, Final Batch Loss: 0.0008683662745170295\n",
      "Epoch 1946, Loss: 0.001334263666649349, Final Batch Loss: 0.0012207850813865662\n",
      "Epoch 1947, Loss: 0.0011515917140059173, Final Batch Loss: 0.000256867497228086\n",
      "Epoch 1948, Loss: 0.02622898353729397, Final Batch Loss: 0.025866417214274406\n",
      "Epoch 1949, Loss: 0.0005873478949069977, Final Batch Loss: 0.000247458548983559\n",
      "Epoch 1950, Loss: 0.004269677447155118, Final Batch Loss: 0.0005000389646738768\n",
      "Epoch 1951, Loss: 0.00038981860416242853, Final Batch Loss: 9.81866687652655e-05\n",
      "Epoch 1952, Loss: 0.004222846881020814, Final Batch Loss: 0.0008782856748439372\n",
      "Epoch 1953, Loss: 0.024082905263639987, Final Batch Loss: 0.0006245902040973306\n",
      "Epoch 1954, Loss: 0.0023204536555567756, Final Batch Loss: 0.0022163772955536842\n",
      "Epoch 1955, Loss: 0.001720039639621973, Final Batch Loss: 0.00033138878643512726\n",
      "Epoch 1956, Loss: 0.0012983413762412965, Final Batch Loss: 0.00014183128951117396\n",
      "Epoch 1957, Loss: 0.0006937489233678207, Final Batch Loss: 0.00021420604025479406\n",
      "Epoch 1958, Loss: 0.0028004758059978485, Final Batch Loss: 0.0006949405651539564\n",
      "Epoch 1959, Loss: 0.0010680236737243831, Final Batch Loss: 0.00076848897151649\n",
      "Epoch 1960, Loss: 0.000235584764595842, Final Batch Loss: 3.354157888679765e-05\n",
      "Epoch 1961, Loss: 0.0016477196186315268, Final Batch Loss: 0.00033045359305106103\n",
      "Epoch 1962, Loss: 0.002460670890286565, Final Batch Loss: 0.0011938803363591433\n",
      "Epoch 1963, Loss: 0.00418900023214519, Final Batch Loss: 0.0003387751057744026\n",
      "Epoch 1964, Loss: 0.0016778003046056256, Final Batch Loss: 0.00023428442364092916\n",
      "Epoch 1965, Loss: 0.0015289983566617593, Final Batch Loss: 0.0012911781668663025\n",
      "Epoch 1966, Loss: 0.003743566805496812, Final Batch Loss: 0.0006240704096853733\n",
      "Epoch 1967, Loss: 0.003590458247344941, Final Batch Loss: 0.0030383754055947065\n",
      "Epoch 1968, Loss: 0.004353258525952697, Final Batch Loss: 0.0036820729728788137\n",
      "Epoch 1969, Loss: 0.0008709067187737674, Final Batch Loss: 0.00038431730354204774\n",
      "Epoch 1970, Loss: 0.03224719414720312, Final Batch Loss: 0.0007499876082874835\n",
      "Epoch 1971, Loss: 0.0034937990130856633, Final Batch Loss: 0.0022558493074029684\n",
      "Epoch 1972, Loss: 0.008793784072622657, Final Batch Loss: 0.0015533214900642633\n",
      "Epoch 1973, Loss: 0.0029962226399220526, Final Batch Loss: 0.0007938049384392798\n",
      "Epoch 1974, Loss: 0.00201136595569551, Final Batch Loss: 0.0012304999399930239\n",
      "Epoch 1975, Loss: 0.0013506154355127364, Final Batch Loss: 0.0009311640169471502\n",
      "Epoch 1976, Loss: 0.0010680301929824054, Final Batch Loss: 0.0003079150337725878\n",
      "Epoch 1977, Loss: 0.003526612592395395, Final Batch Loss: 0.002798322821035981\n",
      "Epoch 1978, Loss: 0.001163599983556196, Final Batch Loss: 0.001059794332832098\n",
      "Epoch 1979, Loss: 0.0024845768930390477, Final Batch Loss: 0.0012458390556275845\n",
      "Epoch 1980, Loss: 0.0022949890699237585, Final Batch Loss: 0.0013315313262864947\n",
      "Epoch 1981, Loss: 0.00031725574808660895, Final Batch Loss: 0.00021872915385756642\n",
      "Epoch 1982, Loss: 0.0020543027785606682, Final Batch Loss: 0.000757531903218478\n",
      "Epoch 1983, Loss: 0.0016657345986459404, Final Batch Loss: 0.0012536043068394065\n",
      "Epoch 1984, Loss: 0.0027444828883744776, Final Batch Loss: 0.000438621558714658\n",
      "Epoch 1985, Loss: 0.0007125441625248641, Final Batch Loss: 0.00041485190740786493\n",
      "Epoch 1986, Loss: 0.0017888960428535938, Final Batch Loss: 0.0010477552423253655\n",
      "Epoch 1987, Loss: 0.000849026873765979, Final Batch Loss: 8.245241042459384e-05\n",
      "Epoch 1988, Loss: 0.0017197984270751476, Final Batch Loss: 0.0007392351981252432\n",
      "Epoch 1989, Loss: 0.00200403860071674, Final Batch Loss: 0.0011653046822175384\n",
      "Epoch 1990, Loss: 0.0023353896685875952, Final Batch Loss: 0.0009500011219643056\n",
      "Epoch 1991, Loss: 0.00035318624577485025, Final Batch Loss: 0.00019899495237041265\n",
      "Epoch 1992, Loss: 0.0014798654010519385, Final Batch Loss: 0.0002642691833898425\n",
      "Epoch 1993, Loss: 0.003908140250132419, Final Batch Loss: 0.000193932224647142\n",
      "Epoch 1994, Loss: 0.0018941080197691917, Final Batch Loss: 0.0016129729337990284\n",
      "Epoch 1995, Loss: 0.003290195483714342, Final Batch Loss: 0.0004898151382803917\n",
      "Epoch 1996, Loss: 0.002905932953581214, Final Batch Loss: 0.0008091672789305449\n",
      "Epoch 1997, Loss: 0.002393585105892271, Final Batch Loss: 0.0020348194520920515\n",
      "Epoch 1998, Loss: 0.013941606972366571, Final Batch Loss: 0.013348815962672234\n",
      "Epoch 1999, Loss: 0.0019217419030610472, Final Batch Loss: 0.0015972881810739636\n",
      "Epoch 2000, Loss: 0.001723630353808403, Final Batch Loss: 0.0008942294516600668\n",
      "Epoch 2001, Loss: 0.003031781525351107, Final Batch Loss: 0.0016800787998363376\n",
      "Epoch 2002, Loss: 0.0034106893654097803, Final Batch Loss: 5.424518167274073e-05\n",
      "Epoch 2003, Loss: 0.0008032700570765883, Final Batch Loss: 0.00028157702763564885\n",
      "Epoch 2004, Loss: 0.0014838844072073698, Final Batch Loss: 0.0004918302875012159\n",
      "Epoch 2005, Loss: 0.0016322925657732412, Final Batch Loss: 0.001496945391409099\n",
      "Epoch 2006, Loss: 0.0007555326883448288, Final Batch Loss: 0.0006716602365486324\n",
      "Epoch 2007, Loss: 0.002415656505036168, Final Batch Loss: 0.00016123235400300473\n",
      "Epoch 2008, Loss: 0.013226092502009124, Final Batch Loss: 0.0009006948093883693\n",
      "Epoch 2009, Loss: 0.0009292745962738991, Final Batch Loss: 0.0003337081288918853\n",
      "Epoch 2010, Loss: 0.0015557430742774159, Final Batch Loss: 0.0010706230532377958\n",
      "Epoch 2011, Loss: 0.002872569748433307, Final Batch Loss: 0.0004177762020844966\n",
      "Epoch 2012, Loss: 0.0003958853776566684, Final Batch Loss: 0.0001228921173606068\n",
      "Epoch 2013, Loss: 0.002020264422753826, Final Batch Loss: 0.0016868296079337597\n",
      "Epoch 2014, Loss: 0.0016134579491335899, Final Batch Loss: 0.0012456279946491122\n",
      "Epoch 2015, Loss: 0.002140914584742859, Final Batch Loss: 0.0018187466775998473\n",
      "Epoch 2016, Loss: 0.0038390447152778506, Final Batch Loss: 0.001942345523275435\n",
      "Epoch 2017, Loss: 0.0016667238087393343, Final Batch Loss: 0.001056105480529368\n",
      "Epoch 2018, Loss: 0.0009910544904414564, Final Batch Loss: 0.0005821334198117256\n",
      "Epoch 2019, Loss: 0.0016341987065970898, Final Batch Loss: 0.0005387371638789773\n",
      "Epoch 2020, Loss: 0.000874097109772265, Final Batch Loss: 4.226603778079152e-05\n",
      "Epoch 2021, Loss: 0.0005690855832654051, Final Batch Loss: 7.416930020553991e-05\n",
      "Epoch 2022, Loss: 0.01501204026862979, Final Batch Loss: 0.0024284902028739452\n",
      "Epoch 2023, Loss: 0.00085544801549986, Final Batch Loss: 0.00040046428330242634\n",
      "Epoch 2024, Loss: 0.0005878841911908239, Final Batch Loss: 0.0002677158045116812\n",
      "Epoch 2025, Loss: 0.0029008685087319463, Final Batch Loss: 0.0003985307121183723\n",
      "Epoch 2026, Loss: 0.001234932686202228, Final Batch Loss: 0.00025412708055227995\n",
      "Epoch 2027, Loss: 0.003850159759167582, Final Batch Loss: 0.0007726853364147246\n",
      "Epoch 2028, Loss: 0.0009702133538667113, Final Batch Loss: 0.0003050804079975933\n",
      "Epoch 2029, Loss: 0.00564947968814522, Final Batch Loss: 0.0012930595548823476\n",
      "Epoch 2030, Loss: 0.0044293004320934415, Final Batch Loss: 0.0036625713109970093\n",
      "Epoch 2031, Loss: 0.0009358519455417991, Final Batch Loss: 0.0003671660088002682\n",
      "Epoch 2032, Loss: 0.002886706148274243, Final Batch Loss: 0.0011491890763863921\n",
      "Epoch 2033, Loss: 0.0019419303280301392, Final Batch Loss: 0.0012327664298936725\n",
      "Epoch 2034, Loss: 0.001541858509881422, Final Batch Loss: 0.00032439743517898023\n",
      "Epoch 2035, Loss: 0.0009032186353579164, Final Batch Loss: 0.0005323762306943536\n",
      "Epoch 2036, Loss: 0.000504046372952871, Final Batch Loss: 0.0002728177350945771\n",
      "Epoch 2037, Loss: 0.0016365795163437724, Final Batch Loss: 0.0011166715994477272\n",
      "Epoch 2038, Loss: 0.0020639270078390837, Final Batch Loss: 0.0013519077328965068\n",
      "Epoch 2039, Loss: 0.00016554431203985587, Final Batch Loss: 7.472783181583509e-05\n",
      "Epoch 2040, Loss: 0.0007706737669650465, Final Batch Loss: 0.0003537616285029799\n",
      "Epoch 2041, Loss: 0.002469325831043534, Final Batch Loss: 0.002234796527773142\n",
      "Epoch 2042, Loss: 0.0009431882426724769, Final Batch Loss: 6.188572297105566e-05\n",
      "Epoch 2043, Loss: 0.0006953330303076655, Final Batch Loss: 0.0004830538237001747\n",
      "Epoch 2044, Loss: 0.0015823545400053263, Final Batch Loss: 0.0004359922604635358\n",
      "Epoch 2045, Loss: 0.0005861338649992831, Final Batch Loss: 8.147717016981915e-05\n",
      "Epoch 2046, Loss: 0.0005056961381342262, Final Batch Loss: 0.0004464464436750859\n",
      "Epoch 2047, Loss: 0.0004276270392438164, Final Batch Loss: 0.00039873592322692275\n",
      "Epoch 2048, Loss: 0.0009076979185920209, Final Batch Loss: 0.0004635283548850566\n",
      "Epoch 2049, Loss: 0.005692669830750674, Final Batch Loss: 0.0004945813561789691\n",
      "Epoch 2050, Loss: 0.0017390396096743643, Final Batch Loss: 0.001437004772014916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2051, Loss: 0.000698912248481065, Final Batch Loss: 0.000127877457998693\n",
      "Epoch 2052, Loss: 0.0014225072227418423, Final Batch Loss: 0.000511509831994772\n",
      "Epoch 2053, Loss: 0.00034200269874418154, Final Batch Loss: 0.00029852171428501606\n",
      "Epoch 2054, Loss: 0.001396775187458843, Final Batch Loss: 0.0009223754750564694\n",
      "Epoch 2055, Loss: 0.0020281258039176464, Final Batch Loss: 0.0009799109539017081\n",
      "Epoch 2056, Loss: 0.00138856063131243, Final Batch Loss: 0.0002731950953602791\n",
      "Epoch 2057, Loss: 0.0007099251452018507, Final Batch Loss: 0.00010806829232024029\n",
      "Epoch 2058, Loss: 0.005707526404876262, Final Batch Loss: 0.0007414452848024666\n",
      "Epoch 2059, Loss: 0.002238569548353553, Final Batch Loss: 0.0008159899152815342\n",
      "Epoch 2060, Loss: 0.004399334769914276, Final Batch Loss: 0.004385836888104677\n",
      "Epoch 2061, Loss: 0.0005760146013926715, Final Batch Loss: 0.0002928918111138046\n",
      "Epoch 2062, Loss: 0.0012441569124348462, Final Batch Loss: 0.0007365944911725819\n",
      "Epoch 2063, Loss: 0.0011008318397216499, Final Batch Loss: 0.0005624145269393921\n",
      "Epoch 2064, Loss: 0.03033280186355114, Final Batch Loss: 0.02102905511856079\n",
      "Epoch 2065, Loss: 0.0005203408509260044, Final Batch Loss: 0.00013519618369173259\n",
      "Epoch 2066, Loss: 0.0013031140842940658, Final Batch Loss: 0.0009261589730158448\n",
      "Epoch 2067, Loss: 0.0010164350969716907, Final Batch Loss: 0.0008865291601978242\n",
      "Epoch 2068, Loss: 0.000533462647581473, Final Batch Loss: 0.000274986115982756\n",
      "Epoch 2069, Loss: 0.0013520547072403133, Final Batch Loss: 0.00020307739032432437\n",
      "Epoch 2070, Loss: 0.001212275674333796, Final Batch Loss: 0.0007635054062120616\n",
      "Epoch 2071, Loss: 0.0011125144956167787, Final Batch Loss: 0.00043164679664187133\n",
      "Epoch 2072, Loss: 0.00019671826157718897, Final Batch Loss: 4.5724475057795644e-05\n",
      "Epoch 2073, Loss: 0.0008723359787836671, Final Batch Loss: 0.00011655932758003473\n",
      "Epoch 2074, Loss: 0.0007553848481620662, Final Batch Loss: 0.0006855403771623969\n",
      "Epoch 2075, Loss: 0.00064958626171574, Final Batch Loss: 0.00018958497093990445\n",
      "Epoch 2076, Loss: 0.0011512651690281928, Final Batch Loss: 0.000542934110853821\n",
      "Epoch 2077, Loss: 0.007837360666599125, Final Batch Loss: 0.0005048340535722673\n",
      "Epoch 2078, Loss: 0.0037704638089053333, Final Batch Loss: 0.0029740578029304743\n",
      "Epoch 2079, Loss: 0.0018093877588398755, Final Batch Loss: 0.0007178483647294343\n",
      "Epoch 2080, Loss: 0.0008310077828355134, Final Batch Loss: 0.0004432711284607649\n",
      "Epoch 2081, Loss: 0.0019455756591924, Final Batch Loss: 3.164327426929958e-05\n",
      "Epoch 2082, Loss: 0.00032514067424926907, Final Batch Loss: 6.473543180618435e-05\n",
      "Epoch 2083, Loss: 0.013672097324160859, Final Batch Loss: 0.013486032374203205\n",
      "Epoch 2084, Loss: 0.0012275157787371427, Final Batch Loss: 0.0003019555879291147\n",
      "Epoch 2085, Loss: 0.0022202330001164228, Final Batch Loss: 0.002014423720538616\n",
      "Epoch 2086, Loss: 0.014902479480952024, Final Batch Loss: 0.007925060577690601\n",
      "Epoch 2087, Loss: 0.04301020596176386, Final Batch Loss: 0.012523320503532887\n",
      "Epoch 2088, Loss: 0.0011865111300721765, Final Batch Loss: 0.0009306570864282548\n",
      "Epoch 2089, Loss: 0.0027203344798181206, Final Batch Loss: 0.00018968191579915583\n",
      "Epoch 2090, Loss: 0.0027808510785689577, Final Batch Loss: 0.0002050857146969065\n",
      "Epoch 2091, Loss: 0.0651969201862812, Final Batch Loss: 0.03593635559082031\n",
      "Epoch 2092, Loss: 0.015809927630471066, Final Batch Loss: 8.319181506522e-05\n",
      "Epoch 2093, Loss: 0.0022576081100851297, Final Batch Loss: 0.0008424600819125772\n",
      "Epoch 2094, Loss: 0.01703515648841858, Final Batch Loss: 0.015070222318172455\n",
      "Epoch 2095, Loss: 0.002230457350378856, Final Batch Loss: 0.00032907057902775705\n",
      "Epoch 2096, Loss: 0.008243580057751387, Final Batch Loss: 0.007811138406395912\n",
      "Epoch 2097, Loss: 0.0014006163692101836, Final Batch Loss: 0.0005991589860059321\n",
      "Epoch 2098, Loss: 0.007541797938756645, Final Batch Loss: 0.0008845188422128558\n",
      "Epoch 2099, Loss: 0.004772648157086223, Final Batch Loss: 0.003965409006923437\n",
      "Epoch 2100, Loss: 0.011897734802914783, Final Batch Loss: 0.00013556747580878437\n",
      "Epoch 2101, Loss: 0.0006859561253804713, Final Batch Loss: 0.00019741596770472825\n",
      "Epoch 2102, Loss: 0.002338921884074807, Final Batch Loss: 0.0019749822095036507\n",
      "Epoch 2103, Loss: 0.008407939225435257, Final Batch Loss: 0.007339389994740486\n",
      "Epoch 2104, Loss: 0.012826644349843264, Final Batch Loss: 0.010786142200231552\n",
      "Epoch 2105, Loss: 0.005539076402783394, Final Batch Loss: 0.003489693393930793\n",
      "Epoch 2106, Loss: 0.005491708172485232, Final Batch Loss: 0.0022604286205023527\n",
      "Epoch 2107, Loss: 0.005680735630448908, Final Batch Loss: 0.0005797137855552137\n",
      "Epoch 2108, Loss: 0.00533247011480853, Final Batch Loss: 0.0002604971523396671\n",
      "Epoch 2109, Loss: 0.0036740580981131643, Final Batch Loss: 0.0004597162769641727\n",
      "Epoch 2110, Loss: 0.004618076665792614, Final Batch Loss: 0.0001500002690590918\n",
      "Epoch 2111, Loss: 0.0022432644618675113, Final Batch Loss: 0.0008435306372120976\n",
      "Epoch 2112, Loss: 0.0008204214100260288, Final Batch Loss: 0.000374590017599985\n",
      "Epoch 2113, Loss: 0.0003630850842455402, Final Batch Loss: 0.00019066782260779291\n",
      "Epoch 2114, Loss: 0.0022103795781731606, Final Batch Loss: 0.0019379685400053859\n",
      "Epoch 2115, Loss: 0.0008961354033090174, Final Batch Loss: 0.0005532062496058643\n",
      "Epoch 2116, Loss: 0.0016279309638775885, Final Batch Loss: 0.0008113339426927269\n",
      "Epoch 2117, Loss: 0.00023906757269287482, Final Batch Loss: 6.409419438568875e-05\n",
      "Epoch 2118, Loss: 0.006277632957790047, Final Batch Loss: 0.005578396841883659\n",
      "Epoch 2119, Loss: 0.0005347281985450536, Final Batch Loss: 0.00024877407122403383\n",
      "Epoch 2120, Loss: 0.005179415369639173, Final Batch Loss: 0.0048231943510472775\n",
      "Epoch 2121, Loss: 0.0035737969301408157, Final Batch Loss: 0.00024242674408014864\n",
      "Epoch 2122, Loss: 0.0010723029772634618, Final Batch Loss: 0.00010759400174720213\n",
      "Epoch 2123, Loss: 0.0003233004390494898, Final Batch Loss: 0.00014404817193280905\n",
      "Epoch 2124, Loss: 0.0008351900905836374, Final Batch Loss: 0.00016249201144091785\n",
      "Epoch 2125, Loss: 0.004902802756987512, Final Batch Loss: 0.0030627993401139975\n",
      "Epoch 2126, Loss: 0.0004592590994434431, Final Batch Loss: 0.0002736403257586062\n",
      "Epoch 2127, Loss: 0.0034195813350379467, Final Batch Loss: 0.0028477059677243233\n",
      "Epoch 2128, Loss: 0.0024528263602405787, Final Batch Loss: 0.0008608457865193486\n",
      "Epoch 2129, Loss: 0.0022081053466536105, Final Batch Loss: 0.00010708329500630498\n",
      "Epoch 2130, Loss: 0.0010662945278454572, Final Batch Loss: 0.0007566367858089507\n",
      "Epoch 2131, Loss: 0.0011483157868497074, Final Batch Loss: 0.0004223742871545255\n",
      "Epoch 2132, Loss: 0.0017835649196058512, Final Batch Loss: 0.000445740413852036\n",
      "Epoch 2133, Loss: 0.01664292489294894, Final Batch Loss: 0.016356155276298523\n",
      "Epoch 2134, Loss: 0.0008107200774247758, Final Batch Loss: 0.00011355266178725287\n",
      "Epoch 2135, Loss: 0.000789020603406243, Final Batch Loss: 0.00013308784400578588\n",
      "Epoch 2136, Loss: 0.0014314517029561102, Final Batch Loss: 0.0006573872524313629\n",
      "Epoch 2137, Loss: 0.0024369509774260223, Final Batch Loss: 0.0006746748113073409\n",
      "Epoch 2138, Loss: 0.016177305369637907, Final Batch Loss: 0.01586281880736351\n",
      "Epoch 2139, Loss: 0.0002499981637811288, Final Batch Loss: 0.0001005801314022392\n",
      "Epoch 2140, Loss: 0.0010857493034563959, Final Batch Loss: 0.0005656886496581137\n",
      "Epoch 2141, Loss: 0.023245957912877202, Final Batch Loss: 0.002417587907984853\n",
      "Epoch 2142, Loss: 0.0026081676478497684, Final Batch Loss: 0.0002889774623326957\n",
      "Epoch 2143, Loss: 0.04368054575752467, Final Batch Loss: 0.04285188764333725\n",
      "Epoch 2144, Loss: 0.007931476109661162, Final Batch Loss: 0.007736733183264732\n",
      "Epoch 2145, Loss: 0.0013753510284004733, Final Batch Loss: 0.00011822853412013501\n",
      "Epoch 2146, Loss: 0.005796201294288039, Final Batch Loss: 0.00440168334171176\n",
      "Epoch 2147, Loss: 0.00589278619736433, Final Batch Loss: 0.0042291004210710526\n",
      "Epoch 2148, Loss: 0.03240478516090661, Final Batch Loss: 0.031799182295799255\n",
      "Epoch 2149, Loss: 0.0030563805485144258, Final Batch Loss: 0.0004779534647241235\n",
      "Epoch 2150, Loss: 0.0018540282035246491, Final Batch Loss: 0.0010512018343433738\n",
      "Epoch 2151, Loss: 0.0018671222715056501, Final Batch Loss: 0.0017671658424660563\n",
      "Epoch 2152, Loss: 0.005360097391530871, Final Batch Loss: 0.003272556932643056\n",
      "Epoch 2153, Loss: 0.015789159864652902, Final Batch Loss: 0.015351693145930767\n",
      "Epoch 2154, Loss: 0.0005202566098887473, Final Batch Loss: 0.0001722732267808169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2155, Loss: 0.004122594720683992, Final Batch Loss: 0.0005880525568500161\n",
      "Epoch 2156, Loss: 0.040548439137637615, Final Batch Loss: 0.03924405574798584\n",
      "Epoch 2157, Loss: 0.00034827625495381653, Final Batch Loss: 0.0001506911066826433\n",
      "Epoch 2158, Loss: 0.001531612768303603, Final Batch Loss: 0.0003707708674483001\n",
      "Epoch 2159, Loss: 0.002940450664027594, Final Batch Loss: 0.00017290642426814884\n",
      "Epoch 2160, Loss: 0.0010076700273202732, Final Batch Loss: 0.00017050800670403987\n",
      "Epoch 2161, Loss: 0.0009404392185388133, Final Batch Loss: 0.00016210477042477578\n",
      "Epoch 2162, Loss: 0.004098149249330163, Final Batch Loss: 0.0030261341016739607\n",
      "Epoch 2163, Loss: 0.0016972088706097566, Final Batch Loss: 0.0001203728825203143\n",
      "Epoch 2164, Loss: 0.0012037078995490447, Final Batch Loss: 0.0010770709486678243\n",
      "Epoch 2165, Loss: 0.012848648999352008, Final Batch Loss: 0.012295279651880264\n",
      "Epoch 2166, Loss: 0.0009678398200776428, Final Batch Loss: 0.0008301765192300081\n",
      "Epoch 2167, Loss: 0.0005023932026233524, Final Batch Loss: 4.90730453748256e-05\n",
      "Epoch 2168, Loss: 0.0022203773842193186, Final Batch Loss: 0.00025041826302185655\n",
      "Epoch 2169, Loss: 0.007174489728640765, Final Batch Loss: 0.0009012987720780075\n",
      "Epoch 2170, Loss: 0.0009271810704376549, Final Batch Loss: 0.0006654338794760406\n",
      "Epoch 2171, Loss: 0.016869213388417847, Final Batch Loss: 0.016724133864045143\n",
      "Epoch 2172, Loss: 0.001148078852565959, Final Batch Loss: 0.00028396726702339947\n",
      "Epoch 2173, Loss: 0.012169025605544448, Final Batch Loss: 0.010697348974645138\n",
      "Epoch 2174, Loss: 0.0010975908226100728, Final Batch Loss: 0.00019747453916352242\n",
      "Epoch 2175, Loss: 0.002466903708409518, Final Batch Loss: 0.00025023421039804816\n",
      "Epoch 2176, Loss: 0.005080573529994581, Final Batch Loss: 9.434883395442739e-05\n",
      "Epoch 2177, Loss: 0.007720122463069856, Final Batch Loss: 0.0006079928716644645\n",
      "Epoch 2178, Loss: 0.0010105353430844843, Final Batch Loss: 0.0005742780049331486\n",
      "Epoch 2179, Loss: 0.005639125738525763, Final Batch Loss: 0.0052596102468669415\n",
      "Epoch 2180, Loss: 0.005690206133294851, Final Batch Loss: 0.005125204101204872\n",
      "Epoch 2181, Loss: 0.003538714605383575, Final Batch Loss: 0.0018009087070822716\n",
      "Epoch 2182, Loss: 0.03259566432097927, Final Batch Loss: 0.0009456836269237101\n",
      "Epoch 2183, Loss: 0.001891305553726852, Final Batch Loss: 0.0013033272698521614\n",
      "Epoch 2184, Loss: 0.0008910973556339741, Final Batch Loss: 0.00044695724500343204\n",
      "Epoch 2185, Loss: 0.010170531691983342, Final Batch Loss: 0.007604832760989666\n",
      "Epoch 2186, Loss: 0.0012434230302460492, Final Batch Loss: 0.00033828074811026454\n",
      "Epoch 2187, Loss: 0.0007907070103101432, Final Batch Loss: 0.000427335238782689\n",
      "Epoch 2188, Loss: 0.0017991022032219917, Final Batch Loss: 0.0016120043583214283\n",
      "Epoch 2189, Loss: 0.010002740717027336, Final Batch Loss: 0.0002513668150641024\n",
      "Epoch 2190, Loss: 0.008169445267412812, Final Batch Loss: 0.007553048897534609\n",
      "Epoch 2191, Loss: 0.0021312038879841566, Final Batch Loss: 0.0009921124437823892\n",
      "Epoch 2192, Loss: 0.001155125384684652, Final Batch Loss: 0.0004998360527679324\n",
      "Epoch 2193, Loss: 0.0009377039386890829, Final Batch Loss: 0.00030683347722515464\n",
      "Epoch 2194, Loss: 0.000454111082945019, Final Batch Loss: 9.208888513967395e-05\n",
      "Epoch 2195, Loss: 0.006928351242095232, Final Batch Loss: 0.005591070279479027\n",
      "Epoch 2196, Loss: 0.00073894442175515, Final Batch Loss: 0.0003625707468017936\n",
      "Epoch 2197, Loss: 0.002596676873508841, Final Batch Loss: 0.0017320470651611686\n",
      "Epoch 2198, Loss: 0.002950158144813031, Final Batch Loss: 0.0004595764330588281\n",
      "Epoch 2199, Loss: 0.0005271879344945773, Final Batch Loss: 0.00036409529275260866\n",
      "Epoch 2200, Loss: 0.007392350322334096, Final Batch Loss: 0.00024768264847807586\n",
      "Epoch 2201, Loss: 0.006602660228963941, Final Batch Loss: 0.005909187253564596\n",
      "Epoch 2202, Loss: 0.007487327558919787, Final Batch Loss: 0.0037447705399245024\n",
      "Epoch 2203, Loss: 0.0034293209319002926, Final Batch Loss: 0.0028655289206653833\n",
      "Epoch 2204, Loss: 0.000628100911853835, Final Batch Loss: 0.00017563512665219605\n",
      "Epoch 2205, Loss: 0.0013257850660011172, Final Batch Loss: 0.0007806924404576421\n",
      "Epoch 2206, Loss: 0.0006622226355830207, Final Batch Loss: 0.0002238209854112938\n",
      "Epoch 2207, Loss: 0.0033412277698516846, Final Batch Loss: 0.0021591668482869864\n",
      "Epoch 2208, Loss: 0.0007400276299449615, Final Batch Loss: 0.0006232052110135555\n",
      "Epoch 2209, Loss: 0.0018088670767610893, Final Batch Loss: 0.00021618067694362253\n",
      "Epoch 2210, Loss: 0.005152140889549628, Final Batch Loss: 0.00492855766788125\n",
      "Epoch 2211, Loss: 0.001563305253512226, Final Batch Loss: 0.00021813726925756782\n",
      "Epoch 2212, Loss: 0.0014687301445519552, Final Batch Loss: 0.0013023142237216234\n",
      "Epoch 2213, Loss: 0.0018035118919215165, Final Batch Loss: 8.70675066835247e-05\n",
      "Epoch 2214, Loss: 0.0009269794973079115, Final Batch Loss: 0.0003555550065357238\n",
      "Epoch 2215, Loss: 0.0015352194313891232, Final Batch Loss: 0.0009133558487519622\n",
      "Epoch 2216, Loss: 0.001284537123865448, Final Batch Loss: 7.152183388825506e-05\n",
      "Epoch 2217, Loss: 0.0010858809400815517, Final Batch Loss: 0.00022850200184620917\n",
      "Epoch 2218, Loss: 0.0008326374518219382, Final Batch Loss: 0.0007619443931616843\n",
      "Epoch 2219, Loss: 0.0004213055217405781, Final Batch Loss: 0.0002020463434746489\n",
      "Epoch 2220, Loss: 0.0017473534680902958, Final Batch Loss: 0.0015372280031442642\n",
      "Epoch 2221, Loss: 0.0007526734698330984, Final Batch Loss: 0.0005944438744336367\n",
      "Epoch 2222, Loss: 0.0016452917479909956, Final Batch Loss: 0.0010710181668400764\n",
      "Epoch 2223, Loss: 0.0005919608229305595, Final Batch Loss: 0.0005099228001199663\n",
      "Epoch 2224, Loss: 0.0005150191718712449, Final Batch Loss: 0.00012182109639979899\n",
      "Epoch 2225, Loss: 0.002091036585625261, Final Batch Loss: 0.0018041374860331416\n",
      "Epoch 2226, Loss: 0.0006839974957983941, Final Batch Loss: 0.00039459604886360466\n",
      "Epoch 2227, Loss: 0.0014140457496978343, Final Batch Loss: 0.0008397541241720319\n",
      "Epoch 2228, Loss: 0.003168562427163124, Final Batch Loss: 0.002053643576800823\n",
      "Epoch 2229, Loss: 0.0008350874995812774, Final Batch Loss: 0.00028278445824980736\n",
      "Epoch 2230, Loss: 0.0006435837422031909, Final Batch Loss: 0.0003425614850129932\n",
      "Epoch 2231, Loss: 0.004554346785880625, Final Batch Loss: 0.003929293714463711\n",
      "Epoch 2232, Loss: 0.0007217265374492854, Final Batch Loss: 0.00015010670176707208\n",
      "Epoch 2233, Loss: 0.00017363790175295435, Final Batch Loss: 0.00012869673082605004\n",
      "Epoch 2234, Loss: 0.0009549768874421716, Final Batch Loss: 0.00046202726662158966\n",
      "Epoch 2235, Loss: 0.000871133292093873, Final Batch Loss: 0.0006521947216242552\n",
      "Epoch 2236, Loss: 0.0010527685517445207, Final Batch Loss: 0.0005599124706350267\n",
      "Epoch 2237, Loss: 0.00023224895994644612, Final Batch Loss: 6.603667861782014e-05\n",
      "Epoch 2238, Loss: 0.00021754547924501821, Final Batch Loss: 0.00013177392247598618\n",
      "Epoch 2239, Loss: 0.0006371014314936474, Final Batch Loss: 0.0003933260450139642\n",
      "Epoch 2240, Loss: 0.0007360191084444523, Final Batch Loss: 0.00039742214721627533\n",
      "Epoch 2241, Loss: 0.00123134495515842, Final Batch Loss: 9.233441960532218e-05\n",
      "Epoch 2242, Loss: 0.004463776131160557, Final Batch Loss: 0.0003375463420525193\n",
      "Epoch 2243, Loss: 0.004015184938907623, Final Batch Loss: 0.0006098637823015451\n",
      "Epoch 2244, Loss: 0.001266397288418375, Final Batch Loss: 8.313298167195171e-05\n",
      "Epoch 2245, Loss: 0.0025495538429822773, Final Batch Loss: 0.0022014027927070856\n",
      "Epoch 2246, Loss: 0.005944380478467792, Final Batch Loss: 0.0053171562030911446\n",
      "Epoch 2247, Loss: 0.0007610215106979012, Final Batch Loss: 0.00024849362671375275\n",
      "Epoch 2248, Loss: 0.009095002576941624, Final Batch Loss: 0.008797628805041313\n",
      "Epoch 2249, Loss: 0.0016937613836489618, Final Batch Loss: 0.00042785395635291934\n",
      "Epoch 2250, Loss: 0.0012006912438664585, Final Batch Loss: 0.0008626251947134733\n",
      "Epoch 2251, Loss: 0.0025003976770676672, Final Batch Loss: 0.0005576155963353813\n",
      "Epoch 2252, Loss: 0.0011690150713548064, Final Batch Loss: 0.00026933965273201466\n",
      "Epoch 2253, Loss: 0.0017955359653569758, Final Batch Loss: 0.001141935819759965\n",
      "Epoch 2254, Loss: 0.001145113528764341, Final Batch Loss: 3.924352495232597e-05\n",
      "Epoch 2255, Loss: 0.005684587609721348, Final Batch Loss: 0.005543850362300873\n",
      "Epoch 2256, Loss: 0.003581266219043755, Final Batch Loss: 2.958259756269399e-05\n",
      "Epoch 2257, Loss: 0.0017953993519768119, Final Batch Loss: 0.0009779187384992838\n",
      "Epoch 2258, Loss: 0.0009909729124046862, Final Batch Loss: 0.00018200656631961465\n",
      "Epoch 2259, Loss: 0.002909919116063975, Final Batch Loss: 0.00021381453552749008\n",
      "Epoch 2260, Loss: 0.010712178438552655, Final Batch Loss: 0.00019837358559016138\n",
      "Epoch 2261, Loss: 0.0013171690661692992, Final Batch Loss: 0.0011786069953814149\n",
      "Epoch 2262, Loss: 0.0038352946867235005, Final Batch Loss: 0.00025939970510080457\n",
      "Epoch 2263, Loss: 0.002296754282724578, Final Batch Loss: 0.00010339811706217006\n",
      "Epoch 2264, Loss: 0.002346015418879688, Final Batch Loss: 0.001242471975274384\n",
      "Epoch 2265, Loss: 0.0006771081243641675, Final Batch Loss: 0.00016787747154012322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2266, Loss: 0.0006103921296016779, Final Batch Loss: 2.272211349918507e-05\n",
      "Epoch 2267, Loss: 0.0028312199283391237, Final Batch Loss: 0.0014513676287606359\n",
      "Epoch 2268, Loss: 0.0005344216770026833, Final Batch Loss: 0.0003974882129114121\n",
      "Epoch 2269, Loss: 0.013628305692691356, Final Batch Loss: 0.012809690088033676\n",
      "Epoch 2270, Loss: 0.00028007816581521183, Final Batch Loss: 9.864417370408773e-05\n",
      "Epoch 2271, Loss: 0.002044245135039091, Final Batch Loss: 0.0014559495029971004\n",
      "Epoch 2272, Loss: 0.002960798767162487, Final Batch Loss: 0.0026451454032212496\n",
      "Epoch 2273, Loss: 0.0007591845496790484, Final Batch Loss: 9.227429109159857e-05\n",
      "Epoch 2274, Loss: 0.0007341396412812173, Final Batch Loss: 0.00028776636463589966\n",
      "Epoch 2275, Loss: 0.002418421325273812, Final Batch Loss: 0.0007033786969259381\n",
      "Epoch 2276, Loss: 0.008592632715590298, Final Batch Loss: 0.0005322695942595601\n",
      "Epoch 2277, Loss: 0.000768122379668057, Final Batch Loss: 0.0005944662261754274\n",
      "Epoch 2278, Loss: 0.003764859546208754, Final Batch Loss: 0.0033205284271389246\n",
      "Epoch 2279, Loss: 0.060466041330073494, Final Batch Loss: 0.06040399149060249\n",
      "Epoch 2280, Loss: 0.00042693031718954444, Final Batch Loss: 0.0001578980591148138\n",
      "Epoch 2281, Loss: 0.0003934773849323392, Final Batch Loss: 1.6389996744692326e-05\n",
      "Epoch 2282, Loss: 0.00047315657866420224, Final Batch Loss: 0.00036869579344056547\n",
      "Epoch 2283, Loss: 0.0005195923440624028, Final Batch Loss: 7.300713332369924e-05\n",
      "Epoch 2284, Loss: 0.0005971396749373525, Final Batch Loss: 0.0002866282593458891\n",
      "Epoch 2285, Loss: 0.0009920720476657152, Final Batch Loss: 0.0005778167396783829\n",
      "Epoch 2286, Loss: 0.00042506231693550944, Final Batch Loss: 0.00021257365006022155\n",
      "Epoch 2287, Loss: 0.011083695411798544, Final Batch Loss: 0.00021456585091073066\n",
      "Epoch 2288, Loss: 0.006777313319616951, Final Batch Loss: 0.006623722147196531\n",
      "Epoch 2289, Loss: 0.0006763191631762311, Final Batch Loss: 0.0004371082177385688\n",
      "Epoch 2290, Loss: 0.0015855058445595205, Final Batch Loss: 0.0008280606707558036\n",
      "Epoch 2291, Loss: 0.00080191624147119, Final Batch Loss: 5.654426786350086e-05\n",
      "Epoch 2292, Loss: 0.0017229934746865183, Final Batch Loss: 0.00035273891990073025\n",
      "Epoch 2293, Loss: 0.0017901148094097152, Final Batch Loss: 0.0016796572599560022\n",
      "Epoch 2294, Loss: 0.002749195060459897, Final Batch Loss: 0.0024686118122190237\n",
      "Epoch 2295, Loss: 0.0008230110543081537, Final Batch Loss: 0.00017681696044746786\n",
      "Epoch 2296, Loss: 0.0015738821821287274, Final Batch Loss: 0.0010354171972721815\n",
      "Epoch 2297, Loss: 0.004637101315893233, Final Batch Loss: 0.0003765957662835717\n",
      "Epoch 2298, Loss: 0.0007197402155725285, Final Batch Loss: 0.0005180645966902375\n",
      "Epoch 2299, Loss: 0.0007421055306622293, Final Batch Loss: 5.374091779231094e-05\n",
      "Epoch 2300, Loss: 0.010179735720157623, Final Batch Loss: 0.009084947407245636\n",
      "Epoch 2301, Loss: 0.0007172455370891839, Final Batch Loss: 3.8337340811267495e-05\n",
      "Epoch 2302, Loss: 0.0020402550289873034, Final Batch Loss: 0.0017256643623113632\n",
      "Epoch 2303, Loss: 0.003695420833537355, Final Batch Loss: 0.0002823673712555319\n",
      "Epoch 2304, Loss: 0.0022789948852732778, Final Batch Loss: 0.0009969318052753806\n",
      "Epoch 2305, Loss: 0.001178145408630371, Final Batch Loss: 2.1869433112442493e-05\n",
      "Epoch 2306, Loss: 0.0008676627621753141, Final Batch Loss: 0.000134494315716438\n",
      "Epoch 2307, Loss: 0.0018299500516150147, Final Batch Loss: 0.0015413380460813642\n",
      "Epoch 2308, Loss: 0.003905509744072333, Final Batch Loss: 0.0037980058696120977\n",
      "Epoch 2309, Loss: 0.00093976037169341, Final Batch Loss: 0.00022451272525358945\n",
      "Epoch 2310, Loss: 0.002571761899162084, Final Batch Loss: 0.0016113368328660727\n",
      "Epoch 2311, Loss: 0.005094835942145437, Final Batch Loss: 0.004386847838759422\n",
      "Epoch 2312, Loss: 0.00042915766971418634, Final Batch Loss: 9.424251766176894e-05\n",
      "Epoch 2313, Loss: 0.0011340647033648565, Final Batch Loss: 0.00014212385576684028\n",
      "Epoch 2314, Loss: 0.001329802325926721, Final Batch Loss: 0.00012469675857573748\n",
      "Epoch 2315, Loss: 0.00039419781387550756, Final Batch Loss: 0.000318318692734465\n",
      "Epoch 2316, Loss: 0.01668361078191083, Final Batch Loss: 0.000145944461110048\n",
      "Epoch 2317, Loss: 0.010666517831850797, Final Batch Loss: 0.0008587113698013127\n",
      "Epoch 2318, Loss: 0.0008553080770070665, Final Batch Loss: 0.0007455090526491404\n",
      "Epoch 2319, Loss: 0.0041617277602199465, Final Batch Loss: 0.003903151722624898\n",
      "Epoch 2320, Loss: 0.0023392922012135386, Final Batch Loss: 0.00041610514745116234\n",
      "Epoch 2321, Loss: 0.0010075120662804693, Final Batch Loss: 0.00046348272007890046\n",
      "Epoch 2322, Loss: 0.0025245245778933167, Final Batch Loss: 0.0012835334055125713\n",
      "Epoch 2323, Loss: 0.001518094701168593, Final Batch Loss: 5.7939345424529165e-05\n",
      "Epoch 2324, Loss: 0.0009852786533883773, Final Batch Loss: 0.00010226517770206556\n",
      "Epoch 2325, Loss: 0.00038026436959626153, Final Batch Loss: 8.534250810043886e-05\n",
      "Epoch 2326, Loss: 0.0012062403839081526, Final Batch Loss: 0.0009560382459312677\n",
      "Epoch 2327, Loss: 0.00032112452026922256, Final Batch Loss: 0.00019060187332797796\n",
      "Epoch 2328, Loss: 0.001059527523466386, Final Batch Loss: 0.0008279145695269108\n",
      "Epoch 2329, Loss: 0.0002540865170885809, Final Batch Loss: 0.0001541780075058341\n",
      "Epoch 2330, Loss: 0.0014111905475147069, Final Batch Loss: 0.0006241227383725345\n",
      "Epoch 2331, Loss: 0.00020111288904445246, Final Batch Loss: 3.529417881509289e-05\n",
      "Epoch 2332, Loss: 0.0006130264664534479, Final Batch Loss: 0.00030045307357795537\n",
      "Epoch 2333, Loss: 0.008110573457088321, Final Batch Loss: 0.007578035816550255\n",
      "Epoch 2334, Loss: 0.0010623895504977554, Final Batch Loss: 0.00023801819770596921\n",
      "Epoch 2335, Loss: 0.01283030338527169, Final Batch Loss: 0.01270570233464241\n",
      "Epoch 2336, Loss: 0.000874852790730074, Final Batch Loss: 0.00038101375685073435\n",
      "Epoch 2337, Loss: 0.0010456019081175327, Final Batch Loss: 0.0007336290436796844\n",
      "Epoch 2338, Loss: 0.0018550396271166392, Final Batch Loss: 4.9402246077079326e-05\n",
      "Epoch 2339, Loss: 0.02597623597830534, Final Batch Loss: 0.024283116683363914\n",
      "Epoch 2340, Loss: 0.006958433135878295, Final Batch Loss: 0.0005518725956790149\n",
      "Epoch 2341, Loss: 0.02488502173218876, Final Batch Loss: 0.023246899247169495\n",
      "Epoch 2342, Loss: 0.035612097941339016, Final Batch Loss: 0.011213663034141064\n",
      "Epoch 2343, Loss: 0.022721252404153347, Final Batch Loss: 0.005546455271542072\n",
      "Epoch 2344, Loss: 0.003846915904432535, Final Batch Loss: 0.0023074059281498194\n",
      "Epoch 2345, Loss: 0.03671269491314888, Final Batch Loss: 0.020547620952129364\n",
      "Epoch 2346, Loss: 0.06311696395277977, Final Batch Loss: 0.03721379488706589\n",
      "Epoch 2347, Loss: 0.014787359366891906, Final Batch Loss: 0.00017514100181870162\n",
      "Epoch 2348, Loss: 0.0005812159506604075, Final Batch Loss: 0.000279430765658617\n",
      "Epoch 2349, Loss: 0.013980780728161335, Final Batch Loss: 0.00028972700238227844\n",
      "Epoch 2350, Loss: 0.012969391333172098, Final Batch Loss: 0.0126004284247756\n",
      "Epoch 2351, Loss: 0.0005171839875401929, Final Batch Loss: 0.000404670019634068\n",
      "Epoch 2352, Loss: 0.0015008786576800048, Final Batch Loss: 0.0009950638050213456\n",
      "Epoch 2353, Loss: 0.0029557946836575866, Final Batch Loss: 0.0018437969265505672\n",
      "Epoch 2354, Loss: 0.0023024067049846053, Final Batch Loss: 0.000557201448827982\n",
      "Epoch 2355, Loss: 0.011893114606209565, Final Batch Loss: 0.011786509305238724\n",
      "Epoch 2356, Loss: 0.0011634402180789039, Final Batch Loss: 0.0010148745495826006\n",
      "Epoch 2357, Loss: 0.0025252674822695553, Final Batch Loss: 0.001580696669407189\n",
      "Epoch 2358, Loss: 0.0014660164015367627, Final Batch Loss: 0.00013539474457502365\n",
      "Epoch 2359, Loss: 0.0032338533783331513, Final Batch Loss: 0.002319216262549162\n",
      "Epoch 2360, Loss: 0.0013356650597415864, Final Batch Loss: 0.0003019502037204802\n",
      "Epoch 2361, Loss: 0.015571121824905276, Final Batch Loss: 0.0032886972185224295\n",
      "Epoch 2362, Loss: 0.005407982738688588, Final Batch Loss: 0.004404900129884481\n",
      "Epoch 2363, Loss: 0.00278320349752903, Final Batch Loss: 0.0005314885638654232\n",
      "Epoch 2364, Loss: 0.01520740578416735, Final Batch Loss: 0.0008220780873671174\n",
      "Epoch 2365, Loss: 0.0018640542402863503, Final Batch Loss: 0.0007908821571618319\n",
      "Epoch 2366, Loss: 0.00047942979290382937, Final Batch Loss: 0.00010358636063756421\n",
      "Epoch 2367, Loss: 0.003211305825971067, Final Batch Loss: 0.00042670697439461946\n",
      "Epoch 2368, Loss: 0.0026877768395934254, Final Batch Loss: 0.00046769031905569136\n",
      "Epoch 2369, Loss: 0.0023618373670615256, Final Batch Loss: 0.0008216836140491068\n",
      "Epoch 2370, Loss: 0.0030080777942202985, Final Batch Loss: 0.0006757168448530138\n",
      "Epoch 2371, Loss: 0.002697061689104885, Final Batch Loss: 0.0003488659276627004\n",
      "Epoch 2372, Loss: 0.00559148087631911, Final Batch Loss: 0.0013235475635156035\n",
      "Epoch 2373, Loss: 0.003637290035840124, Final Batch Loss: 0.0008411437156610191\n",
      "Epoch 2374, Loss: 0.00143297272734344, Final Batch Loss: 0.0005936733796261251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2375, Loss: 0.002913262869697064, Final Batch Loss: 0.0023032857570797205\n",
      "Epoch 2376, Loss: 0.0012744554842356592, Final Batch Loss: 0.0009990520775318146\n",
      "Epoch 2377, Loss: 0.0028032216941937804, Final Batch Loss: 0.0007073198212310672\n",
      "Epoch 2378, Loss: 0.0027308439020998776, Final Batch Loss: 0.0008730076369829476\n",
      "Epoch 2379, Loss: 0.012658474617637694, Final Batch Loss: 0.012034355662763119\n",
      "Epoch 2380, Loss: 0.006251170649193227, Final Batch Loss: 0.004765873309224844\n",
      "Epoch 2381, Loss: 0.0035504919360391796, Final Batch Loss: 0.0030430236365646124\n",
      "Epoch 2382, Loss: 0.0008310662087751552, Final Batch Loss: 0.00022467788949143142\n",
      "Epoch 2383, Loss: 0.0005308484251145273, Final Batch Loss: 0.00031382738961838186\n",
      "Epoch 2384, Loss: 0.001866859442088753, Final Batch Loss: 0.0007341800373978913\n",
      "Epoch 2385, Loss: 0.0014900724636390805, Final Batch Loss: 0.0003933707484975457\n",
      "Epoch 2386, Loss: 0.0017037220823112875, Final Batch Loss: 0.0012873760424554348\n",
      "Epoch 2387, Loss: 0.007679363014176488, Final Batch Loss: 0.007538637146353722\n",
      "Epoch 2388, Loss: 0.0003606697719078511, Final Batch Loss: 0.0001396808511344716\n",
      "Epoch 2389, Loss: 0.0015157643938437104, Final Batch Loss: 0.0004025810630992055\n",
      "Epoch 2390, Loss: 0.001939323206897825, Final Batch Loss: 0.0011773983715102077\n",
      "Epoch 2391, Loss: 0.0011081512784585357, Final Batch Loss: 0.00046597153414040804\n",
      "Epoch 2392, Loss: 0.00132222575484775, Final Batch Loss: 0.001154075376689434\n",
      "Epoch 2393, Loss: 0.0006265869160415605, Final Batch Loss: 0.0002228303492302075\n",
      "Epoch 2394, Loss: 0.0035585937730502337, Final Batch Loss: 0.00037163213710300624\n",
      "Epoch 2395, Loss: 0.02958973217755556, Final Batch Loss: 0.025461552664637566\n",
      "Epoch 2396, Loss: 0.004337312537245452, Final Batch Loss: 0.00362135237082839\n",
      "Epoch 2397, Loss: 0.0012233828310854733, Final Batch Loss: 0.0009559816680848598\n",
      "Epoch 2398, Loss: 0.0005999599525239319, Final Batch Loss: 0.0002286745875608176\n",
      "Epoch 2399, Loss: 0.028297786135226488, Final Batch Loss: 0.027073437348008156\n",
      "Epoch 2400, Loss: 0.004893948935205117, Final Batch Loss: 0.004480771720409393\n",
      "Epoch 2401, Loss: 0.0015868855407461524, Final Batch Loss: 0.0008163406746461987\n",
      "Epoch 2402, Loss: 0.003933296771720052, Final Batch Loss: 0.0003132815472781658\n",
      "Epoch 2403, Loss: 0.0012364619178697467, Final Batch Loss: 0.0006112983683124185\n",
      "Epoch 2404, Loss: 0.0015077132848091424, Final Batch Loss: 0.0007223078864626586\n",
      "Epoch 2405, Loss: 0.005195483914576471, Final Batch Loss: 0.004352953750640154\n",
      "Epoch 2406, Loss: 0.0018389813776593655, Final Batch Loss: 0.0013857559533789754\n",
      "Epoch 2407, Loss: 0.03098887983651366, Final Batch Loss: 0.03077278658747673\n",
      "Epoch 2408, Loss: 0.0029355825390666723, Final Batch Loss: 0.0002566962502896786\n",
      "Epoch 2409, Loss: 0.006146236497443169, Final Batch Loss: 0.00018026557518169284\n",
      "Epoch 2410, Loss: 0.0017425163823645562, Final Batch Loss: 0.0013172855833545327\n",
      "Epoch 2411, Loss: 0.011670196428894997, Final Batch Loss: 0.009636844508349895\n",
      "Epoch 2412, Loss: 0.0005727523239329457, Final Batch Loss: 0.0002596641716081649\n",
      "Epoch 2413, Loss: 0.003644699085270986, Final Batch Loss: 0.00028176498017273843\n",
      "Epoch 2414, Loss: 0.003918445901945233, Final Batch Loss: 0.0012123691849410534\n",
      "Epoch 2415, Loss: 0.009341946511995047, Final Batch Loss: 0.008445177227258682\n",
      "Epoch 2416, Loss: 0.0043778413673862815, Final Batch Loss: 0.0006856370018795133\n",
      "Epoch 2417, Loss: 0.0017747012025211006, Final Batch Loss: 0.00023145441082306206\n",
      "Epoch 2418, Loss: 0.000843699075630866, Final Batch Loss: 0.00024018784461077303\n",
      "Epoch 2419, Loss: 0.0008267754892585799, Final Batch Loss: 0.00012933560356032103\n",
      "Epoch 2420, Loss: 0.0007368996302830055, Final Batch Loss: 0.00023959508689586073\n",
      "Epoch 2421, Loss: 0.003835391136817634, Final Batch Loss: 0.0006928745424374938\n",
      "Epoch 2422, Loss: 0.002967039414215833, Final Batch Loss: 0.0003359595430083573\n",
      "Epoch 2423, Loss: 0.007988537254277617, Final Batch Loss: 0.0005024192505516112\n",
      "Epoch 2424, Loss: 0.005038183357100934, Final Batch Loss: 0.0049648829735815525\n",
      "Epoch 2425, Loss: 0.0034660399542190135, Final Batch Loss: 0.0028117275796830654\n",
      "Epoch 2426, Loss: 0.0031923731439746916, Final Batch Loss: 0.0009626255487091839\n",
      "Epoch 2427, Loss: 0.0026850758004002273, Final Batch Loss: 0.00039338128408417106\n",
      "Epoch 2428, Loss: 0.0001841963385231793, Final Batch Loss: 7.995760824996978e-05\n",
      "Epoch 2429, Loss: 0.001909537983010523, Final Batch Loss: 0.001859097508713603\n",
      "Epoch 2430, Loss: 0.00331916130380705, Final Batch Loss: 0.0008201506570912898\n",
      "Epoch 2431, Loss: 0.0005097657995065674, Final Batch Loss: 0.00020015319751109928\n",
      "Epoch 2432, Loss: 0.0020891882304567844, Final Batch Loss: 0.0004195939109195024\n",
      "Epoch 2433, Loss: 0.0011200426379218698, Final Batch Loss: 0.0007693308871239424\n",
      "Epoch 2434, Loss: 0.0012899360226583667, Final Batch Loss: 9.807316382648423e-05\n",
      "Epoch 2435, Loss: 0.0021504094984265976, Final Batch Loss: 8.417094795731828e-05\n",
      "Epoch 2436, Loss: 0.0006817935063736513, Final Batch Loss: 0.00013755315740127116\n",
      "Epoch 2437, Loss: 0.0008320437336806208, Final Batch Loss: 0.00010049078264273703\n",
      "Epoch 2438, Loss: 0.001170398376416415, Final Batch Loss: 0.0005861892714165151\n",
      "Epoch 2439, Loss: 0.0014376813487615436, Final Batch Loss: 0.001140868291258812\n",
      "Epoch 2440, Loss: 0.0020354179432615638, Final Batch Loss: 0.000984677579253912\n",
      "Epoch 2441, Loss: 0.0004002495334134437, Final Batch Loss: 0.00030257165781222284\n",
      "Epoch 2442, Loss: 0.007449062308296561, Final Batch Loss: 0.004765013232827187\n",
      "Epoch 2443, Loss: 0.00022220036044018343, Final Batch Loss: 0.00015651178546249866\n",
      "Epoch 2444, Loss: 0.0007130026060622185, Final Batch Loss: 0.0004485060053411871\n",
      "Epoch 2445, Loss: 0.005048557475674897, Final Batch Loss: 0.00019398826407268643\n",
      "Epoch 2446, Loss: 0.0005331359861884266, Final Batch Loss: 0.0001443801447749138\n",
      "Epoch 2447, Loss: 0.0021383212006185204, Final Batch Loss: 0.000386102037737146\n",
      "Epoch 2448, Loss: 0.0014418837381526828, Final Batch Loss: 0.0009779229294508696\n",
      "Epoch 2449, Loss: 0.000631888338830322, Final Batch Loss: 0.0004095829790458083\n",
      "Epoch 2450, Loss: 0.0015007313922978938, Final Batch Loss: 0.000948531087487936\n",
      "Epoch 2451, Loss: 0.0027327437710482627, Final Batch Loss: 0.0022938030306249857\n",
      "Epoch 2452, Loss: 0.0033995588164543733, Final Batch Loss: 0.0033124866895377636\n",
      "Epoch 2453, Loss: 0.0003274100454291329, Final Batch Loss: 0.00014930620091035962\n",
      "Epoch 2454, Loss: 0.0009470688528381288, Final Batch Loss: 0.00027310813311487436\n",
      "Epoch 2455, Loss: 0.0007253276562551036, Final Batch Loss: 0.0004963214742019773\n",
      "Epoch 2456, Loss: 0.00089593994198367, Final Batch Loss: 0.0004360903985798359\n",
      "Epoch 2457, Loss: 0.0008426003914792091, Final Batch Loss: 0.00013395168934948742\n",
      "Epoch 2458, Loss: 0.0003411013021832332, Final Batch Loss: 8.162147423718125e-05\n",
      "Epoch 2459, Loss: 0.0006438934215111658, Final Batch Loss: 0.00041252540540881455\n",
      "Epoch 2460, Loss: 0.0021257154876366258, Final Batch Loss: 0.0012670980067923665\n",
      "Epoch 2461, Loss: 0.00023193081142380834, Final Batch Loss: 0.0001159666499006562\n",
      "Epoch 2462, Loss: 0.0006928046059329063, Final Batch Loss: 0.00015700465883128345\n",
      "Epoch 2463, Loss: 0.011253445874899626, Final Batch Loss: 0.00014025671407580376\n",
      "Epoch 2464, Loss: 0.000722686636436265, Final Batch Loss: 4.126928251935169e-05\n",
      "Epoch 2465, Loss: 0.0009426476317457855, Final Batch Loss: 0.0007293983944691718\n",
      "Epoch 2466, Loss: 0.012665471804211847, Final Batch Loss: 0.00013277381367515773\n",
      "Epoch 2467, Loss: 0.0004057213736814447, Final Batch Loss: 0.0001212944116559811\n",
      "Epoch 2468, Loss: 0.0013425642682705075, Final Batch Loss: 0.0010593482293188572\n",
      "Epoch 2469, Loss: 0.000567590759601444, Final Batch Loss: 0.00033173258998431265\n",
      "Epoch 2470, Loss: 0.003156030645186547, Final Batch Loss: 7.424652721965685e-05\n",
      "Epoch 2471, Loss: 0.0011405889526940882, Final Batch Loss: 0.0002230137470178306\n",
      "Epoch 2472, Loss: 0.0017357065808027983, Final Batch Loss: 0.000807952310424298\n",
      "Epoch 2473, Loss: 0.0010517794435145333, Final Batch Loss: 0.000130437794723548\n",
      "Epoch 2474, Loss: 0.001802908576792106, Final Batch Loss: 0.00045293671428225935\n",
      "Epoch 2475, Loss: 0.0004932381125399843, Final Batch Loss: 0.00030225605587475\n",
      "Epoch 2476, Loss: 0.0005361331714084372, Final Batch Loss: 0.0004354890261311084\n",
      "Epoch 2477, Loss: 0.000470024227979593, Final Batch Loss: 0.0002153399254893884\n",
      "Epoch 2478, Loss: 0.04761051048990339, Final Batch Loss: 0.04676162078976631\n",
      "Epoch 2479, Loss: 0.0003041658201254904, Final Batch Loss: 0.00013233599020168185\n",
      "Epoch 2480, Loss: 0.006739127607943374, Final Batch Loss: 2.7873711587744765e-05\n",
      "Epoch 2481, Loss: 0.0021867488976567984, Final Batch Loss: 0.0003742816625162959\n",
      "Epoch 2482, Loss: 0.04437860636971891, Final Batch Loss: 0.0021794044878333807\n",
      "Epoch 2483, Loss: 0.02669866941869259, Final Batch Loss: 0.007765362039208412\n",
      "Epoch 2484, Loss: 0.021472742897458375, Final Batch Loss: 0.0017111060442402959\n",
      "Epoch 2485, Loss: 0.006726904983224813, Final Batch Loss: 0.00011832427844638005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2486, Loss: 0.00127441220683977, Final Batch Loss: 0.0009913425892591476\n",
      "Epoch 2487, Loss: 0.009690689737908542, Final Batch Loss: 0.0008851055754348636\n",
      "Epoch 2488, Loss: 0.010768285021185875, Final Batch Loss: 0.0017926022410392761\n",
      "Epoch 2489, Loss: 0.01652757776901126, Final Batch Loss: 0.0008227317593991756\n",
      "Epoch 2490, Loss: 0.010443300649058074, Final Batch Loss: 0.009636040776968002\n",
      "Epoch 2491, Loss: 0.004968279885360971, Final Batch Loss: 0.004749184008687735\n",
      "Epoch 2492, Loss: 0.004297543782740831, Final Batch Loss: 0.0006655121687799692\n",
      "Epoch 2493, Loss: 0.00719612865941599, Final Batch Loss: 0.006629734765738249\n",
      "Epoch 2494, Loss: 0.001984353773877956, Final Batch Loss: 0.0018583951750770211\n",
      "Epoch 2495, Loss: 0.0017119006952270865, Final Batch Loss: 0.0004184384597465396\n",
      "Epoch 2496, Loss: 0.00787611398845911, Final Batch Loss: 0.0010820678435266018\n",
      "Epoch 2497, Loss: 0.0019548245109035634, Final Batch Loss: 0.00011555788660189137\n",
      "Epoch 2498, Loss: 0.0023952554911375046, Final Batch Loss: 0.0008427116554230452\n",
      "Epoch 2499, Loss: 0.000615846409345977, Final Batch Loss: 0.0004624405992217362\n",
      "Epoch 2500, Loss: 0.0034834033576771617, Final Batch Loss: 0.0024947121273726225\n",
      "Epoch 2501, Loss: 0.00810751342214644, Final Batch Loss: 0.005759099498391151\n",
      "Epoch 2502, Loss: 0.0007475637830793858, Final Batch Loss: 0.00043606170220300555\n",
      "Epoch 2503, Loss: 0.005765087145846337, Final Batch Loss: 0.005211603827774525\n",
      "Epoch 2504, Loss: 0.0043918220908381045, Final Batch Loss: 0.00022896617883816361\n",
      "Epoch 2505, Loss: 0.00237260248104576, Final Batch Loss: 0.00013130951265338808\n",
      "Epoch 2506, Loss: 0.0005905630096094683, Final Batch Loss: 0.0002187457721447572\n",
      "Epoch 2507, Loss: 0.0005163366440683603, Final Batch Loss: 0.00012303615221753716\n",
      "Epoch 2508, Loss: 0.0023448214633390307, Final Batch Loss: 0.00023835699539631605\n",
      "Epoch 2509, Loss: 0.027527718688361347, Final Batch Loss: 0.02634093351662159\n",
      "Epoch 2510, Loss: 0.01312232343479991, Final Batch Loss: 0.008564174175262451\n",
      "Epoch 2511, Loss: 0.0025883409834932536, Final Batch Loss: 0.002343640895560384\n",
      "Epoch 2512, Loss: 0.0034444115590304136, Final Batch Loss: 0.002961355959996581\n",
      "Epoch 2513, Loss: 0.002050300012342632, Final Batch Loss: 0.0012797496747225523\n",
      "Epoch 2514, Loss: 0.001535340335976798, Final Batch Loss: 0.0014319905312731862\n",
      "Epoch 2515, Loss: 0.0003243533938075416, Final Batch Loss: 8.915147191146389e-05\n",
      "Epoch 2516, Loss: 0.0019064884982071817, Final Batch Loss: 0.0010275867534801364\n",
      "Epoch 2517, Loss: 0.0012208775151520967, Final Batch Loss: 0.0005993846571072936\n",
      "Epoch 2518, Loss: 0.00072724639903754, Final Batch Loss: 0.0002532400831114501\n",
      "Epoch 2519, Loss: 0.001376347332552541, Final Batch Loss: 0.00010829600068973377\n",
      "Epoch 2520, Loss: 0.0008485135622322559, Final Batch Loss: 0.0005983021692372859\n",
      "Epoch 2521, Loss: 0.001730944262817502, Final Batch Loss: 0.0003562190104275942\n",
      "Epoch 2522, Loss: 0.0005645029013976455, Final Batch Loss: 0.00015039471327327192\n",
      "Epoch 2523, Loss: 0.0008249027305282652, Final Batch Loss: 0.00026474136393517256\n",
      "Epoch 2524, Loss: 0.002155733876861632, Final Batch Loss: 0.0008765286765992641\n",
      "Epoch 2525, Loss: 0.0014375250320881605, Final Batch Loss: 0.0007771606324240565\n",
      "Epoch 2526, Loss: 0.0008390555740334094, Final Batch Loss: 0.0005445349379442632\n",
      "Epoch 2527, Loss: 0.0004253318729752209, Final Batch Loss: 0.0004030622076243162\n",
      "Epoch 2528, Loss: 0.00125550152733922, Final Batch Loss: 0.0006435983232222497\n",
      "Epoch 2529, Loss: 0.0006113860872574151, Final Batch Loss: 0.0005105143645778298\n",
      "Epoch 2530, Loss: 0.0038887115515535697, Final Batch Loss: 0.0001765191409504041\n",
      "Epoch 2531, Loss: 0.0035498895740602165, Final Batch Loss: 0.00042793681495822966\n",
      "Epoch 2532, Loss: 0.001352662715362385, Final Batch Loss: 0.0004201771516818553\n",
      "Epoch 2533, Loss: 0.0015696757764089853, Final Batch Loss: 0.000360564241418615\n",
      "Epoch 2534, Loss: 0.0003425144241191447, Final Batch Loss: 4.587965668179095e-05\n",
      "Epoch 2535, Loss: 0.00022914686996955425, Final Batch Loss: 6.164103979244828e-05\n",
      "Epoch 2536, Loss: 0.0006200648640515283, Final Batch Loss: 0.0004092601011507213\n",
      "Epoch 2537, Loss: 0.038655701850075275, Final Batch Loss: 0.0005507616442628205\n",
      "Epoch 2538, Loss: 0.0010763014797703363, Final Batch Loss: 0.0010241634445264935\n",
      "Epoch 2539, Loss: 0.0006353410572046414, Final Batch Loss: 0.00043681098031811416\n",
      "Epoch 2540, Loss: 0.001968200391274877, Final Batch Loss: 0.0017312346026301384\n",
      "Epoch 2541, Loss: 0.004177786991931498, Final Batch Loss: 0.0028384963516145945\n",
      "Epoch 2542, Loss: 0.0007788812799844891, Final Batch Loss: 0.0001512948947492987\n",
      "Epoch 2543, Loss: 0.0007076494657667354, Final Batch Loss: 0.00047961241216398776\n",
      "Epoch 2544, Loss: 0.0007537277269875631, Final Batch Loss: 0.0005294404691085219\n",
      "Epoch 2545, Loss: 0.02448246971471235, Final Batch Loss: 0.0009669788996689022\n",
      "Epoch 2546, Loss: 0.004545869072899222, Final Batch Loss: 0.0019093926530331373\n",
      "Epoch 2547, Loss: 0.014867774676531553, Final Batch Loss: 0.012874630279839039\n",
      "Epoch 2548, Loss: 0.0023249320656759664, Final Batch Loss: 3.719776577781886e-05\n",
      "Epoch 2549, Loss: 0.003262973972596228, Final Batch Loss: 0.002245898125693202\n",
      "Epoch 2550, Loss: 0.0005459550011437386, Final Batch Loss: 0.0002166360500268638\n",
      "Epoch 2551, Loss: 0.0005853417824255303, Final Batch Loss: 9.691373270470649e-05\n",
      "Epoch 2552, Loss: 0.003981931949965656, Final Batch Loss: 0.002363892737776041\n",
      "Epoch 2553, Loss: 0.005622579017654061, Final Batch Loss: 0.003643402364104986\n",
      "Epoch 2554, Loss: 0.0032866575638763607, Final Batch Loss: 0.0009517508442513645\n",
      "Epoch 2555, Loss: 0.0013532598386518657, Final Batch Loss: 0.0006469117943197489\n",
      "Epoch 2556, Loss: 0.0019553489983081818, Final Batch Loss: 0.0014241533353924751\n",
      "Epoch 2557, Loss: 0.002262062538648024, Final Batch Loss: 0.0017809878336265683\n",
      "Epoch 2558, Loss: 0.0009730634046718478, Final Batch Loss: 0.00045164587209001184\n",
      "Epoch 2559, Loss: 0.001215049451275263, Final Batch Loss: 6.897529965499416e-05\n",
      "Epoch 2560, Loss: 0.0002722455137700308, Final Batch Loss: 0.00022933293075766414\n",
      "Epoch 2561, Loss: 0.00045163711911300197, Final Batch Loss: 4.146423452766612e-05\n",
      "Epoch 2562, Loss: 0.0013711340143345296, Final Batch Loss: 0.0009156949818134308\n",
      "Epoch 2563, Loss: 0.0011220081069041044, Final Batch Loss: 0.000893561402335763\n",
      "Epoch 2564, Loss: 0.0010042722569778562, Final Batch Loss: 0.0005546215106733143\n",
      "Epoch 2565, Loss: 0.0005801213264930993, Final Batch Loss: 0.0003023404278792441\n",
      "Epoch 2566, Loss: 0.00027528694408829324, Final Batch Loss: 0.00022910158440936357\n",
      "Epoch 2567, Loss: 0.0038551225952687673, Final Batch Loss: 9.030510409502313e-05\n",
      "Epoch 2568, Loss: 0.0010713271767599508, Final Batch Loss: 0.00017112358182203025\n",
      "Epoch 2569, Loss: 0.00027704726380761713, Final Batch Loss: 0.00013826281065121293\n",
      "Epoch 2570, Loss: 0.0013705285382457078, Final Batch Loss: 0.0004892174038104713\n",
      "Epoch 2571, Loss: 0.00038748589577153325, Final Batch Loss: 0.00012534789857454598\n",
      "Epoch 2572, Loss: 0.00013414177010417916, Final Batch Loss: 4.722553785541095e-05\n",
      "Epoch 2573, Loss: 0.0005162982888577972, Final Batch Loss: 0.0004687351465690881\n",
      "Epoch 2574, Loss: 0.02957520048948936, Final Batch Loss: 0.0003214457246940583\n",
      "Epoch 2575, Loss: 0.001954690698767081, Final Batch Loss: 0.0016380922170355916\n",
      "Epoch 2576, Loss: 0.001648725155973807, Final Batch Loss: 0.00026546805747784674\n",
      "Epoch 2577, Loss: 0.0010126013512490317, Final Batch Loss: 9.711935126688331e-05\n",
      "Epoch 2578, Loss: 0.0011087393068009987, Final Batch Loss: 0.0009072850807569921\n",
      "Epoch 2579, Loss: 0.0030368826119229198, Final Batch Loss: 0.0018822301644831896\n",
      "Epoch 2580, Loss: 0.005141579022165388, Final Batch Loss: 0.004238570109009743\n",
      "Epoch 2581, Loss: 0.0008153386879712343, Final Batch Loss: 0.0004465514502953738\n",
      "Epoch 2582, Loss: 0.008065516478382051, Final Batch Loss: 0.007205642759799957\n",
      "Epoch 2583, Loss: 0.0011101517302449793, Final Batch Loss: 0.0009153388091363013\n",
      "Epoch 2584, Loss: 0.0013457177701639012, Final Batch Loss: 0.00011116355017293245\n",
      "Epoch 2585, Loss: 0.002529150544432923, Final Batch Loss: 0.002386789070442319\n",
      "Epoch 2586, Loss: 0.0012797327945008874, Final Batch Loss: 0.0005703223869204521\n",
      "Epoch 2587, Loss: 0.0018079854853567667, Final Batch Loss: 0.0001001411656034179\n",
      "Epoch 2588, Loss: 0.001831889123423025, Final Batch Loss: 0.00047781653120182455\n",
      "Epoch 2589, Loss: 0.0007130998419597745, Final Batch Loss: 0.000135888927616179\n",
      "Epoch 2590, Loss: 0.008590361656388268, Final Batch Loss: 0.00024448204203508794\n",
      "Epoch 2591, Loss: 0.00037624668038915843, Final Batch Loss: 0.0002394817565800622\n",
      "Epoch 2592, Loss: 0.0010464846855029464, Final Batch Loss: 0.00034918152960017323\n",
      "Epoch 2593, Loss: 0.0008132542934617959, Final Batch Loss: 9.221987420460209e-05\n",
      "Epoch 2594, Loss: 0.0003557757445378229, Final Batch Loss: 9.933758701663464e-05\n",
      "Epoch 2595, Loss: 0.0008070280600804836, Final Batch Loss: 0.0002496177621651441\n",
      "Epoch 2596, Loss: 0.007653818465769291, Final Batch Loss: 0.00044204527512192726\n",
      "Epoch 2597, Loss: 0.0009472546953475103, Final Batch Loss: 0.0007852530688978732\n",
      "Epoch 2598, Loss: 0.0018384575669188052, Final Batch Loss: 0.0002938296238426119\n",
      "Epoch 2599, Loss: 0.0047769494412932545, Final Batch Loss: 0.004536646883934736\n",
      "Epoch 2600, Loss: 0.00249473555595614, Final Batch Loss: 0.002168839331716299\n",
      "Epoch 2601, Loss: 0.0005895251524634659, Final Batch Loss: 0.0003578771429602057\n",
      "Epoch 2602, Loss: 0.002476267807651311, Final Batch Loss: 0.0017218103166669607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2603, Loss: 0.0015547816728940234, Final Batch Loss: 0.00016083531954791397\n",
      "Epoch 2604, Loss: 0.002953862349386327, Final Batch Loss: 0.00020005162514280528\n",
      "Epoch 2605, Loss: 0.0023797823523636907, Final Batch Loss: 0.0020764353685081005\n",
      "Epoch 2606, Loss: 0.0006190623244037852, Final Batch Loss: 0.00013989458966534585\n",
      "Epoch 2607, Loss: 0.0016560973890591413, Final Batch Loss: 0.0011980863055214286\n",
      "Epoch 2608, Loss: 0.00048037077067419887, Final Batch Loss: 0.000291975011350587\n",
      "Epoch 2609, Loss: 0.07913452919456176, Final Batch Loss: 0.07871375977993011\n",
      "Epoch 2610, Loss: 0.0005556861869990826, Final Batch Loss: 0.0003061590250581503\n",
      "Epoch 2611, Loss: 0.008509138016961515, Final Batch Loss: 0.00014025566633790731\n",
      "Epoch 2612, Loss: 0.00034085570950992405, Final Batch Loss: 0.00015833831275813282\n",
      "Epoch 2613, Loss: 0.0004992176254745573, Final Batch Loss: 0.00027029268676415086\n",
      "Epoch 2614, Loss: 0.0011234311095904559, Final Batch Loss: 0.0009171149577014148\n",
      "Epoch 2615, Loss: 0.004787149955518544, Final Batch Loss: 0.001717343577183783\n",
      "Epoch 2616, Loss: 0.0020940890826750547, Final Batch Loss: 0.0002819242945406586\n",
      "Epoch 2617, Loss: 0.01018303690943867, Final Batch Loss: 0.001916722976602614\n",
      "Epoch 2618, Loss: 0.0010602422116789967, Final Batch Loss: 0.0006207908154465258\n",
      "Epoch 2619, Loss: 0.0008068639581324533, Final Batch Loss: 0.0006824548472650349\n",
      "Epoch 2620, Loss: 0.0004684495506808162, Final Batch Loss: 0.00024717985070310533\n",
      "Epoch 2621, Loss: 0.0007887921383371577, Final Batch Loss: 0.00014137550897430629\n",
      "Epoch 2622, Loss: 0.0054371432634070516, Final Batch Loss: 0.004596611484885216\n",
      "Epoch 2623, Loss: 0.0005797288904432207, Final Batch Loss: 0.00022740699932910502\n",
      "Epoch 2624, Loss: 0.0004664013395085931, Final Batch Loss: 0.0001069118152372539\n",
      "Epoch 2625, Loss: 0.006345142814097926, Final Batch Loss: 0.005972252227365971\n",
      "Epoch 2626, Loss: 0.0007205610381788574, Final Batch Loss: 0.00010621043475111946\n",
      "Epoch 2627, Loss: 0.00144771792110987, Final Batch Loss: 0.00014740080223418772\n",
      "Epoch 2628, Loss: 0.0011253647971898317, Final Batch Loss: 0.0008170868386514485\n",
      "Epoch 2629, Loss: 0.0018209758782177232, Final Batch Loss: 7.057931361487135e-05\n",
      "Epoch 2630, Loss: 0.0013857801677659154, Final Batch Loss: 0.0009843165753409266\n",
      "Epoch 2631, Loss: 0.000728334161976818, Final Batch Loss: 0.0006205987301655114\n",
      "Epoch 2632, Loss: 0.004977004078682512, Final Batch Loss: 0.0004211747436784208\n",
      "Epoch 2633, Loss: 0.009001457714475691, Final Batch Loss: 0.0012752778129652143\n",
      "Epoch 2634, Loss: 0.002227352320915088, Final Batch Loss: 0.00028303483850322664\n",
      "Epoch 2635, Loss: 0.0014604633615817875, Final Batch Loss: 0.0004604825226124376\n",
      "Epoch 2636, Loss: 0.0003382507093192544, Final Batch Loss: 2.5904151698341593e-05\n",
      "Epoch 2637, Loss: 0.002165832440368831, Final Batch Loss: 0.0005863771075382829\n",
      "Epoch 2638, Loss: 0.00039384682895615697, Final Batch Loss: 0.0002349884161958471\n",
      "Epoch 2639, Loss: 0.015325451226090081, Final Batch Loss: 0.0002414444024907425\n",
      "Epoch 2640, Loss: 0.002142358891433105, Final Batch Loss: 0.001835476839914918\n",
      "Epoch 2641, Loss: 0.00028636508068302646, Final Batch Loss: 0.0001938034693012014\n",
      "Epoch 2642, Loss: 0.0005152804351382656, Final Batch Loss: 2.926055276475381e-05\n",
      "Epoch 2643, Loss: 0.001671352598350495, Final Batch Loss: 0.0007961111841723323\n",
      "Epoch 2644, Loss: 0.0002793730527628213, Final Batch Loss: 0.00018916960107162595\n",
      "Epoch 2645, Loss: 0.000568743038456887, Final Batch Loss: 6.221240619197488e-05\n",
      "Epoch 2646, Loss: 0.00860765716060996, Final Batch Loss: 0.003988328855484724\n",
      "Epoch 2647, Loss: 0.000503285598824732, Final Batch Loss: 0.00015710473235230893\n",
      "Epoch 2648, Loss: 0.0017158093396574259, Final Batch Loss: 0.0008677236037328839\n",
      "Epoch 2649, Loss: 0.0008721558551769704, Final Batch Loss: 0.00016864066128619015\n",
      "Epoch 2650, Loss: 0.0005415825871750712, Final Batch Loss: 0.00022471515694633126\n",
      "Epoch 2651, Loss: 9.979051901609637e-05, Final Batch Loss: 3.878356801578775e-05\n",
      "Epoch 2652, Loss: 0.0009021724690683186, Final Batch Loss: 0.00020161777501925826\n",
      "Epoch 2653, Loss: 0.0010008399258367717, Final Batch Loss: 0.0007419143221341074\n",
      "Epoch 2654, Loss: 0.006789553321141284, Final Batch Loss: 0.006723667029291391\n",
      "Epoch 2655, Loss: 0.0009201312786899507, Final Batch Loss: 0.0003555829753167927\n",
      "Epoch 2656, Loss: 0.0012452804658096284, Final Batch Loss: 0.0011583258165046573\n",
      "Epoch 2657, Loss: 0.0036511911312118173, Final Batch Loss: 0.001978914486244321\n",
      "Epoch 2658, Loss: 0.04168490486335941, Final Batch Loss: 0.04148466885089874\n",
      "Epoch 2659, Loss: 0.0009169094555545598, Final Batch Loss: 0.000690940476488322\n",
      "Epoch 2660, Loss: 0.0005289106338750571, Final Batch Loss: 0.0003315249632578343\n",
      "Epoch 2661, Loss: 0.0006315407226793468, Final Batch Loss: 0.00041551757021807134\n",
      "Epoch 2662, Loss: 0.0004838660970563069, Final Batch Loss: 0.000323812710121274\n",
      "Epoch 2663, Loss: 0.0013448967802105471, Final Batch Loss: 0.0001789934904081747\n",
      "Epoch 2664, Loss: 0.0012191933128633536, Final Batch Loss: 8.724196959519759e-05\n",
      "Epoch 2665, Loss: 0.0012530745880212635, Final Batch Loss: 0.0003773276403080672\n",
      "Epoch 2666, Loss: 0.0005661081522703171, Final Batch Loss: 0.00040011396049521863\n",
      "Epoch 2667, Loss: 0.0019303938606753945, Final Batch Loss: 0.0010468531399965286\n",
      "Epoch 2668, Loss: 0.003783284511882812, Final Batch Loss: 0.003711516270413995\n",
      "Epoch 2669, Loss: 0.001320412615314126, Final Batch Loss: 0.00013955635949969292\n",
      "Epoch 2670, Loss: 0.0017269922536797822, Final Batch Loss: 0.0012883602175861597\n",
      "Epoch 2671, Loss: 0.004356910634669475, Final Batch Loss: 0.0041937632486224174\n",
      "Epoch 2672, Loss: 0.0019274625228717923, Final Batch Loss: 0.00119100755546242\n",
      "Epoch 2673, Loss: 0.010560244496446103, Final Batch Loss: 0.00018968357471749187\n",
      "Epoch 2674, Loss: 0.002133973172021797, Final Batch Loss: 2.5131968868663535e-05\n",
      "Epoch 2675, Loss: 0.0017343368963338435, Final Batch Loss: 0.0010900141205638647\n",
      "Epoch 2676, Loss: 0.009743616406922229, Final Batch Loss: 0.00018760417879093438\n",
      "Epoch 2677, Loss: 0.004911330837785499, Final Batch Loss: 4.9819547712104395e-05\n",
      "Epoch 2678, Loss: 0.00016575225163251162, Final Batch Loss: 4.4014930608682334e-05\n",
      "Epoch 2679, Loss: 0.003639141796156764, Final Batch Loss: 0.0023676250129938126\n",
      "Epoch 2680, Loss: 0.0005023028497816995, Final Batch Loss: 0.00013909621338825673\n",
      "Epoch 2681, Loss: 0.0010256401146762073, Final Batch Loss: 0.0007641919073648751\n",
      "Epoch 2682, Loss: 0.003053996479138732, Final Batch Loss: 0.001134800142608583\n",
      "Epoch 2683, Loss: 0.0002362985906074755, Final Batch Loss: 0.0001331386883975938\n",
      "Epoch 2684, Loss: 0.008362354506971315, Final Batch Loss: 0.007965351454913616\n",
      "Epoch 2685, Loss: 0.005660577880917117, Final Batch Loss: 0.005260884761810303\n",
      "Epoch 2686, Loss: 0.009870090172626078, Final Batch Loss: 0.009033102542161942\n",
      "Epoch 2687, Loss: 0.001229367138876114, Final Batch Loss: 0.00011802293738583103\n",
      "Epoch 2688, Loss: 0.002248348231660202, Final Batch Loss: 0.0017618086421862245\n",
      "Epoch 2689, Loss: 0.0006569623437826522, Final Batch Loss: 6.526447396026924e-05\n",
      "Epoch 2690, Loss: 0.0004506378754740581, Final Batch Loss: 0.00019649970636237413\n",
      "Epoch 2691, Loss: 0.000834178106742911, Final Batch Loss: 0.0002168690407415852\n",
      "Epoch 2692, Loss: 0.0025527437537675723, Final Batch Loss: 0.0025285251904278994\n",
      "Epoch 2693, Loss: 0.0002911347401095554, Final Batch Loss: 7.78647226979956e-05\n",
      "Epoch 2694, Loss: 0.0011070611653849483, Final Batch Loss: 0.0006082435720600188\n",
      "Epoch 2695, Loss: 0.002360006852541119, Final Batch Loss: 0.002145495731383562\n",
      "Epoch 2696, Loss: 0.0007647157472092658, Final Batch Loss: 0.00013083338853903115\n",
      "Epoch 2697, Loss: 0.0039265457016881555, Final Batch Loss: 0.0002506036253180355\n",
      "Epoch 2698, Loss: 0.00949658545141574, Final Batch Loss: 0.009313825517892838\n",
      "Epoch 2699, Loss: 0.00029037495551165193, Final Batch Loss: 0.00016161768871825188\n",
      "Epoch 2700, Loss: 0.001042982650687918, Final Batch Loss: 0.0004435947921592742\n",
      "Epoch 2701, Loss: 0.0003886696358677, Final Batch Loss: 1.0168994776904583e-05\n",
      "Epoch 2702, Loss: 0.0015893331146799028, Final Batch Loss: 0.0009114716085605323\n",
      "Epoch 2703, Loss: 0.001102227412047796, Final Batch Loss: 2.0962717826478183e-05\n",
      "Epoch 2704, Loss: 0.02298260103270877, Final Batch Loss: 0.0001982673566089943\n",
      "Epoch 2705, Loss: 0.010587977827526629, Final Batch Loss: 0.0007010983536019921\n",
      "Epoch 2706, Loss: 0.0009093123662751168, Final Batch Loss: 7.37626978661865e-05\n",
      "Epoch 2707, Loss: 0.0005543355291592889, Final Batch Loss: 9.535814024275169e-05\n",
      "Epoch 2708, Loss: 0.00036422178527573124, Final Batch Loss: 0.00026777343009598553\n",
      "Epoch 2709, Loss: 0.0003552870257408358, Final Batch Loss: 4.4563210394699126e-05\n",
      "Epoch 2710, Loss: 0.0005425397393992171, Final Batch Loss: 0.0002151579683413729\n",
      "Epoch 2711, Loss: 0.0005892900480830576, Final Batch Loss: 5.982711081742309e-05\n",
      "Epoch 2712, Loss: 0.00029584743606392294, Final Batch Loss: 0.00019108562264591455\n",
      "Epoch 2713, Loss: 0.006203702534548938, Final Batch Loss: 0.005567873828113079\n",
      "Epoch 2714, Loss: 0.001894536631880328, Final Batch Loss: 0.001546776038594544\n",
      "Epoch 2715, Loss: 0.00048343116941396147, Final Batch Loss: 0.00031412221142090857\n",
      "Epoch 2716, Loss: 0.0007576700008939952, Final Batch Loss: 0.00019139828509651124\n",
      "Epoch 2717, Loss: 0.0017874694021884352, Final Batch Loss: 0.00023198130656965077\n",
      "Epoch 2718, Loss: 0.0007116948690963909, Final Batch Loss: 0.00019787786004599184\n",
      "Epoch 2719, Loss: 0.00038490555743919685, Final Batch Loss: 9.225487156072631e-05\n",
      "Epoch 2720, Loss: 0.0006852981969132088, Final Batch Loss: 6.486989877885208e-05\n",
      "Epoch 2721, Loss: 0.00023425482504535466, Final Batch Loss: 7.123469549696892e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2722, Loss: 0.000866803718963638, Final Batch Loss: 0.000516890489961952\n",
      "Epoch 2723, Loss: 0.000895777324330993, Final Batch Loss: 4.988339787814766e-05\n",
      "Epoch 2724, Loss: 0.0007818611775292084, Final Batch Loss: 7.695045496802777e-05\n",
      "Epoch 2725, Loss: 0.0003281211538705975, Final Batch Loss: 0.00018226291285827756\n",
      "Epoch 2726, Loss: 0.0006860452704131603, Final Batch Loss: 7.531529990956187e-05\n",
      "Epoch 2727, Loss: 0.000550611992366612, Final Batch Loss: 0.00013244521687738597\n",
      "Epoch 2728, Loss: 0.0007269129855558276, Final Batch Loss: 0.0002819623041432351\n",
      "Epoch 2729, Loss: 0.0010587840079097077, Final Batch Loss: 0.0009577801683917642\n",
      "Epoch 2730, Loss: 0.02559008909156546, Final Batch Loss: 0.00011561153223738074\n",
      "Epoch 2731, Loss: 0.00031531987042399123, Final Batch Loss: 0.00011678135342663154\n",
      "Epoch 2732, Loss: 0.0014524087600875646, Final Batch Loss: 0.00123578158672899\n",
      "Epoch 2733, Loss: 0.0005150410579517484, Final Batch Loss: 0.00021002395078539848\n",
      "Epoch 2734, Loss: 0.00046222266973927617, Final Batch Loss: 0.00032744568306952715\n",
      "Epoch 2735, Loss: 0.0004669483896577731, Final Batch Loss: 0.00031080737244337797\n",
      "Epoch 2736, Loss: 0.0006876719853607938, Final Batch Loss: 0.00023630638315808028\n",
      "Epoch 2737, Loss: 0.0010988776048179716, Final Batch Loss: 0.00030498215346597135\n",
      "Epoch 2738, Loss: 0.0005433680344140157, Final Batch Loss: 0.00022603913384955376\n",
      "Epoch 2739, Loss: 0.0007627629966009408, Final Batch Loss: 0.00036746374098584056\n",
      "Epoch 2740, Loss: 0.0005527432804228738, Final Batch Loss: 0.0001106753625208512\n",
      "Epoch 2741, Loss: 0.0021353865158744156, Final Batch Loss: 0.0009669714490883052\n",
      "Epoch 2742, Loss: 0.0005400000518420711, Final Batch Loss: 0.0004356458957772702\n",
      "Epoch 2743, Loss: 0.005011400498915464, Final Batch Loss: 0.004453334491699934\n",
      "Epoch 2744, Loss: 0.001044877921231091, Final Batch Loss: 0.0006885695038363338\n",
      "Epoch 2745, Loss: 0.0007622090706718154, Final Batch Loss: 0.0006514457054436207\n",
      "Epoch 2746, Loss: 0.0005405335978139192, Final Batch Loss: 0.00037805744796060026\n",
      "Epoch 2747, Loss: 0.0004136772913625464, Final Batch Loss: 0.00031489713001064956\n",
      "Epoch 2748, Loss: 0.006080150604248047, Final Batch Loss: 0.004917494487017393\n",
      "Epoch 2749, Loss: 0.0003992945494246669, Final Batch Loss: 9.897017298499122e-05\n",
      "Epoch 2750, Loss: 0.0006556503212777898, Final Batch Loss: 0.00023661703744437546\n",
      "Epoch 2751, Loss: 0.005313227651640773, Final Batch Loss: 0.0008372196462005377\n",
      "Epoch 2752, Loss: 0.00012849169434048235, Final Batch Loss: 5.3555413614958525e-05\n",
      "Epoch 2753, Loss: 0.0010973423341056332, Final Batch Loss: 0.0009491711389273405\n",
      "Epoch 2754, Loss: 0.00013946651597507298, Final Batch Loss: 8.37244515423663e-05\n",
      "Epoch 2755, Loss: 0.002406726940535009, Final Batch Loss: 0.0012488332577049732\n",
      "Epoch 2756, Loss: 0.00019823599541268777, Final Batch Loss: 3.003148412972223e-05\n",
      "Epoch 2757, Loss: 0.005862471356522292, Final Batch Loss: 0.005356720648705959\n",
      "Epoch 2758, Loss: 0.00024048876730375923, Final Batch Loss: 3.3370964956702664e-05\n",
      "Epoch 2759, Loss: 0.0019462694181129336, Final Batch Loss: 0.000977680436335504\n",
      "Epoch 2760, Loss: 0.0011821893276646733, Final Batch Loss: 0.0002815856132656336\n",
      "Epoch 2761, Loss: 0.00024749176736804657, Final Batch Loss: 0.0002053836506092921\n",
      "Epoch 2762, Loss: 0.0006229606151464395, Final Batch Loss: 0.0005288819666020572\n",
      "Epoch 2763, Loss: 0.0007425161602441221, Final Batch Loss: 0.0002383115643169731\n",
      "Epoch 2764, Loss: 0.0003035280024050735, Final Batch Loss: 8.820968650979921e-05\n",
      "Epoch 2765, Loss: 0.00028518847466330044, Final Batch Loss: 5.9605659771477804e-05\n",
      "Epoch 2766, Loss: 0.0022375333355739713, Final Batch Loss: 0.0014558346010744572\n",
      "Epoch 2767, Loss: 0.0003556472802301869, Final Batch Loss: 0.00019699100812431425\n",
      "Epoch 2768, Loss: 0.0009303779515903443, Final Batch Loss: 0.00047564684064127505\n",
      "Epoch 2769, Loss: 0.0004019673360744491, Final Batch Loss: 0.0002821586967911571\n",
      "Epoch 2770, Loss: 0.002647647459525615, Final Batch Loss: 0.001770858303643763\n",
      "Epoch 2771, Loss: 0.004415843970491551, Final Batch Loss: 0.0001620257826289162\n",
      "Epoch 2772, Loss: 0.015033204690553248, Final Batch Loss: 0.014048806391656399\n",
      "Epoch 2773, Loss: 0.0020063443371327594, Final Batch Loss: 0.0019025946967303753\n",
      "Epoch 2774, Loss: 0.0002797496745188255, Final Batch Loss: 4.023233850602992e-05\n",
      "Epoch 2775, Loss: 0.028345807862933725, Final Batch Loss: 0.027961354702711105\n",
      "Epoch 2776, Loss: 0.0006273448816500604, Final Batch Loss: 0.0005534171359613538\n",
      "Epoch 2777, Loss: 0.0005078918547951616, Final Batch Loss: 0.00010375970305176452\n",
      "Epoch 2778, Loss: 0.0001804848070605658, Final Batch Loss: 6.746142753399909e-05\n",
      "Epoch 2779, Loss: 0.0012152669587521814, Final Batch Loss: 3.853820817312226e-05\n",
      "Epoch 2780, Loss: 0.0016048148390837014, Final Batch Loss: 0.0006911340751685202\n",
      "Epoch 2781, Loss: 0.0008035329046833795, Final Batch Loss: 4.678354525822215e-05\n",
      "Epoch 2782, Loss: 0.00022762334992876276, Final Batch Loss: 0.00015323919069487602\n",
      "Epoch 2783, Loss: 0.0004527149758359883, Final Batch Loss: 5.903028431930579e-05\n",
      "Epoch 2784, Loss: 0.0012025802861899137, Final Batch Loss: 0.0005767992115579545\n",
      "Epoch 2785, Loss: 0.0010574032785370946, Final Batch Loss: 0.00025789730716496706\n",
      "Epoch 2786, Loss: 0.0005210954768699594, Final Batch Loss: 3.149640542687848e-05\n",
      "Epoch 2787, Loss: 0.0007740281289443374, Final Batch Loss: 0.0003223076637368649\n",
      "Epoch 2788, Loss: 0.000566896593227284, Final Batch Loss: 0.0005139071145094931\n",
      "Epoch 2789, Loss: 0.0011849317816086113, Final Batch Loss: 0.0007156735518947244\n",
      "Epoch 2790, Loss: 0.0005473671481013298, Final Batch Loss: 0.00039260974153876305\n",
      "Epoch 2791, Loss: 0.0002454847053741105, Final Batch Loss: 8.048673771554604e-05\n",
      "Epoch 2792, Loss: 0.0010767826024675742, Final Batch Loss: 0.00015592041017953306\n",
      "Epoch 2793, Loss: 0.005998579639708623, Final Batch Loss: 8.635115227662027e-05\n",
      "Epoch 2794, Loss: 0.0004151072571403347, Final Batch Loss: 9.90341286524199e-05\n",
      "Epoch 2795, Loss: 0.000997167342575267, Final Batch Loss: 0.0006184232188388705\n",
      "Epoch 2796, Loss: 0.00033686285132716876, Final Batch Loss: 2.705758197407704e-05\n",
      "Epoch 2797, Loss: 0.0013572218449553475, Final Batch Loss: 0.00019633058400359005\n",
      "Epoch 2798, Loss: 0.00043462650501169264, Final Batch Loss: 0.0002014390629483387\n",
      "Epoch 2799, Loss: 0.006178681098390371, Final Batch Loss: 0.0006134214927442372\n",
      "Epoch 2800, Loss: 0.0010298231500200927, Final Batch Loss: 0.0008393925381824374\n",
      "Epoch 2801, Loss: 0.0003718679799931124, Final Batch Loss: 0.00025321394787169993\n",
      "Epoch 2802, Loss: 0.0004097111159353517, Final Batch Loss: 0.0003727099683601409\n",
      "Epoch 2803, Loss: 0.00034564405359560624, Final Batch Loss: 0.00011858122161356732\n",
      "Epoch 2804, Loss: 0.00022101886861491948, Final Batch Loss: 0.00011283256753813475\n",
      "Epoch 2805, Loss: 0.00021794807980768383, Final Batch Loss: 0.0001916311593959108\n",
      "Epoch 2806, Loss: 0.0008363586093764752, Final Batch Loss: 0.0004232554347254336\n",
      "Epoch 2807, Loss: 0.005530177033506334, Final Batch Loss: 0.0051514399237930775\n",
      "Epoch 2808, Loss: 0.003443206471274607, Final Batch Loss: 7.583135447930545e-05\n",
      "Epoch 2809, Loss: 0.0008099645492620766, Final Batch Loss: 0.0006577605963684618\n",
      "Epoch 2810, Loss: 0.0006055109406588599, Final Batch Loss: 0.00039633686537854373\n",
      "Epoch 2811, Loss: 0.0021392579656094313, Final Batch Loss: 0.0007035558810457587\n",
      "Epoch 2812, Loss: 0.0006667925044894218, Final Batch Loss: 0.00025375690893270075\n",
      "Epoch 2813, Loss: 0.0006843725132057443, Final Batch Loss: 0.000578664185013622\n",
      "Epoch 2814, Loss: 0.00024720356304896995, Final Batch Loss: 0.0001377466251142323\n",
      "Epoch 2815, Loss: 0.0008406961896980647, Final Batch Loss: 0.0008091104100458324\n",
      "Epoch 2816, Loss: 0.00024867116371751763, Final Batch Loss: 0.00020368958939798176\n",
      "Epoch 2817, Loss: 0.003859748539980501, Final Batch Loss: 0.0034726683516055346\n",
      "Epoch 2818, Loss: 0.0010380625244579278, Final Batch Loss: 5.6370066886302084e-05\n",
      "Epoch 2819, Loss: 0.001454257479053922, Final Batch Loss: 0.0013608495937660336\n",
      "Epoch 2820, Loss: 0.0014419991421164013, Final Batch Loss: 2.2945379896555096e-05\n",
      "Epoch 2821, Loss: 0.0007562604732811451, Final Batch Loss: 0.0005331422435119748\n",
      "Epoch 2822, Loss: 0.0014734012074768543, Final Batch Loss: 0.001232033595442772\n",
      "Epoch 2823, Loss: 0.00010049004413303919, Final Batch Loss: 5.7040746469283476e-05\n",
      "Epoch 2824, Loss: 0.01031586920726113, Final Batch Loss: 0.010069009847939014\n",
      "Epoch 2825, Loss: 0.0005546038883039728, Final Batch Loss: 4.229661135468632e-05\n",
      "Epoch 2826, Loss: 0.018575480818981305, Final Batch Loss: 7.644729339517653e-05\n",
      "Epoch 2827, Loss: 0.00126926094526425, Final Batch Loss: 0.0005802506348118186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2828, Loss: 0.00023716029136267025, Final Batch Loss: 2.195655724790413e-05\n",
      "Epoch 2829, Loss: 0.00031530787964584306, Final Batch Loss: 6.043303437763825e-05\n",
      "Epoch 2830, Loss: 0.0002761613213806413, Final Batch Loss: 0.00019827019423246384\n",
      "Epoch 2831, Loss: 0.007567239634227008, Final Batch Loss: 0.007110114209353924\n",
      "Epoch 2832, Loss: 0.00015118779992917553, Final Batch Loss: 9.43281629588455e-05\n",
      "Epoch 2833, Loss: 0.00262358010513708, Final Batch Loss: 0.00026345154037699103\n",
      "Epoch 2834, Loss: 0.0015397053066408262, Final Batch Loss: 0.0014626807533204556\n",
      "Epoch 2835, Loss: 0.0003591463537304662, Final Batch Loss: 0.00028775999089702964\n",
      "Epoch 2836, Loss: 0.001072179882612545, Final Batch Loss: 6.307278090389445e-05\n",
      "Epoch 2837, Loss: 0.0007051011198200285, Final Batch Loss: 0.00016062083886936307\n",
      "Epoch 2838, Loss: 0.002165632846299559, Final Batch Loss: 0.0004952158196829259\n",
      "Epoch 2839, Loss: 0.000716458962415345, Final Batch Loss: 7.20123789506033e-05\n",
      "Epoch 2840, Loss: 0.011152720595418941, Final Batch Loss: 3.6236415326129645e-05\n",
      "Epoch 2841, Loss: 0.020261205529095605, Final Batch Loss: 0.01981252059340477\n",
      "Epoch 2842, Loss: 0.0014699656749144197, Final Batch Loss: 0.000647124950774014\n",
      "Epoch 2843, Loss: 0.0015793853381182998, Final Batch Loss: 0.001369303441606462\n",
      "Epoch 2844, Loss: 0.0016378771106246859, Final Batch Loss: 0.0014068613527342677\n",
      "Epoch 2845, Loss: 0.0011098286195192486, Final Batch Loss: 0.00039372991886921227\n",
      "Epoch 2846, Loss: 0.0009484529773544637, Final Batch Loss: 1.1701432413246948e-05\n",
      "Epoch 2847, Loss: 0.0007083875971147791, Final Batch Loss: 0.0005877056973986328\n",
      "Epoch 2848, Loss: 0.0007199997126008384, Final Batch Loss: 0.0006302507244981825\n",
      "Epoch 2849, Loss: 0.00020196922559989616, Final Batch Loss: 0.00016132148448377848\n",
      "Epoch 2850, Loss: 0.0010953583987429738, Final Batch Loss: 0.0008688349043950438\n",
      "Epoch 2851, Loss: 0.000835645041661337, Final Batch Loss: 0.0008110482012853026\n",
      "Epoch 2852, Loss: 0.0005881889301235788, Final Batch Loss: 0.00012206273822812364\n",
      "Epoch 2853, Loss: 0.00041399728070246056, Final Batch Loss: 0.0003399265988264233\n",
      "Epoch 2854, Loss: 0.0009970620012609288, Final Batch Loss: 0.00018777463992591947\n",
      "Epoch 2855, Loss: 0.0006013165402691811, Final Batch Loss: 2.3531581973657012e-05\n",
      "Epoch 2856, Loss: 0.0014501728874165565, Final Batch Loss: 0.0001285312755499035\n",
      "Epoch 2857, Loss: 0.00030229027720451995, Final Batch Loss: 3.3166677440021886e-06\n",
      "Epoch 2858, Loss: 0.0002423679397907108, Final Batch Loss: 9.388488251715899e-05\n",
      "Epoch 2859, Loss: 0.0057169243755197385, Final Batch Loss: 2.3175316528067924e-05\n",
      "Epoch 2860, Loss: 0.011958243187109474, Final Batch Loss: 0.01188145112246275\n",
      "Epoch 2861, Loss: 4.5386954298010096e-05, Final Batch Loss: 2.2013697162037715e-05\n",
      "Epoch 2862, Loss: 0.017953429822227918, Final Batch Loss: 0.01772041991353035\n",
      "Epoch 2863, Loss: 0.000259422798990272, Final Batch Loss: 0.00011818630446214229\n",
      "Epoch 2864, Loss: 0.0003748700692085549, Final Batch Loss: 0.00013102249067742378\n",
      "Epoch 2865, Loss: 0.004494177526794374, Final Batch Loss: 0.0008912492776289582\n",
      "Epoch 2866, Loss: 0.012807078441255726, Final Batch Loss: 0.00018645708041731268\n",
      "Epoch 2867, Loss: 0.025375170189363416, Final Batch Loss: 2.762444637482986e-05\n",
      "Epoch 2868, Loss: 0.00026374122535344213, Final Batch Loss: 0.00013617362128570676\n",
      "Epoch 2869, Loss: 0.0019944146915804595, Final Batch Loss: 0.001706657581962645\n",
      "Epoch 2870, Loss: 0.0010327569907531142, Final Batch Loss: 0.00050595827633515\n",
      "Epoch 2871, Loss: 0.011452449733042158, Final Batch Loss: 0.0001240989804500714\n",
      "Epoch 2872, Loss: 0.005268904089462012, Final Batch Loss: 0.0044873179867863655\n",
      "Epoch 2873, Loss: 0.0012244341778568923, Final Batch Loss: 0.0001439791521988809\n",
      "Epoch 2874, Loss: 0.016326102435414214, Final Batch Loss: 9.916816634358838e-05\n",
      "Epoch 2875, Loss: 0.0047838054451858625, Final Batch Loss: 0.00010307178308721632\n",
      "Epoch 2876, Loss: 0.0029386478126980364, Final Batch Loss: 0.000821656605694443\n",
      "Epoch 2877, Loss: 0.00017206906341016293, Final Batch Loss: 8.322124631376937e-05\n",
      "Epoch 2878, Loss: 0.00019056482778978534, Final Batch Loss: 3.272864341852255e-05\n",
      "Epoch 2879, Loss: 0.003757810336537659, Final Batch Loss: 0.00310957501642406\n",
      "Epoch 2880, Loss: 0.0004016914317617193, Final Batch Loss: 0.00017453543841838837\n",
      "Epoch 2881, Loss: 0.0006094934069551528, Final Batch Loss: 0.0001169443130493164\n",
      "Epoch 2882, Loss: 0.0005286026425892487, Final Batch Loss: 0.00022156820341479033\n",
      "Epoch 2883, Loss: 0.015339171746745706, Final Batch Loss: 0.012258555740118027\n",
      "Epoch 2884, Loss: 0.003312909509986639, Final Batch Loss: 0.0013558818027377129\n",
      "Epoch 2885, Loss: 0.0008177344643627293, Final Batch Loss: 0.0007510814466513693\n",
      "Epoch 2886, Loss: 0.0002600104453449603, Final Batch Loss: 4.6459488658001646e-05\n",
      "Epoch 2887, Loss: 0.000609287031693384, Final Batch Loss: 0.00035294913686811924\n",
      "Epoch 2888, Loss: 0.0032106749422382563, Final Batch Loss: 0.0030689481645822525\n",
      "Epoch 2889, Loss: 0.0018834495567716658, Final Batch Loss: 0.0006669395952485502\n",
      "Epoch 2890, Loss: 0.00021527698845602572, Final Batch Loss: 4.411325789988041e-05\n",
      "Epoch 2891, Loss: 0.0019308015471324325, Final Batch Loss: 0.0005016286158934236\n",
      "Epoch 2892, Loss: 0.0012410353810992092, Final Batch Loss: 0.0002526006137486547\n",
      "Epoch 2893, Loss: 0.0002864287162083201, Final Batch Loss: 0.00018759856175165623\n",
      "Epoch 2894, Loss: 0.0026300456083845347, Final Batch Loss: 0.0001542390964459628\n",
      "Epoch 2895, Loss: 0.0005842057726113126, Final Batch Loss: 0.00023438023345079273\n",
      "Epoch 2896, Loss: 0.00019878595048794523, Final Batch Loss: 0.00015702861128374934\n",
      "Epoch 2897, Loss: 0.0001965936171473004, Final Batch Loss: 0.0001008011240628548\n",
      "Epoch 2898, Loss: 0.000326410365346419, Final Batch Loss: 1.8715728629103978e-06\n",
      "Epoch 2899, Loss: 0.0003641504590632394, Final Batch Loss: 0.00011816689220722765\n",
      "Epoch 2900, Loss: 0.0008004191622603685, Final Batch Loss: 0.00016189509187825024\n",
      "Epoch 2901, Loss: 0.0016347833443433046, Final Batch Loss: 0.0010269515914842486\n",
      "Epoch 2902, Loss: 0.0010525407415116206, Final Batch Loss: 0.0008881640387699008\n",
      "Epoch 2903, Loss: 0.0006679716898361221, Final Batch Loss: 6.753027264494449e-05\n",
      "Epoch 2904, Loss: 0.003733827732503414, Final Batch Loss: 0.0024254501331597567\n",
      "Epoch 2905, Loss: 0.0015681053046137094, Final Batch Loss: 0.0009435409447178245\n",
      "Epoch 2906, Loss: 0.00048305615200661123, Final Batch Loss: 8.71936499606818e-05\n",
      "Epoch 2907, Loss: 0.0012579586036736146, Final Batch Loss: 0.0010977438651025295\n",
      "Epoch 2908, Loss: 0.0007842570994398557, Final Batch Loss: 0.0007055355235934258\n",
      "Epoch 2909, Loss: 0.05468933540396392, Final Batch Loss: 0.0006006013136357069\n",
      "Epoch 2910, Loss: 0.008282904047518969, Final Batch Loss: 0.0015257210470736027\n",
      "Epoch 2911, Loss: 0.000117844403575873, Final Batch Loss: 3.9631046092836186e-05\n",
      "Epoch 2912, Loss: 0.004886199487373233, Final Batch Loss: 0.0030864235013723373\n",
      "Epoch 2913, Loss: 0.0013081844081170857, Final Batch Loss: 0.001199980266392231\n",
      "Epoch 2914, Loss: 0.014467157496255822, Final Batch Loss: 2.421073440928012e-05\n",
      "Epoch 2915, Loss: 0.0011321657511871308, Final Batch Loss: 0.00016822907491587102\n",
      "Epoch 2916, Loss: 0.034358600663836114, Final Batch Loss: 0.03428919240832329\n",
      "Epoch 2917, Loss: 0.00040691990670893574, Final Batch Loss: 1.0712058610806707e-05\n",
      "Epoch 2918, Loss: 0.000201367507543182, Final Batch Loss: 4.7422985517187044e-05\n",
      "Epoch 2919, Loss: 0.0007273716037161648, Final Batch Loss: 0.0002897223748732358\n",
      "Epoch 2920, Loss: 0.003930388840672094, Final Batch Loss: 0.0038611763156950474\n",
      "Epoch 2921, Loss: 0.0005287290914566256, Final Batch Loss: 0.00043996868771500885\n",
      "Epoch 2922, Loss: 0.009036581526743248, Final Batch Loss: 0.008876843377947807\n",
      "Epoch 2923, Loss: 0.0004624025477824034, Final Batch Loss: 2.482223862898536e-06\n",
      "Epoch 2924, Loss: 0.003362801391631365, Final Batch Loss: 0.00017843395471572876\n",
      "Epoch 2925, Loss: 0.0021312194658094086, Final Batch Loss: 0.0001132040997617878\n",
      "Epoch 2926, Loss: 0.004067951871547848, Final Batch Loss: 0.0007307211053557694\n",
      "Epoch 2927, Loss: 0.0012126266956329346, Final Batch Loss: 0.0008879160159267485\n",
      "Epoch 2928, Loss: 0.0016865386351128109, Final Batch Loss: 0.00011304015788482502\n",
      "Epoch 2929, Loss: 0.000953222654061392, Final Batch Loss: 0.00027659369516186416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2930, Loss: 0.004149972082814202, Final Batch Loss: 0.0038027993869036436\n",
      "Epoch 2931, Loss: 0.0015392160275951028, Final Batch Loss: 2.005568239837885e-05\n",
      "Epoch 2932, Loss: 0.002750359184574336, Final Batch Loss: 0.00027086184127256274\n",
      "Epoch 2933, Loss: 0.0015862604486756027, Final Batch Loss: 0.0011647295905277133\n",
      "Epoch 2934, Loss: 0.003595890069846064, Final Batch Loss: 0.0029523097909986973\n",
      "Epoch 2935, Loss: 0.000639885023701936, Final Batch Loss: 0.00015932341921143234\n",
      "Epoch 2936, Loss: 0.0005364629032555968, Final Batch Loss: 3.893280518241227e-05\n",
      "Epoch 2937, Loss: 0.0002936080454674084, Final Batch Loss: 0.0002693906717468053\n",
      "Epoch 2938, Loss: 0.0034460505994502455, Final Batch Loss: 0.0031100306659936905\n",
      "Epoch 2939, Loss: 0.0011225466732867062, Final Batch Loss: 0.00043420540168881416\n",
      "Epoch 2940, Loss: 0.0005079669062979519, Final Batch Loss: 0.00012955363490618765\n",
      "Epoch 2941, Loss: 0.004812416242202744, Final Batch Loss: 0.004721539560705423\n",
      "Epoch 2942, Loss: 0.0010237055939796846, Final Batch Loss: 1.954218532773666e-05\n",
      "Epoch 2943, Loss: 0.00038049667091399897, Final Batch Loss: 1.827933192544151e-05\n",
      "Epoch 2944, Loss: 0.00340155532467179, Final Batch Loss: 0.0033490790519863367\n",
      "Epoch 2945, Loss: 7.250947601278313e-05, Final Batch Loss: 5.0285620091017336e-05\n",
      "Epoch 2946, Loss: 0.00021526716591324657, Final Batch Loss: 0.0001010400228551589\n",
      "Epoch 2947, Loss: 0.0005232505063759163, Final Batch Loss: 0.0003547978703863919\n",
      "Epoch 2948, Loss: 0.0007420983274641912, Final Batch Loss: 0.0007300504366867244\n",
      "Epoch 2949, Loss: 0.00045449231402017176, Final Batch Loss: 0.00033182508195750415\n",
      "Epoch 2950, Loss: 0.00011399316645110957, Final Batch Loss: 3.114524224656634e-05\n",
      "Epoch 2951, Loss: 0.0008784447563812137, Final Batch Loss: 0.0005237567820586264\n",
      "Epoch 2952, Loss: 0.0005900502001168206, Final Batch Loss: 0.0002113666123477742\n",
      "Epoch 2953, Loss: 0.00176693189132493, Final Batch Loss: 0.00018904257740359753\n",
      "Epoch 2954, Loss: 0.000370647365343757, Final Batch Loss: 7.745072070974857e-05\n",
      "Epoch 2955, Loss: 0.0006315393256954849, Final Batch Loss: 0.00033025615266524255\n",
      "Epoch 2956, Loss: 0.0010318067797925323, Final Batch Loss: 0.0007147823343984783\n",
      "Epoch 2957, Loss: 0.0016114394238684326, Final Batch Loss: 0.0015732005704194307\n",
      "Epoch 2958, Loss: 0.0011828001297544688, Final Batch Loss: 0.00013452998246066272\n",
      "Epoch 2959, Loss: 0.0012374887010082603, Final Batch Loss: 0.0007181114633567631\n",
      "Epoch 2960, Loss: 0.000475173641461879, Final Batch Loss: 0.0001586073194630444\n",
      "Epoch 2961, Loss: 0.0007713049562880769, Final Batch Loss: 0.0005896288785152137\n",
      "Epoch 2962, Loss: 0.0003334039793116972, Final Batch Loss: 0.0002984938910230994\n",
      "Epoch 2963, Loss: 0.001559126962092705, Final Batch Loss: 7.605920836795121e-05\n",
      "Epoch 2964, Loss: 0.0030513511592289433, Final Batch Loss: 2.4211927666328847e-05\n",
      "Epoch 2965, Loss: 0.0008148988417815417, Final Batch Loss: 0.0006511036772280931\n",
      "Epoch 2966, Loss: 0.0013282338122735382, Final Batch Loss: 1.044415057549486e-05\n",
      "Epoch 2967, Loss: 0.00039384257252095267, Final Batch Loss: 0.00027799050440080464\n",
      "Epoch 2968, Loss: 0.00013128697537467815, Final Batch Loss: 5.412536484072916e-05\n",
      "Epoch 2969, Loss: 0.0018543376718298532, Final Batch Loss: 6.0592581576202065e-05\n",
      "Epoch 2970, Loss: 0.005258285906165838, Final Batch Loss: 0.0023410464636981487\n",
      "Epoch 2971, Loss: 0.001832389083574526, Final Batch Loss: 0.00014091299090068787\n",
      "Epoch 2972, Loss: 0.00014333918443298899, Final Batch Loss: 4.0103561332216486e-05\n",
      "Epoch 2973, Loss: 0.0005007083236705512, Final Batch Loss: 0.00033586416975595057\n",
      "Epoch 2974, Loss: 0.0015843725996091962, Final Batch Loss: 0.00141234346665442\n",
      "Epoch 2975, Loss: 0.0013098757481202483, Final Batch Loss: 0.0005537327378988266\n",
      "Epoch 2976, Loss: 0.0011134493979625404, Final Batch Loss: 0.0005551704089157283\n",
      "Epoch 2977, Loss: 0.0006279155422816984, Final Batch Loss: 0.0005813369643874466\n",
      "Epoch 2978, Loss: 0.000754513093852438, Final Batch Loss: 0.0005770003772340715\n",
      "Epoch 2979, Loss: 0.0005133820668561384, Final Batch Loss: 0.00013961184595245868\n",
      "Epoch 2980, Loss: 0.0011267280206084251, Final Batch Loss: 0.00033396738581359386\n",
      "Epoch 2981, Loss: 9.288401633966714e-05, Final Batch Loss: 5.490050898515619e-05\n",
      "Epoch 2982, Loss: 0.0008805967954685912, Final Batch Loss: 0.00017173202650155872\n",
      "Epoch 2983, Loss: 0.006003667596814921, Final Batch Loss: 5.9883572248509154e-05\n",
      "Epoch 2984, Loss: 0.0006508249771286501, Final Batch Loss: 2.4002276404644363e-05\n",
      "Epoch 2985, Loss: 0.0006237197376322001, Final Batch Loss: 4.564467235468328e-05\n",
      "Epoch 2986, Loss: 0.0003553997739800252, Final Batch Loss: 0.0003089754609391093\n",
      "Epoch 2987, Loss: 0.0016080921341199428, Final Batch Loss: 0.0004236693785060197\n",
      "Epoch 2988, Loss: 0.0006977841112529859, Final Batch Loss: 1.857690222095698e-05\n",
      "Epoch 2989, Loss: 0.0003664210526039824, Final Batch Loss: 0.00021424719307105988\n",
      "Epoch 2990, Loss: 0.0010319856373826042, Final Batch Loss: 0.0009096720023080707\n",
      "Epoch 2991, Loss: 0.0007235491357278079, Final Batch Loss: 0.00020610776846297085\n",
      "Epoch 2992, Loss: 0.0006399295598384924, Final Batch Loss: 0.0005440486711449921\n",
      "Epoch 2993, Loss: 0.0008405486769333947, Final Batch Loss: 6.0021080571459606e-05\n",
      "Epoch 2994, Loss: 0.00037948293902445585, Final Batch Loss: 5.588655767496675e-05\n",
      "Epoch 2995, Loss: 0.0003386582757229917, Final Batch Loss: 6.310550816124305e-05\n",
      "Epoch 2996, Loss: 0.0016504996092407964, Final Batch Loss: 0.0015376772498711944\n",
      "Epoch 2997, Loss: 0.0003848176565952599, Final Batch Loss: 0.00012235011672601104\n",
      "Epoch 2998, Loss: 0.00017486841898062266, Final Batch Loss: 5.7444438425591215e-05\n",
      "Epoch 2999, Loss: 0.000665200590447057, Final Batch Loss: 4.7914574679452926e-05\n",
      "Epoch 3000, Loss: 0.0009098128066398203, Final Batch Loss: 0.000591139541938901\n",
      "Epoch 3001, Loss: 9.394428161613178e-05, Final Batch Loss: 1.1949754480156116e-05\n",
      "Epoch 3002, Loss: 0.0002344300228287466, Final Batch Loss: 0.00012139909085817635\n",
      "Epoch 3003, Loss: 0.0006775564688723534, Final Batch Loss: 0.00029250813531689346\n",
      "Epoch 3004, Loss: 0.00048820678784977645, Final Batch Loss: 0.00017924477288033813\n",
      "Epoch 3005, Loss: 0.002627505524287699, Final Batch Loss: 0.0025759555865079165\n",
      "Epoch 3006, Loss: 0.0008052160264924169, Final Batch Loss: 0.00024650373961776495\n",
      "Epoch 3007, Loss: 0.04423953176592477, Final Batch Loss: 0.00028415725682862103\n",
      "Epoch 3008, Loss: 0.00013413785927696154, Final Batch Loss: 4.999699012842029e-05\n",
      "Epoch 3009, Loss: 0.00040825665200827643, Final Batch Loss: 1.1223652109038085e-05\n",
      "Epoch 3010, Loss: 0.0018117733125109226, Final Batch Loss: 0.00013631643378175795\n",
      "Epoch 3011, Loss: 0.011598288750974461, Final Batch Loss: 0.011554542928934097\n",
      "Epoch 3012, Loss: 0.010296122985891998, Final Batch Loss: 0.0010252882493659854\n",
      "Epoch 3013, Loss: 0.0009353305504191667, Final Batch Loss: 0.000804762588813901\n",
      "Epoch 3014, Loss: 0.0007130112644517794, Final Batch Loss: 0.000135710826725699\n",
      "Epoch 3015, Loss: 0.005233195959590375, Final Batch Loss: 0.001034574001096189\n",
      "Epoch 3016, Loss: 0.0001758667131070979, Final Batch Loss: 0.00011461048416094854\n",
      "Epoch 3017, Loss: 0.03737790376180783, Final Batch Loss: 0.036999791860580444\n",
      "Epoch 3018, Loss: 0.0012199370103189722, Final Batch Loss: 0.0010974424658343196\n",
      "Epoch 3019, Loss: 0.0008717414457350969, Final Batch Loss: 0.00027776940260082483\n",
      "Epoch 3020, Loss: 0.000471959958304069, Final Batch Loss: 2.6672574676922522e-05\n",
      "Epoch 3021, Loss: 0.00138789729680866, Final Batch Loss: 0.0007195188081823289\n",
      "Epoch 3022, Loss: 0.0005553072260227054, Final Batch Loss: 0.00019868233357556164\n",
      "Epoch 3023, Loss: 0.008134435207466595, Final Batch Loss: 0.0079354802146554\n",
      "Epoch 3024, Loss: 0.0008217555441660807, Final Batch Loss: 0.000210448561119847\n",
      "Epoch 3025, Loss: 0.000860436104630935, Final Batch Loss: 2.2302947400021367e-05\n",
      "Epoch 3026, Loss: 0.00022759596322430298, Final Batch Loss: 0.0001827524829423055\n",
      "Epoch 3027, Loss: 0.003472175099886954, Final Batch Loss: 0.002374592237174511\n",
      "Epoch 3028, Loss: 0.0014863778196740896, Final Batch Loss: 0.0011639229487627745\n",
      "Epoch 3029, Loss: 0.0007306532643269747, Final Batch Loss: 0.00040230044396594167\n",
      "Epoch 3030, Loss: 0.008278485081973486, Final Batch Loss: 0.0002102047874359414\n",
      "Epoch 3031, Loss: 0.007596009087137645, Final Batch Loss: 0.007561711128801107\n",
      "Epoch 3032, Loss: 0.0007545098815171514, Final Batch Loss: 3.079697853536345e-05\n",
      "Epoch 3033, Loss: 0.0007014143338892609, Final Batch Loss: 0.0005725379451178014\n",
      "Epoch 3034, Loss: 0.0010313780803699046, Final Batch Loss: 0.0005523819127120078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3035, Loss: 0.0063701367762405425, Final Batch Loss: 0.0003475596022326499\n",
      "Epoch 3036, Loss: 0.0009548995294608176, Final Batch Loss: 0.00048768677515909076\n",
      "Epoch 3037, Loss: 0.0005565275641856715, Final Batch Loss: 0.00018841754354070872\n",
      "Epoch 3038, Loss: 0.004049934912472963, Final Batch Loss: 0.0026353970170021057\n",
      "Epoch 3039, Loss: 0.006084717228077352, Final Batch Loss: 0.005379560869187117\n",
      "Epoch 3040, Loss: 0.0003593002911657095, Final Batch Loss: 0.00017659060540609062\n",
      "Epoch 3041, Loss: 0.00043091107090731384, Final Batch Loss: 1.267540665139677e-05\n",
      "Epoch 3042, Loss: 0.0003465721383690834, Final Batch Loss: 9.672826854512095e-05\n",
      "Epoch 3043, Loss: 0.000271138378593605, Final Batch Loss: 0.0001929508289322257\n",
      "Epoch 3044, Loss: 0.0001602889533387497, Final Batch Loss: 6.750390457455069e-05\n",
      "Epoch 3045, Loss: 0.0006657570047536865, Final Batch Loss: 0.00048339652130380273\n",
      "Epoch 3046, Loss: 0.00045635718561243266, Final Batch Loss: 0.0002232506958534941\n",
      "Epoch 3047, Loss: 0.0019680759869515896, Final Batch Loss: 0.0002476877998560667\n",
      "Epoch 3048, Loss: 0.00016570877414778806, Final Batch Loss: 4.461522985366173e-05\n",
      "Epoch 3049, Loss: 0.0023993923678062856, Final Batch Loss: 0.0019226481672376394\n",
      "Epoch 3050, Loss: 0.0007103738316800445, Final Batch Loss: 0.00046590797137469053\n",
      "Epoch 3051, Loss: 0.00031223983751260675, Final Batch Loss: 4.6128352551022545e-05\n",
      "Epoch 3052, Loss: 0.000318992850225186, Final Batch Loss: 0.0002678004093468189\n",
      "Epoch 3053, Loss: 0.0013898203033022583, Final Batch Loss: 0.0009565178188495338\n",
      "Epoch 3054, Loss: 0.0011151470243930817, Final Batch Loss: 0.0008139567216858268\n",
      "Epoch 3055, Loss: 0.00041497303755022585, Final Batch Loss: 0.0002465553116053343\n",
      "Epoch 3056, Loss: 0.001104712107917294, Final Batch Loss: 0.0001799768942873925\n",
      "Epoch 3057, Loss: 0.0008322798239532858, Final Batch Loss: 0.0005225931527093053\n",
      "Epoch 3058, Loss: 0.00016442377091152593, Final Batch Loss: 0.00012084271293133497\n",
      "Epoch 3059, Loss: 0.0015914496034383774, Final Batch Loss: 0.00105357076972723\n",
      "Epoch 3060, Loss: 0.001712997502181679, Final Batch Loss: 0.0006056231795810163\n",
      "Epoch 3061, Loss: 0.0017490243044449016, Final Batch Loss: 0.001602351781912148\n",
      "Epoch 3062, Loss: 0.0022929743863642216, Final Batch Loss: 0.0006609165575355291\n",
      "Epoch 3063, Loss: 0.0013308376946952194, Final Batch Loss: 0.00031633078469894826\n",
      "Epoch 3064, Loss: 0.0003497049765428528, Final Batch Loss: 0.00027355997008271515\n",
      "Epoch 3065, Loss: 6.358063183142804e-05, Final Batch Loss: 2.6207319024251774e-05\n",
      "Epoch 3066, Loss: 0.0013498577172867954, Final Batch Loss: 0.0006697523058392107\n",
      "Epoch 3067, Loss: 0.0005953940271865577, Final Batch Loss: 0.0003198689373675734\n",
      "Epoch 3068, Loss: 0.0003402230649953708, Final Batch Loss: 0.00010313680104445666\n",
      "Epoch 3069, Loss: 0.0001916384426294826, Final Batch Loss: 7.673056097701192e-05\n",
      "Epoch 3070, Loss: 0.0004208266254863702, Final Batch Loss: 0.0003362773568369448\n",
      "Epoch 3071, Loss: 0.0008977334309747675, Final Batch Loss: 2.6012648959294893e-05\n",
      "Epoch 3072, Loss: 0.001406004506861791, Final Batch Loss: 0.00041851724381558597\n",
      "Epoch 3073, Loss: 0.0005224536871537566, Final Batch Loss: 0.0003135262231808156\n",
      "Epoch 3074, Loss: 0.00031952510471455753, Final Batch Loss: 0.00018696275947149843\n",
      "Epoch 3075, Loss: 0.012336223677266389, Final Batch Loss: 0.00012987229274585843\n",
      "Epoch 3076, Loss: 0.0002850669407052919, Final Batch Loss: 0.00020412584126461297\n",
      "Epoch 3077, Loss: 0.0008013796905288473, Final Batch Loss: 0.00010896417370531708\n",
      "Epoch 3078, Loss: 0.004014391015516594, Final Batch Loss: 0.003856057533994317\n",
      "Epoch 3079, Loss: 0.0012232056760694832, Final Batch Loss: 0.0011009901063516736\n",
      "Epoch 3080, Loss: 0.001603620738023892, Final Batch Loss: 0.00044497582712210715\n",
      "Epoch 3081, Loss: 0.0028317921751295216, Final Batch Loss: 4.0588151023257524e-05\n",
      "Epoch 3082, Loss: 0.0005146331677678972, Final Batch Loss: 9.805074660107493e-05\n",
      "Epoch 3083, Loss: 0.0007031987042864785, Final Batch Loss: 0.00013596912322100252\n",
      "Epoch 3084, Loss: 0.0008926928276196122, Final Batch Loss: 0.00025995419127866626\n",
      "Epoch 3085, Loss: 0.0012255629299033899, Final Batch Loss: 4.08384257752914e-05\n",
      "Epoch 3086, Loss: 0.00042919573024846613, Final Batch Loss: 8.612981764599681e-05\n",
      "Epoch 3087, Loss: 0.00017688945081317797, Final Batch Loss: 0.00010867167293326929\n",
      "Epoch 3088, Loss: 0.0004989044246030971, Final Batch Loss: 0.00046676656347699463\n",
      "Epoch 3089, Loss: 0.0004735027177957818, Final Batch Loss: 0.0001833787391660735\n",
      "Epoch 3090, Loss: 0.00014479796300292946, Final Batch Loss: 5.541656355489977e-05\n",
      "Epoch 3091, Loss: 0.0015526041388511658, Final Batch Loss: 0.0006573402788490057\n",
      "Epoch 3092, Loss: 0.0004970235168002546, Final Batch Loss: 0.00038683900493197143\n",
      "Epoch 3093, Loss: 0.0008042141434998484, Final Batch Loss: 1.7159780327347107e-05\n",
      "Epoch 3094, Loss: 0.0002457628579577431, Final Batch Loss: 0.00015111803077161312\n",
      "Epoch 3095, Loss: 0.0001750071219248639, Final Batch Loss: 5.727325969928643e-06\n",
      "Epoch 3096, Loss: 0.0003013793902937323, Final Batch Loss: 7.712612568866462e-05\n",
      "Epoch 3097, Loss: 0.00012574052993841178, Final Batch Loss: 3.1316510558099253e-06\n",
      "Epoch 3098, Loss: 0.0011388443017494865, Final Batch Loss: 0.0010721004800871015\n",
      "Epoch 3099, Loss: 0.00040731214539846405, Final Batch Loss: 7.317368726944551e-05\n",
      "Epoch 3100, Loss: 0.0005284961571305757, Final Batch Loss: 1.6720839994377457e-05\n",
      "Epoch 3101, Loss: 0.0005280295008560643, Final Batch Loss: 0.00021542249305639416\n",
      "Epoch 3102, Loss: 0.0006477916758740321, Final Batch Loss: 0.00024064425087999552\n",
      "Epoch 3103, Loss: 0.0005671526014339179, Final Batch Loss: 0.00024068274069577456\n",
      "Epoch 3104, Loss: 0.0014985339366830885, Final Batch Loss: 0.0009414589148946106\n",
      "Epoch 3105, Loss: 0.000137390768941259, Final Batch Loss: 3.597441900637932e-05\n",
      "Epoch 3106, Loss: 0.0001633727406442631, Final Batch Loss: 0.00011772220022976398\n",
      "Epoch 3107, Loss: 0.00014423570974031463, Final Batch Loss: 6.838649278506637e-05\n",
      "Epoch 3108, Loss: 0.0012315199528529774, Final Batch Loss: 3.1695333746029064e-05\n",
      "Epoch 3109, Loss: 0.0006607815739698708, Final Batch Loss: 0.0003336425288580358\n",
      "Epoch 3110, Loss: 9.967802543542348e-05, Final Batch Loss: 7.434686267515644e-05\n",
      "Epoch 3111, Loss: 0.0020954765495844185, Final Batch Loss: 6.983923958614469e-05\n",
      "Epoch 3112, Loss: 0.008087997795200863, Final Batch Loss: 3.5711611872102367e-06\n",
      "Epoch 3113, Loss: 0.00011506478404044174, Final Batch Loss: 3.797718454734422e-05\n",
      "Epoch 3114, Loss: 0.013228703955974197, Final Batch Loss: 0.01318327710032463\n",
      "Epoch 3115, Loss: 0.000270777840341907, Final Batch Loss: 0.00022419240849558264\n",
      "Epoch 3116, Loss: 8.692696792422794e-05, Final Batch Loss: 3.327099693706259e-05\n",
      "Epoch 3117, Loss: 0.0005573679809458554, Final Batch Loss: 8.363238885067403e-05\n",
      "Epoch 3118, Loss: 0.00037625540426233783, Final Batch Loss: 6.777616363251582e-05\n",
      "Epoch 3119, Loss: 0.00034329922345932573, Final Batch Loss: 0.00017121655400842428\n",
      "Epoch 3120, Loss: 0.00045695677545154467, Final Batch Loss: 8.828219870338216e-05\n",
      "Epoch 3121, Loss: 0.002164167399314465, Final Batch Loss: 3.083567207795568e-05\n",
      "Epoch 3122, Loss: 0.00015230439021252096, Final Batch Loss: 0.00012210830755066127\n",
      "Epoch 3123, Loss: 0.0006800592091167346, Final Batch Loss: 0.0004469351260922849\n",
      "Epoch 3124, Loss: 0.0006492347893072292, Final Batch Loss: 0.00018371552869211882\n",
      "Epoch 3125, Loss: 0.00013044347724644467, Final Batch Loss: 7.900753553258255e-05\n",
      "Epoch 3126, Loss: 0.0016684927468304522, Final Batch Loss: 5.27318989043124e-05\n",
      "Epoch 3127, Loss: 0.0007708197008469142, Final Batch Loss: 9.002493607113138e-05\n",
      "Epoch 3128, Loss: 0.0006879942593513988, Final Batch Loss: 0.0005682666087523103\n",
      "Epoch 3129, Loss: 0.0006556657608598471, Final Batch Loss: 0.0003139067266602069\n",
      "Epoch 3130, Loss: 0.002740944502875209, Final Batch Loss: 0.0007828280795365572\n",
      "Epoch 3131, Loss: 0.00032975014619296417, Final Batch Loss: 0.0002586883492767811\n",
      "Epoch 3132, Loss: 0.002634754160681041, Final Batch Loss: 5.9666101151378825e-05\n",
      "Epoch 3133, Loss: 0.0006482460012193769, Final Batch Loss: 0.00038331517134793103\n",
      "Epoch 3134, Loss: 0.00015053504830575548, Final Batch Loss: 9.671328734839335e-05\n",
      "Epoch 3135, Loss: 0.0008359044004464522, Final Batch Loss: 0.0007042244542390108\n",
      "Epoch 3136, Loss: 0.0003073714251513593, Final Batch Loss: 5.30228644493036e-05\n",
      "Epoch 3137, Loss: 0.050865776545833796, Final Batch Loss: 0.05035964399576187\n",
      "Epoch 3138, Loss: 0.0001317578280577436, Final Batch Loss: 6.0832266171928495e-05\n",
      "Epoch 3139, Loss: 0.005398655135650188, Final Batch Loss: 0.0053203958086669445\n",
      "Epoch 3140, Loss: 0.0047041005454957485, Final Batch Loss: 0.002212837338447571\n",
      "Epoch 3141, Loss: 0.0021277477499097586, Final Batch Loss: 0.0007677399553358555\n",
      "Epoch 3142, Loss: 0.010376839665696025, Final Batch Loss: 0.010206480510532856\n",
      "Epoch 3143, Loss: 0.00012159908692410681, Final Batch Loss: 1.3129576473147608e-05\n",
      "Epoch 3144, Loss: 0.0005679394089384004, Final Batch Loss: 0.0004312402743380517\n",
      "Epoch 3145, Loss: 0.002124784921761602, Final Batch Loss: 0.00144234299659729\n",
      "Epoch 3146, Loss: 0.001017582617350854, Final Batch Loss: 0.0008643569308333099\n",
      "Epoch 3147, Loss: 0.0002561949077062309, Final Batch Loss: 7.370559615083039e-05\n",
      "Epoch 3148, Loss: 0.0005484964640345424, Final Batch Loss: 0.0003769572649616748\n",
      "Epoch 3149, Loss: 0.0012706142151728272, Final Batch Loss: 0.001030606566928327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3150, Loss: 0.0015332637267420068, Final Batch Loss: 0.0014618266141042113\n",
      "Epoch 3151, Loss: 0.0007982902752701193, Final Batch Loss: 0.0005685798823833466\n",
      "Epoch 3152, Loss: 0.002115616953233257, Final Batch Loss: 0.0018057733541354537\n",
      "Epoch 3153, Loss: 0.0014577747497241944, Final Batch Loss: 0.00026055131456814706\n",
      "Epoch 3154, Loss: 9.035034554472077e-05, Final Batch Loss: 4.541470389085589e-06\n",
      "Epoch 3155, Loss: 0.00032081081735668704, Final Batch Loss: 3.943696356145665e-05\n",
      "Epoch 3156, Loss: 0.0004725840008177329, Final Batch Loss: 5.728371979785152e-05\n",
      "Epoch 3157, Loss: 0.00019489211263135076, Final Batch Loss: 7.511462172260508e-05\n",
      "Epoch 3158, Loss: 0.0018317237845622003, Final Batch Loss: 0.0009664701647125185\n",
      "Epoch 3159, Loss: 0.0010835273133125156, Final Batch Loss: 0.0003936124558094889\n",
      "Epoch 3160, Loss: 0.00025227345031453297, Final Batch Loss: 0.00018916334374807775\n",
      "Epoch 3161, Loss: 0.0005969416815787554, Final Batch Loss: 0.0002583168388810009\n",
      "Epoch 3162, Loss: 0.0031347486074082553, Final Batch Loss: 0.0004884567460976541\n",
      "Epoch 3163, Loss: 0.00013233728896011598, Final Batch Loss: 4.173355773673393e-05\n",
      "Epoch 3164, Loss: 0.0004183563287369907, Final Batch Loss: 0.00022225233260542154\n",
      "Epoch 3165, Loss: 0.0005723520662286319, Final Batch Loss: 0.00010297730477759615\n",
      "Epoch 3166, Loss: 0.005950797291006893, Final Batch Loss: 0.00035987416049465537\n",
      "Epoch 3167, Loss: 0.0006231898878468201, Final Batch Loss: 0.0004668674082495272\n",
      "Epoch 3168, Loss: 0.00397007615538314, Final Batch Loss: 0.00028597546042874455\n",
      "Epoch 3169, Loss: 0.015414387482451275, Final Batch Loss: 0.015255840495228767\n",
      "Epoch 3170, Loss: 0.00030929208696761634, Final Batch Loss: 1.7954245777218603e-05\n",
      "Epoch 3171, Loss: 0.0002574817553977482, Final Batch Loss: 0.00014676809951197356\n",
      "Epoch 3172, Loss: 0.0010640702821547166, Final Batch Loss: 0.00012223726662341505\n",
      "Epoch 3173, Loss: 0.0006925099005457014, Final Batch Loss: 0.00015633515431545675\n",
      "Epoch 3174, Loss: 0.0005536465905606747, Final Batch Loss: 0.0002542816800996661\n",
      "Epoch 3175, Loss: 0.001819989352952689, Final Batch Loss: 0.0012653146404772997\n",
      "Epoch 3176, Loss: 0.0006386793102137744, Final Batch Loss: 0.00031548339757137\n",
      "Epoch 3177, Loss: 0.001879017276223749, Final Batch Loss: 0.0010181833058595657\n",
      "Epoch 3178, Loss: 0.0008199556759791449, Final Batch Loss: 0.000684821920003742\n",
      "Epoch 3179, Loss: 0.0002782963929348625, Final Batch Loss: 0.0002278751489939168\n",
      "Epoch 3180, Loss: 0.0007818437734385952, Final Batch Loss: 0.00013816005957778543\n",
      "Epoch 3181, Loss: 0.0006565485127794091, Final Batch Loss: 5.6468797993147746e-05\n",
      "Epoch 3182, Loss: 0.000338578931405209, Final Batch Loss: 0.00013895118900109082\n",
      "Epoch 3183, Loss: 0.0026093333144672215, Final Batch Loss: 0.0018623098731040955\n",
      "Epoch 3184, Loss: 0.0027592265705607133, Final Batch Loss: 0.002741469070315361\n",
      "Epoch 3185, Loss: 0.0003797470490098931, Final Batch Loss: 0.0002903164713643491\n",
      "Epoch 3186, Loss: 0.0033190668327733874, Final Batch Loss: 0.0010366101050749421\n",
      "Epoch 3187, Loss: 0.0015381955636257771, Final Batch Loss: 6.0230759117985144e-05\n",
      "Epoch 3188, Loss: 0.00031914672581478953, Final Batch Loss: 0.00011500863183755428\n",
      "Epoch 3189, Loss: 0.0005747434988734312, Final Batch Loss: 0.00010433462011860684\n",
      "Epoch 3190, Loss: 0.0013227341732999776, Final Batch Loss: 4.2725125240394846e-05\n",
      "Epoch 3191, Loss: 0.003570758970454335, Final Batch Loss: 0.003084279363974929\n",
      "Epoch 3192, Loss: 0.0005185184872971149, Final Batch Loss: 1.7434171240893193e-05\n",
      "Epoch 3193, Loss: 0.000161679825396277, Final Batch Loss: 8.492553752148524e-05\n",
      "Epoch 3194, Loss: 9.403877993463539e-05, Final Batch Loss: 3.131511402898468e-05\n",
      "Epoch 3195, Loss: 0.00018843265570467338, Final Batch Loss: 0.00012418723781593144\n",
      "Epoch 3196, Loss: 0.0013007083907723427, Final Batch Loss: 0.0006547956727445126\n",
      "Epoch 3197, Loss: 0.001939622830832377, Final Batch Loss: 0.00017279377789236605\n",
      "Epoch 3198, Loss: 0.00016113770107040182, Final Batch Loss: 7.05909842508845e-05\n",
      "Epoch 3199, Loss: 0.0005601561206276529, Final Batch Loss: 0.0004897667677141726\n",
      "Epoch 3200, Loss: 0.0013846340771124233, Final Batch Loss: 0.0013423492200672626\n",
      "Epoch 3201, Loss: 6.258683606574778e-05, Final Batch Loss: 2.2823684048489667e-05\n",
      "Epoch 3202, Loss: 0.000607747340836795, Final Batch Loss: 0.0005708803655579686\n",
      "Epoch 3203, Loss: 0.0005315265134413494, Final Batch Loss: 0.0005069677135907114\n",
      "Epoch 3204, Loss: 0.00038780523755121976, Final Batch Loss: 0.00020891086023766547\n",
      "Epoch 3205, Loss: 0.000410556258430006, Final Batch Loss: 0.0003670383885037154\n",
      "Epoch 3206, Loss: 0.0008941076375776902, Final Batch Loss: 0.00022289152548182756\n",
      "Epoch 3207, Loss: 0.0003384281735634431, Final Batch Loss: 1.9947168766520917e-05\n",
      "Epoch 3208, Loss: 0.00030188342498149723, Final Batch Loss: 0.00021336713689379394\n",
      "Epoch 3209, Loss: 0.00017563446363055846, Final Batch Loss: 1.4480442587228026e-05\n",
      "Epoch 3210, Loss: 0.00021542761169257574, Final Batch Loss: 4.0517548768548295e-05\n",
      "Epoch 3211, Loss: 0.0033461618586443365, Final Batch Loss: 0.00014683714834973216\n",
      "Epoch 3212, Loss: 0.0005942648713244125, Final Batch Loss: 0.00011249609815422446\n",
      "Epoch 3213, Loss: 0.0006356996655085823, Final Batch Loss: 0.0006055979756638408\n",
      "Epoch 3214, Loss: 0.0030673329456476495, Final Batch Loss: 0.003038077848032117\n",
      "Epoch 3215, Loss: 0.00014990532145020552, Final Batch Loss: 2.3149437765823677e-05\n",
      "Epoch 3216, Loss: 0.00034575983590912074, Final Batch Loss: 0.00024186949303839356\n",
      "Epoch 3217, Loss: 0.0018245989922434092, Final Batch Loss: 0.0016384274931624532\n",
      "Epoch 3218, Loss: 0.0002190547893405892, Final Batch Loss: 6.70955705572851e-05\n",
      "Epoch 3219, Loss: 0.00016499521007062867, Final Batch Loss: 3.229772119084373e-05\n",
      "Epoch 3220, Loss: 0.000771609164075926, Final Batch Loss: 0.00038972130278125405\n",
      "Epoch 3221, Loss: 0.00045238072925712913, Final Batch Loss: 3.7857957067899406e-05\n",
      "Epoch 3222, Loss: 0.0001948067765624728, Final Batch Loss: 0.00018673435261007398\n",
      "Epoch 3223, Loss: 0.0006354245488182642, Final Batch Loss: 0.000550707511138171\n",
      "Epoch 3224, Loss: 0.0012611441634362563, Final Batch Loss: 0.0011270593386143446\n",
      "Epoch 3225, Loss: 0.0006041171473043505, Final Batch Loss: 6.006102557876147e-05\n",
      "Epoch 3226, Loss: 0.00027617601153906435, Final Batch Loss: 0.0002197612338932231\n",
      "Epoch 3227, Loss: 0.0009664464232628234, Final Batch Loss: 0.000854926067404449\n",
      "Epoch 3228, Loss: 2.311663820364629e-05, Final Batch Loss: 4.853029622609029e-06\n",
      "Epoch 3229, Loss: 0.0002016045600612415, Final Batch Loss: 0.0001832393027143553\n",
      "Epoch 3230, Loss: 0.0012060192457283847, Final Batch Loss: 6.219342321855947e-05\n",
      "Epoch 3231, Loss: 0.00019848801457555965, Final Batch Loss: 0.00012037445412715897\n",
      "Epoch 3232, Loss: 0.0004344276021583937, Final Batch Loss: 0.00010220697004115209\n",
      "Epoch 3233, Loss: 0.00018322624691791134, Final Batch Loss: 1.5037102457426954e-05\n",
      "Epoch 3234, Loss: 4.627992893802002e-05, Final Batch Loss: 3.414105231058784e-05\n",
      "Epoch 3235, Loss: 0.00011232526594540104, Final Batch Loss: 8.126331522362307e-05\n",
      "Epoch 3236, Loss: 0.0007728787641099188, Final Batch Loss: 5.641067764372565e-05\n",
      "Epoch 3237, Loss: 0.00026939715462503955, Final Batch Loss: 0.00024962308816611767\n",
      "Epoch 3238, Loss: 0.0002570574142737314, Final Batch Loss: 0.0001829951215768233\n",
      "Epoch 3239, Loss: 6.170673987071496e-05, Final Batch Loss: 4.397314114612527e-06\n",
      "Epoch 3240, Loss: 0.00010840471077244729, Final Batch Loss: 1.9564919057302177e-05\n",
      "Epoch 3241, Loss: 0.00021517995446629357, Final Batch Loss: 0.0002065613225568086\n",
      "Epoch 3242, Loss: 0.0021528099869101425, Final Batch Loss: 1.495552442065673e-05\n",
      "Epoch 3243, Loss: 0.0018016521353274584, Final Batch Loss: 0.0011948710307478905\n",
      "Epoch 3244, Loss: 0.0003202380503353197, Final Batch Loss: 2.427086656098254e-05\n",
      "Epoch 3245, Loss: 0.00014529790496453643, Final Batch Loss: 0.00012158537720097229\n",
      "Epoch 3246, Loss: 8.142919614329003e-05, Final Batch Loss: 4.2964649765053764e-05\n",
      "Epoch 3247, Loss: 0.0005973035367787816, Final Batch Loss: 0.0005619178991764784\n",
      "Epoch 3248, Loss: 0.00016069771299953572, Final Batch Loss: 4.484501914703287e-05\n",
      "Epoch 3249, Loss: 0.0006411253125406802, Final Batch Loss: 0.00024407354067079723\n",
      "Epoch 3250, Loss: 0.0018271489825565368, Final Batch Loss: 0.0015120137250050902\n",
      "Epoch 3251, Loss: 0.0002832109676091932, Final Batch Loss: 6.048277282388881e-05\n",
      "Epoch 3252, Loss: 0.000969733446254395, Final Batch Loss: 0.00013575439515989274\n",
      "Epoch 3253, Loss: 0.0003863642778014764, Final Batch Loss: 0.00014310359256342053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3254, Loss: 0.0011745755327865481, Final Batch Loss: 0.0005578775308094919\n",
      "Epoch 3255, Loss: 0.00036962823833164293, Final Batch Loss: 9.836237950366922e-06\n",
      "Epoch 3256, Loss: 0.0003748790768440813, Final Batch Loss: 0.0001665430754655972\n",
      "Epoch 3257, Loss: 8.79406161402585e-05, Final Batch Loss: 8.281178452307358e-05\n",
      "Epoch 3258, Loss: 0.025991061585955322, Final Batch Loss: 0.025659019127488136\n",
      "Epoch 3259, Loss: 0.00043913410627283156, Final Batch Loss: 6.172916619107127e-05\n",
      "Epoch 3260, Loss: 0.002081467246171087, Final Batch Loss: 0.0008304567891173065\n",
      "Epoch 3261, Loss: 0.00026350249027018435, Final Batch Loss: 0.00022044125944375992\n",
      "Epoch 3262, Loss: 0.0010230844345642254, Final Batch Loss: 6.650497380178422e-05\n",
      "Epoch 3263, Loss: 0.00020521348596957978, Final Batch Loss: 2.3435763068846427e-05\n",
      "Epoch 3264, Loss: 0.007583295118820388, Final Batch Loss: 0.0001214362055179663\n",
      "Epoch 3265, Loss: 0.0013795453523925971, Final Batch Loss: 0.00134024559520185\n",
      "Epoch 3266, Loss: 0.00014163629748509265, Final Batch Loss: 4.0491850086255e-05\n",
      "Epoch 3267, Loss: 3.41697104886407e-05, Final Batch Loss: 1.1819416613434441e-05\n",
      "Epoch 3268, Loss: 8.92675707291346e-05, Final Batch Loss: 2.4703931558178738e-05\n",
      "Epoch 3269, Loss: 0.000610495217188145, Final Batch Loss: 2.206116732850205e-05\n",
      "Epoch 3270, Loss: 0.0002816929409164004, Final Batch Loss: 0.00010524196113692597\n",
      "Epoch 3271, Loss: 0.000731112391804345, Final Batch Loss: 0.0006252601742744446\n",
      "Epoch 3272, Loss: 0.0013248783070594072, Final Batch Loss: 0.0011465055868029594\n",
      "Epoch 3273, Loss: 0.0006611349681406864, Final Batch Loss: 8.770978638494853e-06\n",
      "Epoch 3274, Loss: 0.0008973359435913153, Final Batch Loss: 0.0008105755550786853\n",
      "Epoch 3275, Loss: 0.00888599680911284, Final Batch Loss: 0.00012703372340183705\n",
      "Epoch 3276, Loss: 0.00020556431991280988, Final Batch Loss: 2.8950795240234584e-05\n",
      "Epoch 3277, Loss: 0.006816103996243328, Final Batch Loss: 3.818602999672294e-05\n",
      "Epoch 3278, Loss: 0.006771679411031073, Final Batch Loss: 0.006727459374815226\n",
      "Epoch 3279, Loss: 0.0028997854606132023, Final Batch Loss: 3.96887116949074e-05\n",
      "Epoch 3280, Loss: 0.0003907532045559492, Final Batch Loss: 4.010065094917081e-05\n",
      "Epoch 3281, Loss: 0.00031912066424411023, Final Batch Loss: 1.0398173799330834e-05\n",
      "Epoch 3282, Loss: 0.0024476905236952007, Final Batch Loss: 0.0008502238779328763\n",
      "Epoch 3283, Loss: 0.00046125618973746896, Final Batch Loss: 0.00041931189480237663\n",
      "Epoch 3284, Loss: 0.0016801261226646602, Final Batch Loss: 0.00012956425780430436\n",
      "Epoch 3285, Loss: 0.0024108985307975672, Final Batch Loss: 9.23015977605246e-05\n",
      "Epoch 3286, Loss: 0.0012813505018129945, Final Batch Loss: 0.00011197163257747889\n",
      "Epoch 3287, Loss: 0.00030168655212037265, Final Batch Loss: 0.0002256293810205534\n",
      "Epoch 3288, Loss: 0.024021196077228524, Final Batch Loss: 0.023889007046818733\n",
      "Epoch 3289, Loss: 0.01064205207512714, Final Batch Loss: 6.656572804786265e-05\n",
      "Epoch 3290, Loss: 0.0015384136058855802, Final Batch Loss: 0.0011402030941098928\n",
      "Epoch 3291, Loss: 0.07394466595724225, Final Batch Loss: 0.07265336066484451\n",
      "Epoch 3292, Loss: 0.010283048148266971, Final Batch Loss: 0.0011504943249747157\n",
      "Epoch 3293, Loss: 0.0001178955462819431, Final Batch Loss: 4.563125912682153e-05\n",
      "Epoch 3294, Loss: 0.002537715685321018, Final Batch Loss: 0.00031581983785144985\n",
      "Epoch 3295, Loss: 0.026868037413805723, Final Batch Loss: 0.019828587770462036\n",
      "Epoch 3296, Loss: 0.003577467703507864, Final Batch Loss: 9.63331876846496e-06\n",
      "Epoch 3297, Loss: 0.0009228737035300583, Final Batch Loss: 0.0001476552861277014\n",
      "Epoch 3298, Loss: 0.001692562182142865, Final Batch Loss: 0.0016085795359686017\n",
      "Epoch 3299, Loss: 0.00039154010300990194, Final Batch Loss: 0.00018915950204245746\n",
      "Epoch 3300, Loss: 0.010419427824672312, Final Batch Loss: 0.009784218855202198\n",
      "Epoch 3301, Loss: 0.015575048368191347, Final Batch Loss: 0.015299149788916111\n",
      "Epoch 3302, Loss: 0.0017964859725907445, Final Batch Loss: 0.00020410330034792423\n",
      "Epoch 3303, Loss: 0.00045484144175134134, Final Batch Loss: 9.993758794735186e-06\n",
      "Epoch 3304, Loss: 0.00041012949077412486, Final Batch Loss: 0.00012307276483625174\n",
      "Epoch 3305, Loss: 0.0026781386113725603, Final Batch Loss: 0.0019463869975879788\n",
      "Epoch 3306, Loss: 0.00028467652737163007, Final Batch Loss: 0.0001502305531175807\n",
      "Epoch 3307, Loss: 0.00048660260654287413, Final Batch Loss: 0.00010327995551051572\n",
      "Epoch 3308, Loss: 0.0020240441954229027, Final Batch Loss: 0.001800213591195643\n",
      "Epoch 3309, Loss: 0.0006722380203427747, Final Batch Loss: 8.384558896068484e-05\n",
      "Epoch 3310, Loss: 0.0007874316215747967, Final Batch Loss: 0.00012172119750175625\n",
      "Epoch 3311, Loss: 0.0009235489924321882, Final Batch Loss: 0.00011396215268177912\n",
      "Epoch 3312, Loss: 0.0005010119930375367, Final Batch Loss: 0.0002393662289250642\n",
      "Epoch 3313, Loss: 0.00010640754771884531, Final Batch Loss: 6.721455429214984e-05\n",
      "Epoch 3314, Loss: 0.007978835532412631, Final Batch Loss: 1.0462867066962644e-05\n",
      "Epoch 3315, Loss: 0.0002285452646901831, Final Batch Loss: 6.907543865963817e-05\n",
      "Epoch 3316, Loss: 0.0001935926775331609, Final Batch Loss: 0.000147253813338466\n",
      "Epoch 3317, Loss: 0.00032862741500139236, Final Batch Loss: 0.00012677590711973608\n",
      "Epoch 3318, Loss: 0.00021679308702005073, Final Batch Loss: 3.48504472640343e-05\n",
      "Epoch 3319, Loss: 0.0007719961577095091, Final Batch Loss: 0.0005342820659279823\n",
      "Epoch 3320, Loss: 0.00013550365474657156, Final Batch Loss: 2.7738798962673172e-05\n",
      "Epoch 3321, Loss: 0.00035945903073297814, Final Batch Loss: 6.98167787049897e-05\n",
      "Epoch 3322, Loss: 0.00032561703847022727, Final Batch Loss: 0.0002169854415114969\n",
      "Epoch 3323, Loss: 0.0013970650034025311, Final Batch Loss: 0.0006907826173119247\n",
      "Epoch 3324, Loss: 0.0031947962124831975, Final Batch Loss: 0.00024560262681916356\n",
      "Epoch 3325, Loss: 0.001995556980546098, Final Batch Loss: 9.100627357838675e-05\n",
      "Epoch 3326, Loss: 0.0001541778565297136, Final Batch Loss: 2.5844574338407256e-05\n",
      "Epoch 3327, Loss: 0.0005883050325792283, Final Batch Loss: 0.00031332028447650373\n",
      "Epoch 3328, Loss: 0.004488266275075148, Final Batch Loss: 1.9318160411785357e-05\n",
      "Epoch 3329, Loss: 0.008335011632880196, Final Batch Loss: 0.00027209948166273534\n",
      "Epoch 3330, Loss: 0.0011745818137569586, Final Batch Loss: 0.0011511897901073098\n",
      "Epoch 3331, Loss: 0.00011933214773307554, Final Batch Loss: 7.967071724124253e-05\n",
      "Epoch 3332, Loss: 0.00017698434385238215, Final Batch Loss: 0.00010691048373701051\n",
      "Epoch 3333, Loss: 0.00010584756819298491, Final Batch Loss: 3.7372607039287686e-05\n",
      "Epoch 3334, Loss: 0.00010058634507004172, Final Batch Loss: 4.5920824049972e-05\n",
      "Epoch 3335, Loss: 0.0005852265821886249, Final Batch Loss: 0.00010672756616258994\n",
      "Epoch 3336, Loss: 0.0047012666473165154, Final Batch Loss: 0.00029388873372226954\n",
      "Epoch 3337, Loss: 0.0011722467024810612, Final Batch Loss: 0.0008784565725363791\n",
      "Epoch 3338, Loss: 0.006776905822334811, Final Batch Loss: 0.00021008422481827438\n",
      "Epoch 3339, Loss: 0.0005058244278188795, Final Batch Loss: 0.00026432593585923314\n",
      "Epoch 3340, Loss: 0.016018187212466728, Final Batch Loss: 0.015962697565555573\n",
      "Epoch 3341, Loss: 0.0002045238288701512, Final Batch Loss: 0.00015749846352264285\n",
      "Epoch 3342, Loss: 0.0005028340965509415, Final Batch Loss: 0.00019115873146802187\n",
      "Epoch 3343, Loss: 0.0033724300155881792, Final Batch Loss: 0.003024362726137042\n",
      "Epoch 3344, Loss: 0.012878783916676184, Final Batch Loss: 0.012841949239373207\n",
      "Epoch 3345, Loss: 0.0007687390752835199, Final Batch Loss: 0.00022113315935712308\n",
      "Epoch 3346, Loss: 0.00022731930948793888, Final Batch Loss: 0.0001636320084799081\n",
      "Epoch 3347, Loss: 0.0008304141229018569, Final Batch Loss: 0.0006421642610803246\n",
      "Epoch 3348, Loss: 0.007019516488071531, Final Batch Loss: 7.053319131955504e-05\n",
      "Epoch 3349, Loss: 0.001044142380123958, Final Batch Loss: 0.0002198177680838853\n",
      "Epoch 3350, Loss: 0.000630615375484922, Final Batch Loss: 2.8517310056486167e-05\n",
      "Epoch 3351, Loss: 0.003807048487942666, Final Batch Loss: 0.0008322081412188709\n",
      "Epoch 3352, Loss: 0.000587771282880567, Final Batch Loss: 0.0003945687785744667\n",
      "Epoch 3353, Loss: 0.029979661107063293, Final Batch Loss: 0.019738219678401947\n",
      "Epoch 3354, Loss: 0.0009479573200223967, Final Batch Loss: 0.0007417720044031739\n",
      "Epoch 3355, Loss: 0.0020867518906015903, Final Batch Loss: 0.001938680768944323\n",
      "Epoch 3356, Loss: 0.001025941914122086, Final Batch Loss: 0.000928709574509412\n",
      "Epoch 3357, Loss: 0.003988082753494382, Final Batch Loss: 0.0023576098028570414\n",
      "Epoch 3358, Loss: 0.00789657881250605, Final Batch Loss: 0.0071796211414039135\n",
      "Epoch 3359, Loss: 0.039311019354499876, Final Batch Loss: 0.038094937801361084\n",
      "Epoch 3360, Loss: 0.0009808442846406251, Final Batch Loss: 0.00050052982987836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3361, Loss: 0.0010942105436697602, Final Batch Loss: 0.0005607394268736243\n",
      "Epoch 3362, Loss: 0.006740769364114385, Final Batch Loss: 8.241831528721377e-05\n",
      "Epoch 3363, Loss: 0.0009002853075799067, Final Batch Loss: 0.0008549572667106986\n",
      "Epoch 3364, Loss: 0.0009778310777619481, Final Batch Loss: 0.00023970456095412374\n",
      "Epoch 3365, Loss: 0.0006753226116416045, Final Batch Loss: 0.000116033545054961\n",
      "Epoch 3366, Loss: 0.001371680584270507, Final Batch Loss: 7.172423647716641e-05\n",
      "Epoch 3367, Loss: 0.0007067010446917266, Final Batch Loss: 0.00040752324275672436\n",
      "Epoch 3368, Loss: 0.00043512820411706343, Final Batch Loss: 0.0003455380501691252\n",
      "Epoch 3369, Loss: 0.0030927393527235836, Final Batch Loss: 0.0003293145855423063\n",
      "Epoch 3370, Loss: 0.0005826944252476096, Final Batch Loss: 0.0005204239278100431\n",
      "Epoch 3371, Loss: 0.0010605534916976467, Final Batch Loss: 0.00016782422608230263\n",
      "Epoch 3372, Loss: 0.0049604470550548285, Final Batch Loss: 0.0003282050311099738\n",
      "Epoch 3373, Loss: 0.0002926306697190739, Final Batch Loss: 7.962079689605162e-05\n",
      "Epoch 3374, Loss: 0.0030416581430472434, Final Batch Loss: 0.00015974283451214433\n",
      "Epoch 3375, Loss: 0.00020888528524665162, Final Batch Loss: 0.00014772133727092296\n",
      "Epoch 3376, Loss: 0.0030622537015005946, Final Batch Loss: 9.189208503812551e-05\n",
      "Epoch 3377, Loss: 0.0004932533192913979, Final Batch Loss: 0.0002446345752105117\n",
      "Epoch 3378, Loss: 0.0004568565636873245, Final Batch Loss: 0.0001311247469857335\n",
      "Epoch 3379, Loss: 0.0015543831686954945, Final Batch Loss: 4.313079989515245e-05\n",
      "Epoch 3380, Loss: 0.0007254704541992396, Final Batch Loss: 0.0003183653752785176\n",
      "Epoch 3381, Loss: 0.011347345192916691, Final Batch Loss: 9.069975931197405e-05\n",
      "Epoch 3382, Loss: 0.0002760801544354763, Final Batch Loss: 0.00022388400975614786\n",
      "Epoch 3383, Loss: 0.00039673772698733956, Final Batch Loss: 0.00016437094018328935\n",
      "Epoch 3384, Loss: 0.00013043196668149903, Final Batch Loss: 9.69054308370687e-05\n",
      "Epoch 3385, Loss: 0.015472283092094585, Final Batch Loss: 7.413930143229663e-05\n",
      "Epoch 3386, Loss: 0.0004227188474033028, Final Batch Loss: 0.0002228595403721556\n",
      "Epoch 3387, Loss: 0.004102552804397419, Final Batch Loss: 0.00019308322225697339\n",
      "Epoch 3388, Loss: 0.00011628796710283495, Final Batch Loss: 2.186884739785455e-05\n",
      "Epoch 3389, Loss: 0.00041510010487399995, Final Batch Loss: 0.0002716831222642213\n",
      "Epoch 3390, Loss: 0.0017797459149733186, Final Batch Loss: 0.0012689721770584583\n",
      "Epoch 3391, Loss: 0.0004743419849546626, Final Batch Loss: 0.00025702855782583356\n",
      "Epoch 3392, Loss: 0.0006852404621895403, Final Batch Loss: 0.00027864641742780805\n",
      "Epoch 3393, Loss: 0.0005157486593816429, Final Batch Loss: 0.00011451897444203496\n",
      "Epoch 3394, Loss: 0.0007034273294266313, Final Batch Loss: 0.000297940568998456\n",
      "Epoch 3395, Loss: 0.0012083768378943205, Final Batch Loss: 0.0005649771192111075\n",
      "Epoch 3396, Loss: 0.000563313951715827, Final Batch Loss: 0.00010273486259393394\n",
      "Epoch 3397, Loss: 0.00088518786651548, Final Batch Loss: 0.00022842762700747699\n",
      "Epoch 3398, Loss: 0.005025814869441092, Final Batch Loss: 0.0005829246947541833\n",
      "Epoch 3399, Loss: 0.0028584373503690585, Final Batch Loss: 0.0026787202805280685\n",
      "Epoch 3400, Loss: 0.0005546596948988736, Final Batch Loss: 0.0003840219578705728\n",
      "Epoch 3401, Loss: 0.0017938778910320252, Final Batch Loss: 0.001332693500444293\n",
      "Epoch 3402, Loss: 0.0013193712002248503, Final Batch Loss: 4.0960068872664124e-05\n",
      "Epoch 3403, Loss: 0.0015218075714074075, Final Batch Loss: 0.0008502264972776175\n",
      "Epoch 3404, Loss: 0.00046131917042657733, Final Batch Loss: 0.00028839270817115903\n",
      "Epoch 3405, Loss: 0.000405092621804215, Final Batch Loss: 0.00025453680427744985\n",
      "Epoch 3406, Loss: 0.0007759250293020159, Final Batch Loss: 0.00038876841426827013\n",
      "Epoch 3407, Loss: 0.000756190886022523, Final Batch Loss: 0.0006937995785847306\n",
      "Epoch 3408, Loss: 0.0008755224262131378, Final Batch Loss: 0.00010367848153691739\n",
      "Epoch 3409, Loss: 0.0005031457521909033, Final Batch Loss: 6.562983799085487e-06\n",
      "Epoch 3410, Loss: 0.003788725007325411, Final Batch Loss: 0.0008578870911151171\n",
      "Epoch 3411, Loss: 0.0001490720060246531, Final Batch Loss: 9.543739724904299e-05\n",
      "Epoch 3412, Loss: 0.001423961490218062, Final Batch Loss: 0.00012084877380402759\n",
      "Epoch 3413, Loss: 0.0007885713275754824, Final Batch Loss: 0.0006231393781490624\n",
      "Epoch 3414, Loss: 0.0001508962595835328, Final Batch Loss: 6.343563291011378e-05\n",
      "Epoch 3415, Loss: 0.003990936766058439, Final Batch Loss: 0.0039439015090465546\n",
      "Epoch 3416, Loss: 0.0006691266607958823, Final Batch Loss: 0.00019512794096954167\n",
      "Epoch 3417, Loss: 0.0003594190056901425, Final Batch Loss: 0.00015267213166225702\n",
      "Epoch 3418, Loss: 0.003238530163798714, Final Batch Loss: 0.0032202950678765774\n",
      "Epoch 3419, Loss: 0.00017606332403374836, Final Batch Loss: 0.00010592857870506123\n",
      "Epoch 3420, Loss: 0.0007137489737942815, Final Batch Loss: 0.0005055991932749748\n",
      "Epoch 3421, Loss: 0.0005901709955651313, Final Batch Loss: 0.00041393982246518135\n",
      "Epoch 3422, Loss: 0.0010613651247695088, Final Batch Loss: 0.000908703834284097\n",
      "Epoch 3423, Loss: 0.0007376093926723115, Final Batch Loss: 8.361267828149721e-05\n",
      "Epoch 3424, Loss: 0.0015187213430181146, Final Batch Loss: 0.0006240431102924049\n",
      "Epoch 3425, Loss: 0.0008782781951595098, Final Batch Loss: 0.0008100714767351747\n",
      "Epoch 3426, Loss: 0.0001502340819570236, Final Batch Loss: 8.375511242775247e-05\n",
      "Epoch 3427, Loss: 0.0007407266821246594, Final Batch Loss: 0.0003041051677428186\n",
      "Epoch 3428, Loss: 0.000627407367574051, Final Batch Loss: 0.0002035633660852909\n",
      "Epoch 3429, Loss: 0.0009113351479754783, Final Batch Loss: 9.367467282572761e-05\n",
      "Epoch 3430, Loss: 0.0013092425069771707, Final Batch Loss: 0.0009699861984699965\n",
      "Epoch 3431, Loss: 0.006769388040993363, Final Batch Loss: 0.0006358358659781516\n",
      "Epoch 3432, Loss: 0.0003710245291586034, Final Batch Loss: 0.00011765924136852846\n",
      "Epoch 3433, Loss: 0.00041534491174388677, Final Batch Loss: 0.0002823826507665217\n",
      "Epoch 3434, Loss: 0.002248242039058823, Final Batch Loss: 6.62657039356418e-05\n",
      "Epoch 3435, Loss: 0.00018621566414367408, Final Batch Loss: 1.7250669770874083e-05\n",
      "Epoch 3436, Loss: 0.0018869084306061268, Final Batch Loss: 0.001661075046285987\n",
      "Epoch 3437, Loss: 0.00025916848971974105, Final Batch Loss: 0.00016941310605034232\n",
      "Epoch 3438, Loss: 0.0012201141216792166, Final Batch Loss: 0.0005924355355091393\n",
      "Epoch 3439, Loss: 0.0001833731948863715, Final Batch Loss: 0.00010536501213209704\n",
      "Epoch 3440, Loss: 0.001977776875719428, Final Batch Loss: 0.0017886919667944312\n",
      "Epoch 3441, Loss: 0.0014109056792221963, Final Batch Loss: 0.0002439530217088759\n",
      "Epoch 3442, Loss: 0.0003876732698699925, Final Batch Loss: 0.00034860786399804056\n",
      "Epoch 3443, Loss: 0.0016377918072976172, Final Batch Loss: 0.0011481125839054585\n",
      "Epoch 3444, Loss: 0.00014304117576102726, Final Batch Loss: 1.6539106582058594e-05\n",
      "Epoch 3445, Loss: 0.0017836320548667572, Final Batch Loss: 0.0017329308902844787\n",
      "Epoch 3446, Loss: 0.0005381584487622604, Final Batch Loss: 0.00020883702381979674\n",
      "Epoch 3447, Loss: 0.00015465778415091336, Final Batch Loss: 3.174676385242492e-05\n",
      "Epoch 3448, Loss: 0.0003019511350430548, Final Batch Loss: 8.693989366292953e-05\n",
      "Epoch 3449, Loss: 0.00040023052861215547, Final Batch Loss: 0.0003056902205571532\n",
      "Epoch 3450, Loss: 0.00016166199566214345, Final Batch Loss: 3.7211542803561315e-05\n",
      "Epoch 3451, Loss: 0.0010983835672959685, Final Batch Loss: 0.0006262374809011817\n",
      "Epoch 3452, Loss: 0.00013796502753393725, Final Batch Loss: 5.8088015066459775e-05\n",
      "Epoch 3453, Loss: 0.0023933234106152668, Final Batch Loss: 5.302200406731572e-06\n",
      "Epoch 3454, Loss: 7.983199247973971e-05, Final Batch Loss: 5.188346767681651e-05\n",
      "Epoch 3455, Loss: 0.0002696456722333096, Final Batch Loss: 0.0001539439253974706\n",
      "Epoch 3456, Loss: 0.0003089973106398247, Final Batch Loss: 6.289179873419926e-05\n",
      "Epoch 3457, Loss: 0.0005254375282675028, Final Batch Loss: 0.00017408354324288666\n",
      "Epoch 3458, Loss: 0.0004622981359716505, Final Batch Loss: 9.776937076821923e-05\n",
      "Epoch 3459, Loss: 0.00019924860862374771, Final Batch Loss: 5.454205165733583e-06\n",
      "Epoch 3460, Loss: 0.00010805396505020326, Final Batch Loss: 1.5046453881950583e-05\n",
      "Epoch 3461, Loss: 0.0005779302591690794, Final Batch Loss: 0.0003910686355084181\n",
      "Epoch 3462, Loss: 0.00020742211199831218, Final Batch Loss: 2.9710907256230712e-05\n",
      "Epoch 3463, Loss: 0.00026731524121714756, Final Batch Loss: 2.2636486392002553e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3464, Loss: 8.510366387781687e-05, Final Batch Loss: 4.174931746092625e-05\n",
      "Epoch 3465, Loss: 0.0012746431639243383, Final Batch Loss: 0.0012473404640331864\n",
      "Epoch 3466, Loss: 0.002734140209213365, Final Batch Loss: 0.0026538975071161985\n",
      "Epoch 3467, Loss: 0.0003140337739750976, Final Batch Loss: 2.164135548810009e-05\n",
      "Epoch 3468, Loss: 0.0033313462045043707, Final Batch Loss: 0.00033211964182555676\n",
      "Epoch 3469, Loss: 0.0001007927926366392, Final Batch Loss: 7.3685218922037166e-06\n",
      "Epoch 3470, Loss: 6.930733434273861e-05, Final Batch Loss: 2.2022475604899228e-05\n",
      "Epoch 3471, Loss: 0.00881538912653923, Final Batch Loss: 8.43685120344162e-06\n",
      "Epoch 3472, Loss: 0.00044306246854830533, Final Batch Loss: 5.966953176539391e-05\n",
      "Epoch 3473, Loss: 0.002559136861236766, Final Batch Loss: 0.00230616657063365\n",
      "Epoch 3474, Loss: 0.0002960364554382977, Final Batch Loss: 1.1499015272420365e-05\n",
      "Epoch 3475, Loss: 0.00011828228161903098, Final Batch Loss: 3.2581847335677594e-05\n",
      "Epoch 3476, Loss: 0.0006341512562357821, Final Batch Loss: 0.000521767302416265\n",
      "Epoch 3477, Loss: 0.00011474505117803346, Final Batch Loss: 2.5123683371930383e-05\n",
      "Epoch 3478, Loss: 0.0004919634811813012, Final Batch Loss: 0.0004473926092032343\n",
      "Epoch 3479, Loss: 7.723279304627795e-05, Final Batch Loss: 1.739938488753978e-05\n",
      "Epoch 3480, Loss: 0.00028003432089462876, Final Batch Loss: 0.0001455931196687743\n",
      "Epoch 3481, Loss: 0.0001221179663843941, Final Batch Loss: 8.004002302186564e-05\n",
      "Epoch 3482, Loss: 0.0003464457943209709, Final Batch Loss: 3.002812491104123e-06\n",
      "Epoch 3483, Loss: 0.0002614245386212133, Final Batch Loss: 5.787655391031876e-05\n",
      "Epoch 3484, Loss: 0.00010970425137202255, Final Batch Loss: 6.520756869576871e-05\n",
      "Epoch 3485, Loss: 0.00029828589322278276, Final Batch Loss: 5.4441487009171396e-05\n",
      "Epoch 3486, Loss: 3.537644261086825e-05, Final Batch Loss: 4.0762624848866835e-06\n",
      "Epoch 3487, Loss: 4.9326405132887885e-05, Final Batch Loss: 4.0037139115156606e-05\n",
      "Epoch 3488, Loss: 0.017012749100103974, Final Batch Loss: 0.00012412876822054386\n",
      "Epoch 3489, Loss: 0.000682364003296243, Final Batch Loss: 5.2101928304182366e-05\n",
      "Epoch 3490, Loss: 0.00040990227716974914, Final Batch Loss: 1.5619880286976695e-05\n",
      "Epoch 3491, Loss: 0.0004355493583716452, Final Batch Loss: 6.636709440499544e-05\n",
      "Epoch 3492, Loss: 0.0001619675531401299, Final Batch Loss: 4.218048707116395e-05\n",
      "Epoch 3493, Loss: 0.0007883227517595515, Final Batch Loss: 0.00020879726798739284\n",
      "Epoch 3494, Loss: 0.0005348862760001794, Final Batch Loss: 7.907369581516832e-05\n",
      "Epoch 3495, Loss: 0.0002566493203630671, Final Batch Loss: 8.52505472721532e-05\n",
      "Epoch 3496, Loss: 0.00027001920534530655, Final Batch Loss: 9.706598211778328e-05\n",
      "Epoch 3497, Loss: 0.0004733356327051297, Final Batch Loss: 0.00014274749264586717\n",
      "Epoch 3498, Loss: 0.00011313493814668618, Final Batch Loss: 3.6698675103252754e-05\n",
      "Epoch 3499, Loss: 0.007551251066615805, Final Batch Loss: 8.158860146068037e-05\n",
      "Epoch 3500, Loss: 5.592009438259993e-05, Final Batch Loss: 1.7358552213408984e-05\n",
      "Epoch 3501, Loss: 0.00035277294045954477, Final Batch Loss: 0.0003469822113402188\n",
      "Epoch 3502, Loss: 0.0012024236202705652, Final Batch Loss: 0.0011537119280546904\n",
      "Epoch 3503, Loss: 0.0012673104065470397, Final Batch Loss: 0.000403540616389364\n",
      "Epoch 3504, Loss: 0.00029822806391166523, Final Batch Loss: 0.00019090955902356654\n",
      "Epoch 3505, Loss: 0.013136430032318458, Final Batch Loss: 0.0004440148768480867\n",
      "Epoch 3506, Loss: 2.5944141725631198e-05, Final Batch Loss: 2.0437955754459836e-05\n",
      "Epoch 3507, Loss: 0.0020803940715268254, Final Batch Loss: 2.0808656699955463e-05\n",
      "Epoch 3508, Loss: 0.0005404018434091995, Final Batch Loss: 6.836604825366521e-06\n",
      "Epoch 3509, Loss: 0.0015350897156167775, Final Batch Loss: 0.0012338103260844946\n",
      "Epoch 3510, Loss: 0.017523795453598723, Final Batch Loss: 0.000295454723527655\n",
      "Epoch 3511, Loss: 0.003043299632736307, Final Batch Loss: 8.779204108577687e-06\n",
      "Epoch 3512, Loss: 0.0001705564409348881, Final Batch Loss: 0.0001504256360931322\n",
      "Epoch 3513, Loss: 0.0012401447165757418, Final Batch Loss: 0.0007898122421465814\n",
      "Epoch 3514, Loss: 0.00024936406407505274, Final Batch Loss: 7.2854760219343e-05\n",
      "Epoch 3515, Loss: 0.0013920341443736106, Final Batch Loss: 8.391129085794091e-06\n",
      "Epoch 3516, Loss: 0.0013153054096619599, Final Batch Loss: 0.00011782306683016941\n",
      "Epoch 3517, Loss: 0.0025645215064287186, Final Batch Loss: 0.0011188972275704145\n",
      "Epoch 3518, Loss: 0.0042597371866577305, Final Batch Loss: 0.004176110494881868\n",
      "Epoch 3519, Loss: 0.01396063668653369, Final Batch Loss: 0.007810997311025858\n",
      "Epoch 3520, Loss: 0.00041139302629744634, Final Batch Loss: 2.167800994357094e-05\n",
      "Epoch 3521, Loss: 0.002588977851701202, Final Batch Loss: 0.002542915055528283\n",
      "Epoch 3522, Loss: 0.0004699448918472626, Final Batch Loss: 1.2737044926325325e-05\n",
      "Epoch 3523, Loss: 0.000491704027808737, Final Batch Loss: 0.00045968551421537995\n",
      "Epoch 3524, Loss: 6.954398850211874e-05, Final Batch Loss: 3.7864621845074e-05\n",
      "Epoch 3525, Loss: 0.00014131988609733526, Final Batch Loss: 1.7468215446569957e-05\n",
      "Epoch 3526, Loss: 0.00025527233083266765, Final Batch Loss: 0.00013380502059590071\n",
      "Epoch 3527, Loss: 0.004215251919958973, Final Batch Loss: 4.8597143177175894e-05\n",
      "Epoch 3528, Loss: 0.0004918804770568386, Final Batch Loss: 0.0003521184262353927\n",
      "Epoch 3529, Loss: 0.015036658849567175, Final Batch Loss: 0.0009023719467222691\n",
      "Epoch 3530, Loss: 0.000962982652708888, Final Batch Loss: 0.0007877678144723177\n",
      "Epoch 3531, Loss: 0.0023031448872643523, Final Batch Loss: 5.874130147276446e-05\n",
      "Epoch 3532, Loss: 0.0002800679940264672, Final Batch Loss: 0.00018073544197250158\n",
      "Epoch 3533, Loss: 0.005394282328779809, Final Batch Loss: 0.0052365949377417564\n",
      "Epoch 3534, Loss: 0.0003457861348579172, Final Batch Loss: 0.0003065727651119232\n",
      "Epoch 3535, Loss: 0.00029176932730479166, Final Batch Loss: 5.58649844606407e-05\n",
      "Epoch 3536, Loss: 0.0001525905536254868, Final Batch Loss: 4.3763473513536155e-05\n",
      "Epoch 3537, Loss: 0.0016974910977296531, Final Batch Loss: 0.0006441167206503451\n",
      "Epoch 3538, Loss: 0.0012460028228815645, Final Batch Loss: 0.0008740381454117596\n",
      "Epoch 3539, Loss: 0.00046685649431310594, Final Batch Loss: 9.631679859012365e-05\n",
      "Epoch 3540, Loss: 0.0002047766283794772, Final Batch Loss: 4.267113035893999e-05\n",
      "Epoch 3541, Loss: 0.0006238402565941215, Final Batch Loss: 0.0004679614503402263\n",
      "Epoch 3542, Loss: 0.00025110546994255856, Final Batch Loss: 0.0001768153888406232\n",
      "Epoch 3543, Loss: 0.0005876558934687637, Final Batch Loss: 0.000520786561537534\n",
      "Epoch 3544, Loss: 0.0022658952802885324, Final Batch Loss: 5.689149838872254e-05\n",
      "Epoch 3545, Loss: 0.0008315599989145994, Final Batch Loss: 0.0005126761388964951\n",
      "Epoch 3546, Loss: 0.0020138383843004704, Final Batch Loss: 0.001167698996141553\n",
      "Epoch 3547, Loss: 0.00010194621609116439, Final Batch Loss: 2.4055940230027772e-05\n",
      "Epoch 3548, Loss: 7.724620081717148e-05, Final Batch Loss: 4.518818241194822e-05\n",
      "Epoch 3549, Loss: 0.0004577998770400882, Final Batch Loss: 0.00039451857446692884\n",
      "Epoch 3550, Loss: 0.000545077899005264, Final Batch Loss: 0.00018870766507461667\n",
      "Epoch 3551, Loss: 0.00012284011972951703, Final Batch Loss: 5.672948100254871e-05\n",
      "Epoch 3552, Loss: 0.0010950189825962298, Final Batch Loss: 0.0009949076920747757\n",
      "Epoch 3553, Loss: 0.0005960292328381911, Final Batch Loss: 0.000139568917802535\n",
      "Epoch 3554, Loss: 0.0054375961735786404, Final Batch Loss: 4.1845192754408345e-05\n",
      "Epoch 3555, Loss: 0.0024662779760546982, Final Batch Loss: 0.0018682761583477259\n",
      "Epoch 3556, Loss: 0.002817654960381333, Final Batch Loss: 0.00010511556320125237\n",
      "Epoch 3557, Loss: 0.0003475197327134083, Final Batch Loss: 1.1089755389548372e-05\n",
      "Epoch 3558, Loss: 0.00020617471454897895, Final Batch Loss: 3.924540214939043e-05\n",
      "Epoch 3559, Loss: 0.004576507082674652, Final Batch Loss: 0.0036637685261666775\n",
      "Epoch 3560, Loss: 0.0004856658852077089, Final Batch Loss: 8.904336573323235e-05\n",
      "Epoch 3561, Loss: 0.0007259592202899512, Final Batch Loss: 5.197137579671107e-05\n",
      "Epoch 3562, Loss: 0.0009377661626785994, Final Batch Loss: 0.0006991965929046273\n",
      "Epoch 3563, Loss: 0.0003328579728076875, Final Batch Loss: 6.694313469779445e-06\n",
      "Epoch 3564, Loss: 0.00015635456384188728, Final Batch Loss: 0.00014308933168649673\n",
      "Epoch 3565, Loss: 0.0007216388185042888, Final Batch Loss: 0.00027404670254327357\n",
      "Epoch 3566, Loss: 0.0003093284467468038, Final Batch Loss: 0.00018463713058736175\n",
      "Epoch 3567, Loss: 0.0036026866728207096, Final Batch Loss: 0.003534790128469467\n",
      "Epoch 3568, Loss: 0.0001676167084951885, Final Batch Loss: 9.240699000656605e-05\n",
      "Epoch 3569, Loss: 0.0003696982039400609, Final Batch Loss: 2.7507559934747405e-05\n",
      "Epoch 3570, Loss: 7.376786197710317e-05, Final Batch Loss: 1.901276300486643e-05\n",
      "Epoch 3571, Loss: 0.0010893024555116426, Final Batch Loss: 0.0010351373348385096\n",
      "Epoch 3572, Loss: 0.0007258902187459171, Final Batch Loss: 0.0005893364432267845\n",
      "Epoch 3573, Loss: 0.0007959066642797552, Final Batch Loss: 4.589356103679165e-05\n",
      "Epoch 3574, Loss: 0.00016453916759928688, Final Batch Loss: 3.0774455808568746e-05\n",
      "Epoch 3575, Loss: 0.00022361611263477243, Final Batch Loss: 4.009477925137617e-05\n",
      "Epoch 3576, Loss: 0.0003388156646906282, Final Batch Loss: 0.0003238689969293773\n",
      "Epoch 3577, Loss: 0.02790818826542818, Final Batch Loss: 3.033221946679987e-05\n",
      "Epoch 3578, Loss: 0.00016598076035734266, Final Batch Loss: 7.754324178677052e-05\n",
      "Epoch 3579, Loss: 0.015941476041916758, Final Batch Loss: 0.0004719519638456404\n",
      "Epoch 3580, Loss: 0.0004841956979362294, Final Batch Loss: 0.00013440042675938457\n",
      "Epoch 3581, Loss: 0.10765912466013106, Final Batch Loss: 0.10754953324794769\n",
      "Epoch 3582, Loss: 0.0027257810834271368, Final Batch Loss: 4.3138537876075134e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3583, Loss: 0.00014326274686027318, Final Batch Loss: 7.153007027227432e-05\n",
      "Epoch 3584, Loss: 0.0006078327969589736, Final Batch Loss: 0.0005678775487467647\n",
      "Epoch 3585, Loss: 0.0002164407414966263, Final Batch Loss: 0.00013259975821711123\n",
      "Epoch 3586, Loss: 0.001210737282235641, Final Batch Loss: 0.0001090654477593489\n",
      "Epoch 3587, Loss: 0.011197860585525632, Final Batch Loss: 0.01099319290369749\n",
      "Epoch 3588, Loss: 0.0005328942970663775, Final Batch Loss: 0.0005094665684737265\n",
      "Epoch 3589, Loss: 0.0008500482799718156, Final Batch Loss: 0.00010806684440467507\n",
      "Epoch 3590, Loss: 0.0080400844453834, Final Batch Loss: 0.007440167013555765\n",
      "Epoch 3591, Loss: 0.002602101842057891, Final Batch Loss: 0.002392912982031703\n",
      "Epoch 3592, Loss: 0.0005035986541770399, Final Batch Loss: 0.00012299712398089468\n",
      "Epoch 3593, Loss: 0.001362458657240495, Final Batch Loss: 0.0011765974340960383\n",
      "Epoch 3594, Loss: 0.00019258204702055082, Final Batch Loss: 9.32971597649157e-05\n",
      "Epoch 3595, Loss: 0.001001046970486641, Final Batch Loss: 0.0006998353637754917\n",
      "Epoch 3596, Loss: 0.00021125136845512316, Final Batch Loss: 6.77602001815103e-05\n",
      "Epoch 3597, Loss: 0.014425784756895155, Final Batch Loss: 0.014142412692308426\n",
      "Epoch 3598, Loss: 0.002092923066811636, Final Batch Loss: 0.001809520530514419\n",
      "Epoch 3599, Loss: 0.00040117754542734474, Final Batch Loss: 0.00013298644626047462\n",
      "Epoch 3600, Loss: 0.0004328227660153061, Final Batch Loss: 0.00032557829399593174\n",
      "Epoch 3601, Loss: 0.0011304866056889296, Final Batch Loss: 0.000437225098721683\n",
      "Epoch 3602, Loss: 0.0015304028056561947, Final Batch Loss: 0.000736223126295954\n",
      "Epoch 3603, Loss: 0.00046558044414268807, Final Batch Loss: 8.867943688528612e-05\n",
      "Epoch 3604, Loss: 0.00233705123719119, Final Batch Loss: 0.0023069472517818213\n",
      "Epoch 3605, Loss: 0.004785709781572223, Final Batch Loss: 0.004618177656084299\n",
      "Epoch 3606, Loss: 0.00039376977656502277, Final Batch Loss: 0.00012724952830467373\n",
      "Epoch 3607, Loss: 0.00017972032947000116, Final Batch Loss: 6.345225119730458e-05\n",
      "Epoch 3608, Loss: 0.0010256204914185219, Final Batch Loss: 7.561989332316443e-05\n",
      "Epoch 3609, Loss: 0.0002093435869028326, Final Batch Loss: 3.29397116729524e-05\n",
      "Epoch 3610, Loss: 0.0003910198465746362, Final Batch Loss: 0.0003571927663870156\n",
      "Epoch 3611, Loss: 0.0035035363398492336, Final Batch Loss: 0.003298690542578697\n",
      "Epoch 3612, Loss: 0.0014770020643481985, Final Batch Loss: 0.00019748964405152947\n",
      "Epoch 3613, Loss: 0.005091952014481649, Final Batch Loss: 6.22135994490236e-05\n",
      "Epoch 3614, Loss: 0.0008521925046807155, Final Batch Loss: 0.0007910992135293782\n",
      "Epoch 3615, Loss: 0.0007858812168706208, Final Batch Loss: 0.00011362819350324571\n",
      "Epoch 3616, Loss: 0.0004562022440950386, Final Batch Loss: 0.0003464457986410707\n",
      "Epoch 3617, Loss: 0.006061202788259834, Final Batch Loss: 6.223696982488036e-05\n",
      "Epoch 3618, Loss: 0.006051280099200085, Final Batch Loss: 0.0059379576705396175\n",
      "Epoch 3619, Loss: 0.0001454959055990912, Final Batch Loss: 8.659439481562003e-05\n",
      "Epoch 3620, Loss: 0.0025423385959584266, Final Batch Loss: 0.0020882149692624807\n",
      "Epoch 3621, Loss: 0.00019939556113968138, Final Batch Loss: 1.6504835002706386e-05\n",
      "Epoch 3622, Loss: 0.0011806197580881417, Final Batch Loss: 0.0007029234548099339\n",
      "Epoch 3623, Loss: 0.0009333202033303678, Final Batch Loss: 0.00029003730742260814\n",
      "Epoch 3624, Loss: 0.00024976405256893486, Final Batch Loss: 0.0001807315566111356\n",
      "Epoch 3625, Loss: 0.0008740104312892072, Final Batch Loss: 0.0008466861327178776\n",
      "Epoch 3626, Loss: 0.0009654988843976753, Final Batch Loss: 8.42698682390619e-06\n",
      "Epoch 3627, Loss: 0.0006419229903258383, Final Batch Loss: 0.0004414088325574994\n",
      "Epoch 3628, Loss: 0.0008061871994868852, Final Batch Loss: 4.461830394575372e-05\n",
      "Epoch 3629, Loss: 0.0001441770546080079, Final Batch Loss: 4.374420313979499e-05\n",
      "Epoch 3630, Loss: 0.003563379228580743, Final Batch Loss: 0.0034908188972622156\n",
      "Epoch 3631, Loss: 0.0027307579293847084, Final Batch Loss: 0.001246603555046022\n",
      "Epoch 3632, Loss: 0.001246931031346321, Final Batch Loss: 0.0006922300672158599\n",
      "Epoch 3633, Loss: 0.0003891996427682898, Final Batch Loss: 2.5640445073804585e-06\n",
      "Epoch 3634, Loss: 0.0005273628048598766, Final Batch Loss: 0.0003374529187567532\n",
      "Epoch 3635, Loss: 0.0001394859236825141, Final Batch Loss: 0.00012462744780350477\n",
      "Epoch 3636, Loss: 0.000144613666634541, Final Batch Loss: 7.445162918884307e-05\n",
      "Epoch 3637, Loss: 0.0005423997936304659, Final Batch Loss: 0.00043618789641186595\n",
      "Epoch 3638, Loss: 0.0008439996163360775, Final Batch Loss: 0.00041674767271615565\n",
      "Epoch 3639, Loss: 0.00042079447462128883, Final Batch Loss: 2.523565626688651e-06\n",
      "Epoch 3640, Loss: 0.0003173674049321562, Final Batch Loss: 0.0001670484634814784\n",
      "Epoch 3641, Loss: 0.00020425398543011397, Final Batch Loss: 8.8832042820286e-05\n",
      "Epoch 3642, Loss: 0.00012293920053707552, Final Batch Loss: 5.59094087293488e-06\n",
      "Epoch 3643, Loss: 0.0004918429631288745, Final Batch Loss: 0.00048008060548454523\n",
      "Epoch 3644, Loss: 0.007716275526036043, Final Batch Loss: 6.70359077048488e-05\n",
      "Epoch 3645, Loss: 0.0007580127748951782, Final Batch Loss: 4.008501491625793e-05\n",
      "Epoch 3646, Loss: 0.00043925768113695085, Final Batch Loss: 0.00016754743410274386\n",
      "Epoch 3647, Loss: 0.0005063877542852424, Final Batch Loss: 7.926267426228151e-05\n",
      "Epoch 3648, Loss: 0.0001477924088248983, Final Batch Loss: 1.2151649571023881e-05\n",
      "Epoch 3649, Loss: 0.00013512679652194493, Final Batch Loss: 4.4119416998000816e-05\n",
      "Epoch 3650, Loss: 0.0006237464003788773, Final Batch Loss: 0.0005644998163916171\n",
      "Epoch 3651, Loss: 0.0006454650283558294, Final Batch Loss: 0.0006157832685858011\n",
      "Epoch 3652, Loss: 0.001000244403257966, Final Batch Loss: 0.000967447878792882\n",
      "Epoch 3653, Loss: 0.0004942957748426124, Final Batch Loss: 0.00031707342714071274\n",
      "Epoch 3654, Loss: 0.00021820771326019894, Final Batch Loss: 2.949642475869041e-05\n",
      "Epoch 3655, Loss: 0.00016179556405404583, Final Batch Loss: 4.344218905316666e-05\n",
      "Epoch 3656, Loss: 0.00023576661624247208, Final Batch Loss: 0.00010902087524300441\n",
      "Epoch 3657, Loss: 0.0005922208802076057, Final Batch Loss: 0.0005240297177806497\n",
      "Epoch 3658, Loss: 0.00017001132800942287, Final Batch Loss: 8.011735917534679e-05\n",
      "Epoch 3659, Loss: 0.0003545614454196766, Final Batch Loss: 0.00018128930241800845\n",
      "Epoch 3660, Loss: 0.00014234007176128216, Final Batch Loss: 3.8007452531019226e-05\n",
      "Epoch 3661, Loss: 0.00012939480438944884, Final Batch Loss: 4.759220973937772e-05\n",
      "Epoch 3662, Loss: 0.00023439418146153912, Final Batch Loss: 5.668996163876727e-05\n",
      "Epoch 3663, Loss: 0.002042284933850169, Final Batch Loss: 0.0008234395645558834\n",
      "Epoch 3664, Loss: 0.0006728003409079975, Final Batch Loss: 1.205409898830112e-05\n",
      "Epoch 3665, Loss: 0.000257583529673866, Final Batch Loss: 1.8099255612469278e-05\n",
      "Epoch 3666, Loss: 0.0005138469714438543, Final Batch Loss: 0.00032861685031093657\n",
      "Epoch 3667, Loss: 0.0007377278961939737, Final Batch Loss: 0.000569711672142148\n",
      "Epoch 3668, Loss: 0.0002819585188262863, Final Batch Loss: 2.0753968783537857e-05\n",
      "Epoch 3669, Loss: 0.00014095613732933998, Final Batch Loss: 8.355524914804846e-05\n",
      "Epoch 3670, Loss: 4.9997353926301e-05, Final Batch Loss: 3.093790655839257e-05\n",
      "Epoch 3671, Loss: 0.0002915348086389713, Final Batch Loss: 1.526739652035758e-05\n",
      "Epoch 3672, Loss: 0.00045795287951477803, Final Batch Loss: 0.00042545009637251496\n",
      "Epoch 3673, Loss: 0.00031376827973872423, Final Batch Loss: 0.00029924625414423645\n",
      "Epoch 3674, Loss: 6.12598942097975e-05, Final Batch Loss: 3.336338704684749e-05\n",
      "Epoch 3675, Loss: 2.0280565877328627e-05, Final Batch Loss: 1.1007941793650389e-05\n",
      "Epoch 3676, Loss: 0.00013674710316990968, Final Batch Loss: 2.6825216991710477e-05\n",
      "Epoch 3677, Loss: 0.000251412970101228, Final Batch Loss: 5.3675812523579225e-05\n",
      "Epoch 3678, Loss: 0.0010199272437603213, Final Batch Loss: 0.000981737277470529\n",
      "Epoch 3679, Loss: 0.00032274772456730716, Final Batch Loss: 5.3107050916878507e-05\n",
      "Epoch 3680, Loss: 0.0004948869827785529, Final Batch Loss: 3.242443926865235e-05\n",
      "Epoch 3681, Loss: 0.0005933501815889031, Final Batch Loss: 0.00032056577038019896\n",
      "Epoch 3682, Loss: 4.641383293346735e-05, Final Batch Loss: 5.615992449747864e-06\n",
      "Epoch 3683, Loss: 0.00035778848905465566, Final Batch Loss: 3.151941564283334e-05\n",
      "Epoch 3684, Loss: 0.004610771429724991, Final Batch Loss: 0.00038195226807147264\n",
      "Epoch 3685, Loss: 8.046826042118482e-05, Final Batch Loss: 4.971379166818224e-05\n",
      "Epoch 3686, Loss: 0.00015602008352288976, Final Batch Loss: 8.601403533248231e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3687, Loss: 0.0007129660516511649, Final Batch Loss: 0.0002043528074864298\n",
      "Epoch 3688, Loss: 0.0014566699246643111, Final Batch Loss: 0.0013780330773442984\n",
      "Epoch 3689, Loss: 0.00018320062008569948, Final Batch Loss: 1.6786780179245397e-05\n",
      "Epoch 3690, Loss: 3.7607361264235806e-05, Final Batch Loss: 1.0372438737249468e-05\n",
      "Epoch 3691, Loss: 0.007561135163996369, Final Batch Loss: 0.0005845437408424914\n",
      "Epoch 3692, Loss: 0.0011173607490491122, Final Batch Loss: 0.0009152127895504236\n",
      "Epoch 3693, Loss: 0.001472706935601309, Final Batch Loss: 0.0010404438944533467\n",
      "Epoch 3694, Loss: 0.0011869797090184875, Final Batch Loss: 0.001069359597750008\n",
      "Epoch 3695, Loss: 0.0011827559355879202, Final Batch Loss: 0.0010254577500745654\n",
      "Epoch 3696, Loss: 0.0004111349117010832, Final Batch Loss: 7.602738332934678e-05\n",
      "Epoch 3697, Loss: 0.00015438835544046015, Final Batch Loss: 7.70225960877724e-05\n",
      "Epoch 3698, Loss: 0.0003698267028084956, Final Batch Loss: 6.465057231253013e-05\n",
      "Epoch 3699, Loss: 0.00015477827037102543, Final Batch Loss: 3.892051972798072e-05\n",
      "Epoch 3700, Loss: 0.00027051178767578676, Final Batch Loss: 9.536339348414913e-05\n",
      "Epoch 3701, Loss: 4.973535396857187e-05, Final Batch Loss: 2.3652470190427266e-05\n",
      "Epoch 3702, Loss: 0.0001637303503230214, Final Batch Loss: 0.00014668928633909672\n",
      "Epoch 3703, Loss: 0.008208596882468555, Final Batch Loss: 0.00809827633202076\n",
      "Epoch 3704, Loss: 2.6458524644112913e-05, Final Batch Loss: 1.7718625713314395e-06\n",
      "Epoch 3705, Loss: 0.0008739308177609928, Final Batch Loss: 6.348465831251815e-05\n",
      "Epoch 3706, Loss: 0.000906760738871526, Final Batch Loss: 0.00010395043500466272\n",
      "Epoch 3707, Loss: 0.00012889602294308133, Final Batch Loss: 7.097680645529181e-05\n",
      "Epoch 3708, Loss: 0.0002988133201142773, Final Batch Loss: 0.00013302474690135568\n",
      "Epoch 3709, Loss: 0.0004977121643605642, Final Batch Loss: 0.00039585682679899037\n",
      "Epoch 3710, Loss: 0.0001761548628564924, Final Batch Loss: 5.014108319301158e-05\n",
      "Epoch 3711, Loss: 8.667275642437744e-05, Final Batch Loss: 6.608227977267234e-06\n",
      "Epoch 3712, Loss: 5.3504769311985e-05, Final Batch Loss: 4.1237690311390907e-05\n",
      "Epoch 3713, Loss: 0.0006853113591205329, Final Batch Loss: 0.00029852704028598964\n",
      "Epoch 3714, Loss: 7.914824618637795e-05, Final Batch Loss: 6.866875082778279e-06\n",
      "Epoch 3715, Loss: 0.0005045806028647348, Final Batch Loss: 0.0001312114327447489\n",
      "Epoch 3716, Loss: 0.007323592948523583, Final Batch Loss: 4.239943882566877e-05\n",
      "Epoch 3717, Loss: 0.00022664205789624248, Final Batch Loss: 0.00020179078273940831\n",
      "Epoch 3718, Loss: 5.7174984249286354e-05, Final Batch Loss: 3.522106271702796e-05\n",
      "Epoch 3719, Loss: 9.309384404332377e-05, Final Batch Loss: 3.159247353323735e-05\n",
      "Epoch 3720, Loss: 0.0007336871494771913, Final Batch Loss: 0.000669881294015795\n",
      "Epoch 3721, Loss: 4.366543362266384e-05, Final Batch Loss: 1.4063194612390362e-05\n",
      "Epoch 3722, Loss: 0.0003224238025723025, Final Batch Loss: 0.0001365840871585533\n",
      "Epoch 3723, Loss: 0.00020155650418018922, Final Batch Loss: 0.00018334266496822238\n",
      "Epoch 3724, Loss: 8.926031659939326e-05, Final Batch Loss: 5.781173604191281e-05\n",
      "Epoch 3725, Loss: 0.00022396353597287089, Final Batch Loss: 4.86500357510522e-05\n",
      "Epoch 3726, Loss: 4.34670382674085e-05, Final Batch Loss: 2.2640359020442702e-05\n",
      "Epoch 3727, Loss: 0.00014226569692254998, Final Batch Loss: 1.4459135854849592e-05\n",
      "Epoch 3728, Loss: 0.0001736265840008855, Final Batch Loss: 3.510562237352133e-05\n",
      "Epoch 3729, Loss: 0.0006467438670370029, Final Batch Loss: 0.0006272034370340407\n",
      "Epoch 3730, Loss: 0.0005211314492044039, Final Batch Loss: 0.00041766141657717526\n",
      "Epoch 3731, Loss: 0.00020597654292942025, Final Batch Loss: 0.00016817498544696718\n",
      "Epoch 3732, Loss: 0.0003950302161683794, Final Batch Loss: 0.0003877845883835107\n",
      "Epoch 3733, Loss: 0.002882577678974485, Final Batch Loss: 0.0028704453725367785\n",
      "Epoch 3734, Loss: 0.0009316492796642706, Final Batch Loss: 1.939879439305514e-05\n",
      "Epoch 3735, Loss: 0.00010066719914902933, Final Batch Loss: 5.127537951921113e-05\n",
      "Epoch 3736, Loss: 0.0007012327023403486, Final Batch Loss: 3.0139641239657067e-05\n",
      "Epoch 3737, Loss: 0.00015668776268285, Final Batch Loss: 9.165437404590193e-06\n",
      "Epoch 3738, Loss: 0.00023957926168804988, Final Batch Loss: 0.0001098457069019787\n",
      "Epoch 3739, Loss: 0.00024255330208688974, Final Batch Loss: 7.875351002439857e-05\n",
      "Epoch 3740, Loss: 0.0006286862699198537, Final Batch Loss: 6.722308899043128e-05\n",
      "Epoch 3741, Loss: 0.00875925028230995, Final Batch Loss: 0.0074779135175049305\n",
      "Epoch 3742, Loss: 0.00014068716609472176, Final Batch Loss: 9.695248991192784e-06\n",
      "Epoch 3743, Loss: 0.00011479776003398001, Final Batch Loss: 4.627761518349871e-05\n",
      "Epoch 3744, Loss: 0.0006613151854253374, Final Batch Loss: 0.0005689311074092984\n",
      "Epoch 3745, Loss: 0.00021889271010877565, Final Batch Loss: 5.3075818868819624e-05\n",
      "Epoch 3746, Loss: 0.00038866818158567185, Final Batch Loss: 1.4605816431867424e-05\n",
      "Epoch 3747, Loss: 0.00018850567721528932, Final Batch Loss: 9.413642692379653e-05\n",
      "Epoch 3748, Loss: 0.000527857100678375, Final Batch Loss: 0.00048528140177950263\n",
      "Epoch 3749, Loss: 0.0003305094942334108, Final Batch Loss: 0.0003069684898946434\n",
      "Epoch 3750, Loss: 0.00016632326878607273, Final Batch Loss: 9.874712850432843e-05\n",
      "Epoch 3751, Loss: 0.0006444280370487832, Final Batch Loss: 0.00011203847680008039\n",
      "Epoch 3752, Loss: 0.0011447710130596533, Final Batch Loss: 9.346638398710638e-05\n",
      "Epoch 3753, Loss: 0.0010617077932693064, Final Batch Loss: 0.0009121469338424504\n",
      "Epoch 3754, Loss: 3.34728647430893e-05, Final Batch Loss: 2.0860336007899605e-05\n",
      "Epoch 3755, Loss: 0.0001478490376030095, Final Batch Loss: 7.481469219783321e-05\n",
      "Epoch 3756, Loss: 0.0011278546116955113, Final Batch Loss: 0.001096549560315907\n",
      "Epoch 3757, Loss: 0.0001016792102745967, Final Batch Loss: 3.0120283554424532e-05\n",
      "Epoch 3758, Loss: 0.0002211089595220983, Final Batch Loss: 0.000138809802592732\n",
      "Epoch 3759, Loss: 0.010455703362822533, Final Batch Loss: 0.0018837908282876015\n",
      "Epoch 3760, Loss: 0.0001684508733887924, Final Batch Loss: 0.00014328272663988173\n",
      "Epoch 3761, Loss: 4.677523611462675e-05, Final Batch Loss: 1.550165325170383e-05\n",
      "Epoch 3762, Loss: 0.0029182294092606753, Final Batch Loss: 0.00024134942214004695\n",
      "Epoch 3763, Loss: 0.006453515816247091, Final Batch Loss: 0.006292955484241247\n",
      "Epoch 3764, Loss: 0.00021822586859343573, Final Batch Loss: 8.088809408945963e-05\n",
      "Epoch 3765, Loss: 0.008184046562291769, Final Batch Loss: 2.753067292360356e-06\n",
      "Epoch 3766, Loss: 0.0008268565434264019, Final Batch Loss: 0.0006234838510863483\n",
      "Epoch 3767, Loss: 6.290611781878397e-05, Final Batch Loss: 3.983099668403156e-05\n",
      "Epoch 3768, Loss: 0.0004093858879059553, Final Batch Loss: 0.00028136660694144666\n",
      "Epoch 3769, Loss: 0.0016064816227299161, Final Batch Loss: 4.0496008296031505e-05\n",
      "Epoch 3770, Loss: 3.9915263187140226e-05, Final Batch Loss: 1.77697220351547e-05\n",
      "Epoch 3771, Loss: 0.00020909243085043272, Final Batch Loss: 0.0002008656447287649\n",
      "Epoch 3772, Loss: 0.0002649581292644143, Final Batch Loss: 3.976946754846722e-05\n",
      "Epoch 3773, Loss: 4.280359280528501e-05, Final Batch Loss: 2.9283613912411965e-05\n",
      "Epoch 3774, Loss: 0.001307554344748496, Final Batch Loss: 1.521691410744097e-05\n",
      "Epoch 3775, Loss: 0.0001536396721348865, Final Batch Loss: 2.202250288974028e-05\n",
      "Epoch 3776, Loss: 0.00021286260380293243, Final Batch Loss: 4.647718014894053e-06\n",
      "Epoch 3777, Loss: 0.00011022794569726102, Final Batch Loss: 8.853279723552987e-05\n",
      "Epoch 3778, Loss: 0.00015825077571207657, Final Batch Loss: 9.533554839435965e-05\n",
      "Epoch 3779, Loss: 0.00011378206636436516, Final Batch Loss: 0.00010124266555067152\n",
      "Epoch 3780, Loss: 0.0001506827520643128, Final Batch Loss: 0.00012500202865339816\n",
      "Epoch 3781, Loss: 0.0007122576898836996, Final Batch Loss: 5.30626239196863e-05\n",
      "Epoch 3782, Loss: 0.00013257999080451555, Final Batch Loss: 5.916482678003376e-06\n",
      "Epoch 3783, Loss: 0.0011311783300698153, Final Batch Loss: 1.0331378689443227e-05\n",
      "Epoch 3784, Loss: 0.003361001188750379, Final Batch Loss: 0.00020245280757080764\n",
      "Epoch 3785, Loss: 6.230978851817781e-05, Final Batch Loss: 1.1210123375349212e-05\n",
      "Epoch 3786, Loss: 4.712138797913212e-05, Final Batch Loss: 1.5957490177243017e-05\n",
      "Epoch 3787, Loss: 0.0002156803966499865, Final Batch Loss: 4.628649912774563e-05\n",
      "Epoch 3788, Loss: 3.491941424726974e-05, Final Batch Loss: 1.1803347661043517e-05\n",
      "Epoch 3789, Loss: 0.011450881473137997, Final Batch Loss: 1.9247978343628347e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3790, Loss: 0.0007315946945709584, Final Batch Loss: 5.120420155435568e-06\n",
      "Epoch 3791, Loss: 0.0013496582978405058, Final Batch Loss: 0.001216393313370645\n",
      "Epoch 3792, Loss: 0.00160554054309614, Final Batch Loss: 8.327121031470597e-05\n",
      "Epoch 3793, Loss: 0.00033431247720727697, Final Batch Loss: 7.250044291140512e-05\n",
      "Epoch 3794, Loss: 7.520761118939845e-05, Final Batch Loss: 4.34682715422241e-06\n",
      "Epoch 3795, Loss: 0.0006926172063685954, Final Batch Loss: 0.000289654650259763\n",
      "Epoch 3796, Loss: 0.00016827186482260004, Final Batch Loss: 0.00010657429811544716\n",
      "Epoch 3797, Loss: 0.00020361234055599198, Final Batch Loss: 0.000117178336950019\n",
      "Epoch 3798, Loss: 0.0034541108179837465, Final Batch Loss: 0.002850290620699525\n",
      "Epoch 3799, Loss: 0.00017813062368077226, Final Batch Loss: 4.913761586067267e-05\n",
      "Epoch 3800, Loss: 0.0012257311027497053, Final Batch Loss: 0.0005637981812469661\n",
      "Epoch 3801, Loss: 0.0036128369029029272, Final Batch Loss: 0.00350602506659925\n",
      "Epoch 3802, Loss: 0.0027399720506764424, Final Batch Loss: 5.008268544770544e-06\n",
      "Epoch 3803, Loss: 0.0024365560966543853, Final Batch Loss: 0.0022018917370587587\n",
      "Epoch 3804, Loss: 0.002728384919464588, Final Batch Loss: 0.0025296357925981283\n",
      "Epoch 3805, Loss: 0.00022042928321752697, Final Batch Loss: 0.00017647042113821954\n",
      "Epoch 3806, Loss: 0.006875714931084076, Final Batch Loss: 0.0068246531300246716\n",
      "Epoch 3807, Loss: 5.6654813306522556e-05, Final Batch Loss: 4.4366108340909705e-05\n",
      "Epoch 3808, Loss: 0.0003649473947007209, Final Batch Loss: 0.0002559736021794379\n",
      "Epoch 3809, Loss: 0.002654877956956625, Final Batch Loss: 0.0011346519459038973\n",
      "Epoch 3810, Loss: 0.001471783543820493, Final Batch Loss: 0.0014468712033703923\n",
      "Epoch 3811, Loss: 4.309208452468738e-05, Final Batch Loss: 2.0173678421997465e-05\n",
      "Epoch 3812, Loss: 0.00012421108476701193, Final Batch Loss: 0.0001011291824397631\n",
      "Epoch 3813, Loss: 0.00027006070013158023, Final Batch Loss: 0.0001982773537747562\n",
      "Epoch 3814, Loss: 0.00021458693663589656, Final Batch Loss: 9.952442633220926e-05\n",
      "Epoch 3815, Loss: 4.676627759181429e-05, Final Batch Loss: 4.526436896412633e-06\n",
      "Epoch 3816, Loss: 3.478761482256232e-05, Final Batch Loss: 2.3618289560545236e-05\n",
      "Epoch 3817, Loss: 0.0008556550019420683, Final Batch Loss: 0.00044353120028972626\n",
      "Epoch 3818, Loss: 0.0005425558338174596, Final Batch Loss: 1.840067852754146e-05\n",
      "Epoch 3819, Loss: 0.0015112295377548435, Final Batch Loss: 1.5028156667540316e-05\n",
      "Epoch 3820, Loss: 0.00018327755242353305, Final Batch Loss: 0.00012827188766095787\n",
      "Epoch 3821, Loss: 3.9262245991267264e-05, Final Batch Loss: 2.5630486561567523e-05\n",
      "Epoch 3822, Loss: 0.0002965810417663306, Final Batch Loss: 7.66629382269457e-05\n",
      "Epoch 3823, Loss: 0.0004719032258435618, Final Batch Loss: 0.00043888521031476557\n",
      "Epoch 3824, Loss: 1.9909982484023203e-05, Final Batch Loss: 3.8118098473205464e-06\n",
      "Epoch 3825, Loss: 0.0026242993772029877, Final Batch Loss: 0.0008009647717699409\n",
      "Epoch 3826, Loss: 2.1255573301459663e-05, Final Batch Loss: 1.124566188082099e-05\n",
      "Epoch 3827, Loss: 0.0015322659746743739, Final Batch Loss: 0.0010458794422447681\n",
      "Epoch 3828, Loss: 0.017496205040515633, Final Batch Loss: 0.01745828241109848\n",
      "Epoch 3829, Loss: 0.0006210150586412055, Final Batch Loss: 0.0006035438273102045\n",
      "Epoch 3830, Loss: 0.0001289762367377989, Final Batch Loss: 5.1826042181346565e-05\n",
      "Epoch 3831, Loss: 0.0006009759817970917, Final Batch Loss: 0.0005588917410932481\n",
      "Epoch 3832, Loss: 0.001140816995757632, Final Batch Loss: 0.0009631616994738579\n",
      "Epoch 3833, Loss: 0.0011416312481742352, Final Batch Loss: 0.0008612569072283804\n",
      "Epoch 3834, Loss: 9.462320667807944e-05, Final Batch Loss: 3.895537156495266e-05\n",
      "Epoch 3835, Loss: 0.0002653805131558329, Final Batch Loss: 0.0001836387236835435\n",
      "Epoch 3836, Loss: 0.0001776706922100857, Final Batch Loss: 0.00010885501251323149\n",
      "Epoch 3837, Loss: 5.4089749937702436e-05, Final Batch Loss: 4.42970576841617e-06\n",
      "Epoch 3838, Loss: 0.00032497399115527514, Final Batch Loss: 2.3014183170744218e-05\n",
      "Epoch 3839, Loss: 0.00022781325606047176, Final Batch Loss: 3.285280763520859e-05\n",
      "Epoch 3840, Loss: 0.0002001359011956083, Final Batch Loss: 5.255313681118423e-06\n",
      "Epoch 3841, Loss: 0.0001367566583212465, Final Batch Loss: 7.528559217462316e-05\n",
      "Epoch 3842, Loss: 0.0006861211004434153, Final Batch Loss: 0.000662009755615145\n",
      "Epoch 3843, Loss: 0.000450417552201543, Final Batch Loss: 0.0003710445889737457\n",
      "Epoch 3844, Loss: 0.0002433165332149656, Final Batch Loss: 2.050013335974654e-06\n",
      "Epoch 3845, Loss: 0.00036760881448572036, Final Batch Loss: 0.00034779994166456163\n",
      "Epoch 3846, Loss: 0.0005159868524060585, Final Batch Loss: 0.00045131603837944567\n",
      "Epoch 3847, Loss: 0.0005479668143379968, Final Batch Loss: 0.0004965076223015785\n",
      "Epoch 3848, Loss: 0.00012127349646107177, Final Batch Loss: 4.7946482482075226e-06\n",
      "Epoch 3849, Loss: 0.0001371519683743827, Final Batch Loss: 4.081413499079645e-05\n",
      "Epoch 3850, Loss: 0.0001272847002837807, Final Batch Loss: 6.223456148291007e-05\n",
      "Epoch 3851, Loss: 4.57493824796984e-05, Final Batch Loss: 8.831850209389813e-06\n",
      "Epoch 3852, Loss: 0.0006513326770800631, Final Batch Loss: 5.108765253680758e-05\n",
      "Epoch 3853, Loss: 0.0004343637847341597, Final Batch Loss: 0.00034168516867794096\n",
      "Epoch 3854, Loss: 0.0030215106344257947, Final Batch Loss: 0.002965265419334173\n",
      "Epoch 3855, Loss: 0.00011513824210851453, Final Batch Loss: 6.095199569244869e-05\n",
      "Epoch 3856, Loss: 4.253512088325806e-05, Final Batch Loss: 3.1998690246837214e-05\n",
      "Epoch 3857, Loss: 9.108998301599058e-05, Final Batch Loss: 5.379951744544087e-06\n",
      "Epoch 3858, Loss: 9.551125003781635e-05, Final Batch Loss: 2.867522016458679e-05\n",
      "Epoch 3859, Loss: 0.00011350393288012128, Final Batch Loss: 9.417049295734614e-05\n",
      "Epoch 3860, Loss: 3.467454041583551e-05, Final Batch Loss: 1.6906855080378591e-06\n",
      "Epoch 3861, Loss: 0.0001672729003985296, Final Batch Loss: 0.0001582037948537618\n",
      "Epoch 3862, Loss: 0.00016633480481687002, Final Batch Loss: 4.9790502089308575e-05\n",
      "Epoch 3863, Loss: 0.00097921809356194, Final Batch Loss: 0.0002356823970330879\n",
      "Epoch 3864, Loss: 0.0003115992876701057, Final Batch Loss: 0.00022236754011828452\n",
      "Epoch 3865, Loss: 0.00011344303129590116, Final Batch Loss: 3.4620472433744e-05\n",
      "Epoch 3866, Loss: 4.3574642404564656e-05, Final Batch Loss: 1.5033152521937154e-05\n",
      "Epoch 3867, Loss: 9.688733916846104e-05, Final Batch Loss: 3.3454864023951814e-05\n",
      "Epoch 3868, Loss: 0.00011628556649156963, Final Batch Loss: 0.00011203979374840856\n",
      "Epoch 3869, Loss: 0.001539965785923414, Final Batch Loss: 0.001315517583861947\n",
      "Epoch 3870, Loss: 4.7705827455502003e-05, Final Batch Loss: 1.1059568350901827e-05\n",
      "Epoch 3871, Loss: 0.0006037531056790613, Final Batch Loss: 0.0004886712995357811\n",
      "Epoch 3872, Loss: 0.00017202783055836335, Final Batch Loss: 4.398042074171826e-05\n",
      "Epoch 3873, Loss: 0.00032934225600911304, Final Batch Loss: 4.439014446688816e-05\n",
      "Epoch 3874, Loss: 3.533129165589344e-05, Final Batch Loss: 1.0232432032353245e-05\n",
      "Epoch 3875, Loss: 0.016282319906167686, Final Batch Loss: 0.0005295871524140239\n",
      "Epoch 3876, Loss: 0.0014560419222107157, Final Batch Loss: 0.0013891055714339018\n",
      "Epoch 3877, Loss: 0.0010595060011837631, Final Batch Loss: 0.00033751115552149713\n",
      "Epoch 3878, Loss: 0.03910006722435355, Final Batch Loss: 0.036855753511190414\n",
      "Epoch 3879, Loss: 0.01842162781395018, Final Batch Loss: 0.003860613564029336\n",
      "Epoch 3880, Loss: 0.000900005987205077, Final Batch Loss: 3.5676937841344625e-05\n",
      "Epoch 3881, Loss: 0.0027764118058257736, Final Batch Loss: 0.002726556034758687\n",
      "Epoch 3882, Loss: 0.007766599963360932, Final Batch Loss: 4.542964597931132e-05\n",
      "Epoch 3883, Loss: 0.0347221375668596, Final Batch Loss: 0.03466929495334625\n",
      "Epoch 3884, Loss: 0.004881674511125311, Final Batch Loss: 0.00037691890611313283\n",
      "Epoch 3885, Loss: 0.00035941752867074683, Final Batch Loss: 7.046995597193018e-05\n",
      "Epoch 3886, Loss: 0.00010365936032030731, Final Batch Loss: 7.046464452287182e-05\n",
      "Epoch 3887, Loss: 0.0005381967894209083, Final Batch Loss: 5.460474858409725e-05\n",
      "Epoch 3888, Loss: 0.0014567601901944727, Final Batch Loss: 0.00045374964247457683\n",
      "Epoch 3889, Loss: 0.000326430206769146, Final Batch Loss: 5.268525274004787e-05\n",
      "Epoch 3890, Loss: 0.0022540813661180437, Final Batch Loss: 0.0015241397777572274\n",
      "Epoch 3891, Loss: 0.000649062218144536, Final Batch Loss: 0.0003099134482908994\n",
      "Epoch 3892, Loss: 0.005084245698526502, Final Batch Loss: 0.003910910338163376\n",
      "Epoch 3893, Loss: 0.01864126417785883, Final Batch Loss: 0.010375214740633965\n",
      "Epoch 3894, Loss: 0.0010596292340778746, Final Batch Loss: 0.0009476460400037467\n",
      "Epoch 3895, Loss: 0.00013094289533910342, Final Batch Loss: 1.9923671061405912e-05\n",
      "Epoch 3896, Loss: 0.0001622899144422263, Final Batch Loss: 6.084707274567336e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3897, Loss: 0.005827861779835075, Final Batch Loss: 0.005302704870700836\n",
      "Epoch 3898, Loss: 0.0013797986030112952, Final Batch Loss: 0.001248240820132196\n",
      "Epoch 3899, Loss: 0.00897256046300754, Final Batch Loss: 0.0003090868121944368\n",
      "Epoch 3900, Loss: 0.001009706553304568, Final Batch Loss: 0.00021060692961327732\n",
      "Epoch 3901, Loss: 0.0005705067815142684, Final Batch Loss: 0.0004630687471944839\n",
      "Epoch 3902, Loss: 0.0007692951839999296, Final Batch Loss: 1.9722421711776406e-05\n",
      "Epoch 3903, Loss: 0.0005460422689793631, Final Batch Loss: 0.0003222953528165817\n",
      "Epoch 3904, Loss: 0.00021120293968124315, Final Batch Loss: 9.214667079504579e-05\n",
      "Epoch 3905, Loss: 0.0001703163179627154, Final Batch Loss: 0.00016103348752949387\n",
      "Epoch 3906, Loss: 0.00033479646663181484, Final Batch Loss: 8.357129991054535e-05\n",
      "Epoch 3907, Loss: 0.0370007833771524, Final Batch Loss: 2.5451772671658546e-05\n",
      "Epoch 3908, Loss: 5.31205378138111e-05, Final Batch Loss: 1.4008907783136237e-05\n",
      "Epoch 3909, Loss: 3.195265890099108e-05, Final Batch Loss: 2.302217217220459e-05\n",
      "Epoch 3910, Loss: 0.00020505346765276045, Final Batch Loss: 0.00011210171214770526\n",
      "Epoch 3911, Loss: 0.0002786410041153431, Final Batch Loss: 7.065184763632715e-05\n",
      "Epoch 3912, Loss: 0.00028212019242346287, Final Batch Loss: 0.00010180400568060577\n",
      "Epoch 3913, Loss: 0.00016939825582085177, Final Batch Loss: 4.4224441808182746e-05\n",
      "Epoch 3914, Loss: 8.712327689863741e-05, Final Batch Loss: 4.390031608636491e-05\n",
      "Epoch 3915, Loss: 7.245388133014785e-05, Final Batch Loss: 9.627442523196805e-06\n",
      "Epoch 3916, Loss: 0.00010893247235799208, Final Batch Loss: 6.046879934729077e-05\n",
      "Epoch 3917, Loss: 0.00013284209853736684, Final Batch Loss: 4.4311607780400664e-05\n",
      "Epoch 3918, Loss: 0.0005541257851291448, Final Batch Loss: 0.00012609365512616932\n",
      "Epoch 3919, Loss: 0.0003266994499426801, Final Batch Loss: 1.7054397176252678e-05\n",
      "Epoch 3920, Loss: 0.009488034876994789, Final Batch Loss: 0.0006111067486926913\n",
      "Epoch 3921, Loss: 0.00041272028920502635, Final Batch Loss: 1.012339362205239e-05\n",
      "Epoch 3922, Loss: 0.00012854711167165078, Final Batch Loss: 9.720912203192711e-05\n",
      "Epoch 3923, Loss: 0.00010782367826323025, Final Batch Loss: 5.7372348237549886e-05\n",
      "Epoch 3924, Loss: 0.0009208590781781822, Final Batch Loss: 0.0008215631823986769\n",
      "Epoch 3925, Loss: 0.00022093124061939307, Final Batch Loss: 4.701088255387731e-05\n",
      "Epoch 3926, Loss: 0.0004115645424462855, Final Batch Loss: 0.00034352403599768877\n",
      "Epoch 3927, Loss: 2.9478414944605902e-05, Final Batch Loss: 1.3236867744126357e-05\n",
      "Epoch 3928, Loss: 0.00011443992593740404, Final Batch Loss: 2.5729652861627983e-06\n",
      "Epoch 3929, Loss: 0.0018032173975370824, Final Batch Loss: 0.0007775879348628223\n",
      "Epoch 3930, Loss: 0.0017610426584724337, Final Batch Loss: 0.0003079698944929987\n",
      "Epoch 3931, Loss: 0.00013583112740889192, Final Batch Loss: 3.355365333845839e-05\n",
      "Epoch 3932, Loss: 3.9274655136978254e-05, Final Batch Loss: 3.656253466033377e-05\n",
      "Epoch 3933, Loss: 0.00020524210049188696, Final Batch Loss: 0.00017041967657860368\n",
      "Epoch 3934, Loss: 0.009687355312053114, Final Batch Loss: 0.009499814361333847\n",
      "Epoch 3935, Loss: 0.00010179841774515808, Final Batch Loss: 5.91656134929508e-05\n",
      "Epoch 3936, Loss: 6.987755841691978e-05, Final Batch Loss: 2.746448080870323e-05\n",
      "Epoch 3937, Loss: 5.176149352337234e-05, Final Batch Loss: 2.312469769094605e-05\n",
      "Epoch 3938, Loss: 0.01189587921180646, Final Batch Loss: 2.1723139070672914e-05\n",
      "Epoch 3939, Loss: 0.0016374343686038628, Final Batch Loss: 0.00020958193636033684\n",
      "Epoch 3940, Loss: 0.00047228700714185834, Final Batch Loss: 0.00018848679610528052\n",
      "Epoch 3941, Loss: 0.001526454696431756, Final Batch Loss: 0.0007479243795387447\n",
      "Epoch 3942, Loss: 0.00017240389570361003, Final Batch Loss: 7.940870273159817e-05\n",
      "Epoch 3943, Loss: 0.001093749058782123, Final Batch Loss: 0.0009000495774671435\n",
      "Epoch 3944, Loss: 0.011950798245379701, Final Batch Loss: 0.0004482855147216469\n",
      "Epoch 3945, Loss: 0.0019383699691388756, Final Batch Loss: 6.709728040732443e-05\n",
      "Epoch 3946, Loss: 0.00061301703681238, Final Batch Loss: 0.0003729021700564772\n",
      "Epoch 3947, Loss: 0.0001711370496195741, Final Batch Loss: 0.00010696082608774304\n",
      "Epoch 3948, Loss: 0.0008631910641270224, Final Batch Loss: 0.0008106183377094567\n",
      "Epoch 3949, Loss: 0.00017521486734040082, Final Batch Loss: 0.00015454752428922802\n",
      "Epoch 3950, Loss: 0.0001116680541599635, Final Batch Loss: 7.969289436005056e-05\n",
      "Epoch 3951, Loss: 0.0011685143108479679, Final Batch Loss: 0.0005616944399662316\n",
      "Epoch 3952, Loss: 0.00010112034942721948, Final Batch Loss: 3.834177186945453e-05\n",
      "Epoch 3953, Loss: 0.0001336992900178302, Final Batch Loss: 8.314825390698388e-05\n",
      "Epoch 3954, Loss: 6.569627521457733e-05, Final Batch Loss: 7.223936790978769e-06\n",
      "Epoch 3955, Loss: 0.00029848087069694884, Final Batch Loss: 9.69328175415285e-06\n",
      "Epoch 3956, Loss: 0.0001248687258339487, Final Batch Loss: 0.00010499218478798866\n",
      "Epoch 3957, Loss: 0.00022503224681713618, Final Batch Loss: 0.0001796476572053507\n",
      "Epoch 3958, Loss: 8.243888987635728e-05, Final Batch Loss: 5.689193494617939e-05\n",
      "Epoch 3959, Loss: 0.0003181376523571089, Final Batch Loss: 1.1625365004874766e-05\n",
      "Epoch 3960, Loss: 0.0014363157279149164, Final Batch Loss: 3.643021409516223e-05\n",
      "Epoch 3961, Loss: 0.000188015812454978, Final Batch Loss: 5.952432184130885e-05\n",
      "Epoch 3962, Loss: 0.0006538231682498008, Final Batch Loss: 0.00044313387479633093\n",
      "Epoch 3963, Loss: 6.960938480915502e-05, Final Batch Loss: 2.852635589079e-05\n",
      "Epoch 3964, Loss: 0.001357988832751289, Final Batch Loss: 0.0009620110504329205\n",
      "Epoch 3965, Loss: 0.0006824848605901934, Final Batch Loss: 0.0006022605230100453\n",
      "Epoch 3966, Loss: 0.0011357499870428, Final Batch Loss: 1.4877307876304258e-05\n",
      "Epoch 3967, Loss: 0.0007107716392056318, Final Batch Loss: 2.9212316803750582e-05\n",
      "Epoch 3968, Loss: 0.0013054047376499511, Final Batch Loss: 0.0012203716905787587\n",
      "Epoch 3969, Loss: 0.0006974392399570206, Final Batch Loss: 0.0006770980544388294\n",
      "Epoch 3970, Loss: 0.00015633838120265864, Final Batch Loss: 3.3508327760500833e-05\n",
      "Epoch 3971, Loss: 0.000798285094788298, Final Batch Loss: 0.0001028043043334037\n",
      "Epoch 3972, Loss: 0.000141737222293159, Final Batch Loss: 9.098568261833861e-05\n",
      "Epoch 3973, Loss: 0.0005599137584795244, Final Batch Loss: 1.3509656128007919e-05\n",
      "Epoch 3974, Loss: 0.0004024860227218596, Final Batch Loss: 2.3003942260402255e-05\n",
      "Epoch 3975, Loss: 9.261863669962622e-05, Final Batch Loss: 5.840615267516114e-05\n",
      "Epoch 3976, Loss: 0.0005693075063391007, Final Batch Loss: 1.5000840903667267e-05\n",
      "Epoch 3977, Loss: 0.0002865886544896057, Final Batch Loss: 1.6426294678240083e-05\n",
      "Epoch 3978, Loss: 0.00025847046345006675, Final Batch Loss: 6.697926437482238e-05\n",
      "Epoch 3979, Loss: 0.00029195016031735577, Final Batch Loss: 0.0002416457427898422\n",
      "Epoch 3980, Loss: 0.0002646054945216747, Final Batch Loss: 2.0954048522980884e-06\n",
      "Epoch 3981, Loss: 0.009914840426063165, Final Batch Loss: 0.0003616016765590757\n",
      "Epoch 3982, Loss: 0.013731593986449298, Final Batch Loss: 0.013664782047271729\n",
      "Epoch 3983, Loss: 0.0003113864950137213, Final Batch Loss: 1.952248567249626e-05\n",
      "Epoch 3984, Loss: 0.0020748447568621486, Final Batch Loss: 0.001713283360004425\n",
      "Epoch 3985, Loss: 0.0004951995069859549, Final Batch Loss: 0.0002633718540892005\n",
      "Epoch 3986, Loss: 0.0011187807831447572, Final Batch Loss: 0.0004583944974001497\n",
      "Epoch 3987, Loss: 0.00037205345142865553, Final Batch Loss: 8.694365533301607e-05\n",
      "Epoch 3988, Loss: 0.0002695924649742665, Final Batch Loss: 2.1222384020802565e-05\n",
      "Epoch 3989, Loss: 0.0006191615539137274, Final Batch Loss: 0.00015629007248207927\n",
      "Epoch 3990, Loss: 0.0018399837108518113, Final Batch Loss: 6.078477781557012e-06\n",
      "Epoch 3991, Loss: 0.00022373950923793018, Final Batch Loss: 8.444799459539354e-05\n",
      "Epoch 3992, Loss: 0.0023895937047200277, Final Batch Loss: 0.0023242768365889788\n",
      "Epoch 3993, Loss: 3.903953438566532e-05, Final Batch Loss: 1.98964771698229e-05\n",
      "Epoch 3994, Loss: 0.0048547122751188, Final Batch Loss: 3.805999949690886e-05\n",
      "Epoch 3995, Loss: 0.0005814864925923757, Final Batch Loss: 9.807958122109994e-05\n",
      "Epoch 3996, Loss: 0.0007134358202165458, Final Batch Loss: 0.0006825643358752131\n",
      "Epoch 3997, Loss: 0.0001669414086791221, Final Batch Loss: 0.0001059231799445115\n",
      "Epoch 3998, Loss: 0.0014289569980974193, Final Batch Loss: 0.0014151810901239514\n",
      "Epoch 3999, Loss: 0.00026579309633234516, Final Batch Loss: 0.00020167358161415905\n",
      "Epoch 4000, Loss: 0.000736953312298283, Final Batch Loss: 0.0003082089242525399\n",
      "Epoch 4001, Loss: 0.0009787785493244883, Final Batch Loss: 1.3060835044598207e-05\n",
      "Epoch 4002, Loss: 0.0014070285542402416, Final Batch Loss: 0.0012900915462523699\n",
      "Epoch 4003, Loss: 0.003222988569177687, Final Batch Loss: 0.0011079713003709912\n",
      "Epoch 4004, Loss: 0.00028750781348207965, Final Batch Loss: 1.642492861719802e-05\n",
      "Epoch 4005, Loss: 8.698385863681324e-05, Final Batch Loss: 5.637057256535627e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4006, Loss: 0.0010479889169801027, Final Batch Loss: 2.728463732637465e-05\n",
      "Epoch 4007, Loss: 5.710302139050327e-05, Final Batch Loss: 3.9888996980153024e-05\n",
      "Epoch 4008, Loss: 0.0003908606777258683, Final Batch Loss: 4.645985973183997e-05\n",
      "Epoch 4009, Loss: 2.4936039267231536e-05, Final Batch Loss: 1.233368607245211e-06\n",
      "Epoch 4010, Loss: 0.00020625272009056062, Final Batch Loss: 5.5583936045877635e-05\n",
      "Epoch 4011, Loss: 0.00015457052541023586, Final Batch Loss: 0.00014759124314878136\n",
      "Epoch 4012, Loss: 0.0003096105356235057, Final Batch Loss: 0.00017117185052484274\n",
      "Epoch 4013, Loss: 0.012872572522610426, Final Batch Loss: 0.005175685975700617\n",
      "Epoch 4014, Loss: 6.685187872790266e-05, Final Batch Loss: 4.328070644987747e-05\n",
      "Epoch 4015, Loss: 9.527543443255126e-05, Final Batch Loss: 2.497356035746634e-05\n",
      "Epoch 4016, Loss: 9.037841118697543e-05, Final Batch Loss: 1.2507809515227564e-05\n",
      "Epoch 4017, Loss: 0.00017723298515193164, Final Batch Loss: 4.567575524561107e-05\n",
      "Epoch 4018, Loss: 0.0014343928851303644, Final Batch Loss: 0.001388467033393681\n",
      "Epoch 4019, Loss: 0.00015136480215005577, Final Batch Loss: 2.0831168512813747e-05\n",
      "Epoch 4020, Loss: 0.00018460414139553905, Final Batch Loss: 3.155767626594752e-05\n",
      "Epoch 4021, Loss: 8.308768519782461e-05, Final Batch Loss: 4.4044438254786655e-05\n",
      "Epoch 4022, Loss: 5.539322410186287e-05, Final Batch Loss: 3.3712582080625e-05\n",
      "Epoch 4023, Loss: 0.00017497818953415845, Final Batch Loss: 2.9457843993441202e-05\n",
      "Epoch 4024, Loss: 0.00026101572075276636, Final Batch Loss: 5.3412073611980304e-05\n",
      "Epoch 4025, Loss: 0.00014004077456775121, Final Batch Loss: 4.841840927838348e-05\n",
      "Epoch 4026, Loss: 3.0070956199779175e-05, Final Batch Loss: 1.9855116988765076e-05\n",
      "Epoch 4027, Loss: 0.00016010979743441567, Final Batch Loss: 6.381218554452062e-05\n",
      "Epoch 4028, Loss: 0.0006795196277380455, Final Batch Loss: 0.0006282331305555999\n",
      "Epoch 4029, Loss: 0.0003895012450811919, Final Batch Loss: 0.0003644654934760183\n",
      "Epoch 4030, Loss: 0.0001573823483340675, Final Batch Loss: 0.00014167296467348933\n",
      "Epoch 4031, Loss: 0.0001528885513835121, Final Batch Loss: 0.00011074971553171054\n",
      "Epoch 4032, Loss: 0.00011041660400223918, Final Batch Loss: 2.7043995942221954e-05\n",
      "Epoch 4033, Loss: 0.00022741809152648784, Final Batch Loss: 4.716324110631831e-05\n",
      "Epoch 4034, Loss: 0.0003108638666162733, Final Batch Loss: 0.0002874824858736247\n",
      "Epoch 4035, Loss: 0.00022792206254962366, Final Batch Loss: 2.264106115035247e-05\n",
      "Epoch 4036, Loss: 0.00011746983545890544, Final Batch Loss: 9.688114369055256e-05\n",
      "Epoch 4037, Loss: 7.221102350740694e-05, Final Batch Loss: 4.685362728196196e-05\n",
      "Epoch 4038, Loss: 0.0004615585548890522, Final Batch Loss: 1.4953204299672507e-05\n",
      "Epoch 4039, Loss: 5.905674788664328e-05, Final Batch Loss: 5.055090514360927e-05\n",
      "Epoch 4040, Loss: 0.0008449071428913157, Final Batch Loss: 0.0008095697266981006\n",
      "Epoch 4041, Loss: 7.188282688730396e-05, Final Batch Loss: 3.4066564694512635e-05\n",
      "Epoch 4042, Loss: 0.00021759044466307387, Final Batch Loss: 8.110056660370901e-05\n",
      "Epoch 4043, Loss: 0.000555344366148347, Final Batch Loss: 0.0005231746472418308\n",
      "Epoch 4044, Loss: 0.0003525488937157206, Final Batch Loss: 0.0002461711410433054\n",
      "Epoch 4045, Loss: 0.000345582899171859, Final Batch Loss: 0.00011039407399948686\n",
      "Epoch 4046, Loss: 0.0005704701907234266, Final Batch Loss: 0.00047266980982385576\n",
      "Epoch 4047, Loss: 4.4219650590093806e-05, Final Batch Loss: 3.0642535421065986e-05\n",
      "Epoch 4048, Loss: 0.0010439723264425993, Final Batch Loss: 0.0005090725608170033\n",
      "Epoch 4049, Loss: 0.0001551084642414935, Final Batch Loss: 9.374685760121793e-05\n",
      "Epoch 4050, Loss: 0.0027429835172370076, Final Batch Loss: 0.00042645155917853117\n",
      "Epoch 4051, Loss: 0.0002352528608753346, Final Batch Loss: 9.488841897109523e-05\n",
      "Epoch 4052, Loss: 6.905464215378743e-05, Final Batch Loss: 4.506579352892004e-05\n",
      "Epoch 4053, Loss: 0.0006030735821695998, Final Batch Loss: 0.0005620772135443985\n",
      "Epoch 4054, Loss: 4.564455957734026e-05, Final Batch Loss: 1.4869143342366442e-05\n",
      "Epoch 4055, Loss: 3.581596092772088e-05, Final Batch Loss: 2.9682114472961985e-05\n",
      "Epoch 4056, Loss: 0.0010948940467301327, Final Batch Loss: 8.725615430194011e-07\n",
      "Epoch 4057, Loss: 0.0004782291944138706, Final Batch Loss: 0.00037478964077308774\n",
      "Epoch 4058, Loss: 5.8067193094757386e-05, Final Batch Loss: 2.5622406610636972e-05\n",
      "Epoch 4059, Loss: 0.00044977787183597684, Final Batch Loss: 0.0003693561884574592\n",
      "Epoch 4060, Loss: 0.00022454171448771376, Final Batch Loss: 0.00021648642723448575\n",
      "Epoch 4061, Loss: 0.0006454706635850016, Final Batch Loss: 3.568057218217291e-05\n",
      "Epoch 4062, Loss: 0.0014541706532327225, Final Batch Loss: 2.7434294679551385e-05\n",
      "Epoch 4063, Loss: 0.00024577185104135424, Final Batch Loss: 5.59469626750797e-05\n",
      "Epoch 4064, Loss: 0.00024122923423419707, Final Batch Loss: 0.00020987988682463765\n",
      "Epoch 4065, Loss: 8.774180059845094e-05, Final Batch Loss: 2.5196570277330466e-05\n",
      "Epoch 4066, Loss: 0.006077256224671146, Final Batch Loss: 4.854908547713421e-05\n",
      "Epoch 4067, Loss: 0.001270994580409024, Final Batch Loss: 0.0011648297077044845\n",
      "Epoch 4068, Loss: 0.0005824162799399346, Final Batch Loss: 0.0003850261273328215\n",
      "Epoch 4069, Loss: 0.006153095528134145, Final Batch Loss: 0.0059195938520133495\n",
      "Epoch 4070, Loss: 0.0007945798206492327, Final Batch Loss: 0.0007001766934990883\n",
      "Epoch 4071, Loss: 6.289336317877314e-05, Final Batch Loss: 6.187819963088259e-05\n",
      "Epoch 4072, Loss: 0.00025924661440512864, Final Batch Loss: 0.00024606226361356676\n",
      "Epoch 4073, Loss: 0.0021351152972783893, Final Batch Loss: 0.0016479188343510032\n",
      "Epoch 4074, Loss: 7.708011844442808e-05, Final Batch Loss: 4.2241067603754345e-06\n",
      "Epoch 4075, Loss: 0.0034564636880531907, Final Batch Loss: 0.0005556218093261123\n",
      "Epoch 4076, Loss: 8.821018491289578e-05, Final Batch Loss: 2.2330747015075758e-05\n",
      "Epoch 4077, Loss: 1.5657864196327864e-05, Final Batch Loss: 2.1900966657995014e-06\n",
      "Epoch 4078, Loss: 3.9343041862593964e-05, Final Batch Loss: 6.376089004334062e-06\n",
      "Epoch 4079, Loss: 9.413870066055097e-05, Final Batch Loss: 5.606738704955205e-05\n",
      "Epoch 4080, Loss: 0.00012354173668427393, Final Batch Loss: 5.7856246712617576e-05\n",
      "Epoch 4081, Loss: 0.0005028585628679139, Final Batch Loss: 1.0646840564731974e-05\n",
      "Epoch 4082, Loss: 0.04114408544410253, Final Batch Loss: 0.0410907045006752\n",
      "Epoch 4083, Loss: 6.192576256580651e-05, Final Batch Loss: 1.951448939507827e-05\n",
      "Epoch 4084, Loss: 0.000806989090051502, Final Batch Loss: 0.0006328655290417373\n",
      "Epoch 4085, Loss: 8.803286527836462e-05, Final Batch Loss: 7.584644481539726e-05\n",
      "Epoch 4086, Loss: 0.0007747438357910141, Final Batch Loss: 0.00015628365508746356\n",
      "Epoch 4087, Loss: 0.00016830397362355143, Final Batch Loss: 7.873016875237226e-05\n",
      "Epoch 4088, Loss: 0.0002186294732382521, Final Batch Loss: 4.934842581860721e-05\n",
      "Epoch 4089, Loss: 5.0980388550669886e-05, Final Batch Loss: 1.751720810716506e-05\n",
      "Epoch 4090, Loss: 0.019400852965191007, Final Batch Loss: 0.017460394650697708\n",
      "Epoch 4091, Loss: 0.0068195293461030815, Final Batch Loss: 0.006784449331462383\n",
      "Epoch 4092, Loss: 0.0005068194368504919, Final Batch Loss: 0.00011763236398110166\n",
      "Epoch 4093, Loss: 0.00030507480369124096, Final Batch Loss: 2.4954131731647067e-05\n",
      "Epoch 4094, Loss: 0.003286976214440074, Final Batch Loss: 0.00317061017267406\n",
      "Epoch 4095, Loss: 0.00018664733943296596, Final Batch Loss: 4.625540896086022e-05\n",
      "Epoch 4096, Loss: 0.005412617756519467, Final Batch Loss: 0.005341778974980116\n",
      "Epoch 4097, Loss: 0.0016665232160448795, Final Batch Loss: 1.9438497474766336e-05\n",
      "Epoch 4098, Loss: 0.000620887236436829, Final Batch Loss: 8.987539331428707e-05\n",
      "Epoch 4099, Loss: 0.0004247653851052746, Final Batch Loss: 0.0003090472600888461\n",
      "Epoch 4100, Loss: 0.0009240852486982476, Final Batch Loss: 5.018470619688742e-05\n",
      "Epoch 4101, Loss: 0.0008319383778143674, Final Batch Loss: 0.0004442205827217549\n",
      "Epoch 4102, Loss: 0.00012744038758683018, Final Batch Loss: 5.387910277931951e-05\n",
      "Epoch 4103, Loss: 0.0002465349662088556, Final Batch Loss: 1.6319025235134177e-05\n",
      "Epoch 4104, Loss: 0.0009790087497094646, Final Batch Loss: 0.0008798122289590538\n",
      "Epoch 4105, Loss: 5.644564953399822e-05, Final Batch Loss: 2.2699729015585035e-05\n",
      "Epoch 4106, Loss: 0.0004540957675089885, Final Batch Loss: 6.198119535838487e-06\n",
      "Epoch 4107, Loss: 0.00019470932966214605, Final Batch Loss: 4.934841490467079e-05\n",
      "Epoch 4108, Loss: 0.0008616237082605949, Final Batch Loss: 0.0008337061735801399\n",
      "Epoch 4109, Loss: 0.00026823070948012173, Final Batch Loss: 0.00013929330452810973\n",
      "Epoch 4110, Loss: 2.811763624777086e-05, Final Batch Loss: 1.2128577509429306e-05\n",
      "Epoch 4111, Loss: 9.657781993155368e-05, Final Batch Loss: 3.133147765765898e-05\n",
      "Epoch 4112, Loss: 0.0004382777988212183, Final Batch Loss: 0.00036921986611559987\n",
      "Epoch 4113, Loss: 0.0024190999974962324, Final Batch Loss: 0.0022999413777142763\n",
      "Epoch 4114, Loss: 0.0005279736506054178, Final Batch Loss: 0.00023943728592712432\n",
      "Epoch 4115, Loss: 0.0001552074681967497, Final Batch Loss: 4.182152770226821e-05\n",
      "Epoch 4116, Loss: 0.00036506971082417294, Final Batch Loss: 7.48279198887758e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4117, Loss: 0.0002913932552246479, Final Batch Loss: 8.085047511485755e-07\n",
      "Epoch 4118, Loss: 0.0003333957210998051, Final Batch Loss: 0.00010359360749134794\n",
      "Epoch 4119, Loss: 0.000233222244787612, Final Batch Loss: 0.0002079190016957\n",
      "Epoch 4120, Loss: 0.0006698443321511149, Final Batch Loss: 0.0002655776042956859\n",
      "Epoch 4121, Loss: 5.40025730515481e-05, Final Batch Loss: 4.571388853946701e-05\n",
      "Epoch 4122, Loss: 0.00020130570555920713, Final Batch Loss: 5.5780616094125435e-05\n",
      "Epoch 4123, Loss: 0.00024095392291201279, Final Batch Loss: 3.519038000376895e-05\n",
      "Epoch 4124, Loss: 0.0017559362458996475, Final Batch Loss: 0.0011949825566262007\n",
      "Epoch 4125, Loss: 0.0178412273307913, Final Batch Loss: 0.01774320751428604\n",
      "Epoch 4126, Loss: 1.4119348634267226e-05, Final Batch Loss: 1.0250940249534324e-05\n",
      "Epoch 4127, Loss: 0.00014038355675438652, Final Batch Loss: 0.00013226135342847556\n",
      "Epoch 4128, Loss: 0.00045510527706937864, Final Batch Loss: 9.136199514614418e-05\n",
      "Epoch 4129, Loss: 5.934734144830145e-05, Final Batch Loss: 2.3719010641798377e-05\n",
      "Epoch 4130, Loss: 0.00021277404084685259, Final Batch Loss: 3.650670623756014e-05\n",
      "Epoch 4131, Loss: 0.00017574109369888902, Final Batch Loss: 7.691238715779036e-05\n",
      "Epoch 4132, Loss: 0.000969784070548485, Final Batch Loss: 1.916425935633015e-05\n",
      "Epoch 4133, Loss: 0.0005963568546576425, Final Batch Loss: 0.00048819786752574146\n",
      "Epoch 4134, Loss: 0.012702348234597594, Final Batch Loss: 0.012605557218194008\n",
      "Epoch 4135, Loss: 0.00030344179685926065, Final Batch Loss: 7.356411515502259e-05\n",
      "Epoch 4136, Loss: 0.0008645584748592228, Final Batch Loss: 0.000630928436294198\n",
      "Epoch 4137, Loss: 0.006891288536280626, Final Batch Loss: 0.006858077831566334\n",
      "Epoch 4138, Loss: 0.0003016254195244983, Final Batch Loss: 0.00016525667160749435\n",
      "Epoch 4139, Loss: 0.0001443380897399038, Final Batch Loss: 7.462571375072002e-05\n",
      "Epoch 4140, Loss: 0.0001410615641361801, Final Batch Loss: 2.053309253824409e-05\n",
      "Epoch 4141, Loss: 0.0003942165531043429, Final Batch Loss: 5.259011595626362e-05\n",
      "Epoch 4142, Loss: 5.547388536797371e-05, Final Batch Loss: 3.517163349897601e-05\n",
      "Epoch 4143, Loss: 0.0141522838275705, Final Batch Loss: 0.01409479882568121\n",
      "Epoch 4144, Loss: 0.0006195659807417542, Final Batch Loss: 0.0005776617326773703\n",
      "Epoch 4145, Loss: 0.0014974664445617236, Final Batch Loss: 0.0014461196260526776\n",
      "Epoch 4146, Loss: 0.0003452058517723344, Final Batch Loss: 0.00025206225109286606\n",
      "Epoch 4147, Loss: 0.0003688362776301801, Final Batch Loss: 0.00022357846319209784\n",
      "Epoch 4148, Loss: 0.0004607279770425521, Final Batch Loss: 0.00012181459896964952\n",
      "Epoch 4149, Loss: 0.0004240220150677487, Final Batch Loss: 0.00015311753668356687\n",
      "Epoch 4150, Loss: 0.0005988904740661383, Final Batch Loss: 0.00035927107091993093\n",
      "Epoch 4151, Loss: 0.0007306197949219495, Final Batch Loss: 0.000599391758441925\n",
      "Epoch 4152, Loss: 0.006860410510853399, Final Batch Loss: 0.00680982181802392\n",
      "Epoch 4153, Loss: 0.0006548185483552516, Final Batch Loss: 0.00011012470349669456\n",
      "Epoch 4154, Loss: 0.0011607924170675687, Final Batch Loss: 0.0010603710543364286\n",
      "Epoch 4155, Loss: 0.0001634036780160386, Final Batch Loss: 5.75492849748116e-05\n",
      "Epoch 4156, Loss: 4.35408064731746e-05, Final Batch Loss: 3.139362524962053e-05\n",
      "Epoch 4157, Loss: 0.0008113859803415835, Final Batch Loss: 0.0006371906492859125\n",
      "Epoch 4158, Loss: 0.00044171402987558395, Final Batch Loss: 0.00028368784114718437\n",
      "Epoch 4159, Loss: 0.0010272063373122364, Final Batch Loss: 0.00028016287251375616\n",
      "Epoch 4160, Loss: 0.0004178911131020868, Final Batch Loss: 0.00039869145257398486\n",
      "Epoch 4161, Loss: 1.4972710687288782e-05, Final Batch Loss: 8.22685342427576e-06\n",
      "Epoch 4162, Loss: 0.0019326759938849136, Final Batch Loss: 0.001788185560144484\n",
      "Epoch 4163, Loss: 0.00037659834288206184, Final Batch Loss: 1.437765695300186e-05\n",
      "Epoch 4164, Loss: 0.000474014117344268, Final Batch Loss: 2.388145503573469e-06\n",
      "Epoch 4165, Loss: 0.0006090914093874744, Final Batch Loss: 0.0006003631860949099\n",
      "Epoch 4166, Loss: 3.881498378177639e-05, Final Batch Loss: 2.220876376668457e-05\n",
      "Epoch 4167, Loss: 0.0008023142736419686, Final Batch Loss: 1.1793411431426648e-05\n",
      "Epoch 4168, Loss: 0.00020036721252836287, Final Batch Loss: 9.927318023983389e-05\n",
      "Epoch 4169, Loss: 0.0005682985138264485, Final Batch Loss: 0.0004983608960174024\n",
      "Epoch 4170, Loss: 0.0014139535705908202, Final Batch Loss: 0.0001028990009217523\n",
      "Epoch 4171, Loss: 0.00027613112820290553, Final Batch Loss: 0.0002740517084021121\n",
      "Epoch 4172, Loss: 6.983151070016902e-05, Final Batch Loss: 2.2972957594902255e-05\n",
      "Epoch 4173, Loss: 3.923894746549195e-05, Final Batch Loss: 4.860473381995689e-06\n",
      "Epoch 4174, Loss: 0.015870788523898227, Final Batch Loss: 1.954978142748587e-05\n",
      "Epoch 4175, Loss: 0.16969709519617027, Final Batch Loss: 8.617762796347961e-05\n",
      "Epoch 4176, Loss: 0.00024672094878042117, Final Batch Loss: 0.00014007536810822785\n",
      "Epoch 4177, Loss: 0.06049246480688453, Final Batch Loss: 0.000532583799213171\n",
      "Epoch 4178, Loss: 0.0028137145254731877, Final Batch Loss: 0.0027906852774322033\n",
      "Epoch 4179, Loss: 0.00317813761648722, Final Batch Loss: 0.003119691740721464\n",
      "Epoch 4180, Loss: 0.0009772035336936824, Final Batch Loss: 0.0009035288821905851\n",
      "Epoch 4181, Loss: 0.0003662561957753496, Final Batch Loss: 1.587605402164627e-05\n",
      "Epoch 4182, Loss: 0.0035018098569707945, Final Batch Loss: 0.00011768723197747022\n",
      "Epoch 4183, Loss: 9.448527271160856e-05, Final Batch Loss: 4.822270784643479e-05\n",
      "Epoch 4184, Loss: 5.107119068270549e-05, Final Batch Loss: 4.044077650178224e-05\n",
      "Epoch 4185, Loss: 0.001737141159537714, Final Batch Loss: 4.9379530537407845e-05\n",
      "Epoch 4186, Loss: 0.00651789378025569, Final Batch Loss: 0.006333677098155022\n",
      "Epoch 4187, Loss: 0.03407142937066965, Final Batch Loss: 0.0001318666327279061\n",
      "Epoch 4188, Loss: 0.0005650595194310881, Final Batch Loss: 8.073863136814907e-05\n",
      "Epoch 4189, Loss: 0.004832816703128628, Final Batch Loss: 0.004732170142233372\n",
      "Epoch 4190, Loss: 0.0025366174522787333, Final Batch Loss: 0.0014454323099926114\n",
      "Epoch 4191, Loss: 0.007322259261854924, Final Batch Loss: 0.007132277358323336\n",
      "Epoch 4192, Loss: 0.00056767119167489, Final Batch Loss: 1.7185218894155696e-05\n",
      "Epoch 4193, Loss: 0.00015623544459231198, Final Batch Loss: 7.898105104686692e-05\n",
      "Epoch 4194, Loss: 0.000784206495154649, Final Batch Loss: 0.00048489021719433367\n",
      "Epoch 4195, Loss: 0.000658144177577924, Final Batch Loss: 8.482624980388209e-05\n",
      "Epoch 4196, Loss: 0.00012426315151969902, Final Batch Loss: 4.0267430449603125e-05\n",
      "Epoch 4197, Loss: 0.0001143987992691109, Final Batch Loss: 9.193710138788447e-05\n",
      "Epoch 4198, Loss: 0.00022654838357993867, Final Batch Loss: 0.00020566914463415742\n",
      "Epoch 4199, Loss: 0.0019688681786647066, Final Batch Loss: 0.000171353793120943\n",
      "Epoch 4200, Loss: 0.0005072609783383086, Final Batch Loss: 3.33009083988145e-05\n",
      "Epoch 4201, Loss: 0.0002685786093934439, Final Batch Loss: 8.200202864827588e-05\n",
      "Epoch 4202, Loss: 0.002117641532095149, Final Batch Loss: 0.00037537157186307013\n",
      "Epoch 4203, Loss: 0.000366591673810035, Final Batch Loss: 0.00025053086574189365\n",
      "Epoch 4204, Loss: 0.0003463925822870806, Final Batch Loss: 8.067853923421353e-05\n",
      "Epoch 4205, Loss: 0.001031297113513574, Final Batch Loss: 0.0007140066009014845\n",
      "Epoch 4206, Loss: 0.0014103402354521677, Final Batch Loss: 0.00016367218631785363\n",
      "Epoch 4207, Loss: 0.0008523164287908003, Final Batch Loss: 0.0001440562045900151\n",
      "Epoch 4208, Loss: 0.0015179324368546077, Final Batch Loss: 7.526756689912872e-06\n",
      "Epoch 4209, Loss: 0.00881958706304431, Final Batch Loss: 0.0011718850582838058\n",
      "Epoch 4210, Loss: 0.00026501851789362263, Final Batch Loss: 0.00024120192392729223\n",
      "Epoch 4211, Loss: 0.0003727910007000901, Final Batch Loss: 7.588472362840548e-05\n",
      "Epoch 4212, Loss: 0.0020816121377720265, Final Batch Loss: 2.002694054681342e-05\n",
      "Epoch 4213, Loss: 0.0006170844862936065, Final Batch Loss: 0.00021101035235915333\n",
      "Epoch 4214, Loss: 0.007108380974386819, Final Batch Loss: 0.0070339529775083065\n",
      "Epoch 4215, Loss: 0.00155567548063118, Final Batch Loss: 0.00020154118828941137\n",
      "Epoch 4216, Loss: 0.0007476738828700036, Final Batch Loss: 0.0002802348753903061\n",
      "Epoch 4217, Loss: 0.03554183285450563, Final Batch Loss: 0.03535696864128113\n",
      "Epoch 4218, Loss: 0.005396694476075936, Final Batch Loss: 0.005326207727193832\n",
      "Epoch 4219, Loss: 0.0005985486786812544, Final Batch Loss: 0.00029688264476135373\n",
      "Epoch 4220, Loss: 0.013662719036801718, Final Batch Loss: 0.01359805092215538\n",
      "Epoch 4221, Loss: 0.00038375446092686616, Final Batch Loss: 5.677726221620105e-05\n",
      "Epoch 4222, Loss: 0.00380073797168734, Final Batch Loss: 0.003780159866437316\n",
      "Epoch 4223, Loss: 0.0001859609219536651, Final Batch Loss: 3.592283246689476e-05\n",
      "Epoch 4224, Loss: 0.00034922354825539514, Final Batch Loss: 0.000279224623227492\n",
      "Epoch 4225, Loss: 0.00036949240165995434, Final Batch Loss: 0.0002638890000525862\n",
      "Epoch 4226, Loss: 0.0008775672940828372, Final Batch Loss: 4.750154403154738e-05\n",
      "Epoch 4227, Loss: 0.0018946319323731586, Final Batch Loss: 0.0018084975890815258\n",
      "Epoch 4228, Loss: 0.0001423298381268978, Final Batch Loss: 0.00010563133400864899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4229, Loss: 0.0025554949170327745, Final Batch Loss: 0.0024413049686700106\n",
      "Epoch 4230, Loss: 0.0001797947261366062, Final Batch Loss: 6.508060323540121e-05\n",
      "Epoch 4231, Loss: 0.0008690789400134236, Final Batch Loss: 0.0003279868687968701\n",
      "Epoch 4232, Loss: 0.0014560840791091323, Final Batch Loss: 0.0013762058224529028\n",
      "Epoch 4233, Loss: 0.00014841631400486222, Final Batch Loss: 1.3927455256634858e-05\n",
      "Epoch 4234, Loss: 0.0016054176157922484, Final Batch Loss: 3.866435872623697e-05\n",
      "Epoch 4235, Loss: 0.0007664503937121481, Final Batch Loss: 0.0005771897849626839\n",
      "Epoch 4236, Loss: 0.00028379282957757823, Final Batch Loss: 0.0002520530833862722\n",
      "Epoch 4237, Loss: 0.0016452340933028609, Final Batch Loss: 0.0013464309740811586\n",
      "Epoch 4238, Loss: 0.0035643617156893015, Final Batch Loss: 0.0005597246345132589\n",
      "Epoch 4239, Loss: 0.0002689587745408062, Final Batch Loss: 4.1100520320469514e-05\n",
      "Epoch 4240, Loss: 0.0007448795113305096, Final Batch Loss: 0.0006949621019884944\n",
      "Epoch 4241, Loss: 0.0002090099369524978, Final Batch Loss: 0.00012306933058425784\n",
      "Epoch 4242, Loss: 0.0002595829500933178, Final Batch Loss: 0.00010545049008214846\n",
      "Epoch 4243, Loss: 0.003019781521288678, Final Batch Loss: 0.0028289365582168102\n",
      "Epoch 4244, Loss: 0.008158731216099113, Final Batch Loss: 7.543334504589438e-05\n",
      "Epoch 4245, Loss: 0.0002335316239623353, Final Batch Loss: 0.00016595526540186256\n",
      "Epoch 4246, Loss: 0.0019788182398770005, Final Batch Loss: 0.0015319547383114696\n",
      "Epoch 4247, Loss: 0.0002785769393085502, Final Batch Loss: 0.00016391847748309374\n",
      "Epoch 4248, Loss: 0.0009154067665804178, Final Batch Loss: 0.00015054093091748655\n",
      "Epoch 4249, Loss: 0.0011048902379116043, Final Batch Loss: 0.0008958936668932438\n",
      "Epoch 4250, Loss: 0.0029328386299312115, Final Batch Loss: 0.00010262546129524708\n",
      "Epoch 4251, Loss: 0.0003516397664498072, Final Batch Loss: 0.00033374433405697346\n",
      "Epoch 4252, Loss: 0.0005490892108355183, Final Batch Loss: 4.971567614120431e-05\n",
      "Epoch 4253, Loss: 9.00009399629198e-05, Final Batch Loss: 1.7935621144715697e-05\n",
      "Epoch 4254, Loss: 0.00021589916377706686, Final Batch Loss: 9.204414709529374e-06\n",
      "Epoch 4255, Loss: 0.0008180867880582809, Final Batch Loss: 0.00024133670376613736\n",
      "Epoch 4256, Loss: 0.00026181537396041676, Final Batch Loss: 0.00014909679885022342\n",
      "Epoch 4257, Loss: 0.0007490769057767466, Final Batch Loss: 9.755628707353026e-05\n",
      "Epoch 4258, Loss: 0.0003854541719192639, Final Batch Loss: 0.00019329624774400145\n",
      "Epoch 4259, Loss: 0.00018794187781168148, Final Batch Loss: 7.868091779528186e-05\n",
      "Epoch 4260, Loss: 0.0004349327882664511, Final Batch Loss: 2.5614624973968603e-05\n",
      "Epoch 4261, Loss: 0.00405634829076007, Final Batch Loss: 0.003878258867189288\n",
      "Epoch 4262, Loss: 0.0005339330818969756, Final Batch Loss: 4.00229764636606e-05\n",
      "Epoch 4263, Loss: 3.407617987249978e-05, Final Batch Loss: 7.020871635177173e-06\n",
      "Epoch 4264, Loss: 0.00026928337319986895, Final Batch Loss: 0.00015236466424539685\n",
      "Epoch 4265, Loss: 0.0002522163731555338, Final Batch Loss: 8.266771146736573e-06\n",
      "Epoch 4266, Loss: 0.0003582644567359239, Final Batch Loss: 0.0001475704339100048\n",
      "Epoch 4267, Loss: 0.007589805820316542, Final Batch Loss: 7.61374321882613e-05\n",
      "Epoch 4268, Loss: 0.0037788310437463224, Final Batch Loss: 0.0034885897766798735\n",
      "Epoch 4269, Loss: 0.00045936889364384115, Final Batch Loss: 7.739377906545997e-05\n",
      "Epoch 4270, Loss: 0.0022353435051627457, Final Batch Loss: 0.0007708429475314915\n",
      "Epoch 4271, Loss: 0.0004008668001915794, Final Batch Loss: 0.00036475385422818363\n",
      "Epoch 4272, Loss: 0.0005531345013878308, Final Batch Loss: 0.00047276559052988887\n",
      "Epoch 4273, Loss: 0.000435907713836059, Final Batch Loss: 0.00012891978258267045\n",
      "Epoch 4274, Loss: 0.00021019778796471655, Final Batch Loss: 0.00011430209269747138\n",
      "Epoch 4275, Loss: 0.00034182593662990257, Final Batch Loss: 4.9654154281597584e-05\n",
      "Epoch 4276, Loss: 0.0006742298573954031, Final Batch Loss: 0.00016293853695970029\n",
      "Epoch 4277, Loss: 0.0003409979472053237, Final Batch Loss: 8.932868513511494e-05\n",
      "Epoch 4278, Loss: 0.0002424330814392306, Final Batch Loss: 0.0001497962948633358\n",
      "Epoch 4279, Loss: 0.00021014260346419178, Final Batch Loss: 4.405421714182012e-05\n",
      "Epoch 4280, Loss: 0.0001512012204329949, Final Batch Loss: 5.2653962484328076e-05\n",
      "Epoch 4281, Loss: 0.0006430964567698538, Final Batch Loss: 0.0001847435487434268\n",
      "Epoch 4282, Loss: 0.00023861283261794597, Final Batch Loss: 0.00010091948206536472\n",
      "Epoch 4283, Loss: 0.0005910308609600179, Final Batch Loss: 6.954184937058017e-05\n",
      "Epoch 4284, Loss: 3.884671104970039e-05, Final Batch Loss: 7.2879033723438624e-06\n",
      "Epoch 4285, Loss: 0.0037881843418290373, Final Batch Loss: 0.0037717288359999657\n",
      "Epoch 4286, Loss: 0.00116932594391983, Final Batch Loss: 0.0011213542893528938\n",
      "Epoch 4287, Loss: 0.006468735802627634, Final Batch Loss: 0.00011105665907962248\n",
      "Epoch 4288, Loss: 0.0006372098869178444, Final Batch Loss: 0.0002517348912078887\n",
      "Epoch 4289, Loss: 0.00012383488319755998, Final Batch Loss: 1.7966738596442156e-05\n",
      "Epoch 4290, Loss: 0.0013411967229330912, Final Batch Loss: 0.00020511391630861908\n",
      "Epoch 4291, Loss: 0.0009574307478033006, Final Batch Loss: 5.115347448736429e-05\n",
      "Epoch 4292, Loss: 0.0002299806074006483, Final Batch Loss: 0.00019331763905938715\n",
      "Epoch 4293, Loss: 0.0005980164860375226, Final Batch Loss: 0.0003352068306412548\n",
      "Epoch 4294, Loss: 0.0014295634609879926, Final Batch Loss: 0.001254730741493404\n",
      "Epoch 4295, Loss: 0.0006621761422138661, Final Batch Loss: 0.000640910817310214\n",
      "Epoch 4296, Loss: 0.00017509730878373375, Final Batch Loss: 1.2187177162559237e-05\n",
      "Epoch 4297, Loss: 0.009786573762539774, Final Batch Loss: 0.008975929580628872\n",
      "Epoch 4298, Loss: 0.00012685052934102714, Final Batch Loss: 7.518314669141546e-05\n",
      "Epoch 4299, Loss: 0.0002669276454980718, Final Batch Loss: 3.930794264306314e-06\n",
      "Epoch 4300, Loss: 0.00018361229376750998, Final Batch Loss: 5.7303226640215144e-05\n",
      "Epoch 4301, Loss: 0.00027489697822602466, Final Batch Loss: 8.250003884313628e-05\n",
      "Epoch 4302, Loss: 0.00013618778575619217, Final Batch Loss: 2.0208628484397195e-05\n",
      "Epoch 4303, Loss: 0.00015773511040606536, Final Batch Loss: 3.1744744774186984e-05\n",
      "Epoch 4304, Loss: 0.001009867206448689, Final Batch Loss: 0.000987530336715281\n",
      "Epoch 4305, Loss: 0.0013059901539236307, Final Batch Loss: 0.0010158902732655406\n",
      "Epoch 4306, Loss: 0.00018695276594371535, Final Batch Loss: 0.00015790591714903712\n",
      "Epoch 4307, Loss: 0.02356533376587322, Final Batch Loss: 1.1384916433598846e-05\n",
      "Epoch 4308, Loss: 0.0003075846398132853, Final Batch Loss: 0.00010913333244388923\n",
      "Epoch 4309, Loss: 0.00013092410154058598, Final Batch Loss: 5.233277261140756e-05\n",
      "Epoch 4310, Loss: 0.0017790479469113052, Final Batch Loss: 0.0008306920644827187\n",
      "Epoch 4311, Loss: 0.00012047970449202694, Final Batch Loss: 5.559253258979879e-05\n",
      "Epoch 4312, Loss: 0.0006019679713062942, Final Batch Loss: 0.00019453366985544562\n",
      "Epoch 4313, Loss: 0.0002448016239213757, Final Batch Loss: 0.00011669024388538674\n",
      "Epoch 4314, Loss: 0.004544494906440377, Final Batch Loss: 0.0005503466818481684\n",
      "Epoch 4315, Loss: 0.0009052313980646431, Final Batch Loss: 0.0006651145522482693\n",
      "Epoch 4316, Loss: 0.00042685362859629095, Final Batch Loss: 0.00024598409072495997\n",
      "Epoch 4317, Loss: 0.00016732602671254426, Final Batch Loss: 6.795995432185009e-05\n",
      "Epoch 4318, Loss: 0.00038992110057733953, Final Batch Loss: 0.00020259727898519486\n",
      "Epoch 4319, Loss: 0.0043639144860208035, Final Batch Loss: 0.0029970963951200247\n",
      "Epoch 4320, Loss: 0.008973825722932816, Final Batch Loss: 0.00875878520309925\n",
      "Epoch 4321, Loss: 0.00021621670384774916, Final Batch Loss: 0.00018307757272850722\n",
      "Epoch 4322, Loss: 0.0005213105323491618, Final Batch Loss: 0.000459755101474002\n",
      "Epoch 4323, Loss: 8.256235742010176e-05, Final Batch Loss: 1.977450301637873e-05\n",
      "Epoch 4324, Loss: 0.006894651171023725, Final Batch Loss: 5.527383109438233e-05\n",
      "Epoch 4325, Loss: 0.0010586681446511648, Final Batch Loss: 1.0693226613511797e-05\n",
      "Epoch 4326, Loss: 0.00019346711633261293, Final Batch Loss: 7.903973164502531e-05\n",
      "Epoch 4327, Loss: 0.0038980755216471152, Final Batch Loss: 0.0038774111308157444\n",
      "Epoch 4328, Loss: 0.0005823886094731279, Final Batch Loss: 9.409274935023859e-05\n",
      "Epoch 4329, Loss: 0.016209915920626372, Final Batch Loss: 0.015794258564710617\n",
      "Epoch 4330, Loss: 0.00027580722417042125, Final Batch Loss: 0.00025563465896993876\n",
      "Epoch 4331, Loss: 0.00022649903257843107, Final Batch Loss: 7.36518413759768e-05\n",
      "Epoch 4332, Loss: 0.00012121853251301218, Final Batch Loss: 0.00011336756870150566\n",
      "Epoch 4333, Loss: 0.001235429233929608, Final Batch Loss: 0.00010838922025868669\n",
      "Epoch 4334, Loss: 0.00020028621293022297, Final Batch Loss: 0.0001480075588915497\n",
      "Epoch 4335, Loss: 0.00035089765151496977, Final Batch Loss: 0.00015117830480448902\n",
      "Epoch 4336, Loss: 0.00020540668174362509, Final Batch Loss: 0.0001935084437718615\n",
      "Epoch 4337, Loss: 0.000916253446121118, Final Batch Loss: 1.6939322449616157e-05\n",
      "Epoch 4338, Loss: 0.0008030475000850856, Final Batch Loss: 0.0004738964489661157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4339, Loss: 0.0016577839596720878, Final Batch Loss: 0.0016133302124217153\n",
      "Epoch 4340, Loss: 0.0036341601226013154, Final Batch Loss: 0.00014326462405733764\n",
      "Epoch 4341, Loss: 0.00019234877277085616, Final Batch Loss: 3.0595695079682628e-06\n",
      "Epoch 4342, Loss: 0.010183498030528426, Final Batch Loss: 0.002757615176960826\n",
      "Epoch 4343, Loss: 0.0006940875318832695, Final Batch Loss: 0.00029010168509557843\n",
      "Epoch 4344, Loss: 0.0004063698615937028, Final Batch Loss: 3.835044117295183e-05\n",
      "Epoch 4345, Loss: 9.025439430843107e-05, Final Batch Loss: 8.524610166205093e-06\n",
      "Epoch 4346, Loss: 0.0010799881274579093, Final Batch Loss: 0.0010103234089910984\n",
      "Epoch 4347, Loss: 0.0005071902342024259, Final Batch Loss: 6.808473699493334e-05\n",
      "Epoch 4348, Loss: 6.621911416004878e-05, Final Batch Loss: 4.573377736960538e-05\n",
      "Epoch 4349, Loss: 0.00014065673167351633, Final Batch Loss: 7.672859646845609e-05\n",
      "Epoch 4350, Loss: 0.00018618060494191013, Final Batch Loss: 4.4924436224391684e-05\n",
      "Epoch 4351, Loss: 0.0003158806648571044, Final Batch Loss: 0.00015731141320429742\n",
      "Epoch 4352, Loss: 0.00032496136373083573, Final Batch Loss: 1.684871494944673e-05\n",
      "Epoch 4353, Loss: 0.0038269811670943454, Final Batch Loss: 4.763704509969102e-06\n",
      "Epoch 4354, Loss: 0.004871562268817797, Final Batch Loss: 0.004727529361844063\n",
      "Epoch 4355, Loss: 0.0001309071321884403, Final Batch Loss: 1.6789113942650147e-05\n",
      "Epoch 4356, Loss: 0.0006204540695762262, Final Batch Loss: 9.646247781347483e-05\n",
      "Epoch 4357, Loss: 3.509445195959415e-05, Final Batch Loss: 1.6812611647765152e-05\n",
      "Epoch 4358, Loss: 0.00012650421558646485, Final Batch Loss: 8.097919635474682e-05\n",
      "Epoch 4359, Loss: 0.00016592005886195693, Final Batch Loss: 0.0001405322691425681\n",
      "Epoch 4360, Loss: 3.631420258898288e-05, Final Batch Loss: 2.534512350393925e-05\n",
      "Epoch 4361, Loss: 0.00020261095778550953, Final Batch Loss: 1.6779828001745045e-05\n",
      "Epoch 4362, Loss: 0.0001675342646194622, Final Batch Loss: 6.915670383023098e-05\n",
      "Epoch 4363, Loss: 7.454134356521536e-05, Final Batch Loss: 6.039286745362915e-06\n",
      "Epoch 4364, Loss: 0.0015284610199159943, Final Batch Loss: 0.00010175609349971637\n",
      "Epoch 4365, Loss: 0.0006761939584976062, Final Batch Loss: 0.00024192988348659128\n",
      "Epoch 4366, Loss: 0.0006621186330448836, Final Batch Loss: 0.00013539122301153839\n",
      "Epoch 4367, Loss: 0.01825488224858418, Final Batch Loss: 0.017659761011600494\n",
      "Epoch 4368, Loss: 0.0004366660350569873, Final Batch Loss: 8.81752112036338e-06\n",
      "Epoch 4369, Loss: 0.0027953846802120097, Final Batch Loss: 6.248098361538723e-05\n",
      "Epoch 4370, Loss: 0.01129934782784403, Final Batch Loss: 3.894182555086445e-06\n",
      "Epoch 4371, Loss: 0.004211000457871705, Final Batch Loss: 0.00025042035849764943\n",
      "Epoch 4372, Loss: 0.0009318088123109192, Final Batch Loss: 0.0007360418094322085\n",
      "Epoch 4373, Loss: 0.0009160729096038267, Final Batch Loss: 0.00015366716252174228\n",
      "Epoch 4374, Loss: 0.0001525977386336308, Final Batch Loss: 0.00012899735884275287\n",
      "Epoch 4375, Loss: 0.0002821096313709859, Final Batch Loss: 0.00023107654124032706\n",
      "Epoch 4376, Loss: 0.00041868236803566106, Final Batch Loss: 5.54681355424691e-05\n",
      "Epoch 4377, Loss: 0.0017834460340964142, Final Batch Loss: 2.5602497771615162e-05\n",
      "Epoch 4378, Loss: 0.005210058952798136, Final Batch Loss: 0.0050199683755636215\n",
      "Epoch 4379, Loss: 0.0002613628284962033, Final Batch Loss: 1.2435030839696992e-05\n",
      "Epoch 4380, Loss: 0.017276472819503397, Final Batch Loss: 0.016993191093206406\n",
      "Epoch 4381, Loss: 0.0007326976010517683, Final Batch Loss: 2.0382398361107334e-05\n",
      "Epoch 4382, Loss: 0.0005285242405079771, Final Batch Loss: 0.0004962749662809074\n",
      "Epoch 4383, Loss: 0.0023037081555230543, Final Batch Loss: 0.0021620835177600384\n",
      "Epoch 4384, Loss: 0.008072024109424092, Final Batch Loss: 0.007862415164709091\n",
      "Epoch 4385, Loss: 8.671245359437307e-05, Final Batch Loss: 7.38438538974151e-05\n",
      "Epoch 4386, Loss: 0.00024087869314826094, Final Batch Loss: 1.6716829122742638e-05\n",
      "Epoch 4387, Loss: 0.00012261124356882647, Final Batch Loss: 4.2859421228058636e-05\n",
      "Epoch 4388, Loss: 0.00038233259692788124, Final Batch Loss: 0.00010825891513377428\n",
      "Epoch 4389, Loss: 0.00035084705814369954, Final Batch Loss: 4.414350041770376e-05\n",
      "Epoch 4390, Loss: 0.00014839172536085243, Final Batch Loss: 7.622871180501534e-06\n",
      "Epoch 4391, Loss: 3.147853567497805e-05, Final Batch Loss: 1.0412870324216783e-05\n",
      "Epoch 4392, Loss: 0.005341908708942356, Final Batch Loss: 5.8374182117404416e-05\n",
      "Epoch 4393, Loss: 0.00012493703343352536, Final Batch Loss: 1.2284946024010424e-05\n",
      "Epoch 4394, Loss: 0.00339159619397833, Final Batch Loss: 3.4647233405848965e-05\n",
      "Epoch 4395, Loss: 0.0003460279549472034, Final Batch Loss: 0.00016111013246700168\n",
      "Epoch 4396, Loss: 0.0009928119980031624, Final Batch Loss: 0.00012447750486899167\n",
      "Epoch 4397, Loss: 0.00016666063675074838, Final Batch Loss: 3.355480657774024e-05\n",
      "Epoch 4398, Loss: 0.00024693289742572233, Final Batch Loss: 7.534366886829957e-05\n",
      "Epoch 4399, Loss: 0.0032395749585703015, Final Batch Loss: 0.002939714351668954\n",
      "Epoch 4400, Loss: 0.0023373987642116845, Final Batch Loss: 0.0018438206752762198\n",
      "Epoch 4401, Loss: 0.0032700892188586295, Final Batch Loss: 0.00041120947571471334\n",
      "Epoch 4402, Loss: 0.0006419762066798285, Final Batch Loss: 0.0004495902976486832\n",
      "Epoch 4403, Loss: 0.0004617874219547957, Final Batch Loss: 0.000334329524775967\n",
      "Epoch 4404, Loss: 0.011816902551800013, Final Batch Loss: 0.011643312871456146\n",
      "Epoch 4405, Loss: 0.0001562849574838765, Final Batch Loss: 9.118615707848221e-06\n",
      "Epoch 4406, Loss: 8.27616750029847e-05, Final Batch Loss: 1.7228172509931028e-05\n",
      "Epoch 4407, Loss: 0.0013876549783162773, Final Batch Loss: 0.0008393855532631278\n",
      "Epoch 4408, Loss: 0.0007576819334644824, Final Batch Loss: 0.00047646198072470725\n",
      "Epoch 4409, Loss: 0.00042641368054319173, Final Batch Loss: 0.00011788443953264505\n",
      "Epoch 4410, Loss: 0.0008803609543974744, Final Batch Loss: 1.8367778466199525e-05\n",
      "Epoch 4411, Loss: 0.00043263241241220385, Final Batch Loss: 0.00019089736451860517\n",
      "Epoch 4412, Loss: 0.00021027724142186344, Final Batch Loss: 0.00014365650713443756\n",
      "Epoch 4413, Loss: 0.0003956673535867594, Final Batch Loss: 8.447647996945307e-05\n",
      "Epoch 4414, Loss: 0.0009879488206934184, Final Batch Loss: 0.00039864148129709065\n",
      "Epoch 4415, Loss: 0.0009024377141031437, Final Batch Loss: 0.0008400477236136794\n",
      "Epoch 4416, Loss: 0.0005556011747103184, Final Batch Loss: 0.00042624250636436045\n",
      "Epoch 4417, Loss: 0.0013474280658556381, Final Batch Loss: 2.463906457705889e-05\n",
      "Epoch 4418, Loss: 0.0018964395276270807, Final Batch Loss: 0.0009316069190390408\n",
      "Epoch 4419, Loss: 0.0002193770560552366, Final Batch Loss: 0.000139743642648682\n",
      "Epoch 4420, Loss: 0.0011317925818730146, Final Batch Loss: 0.000989227439276874\n",
      "Epoch 4421, Loss: 5.907839477004018e-05, Final Batch Loss: 2.2477559468825348e-05\n",
      "Epoch 4422, Loss: 0.006524086005811114, Final Batch Loss: 6.872462836327031e-05\n",
      "Epoch 4423, Loss: 4.501992179939407e-05, Final Batch Loss: 4.175387221039273e-05\n",
      "Epoch 4424, Loss: 0.0006340420804917812, Final Batch Loss: 0.000300827668979764\n",
      "Epoch 4425, Loss: 0.001167943799373461, Final Batch Loss: 0.0011320849880576134\n",
      "Epoch 4426, Loss: 0.0003497176294331439, Final Batch Loss: 3.128837124677375e-05\n",
      "Epoch 4427, Loss: 0.0002463010205246974, Final Batch Loss: 5.331941429176368e-05\n",
      "Epoch 4428, Loss: 0.0003797482422669418, Final Batch Loss: 0.0001144894995377399\n",
      "Epoch 4429, Loss: 0.0008186766353901476, Final Batch Loss: 0.0007373515982180834\n",
      "Epoch 4430, Loss: 0.0032851635478436947, Final Batch Loss: 0.00022661220282316208\n",
      "Epoch 4431, Loss: 0.0007636793598067015, Final Batch Loss: 0.0001734789984766394\n",
      "Epoch 4432, Loss: 9.869086170510855e-05, Final Batch Loss: 8.445020284852944e-06\n",
      "Epoch 4433, Loss: 0.00021245116295176558, Final Batch Loss: 0.00019485680968500674\n",
      "Epoch 4434, Loss: 0.0005542303115362301, Final Batch Loss: 0.00047859863843768835\n",
      "Epoch 4435, Loss: 0.001092924750992097, Final Batch Loss: 4.2305575334466994e-05\n",
      "Epoch 4436, Loss: 0.00031701105035608634, Final Batch Loss: 0.0002192858373746276\n",
      "Epoch 4437, Loss: 0.00013973391833133064, Final Batch Loss: 9.749066521180794e-06\n",
      "Epoch 4438, Loss: 0.000494901993079111, Final Batch Loss: 0.0002743922232184559\n",
      "Epoch 4439, Loss: 0.0014042154070921242, Final Batch Loss: 0.0008302940987050533\n",
      "Epoch 4440, Loss: 0.0008986531865957659, Final Batch Loss: 0.0008520634728483856\n",
      "Epoch 4441, Loss: 0.0006066248060960788, Final Batch Loss: 5.9027155657531694e-05\n",
      "Epoch 4442, Loss: 0.005731963639846072, Final Batch Loss: 0.00553022651001811\n",
      "Epoch 4443, Loss: 9.037062795869133e-05, Final Batch Loss: 1.3307255812833318e-06\n",
      "Epoch 4444, Loss: 0.0001614787288417574, Final Batch Loss: 0.00015103818441275507\n",
      "Epoch 4445, Loss: 0.00043417922279331833, Final Batch Loss: 0.0002912348718382418\n",
      "Epoch 4446, Loss: 0.000678493088344112, Final Batch Loss: 0.00026156188687309623\n",
      "Epoch 4447, Loss: 0.00015776228610775433, Final Batch Loss: 0.00013116339687258005\n",
      "Epoch 4448, Loss: 6.01233168708859e-05, Final Batch Loss: 2.711411980271805e-05\n",
      "Epoch 4449, Loss: 0.0002857651015801821, Final Batch Loss: 0.0002446151920594275\n",
      "Epoch 4450, Loss: 0.0002034900553553598, Final Batch Loss: 0.00017918492085300386\n",
      "Epoch 4451, Loss: 0.00025402396022400353, Final Batch Loss: 6.854557796032168e-06\n",
      "Epoch 4452, Loss: 0.00010403416672488675, Final Batch Loss: 3.161783388350159e-05\n",
      "Epoch 4453, Loss: 5.4949581681285053e-05, Final Batch Loss: 2.844331356754992e-05\n",
      "Epoch 4454, Loss: 0.00022558277487405576, Final Batch Loss: 3.623836164479144e-05\n",
      "Epoch 4455, Loss: 0.0009409188642166555, Final Batch Loss: 0.0007776203565299511\n",
      "Epoch 4456, Loss: 0.0015354873321484774, Final Batch Loss: 0.0002889871539082378\n",
      "Epoch 4457, Loss: 0.0005962180694041308, Final Batch Loss: 5.46723858860787e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4458, Loss: 0.0013188161246944219, Final Batch Loss: 0.0003528695378918201\n",
      "Epoch 4459, Loss: 0.0004437949278326414, Final Batch Loss: 2.161879365303321e-06\n",
      "Epoch 4460, Loss: 0.00022593743415200152, Final Batch Loss: 3.069042941206135e-05\n",
      "Epoch 4461, Loss: 0.00010016618034569547, Final Batch Loss: 5.853006223333068e-05\n",
      "Epoch 4462, Loss: 0.0017834647787822178, Final Batch Loss: 1.593991146364715e-05\n",
      "Epoch 4463, Loss: 2.2121811070974218e-05, Final Batch Loss: 3.045796347578289e-06\n",
      "Epoch 4464, Loss: 0.0002977168671804975, Final Batch Loss: 2.274541884617065e-06\n",
      "Epoch 4465, Loss: 0.0008919570536818355, Final Batch Loss: 0.00030298400088213384\n",
      "Epoch 4466, Loss: 5.365022843761835e-05, Final Batch Loss: 1.3946590115665458e-05\n",
      "Epoch 4467, Loss: 0.0002443054909235798, Final Batch Loss: 0.00010397475125500932\n",
      "Epoch 4468, Loss: 0.0001974667320610024, Final Batch Loss: 7.162555266404524e-05\n",
      "Epoch 4469, Loss: 0.028952506312634796, Final Batch Loss: 0.028747467324137688\n",
      "Epoch 4470, Loss: 0.00022265723964665085, Final Batch Loss: 6.654828030150384e-05\n",
      "Epoch 4471, Loss: 0.017430066043743864, Final Batch Loss: 0.01702362671494484\n",
      "Epoch 4472, Loss: 0.003697367670611129, Final Batch Loss: 2.0975532606826164e-05\n",
      "Epoch 4473, Loss: 0.002608094539027661, Final Batch Loss: 0.0023126364685595036\n",
      "Epoch 4474, Loss: 0.0005848394430358894, Final Batch Loss: 0.0005286682862788439\n",
      "Epoch 4475, Loss: 0.000610369213973172, Final Batch Loss: 4.873373836744577e-05\n",
      "Epoch 4476, Loss: 0.0031230583554133773, Final Batch Loss: 0.0028650755994021893\n",
      "Epoch 4477, Loss: 0.0005544222440221347, Final Batch Loss: 5.9294085076544434e-05\n",
      "Epoch 4478, Loss: 0.004951358860125765, Final Batch Loss: 0.004621933680027723\n",
      "Epoch 4479, Loss: 0.00034980708733201027, Final Batch Loss: 0.00014925131108611822\n",
      "Epoch 4480, Loss: 0.0015115407150005922, Final Batch Loss: 2.3586544557474554e-05\n",
      "Epoch 4481, Loss: 0.00024344909616047516, Final Batch Loss: 0.00010621098772389814\n",
      "Epoch 4482, Loss: 0.02224133681738749, Final Batch Loss: 0.021716373041272163\n",
      "Epoch 4483, Loss: 0.0016556792397750542, Final Batch Loss: 0.0014948580646887422\n",
      "Epoch 4484, Loss: 0.00010308593846275471, Final Batch Loss: 9.07493376871571e-05\n",
      "Epoch 4485, Loss: 0.0007730490760877728, Final Batch Loss: 0.0002586183836683631\n",
      "Epoch 4486, Loss: 0.0002650495462148683, Final Batch Loss: 0.0002504666626919061\n",
      "Epoch 4487, Loss: 0.0002735646485234611, Final Batch Loss: 9.529454837320372e-05\n",
      "Epoch 4488, Loss: 0.00014365880997502245, Final Batch Loss: 5.6455424783052877e-05\n",
      "Epoch 4489, Loss: 0.0020315284054959193, Final Batch Loss: 0.0018329849699512124\n",
      "Epoch 4490, Loss: 0.007118459547200473, Final Batch Loss: 0.007061426993459463\n",
      "Epoch 4491, Loss: 0.0008488275270792656, Final Batch Loss: 0.00010657018719939515\n",
      "Epoch 4492, Loss: 0.0005020641256123781, Final Batch Loss: 0.0002445146965328604\n",
      "Epoch 4493, Loss: 0.0031161473889369518, Final Batch Loss: 0.002777212532237172\n",
      "Epoch 4494, Loss: 0.0017789693956729025, Final Batch Loss: 0.001680311979725957\n",
      "Epoch 4495, Loss: 0.00026939100644085556, Final Batch Loss: 0.00014254299458116293\n",
      "Epoch 4496, Loss: 0.00037650468584615737, Final Batch Loss: 0.00011477306543383747\n",
      "Epoch 4497, Loss: 0.0007134578190743923, Final Batch Loss: 0.00023495449568144977\n",
      "Epoch 4498, Loss: 0.00291943110619286, Final Batch Loss: 2.4051694254012546e-06\n",
      "Epoch 4499, Loss: 0.00278853383497335, Final Batch Loss: 0.0026959131937474012\n",
      "Epoch 4500, Loss: 0.00044102776155341417, Final Batch Loss: 0.00028906221268698573\n",
      "Epoch 4501, Loss: 0.002047731017228216, Final Batch Loss: 0.0012064091861248016\n",
      "Epoch 4502, Loss: 0.0002452588341839146, Final Batch Loss: 5.8071014791494235e-05\n",
      "Epoch 4503, Loss: 0.00018365777941653505, Final Batch Loss: 2.9923270631115884e-05\n",
      "Epoch 4504, Loss: 0.00012014060666842852, Final Batch Loss: 2.7644209694699384e-05\n",
      "Epoch 4505, Loss: 0.0011602824233705178, Final Batch Loss: 0.00011782477668020874\n",
      "Epoch 4506, Loss: 0.0004530301521299407, Final Batch Loss: 0.00031238439260050654\n",
      "Epoch 4507, Loss: 0.00015070910740178078, Final Batch Loss: 2.983927697641775e-05\n",
      "Epoch 4508, Loss: 0.0018495723270461895, Final Batch Loss: 1.702112058410421e-05\n",
      "Epoch 4509, Loss: 0.00019093661103397608, Final Batch Loss: 0.0001238224795088172\n",
      "Epoch 4510, Loss: 0.0001159205894509796, Final Batch Loss: 7.307634223252535e-05\n",
      "Epoch 4511, Loss: 0.0005149989810888655, Final Batch Loss: 0.00011395529872970656\n",
      "Epoch 4512, Loss: 0.006572055834112689, Final Batch Loss: 0.00026576381060294807\n",
      "Epoch 4513, Loss: 0.00038410991692217067, Final Batch Loss: 0.0002767761470749974\n",
      "Epoch 4514, Loss: 0.0006287753349170089, Final Batch Loss: 0.00011093559442088008\n",
      "Epoch 4515, Loss: 0.0008256682194769382, Final Batch Loss: 0.0003833367954939604\n",
      "Epoch 4516, Loss: 0.008969385453383438, Final Batch Loss: 0.008752638474106789\n",
      "Epoch 4517, Loss: 7.514983917644713e-05, Final Batch Loss: 4.8501009587198496e-05\n",
      "Epoch 4518, Loss: 4.273397280485369e-05, Final Batch Loss: 1.0337025742046535e-05\n",
      "Epoch 4519, Loss: 0.0001857527022366412, Final Batch Loss: 0.00014121276035439223\n",
      "Epoch 4520, Loss: 0.0021096783857501578, Final Batch Loss: 3.572871719370596e-05\n",
      "Epoch 4521, Loss: 0.000792075356002897, Final Batch Loss: 0.0006073228432796896\n",
      "Epoch 4522, Loss: 0.00044060735672246665, Final Batch Loss: 0.0003128781099803746\n",
      "Epoch 4523, Loss: 0.00015471445658477023, Final Batch Loss: 0.00011372098379069939\n",
      "Epoch 4524, Loss: 0.0014383423840627074, Final Batch Loss: 0.00047093169996514916\n",
      "Epoch 4525, Loss: 0.0008793757733656093, Final Batch Loss: 0.0006594689330086112\n",
      "Epoch 4526, Loss: 0.0004257856635376811, Final Batch Loss: 0.000362491759005934\n",
      "Epoch 4527, Loss: 0.0004418513854034245, Final Batch Loss: 6.128600216470659e-05\n",
      "Epoch 4528, Loss: 0.0013635254108521622, Final Batch Loss: 8.531274943379685e-06\n",
      "Epoch 4529, Loss: 0.0004667734610848129, Final Batch Loss: 0.00017911422764882445\n",
      "Epoch 4530, Loss: 0.000910226532141678, Final Batch Loss: 0.000826348434202373\n",
      "Epoch 4531, Loss: 0.0019314518649480306, Final Batch Loss: 0.001888675382360816\n",
      "Epoch 4532, Loss: 0.00024518967256881297, Final Batch Loss: 0.0001563659607199952\n",
      "Epoch 4533, Loss: 0.0002659358906385023, Final Batch Loss: 6.077219222788699e-05\n",
      "Epoch 4534, Loss: 0.0005605784485851473, Final Batch Loss: 3.6943479244655464e-06\n",
      "Epoch 4535, Loss: 0.00014842992641206365, Final Batch Loss: 0.00011799128697020933\n",
      "Epoch 4536, Loss: 0.0006716469069942832, Final Batch Loss: 0.00019010185496881604\n",
      "Epoch 4537, Loss: 0.0002580503532954026, Final Batch Loss: 0.00022301939316093922\n",
      "Epoch 4538, Loss: 0.00141896049171919, Final Batch Loss: 0.0013700616545975208\n",
      "Epoch 4539, Loss: 0.0001771048737282399, Final Batch Loss: 0.0001267504267161712\n",
      "Epoch 4540, Loss: 4.848205298912944e-05, Final Batch Loss: 1.3413308806775603e-05\n",
      "Epoch 4541, Loss: 0.00012945221897098236, Final Batch Loss: 0.00010401321924291551\n",
      "Epoch 4542, Loss: 0.0004313485842430964, Final Batch Loss: 0.0001499181817052886\n",
      "Epoch 4543, Loss: 0.00013758079239778453, Final Batch Loss: 1.4026388271304313e-05\n",
      "Epoch 4544, Loss: 0.0009266780180041678, Final Batch Loss: 2.4213055439759046e-05\n",
      "Epoch 4545, Loss: 0.008219714483857388, Final Batch Loss: 3.260953599237837e-05\n",
      "Epoch 4546, Loss: 0.00011416804045438766, Final Batch Loss: 7.977031054906547e-05\n",
      "Epoch 4547, Loss: 0.00023749055253574625, Final Batch Loss: 9.146346565103158e-05\n",
      "Epoch 4548, Loss: 0.0015224494563881308, Final Batch Loss: 0.0002527962496969849\n",
      "Epoch 4549, Loss: 0.00029835020541213453, Final Batch Loss: 0.00016599215450696647\n",
      "Epoch 4550, Loss: 0.00013448279696604004, Final Batch Loss: 9.052592758962419e-06\n",
      "Epoch 4551, Loss: 0.0003908029175363481, Final Batch Loss: 0.00018460788123775274\n",
      "Epoch 4552, Loss: 0.010092611773870885, Final Batch Loss: 0.001386969699524343\n",
      "Epoch 4553, Loss: 4.397194015837158e-05, Final Batch Loss: 5.056753707322059e-06\n",
      "Epoch 4554, Loss: 0.00016031866329058175, Final Batch Loss: 9.049931009030843e-07\n",
      "Epoch 4555, Loss: 0.005100920709082857, Final Batch Loss: 0.004929357673972845\n",
      "Epoch 4556, Loss: 0.0005192273565626238, Final Batch Loss: 5.80550440645311e-05\n",
      "Epoch 4557, Loss: 0.0004757989590871148, Final Batch Loss: 2.0754690922331065e-05\n",
      "Epoch 4558, Loss: 0.002543293875078234, Final Batch Loss: 6.164661044749664e-06\n",
      "Epoch 4559, Loss: 0.00012808474275516346, Final Batch Loss: 3.809512418229133e-05\n",
      "Epoch 4560, Loss: 0.004273497908798163, Final Batch Loss: 1.6391220924560912e-05\n",
      "Epoch 4561, Loss: 0.004115902396733873, Final Batch Loss: 0.0039042304269969463\n",
      "Epoch 4562, Loss: 0.0004257384571246803, Final Batch Loss: 0.00022077672474551946\n",
      "Epoch 4563, Loss: 0.0017569597839610651, Final Batch Loss: 0.0016647845041006804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4564, Loss: 0.017969442564208293, Final Batch Loss: 0.017933759838342667\n",
      "Epoch 4565, Loss: 0.00032796907908050343, Final Batch Loss: 8.961988351074979e-05\n",
      "Epoch 4566, Loss: 0.0012461579899536446, Final Batch Loss: 0.0011089702602475882\n",
      "Epoch 4567, Loss: 6.650272462138673e-05, Final Batch Loss: 1.3615229363495018e-05\n",
      "Epoch 4568, Loss: 7.337343703284205e-05, Final Batch Loss: 7.793088911967061e-07\n",
      "Epoch 4569, Loss: 1.902187477753614e-05, Final Batch Loss: 1.5164044270932209e-05\n",
      "Epoch 4570, Loss: 0.0003159206680720672, Final Batch Loss: 0.00014418212231248617\n",
      "Epoch 4571, Loss: 0.00021645530250680167, Final Batch Loss: 0.00018673385784495622\n",
      "Epoch 4572, Loss: 0.0010163805272895843, Final Batch Loss: 0.0003935839340556413\n",
      "Epoch 4573, Loss: 0.0009560619073454291, Final Batch Loss: 0.0006218365742824972\n",
      "Epoch 4574, Loss: 0.0012710140499621048, Final Batch Loss: 0.0012598497560247779\n",
      "Epoch 4575, Loss: 0.0004914038581773639, Final Batch Loss: 6.697711069136858e-05\n",
      "Epoch 4576, Loss: 0.00036249059485271573, Final Batch Loss: 0.00022582910605706275\n",
      "Epoch 4577, Loss: 0.0033360786947014276, Final Batch Loss: 4.8245976358884946e-05\n",
      "Epoch 4578, Loss: 0.00034699954267125577, Final Batch Loss: 0.00016846638754941523\n",
      "Epoch 4579, Loss: 5.114628265801002e-05, Final Batch Loss: 3.968555120081874e-06\n",
      "Epoch 4580, Loss: 0.0005916433874517679, Final Batch Loss: 0.0004435588198248297\n",
      "Epoch 4581, Loss: 0.0018580279793241061, Final Batch Loss: 0.0001007637256407179\n",
      "Epoch 4582, Loss: 9.834149750531651e-05, Final Batch Loss: 2.5980389182223007e-05\n",
      "Epoch 4583, Loss: 0.0003668660256153089, Final Batch Loss: 0.0003558729949872941\n",
      "Epoch 4584, Loss: 0.002918549640071433, Final Batch Loss: 7.363794338743901e-06\n",
      "Epoch 4585, Loss: 6.753288653271738e-05, Final Batch Loss: 2.358996971452143e-05\n",
      "Epoch 4586, Loss: 0.003522829560097307, Final Batch Loss: 0.0009536526049487293\n",
      "Epoch 4587, Loss: 0.00013913587736169575, Final Batch Loss: 7.81527614890365e-06\n",
      "Epoch 4588, Loss: 0.0005116770007589366, Final Batch Loss: 1.2608416000148281e-05\n",
      "Epoch 4589, Loss: 8.9102286437992e-05, Final Batch Loss: 7.598289084853604e-05\n",
      "Epoch 4590, Loss: 0.0009683293246780522, Final Batch Loss: 0.000109294087451417\n",
      "Epoch 4591, Loss: 3.9251412999874447e-05, Final Batch Loss: 2.5493673092569225e-05\n",
      "Epoch 4592, Loss: 0.00021662027211277746, Final Batch Loss: 3.70552261301782e-05\n",
      "Epoch 4593, Loss: 2.9743254344793968e-05, Final Batch Loss: 8.139882993418723e-06\n",
      "Epoch 4594, Loss: 0.00015685213566030143, Final Batch Loss: 1.461716146877734e-05\n",
      "Epoch 4595, Loss: 0.001149314339272678, Final Batch Loss: 0.00031759636476635933\n",
      "Epoch 4596, Loss: 0.002767744765151292, Final Batch Loss: 0.0023957279045134783\n",
      "Epoch 4597, Loss: 4.600504144036677e-05, Final Batch Loss: 2.6644134777598083e-05\n",
      "Epoch 4598, Loss: 0.00042090377337444806, Final Batch Loss: 0.00040929848910309374\n",
      "Epoch 4599, Loss: 4.8220584744740336e-05, Final Batch Loss: 4.6586508688051254e-05\n",
      "Epoch 4600, Loss: 3.0209936085157096e-05, Final Batch Loss: 1.9662626073113643e-05\n",
      "Epoch 4601, Loss: 0.0008122941762849223, Final Batch Loss: 9.995226719183847e-06\n",
      "Epoch 4602, Loss: 0.003259620352764614, Final Batch Loss: 0.0032440205104649067\n",
      "Epoch 4603, Loss: 0.00023165527818491682, Final Batch Loss: 3.8406527892220765e-05\n",
      "Epoch 4604, Loss: 0.0004233636900607962, Final Batch Loss: 0.00040486143552698195\n",
      "Epoch 4605, Loss: 0.001249848439329071, Final Batch Loss: 1.0799074516398832e-05\n",
      "Epoch 4606, Loss: 0.0014810783141001593, Final Batch Loss: 0.0014596364926546812\n",
      "Epoch 4607, Loss: 0.00022512134455610067, Final Batch Loss: 1.0053408914245665e-05\n",
      "Epoch 4608, Loss: 0.0005467081573442556, Final Batch Loss: 0.00045698430039919913\n",
      "Epoch 4609, Loss: 0.0006499876617453992, Final Batch Loss: 0.0002924924483522773\n",
      "Epoch 4610, Loss: 0.00021925230976194143, Final Batch Loss: 9.535094432067126e-05\n",
      "Epoch 4611, Loss: 8.991956019599456e-05, Final Batch Loss: 1.047027217282448e-05\n",
      "Epoch 4612, Loss: 0.00012576161316246726, Final Batch Loss: 4.5304110244615003e-05\n",
      "Epoch 4613, Loss: 0.00011308601824566722, Final Batch Loss: 7.159700180636719e-05\n",
      "Epoch 4614, Loss: 3.8650058741040993e-05, Final Batch Loss: 1.3309866517374758e-05\n",
      "Epoch 4615, Loss: 0.00046979454964457545, Final Batch Loss: 2.0689238226623274e-05\n",
      "Epoch 4616, Loss: 0.005007729912904324, Final Batch Loss: 0.004966081585735083\n",
      "Epoch 4617, Loss: 0.0004137705473112874, Final Batch Loss: 2.1385894797276706e-05\n",
      "Epoch 4618, Loss: 0.002215116663137451, Final Batch Loss: 0.0019617199432104826\n",
      "Epoch 4619, Loss: 8.1043001046055e-05, Final Batch Loss: 1.7230735466000624e-05\n",
      "Epoch 4620, Loss: 0.0013161258539184928, Final Batch Loss: 0.00044764275662600994\n",
      "Epoch 4621, Loss: 0.0008380308281630278, Final Batch Loss: 0.0007765597547404468\n",
      "Epoch 4622, Loss: 5.455668724607676e-05, Final Batch Loss: 3.690085213747807e-05\n",
      "Epoch 4623, Loss: 0.0001053316009347327, Final Batch Loss: 6.662331725237891e-05\n",
      "Epoch 4624, Loss: 0.00030735437030671164, Final Batch Loss: 0.0002148270286852494\n",
      "Epoch 4625, Loss: 0.0005205342022236437, Final Batch Loss: 0.00024702749215066433\n",
      "Epoch 4626, Loss: 0.0021249640303722117, Final Batch Loss: 0.0021129853557795286\n",
      "Epoch 4627, Loss: 0.00016769700596341863, Final Batch Loss: 7.028435356914997e-05\n",
      "Epoch 4628, Loss: 0.0004993718030164018, Final Batch Loss: 0.00021704180107917637\n",
      "Epoch 4629, Loss: 0.000455224112556607, Final Batch Loss: 1.050666924129473e-05\n",
      "Epoch 4630, Loss: 0.007795702666044235, Final Batch Loss: 0.000597828533500433\n",
      "Epoch 4631, Loss: 0.0001363915580441244, Final Batch Loss: 7.995154737727717e-05\n",
      "Epoch 4632, Loss: 0.0003022735381819075, Final Batch Loss: 0.00028894393472000957\n",
      "Epoch 4633, Loss: 0.0001584805577294901, Final Batch Loss: 3.074045525863767e-05\n",
      "Epoch 4634, Loss: 0.00024698328161321115, Final Batch Loss: 2.263250462419819e-05\n",
      "Epoch 4635, Loss: 5.7044018831220455e-05, Final Batch Loss: 4.600617103278637e-05\n",
      "Epoch 4636, Loss: 4.923723372485256e-05, Final Batch Loss: 3.571368142729625e-05\n",
      "Epoch 4637, Loss: 9.821392723097233e-05, Final Batch Loss: 5.232122020970564e-06\n",
      "Epoch 4638, Loss: 1.9529184100974817e-05, Final Batch Loss: 9.585839507053606e-06\n",
      "Epoch 4639, Loss: 7.519487780882628e-05, Final Batch Loss: 5.118114586366573e-06\n",
      "Epoch 4640, Loss: 0.014676136648631655, Final Batch Loss: 0.014541747979819775\n",
      "Epoch 4641, Loss: 0.0013516459584934637, Final Batch Loss: 0.00011306970554869622\n",
      "Epoch 4642, Loss: 0.00016629547826596536, Final Batch Loss: 0.00012375367805361748\n",
      "Epoch 4643, Loss: 0.00029452941816998646, Final Batch Loss: 6.246395787457004e-05\n",
      "Epoch 4644, Loss: 0.016493142131366767, Final Batch Loss: 0.01636974886059761\n",
      "Epoch 4645, Loss: 0.00025016160543600563, Final Batch Loss: 2.0101233531022444e-06\n",
      "Epoch 4646, Loss: 0.00012145856271672528, Final Batch Loss: 5.937783498666249e-06\n",
      "Epoch 4647, Loss: 0.00021891932601647568, Final Batch Loss: 0.00021375366486608982\n",
      "Epoch 4648, Loss: 0.050365195333142765, Final Batch Loss: 0.05025487765669823\n",
      "Epoch 4649, Loss: 0.00019251254343544133, Final Batch Loss: 0.00017483870033174753\n",
      "Epoch 4650, Loss: 0.018089411256369203, Final Batch Loss: 0.0004942113882862031\n",
      "Epoch 4651, Loss: 0.009785460319108097, Final Batch Loss: 1.337007779511623e-05\n",
      "Epoch 4652, Loss: 0.00015125621030165348, Final Batch Loss: 2.9228265702840872e-05\n",
      "Epoch 4653, Loss: 0.0005266117295832373, Final Batch Loss: 0.00041531212627887726\n",
      "Epoch 4654, Loss: 0.0037704966962337494, Final Batch Loss: 0.0011184827890247107\n",
      "Epoch 4655, Loss: 0.002281942739500664, Final Batch Loss: 0.00014579166600015014\n",
      "Epoch 4656, Loss: 0.002021458636590978, Final Batch Loss: 4.759564399137162e-05\n",
      "Epoch 4657, Loss: 0.0006027994604664855, Final Batch Loss: 5.779077037004754e-05\n",
      "Epoch 4658, Loss: 0.006188046638271771, Final Batch Loss: 5.419131775852293e-05\n",
      "Epoch 4659, Loss: 0.003390143290744163, Final Batch Loss: 0.00022518484911415726\n",
      "Epoch 4660, Loss: 0.003464464331045747, Final Batch Loss: 0.00038624322041869164\n",
      "Epoch 4661, Loss: 0.003659936111944262, Final Batch Loss: 7.829254172975197e-05\n",
      "Epoch 4662, Loss: 0.00019135950424242765, Final Batch Loss: 9.257724741473794e-05\n",
      "Epoch 4663, Loss: 0.00015999214519979432, Final Batch Loss: 0.00012044810137012973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4664, Loss: 0.0009643413941375911, Final Batch Loss: 0.0006901034503243864\n",
      "Epoch 4665, Loss: 0.0004332938260631636, Final Batch Loss: 0.00027274645981378853\n",
      "Epoch 4666, Loss: 0.00042429202585481107, Final Batch Loss: 0.00019615325436461717\n",
      "Epoch 4667, Loss: 0.0067068220232613385, Final Batch Loss: 0.006550215650349855\n",
      "Epoch 4668, Loss: 0.04443028042442165, Final Batch Loss: 6.977314478717744e-05\n",
      "Epoch 4669, Loss: 9.986877921619453e-05, Final Batch Loss: 4.4490861910162494e-05\n",
      "Epoch 4670, Loss: 0.0002871125179808587, Final Batch Loss: 6.639385537710041e-05\n",
      "Epoch 4671, Loss: 9.186784518533386e-05, Final Batch Loss: 3.7615060136886314e-05\n",
      "Epoch 4672, Loss: 0.00025071892014238983, Final Batch Loss: 7.206600275821984e-05\n",
      "Epoch 4673, Loss: 0.007941298885270953, Final Batch Loss: 0.0073255691677331924\n",
      "Epoch 4674, Loss: 0.00011128651021863334, Final Batch Loss: 8.156487456290051e-05\n",
      "Epoch 4675, Loss: 0.0005612572349491529, Final Batch Loss: 0.0004682815633714199\n",
      "Epoch 4676, Loss: 0.0009055461885623117, Final Batch Loss: 5.335930950423062e-07\n",
      "Epoch 4677, Loss: 0.0010892982827499509, Final Batch Loss: 0.0006486773490905762\n",
      "Epoch 4678, Loss: 0.00027081763255409896, Final Batch Loss: 4.716671537607908e-05\n",
      "Epoch 4679, Loss: 0.00040218737558461726, Final Batch Loss: 0.0002448525629006326\n",
      "Epoch 4680, Loss: 0.0010948214439849835, Final Batch Loss: 9.437975677428767e-06\n",
      "Epoch 4681, Loss: 0.0012280899536563084, Final Batch Loss: 0.00013612471229862422\n",
      "Epoch 4682, Loss: 0.001176832418423146, Final Batch Loss: 0.00018481345614418387\n",
      "Epoch 4683, Loss: 0.00012424200951954845, Final Batch Loss: 1.8481060806152527e-06\n",
      "Epoch 4684, Loss: 0.0005320869931892958, Final Batch Loss: 3.154825753881596e-05\n",
      "Epoch 4685, Loss: 0.0009181381756206974, Final Batch Loss: 0.0008900880347937346\n",
      "Epoch 4686, Loss: 0.0006585771916434169, Final Batch Loss: 0.0005915152141824365\n",
      "Epoch 4687, Loss: 0.0007885972809162922, Final Batch Loss: 7.226918387459591e-05\n",
      "Epoch 4688, Loss: 0.0001762680767569691, Final Batch Loss: 0.0001029356280923821\n",
      "Epoch 4689, Loss: 0.0002032531629083678, Final Batch Loss: 0.0001396663428749889\n",
      "Epoch 4690, Loss: 0.002183214724936988, Final Batch Loss: 0.0021378379315137863\n",
      "Epoch 4691, Loss: 0.00026584258739603683, Final Batch Loss: 8.327503019245341e-05\n",
      "Epoch 4692, Loss: 0.0021352365147322416, Final Batch Loss: 0.001962122041732073\n",
      "Epoch 4693, Loss: 0.002758924543741159, Final Batch Loss: 6.990174006205052e-05\n",
      "Epoch 4694, Loss: 0.0001351266291749198, Final Batch Loss: 4.589218951878138e-05\n",
      "Epoch 4695, Loss: 0.00014477709191851318, Final Batch Loss: 5.350334686227143e-05\n",
      "Epoch 4696, Loss: 0.00024247193687187973, Final Batch Loss: 2.6846881155506708e-05\n",
      "Epoch 4697, Loss: 0.0015978593146428466, Final Batch Loss: 0.0012528817169368267\n",
      "Epoch 4698, Loss: 0.0013968617568025365, Final Batch Loss: 0.0012740042293444276\n",
      "Epoch 4699, Loss: 0.0002163394171930122, Final Batch Loss: 0.00021272501908242702\n",
      "Epoch 4700, Loss: 0.00022101731519796886, Final Batch Loss: 0.00017799015040509403\n",
      "Epoch 4701, Loss: 0.0009083784025278874, Final Batch Loss: 0.0007878853939473629\n",
      "Epoch 4702, Loss: 0.0034067579836118966, Final Batch Loss: 0.003116051899269223\n",
      "Epoch 4703, Loss: 0.0020946742079104297, Final Batch Loss: 4.241434362484142e-05\n",
      "Epoch 4704, Loss: 0.00012384701585688163, Final Batch Loss: 9.535498247714713e-05\n",
      "Epoch 4705, Loss: 0.00015525045091635548, Final Batch Loss: 1.6351983504137024e-05\n",
      "Epoch 4706, Loss: 0.013147642413969152, Final Batch Loss: 0.012968202121555805\n",
      "Epoch 4707, Loss: 0.0003511763861752115, Final Batch Loss: 9.132880222750828e-05\n",
      "Epoch 4708, Loss: 0.00011656911738100462, Final Batch Loss: 5.56538907403592e-05\n",
      "Epoch 4709, Loss: 0.0005408418701335904, Final Batch Loss: 0.0005274624563753605\n",
      "Epoch 4710, Loss: 0.0002378040226176381, Final Batch Loss: 0.00017342828505206853\n",
      "Epoch 4711, Loss: 7.404857751680538e-05, Final Batch Loss: 3.8250876968959346e-05\n",
      "Epoch 4712, Loss: 9.03602376638446e-05, Final Batch Loss: 4.85117343487218e-05\n",
      "Epoch 4713, Loss: 7.715875835856423e-05, Final Batch Loss: 4.782737232744694e-05\n",
      "Epoch 4714, Loss: 0.00015006314060883597, Final Batch Loss: 4.000760964117944e-05\n",
      "Epoch 4715, Loss: 0.0002970564382849261, Final Batch Loss: 0.0001592223852640018\n",
      "Epoch 4716, Loss: 0.00033136673300759867, Final Batch Loss: 0.00011539836850715801\n",
      "Epoch 4717, Loss: 0.000978694821242243, Final Batch Loss: 0.0005714154103770852\n",
      "Epoch 4718, Loss: 0.00017284083514823578, Final Batch Loss: 0.00014956328959669918\n",
      "Epoch 4719, Loss: 0.000726123180356808, Final Batch Loss: 0.0001222677674377337\n",
      "Epoch 4720, Loss: 0.0006533706618938595, Final Batch Loss: 5.484450957737863e-05\n",
      "Epoch 4721, Loss: 0.0003812303621089086, Final Batch Loss: 0.00016048279940150678\n",
      "Epoch 4722, Loss: 0.00035569015017244965, Final Batch Loss: 0.00015378421812783927\n",
      "Epoch 4723, Loss: 0.00032135819492395967, Final Batch Loss: 0.0001954056933755055\n",
      "Epoch 4724, Loss: 0.00020767863315995783, Final Batch Loss: 8.138484554365277e-05\n",
      "Epoch 4725, Loss: 0.00025863000337267295, Final Batch Loss: 0.00021965934138279408\n",
      "Epoch 4726, Loss: 0.00023842554037400987, Final Batch Loss: 0.00020825141109526157\n",
      "Epoch 4727, Loss: 0.0010319475068172324, Final Batch Loss: 5.649354534398299e-06\n",
      "Epoch 4728, Loss: 0.0001132528832386015, Final Batch Loss: 9.746508294483647e-05\n",
      "Epoch 4729, Loss: 0.00025559408095432445, Final Batch Loss: 8.044177229749039e-05\n",
      "Epoch 4730, Loss: 0.00010641320386639563, Final Batch Loss: 1.2257335583854001e-05\n",
      "Epoch 4731, Loss: 0.0005200600280659273, Final Batch Loss: 0.0004108228604309261\n",
      "Epoch 4732, Loss: 0.007500353764044121, Final Batch Loss: 0.00013375657727010548\n",
      "Epoch 4733, Loss: 0.0005394541367422789, Final Batch Loss: 0.00018701129010878503\n",
      "Epoch 4734, Loss: 0.00022996391726337606, Final Batch Loss: 6.326300535874907e-06\n",
      "Epoch 4735, Loss: 0.010485520062502474, Final Batch Loss: 0.010351673699915409\n",
      "Epoch 4736, Loss: 0.007378564494047168, Final Batch Loss: 5.224066171649611e-06\n",
      "Epoch 4737, Loss: 0.0004552059108391404, Final Batch Loss: 0.00031845460762269795\n",
      "Epoch 4738, Loss: 0.0003872342349495739, Final Batch Loss: 3.580382326617837e-05\n",
      "Epoch 4739, Loss: 0.0007377642286883201, Final Batch Loss: 0.000706107763107866\n",
      "Epoch 4740, Loss: 0.001692219011601992, Final Batch Loss: 0.0002101038844557479\n",
      "Epoch 4741, Loss: 0.0003445991169428453, Final Batch Loss: 0.00013415073044598103\n",
      "Epoch 4742, Loss: 0.00033782148420868907, Final Batch Loss: 2.488897916919086e-05\n",
      "Epoch 4743, Loss: 0.00020914389460813254, Final Batch Loss: 1.1393247405067086e-05\n",
      "Epoch 4744, Loss: 0.00036459791590459645, Final Batch Loss: 0.00011006949353031814\n",
      "Epoch 4745, Loss: 0.0007357997019425966, Final Batch Loss: 0.0006166243692860007\n",
      "Epoch 4746, Loss: 0.00023334719662670977, Final Batch Loss: 0.00019167759455740452\n",
      "Epoch 4747, Loss: 0.0001672546932240948, Final Batch Loss: 9.07470821402967e-05\n",
      "Epoch 4748, Loss: 6.324322839645902e-05, Final Batch Loss: 3.0425226213992573e-06\n",
      "Epoch 4749, Loss: 0.000538503474672325, Final Batch Loss: 0.0003268323780503124\n",
      "Epoch 4750, Loss: 0.0030171241669449955, Final Batch Loss: 0.002689582062885165\n",
      "Epoch 4751, Loss: 0.00043840856960741803, Final Batch Loss: 0.00012189329572720453\n",
      "Epoch 4752, Loss: 0.0005327259550540475, Final Batch Loss: 0.0005090193590149283\n",
      "Epoch 4753, Loss: 0.0017054362106136978, Final Batch Loss: 0.001162088243290782\n",
      "Epoch 4754, Loss: 8.300634817715036e-05, Final Batch Loss: 8.11955123936059e-06\n",
      "Epoch 4755, Loss: 0.0002530584424675908, Final Batch Loss: 4.4296521082287654e-05\n",
      "Epoch 4756, Loss: 0.00043035488124587573, Final Batch Loss: 0.00038676816620863974\n",
      "Epoch 4757, Loss: 0.0011704672215273604, Final Batch Loss: 0.0009316480718553066\n",
      "Epoch 4758, Loss: 0.0005001843492209446, Final Batch Loss: 0.0004656087257899344\n",
      "Epoch 4759, Loss: 0.000939357458264567, Final Batch Loss: 0.0002312420547241345\n",
      "Epoch 4760, Loss: 0.000222083275730256, Final Batch Loss: 9.155010775430128e-05\n",
      "Epoch 4761, Loss: 9.478437732468592e-05, Final Batch Loss: 1.0818211194418836e-05\n",
      "Epoch 4762, Loss: 0.0005250907124718651, Final Batch Loss: 0.00036288544652052224\n",
      "Epoch 4763, Loss: 0.0002404306796961464, Final Batch Loss: 0.00010912390280282125\n",
      "Epoch 4764, Loss: 0.00012152016051913961, Final Batch Loss: 7.455431386915734e-06\n",
      "Epoch 4765, Loss: 0.0003054078229070001, Final Batch Loss: 0.0002981644356623292\n",
      "Epoch 4766, Loss: 0.0003323895507492125, Final Batch Loss: 0.00017089582979679108\n",
      "Epoch 4767, Loss: 8.982829240267165e-05, Final Batch Loss: 7.024544174782932e-05\n",
      "Epoch 4768, Loss: 6.443730444516405e-05, Final Batch Loss: 7.284551884367829e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4769, Loss: 0.00019551037985365838, Final Batch Loss: 3.341154661029577e-05\n",
      "Epoch 4770, Loss: 0.0003263541220803745, Final Batch Loss: 0.00028134274180047214\n",
      "Epoch 4771, Loss: 0.0001102719015761977, Final Batch Loss: 7.764681868138723e-06\n",
      "Epoch 4772, Loss: 0.0014539374969899654, Final Batch Loss: 0.0009649060666561127\n",
      "Epoch 4773, Loss: 0.0002751837237155996, Final Batch Loss: 0.00022520158381666988\n",
      "Epoch 4774, Loss: 0.00016963817506621126, Final Batch Loss: 4.113573595532216e-06\n",
      "Epoch 4775, Loss: 0.0021364345147958375, Final Batch Loss: 7.355439265666064e-06\n",
      "Epoch 4776, Loss: 5.387611599871889e-05, Final Batch Loss: 7.226586603792384e-06\n",
      "Epoch 4777, Loss: 0.003949650632421253, Final Batch Loss: 0.003938314970582724\n",
      "Epoch 4778, Loss: 9.808674622036051e-05, Final Batch Loss: 1.4716320947627537e-05\n",
      "Epoch 4779, Loss: 0.0005211043171584606, Final Batch Loss: 9.131856495514512e-05\n",
      "Epoch 4780, Loss: 0.000754823035094887, Final Batch Loss: 0.0005963873118162155\n",
      "Epoch 4781, Loss: 0.00020683917682617903, Final Batch Loss: 0.00012254185276106\n",
      "Epoch 4782, Loss: 2.4511435185559094e-05, Final Batch Loss: 6.333053534035571e-06\n",
      "Epoch 4783, Loss: 0.007450990080542397, Final Batch Loss: 0.007416001055389643\n",
      "Epoch 4784, Loss: 0.0001424039619450923, Final Batch Loss: 9.845292515819892e-05\n",
      "Epoch 4785, Loss: 0.000925591099075973, Final Batch Loss: 0.00014823919627815485\n",
      "Epoch 4786, Loss: 5.7644170738058165e-05, Final Batch Loss: 1.2529930245364085e-05\n",
      "Epoch 4787, Loss: 0.0005177946732146665, Final Batch Loss: 0.00035683458554558456\n",
      "Epoch 4788, Loss: 0.00504817314867978, Final Batch Loss: 4.3069147068308666e-05\n",
      "Epoch 4789, Loss: 0.0001971265683096135, Final Batch Loss: 2.9092649128870107e-05\n",
      "Epoch 4790, Loss: 0.000869746581884101, Final Batch Loss: 0.00016809397493489087\n",
      "Epoch 4791, Loss: 0.0002472677588229999, Final Batch Loss: 0.00015405949670821428\n",
      "Epoch 4792, Loss: 0.0016939021661528386, Final Batch Loss: 8.896130748325959e-05\n",
      "Epoch 4793, Loss: 0.0013000824255868793, Final Batch Loss: 0.00020230957306921482\n",
      "Epoch 4794, Loss: 0.0034989752384717576, Final Batch Loss: 6.51774971629493e-05\n",
      "Epoch 4795, Loss: 0.00013001218212593812, Final Batch Loss: 1.7889544324134476e-05\n",
      "Epoch 4796, Loss: 0.00028452123660827056, Final Batch Loss: 0.00019395363051444292\n",
      "Epoch 4797, Loss: 0.00024913431116146967, Final Batch Loss: 6.214666791493073e-05\n",
      "Epoch 4798, Loss: 0.00013312559076439356, Final Batch Loss: 1.5161130249907728e-05\n",
      "Epoch 4799, Loss: 0.0006539422320201993, Final Batch Loss: 0.00016573257744312286\n",
      "Epoch 4800, Loss: 2.8090540581615642e-05, Final Batch Loss: 1.3584662156063132e-05\n",
      "Epoch 4801, Loss: 0.008819491721624217, Final Batch Loss: 1.1940605872950982e-05\n",
      "Epoch 4802, Loss: 9.208916162606329e-05, Final Batch Loss: 3.7141191569389775e-05\n",
      "Epoch 4803, Loss: 7.368972728727385e-05, Final Batch Loss: 2.5272434868384153e-05\n",
      "Epoch 4804, Loss: 9.038284770213068e-05, Final Batch Loss: 2.3199099814519286e-05\n",
      "Epoch 4805, Loss: 0.0005854765986441635, Final Batch Loss: 0.00048120395513251424\n",
      "Epoch 4806, Loss: 0.0006926112419023411, Final Batch Loss: 0.0006684281979687512\n",
      "Epoch 4807, Loss: 0.00015473329403903335, Final Batch Loss: 8.683907799422741e-05\n",
      "Epoch 4808, Loss: 0.00010006492721004179, Final Batch Loss: 1.2911105841340031e-05\n",
      "Epoch 4809, Loss: 0.00014624031609855592, Final Batch Loss: 8.157227421179414e-05\n",
      "Epoch 4810, Loss: 0.009274099011236103, Final Batch Loss: 0.009253115393221378\n",
      "Epoch 4811, Loss: 0.000185689190402627, Final Batch Loss: 9.010997018776834e-05\n",
      "Epoch 4812, Loss: 0.0003630434221122414, Final Batch Loss: 0.00023501845134887844\n",
      "Epoch 4813, Loss: 0.0002400564553681761, Final Batch Loss: 8.91247036634013e-05\n",
      "Epoch 4814, Loss: 0.0006376845631166361, Final Batch Loss: 0.0005360188661143184\n",
      "Epoch 4815, Loss: 5.3980958909960464e-05, Final Batch Loss: 1.4217854186426848e-05\n",
      "Epoch 4816, Loss: 0.001198492132971296, Final Batch Loss: 0.0011747423559427261\n",
      "Epoch 4817, Loss: 0.0002718344949244056, Final Batch Loss: 2.4717508495086804e-05\n",
      "Epoch 4818, Loss: 0.0013317169323272537, Final Batch Loss: 4.6522047341568395e-05\n",
      "Epoch 4819, Loss: 0.003244589432142675, Final Batch Loss: 0.0032034022733569145\n",
      "Epoch 4820, Loss: 0.0007112240473361453, Final Batch Loss: 0.0006940671009942889\n",
      "Epoch 4821, Loss: 0.00025567687407601625, Final Batch Loss: 0.0001728316565277055\n",
      "Epoch 4822, Loss: 7.027671472314978e-05, Final Batch Loss: 7.910960448498372e-06\n",
      "Epoch 4823, Loss: 9.917092756950296e-05, Final Batch Loss: 7.99276604084298e-05\n",
      "Epoch 4824, Loss: 6.679303260170855e-05, Final Batch Loss: 1.948338103829883e-05\n",
      "Epoch 4825, Loss: 0.00013687807222595438, Final Batch Loss: 5.8424469898454845e-05\n",
      "Epoch 4826, Loss: 0.00037380588037194684, Final Batch Loss: 0.00011024808190995827\n",
      "Epoch 4827, Loss: 0.00024637804744997993, Final Batch Loss: 0.00015731732128188014\n",
      "Epoch 4828, Loss: 0.00024022515572141856, Final Batch Loss: 0.0001620926195755601\n",
      "Epoch 4829, Loss: 4.367921087577997e-05, Final Batch Loss: 2.1456728518387536e-06\n",
      "Epoch 4830, Loss: 0.00012605438496393617, Final Batch Loss: 1.1291578630334698e-05\n",
      "Epoch 4831, Loss: 0.00020657524510170333, Final Batch Loss: 1.6535614122403786e-05\n",
      "Epoch 4832, Loss: 0.00010244374607282225, Final Batch Loss: 8.530972263542935e-05\n",
      "Epoch 4833, Loss: 0.0011143620613438543, Final Batch Loss: 2.36192972806748e-05\n",
      "Epoch 4834, Loss: 0.004736834147479385, Final Batch Loss: 0.000960067322012037\n",
      "Epoch 4835, Loss: 0.0029511937227653107, Final Batch Loss: 6.566411684616469e-06\n",
      "Epoch 4836, Loss: 0.001021755910187494, Final Batch Loss: 6.186390965012833e-05\n",
      "Epoch 4837, Loss: 0.0003994352555309888, Final Batch Loss: 1.8592047126730904e-05\n",
      "Epoch 4838, Loss: 9.278018478653394e-05, Final Batch Loss: 6.12039802945219e-05\n",
      "Epoch 4839, Loss: 0.00011713494495779742, Final Batch Loss: 8.715407602721825e-05\n",
      "Epoch 4840, Loss: 6.1021763940516394e-05, Final Batch Loss: 4.8285717639373615e-05\n",
      "Epoch 4841, Loss: 0.0023816922002879437, Final Batch Loss: 0.0023636973928660154\n",
      "Epoch 4842, Loss: 0.00028954448498552665, Final Batch Loss: 5.661567411152646e-05\n",
      "Epoch 4843, Loss: 4.6943678171373904e-05, Final Batch Loss: 3.909568476956338e-05\n",
      "Epoch 4844, Loss: 0.000639603691524826, Final Batch Loss: 0.00023359515762422234\n",
      "Epoch 4845, Loss: 0.002435918024275452, Final Batch Loss: 0.00035192008363083005\n",
      "Epoch 4846, Loss: 0.0001728243769321125, Final Batch Loss: 0.00016460230108350515\n",
      "Epoch 4847, Loss: 0.00019080871788901277, Final Batch Loss: 5.700828114640899e-05\n",
      "Epoch 4848, Loss: 3.152649492221826e-05, Final Batch Loss: 2.740776608334272e-06\n",
      "Epoch 4849, Loss: 0.0020562504651024938, Final Batch Loss: 0.0009311478352174163\n",
      "Epoch 4850, Loss: 0.0006287342548603192, Final Batch Loss: 0.00010508364357519895\n",
      "Epoch 4851, Loss: 0.0008679016755195335, Final Batch Loss: 0.0008490647305734456\n",
      "Epoch 4852, Loss: 7.137161765058408e-05, Final Batch Loss: 6.662415671598865e-06\n",
      "Epoch 4853, Loss: 0.00011941873344767373, Final Batch Loss: 0.00010679113620426506\n",
      "Epoch 4854, Loss: 0.0006517426518257707, Final Batch Loss: 0.00018728096620179713\n",
      "Epoch 4855, Loss: 0.00028766898321919143, Final Batch Loss: 0.00013994280016049743\n",
      "Epoch 4856, Loss: 3.068395722038986e-05, Final Batch Loss: 2.81707775684481e-06\n",
      "Epoch 4857, Loss: 8.094998702290468e-05, Final Batch Loss: 3.222941086278297e-05\n",
      "Epoch 4858, Loss: 0.00014330208068713546, Final Batch Loss: 3.864914469886571e-05\n",
      "Epoch 4859, Loss: 0.0025769699259399204, Final Batch Loss: 0.002561259316280484\n",
      "Epoch 4860, Loss: 8.873030310496688e-05, Final Batch Loss: 2.9077313229208812e-05\n",
      "Epoch 4861, Loss: 0.00011041003381251357, Final Batch Loss: 5.8480862207943574e-05\n",
      "Epoch 4862, Loss: 0.0008681332838023081, Final Batch Loss: 6.17434416199103e-05\n",
      "Epoch 4863, Loss: 6.109341438786942e-05, Final Batch Loss: 4.804368927580072e-06\n",
      "Epoch 4864, Loss: 0.0004392223672766704, Final Batch Loss: 5.8046472986461595e-05\n",
      "Epoch 4865, Loss: 0.0010035742197942454, Final Batch Loss: 4.3733500206144527e-05\n",
      "Epoch 4866, Loss: 0.0013279174017952755, Final Batch Loss: 0.0011735070729628205\n",
      "Epoch 4867, Loss: 0.0023904681438580155, Final Batch Loss: 0.0002429391024634242\n",
      "Epoch 4868, Loss: 0.00024515037694072817, Final Batch Loss: 7.95167034084443e-06\n",
      "Epoch 4869, Loss: 0.00026164395490013703, Final Batch Loss: 2.5121796625171555e-06\n",
      "Epoch 4870, Loss: 0.0001960630288522225, Final Batch Loss: 0.0001712238445179537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4871, Loss: 2.94776955342968e-05, Final Batch Loss: 1.4494933566311374e-05\n",
      "Epoch 4872, Loss: 8.618009178462671e-05, Final Batch Loss: 8.201852324418724e-05\n",
      "Epoch 4873, Loss: 0.0009867958269751398, Final Batch Loss: 1.5794195860507898e-05\n",
      "Epoch 4874, Loss: 0.00012963916105945827, Final Batch Loss: 0.00011984672164544463\n",
      "Epoch 4875, Loss: 0.0004371376853669062, Final Batch Loss: 8.627046190667897e-05\n",
      "Epoch 4876, Loss: 0.00026903641264652833, Final Batch Loss: 9.682396921562031e-05\n",
      "Epoch 4877, Loss: 0.008623289177194238, Final Batch Loss: 0.0012270587030798197\n",
      "Epoch 4878, Loss: 0.00028374743124004453, Final Batch Loss: 0.0002081408747471869\n",
      "Epoch 4879, Loss: 0.0001678028238529805, Final Batch Loss: 0.00011019869998563081\n",
      "Epoch 4880, Loss: 0.0014514115027850494, Final Batch Loss: 0.0013626719592139125\n",
      "Epoch 4881, Loss: 0.0011212934500690608, Final Batch Loss: 6.459000815084437e-06\n",
      "Epoch 4882, Loss: 0.0002545963870943524, Final Batch Loss: 0.00020905700512230396\n",
      "Epoch 4883, Loss: 0.0001328485377598554, Final Batch Loss: 0.00010870918049477041\n",
      "Epoch 4884, Loss: 0.010542645453824662, Final Batch Loss: 0.010510053485631943\n",
      "Epoch 4885, Loss: 0.0012898373533971608, Final Batch Loss: 0.0011209668591618538\n",
      "Epoch 4886, Loss: 0.003595106520151603, Final Batch Loss: 1.2205198800074868e-05\n",
      "Epoch 4887, Loss: 0.00020819465862587094, Final Batch Loss: 1.7601967556402087e-05\n",
      "Epoch 4888, Loss: 0.0015776133368490264, Final Batch Loss: 9.79227916104719e-05\n",
      "Epoch 4889, Loss: 0.004869754004175775, Final Batch Loss: 0.00020564212172757834\n",
      "Epoch 4890, Loss: 4.0567272662883624e-05, Final Batch Loss: 2.84984489553608e-05\n",
      "Epoch 4891, Loss: 6.592016325157601e-05, Final Batch Loss: 1.5642837752238847e-05\n",
      "Epoch 4892, Loss: 9.002057231555227e-05, Final Batch Loss: 9.098761438508518e-06\n",
      "Epoch 4893, Loss: 0.015351687674410641, Final Batch Loss: 0.0008475465001538396\n",
      "Epoch 4894, Loss: 0.004357727586466353, Final Batch Loss: 9.50627654674463e-05\n",
      "Epoch 4895, Loss: 0.00016193389365071198, Final Batch Loss: 1.482006973674288e-05\n",
      "Epoch 4896, Loss: 0.0002706697559915483, Final Batch Loss: 0.00015651999274268746\n",
      "Epoch 4897, Loss: 0.0005398383946157992, Final Batch Loss: 0.0003641668299678713\n",
      "Epoch 4898, Loss: 0.0013297500263433903, Final Batch Loss: 0.00027820441755466163\n",
      "Epoch 4899, Loss: 0.00024167163064703345, Final Batch Loss: 0.00020791323913726956\n",
      "Epoch 4900, Loss: 0.008532117935828865, Final Batch Loss: 0.008062749169766903\n",
      "Epoch 4901, Loss: 0.00038292044337140396, Final Batch Loss: 0.0003062829200644046\n",
      "Epoch 4902, Loss: 0.00041590030559746083, Final Batch Loss: 3.0517103368765675e-05\n",
      "Epoch 4903, Loss: 0.004443605785127147, Final Batch Loss: 1.1647940482362173e-05\n",
      "Epoch 4904, Loss: 0.004221901916025672, Final Batch Loss: 2.658708399394527e-05\n",
      "Epoch 4905, Loss: 0.00412439982756041, Final Batch Loss: 0.0039071328938007355\n",
      "Epoch 4906, Loss: 0.0002179332368541509, Final Batch Loss: 4.730580258183181e-05\n",
      "Epoch 4907, Loss: 0.0001364432209811639, Final Batch Loss: 0.00010783608013298362\n",
      "Epoch 4908, Loss: 0.0032282145984936506, Final Batch Loss: 0.00013450582628138363\n",
      "Epoch 4909, Loss: 0.0001522267521067988, Final Batch Loss: 0.00011230627569602802\n",
      "Epoch 4910, Loss: 5.079908987681847e-05, Final Batch Loss: 1.897245783766266e-05\n",
      "Epoch 4911, Loss: 0.0006565758376382291, Final Batch Loss: 0.0004657890531234443\n",
      "Epoch 4912, Loss: 0.00042096578181372024, Final Batch Loss: 0.00038969528395682573\n",
      "Epoch 4913, Loss: 0.0006451837543863803, Final Batch Loss: 0.0003436896950006485\n",
      "Epoch 4914, Loss: 7.19169111107476e-05, Final Batch Loss: 3.2723684853408486e-05\n",
      "Epoch 4915, Loss: 8.726642136025475e-05, Final Batch Loss: 1.2744251762342174e-05\n",
      "Epoch 4916, Loss: 0.00418790134426672, Final Batch Loss: 7.536572229582816e-05\n",
      "Epoch 4917, Loss: 0.0030235728263505735, Final Batch Loss: 6.861807923996821e-05\n",
      "Epoch 4918, Loss: 0.0001837075687944889, Final Batch Loss: 3.5082397516816854e-05\n",
      "Epoch 4919, Loss: 0.0002371387672610581, Final Batch Loss: 0.00011943817662540823\n",
      "Epoch 4920, Loss: 0.0005363600357668474, Final Batch Loss: 0.00013231411867309362\n",
      "Epoch 4921, Loss: 2.8888886845379602e-05, Final Batch Loss: 1.0949001989501994e-05\n",
      "Epoch 4922, Loss: 0.0124689173680963, Final Batch Loss: 0.012260088697075844\n",
      "Epoch 4923, Loss: 3.6256354633223964e-05, Final Batch Loss: 6.6376755967212375e-06\n",
      "Epoch 4924, Loss: 0.00016329047866747715, Final Batch Loss: 4.070824434165843e-05\n",
      "Epoch 4925, Loss: 0.0006466841223300435, Final Batch Loss: 3.630415449151769e-05\n",
      "Epoch 4926, Loss: 0.00010592959733912721, Final Batch Loss: 5.384225369198248e-05\n",
      "Epoch 4927, Loss: 0.0002761948271654546, Final Batch Loss: 6.510030652862042e-05\n",
      "Epoch 4928, Loss: 0.016272713226499036, Final Batch Loss: 5.675925058312714e-05\n",
      "Epoch 4929, Loss: 0.00031754281371831894, Final Batch Loss: 0.00014755531447008252\n",
      "Epoch 4930, Loss: 4.7750196245033294e-05, Final Batch Loss: 2.5759198251762427e-05\n",
      "Epoch 4931, Loss: 0.00026093733322340995, Final Batch Loss: 0.000131421911646612\n",
      "Epoch 4932, Loss: 0.00022190628806129098, Final Batch Loss: 3.779739199671894e-05\n",
      "Epoch 4933, Loss: 0.01495636579056736, Final Batch Loss: 0.01490023359656334\n",
      "Epoch 4934, Loss: 0.0009212838431267301, Final Batch Loss: 1.861183591245208e-05\n",
      "Epoch 4935, Loss: 8.957076715887524e-05, Final Batch Loss: 6.885453331051394e-05\n",
      "Epoch 4936, Loss: 0.0008905028953449801, Final Batch Loss: 0.0006975047290325165\n",
      "Epoch 4937, Loss: 0.00011343526421114802, Final Batch Loss: 3.817556716967374e-05\n",
      "Epoch 4938, Loss: 0.0002913382813858334, Final Batch Loss: 2.4461569410050288e-05\n",
      "Epoch 4939, Loss: 3.214141270291293e-05, Final Batch Loss: 1.0963330169033725e-05\n",
      "Epoch 4940, Loss: 0.00047066037950571626, Final Batch Loss: 0.0002486030862201005\n",
      "Epoch 4941, Loss: 8.175910261343233e-05, Final Batch Loss: 4.917342812404968e-05\n",
      "Epoch 4942, Loss: 0.00013118489005137235, Final Batch Loss: 9.172422142000869e-05\n",
      "Epoch 4943, Loss: 0.00031871290411800146, Final Batch Loss: 0.00010860055044759065\n",
      "Epoch 4944, Loss: 0.009242179345164914, Final Batch Loss: 9.490410593571141e-05\n",
      "Epoch 4945, Loss: 0.0006345101555780275, Final Batch Loss: 0.0006282548420131207\n",
      "Epoch 4946, Loss: 3.27368770740577e-05, Final Batch Loss: 8.857780812832061e-06\n",
      "Epoch 4947, Loss: 5.4200837894313736e-05, Final Batch Loss: 7.263253337441711e-06\n",
      "Epoch 4948, Loss: 0.001149346491729375, Final Batch Loss: 8.276351582026109e-05\n",
      "Epoch 4949, Loss: 0.00023915301062515937, Final Batch Loss: 0.00020419905195012689\n",
      "Epoch 4950, Loss: 0.0003454008183325641, Final Batch Loss: 0.0002587693161331117\n",
      "Epoch 4951, Loss: 0.00012097573198843747, Final Batch Loss: 5.2301897085271776e-05\n",
      "Epoch 4952, Loss: 0.0019406913197599351, Final Batch Loss: 0.001063685747794807\n",
      "Epoch 4953, Loss: 0.0012323989321885165, Final Batch Loss: 0.0011968298349529505\n",
      "Epoch 4954, Loss: 0.0019694171387527604, Final Batch Loss: 7.155864295782521e-06\n",
      "Epoch 4955, Loss: 0.0011229503061258583, Final Batch Loss: 1.0388982445874717e-05\n",
      "Epoch 4956, Loss: 0.0017732572741806507, Final Batch Loss: 0.0012654728488996625\n",
      "Epoch 4957, Loss: 8.206784696085379e-05, Final Batch Loss: 3.2020117942010984e-05\n",
      "Epoch 4958, Loss: 0.000498093810165301, Final Batch Loss: 0.0004211976192891598\n",
      "Epoch 4959, Loss: 0.0007128060742616071, Final Batch Loss: 0.0007080883369781077\n",
      "Epoch 4960, Loss: 0.0030947125524107832, Final Batch Loss: 5.321442222339101e-05\n",
      "Epoch 4961, Loss: 0.0004929434944642708, Final Batch Loss: 0.00010255449160467833\n",
      "Epoch 4962, Loss: 0.013658500043675303, Final Batch Loss: 0.010479926131665707\n",
      "Epoch 4963, Loss: 0.00039415123319486156, Final Batch Loss: 8.134370000334457e-05\n",
      "Epoch 4964, Loss: 0.00032882886443985626, Final Batch Loss: 8.334923040820286e-05\n",
      "Epoch 4965, Loss: 0.0005536628923437092, Final Batch Loss: 2.853118712664582e-05\n",
      "Epoch 4966, Loss: 0.00012495276314439252, Final Batch Loss: 9.060020965989679e-05\n",
      "Epoch 4967, Loss: 0.00016953679005382583, Final Batch Loss: 0.00014504142745863646\n",
      "Epoch 4968, Loss: 0.00024180525360861793, Final Batch Loss: 5.593097739620134e-05\n",
      "Epoch 4969, Loss: 0.0008597750238550361, Final Batch Loss: 4.284569513401948e-05\n",
      "Epoch 4970, Loss: 0.0055986443476285785, Final Batch Loss: 0.0002806113043334335\n",
      "Epoch 4971, Loss: 0.000208769957680488, Final Batch Loss: 3.200040737283416e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4972, Loss: 0.0011068337480537593, Final Batch Loss: 0.00015148607781156898\n",
      "Epoch 4973, Loss: 5.244573185336776e-05, Final Batch Loss: 2.5341883883811533e-05\n",
      "Epoch 4974, Loss: 0.0006102504266891629, Final Batch Loss: 7.088927668519318e-05\n",
      "Epoch 4975, Loss: 0.053342120721936226, Final Batch Loss: 0.0438234768807888\n",
      "Epoch 4976, Loss: 0.00010477547766640782, Final Batch Loss: 2.320507337572053e-05\n",
      "Epoch 4977, Loss: 0.0024040243442868814, Final Batch Loss: 0.0022539307828992605\n",
      "Epoch 4978, Loss: 0.0004416939045768231, Final Batch Loss: 0.00014741247287020087\n",
      "Epoch 4979, Loss: 0.000994931921013631, Final Batch Loss: 9.390486229676753e-05\n",
      "Epoch 4980, Loss: 0.004964681051205844, Final Batch Loss: 0.0007880820776335895\n",
      "Epoch 4981, Loss: 0.011447693570517004, Final Batch Loss: 0.0004784570774063468\n",
      "Epoch 4982, Loss: 0.003932070641894825, Final Batch Loss: 0.00016821474127937108\n",
      "Epoch 4983, Loss: 0.0016932617290876806, Final Batch Loss: 0.0013645726721733809\n",
      "Epoch 4984, Loss: 0.00027483156009111553, Final Batch Loss: 2.153952664230019e-05\n",
      "Epoch 4985, Loss: 0.0010472975718585076, Final Batch Loss: 0.0010351252276450396\n",
      "Epoch 4986, Loss: 0.000489290920086205, Final Batch Loss: 4.002643981948495e-05\n",
      "Epoch 4987, Loss: 0.0005647020516335033, Final Batch Loss: 8.05523814051412e-05\n",
      "Epoch 4988, Loss: 0.00042301944449718576, Final Batch Loss: 2.185073208238464e-05\n",
      "Epoch 4989, Loss: 0.00027378876984585077, Final Batch Loss: 4.03906888095662e-05\n",
      "Epoch 4990, Loss: 0.005284066224703565, Final Batch Loss: 0.0003925276978407055\n",
      "Epoch 4991, Loss: 0.000434402420069091, Final Batch Loss: 5.191254604142159e-05\n",
      "Epoch 4992, Loss: 0.00037983546462783124, Final Batch Loss: 0.00035755205317400396\n",
      "Epoch 4993, Loss: 0.00043055865535279736, Final Batch Loss: 8.371841249754652e-05\n",
      "Epoch 4994, Loss: 0.0005048886123404372, Final Batch Loss: 5.1510014600353315e-05\n",
      "Epoch 4995, Loss: 0.00043534474389161915, Final Batch Loss: 0.0001374800776829943\n",
      "Epoch 4996, Loss: 0.000510581157868728, Final Batch Loss: 0.00044738411088474095\n",
      "Epoch 4997, Loss: 0.0013419197530311067, Final Batch Loss: 0.0013091110158711672\n",
      "Epoch 4998, Loss: 0.00023126073392631952, Final Batch Loss: 2.608332761155907e-05\n",
      "Epoch 4999, Loss: 0.00017192758423334453, Final Batch Loss: 3.0053221053094603e-05\n",
      "Epoch 5000, Loss: 0.0011042484911740758, Final Batch Loss: 9.683069220045581e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43  0  0]\n",
      " [ 1 29  0]\n",
      " [ 0  0 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97727   1.00000   0.98851        43\n",
      "           1    1.00000   0.96667   0.98305        30\n",
      "           2    1.00000   1.00000   1.00000        27\n",
      "\n",
      "    accuracy                        0.99000       100\n",
      "   macro avg    0.99242   0.98889   0.99052       100\n",
      "weighted avg    0.99023   0.99000   0.98997       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A0 Solo GAN_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_1 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A0 Solo GAN_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_2 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A0 Solo GAN_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_3 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_1 = np.zeros(n_samples * 3)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A1 Solo GAN_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_4 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A1 Solo GAN_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_5 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A1 Solo GAN_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_6 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_2 = np.ones(n_samples * 3)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A2 Solo GAN_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_7 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A2 Solo GAN_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_8 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A2 Solo GAN_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_9 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_3 = np.ones(n_samples * 3) + 1\n",
    "\n",
    "fake_features = np.concatenate((fake_features_1, fake_features_2, fake_features_3, fake_features_4, fake_features_5, fake_features_6,\n",
    "                         fake_features_7, fake_features_8, fake_features_9))\n",
    "fake_labels = np.concatenate((y_1, y_2, y_3))\n",
    "\n",
    "fake_features = torch.Tensor(fake_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  0  0]\n",
      " [ 0 30  0]\n",
      " [ 0  0 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    1.00000   1.00000   1.00000        30\n",
      "         1.0    1.00000   1.00000   1.00000        30\n",
      "         2.0    1.00000   1.00000   1.00000        30\n",
      "\n",
      "    accuracy                        1.00000        90\n",
      "   macro avg    1.00000   1.00000   1.00000        90\n",
      "weighted avg    1.00000   1.00000   1.00000        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix((fake_labels), preds.cpu()))\n",
    "print(metrics.classification_report((fake_labels), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.609975576400757, Final Batch Loss: 2.3012683391571045\n",
      "Epoch 2, Loss: 4.586054086685181, Final Batch Loss: 2.289593458175659\n",
      "Epoch 3, Loss: 4.565965414047241, Final Batch Loss: 2.2710883617401123\n",
      "Epoch 4, Loss: 4.54191780090332, Final Batch Loss: 2.2621238231658936\n",
      "Epoch 5, Loss: 4.524929046630859, Final Batch Loss: 2.256298303604126\n",
      "Epoch 6, Loss: 4.510240793228149, Final Batch Loss: 2.2469875812530518\n",
      "Epoch 7, Loss: 4.500760078430176, Final Batch Loss: 2.254378318786621\n",
      "Epoch 8, Loss: 4.479606866836548, Final Batch Loss: 2.2345523834228516\n",
      "Epoch 9, Loss: 4.470067024230957, Final Batch Loss: 2.2366249561309814\n",
      "Epoch 10, Loss: 4.462719440460205, Final Batch Loss: 2.241452932357788\n",
      "Epoch 11, Loss: 4.446505546569824, Final Batch Loss: 2.2324743270874023\n",
      "Epoch 12, Loss: 4.432318687438965, Final Batch Loss: 2.2143406867980957\n",
      "Epoch 13, Loss: 4.424461841583252, Final Batch Loss: 2.21889591217041\n",
      "Epoch 14, Loss: 4.409650802612305, Final Batch Loss: 2.1961886882781982\n",
      "Epoch 15, Loss: 4.4068284034729, Final Batch Loss: 2.206620931625366\n",
      "Epoch 16, Loss: 4.399400234222412, Final Batch Loss: 2.2012946605682373\n",
      "Epoch 17, Loss: 4.3905229568481445, Final Batch Loss: 2.1965725421905518\n",
      "Epoch 18, Loss: 4.377859115600586, Final Batch Loss: 2.1813740730285645\n",
      "Epoch 19, Loss: 4.373084545135498, Final Batch Loss: 2.1826372146606445\n",
      "Epoch 20, Loss: 4.3618292808532715, Final Batch Loss: 2.170806407928467\n",
      "Epoch 21, Loss: 4.358198404312134, Final Batch Loss: 2.1743104457855225\n",
      "Epoch 22, Loss: 4.348602056503296, Final Batch Loss: 2.175260543823242\n",
      "Epoch 23, Loss: 4.343673467636108, Final Batch Loss: 2.1725966930389404\n",
      "Epoch 24, Loss: 4.339481353759766, Final Batch Loss: 2.1720540523529053\n",
      "Epoch 25, Loss: 4.328256130218506, Final Batch Loss: 2.1660408973693848\n",
      "Epoch 26, Loss: 4.3140833377838135, Final Batch Loss: 2.156141996383667\n",
      "Epoch 27, Loss: 4.305495023727417, Final Batch Loss: 2.1482300758361816\n",
      "Epoch 28, Loss: 4.291868448257446, Final Batch Loss: 2.135652542114258\n",
      "Epoch 29, Loss: 4.2861669063568115, Final Batch Loss: 2.145414352416992\n",
      "Epoch 30, Loss: 4.256210565567017, Final Batch Loss: 2.1179399490356445\n",
      "Epoch 31, Loss: 4.24735164642334, Final Batch Loss: 2.1208043098449707\n",
      "Epoch 32, Loss: 4.220613241195679, Final Batch Loss: 2.1068661212921143\n",
      "Epoch 33, Loss: 4.204419136047363, Final Batch Loss: 2.1091864109039307\n",
      "Epoch 34, Loss: 4.165334463119507, Final Batch Loss: 2.0740444660186768\n",
      "Epoch 35, Loss: 4.135343074798584, Final Batch Loss: 2.076718807220459\n",
      "Epoch 36, Loss: 4.11763596534729, Final Batch Loss: 2.0600152015686035\n",
      "Epoch 37, Loss: 4.057932615280151, Final Batch Loss: 2.0140340328216553\n",
      "Epoch 38, Loss: 4.013642907142639, Final Batch Loss: 1.9968894720077515\n",
      "Epoch 39, Loss: 3.9945374727249146, Final Batch Loss: 1.9865392446517944\n",
      "Epoch 40, Loss: 3.8930972814559937, Final Batch Loss: 1.9279216527938843\n",
      "Epoch 41, Loss: 3.8666458129882812, Final Batch Loss: 1.9250766038894653\n",
      "Epoch 42, Loss: 3.798334240913391, Final Batch Loss: 1.9106820821762085\n",
      "Epoch 43, Loss: 3.7821766138076782, Final Batch Loss: 1.891550064086914\n",
      "Epoch 44, Loss: 3.7230175733566284, Final Batch Loss: 1.890376091003418\n",
      "Epoch 45, Loss: 3.6148263216018677, Final Batch Loss: 1.7743334770202637\n",
      "Epoch 46, Loss: 3.5925360918045044, Final Batch Loss: 1.8085274696350098\n",
      "Epoch 47, Loss: 3.5542229413986206, Final Batch Loss: 1.7766767740249634\n",
      "Epoch 48, Loss: 3.4892756938934326, Final Batch Loss: 1.741325855255127\n",
      "Epoch 49, Loss: 3.4395588636398315, Final Batch Loss: 1.6996753215789795\n",
      "Epoch 50, Loss: 3.307099938392639, Final Batch Loss: 1.6460564136505127\n",
      "Epoch 51, Loss: 3.268696427345276, Final Batch Loss: 1.6480982303619385\n",
      "Epoch 52, Loss: 3.2279738187789917, Final Batch Loss: 1.5797926187515259\n",
      "Epoch 53, Loss: 3.2109177112579346, Final Batch Loss: 1.643506407737732\n",
      "Epoch 54, Loss: 3.178073287010193, Final Batch Loss: 1.6201564073562622\n",
      "Epoch 55, Loss: 3.0057300329208374, Final Batch Loss: 1.5145752429962158\n",
      "Epoch 56, Loss: 2.9716074466705322, Final Batch Loss: 1.4866794347763062\n",
      "Epoch 57, Loss: 2.971176028251648, Final Batch Loss: 1.4992061853408813\n",
      "Epoch 58, Loss: 2.866825580596924, Final Batch Loss: 1.375913381576538\n",
      "Epoch 59, Loss: 2.8455921411514282, Final Batch Loss: 1.394208550453186\n",
      "Epoch 60, Loss: 2.7092140913009644, Final Batch Loss: 1.34513258934021\n",
      "Epoch 61, Loss: 2.750260829925537, Final Batch Loss: 1.3944435119628906\n",
      "Epoch 62, Loss: 2.6396217346191406, Final Batch Loss: 1.2920002937316895\n",
      "Epoch 63, Loss: 2.6008594036102295, Final Batch Loss: 1.315534234046936\n",
      "Epoch 64, Loss: 2.549081325531006, Final Batch Loss: 1.2993502616882324\n",
      "Epoch 65, Loss: 2.5544968843460083, Final Batch Loss: 1.2765854597091675\n",
      "Epoch 66, Loss: 2.494879364967346, Final Batch Loss: 1.2616747617721558\n",
      "Epoch 67, Loss: 2.4296014308929443, Final Batch Loss: 1.2083522081375122\n",
      "Epoch 68, Loss: 2.398201584815979, Final Batch Loss: 1.2040417194366455\n",
      "Epoch 69, Loss: 2.3965046405792236, Final Batch Loss: 1.194989800453186\n",
      "Epoch 70, Loss: 2.441840410232544, Final Batch Loss: 1.236034870147705\n",
      "Epoch 71, Loss: 2.3336877822875977, Final Batch Loss: 1.145506739616394\n",
      "Epoch 72, Loss: 2.352285146713257, Final Batch Loss: 1.1349282264709473\n",
      "Epoch 73, Loss: 2.314248561859131, Final Batch Loss: 1.185705542564392\n",
      "Epoch 74, Loss: 2.2751656770706177, Final Batch Loss: 1.1312686204910278\n",
      "Epoch 75, Loss: 2.296716809272766, Final Batch Loss: 1.1494245529174805\n",
      "Epoch 76, Loss: 2.328518867492676, Final Batch Loss: 1.1714587211608887\n",
      "Epoch 77, Loss: 2.2938523292541504, Final Batch Loss: 1.1573091745376587\n",
      "Epoch 78, Loss: 2.29548180103302, Final Batch Loss: 1.1333436965942383\n",
      "Epoch 79, Loss: 2.3028212785720825, Final Batch Loss: 1.1472159624099731\n",
      "Epoch 80, Loss: 2.2911990880966187, Final Batch Loss: 1.1519595384597778\n",
      "Epoch 81, Loss: 2.316360592842102, Final Batch Loss: 1.1579457521438599\n",
      "Epoch 82, Loss: 2.203984260559082, Final Batch Loss: 1.0998778343200684\n",
      "Epoch 83, Loss: 2.2917213439941406, Final Batch Loss: 1.1483252048492432\n",
      "Epoch 84, Loss: 2.346217393875122, Final Batch Loss: 1.1925307512283325\n",
      "Epoch 85, Loss: 2.288499116897583, Final Batch Loss: 1.1307427883148193\n",
      "Epoch 86, Loss: 2.2601429224014282, Final Batch Loss: 1.13738214969635\n",
      "Epoch 87, Loss: 2.2804828882217407, Final Batch Loss: 1.1506218910217285\n",
      "Epoch 88, Loss: 2.251397132873535, Final Batch Loss: 1.1361411809921265\n",
      "Epoch 89, Loss: 2.259348750114441, Final Batch Loss: 1.1424329280853271\n",
      "Epoch 90, Loss: 2.2203339338302612, Final Batch Loss: 1.1029664278030396\n",
      "Epoch 91, Loss: 2.2825214862823486, Final Batch Loss: 1.1469433307647705\n",
      "Epoch 92, Loss: 2.1892729997634888, Final Batch Loss: 1.0989409685134888\n",
      "Epoch 93, Loss: 2.2343560457229614, Final Batch Loss: 1.0969957113265991\n",
      "Epoch 94, Loss: 2.2518361806869507, Final Batch Loss: 1.1275907754898071\n",
      "Epoch 95, Loss: 2.199188709259033, Final Batch Loss: 1.1079432964324951\n",
      "Epoch 96, Loss: 2.2102010250091553, Final Batch Loss: 1.105625867843628\n",
      "Epoch 97, Loss: 2.1690402030944824, Final Batch Loss: 1.1003936529159546\n",
      "Epoch 98, Loss: 2.188093423843384, Final Batch Loss: 1.0849791765213013\n",
      "Epoch 99, Loss: 2.199339747428894, Final Batch Loss: 1.105637788772583\n",
      "Epoch 100, Loss: 2.242216110229492, Final Batch Loss: 1.1595326662063599\n",
      "Epoch 101, Loss: 2.183675169944763, Final Batch Loss: 1.0691237449645996\n",
      "Epoch 102, Loss: 2.197891354560852, Final Batch Loss: 1.111457109451294\n",
      "Epoch 103, Loss: 2.217321038246155, Final Batch Loss: 1.1255897283554077\n",
      "Epoch 104, Loss: 2.219973087310791, Final Batch Loss: 1.133920669555664\n",
      "Epoch 105, Loss: 2.16497540473938, Final Batch Loss: 1.073753833770752\n",
      "Epoch 106, Loss: 2.149180054664612, Final Batch Loss: 1.0497119426727295\n",
      "Epoch 107, Loss: 2.176331877708435, Final Batch Loss: 1.08726966381073\n",
      "Epoch 108, Loss: 2.156797170639038, Final Batch Loss: 1.1018720865249634\n",
      "Epoch 109, Loss: 2.1549469232559204, Final Batch Loss: 1.102250099182129\n",
      "Epoch 110, Loss: 2.1146490573883057, Final Batch Loss: 1.03165602684021\n",
      "Epoch 111, Loss: 2.1448819637298584, Final Batch Loss: 1.0940653085708618\n",
      "Epoch 112, Loss: 2.128340482711792, Final Batch Loss: 1.0678482055664062\n",
      "Epoch 113, Loss: 2.1118643283843994, Final Batch Loss: 1.0516117811203003\n",
      "Epoch 114, Loss: 2.112576723098755, Final Batch Loss: 1.0516294240951538\n",
      "Epoch 115, Loss: 2.1085132360458374, Final Batch Loss: 1.0341310501098633\n",
      "Epoch 116, Loss: 2.072063684463501, Final Batch Loss: 1.057572841644287\n",
      "Epoch 117, Loss: 2.1369576454162598, Final Batch Loss: 1.0628252029418945\n",
      "Epoch 118, Loss: 2.081536054611206, Final Batch Loss: 1.0160001516342163\n",
      "Epoch 119, Loss: 2.1056764125823975, Final Batch Loss: 1.0679190158843994\n",
      "Epoch 120, Loss: 2.0899726152420044, Final Batch Loss: 1.0431230068206787\n",
      "Epoch 121, Loss: 2.0767499208450317, Final Batch Loss: 1.0123857259750366\n",
      "Epoch 122, Loss: 2.1182748079299927, Final Batch Loss: 1.0589988231658936\n",
      "Epoch 123, Loss: 2.0998719930648804, Final Batch Loss: 1.0543904304504395\n",
      "Epoch 124, Loss: 2.063885807991028, Final Batch Loss: 1.0380668640136719\n",
      "Epoch 125, Loss: 2.074655771255493, Final Batch Loss: 1.052356481552124\n",
      "Epoch 126, Loss: 2.066397786140442, Final Batch Loss: 1.0207905769348145\n",
      "Epoch 127, Loss: 2.01543790102005, Final Batch Loss: 0.9864458441734314\n",
      "Epoch 128, Loss: 2.0445427894592285, Final Batch Loss: 1.0220545530319214\n",
      "Epoch 129, Loss: 2.0173338651657104, Final Batch Loss: 1.0096352100372314\n",
      "Epoch 130, Loss: 1.9967935681343079, Final Batch Loss: 1.0084927082061768\n",
      "Epoch 131, Loss: 1.9977202415466309, Final Batch Loss: 0.9818702936172485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132, Loss: 2.0259915590286255, Final Batch Loss: 1.033648133277893\n",
      "Epoch 133, Loss: 1.9803404211997986, Final Batch Loss: 0.9971688389778137\n",
      "Epoch 134, Loss: 1.987761914730072, Final Batch Loss: 0.9940436482429504\n",
      "Epoch 135, Loss: 1.9792904257774353, Final Batch Loss: 1.003831148147583\n",
      "Epoch 136, Loss: 2.013852894306183, Final Batch Loss: 1.018222689628601\n",
      "Epoch 137, Loss: 2.002758264541626, Final Batch Loss: 1.0083550214767456\n",
      "Epoch 138, Loss: 1.9693964123725891, Final Batch Loss: 1.0003585815429688\n",
      "Epoch 139, Loss: 1.9465965628623962, Final Batch Loss: 0.9644733667373657\n",
      "Epoch 140, Loss: 1.9141857624053955, Final Batch Loss: 0.9590333700180054\n",
      "Epoch 141, Loss: 1.9132484197616577, Final Batch Loss: 0.9690902829170227\n",
      "Epoch 142, Loss: 1.9015824794769287, Final Batch Loss: 0.9580671787261963\n",
      "Epoch 143, Loss: 1.9448322057724, Final Batch Loss: 0.9889278411865234\n",
      "Epoch 144, Loss: 1.8992788195610046, Final Batch Loss: 0.9320835471153259\n",
      "Epoch 145, Loss: 1.8529087901115417, Final Batch Loss: 0.9139159321784973\n",
      "Epoch 146, Loss: 1.890443205833435, Final Batch Loss: 0.923309862613678\n",
      "Epoch 147, Loss: 1.8518596291542053, Final Batch Loss: 0.9190938472747803\n",
      "Epoch 148, Loss: 1.8931873440742493, Final Batch Loss: 0.9674364924430847\n",
      "Epoch 149, Loss: 1.8254279494285583, Final Batch Loss: 0.923972487449646\n",
      "Epoch 150, Loss: 1.8538365364074707, Final Batch Loss: 0.9292877316474915\n",
      "Epoch 151, Loss: 1.7947866916656494, Final Batch Loss: 0.9072675704956055\n",
      "Epoch 152, Loss: 1.783292293548584, Final Batch Loss: 0.9011289477348328\n",
      "Epoch 153, Loss: 1.8439297080039978, Final Batch Loss: 0.9113664627075195\n",
      "Epoch 154, Loss: 1.84824538230896, Final Batch Loss: 0.9304105639457703\n",
      "Epoch 155, Loss: 1.8229045271873474, Final Batch Loss: 0.9098103642463684\n",
      "Epoch 156, Loss: 1.8168230056762695, Final Batch Loss: 0.9380749464035034\n",
      "Epoch 157, Loss: 1.7693461775779724, Final Batch Loss: 0.8933088779449463\n",
      "Epoch 158, Loss: 1.7476390600204468, Final Batch Loss: 0.8497627377510071\n",
      "Epoch 159, Loss: 1.7730422019958496, Final Batch Loss: 0.8684415221214294\n",
      "Epoch 160, Loss: 1.7771469950675964, Final Batch Loss: 0.8843936920166016\n",
      "Epoch 161, Loss: 1.7568029761314392, Final Batch Loss: 0.8619607090950012\n",
      "Epoch 162, Loss: 1.830666422843933, Final Batch Loss: 0.9612569212913513\n",
      "Epoch 163, Loss: 1.7446892261505127, Final Batch Loss: 0.8773512840270996\n",
      "Epoch 164, Loss: 1.7883338332176208, Final Batch Loss: 0.9205867052078247\n",
      "Epoch 165, Loss: 1.800935685634613, Final Batch Loss: 0.9377123713493347\n",
      "Epoch 166, Loss: 1.683587670326233, Final Batch Loss: 0.8066918253898621\n",
      "Epoch 167, Loss: 1.7383549809455872, Final Batch Loss: 0.8726151585578918\n",
      "Epoch 168, Loss: 1.6913982033729553, Final Batch Loss: 0.8279232382774353\n",
      "Epoch 169, Loss: 1.7076656818389893, Final Batch Loss: 0.8459787964820862\n",
      "Epoch 170, Loss: 1.7365784645080566, Final Batch Loss: 0.8782868385314941\n",
      "Epoch 171, Loss: 1.6917952299118042, Final Batch Loss: 0.8766371607780457\n",
      "Epoch 172, Loss: 1.7318329215049744, Final Batch Loss: 0.8777462840080261\n",
      "Epoch 173, Loss: 1.728114128112793, Final Batch Loss: 0.8604699969291687\n",
      "Epoch 174, Loss: 1.738740622997284, Final Batch Loss: 0.8568750023841858\n",
      "Epoch 175, Loss: 1.6783788800239563, Final Batch Loss: 0.8394176363945007\n",
      "Epoch 176, Loss: 1.6771097779273987, Final Batch Loss: 0.8201108574867249\n",
      "Epoch 177, Loss: 1.6804807782173157, Final Batch Loss: 0.834546685218811\n",
      "Epoch 178, Loss: 1.691032588481903, Final Batch Loss: 0.9041245579719543\n",
      "Epoch 179, Loss: 1.659009337425232, Final Batch Loss: 0.8309521675109863\n",
      "Epoch 180, Loss: 1.6620329022407532, Final Batch Loss: 0.780629575252533\n",
      "Epoch 181, Loss: 1.7190423011779785, Final Batch Loss: 0.916933536529541\n",
      "Epoch 182, Loss: 1.7227177619934082, Final Batch Loss: 0.8698215484619141\n",
      "Epoch 183, Loss: 1.662520945072174, Final Batch Loss: 0.8719515800476074\n",
      "Epoch 184, Loss: 1.667702078819275, Final Batch Loss: 0.8400814533233643\n",
      "Epoch 185, Loss: 1.5968588590621948, Final Batch Loss: 0.7826471924781799\n",
      "Epoch 186, Loss: 1.6278344988822937, Final Batch Loss: 0.8018311858177185\n",
      "Epoch 187, Loss: 1.7202397584915161, Final Batch Loss: 0.9163480997085571\n",
      "Epoch 188, Loss: 1.6943140625953674, Final Batch Loss: 0.860675573348999\n",
      "Epoch 189, Loss: 1.6279618740081787, Final Batch Loss: 0.7934919595718384\n",
      "Epoch 190, Loss: 1.6663391590118408, Final Batch Loss: 0.8175716996192932\n",
      "Epoch 191, Loss: 1.6620649695396423, Final Batch Loss: 0.8431434631347656\n",
      "Epoch 192, Loss: 1.6261186599731445, Final Batch Loss: 0.7970688343048096\n",
      "Epoch 193, Loss: 1.6148924827575684, Final Batch Loss: 0.8158217668533325\n",
      "Epoch 194, Loss: 1.5858315825462341, Final Batch Loss: 0.7662360072135925\n",
      "Epoch 195, Loss: 1.6170015931129456, Final Batch Loss: 0.7992479205131531\n",
      "Epoch 196, Loss: 1.585372805595398, Final Batch Loss: 0.7889394760131836\n",
      "Epoch 197, Loss: 1.6153882145881653, Final Batch Loss: 0.8511427044868469\n",
      "Epoch 198, Loss: 1.595643401145935, Final Batch Loss: 0.8258519172668457\n",
      "Epoch 199, Loss: 1.6428884863853455, Final Batch Loss: 0.8276218771934509\n",
      "Epoch 200, Loss: 1.5796718001365662, Final Batch Loss: 0.8040990829467773\n",
      "Epoch 201, Loss: 1.5442733764648438, Final Batch Loss: 0.7957225441932678\n",
      "Epoch 202, Loss: 1.5617057085037231, Final Batch Loss: 0.7734515070915222\n",
      "Epoch 203, Loss: 1.6063571572303772, Final Batch Loss: 0.8455522656440735\n",
      "Epoch 204, Loss: 1.6143940091133118, Final Batch Loss: 0.8024329543113708\n",
      "Epoch 205, Loss: 1.5329176187515259, Final Batch Loss: 0.7771074175834656\n",
      "Epoch 206, Loss: 1.5507968068122864, Final Batch Loss: 0.7930188775062561\n",
      "Epoch 207, Loss: 1.5030097961425781, Final Batch Loss: 0.7505558729171753\n",
      "Epoch 208, Loss: 1.4682932496070862, Final Batch Loss: 0.7681092619895935\n",
      "Epoch 209, Loss: 1.5521184206008911, Final Batch Loss: 0.808454692363739\n",
      "Epoch 210, Loss: 1.55245840549469, Final Batch Loss: 0.7754025459289551\n",
      "Epoch 211, Loss: 1.5231119990348816, Final Batch Loss: 0.759626030921936\n",
      "Epoch 212, Loss: 1.569594919681549, Final Batch Loss: 0.8351810574531555\n",
      "Epoch 213, Loss: 1.4951687455177307, Final Batch Loss: 0.7293217778205872\n",
      "Epoch 214, Loss: 1.5324282050132751, Final Batch Loss: 0.7526944875717163\n",
      "Epoch 215, Loss: 1.5107691884040833, Final Batch Loss: 0.7965750694274902\n",
      "Epoch 216, Loss: 1.539137601852417, Final Batch Loss: 0.7550987005233765\n",
      "Epoch 217, Loss: 1.4524755477905273, Final Batch Loss: 0.7577513456344604\n",
      "Epoch 218, Loss: 1.5013863444328308, Final Batch Loss: 0.7502897381782532\n",
      "Epoch 219, Loss: 1.4302555322647095, Final Batch Loss: 0.7235495448112488\n",
      "Epoch 220, Loss: 1.4920530915260315, Final Batch Loss: 0.7897798418998718\n",
      "Epoch 221, Loss: 1.4303449988365173, Final Batch Loss: 0.7046257257461548\n",
      "Epoch 222, Loss: 1.479701817035675, Final Batch Loss: 0.7313591837882996\n",
      "Epoch 223, Loss: 1.4701650142669678, Final Batch Loss: 0.7364166975021362\n",
      "Epoch 224, Loss: 1.4354737997055054, Final Batch Loss: 0.7617124915122986\n",
      "Epoch 225, Loss: 1.4355692863464355, Final Batch Loss: 0.6796251535415649\n",
      "Epoch 226, Loss: 1.4150884747505188, Final Batch Loss: 0.7388452291488647\n",
      "Epoch 227, Loss: 1.542376697063446, Final Batch Loss: 0.7837780714035034\n",
      "Epoch 228, Loss: 1.436265766620636, Final Batch Loss: 0.7196645736694336\n",
      "Epoch 229, Loss: 1.4189163446426392, Final Batch Loss: 0.6976703405380249\n",
      "Epoch 230, Loss: 1.3935786485671997, Final Batch Loss: 0.6372422575950623\n",
      "Epoch 231, Loss: 1.4439956545829773, Final Batch Loss: 0.7173165678977966\n",
      "Epoch 232, Loss: 1.4095796346664429, Final Batch Loss: 0.7435501217842102\n",
      "Epoch 233, Loss: 1.4166738986968994, Final Batch Loss: 0.66119384765625\n",
      "Epoch 234, Loss: 1.4307520985603333, Final Batch Loss: 0.7255417108535767\n",
      "Epoch 235, Loss: 1.3753719925880432, Final Batch Loss: 0.7029864192008972\n",
      "Epoch 236, Loss: 1.4603011012077332, Final Batch Loss: 0.6986231207847595\n",
      "Epoch 237, Loss: 1.4272557497024536, Final Batch Loss: 0.7399763464927673\n",
      "Epoch 238, Loss: 1.503498911857605, Final Batch Loss: 0.8489732146263123\n",
      "Epoch 239, Loss: 1.350500226020813, Final Batch Loss: 0.6182903051376343\n",
      "Epoch 240, Loss: 1.5187900066375732, Final Batch Loss: 0.7894746661186218\n",
      "Epoch 241, Loss: 1.389244258403778, Final Batch Loss: 0.7126170992851257\n",
      "Epoch 242, Loss: 1.41753751039505, Final Batch Loss: 0.7401277422904968\n",
      "Epoch 243, Loss: 1.428856909275055, Final Batch Loss: 0.7463856339454651\n",
      "Epoch 244, Loss: 1.3935455083847046, Final Batch Loss: 0.6629892587661743\n",
      "Epoch 245, Loss: 1.4116826057434082, Final Batch Loss: 0.7424625754356384\n",
      "Epoch 246, Loss: 1.3754106163978577, Final Batch Loss: 0.689070463180542\n",
      "Epoch 247, Loss: 1.3034549355506897, Final Batch Loss: 0.5950473546981812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248, Loss: 1.4582616090774536, Final Batch Loss: 0.7547324895858765\n",
      "Epoch 249, Loss: 1.395854890346527, Final Batch Loss: 0.7345539331436157\n",
      "Epoch 250, Loss: 1.43478262424469, Final Batch Loss: 0.7398431301116943\n",
      "Epoch 251, Loss: 1.4122412204742432, Final Batch Loss: 0.7184169292449951\n",
      "Epoch 252, Loss: 1.4265809655189514, Final Batch Loss: 0.7301911115646362\n",
      "Epoch 253, Loss: 1.2865977883338928, Final Batch Loss: 0.6051340699195862\n",
      "Epoch 254, Loss: 1.460637092590332, Final Batch Loss: 0.7156751155853271\n",
      "Epoch 255, Loss: 1.4376250505447388, Final Batch Loss: 0.7581589221954346\n",
      "Epoch 256, Loss: 1.3889211416244507, Final Batch Loss: 0.6728999614715576\n",
      "Epoch 257, Loss: 1.374009609222412, Final Batch Loss: 0.6949172616004944\n",
      "Epoch 258, Loss: 1.415930986404419, Final Batch Loss: 0.7359036207199097\n",
      "Epoch 259, Loss: 1.350686490535736, Final Batch Loss: 0.6223907470703125\n",
      "Epoch 260, Loss: 1.3143553733825684, Final Batch Loss: 0.6219771504402161\n",
      "Epoch 261, Loss: 1.3402056694030762, Final Batch Loss: 0.6602972149848938\n",
      "Epoch 262, Loss: 1.2830095291137695, Final Batch Loss: 0.5793471932411194\n",
      "Epoch 263, Loss: 1.3943222761154175, Final Batch Loss: 0.6638760566711426\n",
      "Epoch 264, Loss: 1.31850928068161, Final Batch Loss: 0.6467650532722473\n",
      "Epoch 265, Loss: 1.3814042806625366, Final Batch Loss: 0.6705513000488281\n",
      "Epoch 266, Loss: 1.3258878588676453, Final Batch Loss: 0.6224716305732727\n",
      "Epoch 267, Loss: 1.3262513279914856, Final Batch Loss: 0.6756708025932312\n",
      "Epoch 268, Loss: 1.313742458820343, Final Batch Loss: 0.6523346304893494\n",
      "Epoch 269, Loss: 1.3621063232421875, Final Batch Loss: 0.6976000070571899\n",
      "Epoch 270, Loss: 1.356839895248413, Final Batch Loss: 0.7160157561302185\n",
      "Epoch 271, Loss: 1.331659197807312, Final Batch Loss: 0.6109693050384521\n",
      "Epoch 272, Loss: 1.3677213191986084, Final Batch Loss: 0.6688335537910461\n",
      "Epoch 273, Loss: 1.3697759509086609, Final Batch Loss: 0.6956785917282104\n",
      "Epoch 274, Loss: 1.3823950290679932, Final Batch Loss: 0.7021605372428894\n",
      "Epoch 275, Loss: 1.3601382374763489, Final Batch Loss: 0.7039793133735657\n",
      "Epoch 276, Loss: 1.3249250054359436, Final Batch Loss: 0.6586297750473022\n",
      "Epoch 277, Loss: 1.2741782665252686, Final Batch Loss: 0.607322633266449\n",
      "Epoch 278, Loss: 1.3126725554466248, Final Batch Loss: 0.6523232460021973\n",
      "Epoch 279, Loss: 1.3464003801345825, Final Batch Loss: 0.6623740792274475\n",
      "Epoch 280, Loss: 1.3031408786773682, Final Batch Loss: 0.6774019598960876\n",
      "Epoch 281, Loss: 1.2994288802146912, Final Batch Loss: 0.6211244463920593\n",
      "Epoch 282, Loss: 1.3396133184432983, Final Batch Loss: 0.7006595134735107\n",
      "Epoch 283, Loss: 1.2698528170585632, Final Batch Loss: 0.6194703578948975\n",
      "Epoch 284, Loss: 1.2828014492988586, Final Batch Loss: 0.5886862277984619\n",
      "Epoch 285, Loss: 1.3621841669082642, Final Batch Loss: 0.6710851192474365\n",
      "Epoch 286, Loss: 1.3205692768096924, Final Batch Loss: 0.6677854657173157\n",
      "Epoch 287, Loss: 1.395145058631897, Final Batch Loss: 0.7027181386947632\n",
      "Epoch 288, Loss: 1.3135484457015991, Final Batch Loss: 0.6444675922393799\n",
      "Epoch 289, Loss: 1.321303129196167, Final Batch Loss: 0.7224981188774109\n",
      "Epoch 290, Loss: 1.2702832221984863, Final Batch Loss: 0.6299456357955933\n",
      "Epoch 291, Loss: 1.2580910921096802, Final Batch Loss: 0.6107670664787292\n",
      "Epoch 292, Loss: 1.2828187346458435, Final Batch Loss: 0.6152895092964172\n",
      "Epoch 293, Loss: 1.2706168293952942, Final Batch Loss: 0.6458490490913391\n",
      "Epoch 294, Loss: 1.3462427854537964, Final Batch Loss: 0.690906822681427\n",
      "Epoch 295, Loss: 1.2001762390136719, Final Batch Loss: 0.5639902353286743\n",
      "Epoch 296, Loss: 1.332440197467804, Final Batch Loss: 0.6883470416069031\n",
      "Epoch 297, Loss: 1.3151602745056152, Final Batch Loss: 0.6805981993675232\n",
      "Epoch 298, Loss: 1.2800178527832031, Final Batch Loss: 0.6669797301292419\n",
      "Epoch 299, Loss: 1.2648049592971802, Final Batch Loss: 0.666658341884613\n",
      "Epoch 300, Loss: 1.276097297668457, Final Batch Loss: 0.6890137791633606\n",
      "Epoch 301, Loss: 1.3111395239830017, Final Batch Loss: 0.6833770275115967\n",
      "Epoch 302, Loss: 1.2679702043533325, Final Batch Loss: 0.6399983763694763\n",
      "Epoch 303, Loss: 1.273955225944519, Final Batch Loss: 0.6376705169677734\n",
      "Epoch 304, Loss: 1.2681527137756348, Final Batch Loss: 0.581300675868988\n",
      "Epoch 305, Loss: 1.2171813249588013, Final Batch Loss: 0.5590717792510986\n",
      "Epoch 306, Loss: 1.3005779385566711, Final Batch Loss: 0.6391924619674683\n",
      "Epoch 307, Loss: 1.2802960276603699, Final Batch Loss: 0.5767229795455933\n",
      "Epoch 308, Loss: 1.2603420615196228, Final Batch Loss: 0.6352853775024414\n",
      "Epoch 309, Loss: 1.232798159122467, Final Batch Loss: 0.5698729753494263\n",
      "Epoch 310, Loss: 1.2724323868751526, Final Batch Loss: 0.6362777948379517\n",
      "Epoch 311, Loss: 1.2659806609153748, Final Batch Loss: 0.6812478303909302\n",
      "Epoch 312, Loss: 1.2981290817260742, Final Batch Loss: 0.643284261226654\n",
      "Epoch 313, Loss: 1.2891908884048462, Final Batch Loss: 0.6527870893478394\n",
      "Epoch 314, Loss: 1.303754985332489, Final Batch Loss: 0.6169215440750122\n",
      "Epoch 315, Loss: 1.2009816765785217, Final Batch Loss: 0.5869415998458862\n",
      "Epoch 316, Loss: 1.2743679285049438, Final Batch Loss: 0.638049304485321\n",
      "Epoch 317, Loss: 1.2655554413795471, Final Batch Loss: 0.5910477638244629\n",
      "Epoch 318, Loss: 1.24005925655365, Final Batch Loss: 0.6777349710464478\n",
      "Epoch 319, Loss: 1.1826242208480835, Final Batch Loss: 0.5837571024894714\n",
      "Epoch 320, Loss: 1.1915363073349, Final Batch Loss: 0.5476246476173401\n",
      "Epoch 321, Loss: 1.1994788646697998, Final Batch Loss: 0.5700356364250183\n",
      "Epoch 322, Loss: 1.2191861271858215, Final Batch Loss: 0.5939574241638184\n",
      "Epoch 323, Loss: 1.2416778802871704, Final Batch Loss: 0.6361026763916016\n",
      "Epoch 324, Loss: 1.244969666004181, Final Batch Loss: 0.6325932741165161\n",
      "Epoch 325, Loss: 1.219493567943573, Final Batch Loss: 0.6165574789047241\n",
      "Epoch 326, Loss: 1.200596034526825, Final Batch Loss: 0.6263719797134399\n",
      "Epoch 327, Loss: 1.1965268850326538, Final Batch Loss: 0.5762921571731567\n",
      "Epoch 328, Loss: 1.247539758682251, Final Batch Loss: 0.6475219130516052\n",
      "Epoch 329, Loss: 1.2064127326011658, Final Batch Loss: 0.5791873931884766\n",
      "Epoch 330, Loss: 1.2396456599235535, Final Batch Loss: 0.6270245313644409\n",
      "Epoch 331, Loss: 1.2406986951828003, Final Batch Loss: 0.6188790202140808\n",
      "Epoch 332, Loss: 1.1194193959236145, Final Batch Loss: 0.5270532369613647\n",
      "Epoch 333, Loss: 1.2450562715530396, Final Batch Loss: 0.6702790260314941\n",
      "Epoch 334, Loss: 1.202325463294983, Final Batch Loss: 0.5973202586174011\n",
      "Epoch 335, Loss: 1.1370612382888794, Final Batch Loss: 0.5083704590797424\n",
      "Epoch 336, Loss: 1.2289349436759949, Final Batch Loss: 0.62956303358078\n",
      "Epoch 337, Loss: 1.2301051020622253, Final Batch Loss: 0.6275951266288757\n",
      "Epoch 338, Loss: 1.1646370887756348, Final Batch Loss: 0.6184680461883545\n",
      "Epoch 339, Loss: 1.1947417855262756, Final Batch Loss: 0.563858687877655\n",
      "Epoch 340, Loss: 1.1947667598724365, Final Batch Loss: 0.6415776610374451\n",
      "Epoch 341, Loss: 1.2540543675422668, Final Batch Loss: 0.6810996532440186\n",
      "Epoch 342, Loss: 1.123895287513733, Final Batch Loss: 0.4685536026954651\n",
      "Epoch 343, Loss: 1.167114794254303, Final Batch Loss: 0.5541382431983948\n",
      "Epoch 344, Loss: 1.2285355925559998, Final Batch Loss: 0.6294873356819153\n",
      "Epoch 345, Loss: 1.1883199214935303, Final Batch Loss: 0.5563769340515137\n",
      "Epoch 346, Loss: 1.2192158699035645, Final Batch Loss: 0.6446306109428406\n",
      "Epoch 347, Loss: 1.2411813139915466, Final Batch Loss: 0.6511605978012085\n",
      "Epoch 348, Loss: 1.2011626958847046, Final Batch Loss: 0.5498325824737549\n",
      "Epoch 349, Loss: 1.2510841488838196, Final Batch Loss: 0.6122229695320129\n",
      "Epoch 350, Loss: 1.1679006218910217, Final Batch Loss: 0.6328012347221375\n",
      "Epoch 351, Loss: 1.1322447657585144, Final Batch Loss: 0.5567712783813477\n",
      "Epoch 352, Loss: 1.1475706696510315, Final Batch Loss: 0.5671424865722656\n",
      "Epoch 353, Loss: 1.2338202595710754, Final Batch Loss: 0.6761575937271118\n",
      "Epoch 354, Loss: 1.165357768535614, Final Batch Loss: 0.5603116750717163\n",
      "Epoch 355, Loss: 1.1823883652687073, Final Batch Loss: 0.6522287130355835\n",
      "Epoch 356, Loss: 1.1123128533363342, Final Batch Loss: 0.51739901304245\n",
      "Epoch 357, Loss: 1.1762270331382751, Final Batch Loss: 0.5943043828010559\n",
      "Epoch 358, Loss: 1.0833811163902283, Final Batch Loss: 0.5520902276039124\n",
      "Epoch 359, Loss: 1.1738227009773254, Final Batch Loss: 0.6050974726676941\n",
      "Epoch 360, Loss: 1.1750308275222778, Final Batch Loss: 0.5870795845985413\n",
      "Epoch 361, Loss: 1.225568413734436, Final Batch Loss: 0.6405509114265442\n",
      "Epoch 362, Loss: 1.1729891896247864, Final Batch Loss: 0.6146124005317688\n",
      "Epoch 363, Loss: 1.0882684886455536, Final Batch Loss: 0.48887303471565247\n",
      "Epoch 364, Loss: 1.1396640539169312, Final Batch Loss: 0.5238336324691772\n",
      "Epoch 365, Loss: 1.1256458759307861, Final Batch Loss: 0.6004369854927063\n",
      "Epoch 366, Loss: 1.144361138343811, Final Batch Loss: 0.5063799619674683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367, Loss: 1.098425805568695, Final Batch Loss: 0.5686152577400208\n",
      "Epoch 368, Loss: 1.0611799359321594, Final Batch Loss: 0.4727662205696106\n",
      "Epoch 369, Loss: 1.1088201403617859, Final Batch Loss: 0.5021417140960693\n",
      "Epoch 370, Loss: 1.0859997272491455, Final Batch Loss: 0.5559614896774292\n",
      "Epoch 371, Loss: 1.1062759757041931, Final Batch Loss: 0.5458946824073792\n",
      "Epoch 372, Loss: 1.136043667793274, Final Batch Loss: 0.5885178446769714\n",
      "Epoch 373, Loss: 1.1081672310829163, Final Batch Loss: 0.5706725120544434\n",
      "Epoch 374, Loss: 1.1121897101402283, Final Batch Loss: 0.5888597965240479\n",
      "Epoch 375, Loss: 1.1035274863243103, Final Batch Loss: 0.5676025748252869\n",
      "Epoch 376, Loss: 1.1042283773422241, Final Batch Loss: 0.5526482462882996\n",
      "Epoch 377, Loss: 1.1363344192504883, Final Batch Loss: 0.5453546047210693\n",
      "Epoch 378, Loss: 1.0405402779579163, Final Batch Loss: 0.4978369474411011\n",
      "Epoch 379, Loss: 1.0993768572807312, Final Batch Loss: 0.584067702293396\n",
      "Epoch 380, Loss: 1.0485073924064636, Final Batch Loss: 0.5167251229286194\n",
      "Epoch 381, Loss: 1.0333561301231384, Final Batch Loss: 0.5256512761116028\n",
      "Epoch 382, Loss: 1.09344482421875, Final Batch Loss: 0.5837398171424866\n",
      "Epoch 383, Loss: 1.0475297272205353, Final Batch Loss: 0.4950273931026459\n",
      "Epoch 384, Loss: 1.0357432663440704, Final Batch Loss: 0.4944157898426056\n",
      "Epoch 385, Loss: 1.05365788936615, Final Batch Loss: 0.5234618186950684\n",
      "Epoch 386, Loss: 1.1189231872558594, Final Batch Loss: 0.6050504446029663\n",
      "Epoch 387, Loss: 1.0534242391586304, Final Batch Loss: 0.5050114989280701\n",
      "Epoch 388, Loss: 1.0489251911640167, Final Batch Loss: 0.4867205321788788\n",
      "Epoch 389, Loss: 1.0175846815109253, Final Batch Loss: 0.49107682704925537\n",
      "Epoch 390, Loss: 1.1317134499549866, Final Batch Loss: 0.581824779510498\n",
      "Epoch 391, Loss: 1.058826059103012, Final Batch Loss: 0.57753986120224\n",
      "Epoch 392, Loss: 1.0288445353507996, Final Batch Loss: 0.5360928177833557\n",
      "Epoch 393, Loss: 1.0313619375228882, Final Batch Loss: 0.5277712345123291\n",
      "Epoch 394, Loss: 1.0722850561141968, Final Batch Loss: 0.5700210332870483\n",
      "Epoch 395, Loss: 1.0195479691028595, Final Batch Loss: 0.46753987669944763\n",
      "Epoch 396, Loss: 1.049563080072403, Final Batch Loss: 0.4783797562122345\n",
      "Epoch 397, Loss: 1.053688108921051, Final Batch Loss: 0.5073936581611633\n",
      "Epoch 398, Loss: 0.9877286553382874, Final Batch Loss: 0.4588017463684082\n",
      "Epoch 399, Loss: 1.0433499217033386, Final Batch Loss: 0.5071461200714111\n",
      "Epoch 400, Loss: 1.0612072348594666, Final Batch Loss: 0.5540564060211182\n",
      "Epoch 401, Loss: 1.0098299086093903, Final Batch Loss: 0.5149236917495728\n",
      "Epoch 402, Loss: 0.9837858974933624, Final Batch Loss: 0.4539448320865631\n",
      "Epoch 403, Loss: 0.9746681451797485, Final Batch Loss: 0.45427626371383667\n",
      "Epoch 404, Loss: 1.1036535501480103, Final Batch Loss: 0.5604501366615295\n",
      "Epoch 405, Loss: 0.9946154356002808, Final Batch Loss: 0.43698590993881226\n",
      "Epoch 406, Loss: 0.9710521101951599, Final Batch Loss: 0.4583978056907654\n",
      "Epoch 407, Loss: 1.0262373387813568, Final Batch Loss: 0.4868049919605255\n",
      "Epoch 408, Loss: 1.0177878439426422, Final Batch Loss: 0.5234049558639526\n",
      "Epoch 409, Loss: 1.1029224395751953, Final Batch Loss: 0.580326497554779\n",
      "Epoch 410, Loss: 1.0538761615753174, Final Batch Loss: 0.5577481389045715\n",
      "Epoch 411, Loss: 0.9759345650672913, Final Batch Loss: 0.46024733781814575\n",
      "Epoch 412, Loss: 0.983719527721405, Final Batch Loss: 0.47703033685684204\n",
      "Epoch 413, Loss: 1.0310148298740387, Final Batch Loss: 0.49156132340431213\n",
      "Epoch 414, Loss: 1.0172534584999084, Final Batch Loss: 0.5116749405860901\n",
      "Epoch 415, Loss: 0.9852327704429626, Final Batch Loss: 0.5104357004165649\n",
      "Epoch 416, Loss: 0.9849835336208344, Final Batch Loss: 0.49628743529319763\n",
      "Epoch 417, Loss: 1.0443572402000427, Final Batch Loss: 0.5204393863677979\n",
      "Epoch 418, Loss: 1.05734783411026, Final Batch Loss: 0.5526356101036072\n",
      "Epoch 419, Loss: 0.9234718978404999, Final Batch Loss: 0.426518976688385\n",
      "Epoch 420, Loss: 0.9450369775295258, Final Batch Loss: 0.44892260432243347\n",
      "Epoch 421, Loss: 0.9643486738204956, Final Batch Loss: 0.4416893720626831\n",
      "Epoch 422, Loss: 0.9724026918411255, Final Batch Loss: 0.46248096227645874\n",
      "Epoch 423, Loss: 0.9452781081199646, Final Batch Loss: 0.4416002631187439\n",
      "Epoch 424, Loss: 0.9856079816818237, Final Batch Loss: 0.5519047379493713\n",
      "Epoch 425, Loss: 0.949623167514801, Final Batch Loss: 0.47518739104270935\n",
      "Epoch 426, Loss: 0.9381107687950134, Final Batch Loss: 0.4692109227180481\n",
      "Epoch 427, Loss: 0.9314331710338593, Final Batch Loss: 0.4471510350704193\n",
      "Epoch 428, Loss: 0.9505389034748077, Final Batch Loss: 0.5006181001663208\n",
      "Epoch 429, Loss: 0.9037436842918396, Final Batch Loss: 0.4866602420806885\n",
      "Epoch 430, Loss: 0.9996288418769836, Final Batch Loss: 0.5010218024253845\n",
      "Epoch 431, Loss: 0.9262975752353668, Final Batch Loss: 0.47883570194244385\n",
      "Epoch 432, Loss: 0.9196848273277283, Final Batch Loss: 0.48153796792030334\n",
      "Epoch 433, Loss: 0.9201548993587494, Final Batch Loss: 0.45621806383132935\n",
      "Epoch 434, Loss: 0.8804824948310852, Final Batch Loss: 0.44155555963516235\n",
      "Epoch 435, Loss: 1.0399676859378815, Final Batch Loss: 0.5414868593215942\n",
      "Epoch 436, Loss: 0.9692604839801788, Final Batch Loss: 0.4996747374534607\n",
      "Epoch 437, Loss: 0.9042714536190033, Final Batch Loss: 0.4495081603527069\n",
      "Epoch 438, Loss: 0.8905982971191406, Final Batch Loss: 0.4184788167476654\n",
      "Epoch 439, Loss: 0.9203773438930511, Final Batch Loss: 0.49173206090927124\n",
      "Epoch 440, Loss: 0.9640078544616699, Final Batch Loss: 0.4871034026145935\n",
      "Epoch 441, Loss: 0.9439913332462311, Final Batch Loss: 0.4625788629055023\n",
      "Epoch 442, Loss: 0.9526947140693665, Final Batch Loss: 0.5137056708335876\n",
      "Epoch 443, Loss: 0.9234438240528107, Final Batch Loss: 0.4713001251220703\n",
      "Epoch 444, Loss: 0.8735731542110443, Final Batch Loss: 0.3863072991371155\n",
      "Epoch 445, Loss: 0.8106420040130615, Final Batch Loss: 0.3704678416252136\n",
      "Epoch 446, Loss: 0.860328733921051, Final Batch Loss: 0.4232604503631592\n",
      "Epoch 447, Loss: 0.9058050215244293, Final Batch Loss: 0.46131888031959534\n",
      "Epoch 448, Loss: 0.9162139296531677, Final Batch Loss: 0.48446908593177795\n",
      "Epoch 449, Loss: 0.8361082971096039, Final Batch Loss: 0.41446322202682495\n",
      "Epoch 450, Loss: 0.8649029731750488, Final Batch Loss: 0.4183451533317566\n",
      "Epoch 451, Loss: 0.8742882013320923, Final Batch Loss: 0.4191540777683258\n",
      "Epoch 452, Loss: 0.8248471915721893, Final Batch Loss: 0.4278416931629181\n",
      "Epoch 453, Loss: 0.8801701664924622, Final Batch Loss: 0.48423516750335693\n",
      "Epoch 454, Loss: 0.9098290503025055, Final Batch Loss: 0.4727218449115753\n",
      "Epoch 455, Loss: 0.859284907579422, Final Batch Loss: 0.4382028877735138\n",
      "Epoch 456, Loss: 0.8417908251285553, Final Batch Loss: 0.42686769366264343\n",
      "Epoch 457, Loss: 0.8697666823863983, Final Batch Loss: 0.4468790590763092\n",
      "Epoch 458, Loss: 0.8464588820934296, Final Batch Loss: 0.44691914319992065\n",
      "Epoch 459, Loss: 0.848423182964325, Final Batch Loss: 0.46725010871887207\n",
      "Epoch 460, Loss: 0.9035545587539673, Final Batch Loss: 0.4672047197818756\n",
      "Epoch 461, Loss: 0.8008049726486206, Final Batch Loss: 0.3923620879650116\n",
      "Epoch 462, Loss: 0.77477166056633, Final Batch Loss: 0.4241572916507721\n",
      "Epoch 463, Loss: 0.925497442483902, Final Batch Loss: 0.5068427324295044\n",
      "Epoch 464, Loss: 0.843742161989212, Final Batch Loss: 0.44179996848106384\n",
      "Epoch 465, Loss: 0.8210046291351318, Final Batch Loss: 0.4178403913974762\n",
      "Epoch 466, Loss: 0.8151200413703918, Final Batch Loss: 0.3884560763835907\n",
      "Epoch 467, Loss: 0.8358074426651001, Final Batch Loss: 0.42276692390441895\n",
      "Epoch 468, Loss: 0.7350799739360809, Final Batch Loss: 0.30098140239715576\n",
      "Epoch 469, Loss: 0.8141591846942902, Final Batch Loss: 0.43157196044921875\n",
      "Epoch 470, Loss: 0.8264480829238892, Final Batch Loss: 0.39475223422050476\n",
      "Epoch 471, Loss: 0.7669163942337036, Final Batch Loss: 0.3381914794445038\n",
      "Epoch 472, Loss: 0.7482441067695618, Final Batch Loss: 0.35012543201446533\n",
      "Epoch 473, Loss: 0.8038672208786011, Final Batch Loss: 0.3615632951259613\n",
      "Epoch 474, Loss: 0.76753830909729, Final Batch Loss: 0.3568814694881439\n",
      "Epoch 475, Loss: 0.8627231419086456, Final Batch Loss: 0.45298299193382263\n",
      "Epoch 476, Loss: 0.7623290717601776, Final Batch Loss: 0.392642080783844\n",
      "Epoch 477, Loss: 0.8123776018619537, Final Batch Loss: 0.39870911836624146\n",
      "Epoch 478, Loss: 0.7834619581699371, Final Batch Loss: 0.4029320478439331\n",
      "Epoch 479, Loss: 0.8045592308044434, Final Batch Loss: 0.4062877893447876\n",
      "Epoch 480, Loss: 0.8200350701808929, Final Batch Loss: 0.41833004355430603\n",
      "Epoch 481, Loss: 0.7782455384731293, Final Batch Loss: 0.4045516550540924\n",
      "Epoch 482, Loss: 0.8162491321563721, Final Batch Loss: 0.369343638420105\n",
      "Epoch 483, Loss: 0.8146672546863556, Final Batch Loss: 0.43079373240470886\n",
      "Epoch 484, Loss: 0.8051528930664062, Final Batch Loss: 0.4167828857898712\n",
      "Epoch 485, Loss: 0.7653829157352448, Final Batch Loss: 0.3788408935070038\n",
      "Epoch 486, Loss: 0.778697282075882, Final Batch Loss: 0.4674031138420105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487, Loss: 0.7910944223403931, Final Batch Loss: 0.4001050293445587\n",
      "Epoch 488, Loss: 0.7390953600406647, Final Batch Loss: 0.314117431640625\n",
      "Epoch 489, Loss: 0.8749294877052307, Final Batch Loss: 0.40174782276153564\n",
      "Epoch 490, Loss: 0.7641454935073853, Final Batch Loss: 0.3439861834049225\n",
      "Epoch 491, Loss: 0.8567964434623718, Final Batch Loss: 0.49128079414367676\n",
      "Epoch 492, Loss: 0.7960097789764404, Final Batch Loss: 0.3891165256500244\n",
      "Epoch 493, Loss: 0.8238874077796936, Final Batch Loss: 0.41962313652038574\n",
      "Epoch 494, Loss: 0.8223270177841187, Final Batch Loss: 0.4308856725692749\n",
      "Epoch 495, Loss: 0.8633500933647156, Final Batch Loss: 0.44941842555999756\n",
      "Epoch 496, Loss: 0.7281408905982971, Final Batch Loss: 0.43461108207702637\n",
      "Epoch 497, Loss: 0.7497831284999847, Final Batch Loss: 0.4015522599220276\n",
      "Epoch 498, Loss: 0.7210688591003418, Final Batch Loss: 0.36084797978401184\n",
      "Epoch 499, Loss: 0.7334306836128235, Final Batch Loss: 0.34532445669174194\n",
      "Epoch 500, Loss: 0.7669994235038757, Final Batch Loss: 0.36513638496398926\n",
      "Epoch 501, Loss: 0.7130603790283203, Final Batch Loss: 0.3124088644981384\n",
      "Epoch 502, Loss: 0.7764645516872406, Final Batch Loss: 0.3873935043811798\n",
      "Epoch 503, Loss: 0.7364997565746307, Final Batch Loss: 0.37538155913352966\n",
      "Epoch 504, Loss: 0.7376026809215546, Final Batch Loss: 0.35996294021606445\n",
      "Epoch 505, Loss: 0.8073685467243195, Final Batch Loss: 0.4069302976131439\n",
      "Epoch 506, Loss: 0.6969420909881592, Final Batch Loss: 0.32255029678344727\n",
      "Epoch 507, Loss: 0.7647783160209656, Final Batch Loss: 0.4026694893836975\n",
      "Epoch 508, Loss: 0.7373247444629669, Final Batch Loss: 0.3907358646392822\n",
      "Epoch 509, Loss: 0.751404345035553, Final Batch Loss: 0.3690074682235718\n",
      "Epoch 510, Loss: 0.7044945657253265, Final Batch Loss: 0.3493765592575073\n",
      "Epoch 511, Loss: 0.7485643625259399, Final Batch Loss: 0.40108799934387207\n",
      "Epoch 512, Loss: 0.7108114361763, Final Batch Loss: 0.3420454263687134\n",
      "Epoch 513, Loss: 0.7386854588985443, Final Batch Loss: 0.36999398469924927\n",
      "Epoch 514, Loss: 0.722110241651535, Final Batch Loss: 0.3749840259552002\n",
      "Epoch 515, Loss: 0.7515114545822144, Final Batch Loss: 0.35765495896339417\n",
      "Epoch 516, Loss: 0.7695062160491943, Final Batch Loss: 0.3632829487323761\n",
      "Epoch 517, Loss: 0.7332799732685089, Final Batch Loss: 0.36415940523147583\n",
      "Epoch 518, Loss: 0.7030214369297028, Final Batch Loss: 0.33150893449783325\n",
      "Epoch 519, Loss: 0.7295206189155579, Final Batch Loss: 0.3717327117919922\n",
      "Epoch 520, Loss: 0.721027135848999, Final Batch Loss: 0.32405930757522583\n",
      "Epoch 521, Loss: 0.770735502243042, Final Batch Loss: 0.3800378739833832\n",
      "Epoch 522, Loss: 0.777251809835434, Final Batch Loss: 0.40414002537727356\n",
      "Epoch 523, Loss: 0.6976285576820374, Final Batch Loss: 0.36447232961654663\n",
      "Epoch 524, Loss: 0.7253541350364685, Final Batch Loss: 0.3436577618122101\n",
      "Epoch 525, Loss: 0.675476461648941, Final Batch Loss: 0.3541947901248932\n",
      "Epoch 526, Loss: 0.6693159639835358, Final Batch Loss: 0.3487071096897125\n",
      "Epoch 527, Loss: 0.7438043057918549, Final Batch Loss: 0.38290315866470337\n",
      "Epoch 528, Loss: 0.6846330463886261, Final Batch Loss: 0.34893614053726196\n",
      "Epoch 529, Loss: 0.7526782155036926, Final Batch Loss: 0.437112033367157\n",
      "Epoch 530, Loss: 0.6548638343811035, Final Batch Loss: 0.3463294804096222\n",
      "Epoch 531, Loss: 0.7316917181015015, Final Batch Loss: 0.4073808491230011\n",
      "Epoch 532, Loss: 0.7088242769241333, Final Batch Loss: 0.3540281355381012\n",
      "Epoch 533, Loss: 0.6888852715492249, Final Batch Loss: 0.31455865502357483\n",
      "Epoch 534, Loss: 0.6926354765892029, Final Batch Loss: 0.33773350715637207\n",
      "Epoch 535, Loss: 0.6485898196697235, Final Batch Loss: 0.3290710747241974\n",
      "Epoch 536, Loss: 0.6852947473526001, Final Batch Loss: 0.2989767789840698\n",
      "Epoch 537, Loss: 0.6493695974349976, Final Batch Loss: 0.30699047446250916\n",
      "Epoch 538, Loss: 0.7816247344017029, Final Batch Loss: 0.3912956118583679\n",
      "Epoch 539, Loss: 0.6875379979610443, Final Batch Loss: 0.29260605573654175\n",
      "Epoch 540, Loss: 0.7312516570091248, Final Batch Loss: 0.3966830372810364\n",
      "Epoch 541, Loss: 0.7214782238006592, Final Batch Loss: 0.3641420304775238\n",
      "Epoch 542, Loss: 0.6976808309555054, Final Batch Loss: 0.3359815180301666\n",
      "Epoch 543, Loss: 0.7496751248836517, Final Batch Loss: 0.358263224363327\n",
      "Epoch 544, Loss: 0.6554906666278839, Final Batch Loss: 0.34448865056037903\n",
      "Epoch 545, Loss: 0.6908422410488129, Final Batch Loss: 0.3448464572429657\n",
      "Epoch 546, Loss: 0.6860457360744476, Final Batch Loss: 0.3277207016944885\n",
      "Epoch 547, Loss: 0.6744149327278137, Final Batch Loss: 0.3323694169521332\n",
      "Epoch 548, Loss: 0.6587018668651581, Final Batch Loss: 0.26369455456733704\n",
      "Epoch 549, Loss: 0.7150083184242249, Final Batch Loss: 0.3503277599811554\n",
      "Epoch 550, Loss: 0.6782879531383514, Final Batch Loss: 0.32985395193099976\n",
      "Epoch 551, Loss: 0.6852173209190369, Final Batch Loss: 0.32887521386146545\n",
      "Epoch 552, Loss: 0.7159329652786255, Final Batch Loss: 0.33690378069877625\n",
      "Epoch 553, Loss: 0.6826731264591217, Final Batch Loss: 0.3103002607822418\n",
      "Epoch 554, Loss: 0.6785378158092499, Final Batch Loss: 0.32280248403549194\n",
      "Epoch 555, Loss: 0.6539488732814789, Final Batch Loss: 0.31900277733802795\n",
      "Epoch 556, Loss: 0.6203269362449646, Final Batch Loss: 0.265453040599823\n",
      "Epoch 557, Loss: 0.6700215935707092, Final Batch Loss: 0.35183271765708923\n",
      "Epoch 558, Loss: 0.6795267760753632, Final Batch Loss: 0.3219732344150543\n",
      "Epoch 559, Loss: 0.7955363392829895, Final Batch Loss: 0.45503681898117065\n",
      "Epoch 560, Loss: 0.6430456936359406, Final Batch Loss: 0.36800509691238403\n",
      "Epoch 561, Loss: 0.6316541433334351, Final Batch Loss: 0.30389514565467834\n",
      "Epoch 562, Loss: 0.7128037810325623, Final Batch Loss: 0.3518722951412201\n",
      "Epoch 563, Loss: 0.6927379667758942, Final Batch Loss: 0.3192380368709564\n",
      "Epoch 564, Loss: 0.6913336217403412, Final Batch Loss: 0.32272177934646606\n",
      "Epoch 565, Loss: 0.7015382945537567, Final Batch Loss: 0.3174162805080414\n",
      "Epoch 566, Loss: 0.7775412499904633, Final Batch Loss: 0.44067397713661194\n",
      "Epoch 567, Loss: 0.6611502766609192, Final Batch Loss: 0.3055259883403778\n",
      "Epoch 568, Loss: 0.6537067294120789, Final Batch Loss: 0.3726976215839386\n",
      "Epoch 569, Loss: 0.6571197211742401, Final Batch Loss: 0.3352927565574646\n",
      "Epoch 570, Loss: 0.6975685060024261, Final Batch Loss: 0.3922269642353058\n",
      "Epoch 571, Loss: 0.6988875269889832, Final Batch Loss: 0.313159704208374\n",
      "Epoch 572, Loss: 0.7341301441192627, Final Batch Loss: 0.3770836293697357\n",
      "Epoch 573, Loss: 0.6447769701480865, Final Batch Loss: 0.297390878200531\n",
      "Epoch 574, Loss: 0.6195106208324432, Final Batch Loss: 0.3099333941936493\n",
      "Epoch 575, Loss: 0.643642246723175, Final Batch Loss: 0.32295119762420654\n",
      "Epoch 576, Loss: 0.6831050217151642, Final Batch Loss: 0.30323147773742676\n",
      "Epoch 577, Loss: 0.6462843716144562, Final Batch Loss: 0.2952817380428314\n",
      "Epoch 578, Loss: 0.6590541899204254, Final Batch Loss: 0.3101631999015808\n",
      "Epoch 579, Loss: 0.6429690718650818, Final Batch Loss: 0.3375456631183624\n",
      "Epoch 580, Loss: 0.5916615426540375, Final Batch Loss: 0.26454415917396545\n",
      "Epoch 581, Loss: 0.6660566627979279, Final Batch Loss: 0.2999974489212036\n",
      "Epoch 582, Loss: 0.6369683742523193, Final Batch Loss: 0.3172835409641266\n",
      "Epoch 583, Loss: 0.6385622322559357, Final Batch Loss: 0.2924197316169739\n",
      "Epoch 584, Loss: 0.6231288313865662, Final Batch Loss: 0.31538814306259155\n",
      "Epoch 585, Loss: 0.6590699553489685, Final Batch Loss: 0.3806886076927185\n",
      "Epoch 586, Loss: 0.6115613877773285, Final Batch Loss: 0.29831793904304504\n",
      "Epoch 587, Loss: 0.6347305774688721, Final Batch Loss: 0.28650301694869995\n",
      "Epoch 588, Loss: 0.6604130566120148, Final Batch Loss: 0.30499038100242615\n",
      "Epoch 589, Loss: 0.6928712427616119, Final Batch Loss: 0.3836030960083008\n",
      "Epoch 590, Loss: 0.6859784424304962, Final Batch Loss: 0.3823833763599396\n",
      "Epoch 591, Loss: 0.6289739310741425, Final Batch Loss: 0.28633826971054077\n",
      "Epoch 592, Loss: 0.5838074088096619, Final Batch Loss: 0.2679769694805145\n",
      "Epoch 593, Loss: 0.640405684709549, Final Batch Loss: 0.35033488273620605\n",
      "Epoch 594, Loss: 0.6426281034946442, Final Batch Loss: 0.32465335726737976\n",
      "Epoch 595, Loss: 0.6619085371494293, Final Batch Loss: 0.30262991786003113\n",
      "Epoch 596, Loss: 0.6232460141181946, Final Batch Loss: 0.31562113761901855\n",
      "Epoch 597, Loss: 0.613040417432785, Final Batch Loss: 0.3022008240222931\n",
      "Epoch 598, Loss: 0.6144628822803497, Final Batch Loss: 0.2914782166481018\n",
      "Epoch 599, Loss: 0.5717975497245789, Final Batch Loss: 0.3089602589607239\n",
      "Epoch 600, Loss: 0.6729811728000641, Final Batch Loss: 0.3996921181678772\n",
      "Epoch 601, Loss: 0.5988762974739075, Final Batch Loss: 0.2840298116207123\n",
      "Epoch 602, Loss: 0.632256418466568, Final Batch Loss: 0.3577665090560913\n",
      "Epoch 603, Loss: 0.5836566984653473, Final Batch Loss: 0.25989261269569397\n",
      "Epoch 604, Loss: 0.5997882187366486, Final Batch Loss: 0.31213709712028503\n",
      "Epoch 605, Loss: 0.6353780925273895, Final Batch Loss: 0.3222793638706207\n",
      "Epoch 606, Loss: 0.6339111328125, Final Batch Loss: 0.314341276884079\n",
      "Epoch 607, Loss: 0.6227396726608276, Final Batch Loss: 0.33000242710113525\n",
      "Epoch 608, Loss: 0.6190571188926697, Final Batch Loss: 0.310503214597702\n",
      "Epoch 609, Loss: 0.5855919271707535, Final Batch Loss: 0.24234606325626373\n",
      "Epoch 610, Loss: 0.6191730201244354, Final Batch Loss: 0.2670840919017792\n",
      "Epoch 611, Loss: 0.6529612243175507, Final Batch Loss: 0.3265160918235779\n",
      "Epoch 612, Loss: 0.6063427627086639, Final Batch Loss: 0.2707391083240509\n",
      "Epoch 613, Loss: 0.5738756358623505, Final Batch Loss: 0.2982742190361023\n",
      "Epoch 614, Loss: 0.5773625671863556, Final Batch Loss: 0.29097068309783936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 615, Loss: 0.6210347414016724, Final Batch Loss: 0.3414212167263031\n",
      "Epoch 616, Loss: 0.5785291790962219, Final Batch Loss: 0.3094542920589447\n",
      "Epoch 617, Loss: 0.5421634912490845, Final Batch Loss: 0.2647923529148102\n",
      "Epoch 618, Loss: 0.6543834805488586, Final Batch Loss: 0.39771130681037903\n",
      "Epoch 619, Loss: 0.6188400685787201, Final Batch Loss: 0.3152151107788086\n",
      "Epoch 620, Loss: 0.5775604248046875, Final Batch Loss: 0.2502807676792145\n",
      "Epoch 621, Loss: 0.556579977273941, Final Batch Loss: 0.27493131160736084\n",
      "Epoch 622, Loss: 0.5817444026470184, Final Batch Loss: 0.30952638387680054\n",
      "Epoch 623, Loss: 0.540206640958786, Final Batch Loss: 0.26341304183006287\n",
      "Epoch 624, Loss: 0.5571762919425964, Final Batch Loss: 0.27852556109428406\n",
      "Epoch 625, Loss: 0.630157470703125, Final Batch Loss: 0.32630455493927\n",
      "Epoch 626, Loss: 0.6302086412906647, Final Batch Loss: 0.30717986822128296\n",
      "Epoch 627, Loss: 0.5537175834178925, Final Batch Loss: 0.2691195607185364\n",
      "Epoch 628, Loss: 0.595315545797348, Final Batch Loss: 0.31213894486427307\n",
      "Epoch 629, Loss: 0.5962393879890442, Final Batch Loss: 0.263526052236557\n",
      "Epoch 630, Loss: 0.5629431903362274, Final Batch Loss: 0.2846607565879822\n",
      "Epoch 631, Loss: 0.5989313721656799, Final Batch Loss: 0.32240647077560425\n",
      "Epoch 632, Loss: 0.517644390463829, Final Batch Loss: 0.20944730937480927\n",
      "Epoch 633, Loss: 0.5859352350234985, Final Batch Loss: 0.2939998209476471\n",
      "Epoch 634, Loss: 0.5597525238990784, Final Batch Loss: 0.2647704482078552\n",
      "Epoch 635, Loss: 0.6061964929103851, Final Batch Loss: 0.287390798330307\n",
      "Epoch 636, Loss: 0.5799546241760254, Final Batch Loss: 0.2780064344406128\n",
      "Epoch 637, Loss: 0.5111686736345291, Final Batch Loss: 0.1941230148077011\n",
      "Epoch 638, Loss: 0.6436299681663513, Final Batch Loss: 0.3460208475589752\n",
      "Epoch 639, Loss: 0.5830782949924469, Final Batch Loss: 0.302754282951355\n",
      "Epoch 640, Loss: 0.5594628751277924, Final Batch Loss: 0.2982158660888672\n",
      "Epoch 641, Loss: 0.5393878817558289, Final Batch Loss: 0.23548927903175354\n",
      "Epoch 642, Loss: 0.5508230775594711, Final Batch Loss: 0.24834899604320526\n",
      "Epoch 643, Loss: 0.5661906003952026, Final Batch Loss: 0.29072409868240356\n",
      "Epoch 644, Loss: 0.5584240853786469, Final Batch Loss: 0.2770252525806427\n",
      "Epoch 645, Loss: 0.6572389900684357, Final Batch Loss: 0.3867846727371216\n",
      "Epoch 646, Loss: 0.6098116934299469, Final Batch Loss: 0.3378717005252838\n",
      "Epoch 647, Loss: 0.5448901504278183, Final Batch Loss: 0.23427875339984894\n",
      "Epoch 648, Loss: 0.5545165240764618, Final Batch Loss: 0.30277329683303833\n",
      "Epoch 649, Loss: 0.5485714673995972, Final Batch Loss: 0.24009045958518982\n",
      "Epoch 650, Loss: 0.5447573363780975, Final Batch Loss: 0.2614251971244812\n",
      "Epoch 651, Loss: 0.5893080234527588, Final Batch Loss: 0.270813524723053\n",
      "Epoch 652, Loss: 0.558696836233139, Final Batch Loss: 0.24521476030349731\n",
      "Epoch 653, Loss: 0.5820863544940948, Final Batch Loss: 0.30488914251327515\n",
      "Epoch 654, Loss: 0.5141347497701645, Final Batch Loss: 0.24646227061748505\n",
      "Epoch 655, Loss: 0.5828810036182404, Final Batch Loss: 0.2983868420124054\n",
      "Epoch 656, Loss: 0.5439017713069916, Final Batch Loss: 0.25117695331573486\n",
      "Epoch 657, Loss: 0.5578644275665283, Final Batch Loss: 0.24815213680267334\n",
      "Epoch 658, Loss: 0.502196878194809, Final Batch Loss: 0.2696259021759033\n",
      "Epoch 659, Loss: 0.578455239534378, Final Batch Loss: 0.2775760889053345\n",
      "Epoch 660, Loss: 0.5582668483257294, Final Batch Loss: 0.26386070251464844\n",
      "Epoch 661, Loss: 0.5995295345783234, Final Batch Loss: 0.3275623917579651\n",
      "Epoch 662, Loss: 0.5041064023971558, Final Batch Loss: 0.229432612657547\n",
      "Epoch 663, Loss: 0.5332323312759399, Final Batch Loss: 0.2770219147205353\n",
      "Epoch 664, Loss: 0.5303328633308411, Final Batch Loss: 0.2311369776725769\n",
      "Epoch 665, Loss: 0.5309464633464813, Final Batch Loss: 0.23385655879974365\n",
      "Epoch 666, Loss: 0.5281020104885101, Final Batch Loss: 0.27726173400878906\n",
      "Epoch 667, Loss: 0.5466167032718658, Final Batch Loss: 0.2772837281227112\n",
      "Epoch 668, Loss: 0.5783587098121643, Final Batch Loss: 0.33037975430488586\n",
      "Epoch 669, Loss: 0.5618593692779541, Final Batch Loss: 0.27940642833709717\n",
      "Epoch 670, Loss: 0.5645628273487091, Final Batch Loss: 0.32273927330970764\n",
      "Epoch 671, Loss: 0.5283263325691223, Final Batch Loss: 0.23843583464622498\n",
      "Epoch 672, Loss: 0.5166273266077042, Final Batch Loss: 0.23307733237743378\n",
      "Epoch 673, Loss: 0.5191792100667953, Final Batch Loss: 0.2405533343553543\n",
      "Epoch 674, Loss: 0.5414048731327057, Final Batch Loss: 0.31847095489501953\n",
      "Epoch 675, Loss: 0.49940334260463715, Final Batch Loss: 0.2256992906332016\n",
      "Epoch 676, Loss: 0.520117849111557, Final Batch Loss: 0.2524557411670685\n",
      "Epoch 677, Loss: 0.5318575501441956, Final Batch Loss: 0.24913927912712097\n",
      "Epoch 678, Loss: 0.5273006558418274, Final Batch Loss: 0.26122578978538513\n",
      "Epoch 679, Loss: 0.48564042150974274, Final Batch Loss: 0.22462691366672516\n",
      "Epoch 680, Loss: 0.4950825423002243, Final Batch Loss: 0.20907588303089142\n",
      "Epoch 681, Loss: 0.5145824253559113, Final Batch Loss: 0.2666386067867279\n",
      "Epoch 682, Loss: 0.5514716506004333, Final Batch Loss: 0.2861015796661377\n",
      "Epoch 683, Loss: 0.5241233855485916, Final Batch Loss: 0.2400762289762497\n",
      "Epoch 684, Loss: 0.5309214442968369, Final Batch Loss: 0.28099772334098816\n",
      "Epoch 685, Loss: 0.4959270507097244, Final Batch Loss: 0.23044459521770477\n",
      "Epoch 686, Loss: 0.5365075170993805, Final Batch Loss: 0.31999972462654114\n",
      "Epoch 687, Loss: 0.47195959091186523, Final Batch Loss: 0.23329788446426392\n",
      "Epoch 688, Loss: 0.5339465290307999, Final Batch Loss: 0.3156026005744934\n",
      "Epoch 689, Loss: 0.518766775727272, Final Batch Loss: 0.27676576375961304\n",
      "Epoch 690, Loss: 0.467210128903389, Final Batch Loss: 0.24088987708091736\n",
      "Epoch 691, Loss: 0.5141398012638092, Final Batch Loss: 0.2514152228832245\n",
      "Epoch 692, Loss: 0.5076175332069397, Final Batch Loss: 0.23769742250442505\n",
      "Epoch 693, Loss: 0.48436325788497925, Final Batch Loss: 0.2570396363735199\n",
      "Epoch 694, Loss: 0.4445790797472, Final Batch Loss: 0.22644634544849396\n",
      "Epoch 695, Loss: 0.45851245522499084, Final Batch Loss: 0.19204550981521606\n",
      "Epoch 696, Loss: 0.5148635655641556, Final Batch Loss: 0.31055909395217896\n",
      "Epoch 697, Loss: 0.44562390446662903, Final Batch Loss: 0.22209030389785767\n",
      "Epoch 698, Loss: 0.46498847007751465, Final Batch Loss: 0.2859887480735779\n",
      "Epoch 699, Loss: 0.45425498485565186, Final Batch Loss: 0.24139051139354706\n",
      "Epoch 700, Loss: 0.47454455494880676, Final Batch Loss: 0.2530395984649658\n",
      "Epoch 701, Loss: 0.45138801634311676, Final Batch Loss: 0.21558253467082977\n",
      "Epoch 702, Loss: 0.44214628636837006, Final Batch Loss: 0.1844579428434372\n",
      "Epoch 703, Loss: 0.4494284391403198, Final Batch Loss: 0.24634993076324463\n",
      "Epoch 704, Loss: 0.42992793023586273, Final Batch Loss: 0.2109803855419159\n",
      "Epoch 705, Loss: 0.38872210681438446, Final Batch Loss: 0.17200951278209686\n",
      "Epoch 706, Loss: 0.4263877421617508, Final Batch Loss: 0.2135341614484787\n",
      "Epoch 707, Loss: 0.4843614250421524, Final Batch Loss: 0.2711348533630371\n",
      "Epoch 708, Loss: 0.44125354290008545, Final Batch Loss: 0.23915904760360718\n",
      "Epoch 709, Loss: 0.39801572263240814, Final Batch Loss: 0.18279284238815308\n",
      "Epoch 710, Loss: 0.446726530790329, Final Batch Loss: 0.23907247185707092\n",
      "Epoch 711, Loss: 0.40972040593624115, Final Batch Loss: 0.1867183893918991\n",
      "Epoch 712, Loss: 0.4333660453557968, Final Batch Loss: 0.2530044615268707\n",
      "Epoch 713, Loss: 0.4675929397344589, Final Batch Loss: 0.26217910647392273\n",
      "Epoch 714, Loss: 0.4062621742486954, Final Batch Loss: 0.19434045255184174\n",
      "Epoch 715, Loss: 0.4905010014772415, Final Batch Loss: 0.31466251611709595\n",
      "Epoch 716, Loss: 0.4125646948814392, Final Batch Loss: 0.19325219094753265\n",
      "Epoch 717, Loss: 0.4129834920167923, Final Batch Loss: 0.23132583498954773\n",
      "Epoch 718, Loss: 0.3904685080051422, Final Batch Loss: 0.22942839562892914\n",
      "Epoch 719, Loss: 0.45294831693172455, Final Batch Loss: 0.2610781788825989\n",
      "Epoch 720, Loss: 0.36446109414100647, Final Batch Loss: 0.14080752432346344\n",
      "Epoch 721, Loss: 0.358761802315712, Final Batch Loss: 0.18655972182750702\n",
      "Epoch 722, Loss: 0.44871294498443604, Final Batch Loss: 0.23395320773124695\n",
      "Epoch 723, Loss: 0.3881554752588272, Final Batch Loss: 0.15727581083774567\n",
      "Epoch 724, Loss: 0.4234470874071121, Final Batch Loss: 0.2113489955663681\n",
      "Epoch 725, Loss: 0.42295119166374207, Final Batch Loss: 0.22515201568603516\n",
      "Epoch 726, Loss: 0.4285655915737152, Final Batch Loss: 0.2113543152809143\n",
      "Epoch 727, Loss: 0.42395806312561035, Final Batch Loss: 0.20140856504440308\n",
      "Epoch 728, Loss: 0.3985522538423538, Final Batch Loss: 0.23621635138988495\n",
      "Epoch 729, Loss: 0.3926602452993393, Final Batch Loss: 0.19792933762073517\n",
      "Epoch 730, Loss: 0.41907648742198944, Final Batch Loss: 0.21424686908721924\n",
      "Epoch 731, Loss: 0.4033893048763275, Final Batch Loss: 0.18149793148040771\n",
      "Epoch 732, Loss: 0.3798593580722809, Final Batch Loss: 0.21371056139469147\n",
      "Epoch 733, Loss: 0.4744407832622528, Final Batch Loss: 0.24366645514965057\n",
      "Epoch 734, Loss: 0.477599635720253, Final Batch Loss: 0.2808036208152771\n",
      "Epoch 735, Loss: 0.399209588766098, Final Batch Loss: 0.1921912133693695\n",
      "Epoch 736, Loss: 0.39484769105911255, Final Batch Loss: 0.20380166172981262\n",
      "Epoch 737, Loss: 0.4243343770503998, Final Batch Loss: 0.23543797433376312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 738, Loss: 0.38769127428531647, Final Batch Loss: 0.18425102531909943\n",
      "Epoch 739, Loss: 0.3984866291284561, Final Batch Loss: 0.19381578266620636\n",
      "Epoch 740, Loss: 0.4034416079521179, Final Batch Loss: 0.21445128321647644\n",
      "Epoch 741, Loss: 0.37261559069156647, Final Batch Loss: 0.17929311096668243\n",
      "Epoch 742, Loss: 0.41162119805812836, Final Batch Loss: 0.22076496481895447\n",
      "Epoch 743, Loss: 0.3607676327228546, Final Batch Loss: 0.20017579197883606\n",
      "Epoch 744, Loss: 0.40994924306869507, Final Batch Loss: 0.24778664112091064\n",
      "Epoch 745, Loss: 0.35048121213912964, Final Batch Loss: 0.1410863697528839\n",
      "Epoch 746, Loss: 0.41495445370674133, Final Batch Loss: 0.21174925565719604\n",
      "Epoch 747, Loss: 0.41084034740924835, Final Batch Loss: 0.21325838565826416\n",
      "Epoch 748, Loss: 0.3645358681678772, Final Batch Loss: 0.17588530480861664\n",
      "Epoch 749, Loss: 0.4056253433227539, Final Batch Loss: 0.2024282068014145\n",
      "Epoch 750, Loss: 0.4397321194410324, Final Batch Loss: 0.24545353651046753\n",
      "Epoch 751, Loss: 0.38199877738952637, Final Batch Loss: 0.20343971252441406\n",
      "Epoch 752, Loss: 0.4258725792169571, Final Batch Loss: 0.2319212108850479\n",
      "Epoch 753, Loss: 0.3635518252849579, Final Batch Loss: 0.17512936890125275\n",
      "Epoch 754, Loss: 0.3497267961502075, Final Batch Loss: 0.12572413682937622\n",
      "Epoch 755, Loss: 0.399156391620636, Final Batch Loss: 0.2097984403371811\n",
      "Epoch 756, Loss: 0.4342677593231201, Final Batch Loss: 0.2423914223909378\n",
      "Epoch 757, Loss: 0.41131721436977386, Final Batch Loss: 0.19217227399349213\n",
      "Epoch 758, Loss: 0.40774567425251007, Final Batch Loss: 0.26882266998291016\n",
      "Epoch 759, Loss: 0.3793797045946121, Final Batch Loss: 0.2111475020647049\n",
      "Epoch 760, Loss: 0.32653679698705673, Final Batch Loss: 0.12465312331914902\n",
      "Epoch 761, Loss: 0.35416531562805176, Final Batch Loss: 0.1816745102405548\n",
      "Epoch 762, Loss: 0.3853369653224945, Final Batch Loss: 0.1959119737148285\n",
      "Epoch 763, Loss: 0.4491470605134964, Final Batch Loss: 0.25459757447242737\n",
      "Epoch 764, Loss: 0.373503178358078, Final Batch Loss: 0.18017525970935822\n",
      "Epoch 765, Loss: 0.4021897315979004, Final Batch Loss: 0.19608309864997864\n",
      "Epoch 766, Loss: 0.3621929734945297, Final Batch Loss: 0.1867343932390213\n",
      "Epoch 767, Loss: 0.37473101913928986, Final Batch Loss: 0.18093784153461456\n",
      "Epoch 768, Loss: 0.38690127432346344, Final Batch Loss: 0.17922945320606232\n",
      "Epoch 769, Loss: 0.4308539628982544, Final Batch Loss: 0.24333257973194122\n",
      "Epoch 770, Loss: 0.3706803321838379, Final Batch Loss: 0.20460113883018494\n",
      "Epoch 771, Loss: 0.35438272356987, Final Batch Loss: 0.1969677209854126\n",
      "Epoch 772, Loss: 0.389662429690361, Final Batch Loss: 0.2045055627822876\n",
      "Epoch 773, Loss: 0.41372331976890564, Final Batch Loss: 0.24322886765003204\n",
      "Epoch 774, Loss: 0.37231770157814026, Final Batch Loss: 0.20162728428840637\n",
      "Epoch 775, Loss: 0.3493124544620514, Final Batch Loss: 0.1552034169435501\n",
      "Epoch 776, Loss: 0.375180646777153, Final Batch Loss: 0.1543007493019104\n",
      "Epoch 777, Loss: 0.35551951825618744, Final Batch Loss: 0.1676429808139801\n",
      "Epoch 778, Loss: 0.4528566747903824, Final Batch Loss: 0.2654482424259186\n",
      "Epoch 779, Loss: 0.3892343044281006, Final Batch Loss: 0.1873120814561844\n",
      "Epoch 780, Loss: 0.3390963077545166, Final Batch Loss: 0.1810062676668167\n",
      "Epoch 781, Loss: 0.37759216129779816, Final Batch Loss: 0.20795324444770813\n",
      "Epoch 782, Loss: 0.3816303014755249, Final Batch Loss: 0.18468722701072693\n",
      "Epoch 783, Loss: 0.3414561003446579, Final Batch Loss: 0.16179805994033813\n",
      "Epoch 784, Loss: 0.3568769246339798, Final Batch Loss: 0.18675126135349274\n",
      "Epoch 785, Loss: 0.4309217780828476, Final Batch Loss: 0.2260763943195343\n",
      "Epoch 786, Loss: 0.37401455640792847, Final Batch Loss: 0.18648909032344818\n",
      "Epoch 787, Loss: 0.341377854347229, Final Batch Loss: 0.17067977786064148\n",
      "Epoch 788, Loss: 0.3479137122631073, Final Batch Loss: 0.15846876800060272\n",
      "Epoch 789, Loss: 0.37500613927841187, Final Batch Loss: 0.16013486683368683\n",
      "Epoch 790, Loss: 0.36361171305179596, Final Batch Loss: 0.18237605690956116\n",
      "Epoch 791, Loss: 0.34989728033542633, Final Batch Loss: 0.17911751568317413\n",
      "Epoch 792, Loss: 0.3729183226823807, Final Batch Loss: 0.1559404879808426\n",
      "Epoch 793, Loss: 0.40686818957328796, Final Batch Loss: 0.22731249034404755\n",
      "Epoch 794, Loss: 0.33380983769893646, Final Batch Loss: 0.1736859530210495\n",
      "Epoch 795, Loss: 0.36045393347740173, Final Batch Loss: 0.18338091671466827\n",
      "Epoch 796, Loss: 0.38657885789871216, Final Batch Loss: 0.20838314294815063\n",
      "Epoch 797, Loss: 0.3404432237148285, Final Batch Loss: 0.12725622951984406\n",
      "Epoch 798, Loss: 0.3186175674200058, Final Batch Loss: 0.15635275840759277\n",
      "Epoch 799, Loss: 0.37526729702949524, Final Batch Loss: 0.195443794131279\n",
      "Epoch 800, Loss: 0.34418682754039764, Final Batch Loss: 0.14455272257328033\n",
      "Epoch 801, Loss: 0.40671685338020325, Final Batch Loss: 0.21205340325832367\n",
      "Epoch 802, Loss: 0.37577030062675476, Final Batch Loss: 0.1782638132572174\n",
      "Epoch 803, Loss: 0.35553933680057526, Final Batch Loss: 0.1600198745727539\n",
      "Epoch 804, Loss: 0.36042727530002594, Final Batch Loss: 0.19332101941108704\n",
      "Epoch 805, Loss: 0.37815964221954346, Final Batch Loss: 0.1651451736688614\n",
      "Epoch 806, Loss: 0.3780312240123749, Final Batch Loss: 0.17775289714336395\n",
      "Epoch 807, Loss: 0.34034664928913116, Final Batch Loss: 0.15226437151432037\n",
      "Epoch 808, Loss: 0.38767173886299133, Final Batch Loss: 0.2065943330526352\n",
      "Epoch 809, Loss: 0.41530999541282654, Final Batch Loss: 0.22660981118679047\n",
      "Epoch 810, Loss: 0.3272296190261841, Final Batch Loss: 0.18694688379764557\n",
      "Epoch 811, Loss: 0.3871118128299713, Final Batch Loss: 0.24239033460617065\n",
      "Epoch 812, Loss: 0.3932500630617142, Final Batch Loss: 0.22090639173984528\n",
      "Epoch 813, Loss: 0.30610425770282745, Final Batch Loss: 0.13095159828662872\n",
      "Epoch 814, Loss: 0.3212817907333374, Final Batch Loss: 0.16252993047237396\n",
      "Epoch 815, Loss: 0.3928822726011276, Final Batch Loss: 0.22260771691799164\n",
      "Epoch 816, Loss: 0.36962108314037323, Final Batch Loss: 0.18739907443523407\n",
      "Epoch 817, Loss: 0.3629877418279648, Final Batch Loss: 0.17431536316871643\n",
      "Epoch 818, Loss: 0.407930850982666, Final Batch Loss: 0.2826521098613739\n",
      "Epoch 819, Loss: 0.35431139171123505, Final Batch Loss: 0.19030678272247314\n",
      "Epoch 820, Loss: 0.372758150100708, Final Batch Loss: 0.1742011308670044\n",
      "Epoch 821, Loss: 0.3722950965166092, Final Batch Loss: 0.16366522014141083\n",
      "Epoch 822, Loss: 0.3584062308073044, Final Batch Loss: 0.1973779946565628\n",
      "Epoch 823, Loss: 0.3565633296966553, Final Batch Loss: 0.15438705682754517\n",
      "Epoch 824, Loss: 0.3393521010875702, Final Batch Loss: 0.15883073210716248\n",
      "Epoch 825, Loss: 0.34173583984375, Final Batch Loss: 0.15787990391254425\n",
      "Epoch 826, Loss: 0.3223781883716583, Final Batch Loss: 0.1547158658504486\n",
      "Epoch 827, Loss: 0.3736444413661957, Final Batch Loss: 0.16210171580314636\n",
      "Epoch 828, Loss: 0.3586341291666031, Final Batch Loss: 0.1814730167388916\n",
      "Epoch 829, Loss: 0.3323495090007782, Final Batch Loss: 0.13445666432380676\n",
      "Epoch 830, Loss: 0.3229614794254303, Final Batch Loss: 0.13212065398693085\n",
      "Epoch 831, Loss: 0.3800760507583618, Final Batch Loss: 0.20658572018146515\n",
      "Epoch 832, Loss: 0.3956141173839569, Final Batch Loss: 0.22118301689624786\n",
      "Epoch 833, Loss: 0.3280530124902725, Final Batch Loss: 0.15751664340496063\n",
      "Epoch 834, Loss: 0.3712524324655533, Final Batch Loss: 0.17663279175758362\n",
      "Epoch 835, Loss: 0.3394389897584915, Final Batch Loss: 0.16573505103588104\n",
      "Epoch 836, Loss: 0.3782425969839096, Final Batch Loss: 0.16509392857551575\n",
      "Epoch 837, Loss: 0.39845865964889526, Final Batch Loss: 0.1930384337902069\n",
      "Epoch 838, Loss: 0.3177131488919258, Final Batch Loss: 0.12294013053178787\n",
      "Epoch 839, Loss: 0.35750745236873627, Final Batch Loss: 0.18458443880081177\n",
      "Epoch 840, Loss: 0.3054334372282028, Final Batch Loss: 0.1351991444826126\n",
      "Epoch 841, Loss: 0.324558362364769, Final Batch Loss: 0.17449621856212616\n",
      "Epoch 842, Loss: 0.3326549679040909, Final Batch Loss: 0.13938985764980316\n",
      "Epoch 843, Loss: 0.33052246272563934, Final Batch Loss: 0.15946443378925323\n",
      "Epoch 844, Loss: 0.37635986506938934, Final Batch Loss: 0.21642257273197174\n",
      "Epoch 845, Loss: 0.3716433048248291, Final Batch Loss: 0.16875584423542023\n",
      "Epoch 846, Loss: 0.3557206988334656, Final Batch Loss: 0.1980883777141571\n",
      "Epoch 847, Loss: 0.3836928904056549, Final Batch Loss: 0.19307655096054077\n",
      "Epoch 848, Loss: 0.34864671528339386, Final Batch Loss: 0.16976933181285858\n",
      "Epoch 849, Loss: 0.3939609080553055, Final Batch Loss: 0.2302921861410141\n",
      "Epoch 850, Loss: 0.3205294907093048, Final Batch Loss: 0.16176585853099823\n",
      "Epoch 851, Loss: 0.33810271322727203, Final Batch Loss: 0.18002820014953613\n",
      "Epoch 852, Loss: 0.3164954036474228, Final Batch Loss: 0.15482795238494873\n",
      "Epoch 853, Loss: 0.3548100143671036, Final Batch Loss: 0.16349393129348755\n",
      "Epoch 854, Loss: 0.3894374668598175, Final Batch Loss: 0.23914386332035065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 855, Loss: 0.4075491279363632, Final Batch Loss: 0.24001668393611908\n",
      "Epoch 856, Loss: 0.3901157081127167, Final Batch Loss: 0.2111022025346756\n",
      "Epoch 857, Loss: 0.42744001746177673, Final Batch Loss: 0.23887480795383453\n",
      "Epoch 858, Loss: 0.3219553232192993, Final Batch Loss: 0.16148114204406738\n",
      "Epoch 859, Loss: 0.36463841795921326, Final Batch Loss: 0.1941768378019333\n",
      "Epoch 860, Loss: 0.3754369765520096, Final Batch Loss: 0.1872662454843521\n",
      "Epoch 861, Loss: 0.3712475448846817, Final Batch Loss: 0.18932156264781952\n",
      "Epoch 862, Loss: 0.34355609118938446, Final Batch Loss: 0.1967691332101822\n",
      "Epoch 863, Loss: 0.3889561742544174, Final Batch Loss: 0.2263946235179901\n",
      "Epoch 864, Loss: 0.3286992311477661, Final Batch Loss: 0.15339334309101105\n",
      "Epoch 865, Loss: 0.29422125965356827, Final Batch Loss: 0.110283263027668\n",
      "Epoch 866, Loss: 0.3991004675626755, Final Batch Loss: 0.20224420726299286\n",
      "Epoch 867, Loss: 0.36380964517593384, Final Batch Loss: 0.2167878895998001\n",
      "Epoch 868, Loss: 0.3139610290527344, Final Batch Loss: 0.1534719616174698\n",
      "Epoch 869, Loss: 0.36201630532741547, Final Batch Loss: 0.1743057817220688\n",
      "Epoch 870, Loss: 0.319675013422966, Final Batch Loss: 0.1711191087961197\n",
      "Epoch 871, Loss: 0.34256136417388916, Final Batch Loss: 0.14792455732822418\n",
      "Epoch 872, Loss: 0.3501301556825638, Final Batch Loss: 0.15962794423103333\n",
      "Epoch 873, Loss: 0.3145039677619934, Final Batch Loss: 0.14738695323467255\n",
      "Epoch 874, Loss: 0.36281155049800873, Final Batch Loss: 0.17687690258026123\n",
      "Epoch 875, Loss: 0.35178905725479126, Final Batch Loss: 0.20065967738628387\n",
      "Epoch 876, Loss: 0.34665533900260925, Final Batch Loss: 0.17539197206497192\n",
      "Epoch 877, Loss: 0.3527783751487732, Final Batch Loss: 0.18333356082439423\n",
      "Epoch 878, Loss: 0.34809447824954987, Final Batch Loss: 0.18207009136676788\n",
      "Epoch 879, Loss: 0.31856873631477356, Final Batch Loss: 0.15357883274555206\n",
      "Epoch 880, Loss: 0.3181089609861374, Final Batch Loss: 0.14831413328647614\n",
      "Epoch 881, Loss: 0.35530707240104675, Final Batch Loss: 0.1904028356075287\n",
      "Epoch 882, Loss: 0.37207767367362976, Final Batch Loss: 0.21500913798809052\n",
      "Epoch 883, Loss: 0.3067169338464737, Final Batch Loss: 0.12854021787643433\n",
      "Epoch 884, Loss: 0.3382796198129654, Final Batch Loss: 0.1868319809436798\n",
      "Epoch 885, Loss: 0.4067853093147278, Final Batch Loss: 0.23900233209133148\n",
      "Epoch 886, Loss: 0.3441101014614105, Final Batch Loss: 0.1657238006591797\n",
      "Epoch 887, Loss: 0.3970084935426712, Final Batch Loss: 0.22530966997146606\n",
      "Epoch 888, Loss: 0.3387499004602432, Final Batch Loss: 0.18019945919513702\n",
      "Epoch 889, Loss: 0.36023271083831787, Final Batch Loss: 0.18028807640075684\n",
      "Epoch 890, Loss: 0.3699095696210861, Final Batch Loss: 0.19807136058807373\n",
      "Epoch 891, Loss: 0.3468272089958191, Final Batch Loss: 0.1838921755552292\n",
      "Epoch 892, Loss: 0.3300156146287918, Final Batch Loss: 0.14486932754516602\n",
      "Epoch 893, Loss: 0.32677488029003143, Final Batch Loss: 0.157894566655159\n",
      "Epoch 894, Loss: 0.3714248687028885, Final Batch Loss: 0.1865106225013733\n",
      "Epoch 895, Loss: 0.31128475069999695, Final Batch Loss: 0.12689897418022156\n",
      "Epoch 896, Loss: 0.3984876424074173, Final Batch Loss: 0.20789824426174164\n",
      "Epoch 897, Loss: 0.35191577672958374, Final Batch Loss: 0.16422298550605774\n",
      "Epoch 898, Loss: 0.388741210103035, Final Batch Loss: 0.24103346467018127\n",
      "Epoch 899, Loss: 0.31139467656612396, Final Batch Loss: 0.13020886480808258\n",
      "Epoch 900, Loss: 0.329783633351326, Final Batch Loss: 0.15753485262393951\n",
      "Epoch 901, Loss: 0.3442806750535965, Final Batch Loss: 0.18711134791374207\n",
      "Epoch 902, Loss: 0.35384440422058105, Final Batch Loss: 0.16282913088798523\n",
      "Epoch 903, Loss: 0.37890981137752533, Final Batch Loss: 0.1949099451303482\n",
      "Epoch 904, Loss: 0.3259388953447342, Final Batch Loss: 0.1528327614068985\n",
      "Epoch 905, Loss: 0.3473735898733139, Final Batch Loss: 0.19070324301719666\n",
      "Epoch 906, Loss: 0.3422499895095825, Final Batch Loss: 0.13834671676158905\n",
      "Epoch 907, Loss: 0.35661353170871735, Final Batch Loss: 0.1823681741952896\n",
      "Epoch 908, Loss: 0.3547385632991791, Final Batch Loss: 0.18086569011211395\n",
      "Epoch 909, Loss: 0.33041779696941376, Final Batch Loss: 0.1570277363061905\n",
      "Epoch 910, Loss: 0.3592979311943054, Final Batch Loss: 0.20043981075286865\n",
      "Epoch 911, Loss: 0.3503842353820801, Final Batch Loss: 0.2099810540676117\n",
      "Epoch 912, Loss: 0.34631015360355377, Final Batch Loss: 0.18337440490722656\n",
      "Epoch 913, Loss: 0.34456872940063477, Final Batch Loss: 0.16352243721485138\n",
      "Epoch 914, Loss: 0.31870314478874207, Final Batch Loss: 0.1506933569908142\n",
      "Epoch 915, Loss: 0.35259924829006195, Final Batch Loss: 0.16691835224628448\n",
      "Epoch 916, Loss: 0.34331074357032776, Final Batch Loss: 0.14702846109867096\n",
      "Epoch 917, Loss: 0.34451355040073395, Final Batch Loss: 0.13015882670879364\n",
      "Epoch 918, Loss: 0.32895292341709137, Final Batch Loss: 0.18352793157100677\n",
      "Epoch 919, Loss: 0.33727921545505524, Final Batch Loss: 0.16845886409282684\n",
      "Epoch 920, Loss: 0.36373762786388397, Final Batch Loss: 0.18656609952449799\n",
      "Epoch 921, Loss: 0.34988313913345337, Final Batch Loss: 0.17687177658081055\n",
      "Epoch 922, Loss: 0.3363862484693527, Final Batch Loss: 0.15904931724071503\n",
      "Epoch 923, Loss: 0.31610943377017975, Final Batch Loss: 0.14329132437705994\n",
      "Epoch 924, Loss: 0.35605576634407043, Final Batch Loss: 0.20852872729301453\n",
      "Epoch 925, Loss: 0.3553684502840042, Final Batch Loss: 0.17259040474891663\n",
      "Epoch 926, Loss: 0.3268011808395386, Final Batch Loss: 0.17591525614261627\n",
      "Epoch 927, Loss: 0.30177997052669525, Final Batch Loss: 0.1282595992088318\n",
      "Epoch 928, Loss: 0.33360210061073303, Final Batch Loss: 0.20849967002868652\n",
      "Epoch 929, Loss: 0.3068944215774536, Final Batch Loss: 0.15785060822963715\n",
      "Epoch 930, Loss: 0.29263125360012054, Final Batch Loss: 0.16026140749454498\n",
      "Epoch 931, Loss: 0.3435351848602295, Final Batch Loss: 0.17023640871047974\n",
      "Epoch 932, Loss: 0.35198429226875305, Final Batch Loss: 0.1722392439842224\n",
      "Epoch 933, Loss: 0.3064051419496536, Final Batch Loss: 0.1643020063638687\n",
      "Epoch 934, Loss: 0.3744012415409088, Final Batch Loss: 0.21403691172599792\n",
      "Epoch 935, Loss: 0.3470829427242279, Final Batch Loss: 0.17219945788383484\n",
      "Epoch 936, Loss: 0.3261152058839798, Final Batch Loss: 0.1518968790769577\n",
      "Epoch 937, Loss: 0.3269883692264557, Final Batch Loss: 0.16079647839069366\n",
      "Epoch 938, Loss: 0.31493665277957916, Final Batch Loss: 0.16614378988742828\n",
      "Epoch 939, Loss: 0.3585440665483475, Final Batch Loss: 0.18125705420970917\n",
      "Epoch 940, Loss: 0.349922850728035, Final Batch Loss: 0.18018892407417297\n",
      "Epoch 941, Loss: 0.33207967877388, Final Batch Loss: 0.12421184778213501\n",
      "Epoch 942, Loss: 0.31035682559013367, Final Batch Loss: 0.1378737986087799\n",
      "Epoch 943, Loss: 0.33054855465888977, Final Batch Loss: 0.1900889277458191\n",
      "Epoch 944, Loss: 0.3350250869989395, Final Batch Loss: 0.19411136209964752\n",
      "Epoch 945, Loss: 0.2830112800002098, Final Batch Loss: 0.11753249913454056\n",
      "Epoch 946, Loss: 0.340954914689064, Final Batch Loss: 0.17639416456222534\n",
      "Epoch 947, Loss: 0.3845057636499405, Final Batch Loss: 0.2508397400379181\n",
      "Epoch 948, Loss: 0.29032961279153824, Final Batch Loss: 0.12306772917509079\n",
      "Epoch 949, Loss: 0.38520823419094086, Final Batch Loss: 0.20110851526260376\n",
      "Epoch 950, Loss: 0.36697354912757874, Final Batch Loss: 0.18327027559280396\n",
      "Epoch 951, Loss: 0.27870874106884, Final Batch Loss: 0.12896232306957245\n",
      "Epoch 952, Loss: 0.29671430587768555, Final Batch Loss: 0.15032914280891418\n",
      "Epoch 953, Loss: 0.2758606970310211, Final Batch Loss: 0.14196480810642242\n",
      "Epoch 954, Loss: 0.3405970185995102, Final Batch Loss: 0.15501588582992554\n",
      "Epoch 955, Loss: 0.33512376993894577, Final Batch Loss: 0.11459306627511978\n",
      "Epoch 956, Loss: 0.2981836497783661, Final Batch Loss: 0.17553555965423584\n",
      "Epoch 957, Loss: 0.32144302129745483, Final Batch Loss: 0.1427338719367981\n",
      "Epoch 958, Loss: 0.327788770198822, Final Batch Loss: 0.1954231560230255\n",
      "Epoch 959, Loss: 0.30447763204574585, Final Batch Loss: 0.15168976783752441\n",
      "Epoch 960, Loss: 0.3348361402750015, Final Batch Loss: 0.1697811782360077\n",
      "Epoch 961, Loss: 0.2861769199371338, Final Batch Loss: 0.1616242527961731\n",
      "Epoch 962, Loss: 0.33023183047771454, Final Batch Loss: 0.17408859729766846\n",
      "Epoch 963, Loss: 0.3297801911830902, Final Batch Loss: 0.1378375142812729\n",
      "Epoch 964, Loss: 0.34951792657375336, Final Batch Loss: 0.16021670401096344\n",
      "Epoch 965, Loss: 0.3577995300292969, Final Batch Loss: 0.17651131749153137\n",
      "Epoch 966, Loss: 0.30942439287900925, Final Batch Loss: 0.11196159571409225\n",
      "Epoch 967, Loss: 0.31709766387939453, Final Batch Loss: 0.1217949241399765\n",
      "Epoch 968, Loss: 0.32772235572338104, Final Batch Loss: 0.1799435019493103\n",
      "Epoch 969, Loss: 0.3507155776023865, Final Batch Loss: 0.16770628094673157\n",
      "Epoch 970, Loss: 0.34119561314582825, Final Batch Loss: 0.1893363893032074\n",
      "Epoch 971, Loss: 0.2917250990867615, Final Batch Loss: 0.14242444932460785\n",
      "Epoch 972, Loss: 0.3045176565647125, Final Batch Loss: 0.14758047461509705\n",
      "Epoch 973, Loss: 0.31165242195129395, Final Batch Loss: 0.15013593435287476\n",
      "Epoch 974, Loss: 0.33496981859207153, Final Batch Loss: 0.18799138069152832\n",
      "Epoch 975, Loss: 0.3063480108976364, Final Batch Loss: 0.14396899938583374\n",
      "Epoch 976, Loss: 0.3431142270565033, Final Batch Loss: 0.15073174238204956\n",
      "Epoch 977, Loss: 0.31979532539844513, Final Batch Loss: 0.14493554830551147\n",
      "Epoch 978, Loss: 0.28862781822681427, Final Batch Loss: 0.15372532606124878\n",
      "Epoch 979, Loss: 0.27137161791324615, Final Batch Loss: 0.12866970896720886\n",
      "Epoch 980, Loss: 0.358858585357666, Final Batch Loss: 0.18136706948280334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 981, Loss: 0.2899061441421509, Final Batch Loss: 0.13610248267650604\n",
      "Epoch 982, Loss: 0.32581567764282227, Final Batch Loss: 0.14823436737060547\n",
      "Epoch 983, Loss: 0.35989704728126526, Final Batch Loss: 0.2166142761707306\n",
      "Epoch 984, Loss: 0.29600293934345245, Final Batch Loss: 0.1438540369272232\n",
      "Epoch 985, Loss: 0.3084644675254822, Final Batch Loss: 0.1513906568288803\n",
      "Epoch 986, Loss: 0.31239187717437744, Final Batch Loss: 0.1481785923242569\n",
      "Epoch 987, Loss: 0.29180335998535156, Final Batch Loss: 0.15606319904327393\n",
      "Epoch 988, Loss: 0.35180383920669556, Final Batch Loss: 0.22010667622089386\n",
      "Epoch 989, Loss: 0.30588825047016144, Final Batch Loss: 0.1540961116552353\n",
      "Epoch 990, Loss: 0.3495551198720932, Final Batch Loss: 0.15466676652431488\n",
      "Epoch 991, Loss: 0.29638081043958664, Final Batch Loss: 0.11144543439149857\n",
      "Epoch 992, Loss: 0.3187027871608734, Final Batch Loss: 0.14358149468898773\n",
      "Epoch 993, Loss: 0.31705398857593536, Final Batch Loss: 0.15690259635448456\n",
      "Epoch 994, Loss: 0.34575721621513367, Final Batch Loss: 0.18713033199310303\n",
      "Epoch 995, Loss: 0.3011041134595871, Final Batch Loss: 0.14193038642406464\n",
      "Epoch 996, Loss: 0.3282410502433777, Final Batch Loss: 0.1914592981338501\n",
      "Epoch 997, Loss: 0.3208981901407242, Final Batch Loss: 0.1464909166097641\n",
      "Epoch 998, Loss: 0.3528602570295334, Final Batch Loss: 0.19726386666297913\n",
      "Epoch 999, Loss: 0.2855626940727234, Final Batch Loss: 0.14757536351680756\n",
      "Epoch 1000, Loss: 0.3245205879211426, Final Batch Loss: 0.15780705213546753\n",
      "Epoch 1001, Loss: 0.2682165578007698, Final Batch Loss: 0.10206896811723709\n",
      "Epoch 1002, Loss: 0.32051563262939453, Final Batch Loss: 0.16714806854724884\n",
      "Epoch 1003, Loss: 0.3037617355585098, Final Batch Loss: 0.14492134749889374\n",
      "Epoch 1004, Loss: 0.3040914535522461, Final Batch Loss: 0.1166786253452301\n",
      "Epoch 1005, Loss: 0.3009043335914612, Final Batch Loss: 0.1403917521238327\n",
      "Epoch 1006, Loss: 0.30380694568157196, Final Batch Loss: 0.13299916684627533\n",
      "Epoch 1007, Loss: 0.2739056795835495, Final Batch Loss: 0.12558211386203766\n",
      "Epoch 1008, Loss: 0.2913215607404709, Final Batch Loss: 0.12255798280239105\n",
      "Epoch 1009, Loss: 0.37012961506843567, Final Batch Loss: 0.2168751358985901\n",
      "Epoch 1010, Loss: 0.31387244164943695, Final Batch Loss: 0.17725017666816711\n",
      "Epoch 1011, Loss: 0.30912894010543823, Final Batch Loss: 0.14866062998771667\n",
      "Epoch 1012, Loss: 0.2812936529517174, Final Batch Loss: 0.1193828359246254\n",
      "Epoch 1013, Loss: 0.28059206902980804, Final Batch Loss: 0.1455260068178177\n",
      "Epoch 1014, Loss: 0.32300642132759094, Final Batch Loss: 0.16674518585205078\n",
      "Epoch 1015, Loss: 0.26254716515541077, Final Batch Loss: 0.13793347775936127\n",
      "Epoch 1016, Loss: 0.31950755417346954, Final Batch Loss: 0.18158291280269623\n",
      "Epoch 1017, Loss: 0.2967955619096756, Final Batch Loss: 0.1618480682373047\n",
      "Epoch 1018, Loss: 0.3023914769291878, Final Batch Loss: 0.11906128376722336\n",
      "Epoch 1019, Loss: 0.29442474246025085, Final Batch Loss: 0.12288305163383484\n",
      "Epoch 1020, Loss: 0.28866371512413025, Final Batch Loss: 0.14136509597301483\n",
      "Epoch 1021, Loss: 0.305403009057045, Final Batch Loss: 0.15655288100242615\n",
      "Epoch 1022, Loss: 0.29246188700199127, Final Batch Loss: 0.14336006343364716\n",
      "Epoch 1023, Loss: 0.3244861215353012, Final Batch Loss: 0.15432271361351013\n",
      "Epoch 1024, Loss: 0.31270451843738556, Final Batch Loss: 0.15616483986377716\n",
      "Epoch 1025, Loss: 0.3034161925315857, Final Batch Loss: 0.1284816414117813\n",
      "Epoch 1026, Loss: 0.31866680085659027, Final Batch Loss: 0.1645451933145523\n",
      "Epoch 1027, Loss: 0.3351980298757553, Final Batch Loss: 0.17266882956027985\n",
      "Epoch 1028, Loss: 0.28604651987552643, Final Batch Loss: 0.1275443583726883\n",
      "Epoch 1029, Loss: 0.28586238622665405, Final Batch Loss: 0.13076800107955933\n",
      "Epoch 1030, Loss: 0.3345894068479538, Final Batch Loss: 0.1655648946762085\n",
      "Epoch 1031, Loss: 0.3074646592140198, Final Batch Loss: 0.1613372415304184\n",
      "Epoch 1032, Loss: 0.2739349901676178, Final Batch Loss: 0.09665212035179138\n",
      "Epoch 1033, Loss: 0.3634447604417801, Final Batch Loss: 0.20257416367530823\n",
      "Epoch 1034, Loss: 0.27279242873191833, Final Batch Loss: 0.12296958267688751\n",
      "Epoch 1035, Loss: 0.280879944562912, Final Batch Loss: 0.12013424932956696\n",
      "Epoch 1036, Loss: 0.34596939384937286, Final Batch Loss: 0.20133091509342194\n",
      "Epoch 1037, Loss: 0.3332711160182953, Final Batch Loss: 0.17984411120414734\n",
      "Epoch 1038, Loss: 0.2883330136537552, Final Batch Loss: 0.15191785991191864\n",
      "Epoch 1039, Loss: 0.3044091463088989, Final Batch Loss: 0.16890500485897064\n",
      "Epoch 1040, Loss: 0.3596564084291458, Final Batch Loss: 0.2170809805393219\n",
      "Epoch 1041, Loss: 0.3244719058275223, Final Batch Loss: 0.19013595581054688\n",
      "Epoch 1042, Loss: 0.3011544793844223, Final Batch Loss: 0.14616313576698303\n",
      "Epoch 1043, Loss: 0.288403183221817, Final Batch Loss: 0.1386716365814209\n",
      "Epoch 1044, Loss: 0.3224198967218399, Final Batch Loss: 0.1379937082529068\n",
      "Epoch 1045, Loss: 0.28947576880455017, Final Batch Loss: 0.13318021595478058\n",
      "Epoch 1046, Loss: 0.30006762593984604, Final Batch Loss: 0.11498107761144638\n",
      "Epoch 1047, Loss: 0.32076840102672577, Final Batch Loss: 0.1397465169429779\n",
      "Epoch 1048, Loss: 0.2906460165977478, Final Batch Loss: 0.1123095154762268\n",
      "Epoch 1049, Loss: 0.28803926706314087, Final Batch Loss: 0.12899526953697205\n",
      "Epoch 1050, Loss: 0.276631698012352, Final Batch Loss: 0.1138986200094223\n",
      "Epoch 1051, Loss: 0.31355008482933044, Final Batch Loss: 0.1720799207687378\n",
      "Epoch 1052, Loss: 0.25941817462444305, Final Batch Loss: 0.11680592596530914\n",
      "Epoch 1053, Loss: 0.3022643178701401, Final Batch Loss: 0.19096258282661438\n",
      "Epoch 1054, Loss: 0.28059445321559906, Final Batch Loss: 0.11601187288761139\n",
      "Epoch 1055, Loss: 0.34375323355197906, Final Batch Loss: 0.16458021104335785\n",
      "Epoch 1056, Loss: 0.2988803833723068, Final Batch Loss: 0.13494646549224854\n",
      "Epoch 1057, Loss: 0.3378596007823944, Final Batch Loss: 0.19551454484462738\n",
      "Epoch 1058, Loss: 0.2818147540092468, Final Batch Loss: 0.13232137262821198\n",
      "Epoch 1059, Loss: 0.32481835782527924, Final Batch Loss: 0.16196458041667938\n",
      "Epoch 1060, Loss: 0.34730273485183716, Final Batch Loss: 0.15921464562416077\n",
      "Epoch 1061, Loss: 0.2850872278213501, Final Batch Loss: 0.10749714076519012\n",
      "Epoch 1062, Loss: 0.3134624511003494, Final Batch Loss: 0.14124532043933868\n",
      "Epoch 1063, Loss: 0.33646006882190704, Final Batch Loss: 0.19267310202121735\n",
      "Epoch 1064, Loss: 0.2668813019990921, Final Batch Loss: 0.1324242651462555\n",
      "Epoch 1065, Loss: 0.27722831070423126, Final Batch Loss: 0.13109034299850464\n",
      "Epoch 1066, Loss: 0.2744504064321518, Final Batch Loss: 0.11320827901363373\n",
      "Epoch 1067, Loss: 0.3136632740497589, Final Batch Loss: 0.1670038253068924\n",
      "Epoch 1068, Loss: 0.2874465063214302, Final Batch Loss: 0.11825547367334366\n",
      "Epoch 1069, Loss: 0.29392004013061523, Final Batch Loss: 0.12954594194889069\n",
      "Epoch 1070, Loss: 0.316922128200531, Final Batch Loss: 0.1494244635105133\n",
      "Epoch 1071, Loss: 0.33994483947753906, Final Batch Loss: 0.16326315701007843\n",
      "Epoch 1072, Loss: 0.35072536766529083, Final Batch Loss: 0.21962271630764008\n",
      "Epoch 1073, Loss: 0.300395205616951, Final Batch Loss: 0.1139954924583435\n",
      "Epoch 1074, Loss: 0.3191305696964264, Final Batch Loss: 0.13650083541870117\n",
      "Epoch 1075, Loss: 0.3331296741962433, Final Batch Loss: 0.17661260068416595\n",
      "Epoch 1076, Loss: 0.2829013839364052, Final Batch Loss: 0.11816803365945816\n",
      "Epoch 1077, Loss: 0.3627586215734482, Final Batch Loss: 0.16144245862960815\n",
      "Epoch 1078, Loss: 0.33763712644577026, Final Batch Loss: 0.1605416089296341\n",
      "Epoch 1079, Loss: 0.2974284067749977, Final Batch Loss: 0.11930841952562332\n",
      "Epoch 1080, Loss: 0.3155418187379837, Final Batch Loss: 0.16004015505313873\n",
      "Epoch 1081, Loss: 0.2953605055809021, Final Batch Loss: 0.15072987973690033\n",
      "Epoch 1082, Loss: 0.29970425367355347, Final Batch Loss: 0.16058635711669922\n",
      "Epoch 1083, Loss: 0.3106818199157715, Final Batch Loss: 0.14937621355056763\n",
      "Epoch 1084, Loss: 0.27093131840229034, Final Batch Loss: 0.13308294117450714\n",
      "Epoch 1085, Loss: 0.28969040513038635, Final Batch Loss: 0.1185801774263382\n",
      "Epoch 1086, Loss: 0.333140030503273, Final Batch Loss: 0.18332907557487488\n",
      "Epoch 1087, Loss: 0.2769702225923538, Final Batch Loss: 0.12829551100730896\n",
      "Epoch 1088, Loss: 0.28378254920244217, Final Batch Loss: 0.15981872379779816\n",
      "Epoch 1089, Loss: 0.3157530575990677, Final Batch Loss: 0.1302887201309204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1090, Loss: 0.26403965055942535, Final Batch Loss: 0.1329461634159088\n",
      "Epoch 1091, Loss: 0.28896065056324005, Final Batch Loss: 0.1259126216173172\n",
      "Epoch 1092, Loss: 0.34384679794311523, Final Batch Loss: 0.18568368256092072\n",
      "Epoch 1093, Loss: 0.26614172011613846, Final Batch Loss: 0.11381082981824875\n",
      "Epoch 1094, Loss: 0.2885989844799042, Final Batch Loss: 0.15090954303741455\n",
      "Epoch 1095, Loss: 0.31700071692466736, Final Batch Loss: 0.14211499691009521\n",
      "Epoch 1096, Loss: 0.29088759422302246, Final Batch Loss: 0.15306106209754944\n",
      "Epoch 1097, Loss: 0.29309992492198944, Final Batch Loss: 0.14952529966831207\n",
      "Epoch 1098, Loss: 0.2795571908354759, Final Batch Loss: 0.10951701551675797\n",
      "Epoch 1099, Loss: 0.28737762570381165, Final Batch Loss: 0.15191133320331573\n",
      "Epoch 1100, Loss: 0.2841009199619293, Final Batch Loss: 0.14654552936553955\n",
      "Epoch 1101, Loss: 0.2919023334980011, Final Batch Loss: 0.12848277390003204\n",
      "Epoch 1102, Loss: 0.29535920917987823, Final Batch Loss: 0.1571282595396042\n",
      "Epoch 1103, Loss: 0.33264946192502975, Final Batch Loss: 0.21319255232810974\n",
      "Epoch 1104, Loss: 0.27112923562526703, Final Batch Loss: 0.16095396876335144\n",
      "Epoch 1105, Loss: 0.27905334532260895, Final Batch Loss: 0.13478334248065948\n",
      "Epoch 1106, Loss: 0.2722322940826416, Final Batch Loss: 0.14166460931301117\n",
      "Epoch 1107, Loss: 0.36266687512397766, Final Batch Loss: 0.1856403946876526\n",
      "Epoch 1108, Loss: 0.3201385363936424, Final Batch Loss: 0.1956939995288849\n",
      "Epoch 1109, Loss: 0.3380766659975052, Final Batch Loss: 0.1796184778213501\n",
      "Epoch 1110, Loss: 0.3201453983783722, Final Batch Loss: 0.16390196979045868\n",
      "Epoch 1111, Loss: 0.2879888117313385, Final Batch Loss: 0.15213902294635773\n",
      "Epoch 1112, Loss: 0.3188617527484894, Final Batch Loss: 0.20417971909046173\n",
      "Epoch 1113, Loss: 0.2917220890522003, Final Batch Loss: 0.15857058763504028\n",
      "Epoch 1114, Loss: 0.28622183203697205, Final Batch Loss: 0.1591506153345108\n",
      "Epoch 1115, Loss: 0.2833353206515312, Final Batch Loss: 0.16327954828739166\n",
      "Epoch 1116, Loss: 0.26417872309684753, Final Batch Loss: 0.13645529747009277\n",
      "Epoch 1117, Loss: 0.29559117555618286, Final Batch Loss: 0.1573437601327896\n",
      "Epoch 1118, Loss: 0.26756366342306137, Final Batch Loss: 0.10135578364133835\n",
      "Epoch 1119, Loss: 0.33545856177806854, Final Batch Loss: 0.1462922841310501\n",
      "Epoch 1120, Loss: 0.3266785889863968, Final Batch Loss: 0.18150073289871216\n",
      "Epoch 1121, Loss: 0.3195023834705353, Final Batch Loss: 0.1527101844549179\n",
      "Epoch 1122, Loss: 0.31427358090877533, Final Batch Loss: 0.14839407801628113\n",
      "Epoch 1123, Loss: 0.2732616513967514, Final Batch Loss: 0.12497669458389282\n",
      "Epoch 1124, Loss: 0.266054630279541, Final Batch Loss: 0.12336833775043488\n",
      "Epoch 1125, Loss: 0.2734936773777008, Final Batch Loss: 0.13263237476348877\n",
      "Epoch 1126, Loss: 0.28596751391887665, Final Batch Loss: 0.14815448224544525\n",
      "Epoch 1127, Loss: 0.26787297427654266, Final Batch Loss: 0.10343940556049347\n",
      "Epoch 1128, Loss: 0.3094310164451599, Final Batch Loss: 0.1648319959640503\n",
      "Epoch 1129, Loss: 0.3430096507072449, Final Batch Loss: 0.20411328971385956\n",
      "Epoch 1130, Loss: 0.30817726254463196, Final Batch Loss: 0.16839709877967834\n",
      "Epoch 1131, Loss: 0.2732669338583946, Final Batch Loss: 0.10634820908308029\n",
      "Epoch 1132, Loss: 0.2886635661125183, Final Batch Loss: 0.1632811427116394\n",
      "Epoch 1133, Loss: 0.28407005965709686, Final Batch Loss: 0.14480800926685333\n",
      "Epoch 1134, Loss: 0.28006425499916077, Final Batch Loss: 0.1528269350528717\n",
      "Epoch 1135, Loss: 0.271956667304039, Final Batch Loss: 0.1173236221075058\n",
      "Epoch 1136, Loss: 0.2752663344144821, Final Batch Loss: 0.12713339924812317\n",
      "Epoch 1137, Loss: 0.30296626687049866, Final Batch Loss: 0.1396978497505188\n",
      "Epoch 1138, Loss: 0.31849856674671173, Final Batch Loss: 0.18950121104717255\n",
      "Epoch 1139, Loss: 0.2931973338127136, Final Batch Loss: 0.13745614886283875\n",
      "Epoch 1140, Loss: 0.2847932204604149, Final Batch Loss: 0.09492241591215134\n",
      "Epoch 1141, Loss: 0.24302825331687927, Final Batch Loss: 0.1315339207649231\n",
      "Epoch 1142, Loss: 0.29583074152469635, Final Batch Loss: 0.14795860648155212\n",
      "Epoch 1143, Loss: 0.27491649985313416, Final Batch Loss: 0.17088544368743896\n",
      "Epoch 1144, Loss: 0.3113458752632141, Final Batch Loss: 0.11334820091724396\n",
      "Epoch 1145, Loss: 0.3191928416490555, Final Batch Loss: 0.16519249975681305\n",
      "Epoch 1146, Loss: 0.3028225898742676, Final Batch Loss: 0.16803544759750366\n",
      "Epoch 1147, Loss: 0.25405707210302353, Final Batch Loss: 0.13470110297203064\n",
      "Epoch 1148, Loss: 0.35736316442489624, Final Batch Loss: 0.20588895678520203\n",
      "Epoch 1149, Loss: 0.25437159091234207, Final Batch Loss: 0.09670158475637436\n",
      "Epoch 1150, Loss: 0.3199699819087982, Final Batch Loss: 0.1826876401901245\n",
      "Epoch 1151, Loss: 0.3142035901546478, Final Batch Loss: 0.19155937433242798\n",
      "Epoch 1152, Loss: 0.27936939150094986, Final Batch Loss: 0.16625559329986572\n",
      "Epoch 1153, Loss: 0.3232479840517044, Final Batch Loss: 0.19366435706615448\n",
      "Epoch 1154, Loss: 0.2978314012289047, Final Batch Loss: 0.18182320892810822\n",
      "Epoch 1155, Loss: 0.2736065089702606, Final Batch Loss: 0.12952515482902527\n",
      "Epoch 1156, Loss: 0.27755774557590485, Final Batch Loss: 0.12992100417613983\n",
      "Epoch 1157, Loss: 0.2781555503606796, Final Batch Loss: 0.13747990131378174\n",
      "Epoch 1158, Loss: 0.26248563826084137, Final Batch Loss: 0.1306515485048294\n",
      "Epoch 1159, Loss: 0.3037489652633667, Final Batch Loss: 0.16186146438121796\n",
      "Epoch 1160, Loss: 0.2629920318722725, Final Batch Loss: 0.1216701939702034\n",
      "Epoch 1161, Loss: 0.3194756954908371, Final Batch Loss: 0.15506157279014587\n",
      "Epoch 1162, Loss: 0.2747201919555664, Final Batch Loss: 0.14828801155090332\n",
      "Epoch 1163, Loss: 0.27571044862270355, Final Batch Loss: 0.12821181118488312\n",
      "Epoch 1164, Loss: 0.2939102500677109, Final Batch Loss: 0.14569061994552612\n",
      "Epoch 1165, Loss: 0.2528911381959915, Final Batch Loss: 0.08199699223041534\n",
      "Epoch 1166, Loss: 0.24229251593351364, Final Batch Loss: 0.0833735540509224\n",
      "Epoch 1167, Loss: 0.3011830151081085, Final Batch Loss: 0.16163015365600586\n",
      "Epoch 1168, Loss: 0.2972279340028763, Final Batch Loss: 0.13864046335220337\n",
      "Epoch 1169, Loss: 0.2676096111536026, Final Batch Loss: 0.12597154080867767\n",
      "Epoch 1170, Loss: 0.34302400052547455, Final Batch Loss: 0.20667879283428192\n",
      "Epoch 1171, Loss: 0.3197801560163498, Final Batch Loss: 0.14206136763095856\n",
      "Epoch 1172, Loss: 0.30720019340515137, Final Batch Loss: 0.12705139815807343\n",
      "Epoch 1173, Loss: 0.32284072041511536, Final Batch Loss: 0.18088828027248383\n",
      "Epoch 1174, Loss: 0.24789664149284363, Final Batch Loss: 0.10562402009963989\n",
      "Epoch 1175, Loss: 0.2682074010372162, Final Batch Loss: 0.13166332244873047\n",
      "Epoch 1176, Loss: 0.2996755987405777, Final Batch Loss: 0.16514888405799866\n",
      "Epoch 1177, Loss: 0.3111220449209213, Final Batch Loss: 0.16726647317409515\n",
      "Epoch 1178, Loss: 0.26882656663656235, Final Batch Loss: 0.11804283410310745\n",
      "Epoch 1179, Loss: 0.2775881141424179, Final Batch Loss: 0.13844622671604156\n",
      "Epoch 1180, Loss: 0.3085140734910965, Final Batch Loss: 0.17862659692764282\n",
      "Epoch 1181, Loss: 0.2761588990688324, Final Batch Loss: 0.12007199227809906\n",
      "Epoch 1182, Loss: 0.30303412675857544, Final Batch Loss: 0.17120684683322906\n",
      "Epoch 1183, Loss: 0.29197248816490173, Final Batch Loss: 0.14499573409557343\n",
      "Epoch 1184, Loss: 0.27888138592243195, Final Batch Loss: 0.13119740784168243\n",
      "Epoch 1185, Loss: 0.24502070248126984, Final Batch Loss: 0.09953330457210541\n",
      "Epoch 1186, Loss: 0.3145112842321396, Final Batch Loss: 0.14384658634662628\n",
      "Epoch 1187, Loss: 0.2976984679698944, Final Batch Loss: 0.14334753155708313\n",
      "Epoch 1188, Loss: 0.26456642150878906, Final Batch Loss: 0.12615056335926056\n",
      "Epoch 1189, Loss: 0.2975829392671585, Final Batch Loss: 0.1353023499250412\n",
      "Epoch 1190, Loss: 0.31047090888023376, Final Batch Loss: 0.15430745482444763\n",
      "Epoch 1191, Loss: 0.32653629779815674, Final Batch Loss: 0.19105283915996552\n",
      "Epoch 1192, Loss: 0.2951689660549164, Final Batch Loss: 0.14234977960586548\n",
      "Epoch 1193, Loss: 0.2700468450784683, Final Batch Loss: 0.1320190131664276\n",
      "Epoch 1194, Loss: 0.3082037568092346, Final Batch Loss: 0.18140573799610138\n",
      "Epoch 1195, Loss: 0.2736719474196434, Final Batch Loss: 0.1246752217411995\n",
      "Epoch 1196, Loss: 0.320506289601326, Final Batch Loss: 0.17526863515377045\n",
      "Epoch 1197, Loss: 0.25418295711278915, Final Batch Loss: 0.11467447131872177\n",
      "Epoch 1198, Loss: 0.3099170923233032, Final Batch Loss: 0.1718989610671997\n",
      "Epoch 1199, Loss: 0.27514105290174484, Final Batch Loss: 0.11958689242601395\n",
      "Epoch 1200, Loss: 0.2974686920642853, Final Batch Loss: 0.14940983057022095\n",
      "Epoch 1201, Loss: 0.28996993601322174, Final Batch Loss: 0.13004277646541595\n",
      "Epoch 1202, Loss: 0.2976784408092499, Final Batch Loss: 0.19322994351387024\n",
      "Epoch 1203, Loss: 0.3282860815525055, Final Batch Loss: 0.16000179946422577\n",
      "Epoch 1204, Loss: 0.2283584401011467, Final Batch Loss: 0.08535074442625046\n",
      "Epoch 1205, Loss: 0.32224883139133453, Final Batch Loss: 0.13441501557826996\n",
      "Epoch 1206, Loss: 0.2882918566465378, Final Batch Loss: 0.14482799172401428\n",
      "Epoch 1207, Loss: 0.23652537912130356, Final Batch Loss: 0.09155867248773575\n",
      "Epoch 1208, Loss: 0.31319405138492584, Final Batch Loss: 0.18235217034816742\n",
      "Epoch 1209, Loss: 0.27133554965257645, Final Batch Loss: 0.10877952724695206\n",
      "Epoch 1210, Loss: 0.2806278467178345, Final Batch Loss: 0.14077161252498627\n",
      "Epoch 1211, Loss: 0.268082857131958, Final Batch Loss: 0.11730052530765533\n",
      "Epoch 1212, Loss: 0.24341151118278503, Final Batch Loss: 0.14866985380649567\n",
      "Epoch 1213, Loss: 0.2687874287366867, Final Batch Loss: 0.09364067018032074\n",
      "Epoch 1214, Loss: 0.24933253228664398, Final Batch Loss: 0.14387798309326172\n",
      "Epoch 1215, Loss: 0.28130754828453064, Final Batch Loss: 0.12824101746082306\n",
      "Epoch 1216, Loss: 0.2996077761054039, Final Batch Loss: 0.1835654079914093\n",
      "Epoch 1217, Loss: 0.29501858353614807, Final Batch Loss: 0.18943454325199127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1218, Loss: 0.2918742448091507, Final Batch Loss: 0.151030495762825\n",
      "Epoch 1219, Loss: 0.28401732444763184, Final Batch Loss: 0.14467757940292358\n",
      "Epoch 1220, Loss: 0.2980911582708359, Final Batch Loss: 0.16434721648693085\n",
      "Epoch 1221, Loss: 0.2708101272583008, Final Batch Loss: 0.11745564639568329\n",
      "Epoch 1222, Loss: 0.2410750612616539, Final Batch Loss: 0.11344160884618759\n",
      "Epoch 1223, Loss: 0.2616013288497925, Final Batch Loss: 0.1408802717924118\n",
      "Epoch 1224, Loss: 0.25743256509304047, Final Batch Loss: 0.12596344947814941\n",
      "Epoch 1225, Loss: 0.2885076552629471, Final Batch Loss: 0.13881172239780426\n",
      "Epoch 1226, Loss: 0.2745727002620697, Final Batch Loss: 0.1394796520471573\n",
      "Epoch 1227, Loss: 0.2836489826440811, Final Batch Loss: 0.15643592178821564\n",
      "Epoch 1228, Loss: 0.2524654418230057, Final Batch Loss: 0.09755201637744904\n",
      "Epoch 1229, Loss: 0.27069567143917084, Final Batch Loss: 0.1632537543773651\n",
      "Epoch 1230, Loss: 0.26043708622455597, Final Batch Loss: 0.12615451216697693\n",
      "Epoch 1231, Loss: 0.2691783308982849, Final Batch Loss: 0.13536126911640167\n",
      "Epoch 1232, Loss: 0.24076301604509354, Final Batch Loss: 0.11543732136487961\n",
      "Epoch 1233, Loss: 0.25847113132476807, Final Batch Loss: 0.12516501545906067\n",
      "Epoch 1234, Loss: 0.26254818588495255, Final Batch Loss: 0.1499873399734497\n",
      "Epoch 1235, Loss: 0.2805953174829483, Final Batch Loss: 0.1431666761636734\n",
      "Epoch 1236, Loss: 0.2677628621459007, Final Batch Loss: 0.17083501815795898\n",
      "Epoch 1237, Loss: 0.2834515795111656, Final Batch Loss: 0.1614098846912384\n",
      "Epoch 1238, Loss: 0.2444131225347519, Final Batch Loss: 0.10531407594680786\n",
      "Epoch 1239, Loss: 0.2834928035736084, Final Batch Loss: 0.12936601042747498\n",
      "Epoch 1240, Loss: 0.27331723272800446, Final Batch Loss: 0.11529378592967987\n",
      "Epoch 1241, Loss: 0.3065754175186157, Final Batch Loss: 0.16539880633354187\n",
      "Epoch 1242, Loss: 0.26102304458618164, Final Batch Loss: 0.1327044665813446\n",
      "Epoch 1243, Loss: 0.32346299290657043, Final Batch Loss: 0.16017358005046844\n",
      "Epoch 1244, Loss: 0.2703363299369812, Final Batch Loss: 0.14134959876537323\n",
      "Epoch 1245, Loss: 0.30355576425790787, Final Batch Loss: 0.19326990842819214\n",
      "Epoch 1246, Loss: 0.2690334767103195, Final Batch Loss: 0.13815729320049286\n",
      "Epoch 1247, Loss: 0.29203058779239655, Final Batch Loss: 0.16448697447776794\n",
      "Epoch 1248, Loss: 0.296096608042717, Final Batch Loss: 0.16562606394290924\n",
      "Epoch 1249, Loss: 0.2768201380968094, Final Batch Loss: 0.14398668706417084\n",
      "Epoch 1250, Loss: 0.297722190618515, Final Batch Loss: 0.12898851931095123\n",
      "Epoch 1251, Loss: 0.27660181373357773, Final Batch Loss: 0.11193840950727463\n",
      "Epoch 1252, Loss: 0.27518250048160553, Final Batch Loss: 0.14509253203868866\n",
      "Epoch 1253, Loss: 0.23718463629484177, Final Batch Loss: 0.10900702327489853\n",
      "Epoch 1254, Loss: 0.28147220611572266, Final Batch Loss: 0.16460925340652466\n",
      "Epoch 1255, Loss: 0.2941874563694, Final Batch Loss: 0.1390511840581894\n",
      "Epoch 1256, Loss: 0.31201256811618805, Final Batch Loss: 0.15115030109882355\n",
      "Epoch 1257, Loss: 0.2718973010778427, Final Batch Loss: 0.10973270237445831\n",
      "Epoch 1258, Loss: 0.27932821214199066, Final Batch Loss: 0.16459695994853973\n",
      "Epoch 1259, Loss: 0.26092221587896347, Final Batch Loss: 0.09726535528898239\n",
      "Epoch 1260, Loss: 0.2483391910791397, Final Batch Loss: 0.1205931305885315\n",
      "Epoch 1261, Loss: 0.2690396308898926, Final Batch Loss: 0.1425161361694336\n",
      "Epoch 1262, Loss: 0.2769780457019806, Final Batch Loss: 0.13356517255306244\n",
      "Epoch 1263, Loss: 0.2922917753458023, Final Batch Loss: 0.16862362623214722\n",
      "Epoch 1264, Loss: 0.2671418637037277, Final Batch Loss: 0.1504964530467987\n",
      "Epoch 1265, Loss: 0.2880202382802963, Final Batch Loss: 0.15857729315757751\n",
      "Epoch 1266, Loss: 0.24525728821754456, Final Batch Loss: 0.09605076909065247\n",
      "Epoch 1267, Loss: 0.2770702689886093, Final Batch Loss: 0.1357983499765396\n",
      "Epoch 1268, Loss: 0.27813979983329773, Final Batch Loss: 0.15810176730155945\n",
      "Epoch 1269, Loss: 0.2578694149851799, Final Batch Loss: 0.14057576656341553\n",
      "Epoch 1270, Loss: 0.28314557671546936, Final Batch Loss: 0.14432017505168915\n",
      "Epoch 1271, Loss: 0.2592241168022156, Final Batch Loss: 0.11475884914398193\n",
      "Epoch 1272, Loss: 0.23939082771539688, Final Batch Loss: 0.12010917067527771\n",
      "Epoch 1273, Loss: 0.2317911759018898, Final Batch Loss: 0.10364805907011032\n",
      "Epoch 1274, Loss: 0.27422191202640533, Final Batch Loss: 0.1304575502872467\n",
      "Epoch 1275, Loss: 0.27038586139678955, Final Batch Loss: 0.13745169341564178\n",
      "Epoch 1276, Loss: 0.27695490419864655, Final Batch Loss: 0.13461562991142273\n",
      "Epoch 1277, Loss: 0.2899009883403778, Final Batch Loss: 0.12352502346038818\n",
      "Epoch 1278, Loss: 0.27879299968481064, Final Batch Loss: 0.11805226653814316\n",
      "Epoch 1279, Loss: 0.313400462269783, Final Batch Loss: 0.1748111993074417\n",
      "Epoch 1280, Loss: 0.218033105134964, Final Batch Loss: 0.09782562404870987\n",
      "Epoch 1281, Loss: 0.2313489019870758, Final Batch Loss: 0.09323278069496155\n",
      "Epoch 1282, Loss: 0.28842030465602875, Final Batch Loss: 0.11963522434234619\n",
      "Epoch 1283, Loss: 0.27530115097761154, Final Batch Loss: 0.11075247079133987\n",
      "Epoch 1284, Loss: 0.2614537328481674, Final Batch Loss: 0.14392125606536865\n",
      "Epoch 1285, Loss: 0.30135026574134827, Final Batch Loss: 0.17121025919914246\n",
      "Epoch 1286, Loss: 0.2632790207862854, Final Batch Loss: 0.14897553622722626\n",
      "Epoch 1287, Loss: 0.2790740504860878, Final Batch Loss: 0.1575007438659668\n",
      "Epoch 1288, Loss: 0.2854969650506973, Final Batch Loss: 0.14973464608192444\n",
      "Epoch 1289, Loss: 0.25520024448633194, Final Batch Loss: 0.1355159729719162\n",
      "Epoch 1290, Loss: 0.28999075293540955, Final Batch Loss: 0.18295413255691528\n",
      "Epoch 1291, Loss: 0.255999393761158, Final Batch Loss: 0.1495322734117508\n",
      "Epoch 1292, Loss: 0.26300395280122757, Final Batch Loss: 0.11343016475439072\n",
      "Epoch 1293, Loss: 0.26820258051157, Final Batch Loss: 0.15790630877017975\n",
      "Epoch 1294, Loss: 0.2599959149956703, Final Batch Loss: 0.08763901144266129\n",
      "Epoch 1295, Loss: 0.2553023397922516, Final Batch Loss: 0.12695689499378204\n",
      "Epoch 1296, Loss: 0.27326881885528564, Final Batch Loss: 0.14462031424045563\n",
      "Epoch 1297, Loss: 0.2941834628582001, Final Batch Loss: 0.1627127230167389\n",
      "Epoch 1298, Loss: 0.2573291137814522, Final Batch Loss: 0.1216462180018425\n",
      "Epoch 1299, Loss: 0.27096734941005707, Final Batch Loss: 0.15356199443340302\n",
      "Epoch 1300, Loss: 0.265629306435585, Final Batch Loss: 0.18315160274505615\n",
      "Epoch 1301, Loss: 0.3219462111592293, Final Batch Loss: 0.1243446096777916\n",
      "Epoch 1302, Loss: 0.2664145976305008, Final Batch Loss: 0.11635741591453552\n",
      "Epoch 1303, Loss: 0.23214061558246613, Final Batch Loss: 0.09364922344684601\n",
      "Epoch 1304, Loss: 0.2575068548321724, Final Batch Loss: 0.1424267739057541\n",
      "Epoch 1305, Loss: 0.2251436710357666, Final Batch Loss: 0.10256738215684891\n",
      "Epoch 1306, Loss: 0.2501947283744812, Final Batch Loss: 0.10383602976799011\n",
      "Epoch 1307, Loss: 0.28056909143924713, Final Batch Loss: 0.12523867189884186\n",
      "Epoch 1308, Loss: 0.24315956234931946, Final Batch Loss: 0.09874692559242249\n",
      "Epoch 1309, Loss: 0.25573253631591797, Final Batch Loss: 0.1404639184474945\n",
      "Epoch 1310, Loss: 0.26668402552604675, Final Batch Loss: 0.11118203401565552\n",
      "Epoch 1311, Loss: 0.307120144367218, Final Batch Loss: 0.16178137063980103\n",
      "Epoch 1312, Loss: 0.2588825523853302, Final Batch Loss: 0.125102236866951\n",
      "Epoch 1313, Loss: 0.26821794360876083, Final Batch Loss: 0.15989543497562408\n",
      "Epoch 1314, Loss: 0.2705449312925339, Final Batch Loss: 0.11992421746253967\n",
      "Epoch 1315, Loss: 0.24645449966192245, Final Batch Loss: 0.11181626468896866\n",
      "Epoch 1316, Loss: 0.24386174976825714, Final Batch Loss: 0.11900770664215088\n",
      "Epoch 1317, Loss: 0.2543213963508606, Final Batch Loss: 0.1418837457895279\n",
      "Epoch 1318, Loss: 0.2800976112484932, Final Batch Loss: 0.19188420474529266\n",
      "Epoch 1319, Loss: 0.2405971735715866, Final Batch Loss: 0.11178471148014069\n",
      "Epoch 1320, Loss: 0.24335800856351852, Final Batch Loss: 0.09602057188749313\n",
      "Epoch 1321, Loss: 0.23768632858991623, Final Batch Loss: 0.13486431539058685\n",
      "Epoch 1322, Loss: 0.2662346363067627, Final Batch Loss: 0.133712500333786\n",
      "Epoch 1323, Loss: 0.22505423426628113, Final Batch Loss: 0.10176616162061691\n",
      "Epoch 1324, Loss: 0.26676442474126816, Final Batch Loss: 0.11020726710557938\n",
      "Epoch 1325, Loss: 0.24795203655958176, Final Batch Loss: 0.1438317447900772\n",
      "Epoch 1326, Loss: 0.289529949426651, Final Batch Loss: 0.14928318560123444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1327, Loss: 0.2114042118191719, Final Batch Loss: 0.11673269420862198\n",
      "Epoch 1328, Loss: 0.2167486473917961, Final Batch Loss: 0.10633672028779984\n",
      "Epoch 1329, Loss: 0.24463824927806854, Final Batch Loss: 0.12655238807201385\n",
      "Epoch 1330, Loss: 0.24809525161981583, Final Batch Loss: 0.12093690782785416\n",
      "Epoch 1331, Loss: 0.2255353182554245, Final Batch Loss: 0.10978326201438904\n",
      "Epoch 1332, Loss: 0.24628353118896484, Final Batch Loss: 0.12999242544174194\n",
      "Epoch 1333, Loss: 0.257921427488327, Final Batch Loss: 0.10661548376083374\n",
      "Epoch 1334, Loss: 0.2571645602583885, Final Batch Loss: 0.12470392137765884\n",
      "Epoch 1335, Loss: 0.33579038083553314, Final Batch Loss: 0.18103955686092377\n",
      "Epoch 1336, Loss: 0.2708766758441925, Final Batch Loss: 0.13433527946472168\n",
      "Epoch 1337, Loss: 0.2538983002305031, Final Batch Loss: 0.08735056966543198\n",
      "Epoch 1338, Loss: 0.2818434536457062, Final Batch Loss: 0.13740898668766022\n",
      "Epoch 1339, Loss: 0.2642112374305725, Final Batch Loss: 0.13088709115982056\n",
      "Epoch 1340, Loss: 0.2666197270154953, Final Batch Loss: 0.137418732047081\n",
      "Epoch 1341, Loss: 0.24544329196214676, Final Batch Loss: 0.14476747810840607\n",
      "Epoch 1342, Loss: 0.267129085958004, Final Batch Loss: 0.17584973573684692\n",
      "Epoch 1343, Loss: 0.22919785231351852, Final Batch Loss: 0.13215965032577515\n",
      "Epoch 1344, Loss: 0.2818925678730011, Final Batch Loss: 0.15802058577537537\n",
      "Epoch 1345, Loss: 0.2930774986743927, Final Batch Loss: 0.16465753316879272\n",
      "Epoch 1346, Loss: 0.2958603501319885, Final Batch Loss: 0.19335998594760895\n",
      "Epoch 1347, Loss: 0.24560698121786118, Final Batch Loss: 0.12462357431650162\n",
      "Epoch 1348, Loss: 0.252576008439064, Final Batch Loss: 0.11902064085006714\n",
      "Epoch 1349, Loss: 0.2634638026356697, Final Batch Loss: 0.14062239229679108\n",
      "Epoch 1350, Loss: 0.21779489517211914, Final Batch Loss: 0.08802065253257751\n",
      "Epoch 1351, Loss: 0.22638432681560516, Final Batch Loss: 0.09669230878353119\n",
      "Epoch 1352, Loss: 0.20442761480808258, Final Batch Loss: 0.09071819484233856\n",
      "Epoch 1353, Loss: 0.23952966928482056, Final Batch Loss: 0.11072653532028198\n",
      "Epoch 1354, Loss: 0.32586827874183655, Final Batch Loss: 0.13924233615398407\n",
      "Epoch 1355, Loss: 0.2899088114500046, Final Batch Loss: 0.1476224809885025\n",
      "Epoch 1356, Loss: 0.20934634655714035, Final Batch Loss: 0.09340524673461914\n",
      "Epoch 1357, Loss: 0.25286678224802017, Final Batch Loss: 0.09959142655134201\n",
      "Epoch 1358, Loss: 0.24871525913476944, Final Batch Loss: 0.13360248506069183\n",
      "Epoch 1359, Loss: 0.24150554090738297, Final Batch Loss: 0.11786769330501556\n",
      "Epoch 1360, Loss: 0.2834964394569397, Final Batch Loss: 0.16968934237957\n",
      "Epoch 1361, Loss: 0.2508477568626404, Final Batch Loss: 0.14710815250873566\n",
      "Epoch 1362, Loss: 0.26761411875486374, Final Batch Loss: 0.14328166842460632\n",
      "Epoch 1363, Loss: 0.24991878867149353, Final Batch Loss: 0.11364296078681946\n",
      "Epoch 1364, Loss: 0.22029301524162292, Final Batch Loss: 0.09244191646575928\n",
      "Epoch 1365, Loss: 0.25838882476091385, Final Batch Loss: 0.11190790683031082\n",
      "Epoch 1366, Loss: 0.22441135346889496, Final Batch Loss: 0.11645358800888062\n",
      "Epoch 1367, Loss: 0.22008423507213593, Final Batch Loss: 0.09718714654445648\n",
      "Epoch 1368, Loss: 0.2799062877893448, Final Batch Loss: 0.14535097777843475\n",
      "Epoch 1369, Loss: 0.3017707020044327, Final Batch Loss: 0.11838036775588989\n",
      "Epoch 1370, Loss: 0.20591390132904053, Final Batch Loss: 0.09720609337091446\n",
      "Epoch 1371, Loss: 0.23002634197473526, Final Batch Loss: 0.10155359655618668\n",
      "Epoch 1372, Loss: 0.30203086882829666, Final Batch Loss: 0.19176332652568817\n",
      "Epoch 1373, Loss: 0.33212780952453613, Final Batch Loss: 0.1678709089756012\n",
      "Epoch 1374, Loss: 0.26226532459259033, Final Batch Loss: 0.12799571454524994\n",
      "Epoch 1375, Loss: 0.3042285442352295, Final Batch Loss: 0.15018007159233093\n",
      "Epoch 1376, Loss: 0.2581510469317436, Final Batch Loss: 0.1451931744813919\n",
      "Epoch 1377, Loss: 0.26988571137189865, Final Batch Loss: 0.16258405148983002\n",
      "Epoch 1378, Loss: 0.2446424961090088, Final Batch Loss: 0.10603503882884979\n",
      "Epoch 1379, Loss: 0.2598155736923218, Final Batch Loss: 0.1258630007505417\n",
      "Epoch 1380, Loss: 0.2525133714079857, Final Batch Loss: 0.10208363085985184\n",
      "Epoch 1381, Loss: 0.2578228488564491, Final Batch Loss: 0.13283875584602356\n",
      "Epoch 1382, Loss: 0.26716198772192, Final Batch Loss: 0.15575072169303894\n",
      "Epoch 1383, Loss: 0.2822335809469223, Final Batch Loss: 0.12869001924991608\n",
      "Epoch 1384, Loss: 0.28924618661403656, Final Batch Loss: 0.14946703612804413\n",
      "Epoch 1385, Loss: 0.2409921959042549, Final Batch Loss: 0.10203022509813309\n",
      "Epoch 1386, Loss: 0.26276329159736633, Final Batch Loss: 0.128688246011734\n",
      "Epoch 1387, Loss: 0.30910711735486984, Final Batch Loss: 0.2009640783071518\n",
      "Epoch 1388, Loss: 0.21705158799886703, Final Batch Loss: 0.10794782638549805\n",
      "Epoch 1389, Loss: 0.23614519089460373, Final Batch Loss: 0.111313596367836\n",
      "Epoch 1390, Loss: 0.24634715169668198, Final Batch Loss: 0.13435371220111847\n",
      "Epoch 1391, Loss: 0.276725210249424, Final Batch Loss: 0.1679128259420395\n",
      "Epoch 1392, Loss: 0.21705059707164764, Final Batch Loss: 0.09567258507013321\n",
      "Epoch 1393, Loss: 0.29447685927152634, Final Batch Loss: 0.17097200453281403\n",
      "Epoch 1394, Loss: 0.24631739407777786, Final Batch Loss: 0.12041901797056198\n",
      "Epoch 1395, Loss: 0.25844545662403107, Final Batch Loss: 0.14246909320354462\n",
      "Epoch 1396, Loss: 0.25789663940668106, Final Batch Loss: 0.10250852257013321\n",
      "Epoch 1397, Loss: 0.28876255452632904, Final Batch Loss: 0.16177493333816528\n",
      "Epoch 1398, Loss: 0.20457768440246582, Final Batch Loss: 0.0863223597407341\n",
      "Epoch 1399, Loss: 0.22754636406898499, Final Batch Loss: 0.1298769861459732\n",
      "Epoch 1400, Loss: 0.24126805365085602, Final Batch Loss: 0.14146901667118073\n",
      "Epoch 1401, Loss: 0.2636006101965904, Final Batch Loss: 0.16230858862400055\n",
      "Epoch 1402, Loss: 0.25512728840112686, Final Batch Loss: 0.10263972729444504\n",
      "Epoch 1403, Loss: 0.23357395827770233, Final Batch Loss: 0.11774741858243942\n",
      "Epoch 1404, Loss: 0.2395472303032875, Final Batch Loss: 0.09303150326013565\n",
      "Epoch 1405, Loss: 0.2233010232448578, Final Batch Loss: 0.12247804552316666\n",
      "Epoch 1406, Loss: 0.2160826250910759, Final Batch Loss: 0.10077763348817825\n",
      "Epoch 1407, Loss: 0.24642685800790787, Final Batch Loss: 0.1445133090019226\n",
      "Epoch 1408, Loss: 0.26113131642341614, Final Batch Loss: 0.12087137997150421\n",
      "Epoch 1409, Loss: 0.19507528841495514, Final Batch Loss: 0.07221350073814392\n",
      "Epoch 1410, Loss: 0.23712579160928726, Final Batch Loss: 0.11098798364400864\n",
      "Epoch 1411, Loss: 0.2623347118496895, Final Batch Loss: 0.09908267110586166\n",
      "Epoch 1412, Loss: 0.26458270847797394, Final Batch Loss: 0.15648625791072845\n",
      "Epoch 1413, Loss: 0.21910688281059265, Final Batch Loss: 0.11165463179349899\n",
      "Epoch 1414, Loss: 0.2809717729687691, Final Batch Loss: 0.17058004438877106\n",
      "Epoch 1415, Loss: 0.22799552977085114, Final Batch Loss: 0.09650516510009766\n",
      "Epoch 1416, Loss: 0.2256896123290062, Final Batch Loss: 0.1278347671031952\n",
      "Epoch 1417, Loss: 0.22882506996393204, Final Batch Loss: 0.08852142840623856\n",
      "Epoch 1418, Loss: 0.1947552040219307, Final Batch Loss: 0.09921929985284805\n",
      "Epoch 1419, Loss: 0.19508221745491028, Final Batch Loss: 0.09582687169313431\n",
      "Epoch 1420, Loss: 0.2126890942454338, Final Batch Loss: 0.11301836371421814\n",
      "Epoch 1421, Loss: 0.2732047587633133, Final Batch Loss: 0.14542695879936218\n",
      "Epoch 1422, Loss: 0.2063220664858818, Final Batch Loss: 0.1117287203669548\n",
      "Epoch 1423, Loss: 0.22148974239826202, Final Batch Loss: 0.10060754418373108\n",
      "Epoch 1424, Loss: 0.21820594370365143, Final Batch Loss: 0.10768275707960129\n",
      "Epoch 1425, Loss: 0.23836859315633774, Final Batch Loss: 0.09784965962171555\n",
      "Epoch 1426, Loss: 0.2376449778676033, Final Batch Loss: 0.12245180457830429\n",
      "Epoch 1427, Loss: 0.21849482506513596, Final Batch Loss: 0.09656533598899841\n",
      "Epoch 1428, Loss: 0.21225346624851227, Final Batch Loss: 0.09290791302919388\n",
      "Epoch 1429, Loss: 0.23002832382917404, Final Batch Loss: 0.10038989037275314\n",
      "Epoch 1430, Loss: 0.21016085147857666, Final Batch Loss: 0.10154018551111221\n",
      "Epoch 1431, Loss: 0.25552523881196976, Final Batch Loss: 0.10218853503465652\n",
      "Epoch 1432, Loss: 0.21377600729465485, Final Batch Loss: 0.10354819893836975\n",
      "Epoch 1433, Loss: 0.2414635494351387, Final Batch Loss: 0.10400993376970291\n",
      "Epoch 1434, Loss: 0.22670558094978333, Final Batch Loss: 0.1263037621974945\n",
      "Epoch 1435, Loss: 0.20516107231378555, Final Batch Loss: 0.10937986522912979\n",
      "Epoch 1436, Loss: 0.25491899251937866, Final Batch Loss: 0.13846014440059662\n",
      "Epoch 1437, Loss: 0.23778043687343597, Final Batch Loss: 0.1369732916355133\n",
      "Epoch 1438, Loss: 0.23359709978103638, Final Batch Loss: 0.12730884552001953\n",
      "Epoch 1439, Loss: 0.22468457370996475, Final Batch Loss: 0.06369215995073318\n",
      "Epoch 1440, Loss: 0.24630214273929596, Final Batch Loss: 0.13886886835098267\n",
      "Epoch 1441, Loss: 0.2363412007689476, Final Batch Loss: 0.1336929053068161\n",
      "Epoch 1442, Loss: 0.24742808192968369, Final Batch Loss: 0.10436133295297623\n",
      "Epoch 1443, Loss: 0.22640011459589005, Final Batch Loss: 0.11215603351593018\n",
      "Epoch 1444, Loss: 0.22847877442836761, Final Batch Loss: 0.09973965585231781\n",
      "Epoch 1445, Loss: 0.25413940846920013, Final Batch Loss: 0.14444252848625183\n",
      "Epoch 1446, Loss: 0.25258056074380875, Final Batch Loss: 0.111139677464962\n",
      "Epoch 1447, Loss: 0.25998489558696747, Final Batch Loss: 0.15581446886062622\n",
      "Epoch 1448, Loss: 0.1854252815246582, Final Batch Loss: 0.06601705402135849\n",
      "Epoch 1449, Loss: 0.24645883589982986, Final Batch Loss: 0.13389328122138977\n",
      "Epoch 1450, Loss: 0.27127812802791595, Final Batch Loss: 0.13738317787647247\n",
      "Epoch 1451, Loss: 0.21125585585832596, Final Batch Loss: 0.09819292277097702\n",
      "Epoch 1452, Loss: 0.2764899656176567, Final Batch Loss: 0.16701863706111908\n",
      "Epoch 1453, Loss: 0.1998457908630371, Final Batch Loss: 0.08327499777078629\n",
      "Epoch 1454, Loss: 0.20249715447425842, Final Batch Loss: 0.08531766384840012\n",
      "Epoch 1455, Loss: 0.21897505968809128, Final Batch Loss: 0.1133638471364975\n",
      "Epoch 1456, Loss: 0.24263877421617508, Final Batch Loss: 0.1210496574640274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1457, Loss: 0.23017024248838425, Final Batch Loss: 0.13203246891498566\n",
      "Epoch 1458, Loss: 0.36542079597711563, Final Batch Loss: 0.2685292661190033\n",
      "Epoch 1459, Loss: 0.24692443758249283, Final Batch Loss: 0.11844692379236221\n",
      "Epoch 1460, Loss: 0.2294599860906601, Final Batch Loss: 0.12154605239629745\n",
      "Epoch 1461, Loss: 0.22256064414978027, Final Batch Loss: 0.1089409813284874\n",
      "Epoch 1462, Loss: 0.25990527123212814, Final Batch Loss: 0.15868538618087769\n",
      "Epoch 1463, Loss: 0.227071113884449, Final Batch Loss: 0.10421089828014374\n",
      "Epoch 1464, Loss: 0.21114542335271835, Final Batch Loss: 0.11493457108736038\n",
      "Epoch 1465, Loss: 0.20809771120548248, Final Batch Loss: 0.1056651920080185\n",
      "Epoch 1466, Loss: 0.22124429047107697, Final Batch Loss: 0.09937132149934769\n",
      "Epoch 1467, Loss: 0.23509565740823746, Final Batch Loss: 0.1475299596786499\n",
      "Epoch 1468, Loss: 0.2774902582168579, Final Batch Loss: 0.11938777565956116\n",
      "Epoch 1469, Loss: 0.2255006730556488, Final Batch Loss: 0.11247844994068146\n",
      "Epoch 1470, Loss: 0.24067378044128418, Final Batch Loss: 0.11639805138111115\n",
      "Epoch 1471, Loss: 0.21532170474529266, Final Batch Loss: 0.08314208686351776\n",
      "Epoch 1472, Loss: 0.22191903740167618, Final Batch Loss: 0.12173864245414734\n",
      "Epoch 1473, Loss: 0.2611789032816887, Final Batch Loss: 0.07295232266187668\n",
      "Epoch 1474, Loss: 0.23665054887533188, Final Batch Loss: 0.13779295980930328\n",
      "Epoch 1475, Loss: 0.2484258934855461, Final Batch Loss: 0.13138116896152496\n",
      "Epoch 1476, Loss: 0.2349335104227066, Final Batch Loss: 0.1278679221868515\n",
      "Epoch 1477, Loss: 0.25239720195531845, Final Batch Loss: 0.09089281409978867\n",
      "Epoch 1478, Loss: 0.2678534984588623, Final Batch Loss: 0.1495329588651657\n",
      "Epoch 1479, Loss: 0.2460494339466095, Final Batch Loss: 0.11611990630626678\n",
      "Epoch 1480, Loss: 0.21871019154787064, Final Batch Loss: 0.1057753935456276\n",
      "Epoch 1481, Loss: 0.27330993115901947, Final Batch Loss: 0.12676849961280823\n",
      "Epoch 1482, Loss: 0.24581053107976913, Final Batch Loss: 0.1208825409412384\n",
      "Epoch 1483, Loss: 0.24348270893096924, Final Batch Loss: 0.1265702098608017\n",
      "Epoch 1484, Loss: 0.268606498837471, Final Batch Loss: 0.1266442835330963\n",
      "Epoch 1485, Loss: 0.24244939535856247, Final Batch Loss: 0.1104976013302803\n",
      "Epoch 1486, Loss: 0.2975437417626381, Final Batch Loss: 0.1963411122560501\n",
      "Epoch 1487, Loss: 0.2127307653427124, Final Batch Loss: 0.10032733529806137\n",
      "Epoch 1488, Loss: 0.23755332082509995, Final Batch Loss: 0.10358632355928421\n",
      "Epoch 1489, Loss: 0.2123539224267006, Final Batch Loss: 0.12175491452217102\n",
      "Epoch 1490, Loss: 0.240641787648201, Final Batch Loss: 0.11748282611370087\n",
      "Epoch 1491, Loss: 0.23334677517414093, Final Batch Loss: 0.11769010871648788\n",
      "Epoch 1492, Loss: 0.23717018961906433, Final Batch Loss: 0.12479101866483688\n",
      "Epoch 1493, Loss: 0.18045435845851898, Final Batch Loss: 0.08729188144207001\n",
      "Epoch 1494, Loss: 0.2341608628630638, Final Batch Loss: 0.11828172206878662\n",
      "Epoch 1495, Loss: 0.24382246285676956, Final Batch Loss: 0.13184623420238495\n",
      "Epoch 1496, Loss: 0.27053798735141754, Final Batch Loss: 0.1290595680475235\n",
      "Epoch 1497, Loss: 0.2351825311779976, Final Batch Loss: 0.11052373051643372\n",
      "Epoch 1498, Loss: 0.22991279512643814, Final Batch Loss: 0.1520368754863739\n",
      "Epoch 1499, Loss: 0.23989244550466537, Final Batch Loss: 0.127838596701622\n",
      "Epoch 1500, Loss: 0.2125871628522873, Final Batch Loss: 0.11908186227083206\n",
      "Epoch 1501, Loss: 0.22942060232162476, Final Batch Loss: 0.12265975773334503\n",
      "Epoch 1502, Loss: 0.23510780185461044, Final Batch Loss: 0.13352467119693756\n",
      "Epoch 1503, Loss: 0.22462335973978043, Final Batch Loss: 0.1226525604724884\n",
      "Epoch 1504, Loss: 0.2595226839184761, Final Batch Loss: 0.10567241162061691\n",
      "Epoch 1505, Loss: 0.20485752820968628, Final Batch Loss: 0.0782400518655777\n",
      "Epoch 1506, Loss: 0.21995753794908524, Final Batch Loss: 0.10830552875995636\n",
      "Epoch 1507, Loss: 0.20879154652357101, Final Batch Loss: 0.10217039287090302\n",
      "Epoch 1508, Loss: 0.21658794581890106, Final Batch Loss: 0.07615512609481812\n",
      "Epoch 1509, Loss: 0.2496795654296875, Final Batch Loss: 0.12044553458690643\n",
      "Epoch 1510, Loss: 0.2716220021247864, Final Batch Loss: 0.15044960379600525\n",
      "Epoch 1511, Loss: 0.2173021286725998, Final Batch Loss: 0.12265807390213013\n",
      "Epoch 1512, Loss: 0.22119217365980148, Final Batch Loss: 0.09312915056943893\n",
      "Epoch 1513, Loss: 0.2305983155965805, Final Batch Loss: 0.0772099494934082\n",
      "Epoch 1514, Loss: 0.25953109562397003, Final Batch Loss: 0.14407289028167725\n",
      "Epoch 1515, Loss: 0.254938006401062, Final Batch Loss: 0.15798531472682953\n",
      "Epoch 1516, Loss: 0.2583569660782814, Final Batch Loss: 0.13973525166511536\n",
      "Epoch 1517, Loss: 0.23466774821281433, Final Batch Loss: 0.08441014587879181\n",
      "Epoch 1518, Loss: 0.22741759568452835, Final Batch Loss: 0.11314605921506882\n",
      "Epoch 1519, Loss: 0.21796518564224243, Final Batch Loss: 0.10393456369638443\n",
      "Epoch 1520, Loss: 0.2467113435268402, Final Batch Loss: 0.1489218771457672\n",
      "Epoch 1521, Loss: 0.20804515480995178, Final Batch Loss: 0.08307434618473053\n",
      "Epoch 1522, Loss: 0.18970273435115814, Final Batch Loss: 0.0691656544804573\n",
      "Epoch 1523, Loss: 0.2466970533132553, Final Batch Loss: 0.16404090821743011\n",
      "Epoch 1524, Loss: 0.23398149758577347, Final Batch Loss: 0.12400654703378677\n",
      "Epoch 1525, Loss: 0.20727815479040146, Final Batch Loss: 0.10380888730287552\n",
      "Epoch 1526, Loss: 0.22697671502828598, Final Batch Loss: 0.09873025864362717\n",
      "Epoch 1527, Loss: 0.19490012526512146, Final Batch Loss: 0.10408409684896469\n",
      "Epoch 1528, Loss: 0.23439138382673264, Final Batch Loss: 0.112525574862957\n",
      "Epoch 1529, Loss: 0.19769778847694397, Final Batch Loss: 0.07076726853847504\n",
      "Epoch 1530, Loss: 0.2024574875831604, Final Batch Loss: 0.09528975933790207\n",
      "Epoch 1531, Loss: 0.1895967423915863, Final Batch Loss: 0.09806529432535172\n",
      "Epoch 1532, Loss: 0.21905016154050827, Final Batch Loss: 0.12340327352285385\n",
      "Epoch 1533, Loss: 0.1959989219903946, Final Batch Loss: 0.1061382070183754\n",
      "Epoch 1534, Loss: 0.260907381772995, Final Batch Loss: 0.1290086954832077\n",
      "Epoch 1535, Loss: 0.19272951036691666, Final Batch Loss: 0.09376180917024612\n",
      "Epoch 1536, Loss: 0.23069704324007034, Final Batch Loss: 0.1201072484254837\n",
      "Epoch 1537, Loss: 0.2615556940436363, Final Batch Loss: 0.14594092965126038\n",
      "Epoch 1538, Loss: 0.24782826006412506, Final Batch Loss: 0.11304545402526855\n",
      "Epoch 1539, Loss: 0.22964315116405487, Final Batch Loss: 0.10578329116106033\n",
      "Epoch 1540, Loss: 0.21597646176815033, Final Batch Loss: 0.10666069388389587\n",
      "Epoch 1541, Loss: 0.20963748544454575, Final Batch Loss: 0.09698189049959183\n",
      "Epoch 1542, Loss: 0.2292303666472435, Final Batch Loss: 0.11734592914581299\n",
      "Epoch 1543, Loss: 0.22791657596826553, Final Batch Loss: 0.13542547821998596\n",
      "Epoch 1544, Loss: 0.23312928527593613, Final Batch Loss: 0.1423521190881729\n",
      "Epoch 1545, Loss: 0.21184222400188446, Final Batch Loss: 0.1122221127152443\n",
      "Epoch 1546, Loss: 0.1970246210694313, Final Batch Loss: 0.10748400539159775\n",
      "Epoch 1547, Loss: 0.1771933138370514, Final Batch Loss: 0.0964697003364563\n",
      "Epoch 1548, Loss: 0.23153600841760635, Final Batch Loss: 0.13946875929832458\n",
      "Epoch 1549, Loss: 0.20240715146064758, Final Batch Loss: 0.09407401829957962\n",
      "Epoch 1550, Loss: 0.23950672894716263, Final Batch Loss: 0.07300547510385513\n",
      "Epoch 1551, Loss: 0.18038804084062576, Final Batch Loss: 0.09013064205646515\n",
      "Epoch 1552, Loss: 0.17993837594985962, Final Batch Loss: 0.07385796308517456\n",
      "Epoch 1553, Loss: 0.19443392753601074, Final Batch Loss: 0.08630352467298508\n",
      "Epoch 1554, Loss: 0.20054849237203598, Final Batch Loss: 0.0829969197511673\n",
      "Epoch 1555, Loss: 0.22889277338981628, Final Batch Loss: 0.09144631028175354\n",
      "Epoch 1556, Loss: 0.21935583651065826, Final Batch Loss: 0.11964213103055954\n",
      "Epoch 1557, Loss: 0.18647723644971848, Final Batch Loss: 0.0873471349477768\n",
      "Epoch 1558, Loss: 0.22250422835350037, Final Batch Loss: 0.12545420229434967\n",
      "Epoch 1559, Loss: 0.1738642379641533, Final Batch Loss: 0.08248139917850494\n",
      "Epoch 1560, Loss: 0.23190195858478546, Final Batch Loss: 0.12468522042036057\n",
      "Epoch 1561, Loss: 0.23285139352083206, Final Batch Loss: 0.10120461136102676\n",
      "Epoch 1562, Loss: 0.17873722314834595, Final Batch Loss: 0.09031599760055542\n",
      "Epoch 1563, Loss: 0.24571309238672256, Final Batch Loss: 0.15176112949848175\n",
      "Epoch 1564, Loss: 0.2260250598192215, Final Batch Loss: 0.10772168636322021\n",
      "Epoch 1565, Loss: 0.2066032588481903, Final Batch Loss: 0.10175275802612305\n",
      "Epoch 1566, Loss: 0.2527647390961647, Final Batch Loss: 0.14904233813285828\n",
      "Epoch 1567, Loss: 0.22427022457122803, Final Batch Loss: 0.12912313640117645\n",
      "Epoch 1568, Loss: 0.2003641054034233, Final Batch Loss: 0.10571151226758957\n",
      "Epoch 1569, Loss: 0.21374712884426117, Final Batch Loss: 0.14348037540912628\n",
      "Epoch 1570, Loss: 0.29989253729581833, Final Batch Loss: 0.21444189548492432\n",
      "Epoch 1571, Loss: 0.21485255658626556, Final Batch Loss: 0.1101040244102478\n",
      "Epoch 1572, Loss: 0.186106875538826, Final Batch Loss: 0.08141130208969116\n",
      "Epoch 1573, Loss: 0.2457083985209465, Final Batch Loss: 0.09279952198266983\n",
      "Epoch 1574, Loss: 0.21013496816158295, Final Batch Loss: 0.09085095673799515\n",
      "Epoch 1575, Loss: 0.20664996653795242, Final Batch Loss: 0.08465109765529633\n",
      "Epoch 1576, Loss: 0.2318516969680786, Final Batch Loss: 0.14586825668811798\n",
      "Epoch 1577, Loss: 0.20330968499183655, Final Batch Loss: 0.10776601731777191\n",
      "Epoch 1578, Loss: 0.18915098160505295, Final Batch Loss: 0.07909444719552994\n",
      "Epoch 1579, Loss: 0.20828692615032196, Final Batch Loss: 0.12111121416091919\n",
      "Epoch 1580, Loss: 0.2387186959385872, Final Batch Loss: 0.12914447486400604\n",
      "Epoch 1581, Loss: 0.21602598577737808, Final Batch Loss: 0.09498079866170883\n",
      "Epoch 1582, Loss: 0.21682024747133255, Final Batch Loss: 0.11934170126914978\n",
      "Epoch 1583, Loss: 0.20420138537883759, Final Batch Loss: 0.10114002972841263\n",
      "Epoch 1584, Loss: 0.26667335629463196, Final Batch Loss: 0.15657876431941986\n",
      "Epoch 1585, Loss: 0.22284287214279175, Final Batch Loss: 0.13348530232906342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1586, Loss: 0.19964616745710373, Final Batch Loss: 0.07233697921037674\n",
      "Epoch 1587, Loss: 0.19041375070810318, Final Batch Loss: 0.09617193043231964\n",
      "Epoch 1588, Loss: 0.23530924320220947, Final Batch Loss: 0.13393108546733856\n",
      "Epoch 1589, Loss: 0.2006974071264267, Final Batch Loss: 0.09709686785936356\n",
      "Epoch 1590, Loss: 0.19409481436014175, Final Batch Loss: 0.08951184898614883\n",
      "Epoch 1591, Loss: 0.24221312254667282, Final Batch Loss: 0.13112545013427734\n",
      "Epoch 1592, Loss: 0.253935731947422, Final Batch Loss: 0.1451592594385147\n",
      "Epoch 1593, Loss: 0.2284127175807953, Final Batch Loss: 0.1091785803437233\n",
      "Epoch 1594, Loss: 0.2698732912540436, Final Batch Loss: 0.12695100903511047\n",
      "Epoch 1595, Loss: 0.20643765479326248, Final Batch Loss: 0.10675705224275589\n",
      "Epoch 1596, Loss: 0.2130778431892395, Final Batch Loss: 0.09819509834051132\n",
      "Epoch 1597, Loss: 0.18970531225204468, Final Batch Loss: 0.0778069719672203\n",
      "Epoch 1598, Loss: 0.22823912650346756, Final Batch Loss: 0.11130217462778091\n",
      "Epoch 1599, Loss: 0.22153590619564056, Final Batch Loss: 0.13435669243335724\n",
      "Epoch 1600, Loss: 0.19305334985256195, Final Batch Loss: 0.08364841341972351\n",
      "Epoch 1601, Loss: 0.24160301685333252, Final Batch Loss: 0.10684934258460999\n",
      "Epoch 1602, Loss: 0.18571390956640244, Final Batch Loss: 0.10111956298351288\n",
      "Epoch 1603, Loss: 0.19095827639102936, Final Batch Loss: 0.0693984255194664\n",
      "Epoch 1604, Loss: 0.18336210399866104, Final Batch Loss: 0.10426947474479675\n",
      "Epoch 1605, Loss: 0.1908136084675789, Final Batch Loss: 0.09426140785217285\n",
      "Epoch 1606, Loss: 0.2605518102645874, Final Batch Loss: 0.0913243293762207\n",
      "Epoch 1607, Loss: 0.22545062005519867, Final Batch Loss: 0.13804933428764343\n",
      "Epoch 1608, Loss: 0.2021397426724434, Final Batch Loss: 0.09140153974294662\n",
      "Epoch 1609, Loss: 0.2285594418644905, Final Batch Loss: 0.0784621611237526\n",
      "Epoch 1610, Loss: 0.21390601247549057, Final Batch Loss: 0.12146185338497162\n",
      "Epoch 1611, Loss: 0.30891405045986176, Final Batch Loss: 0.13388694822788239\n",
      "Epoch 1612, Loss: 0.19777870923280716, Final Batch Loss: 0.09311061352491379\n",
      "Epoch 1613, Loss: 0.1926579773426056, Final Batch Loss: 0.11477965116500854\n",
      "Epoch 1614, Loss: 0.2506386488676071, Final Batch Loss: 0.1410650908946991\n",
      "Epoch 1615, Loss: 0.25654836744070053, Final Batch Loss: 0.1401268094778061\n",
      "Epoch 1616, Loss: 0.33816228806972504, Final Batch Loss: 0.24286077916622162\n",
      "Epoch 1617, Loss: 0.22987765073776245, Final Batch Loss: 0.10465949773788452\n",
      "Epoch 1618, Loss: 0.21653559058904648, Final Batch Loss: 0.08790557831525803\n",
      "Epoch 1619, Loss: 0.24832740426063538, Final Batch Loss: 0.1558407098054886\n",
      "Epoch 1620, Loss: 0.21340684592723846, Final Batch Loss: 0.09293855726718903\n",
      "Epoch 1621, Loss: 0.17925237864255905, Final Batch Loss: 0.07628724724054337\n",
      "Epoch 1622, Loss: 0.20479518920183182, Final Batch Loss: 0.06315893679857254\n",
      "Epoch 1623, Loss: 0.193718321621418, Final Batch Loss: 0.1000140830874443\n",
      "Epoch 1624, Loss: 0.17986413091421127, Final Batch Loss: 0.09041670709848404\n",
      "Epoch 1625, Loss: 0.21375444531440735, Final Batch Loss: 0.11739245802164078\n",
      "Epoch 1626, Loss: 0.24070832878351212, Final Batch Loss: 0.07055554538965225\n",
      "Epoch 1627, Loss: 0.2011139765381813, Final Batch Loss: 0.09388770908117294\n",
      "Epoch 1628, Loss: 0.2534365579485893, Final Batch Loss: 0.11021458357572556\n",
      "Epoch 1629, Loss: 0.18903207778930664, Final Batch Loss: 0.09753185510635376\n",
      "Epoch 1630, Loss: 0.19330890476703644, Final Batch Loss: 0.08933427929878235\n",
      "Epoch 1631, Loss: 0.20078392326831818, Final Batch Loss: 0.08437442779541016\n",
      "Epoch 1632, Loss: 0.18910861015319824, Final Batch Loss: 0.10467620939016342\n",
      "Epoch 1633, Loss: 0.24660953134298325, Final Batch Loss: 0.08904942125082016\n",
      "Epoch 1634, Loss: 0.2046322524547577, Final Batch Loss: 0.10811778903007507\n",
      "Epoch 1635, Loss: 0.2194894626736641, Final Batch Loss: 0.13437969982624054\n",
      "Epoch 1636, Loss: 0.22083843499422073, Final Batch Loss: 0.12002307921648026\n",
      "Epoch 1637, Loss: 0.2343348041176796, Final Batch Loss: 0.10839017480611801\n",
      "Epoch 1638, Loss: 0.18919657915830612, Final Batch Loss: 0.08032610267400742\n",
      "Epoch 1639, Loss: 0.24912551045417786, Final Batch Loss: 0.1667284220457077\n",
      "Epoch 1640, Loss: 0.19363059848546982, Final Batch Loss: 0.08127295225858688\n",
      "Epoch 1641, Loss: 0.30852316319942474, Final Batch Loss: 0.18896320462226868\n",
      "Epoch 1642, Loss: 0.21545054763555527, Final Batch Loss: 0.07690665870904922\n",
      "Epoch 1643, Loss: 0.19633661210536957, Final Batch Loss: 0.09063316881656647\n",
      "Epoch 1644, Loss: 0.19287490844726562, Final Batch Loss: 0.07846072316169739\n",
      "Epoch 1645, Loss: 0.2668544203042984, Final Batch Loss: 0.1302756816148758\n",
      "Epoch 1646, Loss: 0.19731484353542328, Final Batch Loss: 0.09091774374246597\n",
      "Epoch 1647, Loss: 0.1814645305275917, Final Batch Loss: 0.08257057517766953\n",
      "Epoch 1648, Loss: 0.23763062059879303, Final Batch Loss: 0.11332422494888306\n",
      "Epoch 1649, Loss: 0.2293156534433365, Final Batch Loss: 0.0973929762840271\n",
      "Epoch 1650, Loss: 0.22500666230916977, Final Batch Loss: 0.09298839420080185\n",
      "Epoch 1651, Loss: 0.206233449280262, Final Batch Loss: 0.10309848934412003\n",
      "Epoch 1652, Loss: 0.15635058656334877, Final Batch Loss: 0.053484443575143814\n",
      "Epoch 1653, Loss: 0.20130706578493118, Final Batch Loss: 0.09483393281698227\n",
      "Epoch 1654, Loss: 0.1831567957997322, Final Batch Loss: 0.0893038958311081\n",
      "Epoch 1655, Loss: 0.21040582656860352, Final Batch Loss: 0.08871675282716751\n",
      "Epoch 1656, Loss: 0.21902286261320114, Final Batch Loss: 0.125370591878891\n",
      "Epoch 1657, Loss: 0.237594373524189, Final Batch Loss: 0.12935003638267517\n",
      "Epoch 1658, Loss: 0.17520858347415924, Final Batch Loss: 0.07277637720108032\n",
      "Epoch 1659, Loss: 0.1922641545534134, Final Batch Loss: 0.09138578176498413\n",
      "Epoch 1660, Loss: 0.18672388792037964, Final Batch Loss: 0.08402841538190842\n",
      "Epoch 1661, Loss: 0.17458966374397278, Final Batch Loss: 0.08945321291685104\n",
      "Epoch 1662, Loss: 0.19982966035604477, Final Batch Loss: 0.08883469551801682\n",
      "Epoch 1663, Loss: 0.1945880949497223, Final Batch Loss: 0.08964576572179794\n",
      "Epoch 1664, Loss: 0.19991128146648407, Final Batch Loss: 0.08960661292076111\n",
      "Epoch 1665, Loss: 0.21874307841062546, Final Batch Loss: 0.11294076591730118\n",
      "Epoch 1666, Loss: 0.2145218700170517, Final Batch Loss: 0.06961092352867126\n",
      "Epoch 1667, Loss: 0.22540904581546783, Final Batch Loss: 0.13244493305683136\n",
      "Epoch 1668, Loss: 0.2059917226433754, Final Batch Loss: 0.12267110496759415\n",
      "Epoch 1669, Loss: 0.22998815774917603, Final Batch Loss: 0.15028433501720428\n",
      "Epoch 1670, Loss: 0.19684377312660217, Final Batch Loss: 0.10522989928722382\n",
      "Epoch 1671, Loss: 0.1872621327638626, Final Batch Loss: 0.10939010232686996\n",
      "Epoch 1672, Loss: 0.22575613856315613, Final Batch Loss: 0.1359875202178955\n",
      "Epoch 1673, Loss: 0.19751857221126556, Final Batch Loss: 0.08651381731033325\n",
      "Epoch 1674, Loss: 0.18873006850481033, Final Batch Loss: 0.10392335802316666\n",
      "Epoch 1675, Loss: 0.20232615619897842, Final Batch Loss: 0.13096120953559875\n",
      "Epoch 1676, Loss: 0.20397280901670456, Final Batch Loss: 0.10634932667016983\n",
      "Epoch 1677, Loss: 0.1745610386133194, Final Batch Loss: 0.08718816936016083\n",
      "Epoch 1678, Loss: 0.1741699054837227, Final Batch Loss: 0.08592528849840164\n",
      "Epoch 1679, Loss: 0.22029803693294525, Final Batch Loss: 0.08961962163448334\n",
      "Epoch 1680, Loss: 0.2256208136677742, Final Batch Loss: 0.105692557990551\n",
      "Epoch 1681, Loss: 0.16424430906772614, Final Batch Loss: 0.0586298406124115\n",
      "Epoch 1682, Loss: 0.17121638357639313, Final Batch Loss: 0.0914355218410492\n",
      "Epoch 1683, Loss: 0.24354888498783112, Final Batch Loss: 0.15294110774993896\n",
      "Epoch 1684, Loss: 0.18722201883792877, Final Batch Loss: 0.1053483635187149\n",
      "Epoch 1685, Loss: 0.21228720247745514, Final Batch Loss: 0.12110362201929092\n",
      "Epoch 1686, Loss: 0.1903614103794098, Final Batch Loss: 0.08514639735221863\n",
      "Epoch 1687, Loss: 0.1840517744421959, Final Batch Loss: 0.08633870631456375\n",
      "Epoch 1688, Loss: 0.2084050104022026, Final Batch Loss: 0.12435878068208694\n",
      "Epoch 1689, Loss: 0.18880658596754074, Final Batch Loss: 0.09163354337215424\n",
      "Epoch 1690, Loss: 0.339115746319294, Final Batch Loss: 0.2439146488904953\n",
      "Epoch 1691, Loss: 0.20289549231529236, Final Batch Loss: 0.10392098873853683\n",
      "Epoch 1692, Loss: 0.19441034644842148, Final Batch Loss: 0.0928022563457489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1693, Loss: 0.23723485320806503, Final Batch Loss: 0.14578929543495178\n",
      "Epoch 1694, Loss: 0.20189812034368515, Final Batch Loss: 0.11885300278663635\n",
      "Epoch 1695, Loss: 0.21500827372074127, Final Batch Loss: 0.1063145324587822\n",
      "Epoch 1696, Loss: 0.2022080048918724, Final Batch Loss: 0.08748704195022583\n",
      "Epoch 1697, Loss: 0.17842302471399307, Final Batch Loss: 0.0686497837305069\n",
      "Epoch 1698, Loss: 0.21222199499607086, Final Batch Loss: 0.11692351847887039\n",
      "Epoch 1699, Loss: 0.17053331434726715, Final Batch Loss: 0.0646735280752182\n",
      "Epoch 1700, Loss: 0.1807742789387703, Final Batch Loss: 0.08101288229227066\n",
      "Epoch 1701, Loss: 0.2186761200428009, Final Batch Loss: 0.1333325058221817\n",
      "Epoch 1702, Loss: 0.17778179049491882, Final Batch Loss: 0.09156084805727005\n",
      "Epoch 1703, Loss: 0.1920957863330841, Final Batch Loss: 0.06874045729637146\n",
      "Epoch 1704, Loss: 0.18348494172096252, Final Batch Loss: 0.07726069539785385\n",
      "Epoch 1705, Loss: 0.20957425981760025, Final Batch Loss: 0.10630355775356293\n",
      "Epoch 1706, Loss: 0.19725631177425385, Final Batch Loss: 0.12148862332105637\n",
      "Epoch 1707, Loss: 0.19891289621591568, Final Batch Loss: 0.10946821421384811\n",
      "Epoch 1708, Loss: 0.2434253916144371, Final Batch Loss: 0.16511447727680206\n",
      "Epoch 1709, Loss: 0.2938891500234604, Final Batch Loss: 0.09911699593067169\n",
      "Epoch 1710, Loss: 0.1856999546289444, Final Batch Loss: 0.09499438107013702\n",
      "Epoch 1711, Loss: 0.20239289849996567, Final Batch Loss: 0.10699555277824402\n",
      "Epoch 1712, Loss: 0.2230912297964096, Final Batch Loss: 0.0942702442407608\n",
      "Epoch 1713, Loss: 0.17090274021029472, Final Batch Loss: 0.05824955180287361\n",
      "Epoch 1714, Loss: 0.20959895104169846, Final Batch Loss: 0.09416814893484116\n",
      "Epoch 1715, Loss: 0.2096506580710411, Final Batch Loss: 0.13038399815559387\n",
      "Epoch 1716, Loss: 0.20933076739311218, Final Batch Loss: 0.1033342182636261\n",
      "Epoch 1717, Loss: 0.23427284508943558, Final Batch Loss: 0.1531400829553604\n",
      "Epoch 1718, Loss: 0.190173901617527, Final Batch Loss: 0.10582190752029419\n",
      "Epoch 1719, Loss: 0.18767855316400528, Final Batch Loss: 0.11683910340070724\n",
      "Epoch 1720, Loss: 0.17212259769439697, Final Batch Loss: 0.07060284167528152\n",
      "Epoch 1721, Loss: 0.18985994905233383, Final Batch Loss: 0.07658030837774277\n",
      "Epoch 1722, Loss: 0.18032196909189224, Final Batch Loss: 0.08767476677894592\n",
      "Epoch 1723, Loss: 0.21406377106904984, Final Batch Loss: 0.08534087985754013\n",
      "Epoch 1724, Loss: 0.1527371183037758, Final Batch Loss: 0.06275228410959244\n",
      "Epoch 1725, Loss: 0.18253213167190552, Final Batch Loss: 0.10094933211803436\n",
      "Epoch 1726, Loss: 0.2584117352962494, Final Batch Loss: 0.17418210208415985\n",
      "Epoch 1727, Loss: 0.19016703963279724, Final Batch Loss: 0.08407796174287796\n",
      "Epoch 1728, Loss: 0.22408439964056015, Final Batch Loss: 0.10642267018556595\n",
      "Epoch 1729, Loss: 0.16951942443847656, Final Batch Loss: 0.09456581622362137\n",
      "Epoch 1730, Loss: 0.2466086968779564, Final Batch Loss: 0.14272883534431458\n",
      "Epoch 1731, Loss: 0.2767382860183716, Final Batch Loss: 0.15169712901115417\n",
      "Epoch 1732, Loss: 0.19722582399845123, Final Batch Loss: 0.10748196393251419\n",
      "Epoch 1733, Loss: 0.19279218465089798, Final Batch Loss: 0.06742287427186966\n",
      "Epoch 1734, Loss: 0.19567375630140305, Final Batch Loss: 0.09767981618642807\n",
      "Epoch 1735, Loss: 0.17991901189088821, Final Batch Loss: 0.10456787794828415\n",
      "Epoch 1736, Loss: 0.1771416738629341, Final Batch Loss: 0.07677942514419556\n",
      "Epoch 1737, Loss: 0.18352793902158737, Final Batch Loss: 0.09570232778787613\n",
      "Epoch 1738, Loss: 0.2051619589328766, Final Batch Loss: 0.09245703369379044\n",
      "Epoch 1739, Loss: 0.1917874440550804, Final Batch Loss: 0.09405841678380966\n",
      "Epoch 1740, Loss: 0.18647097796201706, Final Batch Loss: 0.09118376672267914\n",
      "Epoch 1741, Loss: 0.16656839847564697, Final Batch Loss: 0.08804820477962494\n",
      "Epoch 1742, Loss: 0.17522448301315308, Final Batch Loss: 0.08143196254968643\n",
      "Epoch 1743, Loss: 0.18980105221271515, Final Batch Loss: 0.10300246626138687\n",
      "Epoch 1744, Loss: 0.20734161138534546, Final Batch Loss: 0.09619048982858658\n",
      "Epoch 1745, Loss: 0.1999807208776474, Final Batch Loss: 0.09363535046577454\n",
      "Epoch 1746, Loss: 0.1495046727359295, Final Batch Loss: 0.04840743914246559\n",
      "Epoch 1747, Loss: 0.17428074777126312, Final Batch Loss: 0.08142462372779846\n",
      "Epoch 1748, Loss: 0.1873665750026703, Final Batch Loss: 0.1002512201666832\n",
      "Epoch 1749, Loss: 0.182232104241848, Final Batch Loss: 0.09883425384759903\n",
      "Epoch 1750, Loss: 0.17984315752983093, Final Batch Loss: 0.09721768647432327\n",
      "Epoch 1751, Loss: 0.20566264539957047, Final Batch Loss: 0.10666617006063461\n",
      "Epoch 1752, Loss: 0.20700713247060776, Final Batch Loss: 0.100550577044487\n",
      "Epoch 1753, Loss: 0.2122451737523079, Final Batch Loss: 0.11114645004272461\n",
      "Epoch 1754, Loss: 0.19069581478834152, Final Batch Loss: 0.09722024202346802\n",
      "Epoch 1755, Loss: 0.17907192558050156, Final Batch Loss: 0.07214409857988358\n",
      "Epoch 1756, Loss: 0.18869580328464508, Final Batch Loss: 0.11254695802927017\n",
      "Epoch 1757, Loss: 0.1871163472533226, Final Batch Loss: 0.094212107360363\n",
      "Epoch 1758, Loss: 0.16785318404436111, Final Batch Loss: 0.04135759919881821\n",
      "Epoch 1759, Loss: 0.20040679723024368, Final Batch Loss: 0.09951687604188919\n",
      "Epoch 1760, Loss: 0.1770462617278099, Final Batch Loss: 0.0966176688671112\n",
      "Epoch 1761, Loss: 0.18464245647192, Final Batch Loss: 0.09039260447025299\n",
      "Epoch 1762, Loss: 0.19068221747875214, Final Batch Loss: 0.10867032408714294\n",
      "Epoch 1763, Loss: 0.18663189560174942, Final Batch Loss: 0.09148343652486801\n",
      "Epoch 1764, Loss: 0.2120266556739807, Final Batch Loss: 0.07627956569194794\n",
      "Epoch 1765, Loss: 0.19725332409143448, Final Batch Loss: 0.10756278783082962\n",
      "Epoch 1766, Loss: 0.20713945478200912, Final Batch Loss: 0.08052737265825272\n",
      "Epoch 1767, Loss: 0.2018132358789444, Final Batch Loss: 0.11199866980314255\n",
      "Epoch 1768, Loss: 0.18164880573749542, Final Batch Loss: 0.08779997378587723\n",
      "Epoch 1769, Loss: 0.15672414749860764, Final Batch Loss: 0.06846369057893753\n",
      "Epoch 1770, Loss: 0.17474889010190964, Final Batch Loss: 0.07043837010860443\n",
      "Epoch 1771, Loss: 0.2076905444264412, Final Batch Loss: 0.09853824228048325\n",
      "Epoch 1772, Loss: 0.20694974809885025, Final Batch Loss: 0.09410782158374786\n",
      "Epoch 1773, Loss: 0.18887614458799362, Final Batch Loss: 0.10934560000896454\n",
      "Epoch 1774, Loss: 0.2493850514292717, Final Batch Loss: 0.12903757393360138\n",
      "Epoch 1775, Loss: 0.23377321660518646, Final Batch Loss: 0.10866016149520874\n",
      "Epoch 1776, Loss: 0.1956823617219925, Final Batch Loss: 0.10683061182498932\n",
      "Epoch 1777, Loss: 0.19563964754343033, Final Batch Loss: 0.10310599207878113\n",
      "Epoch 1778, Loss: 0.16588500142097473, Final Batch Loss: 0.09042798727750778\n",
      "Epoch 1779, Loss: 0.22114093601703644, Final Batch Loss: 0.12312228977680206\n",
      "Epoch 1780, Loss: 0.1873558834195137, Final Batch Loss: 0.08382094651460648\n",
      "Epoch 1781, Loss: 0.2318674623966217, Final Batch Loss: 0.08992280066013336\n",
      "Epoch 1782, Loss: 0.19788815081119537, Final Batch Loss: 0.09828640520572662\n",
      "Epoch 1783, Loss: 0.1869477555155754, Final Batch Loss: 0.08934670686721802\n",
      "Epoch 1784, Loss: 0.1770939975976944, Final Batch Loss: 0.08095057308673859\n",
      "Epoch 1785, Loss: 0.1855047270655632, Final Batch Loss: 0.10635735094547272\n",
      "Epoch 1786, Loss: 0.21447664499282837, Final Batch Loss: 0.12610624730587006\n",
      "Epoch 1787, Loss: 0.2050500586628914, Final Batch Loss: 0.105025514960289\n",
      "Epoch 1788, Loss: 0.20262839645147324, Final Batch Loss: 0.08253014832735062\n",
      "Epoch 1789, Loss: 0.17423156648874283, Final Batch Loss: 0.0866323709487915\n",
      "Epoch 1790, Loss: 0.20137346535921097, Final Batch Loss: 0.06904592365026474\n",
      "Epoch 1791, Loss: 0.20550312101840973, Final Batch Loss: 0.10427595674991608\n",
      "Epoch 1792, Loss: 0.1913604587316513, Final Batch Loss: 0.09212324768304825\n",
      "Epoch 1793, Loss: 0.19132739305496216, Final Batch Loss: 0.07746409624814987\n",
      "Epoch 1794, Loss: 0.23340793699026108, Final Batch Loss: 0.10967498272657394\n",
      "Epoch 1795, Loss: 0.21557167172431946, Final Batch Loss: 0.09882142394781113\n",
      "Epoch 1796, Loss: 0.19754067808389664, Final Batch Loss: 0.0853516086935997\n",
      "Epoch 1797, Loss: 0.1645761802792549, Final Batch Loss: 0.0699283704161644\n",
      "Epoch 1798, Loss: 0.17137601971626282, Final Batch Loss: 0.07033439725637436\n",
      "Epoch 1799, Loss: 0.23081819713115692, Final Batch Loss: 0.10362531244754791\n",
      "Epoch 1800, Loss: 0.23779881745576859, Final Batch Loss: 0.1468009054660797\n",
      "Epoch 1801, Loss: 0.16509950906038284, Final Batch Loss: 0.0745660588145256\n",
      "Epoch 1802, Loss: 0.2128617838025093, Final Batch Loss: 0.07237649708986282\n",
      "Epoch 1803, Loss: 0.19603896886110306, Final Batch Loss: 0.13037891685962677\n",
      "Epoch 1804, Loss: 0.21065431088209152, Final Batch Loss: 0.11173208057880402\n",
      "Epoch 1805, Loss: 0.1749945655465126, Final Batch Loss: 0.07533697038888931\n",
      "Epoch 1806, Loss: 0.16091232001781464, Final Batch Loss: 0.08355250209569931\n",
      "Epoch 1807, Loss: 0.17277950793504715, Final Batch Loss: 0.06145726889371872\n",
      "Epoch 1808, Loss: 0.18343637138605118, Final Batch Loss: 0.08173990249633789\n",
      "Epoch 1809, Loss: 0.2005523219704628, Final Batch Loss: 0.09984686225652695\n",
      "Epoch 1810, Loss: 0.1700495332479477, Final Batch Loss: 0.07498273253440857\n",
      "Epoch 1811, Loss: 0.23658809810876846, Final Batch Loss: 0.08984387665987015\n",
      "Epoch 1812, Loss: 0.24747160822153091, Final Batch Loss: 0.16353371739387512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1813, Loss: 0.24197975546121597, Final Batch Loss: 0.13351665437221527\n",
      "Epoch 1814, Loss: 0.17963238060474396, Final Batch Loss: 0.07975710183382034\n",
      "Epoch 1815, Loss: 0.2060643434524536, Final Batch Loss: 0.12657742202281952\n",
      "Epoch 1816, Loss: 0.17118220776319504, Final Batch Loss: 0.0973723828792572\n",
      "Epoch 1817, Loss: 0.1845756098628044, Final Batch Loss: 0.08257409930229187\n",
      "Epoch 1818, Loss: 0.1570395827293396, Final Batch Loss: 0.07081832736730576\n",
      "Epoch 1819, Loss: 0.19274453073740005, Final Batch Loss: 0.09969332069158554\n",
      "Epoch 1820, Loss: 0.18225858360528946, Final Batch Loss: 0.10077386349439621\n",
      "Epoch 1821, Loss: 0.21012887358665466, Final Batch Loss: 0.08533252030611038\n",
      "Epoch 1822, Loss: 0.21690034866333008, Final Batch Loss: 0.13540345430374146\n",
      "Epoch 1823, Loss: 0.18597475439310074, Final Batch Loss: 0.11241032928228378\n",
      "Epoch 1824, Loss: 0.1463438868522644, Final Batch Loss: 0.08060931414365768\n",
      "Epoch 1825, Loss: 0.2138153463602066, Final Batch Loss: 0.131912499666214\n",
      "Epoch 1826, Loss: 0.2415708377957344, Final Batch Loss: 0.12830713391304016\n",
      "Epoch 1827, Loss: 0.26448357850313187, Final Batch Loss: 0.18324419856071472\n",
      "Epoch 1828, Loss: 0.20771315693855286, Final Batch Loss: 0.10481855273246765\n",
      "Epoch 1829, Loss: 0.17802713066339493, Final Batch Loss: 0.07505680620670319\n",
      "Epoch 1830, Loss: 0.1888023242354393, Final Batch Loss: 0.10156548768281937\n",
      "Epoch 1831, Loss: 0.19254028052091599, Final Batch Loss: 0.09560036659240723\n",
      "Epoch 1832, Loss: 0.16355891525745392, Final Batch Loss: 0.08644742518663406\n",
      "Epoch 1833, Loss: 0.19175780564546585, Final Batch Loss: 0.1240963563323021\n",
      "Epoch 1834, Loss: 0.1872822642326355, Final Batch Loss: 0.09005242586135864\n",
      "Epoch 1835, Loss: 0.17298607900738716, Final Batch Loss: 0.11100975424051285\n",
      "Epoch 1836, Loss: 0.2022620290517807, Final Batch Loss: 0.10723529756069183\n",
      "Epoch 1837, Loss: 0.21890725940465927, Final Batch Loss: 0.09234444051980972\n",
      "Epoch 1838, Loss: 0.17605046927928925, Final Batch Loss: 0.07360456883907318\n",
      "Epoch 1839, Loss: 0.1998170092701912, Final Batch Loss: 0.07896122336387634\n",
      "Epoch 1840, Loss: 0.16070955991744995, Final Batch Loss: 0.06891373544931412\n",
      "Epoch 1841, Loss: 0.18811917304992676, Final Batch Loss: 0.07527047395706177\n",
      "Epoch 1842, Loss: 0.17274615168571472, Final Batch Loss: 0.07642145454883575\n",
      "Epoch 1843, Loss: 0.17941853404045105, Final Batch Loss: 0.1134655624628067\n",
      "Epoch 1844, Loss: 0.22129298001527786, Final Batch Loss: 0.11548866331577301\n",
      "Epoch 1845, Loss: 0.18573500216007233, Final Batch Loss: 0.07950864732265472\n",
      "Epoch 1846, Loss: 0.2236635908484459, Final Batch Loss: 0.12289551645517349\n",
      "Epoch 1847, Loss: 0.17964424937963486, Final Batch Loss: 0.08804035931825638\n",
      "Epoch 1848, Loss: 0.18991395831108093, Final Batch Loss: 0.10989230871200562\n",
      "Epoch 1849, Loss: 0.19314993917942047, Final Batch Loss: 0.08417238295078278\n",
      "Epoch 1850, Loss: 0.183209590613842, Final Batch Loss: 0.09016977995634079\n",
      "Epoch 1851, Loss: 0.1950320079922676, Final Batch Loss: 0.10580363124608994\n",
      "Epoch 1852, Loss: 0.21332909166812897, Final Batch Loss: 0.113658607006073\n",
      "Epoch 1853, Loss: 0.21617768704891205, Final Batch Loss: 0.10872281342744827\n",
      "Epoch 1854, Loss: 0.19545163214206696, Final Batch Loss: 0.08790808171033859\n",
      "Epoch 1855, Loss: 0.2386225014925003, Final Batch Loss: 0.14850114285945892\n",
      "Epoch 1856, Loss: 0.161329947412014, Final Batch Loss: 0.08057910948991776\n",
      "Epoch 1857, Loss: 0.23179924488067627, Final Batch Loss: 0.13613483309745789\n",
      "Epoch 1858, Loss: 0.18194403499364853, Final Batch Loss: 0.0955079048871994\n",
      "Epoch 1859, Loss: 0.1991700455546379, Final Batch Loss: 0.12154228985309601\n",
      "Epoch 1860, Loss: 0.247376948595047, Final Batch Loss: 0.12811753153800964\n",
      "Epoch 1861, Loss: 0.1959761157631874, Final Batch Loss: 0.128866046667099\n",
      "Epoch 1862, Loss: 0.15852950513362885, Final Batch Loss: 0.05844102054834366\n",
      "Epoch 1863, Loss: 0.20473893731832504, Final Batch Loss: 0.13454782962799072\n",
      "Epoch 1864, Loss: 0.18973148614168167, Final Batch Loss: 0.10155245661735535\n",
      "Epoch 1865, Loss: 0.17267201095819473, Final Batch Loss: 0.08861131966114044\n",
      "Epoch 1866, Loss: 0.15985699743032455, Final Batch Loss: 0.09389175474643707\n",
      "Epoch 1867, Loss: 0.21045200526714325, Final Batch Loss: 0.1000567078590393\n",
      "Epoch 1868, Loss: 0.2529401481151581, Final Batch Loss: 0.1529863476753235\n",
      "Epoch 1869, Loss: 0.16522859036922455, Final Batch Loss: 0.0865616425871849\n",
      "Epoch 1870, Loss: 0.1932137906551361, Final Batch Loss: 0.051752105355262756\n",
      "Epoch 1871, Loss: 0.17198220267891884, Final Batch Loss: 0.11091982573270798\n",
      "Epoch 1872, Loss: 0.17818830162286758, Final Batch Loss: 0.08375455439090729\n",
      "Epoch 1873, Loss: 0.16713052988052368, Final Batch Loss: 0.08757081627845764\n",
      "Epoch 1874, Loss: 0.15265652164816856, Final Batch Loss: 0.060043301433324814\n",
      "Epoch 1875, Loss: 0.23365938663482666, Final Batch Loss: 0.08916385471820831\n",
      "Epoch 1876, Loss: 0.1863524094223976, Final Batch Loss: 0.0896899551153183\n",
      "Epoch 1877, Loss: 0.1503511667251587, Final Batch Loss: 0.06866646558046341\n",
      "Epoch 1878, Loss: 0.18122712522745132, Final Batch Loss: 0.10727978497743607\n",
      "Epoch 1879, Loss: 0.1609398052096367, Final Batch Loss: 0.06770733743906021\n",
      "Epoch 1880, Loss: 0.15144266933202744, Final Batch Loss: 0.08089564740657806\n",
      "Epoch 1881, Loss: 0.22641711682081223, Final Batch Loss: 0.13280317187309265\n",
      "Epoch 1882, Loss: 0.2285607010126114, Final Batch Loss: 0.1157354861497879\n",
      "Epoch 1883, Loss: 0.176760695874691, Final Batch Loss: 0.08720527589321136\n",
      "Epoch 1884, Loss: 0.1938898116350174, Final Batch Loss: 0.08985670655965805\n",
      "Epoch 1885, Loss: 0.1606467291712761, Final Batch Loss: 0.06276846677064896\n",
      "Epoch 1886, Loss: 0.20446398854255676, Final Batch Loss: 0.10988450795412064\n",
      "Epoch 1887, Loss: 0.17411433160305023, Final Batch Loss: 0.08433996140956879\n",
      "Epoch 1888, Loss: 0.19371815770864487, Final Batch Loss: 0.07023383677005768\n",
      "Epoch 1889, Loss: 0.21453490108251572, Final Batch Loss: 0.09903170168399811\n",
      "Epoch 1890, Loss: 0.16760007292032242, Final Batch Loss: 0.07476814091205597\n",
      "Epoch 1891, Loss: 0.1957385241985321, Final Batch Loss: 0.11060450226068497\n",
      "Epoch 1892, Loss: 0.21645194292068481, Final Batch Loss: 0.13039474189281464\n",
      "Epoch 1893, Loss: 0.19718162715435028, Final Batch Loss: 0.08285920321941376\n",
      "Epoch 1894, Loss: 0.1539391726255417, Final Batch Loss: 0.07396671175956726\n",
      "Epoch 1895, Loss: 0.20476333051919937, Final Batch Loss: 0.12103559821844101\n",
      "Epoch 1896, Loss: 0.1702006384730339, Final Batch Loss: 0.09510283917188644\n",
      "Epoch 1897, Loss: 0.199490524828434, Final Batch Loss: 0.09790703654289246\n",
      "Epoch 1898, Loss: 0.14802104234695435, Final Batch Loss: 0.07555866986513138\n",
      "Epoch 1899, Loss: 0.18756712973117828, Final Batch Loss: 0.07183018326759338\n",
      "Epoch 1900, Loss: 0.16475634276866913, Final Batch Loss: 0.07984532415866852\n",
      "Epoch 1901, Loss: 0.18762019276618958, Final Batch Loss: 0.08831407874822617\n",
      "Epoch 1902, Loss: 0.16118938848376274, Final Batch Loss: 0.060176726430654526\n",
      "Epoch 1903, Loss: 0.15674380213022232, Final Batch Loss: 0.044631391763687134\n",
      "Epoch 1904, Loss: 0.22156843543052673, Final Batch Loss: 0.1448184698820114\n",
      "Epoch 1905, Loss: 0.21853122115135193, Final Batch Loss: 0.0959552749991417\n",
      "Epoch 1906, Loss: 0.18068556487560272, Final Batch Loss: 0.11531105637550354\n",
      "Epoch 1907, Loss: 0.14376531913876534, Final Batch Loss: 0.04371337965130806\n",
      "Epoch 1908, Loss: 0.1598844677209854, Final Batch Loss: 0.07671371102333069\n",
      "Epoch 1909, Loss: 0.15619190782308578, Final Batch Loss: 0.07179022580385208\n",
      "Epoch 1910, Loss: 0.1823367178440094, Final Batch Loss: 0.10689396411180496\n",
      "Epoch 1911, Loss: 0.23237931728363037, Final Batch Loss: 0.11843930184841156\n",
      "Epoch 1912, Loss: 0.20146039873361588, Final Batch Loss: 0.112028107047081\n",
      "Epoch 1913, Loss: 0.20367784053087234, Final Batch Loss: 0.11365978419780731\n",
      "Epoch 1914, Loss: 0.19054264575242996, Final Batch Loss: 0.08499836921691895\n",
      "Epoch 1915, Loss: 0.158246248960495, Final Batch Loss: 0.06895522773265839\n",
      "Epoch 1916, Loss: 0.24268917739391327, Final Batch Loss: 0.13427089154720306\n",
      "Epoch 1917, Loss: 0.2227432131767273, Final Batch Loss: 0.1094701886177063\n",
      "Epoch 1918, Loss: 0.1849023848772049, Final Batch Loss: 0.11935997009277344\n",
      "Epoch 1919, Loss: 0.20782164484262466, Final Batch Loss: 0.12353505194187164\n",
      "Epoch 1920, Loss: 0.1637326255440712, Final Batch Loss: 0.09936496615409851\n",
      "Epoch 1921, Loss: 0.16991295665502548, Final Batch Loss: 0.09332152456045151\n",
      "Epoch 1922, Loss: 0.16876143962144852, Final Batch Loss: 0.06945890933275223\n",
      "Epoch 1923, Loss: 0.1292673423886299, Final Batch Loss: 0.0225977823138237\n",
      "Epoch 1924, Loss: 0.1880357339978218, Final Batch Loss: 0.0823662132024765\n",
      "Epoch 1925, Loss: 0.15711060166358948, Final Batch Loss: 0.09238911420106888\n",
      "Epoch 1926, Loss: 0.15335878729820251, Final Batch Loss: 0.07083970308303833\n",
      "Epoch 1927, Loss: 0.1956689953804016, Final Batch Loss: 0.07603400945663452\n",
      "Epoch 1928, Loss: 0.12555139511823654, Final Batch Loss: 0.0559057891368866\n",
      "Epoch 1929, Loss: 0.17122159898281097, Final Batch Loss: 0.11316582560539246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1930, Loss: 0.16321542114019394, Final Batch Loss: 0.09600462019443512\n",
      "Epoch 1931, Loss: 0.1816026046872139, Final Batch Loss: 0.11170367896556854\n",
      "Epoch 1932, Loss: 0.15456629917025566, Final Batch Loss: 0.04992024227976799\n",
      "Epoch 1933, Loss: 0.20808453112840652, Final Batch Loss: 0.11072275787591934\n",
      "Epoch 1934, Loss: 0.20289334654808044, Final Batch Loss: 0.08296586573123932\n",
      "Epoch 1935, Loss: 0.18148159235715866, Final Batch Loss: 0.0749608501791954\n",
      "Epoch 1936, Loss: 0.18169746547937393, Final Batch Loss: 0.1015365794301033\n",
      "Epoch 1937, Loss: 0.1615019589662552, Final Batch Loss: 0.0793718546628952\n",
      "Epoch 1938, Loss: 0.1734938696026802, Final Batch Loss: 0.06782542169094086\n",
      "Epoch 1939, Loss: 0.1446242853999138, Final Batch Loss: 0.06444405019283295\n",
      "Epoch 1940, Loss: 0.18910697847604752, Final Batch Loss: 0.09590231627225876\n",
      "Epoch 1941, Loss: 0.19140563160181046, Final Batch Loss: 0.11343137174844742\n",
      "Epoch 1942, Loss: 0.16627731919288635, Final Batch Loss: 0.06821509450674057\n",
      "Epoch 1943, Loss: 0.19868751615285873, Final Batch Loss: 0.12464731186628342\n",
      "Epoch 1944, Loss: 0.2556720972061157, Final Batch Loss: 0.16540999710559845\n",
      "Epoch 1945, Loss: 0.18041418492794037, Final Batch Loss: 0.09646894782781601\n",
      "Epoch 1946, Loss: 0.1923186182975769, Final Batch Loss: 0.1374627649784088\n",
      "Epoch 1947, Loss: 0.17529762536287308, Final Batch Loss: 0.06505267322063446\n",
      "Epoch 1948, Loss: 0.26430726051330566, Final Batch Loss: 0.1738058477640152\n",
      "Epoch 1949, Loss: 0.21045652031898499, Final Batch Loss: 0.11647974699735641\n",
      "Epoch 1950, Loss: 0.16567359119653702, Final Batch Loss: 0.06359191983938217\n",
      "Epoch 1951, Loss: 0.18017392605543137, Final Batch Loss: 0.09794565290212631\n",
      "Epoch 1952, Loss: 0.17022011429071426, Final Batch Loss: 0.07049449533224106\n",
      "Epoch 1953, Loss: 0.17837367951869965, Final Batch Loss: 0.0923309326171875\n",
      "Epoch 1954, Loss: 0.18099559843540192, Final Batch Loss: 0.08469945192337036\n",
      "Epoch 1955, Loss: 0.1465858519077301, Final Batch Loss: 0.0714251846075058\n",
      "Epoch 1956, Loss: 0.1697184070944786, Final Batch Loss: 0.08799038082361221\n",
      "Epoch 1957, Loss: 0.19585277140140533, Final Batch Loss: 0.06563456356525421\n",
      "Epoch 1958, Loss: 0.19210002571344376, Final Batch Loss: 0.12378951162099838\n",
      "Epoch 1959, Loss: 0.19568973779678345, Final Batch Loss: 0.09902895241975784\n",
      "Epoch 1960, Loss: 0.15460049360990524, Final Batch Loss: 0.08328390121459961\n",
      "Epoch 1961, Loss: 0.23549219965934753, Final Batch Loss: 0.11126987636089325\n",
      "Epoch 1962, Loss: 0.16117316484451294, Final Batch Loss: 0.0845244899392128\n",
      "Epoch 1963, Loss: 0.17191865667700768, Final Batch Loss: 0.11036167293787003\n",
      "Epoch 1964, Loss: 0.21755198389291763, Final Batch Loss: 0.10587558895349503\n",
      "Epoch 1965, Loss: 0.1743742749094963, Final Batch Loss: 0.10111436992883682\n",
      "Epoch 1966, Loss: 0.1679474115371704, Final Batch Loss: 0.09882067888975143\n",
      "Epoch 1967, Loss: 0.184621661901474, Final Batch Loss: 0.07058019936084747\n",
      "Epoch 1968, Loss: 0.15067527815699577, Final Batch Loss: 0.05027638003230095\n",
      "Epoch 1969, Loss: 0.14733775705099106, Final Batch Loss: 0.06242993474006653\n",
      "Epoch 1970, Loss: 0.17804694175720215, Final Batch Loss: 0.03436547517776489\n",
      "Epoch 1971, Loss: 0.18401076644659042, Final Batch Loss: 0.09891176223754883\n",
      "Epoch 1972, Loss: 0.20084352046251297, Final Batch Loss: 0.10685276240110397\n",
      "Epoch 1973, Loss: 0.17719516158103943, Final Batch Loss: 0.09041590243577957\n",
      "Epoch 1974, Loss: 0.18515193462371826, Final Batch Loss: 0.09123498201370239\n",
      "Epoch 1975, Loss: 0.18493588268756866, Final Batch Loss: 0.06907546520233154\n",
      "Epoch 1976, Loss: 0.17462047934532166, Final Batch Loss: 0.08607540279626846\n",
      "Epoch 1977, Loss: 0.1379098892211914, Final Batch Loss: 0.07506192475557327\n",
      "Epoch 1978, Loss: 0.16784588992595673, Final Batch Loss: 0.10211550444364548\n",
      "Epoch 1979, Loss: 0.1260744035243988, Final Batch Loss: 0.06285765022039413\n",
      "Epoch 1980, Loss: 0.18402766436338425, Final Batch Loss: 0.08463933318853378\n",
      "Epoch 1981, Loss: 0.16515234112739563, Final Batch Loss: 0.08426843583583832\n",
      "Epoch 1982, Loss: 0.18008775264024734, Final Batch Loss: 0.09774675965309143\n",
      "Epoch 1983, Loss: 0.17372523248195648, Final Batch Loss: 0.07152445614337921\n",
      "Epoch 1984, Loss: 0.18731983751058578, Final Batch Loss: 0.08260868489742279\n",
      "Epoch 1985, Loss: 0.17843513935804367, Final Batch Loss: 0.08843059092760086\n",
      "Epoch 1986, Loss: 0.18942071497440338, Final Batch Loss: 0.10164003819227219\n",
      "Epoch 1987, Loss: 0.15447182208299637, Final Batch Loss: 0.07519283145666122\n",
      "Epoch 1988, Loss: 0.1840982586145401, Final Batch Loss: 0.085879847407341\n",
      "Epoch 1989, Loss: 0.1297757290303707, Final Batch Loss: 0.07473757117986679\n",
      "Epoch 1990, Loss: 0.17374063283205032, Final Batch Loss: 0.08952618390321732\n",
      "Epoch 1991, Loss: 0.12333299219608307, Final Batch Loss: 0.04242923855781555\n",
      "Epoch 1992, Loss: 0.15268409624695778, Final Batch Loss: 0.10788840800523758\n",
      "Epoch 1993, Loss: 0.14997125416994095, Final Batch Loss: 0.0646495670080185\n",
      "Epoch 1994, Loss: 0.1569906696677208, Final Batch Loss: 0.08346987515687943\n",
      "Epoch 1995, Loss: 0.18786662071943283, Final Batch Loss: 0.09618732333183289\n",
      "Epoch 1996, Loss: 0.13369299098849297, Final Batch Loss: 0.049113813787698746\n",
      "Epoch 1997, Loss: 0.12874959036707878, Final Batch Loss: 0.03939354047179222\n",
      "Epoch 1998, Loss: 0.173739455640316, Final Batch Loss: 0.08637925982475281\n",
      "Epoch 1999, Loss: 0.1564781293272972, Final Batch Loss: 0.08708465844392776\n",
      "Epoch 2000, Loss: 0.15193598717451096, Final Batch Loss: 0.059287577867507935\n",
      "Epoch 2001, Loss: 0.14571963250637054, Final Batch Loss: 0.07175035029649734\n",
      "Epoch 2002, Loss: 0.18215255439281464, Final Batch Loss: 0.10242738574743271\n",
      "Epoch 2003, Loss: 0.14821989089250565, Final Batch Loss: 0.0750420093536377\n",
      "Epoch 2004, Loss: 0.15347357094287872, Final Batch Loss: 0.08327475935220718\n",
      "Epoch 2005, Loss: 0.18358078598976135, Final Batch Loss: 0.08615732938051224\n",
      "Epoch 2006, Loss: 0.1608690246939659, Final Batch Loss: 0.08216476440429688\n",
      "Epoch 2007, Loss: 0.15462642163038254, Final Batch Loss: 0.08026634156703949\n",
      "Epoch 2008, Loss: 0.13961028307676315, Final Batch Loss: 0.06435920298099518\n",
      "Epoch 2009, Loss: 0.21320053935050964, Final Batch Loss: 0.14133428037166595\n",
      "Epoch 2010, Loss: 0.18608935177326202, Final Batch Loss: 0.09005328267812729\n",
      "Epoch 2011, Loss: 0.3033398538827896, Final Batch Loss: 0.22681675851345062\n",
      "Epoch 2012, Loss: 0.16643891483545303, Final Batch Loss: 0.08955051749944687\n",
      "Epoch 2013, Loss: 0.14790448546409607, Final Batch Loss: 0.08305370062589645\n",
      "Epoch 2014, Loss: 0.1840885952115059, Final Batch Loss: 0.08237268030643463\n",
      "Epoch 2015, Loss: 0.20909184962511063, Final Batch Loss: 0.12342336028814316\n",
      "Epoch 2016, Loss: 0.17771156132221222, Final Batch Loss: 0.09625495225191116\n",
      "Epoch 2017, Loss: 0.2677074074745178, Final Batch Loss: 0.06944750249385834\n",
      "Epoch 2018, Loss: 0.22582686692476273, Final Batch Loss: 0.10777166485786438\n",
      "Epoch 2019, Loss: 0.22810299694538116, Final Batch Loss: 0.10710994154214859\n",
      "Epoch 2020, Loss: 0.21194803714752197, Final Batch Loss: 0.09465926140546799\n",
      "Epoch 2021, Loss: 0.19443012028932571, Final Batch Loss: 0.1030883863568306\n",
      "Epoch 2022, Loss: 0.1538412943482399, Final Batch Loss: 0.07296376675367355\n",
      "Epoch 2023, Loss: 0.1575302705168724, Final Batch Loss: 0.0913611650466919\n",
      "Epoch 2024, Loss: 0.18860338628292084, Final Batch Loss: 0.08411168307065964\n",
      "Epoch 2025, Loss: 0.1645413488149643, Final Batch Loss: 0.09191512316465378\n",
      "Epoch 2026, Loss: 0.13664650544524193, Final Batch Loss: 0.05883203074336052\n",
      "Epoch 2027, Loss: 0.14289608597755432, Final Batch Loss: 0.052686162292957306\n",
      "Epoch 2028, Loss: 0.1877306029200554, Final Batch Loss: 0.07011022418737411\n",
      "Epoch 2029, Loss: 0.18395653367042542, Final Batch Loss: 0.11117931455373764\n",
      "Epoch 2030, Loss: 0.17013652995228767, Final Batch Loss: 0.06163092330098152\n",
      "Epoch 2031, Loss: 0.1714940443634987, Final Batch Loss: 0.0904879942536354\n",
      "Epoch 2032, Loss: 0.14158041775226593, Final Batch Loss: 0.07691795378923416\n",
      "Epoch 2033, Loss: 0.17916522920131683, Final Batch Loss: 0.09828752279281616\n",
      "Epoch 2034, Loss: 0.17929945141077042, Final Batch Loss: 0.08237335830926895\n",
      "Epoch 2035, Loss: 0.15274398773908615, Final Batch Loss: 0.06407343596220016\n",
      "Epoch 2036, Loss: 0.14575015008449554, Final Batch Loss: 0.03126771003007889\n",
      "Epoch 2037, Loss: 0.2332698553800583, Final Batch Loss: 0.135072261095047\n",
      "Epoch 2038, Loss: 0.1493515409529209, Final Batch Loss: 0.08901911973953247\n",
      "Epoch 2039, Loss: 0.1828431338071823, Final Batch Loss: 0.08942320197820663\n",
      "Epoch 2040, Loss: 0.1541469469666481, Final Batch Loss: 0.0799683928489685\n",
      "Epoch 2041, Loss: 0.241617351770401, Final Batch Loss: 0.15146972239017487\n",
      "Epoch 2042, Loss: 0.1563292071223259, Final Batch Loss: 0.04853101819753647\n",
      "Epoch 2043, Loss: 0.1633629873394966, Final Batch Loss: 0.06693295389413834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2044, Loss: 0.17088119685649872, Final Batch Loss: 0.10273849964141846\n",
      "Epoch 2045, Loss: 0.15305690467357635, Final Batch Loss: 0.08934032917022705\n",
      "Epoch 2046, Loss: 0.142712090164423, Final Batch Loss: 0.058540914207696915\n",
      "Epoch 2047, Loss: 0.16165540367364883, Final Batch Loss: 0.07238660752773285\n",
      "Epoch 2048, Loss: 0.13599778711795807, Final Batch Loss: 0.06411504745483398\n",
      "Epoch 2049, Loss: 0.14052026718854904, Final Batch Loss: 0.07374703884124756\n",
      "Epoch 2050, Loss: 0.1705104485154152, Final Batch Loss: 0.08532468974590302\n",
      "Epoch 2051, Loss: 0.16605950519442558, Final Batch Loss: 0.06002087518572807\n",
      "Epoch 2052, Loss: 0.1593782901763916, Final Batch Loss: 0.08252207189798355\n",
      "Epoch 2053, Loss: 0.16043838113546371, Final Batch Loss: 0.06766945123672485\n",
      "Epoch 2054, Loss: 0.11321065202355385, Final Batch Loss: 0.03474495932459831\n",
      "Epoch 2055, Loss: 0.1689876914024353, Final Batch Loss: 0.08005779981613159\n",
      "Epoch 2056, Loss: 0.18236631900072098, Final Batch Loss: 0.07833980023860931\n",
      "Epoch 2057, Loss: 0.173166424036026, Final Batch Loss: 0.06289143860340118\n",
      "Epoch 2058, Loss: 0.22842922806739807, Final Batch Loss: 0.15517239272594452\n",
      "Epoch 2059, Loss: 0.11382847279310226, Final Batch Loss: 0.051760233938694\n",
      "Epoch 2060, Loss: 0.1398998200893402, Final Batch Loss: 0.05013096332550049\n",
      "Epoch 2061, Loss: 0.16681520640850067, Final Batch Loss: 0.09705840051174164\n",
      "Epoch 2062, Loss: 0.16003653407096863, Final Batch Loss: 0.06793476641178131\n",
      "Epoch 2063, Loss: 0.17169390246272087, Final Batch Loss: 0.05912330374121666\n",
      "Epoch 2064, Loss: 0.1682620346546173, Final Batch Loss: 0.07699597626924515\n",
      "Epoch 2065, Loss: 0.19462763518095016, Final Batch Loss: 0.09794681519269943\n",
      "Epoch 2066, Loss: 0.2173706591129303, Final Batch Loss: 0.14891256392002106\n",
      "Epoch 2067, Loss: 0.13363377377390862, Final Batch Loss: 0.05471217259764671\n",
      "Epoch 2068, Loss: 0.1849474012851715, Final Batch Loss: 0.09109188616275787\n",
      "Epoch 2069, Loss: 0.1328052207827568, Final Batch Loss: 0.06563139706850052\n",
      "Epoch 2070, Loss: 0.16501472890377045, Final Batch Loss: 0.08832671493291855\n",
      "Epoch 2071, Loss: 0.2363578900694847, Final Batch Loss: 0.14421933889389038\n",
      "Epoch 2072, Loss: 0.1659303903579712, Final Batch Loss: 0.09232643991708755\n",
      "Epoch 2073, Loss: 0.13332877680659294, Final Batch Loss: 0.04762064293026924\n",
      "Epoch 2074, Loss: 0.17364376783370972, Final Batch Loss: 0.07187916338443756\n",
      "Epoch 2075, Loss: 0.17185194790363312, Final Batch Loss: 0.0779244676232338\n",
      "Epoch 2076, Loss: 0.1484336480498314, Final Batch Loss: 0.06992994993925095\n",
      "Epoch 2077, Loss: 0.13388638198375702, Final Batch Loss: 0.06224799156188965\n",
      "Epoch 2078, Loss: 0.15031855553388596, Final Batch Loss: 0.06001713126897812\n",
      "Epoch 2079, Loss: 0.16765562444925308, Final Batch Loss: 0.0825338289141655\n",
      "Epoch 2080, Loss: 0.16038119792938232, Final Batch Loss: 0.08729617297649384\n",
      "Epoch 2081, Loss: 0.1304330863058567, Final Batch Loss: 0.07753662765026093\n",
      "Epoch 2082, Loss: 0.14313293248414993, Final Batch Loss: 0.06332767754793167\n",
      "Epoch 2083, Loss: 0.16406016051769257, Final Batch Loss: 0.06058553606271744\n",
      "Epoch 2084, Loss: 0.17394915223121643, Final Batch Loss: 0.10913429409265518\n",
      "Epoch 2085, Loss: 0.15756337344646454, Final Batch Loss: 0.08693619072437286\n",
      "Epoch 2086, Loss: 0.15156801044940948, Final Batch Loss: 0.06599840521812439\n",
      "Epoch 2087, Loss: 0.15385427325963974, Final Batch Loss: 0.09075409919023514\n",
      "Epoch 2088, Loss: 0.11392533406615257, Final Batch Loss: 0.04368617758154869\n",
      "Epoch 2089, Loss: 0.1972922682762146, Final Batch Loss: 0.13978822529315948\n",
      "Epoch 2090, Loss: 0.17064165323972702, Final Batch Loss: 0.11513342708349228\n",
      "Epoch 2091, Loss: 0.14250855147838593, Final Batch Loss: 0.0763496682047844\n",
      "Epoch 2092, Loss: 0.127845399081707, Final Batch Loss: 0.05037469416856766\n",
      "Epoch 2093, Loss: 0.15165698528289795, Final Batch Loss: 0.08423855900764465\n",
      "Epoch 2094, Loss: 0.1847972832620144, Final Batch Loss: 0.05966876074671745\n",
      "Epoch 2095, Loss: 0.17349091917276382, Final Batch Loss: 0.08824360370635986\n",
      "Epoch 2096, Loss: 0.16261282563209534, Final Batch Loss: 0.09502741694450378\n",
      "Epoch 2097, Loss: 0.1453552097082138, Final Batch Loss: 0.07091124355792999\n",
      "Epoch 2098, Loss: 0.14707984775304794, Final Batch Loss: 0.06482558697462082\n",
      "Epoch 2099, Loss: 0.1667373701930046, Final Batch Loss: 0.05006372183561325\n",
      "Epoch 2100, Loss: 0.11976896598935127, Final Batch Loss: 0.062130849808454514\n",
      "Epoch 2101, Loss: 0.16499539092183113, Final Batch Loss: 0.1040874496102333\n",
      "Epoch 2102, Loss: 0.17749446630477905, Final Batch Loss: 0.09706766158342361\n",
      "Epoch 2103, Loss: 0.20123383402824402, Final Batch Loss: 0.08609149605035782\n",
      "Epoch 2104, Loss: 0.14764845371246338, Final Batch Loss: 0.0661248192191124\n",
      "Epoch 2105, Loss: 0.1668456569314003, Final Batch Loss: 0.07796989381313324\n",
      "Epoch 2106, Loss: 0.15477712452411652, Final Batch Loss: 0.08331091701984406\n",
      "Epoch 2107, Loss: 0.1304355189204216, Final Batch Loss: 0.06263570487499237\n",
      "Epoch 2108, Loss: 0.19410501420497894, Final Batch Loss: 0.13146671652793884\n",
      "Epoch 2109, Loss: 0.1641092672944069, Final Batch Loss: 0.08787916600704193\n",
      "Epoch 2110, Loss: 0.1648004725575447, Final Batch Loss: 0.08397235721349716\n",
      "Epoch 2111, Loss: 0.18501129746437073, Final Batch Loss: 0.08337001502513885\n",
      "Epoch 2112, Loss: 0.17812572419643402, Final Batch Loss: 0.0673430860042572\n",
      "Epoch 2113, Loss: 0.16922976821660995, Final Batch Loss: 0.08003777265548706\n",
      "Epoch 2114, Loss: 0.16835836321115494, Final Batch Loss: 0.09684755653142929\n",
      "Epoch 2115, Loss: 0.13658199459314346, Final Batch Loss: 0.0673680305480957\n",
      "Epoch 2116, Loss: 0.17460279166698456, Final Batch Loss: 0.11428595334291458\n",
      "Epoch 2117, Loss: 0.16824979335069656, Final Batch Loss: 0.09769291430711746\n",
      "Epoch 2118, Loss: 0.18755541741847992, Final Batch Loss: 0.05477896332740784\n",
      "Epoch 2119, Loss: 0.2661738246679306, Final Batch Loss: 0.18358945846557617\n",
      "Epoch 2120, Loss: 0.18255077302455902, Final Batch Loss: 0.07334404438734055\n",
      "Epoch 2121, Loss: 0.19290734827518463, Final Batch Loss: 0.10851515829563141\n",
      "Epoch 2122, Loss: 0.17251969873905182, Final Batch Loss: 0.09741005301475525\n",
      "Epoch 2123, Loss: 0.18791327625513077, Final Batch Loss: 0.11211535334587097\n",
      "Epoch 2124, Loss: 0.19332995638251305, Final Batch Loss: 0.06056692823767662\n",
      "Epoch 2125, Loss: 0.201053224503994, Final Batch Loss: 0.08571244776248932\n",
      "Epoch 2126, Loss: 0.14847873896360397, Final Batch Loss: 0.0797995999455452\n",
      "Epoch 2127, Loss: 0.17702525854110718, Final Batch Loss: 0.10452841967344284\n",
      "Epoch 2128, Loss: 0.16699107736349106, Final Batch Loss: 0.07927331328392029\n",
      "Epoch 2129, Loss: 0.1812187135219574, Final Batch Loss: 0.09449499845504761\n",
      "Epoch 2130, Loss: 0.20066091418266296, Final Batch Loss: 0.13091042637825012\n",
      "Epoch 2131, Loss: 0.3698820322751999, Final Batch Loss: 0.271010160446167\n",
      "Epoch 2132, Loss: 0.18042491376399994, Final Batch Loss: 0.08159685134887695\n",
      "Epoch 2133, Loss: 0.156118743121624, Final Batch Loss: 0.08138459920883179\n",
      "Epoch 2134, Loss: 0.18554067611694336, Final Batch Loss: 0.07999542355537415\n",
      "Epoch 2135, Loss: 0.16554880142211914, Final Batch Loss: 0.09611234068870544\n",
      "Epoch 2136, Loss: 0.19195012748241425, Final Batch Loss: 0.09144298732280731\n",
      "Epoch 2137, Loss: 0.2074676752090454, Final Batch Loss: 0.1197238564491272\n",
      "Epoch 2138, Loss: 0.18377673625946045, Final Batch Loss: 0.09976711124181747\n",
      "Epoch 2139, Loss: 0.2732880562543869, Final Batch Loss: 0.18869318068027496\n",
      "Epoch 2140, Loss: 0.20186568051576614, Final Batch Loss: 0.11071968078613281\n",
      "Epoch 2141, Loss: 0.16699635982513428, Final Batch Loss: 0.08682528883218765\n",
      "Epoch 2142, Loss: 0.1688799113035202, Final Batch Loss: 0.06300394982099533\n",
      "Epoch 2143, Loss: 0.18346648663282394, Final Batch Loss: 0.09527161717414856\n",
      "Epoch 2144, Loss: 0.156774640083313, Final Batch Loss: 0.08399403840303421\n",
      "Epoch 2145, Loss: 0.13898547738790512, Final Batch Loss: 0.06401810795068741\n",
      "Epoch 2146, Loss: 0.13507238402962685, Final Batch Loss: 0.0552065335214138\n",
      "Epoch 2147, Loss: 0.1385970525443554, Final Batch Loss: 0.07627251744270325\n",
      "Epoch 2148, Loss: 0.1414669305086136, Final Batch Loss: 0.07537806779146194\n",
      "Epoch 2149, Loss: 0.18465931713581085, Final Batch Loss: 0.1104898527264595\n",
      "Epoch 2150, Loss: 0.1641632616519928, Final Batch Loss: 0.0710701048374176\n",
      "Epoch 2151, Loss: 0.15870695561170578, Final Batch Loss: 0.06760163605213165\n",
      "Epoch 2152, Loss: 0.17073555663228035, Final Batch Loss: 0.05755307897925377\n",
      "Epoch 2153, Loss: 0.133872639387846, Final Batch Loss: 0.07804539799690247\n",
      "Epoch 2154, Loss: 0.15774022042751312, Final Batch Loss: 0.06857068836688995\n",
      "Epoch 2155, Loss: 0.1545662134885788, Final Batch Loss: 0.06693737953901291\n",
      "Epoch 2156, Loss: 0.17546893656253815, Final Batch Loss: 0.0987185388803482\n",
      "Epoch 2157, Loss: 0.114374540746212, Final Batch Loss: 0.03804698586463928\n",
      "Epoch 2158, Loss: 0.12282342463731766, Final Batch Loss: 0.05565749853849411\n",
      "Epoch 2159, Loss: 0.12723511829972267, Final Batch Loss: 0.07671293616294861\n",
      "Epoch 2160, Loss: 0.15711285918951035, Final Batch Loss: 0.10332047194242477\n",
      "Epoch 2161, Loss: 0.1514415293931961, Final Batch Loss: 0.07811012119054794\n",
      "Epoch 2162, Loss: 0.18758346885442734, Final Batch Loss: 0.08006568253040314\n",
      "Epoch 2163, Loss: 0.14224179461598396, Final Batch Loss: 0.056960489600896835\n",
      "Epoch 2164, Loss: 0.15119395405054092, Final Batch Loss: 0.0799330621957779\n",
      "Epoch 2165, Loss: 0.16608954966068268, Final Batch Loss: 0.054045677185058594\n",
      "Epoch 2166, Loss: 0.19497551769018173, Final Batch Loss: 0.11333325505256653\n",
      "Epoch 2167, Loss: 0.13030137494206429, Final Batch Loss: 0.05831092223525047\n",
      "Epoch 2168, Loss: 0.1167534664273262, Final Batch Loss: 0.04914236068725586\n",
      "Epoch 2169, Loss: 0.1449366919696331, Final Batch Loss: 0.05739395692944527\n",
      "Epoch 2170, Loss: 0.16349131613969803, Final Batch Loss: 0.09203417599201202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2171, Loss: 0.1770607829093933, Final Batch Loss: 0.0991329699754715\n",
      "Epoch 2172, Loss: 0.13030774146318436, Final Batch Loss: 0.04738958179950714\n",
      "Epoch 2173, Loss: 0.15180447697639465, Final Batch Loss: 0.07625006139278412\n",
      "Epoch 2174, Loss: 0.17146679013967514, Final Batch Loss: 0.06329313665628433\n",
      "Epoch 2175, Loss: 0.19799185544252396, Final Batch Loss: 0.08037862926721573\n",
      "Epoch 2176, Loss: 0.16738593578338623, Final Batch Loss: 0.08857035636901855\n",
      "Epoch 2177, Loss: 0.21176906302571297, Final Batch Loss: 0.15064042806625366\n",
      "Epoch 2178, Loss: 0.20776334404945374, Final Batch Loss: 0.08663912862539291\n",
      "Epoch 2179, Loss: 0.17175723239779472, Final Batch Loss: 0.05125943943858147\n",
      "Epoch 2180, Loss: 0.24246326088905334, Final Batch Loss: 0.16336208581924438\n",
      "Epoch 2181, Loss: 0.16942749917507172, Final Batch Loss: 0.1021914929151535\n",
      "Epoch 2182, Loss: 0.15943671390414238, Final Batch Loss: 0.10179503262042999\n",
      "Epoch 2183, Loss: 0.14898944646120071, Final Batch Loss: 0.06735917180776596\n",
      "Epoch 2184, Loss: 0.1428474709391594, Final Batch Loss: 0.07820252329111099\n",
      "Epoch 2185, Loss: 0.15723279118537903, Final Batch Loss: 0.087075375020504\n",
      "Epoch 2186, Loss: 0.2152513638138771, Final Batch Loss: 0.10451307147741318\n",
      "Epoch 2187, Loss: 0.14234762638807297, Final Batch Loss: 0.08094953000545502\n",
      "Epoch 2188, Loss: 0.15681079775094986, Final Batch Loss: 0.08050544559955597\n",
      "Epoch 2189, Loss: 0.1735927313566208, Final Batch Loss: 0.05154138803482056\n",
      "Epoch 2190, Loss: 0.1526191085577011, Final Batch Loss: 0.08251012116670609\n",
      "Epoch 2191, Loss: 0.15109969303011894, Final Batch Loss: 0.052794743329286575\n",
      "Epoch 2192, Loss: 0.19185379892587662, Final Batch Loss: 0.11532267183065414\n",
      "Epoch 2193, Loss: 0.14196763187646866, Final Batch Loss: 0.06642954796552658\n",
      "Epoch 2194, Loss: 0.19743862748146057, Final Batch Loss: 0.08561519533395767\n",
      "Epoch 2195, Loss: 0.1333322823047638, Final Batch Loss: 0.06779345870018005\n",
      "Epoch 2196, Loss: 0.18231210857629776, Final Batch Loss: 0.09213345497846603\n",
      "Epoch 2197, Loss: 0.16676241531968117, Final Batch Loss: 0.11605140566825867\n",
      "Epoch 2198, Loss: 0.1646438017487526, Final Batch Loss: 0.0864318236708641\n",
      "Epoch 2199, Loss: 0.16139670461416245, Final Batch Loss: 0.03908932954072952\n",
      "Epoch 2200, Loss: 0.14290454983711243, Final Batch Loss: 0.06965500861406326\n",
      "Epoch 2201, Loss: 0.1557111218571663, Final Batch Loss: 0.06948742270469666\n",
      "Epoch 2202, Loss: 0.1405448243021965, Final Batch Loss: 0.050264328718185425\n",
      "Epoch 2203, Loss: 0.14174342900514603, Final Batch Loss: 0.06419458240270615\n",
      "Epoch 2204, Loss: 0.1540447399020195, Final Batch Loss: 0.08528998494148254\n",
      "Epoch 2205, Loss: 0.16502510011196136, Final Batch Loss: 0.07469800859689713\n",
      "Epoch 2206, Loss: 0.19301116466522217, Final Batch Loss: 0.09953637421131134\n",
      "Epoch 2207, Loss: 0.1698630154132843, Final Batch Loss: 0.09264571219682693\n",
      "Epoch 2208, Loss: 0.1677578166127205, Final Batch Loss: 0.0878557413816452\n",
      "Epoch 2209, Loss: 0.17551086843013763, Final Batch Loss: 0.09627188742160797\n",
      "Epoch 2210, Loss: 0.13057386130094528, Final Batch Loss: 0.05593198537826538\n",
      "Epoch 2211, Loss: 0.16096831113100052, Final Batch Loss: 0.08876708894968033\n",
      "Epoch 2212, Loss: 0.17132579535245895, Final Batch Loss: 0.08630358427762985\n",
      "Epoch 2213, Loss: 0.18911553174257278, Final Batch Loss: 0.12451635301113129\n",
      "Epoch 2214, Loss: 0.16822268441319466, Final Batch Loss: 0.05077872797846794\n",
      "Epoch 2215, Loss: 0.15257048606872559, Final Batch Loss: 0.05794208496809006\n",
      "Epoch 2216, Loss: 0.15501060336828232, Final Batch Loss: 0.07550399750471115\n",
      "Epoch 2217, Loss: 0.1800675317645073, Final Batch Loss: 0.11332806199789047\n",
      "Epoch 2218, Loss: 0.15224183350801468, Final Batch Loss: 0.08454515784978867\n",
      "Epoch 2219, Loss: 0.13850678503513336, Final Batch Loss: 0.07540666311979294\n",
      "Epoch 2220, Loss: 0.170444056391716, Final Batch Loss: 0.10264714062213898\n",
      "Epoch 2221, Loss: 0.12139016389846802, Final Batch Loss: 0.060507938265800476\n",
      "Epoch 2222, Loss: 0.20895985513925552, Final Batch Loss: 0.10737737268209457\n",
      "Epoch 2223, Loss: 0.13784343376755714, Final Batch Loss: 0.04946016147732735\n",
      "Epoch 2224, Loss: 0.14865001291036606, Final Batch Loss: 0.06599810719490051\n",
      "Epoch 2225, Loss: 0.15644288063049316, Final Batch Loss: 0.08755256235599518\n",
      "Epoch 2226, Loss: 0.17308711260557175, Final Batch Loss: 0.07699940353631973\n",
      "Epoch 2227, Loss: 0.1880275085568428, Final Batch Loss: 0.11666824668645859\n",
      "Epoch 2228, Loss: 0.17481734603643417, Final Batch Loss: 0.09140176326036453\n",
      "Epoch 2229, Loss: 0.1844901740550995, Final Batch Loss: 0.09948533773422241\n",
      "Epoch 2230, Loss: 0.16425053030252457, Final Batch Loss: 0.08333791047334671\n",
      "Epoch 2231, Loss: 0.17432674765586853, Final Batch Loss: 0.060222119092941284\n",
      "Epoch 2232, Loss: 0.247267946600914, Final Batch Loss: 0.09022685885429382\n",
      "Epoch 2233, Loss: 0.2062443569302559, Final Batch Loss: 0.10491577535867691\n",
      "Epoch 2234, Loss: 0.14979535341262817, Final Batch Loss: 0.08797714114189148\n",
      "Epoch 2235, Loss: 0.17501408979296684, Final Batch Loss: 0.05028015747666359\n",
      "Epoch 2236, Loss: 0.16743115335702896, Final Batch Loss: 0.06502746045589447\n",
      "Epoch 2237, Loss: 0.15650732070207596, Final Batch Loss: 0.06134343892335892\n",
      "Epoch 2238, Loss: 0.12690793722867966, Final Batch Loss: 0.03158009052276611\n",
      "Epoch 2239, Loss: 0.1824093833565712, Final Batch Loss: 0.0802866593003273\n",
      "Epoch 2240, Loss: 0.15990179777145386, Final Batch Loss: 0.08269554376602173\n",
      "Epoch 2241, Loss: 0.17506379634141922, Final Batch Loss: 0.0986325666308403\n",
      "Epoch 2242, Loss: 0.20886075496673584, Final Batch Loss: 0.07554259896278381\n",
      "Epoch 2243, Loss: 0.19410507380962372, Final Batch Loss: 0.11757197976112366\n",
      "Epoch 2244, Loss: 0.17916066199541092, Final Batch Loss: 0.09178617596626282\n",
      "Epoch 2245, Loss: 0.12600012868642807, Final Batch Loss: 0.06589438766241074\n",
      "Epoch 2246, Loss: 0.12750474736094475, Final Batch Loss: 0.05573531612753868\n",
      "Epoch 2247, Loss: 0.13622836768627167, Final Batch Loss: 0.06534416973590851\n",
      "Epoch 2248, Loss: 0.1289914809167385, Final Batch Loss: 0.08000291138887405\n",
      "Epoch 2249, Loss: 0.12097112461924553, Final Batch Loss: 0.05565957352519035\n",
      "Epoch 2250, Loss: 0.13888133689761162, Final Batch Loss: 0.052478816360235214\n",
      "Epoch 2251, Loss: 0.12631391733884811, Final Batch Loss: 0.07395286113023758\n",
      "Epoch 2252, Loss: 0.22630515322089195, Final Batch Loss: 0.17253820598125458\n",
      "Epoch 2253, Loss: 0.15537209063768387, Final Batch Loss: 0.08519458025693893\n",
      "Epoch 2254, Loss: 0.17791178077459335, Final Batch Loss: 0.07192211598157883\n",
      "Epoch 2255, Loss: 0.1717013567686081, Final Batch Loss: 0.0957915186882019\n",
      "Epoch 2256, Loss: 0.15409382432699203, Final Batch Loss: 0.06722751259803772\n",
      "Epoch 2257, Loss: 0.15513744950294495, Final Batch Loss: 0.07532880455255508\n",
      "Epoch 2258, Loss: 0.15666215866804123, Final Batch Loss: 0.0767042487859726\n",
      "Epoch 2259, Loss: 0.139374528080225, Final Batch Loss: 0.04959696903824806\n",
      "Epoch 2260, Loss: 0.17133047431707382, Final Batch Loss: 0.07239377498626709\n",
      "Epoch 2261, Loss: 0.22753715887665749, Final Batch Loss: 0.05356417968869209\n",
      "Epoch 2262, Loss: 0.20359673351049423, Final Batch Loss: 0.09260832518339157\n",
      "Epoch 2263, Loss: 0.13848504424095154, Final Batch Loss: 0.06748873740434647\n",
      "Epoch 2264, Loss: 0.11994977295398712, Final Batch Loss: 0.0683722123503685\n",
      "Epoch 2265, Loss: 0.16539617627859116, Final Batch Loss: 0.07923248410224915\n",
      "Epoch 2266, Loss: 0.17588091641664505, Final Batch Loss: 0.08026552200317383\n",
      "Epoch 2267, Loss: 0.14420463889837265, Final Batch Loss: 0.07112102210521698\n",
      "Epoch 2268, Loss: 0.17537305504083633, Final Batch Loss: 0.075503870844841\n",
      "Epoch 2269, Loss: 0.13132041692733765, Final Batch Loss: 0.05024676024913788\n",
      "Epoch 2270, Loss: 0.17273392900824547, Final Batch Loss: 0.057930607348680496\n",
      "Epoch 2271, Loss: 0.17743007093667984, Final Batch Loss: 0.09368068724870682\n",
      "Epoch 2272, Loss: 0.1309422068297863, Final Batch Loss: 0.05226542428135872\n",
      "Epoch 2273, Loss: 0.1727731078863144, Final Batch Loss: 0.0778145045042038\n",
      "Epoch 2274, Loss: 0.16809526458382607, Final Batch Loss: 0.11421063542366028\n",
      "Epoch 2275, Loss: 0.12054449319839478, Final Batch Loss: 0.0695563554763794\n",
      "Epoch 2276, Loss: 0.13374530524015427, Final Batch Loss: 0.06279011815786362\n",
      "Epoch 2277, Loss: 0.12087573856115341, Final Batch Loss: 0.06228885054588318\n",
      "Epoch 2278, Loss: 0.2055707946419716, Final Batch Loss: 0.11880269646644592\n",
      "Epoch 2279, Loss: 0.1383017599582672, Final Batch Loss: 0.07393442839384079\n",
      "Epoch 2280, Loss: 0.13953763619065285, Final Batch Loss: 0.035587433725595474\n",
      "Epoch 2281, Loss: 0.14211302250623703, Final Batch Loss: 0.05603227764368057\n",
      "Epoch 2282, Loss: 0.16293714195489883, Final Batch Loss: 0.09285615384578705\n",
      "Epoch 2283, Loss: 0.17687568068504333, Final Batch Loss: 0.07888805866241455\n",
      "Epoch 2284, Loss: 0.17659340798854828, Final Batch Loss: 0.09429357200860977\n",
      "Epoch 2285, Loss: 0.126337680965662, Final Batch Loss: 0.05682781711220741\n",
      "Epoch 2286, Loss: 0.15638507902622223, Final Batch Loss: 0.07818004488945007\n",
      "Epoch 2287, Loss: 0.1481906920671463, Final Batch Loss: 0.0730370357632637\n",
      "Epoch 2288, Loss: 0.1810387745499611, Final Batch Loss: 0.09917322546243668\n",
      "Epoch 2289, Loss: 0.1549806073307991, Final Batch Loss: 0.0910366103053093\n",
      "Epoch 2290, Loss: 0.15559911727905273, Final Batch Loss: 0.06363213062286377\n",
      "Epoch 2291, Loss: 0.11254052072763443, Final Batch Loss: 0.05266175419092178\n",
      "Epoch 2292, Loss: 0.1408042311668396, Final Batch Loss: 0.04903842508792877\n",
      "Epoch 2293, Loss: 0.1399165615439415, Final Batch Loss: 0.07236407697200775\n",
      "Epoch 2294, Loss: 0.1471308320760727, Final Batch Loss: 0.06935323029756546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2295, Loss: 0.15758221596479416, Final Batch Loss: 0.04484297335147858\n",
      "Epoch 2296, Loss: 0.14871494099497795, Final Batch Loss: 0.04922551289200783\n",
      "Epoch 2297, Loss: 0.12188620865345001, Final Batch Loss: 0.043360479176044464\n",
      "Epoch 2298, Loss: 0.12153645604848862, Final Batch Loss: 0.04454212635755539\n",
      "Epoch 2299, Loss: 0.1351192705333233, Final Batch Loss: 0.04732910916209221\n",
      "Epoch 2300, Loss: 0.13929881900548935, Final Batch Loss: 0.06157568842172623\n",
      "Epoch 2301, Loss: 0.15450821444392204, Final Batch Loss: 0.045635949820280075\n",
      "Epoch 2302, Loss: 0.11493914946913719, Final Batch Loss: 0.04558073356747627\n",
      "Epoch 2303, Loss: 0.13471125811338425, Final Batch Loss: 0.06597922742366791\n",
      "Epoch 2304, Loss: 0.1482347510755062, Final Batch Loss: 0.08653932809829712\n",
      "Epoch 2305, Loss: 0.1581350713968277, Final Batch Loss: 0.08965862542390823\n",
      "Epoch 2306, Loss: 0.1305774748325348, Final Batch Loss: 0.05377093702554703\n",
      "Epoch 2307, Loss: 0.23485062271356583, Final Batch Loss: 0.1720871776342392\n",
      "Epoch 2308, Loss: 0.10666462033987045, Final Batch Loss: 0.0573820136487484\n",
      "Epoch 2309, Loss: 0.1268979348242283, Final Batch Loss: 0.06986605376005173\n",
      "Epoch 2310, Loss: 0.159532368183136, Final Batch Loss: 0.06612932682037354\n",
      "Epoch 2311, Loss: 0.18685459345579147, Final Batch Loss: 0.10320424288511276\n",
      "Epoch 2312, Loss: 0.2021520920097828, Final Batch Loss: 0.14784356951713562\n",
      "Epoch 2313, Loss: 0.20605488866567612, Final Batch Loss: 0.15599144995212555\n",
      "Epoch 2314, Loss: 0.18618541210889816, Final Batch Loss: 0.0645776316523552\n",
      "Epoch 2315, Loss: 0.15248572826385498, Final Batch Loss: 0.04589711129665375\n",
      "Epoch 2316, Loss: 0.18436896800994873, Final Batch Loss: 0.0768333226442337\n",
      "Epoch 2317, Loss: 0.21381723880767822, Final Batch Loss: 0.12767785787582397\n",
      "Epoch 2318, Loss: 0.1780700981616974, Final Batch Loss: 0.09071894735097885\n",
      "Epoch 2319, Loss: 0.15782686322927475, Final Batch Loss: 0.07084151357412338\n",
      "Epoch 2320, Loss: 0.15556978434324265, Final Batch Loss: 0.03596474975347519\n",
      "Epoch 2321, Loss: 0.15799622237682343, Final Batch Loss: 0.07814022153615952\n",
      "Epoch 2322, Loss: 0.1663096845149994, Final Batch Loss: 0.06505294144153595\n",
      "Epoch 2323, Loss: 0.22383426874876022, Final Batch Loss: 0.07401914149522781\n",
      "Epoch 2324, Loss: 0.17317507416009903, Final Batch Loss: 0.11011676490306854\n",
      "Epoch 2325, Loss: 0.14251158386468887, Final Batch Loss: 0.05206961929798126\n",
      "Epoch 2326, Loss: 0.16818391531705856, Final Batch Loss: 0.07937833666801453\n",
      "Epoch 2327, Loss: 0.16689611598849297, Final Batch Loss: 0.11285664141178131\n",
      "Epoch 2328, Loss: 0.157430998980999, Final Batch Loss: 0.08154766261577606\n",
      "Epoch 2329, Loss: 0.15503840148448944, Final Batch Loss: 0.08062741160392761\n",
      "Epoch 2330, Loss: 0.12188377231359482, Final Batch Loss: 0.06945410370826721\n",
      "Epoch 2331, Loss: 0.13115380331873894, Final Batch Loss: 0.06182854250073433\n",
      "Epoch 2332, Loss: 0.2119992971420288, Final Batch Loss: 0.12696473300457\n",
      "Epoch 2333, Loss: 0.15347414836287498, Final Batch Loss: 0.09607503563165665\n",
      "Epoch 2334, Loss: 0.1372155100107193, Final Batch Loss: 0.04579123109579086\n",
      "Epoch 2335, Loss: 0.1548743024468422, Final Batch Loss: 0.06978458911180496\n",
      "Epoch 2336, Loss: 0.10689227655529976, Final Batch Loss: 0.026147428900003433\n",
      "Epoch 2337, Loss: 0.13887599855661392, Final Batch Loss: 0.07094620168209076\n",
      "Epoch 2338, Loss: 0.1658179685473442, Final Batch Loss: 0.08985521644353867\n",
      "Epoch 2339, Loss: 0.14011600241065025, Final Batch Loss: 0.04457208886742592\n",
      "Epoch 2340, Loss: 0.15415606647729874, Final Batch Loss: 0.07309253513813019\n",
      "Epoch 2341, Loss: 0.14146509766578674, Final Batch Loss: 0.0826178565621376\n",
      "Epoch 2342, Loss: 0.10642784833908081, Final Batch Loss: 0.05600295960903168\n",
      "Epoch 2343, Loss: 0.13292155414819717, Final Batch Loss: 0.0831989273428917\n",
      "Epoch 2344, Loss: 0.15478811413049698, Final Batch Loss: 0.09080397337675095\n",
      "Epoch 2345, Loss: 0.21545454859733582, Final Batch Loss: 0.15452972054481506\n",
      "Epoch 2346, Loss: 0.14050191268324852, Final Batch Loss: 0.08537706732749939\n",
      "Epoch 2347, Loss: 0.15176546946167946, Final Batch Loss: 0.05479568615555763\n",
      "Epoch 2348, Loss: 0.17560222744941711, Final Batch Loss: 0.11196031421422958\n",
      "Epoch 2349, Loss: 0.13519800081849098, Final Batch Loss: 0.039679188281297684\n",
      "Epoch 2350, Loss: 0.12194803729653358, Final Batch Loss: 0.02945214882493019\n",
      "Epoch 2351, Loss: 0.18081095069646835, Final Batch Loss: 0.1117074117064476\n",
      "Epoch 2352, Loss: 0.13462697714567184, Final Batch Loss: 0.06450871378183365\n",
      "Epoch 2353, Loss: 0.1492278389632702, Final Batch Loss: 0.04642433300614357\n",
      "Epoch 2354, Loss: 0.16714699566364288, Final Batch Loss: 0.06758960336446762\n",
      "Epoch 2355, Loss: 0.13652773946523666, Final Batch Loss: 0.07537862658500671\n",
      "Epoch 2356, Loss: 0.16002053022384644, Final Batch Loss: 0.10397514700889587\n",
      "Epoch 2357, Loss: 0.16055355966091156, Final Batch Loss: 0.0865337923169136\n",
      "Epoch 2358, Loss: 0.13087891414761543, Final Batch Loss: 0.06091766431927681\n",
      "Epoch 2359, Loss: 0.1501573920249939, Final Batch Loss: 0.08026095479726791\n",
      "Epoch 2360, Loss: 0.13532225042581558, Final Batch Loss: 0.07578583061695099\n",
      "Epoch 2361, Loss: 0.1422506645321846, Final Batch Loss: 0.052189722657203674\n",
      "Epoch 2362, Loss: 0.1001640148460865, Final Batch Loss: 0.04123730957508087\n",
      "Epoch 2363, Loss: 0.1420452781021595, Final Batch Loss: 0.08177581429481506\n",
      "Epoch 2364, Loss: 0.13858506828546524, Final Batch Loss: 0.07059350609779358\n",
      "Epoch 2365, Loss: 0.11472082883119583, Final Batch Loss: 0.06075851246714592\n",
      "Epoch 2366, Loss: 0.11311731487512589, Final Batch Loss: 0.057838667184114456\n",
      "Epoch 2367, Loss: 0.1919098198413849, Final Batch Loss: 0.0994638055562973\n",
      "Epoch 2368, Loss: 0.20182599127292633, Final Batch Loss: 0.06426367163658142\n",
      "Epoch 2369, Loss: 0.22596640139818192, Final Batch Loss: 0.09971121698617935\n",
      "Epoch 2370, Loss: 0.17673961073160172, Final Batch Loss: 0.09964477270841599\n",
      "Epoch 2371, Loss: 0.1185835525393486, Final Batch Loss: 0.0729384645819664\n",
      "Epoch 2372, Loss: 0.22379408031702042, Final Batch Loss: 0.15448684990406036\n",
      "Epoch 2373, Loss: 0.15068022906780243, Final Batch Loss: 0.08529821038246155\n",
      "Epoch 2374, Loss: 0.16765516251325607, Final Batch Loss: 0.06810887902975082\n",
      "Epoch 2375, Loss: 0.15717482939362526, Final Batch Loss: 0.1054690033197403\n",
      "Epoch 2376, Loss: 0.16949380189180374, Final Batch Loss: 0.08508994430303574\n",
      "Epoch 2377, Loss: 0.1367127187550068, Final Batch Loss: 0.046942416578531265\n",
      "Epoch 2378, Loss: 0.15691129118204117, Final Batch Loss: 0.0869620069861412\n",
      "Epoch 2379, Loss: 0.13235193490982056, Final Batch Loss: 0.06238103657960892\n",
      "Epoch 2380, Loss: 0.1518789827823639, Final Batch Loss: 0.08810203522443771\n",
      "Epoch 2381, Loss: 0.16449426114559174, Final Batch Loss: 0.09011713415384293\n",
      "Epoch 2382, Loss: 0.11140085384249687, Final Batch Loss: 0.050707075744867325\n",
      "Epoch 2383, Loss: 0.15419026464223862, Final Batch Loss: 0.07775820791721344\n",
      "Epoch 2384, Loss: 0.1668640598654747, Final Batch Loss: 0.10077723860740662\n",
      "Epoch 2385, Loss: 0.15314555913209915, Final Batch Loss: 0.06274808198213577\n",
      "Epoch 2386, Loss: 0.126031082123518, Final Batch Loss: 0.07145970314741135\n",
      "Epoch 2387, Loss: 0.14108551293611526, Final Batch Loss: 0.04561448097229004\n",
      "Epoch 2388, Loss: 0.1258901208639145, Final Batch Loss: 0.06510526686906815\n",
      "Epoch 2389, Loss: 0.13112174719572067, Final Batch Loss: 0.05089277774095535\n",
      "Epoch 2390, Loss: 0.16174591332674026, Final Batch Loss: 0.08208462595939636\n",
      "Epoch 2391, Loss: 0.11107929050922394, Final Batch Loss: 0.0506998673081398\n",
      "Epoch 2392, Loss: 0.17381557077169418, Final Batch Loss: 0.06525689363479614\n",
      "Epoch 2393, Loss: 0.14400949329137802, Final Batch Loss: 0.057419635355472565\n",
      "Epoch 2394, Loss: 0.1302170716226101, Final Batch Loss: 0.05380093678832054\n",
      "Epoch 2395, Loss: 0.15576057508587837, Final Batch Loss: 0.0933101549744606\n",
      "Epoch 2396, Loss: 0.11925104632973671, Final Batch Loss: 0.05925458297133446\n",
      "Epoch 2397, Loss: 0.1678183674812317, Final Batch Loss: 0.084421806037426\n",
      "Epoch 2398, Loss: 0.2163291648030281, Final Batch Loss: 0.10106636583805084\n",
      "Epoch 2399, Loss: 0.13627582788467407, Final Batch Loss: 0.06010699272155762\n",
      "Epoch 2400, Loss: 0.12401943653821945, Final Batch Loss: 0.056279346346855164\n",
      "Epoch 2401, Loss: 0.11416095867753029, Final Batch Loss: 0.04882821813225746\n",
      "Epoch 2402, Loss: 0.15922385454177856, Final Batch Loss: 0.07982044667005539\n",
      "Epoch 2403, Loss: 0.1170828677713871, Final Batch Loss: 0.0383840911090374\n",
      "Epoch 2404, Loss: 0.19071386754512787, Final Batch Loss: 0.08247620612382889\n",
      "Epoch 2405, Loss: 0.2958074063062668, Final Batch Loss: 0.0673539936542511\n",
      "Epoch 2406, Loss: 0.15521080791950226, Final Batch Loss: 0.07594146579504013\n",
      "Epoch 2407, Loss: 0.1480540707707405, Final Batch Loss: 0.07329583168029785\n",
      "Epoch 2408, Loss: 0.13408580422401428, Final Batch Loss: 0.08209453523159027\n",
      "Epoch 2409, Loss: 0.141940139234066, Final Batch Loss: 0.07028894871473312\n",
      "Epoch 2410, Loss: 0.11317666247487068, Final Batch Loss: 0.05919594690203667\n",
      "Epoch 2411, Loss: 0.1157119907438755, Final Batch Loss: 0.05890798196196556\n",
      "Epoch 2412, Loss: 0.16945557296276093, Final Batch Loss: 0.09229693561792374\n",
      "Epoch 2413, Loss: 0.12970251217484474, Final Batch Loss: 0.05930236354470253\n",
      "Epoch 2414, Loss: 0.11353040114045143, Final Batch Loss: 0.06393839418888092\n",
      "Epoch 2415, Loss: 0.20377164334058762, Final Batch Loss: 0.08763110637664795\n",
      "Epoch 2416, Loss: 0.1910397633910179, Final Batch Loss: 0.09736204147338867\n",
      "Epoch 2417, Loss: 0.15057191252708435, Final Batch Loss: 0.06863897293806076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2418, Loss: 0.14744700863957405, Final Batch Loss: 0.0449049212038517\n",
      "Epoch 2419, Loss: 0.13697129487991333, Final Batch Loss: 0.05868609994649887\n",
      "Epoch 2420, Loss: 0.12642718851566315, Final Batch Loss: 0.06854301691055298\n",
      "Epoch 2421, Loss: 0.15722481906414032, Final Batch Loss: 0.07550326734781265\n",
      "Epoch 2422, Loss: 0.2294432893395424, Final Batch Loss: 0.12754523754119873\n",
      "Epoch 2423, Loss: 0.12423508241772652, Final Batch Loss: 0.07887974381446838\n",
      "Epoch 2424, Loss: 0.12120318785309792, Final Batch Loss: 0.05696349963545799\n",
      "Epoch 2425, Loss: 0.18832606822252274, Final Batch Loss: 0.1060144305229187\n",
      "Epoch 2426, Loss: 0.14792121946811676, Final Batch Loss: 0.08540710061788559\n",
      "Epoch 2427, Loss: 0.10960618034005165, Final Batch Loss: 0.034922730177640915\n",
      "Epoch 2428, Loss: 0.12087103724479675, Final Batch Loss: 0.04571666568517685\n",
      "Epoch 2429, Loss: 0.12497459724545479, Final Batch Loss: 0.04389159008860588\n",
      "Epoch 2430, Loss: 0.18629326671361923, Final Batch Loss: 0.11179833114147186\n",
      "Epoch 2431, Loss: 0.14370916411280632, Final Batch Loss: 0.04790407791733742\n",
      "Epoch 2432, Loss: 0.10920755565166473, Final Batch Loss: 0.03309011459350586\n",
      "Epoch 2433, Loss: 0.09874861314892769, Final Batch Loss: 0.04868585988879204\n",
      "Epoch 2434, Loss: 0.12114042788743973, Final Batch Loss: 0.03735462576150894\n",
      "Epoch 2435, Loss: 0.16164658963680267, Final Batch Loss: 0.09903489798307419\n",
      "Epoch 2436, Loss: 0.12439922615885735, Final Batch Loss: 0.054831791669130325\n",
      "Epoch 2437, Loss: 0.15393459051847458, Final Batch Loss: 0.07559101283550262\n",
      "Epoch 2438, Loss: 0.145416721701622, Final Batch Loss: 0.06955209374427795\n",
      "Epoch 2439, Loss: 0.11980965733528137, Final Batch Loss: 0.0674246996641159\n",
      "Epoch 2440, Loss: 0.13166119903326035, Final Batch Loss: 0.06451009213924408\n",
      "Epoch 2441, Loss: 0.14472589641809464, Final Batch Loss: 0.06724128127098083\n",
      "Epoch 2442, Loss: 0.1557299606502056, Final Batch Loss: 0.03949485346674919\n",
      "Epoch 2443, Loss: 0.13915801793336868, Final Batch Loss: 0.0676305964589119\n",
      "Epoch 2444, Loss: 0.14947282522916794, Final Batch Loss: 0.06700947880744934\n",
      "Epoch 2445, Loss: 0.1076788529753685, Final Batch Loss: 0.03983704745769501\n",
      "Epoch 2446, Loss: 0.16774964332580566, Final Batch Loss: 0.08103868365287781\n",
      "Epoch 2447, Loss: 0.12543492019176483, Final Batch Loss: 0.06475581973791122\n",
      "Epoch 2448, Loss: 0.13862785696983337, Final Batch Loss: 0.04617580771446228\n",
      "Epoch 2449, Loss: 0.1270701065659523, Final Batch Loss: 0.07232304662466049\n",
      "Epoch 2450, Loss: 0.1288430616259575, Final Batch Loss: 0.07992401719093323\n",
      "Epoch 2451, Loss: 0.1655009612441063, Final Batch Loss: 0.10944051295518875\n",
      "Epoch 2452, Loss: 0.10313775762915611, Final Batch Loss: 0.043317873030900955\n",
      "Epoch 2453, Loss: 0.1193045936524868, Final Batch Loss: 0.06184276193380356\n",
      "Epoch 2454, Loss: 0.13414806872606277, Final Batch Loss: 0.09183740615844727\n",
      "Epoch 2455, Loss: 0.13347694650292397, Final Batch Loss: 0.05355830863118172\n",
      "Epoch 2456, Loss: 0.16424352675676346, Final Batch Loss: 0.10270143300294876\n",
      "Epoch 2457, Loss: 0.12574703246355057, Final Batch Loss: 0.05176068842411041\n",
      "Epoch 2458, Loss: 0.11356574296951294, Final Batch Loss: 0.046265363693237305\n",
      "Epoch 2459, Loss: 0.13210221752524376, Final Batch Loss: 0.05121852084994316\n",
      "Epoch 2460, Loss: 0.1329568587243557, Final Batch Loss: 0.060373540967702866\n",
      "Epoch 2461, Loss: 0.12194666266441345, Final Batch Loss: 0.0727924332022667\n",
      "Epoch 2462, Loss: 0.17100416123867035, Final Batch Loss: 0.09356597065925598\n",
      "Epoch 2463, Loss: 0.13950862362980843, Final Batch Loss: 0.09369876235723495\n",
      "Epoch 2464, Loss: 0.15073875337839127, Final Batch Loss: 0.08456669002771378\n",
      "Epoch 2465, Loss: 0.13220173493027687, Final Batch Loss: 0.08191929012537003\n",
      "Epoch 2466, Loss: 0.2054077610373497, Final Batch Loss: 0.10395589470863342\n",
      "Epoch 2467, Loss: 0.08704353123903275, Final Batch Loss: 0.03992323577404022\n",
      "Epoch 2468, Loss: 0.13393529877066612, Final Batch Loss: 0.08445870876312256\n",
      "Epoch 2469, Loss: 0.14027618989348412, Final Batch Loss: 0.04090004041790962\n",
      "Epoch 2470, Loss: 0.1105281338095665, Final Batch Loss: 0.02909409999847412\n",
      "Epoch 2471, Loss: 0.1252579279243946, Final Batch Loss: 0.04707367345690727\n",
      "Epoch 2472, Loss: 0.13966117799282074, Final Batch Loss: 0.07789663225412369\n",
      "Epoch 2473, Loss: 0.12960607185959816, Final Batch Loss: 0.06937630474567413\n",
      "Epoch 2474, Loss: 0.1565457507967949, Final Batch Loss: 0.07018031924962997\n",
      "Epoch 2475, Loss: 0.13053260743618011, Final Batch Loss: 0.059709638357162476\n",
      "Epoch 2476, Loss: 0.14664576202630997, Final Batch Loss: 0.05735719949007034\n",
      "Epoch 2477, Loss: 0.13447004556655884, Final Batch Loss: 0.06412418186664581\n",
      "Epoch 2478, Loss: 0.14416175708174706, Final Batch Loss: 0.0850290060043335\n",
      "Epoch 2479, Loss: 0.17473620176315308, Final Batch Loss: 0.08576451241970062\n",
      "Epoch 2480, Loss: 0.1259588822722435, Final Batch Loss: 0.057220205664634705\n",
      "Epoch 2481, Loss: 0.11426638811826706, Final Batch Loss: 0.051753342151641846\n",
      "Epoch 2482, Loss: 0.09044266864657402, Final Batch Loss: 0.041909780353307724\n",
      "Epoch 2483, Loss: 0.11996893584728241, Final Batch Loss: 0.0704907700419426\n",
      "Epoch 2484, Loss: 0.14120838791131973, Final Batch Loss: 0.0681704729795456\n",
      "Epoch 2485, Loss: 0.1357390433549881, Final Batch Loss: 0.05441088229417801\n",
      "Epoch 2486, Loss: 0.15685318410396576, Final Batch Loss: 0.08009965717792511\n",
      "Epoch 2487, Loss: 0.17463482916355133, Final Batch Loss: 0.11882267147302628\n",
      "Epoch 2488, Loss: 0.1317693591117859, Final Batch Loss: 0.06608652323484421\n",
      "Epoch 2489, Loss: 0.158663310110569, Final Batch Loss: 0.051688067615032196\n",
      "Epoch 2490, Loss: 0.15430419892072678, Final Batch Loss: 0.07938992232084274\n",
      "Epoch 2491, Loss: 0.13400759547948837, Final Batch Loss: 0.07579702883958817\n",
      "Epoch 2492, Loss: 0.1055990606546402, Final Batch Loss: 0.046317555010318756\n",
      "Epoch 2493, Loss: 0.10692691430449486, Final Batch Loss: 0.05093132331967354\n",
      "Epoch 2494, Loss: 0.10534565895795822, Final Batch Loss: 0.04522033780813217\n",
      "Epoch 2495, Loss: 0.16600550338625908, Final Batch Loss: 0.04876779392361641\n",
      "Epoch 2496, Loss: 0.1265297345817089, Final Batch Loss: 0.07373278588056564\n",
      "Epoch 2497, Loss: 0.14174328744411469, Final Batch Loss: 0.08036777377128601\n",
      "Epoch 2498, Loss: 0.1482713297009468, Final Batch Loss: 0.0934724509716034\n",
      "Epoch 2499, Loss: 0.10557674244046211, Final Batch Loss: 0.04373340681195259\n",
      "Epoch 2500, Loss: 0.1361323557794094, Final Batch Loss: 0.09447354823350906\n",
      "Epoch 2501, Loss: 0.13740361481904984, Final Batch Loss: 0.057914331555366516\n",
      "Epoch 2502, Loss: 0.16491316258907318, Final Batch Loss: 0.07494238764047623\n",
      "Epoch 2503, Loss: 0.17039617896080017, Final Batch Loss: 0.09624908119440079\n",
      "Epoch 2504, Loss: 0.11922729015350342, Final Batch Loss: 0.04746223986148834\n",
      "Epoch 2505, Loss: 0.14582405239343643, Final Batch Loss: 0.07570125162601471\n",
      "Epoch 2506, Loss: 0.11214738339185715, Final Batch Loss: 0.03344392776489258\n",
      "Epoch 2507, Loss: 0.15288615226745605, Final Batch Loss: 0.06887336820363998\n",
      "Epoch 2508, Loss: 0.1113833412528038, Final Batch Loss: 0.04253588616847992\n",
      "Epoch 2509, Loss: 0.10284865275025368, Final Batch Loss: 0.03787895664572716\n",
      "Epoch 2510, Loss: 0.1292462758719921, Final Batch Loss: 0.06000683084130287\n",
      "Epoch 2511, Loss: 0.1183556541800499, Final Batch Loss: 0.03501942753791809\n",
      "Epoch 2512, Loss: 0.12354212254285812, Final Batch Loss: 0.07989181578159332\n",
      "Epoch 2513, Loss: 0.14457833021879196, Final Batch Loss: 0.07514633238315582\n",
      "Epoch 2514, Loss: 0.1709020584821701, Final Batch Loss: 0.1001223772764206\n",
      "Epoch 2515, Loss: 0.1353900358080864, Final Batch Loss: 0.08428420126438141\n",
      "Epoch 2516, Loss: 0.1175072230398655, Final Batch Loss: 0.055049870163202286\n",
      "Epoch 2517, Loss: 0.1092536561191082, Final Batch Loss: 0.05552704632282257\n",
      "Epoch 2518, Loss: 0.15596923977136612, Final Batch Loss: 0.06010492146015167\n",
      "Epoch 2519, Loss: 0.12102264910936356, Final Batch Loss: 0.07343856245279312\n",
      "Epoch 2520, Loss: 0.07763742096722126, Final Batch Loss: 0.028538839891552925\n",
      "Epoch 2521, Loss: 0.13171124085783958, Final Batch Loss: 0.05274384841322899\n",
      "Epoch 2522, Loss: 0.16222863271832466, Final Batch Loss: 0.100945845246315\n",
      "Epoch 2523, Loss: 0.10323363542556763, Final Batch Loss: 0.047416213899850845\n",
      "Epoch 2524, Loss: 0.11179475486278534, Final Batch Loss: 0.041278086602687836\n",
      "Epoch 2525, Loss: 0.11590860038995743, Final Batch Loss: 0.057581208646297455\n",
      "Epoch 2526, Loss: 0.18029635399580002, Final Batch Loss: 0.1088588610291481\n",
      "Epoch 2527, Loss: 0.12097105383872986, Final Batch Loss: 0.042421162128448486\n",
      "Epoch 2528, Loss: 0.1096908263862133, Final Batch Loss: 0.05032758414745331\n",
      "Epoch 2529, Loss: 0.11497411131858826, Final Batch Loss: 0.03823356330394745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2530, Loss: 0.12056959792971611, Final Batch Loss: 0.051524389535188675\n",
      "Epoch 2531, Loss: 0.10754327103495598, Final Batch Loss: 0.040983837097883224\n",
      "Epoch 2532, Loss: 0.09996059536933899, Final Batch Loss: 0.04692531004548073\n",
      "Epoch 2533, Loss: 0.11523213982582092, Final Batch Loss: 0.0526590496301651\n",
      "Epoch 2534, Loss: 0.10411613807082176, Final Batch Loss: 0.048032864928245544\n",
      "Epoch 2535, Loss: 0.10405214875936508, Final Batch Loss: 0.047961216419935226\n",
      "Epoch 2536, Loss: 0.14958453923463821, Final Batch Loss: 0.07520079612731934\n",
      "Epoch 2537, Loss: 0.13376132026314735, Final Batch Loss: 0.050610657781362534\n",
      "Epoch 2538, Loss: 0.13613074272871017, Final Batch Loss: 0.05670385807752609\n",
      "Epoch 2539, Loss: 0.1381402462720871, Final Batch Loss: 0.07302454113960266\n",
      "Epoch 2540, Loss: 0.14866472035646439, Final Batch Loss: 0.038937270641326904\n",
      "Epoch 2541, Loss: 0.0983472689986229, Final Batch Loss: 0.0583207905292511\n",
      "Epoch 2542, Loss: 0.14747489988803864, Final Batch Loss: 0.07558180391788483\n",
      "Epoch 2543, Loss: 0.1319759078323841, Final Batch Loss: 0.07420773059129715\n",
      "Epoch 2544, Loss: 0.0993478000164032, Final Batch Loss: 0.044600699096918106\n",
      "Epoch 2545, Loss: 0.15980176627635956, Final Batch Loss: 0.09535912424325943\n",
      "Epoch 2546, Loss: 0.1176685281097889, Final Batch Loss: 0.06266847252845764\n",
      "Epoch 2547, Loss: 0.1447751224040985, Final Batch Loss: 0.08099299669265747\n",
      "Epoch 2548, Loss: 0.10733543708920479, Final Batch Loss: 0.03929327800869942\n",
      "Epoch 2549, Loss: 0.11008321866393089, Final Batch Loss: 0.07621920853853226\n",
      "Epoch 2550, Loss: 0.14322569221258163, Final Batch Loss: 0.07877513021230698\n",
      "Epoch 2551, Loss: 0.10967405512928963, Final Batch Loss: 0.04330692067742348\n",
      "Epoch 2552, Loss: 0.1348489262163639, Final Batch Loss: 0.08916431665420532\n",
      "Epoch 2553, Loss: 0.11227409914135933, Final Batch Loss: 0.05489297956228256\n",
      "Epoch 2554, Loss: 0.11103632673621178, Final Batch Loss: 0.06570860743522644\n",
      "Epoch 2555, Loss: 0.15207358449697495, Final Batch Loss: 0.09665282815694809\n",
      "Epoch 2556, Loss: 0.17203914374113083, Final Batch Loss: 0.08334280550479889\n",
      "Epoch 2557, Loss: 0.10260865464806557, Final Batch Loss: 0.039211031049489975\n",
      "Epoch 2558, Loss: 0.1576024293899536, Final Batch Loss: 0.0809762179851532\n",
      "Epoch 2559, Loss: 0.08915340527892113, Final Batch Loss: 0.041063372045755386\n",
      "Epoch 2560, Loss: 0.11140869557857513, Final Batch Loss: 0.04690283536911011\n",
      "Epoch 2561, Loss: 0.1814766302704811, Final Batch Loss: 0.10956539958715439\n",
      "Epoch 2562, Loss: 0.10914379917085171, Final Batch Loss: 0.028700118884444237\n",
      "Epoch 2563, Loss: 0.10404593497514725, Final Batch Loss: 0.041254617273807526\n",
      "Epoch 2564, Loss: 0.12301528826355934, Final Batch Loss: 0.07362277805805206\n",
      "Epoch 2565, Loss: 0.10817591100931168, Final Batch Loss: 0.06252692639827728\n",
      "Epoch 2566, Loss: 0.12963882833719254, Final Batch Loss: 0.06550315022468567\n",
      "Epoch 2567, Loss: 0.15690389275550842, Final Batch Loss: 0.10051676630973816\n",
      "Epoch 2568, Loss: 0.10058939084410667, Final Batch Loss: 0.046466607600450516\n",
      "Epoch 2569, Loss: 0.15561622753739357, Final Batch Loss: 0.03692873194813728\n",
      "Epoch 2570, Loss: 0.1485232412815094, Final Batch Loss: 0.07335710525512695\n",
      "Epoch 2571, Loss: 0.10538547486066818, Final Batch Loss: 0.059290774166584015\n",
      "Epoch 2572, Loss: 0.09672843478620052, Final Batch Loss: 0.018709635362029076\n",
      "Epoch 2573, Loss: 0.12700504809617996, Final Batch Loss: 0.039846912026405334\n",
      "Epoch 2574, Loss: 0.10715904086828232, Final Batch Loss: 0.05941194295883179\n",
      "Epoch 2575, Loss: 0.09613309800624847, Final Batch Loss: 0.03838808834552765\n",
      "Epoch 2576, Loss: 0.12412118539214134, Final Batch Loss: 0.07304976135492325\n",
      "Epoch 2577, Loss: 0.10844317451119423, Final Batch Loss: 0.04842384159564972\n",
      "Epoch 2578, Loss: 0.18366287648677826, Final Batch Loss: 0.07064791023731232\n",
      "Epoch 2579, Loss: 0.10651161894202232, Final Batch Loss: 0.051817215979099274\n",
      "Epoch 2580, Loss: 0.16293836012482643, Final Batch Loss: 0.05664294585585594\n",
      "Epoch 2581, Loss: 0.16270947456359863, Final Batch Loss: 0.06278613209724426\n",
      "Epoch 2582, Loss: 0.1646374762058258, Final Batch Loss: 0.0782080888748169\n",
      "Epoch 2583, Loss: 0.0842893011868, Final Batch Loss: 0.04193984717130661\n",
      "Epoch 2584, Loss: 0.14240269362926483, Final Batch Loss: 0.07781660556793213\n",
      "Epoch 2585, Loss: 0.13481487333774567, Final Batch Loss: 0.057005830109119415\n",
      "Epoch 2586, Loss: 0.13876523450016975, Final Batch Loss: 0.05391566827893257\n",
      "Epoch 2587, Loss: 0.11184069514274597, Final Batch Loss: 0.0397760346531868\n",
      "Epoch 2588, Loss: 0.12757639586925507, Final Batch Loss: 0.0878998339176178\n",
      "Epoch 2589, Loss: 0.18930597603321075, Final Batch Loss: 0.11574792861938477\n",
      "Epoch 2590, Loss: 0.0978640541434288, Final Batch Loss: 0.037523917853832245\n",
      "Epoch 2591, Loss: 0.11680750176310539, Final Batch Loss: 0.040993448346853256\n",
      "Epoch 2592, Loss: 0.10214253515005112, Final Batch Loss: 0.03228428214788437\n",
      "Epoch 2593, Loss: 0.12543043866753578, Final Batch Loss: 0.0664655938744545\n",
      "Epoch 2594, Loss: 0.12003787606954575, Final Batch Loss: 0.06945998966693878\n",
      "Epoch 2595, Loss: 0.12062275782227516, Final Batch Loss: 0.03900643810629845\n",
      "Epoch 2596, Loss: 0.1210438571870327, Final Batch Loss: 0.039087411016225815\n",
      "Epoch 2597, Loss: 0.09371321648359299, Final Batch Loss: 0.036314960569143295\n",
      "Epoch 2598, Loss: 0.0985957719385624, Final Batch Loss: 0.0409180149435997\n",
      "Epoch 2599, Loss: 0.13921989127993584, Final Batch Loss: 0.07950527966022491\n",
      "Epoch 2600, Loss: 0.13648123666644096, Final Batch Loss: 0.055970627814531326\n",
      "Epoch 2601, Loss: 0.1510520912706852, Final Batch Loss: 0.09376584738492966\n",
      "Epoch 2602, Loss: 0.19663888961076736, Final Batch Loss: 0.06210612505674362\n",
      "Epoch 2603, Loss: 0.20292048901319504, Final Batch Loss: 0.1309654414653778\n",
      "Epoch 2604, Loss: 0.13536038622260094, Final Batch Loss: 0.0778517797589302\n",
      "Epoch 2605, Loss: 0.21288233995437622, Final Batch Loss: 0.17516781389713287\n",
      "Epoch 2606, Loss: 0.09890035167336464, Final Batch Loss: 0.041084930300712585\n",
      "Epoch 2607, Loss: 0.10764840990304947, Final Batch Loss: 0.06227516755461693\n",
      "Epoch 2608, Loss: 0.14190370962023735, Final Batch Loss: 0.04541865363717079\n",
      "Epoch 2609, Loss: 0.11952510476112366, Final Batch Loss: 0.038471393287181854\n",
      "Epoch 2610, Loss: 0.13328256830573082, Final Batch Loss: 0.05666957423090935\n",
      "Epoch 2611, Loss: 0.12100135535001755, Final Batch Loss: 0.06485143303871155\n",
      "Epoch 2612, Loss: 0.14123927801847458, Final Batch Loss: 0.07364815473556519\n",
      "Epoch 2613, Loss: 0.13388778269290924, Final Batch Loss: 0.05027696490287781\n",
      "Epoch 2614, Loss: 0.11392192170023918, Final Batch Loss: 0.04118715599179268\n",
      "Epoch 2615, Loss: 0.10965748131275177, Final Batch Loss: 0.042771339416503906\n",
      "Epoch 2616, Loss: 0.19417783617973328, Final Batch Loss: 0.0973941758275032\n",
      "Epoch 2617, Loss: 0.1225476786494255, Final Batch Loss: 0.05894279479980469\n",
      "Epoch 2618, Loss: 0.11864328756928444, Final Batch Loss: 0.08268767595291138\n",
      "Epoch 2619, Loss: 0.09113037586212158, Final Batch Loss: 0.038564302027225494\n",
      "Epoch 2620, Loss: 0.09008079394698143, Final Batch Loss: 0.043264854699373245\n",
      "Epoch 2621, Loss: 0.1501752957701683, Final Batch Loss: 0.08091508597135544\n",
      "Epoch 2622, Loss: 0.1748793125152588, Final Batch Loss: 0.13565854728221893\n",
      "Epoch 2623, Loss: 0.1397639960050583, Final Batch Loss: 0.058623217046260834\n",
      "Epoch 2624, Loss: 0.13649901002645493, Final Batch Loss: 0.0709289163351059\n",
      "Epoch 2625, Loss: 0.11578071862459183, Final Batch Loss: 0.034904904663562775\n",
      "Epoch 2626, Loss: 0.14179866388440132, Final Batch Loss: 0.10088145732879639\n",
      "Epoch 2627, Loss: 0.13871051371097565, Final Batch Loss: 0.06510188430547714\n",
      "Epoch 2628, Loss: 0.1780344657599926, Final Batch Loss: 0.12123319506645203\n",
      "Epoch 2629, Loss: 0.1341894082725048, Final Batch Loss: 0.06206885352730751\n",
      "Epoch 2630, Loss: 0.12433026731014252, Final Batch Loss: 0.06295100599527359\n",
      "Epoch 2631, Loss: 0.1570415422320366, Final Batch Loss: 0.09453675895929337\n",
      "Epoch 2632, Loss: 0.11824212595820427, Final Batch Loss: 0.0478668175637722\n",
      "Epoch 2633, Loss: 0.14287470281124115, Final Batch Loss: 0.05412817746400833\n",
      "Epoch 2634, Loss: 0.16044186800718307, Final Batch Loss: 0.08458983898162842\n",
      "Epoch 2635, Loss: 0.15059225633740425, Final Batch Loss: 0.04872559383511543\n",
      "Epoch 2636, Loss: 0.10803769156336784, Final Batch Loss: 0.06495150923728943\n",
      "Epoch 2637, Loss: 0.14840935170650482, Final Batch Loss: 0.07698431611061096\n",
      "Epoch 2638, Loss: 0.11305975914001465, Final Batch Loss: 0.04867669939994812\n",
      "Epoch 2639, Loss: 0.12893960997462273, Final Batch Loss: 0.08435182273387909\n",
      "Epoch 2640, Loss: 0.2510067746043205, Final Batch Loss: 0.10659050196409225\n",
      "Epoch 2641, Loss: 0.10706349089741707, Final Batch Loss: 0.047506410628557205\n",
      "Epoch 2642, Loss: 0.09925134852528572, Final Batch Loss: 0.023797791451215744\n",
      "Epoch 2643, Loss: 0.1305081769824028, Final Batch Loss: 0.047426626086235046\n",
      "Epoch 2644, Loss: 0.11769568547606468, Final Batch Loss: 0.06542371958494186\n",
      "Epoch 2645, Loss: 0.18588805198669434, Final Batch Loss: 0.08014290034770966\n",
      "Epoch 2646, Loss: 0.09868651255965233, Final Batch Loss: 0.04911687970161438\n",
      "Epoch 2647, Loss: 0.1074216403067112, Final Batch Loss: 0.05425059050321579\n",
      "Epoch 2648, Loss: 0.1551002413034439, Final Batch Loss: 0.06531248241662979\n",
      "Epoch 2649, Loss: 0.09382373467087746, Final Batch Loss: 0.04117333143949509\n",
      "Epoch 2650, Loss: 0.11895742267370224, Final Batch Loss: 0.07817891985177994\n",
      "Epoch 2651, Loss: 0.09898722544312477, Final Batch Loss: 0.05668089911341667\n",
      "Epoch 2652, Loss: 0.12618329748511314, Final Batch Loss: 0.05336998775601387\n",
      "Epoch 2653, Loss: 0.14638856053352356, Final Batch Loss: 0.07499239593744278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2654, Loss: 0.09558497741818428, Final Batch Loss: 0.040700070559978485\n",
      "Epoch 2655, Loss: 0.11081857606768608, Final Batch Loss: 0.03214007988572121\n",
      "Epoch 2656, Loss: 0.10575298964977264, Final Batch Loss: 0.04592588171362877\n",
      "Epoch 2657, Loss: 0.0694700125604868, Final Batch Loss: 0.02291181869804859\n",
      "Epoch 2658, Loss: 0.0974237211048603, Final Batch Loss: 0.04762730374932289\n",
      "Epoch 2659, Loss: 0.08865652978420258, Final Batch Loss: 0.04197172075510025\n",
      "Epoch 2660, Loss: 0.08056559786200523, Final Batch Loss: 0.0410882942378521\n",
      "Epoch 2661, Loss: 0.0787234827876091, Final Batch Loss: 0.04296765848994255\n",
      "Epoch 2662, Loss: 0.12272873893380165, Final Batch Loss: 0.053694356232881546\n",
      "Epoch 2663, Loss: 0.13898597657680511, Final Batch Loss: 0.03296632319688797\n",
      "Epoch 2664, Loss: 0.07674514502286911, Final Batch Loss: 0.04355435073375702\n",
      "Epoch 2665, Loss: 0.08530084416270256, Final Batch Loss: 0.036040086299180984\n",
      "Epoch 2666, Loss: 0.12109818682074547, Final Batch Loss: 0.07004250586032867\n",
      "Epoch 2667, Loss: 0.10559346526861191, Final Batch Loss: 0.04203479737043381\n",
      "Epoch 2668, Loss: 0.13448771834373474, Final Batch Loss: 0.08640758693218231\n",
      "Epoch 2669, Loss: 0.1310872808098793, Final Batch Loss: 0.0672781765460968\n",
      "Epoch 2670, Loss: 0.1663598045706749, Final Batch Loss: 0.09728715568780899\n",
      "Epoch 2671, Loss: 0.11396444588899612, Final Batch Loss: 0.03735099732875824\n",
      "Epoch 2672, Loss: 0.06998757272958755, Final Batch Loss: 0.03039402887225151\n",
      "Epoch 2673, Loss: 0.1030193381011486, Final Batch Loss: 0.04339008405804634\n",
      "Epoch 2674, Loss: 0.1278868317604065, Final Batch Loss: 0.03294720500707626\n",
      "Epoch 2675, Loss: 0.08797415718436241, Final Batch Loss: 0.05397048965096474\n",
      "Epoch 2676, Loss: 0.11581102386116982, Final Batch Loss: 0.03854319825768471\n",
      "Epoch 2677, Loss: 0.24740231782197952, Final Batch Loss: 0.21583540737628937\n",
      "Epoch 2678, Loss: 0.1979367434978485, Final Batch Loss: 0.09116846323013306\n",
      "Epoch 2679, Loss: 0.0956217423081398, Final Batch Loss: 0.05385899916291237\n",
      "Epoch 2680, Loss: 0.10919790342450142, Final Batch Loss: 0.03432566300034523\n",
      "Epoch 2681, Loss: 0.08786372095346451, Final Batch Loss: 0.042339399456977844\n",
      "Epoch 2682, Loss: 0.12081886827945709, Final Batch Loss: 0.03141818195581436\n",
      "Epoch 2683, Loss: 0.1287752278149128, Final Batch Loss: 0.04863301292061806\n",
      "Epoch 2684, Loss: 0.0803680308163166, Final Batch Loss: 0.03979000076651573\n",
      "Epoch 2685, Loss: 0.14028293266892433, Final Batch Loss: 0.05122397467494011\n",
      "Epoch 2686, Loss: 0.16757656261324883, Final Batch Loss: 0.12282681465148926\n",
      "Epoch 2687, Loss: 0.13672521337866783, Final Batch Loss: 0.057259637862443924\n",
      "Epoch 2688, Loss: 0.12405123561620712, Final Batch Loss: 0.05139555037021637\n",
      "Epoch 2689, Loss: 0.12201634049415588, Final Batch Loss: 0.06060832366347313\n",
      "Epoch 2690, Loss: 0.13263019919395447, Final Batch Loss: 0.06750787049531937\n",
      "Epoch 2691, Loss: 0.15904579311609268, Final Batch Loss: 0.12347053736448288\n",
      "Epoch 2692, Loss: 0.11669280752539635, Final Batch Loss: 0.0711650475859642\n",
      "Epoch 2693, Loss: 0.09248501621186733, Final Batch Loss: 0.031014854088425636\n",
      "Epoch 2694, Loss: 0.1429598368704319, Final Batch Loss: 0.10298171639442444\n",
      "Epoch 2695, Loss: 0.13695746660232544, Final Batch Loss: 0.07838945090770721\n",
      "Epoch 2696, Loss: 0.09137583151459694, Final Batch Loss: 0.051413677632808685\n",
      "Epoch 2697, Loss: 0.17458153516054153, Final Batch Loss: 0.0898698940873146\n",
      "Epoch 2698, Loss: 0.10598587244749069, Final Batch Loss: 0.02844255417585373\n",
      "Epoch 2699, Loss: 0.09506278112530708, Final Batch Loss: 0.0391862690448761\n",
      "Epoch 2700, Loss: 0.10739903897047043, Final Batch Loss: 0.06255629658699036\n",
      "Epoch 2701, Loss: 0.07568246871232986, Final Batch Loss: 0.03944777324795723\n",
      "Epoch 2702, Loss: 0.06486790627241135, Final Batch Loss: 0.023586835712194443\n",
      "Epoch 2703, Loss: 0.09400112181901932, Final Batch Loss: 0.05206508934497833\n",
      "Epoch 2704, Loss: 0.10771200805902481, Final Batch Loss: 0.06903329491615295\n",
      "Epoch 2705, Loss: 0.12449293583631516, Final Batch Loss: 0.07119520008563995\n",
      "Epoch 2706, Loss: 0.11382230743765831, Final Batch Loss: 0.04566885903477669\n",
      "Epoch 2707, Loss: 0.13775519281625748, Final Batch Loss: 0.05750054121017456\n",
      "Epoch 2708, Loss: 0.11168577522039413, Final Batch Loss: 0.047166503965854645\n",
      "Epoch 2709, Loss: 0.11190278083086014, Final Batch Loss: 0.052872080355882645\n",
      "Epoch 2710, Loss: 0.13501352444291115, Final Batch Loss: 0.048210833221673965\n",
      "Epoch 2711, Loss: 0.10468776151537895, Final Batch Loss: 0.06366817653179169\n",
      "Epoch 2712, Loss: 0.12459134683012962, Final Batch Loss: 0.0835849791765213\n",
      "Epoch 2713, Loss: 0.1780955083668232, Final Batch Loss: 0.1317652463912964\n",
      "Epoch 2714, Loss: 0.09884949401021004, Final Batch Loss: 0.05580926686525345\n",
      "Epoch 2715, Loss: 0.12518975511193275, Final Batch Loss: 0.05641283467411995\n",
      "Epoch 2716, Loss: 0.10910987854003906, Final Batch Loss: 0.013296335935592651\n",
      "Epoch 2717, Loss: 0.11595658212900162, Final Batch Loss: 0.039676591753959656\n",
      "Epoch 2718, Loss: 0.15045694261789322, Final Batch Loss: 0.05384649336338043\n",
      "Epoch 2719, Loss: 0.12287912145256996, Final Batch Loss: 0.05074392631649971\n",
      "Epoch 2720, Loss: 0.1259698010981083, Final Batch Loss: 0.05468422546982765\n",
      "Epoch 2721, Loss: 0.10360561683773994, Final Batch Loss: 0.051801424473524094\n",
      "Epoch 2722, Loss: 0.10040009394288063, Final Batch Loss: 0.0430450364947319\n",
      "Epoch 2723, Loss: 0.11521456390619278, Final Batch Loss: 0.05778989940881729\n",
      "Epoch 2724, Loss: 0.1366598643362522, Final Batch Loss: 0.09166382253170013\n",
      "Epoch 2725, Loss: 0.10186316445469856, Final Batch Loss: 0.05438339337706566\n",
      "Epoch 2726, Loss: 0.1515573188662529, Final Batch Loss: 0.11442280560731888\n",
      "Epoch 2727, Loss: 0.21175776422023773, Final Batch Loss: 0.13302379846572876\n",
      "Epoch 2728, Loss: 0.0933186486363411, Final Batch Loss: 0.051227569580078125\n",
      "Epoch 2729, Loss: 0.13372338935732841, Final Batch Loss: 0.047821421176195145\n",
      "Epoch 2730, Loss: 0.11487887054681778, Final Batch Loss: 0.024840444326400757\n",
      "Epoch 2731, Loss: 0.17462054640054703, Final Batch Loss: 0.10780105739831924\n",
      "Epoch 2732, Loss: 0.22013532370328903, Final Batch Loss: 0.12843991816043854\n",
      "Epoch 2733, Loss: 0.12507901340723038, Final Batch Loss: 0.07372535020112991\n",
      "Epoch 2734, Loss: 0.1114894226193428, Final Batch Loss: 0.04541272670030594\n",
      "Epoch 2735, Loss: 0.1175150629132986, Final Batch Loss: 0.018960801884531975\n",
      "Epoch 2736, Loss: 0.08014845103025436, Final Batch Loss: 0.028767529875040054\n",
      "Epoch 2737, Loss: 0.18254812061786652, Final Batch Loss: 0.1111966073513031\n",
      "Epoch 2738, Loss: 0.1233982965350151, Final Batch Loss: 0.07852119207382202\n",
      "Epoch 2739, Loss: 0.08837756514549255, Final Batch Loss: 0.04498521238565445\n",
      "Epoch 2740, Loss: 0.11265848204493523, Final Batch Loss: 0.04760130122303963\n",
      "Epoch 2741, Loss: 0.10790031030774117, Final Batch Loss: 0.04922209307551384\n",
      "Epoch 2742, Loss: 0.12966839596629143, Final Batch Loss: 0.051560934633016586\n",
      "Epoch 2743, Loss: 0.09075072035193443, Final Batch Loss: 0.027552705258131027\n",
      "Epoch 2744, Loss: 0.07740017399191856, Final Batch Loss: 0.020826149731874466\n",
      "Epoch 2745, Loss: 0.11046479642391205, Final Batch Loss: 0.0337841659784317\n",
      "Epoch 2746, Loss: 0.12010422721505165, Final Batch Loss: 0.04586063697934151\n",
      "Epoch 2747, Loss: 0.07601762562990189, Final Batch Loss: 0.024630997329950333\n",
      "Epoch 2748, Loss: 0.17632249742746353, Final Batch Loss: 0.10409252345561981\n",
      "Epoch 2749, Loss: 0.19593267887830734, Final Batch Loss: 0.0830177366733551\n",
      "Epoch 2750, Loss: 0.09882843680679798, Final Batch Loss: 0.019663074985146523\n",
      "Epoch 2751, Loss: 0.14001332223415375, Final Batch Loss: 0.09678296744823456\n",
      "Epoch 2752, Loss: 0.1350133940577507, Final Batch Loss: 0.06413241475820541\n",
      "Epoch 2753, Loss: 0.08018261380493641, Final Batch Loss: 0.05189942941069603\n",
      "Epoch 2754, Loss: 0.11607950180768967, Final Batch Loss: 0.06292766332626343\n",
      "Epoch 2755, Loss: 0.12717683613300323, Final Batch Loss: 0.06576454639434814\n",
      "Epoch 2756, Loss: 0.08462316542863846, Final Batch Loss: 0.050324682146310806\n",
      "Epoch 2757, Loss: 0.12494174763560295, Final Batch Loss: 0.05748644843697548\n",
      "Epoch 2758, Loss: 0.12941164150834084, Final Batch Loss: 0.060779254883527756\n",
      "Epoch 2759, Loss: 0.12324539199471474, Final Batch Loss: 0.060605790466070175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2760, Loss: 0.13807718828320503, Final Batch Loss: 0.05334422364830971\n",
      "Epoch 2761, Loss: 0.13176622986793518, Final Batch Loss: 0.0640241950750351\n",
      "Epoch 2762, Loss: 0.10149448364973068, Final Batch Loss: 0.04589686915278435\n",
      "Epoch 2763, Loss: 0.09883581101894379, Final Batch Loss: 0.030827268958091736\n",
      "Epoch 2764, Loss: 0.08504563570022583, Final Batch Loss: 0.04498962312936783\n",
      "Epoch 2765, Loss: 0.09368930011987686, Final Batch Loss: 0.03205837309360504\n",
      "Epoch 2766, Loss: 0.170844167470932, Final Batch Loss: 0.10904179513454437\n",
      "Epoch 2767, Loss: 0.07515537925064564, Final Batch Loss: 0.04722811281681061\n",
      "Epoch 2768, Loss: 0.11661187186837196, Final Batch Loss: 0.06812649220228195\n",
      "Epoch 2769, Loss: 0.11482848227024078, Final Batch Loss: 0.07912295311689377\n",
      "Epoch 2770, Loss: 0.10238554142415524, Final Batch Loss: 0.07132527977228165\n",
      "Epoch 2771, Loss: 0.09203477948904037, Final Batch Loss: 0.04170210659503937\n",
      "Epoch 2772, Loss: 0.0842899214476347, Final Batch Loss: 0.027018269523978233\n",
      "Epoch 2773, Loss: 0.10376587137579918, Final Batch Loss: 0.051090046763420105\n",
      "Epoch 2774, Loss: 0.1373270731419325, Final Batch Loss: 0.10942105203866959\n",
      "Epoch 2775, Loss: 0.08575553447008133, Final Batch Loss: 0.016141049563884735\n",
      "Epoch 2776, Loss: 0.07496834918856621, Final Batch Loss: 0.02475602552294731\n",
      "Epoch 2777, Loss: 0.1324489414691925, Final Batch Loss: 0.05068213492631912\n",
      "Epoch 2778, Loss: 0.08761502057313919, Final Batch Loss: 0.04758777096867561\n",
      "Epoch 2779, Loss: 0.11885842680931091, Final Batch Loss: 0.0709836557507515\n",
      "Epoch 2780, Loss: 0.10901396349072456, Final Batch Loss: 0.05131043493747711\n",
      "Epoch 2781, Loss: 0.11633938737213612, Final Batch Loss: 0.03006553091108799\n",
      "Epoch 2782, Loss: 0.08987646363675594, Final Batch Loss: 0.06017062067985535\n",
      "Epoch 2783, Loss: 0.07101007737219334, Final Batch Loss: 0.020832108333706856\n",
      "Epoch 2784, Loss: 0.08803940378129482, Final Batch Loss: 0.029584044590592384\n",
      "Epoch 2785, Loss: 0.1407240778207779, Final Batch Loss: 0.05925872176885605\n",
      "Epoch 2786, Loss: 0.18418357521295547, Final Batch Loss: 0.12567570805549622\n",
      "Epoch 2787, Loss: 0.08545108512043953, Final Batch Loss: 0.04506285488605499\n",
      "Epoch 2788, Loss: 0.1359746977686882, Final Batch Loss: 0.06706026196479797\n",
      "Epoch 2789, Loss: 0.16019245609641075, Final Batch Loss: 0.05774896219372749\n",
      "Epoch 2790, Loss: 0.12149650976061821, Final Batch Loss: 0.06960384547710419\n",
      "Epoch 2791, Loss: 0.1088944561779499, Final Batch Loss: 0.06955835223197937\n",
      "Epoch 2792, Loss: 0.12067175284028053, Final Batch Loss: 0.03875284269452095\n",
      "Epoch 2793, Loss: 0.14806624501943588, Final Batch Loss: 0.12041761726140976\n",
      "Epoch 2794, Loss: 0.1978045254945755, Final Batch Loss: 0.0884336605668068\n",
      "Epoch 2795, Loss: 0.07731135934591293, Final Batch Loss: 0.029877617955207825\n",
      "Epoch 2796, Loss: 0.08583412319421768, Final Batch Loss: 0.031661611050367355\n",
      "Epoch 2797, Loss: 0.10874265246093273, Final Batch Loss: 0.0775289386510849\n",
      "Epoch 2798, Loss: 0.08631754666566849, Final Batch Loss: 0.04624519124627113\n",
      "Epoch 2799, Loss: 0.07436834648251534, Final Batch Loss: 0.028120271861553192\n",
      "Epoch 2800, Loss: 0.09147312492132187, Final Batch Loss: 0.03936292231082916\n",
      "Epoch 2801, Loss: 0.1438090018928051, Final Batch Loss: 0.09169569611549377\n",
      "Epoch 2802, Loss: 0.10446465387940407, Final Batch Loss: 0.05975263938307762\n",
      "Epoch 2803, Loss: 0.15446118637919426, Final Batch Loss: 0.09520714730024338\n",
      "Epoch 2804, Loss: 0.13556129857897758, Final Batch Loss: 0.08325042575597763\n",
      "Epoch 2805, Loss: 0.06410554051399231, Final Batch Loss: 0.02833550050854683\n",
      "Epoch 2806, Loss: 0.13982116430997849, Final Batch Loss: 0.07810941338539124\n",
      "Epoch 2807, Loss: 0.09205983206629753, Final Batch Loss: 0.05069565400481224\n",
      "Epoch 2808, Loss: 0.13472618535161018, Final Batch Loss: 0.09839371591806412\n",
      "Epoch 2809, Loss: 0.13242729008197784, Final Batch Loss: 0.07132982462644577\n",
      "Epoch 2810, Loss: 0.11482486501336098, Final Batch Loss: 0.04997224733233452\n",
      "Epoch 2811, Loss: 0.0986473597586155, Final Batch Loss: 0.026176270097494125\n",
      "Epoch 2812, Loss: 0.21051044017076492, Final Batch Loss: 0.15384061634540558\n",
      "Epoch 2813, Loss: 0.11676498875021935, Final Batch Loss: 0.06237959861755371\n",
      "Epoch 2814, Loss: 0.0724020916968584, Final Batch Loss: 0.01985255442559719\n",
      "Epoch 2815, Loss: 0.08793211355805397, Final Batch Loss: 0.046106573194265366\n",
      "Epoch 2816, Loss: 0.09228080324828625, Final Batch Loss: 0.02465212158858776\n",
      "Epoch 2817, Loss: 0.14817024394869804, Final Batch Loss: 0.03470480814576149\n",
      "Epoch 2818, Loss: 0.06542162969708443, Final Batch Loss: 0.040543168783187866\n",
      "Epoch 2819, Loss: 0.08621588721871376, Final Batch Loss: 0.02822234109044075\n",
      "Epoch 2820, Loss: 0.115925382822752, Final Batch Loss: 0.0452156625688076\n",
      "Epoch 2821, Loss: 0.12078806012868881, Final Batch Loss: 0.07801838219165802\n",
      "Epoch 2822, Loss: 0.11723274365067482, Final Batch Loss: 0.04293258115649223\n",
      "Epoch 2823, Loss: 0.09039941057562828, Final Batch Loss: 0.043176498264074326\n",
      "Epoch 2824, Loss: 0.07148731499910355, Final Batch Loss: 0.03526229038834572\n",
      "Epoch 2825, Loss: 0.09794125892221928, Final Batch Loss: 0.026309901848435402\n",
      "Epoch 2826, Loss: 0.09708894602954388, Final Batch Loss: 0.02004462294280529\n",
      "Epoch 2827, Loss: 0.09923248738050461, Final Batch Loss: 0.048014283180236816\n",
      "Epoch 2828, Loss: 0.09440796077251434, Final Batch Loss: 0.058979496359825134\n",
      "Epoch 2829, Loss: 0.08431874960660934, Final Batch Loss: 0.04692817106842995\n",
      "Epoch 2830, Loss: 0.09088263660669327, Final Batch Loss: 0.028110481798648834\n",
      "Epoch 2831, Loss: 0.08293731138110161, Final Batch Loss: 0.04394674673676491\n",
      "Epoch 2832, Loss: 0.07299270667135715, Final Batch Loss: 0.042559120804071426\n",
      "Epoch 2833, Loss: 0.08232888951897621, Final Batch Loss: 0.04414673522114754\n",
      "Epoch 2834, Loss: 0.10365542769432068, Final Batch Loss: 0.058712881058454514\n",
      "Epoch 2835, Loss: 0.16908332705497742, Final Batch Loss: 0.11258082836866379\n",
      "Epoch 2836, Loss: 0.08045189641416073, Final Batch Loss: 0.04983199015259743\n",
      "Epoch 2837, Loss: 0.15072796493768692, Final Batch Loss: 0.06848179548978806\n",
      "Epoch 2838, Loss: 0.08113599568605423, Final Batch Loss: 0.036918483674526215\n",
      "Epoch 2839, Loss: 0.11416073888540268, Final Batch Loss: 0.08159628510475159\n",
      "Epoch 2840, Loss: 0.09954022243618965, Final Batch Loss: 0.05309482663869858\n",
      "Epoch 2841, Loss: 0.10367323458194733, Final Batch Loss: 0.05039404705166817\n",
      "Epoch 2842, Loss: 0.11124062165617943, Final Batch Loss: 0.06295161694288254\n",
      "Epoch 2843, Loss: 0.0774880200624466, Final Batch Loss: 0.04413936287164688\n",
      "Epoch 2844, Loss: 0.10569586977362633, Final Batch Loss: 0.03234417364001274\n",
      "Epoch 2845, Loss: 0.15968303382396698, Final Batch Loss: 0.0895262286067009\n",
      "Epoch 2846, Loss: 0.11615580320358276, Final Batch Loss: 0.044837988913059235\n",
      "Epoch 2847, Loss: 0.13451993465423584, Final Batch Loss: 0.07170306891202927\n",
      "Epoch 2848, Loss: 0.07744168490171432, Final Batch Loss: 0.03968508541584015\n",
      "Epoch 2849, Loss: 0.08679019287228584, Final Batch Loss: 0.04800790175795555\n",
      "Epoch 2850, Loss: 0.0815177671611309, Final Batch Loss: 0.036868635565042496\n",
      "Epoch 2851, Loss: 0.10058272164314985, Final Batch Loss: 0.013953830115497112\n",
      "Epoch 2852, Loss: 0.13437294587492943, Final Batch Loss: 0.0761999562382698\n",
      "Epoch 2853, Loss: 0.10030684620141983, Final Batch Loss: 0.016728609800338745\n",
      "Epoch 2854, Loss: 0.12941700592637062, Final Batch Loss: 0.04179021343588829\n",
      "Epoch 2855, Loss: 0.11228980123996735, Final Batch Loss: 0.055453281849622726\n",
      "Epoch 2856, Loss: 0.1389707438647747, Final Batch Loss: 0.03676958009600639\n",
      "Epoch 2857, Loss: 0.12317445874214172, Final Batch Loss: 0.06481754779815674\n",
      "Epoch 2858, Loss: 0.0680194590240717, Final Batch Loss: 0.025348639115691185\n",
      "Epoch 2859, Loss: 0.08768299408257008, Final Batch Loss: 0.0632527768611908\n",
      "Epoch 2860, Loss: 0.09493309631943703, Final Batch Loss: 0.05742782726883888\n",
      "Epoch 2861, Loss: 0.12373123317956924, Final Batch Loss: 0.0683777704834938\n",
      "Epoch 2862, Loss: 0.11872268095612526, Final Batch Loss: 0.07228688150644302\n",
      "Epoch 2863, Loss: 0.13248544558882713, Final Batch Loss: 0.04265611991286278\n",
      "Epoch 2864, Loss: 0.09510037861764431, Final Batch Loss: 0.01934211514890194\n",
      "Epoch 2865, Loss: 0.13456301391124725, Final Batch Loss: 0.09175850450992584\n",
      "Epoch 2866, Loss: 0.07481656782329082, Final Batch Loss: 0.01616082154214382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2867, Loss: 0.10949235036969185, Final Batch Loss: 0.05478028580546379\n",
      "Epoch 2868, Loss: 0.12286848202347755, Final Batch Loss: 0.041285593062639236\n",
      "Epoch 2869, Loss: 0.10931356623768806, Final Batch Loss: 0.07289367914199829\n",
      "Epoch 2870, Loss: 0.08409887179732323, Final Batch Loss: 0.03413136303424835\n",
      "Epoch 2871, Loss: 0.07950151711702347, Final Batch Loss: 0.03208618611097336\n",
      "Epoch 2872, Loss: 0.09784821793437004, Final Batch Loss: 0.05209789425134659\n",
      "Epoch 2873, Loss: 0.066072141751647, Final Batch Loss: 0.03898122161626816\n",
      "Epoch 2874, Loss: 0.08395344391465187, Final Batch Loss: 0.04049046337604523\n",
      "Epoch 2875, Loss: 0.08893529325723648, Final Batch Loss: 0.03149665147066116\n",
      "Epoch 2876, Loss: 0.10814974829554558, Final Batch Loss: 0.06379290670156479\n",
      "Epoch 2877, Loss: 0.1443130224943161, Final Batch Loss: 0.04302939027547836\n",
      "Epoch 2878, Loss: 0.12055172771215439, Final Batch Loss: 0.0486084520816803\n",
      "Epoch 2879, Loss: 0.0891318991780281, Final Batch Loss: 0.05243871733546257\n",
      "Epoch 2880, Loss: 0.08099618926644325, Final Batch Loss: 0.04131286218762398\n",
      "Epoch 2881, Loss: 0.10664716362953186, Final Batch Loss: 0.05015285685658455\n",
      "Epoch 2882, Loss: 0.13372420892119408, Final Batch Loss: 0.07684139907360077\n",
      "Epoch 2883, Loss: 0.09020869806408882, Final Batch Loss: 0.03989841789007187\n",
      "Epoch 2884, Loss: 0.10166012495756149, Final Batch Loss: 0.049337953329086304\n",
      "Epoch 2885, Loss: 0.11454894579946995, Final Batch Loss: 0.018280180171132088\n",
      "Epoch 2886, Loss: 0.14202062413096428, Final Batch Loss: 0.09517498314380646\n",
      "Epoch 2887, Loss: 0.17647044360637665, Final Batch Loss: 0.07312270253896713\n",
      "Epoch 2888, Loss: 0.12130580469965935, Final Batch Loss: 0.04375655576586723\n",
      "Epoch 2889, Loss: 0.06490743160247803, Final Batch Loss: 0.02902919054031372\n",
      "Epoch 2890, Loss: 0.09899190813302994, Final Batch Loss: 0.061853472143411636\n",
      "Epoch 2891, Loss: 0.1299038641154766, Final Batch Loss: 0.05223792418837547\n",
      "Epoch 2892, Loss: 0.0629377719014883, Final Batch Loss: 0.024890286847949028\n",
      "Epoch 2893, Loss: 0.06693156436085701, Final Batch Loss: 0.01597527042031288\n",
      "Epoch 2894, Loss: 0.09646005742251873, Final Batch Loss: 0.020123479887843132\n",
      "Epoch 2895, Loss: 0.11253873445093632, Final Batch Loss: 0.028455795720219612\n",
      "Epoch 2896, Loss: 0.14545447379350662, Final Batch Loss: 0.04616665095090866\n",
      "Epoch 2897, Loss: 0.12514223158359528, Final Batch Loss: 0.06040407717227936\n",
      "Epoch 2898, Loss: 0.0735610369592905, Final Batch Loss: 0.028240473940968513\n",
      "Epoch 2899, Loss: 0.08559750020503998, Final Batch Loss: 0.05407785251736641\n",
      "Epoch 2900, Loss: 0.10718952119350433, Final Batch Loss: 0.0680064931511879\n",
      "Epoch 2901, Loss: 0.08321098238229752, Final Batch Loss: 0.049899399280548096\n",
      "Epoch 2902, Loss: 0.09918300062417984, Final Batch Loss: 0.03881951421499252\n",
      "Epoch 2903, Loss: 0.1056849006563425, Final Batch Loss: 0.027287514880299568\n",
      "Epoch 2904, Loss: 0.16028166562318802, Final Batch Loss: 0.06129124015569687\n",
      "Epoch 2905, Loss: 0.08944340981543064, Final Batch Loss: 0.024198466911911964\n",
      "Epoch 2906, Loss: 0.11275256425142288, Final Batch Loss: 0.06007910892367363\n",
      "Epoch 2907, Loss: 0.09555137902498245, Final Batch Loss: 0.05314364284276962\n",
      "Epoch 2908, Loss: 0.11294474452733994, Final Batch Loss: 0.06281664222478867\n",
      "Epoch 2909, Loss: 0.0929257795214653, Final Batch Loss: 0.036450810730457306\n",
      "Epoch 2910, Loss: 0.10203654319047928, Final Batch Loss: 0.06088157743215561\n",
      "Epoch 2911, Loss: 0.08047010563313961, Final Batch Loss: 0.026309242472052574\n",
      "Epoch 2912, Loss: 0.14197184517979622, Final Batch Loss: 0.03353143855929375\n",
      "Epoch 2913, Loss: 0.12053608521819115, Final Batch Loss: 0.06028822809457779\n",
      "Epoch 2914, Loss: 0.09682289510965347, Final Batch Loss: 0.05156548321247101\n",
      "Epoch 2915, Loss: 0.0670020692050457, Final Batch Loss: 0.018977247178554535\n",
      "Epoch 2916, Loss: 0.1235421858727932, Final Batch Loss: 0.08965474367141724\n",
      "Epoch 2917, Loss: 0.09745067730545998, Final Batch Loss: 0.06416869163513184\n",
      "Epoch 2918, Loss: 0.1252279132604599, Final Batch Loss: 0.05023310333490372\n",
      "Epoch 2919, Loss: 0.13435393944382668, Final Batch Loss: 0.060490723699331284\n",
      "Epoch 2920, Loss: 0.12062180787324905, Final Batch Loss: 0.05731828510761261\n",
      "Epoch 2921, Loss: 0.1792554222047329, Final Batch Loss: 0.12957832217216492\n",
      "Epoch 2922, Loss: 0.15599075704813004, Final Batch Loss: 0.07829898595809937\n",
      "Epoch 2923, Loss: 0.11256274208426476, Final Batch Loss: 0.048454705625772476\n",
      "Epoch 2924, Loss: 0.09541533142328262, Final Batch Loss: 0.045352790504693985\n",
      "Epoch 2925, Loss: 0.08400140702724457, Final Batch Loss: 0.03942691162228584\n",
      "Epoch 2926, Loss: 0.08529583550989628, Final Batch Loss: 0.02475506253540516\n",
      "Epoch 2927, Loss: 0.06762159429490566, Final Batch Loss: 0.024827374145388603\n",
      "Epoch 2928, Loss: 0.09902627393603325, Final Batch Loss: 0.07348214089870453\n",
      "Epoch 2929, Loss: 0.10675754025578499, Final Batch Loss: 0.05503728613257408\n",
      "Epoch 2930, Loss: 0.08055397123098373, Final Batch Loss: 0.03584173321723938\n",
      "Epoch 2931, Loss: 0.09305958449840546, Final Batch Loss: 0.04623118042945862\n",
      "Epoch 2932, Loss: 0.09776187315583229, Final Batch Loss: 0.05239272117614746\n",
      "Epoch 2933, Loss: 0.1115560345351696, Final Batch Loss: 0.07121481746435165\n",
      "Epoch 2934, Loss: 0.11629972979426384, Final Batch Loss: 0.07102662324905396\n",
      "Epoch 2935, Loss: 0.15041038393974304, Final Batch Loss: 0.07573778182268143\n",
      "Epoch 2936, Loss: 0.07946677505970001, Final Batch Loss: 0.04089514911174774\n",
      "Epoch 2937, Loss: 0.11869389936327934, Final Batch Loss: 0.057471755892038345\n",
      "Epoch 2938, Loss: 0.15217231214046478, Final Batch Loss: 0.08558391779661179\n",
      "Epoch 2939, Loss: 0.07780808210372925, Final Batch Loss: 0.0453464575111866\n",
      "Epoch 2940, Loss: 0.15584281831979752, Final Batch Loss: 0.08864482492208481\n",
      "Epoch 2941, Loss: 0.06418288685381413, Final Batch Loss: 0.025700470432639122\n",
      "Epoch 2942, Loss: 0.10427182540297508, Final Batch Loss: 0.06993559747934341\n",
      "Epoch 2943, Loss: 0.0749477669596672, Final Batch Loss: 0.03428332880139351\n",
      "Epoch 2944, Loss: 0.0651032067835331, Final Batch Loss: 0.025790587067604065\n",
      "Epoch 2945, Loss: 0.11853327788412571, Final Batch Loss: 0.09024404734373093\n",
      "Epoch 2946, Loss: 0.10001217387616634, Final Batch Loss: 0.020512191578745842\n",
      "Epoch 2947, Loss: 0.12594546005129814, Final Batch Loss: 0.08640854805707932\n",
      "Epoch 2948, Loss: 0.10261688381433487, Final Batch Loss: 0.043814096599817276\n",
      "Epoch 2949, Loss: 0.10521754249930382, Final Batch Loss: 0.06808383762836456\n",
      "Epoch 2950, Loss: 0.10806013643741608, Final Batch Loss: 0.06096357852220535\n",
      "Epoch 2951, Loss: 0.11758735403418541, Final Batch Loss: 0.0449645109474659\n",
      "Epoch 2952, Loss: 0.12356333062052727, Final Batch Loss: 0.0359460823237896\n",
      "Epoch 2953, Loss: 0.08913280069828033, Final Batch Loss: 0.04787577688694\n",
      "Epoch 2954, Loss: 0.08003420382738113, Final Batch Loss: 0.024943646043539047\n",
      "Epoch 2955, Loss: 0.1325671263039112, Final Batch Loss: 0.07595421373844147\n",
      "Epoch 2956, Loss: 0.05649168975651264, Final Batch Loss: 0.03556939586997032\n",
      "Epoch 2957, Loss: 0.09637932479381561, Final Batch Loss: 0.0630873516201973\n",
      "Epoch 2958, Loss: 0.1370425447821617, Final Batch Loss: 0.06939798593521118\n",
      "Epoch 2959, Loss: 0.10282500460743904, Final Batch Loss: 0.038125377148389816\n",
      "Epoch 2960, Loss: 0.12705142050981522, Final Batch Loss: 0.05383141338825226\n",
      "Epoch 2961, Loss: 0.06474625132977962, Final Batch Loss: 0.014827551320195198\n",
      "Epoch 2962, Loss: 0.07259939052164555, Final Batch Loss: 0.026412198320031166\n",
      "Epoch 2963, Loss: 0.14520736038684845, Final Batch Loss: 0.036087557673454285\n",
      "Epoch 2964, Loss: 0.08536171168088913, Final Batch Loss: 0.03507066145539284\n",
      "Epoch 2965, Loss: 0.08123534545302391, Final Batch Loss: 0.03344070538878441\n",
      "Epoch 2966, Loss: 0.15504803508520126, Final Batch Loss: 0.1223352774977684\n",
      "Epoch 2967, Loss: 0.08033942990005016, Final Batch Loss: 0.018569381907582283\n",
      "Epoch 2968, Loss: 0.12534385174512863, Final Batch Loss: 0.06552259624004364\n",
      "Epoch 2969, Loss: 0.08917996659874916, Final Batch Loss: 0.05074199289083481\n",
      "Epoch 2970, Loss: 0.08752752840518951, Final Batch Loss: 0.05325278267264366\n",
      "Epoch 2971, Loss: 0.15609999373555183, Final Batch Loss: 0.09974346309900284\n",
      "Epoch 2972, Loss: 0.10262001305818558, Final Batch Loss: 0.0708485096693039\n",
      "Epoch 2973, Loss: 0.10446267947554588, Final Batch Loss: 0.06873148679733276\n",
      "Epoch 2974, Loss: 0.1274382695555687, Final Batch Loss: 0.05131453275680542\n",
      "Epoch 2975, Loss: 0.07916062697768211, Final Batch Loss: 0.0402226559817791\n",
      "Epoch 2976, Loss: 0.10366066172719002, Final Batch Loss: 0.03630591556429863\n",
      "Epoch 2977, Loss: 0.11234839633107185, Final Batch Loss: 0.04558560624718666\n",
      "Epoch 2978, Loss: 0.07810201868414879, Final Batch Loss: 0.042651738971471786\n",
      "Epoch 2979, Loss: 0.16404137015342712, Final Batch Loss: 0.11081334948539734\n",
      "Epoch 2980, Loss: 0.14029335230588913, Final Batch Loss: 0.1005801260471344\n",
      "Epoch 2981, Loss: 0.09228017926216125, Final Batch Loss: 0.02882508933544159\n",
      "Epoch 2982, Loss: 0.1279323361814022, Final Batch Loss: 0.08026321232318878\n",
      "Epoch 2983, Loss: 0.09578010439872742, Final Batch Loss: 0.05702533200383186\n",
      "Epoch 2984, Loss: 0.16613399982452393, Final Batch Loss: 0.11558040976524353\n",
      "Epoch 2985, Loss: 0.11093240231275558, Final Batch Loss: 0.04947642982006073\n",
      "Epoch 2986, Loss: 0.1067979671061039, Final Batch Loss: 0.036514926701784134\n",
      "Epoch 2987, Loss: 0.1191919632256031, Final Batch Loss: 0.05334935709834099\n",
      "Epoch 2988, Loss: 0.08439058065414429, Final Batch Loss: 0.040405869483947754\n",
      "Epoch 2989, Loss: 0.10117002949118614, Final Batch Loss: 0.025121312588453293\n",
      "Epoch 2990, Loss: 0.1535363271832466, Final Batch Loss: 0.04833421856164932\n",
      "Epoch 2991, Loss: 0.0825338214635849, Final Batch Loss: 0.02498679608106613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2992, Loss: 0.08047216013073921, Final Batch Loss: 0.016430053859949112\n",
      "Epoch 2993, Loss: 0.12029990553855896, Final Batch Loss: 0.050003938376903534\n",
      "Epoch 2994, Loss: 0.1491673681885004, Final Batch Loss: 0.027204910293221474\n",
      "Epoch 2995, Loss: 0.07357379794120789, Final Batch Loss: 0.032713793218135834\n",
      "Epoch 2996, Loss: 0.10998865589499474, Final Batch Loss: 0.06294622272253036\n",
      "Epoch 2997, Loss: 0.09383120760321617, Final Batch Loss: 0.04668240621685982\n",
      "Epoch 2998, Loss: 0.12251458317041397, Final Batch Loss: 0.07355759292840958\n",
      "Epoch 2999, Loss: 0.11768592521548271, Final Batch Loss: 0.07279129326343536\n",
      "Epoch 3000, Loss: 0.1154591292142868, Final Batch Loss: 0.05769030749797821\n",
      "Epoch 3001, Loss: 0.08197025768458843, Final Batch Loss: 0.020200451835989952\n",
      "Epoch 3002, Loss: 0.10436585173010826, Final Batch Loss: 0.05386107787489891\n",
      "Epoch 3003, Loss: 0.1288992129266262, Final Batch Loss: 0.09236973524093628\n",
      "Epoch 3004, Loss: 0.07917844131588936, Final Batch Loss: 0.04154125973582268\n",
      "Epoch 3005, Loss: 0.17538455687463284, Final Batch Loss: 0.021854853257536888\n",
      "Epoch 3006, Loss: 0.1686236672103405, Final Batch Loss: 0.1125054880976677\n",
      "Epoch 3007, Loss: 0.10713173449039459, Final Batch Loss: 0.05610611289739609\n",
      "Epoch 3008, Loss: 0.1277975458651781, Final Batch Loss: 0.030502313748002052\n",
      "Epoch 3009, Loss: 0.16465412452816963, Final Batch Loss: 0.05512208864092827\n",
      "Epoch 3010, Loss: 0.11089899763464928, Final Batch Loss: 0.0624387264251709\n",
      "Epoch 3011, Loss: 0.1563294306397438, Final Batch Loss: 0.06064815819263458\n",
      "Epoch 3012, Loss: 0.14136729389429092, Final Batch Loss: 0.07562961429357529\n",
      "Epoch 3013, Loss: 0.06658045947551727, Final Batch Loss: 0.03271080181002617\n",
      "Epoch 3014, Loss: 0.07350411079823971, Final Batch Loss: 0.04333970323204994\n",
      "Epoch 3015, Loss: 0.08577293157577515, Final Batch Loss: 0.05481076240539551\n",
      "Epoch 3016, Loss: 0.09150616824626923, Final Batch Loss: 0.03501448035240173\n",
      "Epoch 3017, Loss: 0.1360144391655922, Final Batch Loss: 0.03703194856643677\n",
      "Epoch 3018, Loss: 0.0895034484565258, Final Batch Loss: 0.03467119112610817\n",
      "Epoch 3019, Loss: 0.11795521154999733, Final Batch Loss: 0.04029962792992592\n",
      "Epoch 3020, Loss: 0.11987507715821266, Final Batch Loss: 0.08784256875514984\n",
      "Epoch 3021, Loss: 0.18609747290611267, Final Batch Loss: 0.07906316965818405\n",
      "Epoch 3022, Loss: 0.122354656457901, Final Batch Loss: 0.03155636042356491\n",
      "Epoch 3023, Loss: 0.10040374472737312, Final Batch Loss: 0.05985504016280174\n",
      "Epoch 3024, Loss: 0.14869895204901695, Final Batch Loss: 0.09934433549642563\n",
      "Epoch 3025, Loss: 0.12283288687467575, Final Batch Loss: 0.07587189972400665\n",
      "Epoch 3026, Loss: 0.05876386724412441, Final Batch Loss: 0.014085544273257256\n",
      "Epoch 3027, Loss: 0.14155623689293861, Final Batch Loss: 0.05328266695141792\n",
      "Epoch 3028, Loss: 0.06590725108981133, Final Batch Loss: 0.03135545179247856\n",
      "Epoch 3029, Loss: 0.1384786292910576, Final Batch Loss: 0.070545993745327\n",
      "Epoch 3030, Loss: 0.2031332030892372, Final Batch Loss: 0.08955971151590347\n",
      "Epoch 3031, Loss: 0.0813429094851017, Final Batch Loss: 0.03854534775018692\n",
      "Epoch 3032, Loss: 0.12052157148718834, Final Batch Loss: 0.05130610242486\n",
      "Epoch 3033, Loss: 0.1094721332192421, Final Batch Loss: 0.06483716517686844\n",
      "Epoch 3034, Loss: 0.08990832418203354, Final Batch Loss: 0.03744513913989067\n",
      "Epoch 3035, Loss: 0.10779357329010963, Final Batch Loss: 0.042096156626939774\n",
      "Epoch 3036, Loss: 0.09254994615912437, Final Batch Loss: 0.05373001843690872\n",
      "Epoch 3037, Loss: 0.12591492384672165, Final Batch Loss: 0.08179771900177002\n",
      "Epoch 3038, Loss: 0.07683823257684708, Final Batch Loss: 0.03132673352956772\n",
      "Epoch 3039, Loss: 0.08450520038604736, Final Batch Loss: 0.04773756116628647\n",
      "Epoch 3040, Loss: 0.12132111191749573, Final Batch Loss: 0.08995670825242996\n",
      "Epoch 3041, Loss: 0.13769474253058434, Final Batch Loss: 0.08004633337259293\n",
      "Epoch 3042, Loss: 0.09429227747023106, Final Batch Loss: 0.0637291893362999\n",
      "Epoch 3043, Loss: 0.10837952420115471, Final Batch Loss: 0.028934773057699203\n",
      "Epoch 3044, Loss: 0.11554031260311604, Final Batch Loss: 0.08995909988880157\n",
      "Epoch 3045, Loss: 0.23530834168195724, Final Batch Loss: 0.18284711241722107\n",
      "Epoch 3046, Loss: 0.09574161842465401, Final Batch Loss: 0.04825881868600845\n",
      "Epoch 3047, Loss: 0.12824749946594238, Final Batch Loss: 0.08080049604177475\n",
      "Epoch 3048, Loss: 0.11893759295344353, Final Batch Loss: 0.06713137030601501\n",
      "Epoch 3049, Loss: 0.08521788939833641, Final Batch Loss: 0.04133623093366623\n",
      "Epoch 3050, Loss: 0.09107053652405739, Final Batch Loss: 0.04217269644141197\n",
      "Epoch 3051, Loss: 0.10697713121771812, Final Batch Loss: 0.03960428014397621\n",
      "Epoch 3052, Loss: 0.12039079330861568, Final Batch Loss: 0.09889297187328339\n",
      "Epoch 3053, Loss: 0.08752426877617836, Final Batch Loss: 0.033675212413072586\n",
      "Epoch 3054, Loss: 0.09807687625288963, Final Batch Loss: 0.05572710931301117\n",
      "Epoch 3055, Loss: 0.07039562612771988, Final Batch Loss: 0.036807116121053696\n",
      "Epoch 3056, Loss: 0.12786919623613358, Final Batch Loss: 0.06507701426744461\n",
      "Epoch 3057, Loss: 0.10069844126701355, Final Batch Loss: 0.03459449112415314\n",
      "Epoch 3058, Loss: 0.11038047820329666, Final Batch Loss: 0.05114369094371796\n",
      "Epoch 3059, Loss: 0.08129790052771568, Final Batch Loss: 0.043418124318122864\n",
      "Epoch 3060, Loss: 0.09707164764404297, Final Batch Loss: 0.0648312121629715\n",
      "Epoch 3061, Loss: 0.1283959187567234, Final Batch Loss: 0.07515714317560196\n",
      "Epoch 3062, Loss: 0.06667510420084, Final Batch Loss: 0.03153535723686218\n",
      "Epoch 3063, Loss: 0.07527001947164536, Final Batch Loss: 0.040630728006362915\n",
      "Epoch 3064, Loss: 0.0809243842959404, Final Batch Loss: 0.04278203099966049\n",
      "Epoch 3065, Loss: 0.07350041344761848, Final Batch Loss: 0.03933817520737648\n",
      "Epoch 3066, Loss: 0.13099779561161995, Final Batch Loss: 0.06929264962673187\n",
      "Epoch 3067, Loss: 0.1384495012462139, Final Batch Loss: 0.0979737639427185\n",
      "Epoch 3068, Loss: 0.09963278844952583, Final Batch Loss: 0.032387007027864456\n",
      "Epoch 3069, Loss: 0.07028833497315645, Final Batch Loss: 0.01306618470698595\n",
      "Epoch 3070, Loss: 0.07718002796173096, Final Batch Loss: 0.021383855491876602\n",
      "Epoch 3071, Loss: 0.0889215562492609, Final Batch Loss: 0.060684170573949814\n",
      "Epoch 3072, Loss: 0.1852281615138054, Final Batch Loss: 0.1305277943611145\n",
      "Epoch 3073, Loss: 0.11819101497530937, Final Batch Loss: 0.06483064591884613\n",
      "Epoch 3074, Loss: 0.15120437741279602, Final Batch Loss: 0.0801885724067688\n",
      "Epoch 3075, Loss: 0.08746857941150665, Final Batch Loss: 0.040202271193265915\n",
      "Epoch 3076, Loss: 0.13318488746881485, Final Batch Loss: 0.06804554909467697\n",
      "Epoch 3077, Loss: 0.07979511842131615, Final Batch Loss: 0.05162769928574562\n",
      "Epoch 3078, Loss: 0.1379486247897148, Final Batch Loss: 0.08919422328472137\n",
      "Epoch 3079, Loss: 0.16938669234514236, Final Batch Loss: 0.04928625375032425\n",
      "Epoch 3080, Loss: 0.10222149640321732, Final Batch Loss: 0.043435096740722656\n",
      "Epoch 3081, Loss: 0.15510156005620956, Final Batch Loss: 0.07059323042631149\n",
      "Epoch 3082, Loss: 0.11681361123919487, Final Batch Loss: 0.06631570309400558\n",
      "Epoch 3083, Loss: 0.07646916434168816, Final Batch Loss: 0.03932759910821915\n",
      "Epoch 3084, Loss: 0.07181083224713802, Final Batch Loss: 0.043798960745334625\n",
      "Epoch 3085, Loss: 0.13754110783338547, Final Batch Loss: 0.10108265280723572\n",
      "Epoch 3086, Loss: 0.1836143434047699, Final Batch Loss: 0.055773571133613586\n",
      "Epoch 3087, Loss: 0.09810739755630493, Final Batch Loss: 0.03956802189350128\n",
      "Epoch 3088, Loss: 0.14480014145374298, Final Batch Loss: 0.0929260328412056\n",
      "Epoch 3089, Loss: 0.12762953341007233, Final Batch Loss: 0.049728333950042725\n",
      "Epoch 3090, Loss: 0.09510109946131706, Final Batch Loss: 0.051447439938783646\n",
      "Epoch 3091, Loss: 0.13892247900366783, Final Batch Loss: 0.08254767954349518\n",
      "Epoch 3092, Loss: 0.08127595111727715, Final Batch Loss: 0.04031575098633766\n",
      "Epoch 3093, Loss: 0.09779424965381622, Final Batch Loss: 0.040023475885391235\n",
      "Epoch 3094, Loss: 0.11933469027280807, Final Batch Loss: 0.0745982900261879\n",
      "Epoch 3095, Loss: 0.09524363279342651, Final Batch Loss: 0.036171309649944305\n",
      "Epoch 3096, Loss: 0.08457505330443382, Final Batch Loss: 0.039718709886074066\n",
      "Epoch 3097, Loss: 0.11181776225566864, Final Batch Loss: 0.014172226190567017\n",
      "Epoch 3098, Loss: 0.05494887940585613, Final Batch Loss: 0.02018873579800129\n",
      "Epoch 3099, Loss: 0.08207440376281738, Final Batch Loss: 0.03771378472447395\n",
      "Epoch 3100, Loss: 0.0727494228631258, Final Batch Loss: 0.045691002160310745\n",
      "Epoch 3101, Loss: 0.0693097673356533, Final Batch Loss: 0.021083485335111618\n",
      "Epoch 3102, Loss: 0.05694922525435686, Final Batch Loss: 0.01330114621669054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3103, Loss: 0.09251729026436806, Final Batch Loss: 0.06467714160680771\n",
      "Epoch 3104, Loss: 0.1412150263786316, Final Batch Loss: 0.08393307030200958\n",
      "Epoch 3105, Loss: 0.06964405067265034, Final Batch Loss: 0.020469436421990395\n",
      "Epoch 3106, Loss: 0.0832242053002119, Final Batch Loss: 0.019357291981577873\n",
      "Epoch 3107, Loss: 0.07684100978076458, Final Batch Loss: 0.05604509264230728\n",
      "Epoch 3108, Loss: 0.07147226668894291, Final Batch Loss: 0.027663694694638252\n",
      "Epoch 3109, Loss: 0.084749735891819, Final Batch Loss: 0.04281264543533325\n",
      "Epoch 3110, Loss: 0.11556374281644821, Final Batch Loss: 0.056823670864105225\n",
      "Epoch 3111, Loss: 0.08881533890962601, Final Batch Loss: 0.03574656695127487\n",
      "Epoch 3112, Loss: 0.09386140294373035, Final Batch Loss: 0.030068034306168556\n",
      "Epoch 3113, Loss: 0.11657856404781342, Final Batch Loss: 0.08460977673530579\n",
      "Epoch 3114, Loss: 0.10095859691500664, Final Batch Loss: 0.04644458368420601\n",
      "Epoch 3115, Loss: 0.10071593895554543, Final Batch Loss: 0.0456315241754055\n",
      "Epoch 3116, Loss: 0.15556983649730682, Final Batch Loss: 0.07841860502958298\n",
      "Epoch 3117, Loss: 0.06673087924718857, Final Batch Loss: 0.0365251861512661\n",
      "Epoch 3118, Loss: 0.05984852649271488, Final Batch Loss: 0.02628312073647976\n",
      "Epoch 3119, Loss: 0.10683270916342735, Final Batch Loss: 0.036357637494802475\n",
      "Epoch 3120, Loss: 0.07169935666024685, Final Batch Loss: 0.018815049901604652\n",
      "Epoch 3121, Loss: 0.07223372720181942, Final Batch Loss: 0.021861063316464424\n",
      "Epoch 3122, Loss: 0.15424765646457672, Final Batch Loss: 0.08185108006000519\n",
      "Epoch 3123, Loss: 0.1376611366868019, Final Batch Loss: 0.07965361326932907\n",
      "Epoch 3124, Loss: 0.11145413294434547, Final Batch Loss: 0.03599512204527855\n",
      "Epoch 3125, Loss: 0.09003341197967529, Final Batch Loss: 0.0566333532333374\n",
      "Epoch 3126, Loss: 0.12683483213186264, Final Batch Loss: 0.07995639741420746\n",
      "Epoch 3127, Loss: 0.09814688563346863, Final Batch Loss: 0.06273221969604492\n",
      "Epoch 3128, Loss: 0.1691301241517067, Final Batch Loss: 0.0743369460105896\n",
      "Epoch 3129, Loss: 0.06964055076241493, Final Batch Loss: 0.024562902748584747\n",
      "Epoch 3130, Loss: 0.05779934860765934, Final Batch Loss: 0.03964678943157196\n",
      "Epoch 3131, Loss: 0.05899345315992832, Final Batch Loss: 0.02607082761824131\n",
      "Epoch 3132, Loss: 0.06829923763871193, Final Batch Loss: 0.04069611430168152\n",
      "Epoch 3133, Loss: 0.13112301006913185, Final Batch Loss: 0.09053549915552139\n",
      "Epoch 3134, Loss: 0.09658361598849297, Final Batch Loss: 0.058133386075496674\n",
      "Epoch 3135, Loss: 0.0807335115969181, Final Batch Loss: 0.03950893506407738\n",
      "Epoch 3136, Loss: 0.0993984267115593, Final Batch Loss: 0.039830561727285385\n",
      "Epoch 3137, Loss: 0.07370652630925179, Final Batch Loss: 0.04221519082784653\n",
      "Epoch 3138, Loss: 0.10293015465140343, Final Batch Loss: 0.0663239061832428\n",
      "Epoch 3139, Loss: 0.12255432084202766, Final Batch Loss: 0.07564011216163635\n",
      "Epoch 3140, Loss: 0.06724173203110695, Final Batch Loss: 0.045007601380348206\n",
      "Epoch 3141, Loss: 0.07743565179407597, Final Batch Loss: 0.029617147520184517\n",
      "Epoch 3142, Loss: 0.059521399438381195, Final Batch Loss: 0.027400121092796326\n",
      "Epoch 3143, Loss: 0.09168832004070282, Final Batch Loss: 0.034203384071588516\n",
      "Epoch 3144, Loss: 0.07840356789529324, Final Batch Loss: 0.02493974380195141\n",
      "Epoch 3145, Loss: 0.06125107407569885, Final Batch Loss: 0.034526798874139786\n",
      "Epoch 3146, Loss: 0.1139443852007389, Final Batch Loss: 0.07943965494632721\n",
      "Epoch 3147, Loss: 0.08510639891028404, Final Batch Loss: 0.04760696738958359\n",
      "Epoch 3148, Loss: 0.0683365911245346, Final Batch Loss: 0.027694683521986008\n",
      "Epoch 3149, Loss: 0.08828456699848175, Final Batch Loss: 0.05078042298555374\n",
      "Epoch 3150, Loss: 0.07956327125430107, Final Batch Loss: 0.036844342947006226\n",
      "Epoch 3151, Loss: 0.04915914125740528, Final Batch Loss: 0.02554287761449814\n",
      "Epoch 3152, Loss: 0.06446066685020924, Final Batch Loss: 0.034103117883205414\n",
      "Epoch 3153, Loss: 0.07209980860352516, Final Batch Loss: 0.027088027447462082\n",
      "Epoch 3154, Loss: 0.07848183438181877, Final Batch Loss: 0.01793140545487404\n",
      "Epoch 3155, Loss: 0.0727635845541954, Final Batch Loss: 0.03468863666057587\n",
      "Epoch 3156, Loss: 0.13107052445411682, Final Batch Loss: 0.07623522728681564\n",
      "Epoch 3157, Loss: 0.1316709816455841, Final Batch Loss: 0.06720669567584991\n",
      "Epoch 3158, Loss: 0.08532654866576195, Final Batch Loss: 0.046014443039894104\n",
      "Epoch 3159, Loss: 0.06482565216720104, Final Batch Loss: 0.03068039007484913\n",
      "Epoch 3160, Loss: 0.19176190346479416, Final Batch Loss: 0.12278255820274353\n",
      "Epoch 3161, Loss: 0.1678825467824936, Final Batch Loss: 0.12648554146289825\n",
      "Epoch 3162, Loss: 0.14425662904977798, Final Batch Loss: 0.0773799791932106\n",
      "Epoch 3163, Loss: 0.19232337176799774, Final Batch Loss: 0.1359364241361618\n",
      "Epoch 3164, Loss: 0.13888803124427795, Final Batch Loss: 0.07753822207450867\n",
      "Epoch 3165, Loss: 0.14166561141610146, Final Batch Loss: 0.044322896748781204\n",
      "Epoch 3166, Loss: 0.11955919861793518, Final Batch Loss: 0.033692553639411926\n",
      "Epoch 3167, Loss: 0.0745973251760006, Final Batch Loss: 0.04000302031636238\n",
      "Epoch 3168, Loss: 0.08246563002467155, Final Batch Loss: 0.03269796445965767\n",
      "Epoch 3169, Loss: 0.09233478643000126, Final Batch Loss: 0.03067605011165142\n",
      "Epoch 3170, Loss: 0.10117033123970032, Final Batch Loss: 0.0622045174241066\n",
      "Epoch 3171, Loss: 0.106326375156641, Final Batch Loss: 0.054865285754203796\n",
      "Epoch 3172, Loss: 0.10809873044490814, Final Batch Loss: 0.034516893327236176\n",
      "Epoch 3173, Loss: 0.18662873283028603, Final Batch Loss: 0.13031955063343048\n",
      "Epoch 3174, Loss: 0.11655106768012047, Final Batch Loss: 0.0767388790845871\n",
      "Epoch 3175, Loss: 0.14226547628641129, Final Batch Loss: 0.07804976403713226\n",
      "Epoch 3176, Loss: 0.0901544876396656, Final Batch Loss: 0.04062936455011368\n",
      "Epoch 3177, Loss: 0.07381102629005909, Final Batch Loss: 0.029766371473670006\n",
      "Epoch 3178, Loss: 0.1390804722905159, Final Batch Loss: 0.0790548101067543\n",
      "Epoch 3179, Loss: 0.09551270306110382, Final Batch Loss: 0.03747541829943657\n",
      "Epoch 3180, Loss: 0.0919654592871666, Final Batch Loss: 0.050185102969408035\n",
      "Epoch 3181, Loss: 0.11880404129624367, Final Batch Loss: 0.05290709808468819\n",
      "Epoch 3182, Loss: 0.12114362418651581, Final Batch Loss: 0.08073373883962631\n",
      "Epoch 3183, Loss: 0.07208563014864922, Final Batch Loss: 0.04179571568965912\n",
      "Epoch 3184, Loss: 0.15993044152855873, Final Batch Loss: 0.0974327027797699\n",
      "Epoch 3185, Loss: 0.08347523584961891, Final Batch Loss: 0.03723819553852081\n",
      "Epoch 3186, Loss: 0.0701415054500103, Final Batch Loss: 0.042601268738508224\n",
      "Epoch 3187, Loss: 0.12103084474802017, Final Batch Loss: 0.06433451920747757\n",
      "Epoch 3188, Loss: 0.12500878423452377, Final Batch Loss: 0.0583052858710289\n",
      "Epoch 3189, Loss: 0.0956631563603878, Final Batch Loss: 0.0592322051525116\n",
      "Epoch 3190, Loss: 0.162221297621727, Final Batch Loss: 0.07451043277978897\n",
      "Epoch 3191, Loss: 0.10095242410898209, Final Batch Loss: 0.04019780457019806\n",
      "Epoch 3192, Loss: 0.11565785855054855, Final Batch Loss: 0.07554908841848373\n",
      "Epoch 3193, Loss: 0.07688326016068459, Final Batch Loss: 0.033494140952825546\n",
      "Epoch 3194, Loss: 0.10108169540762901, Final Batch Loss: 0.04099622368812561\n",
      "Epoch 3195, Loss: 0.10347888246178627, Final Batch Loss: 0.055401742458343506\n",
      "Epoch 3196, Loss: 0.07964063622057438, Final Batch Loss: 0.020207328721880913\n",
      "Epoch 3197, Loss: 0.07127349078655243, Final Batch Loss: 0.03841697424650192\n",
      "Epoch 3198, Loss: 0.11500483751296997, Final Batch Loss: 0.07568790763616562\n",
      "Epoch 3199, Loss: 0.08430816605687141, Final Batch Loss: 0.0448651984333992\n",
      "Epoch 3200, Loss: 0.14193985611200333, Final Batch Loss: 0.0897054523229599\n",
      "Epoch 3201, Loss: 0.08675140514969826, Final Batch Loss: 0.04100480303168297\n",
      "Epoch 3202, Loss: 0.08105428516864777, Final Batch Loss: 0.04812341928482056\n",
      "Epoch 3203, Loss: 0.055299365893006325, Final Batch Loss: 0.020029621198773384\n",
      "Epoch 3204, Loss: 0.11657356098294258, Final Batch Loss: 0.06859533488750458\n",
      "Epoch 3205, Loss: 0.13512542843818665, Final Batch Loss: 0.06835046410560608\n",
      "Epoch 3206, Loss: 0.10873444378376007, Final Batch Loss: 0.06905840337276459\n",
      "Epoch 3207, Loss: 0.14177963137626648, Final Batch Loss: 0.10550855100154877\n",
      "Epoch 3208, Loss: 0.12049146741628647, Final Batch Loss: 0.08680547773838043\n",
      "Epoch 3209, Loss: 0.0999557413160801, Final Batch Loss: 0.05026134103536606\n",
      "Epoch 3210, Loss: 0.05821698158979416, Final Batch Loss: 0.016968917101621628\n",
      "Epoch 3211, Loss: 0.12421023100614548, Final Batch Loss: 0.0500507727265358\n",
      "Epoch 3212, Loss: 0.07292819023132324, Final Batch Loss: 0.03985760360956192\n",
      "Epoch 3213, Loss: 0.0704459473490715, Final Batch Loss: 0.01666988432407379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3214, Loss: 0.0852246955037117, Final Batch Loss: 0.03848055750131607\n",
      "Epoch 3215, Loss: 0.12146458029747009, Final Batch Loss: 0.0759778767824173\n",
      "Epoch 3216, Loss: 0.1317899078130722, Final Batch Loss: 0.025079958140850067\n",
      "Epoch 3217, Loss: 0.10240401700139046, Final Batch Loss: 0.04848451167345047\n",
      "Epoch 3218, Loss: 0.1298750601708889, Final Batch Loss: 0.08995101600885391\n",
      "Epoch 3219, Loss: 0.08888619393110275, Final Batch Loss: 0.02944882959127426\n",
      "Epoch 3220, Loss: 0.09166234731674194, Final Batch Loss: 0.03890039026737213\n",
      "Epoch 3221, Loss: 0.05434843711555004, Final Batch Loss: 0.029738325625658035\n",
      "Epoch 3222, Loss: 0.09000840783119202, Final Batch Loss: 0.03082086518406868\n",
      "Epoch 3223, Loss: 0.07103537023067474, Final Batch Loss: 0.02236320450901985\n",
      "Epoch 3224, Loss: 0.08313260599970818, Final Batch Loss: 0.033861253410577774\n",
      "Epoch 3225, Loss: 0.14650259725749493, Final Batch Loss: 0.12141498923301697\n",
      "Epoch 3226, Loss: 0.1146094910800457, Final Batch Loss: 0.05064772441983223\n",
      "Epoch 3227, Loss: 0.11977234855294228, Final Batch Loss: 0.02686387673020363\n",
      "Epoch 3228, Loss: 0.11807230114936829, Final Batch Loss: 0.06001736596226692\n",
      "Epoch 3229, Loss: 0.2301587238907814, Final Batch Loss: 0.1827046424150467\n",
      "Epoch 3230, Loss: 0.11989597231149673, Final Batch Loss: 0.08643593639135361\n",
      "Epoch 3231, Loss: 0.09716742485761642, Final Batch Loss: 0.05105423182249069\n",
      "Epoch 3232, Loss: 0.12200364470481873, Final Batch Loss: 0.09071287512779236\n",
      "Epoch 3233, Loss: 0.07992437854409218, Final Batch Loss: 0.03753425553441048\n",
      "Epoch 3234, Loss: 0.09227202460169792, Final Batch Loss: 0.039183393120765686\n",
      "Epoch 3235, Loss: 0.10256935656070709, Final Batch Loss: 0.05894458666443825\n",
      "Epoch 3236, Loss: 0.06257212162017822, Final Batch Loss: 0.03483763337135315\n",
      "Epoch 3237, Loss: 0.10707074403762817, Final Batch Loss: 0.06924823671579361\n",
      "Epoch 3238, Loss: 0.07154357992112637, Final Batch Loss: 0.04788462072610855\n",
      "Epoch 3239, Loss: 0.15686067566275597, Final Batch Loss: 0.11215116828680038\n",
      "Epoch 3240, Loss: 0.11552964150905609, Final Batch Loss: 0.07404034584760666\n",
      "Epoch 3241, Loss: 0.09658928960561752, Final Batch Loss: 0.05978481099009514\n",
      "Epoch 3242, Loss: 0.11251553893089294, Final Batch Loss: 0.0494636669754982\n",
      "Epoch 3243, Loss: 0.1568765863776207, Final Batch Loss: 0.05004281550645828\n",
      "Epoch 3244, Loss: 0.06295174546539783, Final Batch Loss: 0.02901565469801426\n",
      "Epoch 3245, Loss: 0.056836143136024475, Final Batch Loss: 0.03950773552060127\n",
      "Epoch 3246, Loss: 0.08036795072257519, Final Batch Loss: 0.020622121170163155\n",
      "Epoch 3247, Loss: 0.11943881213665009, Final Batch Loss: 0.07817786186933517\n",
      "Epoch 3248, Loss: 0.08963681012392044, Final Batch Loss: 0.03954577073454857\n",
      "Epoch 3249, Loss: 0.10565076395869255, Final Batch Loss: 0.0638200119137764\n",
      "Epoch 3250, Loss: 0.15941370278596878, Final Batch Loss: 0.07902036607265472\n",
      "Epoch 3251, Loss: 0.09631671383976936, Final Batch Loss: 0.042525045573711395\n",
      "Epoch 3252, Loss: 0.04823216795921326, Final Batch Loss: 0.028251303359866142\n",
      "Epoch 3253, Loss: 0.08671610057353973, Final Batch Loss: 0.03493829816579819\n",
      "Epoch 3254, Loss: 0.06439487263560295, Final Batch Loss: 0.03247882053256035\n",
      "Epoch 3255, Loss: 0.06417251378297806, Final Batch Loss: 0.036395661532878876\n",
      "Epoch 3256, Loss: 0.06034036725759506, Final Batch Loss: 0.026145517826080322\n",
      "Epoch 3257, Loss: 0.05154813267290592, Final Batch Loss: 0.013820787891745567\n",
      "Epoch 3258, Loss: 0.1272859200835228, Final Batch Loss: 0.0795072540640831\n",
      "Epoch 3259, Loss: 0.05201541632413864, Final Batch Loss: 0.02226625382900238\n",
      "Epoch 3260, Loss: 0.0681556798517704, Final Batch Loss: 0.03976067155599594\n",
      "Epoch 3261, Loss: 0.12773349322378635, Final Batch Loss: 0.09938245266675949\n",
      "Epoch 3262, Loss: 0.10106514394283295, Final Batch Loss: 0.06206004321575165\n",
      "Epoch 3263, Loss: 0.06505494564771652, Final Batch Loss: 0.024038713425397873\n",
      "Epoch 3264, Loss: 0.13166284188628197, Final Batch Loss: 0.05564441904425621\n",
      "Epoch 3265, Loss: 0.06725594401359558, Final Batch Loss: 0.04215265437960625\n",
      "Epoch 3266, Loss: 0.09251343086361885, Final Batch Loss: 0.05596522241830826\n",
      "Epoch 3267, Loss: 0.16958975046873093, Final Batch Loss: 0.13313688337802887\n",
      "Epoch 3268, Loss: 0.09225847199559212, Final Batch Loss: 0.03171185776591301\n",
      "Epoch 3269, Loss: 0.11003432236611843, Final Batch Loss: 0.0941915288567543\n",
      "Epoch 3270, Loss: 0.09850705415010452, Final Batch Loss: 0.042758163064718246\n",
      "Epoch 3271, Loss: 0.09633455984294415, Final Batch Loss: 0.07727596163749695\n",
      "Epoch 3272, Loss: 0.10201361030340195, Final Batch Loss: 0.034540824592113495\n",
      "Epoch 3273, Loss: 0.10776020213961601, Final Batch Loss: 0.031977664679288864\n",
      "Epoch 3274, Loss: 0.09358661249279976, Final Batch Loss: 0.058859605342149734\n",
      "Epoch 3275, Loss: 0.1145634837448597, Final Batch Loss: 0.0886923298239708\n",
      "Epoch 3276, Loss: 0.08094876632094383, Final Batch Loss: 0.05043899267911911\n",
      "Epoch 3277, Loss: 0.14649688825011253, Final Batch Loss: 0.10243353247642517\n",
      "Epoch 3278, Loss: 0.09284189529716969, Final Batch Loss: 0.0617985762655735\n",
      "Epoch 3279, Loss: 0.08153997734189034, Final Batch Loss: 0.04088039696216583\n",
      "Epoch 3280, Loss: 0.12206835672259331, Final Batch Loss: 0.07527650892734528\n",
      "Epoch 3281, Loss: 0.07688630558550358, Final Batch Loss: 0.02377360500395298\n",
      "Epoch 3282, Loss: 0.18180468305945396, Final Batch Loss: 0.13979434967041016\n",
      "Epoch 3283, Loss: 0.1292313113808632, Final Batch Loss: 0.055720239877700806\n",
      "Epoch 3284, Loss: 0.10177691280841827, Final Batch Loss: 0.07027337700128555\n",
      "Epoch 3285, Loss: 0.12545960023999214, Final Batch Loss: 0.07691260427236557\n",
      "Epoch 3286, Loss: 0.08502564579248428, Final Batch Loss: 0.03929450735449791\n",
      "Epoch 3287, Loss: 0.047342851758003235, Final Batch Loss: 0.025736413896083832\n",
      "Epoch 3288, Loss: 0.05906199850142002, Final Batch Loss: 0.031041337177157402\n",
      "Epoch 3289, Loss: 0.07277853786945343, Final Batch Loss: 0.016111209988594055\n",
      "Epoch 3290, Loss: 0.09886008128523827, Final Batch Loss: 0.04490961506962776\n",
      "Epoch 3291, Loss: 0.13826694712042809, Final Batch Loss: 0.044864680618047714\n",
      "Epoch 3292, Loss: 0.051485197618603706, Final Batch Loss: 0.014989728108048439\n",
      "Epoch 3293, Loss: 0.06866571865975857, Final Batch Loss: 0.022415896877646446\n",
      "Epoch 3294, Loss: 0.11991114541888237, Final Batch Loss: 0.06931928545236588\n",
      "Epoch 3295, Loss: 0.057184165343642235, Final Batch Loss: 0.020774202421307564\n",
      "Epoch 3296, Loss: 0.1082208901643753, Final Batch Loss: 0.03308900445699692\n",
      "Epoch 3297, Loss: 0.052548304200172424, Final Batch Loss: 0.027400340884923935\n",
      "Epoch 3298, Loss: 0.0782739594578743, Final Batch Loss: 0.04442235827445984\n",
      "Epoch 3299, Loss: 0.05917298421263695, Final Batch Loss: 0.023436427116394043\n",
      "Epoch 3300, Loss: 0.11106799729168415, Final Batch Loss: 0.08029040694236755\n",
      "Epoch 3301, Loss: 0.060448210686445236, Final Batch Loss: 0.033972643315792084\n",
      "Epoch 3302, Loss: 0.09539677947759628, Final Batch Loss: 0.04695029929280281\n",
      "Epoch 3303, Loss: 0.10018586367368698, Final Batch Loss: 0.04317379742860794\n",
      "Epoch 3304, Loss: 0.0862341821193695, Final Batch Loss: 0.04262170568108559\n",
      "Epoch 3305, Loss: 0.08774251863360405, Final Batch Loss: 0.0261017307639122\n",
      "Epoch 3306, Loss: 0.17725029587745667, Final Batch Loss: 0.03459566831588745\n",
      "Epoch 3307, Loss: 0.20459339767694473, Final Batch Loss: 0.09843940287828445\n",
      "Epoch 3308, Loss: 0.08260180242359638, Final Batch Loss: 0.018106887117028236\n",
      "Epoch 3309, Loss: 0.14224594086408615, Final Batch Loss: 0.10926752537488937\n",
      "Epoch 3310, Loss: 0.12919831275939941, Final Batch Loss: 0.08087147027254105\n",
      "Epoch 3311, Loss: 0.05445623770356178, Final Batch Loss: 0.026188530027866364\n",
      "Epoch 3312, Loss: 0.09111588448286057, Final Batch Loss: 0.03944285586476326\n",
      "Epoch 3313, Loss: 0.07289544492959976, Final Batch Loss: 0.0290839821100235\n",
      "Epoch 3314, Loss: 0.09509889781475067, Final Batch Loss: 0.04667707532644272\n",
      "Epoch 3315, Loss: 0.05642051063477993, Final Batch Loss: 0.019175482913851738\n",
      "Epoch 3316, Loss: 0.13171671330928802, Final Batch Loss: 0.08542188256978989\n",
      "Epoch 3317, Loss: 0.07703362964093685, Final Batch Loss: 0.02931310050189495\n",
      "Epoch 3318, Loss: 0.1342507116496563, Final Batch Loss: 0.0885448306798935\n",
      "Epoch 3319, Loss: 0.06783405691385269, Final Batch Loss: 0.023105230182409286\n",
      "Epoch 3320, Loss: 0.06569619290530682, Final Batch Loss: 0.029066557064652443\n",
      "Epoch 3321, Loss: 0.11696134507656097, Final Batch Loss: 0.036845020949840546\n",
      "Epoch 3322, Loss: 0.08370877057313919, Final Batch Loss: 0.057675424963235855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3323, Loss: 0.10208553075790405, Final Batch Loss: 0.0812436118721962\n",
      "Epoch 3324, Loss: 0.11775397881865501, Final Batch Loss: 0.09053490310907364\n",
      "Epoch 3325, Loss: 0.05908028408885002, Final Batch Loss: 0.019446857273578644\n",
      "Epoch 3326, Loss: 0.0815114788711071, Final Batch Loss: 0.04432952031493187\n",
      "Epoch 3327, Loss: 0.06723635084927082, Final Batch Loss: 0.03990216553211212\n",
      "Epoch 3328, Loss: 0.07247993350028992, Final Batch Loss: 0.03450273722410202\n",
      "Epoch 3329, Loss: 0.07277180626988411, Final Batch Loss: 0.040163252502679825\n",
      "Epoch 3330, Loss: 0.10279849171638489, Final Batch Loss: 0.04203209653496742\n",
      "Epoch 3331, Loss: 0.07002904638648033, Final Batch Loss: 0.02017306536436081\n",
      "Epoch 3332, Loss: 0.07838656567037106, Final Batch Loss: 0.05886238068342209\n",
      "Epoch 3333, Loss: 0.092026736587286, Final Batch Loss: 0.03425844386219978\n",
      "Epoch 3334, Loss: 0.06686380133032799, Final Batch Loss: 0.02762184664607048\n",
      "Epoch 3335, Loss: 0.04214636981487274, Final Batch Loss: 0.01872073858976364\n",
      "Epoch 3336, Loss: 0.06949882581830025, Final Batch Loss: 0.038244299590587616\n",
      "Epoch 3337, Loss: 0.049892719835042953, Final Batch Loss: 0.023081788793206215\n",
      "Epoch 3338, Loss: 0.08052917569875717, Final Batch Loss: 0.05693730711936951\n",
      "Epoch 3339, Loss: 0.1339932382106781, Final Batch Loss: 0.09484981000423431\n",
      "Epoch 3340, Loss: 0.06675861030817032, Final Batch Loss: 0.045889340341091156\n",
      "Epoch 3341, Loss: 0.0878671184182167, Final Batch Loss: 0.03540578857064247\n",
      "Epoch 3342, Loss: 0.11299631372094154, Final Batch Loss: 0.02194282039999962\n",
      "Epoch 3343, Loss: 0.10480637103319168, Final Batch Loss: 0.06353043019771576\n",
      "Epoch 3344, Loss: 0.1012592688202858, Final Batch Loss: 0.021697595715522766\n",
      "Epoch 3345, Loss: 0.04897061176598072, Final Batch Loss: 0.03586767241358757\n",
      "Epoch 3346, Loss: 0.088742695748806, Final Batch Loss: 0.057725198566913605\n",
      "Epoch 3347, Loss: 0.10332303866744041, Final Batch Loss: 0.04280110076069832\n",
      "Epoch 3348, Loss: 0.16691337153315544, Final Batch Loss: 0.1150173768401146\n",
      "Epoch 3349, Loss: 0.08403683453798294, Final Batch Loss: 0.027931638062000275\n",
      "Epoch 3350, Loss: 0.06958926282823086, Final Batch Loss: 0.029437171295285225\n",
      "Epoch 3351, Loss: 0.07007767632603645, Final Batch Loss: 0.043388932943344116\n",
      "Epoch 3352, Loss: 0.1429636999964714, Final Batch Loss: 0.07619471848011017\n",
      "Epoch 3353, Loss: 0.06100165657699108, Final Batch Loss: 0.0337061770260334\n",
      "Epoch 3354, Loss: 0.040640490129590034, Final Batch Loss: 0.0157327800989151\n",
      "Epoch 3355, Loss: 0.08385901339352131, Final Batch Loss: 0.017833413556218147\n",
      "Epoch 3356, Loss: 0.12475918605923653, Final Batch Loss: 0.07579562067985535\n",
      "Epoch 3357, Loss: 0.07608911953866482, Final Batch Loss: 0.028910880908370018\n",
      "Epoch 3358, Loss: 0.06425540149211884, Final Batch Loss: 0.01607968658208847\n",
      "Epoch 3359, Loss: 0.142849151045084, Final Batch Loss: 0.10268328338861465\n",
      "Epoch 3360, Loss: 0.10982446745038033, Final Batch Loss: 0.03259318694472313\n",
      "Epoch 3361, Loss: 0.05639163218438625, Final Batch Loss: 0.03021901659667492\n",
      "Epoch 3362, Loss: 0.07295399904251099, Final Batch Loss: 0.024733982980251312\n",
      "Epoch 3363, Loss: 0.0780867300927639, Final Batch Loss: 0.03328056260943413\n",
      "Epoch 3364, Loss: 0.0921047180891037, Final Batch Loss: 0.02557358890771866\n",
      "Epoch 3365, Loss: 0.13285626471042633, Final Batch Loss: 0.10351546108722687\n",
      "Epoch 3366, Loss: 0.1924586296081543, Final Batch Loss: 0.11406546831130981\n",
      "Epoch 3367, Loss: 0.054442208260297775, Final Batch Loss: 0.037204351276159286\n",
      "Epoch 3368, Loss: 0.08830437436699867, Final Batch Loss: 0.03744833171367645\n",
      "Epoch 3369, Loss: 0.09496825933456421, Final Batch Loss: 0.03438177704811096\n",
      "Epoch 3370, Loss: 0.17618998885154724, Final Batch Loss: 0.043540701270103455\n",
      "Epoch 3371, Loss: 0.10916582494974136, Final Batch Loss: 0.051939740777015686\n",
      "Epoch 3372, Loss: 0.10612809658050537, Final Batch Loss: 0.06314395368099213\n",
      "Epoch 3373, Loss: 0.09102792292833328, Final Batch Loss: 0.05946189910173416\n",
      "Epoch 3374, Loss: 0.057421280071139336, Final Batch Loss: 0.041978806257247925\n",
      "Epoch 3375, Loss: 0.08087473921477795, Final Batch Loss: 0.04974391683936119\n",
      "Epoch 3376, Loss: 0.12741508707404137, Final Batch Loss: 0.0929902046918869\n",
      "Epoch 3377, Loss: 0.06275713443756104, Final Batch Loss: 0.021039754152297974\n",
      "Epoch 3378, Loss: 0.09985266998410225, Final Batch Loss: 0.058036770671606064\n",
      "Epoch 3379, Loss: 0.09524461254477501, Final Batch Loss: 0.04277326539158821\n",
      "Epoch 3380, Loss: 0.05168736167252064, Final Batch Loss: 0.024439217522740364\n",
      "Epoch 3381, Loss: 0.11281347833573818, Final Batch Loss: 0.09070674329996109\n",
      "Epoch 3382, Loss: 0.05852082371711731, Final Batch Loss: 0.025580286979675293\n",
      "Epoch 3383, Loss: 0.06846538744866848, Final Batch Loss: 0.04541105404496193\n",
      "Epoch 3384, Loss: 0.08566244505345821, Final Batch Loss: 0.06243015453219414\n",
      "Epoch 3385, Loss: 0.06839397549629211, Final Batch Loss: 0.024834778159856796\n",
      "Epoch 3386, Loss: 0.10524541139602661, Final Batch Loss: 0.03953827917575836\n",
      "Epoch 3387, Loss: 0.09841134771704674, Final Batch Loss: 0.05665662884712219\n",
      "Epoch 3388, Loss: 0.11565940827131271, Final Batch Loss: 0.059315621852874756\n",
      "Epoch 3389, Loss: 0.08430683612823486, Final Batch Loss: 0.038744036108255386\n",
      "Epoch 3390, Loss: 0.09575967490673065, Final Batch Loss: 0.04071851819753647\n",
      "Epoch 3391, Loss: 0.07898253202438354, Final Batch Loss: 0.029428832232952118\n",
      "Epoch 3392, Loss: 0.12005892768502235, Final Batch Loss: 0.073418028652668\n",
      "Epoch 3393, Loss: 0.08667336031794548, Final Batch Loss: 0.04305309057235718\n",
      "Epoch 3394, Loss: 0.07223821803927422, Final Batch Loss: 0.022126078605651855\n",
      "Epoch 3395, Loss: 0.12808596342802048, Final Batch Loss: 0.10807019472122192\n",
      "Epoch 3396, Loss: 0.10482805501669645, Final Batch Loss: 0.01495735626667738\n",
      "Epoch 3397, Loss: 0.059976233169436455, Final Batch Loss: 0.027810504660010338\n",
      "Epoch 3398, Loss: 0.07800694368779659, Final Batch Loss: 0.05434313416481018\n",
      "Epoch 3399, Loss: 0.07873272523283958, Final Batch Loss: 0.03440596163272858\n",
      "Epoch 3400, Loss: 0.0862412378191948, Final Batch Loss: 0.05085514858365059\n",
      "Epoch 3401, Loss: 0.07990174926817417, Final Batch Loss: 0.029607558622956276\n",
      "Epoch 3402, Loss: 0.06785830110311508, Final Batch Loss: 0.03577897325158119\n",
      "Epoch 3403, Loss: 0.12722500786185265, Final Batch Loss: 0.10125473886728287\n",
      "Epoch 3404, Loss: 0.06270639318972826, Final Batch Loss: 0.015060090459883213\n",
      "Epoch 3405, Loss: 0.11533599719405174, Final Batch Loss: 0.05615554377436638\n",
      "Epoch 3406, Loss: 0.06166119500994682, Final Batch Loss: 0.026800978928804398\n",
      "Epoch 3407, Loss: 0.08072246238589287, Final Batch Loss: 0.04745741933584213\n",
      "Epoch 3408, Loss: 0.05432601273059845, Final Batch Loss: 0.024624843150377274\n",
      "Epoch 3409, Loss: 0.06384023278951645, Final Batch Loss: 0.025901582092046738\n",
      "Epoch 3410, Loss: 0.04795890301465988, Final Batch Loss: 0.010040022432804108\n",
      "Epoch 3411, Loss: 0.07777503505349159, Final Batch Loss: 0.03612590581178665\n",
      "Epoch 3412, Loss: 0.10753173381090164, Final Batch Loss: 0.05934163182973862\n",
      "Epoch 3413, Loss: 0.042730364948511124, Final Batch Loss: 0.025441177189350128\n",
      "Epoch 3414, Loss: 0.06073920987546444, Final Batch Loss: 0.036334458738565445\n",
      "Epoch 3415, Loss: 0.07908821851015091, Final Batch Loss: 0.025149468332529068\n",
      "Epoch 3416, Loss: 0.10005230829119682, Final Batch Loss: 0.06224594637751579\n",
      "Epoch 3417, Loss: 0.06541960872709751, Final Batch Loss: 0.021175356581807137\n",
      "Epoch 3418, Loss: 0.1221945472061634, Final Batch Loss: 0.038817908614873886\n",
      "Epoch 3419, Loss: 0.04419662617146969, Final Batch Loss: 0.015101546421647072\n",
      "Epoch 3420, Loss: 0.05945093743503094, Final Batch Loss: 0.010458322241902351\n",
      "Epoch 3421, Loss: 0.11543184146285057, Final Batch Loss: 0.06035585328936577\n",
      "Epoch 3422, Loss: 0.05180799961090088, Final Batch Loss: 0.02583152800798416\n",
      "Epoch 3423, Loss: 0.07430553622543812, Final Batch Loss: 0.024841779842972755\n",
      "Epoch 3424, Loss: 0.07344400323927402, Final Batch Loss: 0.022062918171286583\n",
      "Epoch 3425, Loss: 0.13450394943356514, Final Batch Loss: 0.0967404693365097\n",
      "Epoch 3426, Loss: 0.06165534071624279, Final Batch Loss: 0.014562519267201424\n",
      "Epoch 3427, Loss: 0.04761645942926407, Final Batch Loss: 0.027302755042910576\n",
      "Epoch 3428, Loss: 0.06823745742440224, Final Batch Loss: 0.034412093460559845\n",
      "Epoch 3429, Loss: 0.17413388192653656, Final Batch Loss: 0.07875934988260269\n",
      "Epoch 3430, Loss: 0.05365171656012535, Final Batch Loss: 0.03565974906086922\n",
      "Epoch 3431, Loss: 0.10712498798966408, Final Batch Loss: 0.049215130507946014\n",
      "Epoch 3432, Loss: 0.06781151704490185, Final Batch Loss: 0.03710288554430008\n",
      "Epoch 3433, Loss: 0.05798998847603798, Final Batch Loss: 0.01979805901646614\n",
      "Epoch 3434, Loss: 0.07018150389194489, Final Batch Loss: 0.03170028701424599\n",
      "Epoch 3435, Loss: 0.21348946541547775, Final Batch Loss: 0.15320518612861633\n",
      "Epoch 3436, Loss: 0.10361823812127113, Final Batch Loss: 0.04895424842834473\n",
      "Epoch 3437, Loss: 0.2152179777622223, Final Batch Loss: 0.1284700334072113\n",
      "Epoch 3438, Loss: 0.13681640848517418, Final Batch Loss: 0.07843386381864548\n",
      "Epoch 3439, Loss: 0.06305838190019131, Final Batch Loss: 0.02477393113076687\n",
      "Epoch 3440, Loss: 0.04109002184122801, Final Batch Loss: 0.014382378198206425\n",
      "Epoch 3441, Loss: 0.05192926153540611, Final Batch Loss: 0.03446820378303528\n",
      "Epoch 3442, Loss: 0.12677665799856186, Final Batch Loss: 0.07047203928232193\n",
      "Epoch 3443, Loss: 0.07845421880483627, Final Batch Loss: 0.04010038822889328\n",
      "Epoch 3444, Loss: 0.10546249896287918, Final Batch Loss: 0.051176607608795166\n",
      "Epoch 3445, Loss: 0.12232037261128426, Final Batch Loss: 0.08062025159597397\n",
      "Epoch 3446, Loss: 0.07024399377405643, Final Batch Loss: 0.03984268009662628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3447, Loss: 0.08804910257458687, Final Batch Loss: 0.05043740198016167\n",
      "Epoch 3448, Loss: 0.074862165376544, Final Batch Loss: 0.02634611167013645\n",
      "Epoch 3449, Loss: 0.11558013409376144, Final Batch Loss: 0.06397155672311783\n",
      "Epoch 3450, Loss: 0.0955654215067625, Final Batch Loss: 0.02618303708732128\n",
      "Epoch 3451, Loss: 0.1930036898702383, Final Batch Loss: 0.028051963075995445\n",
      "Epoch 3452, Loss: 0.07520326599478722, Final Batch Loss: 0.055459484457969666\n",
      "Epoch 3453, Loss: 0.10033157467842102, Final Batch Loss: 0.07198110967874527\n",
      "Epoch 3454, Loss: 0.09363051131367683, Final Batch Loss: 0.05744220316410065\n",
      "Epoch 3455, Loss: 0.059645868837833405, Final Batch Loss: 0.030712950974702835\n",
      "Epoch 3456, Loss: 0.06375526450574398, Final Batch Loss: 0.033643849194049835\n",
      "Epoch 3457, Loss: 0.06788526847958565, Final Batch Loss: 0.03632209822535515\n",
      "Epoch 3458, Loss: 0.06490061990916729, Final Batch Loss: 0.022122355177998543\n",
      "Epoch 3459, Loss: 0.06107440963387489, Final Batch Loss: 0.027139507234096527\n",
      "Epoch 3460, Loss: 0.0831209048628807, Final Batch Loss: 0.04895276948809624\n",
      "Epoch 3461, Loss: 0.06162706017494202, Final Batch Loss: 0.03602392598986626\n",
      "Epoch 3462, Loss: 0.07114915922284126, Final Batch Loss: 0.043725427240133286\n",
      "Epoch 3463, Loss: 0.051133669912815094, Final Batch Loss: 0.03481927514076233\n",
      "Epoch 3464, Loss: 0.14409710094332695, Final Batch Loss: 0.0975344330072403\n",
      "Epoch 3465, Loss: 0.059544721618294716, Final Batch Loss: 0.038210347294807434\n",
      "Epoch 3466, Loss: 0.057205403223633766, Final Batch Loss: 0.03219638392329216\n",
      "Epoch 3467, Loss: 0.06676732562482357, Final Batch Loss: 0.036695949733257294\n",
      "Epoch 3468, Loss: 0.14525055140256882, Final Batch Loss: 0.10301461815834045\n",
      "Epoch 3469, Loss: 0.07416428439319134, Final Batch Loss: 0.0464833565056324\n",
      "Epoch 3470, Loss: 0.0820789746940136, Final Batch Loss: 0.03971343860030174\n",
      "Epoch 3471, Loss: 0.12683912366628647, Final Batch Loss: 0.09674671292304993\n",
      "Epoch 3472, Loss: 0.08346965350210667, Final Batch Loss: 0.022797929123044014\n",
      "Epoch 3473, Loss: 0.05982923321425915, Final Batch Loss: 0.017990319058299065\n",
      "Epoch 3474, Loss: 0.058836791664361954, Final Batch Loss: 0.02198663353919983\n",
      "Epoch 3475, Loss: 0.08773711323738098, Final Batch Loss: 0.034332167357206345\n",
      "Epoch 3476, Loss: 0.07910999283194542, Final Batch Loss: 0.05916972458362579\n",
      "Epoch 3477, Loss: 0.1256171092391014, Final Batch Loss: 0.051686204969882965\n",
      "Epoch 3478, Loss: 0.042325759306550026, Final Batch Loss: 0.026629680767655373\n",
      "Epoch 3479, Loss: 0.07725132256746292, Final Batch Loss: 0.03625042364001274\n",
      "Epoch 3480, Loss: 0.07771274447441101, Final Batch Loss: 0.03321518748998642\n",
      "Epoch 3481, Loss: 0.07368667982518673, Final Batch Loss: 0.020163631066679955\n",
      "Epoch 3482, Loss: 0.10252610594034195, Final Batch Loss: 0.03725532442331314\n",
      "Epoch 3483, Loss: 0.035966137424111366, Final Batch Loss: 0.015388648957014084\n",
      "Epoch 3484, Loss: 0.06562655977904797, Final Batch Loss: 0.014390381053090096\n",
      "Epoch 3485, Loss: 0.0772030521184206, Final Batch Loss: 0.05838271602988243\n",
      "Epoch 3486, Loss: 0.08765722811222076, Final Batch Loss: 0.036840010434389114\n",
      "Epoch 3487, Loss: 0.06581657566130161, Final Batch Loss: 0.02614486776292324\n",
      "Epoch 3488, Loss: 0.07681695371866226, Final Batch Loss: 0.04784468933939934\n",
      "Epoch 3489, Loss: 0.08853153511881828, Final Batch Loss: 0.0521925650537014\n",
      "Epoch 3490, Loss: 0.08099613338708878, Final Batch Loss: 0.04894092306494713\n",
      "Epoch 3491, Loss: 0.04791436530649662, Final Batch Loss: 0.01769286021590233\n",
      "Epoch 3492, Loss: 0.09445393458008766, Final Batch Loss: 0.04742841795086861\n",
      "Epoch 3493, Loss: 0.05919882468879223, Final Batch Loss: 0.03157859295606613\n",
      "Epoch 3494, Loss: 0.06328834965825081, Final Batch Loss: 0.04832843691110611\n",
      "Epoch 3495, Loss: 0.049249811097979546, Final Batch Loss: 0.02914539910852909\n",
      "Epoch 3496, Loss: 0.06601508893072605, Final Batch Loss: 0.029676048085093498\n",
      "Epoch 3497, Loss: 0.0958750806748867, Final Batch Loss: 0.05911735072731972\n",
      "Epoch 3498, Loss: 0.07632523961365223, Final Batch Loss: 0.05568290874361992\n",
      "Epoch 3499, Loss: 0.04945099726319313, Final Batch Loss: 0.02269206941127777\n",
      "Epoch 3500, Loss: 0.06620422005653381, Final Batch Loss: 0.014526467770338058\n",
      "Epoch 3501, Loss: 0.05839822441339493, Final Batch Loss: 0.04005732759833336\n",
      "Epoch 3502, Loss: 0.14325622841715813, Final Batch Loss: 0.03733299300074577\n",
      "Epoch 3503, Loss: 0.07798232324421406, Final Batch Loss: 0.024072708562016487\n",
      "Epoch 3504, Loss: 0.07589870877563953, Final Batch Loss: 0.019426429644227028\n",
      "Epoch 3505, Loss: 0.09111320972442627, Final Batch Loss: 0.04338337108492851\n",
      "Epoch 3506, Loss: 0.046821946278214455, Final Batch Loss: 0.018107615411281586\n",
      "Epoch 3507, Loss: 0.1270875371992588, Final Batch Loss: 0.056121308356523514\n",
      "Epoch 3508, Loss: 0.07670500501990318, Final Batch Loss: 0.02149217575788498\n",
      "Epoch 3509, Loss: 0.12003038078546524, Final Batch Loss: 0.08211986720561981\n",
      "Epoch 3510, Loss: 0.07286542281508446, Final Batch Loss: 0.025123976171016693\n",
      "Epoch 3511, Loss: 0.11264384910464287, Final Batch Loss: 0.06648265570402145\n",
      "Epoch 3512, Loss: 0.10087091848254204, Final Batch Loss: 0.07393442839384079\n",
      "Epoch 3513, Loss: 0.06812053360044956, Final Batch Loss: 0.020305758342146873\n",
      "Epoch 3514, Loss: 0.05439102463424206, Final Batch Loss: 0.025975774973630905\n",
      "Epoch 3515, Loss: 0.09137817844748497, Final Batch Loss: 0.06003464758396149\n",
      "Epoch 3516, Loss: 0.13310669735074043, Final Batch Loss: 0.07669495791196823\n",
      "Epoch 3517, Loss: 0.0550779365003109, Final Batch Loss: 0.02443963848054409\n",
      "Epoch 3518, Loss: 0.08978433907032013, Final Batch Loss: 0.05024933069944382\n",
      "Epoch 3519, Loss: 0.21225567907094955, Final Batch Loss: 0.1501334011554718\n",
      "Epoch 3520, Loss: 0.12584015354514122, Final Batch Loss: 0.08696156740188599\n",
      "Epoch 3521, Loss: 0.07835269160568714, Final Batch Loss: 0.030072858557105064\n",
      "Epoch 3522, Loss: 0.10526323691010475, Final Batch Loss: 0.06380036473274231\n",
      "Epoch 3523, Loss: 0.07201793044805527, Final Batch Loss: 0.040917251259088516\n",
      "Epoch 3524, Loss: 0.08940428867936134, Final Batch Loss: 0.05680651217699051\n",
      "Epoch 3525, Loss: 0.0747013408690691, Final Batch Loss: 0.02381858415901661\n",
      "Epoch 3526, Loss: 0.07639794982969761, Final Batch Loss: 0.05423489585518837\n",
      "Epoch 3527, Loss: 0.0731225311756134, Final Batch Loss: 0.03833732008934021\n",
      "Epoch 3528, Loss: 0.10202343016862869, Final Batch Loss: 0.062114980071783066\n",
      "Epoch 3529, Loss: 0.06283114198595285, Final Batch Loss: 0.014616497792303562\n",
      "Epoch 3530, Loss: 0.08734086155891418, Final Batch Loss: 0.02643245831131935\n",
      "Epoch 3531, Loss: 0.09428661316633224, Final Batch Loss: 0.03758949786424637\n",
      "Epoch 3532, Loss: 0.1905923280864954, Final Batch Loss: 0.025540897622704506\n",
      "Epoch 3533, Loss: 0.056458836421370506, Final Batch Loss: 0.021877260878682137\n",
      "Epoch 3534, Loss: 0.09698639065027237, Final Batch Loss: 0.05186580494046211\n",
      "Epoch 3535, Loss: 0.061178505420684814, Final Batch Loss: 0.022134266793727875\n",
      "Epoch 3536, Loss: 0.07893769443035126, Final Batch Loss: 0.043900806456804276\n",
      "Epoch 3537, Loss: 0.05766012333333492, Final Batch Loss: 0.029333919286727905\n",
      "Epoch 3538, Loss: 0.068117905408144, Final Batch Loss: 0.023856405168771744\n",
      "Epoch 3539, Loss: 0.15330849960446358, Final Batch Loss: 0.1160801500082016\n",
      "Epoch 3540, Loss: 0.052215004339814186, Final Batch Loss: 0.03155696019530296\n",
      "Epoch 3541, Loss: 0.08683518134057522, Final Batch Loss: 0.02706349827349186\n",
      "Epoch 3542, Loss: 0.06976684182882309, Final Batch Loss: 0.03586477041244507\n",
      "Epoch 3543, Loss: 0.08994283154606819, Final Batch Loss: 0.05836673080921173\n",
      "Epoch 3544, Loss: 0.11604053527116776, Final Batch Loss: 0.0772622600197792\n",
      "Epoch 3545, Loss: 0.039730009622871876, Final Batch Loss: 0.014162999577820301\n",
      "Epoch 3546, Loss: 0.07890019193291664, Final Batch Loss: 0.04581101983785629\n",
      "Epoch 3547, Loss: 0.06952705886214972, Final Batch Loss: 0.011322389356791973\n",
      "Epoch 3548, Loss: 0.07456811517477036, Final Batch Loss: 0.03655383735895157\n",
      "Epoch 3549, Loss: 0.0636433083564043, Final Batch Loss: 0.0374600850045681\n",
      "Epoch 3550, Loss: 0.04850164242088795, Final Batch Loss: 0.022762982174754143\n",
      "Epoch 3551, Loss: 0.10382219031453133, Final Batch Loss: 0.049820173531770706\n",
      "Epoch 3552, Loss: 0.0877973884344101, Final Batch Loss: 0.05555189773440361\n",
      "Epoch 3553, Loss: 0.08587621338665485, Final Batch Loss: 0.06846685707569122\n",
      "Epoch 3554, Loss: 0.07634009048342705, Final Batch Loss: 0.037001729011535645\n",
      "Epoch 3555, Loss: 0.07553143613040447, Final Batch Loss: 0.02437647618353367\n",
      "Epoch 3556, Loss: 0.06421648245304823, Final Batch Loss: 0.05147356539964676\n",
      "Epoch 3557, Loss: 0.053864194080233574, Final Batch Loss: 0.015979068353772163\n",
      "Epoch 3558, Loss: 0.13817695248872042, Final Batch Loss: 0.12673728168010712\n",
      "Epoch 3559, Loss: 0.051809798926115036, Final Batch Loss: 0.01762324571609497\n",
      "Epoch 3560, Loss: 0.04459582455456257, Final Batch Loss: 0.01834277994930744\n",
      "Epoch 3561, Loss: 0.08916795626282692, Final Batch Loss: 0.02263611927628517\n",
      "Epoch 3562, Loss: 0.06325381062924862, Final Batch Loss: 0.013386765494942665\n",
      "Epoch 3563, Loss: 0.08580278418958187, Final Batch Loss: 0.060166411101818085\n",
      "Epoch 3564, Loss: 0.08701212890446186, Final Batch Loss: 0.058981753885746\n",
      "Epoch 3565, Loss: 0.12403187900781631, Final Batch Loss: 0.08465049415826797\n",
      "Epoch 3566, Loss: 0.07879269868135452, Final Batch Loss: 0.035273563116788864\n",
      "Epoch 3567, Loss: 0.0617537759244442, Final Batch Loss: 0.042226292192935944\n",
      "Epoch 3568, Loss: 0.05453834868967533, Final Batch Loss: 0.03176269680261612\n",
      "Epoch 3569, Loss: 0.17244132608175278, Final Batch Loss: 0.10938777774572372\n",
      "Epoch 3570, Loss: 0.09749997779726982, Final Batch Loss: 0.07510850578546524\n",
      "Epoch 3571, Loss: 0.1274086944758892, Final Batch Loss: 0.03753119334578514\n",
      "Epoch 3572, Loss: 0.06726282089948654, Final Batch Loss: 0.03456839174032211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3573, Loss: 0.05550994165241718, Final Batch Loss: 0.027462705969810486\n",
      "Epoch 3574, Loss: 0.08755409345030785, Final Batch Loss: 0.05966334417462349\n",
      "Epoch 3575, Loss: 0.09975339844822884, Final Batch Loss: 0.047763943672180176\n",
      "Epoch 3576, Loss: 0.11984490044414997, Final Batch Loss: 0.09710384905338287\n",
      "Epoch 3577, Loss: 0.08686223439872265, Final Batch Loss: 0.030616076663136482\n",
      "Epoch 3578, Loss: 0.05582660436630249, Final Batch Loss: 0.025608455762267113\n",
      "Epoch 3579, Loss: 0.042335158213973045, Final Batch Loss: 0.025563661009073257\n",
      "Epoch 3580, Loss: 0.07522542774677277, Final Batch Loss: 0.04163141921162605\n",
      "Epoch 3581, Loss: 0.08228141069412231, Final Batch Loss: 0.021901529282331467\n",
      "Epoch 3582, Loss: 0.07763860374689102, Final Batch Loss: 0.03560030832886696\n",
      "Epoch 3583, Loss: 0.07098972052335739, Final Batch Loss: 0.03835972025990486\n",
      "Epoch 3584, Loss: 0.07098362036049366, Final Batch Loss: 0.017965180799365044\n",
      "Epoch 3585, Loss: 0.1323019377887249, Final Batch Loss: 0.06044330820441246\n",
      "Epoch 3586, Loss: 0.08078695833683014, Final Batch Loss: 0.03536420688033104\n",
      "Epoch 3587, Loss: 0.06440487504005432, Final Batch Loss: 0.03927256166934967\n",
      "Epoch 3588, Loss: 0.06705142371356487, Final Batch Loss: 0.049252092838287354\n",
      "Epoch 3589, Loss: 0.06968995369970798, Final Batch Loss: 0.01873534359037876\n",
      "Epoch 3590, Loss: 0.14572212100028992, Final Batch Loss: 0.08629902452230453\n",
      "Epoch 3591, Loss: 0.06799757108092308, Final Batch Loss: 0.04004639387130737\n",
      "Epoch 3592, Loss: 0.04953443352133036, Final Batch Loss: 0.014796012081205845\n",
      "Epoch 3593, Loss: 0.053526680916547775, Final Batch Loss: 0.016994602978229523\n",
      "Epoch 3594, Loss: 0.03785189799964428, Final Batch Loss: 0.02216622792184353\n",
      "Epoch 3595, Loss: 0.13880053535103798, Final Batch Loss: 0.07838853448629379\n",
      "Epoch 3596, Loss: 0.07151766121387482, Final Batch Loss: 0.037894055247306824\n",
      "Epoch 3597, Loss: 0.06681391410529613, Final Batch Loss: 0.022287121042609215\n",
      "Epoch 3598, Loss: 0.06173379346728325, Final Batch Loss: 0.0196976475417614\n",
      "Epoch 3599, Loss: 0.06570244953036308, Final Batch Loss: 0.03693104535341263\n",
      "Epoch 3600, Loss: 0.06528650224208832, Final Batch Loss: 0.03451303765177727\n",
      "Epoch 3601, Loss: 0.03730181138962507, Final Batch Loss: 0.014628027565777302\n",
      "Epoch 3602, Loss: 0.045285364612936974, Final Batch Loss: 0.019449466839432716\n",
      "Epoch 3603, Loss: 0.09491891227662563, Final Batch Loss: 0.0638732835650444\n",
      "Epoch 3604, Loss: 0.08026469126343727, Final Batch Loss: 0.040578071027994156\n",
      "Epoch 3605, Loss: 0.07787411287426949, Final Batch Loss: 0.036560166627168655\n",
      "Epoch 3606, Loss: 0.08020116575062275, Final Batch Loss: 0.014660084620118141\n",
      "Epoch 3607, Loss: 0.06764989346265793, Final Batch Loss: 0.04954452067613602\n",
      "Epoch 3608, Loss: 0.06888299435377121, Final Batch Loss: 0.03582127392292023\n",
      "Epoch 3609, Loss: 0.05903645232319832, Final Batch Loss: 0.028814831748604774\n",
      "Epoch 3610, Loss: 0.08437049947679043, Final Batch Loss: 0.028134232386946678\n",
      "Epoch 3611, Loss: 0.06454353034496307, Final Batch Loss: 0.029611635953187943\n",
      "Epoch 3612, Loss: 0.10030983574688435, Final Batch Loss: 0.08034946769475937\n",
      "Epoch 3613, Loss: 0.08334334939718246, Final Batch Loss: 0.04646240174770355\n",
      "Epoch 3614, Loss: 0.06382051482796669, Final Batch Loss: 0.01987117901444435\n",
      "Epoch 3615, Loss: 0.10194559395313263, Final Batch Loss: 0.03761262446641922\n",
      "Epoch 3616, Loss: 0.05841173976659775, Final Batch Loss: 0.026101335883140564\n",
      "Epoch 3617, Loss: 0.04371285252273083, Final Batch Loss: 0.02266182377934456\n",
      "Epoch 3618, Loss: 0.07614035345613956, Final Batch Loss: 0.027347130700945854\n",
      "Epoch 3619, Loss: 0.10795685835182667, Final Batch Loss: 0.014360414817929268\n",
      "Epoch 3620, Loss: 0.09129942581057549, Final Batch Loss: 0.046442415565252304\n",
      "Epoch 3621, Loss: 0.05720473825931549, Final Batch Loss: 0.02422361448407173\n",
      "Epoch 3622, Loss: 0.08684640377759933, Final Batch Loss: 0.05183502286672592\n",
      "Epoch 3623, Loss: 0.06585721671581268, Final Batch Loss: 0.033074866980314255\n",
      "Epoch 3624, Loss: 0.09669110178947449, Final Batch Loss: 0.03191903233528137\n",
      "Epoch 3625, Loss: 0.08982031792402267, Final Batch Loss: 0.015351332724094391\n",
      "Epoch 3626, Loss: 0.10436041094362736, Final Batch Loss: 0.08975537121295929\n",
      "Epoch 3627, Loss: 0.11226058378815651, Final Batch Loss: 0.07821502536535263\n",
      "Epoch 3628, Loss: 0.06459860876202583, Final Batch Loss: 0.03196088597178459\n",
      "Epoch 3629, Loss: 0.05891925096511841, Final Batch Loss: 0.029104148969054222\n",
      "Epoch 3630, Loss: 0.1778298057615757, Final Batch Loss: 0.13375146687030792\n",
      "Epoch 3631, Loss: 0.06857684813439846, Final Batch Loss: 0.025643041357398033\n",
      "Epoch 3632, Loss: 0.07499165832996368, Final Batch Loss: 0.03784620761871338\n",
      "Epoch 3633, Loss: 0.04848610609769821, Final Batch Loss: 0.030657872557640076\n",
      "Epoch 3634, Loss: 0.051868999376893044, Final Batch Loss: 0.031081562861800194\n",
      "Epoch 3635, Loss: 0.06973889842629433, Final Batch Loss: 0.04267748445272446\n",
      "Epoch 3636, Loss: 0.040222241543233395, Final Batch Loss: 0.012181862257421017\n",
      "Epoch 3637, Loss: 0.06097027100622654, Final Batch Loss: 0.01970788650214672\n",
      "Epoch 3638, Loss: 0.09738634526729584, Final Batch Loss: 0.024552151560783386\n",
      "Epoch 3639, Loss: 0.065416119992733, Final Batch Loss: 0.023918308317661285\n",
      "Epoch 3640, Loss: 0.06001165881752968, Final Batch Loss: 0.02099013328552246\n",
      "Epoch 3641, Loss: 0.08930094353854656, Final Batch Loss: 0.06280254572629929\n",
      "Epoch 3642, Loss: 0.13642267137765884, Final Batch Loss: 0.06813656538724899\n",
      "Epoch 3643, Loss: 0.1199065949767828, Final Batch Loss: 0.02458432875573635\n",
      "Epoch 3644, Loss: 0.03136363811790943, Final Batch Loss: 0.009431896731257439\n",
      "Epoch 3645, Loss: 0.040389884263277054, Final Batch Loss: 0.02872813493013382\n",
      "Epoch 3646, Loss: 0.07196998596191406, Final Batch Loss: 0.022199198603630066\n",
      "Epoch 3647, Loss: 0.04778577946126461, Final Batch Loss: 0.021040575578808784\n",
      "Epoch 3648, Loss: 0.05618702434003353, Final Batch Loss: 0.015739383175969124\n",
      "Epoch 3649, Loss: 0.09499713033437729, Final Batch Loss: 0.05815739557147026\n",
      "Epoch 3650, Loss: 0.12777250073850155, Final Batch Loss: 0.10348988324403763\n",
      "Epoch 3651, Loss: 0.060510145500302315, Final Batch Loss: 0.026365140452980995\n",
      "Epoch 3652, Loss: 0.05996260605752468, Final Batch Loss: 0.03569573536515236\n",
      "Epoch 3653, Loss: 0.1104101911187172, Final Batch Loss: 0.07725492119789124\n",
      "Epoch 3654, Loss: 0.04677027650177479, Final Batch Loss: 0.02406071498990059\n",
      "Epoch 3655, Loss: 0.033038634806871414, Final Batch Loss: 0.012656942009925842\n",
      "Epoch 3656, Loss: 0.04955586791038513, Final Batch Loss: 0.023319385945796967\n",
      "Epoch 3657, Loss: 0.043938444927334785, Final Batch Loss: 0.01712886244058609\n",
      "Epoch 3658, Loss: 0.028773452155292034, Final Batch Loss: 0.012219064868986607\n",
      "Epoch 3659, Loss: 0.10556632280349731, Final Batch Loss: 0.03329505771398544\n",
      "Epoch 3660, Loss: 0.0710919089615345, Final Batch Loss: 0.038345273584127426\n",
      "Epoch 3661, Loss: 0.07979401014745235, Final Batch Loss: 0.02169063873589039\n",
      "Epoch 3662, Loss: 0.09453735500574112, Final Batch Loss: 0.06340450793504715\n",
      "Epoch 3663, Loss: 0.08765935152769089, Final Batch Loss: 0.037878040224313736\n",
      "Epoch 3664, Loss: 0.081389544531703, Final Batch Loss: 0.02241555042564869\n",
      "Epoch 3665, Loss: 0.09783757477998734, Final Batch Loss: 0.06553108245134354\n",
      "Epoch 3666, Loss: 0.07070337422192097, Final Batch Loss: 0.014314563944935799\n",
      "Epoch 3667, Loss: 0.12053781747817993, Final Batch Loss: 0.07619693875312805\n",
      "Epoch 3668, Loss: 0.08941856399178505, Final Batch Loss: 0.03903622925281525\n",
      "Epoch 3669, Loss: 0.09834993816912174, Final Batch Loss: 0.030721696093678474\n",
      "Epoch 3670, Loss: 0.10621438920497894, Final Batch Loss: 0.04325377941131592\n",
      "Epoch 3671, Loss: 0.11122012790292501, Final Batch Loss: 0.09638909250497818\n",
      "Epoch 3672, Loss: 0.11405103653669357, Final Batch Loss: 0.0759919136762619\n",
      "Epoch 3673, Loss: 0.10943469032645226, Final Batch Loss: 0.03357357159256935\n",
      "Epoch 3674, Loss: 0.18861955404281616, Final Batch Loss: 0.15024970471858978\n",
      "Epoch 3675, Loss: 0.16895784437656403, Final Batch Loss: 0.06526701152324677\n",
      "Epoch 3676, Loss: 0.06405170634388924, Final Batch Loss: 0.03400688245892525\n",
      "Epoch 3677, Loss: 0.09916737489402294, Final Batch Loss: 0.069276824593544\n",
      "Epoch 3678, Loss: 0.08963115885853767, Final Batch Loss: 0.048089105635881424\n",
      "Epoch 3679, Loss: 0.1177622377872467, Final Batch Loss: 0.08630864322185516\n",
      "Epoch 3680, Loss: 0.05191580951213837, Final Batch Loss: 0.023086480796337128\n",
      "Epoch 3681, Loss: 0.13918105699121952, Final Batch Loss: 0.024845102801918983\n",
      "Epoch 3682, Loss: 0.13345130532979965, Final Batch Loss: 0.06787710636854172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3683, Loss: 0.11994118243455887, Final Batch Loss: 0.0551866814494133\n",
      "Epoch 3684, Loss: 0.09530049003660679, Final Batch Loss: 0.0725099965929985\n",
      "Epoch 3685, Loss: 0.09119906648993492, Final Batch Loss: 0.060544610023498535\n",
      "Epoch 3686, Loss: 0.13709184154868126, Final Batch Loss: 0.09257704019546509\n",
      "Epoch 3687, Loss: 0.13713684305548668, Final Batch Loss: 0.1002022847533226\n",
      "Epoch 3688, Loss: 0.08073598332703114, Final Batch Loss: 0.015151465311646461\n",
      "Epoch 3689, Loss: 0.08759807050228119, Final Batch Loss: 0.05564812198281288\n",
      "Epoch 3690, Loss: 0.07588151656091213, Final Batch Loss: 0.02828710339963436\n",
      "Epoch 3691, Loss: 0.05762733891606331, Final Batch Loss: 0.014500714838504791\n",
      "Epoch 3692, Loss: 0.058620985597372055, Final Batch Loss: 0.028626084327697754\n",
      "Epoch 3693, Loss: 0.13972582668066025, Final Batch Loss: 0.09107786417007446\n",
      "Epoch 3694, Loss: 0.08067018911242485, Final Batch Loss: 0.02039007470011711\n",
      "Epoch 3695, Loss: 0.04768076166510582, Final Batch Loss: 0.024320799857378006\n",
      "Epoch 3696, Loss: 0.1341477409005165, Final Batch Loss: 0.02195725589990616\n",
      "Epoch 3697, Loss: 0.057080790400505066, Final Batch Loss: 0.02316291257739067\n",
      "Epoch 3698, Loss: 0.08235030993819237, Final Batch Loss: 0.0446302630007267\n",
      "Epoch 3699, Loss: 0.05154184252023697, Final Batch Loss: 0.014813724905252457\n",
      "Epoch 3700, Loss: 0.11165402457118034, Final Batch Loss: 0.05924331769347191\n",
      "Epoch 3701, Loss: 0.05941522866487503, Final Batch Loss: 0.020225364714860916\n",
      "Epoch 3702, Loss: 0.04873330891132355, Final Batch Loss: 0.020459095016121864\n",
      "Epoch 3703, Loss: 0.07024874165654182, Final Batch Loss: 0.04792508855462074\n",
      "Epoch 3704, Loss: 0.05933092162013054, Final Batch Loss: 0.03130384534597397\n",
      "Epoch 3705, Loss: 0.06443611159920692, Final Batch Loss: 0.05224820226430893\n",
      "Epoch 3706, Loss: 0.0687265694141388, Final Batch Loss: 0.03346610814332962\n",
      "Epoch 3707, Loss: 0.07011429592967033, Final Batch Loss: 0.05343356356024742\n",
      "Epoch 3708, Loss: 0.05672086030244827, Final Batch Loss: 0.026136556640267372\n",
      "Epoch 3709, Loss: 0.04112837836146355, Final Batch Loss: 0.027531085535883904\n",
      "Epoch 3710, Loss: 0.046052053570747375, Final Batch Loss: 0.020183028653264046\n",
      "Epoch 3711, Loss: 0.0415224926546216, Final Batch Loss: 0.012155414558947086\n",
      "Epoch 3712, Loss: 0.03930196352303028, Final Batch Loss: 0.01558658853173256\n",
      "Epoch 3713, Loss: 0.07479300908744335, Final Batch Loss: 0.04810936748981476\n",
      "Epoch 3714, Loss: 0.05931575037539005, Final Batch Loss: 0.026911428198218346\n",
      "Epoch 3715, Loss: 0.14389272406697273, Final Batch Loss: 0.11188575625419617\n",
      "Epoch 3716, Loss: 0.06803885474801064, Final Batch Loss: 0.02051369473338127\n",
      "Epoch 3717, Loss: 0.07489042729139328, Final Batch Loss: 0.034028004854917526\n",
      "Epoch 3718, Loss: 0.1554449200630188, Final Batch Loss: 0.11059186607599258\n",
      "Epoch 3719, Loss: 0.03027921635657549, Final Batch Loss: 0.008119077421724796\n",
      "Epoch 3720, Loss: 0.06968597695231438, Final Batch Loss: 0.028473328799009323\n",
      "Epoch 3721, Loss: 0.04467801842838526, Final Batch Loss: 0.010307257063686848\n",
      "Epoch 3722, Loss: 0.09235458076000214, Final Batch Loss: 0.06417203694581985\n",
      "Epoch 3723, Loss: 0.06418033316731453, Final Batch Loss: 0.03699307516217232\n",
      "Epoch 3724, Loss: 0.08526885509490967, Final Batch Loss: 0.02079586684703827\n",
      "Epoch 3725, Loss: 0.0823923833668232, Final Batch Loss: 0.04342278465628624\n",
      "Epoch 3726, Loss: 0.054327456280589104, Final Batch Loss: 0.028676539659500122\n",
      "Epoch 3727, Loss: 0.04749097162857652, Final Batch Loss: 0.005464079324156046\n",
      "Epoch 3728, Loss: 0.12021299824118614, Final Batch Loss: 0.096278615295887\n",
      "Epoch 3729, Loss: 0.04181630164384842, Final Batch Loss: 0.010915165767073631\n",
      "Epoch 3730, Loss: 0.07538128644227982, Final Batch Loss: 0.0380479171872139\n",
      "Epoch 3731, Loss: 0.0709119364619255, Final Batch Loss: 0.011530935764312744\n",
      "Epoch 3732, Loss: 0.0720665268599987, Final Batch Loss: 0.04891372099518776\n",
      "Epoch 3733, Loss: 0.035267423838377, Final Batch Loss: 0.012732235714793205\n",
      "Epoch 3734, Loss: 0.06383994221687317, Final Batch Loss: 0.01776251569390297\n",
      "Epoch 3735, Loss: 0.07177245803177357, Final Batch Loss: 0.04745960608124733\n",
      "Epoch 3736, Loss: 0.044923266395926476, Final Batch Loss: 0.014542629942297935\n",
      "Epoch 3737, Loss: 0.066031607799232, Final Batch Loss: 0.015143322758376598\n",
      "Epoch 3738, Loss: 0.06250656582415104, Final Batch Loss: 0.02359582670032978\n",
      "Epoch 3739, Loss: 0.07383020967245102, Final Batch Loss: 0.028353411704301834\n",
      "Epoch 3740, Loss: 0.06828726455569267, Final Batch Loss: 0.03621738404035568\n",
      "Epoch 3741, Loss: 0.1372092068195343, Final Batch Loss: 0.0912904292345047\n",
      "Epoch 3742, Loss: 0.04891691356897354, Final Batch Loss: 0.0363815501332283\n",
      "Epoch 3743, Loss: 0.05591796711087227, Final Batch Loss: 0.016158636659383774\n",
      "Epoch 3744, Loss: 0.04944235924631357, Final Batch Loss: 0.01274909172207117\n",
      "Epoch 3745, Loss: 0.05217643082141876, Final Batch Loss: 0.007893484085798264\n",
      "Epoch 3746, Loss: 0.08758089691400528, Final Batch Loss: 0.04662448912858963\n",
      "Epoch 3747, Loss: 0.1043138187378645, Final Batch Loss: 0.07600364089012146\n",
      "Epoch 3748, Loss: 0.06715892255306244, Final Batch Loss: 0.051119714975357056\n",
      "Epoch 3749, Loss: 0.05416689533740282, Final Batch Loss: 0.015557670034468174\n",
      "Epoch 3750, Loss: 0.093447245657444, Final Batch Loss: 0.05947684124112129\n",
      "Epoch 3751, Loss: 0.04981639143079519, Final Batch Loss: 0.04070998355746269\n",
      "Epoch 3752, Loss: 0.059754155576229095, Final Batch Loss: 0.03507573902606964\n",
      "Epoch 3753, Loss: 0.055283596739172935, Final Batch Loss: 0.018834413960576057\n",
      "Epoch 3754, Loss: 0.07124121487140656, Final Batch Loss: 0.05501549318432808\n",
      "Epoch 3755, Loss: 0.0866929180920124, Final Batch Loss: 0.044948406517505646\n",
      "Epoch 3756, Loss: 0.12275422364473343, Final Batch Loss: 0.08931054919958115\n",
      "Epoch 3757, Loss: 0.07346880063414574, Final Batch Loss: 0.024378858506679535\n",
      "Epoch 3758, Loss: 0.06984874792397022, Final Batch Loss: 0.015762006863951683\n",
      "Epoch 3759, Loss: 0.09767241589725018, Final Batch Loss: 0.029323821887373924\n",
      "Epoch 3760, Loss: 0.13749486580491066, Final Batch Loss: 0.1206955686211586\n",
      "Epoch 3761, Loss: 0.07069684751331806, Final Batch Loss: 0.029758287593722343\n",
      "Epoch 3762, Loss: 0.05996624194085598, Final Batch Loss: 0.020911192521452904\n",
      "Epoch 3763, Loss: 0.04805853217840195, Final Batch Loss: 0.017948215827345848\n",
      "Epoch 3764, Loss: 0.06316902115941048, Final Batch Loss: 0.016580909490585327\n",
      "Epoch 3765, Loss: 0.08731766417622566, Final Batch Loss: 0.05235281214118004\n",
      "Epoch 3766, Loss: 0.06175069324672222, Final Batch Loss: 0.03183494135737419\n",
      "Epoch 3767, Loss: 0.04715952277183533, Final Batch Loss: 0.009807251393795013\n",
      "Epoch 3768, Loss: 0.07110142707824707, Final Batch Loss: 0.042497310787439346\n",
      "Epoch 3769, Loss: 0.05731914471834898, Final Batch Loss: 0.010575464926660061\n",
      "Epoch 3770, Loss: 0.0704524889588356, Final Batch Loss: 0.03711109235882759\n",
      "Epoch 3771, Loss: 0.1040978766977787, Final Batch Loss: 0.06228475645184517\n",
      "Epoch 3772, Loss: 0.026799838989973068, Final Batch Loss: 0.01377947349101305\n",
      "Epoch 3773, Loss: 0.0397209944203496, Final Batch Loss: 0.025828024372458458\n",
      "Epoch 3774, Loss: 0.0699848085641861, Final Batch Loss: 0.008106034249067307\n",
      "Epoch 3775, Loss: 0.07669972255825996, Final Batch Loss: 0.06729400157928467\n",
      "Epoch 3776, Loss: 0.06465330719947815, Final Batch Loss: 0.020737741142511368\n",
      "Epoch 3777, Loss: 0.04750026576220989, Final Batch Loss: 0.02080237865447998\n",
      "Epoch 3778, Loss: 0.07740370184183121, Final Batch Loss: 0.045085884630680084\n",
      "Epoch 3779, Loss: 0.04501483216881752, Final Batch Loss: 0.017032038420438766\n",
      "Epoch 3780, Loss: 0.03678171243518591, Final Batch Loss: 0.024862920865416527\n",
      "Epoch 3781, Loss: 0.06374375522136688, Final Batch Loss: 0.03133375942707062\n",
      "Epoch 3782, Loss: 0.037397079169750214, Final Batch Loss: 0.015355609357357025\n",
      "Epoch 3783, Loss: 0.11192857846617699, Final Batch Loss: 0.055955562740564346\n",
      "Epoch 3784, Loss: 0.04892809875309467, Final Batch Loss: 0.015130309388041496\n",
      "Epoch 3785, Loss: 0.057945518754422665, Final Batch Loss: 0.012194483540952206\n",
      "Epoch 3786, Loss: 0.0979048851877451, Final Batch Loss: 0.021034622564911842\n",
      "Epoch 3787, Loss: 0.06174488365650177, Final Batch Loss: 0.026903271675109863\n",
      "Epoch 3788, Loss: 0.06427369825541973, Final Batch Loss: 0.025837158784270287\n",
      "Epoch 3789, Loss: 0.07007430493831635, Final Batch Loss: 0.016811557114124298\n",
      "Epoch 3790, Loss: 0.08978579565882683, Final Batch Loss: 0.02871096506714821\n",
      "Epoch 3791, Loss: 0.0614637415856123, Final Batch Loss: 0.03689102828502655\n",
      "Epoch 3792, Loss: 0.045961642637848854, Final Batch Loss: 0.025375520810484886\n",
      "Epoch 3793, Loss: 0.051920849829912186, Final Batch Loss: 0.01070687547326088\n",
      "Epoch 3794, Loss: 0.11204250156879425, Final Batch Loss: 0.03163432329893112\n",
      "Epoch 3795, Loss: 0.06729829497635365, Final Batch Loss: 0.04231562465429306\n",
      "Epoch 3796, Loss: 0.08682521060109138, Final Batch Loss: 0.03503596410155296\n",
      "Epoch 3797, Loss: 0.06014174781739712, Final Batch Loss: 0.041447896510362625\n",
      "Epoch 3798, Loss: 0.0713910274207592, Final Batch Loss: 0.03258143737912178\n",
      "Epoch 3799, Loss: 0.05891174543648958, Final Batch Loss: 0.014655631966888905\n",
      "Epoch 3800, Loss: 0.05475764907896519, Final Batch Loss: 0.033157460391521454\n",
      "Epoch 3801, Loss: 0.036553981713950634, Final Batch Loss: 0.012555683963000774\n",
      "Epoch 3802, Loss: 0.09065849334001541, Final Batch Loss: 0.03199666738510132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3803, Loss: 0.054747878573834896, Final Batch Loss: 0.00761586707085371\n",
      "Epoch 3804, Loss: 0.04645637422800064, Final Batch Loss: 0.019184749573469162\n",
      "Epoch 3805, Loss: 0.0876988023519516, Final Batch Loss: 0.03538073971867561\n",
      "Epoch 3806, Loss: 0.10058596730232239, Final Batch Loss: 0.06507556140422821\n",
      "Epoch 3807, Loss: 0.053249744698405266, Final Batch Loss: 0.015006041154265404\n",
      "Epoch 3808, Loss: 0.06012875400483608, Final Batch Loss: 0.021791545674204826\n",
      "Epoch 3809, Loss: 0.1662861667573452, Final Batch Loss: 0.13892588019371033\n",
      "Epoch 3810, Loss: 0.08467409200966358, Final Batch Loss: 0.027949126437306404\n",
      "Epoch 3811, Loss: 0.08889571204781532, Final Batch Loss: 0.02503081038594246\n",
      "Epoch 3812, Loss: 0.07301723584532738, Final Batch Loss: 0.06276477873325348\n",
      "Epoch 3813, Loss: 0.15759627521038055, Final Batch Loss: 0.09844118356704712\n",
      "Epoch 3814, Loss: 0.11872454732656479, Final Batch Loss: 0.0311952605843544\n",
      "Epoch 3815, Loss: 0.06786436215043068, Final Batch Loss: 0.03264657035470009\n",
      "Epoch 3816, Loss: 0.11372542008757591, Final Batch Loss: 0.08197008818387985\n",
      "Epoch 3817, Loss: 0.14422203227877617, Final Batch Loss: 0.06166084483265877\n",
      "Epoch 3818, Loss: 0.13471001386642456, Final Batch Loss: 0.07493089139461517\n",
      "Epoch 3819, Loss: 0.06885170750319958, Final Batch Loss: 0.028361080214381218\n",
      "Epoch 3820, Loss: 0.07434221357107162, Final Batch Loss: 0.041951533406972885\n",
      "Epoch 3821, Loss: 0.10263220965862274, Final Batch Loss: 0.055740512907505035\n",
      "Epoch 3822, Loss: 0.14053314551711082, Final Batch Loss: 0.10884854942560196\n",
      "Epoch 3823, Loss: 0.11809274181723595, Final Batch Loss: 0.0690205842256546\n",
      "Epoch 3824, Loss: 0.19540485739707947, Final Batch Loss: 0.13414333760738373\n",
      "Epoch 3825, Loss: 0.05201089382171631, Final Batch Loss: 0.01891179382801056\n",
      "Epoch 3826, Loss: 0.07441320829093456, Final Batch Loss: 0.05065227672457695\n",
      "Epoch 3827, Loss: 0.18426067382097244, Final Batch Loss: 0.0844946950674057\n",
      "Epoch 3828, Loss: 0.08791767433285713, Final Batch Loss: 0.042283713817596436\n",
      "Epoch 3829, Loss: 0.06743315793573856, Final Batch Loss: 0.011264225468039513\n",
      "Epoch 3830, Loss: 0.06965101137757301, Final Batch Loss: 0.02439074218273163\n",
      "Epoch 3831, Loss: 0.08125627040863037, Final Batch Loss: 0.04643446207046509\n",
      "Epoch 3832, Loss: 0.1202017217874527, Final Batch Loss: 0.08295148611068726\n",
      "Epoch 3833, Loss: 0.06591103225946426, Final Batch Loss: 0.03237786516547203\n",
      "Epoch 3834, Loss: 0.05945157632231712, Final Batch Loss: 0.023540295660495758\n",
      "Epoch 3835, Loss: 0.055293552577495575, Final Batch Loss: 0.037750907242298126\n",
      "Epoch 3836, Loss: 0.06953512318432331, Final Batch Loss: 0.047788456082344055\n",
      "Epoch 3837, Loss: 0.10705772042274475, Final Batch Loss: 0.06851813942193985\n",
      "Epoch 3838, Loss: 0.05914538353681564, Final Batch Loss: 0.019729547202587128\n",
      "Epoch 3839, Loss: 0.05944124981760979, Final Batch Loss: 0.01635795459151268\n",
      "Epoch 3840, Loss: 0.08673888444900513, Final Batch Loss: 0.05512838438153267\n",
      "Epoch 3841, Loss: 0.06815380044281483, Final Batch Loss: 0.027684858068823814\n",
      "Epoch 3842, Loss: 0.0518566332757473, Final Batch Loss: 0.022776398807764053\n",
      "Epoch 3843, Loss: 0.08585365116596222, Final Batch Loss: 0.061784226447343826\n",
      "Epoch 3844, Loss: 0.047716048546135426, Final Batch Loss: 0.012914245016872883\n",
      "Epoch 3845, Loss: 0.09587373957037926, Final Batch Loss: 0.04465382546186447\n",
      "Epoch 3846, Loss: 0.08320214040577412, Final Batch Loss: 0.06093774363398552\n",
      "Epoch 3847, Loss: 0.05858522839844227, Final Batch Loss: 0.02476859651505947\n",
      "Epoch 3848, Loss: 0.042433952912688255, Final Batch Loss: 0.023219013586640358\n",
      "Epoch 3849, Loss: 0.13441627472639084, Final Batch Loss: 0.054955631494522095\n",
      "Epoch 3850, Loss: 0.13100693747401237, Final Batch Loss: 0.035857852548360825\n",
      "Epoch 3851, Loss: 0.040000297129154205, Final Batch Loss: 0.02130449377000332\n",
      "Epoch 3852, Loss: 0.04166411515325308, Final Batch Loss: 0.02934495359659195\n",
      "Epoch 3853, Loss: 0.12819932401180267, Final Batch Loss: 0.09482292830944061\n",
      "Epoch 3854, Loss: 0.14390021562576294, Final Batch Loss: 0.10512734204530716\n",
      "Epoch 3855, Loss: 0.093929722905159, Final Batch Loss: 0.05586959049105644\n",
      "Epoch 3856, Loss: 0.10058946162462234, Final Batch Loss: 0.06045500561594963\n",
      "Epoch 3857, Loss: 0.043816063553094864, Final Batch Loss: 0.025275763124227524\n",
      "Epoch 3858, Loss: 0.07149208150804043, Final Batch Loss: 0.013756012544035912\n",
      "Epoch 3859, Loss: 0.05815877020359039, Final Batch Loss: 0.006709069013595581\n",
      "Epoch 3860, Loss: 0.09886226244270802, Final Batch Loss: 0.08136574923992157\n",
      "Epoch 3861, Loss: 0.07966211251914501, Final Batch Loss: 0.016657760366797447\n",
      "Epoch 3862, Loss: 0.06918053328990936, Final Batch Loss: 0.03256552666425705\n",
      "Epoch 3863, Loss: 0.050701720640063286, Final Batch Loss: 0.029200956225395203\n",
      "Epoch 3864, Loss: 0.07882523909211159, Final Batch Loss: 0.05564342066645622\n",
      "Epoch 3865, Loss: 0.08712368831038475, Final Batch Loss: 0.05133415758609772\n",
      "Epoch 3866, Loss: 0.04574914835393429, Final Batch Loss: 0.012552199885249138\n",
      "Epoch 3867, Loss: 0.192737877368927, Final Batch Loss: 0.09294147789478302\n",
      "Epoch 3868, Loss: 0.03297118376940489, Final Batch Loss: 0.010393531061708927\n",
      "Epoch 3869, Loss: 0.10197887197136879, Final Batch Loss: 0.0618167407810688\n",
      "Epoch 3870, Loss: 0.05611823685467243, Final Batch Loss: 0.03409622982144356\n",
      "Epoch 3871, Loss: 0.06826627161353827, Final Batch Loss: 0.05283861234784126\n",
      "Epoch 3872, Loss: 0.06943431869149208, Final Batch Loss: 0.04936075210571289\n",
      "Epoch 3873, Loss: 0.0696878582239151, Final Batch Loss: 0.020057134330272675\n",
      "Epoch 3874, Loss: 0.08162393048405647, Final Batch Loss: 0.03236978501081467\n",
      "Epoch 3875, Loss: 0.14225775003433228, Final Batch Loss: 0.08487983793020248\n",
      "Epoch 3876, Loss: 0.10952858440577984, Final Batch Loss: 0.09226319938898087\n",
      "Epoch 3877, Loss: 0.2253670059144497, Final Batch Loss: 0.20524226129055023\n",
      "Epoch 3878, Loss: 0.07968868408352137, Final Batch Loss: 0.010891043581068516\n",
      "Epoch 3879, Loss: 0.09195155650377274, Final Batch Loss: 0.056645821779966354\n",
      "Epoch 3880, Loss: 0.05297929607331753, Final Batch Loss: 0.03458734601736069\n",
      "Epoch 3881, Loss: 0.1938048154115677, Final Batch Loss: 0.0887594223022461\n",
      "Epoch 3882, Loss: 0.0595365185290575, Final Batch Loss: 0.03185474872589111\n",
      "Epoch 3883, Loss: 0.07894722744822502, Final Batch Loss: 0.03776687756180763\n",
      "Epoch 3884, Loss: 0.06861233152449131, Final Batch Loss: 0.02910354919731617\n",
      "Epoch 3885, Loss: 0.0676507018506527, Final Batch Loss: 0.02676965668797493\n",
      "Epoch 3886, Loss: 0.059836968779563904, Final Batch Loss: 0.03438055142760277\n",
      "Epoch 3887, Loss: 0.063147759065032, Final Batch Loss: 0.026373131200671196\n",
      "Epoch 3888, Loss: 0.054265597835183144, Final Batch Loss: 0.017000248655676842\n",
      "Epoch 3889, Loss: 0.08238833956420422, Final Batch Loss: 0.023368222638964653\n",
      "Epoch 3890, Loss: 0.06488323025405407, Final Batch Loss: 0.02361227758228779\n",
      "Epoch 3891, Loss: 0.05544804409146309, Final Batch Loss: 0.028183460235595703\n",
      "Epoch 3892, Loss: 0.056885579600930214, Final Batch Loss: 0.022738950327038765\n",
      "Epoch 3893, Loss: 0.06868211645632982, Final Batch Loss: 0.05558732897043228\n",
      "Epoch 3894, Loss: 0.10045739263296127, Final Batch Loss: 0.07658092677593231\n",
      "Epoch 3895, Loss: 0.05738402530550957, Final Batch Loss: 0.027882881462574005\n",
      "Epoch 3896, Loss: 0.054507097229361534, Final Batch Loss: 0.018212521448731422\n",
      "Epoch 3897, Loss: 0.06716806627810001, Final Batch Loss: 0.029628092423081398\n",
      "Epoch 3898, Loss: 0.07568207383155823, Final Batch Loss: 0.03798771649599075\n",
      "Epoch 3899, Loss: 0.07344245910644531, Final Batch Loss: 0.04407741501927376\n",
      "Epoch 3900, Loss: 0.05884834565222263, Final Batch Loss: 0.041064221411943436\n",
      "Epoch 3901, Loss: 0.054784297943115234, Final Batch Loss: 0.015962257981300354\n",
      "Epoch 3902, Loss: 0.06707329489290714, Final Batch Loss: 0.039141543209552765\n",
      "Epoch 3903, Loss: 0.06229742430150509, Final Batch Loss: 0.02671164460480213\n",
      "Epoch 3904, Loss: 0.10984515398740768, Final Batch Loss: 0.0403301939368248\n",
      "Epoch 3905, Loss: 0.0492548868060112, Final Batch Loss: 0.013758119195699692\n",
      "Epoch 3906, Loss: 0.1922409012913704, Final Batch Loss: 0.01808292418718338\n",
      "Epoch 3907, Loss: 0.05347580090165138, Final Batch Loss: 0.0184377059340477\n",
      "Epoch 3908, Loss: 0.05356481298804283, Final Batch Loss: 0.01698160544037819\n",
      "Epoch 3909, Loss: 0.0880750585347414, Final Batch Loss: 0.019548462703824043\n",
      "Epoch 3910, Loss: 0.03681510500609875, Final Batch Loss: 0.020499229431152344\n",
      "Epoch 3911, Loss: 0.06102559994906187, Final Batch Loss: 0.013883094303309917\n",
      "Epoch 3912, Loss: 0.06909819133579731, Final Batch Loss: 0.04087001457810402\n",
      "Epoch 3913, Loss: 0.0797913707792759, Final Batch Loss: 0.028909262269735336\n",
      "Epoch 3914, Loss: 0.07576973363757133, Final Batch Loss: 0.03860510140657425\n",
      "Epoch 3915, Loss: 0.04438861273229122, Final Batch Loss: 0.02218393236398697\n",
      "Epoch 3916, Loss: 0.02436498925089836, Final Batch Loss: 0.009072365239262581\n",
      "Epoch 3917, Loss: 0.11593517661094666, Final Batch Loss: 0.06384109705686569\n",
      "Epoch 3918, Loss: 0.08236134983599186, Final Batch Loss: 0.0250896904617548\n",
      "Epoch 3919, Loss: 0.027247882448136806, Final Batch Loss: 0.012987152673304081\n",
      "Epoch 3920, Loss: 0.03886366914957762, Final Batch Loss: 0.02495558001101017\n",
      "Epoch 3921, Loss: 0.09009017795324326, Final Batch Loss: 0.07042860984802246\n",
      "Epoch 3922, Loss: 0.08406831882894039, Final Batch Loss: 0.019800899550318718\n",
      "Epoch 3923, Loss: 0.13563691079616547, Final Batch Loss: 0.05795352905988693\n",
      "Epoch 3924, Loss: 0.045089710503816605, Final Batch Loss: 0.01796538010239601\n",
      "Epoch 3925, Loss: 0.05549579858779907, Final Batch Loss: 0.017755765467882156\n",
      "Epoch 3926, Loss: 0.07601479813456535, Final Batch Loss: 0.03202943876385689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3927, Loss: 0.03773022163659334, Final Batch Loss: 0.014372640289366245\n",
      "Epoch 3928, Loss: 0.0650116465985775, Final Batch Loss: 0.031811006367206573\n",
      "Epoch 3929, Loss: 0.06305119954049587, Final Batch Loss: 0.011757304891943932\n",
      "Epoch 3930, Loss: 0.08164922147989273, Final Batch Loss: 0.0458156019449234\n",
      "Epoch 3931, Loss: 0.0722635556012392, Final Batch Loss: 0.021714599803090096\n",
      "Epoch 3932, Loss: 0.06721911765635014, Final Batch Loss: 0.037137966603040695\n",
      "Epoch 3933, Loss: 0.05939343199133873, Final Batch Loss: 0.03341693431138992\n",
      "Epoch 3934, Loss: 0.06527725420892239, Final Batch Loss: 0.03618691861629486\n",
      "Epoch 3935, Loss: 0.0479621971026063, Final Batch Loss: 0.009576988406479359\n",
      "Epoch 3936, Loss: 0.05735290236771107, Final Batch Loss: 0.03514036536216736\n",
      "Epoch 3937, Loss: 0.04686019569635391, Final Batch Loss: 0.023056892678141594\n",
      "Epoch 3938, Loss: 0.043188633397221565, Final Batch Loss: 0.021614443510770798\n",
      "Epoch 3939, Loss: 0.05544732324779034, Final Batch Loss: 0.036905281245708466\n",
      "Epoch 3940, Loss: 0.09800157696008682, Final Batch Loss: 0.01715630292892456\n",
      "Epoch 3941, Loss: 0.1742721125483513, Final Batch Loss: 0.06327216327190399\n",
      "Epoch 3942, Loss: 0.09026248380541801, Final Batch Loss: 0.018268313258886337\n",
      "Epoch 3943, Loss: 0.04611815698444843, Final Batch Loss: 0.016960887238383293\n",
      "Epoch 3944, Loss: 0.0631172489374876, Final Batch Loss: 0.02212834544479847\n",
      "Epoch 3945, Loss: 0.13721150159835815, Final Batch Loss: 0.04555969685316086\n",
      "Epoch 3946, Loss: 0.06672178488224745, Final Batch Loss: 0.05785694718360901\n",
      "Epoch 3947, Loss: 0.07125180773437023, Final Batch Loss: 0.045123301446437836\n",
      "Epoch 3948, Loss: 0.0442646648734808, Final Batch Loss: 0.02137726917862892\n",
      "Epoch 3949, Loss: 0.09161348082125187, Final Batch Loss: 0.018850767984986305\n",
      "Epoch 3950, Loss: 0.03686345927417278, Final Batch Loss: 0.01113143004477024\n",
      "Epoch 3951, Loss: 0.09464643523097038, Final Batch Loss: 0.04807383194565773\n",
      "Epoch 3952, Loss: 0.06844277866184711, Final Batch Loss: 0.03039664961397648\n",
      "Epoch 3953, Loss: 0.06943397969007492, Final Batch Loss: 0.03821674361824989\n",
      "Epoch 3954, Loss: 0.04251536959782243, Final Batch Loss: 0.005975721869617701\n",
      "Epoch 3955, Loss: 0.05185779929161072, Final Batch Loss: 0.013460569083690643\n",
      "Epoch 3956, Loss: 0.12081826105713844, Final Batch Loss: 0.06361278891563416\n",
      "Epoch 3957, Loss: 0.05354415066540241, Final Batch Loss: 0.035003677010536194\n",
      "Epoch 3958, Loss: 0.08369572088122368, Final Batch Loss: 0.036547403782606125\n",
      "Epoch 3959, Loss: 0.04639720171689987, Final Batch Loss: 0.0202044490724802\n",
      "Epoch 3960, Loss: 0.07207186333835125, Final Batch Loss: 0.014115987345576286\n",
      "Epoch 3961, Loss: 0.07236479967832565, Final Batch Loss: 0.05405478924512863\n",
      "Epoch 3962, Loss: 0.1278170645236969, Final Batch Loss: 0.0561511367559433\n",
      "Epoch 3963, Loss: 0.042323606088757515, Final Batch Loss: 0.01455909013748169\n",
      "Epoch 3964, Loss: 0.04662681557238102, Final Batch Loss: 0.02735152468085289\n",
      "Epoch 3965, Loss: 0.05303569324314594, Final Batch Loss: 0.031401559710502625\n",
      "Epoch 3966, Loss: 0.04722318425774574, Final Batch Loss: 0.028690723702311516\n",
      "Epoch 3967, Loss: 0.07613831013441086, Final Batch Loss: 0.03395691514015198\n",
      "Epoch 3968, Loss: 0.11943597346544266, Final Batch Loss: 0.06673505902290344\n",
      "Epoch 3969, Loss: 0.06567458063364029, Final Batch Loss: 0.045890238136053085\n",
      "Epoch 3970, Loss: 0.03999084886163473, Final Batch Loss: 0.01306756492704153\n",
      "Epoch 3971, Loss: 0.14591414481401443, Final Batch Loss: 0.1282186508178711\n",
      "Epoch 3972, Loss: 0.05005635228008032, Final Batch Loss: 0.012931990437209606\n",
      "Epoch 3973, Loss: 0.07219101395457983, Final Batch Loss: 0.05899767950177193\n",
      "Epoch 3974, Loss: 0.04605509713292122, Final Batch Loss: 0.025677135214209557\n",
      "Epoch 3975, Loss: 0.06912379898130894, Final Batch Loss: 0.031241679564118385\n",
      "Epoch 3976, Loss: 0.03301308397203684, Final Batch Loss: 0.011919328011572361\n",
      "Epoch 3977, Loss: 0.10396354272961617, Final Batch Loss: 0.07396439462900162\n",
      "Epoch 3978, Loss: 0.020245951134711504, Final Batch Loss: 0.007028650958091021\n",
      "Epoch 3979, Loss: 0.06653851503506303, Final Batch Loss: 0.005888944957405329\n",
      "Epoch 3980, Loss: 0.07848039269447327, Final Batch Loss: 0.051148928701877594\n",
      "Epoch 3981, Loss: 0.0922955647110939, Final Batch Loss: 0.03981151804327965\n",
      "Epoch 3982, Loss: 0.06529954634606838, Final Batch Loss: 0.04683051258325577\n",
      "Epoch 3983, Loss: 0.06468628346920013, Final Batch Loss: 0.04652149975299835\n",
      "Epoch 3984, Loss: 0.08828523010015488, Final Batch Loss: 0.040043026208877563\n",
      "Epoch 3985, Loss: 0.036538016982376575, Final Batch Loss: 0.01284595113247633\n",
      "Epoch 3986, Loss: 0.05908377841114998, Final Batch Loss: 0.013246174901723862\n",
      "Epoch 3987, Loss: 0.09185704402625561, Final Batch Loss: 0.06583090126514435\n",
      "Epoch 3988, Loss: 0.1439250335097313, Final Batch Loss: 0.0802532210946083\n",
      "Epoch 3989, Loss: 0.09876525960862637, Final Batch Loss: 0.0792630985379219\n",
      "Epoch 3990, Loss: 0.047160860151052475, Final Batch Loss: 0.029369214549660683\n",
      "Epoch 3991, Loss: 0.07328144647181034, Final Batch Loss: 0.05255880951881409\n",
      "Epoch 3992, Loss: 0.1021990031003952, Final Batch Loss: 0.03510068356990814\n",
      "Epoch 3993, Loss: 0.08647016994655132, Final Batch Loss: 0.016541613265872\n",
      "Epoch 3994, Loss: 0.04427921958267689, Final Batch Loss: 0.026265770196914673\n",
      "Epoch 3995, Loss: 0.11707667633891106, Final Batch Loss: 0.07341818511486053\n",
      "Epoch 3996, Loss: 0.05393390171229839, Final Batch Loss: 0.022937096655368805\n",
      "Epoch 3997, Loss: 0.0877540372312069, Final Batch Loss: 0.05811776965856552\n",
      "Epoch 3998, Loss: 0.050944734364748, Final Batch Loss: 0.018081575632095337\n",
      "Epoch 3999, Loss: 0.045974375680089, Final Batch Loss: 0.02666281908750534\n",
      "Epoch 4000, Loss: 0.07010105717927217, Final Batch Loss: 0.014750734902918339\n",
      "Epoch 4001, Loss: 0.0922204926609993, Final Batch Loss: 0.05441763624548912\n",
      "Epoch 4002, Loss: 0.06766219809651375, Final Batch Loss: 0.02747279405593872\n",
      "Epoch 4003, Loss: 0.08468107134103775, Final Batch Loss: 0.06033192202448845\n",
      "Epoch 4004, Loss: 0.07411589287221432, Final Batch Loss: 0.04714897274971008\n",
      "Epoch 4005, Loss: 0.07104393467307091, Final Batch Loss: 0.029480058699846268\n",
      "Epoch 4006, Loss: 0.0936835017055273, Final Batch Loss: 0.022504283115267754\n",
      "Epoch 4007, Loss: 0.0512631181627512, Final Batch Loss: 0.01844625733792782\n",
      "Epoch 4008, Loss: 0.09926128387451172, Final Batch Loss: 0.060402125120162964\n",
      "Epoch 4009, Loss: 0.0800110399723053, Final Batch Loss: 0.04474961385130882\n",
      "Epoch 4010, Loss: 0.050655778497457504, Final Batch Loss: 0.031611938029527664\n",
      "Epoch 4011, Loss: 0.07683569192886353, Final Batch Loss: 0.04058828949928284\n",
      "Epoch 4012, Loss: 0.049953706562519073, Final Batch Loss: 0.026104899123311043\n",
      "Epoch 4013, Loss: 0.0458952859044075, Final Batch Loss: 0.02410721406340599\n",
      "Epoch 4014, Loss: 0.06399627029895782, Final Batch Loss: 0.029832985252141953\n",
      "Epoch 4015, Loss: 0.11514668446034193, Final Batch Loss: 0.10232605785131454\n",
      "Epoch 4016, Loss: 0.04840957932174206, Final Batch Loss: 0.031682420521974564\n",
      "Epoch 4017, Loss: 0.05120649002492428, Final Batch Loss: 0.03455520421266556\n",
      "Epoch 4018, Loss: 0.0549955777823925, Final Batch Loss: 0.025210799649357796\n",
      "Epoch 4019, Loss: 0.06386513635516167, Final Batch Loss: 0.018100623041391373\n",
      "Epoch 4020, Loss: 0.10986565425992012, Final Batch Loss: 0.0657203197479248\n",
      "Epoch 4021, Loss: 0.12176303751766682, Final Batch Loss: 0.029253752902150154\n",
      "Epoch 4022, Loss: 0.042440805584192276, Final Batch Loss: 0.02678702585399151\n",
      "Epoch 4023, Loss: 0.11008368618786335, Final Batch Loss: 0.027867736294865608\n",
      "Epoch 4024, Loss: 0.07456652447581291, Final Batch Loss: 0.03638098016381264\n",
      "Epoch 4025, Loss: 0.07162261568009853, Final Batch Loss: 0.02323639579117298\n",
      "Epoch 4026, Loss: 0.053458381444215775, Final Batch Loss: 0.01657634973526001\n",
      "Epoch 4027, Loss: 0.1007872810587287, Final Batch Loss: 0.01225836481899023\n",
      "Epoch 4028, Loss: 0.06967307813465595, Final Batch Loss: 0.031055716797709465\n",
      "Epoch 4029, Loss: 0.04995416849851608, Final Batch Loss: 0.02616826444864273\n",
      "Epoch 4030, Loss: 0.0792219452559948, Final Batch Loss: 0.050961144268512726\n",
      "Epoch 4031, Loss: 0.0650185439735651, Final Batch Loss: 0.01754618249833584\n",
      "Epoch 4032, Loss: 0.03880656138062477, Final Batch Loss: 0.020474225282669067\n",
      "Epoch 4033, Loss: 0.09585219621658325, Final Batch Loss: 0.057131845504045486\n",
      "Epoch 4034, Loss: 0.08511935919523239, Final Batch Loss: 0.0671587809920311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4035, Loss: 0.05818754993379116, Final Batch Loss: 0.03238412365317345\n",
      "Epoch 4036, Loss: 0.07654002960771322, Final Batch Loss: 0.009681097231805325\n",
      "Epoch 4037, Loss: 0.04920920170843601, Final Batch Loss: 0.017137320712208748\n",
      "Epoch 4038, Loss: 0.06847905926406384, Final Batch Loss: 0.02495061419904232\n",
      "Epoch 4039, Loss: 0.07275187969207764, Final Batch Loss: 0.01697516068816185\n",
      "Epoch 4040, Loss: 0.16321024298667908, Final Batch Loss: 0.0756542757153511\n",
      "Epoch 4041, Loss: 0.06418155506253242, Final Batch Loss: 0.01898561418056488\n",
      "Epoch 4042, Loss: 0.027892084792256355, Final Batch Loss: 0.011305144056677818\n",
      "Epoch 4043, Loss: 0.128019779920578, Final Batch Loss: 0.06524600833654404\n",
      "Epoch 4044, Loss: 0.05713336542248726, Final Batch Loss: 0.02728446014225483\n",
      "Epoch 4045, Loss: 0.0814597774296999, Final Batch Loss: 0.05761902406811714\n",
      "Epoch 4046, Loss: 0.07032196410000324, Final Batch Loss: 0.04526621103286743\n",
      "Epoch 4047, Loss: 0.03424807917326689, Final Batch Loss: 0.013546028174459934\n",
      "Epoch 4048, Loss: 0.05761263892054558, Final Batch Loss: 0.027241794392466545\n",
      "Epoch 4049, Loss: 0.05255415290594101, Final Batch Loss: 0.02335132472217083\n",
      "Epoch 4050, Loss: 0.06542424857616425, Final Batch Loss: 0.05179760232567787\n",
      "Epoch 4051, Loss: 0.05885639414191246, Final Batch Loss: 0.023321721702814102\n",
      "Epoch 4052, Loss: 0.07570870034396648, Final Batch Loss: 0.046029042452573776\n",
      "Epoch 4053, Loss: 0.11867405474185944, Final Batch Loss: 0.08302867412567139\n",
      "Epoch 4054, Loss: 0.04561284929513931, Final Batch Loss: 0.026369230821728706\n",
      "Epoch 4055, Loss: 0.08603246137499809, Final Batch Loss: 0.036097779870033264\n",
      "Epoch 4056, Loss: 0.08749707043170929, Final Batch Loss: 0.044690169394016266\n",
      "Epoch 4057, Loss: 0.04323936230503023, Final Batch Loss: 0.003271218156442046\n",
      "Epoch 4058, Loss: 0.10233949311077595, Final Batch Loss: 0.07261502742767334\n",
      "Epoch 4059, Loss: 0.06287505477666855, Final Batch Loss: 0.037575408816337585\n",
      "Epoch 4060, Loss: 0.07114160805940628, Final Batch Loss: 0.03842657059431076\n",
      "Epoch 4061, Loss: 0.07852982729673386, Final Batch Loss: 0.03803865984082222\n",
      "Epoch 4062, Loss: 0.10509384796023369, Final Batch Loss: 0.03053971752524376\n",
      "Epoch 4063, Loss: 0.0636978317052126, Final Batch Loss: 0.02283468283712864\n",
      "Epoch 4064, Loss: 0.04586404375731945, Final Batch Loss: 0.018746238201856613\n",
      "Epoch 4065, Loss: 0.13379692286252975, Final Batch Loss: 0.05380838364362717\n",
      "Epoch 4066, Loss: 0.12946942448616028, Final Batch Loss: 0.05991774797439575\n",
      "Epoch 4067, Loss: 0.041167380288243294, Final Batch Loss: 0.013903602957725525\n",
      "Epoch 4068, Loss: 0.05544401332736015, Final Batch Loss: 0.03147027641534805\n",
      "Epoch 4069, Loss: 0.15250589698553085, Final Batch Loss: 0.12871374189853668\n",
      "Epoch 4070, Loss: 0.0799059048295021, Final Batch Loss: 0.0358709841966629\n",
      "Epoch 4071, Loss: 0.07857998833060265, Final Batch Loss: 0.01324276253581047\n",
      "Epoch 4072, Loss: 0.09430620074272156, Final Batch Loss: 0.04490062966942787\n",
      "Epoch 4073, Loss: 0.11228027567267418, Final Batch Loss: 0.07712340354919434\n",
      "Epoch 4074, Loss: 0.0691612008959055, Final Batch Loss: 0.02155146934092045\n",
      "Epoch 4075, Loss: 0.06264212168753147, Final Batch Loss: 0.021850617602467537\n",
      "Epoch 4076, Loss: 0.10469328984618187, Final Batch Loss: 0.050244055688381195\n",
      "Epoch 4077, Loss: 0.0765177346765995, Final Batch Loss: 0.03329155221581459\n",
      "Epoch 4078, Loss: 0.07281019166111946, Final Batch Loss: 0.027356304228305817\n",
      "Epoch 4079, Loss: 0.09483049344271421, Final Batch Loss: 0.013998742215335369\n",
      "Epoch 4080, Loss: 0.0687561146914959, Final Batch Loss: 0.035002999007701874\n",
      "Epoch 4081, Loss: 0.07487150840461254, Final Batch Loss: 0.024735959246754646\n",
      "Epoch 4082, Loss: 0.10939470678567886, Final Batch Loss: 0.03790033608675003\n",
      "Epoch 4083, Loss: 0.10894661769270897, Final Batch Loss: 0.07521124929189682\n",
      "Epoch 4084, Loss: 0.08139179274439812, Final Batch Loss: 0.043142277747392654\n",
      "Epoch 4085, Loss: 0.07357478141784668, Final Batch Loss: 0.04224949702620506\n",
      "Epoch 4086, Loss: 0.07642719894647598, Final Batch Loss: 0.036761704832315445\n",
      "Epoch 4087, Loss: 0.07015562430024147, Final Batch Loss: 0.03219543397426605\n",
      "Epoch 4088, Loss: 0.08403666317462921, Final Batch Loss: 0.04897673428058624\n",
      "Epoch 4089, Loss: 0.058546753600239754, Final Batch Loss: 0.03629383444786072\n",
      "Epoch 4090, Loss: 0.1194988451898098, Final Batch Loss: 0.07659027725458145\n",
      "Epoch 4091, Loss: 0.06985622271895409, Final Batch Loss: 0.022047773003578186\n",
      "Epoch 4092, Loss: 0.0705252718180418, Final Batch Loss: 0.04553396254777908\n",
      "Epoch 4093, Loss: 0.03774247504770756, Final Batch Loss: 0.019999910145998\n",
      "Epoch 4094, Loss: 0.06221439316868782, Final Batch Loss: 0.024959340691566467\n",
      "Epoch 4095, Loss: 0.07880009151995182, Final Batch Loss: 0.028651876375079155\n",
      "Epoch 4096, Loss: 0.059976786375045776, Final Batch Loss: 0.010710202157497406\n",
      "Epoch 4097, Loss: 0.12062026560306549, Final Batch Loss: 0.09797785431146622\n",
      "Epoch 4098, Loss: 0.06791246309876442, Final Batch Loss: 0.04852497577667236\n",
      "Epoch 4099, Loss: 0.043273866176605225, Final Batch Loss: 0.01126563549041748\n",
      "Epoch 4100, Loss: 0.04647665657103062, Final Batch Loss: 0.02121649868786335\n",
      "Epoch 4101, Loss: 0.1412295550107956, Final Batch Loss: 0.07473921775817871\n",
      "Epoch 4102, Loss: 0.05241830460727215, Final Batch Loss: 0.016557348892092705\n",
      "Epoch 4103, Loss: 0.03918781969696283, Final Batch Loss: 0.01135879848152399\n",
      "Epoch 4104, Loss: 0.09291068278253078, Final Batch Loss: 0.06659349054098129\n",
      "Epoch 4105, Loss: 0.028053591027855873, Final Batch Loss: 0.0062932539731264114\n",
      "Epoch 4106, Loss: 0.044725870713591576, Final Batch Loss: 0.019401729106903076\n",
      "Epoch 4107, Loss: 0.058700430672615767, Final Batch Loss: 0.006041496526449919\n",
      "Epoch 4108, Loss: 0.030609293840825558, Final Batch Loss: 0.005929003469645977\n",
      "Epoch 4109, Loss: 0.04553627222776413, Final Batch Loss: 0.018278943374753\n",
      "Epoch 4110, Loss: 0.02641671895980835, Final Batch Loss: 0.013309698551893234\n",
      "Epoch 4111, Loss: 0.11457374505698681, Final Batch Loss: 0.09149853140115738\n",
      "Epoch 4112, Loss: 0.08166522532701492, Final Batch Loss: 0.019334252923727036\n",
      "Epoch 4113, Loss: 0.040904758498072624, Final Batch Loss: 0.016269497573375702\n",
      "Epoch 4114, Loss: 0.07397427782416344, Final Batch Loss: 0.022518765181303024\n",
      "Epoch 4115, Loss: 0.04937138222157955, Final Batch Loss: 0.026958689093589783\n",
      "Epoch 4116, Loss: 0.047989076003432274, Final Batch Loss: 0.021616488695144653\n",
      "Epoch 4117, Loss: 0.12199040874838829, Final Batch Loss: 0.07510039210319519\n",
      "Epoch 4118, Loss: 0.12113339081406593, Final Batch Loss: 0.05162336304783821\n",
      "Epoch 4119, Loss: 0.057733405381441116, Final Batch Loss: 0.03391679376363754\n",
      "Epoch 4120, Loss: 0.042523548007011414, Final Batch Loss: 0.02398526482284069\n",
      "Epoch 4121, Loss: 0.04921448603272438, Final Batch Loss: 0.010686878114938736\n",
      "Epoch 4122, Loss: 0.08546469733119011, Final Batch Loss: 0.03216543793678284\n",
      "Epoch 4123, Loss: 0.04971352219581604, Final Batch Loss: 0.02109854854643345\n",
      "Epoch 4124, Loss: 0.040703631937503815, Final Batch Loss: 0.014441391453146935\n",
      "Epoch 4125, Loss: 0.06058845855295658, Final Batch Loss: 0.02607881836593151\n",
      "Epoch 4126, Loss: 0.07779710087925196, Final Batch Loss: 0.010163740254938602\n",
      "Epoch 4127, Loss: 0.053787052631378174, Final Batch Loss: 0.0138937309384346\n",
      "Epoch 4128, Loss: 0.0564871970564127, Final Batch Loss: 0.027039583772420883\n",
      "Epoch 4129, Loss: 0.055909331887960434, Final Batch Loss: 0.01994003728032112\n",
      "Epoch 4130, Loss: 0.17247990984469652, Final Batch Loss: 0.01307524461299181\n",
      "Epoch 4131, Loss: 0.0681227408349514, Final Batch Loss: 0.03493489697575569\n",
      "Epoch 4132, Loss: 0.06338469684123993, Final Batch Loss: 0.04887259006500244\n",
      "Epoch 4133, Loss: 0.03828002139925957, Final Batch Loss: 0.005940806120634079\n",
      "Epoch 4134, Loss: 0.06139250285923481, Final Batch Loss: 0.03458258882164955\n",
      "Epoch 4135, Loss: 0.08168145269155502, Final Batch Loss: 0.042964156717061996\n",
      "Epoch 4136, Loss: 0.048577768728137016, Final Batch Loss: 0.024666203185915947\n",
      "Epoch 4137, Loss: 0.0676552839577198, Final Batch Loss: 0.030249346047639847\n",
      "Epoch 4138, Loss: 0.07481962069869041, Final Batch Loss: 0.0178377665579319\n",
      "Epoch 4139, Loss: 0.11035914719104767, Final Batch Loss: 0.05705816671252251\n",
      "Epoch 4140, Loss: 0.0382052231580019, Final Batch Loss: 0.01754714921116829\n",
      "Epoch 4141, Loss: 0.07756768353283405, Final Batch Loss: 0.024908507242798805\n",
      "Epoch 4142, Loss: 0.06526929698884487, Final Batch Loss: 0.026440011337399483\n",
      "Epoch 4143, Loss: 0.09057454578578472, Final Batch Loss: 0.0195265244692564\n",
      "Epoch 4144, Loss: 0.054364271461963654, Final Batch Loss: 0.031277116388082504\n",
      "Epoch 4145, Loss: 0.04403163492679596, Final Batch Loss: 0.01361844688653946\n",
      "Epoch 4146, Loss: 0.08776924572885036, Final Batch Loss: 0.01126597635447979\n",
      "Epoch 4147, Loss: 0.07647190243005753, Final Batch Loss: 0.033006682991981506\n",
      "Epoch 4148, Loss: 0.057661186903715134, Final Batch Loss: 0.006399087607860565\n",
      "Epoch 4149, Loss: 0.026369701139628887, Final Batch Loss: 0.018987786024808884\n",
      "Epoch 4150, Loss: 0.08800793997943401, Final Batch Loss: 0.018881728872656822\n",
      "Epoch 4151, Loss: 0.05015417654067278, Final Batch Loss: 0.015388269908726215\n",
      "Epoch 4152, Loss: 0.05819301027804613, Final Batch Loss: 0.00942723173648119\n",
      "Epoch 4153, Loss: 0.029821984469890594, Final Batch Loss: 0.009050482884049416\n",
      "Epoch 4154, Loss: 0.04416505619883537, Final Batch Loss: 0.01588503271341324\n",
      "Epoch 4155, Loss: 0.06180168781429529, Final Batch Loss: 0.010546923615038395\n",
      "Epoch 4156, Loss: 0.03076383750885725, Final Batch Loss: 0.010652926750481129\n",
      "Epoch 4157, Loss: 0.03355555608868599, Final Batch Loss: 0.011971384286880493\n",
      "Epoch 4158, Loss: 0.060330284759402275, Final Batch Loss: 0.04229322075843811\n",
      "Epoch 4159, Loss: 0.08583504892885685, Final Batch Loss: 0.07328291982412338\n",
      "Epoch 4160, Loss: 0.09738839045166969, Final Batch Loss: 0.04811948165297508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4161, Loss: 0.06219600606709719, Final Batch Loss: 0.011366874910891056\n",
      "Epoch 4162, Loss: 0.048444297164678574, Final Batch Loss: 0.01681877300143242\n",
      "Epoch 4163, Loss: 0.024377579800784588, Final Batch Loss: 0.008926902897655964\n",
      "Epoch 4164, Loss: 0.10475883260369301, Final Batch Loss: 0.08183452486991882\n",
      "Epoch 4165, Loss: 0.07502332143485546, Final Batch Loss: 0.05263200402259827\n",
      "Epoch 4166, Loss: 0.04422606434673071, Final Batch Loss: 0.011464177630841732\n",
      "Epoch 4167, Loss: 0.08657727390527725, Final Batch Loss: 0.03826887905597687\n",
      "Epoch 4168, Loss: 0.11262784898281097, Final Batch Loss: 0.021649956703186035\n",
      "Epoch 4169, Loss: 0.020995683036744595, Final Batch Loss: 0.00850428082048893\n",
      "Epoch 4170, Loss: 0.04026286117732525, Final Batch Loss: 0.022307289764285088\n",
      "Epoch 4171, Loss: 0.07466832175850868, Final Batch Loss: 0.03656463325023651\n",
      "Epoch 4172, Loss: 0.08079036325216293, Final Batch Loss: 0.030795831233263016\n",
      "Epoch 4173, Loss: 0.04513292293995619, Final Batch Loss: 0.029569324105978012\n",
      "Epoch 4174, Loss: 0.08601668663322926, Final Batch Loss: 0.06614726781845093\n",
      "Epoch 4175, Loss: 0.10785814002156258, Final Batch Loss: 0.05608586594462395\n",
      "Epoch 4176, Loss: 0.051049211993813515, Final Batch Loss: 0.02856617234647274\n",
      "Epoch 4177, Loss: 0.08460113499313593, Final Batch Loss: 0.06958971917629242\n",
      "Epoch 4178, Loss: 0.05648954398930073, Final Batch Loss: 0.0411585196852684\n",
      "Epoch 4179, Loss: 0.08079409413039684, Final Batch Loss: 0.058659061789512634\n",
      "Epoch 4180, Loss: 0.04698562528938055, Final Batch Loss: 0.013822964392602444\n",
      "Epoch 4181, Loss: 0.06030922383069992, Final Batch Loss: 0.017151162028312683\n",
      "Epoch 4182, Loss: 0.046657219529151917, Final Batch Loss: 0.025963502004742622\n",
      "Epoch 4183, Loss: 0.053652074187994, Final Batch Loss: 0.03462251275777817\n",
      "Epoch 4184, Loss: 0.045767562463879585, Final Batch Loss: 0.021732758730649948\n",
      "Epoch 4185, Loss: 0.06409587804228067, Final Batch Loss: 0.05292518436908722\n",
      "Epoch 4186, Loss: 0.053338101133704185, Final Batch Loss: 0.029292628169059753\n",
      "Epoch 4187, Loss: 0.037357283756136894, Final Batch Loss: 0.019703570753335953\n",
      "Epoch 4188, Loss: 0.05069504305720329, Final Batch Loss: 0.03250463306903839\n",
      "Epoch 4189, Loss: 0.08000354841351509, Final Batch Loss: 0.04256122559309006\n",
      "Epoch 4190, Loss: 0.04991363640874624, Final Batch Loss: 0.014063115231692791\n",
      "Epoch 4191, Loss: 0.030239720828831196, Final Batch Loss: 0.01925632171332836\n",
      "Epoch 4192, Loss: 0.06613109353929758, Final Batch Loss: 0.006037277169525623\n",
      "Epoch 4193, Loss: 0.05786930210888386, Final Batch Loss: 0.03869321197271347\n",
      "Epoch 4194, Loss: 0.03010877314954996, Final Batch Loss: 0.022163700312376022\n",
      "Epoch 4195, Loss: 0.03240575734525919, Final Batch Loss: 0.01468332577496767\n",
      "Epoch 4196, Loss: 0.06883597001433372, Final Batch Loss: 0.03921368345618248\n",
      "Epoch 4197, Loss: 0.02496786881238222, Final Batch Loss: 0.009487662464380264\n",
      "Epoch 4198, Loss: 0.10553304478526115, Final Batch Loss: 0.07656539231538773\n",
      "Epoch 4199, Loss: 0.040539395064115524, Final Batch Loss: 0.020407915115356445\n",
      "Epoch 4200, Loss: 0.06933369673788548, Final Batch Loss: 0.012859294191002846\n",
      "Epoch 4201, Loss: 0.041022803634405136, Final Batch Loss: 0.010016420856118202\n",
      "Epoch 4202, Loss: 0.07350154779851437, Final Batch Loss: 0.026056451722979546\n",
      "Epoch 4203, Loss: 0.027163724415004253, Final Batch Loss: 0.006960584782063961\n",
      "Epoch 4204, Loss: 0.02556196227669716, Final Batch Loss: 0.00838630273938179\n",
      "Epoch 4205, Loss: 0.0821895431727171, Final Batch Loss: 0.03002420999109745\n",
      "Epoch 4206, Loss: 0.05293011758476496, Final Batch Loss: 0.013307013548910618\n",
      "Epoch 4207, Loss: 0.055240800604224205, Final Batch Loss: 0.029945779591798782\n",
      "Epoch 4208, Loss: 0.04055923968553543, Final Batch Loss: 0.015802208334207535\n",
      "Epoch 4209, Loss: 0.06710202060639858, Final Batch Loss: 0.03883017227053642\n",
      "Epoch 4210, Loss: 0.05684678256511688, Final Batch Loss: 0.017520010471343994\n",
      "Epoch 4211, Loss: 0.026517454534769058, Final Batch Loss: 0.010841410607099533\n",
      "Epoch 4212, Loss: 0.019961818121373653, Final Batch Loss: 0.00862125400453806\n",
      "Epoch 4213, Loss: 0.04944625962525606, Final Batch Loss: 0.03662887588143349\n",
      "Epoch 4214, Loss: 0.12067753449082375, Final Batch Loss: 0.048364732414484024\n",
      "Epoch 4215, Loss: 0.04715175461024046, Final Batch Loss: 0.011984135024249554\n",
      "Epoch 4216, Loss: 0.06258296966552734, Final Batch Loss: 0.014812029898166656\n",
      "Epoch 4217, Loss: 0.07755031064152718, Final Batch Loss: 0.04195718467235565\n",
      "Epoch 4218, Loss: 0.0665755420923233, Final Batch Loss: 0.03132224082946777\n",
      "Epoch 4219, Loss: 0.18921194225549698, Final Batch Loss: 0.1415817141532898\n",
      "Epoch 4220, Loss: 0.055663189850747585, Final Batch Loss: 0.014212912879884243\n",
      "Epoch 4221, Loss: 0.09925161674618721, Final Batch Loss: 0.0619773231446743\n",
      "Epoch 4222, Loss: 0.0797869935631752, Final Batch Loss: 0.02938142791390419\n",
      "Epoch 4223, Loss: 0.08540855348110199, Final Batch Loss: 0.05284307152032852\n",
      "Epoch 4224, Loss: 0.048071302473545074, Final Batch Loss: 0.012860510498285294\n",
      "Epoch 4225, Loss: 0.07660543546080589, Final Batch Loss: 0.05821940302848816\n",
      "Epoch 4226, Loss: 0.06949770078063011, Final Batch Loss: 0.02924015372991562\n",
      "Epoch 4227, Loss: 0.028766606003046036, Final Batch Loss: 0.005871569737792015\n",
      "Epoch 4228, Loss: 0.08082196861505508, Final Batch Loss: 0.04434143379330635\n",
      "Epoch 4229, Loss: 0.07898908853530884, Final Batch Loss: 0.02074010670185089\n",
      "Epoch 4230, Loss: 0.09060832113027573, Final Batch Loss: 0.05228745564818382\n",
      "Epoch 4231, Loss: 0.03967675566673279, Final Batch Loss: 0.006362356245517731\n",
      "Epoch 4232, Loss: 0.09432247653603554, Final Batch Loss: 0.06220899894833565\n",
      "Epoch 4233, Loss: 0.054791759699583054, Final Batch Loss: 0.030582645907998085\n",
      "Epoch 4234, Loss: 0.035623456351459026, Final Batch Loss: 0.02708078920841217\n",
      "Epoch 4235, Loss: 0.11413503438234329, Final Batch Loss: 0.07406779378652573\n",
      "Epoch 4236, Loss: 0.05810141749680042, Final Batch Loss: 0.03260407969355583\n",
      "Epoch 4237, Loss: 0.0522687416523695, Final Batch Loss: 0.02975570596754551\n",
      "Epoch 4238, Loss: 0.13362452760338783, Final Batch Loss: 0.08424658328294754\n",
      "Epoch 4239, Loss: 0.05860801786184311, Final Batch Loss: 0.03868872672319412\n",
      "Epoch 4240, Loss: 0.15919281728565693, Final Batch Loss: 0.1338202804327011\n",
      "Epoch 4241, Loss: 0.049924345687031746, Final Batch Loss: 0.028842011466622353\n",
      "Epoch 4242, Loss: 0.09343795478343964, Final Batch Loss: 0.062031570822000504\n",
      "Epoch 4243, Loss: 0.04594435077160597, Final Batch Loss: 0.013338292948901653\n",
      "Epoch 4244, Loss: 0.05176136828958988, Final Batch Loss: 0.02427445538341999\n",
      "Epoch 4245, Loss: 0.05456101894378662, Final Batch Loss: 0.03149061277508736\n",
      "Epoch 4246, Loss: 0.053259232081472874, Final Batch Loss: 0.015294068492949009\n",
      "Epoch 4247, Loss: 0.0810101106762886, Final Batch Loss: 0.062003303319215775\n",
      "Epoch 4248, Loss: 0.05637286975979805, Final Batch Loss: 0.03374264016747475\n",
      "Epoch 4249, Loss: 0.03980068676173687, Final Batch Loss: 0.017245031893253326\n",
      "Epoch 4250, Loss: 0.05526769533753395, Final Batch Loss: 0.021804459393024445\n",
      "Epoch 4251, Loss: 0.04705875366926193, Final Batch Loss: 0.025776242837309837\n",
      "Epoch 4252, Loss: 0.05803385563194752, Final Batch Loss: 0.0269758477807045\n",
      "Epoch 4253, Loss: 0.06633124127984047, Final Batch Loss: 0.029248736798763275\n",
      "Epoch 4254, Loss: 0.021978114265948534, Final Batch Loss: 0.0072767953388392925\n",
      "Epoch 4255, Loss: 0.05530581623315811, Final Batch Loss: 0.02440367452800274\n",
      "Epoch 4256, Loss: 0.0352059262804687, Final Batch Loss: 0.007187038194388151\n",
      "Epoch 4257, Loss: 0.058856429532170296, Final Batch Loss: 0.029449624940752983\n",
      "Epoch 4258, Loss: 0.06513441354036331, Final Batch Loss: 0.015632852911949158\n",
      "Epoch 4259, Loss: 0.07125561125576496, Final Batch Loss: 0.05645527318120003\n",
      "Epoch 4260, Loss: 0.038942161947488785, Final Batch Loss: 0.020056581124663353\n",
      "Epoch 4261, Loss: 0.09709693677723408, Final Batch Loss: 0.029545897617936134\n",
      "Epoch 4262, Loss: 0.07138586975634098, Final Batch Loss: 0.025434130802750587\n",
      "Epoch 4263, Loss: 0.10446051880717278, Final Batch Loss: 0.06205851957201958\n",
      "Epoch 4264, Loss: 0.04884699918329716, Final Batch Loss: 0.019311748445034027\n",
      "Epoch 4265, Loss: 0.11492381244897842, Final Batch Loss: 0.06579416990280151\n",
      "Epoch 4266, Loss: 0.1291474923491478, Final Batch Loss: 0.07460863888263702\n",
      "Epoch 4267, Loss: 0.06055591255426407, Final Batch Loss: 0.04181194677948952\n",
      "Epoch 4268, Loss: 0.09334042854607105, Final Batch Loss: 0.020774202421307564\n",
      "Epoch 4269, Loss: 0.053345320746302605, Final Batch Loss: 0.02383941225707531\n",
      "Epoch 4270, Loss: 0.04538919776678085, Final Batch Loss: 0.014207553118467331\n",
      "Epoch 4271, Loss: 0.1147623248398304, Final Batch Loss: 0.06480688601732254\n",
      "Epoch 4272, Loss: 0.10104421526193619, Final Batch Loss: 0.050057779997587204\n",
      "Epoch 4273, Loss: 0.0911181028932333, Final Batch Loss: 0.06255421787500381\n",
      "Epoch 4274, Loss: 0.06856402568519115, Final Batch Loss: 0.0232465248554945\n",
      "Epoch 4275, Loss: 0.05370512790977955, Final Batch Loss: 0.031694162636995316\n",
      "Epoch 4276, Loss: 0.059629201889038086, Final Batch Loss: 0.02280755713582039\n",
      "Epoch 4277, Loss: 0.05724007077515125, Final Batch Loss: 0.02854442037642002\n",
      "Epoch 4278, Loss: 0.03654826618731022, Final Batch Loss: 0.016750473529100418\n",
      "Epoch 4279, Loss: 0.062073132023215294, Final Batch Loss: 0.047014448791742325\n",
      "Epoch 4280, Loss: 0.09945326345041394, Final Batch Loss: 0.0053926189430058\n",
      "Epoch 4281, Loss: 0.07460122555494308, Final Batch Loss: 0.004236847162246704\n",
      "Epoch 4282, Loss: 0.10517887771129608, Final Batch Loss: 0.06772254407405853\n",
      "Epoch 4283, Loss: 0.1077067106962204, Final Batch Loss: 0.043905094265937805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4284, Loss: 0.05648233275860548, Final Batch Loss: 0.014612141065299511\n",
      "Epoch 4285, Loss: 0.05846704635769129, Final Batch Loss: 0.043480489403009415\n",
      "Epoch 4286, Loss: 0.05327942967414856, Final Batch Loss: 0.01677704229950905\n",
      "Epoch 4287, Loss: 0.09738491475582123, Final Batch Loss: 0.06248585879802704\n",
      "Epoch 4288, Loss: 0.06233755685389042, Final Batch Loss: 0.009957714006304741\n",
      "Epoch 4289, Loss: 0.07653479091823101, Final Batch Loss: 0.046033766120672226\n",
      "Epoch 4290, Loss: 0.06333913467824459, Final Batch Loss: 0.024403562769293785\n",
      "Epoch 4291, Loss: 0.09953893348574638, Final Batch Loss: 0.04471152648329735\n",
      "Epoch 4292, Loss: 0.06135654076933861, Final Batch Loss: 0.03403075784444809\n",
      "Epoch 4293, Loss: 0.07498922571539879, Final Batch Loss: 0.02870175614953041\n",
      "Epoch 4294, Loss: 0.034951332956552505, Final Batch Loss: 0.01629517413675785\n",
      "Epoch 4295, Loss: 0.03928087651729584, Final Batch Loss: 0.01940818317234516\n",
      "Epoch 4296, Loss: 0.03792889043688774, Final Batch Loss: 0.014332957565784454\n",
      "Epoch 4297, Loss: 0.060745321214199066, Final Batch Loss: 0.020666807889938354\n",
      "Epoch 4298, Loss: 0.08466943353414536, Final Batch Loss: 0.045633357018232346\n",
      "Epoch 4299, Loss: 0.08164159208536148, Final Batch Loss: 0.03515849635004997\n",
      "Epoch 4300, Loss: 0.06653673760592937, Final Batch Loss: 0.0506485253572464\n",
      "Epoch 4301, Loss: 0.04153257887810469, Final Batch Loss: 0.008665668778121471\n",
      "Epoch 4302, Loss: 0.05662316456437111, Final Batch Loss: 0.030545908957719803\n",
      "Epoch 4303, Loss: 0.0748056173324585, Final Batch Loss: 0.030507821589708328\n",
      "Epoch 4304, Loss: 0.12087973766028881, Final Batch Loss: 0.1059977114200592\n",
      "Epoch 4305, Loss: 0.07976968213915825, Final Batch Loss: 0.025753892958164215\n",
      "Epoch 4306, Loss: 0.048936715349555016, Final Batch Loss: 0.024353373795747757\n",
      "Epoch 4307, Loss: 0.11309788376092911, Final Batch Loss: 0.09472419321537018\n",
      "Epoch 4308, Loss: 0.056183175183832645, Final Batch Loss: 0.01557703036814928\n",
      "Epoch 4309, Loss: 0.08593921735882759, Final Batch Loss: 0.04214248061180115\n",
      "Epoch 4310, Loss: 0.06713878642767668, Final Batch Loss: 0.013503673486411572\n",
      "Epoch 4311, Loss: 0.042164521291852, Final Batch Loss: 0.01951748877763748\n",
      "Epoch 4312, Loss: 0.10476452112197876, Final Batch Loss: 0.038236379623413086\n",
      "Epoch 4313, Loss: 0.051430677995085716, Final Batch Loss: 0.03824799135327339\n",
      "Epoch 4314, Loss: 0.07019562926143408, Final Batch Loss: 0.010378818027675152\n",
      "Epoch 4315, Loss: 0.031165532767772675, Final Batch Loss: 0.016384931281208992\n",
      "Epoch 4316, Loss: 0.04682599753141403, Final Batch Loss: 0.014927603304386139\n",
      "Epoch 4317, Loss: 0.03557483572512865, Final Batch Loss: 0.010720535181462765\n",
      "Epoch 4318, Loss: 0.08635349944233894, Final Batch Loss: 0.0571642629802227\n",
      "Epoch 4319, Loss: 0.06881250627338886, Final Batch Loss: 0.052924994379282\n",
      "Epoch 4320, Loss: 0.05287978611886501, Final Batch Loss: 0.017907751724123955\n",
      "Epoch 4321, Loss: 0.0605865977704525, Final Batch Loss: 0.03058532439172268\n",
      "Epoch 4322, Loss: 0.04081476107239723, Final Batch Loss: 0.008141223341226578\n",
      "Epoch 4323, Loss: 0.06634785793721676, Final Batch Loss: 0.012962965294718742\n",
      "Epoch 4324, Loss: 0.05585379898548126, Final Batch Loss: 0.012423135340213776\n",
      "Epoch 4325, Loss: 0.08449699357151985, Final Batch Loss: 0.04780812934041023\n",
      "Epoch 4326, Loss: 0.09200528636574745, Final Batch Loss: 0.04913046956062317\n",
      "Epoch 4327, Loss: 0.04623265005648136, Final Batch Loss: 0.03363633155822754\n",
      "Epoch 4328, Loss: 0.05385254696011543, Final Batch Loss: 0.019119609147310257\n",
      "Epoch 4329, Loss: 0.051613783463835716, Final Batch Loss: 0.02861330844461918\n",
      "Epoch 4330, Loss: 0.06563766300678253, Final Batch Loss: 0.03322715684771538\n",
      "Epoch 4331, Loss: 0.14041760563850403, Final Batch Loss: 0.09978260099887848\n",
      "Epoch 4332, Loss: 0.05750980041921139, Final Batch Loss: 0.0354107990860939\n",
      "Epoch 4333, Loss: 0.040579432621598244, Final Batch Loss: 0.01756725087761879\n",
      "Epoch 4334, Loss: 0.02919634897261858, Final Batch Loss: 0.016613997519016266\n",
      "Epoch 4335, Loss: 0.04312944412231445, Final Batch Loss: 0.0332457572221756\n",
      "Epoch 4336, Loss: 0.08018720149993896, Final Batch Loss: 0.025360722094774246\n",
      "Epoch 4337, Loss: 0.058964572846889496, Final Batch Loss: 0.03392990678548813\n",
      "Epoch 4338, Loss: 0.06371702067553997, Final Batch Loss: 0.027227463200688362\n",
      "Epoch 4339, Loss: 0.027453558519482613, Final Batch Loss: 0.012812172062695026\n",
      "Epoch 4340, Loss: 0.02879526000469923, Final Batch Loss: 0.015311289578676224\n",
      "Epoch 4341, Loss: 0.07262033969163895, Final Batch Loss: 0.052416734397411346\n",
      "Epoch 4342, Loss: 0.12860509753227234, Final Batch Loss: 0.10243648290634155\n",
      "Epoch 4343, Loss: 0.09459812194108963, Final Batch Loss: 0.08120162785053253\n",
      "Epoch 4344, Loss: 0.017437895759940147, Final Batch Loss: 0.00816643051803112\n",
      "Epoch 4345, Loss: 0.038978613913059235, Final Batch Loss: 0.019474761560559273\n",
      "Epoch 4346, Loss: 0.03591206483542919, Final Batch Loss: 0.015592588111758232\n",
      "Epoch 4347, Loss: 0.05913632549345493, Final Batch Loss: 0.04766568914055824\n",
      "Epoch 4348, Loss: 0.06090949475765228, Final Batch Loss: 0.019327934831380844\n",
      "Epoch 4349, Loss: 0.054899660870432854, Final Batch Loss: 0.02012433297932148\n",
      "Epoch 4350, Loss: 0.06476805731654167, Final Batch Loss: 0.03072918951511383\n",
      "Epoch 4351, Loss: 0.08249914832413197, Final Batch Loss: 0.057438597083091736\n",
      "Epoch 4352, Loss: 0.1106402650475502, Final Batch Loss: 0.06920614093542099\n",
      "Epoch 4353, Loss: 0.03712740819901228, Final Batch Loss: 0.004673699848353863\n",
      "Epoch 4354, Loss: 0.08754708990454674, Final Batch Loss: 0.0196894071996212\n",
      "Epoch 4355, Loss: 0.11237496882677078, Final Batch Loss: 0.07911328226327896\n",
      "Epoch 4356, Loss: 0.07013783603906631, Final Batch Loss: 0.009769480675458908\n",
      "Epoch 4357, Loss: 0.028023979626595974, Final Batch Loss: 0.0068863192573189735\n",
      "Epoch 4358, Loss: 0.029028218239545822, Final Batch Loss: 0.018241049721837044\n",
      "Epoch 4359, Loss: 0.037755305878818035, Final Batch Loss: 0.014553782530128956\n",
      "Epoch 4360, Loss: 0.09484140388667583, Final Batch Loss: 0.02577081136405468\n",
      "Epoch 4361, Loss: 0.09348632395267487, Final Batch Loss: 0.05867452174425125\n",
      "Epoch 4362, Loss: 0.045412929728627205, Final Batch Loss: 0.025566736236214638\n",
      "Epoch 4363, Loss: 0.07640275731682777, Final Batch Loss: 0.03855600953102112\n",
      "Epoch 4364, Loss: 0.05542539991438389, Final Batch Loss: 0.032644737511873245\n",
      "Epoch 4365, Loss: 0.05059206672012806, Final Batch Loss: 0.024531427770853043\n",
      "Epoch 4366, Loss: 0.12082675844430923, Final Batch Loss: 0.06435953825712204\n",
      "Epoch 4367, Loss: 0.06686295941472054, Final Batch Loss: 0.030843276530504227\n",
      "Epoch 4368, Loss: 0.05258107744157314, Final Batch Loss: 0.02261359430849552\n",
      "Epoch 4369, Loss: 0.03426220174878836, Final Batch Loss: 0.007069830782711506\n",
      "Epoch 4370, Loss: 0.14455514401197433, Final Batch Loss: 0.07739478349685669\n",
      "Epoch 4371, Loss: 0.04358133487403393, Final Batch Loss: 0.03010396659374237\n",
      "Epoch 4372, Loss: 0.0663148332387209, Final Batch Loss: 0.024850739166140556\n",
      "Epoch 4373, Loss: 0.08743907324969769, Final Batch Loss: 0.06681579351425171\n",
      "Epoch 4374, Loss: 0.08440272882580757, Final Batch Loss: 0.040425173938274384\n",
      "Epoch 4375, Loss: 0.11209220066666603, Final Batch Loss: 0.0566975399851799\n",
      "Epoch 4376, Loss: 0.06502361409366131, Final Batch Loss: 0.029294254258275032\n",
      "Epoch 4377, Loss: 0.14835837855935097, Final Batch Loss: 0.050143051892519\n",
      "Epoch 4378, Loss: 0.09287295863032341, Final Batch Loss: 0.043482761830091476\n",
      "Epoch 4379, Loss: 0.08962663263082504, Final Batch Loss: 0.07400630414485931\n",
      "Epoch 4380, Loss: 0.0888349674642086, Final Batch Loss: 0.03306819871068001\n",
      "Epoch 4381, Loss: 0.08193927258253098, Final Batch Loss: 0.052996255457401276\n",
      "Epoch 4382, Loss: 0.09226556215435266, Final Batch Loss: 0.07966743409633636\n",
      "Epoch 4383, Loss: 0.04839816642925143, Final Batch Loss: 0.005271430592983961\n",
      "Epoch 4384, Loss: 0.04542618803679943, Final Batch Loss: 0.027598844841122627\n",
      "Epoch 4385, Loss: 0.037314845249056816, Final Batch Loss: 0.02068292163312435\n",
      "Epoch 4386, Loss: 0.13785458356142044, Final Batch Loss: 0.10211756080389023\n",
      "Epoch 4387, Loss: 0.085977952927351, Final Batch Loss: 0.04536065459251404\n",
      "Epoch 4388, Loss: 0.125370591878891, Final Batch Loss: 0.07937873154878616\n",
      "Epoch 4389, Loss: 0.041828726418316364, Final Batch Loss: 0.014977346174418926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4390, Loss: 0.07424035668373108, Final Batch Loss: 0.028125565499067307\n",
      "Epoch 4391, Loss: 0.09164967387914658, Final Batch Loss: 0.07860691845417023\n",
      "Epoch 4392, Loss: 0.05668266490101814, Final Batch Loss: 0.03435993567109108\n",
      "Epoch 4393, Loss: 0.06671899184584618, Final Batch Loss: 0.017211798578500748\n",
      "Epoch 4394, Loss: 0.0704679787158966, Final Batch Loss: 0.04568028450012207\n",
      "Epoch 4395, Loss: 0.0929352380335331, Final Batch Loss: 0.026496682316064835\n",
      "Epoch 4396, Loss: 0.12263475358486176, Final Batch Loss: 0.06170472502708435\n",
      "Epoch 4397, Loss: 0.03478000871837139, Final Batch Loss: 0.008303871378302574\n",
      "Epoch 4398, Loss: 0.06964617129415274, Final Batch Loss: 0.012332799844443798\n",
      "Epoch 4399, Loss: 0.1312744915485382, Final Batch Loss: 0.06560955196619034\n",
      "Epoch 4400, Loss: 0.038808309473097324, Final Batch Loss: 0.009715606458485126\n",
      "Epoch 4401, Loss: 0.06455780938267708, Final Batch Loss: 0.016893379390239716\n",
      "Epoch 4402, Loss: 0.060367435216903687, Final Batch Loss: 0.04469845071434975\n",
      "Epoch 4403, Loss: 0.04685068503022194, Final Batch Loss: 0.0329926498234272\n",
      "Epoch 4404, Loss: 0.031271190382540226, Final Batch Loss: 0.009140358306467533\n",
      "Epoch 4405, Loss: 0.09367521479725838, Final Batch Loss: 0.04455682262778282\n",
      "Epoch 4406, Loss: 0.04595840536057949, Final Batch Loss: 0.010787909850478172\n",
      "Epoch 4407, Loss: 0.08360793814063072, Final Batch Loss: 0.046540096402168274\n",
      "Epoch 4408, Loss: 0.03197795432060957, Final Batch Loss: 0.01745624467730522\n",
      "Epoch 4409, Loss: 0.031065975315868855, Final Batch Loss: 0.011863687075674534\n",
      "Epoch 4410, Loss: 0.04091935232281685, Final Batch Loss: 0.01670437678694725\n",
      "Epoch 4411, Loss: 0.05042771063745022, Final Batch Loss: 0.018327904865145683\n",
      "Epoch 4412, Loss: 0.04709360562264919, Final Batch Loss: 0.017132246866822243\n",
      "Epoch 4413, Loss: 0.05399051681160927, Final Batch Loss: 0.02423681877553463\n",
      "Epoch 4414, Loss: 0.0576937273144722, Final Batch Loss: 0.012164391577243805\n",
      "Epoch 4415, Loss: 0.06415792368352413, Final Batch Loss: 0.038083113729953766\n",
      "Epoch 4416, Loss: 0.04056570027023554, Final Batch Loss: 0.027279837056994438\n",
      "Epoch 4417, Loss: 0.0377067681401968, Final Batch Loss: 0.016665326431393623\n",
      "Epoch 4418, Loss: 0.04012032970786095, Final Batch Loss: 0.021554192528128624\n",
      "Epoch 4419, Loss: 0.03620986547321081, Final Batch Loss: 0.020810700953006744\n",
      "Epoch 4420, Loss: 0.03505721502006054, Final Batch Loss: 0.013167660683393478\n",
      "Epoch 4421, Loss: 0.039081755094230175, Final Batch Loss: 0.010395673103630543\n",
      "Epoch 4422, Loss: 0.08536567911505699, Final Batch Loss: 0.059591468423604965\n",
      "Epoch 4423, Loss: 0.051512593403458595, Final Batch Loss: 0.017137954011559486\n",
      "Epoch 4424, Loss: 0.07349511794745922, Final Batch Loss: 0.048384398221969604\n",
      "Epoch 4425, Loss: 0.03551956359297037, Final Batch Loss: 0.012289096601307392\n",
      "Epoch 4426, Loss: 0.0587179958820343, Final Batch Loss: 0.027686582878232002\n",
      "Epoch 4427, Loss: 0.1145620197057724, Final Batch Loss: 0.05747286602854729\n",
      "Epoch 4428, Loss: 0.08423067629337311, Final Batch Loss: 0.026999667286872864\n",
      "Epoch 4429, Loss: 0.1089126281440258, Final Batch Loss: 0.08619312942028046\n",
      "Epoch 4430, Loss: 0.07434779964387417, Final Batch Loss: 0.04418163001537323\n",
      "Epoch 4431, Loss: 0.060481712222099304, Final Batch Loss: 0.03559708595275879\n",
      "Epoch 4432, Loss: 0.07085203751921654, Final Batch Loss: 0.02706936001777649\n",
      "Epoch 4433, Loss: 0.055697218514978886, Final Batch Loss: 0.010519159026443958\n",
      "Epoch 4434, Loss: 0.10809626057744026, Final Batch Loss: 0.01144762709736824\n",
      "Epoch 4435, Loss: 0.12024952098727226, Final Batch Loss: 0.07414187490940094\n",
      "Epoch 4436, Loss: 0.05347348004579544, Final Batch Loss: 0.02509668841958046\n",
      "Epoch 4437, Loss: 0.04938792251050472, Final Batch Loss: 0.011238543316721916\n",
      "Epoch 4438, Loss: 0.05285429395735264, Final Batch Loss: 0.017914647236466408\n",
      "Epoch 4439, Loss: 0.05275905318558216, Final Batch Loss: 0.03215056285262108\n",
      "Epoch 4440, Loss: 0.11256041005253792, Final Batch Loss: 0.08207084983587265\n",
      "Epoch 4441, Loss: 0.02692081406712532, Final Batch Loss: 0.011587239801883698\n",
      "Epoch 4442, Loss: 0.08848962187767029, Final Batch Loss: 0.04902466759085655\n",
      "Epoch 4443, Loss: 0.08361002244055271, Final Batch Loss: 0.014691689983010292\n",
      "Epoch 4444, Loss: 0.13310939073562622, Final Batch Loss: 0.05000524967908859\n",
      "Epoch 4445, Loss: 0.0877186618745327, Final Batch Loss: 0.01076754555106163\n",
      "Epoch 4446, Loss: 0.08110097423195839, Final Batch Loss: 0.04883841425180435\n",
      "Epoch 4447, Loss: 0.06808657012879848, Final Batch Loss: 0.02837829850614071\n",
      "Epoch 4448, Loss: 0.10620544850826263, Final Batch Loss: 0.08233730494976044\n",
      "Epoch 4449, Loss: 0.05122796446084976, Final Batch Loss: 0.025316091254353523\n",
      "Epoch 4450, Loss: 0.10483866184949875, Final Batch Loss: 0.03983721137046814\n",
      "Epoch 4451, Loss: 0.07109311781823635, Final Batch Loss: 0.04291719198226929\n",
      "Epoch 4452, Loss: 0.07633411698043346, Final Batch Loss: 0.016646506264805794\n",
      "Epoch 4453, Loss: 0.03697528224438429, Final Batch Loss: 0.015103056095540524\n",
      "Epoch 4454, Loss: 0.10074416361749172, Final Batch Loss: 0.07505983859300613\n",
      "Epoch 4455, Loss: 0.04136986471712589, Final Batch Loss: 0.019182255491614342\n",
      "Epoch 4456, Loss: 0.03734349738806486, Final Batch Loss: 0.013860017992556095\n",
      "Epoch 4457, Loss: 0.05418544355779886, Final Batch Loss: 0.012635820545256138\n",
      "Epoch 4458, Loss: 0.04050035402178764, Final Batch Loss: 0.020737890154123306\n",
      "Epoch 4459, Loss: 0.07734248414635658, Final Batch Loss: 0.028446152806282043\n",
      "Epoch 4460, Loss: 0.03848142642527819, Final Batch Loss: 0.013486909680068493\n",
      "Epoch 4461, Loss: 0.033529565669596195, Final Batch Loss: 0.01212433259934187\n",
      "Epoch 4462, Loss: 0.02153612207621336, Final Batch Loss: 0.012213659472763538\n",
      "Epoch 4463, Loss: 0.10315517336130142, Final Batch Loss: 0.057489342987537384\n",
      "Epoch 4464, Loss: 0.059795333072543144, Final Batch Loss: 0.022014064714312553\n",
      "Epoch 4465, Loss: 0.061213837005198, Final Batch Loss: 0.015583985485136509\n",
      "Epoch 4466, Loss: 0.07097718492150307, Final Batch Loss: 0.031891077756881714\n",
      "Epoch 4467, Loss: 0.04128519259393215, Final Batch Loss: 0.01783323846757412\n",
      "Epoch 4468, Loss: 0.03683516941964626, Final Batch Loss: 0.013402573764324188\n",
      "Epoch 4469, Loss: 0.04708356410264969, Final Batch Loss: 0.019063496962189674\n",
      "Epoch 4470, Loss: 0.14751309156417847, Final Batch Loss: 0.02958330512046814\n",
      "Epoch 4471, Loss: 0.07842740416526794, Final Batch Loss: 0.025529876351356506\n",
      "Epoch 4472, Loss: 0.0420876145362854, Final Batch Loss: 0.02530941180884838\n",
      "Epoch 4473, Loss: 0.057716790586709976, Final Batch Loss: 0.01249615103006363\n",
      "Epoch 4474, Loss: 0.04232108034193516, Final Batch Loss: 0.029506342485547066\n",
      "Epoch 4475, Loss: 0.044991157948970795, Final Batch Loss: 0.023746822029352188\n",
      "Epoch 4476, Loss: 0.026679247617721558, Final Batch Loss: 0.01476362906396389\n",
      "Epoch 4477, Loss: 0.10979850217700005, Final Batch Loss: 0.0593012273311615\n",
      "Epoch 4478, Loss: 0.05439961701631546, Final Batch Loss: 0.022906839847564697\n",
      "Epoch 4479, Loss: 0.022436218336224556, Final Batch Loss: 0.013233182020485401\n",
      "Epoch 4480, Loss: 0.12236498668789864, Final Batch Loss: 0.06581521779298782\n",
      "Epoch 4481, Loss: 0.058522649109363556, Final Batch Loss: 0.030347982421517372\n",
      "Epoch 4482, Loss: 0.05512010306119919, Final Batch Loss: 0.01840684935450554\n",
      "Epoch 4483, Loss: 0.07541696354746819, Final Batch Loss: 0.06199028342962265\n",
      "Epoch 4484, Loss: 0.06024621240794659, Final Batch Loss: 0.04218078404664993\n",
      "Epoch 4485, Loss: 0.08289318904280663, Final Batch Loss: 0.023714326322078705\n",
      "Epoch 4486, Loss: 0.03987438324838877, Final Batch Loss: 0.015222514979541302\n",
      "Epoch 4487, Loss: 0.05851597338914871, Final Batch Loss: 0.010400883853435516\n",
      "Epoch 4488, Loss: 0.05761256441473961, Final Batch Loss: 0.02745809033513069\n",
      "Epoch 4489, Loss: 0.06883859448134899, Final Batch Loss: 0.018237078562378883\n",
      "Epoch 4490, Loss: 0.07677742838859558, Final Batch Loss: 0.04699873551726341\n",
      "Epoch 4491, Loss: 0.0366694051772356, Final Batch Loss: 0.01678670011460781\n",
      "Epoch 4492, Loss: 0.06245251093059778, Final Batch Loss: 0.011050955392420292\n",
      "Epoch 4493, Loss: 0.08724011480808258, Final Batch Loss: 0.05997351557016373\n",
      "Epoch 4494, Loss: 0.02178326714783907, Final Batch Loss: 0.006612048484385014\n",
      "Epoch 4495, Loss: 0.10186420567333698, Final Batch Loss: 0.013233872130513191\n",
      "Epoch 4496, Loss: 0.06333933398127556, Final Batch Loss: 0.01679462566971779\n",
      "Epoch 4497, Loss: 0.04278552904725075, Final Batch Loss: 0.01648985967040062\n",
      "Epoch 4498, Loss: 0.05349704250693321, Final Batch Loss: 0.017827153205871582\n",
      "Epoch 4499, Loss: 0.03885350562632084, Final Batch Loss: 0.02752862311899662\n",
      "Epoch 4500, Loss: 0.12018322572112083, Final Batch Loss: 0.03237714245915413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4501, Loss: 0.07493017613887787, Final Batch Loss: 0.05326753482222557\n",
      "Epoch 4502, Loss: 0.03214479051530361, Final Batch Loss: 0.012252258136868477\n",
      "Epoch 4503, Loss: 0.058600117452442646, Final Batch Loss: 0.04380488395690918\n",
      "Epoch 4504, Loss: 0.06324422918260098, Final Batch Loss: 0.0476059727370739\n",
      "Epoch 4505, Loss: 0.06626600213348866, Final Batch Loss: 0.04180362820625305\n",
      "Epoch 4506, Loss: 0.06503564305603504, Final Batch Loss: 0.04105044901371002\n",
      "Epoch 4507, Loss: 0.0783156044781208, Final Batch Loss: 0.04481012374162674\n",
      "Epoch 4508, Loss: 0.10140317678451538, Final Batch Loss: 0.056269969791173935\n",
      "Epoch 4509, Loss: 0.09252814762294292, Final Batch Loss: 0.028562812134623528\n",
      "Epoch 4510, Loss: 0.07303647696971893, Final Batch Loss: 0.033692874014377594\n",
      "Epoch 4511, Loss: 0.03445618599653244, Final Batch Loss: 0.02317764423787594\n",
      "Epoch 4512, Loss: 0.1059323139488697, Final Batch Loss: 0.0596490278840065\n",
      "Epoch 4513, Loss: 0.10664783045649529, Final Batch Loss: 0.08586524426937103\n",
      "Epoch 4514, Loss: 0.0548883993178606, Final Batch Loss: 0.018055377528071404\n",
      "Epoch 4515, Loss: 0.029442508704960346, Final Batch Loss: 0.009459235705435276\n",
      "Epoch 4516, Loss: 0.06749780476093292, Final Batch Loss: 0.03302567079663277\n",
      "Epoch 4517, Loss: 0.10260267928242683, Final Batch Loss: 0.054882969707250595\n",
      "Epoch 4518, Loss: 0.09613792411983013, Final Batch Loss: 0.06801100075244904\n",
      "Epoch 4519, Loss: 0.08881977945566177, Final Batch Loss: 0.040589265525341034\n",
      "Epoch 4520, Loss: 0.02459025662392378, Final Batch Loss: 0.010544868186116219\n",
      "Epoch 4521, Loss: 0.07573745585978031, Final Batch Loss: 0.06492423266172409\n",
      "Epoch 4522, Loss: 0.05006030760705471, Final Batch Loss: 0.02046309784054756\n",
      "Epoch 4523, Loss: 0.07335606776177883, Final Batch Loss: 0.04489447921514511\n",
      "Epoch 4524, Loss: 0.06998363323509693, Final Batch Loss: 0.043262779712677\n",
      "Epoch 4525, Loss: 0.08290348388254642, Final Batch Loss: 0.06768544763326645\n",
      "Epoch 4526, Loss: 0.06514345109462738, Final Batch Loss: 0.04538683965802193\n",
      "Epoch 4527, Loss: 0.08014026656746864, Final Batch Loss: 0.020596269518136978\n",
      "Epoch 4528, Loss: 0.04932377301156521, Final Batch Loss: 0.02888084575533867\n",
      "Epoch 4529, Loss: 0.1327106412500143, Final Batch Loss: 0.10719069838523865\n",
      "Epoch 4530, Loss: 0.02510868478566408, Final Batch Loss: 0.014354001730680466\n",
      "Epoch 4531, Loss: 0.18083325028419495, Final Batch Loss: 0.15582576394081116\n",
      "Epoch 4532, Loss: 0.08483383432030678, Final Batch Loss: 0.05353478714823723\n",
      "Epoch 4533, Loss: 0.054716987535357475, Final Batch Loss: 0.027416963130235672\n",
      "Epoch 4534, Loss: 0.05513808969408274, Final Batch Loss: 0.012899079360067844\n",
      "Epoch 4535, Loss: 0.07164350897073746, Final Batch Loss: 0.0281415693461895\n",
      "Epoch 4536, Loss: 0.04802361875772476, Final Batch Loss: 0.01356877014040947\n",
      "Epoch 4537, Loss: 0.04257798846811056, Final Batch Loss: 0.013931895606219769\n",
      "Epoch 4538, Loss: 0.04526315629482269, Final Batch Loss: 0.019844181835651398\n",
      "Epoch 4539, Loss: 0.05669485777616501, Final Batch Loss: 0.03663663566112518\n",
      "Epoch 4540, Loss: 0.07786337286233902, Final Batch Loss: 0.04232122376561165\n",
      "Epoch 4541, Loss: 0.10531150735914707, Final Batch Loss: 0.0838744267821312\n",
      "Epoch 4542, Loss: 0.08896130137145519, Final Batch Loss: 0.012252388522028923\n",
      "Epoch 4543, Loss: 0.06787114404141903, Final Batch Loss: 0.0445978008210659\n",
      "Epoch 4544, Loss: 0.08299370110034943, Final Batch Loss: 0.04770810529589653\n",
      "Epoch 4545, Loss: 0.05550636537373066, Final Batch Loss: 0.016877783462405205\n",
      "Epoch 4546, Loss: 0.05272983945906162, Final Batch Loss: 0.0334138385951519\n",
      "Epoch 4547, Loss: 0.06931431218981743, Final Batch Loss: 0.04248699173331261\n",
      "Epoch 4548, Loss: 0.06846025655977428, Final Batch Loss: 0.0038697354029864073\n",
      "Epoch 4549, Loss: 0.06186334230005741, Final Batch Loss: 0.028176868334412575\n",
      "Epoch 4550, Loss: 0.040479098446667194, Final Batch Loss: 0.014640147797763348\n",
      "Epoch 4551, Loss: 0.08864815160632133, Final Batch Loss: 0.019591573625802994\n",
      "Epoch 4552, Loss: 0.09776180610060692, Final Batch Loss: 0.04444124549627304\n",
      "Epoch 4553, Loss: 0.05055788904428482, Final Batch Loss: 0.02321642078459263\n",
      "Epoch 4554, Loss: 0.06879179179668427, Final Batch Loss: 0.031091485172510147\n",
      "Epoch 4555, Loss: 0.0820572730153799, Final Batch Loss: 0.060074806213378906\n",
      "Epoch 4556, Loss: 0.09802255406975746, Final Batch Loss: 0.054460253566503525\n",
      "Epoch 4557, Loss: 0.023956957273185253, Final Batch Loss: 0.0072505781427025795\n",
      "Epoch 4558, Loss: 0.04766983166337013, Final Batch Loss: 0.015932798385620117\n",
      "Epoch 4559, Loss: 0.08616433292627335, Final Batch Loss: 0.019254423677921295\n",
      "Epoch 4560, Loss: 0.047307418659329414, Final Batch Loss: 0.0179341658949852\n",
      "Epoch 4561, Loss: 0.07632029429078102, Final Batch Loss: 0.04936293140053749\n",
      "Epoch 4562, Loss: 0.04517035372555256, Final Batch Loss: 0.01969512365758419\n",
      "Epoch 4563, Loss: 0.059018367901444435, Final Batch Loss: 0.006750060245394707\n",
      "Epoch 4564, Loss: 0.05927363131195307, Final Batch Loss: 0.012731035239994526\n",
      "Epoch 4565, Loss: 0.06716321408748627, Final Batch Loss: 0.024744398891925812\n",
      "Epoch 4566, Loss: 0.04392803646624088, Final Batch Loss: 0.025128668174147606\n",
      "Epoch 4567, Loss: 0.07170462980866432, Final Batch Loss: 0.05121998116374016\n",
      "Epoch 4568, Loss: 0.03682242427021265, Final Batch Loss: 0.012411327101290226\n",
      "Epoch 4569, Loss: 0.07368641905486584, Final Batch Loss: 0.017068011686205864\n",
      "Epoch 4570, Loss: 0.027809746796265244, Final Batch Loss: 0.0032375662121921778\n",
      "Epoch 4571, Loss: 0.08558895625174046, Final Batch Loss: 0.016522036865353584\n",
      "Epoch 4572, Loss: 0.06299331784248352, Final Batch Loss: 0.015529908239841461\n",
      "Epoch 4573, Loss: 0.07572721317410469, Final Batch Loss: 0.04028631001710892\n",
      "Epoch 4574, Loss: 0.04648173041641712, Final Batch Loss: 0.02479531243443489\n",
      "Epoch 4575, Loss: 0.04484918434172869, Final Batch Loss: 0.029518097639083862\n",
      "Epoch 4576, Loss: 0.03381571266800165, Final Batch Loss: 0.010633829049766064\n",
      "Epoch 4577, Loss: 0.07960513792932034, Final Batch Loss: 0.02633676864206791\n",
      "Epoch 4578, Loss: 0.09150777757167816, Final Batch Loss: 0.07483614981174469\n",
      "Epoch 4579, Loss: 0.043824367225170135, Final Batch Loss: 0.026813164353370667\n",
      "Epoch 4580, Loss: 0.06484146416187286, Final Batch Loss: 0.02815382555127144\n",
      "Epoch 4581, Loss: 0.03890306130051613, Final Batch Loss: 0.013625344261527061\n",
      "Epoch 4582, Loss: 0.08615926280617714, Final Batch Loss: 0.050933267921209335\n",
      "Epoch 4583, Loss: 0.05105325160548091, Final Batch Loss: 0.04569720849394798\n",
      "Epoch 4584, Loss: 0.032931048423051834, Final Batch Loss: 0.011245070025324821\n",
      "Epoch 4585, Loss: 0.040088010020554066, Final Batch Loss: 0.025420449674129486\n",
      "Epoch 4586, Loss: 0.09395582228899002, Final Batch Loss: 0.05254555493593216\n",
      "Epoch 4587, Loss: 0.04054849036037922, Final Batch Loss: 0.016047289595007896\n",
      "Epoch 4588, Loss: 0.05730967037379742, Final Batch Loss: 0.01752168871462345\n",
      "Epoch 4589, Loss: 0.08625519648194313, Final Batch Loss: 0.047389302402734756\n",
      "Epoch 4590, Loss: 0.04510732740163803, Final Batch Loss: 0.03181961178779602\n",
      "Epoch 4591, Loss: 0.0478608226403594, Final Batch Loss: 0.013430426828563213\n",
      "Epoch 4592, Loss: 0.04954827716574073, Final Batch Loss: 0.007078362163156271\n",
      "Epoch 4593, Loss: 0.022783705033361912, Final Batch Loss: 0.009123565629124641\n",
      "Epoch 4594, Loss: 0.07366982288658619, Final Batch Loss: 0.05610661953687668\n",
      "Epoch 4595, Loss: 0.07539819739758968, Final Batch Loss: 0.0639198049902916\n",
      "Epoch 4596, Loss: 0.0457027442753315, Final Batch Loss: 0.008644111454486847\n",
      "Epoch 4597, Loss: 0.024734515696763992, Final Batch Loss: 0.007400369271636009\n",
      "Epoch 4598, Loss: 0.06271002348512411, Final Batch Loss: 0.00337850209325552\n",
      "Epoch 4599, Loss: 0.03548636566847563, Final Batch Loss: 0.011674878187477589\n",
      "Epoch 4600, Loss: 0.046497754752635956, Final Batch Loss: 0.015473652631044388\n",
      "Epoch 4601, Loss: 0.09784463420510292, Final Batch Loss: 0.04724831134080887\n",
      "Epoch 4602, Loss: 0.056407418102025986, Final Batch Loss: 0.017606526613235474\n",
      "Epoch 4603, Loss: 0.032931760884821415, Final Batch Loss: 0.008272682316601276\n",
      "Epoch 4604, Loss: 0.16729610785841942, Final Batch Loss: 0.1298566460609436\n",
      "Epoch 4605, Loss: 0.04436472896486521, Final Batch Loss: 0.03285788372159004\n",
      "Epoch 4606, Loss: 0.08401034213602543, Final Batch Loss: 0.061328064650297165\n",
      "Epoch 4607, Loss: 0.06627502664923668, Final Batch Loss: 0.035306427627801895\n",
      "Epoch 4608, Loss: 0.08086313679814339, Final Batch Loss: 0.047673966735601425\n",
      "Epoch 4609, Loss: 0.05352162383496761, Final Batch Loss: 0.03420806676149368\n",
      "Epoch 4610, Loss: 0.07701137661933899, Final Batch Loss: 0.03749241307377815\n",
      "Epoch 4611, Loss: 0.043667408637702465, Final Batch Loss: 0.01309411134570837\n",
      "Epoch 4612, Loss: 0.04147256538271904, Final Batch Loss: 0.019982293248176575\n",
      "Epoch 4613, Loss: 0.06963520403951406, Final Batch Loss: 0.010963196866214275\n",
      "Epoch 4614, Loss: 0.06418509967625141, Final Batch Loss: 0.022367218509316444\n",
      "Epoch 4615, Loss: 0.08394784852862358, Final Batch Loss: 0.06964056193828583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4616, Loss: 0.07130728289484978, Final Batch Loss: 0.008762475103139877\n",
      "Epoch 4617, Loss: 0.0512765608727932, Final Batch Loss: 0.02867867425084114\n",
      "Epoch 4618, Loss: 0.02848115097731352, Final Batch Loss: 0.005206049419939518\n",
      "Epoch 4619, Loss: 0.11132221668958664, Final Batch Loss: 0.09933539479970932\n",
      "Epoch 4620, Loss: 0.026818384416401386, Final Batch Loss: 0.01654530130326748\n",
      "Epoch 4621, Loss: 0.030997445806860924, Final Batch Loss: 0.01257079653441906\n",
      "Epoch 4622, Loss: 0.053800662979483604, Final Batch Loss: 0.009787211194634438\n",
      "Epoch 4623, Loss: 0.05948742851614952, Final Batch Loss: 0.0344746895134449\n",
      "Epoch 4624, Loss: 0.051534658297896385, Final Batch Loss: 0.01941411755979061\n",
      "Epoch 4625, Loss: 0.08016730844974518, Final Batch Loss: 0.025857068598270416\n",
      "Epoch 4626, Loss: 0.07558638975024223, Final Batch Loss: 0.04543877765536308\n",
      "Epoch 4627, Loss: 0.0277286097407341, Final Batch Loss: 0.019154636189341545\n",
      "Epoch 4628, Loss: 0.08442270010709763, Final Batch Loss: 0.0531587153673172\n",
      "Epoch 4629, Loss: 0.06604354083538055, Final Batch Loss: 0.03116023540496826\n",
      "Epoch 4630, Loss: 0.10298325214534998, Final Batch Loss: 0.09443745762109756\n",
      "Epoch 4631, Loss: 0.049602543003857136, Final Batch Loss: 0.03554576635360718\n",
      "Epoch 4632, Loss: 0.0704038254916668, Final Batch Loss: 0.024281181395053864\n",
      "Epoch 4633, Loss: 0.059051744639873505, Final Batch Loss: 0.014956988394260406\n",
      "Epoch 4634, Loss: 0.03962069936096668, Final Batch Loss: 0.03149908035993576\n",
      "Epoch 4635, Loss: 0.10018666833639145, Final Batch Loss: 0.02312086522579193\n",
      "Epoch 4636, Loss: 0.04025342874228954, Final Batch Loss: 0.022066498175263405\n",
      "Epoch 4637, Loss: 0.06770500540733337, Final Batch Loss: 0.03315725922584534\n",
      "Epoch 4638, Loss: 0.04568571783602238, Final Batch Loss: 0.02772357501089573\n",
      "Epoch 4639, Loss: 0.0339027876034379, Final Batch Loss: 0.015139536000788212\n",
      "Epoch 4640, Loss: 0.033980786334723234, Final Batch Loss: 0.004248283337801695\n",
      "Epoch 4641, Loss: 0.04267875663936138, Final Batch Loss: 0.031439293175935745\n",
      "Epoch 4642, Loss: 0.022202945314347744, Final Batch Loss: 0.0053598349913954735\n",
      "Epoch 4643, Loss: 0.020624108612537384, Final Batch Loss: 0.005548158660531044\n",
      "Epoch 4644, Loss: 0.05273846443742514, Final Batch Loss: 0.0062189726158976555\n",
      "Epoch 4645, Loss: 0.05227986630052328, Final Batch Loss: 0.009865178726613522\n",
      "Epoch 4646, Loss: 0.03833121247589588, Final Batch Loss: 0.01592385396361351\n",
      "Epoch 4647, Loss: 0.02062895242124796, Final Batch Loss: 0.009581719525158405\n",
      "Epoch 4648, Loss: 0.08521215245127678, Final Batch Loss: 0.07215791940689087\n",
      "Epoch 4649, Loss: 0.03795268665999174, Final Batch Loss: 0.013578598387539387\n",
      "Epoch 4650, Loss: 0.020672086626291275, Final Batch Loss: 0.008601740933954716\n",
      "Epoch 4651, Loss: 0.05636683292686939, Final Batch Loss: 0.022263774648308754\n",
      "Epoch 4652, Loss: 0.03803972015157342, Final Batch Loss: 0.006337432656437159\n",
      "Epoch 4653, Loss: 0.042317744344472885, Final Batch Loss: 0.03161277249455452\n",
      "Epoch 4654, Loss: 0.13328292965888977, Final Batch Loss: 0.06818484514951706\n",
      "Epoch 4655, Loss: 0.07439242210239172, Final Batch Loss: 0.011525406502187252\n",
      "Epoch 4656, Loss: 0.06729383394122124, Final Batch Loss: 0.04781138896942139\n",
      "Epoch 4657, Loss: 0.03626719303429127, Final Batch Loss: 0.017649732530117035\n",
      "Epoch 4658, Loss: 0.04342731088399887, Final Batch Loss: 0.0253217164427042\n",
      "Epoch 4659, Loss: 0.046788906678557396, Final Batch Loss: 0.029997073113918304\n",
      "Epoch 4660, Loss: 0.08621658757328987, Final Batch Loss: 0.059861812740564346\n",
      "Epoch 4661, Loss: 0.06388411112129688, Final Batch Loss: 0.03439915180206299\n",
      "Epoch 4662, Loss: 0.10061926022171974, Final Batch Loss: 0.06814612448215485\n",
      "Epoch 4663, Loss: 0.051293084397912025, Final Batch Loss: 0.027610108256340027\n",
      "Epoch 4664, Loss: 0.09017851669341326, Final Batch Loss: 0.012210358865559101\n",
      "Epoch 4665, Loss: 0.09229228645563126, Final Batch Loss: 0.0738195851445198\n",
      "Epoch 4666, Loss: 0.03501173481345177, Final Batch Loss: 0.021228626370429993\n",
      "Epoch 4667, Loss: 0.029374568723142147, Final Batch Loss: 0.011261415667831898\n",
      "Epoch 4668, Loss: 0.10575113818049431, Final Batch Loss: 0.043356575071811676\n",
      "Epoch 4669, Loss: 0.04343765554949641, Final Batch Loss: 0.006384666543453932\n",
      "Epoch 4670, Loss: 0.03904205374419689, Final Batch Loss: 0.01986616849899292\n",
      "Epoch 4671, Loss: 0.04420286975800991, Final Batch Loss: 0.018480174243450165\n",
      "Epoch 4672, Loss: 0.032864928245544434, Final Batch Loss: 0.011160504072904587\n",
      "Epoch 4673, Loss: 0.05519616790115833, Final Batch Loss: 0.028609005734324455\n",
      "Epoch 4674, Loss: 0.04902220610529184, Final Batch Loss: 0.011631605215370655\n",
      "Epoch 4675, Loss: 0.03592863492667675, Final Batch Loss: 0.019881166517734528\n",
      "Epoch 4676, Loss: 0.0756037887185812, Final Batch Loss: 0.027278410270810127\n",
      "Epoch 4677, Loss: 0.06804104335606098, Final Batch Loss: 0.04765069857239723\n",
      "Epoch 4678, Loss: 0.04613366536796093, Final Batch Loss: 0.019912825897336006\n",
      "Epoch 4679, Loss: 0.04543158411979675, Final Batch Loss: 0.022422268986701965\n",
      "Epoch 4680, Loss: 0.0491069070994854, Final Batch Loss: 0.021151242777705193\n",
      "Epoch 4681, Loss: 0.023280542343854904, Final Batch Loss: 0.013026510365307331\n",
      "Epoch 4682, Loss: 0.07220937497913837, Final Batch Loss: 0.014837229624390602\n",
      "Epoch 4683, Loss: 0.02110957633703947, Final Batch Loss: 0.008216972462832928\n",
      "Epoch 4684, Loss: 0.027366414200514555, Final Batch Loss: 0.02132268063724041\n",
      "Epoch 4685, Loss: 0.0759887807071209, Final Batch Loss: 0.05191051959991455\n",
      "Epoch 4686, Loss: 0.035903639160096645, Final Batch Loss: 0.022670209407806396\n",
      "Epoch 4687, Loss: 0.07542539108544588, Final Batch Loss: 0.06146153435111046\n",
      "Epoch 4688, Loss: 0.08831946086138487, Final Batch Loss: 0.07802340388298035\n",
      "Epoch 4689, Loss: 0.0526568740606308, Final Batch Loss: 0.03464534878730774\n",
      "Epoch 4690, Loss: 0.04941914137452841, Final Batch Loss: 0.015421784482896328\n",
      "Epoch 4691, Loss: 0.09064672701060772, Final Batch Loss: 0.06322155892848969\n",
      "Epoch 4692, Loss: 0.05801595002412796, Final Batch Loss: 0.04506506770849228\n",
      "Epoch 4693, Loss: 0.04658895544707775, Final Batch Loss: 0.013037046417593956\n",
      "Epoch 4694, Loss: 0.02164606936275959, Final Batch Loss: 0.012292507104575634\n",
      "Epoch 4695, Loss: 0.044322118163108826, Final Batch Loss: 0.02233297750353813\n",
      "Epoch 4696, Loss: 0.037646764889359474, Final Batch Loss: 0.011984249576926231\n",
      "Epoch 4697, Loss: 0.07632912322878838, Final Batch Loss: 0.03707071393728256\n",
      "Epoch 4698, Loss: 0.03144195303320885, Final Batch Loss: 0.018876375630497932\n",
      "Epoch 4699, Loss: 0.044532354921102524, Final Batch Loss: 0.032560836523771286\n",
      "Epoch 4700, Loss: 0.07065662927925587, Final Batch Loss: 0.044557008892297745\n",
      "Epoch 4701, Loss: 0.03694718424230814, Final Batch Loss: 0.024057211354374886\n",
      "Epoch 4702, Loss: 0.0707403365522623, Final Batch Loss: 0.049737632274627686\n",
      "Epoch 4703, Loss: 0.06654216069728136, Final Batch Loss: 0.05555069074034691\n",
      "Epoch 4704, Loss: 0.04502521641552448, Final Batch Loss: 0.018711812794208527\n",
      "Epoch 4705, Loss: 0.06872007809579372, Final Batch Loss: 0.02693060226738453\n",
      "Epoch 4706, Loss: 0.11047748848795891, Final Batch Loss: 0.03333060070872307\n",
      "Epoch 4707, Loss: 0.06033825594931841, Final Batch Loss: 0.012737334705889225\n",
      "Epoch 4708, Loss: 0.04036412201821804, Final Batch Loss: 0.02131599932909012\n",
      "Epoch 4709, Loss: 0.06606050953269005, Final Batch Loss: 0.04857594147324562\n",
      "Epoch 4710, Loss: 0.05842315033078194, Final Batch Loss: 0.026038825511932373\n",
      "Epoch 4711, Loss: 0.081112926825881, Final Batch Loss: 0.029499990865588188\n",
      "Epoch 4712, Loss: 0.05973079241812229, Final Batch Loss: 0.017954519018530846\n",
      "Epoch 4713, Loss: 0.0440010242164135, Final Batch Loss: 0.012760689482092857\n",
      "Epoch 4714, Loss: 0.0903852079063654, Final Batch Loss: 0.018159011378884315\n",
      "Epoch 4715, Loss: 0.0677462425082922, Final Batch Loss: 0.030910277739167213\n",
      "Epoch 4716, Loss: 0.048570992425084114, Final Batch Loss: 0.025931525975465775\n",
      "Epoch 4717, Loss: 0.03819849342107773, Final Batch Loss: 0.019594019278883934\n",
      "Epoch 4718, Loss: 0.026832017116248608, Final Batch Loss: 0.01185007207095623\n",
      "Epoch 4719, Loss: 0.09865820500999689, Final Batch Loss: 0.00941037479788065\n",
      "Epoch 4720, Loss: 0.04303525201976299, Final Batch Loss: 0.01372610591351986\n",
      "Epoch 4721, Loss: 0.04898831620812416, Final Batch Loss: 0.016904398798942566\n",
      "Epoch 4722, Loss: 0.10001656413078308, Final Batch Loss: 0.05014721304178238\n",
      "Epoch 4723, Loss: 0.058834875002503395, Final Batch Loss: 0.03748927637934685\n",
      "Epoch 4724, Loss: 0.03267439641058445, Final Batch Loss: 0.005074372515082359\n",
      "Epoch 4725, Loss: 0.0643521137535572, Final Batch Loss: 0.025052592158317566\n",
      "Epoch 4726, Loss: 0.043362668715417385, Final Batch Loss: 0.013578708283603191\n",
      "Epoch 4727, Loss: 0.0323440944775939, Final Batch Loss: 0.010632897727191448\n",
      "Epoch 4728, Loss: 0.06908237561583519, Final Batch Loss: 0.04573478177189827\n",
      "Epoch 4729, Loss: 0.025475542061030865, Final Batch Loss: 0.010758323594927788\n",
      "Epoch 4730, Loss: 0.04257648624479771, Final Batch Loss: 0.019696442410349846\n",
      "Epoch 4731, Loss: 0.061751920729875565, Final Batch Loss: 0.03504844754934311\n",
      "Epoch 4732, Loss: 0.01992821041494608, Final Batch Loss: 0.008991571143269539\n",
      "Epoch 4733, Loss: 0.048279112204909325, Final Batch Loss: 0.017087381333112717\n",
      "Epoch 4734, Loss: 0.0485148299485445, Final Batch Loss: 0.008812064304947853\n",
      "Epoch 4735, Loss: 0.1295463778078556, Final Batch Loss: 0.08272675424814224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4736, Loss: 0.023892766796052456, Final Batch Loss: 0.009712906554341316\n",
      "Epoch 4737, Loss: 0.02286219224333763, Final Batch Loss: 0.013004112057387829\n",
      "Epoch 4738, Loss: 0.09170351177453995, Final Batch Loss: 0.05783659592270851\n",
      "Epoch 4739, Loss: 0.02950519137084484, Final Batch Loss: 0.014592417515814304\n",
      "Epoch 4740, Loss: 0.029563426971435547, Final Batch Loss: 0.010636512190103531\n",
      "Epoch 4741, Loss: 0.043602682650089264, Final Batch Loss: 0.02467632293701172\n",
      "Epoch 4742, Loss: 0.03249047510325909, Final Batch Loss: 0.017886560410261154\n",
      "Epoch 4743, Loss: 0.02047168742865324, Final Batch Loss: 0.008971049450337887\n",
      "Epoch 4744, Loss: 0.02804542426019907, Final Batch Loss: 0.014749638736248016\n",
      "Epoch 4745, Loss: 0.016649825032800436, Final Batch Loss: 0.009132507257163525\n",
      "Epoch 4746, Loss: 0.03269634488970041, Final Batch Loss: 0.015233934856951237\n",
      "Epoch 4747, Loss: 0.05521832965314388, Final Batch Loss: 0.03759745508432388\n",
      "Epoch 4748, Loss: 0.09433901682496071, Final Batch Loss: 0.054727282375097275\n",
      "Epoch 4749, Loss: 0.020423027919605374, Final Batch Loss: 0.0035421245265752077\n",
      "Epoch 4750, Loss: 0.11035523563623428, Final Batch Loss: 0.03584299236536026\n",
      "Epoch 4751, Loss: 0.018156006932258606, Final Batch Loss: 0.0039034709334373474\n",
      "Epoch 4752, Loss: 0.0644156951457262, Final Batch Loss: 0.029754502698779106\n",
      "Epoch 4753, Loss: 0.04212958738207817, Final Batch Loss: 0.016724469140172005\n",
      "Epoch 4754, Loss: 0.08489682525396347, Final Batch Loss: 0.047566622495651245\n",
      "Epoch 4755, Loss: 0.035220175981521606, Final Batch Loss: 0.015967298299074173\n",
      "Epoch 4756, Loss: 0.0577513761818409, Final Batch Loss: 0.03341935575008392\n",
      "Epoch 4757, Loss: 0.036937073804438114, Final Batch Loss: 0.011203904636204243\n",
      "Epoch 4758, Loss: 0.06227260362356901, Final Batch Loss: 0.05356578901410103\n",
      "Epoch 4759, Loss: 0.08267339318990707, Final Batch Loss: 0.037106696516275406\n",
      "Epoch 4760, Loss: 0.10369037091732025, Final Batch Loss: 0.06623478978872299\n",
      "Epoch 4761, Loss: 0.04823816753923893, Final Batch Loss: 0.027890866622328758\n",
      "Epoch 4762, Loss: 0.05859093461185694, Final Batch Loss: 0.011469529010355473\n",
      "Epoch 4763, Loss: 0.11000481620430946, Final Batch Loss: 0.05401485785841942\n",
      "Epoch 4764, Loss: 0.0443175220862031, Final Batch Loss: 0.011243973858654499\n",
      "Epoch 4765, Loss: 0.057152191177010536, Final Batch Loss: 0.029341230168938637\n",
      "Epoch 4766, Loss: 0.053606076166033745, Final Batch Loss: 0.03671175613999367\n",
      "Epoch 4767, Loss: 0.053395217284560204, Final Batch Loss: 0.04017779603600502\n",
      "Epoch 4768, Loss: 0.05894007347524166, Final Batch Loss: 0.02456933818757534\n",
      "Epoch 4769, Loss: 0.027648023329675198, Final Batch Loss: 0.012086277827620506\n",
      "Epoch 4770, Loss: 0.03377262782305479, Final Batch Loss: 0.011346408165991306\n",
      "Epoch 4771, Loss: 0.06902590952813625, Final Batch Loss: 0.02846512757241726\n",
      "Epoch 4772, Loss: 0.06456467881798744, Final Batch Loss: 0.026667393743991852\n",
      "Epoch 4773, Loss: 0.1577040683478117, Final Batch Loss: 0.12856073677539825\n",
      "Epoch 4774, Loss: 0.08650865033268929, Final Batch Loss: 0.01603536680340767\n",
      "Epoch 4775, Loss: 0.10063621588051319, Final Batch Loss: 0.07682019472122192\n",
      "Epoch 4776, Loss: 0.11127026006579399, Final Batch Loss: 0.010043937712907791\n",
      "Epoch 4777, Loss: 0.099941685795784, Final Batch Loss: 0.040415775030851364\n",
      "Epoch 4778, Loss: 0.06275558099150658, Final Batch Loss: 0.024052131921052933\n",
      "Epoch 4779, Loss: 0.11414948105812073, Final Batch Loss: 0.05966716632246971\n",
      "Epoch 4780, Loss: 0.07598213106393814, Final Batch Loss: 0.036927901208400726\n",
      "Epoch 4781, Loss: 0.04078187607228756, Final Batch Loss: 0.016629008576273918\n",
      "Epoch 4782, Loss: 0.07527674455195665, Final Batch Loss: 0.01278113666921854\n",
      "Epoch 4783, Loss: 0.05059488117694855, Final Batch Loss: 0.016975045204162598\n",
      "Epoch 4784, Loss: 0.0643460676074028, Final Batch Loss: 0.019303426146507263\n",
      "Epoch 4785, Loss: 0.15654296427965164, Final Batch Loss: 0.12129475921392441\n",
      "Epoch 4786, Loss: 0.11346820741891861, Final Batch Loss: 0.07982471585273743\n",
      "Epoch 4787, Loss: 0.08454487845301628, Final Batch Loss: 0.03509600833058357\n",
      "Epoch 4788, Loss: 0.07166732661426067, Final Batch Loss: 0.022822903469204903\n",
      "Epoch 4789, Loss: 0.07002487033605576, Final Batch Loss: 0.0456368662416935\n",
      "Epoch 4790, Loss: 0.055314041674137115, Final Batch Loss: 0.029396818950772285\n",
      "Epoch 4791, Loss: 0.10027867555618286, Final Batch Loss: 0.04559831693768501\n",
      "Epoch 4792, Loss: 0.05939937382936478, Final Batch Loss: 0.03064236044883728\n",
      "Epoch 4793, Loss: 0.08204087056219578, Final Batch Loss: 0.053324803709983826\n",
      "Epoch 4794, Loss: 0.10834366455674171, Final Batch Loss: 0.06294995546340942\n",
      "Epoch 4795, Loss: 0.06648213602602482, Final Batch Loss: 0.04716437682509422\n",
      "Epoch 4796, Loss: 0.13171563670039177, Final Batch Loss: 0.06985290348529816\n",
      "Epoch 4797, Loss: 0.08735341392457485, Final Batch Loss: 0.06779602915048599\n",
      "Epoch 4798, Loss: 0.1300881914794445, Final Batch Loss: 0.06934459507465363\n",
      "Epoch 4799, Loss: 0.08281744830310345, Final Batch Loss: 0.059705670922994614\n",
      "Epoch 4800, Loss: 0.07153919711709023, Final Batch Loss: 0.03383775055408478\n",
      "Epoch 4801, Loss: 0.08176674507558346, Final Batch Loss: 0.053391024470329285\n",
      "Epoch 4802, Loss: 0.09766938164830208, Final Batch Loss: 0.029602278023958206\n",
      "Epoch 4803, Loss: 0.09671656787395477, Final Batch Loss: 0.033127620816230774\n",
      "Epoch 4804, Loss: 0.08786225691437721, Final Batch Loss: 0.02377912774682045\n",
      "Epoch 4805, Loss: 0.05967296473681927, Final Batch Loss: 0.04431309551000595\n",
      "Epoch 4806, Loss: 0.0771527960896492, Final Batch Loss: 0.07031141221523285\n",
      "Epoch 4807, Loss: 0.10075844079256058, Final Batch Loss: 0.04558928310871124\n",
      "Epoch 4808, Loss: 0.1041982602328062, Final Batch Loss: 0.027923477813601494\n",
      "Epoch 4809, Loss: 0.0470220185816288, Final Batch Loss: 0.011913344264030457\n",
      "Epoch 4810, Loss: 0.0614631362259388, Final Batch Loss: 0.03160104155540466\n",
      "Epoch 4811, Loss: 0.0726122036576271, Final Batch Loss: 0.028449490666389465\n",
      "Epoch 4812, Loss: 0.04947906173765659, Final Batch Loss: 0.015673400834202766\n",
      "Epoch 4813, Loss: 0.10673434659838676, Final Batch Loss: 0.048780374228954315\n",
      "Epoch 4814, Loss: 0.03853396140038967, Final Batch Loss: 0.014579519629478455\n",
      "Epoch 4815, Loss: 0.03282981738448143, Final Batch Loss: 0.017048396170139313\n",
      "Epoch 4816, Loss: 0.11681642383337021, Final Batch Loss: 0.05180692672729492\n",
      "Epoch 4817, Loss: 0.0707347970455885, Final Batch Loss: 0.03009224869310856\n",
      "Epoch 4818, Loss: 0.06302675232291222, Final Batch Loss: 0.023117568343877792\n",
      "Epoch 4819, Loss: 0.04593848064541817, Final Batch Loss: 0.02835475094616413\n",
      "Epoch 4820, Loss: 0.04814575985074043, Final Batch Loss: 0.024173127487301826\n",
      "Epoch 4821, Loss: 0.042967237532138824, Final Batch Loss: 0.014422984793782234\n",
      "Epoch 4822, Loss: 0.05716345272958279, Final Batch Loss: 0.01965184696018696\n",
      "Epoch 4823, Loss: 0.08578697964549065, Final Batch Loss: 0.034660905599594116\n",
      "Epoch 4824, Loss: 0.03593289852142334, Final Batch Loss: 0.01505344733595848\n",
      "Epoch 4825, Loss: 0.07872115261852741, Final Batch Loss: 0.0489698089659214\n",
      "Epoch 4826, Loss: 0.026842516846954823, Final Batch Loss: 0.016169551759958267\n",
      "Epoch 4827, Loss: 0.06143919937312603, Final Batch Loss: 0.039173632860183716\n",
      "Epoch 4828, Loss: 0.03179229237139225, Final Batch Loss: 0.009672993794083595\n",
      "Epoch 4829, Loss: 0.07065988332033157, Final Batch Loss: 0.016162961721420288\n",
      "Epoch 4830, Loss: 0.06129813194274902, Final Batch Loss: 0.04446397349238396\n",
      "Epoch 4831, Loss: 0.03864169120788574, Final Batch Loss: 0.016507098451256752\n",
      "Epoch 4832, Loss: 0.07742408290505409, Final Batch Loss: 0.0633196160197258\n",
      "Epoch 4833, Loss: 0.042028180323541164, Final Batch Loss: 0.029405729845166206\n",
      "Epoch 4834, Loss: 0.03249248582869768, Final Batch Loss: 0.019535209983587265\n",
      "Epoch 4835, Loss: 0.0573982335627079, Final Batch Loss: 0.034122537821531296\n",
      "Epoch 4836, Loss: 0.09518957789987326, Final Batch Loss: 0.08076579868793488\n",
      "Epoch 4837, Loss: 0.03224711772054434, Final Batch Loss: 0.00983423087745905\n",
      "Epoch 4838, Loss: 0.03903443459421396, Final Batch Loss: 0.013095780275762081\n",
      "Epoch 4839, Loss: 0.036587249021977186, Final Batch Loss: 0.007022156845778227\n",
      "Epoch 4840, Loss: 0.09770475700497627, Final Batch Loss: 0.061792995780706406\n",
      "Epoch 4841, Loss: 0.02952373819425702, Final Batch Loss: 0.007289018947631121\n",
      "Epoch 4842, Loss: 0.0750819556415081, Final Batch Loss: 0.03973472863435745\n",
      "Epoch 4843, Loss: 0.09413367509841919, Final Batch Loss: 0.05355418473482132\n",
      "Epoch 4844, Loss: 0.08390909433364868, Final Batch Loss: 0.036103762686252594\n",
      "Epoch 4845, Loss: 0.05980519391596317, Final Batch Loss: 0.04085391387343407\n",
      "Epoch 4846, Loss: 0.041762507520616055, Final Batch Loss: 0.015599147416651249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4847, Loss: 0.1210121437907219, Final Batch Loss: 0.08924856781959534\n",
      "Epoch 4848, Loss: 0.04457064997404814, Final Batch Loss: 0.014864779077470303\n",
      "Epoch 4849, Loss: 0.040714507922530174, Final Batch Loss: 0.0077688079327344894\n",
      "Epoch 4850, Loss: 0.03817863576114178, Final Batch Loss: 0.018538590520620346\n",
      "Epoch 4851, Loss: 0.08603058010339737, Final Batch Loss: 0.050624679774045944\n",
      "Epoch 4852, Loss: 0.034944978542625904, Final Batch Loss: 0.020870478823781013\n",
      "Epoch 4853, Loss: 0.061305390670895576, Final Batch Loss: 0.021221959963440895\n",
      "Epoch 4854, Loss: 0.10292516648769379, Final Batch Loss: 0.053258635103702545\n",
      "Epoch 4855, Loss: 0.035023318603634834, Final Batch Loss: 0.008201615884900093\n",
      "Epoch 4856, Loss: 0.05563250556588173, Final Batch Loss: 0.031843703240156174\n",
      "Epoch 4857, Loss: 0.09700311161577702, Final Batch Loss: 0.07600434869527817\n",
      "Epoch 4858, Loss: 0.028825287707149982, Final Batch Loss: 0.008551637642085552\n",
      "Epoch 4859, Loss: 0.09218345209956169, Final Batch Loss: 0.05407599359750748\n",
      "Epoch 4860, Loss: 0.054041070863604546, Final Batch Loss: 0.019656406715512276\n",
      "Epoch 4861, Loss: 0.0251608956605196, Final Batch Loss: 0.017332106828689575\n",
      "Epoch 4862, Loss: 0.047054875642061234, Final Batch Loss: 0.005796410143375397\n",
      "Epoch 4863, Loss: 0.08665221184492111, Final Batch Loss: 0.05511770397424698\n",
      "Epoch 4864, Loss: 0.05172846745699644, Final Batch Loss: 0.012549574486911297\n",
      "Epoch 4865, Loss: 0.021899078972637653, Final Batch Loss: 0.008387885056436062\n",
      "Epoch 4866, Loss: 0.09456709399819374, Final Batch Loss: 0.06254655122756958\n",
      "Epoch 4867, Loss: 0.07567318947985768, Final Batch Loss: 0.06834439188241959\n",
      "Epoch 4868, Loss: 0.039888722356408834, Final Batch Loss: 0.006045819725841284\n",
      "Epoch 4869, Loss: 0.039546072483062744, Final Batch Loss: 0.029246650636196136\n",
      "Epoch 4870, Loss: 0.042357463389635086, Final Batch Loss: 0.013405585661530495\n",
      "Epoch 4871, Loss: 0.05495180934667587, Final Batch Loss: 0.02451038919389248\n",
      "Epoch 4872, Loss: 0.12660465389490128, Final Batch Loss: 0.07973233610391617\n",
      "Epoch 4873, Loss: 0.09174445644021034, Final Batch Loss: 0.028108973056077957\n",
      "Epoch 4874, Loss: 0.051635609939694405, Final Batch Loss: 0.015519129112362862\n",
      "Epoch 4875, Loss: 0.05033803544938564, Final Batch Loss: 0.027721816673874855\n",
      "Epoch 4876, Loss: 0.045959597453475, Final Batch Loss: 0.01943538896739483\n",
      "Epoch 4877, Loss: 0.08323136623948812, Final Batch Loss: 0.013662203215062618\n",
      "Epoch 4878, Loss: 0.08163078874349594, Final Batch Loss: 0.06822442263364792\n",
      "Epoch 4879, Loss: 0.047381188720464706, Final Batch Loss: 0.012453708797693253\n",
      "Epoch 4880, Loss: 0.041173920035362244, Final Batch Loss: 0.010206114500761032\n",
      "Epoch 4881, Loss: 0.0720348209142685, Final Batch Loss: 0.04337747395038605\n",
      "Epoch 4882, Loss: 0.11405509896576405, Final Batch Loss: 0.0859202966094017\n",
      "Epoch 4883, Loss: 0.07584200985729694, Final Batch Loss: 0.06180460751056671\n",
      "Epoch 4884, Loss: 0.03355458192527294, Final Batch Loss: 0.02130335010588169\n",
      "Epoch 4885, Loss: 0.03322208672761917, Final Batch Loss: 0.016449902206659317\n",
      "Epoch 4886, Loss: 0.028060756623744965, Final Batch Loss: 0.009587449952960014\n",
      "Epoch 4887, Loss: 0.07401480618864298, Final Batch Loss: 0.013920360244810581\n",
      "Epoch 4888, Loss: 0.02462794352322817, Final Batch Loss: 0.010775863192975521\n",
      "Epoch 4889, Loss: 0.052250105887651443, Final Batch Loss: 0.006481461226940155\n",
      "Epoch 4890, Loss: 0.12912552431225777, Final Batch Loss: 0.08182575553655624\n",
      "Epoch 4891, Loss: 0.037066707387566566, Final Batch Loss: 0.018730871379375458\n",
      "Epoch 4892, Loss: 0.04863406531512737, Final Batch Loss: 0.03954450413584709\n",
      "Epoch 4893, Loss: 0.06523756496608257, Final Batch Loss: 0.0302861537784338\n",
      "Epoch 4894, Loss: 0.08962441980838776, Final Batch Loss: 0.0707312747836113\n",
      "Epoch 4895, Loss: 0.053756289184093475, Final Batch Loss: 0.027991363778710365\n",
      "Epoch 4896, Loss: 0.015892858617007732, Final Batch Loss: 0.007697117514908314\n",
      "Epoch 4897, Loss: 0.03912064991891384, Final Batch Loss: 0.026540610939264297\n",
      "Epoch 4898, Loss: 0.08739148546010256, Final Batch Loss: 0.07674093544483185\n",
      "Epoch 4899, Loss: 0.02495991950854659, Final Batch Loss: 0.006160351913422346\n",
      "Epoch 4900, Loss: 0.02524498663842678, Final Batch Loss: 0.008630605414509773\n",
      "Epoch 4901, Loss: 0.06310744676738977, Final Batch Loss: 0.015247815288603306\n",
      "Epoch 4902, Loss: 0.0630187839269638, Final Batch Loss: 0.0417548343539238\n",
      "Epoch 4903, Loss: 0.10410354938358068, Final Batch Loss: 0.00827039685100317\n",
      "Epoch 4904, Loss: 0.07169513683766127, Final Batch Loss: 0.05815272405743599\n",
      "Epoch 4905, Loss: 0.06900283601135015, Final Batch Loss: 0.057680319994688034\n",
      "Epoch 4906, Loss: 0.045778450556099415, Final Batch Loss: 0.03357905149459839\n",
      "Epoch 4907, Loss: 0.05919232312589884, Final Batch Loss: 0.008771591819822788\n",
      "Epoch 4908, Loss: 0.1160273589193821, Final Batch Loss: 0.05039296671748161\n",
      "Epoch 4909, Loss: 0.030341027304530144, Final Batch Loss: 0.014933654107153416\n",
      "Epoch 4910, Loss: 0.026532139629125595, Final Batch Loss: 0.009669099003076553\n",
      "Epoch 4911, Loss: 0.0456763431429863, Final Batch Loss: 0.008134808391332626\n",
      "Epoch 4912, Loss: 0.06951487809419632, Final Batch Loss: 0.024122003465890884\n",
      "Epoch 4913, Loss: 0.07621678337454796, Final Batch Loss: 0.02395673096179962\n",
      "Epoch 4914, Loss: 0.0369756855070591, Final Batch Loss: 0.010918507352471352\n",
      "Epoch 4915, Loss: 0.051831141114234924, Final Batch Loss: 0.026395201683044434\n",
      "Epoch 4916, Loss: 0.04109104536473751, Final Batch Loss: 0.02538270875811577\n",
      "Epoch 4917, Loss: 0.05060422420501709, Final Batch Loss: 0.01428234949707985\n",
      "Epoch 4918, Loss: 0.18268142640590668, Final Batch Loss: 0.14386960864067078\n",
      "Epoch 4919, Loss: 0.05332767590880394, Final Batch Loss: 0.016539886593818665\n",
      "Epoch 4920, Loss: 0.10068099200725555, Final Batch Loss: 0.054299622774124146\n",
      "Epoch 4921, Loss: 0.08656618930399418, Final Batch Loss: 0.06597714126110077\n",
      "Epoch 4922, Loss: 0.07203172706067562, Final Batch Loss: 0.028173940256237984\n",
      "Epoch 4923, Loss: 0.022918781265616417, Final Batch Loss: 0.008360269479453564\n",
      "Epoch 4924, Loss: 0.04993583261966705, Final Batch Loss: 0.01907498575747013\n",
      "Epoch 4925, Loss: 0.03931109979748726, Final Batch Loss: 0.010231247171759605\n",
      "Epoch 4926, Loss: 0.02894282154738903, Final Batch Loss: 0.010373635217547417\n",
      "Epoch 4927, Loss: 0.08467937633395195, Final Batch Loss: 0.03295065090060234\n",
      "Epoch 4928, Loss: 0.036096688359975815, Final Batch Loss: 0.01894649863243103\n",
      "Epoch 4929, Loss: 0.014783626887947321, Final Batch Loss: 0.005930579733103514\n",
      "Epoch 4930, Loss: 0.032709481194615364, Final Batch Loss: 0.024587305262684822\n",
      "Epoch 4931, Loss: 0.040661074221134186, Final Batch Loss: 0.010944057255983353\n",
      "Epoch 4932, Loss: 0.03255971521139145, Final Batch Loss: 0.012636858969926834\n",
      "Epoch 4933, Loss: 0.05019878409802914, Final Batch Loss: 0.02231523208320141\n",
      "Epoch 4934, Loss: 0.058524515479803085, Final Batch Loss: 0.022753432393074036\n",
      "Epoch 4935, Loss: 0.01628592750057578, Final Batch Loss: 0.006022111978381872\n",
      "Epoch 4936, Loss: 0.06202035956084728, Final Batch Loss: 0.020391670987010002\n",
      "Epoch 4937, Loss: 0.09411496669054031, Final Batch Loss: 0.0444532074034214\n",
      "Epoch 4938, Loss: 0.059872872196137905, Final Batch Loss: 0.04864710941910744\n",
      "Epoch 4939, Loss: 0.08061813190579414, Final Batch Loss: 0.025064870715141296\n",
      "Epoch 4940, Loss: 0.05631862208247185, Final Batch Loss: 0.03769117593765259\n",
      "Epoch 4941, Loss: 0.08631936646997929, Final Batch Loss: 0.07738953083753586\n",
      "Epoch 4942, Loss: 0.03776932926848531, Final Batch Loss: 0.03339160606265068\n",
      "Epoch 4943, Loss: 0.11316212639212608, Final Batch Loss: 0.03479744866490364\n",
      "Epoch 4944, Loss: 0.055700238794088364, Final Batch Loss: 0.03607914224267006\n",
      "Epoch 4945, Loss: 0.11330896615982056, Final Batch Loss: 0.09229248017072678\n",
      "Epoch 4946, Loss: 0.03850801009684801, Final Batch Loss: 0.026449060067534447\n",
      "Epoch 4947, Loss: 0.05473974347114563, Final Batch Loss: 0.023628629744052887\n",
      "Epoch 4948, Loss: 0.024609682150185108, Final Batch Loss: 0.007307753898203373\n",
      "Epoch 4949, Loss: 0.08020011708140373, Final Batch Loss: 0.03355244919657707\n",
      "Epoch 4950, Loss: 0.03844572976231575, Final Batch Loss: 0.019385594874620438\n",
      "Epoch 4951, Loss: 0.0402998011559248, Final Batch Loss: 0.018595479428768158\n",
      "Epoch 4952, Loss: 0.07982647977769375, Final Batch Loss: 0.011270320042967796\n",
      "Epoch 4953, Loss: 0.05948852188885212, Final Batch Loss: 0.03760688006877899\n",
      "Epoch 4954, Loss: 0.08409599214792252, Final Batch Loss: 0.042246200144290924\n",
      "Epoch 4955, Loss: 0.04688812326639891, Final Batch Loss: 0.015101260505616665\n",
      "Epoch 4956, Loss: 0.034171322360634804, Final Batch Loss: 0.01597747765481472\n",
      "Epoch 4957, Loss: 0.05117581598460674, Final Batch Loss: 0.021893007680773735\n",
      "Epoch 4958, Loss: 0.03638239298015833, Final Batch Loss: 0.013482439331710339\n",
      "Epoch 4959, Loss: 0.07467965688556433, Final Batch Loss: 0.011363006196916103\n",
      "Epoch 4960, Loss: 0.0381326787173748, Final Batch Loss: 0.023574311286211014\n",
      "Epoch 4961, Loss: 0.03297044150531292, Final Batch Loss: 0.012989887967705727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4962, Loss: 0.036525264382362366, Final Batch Loss: 0.008763235062360764\n",
      "Epoch 4963, Loss: 0.029684318462386727, Final Batch Loss: 0.02736683189868927\n",
      "Epoch 4964, Loss: 0.04699908336624503, Final Batch Loss: 0.005218998994678259\n",
      "Epoch 4965, Loss: 0.14282003231346607, Final Batch Loss: 0.1236017718911171\n",
      "Epoch 4966, Loss: 0.06032184977084398, Final Batch Loss: 0.048999737948179245\n",
      "Epoch 4967, Loss: 0.09121967852115631, Final Batch Loss: 0.045387908816337585\n",
      "Epoch 4968, Loss: 0.0936163179576397, Final Batch Loss: 0.03331755846738815\n",
      "Epoch 4969, Loss: 0.09759348258376122, Final Batch Loss: 0.01847795769572258\n",
      "Epoch 4970, Loss: 0.059398023411631584, Final Batch Loss: 0.030512263998389244\n",
      "Epoch 4971, Loss: 0.04900637827813625, Final Batch Loss: 0.015856536105275154\n",
      "Epoch 4972, Loss: 0.0330607620999217, Final Batch Loss: 0.014416036196053028\n",
      "Epoch 4973, Loss: 0.02891141176223755, Final Batch Loss: 0.009261097759008408\n",
      "Epoch 4974, Loss: 0.04580942168831825, Final Batch Loss: 0.019608864560723305\n",
      "Epoch 4975, Loss: 0.025558901950716972, Final Batch Loss: 0.0036435946822166443\n",
      "Epoch 4976, Loss: 0.0826514158397913, Final Batch Loss: 0.061100199818611145\n",
      "Epoch 4977, Loss: 0.011901176767423749, Final Batch Loss: 0.008070393465459347\n",
      "Epoch 4978, Loss: 0.03872650861740112, Final Batch Loss: 0.007014475762844086\n",
      "Epoch 4979, Loss: 0.046782996505498886, Final Batch Loss: 0.032259151339530945\n",
      "Epoch 4980, Loss: 0.07887336239218712, Final Batch Loss: 0.03173195570707321\n",
      "Epoch 4981, Loss: 0.08815279044210911, Final Batch Loss: 0.057286061346530914\n",
      "Epoch 4982, Loss: 0.022600914351642132, Final Batch Loss: 0.008183242753148079\n",
      "Epoch 4983, Loss: 0.039786430075764656, Final Batch Loss: 0.021802887320518494\n",
      "Epoch 4984, Loss: 0.07559255138039589, Final Batch Loss: 0.04327762871980667\n",
      "Epoch 4985, Loss: 0.0251318896189332, Final Batch Loss: 0.01689659059047699\n",
      "Epoch 4986, Loss: 0.07920733001083136, Final Batch Loss: 0.015203609131276608\n",
      "Epoch 4987, Loss: 0.018536029383540154, Final Batch Loss: 0.007029828615486622\n",
      "Epoch 4988, Loss: 0.03986348584294319, Final Batch Loss: 0.017629720270633698\n",
      "Epoch 4989, Loss: 0.06491006724536419, Final Batch Loss: 0.0417071096599102\n",
      "Epoch 4990, Loss: 0.05367817543447018, Final Batch Loss: 0.0158992987126112\n",
      "Epoch 4991, Loss: 0.08346368744969368, Final Batch Loss: 0.04393652826547623\n",
      "Epoch 4992, Loss: 0.2030042763799429, Final Batch Loss: 0.1748213917016983\n",
      "Epoch 4993, Loss: 0.044772373512387276, Final Batch Loss: 0.028453052043914795\n",
      "Epoch 4994, Loss: 0.0727061415091157, Final Batch Loss: 0.01327683124691248\n",
      "Epoch 4995, Loss: 0.11737468093633652, Final Batch Loss: 0.0757693350315094\n",
      "Epoch 4996, Loss: 0.08893188089132309, Final Batch Loss: 0.031008973717689514\n",
      "Epoch 4997, Loss: 0.03358553163707256, Final Batch Loss: 0.007591575384140015\n",
      "Epoch 4998, Loss: 0.05492296768352389, Final Batch Loss: 0.007683783303946257\n",
      "Epoch 4999, Loss: 0.09627819433808327, Final Batch Loss: 0.03172755613923073\n",
      "Epoch 5000, Loss: 0.10663110949099064, Final Batch Loss: 0.08078118413686752\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  0  0]\n",
      " [ 0 29  0]\n",
      " [ 0  1 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        35\n",
      "           1    0.96667   1.00000   0.98305        29\n",
      "           2    1.00000   0.97222   0.98592        36\n",
      "\n",
      "    accuracy                        0.99000       100\n",
      "   macro avg    0.98889   0.99074   0.98966       100\n",
      "weighted avg    0.99033   0.99000   0.99001       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_labels = [0] * n_samples + [1] * n_samples + [2] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples\n",
    "fake_labels = np.asarray(fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  1  0]\n",
      " [ 2 25  3]\n",
      " [ 5  4 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80556   0.96667   0.87879        30\n",
      "           1    0.83333   0.83333   0.83333        30\n",
      "           2    0.87500   0.70000   0.77778        30\n",
      "\n",
      "    accuracy                        0.83333        90\n",
      "   macro avg    0.83796   0.83333   0.82997        90\n",
      "weighted avg    0.83796   0.83333   0.82997        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(fake_labels, preds.cpu()))\n",
    "print(metrics.classification_report(fake_labels, preds.cpu(), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
