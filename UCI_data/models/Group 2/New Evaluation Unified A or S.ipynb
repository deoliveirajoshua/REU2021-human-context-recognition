{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '125 tBodyGyro-std()-Y',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '138 tBodyGyro-energy()-Y',\n",
    " '165 tBodyGyroJerk-std()-Y',\n",
    " '168 tBodyGyroJerk-mad()-Y',\n",
    " '178 tBodyGyroJerk-energy()-Y',\n",
    " '181 tBodyGyroJerk-iqr()-Y',\n",
    " '425 fBodyGyro-mean()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '431 fBodyGyro-mad()-Y',\n",
    " '441 fBodyGyro-energy()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '478 fBodyGyro-bandsEnergy()-25,32',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '204 tBodyAccMag-max()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '217 tGravityAccMag-max()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '275 fBodyAcc-max()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '506 fBodyAccMag-max()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def get_act_matrix(batch_size, a_dim):\n",
    "    indexes = np.random.randint(a_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((len(indexes), indexes.max()+1))\n",
    "    one_hot[np.arange(len(indexes)),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "    \n",
    "def get_usr_matrix(batch_size, u_dim):\n",
    "    indexes = np.random.randint(u_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((indexes.size, indexes.max()+1))\n",
    "    one_hot[np.arange(indexes.size),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [7, 8, 11]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.189556121826172, Final Batch Loss: 1.095049262046814\n",
      "Epoch 2, Loss: 2.184676766395569, Final Batch Loss: 1.0925415754318237\n",
      "Epoch 3, Loss: 2.18072509765625, Final Batch Loss: 1.0892794132232666\n",
      "Epoch 4, Loss: 2.178658962249756, Final Batch Loss: 1.0903600454330444\n",
      "Epoch 5, Loss: 2.1705089807510376, Final Batch Loss: 1.083122730255127\n",
      "Epoch 6, Loss: 2.161190390586853, Final Batch Loss: 1.0746475458145142\n",
      "Epoch 7, Loss: 2.1628228425979614, Final Batch Loss: 1.0839437246322632\n",
      "Epoch 8, Loss: 2.15415620803833, Final Batch Loss: 1.0750361680984497\n",
      "Epoch 9, Loss: 2.1447118520736694, Final Batch Loss: 1.0677019357681274\n",
      "Epoch 10, Loss: 2.1410871744155884, Final Batch Loss: 1.0691503286361694\n",
      "Epoch 11, Loss: 2.1366323232650757, Final Batch Loss: 1.0684109926223755\n",
      "Epoch 12, Loss: 2.1290310621261597, Final Batch Loss: 1.0642881393432617\n",
      "Epoch 13, Loss: 2.1199722290039062, Final Batch Loss: 1.0564165115356445\n",
      "Epoch 14, Loss: 2.1068304777145386, Final Batch Loss: 1.0526783466339111\n",
      "Epoch 15, Loss: 2.096626400947571, Final Batch Loss: 1.048129916191101\n",
      "Epoch 16, Loss: 2.083460211753845, Final Batch Loss: 1.0358532667160034\n",
      "Epoch 17, Loss: 2.0690393447875977, Final Batch Loss: 1.0318094491958618\n",
      "Epoch 18, Loss: 2.057439088821411, Final Batch Loss: 1.0245139598846436\n",
      "Epoch 19, Loss: 2.0500482320785522, Final Batch Loss: 1.0270696878433228\n",
      "Epoch 20, Loss: 2.0184335708618164, Final Batch Loss: 1.0057545900344849\n",
      "Epoch 21, Loss: 2.002445936203003, Final Batch Loss: 0.9960857629776001\n",
      "Epoch 22, Loss: 1.9810713529586792, Final Batch Loss: 0.9864827990531921\n",
      "Epoch 23, Loss: 1.9569581151008606, Final Batch Loss: 0.980686366558075\n",
      "Epoch 24, Loss: 1.9235863089561462, Final Batch Loss: 0.9600454568862915\n",
      "Epoch 25, Loss: 1.8669184446334839, Final Batch Loss: 0.9221492409706116\n",
      "Epoch 26, Loss: 1.83807373046875, Final Batch Loss: 0.9184802770614624\n",
      "Epoch 27, Loss: 1.7978707551956177, Final Batch Loss: 0.8972558379173279\n",
      "Epoch 28, Loss: 1.7421497106552124, Final Batch Loss: 0.8794286847114563\n",
      "Epoch 29, Loss: 1.6927592158317566, Final Batch Loss: 0.8378081321716309\n",
      "Epoch 30, Loss: 1.6526801586151123, Final Batch Loss: 0.8312331438064575\n",
      "Epoch 31, Loss: 1.606206238269806, Final Batch Loss: 0.8158472776412964\n",
      "Epoch 32, Loss: 1.5411795377731323, Final Batch Loss: 0.7770474553108215\n",
      "Epoch 33, Loss: 1.43696528673172, Final Batch Loss: 0.6697298884391785\n",
      "Epoch 34, Loss: 1.3924978375434875, Final Batch Loss: 0.6515621542930603\n",
      "Epoch 35, Loss: 1.3606497645378113, Final Batch Loss: 0.6573906540870667\n",
      "Epoch 36, Loss: 1.2942543625831604, Final Batch Loss: 0.6379862427711487\n",
      "Epoch 37, Loss: 1.2257397770881653, Final Batch Loss: 0.6179425120353699\n",
      "Epoch 38, Loss: 1.2329174876213074, Final Batch Loss: 0.6356112957000732\n",
      "Epoch 39, Loss: 1.1884292364120483, Final Batch Loss: 0.573688805103302\n",
      "Epoch 40, Loss: 1.1609127521514893, Final Batch Loss: 0.6164211630821228\n",
      "Epoch 41, Loss: 1.1139867305755615, Final Batch Loss: 0.5742806792259216\n",
      "Epoch 42, Loss: 1.0453341901302338, Final Batch Loss: 0.4731813967227936\n",
      "Epoch 43, Loss: 1.0569186806678772, Final Batch Loss: 0.5328800082206726\n",
      "Epoch 44, Loss: 1.0356053113937378, Final Batch Loss: 0.5050774216651917\n",
      "Epoch 45, Loss: 1.0125025510787964, Final Batch Loss: 0.49852657318115234\n",
      "Epoch 46, Loss: 1.0032228827476501, Final Batch Loss: 0.4866296052932739\n",
      "Epoch 47, Loss: 1.0126219987869263, Final Batch Loss: 0.5027946829795837\n",
      "Epoch 48, Loss: 1.008922964334488, Final Batch Loss: 0.5095818042755127\n",
      "Epoch 49, Loss: 1.0136422216892242, Final Batch Loss: 0.5570499300956726\n",
      "Epoch 50, Loss: 0.9379364550113678, Final Batch Loss: 0.3954334557056427\n",
      "Epoch 51, Loss: 0.9791313111782074, Final Batch Loss: 0.48726534843444824\n",
      "Epoch 52, Loss: 0.9499369561672211, Final Batch Loss: 0.4807273745536804\n",
      "Epoch 53, Loss: 1.0053066313266754, Final Batch Loss: 0.5325787663459778\n",
      "Epoch 54, Loss: 0.9319954514503479, Final Batch Loss: 0.42712461948394775\n",
      "Epoch 55, Loss: 0.8996125161647797, Final Batch Loss: 0.4033050239086151\n",
      "Epoch 56, Loss: 0.9687244296073914, Final Batch Loss: 0.516076922416687\n",
      "Epoch 57, Loss: 0.9196903705596924, Final Batch Loss: 0.4490492641925812\n",
      "Epoch 58, Loss: 0.926565408706665, Final Batch Loss: 0.44844406843185425\n",
      "Epoch 59, Loss: 0.892209380865097, Final Batch Loss: 0.4170111119747162\n",
      "Epoch 60, Loss: 0.8961791694164276, Final Batch Loss: 0.4451814591884613\n",
      "Epoch 61, Loss: 0.8838436305522919, Final Batch Loss: 0.4138212203979492\n",
      "Epoch 62, Loss: 0.9220284521579742, Final Batch Loss: 0.4658311903476715\n",
      "Epoch 63, Loss: 0.8892751336097717, Final Batch Loss: 0.4378209412097931\n",
      "Epoch 64, Loss: 0.8702678084373474, Final Batch Loss: 0.399540513753891\n",
      "Epoch 65, Loss: 0.9006598591804504, Final Batch Loss: 0.4664592146873474\n",
      "Epoch 66, Loss: 0.8449980914592743, Final Batch Loss: 0.3994501233100891\n",
      "Epoch 67, Loss: 0.8503772020339966, Final Batch Loss: 0.3969736695289612\n",
      "Epoch 68, Loss: 0.8513814806938171, Final Batch Loss: 0.4184179902076721\n",
      "Epoch 69, Loss: 0.902448445558548, Final Batch Loss: 0.48497793078422546\n",
      "Epoch 70, Loss: 0.8198800086975098, Final Batch Loss: 0.3961246907711029\n",
      "Epoch 71, Loss: 0.8594502210617065, Final Batch Loss: 0.44072186946868896\n",
      "Epoch 72, Loss: 0.8762784004211426, Final Batch Loss: 0.5133554339408875\n",
      "Epoch 73, Loss: 0.8405331969261169, Final Batch Loss: 0.42469021677970886\n",
      "Epoch 74, Loss: 0.8438814282417297, Final Batch Loss: 0.45181626081466675\n",
      "Epoch 75, Loss: 0.9290097951889038, Final Batch Loss: 0.5440288186073303\n",
      "Epoch 76, Loss: 0.7832590043544769, Final Batch Loss: 0.36865586042404175\n",
      "Epoch 77, Loss: 0.8065920472145081, Final Batch Loss: 0.42970946431159973\n",
      "Epoch 78, Loss: 0.786096066236496, Final Batch Loss: 0.4030439853668213\n",
      "Epoch 79, Loss: 0.8231377303600311, Final Batch Loss: 0.419808954000473\n",
      "Epoch 80, Loss: 0.7661342024803162, Final Batch Loss: 0.36432886123657227\n",
      "Epoch 81, Loss: 0.7268562316894531, Final Batch Loss: 0.324577659368515\n",
      "Epoch 82, Loss: 0.7366518378257751, Final Batch Loss: 0.3835006654262543\n",
      "Epoch 83, Loss: 0.7183940410614014, Final Batch Loss: 0.38920775055885315\n",
      "Epoch 84, Loss: 0.6426587402820587, Final Batch Loss: 0.3311973512172699\n",
      "Epoch 85, Loss: 0.5760272443294525, Final Batch Loss: 0.2857625484466553\n",
      "Epoch 86, Loss: 0.565602034330368, Final Batch Loss: 0.27176377177238464\n",
      "Epoch 87, Loss: 0.5776792764663696, Final Batch Loss: 0.31315258145332336\n",
      "Epoch 88, Loss: 0.4832428991794586, Final Batch Loss: 0.2268020510673523\n",
      "Epoch 89, Loss: 0.4322173148393631, Final Batch Loss: 0.17443494498729706\n",
      "Epoch 90, Loss: 0.46444761753082275, Final Batch Loss: 0.2320130169391632\n",
      "Epoch 91, Loss: 0.4620586782693863, Final Batch Loss: 0.263023316860199\n",
      "Epoch 92, Loss: 0.38373224437236786, Final Batch Loss: 0.18917681276798248\n",
      "Epoch 93, Loss: 0.33684109151363373, Final Batch Loss: 0.1763000637292862\n",
      "Epoch 94, Loss: 0.3649674206972122, Final Batch Loss: 0.19267313182353973\n",
      "Epoch 95, Loss: 0.39029696583747864, Final Batch Loss: 0.21126626431941986\n",
      "Epoch 96, Loss: 0.3695720136165619, Final Batch Loss: 0.21001535654067993\n",
      "Epoch 97, Loss: 0.323237881064415, Final Batch Loss: 0.14996011555194855\n",
      "Epoch 98, Loss: 0.27929478883743286, Final Batch Loss: 0.12163399159908295\n",
      "Epoch 99, Loss: 0.3233615905046463, Final Batch Loss: 0.18079259991645813\n",
      "Epoch 100, Loss: 0.2779485136270523, Final Batch Loss: 0.11553193628787994\n",
      "Epoch 101, Loss: 0.2653036043047905, Final Batch Loss: 0.0992121621966362\n",
      "Epoch 102, Loss: 0.26237115263938904, Final Batch Loss: 0.1198602020740509\n",
      "Epoch 103, Loss: 0.27116312086582184, Final Batch Loss: 0.11949072778224945\n",
      "Epoch 104, Loss: 0.28793206810951233, Final Batch Loss: 0.1571129560470581\n",
      "Epoch 105, Loss: 0.23840631544589996, Final Batch Loss: 0.11204981803894043\n",
      "Epoch 106, Loss: 0.23845935612916946, Final Batch Loss: 0.08622320741415024\n",
      "Epoch 107, Loss: 0.33510828018188477, Final Batch Loss: 0.1801379919052124\n",
      "Epoch 108, Loss: 0.2744327560067177, Final Batch Loss: 0.15313047170639038\n",
      "Epoch 109, Loss: 0.2646653801202774, Final Batch Loss: 0.16572390496730804\n",
      "Epoch 110, Loss: 0.25791554898023605, Final Batch Loss: 0.14355073869228363\n",
      "Epoch 111, Loss: 0.18703873455524445, Final Batch Loss: 0.05825948715209961\n",
      "Epoch 112, Loss: 0.24941620975732803, Final Batch Loss: 0.12681221961975098\n",
      "Epoch 113, Loss: 0.27829425781965256, Final Batch Loss: 0.15401922166347504\n",
      "Epoch 114, Loss: 0.19786027073860168, Final Batch Loss: 0.10078746825456619\n",
      "Epoch 115, Loss: 0.2765054479241371, Final Batch Loss: 0.1799972802400589\n",
      "Epoch 116, Loss: 0.26927459239959717, Final Batch Loss: 0.13239915668964386\n",
      "Epoch 117, Loss: 0.22637388855218887, Final Batch Loss: 0.12154795974493027\n",
      "Epoch 118, Loss: 0.15545907244086266, Final Batch Loss: 0.04489896818995476\n",
      "Epoch 119, Loss: 0.2217339426279068, Final Batch Loss: 0.11796951293945312\n",
      "Epoch 120, Loss: 0.20777013152837753, Final Batch Loss: 0.08704468607902527\n",
      "Epoch 121, Loss: 0.21790910512208939, Final Batch Loss: 0.10136936604976654\n",
      "Epoch 122, Loss: 0.18112026154994965, Final Batch Loss: 0.07505497336387634\n",
      "Epoch 123, Loss: 0.21912646293640137, Final Batch Loss: 0.13394410908222198\n",
      "Epoch 124, Loss: 0.2324383333325386, Final Batch Loss: 0.1637086421251297\n",
      "Epoch 125, Loss: 0.20130463689565659, Final Batch Loss: 0.08795280009508133\n",
      "Epoch 126, Loss: 0.19477549195289612, Final Batch Loss: 0.07498160749673843\n",
      "Epoch 127, Loss: 0.20056719332933426, Final Batch Loss: 0.07512811571359634\n",
      "Epoch 128, Loss: 0.17983628064393997, Final Batch Loss: 0.06176719814538956\n",
      "Epoch 129, Loss: 0.19545414298772812, Final Batch Loss: 0.12149234116077423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130, Loss: 0.19412896782159805, Final Batch Loss: 0.11375118046998978\n",
      "Epoch 131, Loss: 0.18774664402008057, Final Batch Loss: 0.06718939542770386\n",
      "Epoch 132, Loss: 0.15959352999925613, Final Batch Loss: 0.08644562214612961\n",
      "Epoch 133, Loss: 0.21082370728254318, Final Batch Loss: 0.11432433873414993\n",
      "Epoch 134, Loss: 0.1319495178759098, Final Batch Loss: 0.031981442123651505\n",
      "Epoch 135, Loss: 0.11795098334550858, Final Batch Loss: 0.037660688161849976\n",
      "Epoch 136, Loss: 0.1811750903725624, Final Batch Loss: 0.11313951015472412\n",
      "Epoch 137, Loss: 0.1418714001774788, Final Batch Loss: 0.0686088502407074\n",
      "Epoch 138, Loss: 0.12117725610733032, Final Batch Loss: 0.0513744130730629\n",
      "Epoch 139, Loss: 0.16134177893400192, Final Batch Loss: 0.08252383768558502\n",
      "Epoch 140, Loss: 0.12526001036167145, Final Batch Loss: 0.05009336769580841\n",
      "Epoch 141, Loss: 0.13985393196344376, Final Batch Loss: 0.044275738298892975\n",
      "Epoch 142, Loss: 0.2069656327366829, Final Batch Loss: 0.11274254322052002\n",
      "Epoch 143, Loss: 0.12109891697764397, Final Batch Loss: 0.06431896984577179\n",
      "Epoch 144, Loss: 0.15328985452651978, Final Batch Loss: 0.0696016401052475\n",
      "Epoch 145, Loss: 0.08676161244511604, Final Batch Loss: 0.03777392953634262\n",
      "Epoch 146, Loss: 0.2254987135529518, Final Batch Loss: 0.1529064029455185\n",
      "Epoch 147, Loss: 0.11904197558760643, Final Batch Loss: 0.06293904036283493\n",
      "Epoch 148, Loss: 0.16505511105060577, Final Batch Loss: 0.08315115422010422\n",
      "Epoch 149, Loss: 0.13278558105230331, Final Batch Loss: 0.07490070909261703\n",
      "Epoch 150, Loss: 0.13797515630722046, Final Batch Loss: 0.05899751931428909\n",
      "Epoch 151, Loss: 0.1445922963321209, Final Batch Loss: 0.061528775840997696\n",
      "Epoch 152, Loss: 0.12386104092001915, Final Batch Loss: 0.06659194082021713\n",
      "Epoch 153, Loss: 0.11358929425477982, Final Batch Loss: 0.045214831829071045\n",
      "Epoch 154, Loss: 0.10837674327194691, Final Batch Loss: 0.027921447530388832\n",
      "Epoch 155, Loss: 0.14687710255384445, Final Batch Loss: 0.08551327884197235\n",
      "Epoch 156, Loss: 0.11951853334903717, Final Batch Loss: 0.04390987753868103\n",
      "Epoch 157, Loss: 0.11122247204184532, Final Batch Loss: 0.07131467014551163\n",
      "Epoch 158, Loss: 0.11393896117806435, Final Batch Loss: 0.05469804257154465\n",
      "Epoch 159, Loss: 0.07639171555638313, Final Batch Loss: 0.02134218066930771\n",
      "Epoch 160, Loss: 0.12567583844065666, Final Batch Loss: 0.09094912558794022\n",
      "Epoch 161, Loss: 0.11924552544951439, Final Batch Loss: 0.03162519261240959\n",
      "Epoch 162, Loss: 0.12491931766271591, Final Batch Loss: 0.06012849509716034\n",
      "Epoch 163, Loss: 0.09168661385774612, Final Batch Loss: 0.04074094817042351\n",
      "Epoch 164, Loss: 0.10345117002725601, Final Batch Loss: 0.034619010984897614\n",
      "Epoch 165, Loss: 0.14090196415781975, Final Batch Loss: 0.05324605479836464\n",
      "Epoch 166, Loss: 0.1099105030298233, Final Batch Loss: 0.037973225116729736\n",
      "Epoch 167, Loss: 0.1076277531683445, Final Batch Loss: 0.030492547899484634\n",
      "Epoch 168, Loss: 0.12170637398958206, Final Batch Loss: 0.029896698892116547\n",
      "Epoch 169, Loss: 0.09793863072991371, Final Batch Loss: 0.03238201513886452\n",
      "Epoch 170, Loss: 0.11222103610634804, Final Batch Loss: 0.057367388159036636\n",
      "Epoch 171, Loss: 0.08095471374690533, Final Batch Loss: 0.018069064244627953\n",
      "Epoch 172, Loss: 0.14794021099805832, Final Batch Loss: 0.09102227538824081\n",
      "Epoch 173, Loss: 0.08639366924762726, Final Batch Loss: 0.022645920515060425\n",
      "Epoch 174, Loss: 0.11504251137375832, Final Batch Loss: 0.073286272585392\n",
      "Epoch 175, Loss: 0.11074826866388321, Final Batch Loss: 0.033444516360759735\n",
      "Epoch 176, Loss: 0.11993356794118881, Final Batch Loss: 0.09007495641708374\n",
      "Epoch 177, Loss: 0.11397295445203781, Final Batch Loss: 0.02879875898361206\n",
      "Epoch 178, Loss: 0.09996970742940903, Final Batch Loss: 0.07922347635030746\n",
      "Epoch 179, Loss: 0.08396219834685326, Final Batch Loss: 0.022155486047267914\n",
      "Epoch 180, Loss: 0.09151949733495712, Final Batch Loss: 0.04571647197008133\n",
      "Epoch 181, Loss: 0.13402236253023148, Final Batch Loss: 0.10253355652093887\n",
      "Epoch 182, Loss: 0.12570805847644806, Final Batch Loss: 0.08359009027481079\n",
      "Epoch 183, Loss: 0.09528500586748123, Final Batch Loss: 0.03458872437477112\n",
      "Epoch 184, Loss: 0.09403521753847599, Final Batch Loss: 0.023938143625855446\n",
      "Epoch 185, Loss: 0.11826052516698837, Final Batch Loss: 0.07183907181024551\n",
      "Epoch 186, Loss: 0.14226504787802696, Final Batch Loss: 0.089046411216259\n",
      "Epoch 187, Loss: 0.11684129759669304, Final Batch Loss: 0.06681711971759796\n",
      "Epoch 188, Loss: 0.14803535863757133, Final Batch Loss: 0.10363521426916122\n",
      "Epoch 189, Loss: 0.1589876115322113, Final Batch Loss: 0.0408625602722168\n",
      "Epoch 190, Loss: 0.11983294412493706, Final Batch Loss: 0.08629561960697174\n",
      "Epoch 191, Loss: 0.11323696374893188, Final Batch Loss: 0.07632505893707275\n",
      "Epoch 192, Loss: 0.07002364657819271, Final Batch Loss: 0.024400250986218452\n",
      "Epoch 193, Loss: 0.07198800891637802, Final Batch Loss: 0.02283884957432747\n",
      "Epoch 194, Loss: 0.09083041921257973, Final Batch Loss: 0.03385383263230324\n",
      "Epoch 195, Loss: 0.09436071291565895, Final Batch Loss: 0.03249777480959892\n",
      "Epoch 196, Loss: 0.10002259165048599, Final Batch Loss: 0.045517463237047195\n",
      "Epoch 197, Loss: 0.11002764105796814, Final Batch Loss: 0.05747952684760094\n",
      "Epoch 198, Loss: 0.09578083083033562, Final Batch Loss: 0.054564494639635086\n",
      "Epoch 199, Loss: 0.0877466918900609, Final Batch Loss: 0.015262951143085957\n",
      "Epoch 200, Loss: 0.09865199029445648, Final Batch Loss: 0.06700324267148972\n",
      "Epoch 201, Loss: 0.09789656475186348, Final Batch Loss: 0.06929656118154526\n",
      "Epoch 202, Loss: 0.06337028183043003, Final Batch Loss: 0.030492180958390236\n",
      "Epoch 203, Loss: 0.06902003288269043, Final Batch Loss: 0.015035625547170639\n",
      "Epoch 204, Loss: 0.07891457807272673, Final Batch Loss: 0.014855208806693554\n",
      "Epoch 205, Loss: 0.08320481702685356, Final Batch Loss: 0.051778290420770645\n",
      "Epoch 206, Loss: 0.08150110580027103, Final Batch Loss: 0.024972112849354744\n",
      "Epoch 207, Loss: 0.09311284497380257, Final Batch Loss: 0.03917563706636429\n",
      "Epoch 208, Loss: 0.11395475082099438, Final Batch Loss: 0.028216784819960594\n",
      "Epoch 209, Loss: 0.11432389169931412, Final Batch Loss: 0.08731638640165329\n",
      "Epoch 210, Loss: 0.07756263390183449, Final Batch Loss: 0.02281053364276886\n",
      "Epoch 211, Loss: 0.10798398405313492, Final Batch Loss: 0.06249607726931572\n",
      "Epoch 212, Loss: 0.1621755100786686, Final Batch Loss: 0.12904618680477142\n",
      "Epoch 213, Loss: 0.075900724157691, Final Batch Loss: 0.026532107964158058\n",
      "Epoch 214, Loss: 0.12382397800683975, Final Batch Loss: 0.08899121731519699\n",
      "Epoch 215, Loss: 0.06940110772848129, Final Batch Loss: 0.01747388020157814\n",
      "Epoch 216, Loss: 0.1276213936507702, Final Batch Loss: 0.07856138795614243\n",
      "Epoch 217, Loss: 0.07633714005351067, Final Batch Loss: 0.020235367119312286\n",
      "Epoch 218, Loss: 0.13925953209400177, Final Batch Loss: 0.0772542878985405\n",
      "Epoch 219, Loss: 0.16017429158091545, Final Batch Loss: 0.1240040510892868\n",
      "Epoch 220, Loss: 0.09487693198025227, Final Batch Loss: 0.028248483315110207\n",
      "Epoch 221, Loss: 0.09734075516462326, Final Batch Loss: 0.042426515370607376\n",
      "Epoch 222, Loss: 0.09922793880105019, Final Batch Loss: 0.04259859398007393\n",
      "Epoch 223, Loss: 0.06513622589409351, Final Batch Loss: 0.020945997908711433\n",
      "Epoch 224, Loss: 0.09098194353282452, Final Batch Loss: 0.06644164770841599\n",
      "Epoch 225, Loss: 0.10349414497613907, Final Batch Loss: 0.019620321691036224\n",
      "Epoch 226, Loss: 0.10398238152265549, Final Batch Loss: 0.06442766636610031\n",
      "Epoch 227, Loss: 0.0828063115477562, Final Batch Loss: 0.060538019984960556\n",
      "Epoch 228, Loss: 0.08640627190470695, Final Batch Loss: 0.04249250143766403\n",
      "Epoch 229, Loss: 0.08341775462031364, Final Batch Loss: 0.04216781631112099\n",
      "Epoch 230, Loss: 0.09385832771658897, Final Batch Loss: 0.05647255480289459\n",
      "Epoch 231, Loss: 0.10638597793877125, Final Batch Loss: 0.08957673609256744\n",
      "Epoch 232, Loss: 0.06049448251724243, Final Batch Loss: 0.02029840275645256\n",
      "Epoch 233, Loss: 0.08615160174667835, Final Batch Loss: 0.06759028881788254\n",
      "Epoch 234, Loss: 0.06747693382203579, Final Batch Loss: 0.04403075575828552\n",
      "Epoch 235, Loss: 0.07367618754506111, Final Batch Loss: 0.057052720338106155\n",
      "Epoch 236, Loss: 0.0677083358168602, Final Batch Loss: 0.01876099780201912\n",
      "Epoch 237, Loss: 0.05732900649309158, Final Batch Loss: 0.023882903158664703\n",
      "Epoch 238, Loss: 0.04067880101501942, Final Batch Loss: 0.0118919238448143\n",
      "Epoch 239, Loss: 0.07245954312384129, Final Batch Loss: 0.024208473041653633\n",
      "Epoch 240, Loss: 0.044157846830785275, Final Batch Loss: 0.008788867853581905\n",
      "Epoch 241, Loss: 0.06140884570777416, Final Batch Loss: 0.03014042042195797\n",
      "Epoch 242, Loss: 0.05932312086224556, Final Batch Loss: 0.0315997339785099\n",
      "Epoch 243, Loss: 0.07001325488090515, Final Batch Loss: 0.031170997768640518\n",
      "Epoch 244, Loss: 0.0642104297876358, Final Batch Loss: 0.019087545573711395\n",
      "Epoch 245, Loss: 0.05754838325083256, Final Batch Loss: 0.013855887576937675\n",
      "Epoch 246, Loss: 0.10323059372603893, Final Batch Loss: 0.08597394078969955\n",
      "Epoch 247, Loss: 0.056230599991977215, Final Batch Loss: 0.006833004765212536\n",
      "Epoch 248, Loss: 0.08056657575070858, Final Batch Loss: 0.02676570974290371\n",
      "Epoch 249, Loss: 0.06262151896953583, Final Batch Loss: 0.025072991847991943\n",
      "Epoch 250, Loss: 0.06316082924604416, Final Batch Loss: 0.019231349229812622\n",
      "Epoch 251, Loss: 0.067510437220335, Final Batch Loss: 0.03132026270031929\n",
      "Epoch 252, Loss: 0.036708785220980644, Final Batch Loss: 0.018734971061348915\n",
      "Epoch 253, Loss: 0.10451132617890835, Final Batch Loss: 0.07819987088441849\n",
      "Epoch 254, Loss: 0.10068677738308907, Final Batch Loss: 0.06888575106859207\n",
      "Epoch 255, Loss: 0.04859909042716026, Final Batch Loss: 0.022172126919031143\n",
      "Epoch 256, Loss: 0.0900806300342083, Final Batch Loss: 0.0695023462176323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257, Loss: 0.06775691825896502, Final Batch Loss: 0.052913010120391846\n",
      "Epoch 258, Loss: 0.05590271111577749, Final Batch Loss: 0.004958777688443661\n",
      "Epoch 259, Loss: 0.07293853908777237, Final Batch Loss: 0.016956612467765808\n",
      "Epoch 260, Loss: 0.07440196350216866, Final Batch Loss: 0.024890299886465073\n",
      "Epoch 261, Loss: 0.08742409572005272, Final Batch Loss: 0.0724361464381218\n",
      "Epoch 262, Loss: 0.04399130027741194, Final Batch Loss: 0.010073269717395306\n",
      "Epoch 263, Loss: 0.04938771761953831, Final Batch Loss: 0.011109927669167519\n",
      "Epoch 264, Loss: 0.051086559891700745, Final Batch Loss: 0.021844036877155304\n",
      "Epoch 265, Loss: 0.059496477246284485, Final Batch Loss: 0.03467296063899994\n",
      "Epoch 266, Loss: 0.07428361847996712, Final Batch Loss: 0.04046666994690895\n",
      "Epoch 267, Loss: 0.04884255863726139, Final Batch Loss: 0.011085854843258858\n",
      "Epoch 268, Loss: 0.05101713538169861, Final Batch Loss: 0.01252610981464386\n",
      "Epoch 269, Loss: 0.06534925568848848, Final Batch Loss: 0.011463952250778675\n",
      "Epoch 270, Loss: 0.07094027101993561, Final Batch Loss: 0.01734832301735878\n",
      "Epoch 271, Loss: 0.037011963315308094, Final Batch Loss: 0.00924780871719122\n",
      "Epoch 272, Loss: 0.06435234099626541, Final Batch Loss: 0.02093258500099182\n",
      "Epoch 273, Loss: 0.051689134910702705, Final Batch Loss: 0.01698336936533451\n",
      "Epoch 274, Loss: 0.093072266317904, Final Batch Loss: 0.07921005040407181\n",
      "Epoch 275, Loss: 0.10872476920485497, Final Batch Loss: 0.06929321587085724\n",
      "Epoch 276, Loss: 0.0824003778398037, Final Batch Loss: 0.03190702199935913\n",
      "Epoch 277, Loss: 0.09021218679845333, Final Batch Loss: 0.02197241596877575\n",
      "Epoch 278, Loss: 0.03761816304177046, Final Batch Loss: 0.004554792307317257\n",
      "Epoch 279, Loss: 0.08146329782903194, Final Batch Loss: 0.05830008164048195\n",
      "Epoch 280, Loss: 0.05582723394036293, Final Batch Loss: 0.02486235275864601\n",
      "Epoch 281, Loss: 0.027651155833154917, Final Batch Loss: 0.006029693875461817\n",
      "Epoch 282, Loss: 0.038586861453950405, Final Batch Loss: 0.012416823767125607\n",
      "Epoch 283, Loss: 0.04104915913194418, Final Batch Loss: 0.009564979933202267\n",
      "Epoch 284, Loss: 0.06886732950806618, Final Batch Loss: 0.0262555293738842\n",
      "Epoch 285, Loss: 0.12909101136028767, Final Batch Loss: 0.10743241757154465\n",
      "Epoch 286, Loss: 0.0492809172719717, Final Batch Loss: 0.012999473139643669\n",
      "Epoch 287, Loss: 0.024032325483858585, Final Batch Loss: 0.004619748331606388\n",
      "Epoch 288, Loss: 0.053835147991776466, Final Batch Loss: 0.020363042131066322\n",
      "Epoch 289, Loss: 0.06569010391831398, Final Batch Loss: 0.02924482151865959\n",
      "Epoch 290, Loss: 0.05666683241724968, Final Batch Loss: 0.022838205099105835\n",
      "Epoch 291, Loss: 0.06827423721551895, Final Batch Loss: 0.0330071784555912\n",
      "Epoch 292, Loss: 0.09759640693664551, Final Batch Loss: 0.07672078162431717\n",
      "Epoch 293, Loss: 0.09033862594515085, Final Batch Loss: 0.07895777374505997\n",
      "Epoch 294, Loss: 0.051682423800230026, Final Batch Loss: 0.01963767409324646\n",
      "Epoch 295, Loss: 0.05822530575096607, Final Batch Loss: 0.036867350339889526\n",
      "Epoch 296, Loss: 0.03947143815457821, Final Batch Loss: 0.009478248655796051\n",
      "Epoch 297, Loss: 0.04509203601628542, Final Batch Loss: 0.007666957564651966\n",
      "Epoch 298, Loss: 0.059598708525300026, Final Batch Loss: 0.02799694426357746\n",
      "Epoch 299, Loss: 0.042675494216382504, Final Batch Loss: 0.027058230713009834\n",
      "Epoch 300, Loss: 0.03960730694234371, Final Batch Loss: 0.010658731684088707\n",
      "Epoch 301, Loss: 0.043140679597854614, Final Batch Loss: 0.03318285197019577\n",
      "Epoch 302, Loss: 0.057703347876667976, Final Batch Loss: 0.023163413628935814\n",
      "Epoch 303, Loss: 0.10626137256622314, Final Batch Loss: 0.08837258070707321\n",
      "Epoch 304, Loss: 0.04070020280778408, Final Batch Loss: 0.01935100182890892\n",
      "Epoch 305, Loss: 0.028554984368383884, Final Batch Loss: 0.014392751269042492\n",
      "Epoch 306, Loss: 0.03921290673315525, Final Batch Loss: 0.021402422338724136\n",
      "Epoch 307, Loss: 0.059862857684493065, Final Batch Loss: 0.026501262560486794\n",
      "Epoch 308, Loss: 0.03577324561774731, Final Batch Loss: 0.018790265545248985\n",
      "Epoch 309, Loss: 0.054288994520902634, Final Batch Loss: 0.042151208966970444\n",
      "Epoch 310, Loss: 0.04631543159484863, Final Batch Loss: 0.0276508592069149\n",
      "Epoch 311, Loss: 0.06335779465734959, Final Batch Loss: 0.048306774348020554\n",
      "Epoch 312, Loss: 0.05712801590561867, Final Batch Loss: 0.0212005153298378\n",
      "Epoch 313, Loss: 0.06194380111992359, Final Batch Loss: 0.038200270384550095\n",
      "Epoch 314, Loss: 0.042698255740106106, Final Batch Loss: 0.007071866653859615\n",
      "Epoch 315, Loss: 0.03502837661653757, Final Batch Loss: 0.006511476822197437\n",
      "Epoch 316, Loss: 0.05075157433748245, Final Batch Loss: 0.0181148461997509\n",
      "Epoch 317, Loss: 0.057437436655163765, Final Batch Loss: 0.010948410257697105\n",
      "Epoch 318, Loss: 0.05986789055168629, Final Batch Loss: 0.02833484672009945\n",
      "Epoch 319, Loss: 0.07021377701312304, Final Batch Loss: 0.05789186805486679\n",
      "Epoch 320, Loss: 0.07468799408525229, Final Batch Loss: 0.0127488998696208\n",
      "Epoch 321, Loss: 0.03298833593726158, Final Batch Loss: 0.016594022512435913\n",
      "Epoch 322, Loss: 0.05271695554256439, Final Batch Loss: 0.011735033243894577\n",
      "Epoch 323, Loss: 0.040295716375112534, Final Batch Loss: 0.03246685862541199\n",
      "Epoch 324, Loss: 0.060228381305933, Final Batch Loss: 0.014927249401807785\n",
      "Epoch 325, Loss: 0.04881331417709589, Final Batch Loss: 0.013713897205889225\n",
      "Epoch 326, Loss: 0.02521310281008482, Final Batch Loss: 0.010329040698707104\n",
      "Epoch 327, Loss: 0.03417980670928955, Final Batch Loss: 0.012497605755925179\n",
      "Epoch 328, Loss: 0.07868185266852379, Final Batch Loss: 0.06251785904169083\n",
      "Epoch 329, Loss: 0.05262698419392109, Final Batch Loss: 0.02161111682653427\n",
      "Epoch 330, Loss: 0.04825064539909363, Final Batch Loss: 0.022220274433493614\n",
      "Epoch 331, Loss: 0.06841777451336384, Final Batch Loss: 0.03842513635754585\n",
      "Epoch 332, Loss: 0.05001871753484011, Final Batch Loss: 0.009904258884489536\n",
      "Epoch 333, Loss: 0.034095149487257004, Final Batch Loss: 0.008262714371085167\n",
      "Epoch 334, Loss: 0.04336320701986551, Final Batch Loss: 0.014618721790611744\n",
      "Epoch 335, Loss: 0.04457044415175915, Final Batch Loss: 0.013933390378952026\n",
      "Epoch 336, Loss: 0.04711863165721297, Final Batch Loss: 0.005961553659290075\n",
      "Epoch 337, Loss: 0.028464294970035553, Final Batch Loss: 0.009197467938065529\n",
      "Epoch 338, Loss: 0.02454950287938118, Final Batch Loss: 0.0069572776556015015\n",
      "Epoch 339, Loss: 0.06263649184256792, Final Batch Loss: 0.04777149483561516\n",
      "Epoch 340, Loss: 0.03550969250500202, Final Batch Loss: 0.007957017049193382\n",
      "Epoch 341, Loss: 0.03044685162603855, Final Batch Loss: 0.005566231906414032\n",
      "Epoch 342, Loss: 0.023839903995394707, Final Batch Loss: 0.00845479965209961\n",
      "Epoch 343, Loss: 0.02675678674131632, Final Batch Loss: 0.010491213761270046\n",
      "Epoch 344, Loss: 0.03220698144286871, Final Batch Loss: 0.013729707337915897\n",
      "Epoch 345, Loss: 0.04596101865172386, Final Batch Loss: 0.010298214852809906\n",
      "Epoch 346, Loss: 0.05132358940318227, Final Batch Loss: 0.0440046563744545\n",
      "Epoch 347, Loss: 0.03703996725380421, Final Batch Loss: 0.014884153380990028\n",
      "Epoch 348, Loss: 0.04534144140779972, Final Batch Loss: 0.01798272132873535\n",
      "Epoch 349, Loss: 0.04972768481820822, Final Batch Loss: 0.034449562430381775\n",
      "Epoch 350, Loss: 0.02491405699402094, Final Batch Loss: 0.014157840050756931\n",
      "Epoch 351, Loss: 0.012106650741770864, Final Batch Loss: 0.003430911572650075\n",
      "Epoch 352, Loss: 0.025937121361494064, Final Batch Loss: 0.00767139159142971\n",
      "Epoch 353, Loss: 0.043513487093150616, Final Batch Loss: 0.011568981222808361\n",
      "Epoch 354, Loss: 0.04417072609066963, Final Batch Loss: 0.01811164617538452\n",
      "Epoch 355, Loss: 0.060709971468895674, Final Batch Loss: 0.053706105798482895\n",
      "Epoch 356, Loss: 0.041534630581736565, Final Batch Loss: 0.02033405192196369\n",
      "Epoch 357, Loss: 0.044198157265782356, Final Batch Loss: 0.013374943286180496\n",
      "Epoch 358, Loss: 0.03188072144985199, Final Batch Loss: 0.016039423644542694\n",
      "Epoch 359, Loss: 0.044986297376453876, Final Batch Loss: 0.031723782420158386\n",
      "Epoch 360, Loss: 0.03987885732203722, Final Batch Loss: 0.031726136803627014\n",
      "Epoch 361, Loss: 0.07154516503214836, Final Batch Loss: 0.05782607942819595\n",
      "Epoch 362, Loss: 0.035231143701821566, Final Batch Loss: 0.007730069104582071\n",
      "Epoch 363, Loss: 0.03493070974946022, Final Batch Loss: 0.018823223188519478\n",
      "Epoch 364, Loss: 0.033943286165595055, Final Batch Loss: 0.023576196283102036\n",
      "Epoch 365, Loss: 0.09703164547681808, Final Batch Loss: 0.08401945978403091\n",
      "Epoch 366, Loss: 0.05394923221319914, Final Batch Loss: 0.043922800570726395\n",
      "Epoch 367, Loss: 0.06859124451875687, Final Batch Loss: 0.04797210171818733\n",
      "Epoch 368, Loss: 0.05637792684137821, Final Batch Loss: 0.03958349674940109\n",
      "Epoch 369, Loss: 0.03158354479819536, Final Batch Loss: 0.010503548197448254\n",
      "Epoch 370, Loss: 0.03875923715531826, Final Batch Loss: 0.012346362695097923\n",
      "Epoch 371, Loss: 0.018845954909920692, Final Batch Loss: 0.0055737607181072235\n",
      "Epoch 372, Loss: 0.016906891018152237, Final Batch Loss: 0.005662131123244762\n",
      "Epoch 373, Loss: 0.01686984021216631, Final Batch Loss: 0.005811095237731934\n",
      "Epoch 374, Loss: 0.017817790154367685, Final Batch Loss: 0.005865280982106924\n",
      "Epoch 375, Loss: 0.017852654680609703, Final Batch Loss: 0.008979384787380695\n",
      "Epoch 376, Loss: 0.0314367413520813, Final Batch Loss: 0.014680080115795135\n",
      "Epoch 377, Loss: 0.02008312800899148, Final Batch Loss: 0.007201837841421366\n",
      "Epoch 378, Loss: 0.037305817008018494, Final Batch Loss: 0.015686847269535065\n",
      "Epoch 379, Loss: 0.01998175960034132, Final Batch Loss: 0.011635979637503624\n",
      "Epoch 380, Loss: 0.02986561506986618, Final Batch Loss: 0.0044919587671756744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381, Loss: 0.020436075516045094, Final Batch Loss: 0.004537581466138363\n",
      "Epoch 382, Loss: 0.054730916395783424, Final Batch Loss: 0.03435564413666725\n",
      "Epoch 383, Loss: 0.03402083180844784, Final Batch Loss: 0.008356388658285141\n",
      "Epoch 384, Loss: 0.05636603198945522, Final Batch Loss: 0.033982083201408386\n",
      "Epoch 385, Loss: 0.04131257254630327, Final Batch Loss: 0.01335382554680109\n",
      "Epoch 386, Loss: 0.02340454515069723, Final Batch Loss: 0.00893782265484333\n",
      "Epoch 387, Loss: 0.0630041528493166, Final Batch Loss: 0.048027537763118744\n",
      "Epoch 388, Loss: 0.02884893026202917, Final Batch Loss: 0.0054559847339987755\n",
      "Epoch 389, Loss: 0.016931725200265646, Final Batch Loss: 0.006495942827314138\n",
      "Epoch 390, Loss: 0.02005172148346901, Final Batch Loss: 0.009427341632544994\n",
      "Epoch 391, Loss: 0.035291386768221855, Final Batch Loss: 0.014745974913239479\n",
      "Epoch 392, Loss: 0.05902056209743023, Final Batch Loss: 0.03455940634012222\n",
      "Epoch 393, Loss: 0.021548299118876457, Final Batch Loss: 0.005665412172675133\n",
      "Epoch 394, Loss: 0.012921830639243126, Final Batch Loss: 0.006052512675523758\n",
      "Epoch 395, Loss: 0.022048959974199533, Final Batch Loss: 0.014770044013857841\n",
      "Epoch 396, Loss: 0.019043395295739174, Final Batch Loss: 0.009177406318485737\n",
      "Epoch 397, Loss: 0.013927395455539227, Final Batch Loss: 0.004417303018271923\n",
      "Epoch 398, Loss: 0.011687107849866152, Final Batch Loss: 0.0054391236044466496\n",
      "Epoch 399, Loss: 0.046183519065380096, Final Batch Loss: 0.03638212010264397\n",
      "Epoch 400, Loss: 0.022729665506631136, Final Batch Loss: 0.004818980116397142\n",
      "Epoch 401, Loss: 0.026450207456946373, Final Batch Loss: 0.012524963356554508\n",
      "Epoch 402, Loss: 0.024555832147598267, Final Batch Loss: 0.008633151650428772\n",
      "Epoch 403, Loss: 0.036994474940001965, Final Batch Loss: 0.022025421261787415\n",
      "Epoch 404, Loss: 0.017371937166899443, Final Batch Loss: 0.005162127781659365\n",
      "Epoch 405, Loss: 0.027190187014639378, Final Batch Loss: 0.020597826689481735\n",
      "Epoch 406, Loss: 0.029368873685598373, Final Batch Loss: 0.01085096038877964\n",
      "Epoch 407, Loss: 0.022627724334597588, Final Batch Loss: 0.010506373830139637\n",
      "Epoch 408, Loss: 0.021233163308352232, Final Batch Loss: 0.01704942062497139\n",
      "Epoch 409, Loss: 0.0471839252859354, Final Batch Loss: 0.013054134324193\n",
      "Epoch 410, Loss: 0.026906685438007116, Final Batch Loss: 0.004577751737087965\n",
      "Epoch 411, Loss: 0.007327006431296468, Final Batch Loss: 0.002183237811550498\n",
      "Epoch 412, Loss: 0.022883444093167782, Final Batch Loss: 0.004436374641954899\n",
      "Epoch 413, Loss: 0.02258388139307499, Final Batch Loss: 0.0064982883632183075\n",
      "Epoch 414, Loss: 0.028078054543584585, Final Batch Loss: 0.02109544165432453\n",
      "Epoch 415, Loss: 0.01691492088139057, Final Batch Loss: 0.011299769394099712\n",
      "Epoch 416, Loss: 0.016069710720330477, Final Batch Loss: 0.010861095041036606\n",
      "Epoch 417, Loss: 0.009152221959084272, Final Batch Loss: 0.0030163340270519257\n",
      "Epoch 418, Loss: 0.017367290798574686, Final Batch Loss: 0.006744507234543562\n",
      "Epoch 419, Loss: 0.036301514133811, Final Batch Loss: 0.029985230416059494\n",
      "Epoch 420, Loss: 0.018933604238554835, Final Batch Loss: 0.003098695306107402\n",
      "Epoch 421, Loss: 0.0142433512955904, Final Batch Loss: 0.004857219755649567\n",
      "Epoch 422, Loss: 0.014066241681575775, Final Batch Loss: 0.004319900646805763\n",
      "Epoch 423, Loss: 0.024537568911910057, Final Batch Loss: 0.010963463224470615\n",
      "Epoch 424, Loss: 0.026917632669210434, Final Batch Loss: 0.002543587237596512\n",
      "Epoch 425, Loss: 0.018755294382572174, Final Batch Loss: 0.01094870176166296\n",
      "Epoch 426, Loss: 0.007096326444298029, Final Batch Loss: 0.002842966467142105\n",
      "Epoch 427, Loss: 0.019059902522712946, Final Batch Loss: 0.012774156406521797\n",
      "Epoch 428, Loss: 0.0227815427351743, Final Batch Loss: 0.0021693699527531862\n",
      "Epoch 429, Loss: 0.028184703551232815, Final Batch Loss: 0.0018449509516358376\n",
      "Epoch 430, Loss: 0.009199087508022785, Final Batch Loss: 0.0027963616885244846\n",
      "Epoch 431, Loss: 0.01626493490766734, Final Batch Loss: 0.0017632226226851344\n",
      "Epoch 432, Loss: 0.012367134913802147, Final Batch Loss: 0.005638466216623783\n",
      "Epoch 433, Loss: 0.013683290220797062, Final Batch Loss: 0.004360776394605637\n",
      "Epoch 434, Loss: 0.016751282149925828, Final Batch Loss: 0.013194785453379154\n",
      "Epoch 435, Loss: 0.029294856823980808, Final Batch Loss: 0.015970002859830856\n",
      "Epoch 436, Loss: 0.02283843536861241, Final Batch Loss: 0.0189988911151886\n",
      "Epoch 437, Loss: 0.011037554126232862, Final Batch Loss: 0.002955938223749399\n",
      "Epoch 438, Loss: 0.010159319266676903, Final Batch Loss: 0.004707330837845802\n",
      "Epoch 439, Loss: 0.004959478508681059, Final Batch Loss: 0.001883193152025342\n",
      "Epoch 440, Loss: 0.02436963189393282, Final Batch Loss: 0.015301796607673168\n",
      "Epoch 441, Loss: 0.010674201883375645, Final Batch Loss: 0.0036796354688704014\n",
      "Epoch 442, Loss: 0.02843256387859583, Final Batch Loss: 0.007832403294742107\n",
      "Epoch 443, Loss: 0.014018099289387465, Final Batch Loss: 0.0066188545897603035\n",
      "Epoch 444, Loss: 0.037315601482987404, Final Batch Loss: 0.003477497026324272\n",
      "Epoch 445, Loss: 0.023989194072782993, Final Batch Loss: 0.00717549491673708\n",
      "Epoch 446, Loss: 0.01525443559512496, Final Batch Loss: 0.004378809127956629\n",
      "Epoch 447, Loss: 0.010082756169140339, Final Batch Loss: 0.0076422602869570255\n",
      "Epoch 448, Loss: 0.0066103419521823525, Final Batch Loss: 0.0009330512257292867\n",
      "Epoch 449, Loss: 0.010890098754316568, Final Batch Loss: 0.006488265469670296\n",
      "Epoch 450, Loss: 0.011620821431279182, Final Batch Loss: 0.007824425585567951\n",
      "Epoch 451, Loss: 0.016952397767454386, Final Batch Loss: 0.0058700586669147015\n",
      "Epoch 452, Loss: 0.02862414438277483, Final Batch Loss: 0.01690676063299179\n",
      "Epoch 453, Loss: 0.007275817915797234, Final Batch Loss: 0.003679961897432804\n",
      "Epoch 454, Loss: 0.019104789476841688, Final Batch Loss: 0.006232485640794039\n",
      "Epoch 455, Loss: 0.016211539041250944, Final Batch Loss: 0.01106256153434515\n",
      "Epoch 456, Loss: 0.01407804386690259, Final Batch Loss: 0.0048927911557257175\n",
      "Epoch 457, Loss: 0.03139170818030834, Final Batch Loss: 0.023474272340536118\n",
      "Epoch 458, Loss: 0.011199677013792098, Final Batch Loss: 0.0015580464387312531\n",
      "Epoch 459, Loss: 0.0056927737314254045, Final Batch Loss: 0.0027933623641729355\n",
      "Epoch 460, Loss: 0.012245963094756007, Final Batch Loss: 0.003309782361611724\n",
      "Epoch 461, Loss: 0.005531064118258655, Final Batch Loss: 0.0015332693001255393\n",
      "Epoch 462, Loss: 0.012199892662465572, Final Batch Loss: 0.0066427914425730705\n",
      "Epoch 463, Loss: 0.00936908705625683, Final Batch Loss: 0.001836189185269177\n",
      "Epoch 464, Loss: 0.02265567728318274, Final Batch Loss: 0.01933620125055313\n",
      "Epoch 465, Loss: 0.015200081281363964, Final Batch Loss: 0.005192635580897331\n",
      "Epoch 466, Loss: 0.009674736997112632, Final Batch Loss: 0.006770667620003223\n",
      "Epoch 467, Loss: 0.06414817832410336, Final Batch Loss: 0.04927979037165642\n",
      "Epoch 468, Loss: 0.0064847751054912806, Final Batch Loss: 0.004705869592726231\n",
      "Epoch 469, Loss: 0.02946543600410223, Final Batch Loss: 0.016345113515853882\n",
      "Epoch 470, Loss: 0.013231048360466957, Final Batch Loss: 0.0029323063790798187\n",
      "Epoch 471, Loss: 0.01984790526330471, Final Batch Loss: 0.008944133296608925\n",
      "Epoch 472, Loss: 0.006332039600238204, Final Batch Loss: 0.0038530812598764896\n",
      "Epoch 473, Loss: 0.01031702314503491, Final Batch Loss: 0.001803871477022767\n",
      "Epoch 474, Loss: 0.013269130140542984, Final Batch Loss: 0.007105013821274042\n",
      "Epoch 475, Loss: 0.03821922745555639, Final Batch Loss: 0.03303920477628708\n",
      "Epoch 476, Loss: 0.008159966790117323, Final Batch Loss: 0.0014139922568574548\n",
      "Epoch 477, Loss: 0.04617797117680311, Final Batch Loss: 0.03829779475927353\n",
      "Epoch 478, Loss: 0.010428644716739655, Final Batch Loss: 0.004309615585952997\n",
      "Epoch 479, Loss: 0.012774885632097721, Final Batch Loss: 0.005956418812274933\n",
      "Epoch 480, Loss: 0.01985023240558803, Final Batch Loss: 0.0034956138115376234\n",
      "Epoch 481, Loss: 0.01138041284866631, Final Batch Loss: 0.0035964169073849916\n",
      "Epoch 482, Loss: 0.022000369033776224, Final Batch Loss: 0.0014651924138888717\n",
      "Epoch 483, Loss: 0.020172221586108208, Final Batch Loss: 0.0074765849858522415\n",
      "Epoch 484, Loss: 0.011341361794620752, Final Batch Loss: 0.0048105488531291485\n",
      "Epoch 485, Loss: 0.06819909811019897, Final Batch Loss: 0.03167922422289848\n",
      "Epoch 486, Loss: 0.010371963027864695, Final Batch Loss: 0.0036289580166339874\n",
      "Epoch 487, Loss: 0.015335429459810257, Final Batch Loss: 0.007010309025645256\n",
      "Epoch 488, Loss: 0.019827986136078835, Final Batch Loss: 0.005629096180200577\n",
      "Epoch 489, Loss: 0.011795886792242527, Final Batch Loss: 0.00236421637237072\n",
      "Epoch 490, Loss: 0.015294850338250399, Final Batch Loss: 0.002224996220320463\n",
      "Epoch 491, Loss: 0.02129745576530695, Final Batch Loss: 0.014979124069213867\n",
      "Epoch 492, Loss: 0.011628357227891684, Final Batch Loss: 0.005214364733546972\n",
      "Epoch 493, Loss: 0.032846162328496575, Final Batch Loss: 0.030093412846326828\n",
      "Epoch 494, Loss: 0.007386579643934965, Final Batch Loss: 0.0018932134844362736\n",
      "Epoch 495, Loss: 0.015372668392956257, Final Batch Loss: 0.011389651335775852\n",
      "Epoch 496, Loss: 0.02265704155433923, Final Batch Loss: 0.0016509845154359937\n",
      "Epoch 497, Loss: 0.007171322591602802, Final Batch Loss: 0.0033697604667395353\n",
      "Epoch 498, Loss: 0.010708264540880919, Final Batch Loss: 0.006554204970598221\n",
      "Epoch 499, Loss: 0.021316723432391882, Final Batch Loss: 0.005333013366907835\n",
      "Epoch 500, Loss: 0.014138670638203621, Final Batch Loss: 0.003868713043630123\n",
      "Epoch 501, Loss: 0.007222360000014305, Final Batch Loss: 0.0020387079566717148\n",
      "Epoch 502, Loss: 0.019118707859888673, Final Batch Loss: 0.0024118556175380945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503, Loss: 0.014974287245422602, Final Batch Loss: 0.012766963802278042\n",
      "Epoch 504, Loss: 0.010161842219531536, Final Batch Loss: 0.004617310129106045\n",
      "Epoch 505, Loss: 0.014934339560568333, Final Batch Loss: 0.005777585320174694\n",
      "Epoch 506, Loss: 0.017299523577094078, Final Batch Loss: 0.004304235801100731\n",
      "Epoch 507, Loss: 0.013993288855999708, Final Batch Loss: 0.006233835592865944\n",
      "Epoch 508, Loss: 0.03044567024335265, Final Batch Loss: 0.02368018962442875\n",
      "Epoch 509, Loss: 0.008470481028780341, Final Batch Loss: 0.0013948052655905485\n",
      "Epoch 510, Loss: 0.0208883136510849, Final Batch Loss: 0.0106586879119277\n",
      "Epoch 511, Loss: 0.00462376547511667, Final Batch Loss: 0.0014730639522895217\n",
      "Epoch 512, Loss: 0.006588720949366689, Final Batch Loss: 0.002061184262856841\n",
      "Epoch 513, Loss: 0.008669006172567606, Final Batch Loss: 0.002223655115813017\n",
      "Epoch 514, Loss: 0.019681390840560198, Final Batch Loss: 0.01491270586848259\n",
      "Epoch 515, Loss: 0.01602329988963902, Final Batch Loss: 0.0026993651408702135\n",
      "Epoch 516, Loss: 0.007108991965651512, Final Batch Loss: 0.004993129055947065\n",
      "Epoch 517, Loss: 0.014761366648599505, Final Batch Loss: 0.0014407148119062185\n",
      "Epoch 518, Loss: 0.018655209220014513, Final Batch Loss: 0.0016689974581822753\n",
      "Epoch 519, Loss: 0.014543587807565928, Final Batch Loss: 0.001148500945419073\n",
      "Epoch 520, Loss: 0.004891882999800146, Final Batch Loss: 0.0032469341531395912\n",
      "Epoch 521, Loss: 0.013092879205942154, Final Batch Loss: 0.007314023096114397\n",
      "Epoch 522, Loss: 0.0064001972787082195, Final Batch Loss: 0.0007794671691954136\n",
      "Epoch 523, Loss: 0.04521930171176791, Final Batch Loss: 0.041093841195106506\n",
      "Epoch 524, Loss: 0.02100224234163761, Final Batch Loss: 0.0006441939622163773\n",
      "Epoch 525, Loss: 0.040355708450078964, Final Batch Loss: 0.03400091826915741\n",
      "Epoch 526, Loss: 0.01177488174289465, Final Batch Loss: 0.00645084073767066\n",
      "Epoch 527, Loss: 0.010891685262322426, Final Batch Loss: 0.0032063727267086506\n",
      "Epoch 528, Loss: 0.009383851429447532, Final Batch Loss: 0.002977504627779126\n",
      "Epoch 529, Loss: 0.013505642302334309, Final Batch Loss: 0.009219697676599026\n",
      "Epoch 530, Loss: 0.016397122060880065, Final Batch Loss: 0.0013034313451498747\n",
      "Epoch 531, Loss: 0.005570651264861226, Final Batch Loss: 0.0022442867048084736\n",
      "Epoch 532, Loss: 0.007285464555025101, Final Batch Loss: 0.002023847308009863\n",
      "Epoch 533, Loss: 0.034332505194470286, Final Batch Loss: 0.031029243022203445\n",
      "Epoch 534, Loss: 0.008538198890164495, Final Batch Loss: 0.006771280895918608\n",
      "Epoch 535, Loss: 0.005269644665531814, Final Batch Loss: 0.0018939293222501874\n",
      "Epoch 536, Loss: 0.01645471667870879, Final Batch Loss: 0.014083094894886017\n",
      "Epoch 537, Loss: 0.010476689552888274, Final Batch Loss: 0.0021081434097141027\n",
      "Epoch 538, Loss: 0.011185385752469301, Final Batch Loss: 0.0070497156120836735\n",
      "Epoch 539, Loss: 0.021211458835750818, Final Batch Loss: 0.004660645965486765\n",
      "Epoch 540, Loss: 0.006727138999849558, Final Batch Loss: 0.005028944928199053\n",
      "Epoch 541, Loss: 0.01596960425376892, Final Batch Loss: 0.006395433098077774\n",
      "Epoch 542, Loss: 0.0072498435620218515, Final Batch Loss: 0.005554168485105038\n",
      "Epoch 543, Loss: 0.006787752034142613, Final Batch Loss: 0.002346628112718463\n",
      "Epoch 544, Loss: 0.00875464966520667, Final Batch Loss: 0.005082819145172834\n",
      "Epoch 545, Loss: 0.007263736799359322, Final Batch Loss: 0.0026855142787098885\n",
      "Epoch 546, Loss: 0.024384542601183057, Final Batch Loss: 0.021097898483276367\n",
      "Epoch 547, Loss: 0.006296161445789039, Final Batch Loss: 0.001418803702108562\n",
      "Epoch 548, Loss: 0.009833285119384527, Final Batch Loss: 0.0051648239605128765\n",
      "Epoch 549, Loss: 0.009011512389406562, Final Batch Loss: 0.006661463528871536\n",
      "Epoch 550, Loss: 0.005373508203774691, Final Batch Loss: 0.0026721127796918154\n",
      "Epoch 551, Loss: 0.020913734566420317, Final Batch Loss: 0.014097176492214203\n",
      "Epoch 552, Loss: 0.005196237470954657, Final Batch Loss: 0.002304068999364972\n",
      "Epoch 553, Loss: 0.009397992864251137, Final Batch Loss: 0.004015448037534952\n",
      "Epoch 554, Loss: 0.007577185286208987, Final Batch Loss: 0.002980280900374055\n",
      "Epoch 555, Loss: 0.006291828234679997, Final Batch Loss: 0.001321028103120625\n",
      "Epoch 556, Loss: 0.00517400773242116, Final Batch Loss: 0.0024189732503145933\n",
      "Epoch 557, Loss: 0.008654515258967876, Final Batch Loss: 0.0030298312194645405\n",
      "Epoch 558, Loss: 0.032278033439069986, Final Batch Loss: 0.028713691979646683\n",
      "Epoch 559, Loss: 0.010707763954997063, Final Batch Loss: 0.0037447484210133553\n",
      "Epoch 560, Loss: 0.02088567614555359, Final Batch Loss: 0.015872567892074585\n",
      "Epoch 561, Loss: 0.0035294744884595275, Final Batch Loss: 0.0017105781007558107\n",
      "Epoch 562, Loss: 0.004588722251355648, Final Batch Loss: 0.0012417305260896683\n",
      "Epoch 563, Loss: 0.02116614510305226, Final Batch Loss: 0.0017100695986300707\n",
      "Epoch 564, Loss: 0.006135675241239369, Final Batch Loss: 0.0017463738331571221\n",
      "Epoch 565, Loss: 0.011862945277243853, Final Batch Loss: 0.00886955950409174\n",
      "Epoch 566, Loss: 0.010921502253040671, Final Batch Loss: 0.0012282633688300848\n",
      "Epoch 567, Loss: 0.011529503972269595, Final Batch Loss: 0.0009499039733782411\n",
      "Epoch 568, Loss: 0.014061284950003028, Final Batch Loss: 0.0014773046132177114\n",
      "Epoch 569, Loss: 0.005959285888820887, Final Batch Loss: 0.0028454100247472525\n",
      "Epoch 570, Loss: 0.010068868286907673, Final Batch Loss: 0.00427605677396059\n",
      "Epoch 571, Loss: 0.008315149927511811, Final Batch Loss: 0.0049287136644124985\n",
      "Epoch 572, Loss: 0.00671291712205857, Final Batch Loss: 0.005429174285382032\n",
      "Epoch 573, Loss: 0.013128944672644138, Final Batch Loss: 0.008639072068035603\n",
      "Epoch 574, Loss: 0.011775800492614508, Final Batch Loss: 0.0020665270276367664\n",
      "Epoch 575, Loss: 0.0052630179561674595, Final Batch Loss: 0.00204368494451046\n",
      "Epoch 576, Loss: 0.012916262727230787, Final Batch Loss: 0.009772520512342453\n",
      "Epoch 577, Loss: 0.007578283315524459, Final Batch Loss: 0.004201206378638744\n",
      "Epoch 578, Loss: 0.007329459069296718, Final Batch Loss: 0.0016833494883030653\n",
      "Epoch 579, Loss: 0.009831318515352905, Final Batch Loss: 0.0014586233301088214\n",
      "Epoch 580, Loss: 0.007337242946960032, Final Batch Loss: 0.00590061629191041\n",
      "Epoch 581, Loss: 0.014582415344193578, Final Batch Loss: 0.003639084519818425\n",
      "Epoch 582, Loss: 0.012534229084849358, Final Batch Loss: 0.007759454660117626\n",
      "Epoch 583, Loss: 0.008742289384827018, Final Batch Loss: 0.007369838654994965\n",
      "Epoch 584, Loss: 0.011574638541787863, Final Batch Loss: 0.010152207687497139\n",
      "Epoch 585, Loss: 0.002720694988965988, Final Batch Loss: 0.0012795949587598443\n",
      "Epoch 586, Loss: 0.011662141652777791, Final Batch Loss: 0.0026652321685105562\n",
      "Epoch 587, Loss: 0.013588912435807288, Final Batch Loss: 0.012939614243805408\n",
      "Epoch 588, Loss: 0.005166223272681236, Final Batch Loss: 0.001875728601589799\n",
      "Epoch 589, Loss: 0.006790352985262871, Final Batch Loss: 0.0036905703600496054\n",
      "Epoch 590, Loss: 0.0120948301628232, Final Batch Loss: 0.006910677533596754\n",
      "Epoch 591, Loss: 0.024892857298254967, Final Batch Loss: 0.009410894475877285\n",
      "Epoch 592, Loss: 0.0184860210865736, Final Batch Loss: 0.002007272094488144\n",
      "Epoch 593, Loss: 0.002642177452798933, Final Batch Loss: 0.0007828038069419563\n",
      "Epoch 594, Loss: 0.020135209430009127, Final Batch Loss: 0.014839835464954376\n",
      "Epoch 595, Loss: 0.023403143044561148, Final Batch Loss: 0.006835916545242071\n",
      "Epoch 596, Loss: 0.022650906816124916, Final Batch Loss: 0.012718478217720985\n",
      "Epoch 597, Loss: 0.005585126578807831, Final Batch Loss: 0.0031742905266582966\n",
      "Epoch 598, Loss: 0.006724031991325319, Final Batch Loss: 0.0007964748656377196\n",
      "Epoch 599, Loss: 0.011622348334640265, Final Batch Loss: 0.00200257683172822\n",
      "Epoch 600, Loss: 0.03420001454651356, Final Batch Loss: 0.024493316188454628\n",
      "Epoch 601, Loss: 0.0036094674142077565, Final Batch Loss: 0.001929230522364378\n",
      "Epoch 602, Loss: 0.004371622926555574, Final Batch Loss: 0.0013818162260577083\n",
      "Epoch 603, Loss: 0.004648612113669515, Final Batch Loss: 0.0017733033746480942\n",
      "Epoch 604, Loss: 0.019273788668215275, Final Batch Loss: 0.007273130118846893\n",
      "Epoch 605, Loss: 0.00851042103022337, Final Batch Loss: 0.0024500302970409393\n",
      "Epoch 606, Loss: 0.008232567459344864, Final Batch Loss: 0.001986559946089983\n",
      "Epoch 607, Loss: 0.0059755421243608, Final Batch Loss: 0.004076946061104536\n",
      "Epoch 608, Loss: 0.004523931536823511, Final Batch Loss: 0.0023010382428765297\n",
      "Epoch 609, Loss: 0.013593391515314579, Final Batch Loss: 0.0038509704172611237\n",
      "Epoch 610, Loss: 0.009152477607131004, Final Batch Loss: 0.001990994904190302\n",
      "Epoch 611, Loss: 0.01580780162476003, Final Batch Loss: 0.0022763104643672705\n",
      "Epoch 612, Loss: 0.004118685144931078, Final Batch Loss: 0.0018475058022886515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 613, Loss: 0.026645585079677403, Final Batch Loss: 0.024708496406674385\n",
      "Epoch 614, Loss: 0.01872031996026635, Final Batch Loss: 0.014756261371076107\n",
      "Epoch 615, Loss: 0.007866266067139804, Final Batch Loss: 0.0014483140548691154\n",
      "Epoch 616, Loss: 0.004141587181948125, Final Batch Loss: 0.0024141790345311165\n",
      "Epoch 617, Loss: 0.004416983341798186, Final Batch Loss: 0.002282578032463789\n",
      "Epoch 618, Loss: 0.010194049682468176, Final Batch Loss: 0.005099314730614424\n",
      "Epoch 619, Loss: 0.003298048279248178, Final Batch Loss: 0.0016631613252684474\n",
      "Epoch 620, Loss: 0.004360886057838798, Final Batch Loss: 0.0018263314850628376\n",
      "Epoch 621, Loss: 0.03610489470884204, Final Batch Loss: 0.02990667149424553\n",
      "Epoch 622, Loss: 0.017269091797061265, Final Batch Loss: 0.01559556182473898\n",
      "Epoch 623, Loss: 0.005470948526635766, Final Batch Loss: 0.004072513431310654\n",
      "Epoch 624, Loss: 0.005257194861769676, Final Batch Loss: 0.0028442046605050564\n",
      "Epoch 625, Loss: 0.007155016966862604, Final Batch Loss: 0.0003686919517349452\n",
      "Epoch 626, Loss: 0.010760580538772047, Final Batch Loss: 0.008987117558717728\n",
      "Epoch 627, Loss: 0.0036392101319506764, Final Batch Loss: 0.002161224139854312\n",
      "Epoch 628, Loss: 0.009837964549660683, Final Batch Loss: 0.006384423468261957\n",
      "Epoch 629, Loss: 0.011604850646108389, Final Batch Loss: 0.00747865904122591\n",
      "Epoch 630, Loss: 0.001739366096444428, Final Batch Loss: 0.000589333358220756\n",
      "Epoch 631, Loss: 0.004559174412861466, Final Batch Loss: 0.0034697141963988543\n",
      "Epoch 632, Loss: 0.014411641983315349, Final Batch Loss: 0.002000044798478484\n",
      "Epoch 633, Loss: 0.004635933320969343, Final Batch Loss: 0.0032812452409416437\n",
      "Epoch 634, Loss: 0.010128810768947005, Final Batch Loss: 0.0035871227737516165\n",
      "Epoch 635, Loss: 0.005819256883114576, Final Batch Loss: 0.002067317022010684\n",
      "Epoch 636, Loss: 0.012259566457942128, Final Batch Loss: 0.00231187348254025\n",
      "Epoch 637, Loss: 0.008624202571809292, Final Batch Loss: 0.005800981540232897\n",
      "Epoch 638, Loss: 0.002358502591960132, Final Batch Loss: 0.0008849455043673515\n",
      "Epoch 639, Loss: 0.003332455176860094, Final Batch Loss: 0.001577849849127233\n",
      "Epoch 640, Loss: 0.003798883524723351, Final Batch Loss: 0.0008142533479258418\n",
      "Epoch 641, Loss: 0.024418045999482274, Final Batch Loss: 0.0020642683375626802\n",
      "Epoch 642, Loss: 0.011883034370839596, Final Batch Loss: 0.004919364582747221\n",
      "Epoch 643, Loss: 0.006026622839272022, Final Batch Loss: 0.0040443530306220055\n",
      "Epoch 644, Loss: 0.0076503712916746736, Final Batch Loss: 0.0019117953488603234\n",
      "Epoch 645, Loss: 0.00829128036275506, Final Batch Loss: 0.002679645549505949\n",
      "Epoch 646, Loss: 0.007027146057225764, Final Batch Loss: 0.006017135921865702\n",
      "Epoch 647, Loss: 0.0074317308608442545, Final Batch Loss: 0.0030790555756539106\n",
      "Epoch 648, Loss: 0.006534343818202615, Final Batch Loss: 0.0045960526913404465\n",
      "Epoch 649, Loss: 0.008144836872816086, Final Batch Loss: 0.005180381238460541\n",
      "Epoch 650, Loss: 0.0041115962085314095, Final Batch Loss: 0.0007294642855413258\n",
      "Epoch 651, Loss: 0.005577195435762405, Final Batch Loss: 0.002856482518836856\n",
      "Epoch 652, Loss: 0.006213513668626547, Final Batch Loss: 0.0024225995875895023\n",
      "Epoch 653, Loss: 0.017553523648530245, Final Batch Loss: 0.01639031618833542\n",
      "Epoch 654, Loss: 0.004815482010599226, Final Batch Loss: 0.0008914716891013086\n",
      "Epoch 655, Loss: 0.007232245639897883, Final Batch Loss: 0.006031775381416082\n",
      "Epoch 656, Loss: 0.01277388446033001, Final Batch Loss: 0.006189342122524977\n",
      "Epoch 657, Loss: 0.010800790973007679, Final Batch Loss: 0.006632053758949041\n",
      "Epoch 658, Loss: 0.0037662656977772713, Final Batch Loss: 0.0016506100073456764\n",
      "Epoch 659, Loss: 0.004927751608192921, Final Batch Loss: 0.00045711034908890724\n",
      "Epoch 660, Loss: 0.004439198179170489, Final Batch Loss: 0.002128524938598275\n",
      "Epoch 661, Loss: 0.021097472170367837, Final Batch Loss: 0.0018445386085659266\n",
      "Epoch 662, Loss: 0.00864800123963505, Final Batch Loss: 0.0012160857440903783\n",
      "Epoch 663, Loss: 0.012682179920375347, Final Batch Loss: 0.003700559027493\n",
      "Epoch 664, Loss: 0.005208824295550585, Final Batch Loss: 0.0026709537487477064\n",
      "Epoch 665, Loss: 0.0028778479900211096, Final Batch Loss: 0.0015054879477247596\n",
      "Epoch 666, Loss: 0.0050706104375422, Final Batch Loss: 0.0019286952447146177\n",
      "Epoch 667, Loss: 0.00702285417355597, Final Batch Loss: 0.005423760507255793\n",
      "Epoch 668, Loss: 0.0023691856185905635, Final Batch Loss: 0.0007694842643104494\n",
      "Epoch 669, Loss: 0.0017179652350023389, Final Batch Loss: 0.000364121631719172\n",
      "Epoch 670, Loss: 0.0021501081064343452, Final Batch Loss: 0.0014046882279217243\n",
      "Epoch 671, Loss: 0.002978024771437049, Final Batch Loss: 0.0014147075125947595\n",
      "Epoch 672, Loss: 0.002321364590898156, Final Batch Loss: 0.0012606221716850996\n",
      "Epoch 673, Loss: 0.006535862572491169, Final Batch Loss: 0.0029134671203792095\n",
      "Epoch 674, Loss: 0.004964165738783777, Final Batch Loss: 0.0013724664459004998\n",
      "Epoch 675, Loss: 0.007230181945487857, Final Batch Loss: 0.004194687586277723\n",
      "Epoch 676, Loss: 0.011323124635964632, Final Batch Loss: 0.0020625325851142406\n",
      "Epoch 677, Loss: 0.002557532920036465, Final Batch Loss: 0.0007447547395713627\n",
      "Epoch 678, Loss: 0.00765010854229331, Final Batch Loss: 0.004271987359970808\n",
      "Epoch 679, Loss: 0.0031870907987467945, Final Batch Loss: 0.0009302580147050321\n",
      "Epoch 680, Loss: 0.0011246440699324012, Final Batch Loss: 0.0006939609884284437\n",
      "Epoch 681, Loss: 0.02678459696471691, Final Batch Loss: 0.011299856938421726\n",
      "Epoch 682, Loss: 0.008309930330142379, Final Batch Loss: 0.007181488908827305\n",
      "Epoch 683, Loss: 0.00422895944211632, Final Batch Loss: 0.0017055942444130778\n",
      "Epoch 684, Loss: 0.001233861781656742, Final Batch Loss: 0.00023905315902084112\n",
      "Epoch 685, Loss: 0.006342532578855753, Final Batch Loss: 0.003785594366490841\n",
      "Epoch 686, Loss: 0.003672270104289055, Final Batch Loss: 0.0026453277096152306\n",
      "Epoch 687, Loss: 0.009493250399827957, Final Batch Loss: 0.007358558475971222\n",
      "Epoch 688, Loss: 0.004283650778234005, Final Batch Loss: 0.003206956200301647\n",
      "Epoch 689, Loss: 0.026239014114253223, Final Batch Loss: 0.024920474737882614\n",
      "Epoch 690, Loss: 0.0054495190270245075, Final Batch Loss: 0.002786139491945505\n",
      "Epoch 691, Loss: 0.003791410243138671, Final Batch Loss: 0.0008378732018172741\n",
      "Epoch 692, Loss: 0.003835797542706132, Final Batch Loss: 0.0024029870983213186\n",
      "Epoch 693, Loss: 0.005980769405141473, Final Batch Loss: 0.003182805608958006\n",
      "Epoch 694, Loss: 0.004099880228750408, Final Batch Loss: 0.002577240113168955\n",
      "Epoch 695, Loss: 0.0029189211782068014, Final Batch Loss: 0.0014055059291422367\n",
      "Epoch 696, Loss: 0.004978186159860343, Final Batch Loss: 0.004039194900542498\n",
      "Epoch 697, Loss: 0.002729974454268813, Final Batch Loss: 0.0007979344809427857\n",
      "Epoch 698, Loss: 0.002532826561946422, Final Batch Loss: 0.0009556145523674786\n",
      "Epoch 699, Loss: 0.002888598421122879, Final Batch Loss: 0.002352503826841712\n",
      "Epoch 700, Loss: 0.0010409164242446423, Final Batch Loss: 0.0006379177211783826\n",
      "Epoch 701, Loss: 0.003587373183108866, Final Batch Loss: 0.002044662367552519\n",
      "Epoch 702, Loss: 0.01722879975568503, Final Batch Loss: 0.0014850356383249164\n",
      "Epoch 703, Loss: 0.002495589491445571, Final Batch Loss: 0.0005734500591643155\n",
      "Epoch 704, Loss: 0.015789230354130268, Final Batch Loss: 0.004214709624648094\n",
      "Epoch 705, Loss: 0.006276396103203297, Final Batch Loss: 0.0016490332782268524\n",
      "Epoch 706, Loss: 0.02720455266535282, Final Batch Loss: 0.023124245926737785\n",
      "Epoch 707, Loss: 0.01841127104125917, Final Batch Loss: 0.002485656877979636\n",
      "Epoch 708, Loss: 0.019823579234071076, Final Batch Loss: 0.0009950177045539021\n",
      "Epoch 709, Loss: 0.0054104524897411466, Final Batch Loss: 0.0035051230806857347\n",
      "Epoch 710, Loss: 0.0028617220232263207, Final Batch Loss: 0.001732329255901277\n",
      "Epoch 711, Loss: 0.006886576418764889, Final Batch Loss: 0.0010454977164044976\n",
      "Epoch 712, Loss: 0.014163417916279286, Final Batch Loss: 0.0008183458703570068\n",
      "Epoch 713, Loss: 0.002433504327200353, Final Batch Loss: 0.0011649543885141611\n",
      "Epoch 714, Loss: 0.0026606519240885973, Final Batch Loss: 0.0007807232905179262\n",
      "Epoch 715, Loss: 0.006494373665191233, Final Batch Loss: 0.0008069389732554555\n",
      "Epoch 716, Loss: 0.0025235050707124174, Final Batch Loss: 0.0005540497950278223\n",
      "Epoch 717, Loss: 0.0037581085925921798, Final Batch Loss: 0.0012419860577210784\n",
      "Epoch 718, Loss: 0.027950468007475138, Final Batch Loss: 0.026658661663532257\n",
      "Epoch 719, Loss: 0.007312672794796526, Final Batch Loss: 0.00034761440474539995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720, Loss: 0.0028937802417203784, Final Batch Loss: 0.001044296775944531\n",
      "Epoch 721, Loss: 0.003421243862248957, Final Batch Loss: 0.000689711538143456\n",
      "Epoch 722, Loss: 0.0089885622728616, Final Batch Loss: 0.006442992482334375\n",
      "Epoch 723, Loss: 0.017892687115818262, Final Batch Loss: 0.0032399077899754047\n",
      "Epoch 724, Loss: 0.00976319401524961, Final Batch Loss: 0.007335097063332796\n",
      "Epoch 725, Loss: 0.005986965261399746, Final Batch Loss: 0.0028337587136775255\n",
      "Epoch 726, Loss: 0.006898566090967506, Final Batch Loss: 0.0008170548244379461\n",
      "Epoch 727, Loss: 0.0034940261393785477, Final Batch Loss: 0.001556360861286521\n",
      "Epoch 728, Loss: 0.005742363631725311, Final Batch Loss: 0.0012009432539343834\n",
      "Epoch 729, Loss: 0.006564596900716424, Final Batch Loss: 0.004948956426233053\n",
      "Epoch 730, Loss: 0.0065591426100581884, Final Batch Loss: 0.0011385364923626184\n",
      "Epoch 731, Loss: 0.005355852539651096, Final Batch Loss: 0.00345697533339262\n",
      "Epoch 732, Loss: 0.0063191149674821645, Final Batch Loss: 0.0004472416185308248\n",
      "Epoch 733, Loss: 0.00418890209402889, Final Batch Loss: 0.0014663106994703412\n",
      "Epoch 734, Loss: 0.04224017891101539, Final Batch Loss: 0.04015277698636055\n",
      "Epoch 735, Loss: 0.017988165142014623, Final Batch Loss: 0.016758214682340622\n",
      "Epoch 736, Loss: 0.0025486097438260913, Final Batch Loss: 0.001344584859907627\n",
      "Epoch 737, Loss: 0.01386145269498229, Final Batch Loss: 0.001578818541020155\n",
      "Epoch 738, Loss: 0.026278411969542503, Final Batch Loss: 0.022244730964303017\n",
      "Epoch 739, Loss: 0.032010835129767656, Final Batch Loss: 0.0026282821781933308\n",
      "Epoch 740, Loss: 0.010503605706617236, Final Batch Loss: 0.002467848127707839\n",
      "Epoch 741, Loss: 0.007362925563938916, Final Batch Loss: 0.0008920511463657022\n",
      "Epoch 742, Loss: 0.004748868523165584, Final Batch Loss: 0.0021972416434437037\n",
      "Epoch 743, Loss: 0.0038880585343576968, Final Batch Loss: 0.003109225071966648\n",
      "Epoch 744, Loss: 0.0014000886876601726, Final Batch Loss: 0.00048819606308825314\n",
      "Epoch 745, Loss: 0.005813209572806954, Final Batch Loss: 0.0030304582323879004\n",
      "Epoch 746, Loss: 0.003811642061918974, Final Batch Loss: 0.0015544486232101917\n",
      "Epoch 747, Loss: 0.0018955689738504589, Final Batch Loss: 0.0006721740937791765\n",
      "Epoch 748, Loss: 0.008644756395369768, Final Batch Loss: 0.0031487238593399525\n",
      "Epoch 749, Loss: 0.00652277166955173, Final Batch Loss: 0.0031264396384358406\n",
      "Epoch 750, Loss: 0.00270113255828619, Final Batch Loss: 0.000909365713596344\n",
      "Epoch 751, Loss: 0.00281931075733155, Final Batch Loss: 0.001697220024652779\n",
      "Epoch 752, Loss: 0.003429605858400464, Final Batch Loss: 0.002746311714872718\n",
      "Epoch 753, Loss: 0.022232364513911307, Final Batch Loss: 0.020365949720144272\n",
      "Epoch 754, Loss: 0.004903574241325259, Final Batch Loss: 0.003219981910660863\n",
      "Epoch 755, Loss: 0.0018782585102599114, Final Batch Loss: 0.00045113611849956214\n",
      "Epoch 756, Loss: 0.004223855561576784, Final Batch Loss: 0.000705340295098722\n",
      "Epoch 757, Loss: 0.0022270040935836732, Final Batch Loss: 0.0008516593952663243\n",
      "Epoch 758, Loss: 0.006776677910238504, Final Batch Loss: 0.0029087639413774014\n",
      "Epoch 759, Loss: 0.0012230270076543093, Final Batch Loss: 0.00044868228724226356\n",
      "Epoch 760, Loss: 0.002417995419818908, Final Batch Loss: 0.0006930783274583519\n",
      "Epoch 761, Loss: 0.0030290092108771205, Final Batch Loss: 0.0007045954698696733\n",
      "Epoch 762, Loss: 0.0023608069168403745, Final Batch Loss: 0.0015268235001713037\n",
      "Epoch 763, Loss: 0.0034013563999906182, Final Batch Loss: 0.0010812260443344712\n",
      "Epoch 764, Loss: 0.006264368537813425, Final Batch Loss: 0.002799592912197113\n",
      "Epoch 765, Loss: 0.0025937233003787696, Final Batch Loss: 0.000754914537537843\n",
      "Epoch 766, Loss: 0.002456681104376912, Final Batch Loss: 0.0010696157114580274\n",
      "Epoch 767, Loss: 0.002422609366476536, Final Batch Loss: 0.0007841169135645032\n",
      "Epoch 768, Loss: 0.001775475568138063, Final Batch Loss: 0.0007439182372763753\n",
      "Epoch 769, Loss: 0.0020357812754809856, Final Batch Loss: 0.0002597966231405735\n",
      "Epoch 770, Loss: 0.00702647038269788, Final Batch Loss: 0.0005619042785838246\n",
      "Epoch 771, Loss: 0.003245087806135416, Final Batch Loss: 0.0017773211002349854\n",
      "Epoch 772, Loss: 0.0027528729988262057, Final Batch Loss: 0.0007896138122305274\n",
      "Epoch 773, Loss: 0.008353231474757195, Final Batch Loss: 0.006749763153493404\n",
      "Epoch 774, Loss: 0.0020863632671535015, Final Batch Loss: 0.0010343757458031178\n",
      "Epoch 775, Loss: 0.005922592710703611, Final Batch Loss: 0.004155332688242197\n",
      "Epoch 776, Loss: 0.012758678873069584, Final Batch Loss: 0.000949280452914536\n",
      "Epoch 777, Loss: 0.022564784972928464, Final Batch Loss: 0.02174369804561138\n",
      "Epoch 778, Loss: 0.0017241641762666404, Final Batch Loss: 0.0006519689341075718\n",
      "Epoch 779, Loss: 0.005967035423964262, Final Batch Loss: 0.0006678244099020958\n",
      "Epoch 780, Loss: 0.002231948950793594, Final Batch Loss: 0.0007418443565256894\n",
      "Epoch 781, Loss: 0.006638002465479076, Final Batch Loss: 0.005534922704100609\n",
      "Epoch 782, Loss: 0.007748250616714358, Final Batch Loss: 0.0014986286405473948\n",
      "Epoch 783, Loss: 0.009258692152798176, Final Batch Loss: 0.0002329666167497635\n",
      "Epoch 784, Loss: 0.0028210965683683753, Final Batch Loss: 0.0009847487090155482\n",
      "Epoch 785, Loss: 0.009309687884524465, Final Batch Loss: 0.006021873559802771\n",
      "Epoch 786, Loss: 0.004613892815541476, Final Batch Loss: 0.0037188741844147444\n",
      "Epoch 787, Loss: 0.006968895089812577, Final Batch Loss: 0.0057081012055277824\n",
      "Epoch 788, Loss: 0.0013658794923685491, Final Batch Loss: 0.0006163693033158779\n",
      "Epoch 789, Loss: 0.0013344667968340218, Final Batch Loss: 0.0005677993758581579\n",
      "Epoch 790, Loss: 0.002418181102257222, Final Batch Loss: 0.0015743743861094117\n",
      "Epoch 791, Loss: 0.02914891135878861, Final Batch Loss: 0.0030506562907248735\n",
      "Epoch 792, Loss: 0.004336351383244619, Final Batch Loss: 0.003983008675277233\n",
      "Epoch 793, Loss: 0.0019529752898961306, Final Batch Loss: 0.0006674005417153239\n",
      "Epoch 794, Loss: 0.0030392121989279985, Final Batch Loss: 0.0027100492734462023\n",
      "Epoch 795, Loss: 0.0027050075586885214, Final Batch Loss: 0.0004147063009440899\n",
      "Epoch 796, Loss: 0.004115381860174239, Final Batch Loss: 0.002340181963518262\n",
      "Epoch 797, Loss: 0.014213863993063569, Final Batch Loss: 0.011382178403437138\n",
      "Epoch 798, Loss: 0.0023668268986511976, Final Batch Loss: 0.00043199225910939276\n",
      "Epoch 799, Loss: 0.0023018766660243273, Final Batch Loss: 0.0014142781728878617\n",
      "Epoch 800, Loss: 0.0016649564495310187, Final Batch Loss: 0.0010790302185341716\n",
      "Epoch 801, Loss: 0.00269015587400645, Final Batch Loss: 0.0006992953130975366\n",
      "Epoch 802, Loss: 0.0018977124709635973, Final Batch Loss: 0.0005447919247671962\n",
      "Epoch 803, Loss: 0.021086971857585013, Final Batch Loss: 0.020532257854938507\n",
      "Epoch 804, Loss: 0.009873720584437251, Final Batch Loss: 0.008653057739138603\n",
      "Epoch 805, Loss: 0.002299283311003819, Final Batch Loss: 0.0004138390359003097\n",
      "Epoch 806, Loss: 0.0024636026355437934, Final Batch Loss: 0.0008974254014901817\n",
      "Epoch 807, Loss: 0.0025655251083662733, Final Batch Loss: 0.0023308582603931427\n",
      "Epoch 808, Loss: 0.0017170131905004382, Final Batch Loss: 0.0007669343613088131\n",
      "Epoch 809, Loss: 0.015709850238636136, Final Batch Loss: 0.014145215973258018\n",
      "Epoch 810, Loss: 0.0039940254064276814, Final Batch Loss: 0.0012555519351735711\n",
      "Epoch 811, Loss: 0.007346614263951778, Final Batch Loss: 0.001010875217616558\n",
      "Epoch 812, Loss: 0.001068493234924972, Final Batch Loss: 0.000334818207193166\n",
      "Epoch 813, Loss: 0.0006321101682260633, Final Batch Loss: 0.000280586740700528\n",
      "Epoch 814, Loss: 0.0030851097544655204, Final Batch Loss: 0.0020106404554098845\n",
      "Epoch 815, Loss: 0.007134269399102777, Final Batch Loss: 0.000796514970716089\n",
      "Epoch 816, Loss: 0.0016222578124143183, Final Batch Loss: 0.001167754759080708\n",
      "Epoch 817, Loss: 0.000670900393743068, Final Batch Loss: 0.000376929237972945\n",
      "Epoch 818, Loss: 0.0016164921107701957, Final Batch Loss: 0.0008872906328178942\n",
      "Epoch 819, Loss: 0.003527533379383385, Final Batch Loss: 0.0021040085703134537\n",
      "Epoch 820, Loss: 0.004305712413042784, Final Batch Loss: 0.0022641527466475964\n",
      "Epoch 821, Loss: 0.00247143890010193, Final Batch Loss: 0.0003437295672483742\n",
      "Epoch 822, Loss: 0.010604458104353398, Final Batch Loss: 0.0006132593262009323\n",
      "Epoch 823, Loss: 0.0027174503775313497, Final Batch Loss: 0.001439842046238482\n",
      "Epoch 824, Loss: 0.0019092526054009795, Final Batch Loss: 0.0011615215335041285\n",
      "Epoch 825, Loss: 0.002893528202548623, Final Batch Loss: 0.0011191490339115262\n",
      "Epoch 826, Loss: 0.0029615816310979426, Final Batch Loss: 0.000592998752836138\n",
      "Epoch 827, Loss: 0.01004038390237838, Final Batch Loss: 0.009061392396688461\n",
      "Epoch 828, Loss: 0.002803341019898653, Final Batch Loss: 0.0006397252436727285\n",
      "Epoch 829, Loss: 0.001190056442283094, Final Batch Loss: 0.000569949799682945\n",
      "Epoch 830, Loss: 0.0019881020416505635, Final Batch Loss: 0.0008587401243858039\n",
      "Epoch 831, Loss: 0.0011163683520862833, Final Batch Loss: 0.0001686280156718567\n",
      "Epoch 832, Loss: 0.014045053161680698, Final Batch Loss: 0.011204865761101246\n",
      "Epoch 833, Loss: 0.0005189251205592882, Final Batch Loss: 4.25554571847897e-05\n",
      "Epoch 834, Loss: 0.015989755396731198, Final Batch Loss: 0.000697655719704926\n",
      "Epoch 835, Loss: 0.011116414912976325, Final Batch Loss: 0.009243331849575043\n",
      "Epoch 836, Loss: 0.0013442363997455686, Final Batch Loss: 0.00016081167268566787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837, Loss: 0.0015818325337022543, Final Batch Loss: 0.0005101804854348302\n",
      "Epoch 838, Loss: 0.005282056285068393, Final Batch Loss: 0.0006561505142599344\n",
      "Epoch 839, Loss: 0.003882365068420768, Final Batch Loss: 0.001341767143458128\n",
      "Epoch 840, Loss: 0.004482217715121806, Final Batch Loss: 0.0032463299576193094\n",
      "Epoch 841, Loss: 0.002991913177538663, Final Batch Loss: 0.0020716004073619843\n",
      "Epoch 842, Loss: 0.013458238448947668, Final Batch Loss: 0.0029196771793067455\n",
      "Epoch 843, Loss: 0.017062754253856838, Final Batch Loss: 0.016071824356913567\n",
      "Epoch 844, Loss: 0.0014009240549057722, Final Batch Loss: 0.0007600756944157183\n",
      "Epoch 845, Loss: 0.009692949301097542, Final Batch Loss: 0.0006286539719440043\n",
      "Epoch 846, Loss: 0.003517630393616855, Final Batch Loss: 0.002025109250098467\n",
      "Epoch 847, Loss: 0.004920881008729339, Final Batch Loss: 0.0011244593188166618\n",
      "Epoch 848, Loss: 0.004666262771934271, Final Batch Loss: 0.0030419679824262857\n",
      "Epoch 849, Loss: 0.004824675153940916, Final Batch Loss: 0.00412101112306118\n",
      "Epoch 850, Loss: 0.0013683716242667288, Final Batch Loss: 0.0009029929642565548\n",
      "Epoch 851, Loss: 0.003706280142068863, Final Batch Loss: 0.0021846978925168514\n",
      "Epoch 852, Loss: 0.0025370348594151437, Final Batch Loss: 0.0019203921547159553\n",
      "Epoch 853, Loss: 0.0016289217746816576, Final Batch Loss: 0.0009451969526708126\n",
      "Epoch 854, Loss: 0.001943614101037383, Final Batch Loss: 0.0009098631562665105\n",
      "Epoch 855, Loss: 0.0037389531498774886, Final Batch Loss: 0.0013020335463806987\n",
      "Epoch 856, Loss: 0.002272094367071986, Final Batch Loss: 0.001414881437085569\n",
      "Epoch 857, Loss: 0.0008992520306492224, Final Batch Loss: 0.0002164482866646722\n",
      "Epoch 858, Loss: 0.0038851293502375484, Final Batch Loss: 0.0017677979776635766\n",
      "Epoch 859, Loss: 0.0038676667027175426, Final Batch Loss: 0.0021564671769738197\n",
      "Epoch 860, Loss: 0.001125758804846555, Final Batch Loss: 0.0003604352241382003\n",
      "Epoch 861, Loss: 0.001321550807915628, Final Batch Loss: 0.0007451907149516046\n",
      "Epoch 862, Loss: 0.003908101876731962, Final Batch Loss: 0.0006471771630458534\n",
      "Epoch 863, Loss: 0.0009017062984639779, Final Batch Loss: 0.000202119248569943\n",
      "Epoch 864, Loss: 0.0020406252006068826, Final Batch Loss: 0.0007970243459567428\n",
      "Epoch 865, Loss: 0.0005167434283066541, Final Batch Loss: 0.00017078491509892046\n",
      "Epoch 866, Loss: 0.0020662291208282113, Final Batch Loss: 0.00036780734080821276\n",
      "Epoch 867, Loss: 0.002766961115412414, Final Batch Loss: 0.0015962867764756083\n",
      "Epoch 868, Loss: 0.0013684002915397286, Final Batch Loss: 0.000444356061052531\n",
      "Epoch 869, Loss: 0.0021000850247219205, Final Batch Loss: 0.00100144580937922\n",
      "Epoch 870, Loss: 0.0011787072871811688, Final Batch Loss: 0.0004418262979015708\n",
      "Epoch 871, Loss: 0.007117241562809795, Final Batch Loss: 0.0005260523757897317\n",
      "Epoch 872, Loss: 0.0020362993236631155, Final Batch Loss: 0.00039617775473743677\n",
      "Epoch 873, Loss: 0.0004309851356083527, Final Batch Loss: 0.00021942867897450924\n",
      "Epoch 874, Loss: 0.0010039123881142586, Final Batch Loss: 0.00021292638848535717\n",
      "Epoch 875, Loss: 0.0027395165525376797, Final Batch Loss: 0.0014970501651987433\n",
      "Epoch 876, Loss: 0.0012131210532970726, Final Batch Loss: 0.0008300404879264534\n",
      "Epoch 877, Loss: 0.002453270528349094, Final Batch Loss: 0.00024348327133338898\n",
      "Epoch 878, Loss: 0.0012482626480050385, Final Batch Loss: 0.000515954103320837\n",
      "Epoch 879, Loss: 0.0012089544907212257, Final Batch Loss: 0.0006239285576157272\n",
      "Epoch 880, Loss: 0.005498537269886583, Final Batch Loss: 0.0002497145324014127\n",
      "Epoch 881, Loss: 0.0011539790139067918, Final Batch Loss: 0.00027847211458720267\n",
      "Epoch 882, Loss: 0.008495288027916104, Final Batch Loss: 0.0008152477093972266\n",
      "Epoch 883, Loss: 0.0013025439984630793, Final Batch Loss: 0.0008331153076142073\n",
      "Epoch 884, Loss: 0.003836298710666597, Final Batch Loss: 0.002555273473262787\n",
      "Epoch 885, Loss: 0.016223010141402483, Final Batch Loss: 0.005217034835368395\n",
      "Epoch 886, Loss: 0.0030520735308527946, Final Batch Loss: 0.0023594405502080917\n",
      "Epoch 887, Loss: 0.010316481813788414, Final Batch Loss: 0.002889973111450672\n",
      "Epoch 888, Loss: 0.0019031643169000745, Final Batch Loss: 0.0005715397419407964\n",
      "Epoch 889, Loss: 0.006098557554651052, Final Batch Loss: 0.0006078931619413197\n",
      "Epoch 890, Loss: 0.014080311229918152, Final Batch Loss: 0.01347331888973713\n",
      "Epoch 891, Loss: 0.0027809689345303923, Final Batch Loss: 0.00042394609772600234\n",
      "Epoch 892, Loss: 0.001357142231427133, Final Batch Loss: 0.0005386923439800739\n",
      "Epoch 893, Loss: 0.0015035723336040974, Final Batch Loss: 0.0008257105364464223\n",
      "Epoch 894, Loss: 0.0011170418874826282, Final Batch Loss: 0.0008355072350241244\n",
      "Epoch 895, Loss: 0.0015607613022439182, Final Batch Loss: 0.0011054400820285082\n",
      "Epoch 896, Loss: 0.014970575924962759, Final Batch Loss: 0.005374555010348558\n",
      "Epoch 897, Loss: 0.003941577859222889, Final Batch Loss: 0.0009171708952635527\n",
      "Epoch 898, Loss: 0.0006408297049347311, Final Batch Loss: 0.0003812801733147353\n",
      "Epoch 899, Loss: 0.004691672744229436, Final Batch Loss: 0.0011188453063368797\n",
      "Epoch 900, Loss: 0.0006994197610765696, Final Batch Loss: 0.00039299187483265996\n",
      "Epoch 901, Loss: 0.0020906071877107024, Final Batch Loss: 0.0006518518785014749\n",
      "Epoch 902, Loss: 0.0011799704079749063, Final Batch Loss: 0.00023267151846084744\n",
      "Epoch 903, Loss: 0.0028347454499453306, Final Batch Loss: 0.002244599163532257\n",
      "Epoch 904, Loss: 0.002229866717243567, Final Batch Loss: 0.0018861492862924933\n",
      "Epoch 905, Loss: 0.003049935679882765, Final Batch Loss: 0.0016811026725918055\n",
      "Epoch 906, Loss: 0.00798228984058369, Final Batch Loss: 0.00023769676045048982\n",
      "Epoch 907, Loss: 0.023543483286630362, Final Batch Loss: 0.0008295166189782321\n",
      "Epoch 908, Loss: 0.006597661413252354, Final Batch Loss: 0.0003773495554924011\n",
      "Epoch 909, Loss: 0.0020861055818386376, Final Batch Loss: 0.0013044236693531275\n",
      "Epoch 910, Loss: 0.006490191561169922, Final Batch Loss: 0.000323020969517529\n",
      "Epoch 911, Loss: 0.007583937040180899, Final Batch Loss: 0.00018235052993986756\n",
      "Epoch 912, Loss: 0.0031955798040144145, Final Batch Loss: 0.0008610973018221557\n",
      "Epoch 913, Loss: 0.0050830168183892965, Final Batch Loss: 0.0014263757038861513\n",
      "Epoch 914, Loss: 0.00241771771106869, Final Batch Loss: 0.0016186386346817017\n",
      "Epoch 915, Loss: 0.006874106067698449, Final Batch Loss: 0.006035249680280685\n",
      "Epoch 916, Loss: 0.008846978540532291, Final Batch Loss: 0.007104957010596991\n",
      "Epoch 917, Loss: 0.022299518110230565, Final Batch Loss: 0.02069026045501232\n",
      "Epoch 918, Loss: 0.000778054294642061, Final Batch Loss: 0.00040494714630767703\n",
      "Epoch 919, Loss: 0.0008217325084842741, Final Batch Loss: 0.0003188069094903767\n",
      "Epoch 920, Loss: 0.0013329433277249336, Final Batch Loss: 0.0002500447444617748\n",
      "Epoch 921, Loss: 0.0044729242799803615, Final Batch Loss: 0.001652812003158033\n",
      "Epoch 922, Loss: 0.012803423218429089, Final Batch Loss: 0.004622394219040871\n",
      "Epoch 923, Loss: 0.012045732233673334, Final Batch Loss: 0.0021446426399052143\n",
      "Epoch 924, Loss: 0.005022104422096163, Final Batch Loss: 0.004345801658928394\n",
      "Epoch 925, Loss: 0.003168783790897578, Final Batch Loss: 0.0004743225290440023\n",
      "Epoch 926, Loss: 0.0011481230903882533, Final Batch Loss: 0.0003969755198340863\n",
      "Epoch 927, Loss: 0.0030042915022931993, Final Batch Loss: 0.0007942017982713878\n",
      "Epoch 928, Loss: 0.003190515097230673, Final Batch Loss: 0.0019240487599745393\n",
      "Epoch 929, Loss: 0.0034010731033049524, Final Batch Loss: 0.002873034914955497\n",
      "Epoch 930, Loss: 0.002934958436526358, Final Batch Loss: 0.0019135994371026754\n",
      "Epoch 931, Loss: 0.024322678276803344, Final Batch Loss: 0.0005093225627206266\n",
      "Epoch 932, Loss: 0.0016148705035448074, Final Batch Loss: 0.0004259048728272319\n",
      "Epoch 933, Loss: 0.0007187153096310794, Final Batch Loss: 0.0003417952102608979\n",
      "Epoch 934, Loss: 0.0010915812163148075, Final Batch Loss: 0.0007826689397916198\n",
      "Epoch 935, Loss: 0.004230544320307672, Final Batch Loss: 0.0005298979813233018\n",
      "Epoch 936, Loss: 0.0015208919066935778, Final Batch Loss: 0.0006786370067857206\n",
      "Epoch 937, Loss: 0.0013567591668106616, Final Batch Loss: 0.000507343967910856\n",
      "Epoch 938, Loss: 0.015834186924621463, Final Batch Loss: 0.001779863378033042\n",
      "Epoch 939, Loss: 0.0017777199682313949, Final Batch Loss: 0.0013521797955036163\n",
      "Epoch 940, Loss: 0.002904770022723824, Final Batch Loss: 0.0007786201895214617\n",
      "Epoch 941, Loss: 0.0015592759009450674, Final Batch Loss: 0.00033759186044335365\n",
      "Epoch 942, Loss: 0.002251085388706997, Final Batch Loss: 0.0018749325536191463\n",
      "Epoch 943, Loss: 0.003556466195732355, Final Batch Loss: 0.0025252033956348896\n",
      "Epoch 944, Loss: 0.0026722855982370675, Final Batch Loss: 0.0006389076006598771\n",
      "Epoch 945, Loss: 0.0018579007009975612, Final Batch Loss: 0.0004559457884170115\n",
      "Epoch 946, Loss: 0.0026211520889773965, Final Batch Loss: 0.0012793350033462048\n",
      "Epoch 947, Loss: 0.000751535379095003, Final Batch Loss: 0.0003364102740306407\n",
      "Epoch 948, Loss: 0.0011585808533709496, Final Batch Loss: 6.610862328670919e-05\n",
      "Epoch 949, Loss: 0.0015144445205805823, Final Batch Loss: 0.0012752177426591516\n",
      "Epoch 950, Loss: 0.0017206690681632608, Final Batch Loss: 0.0003141270426567644\n",
      "Epoch 951, Loss: 0.0019400350574869663, Final Batch Loss: 0.0015978936571627855\n",
      "Epoch 952, Loss: 0.0007136695203371346, Final Batch Loss: 0.0002530708734411746\n",
      "Epoch 953, Loss: 0.0057887420989573, Final Batch Loss: 0.0022141721565276384\n",
      "Epoch 954, Loss: 0.0009885426552500576, Final Batch Loss: 0.0003921616298612207\n",
      "Epoch 955, Loss: 0.0006350268959067762, Final Batch Loss: 0.00014741046470589936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 956, Loss: 0.0013786693452857435, Final Batch Loss: 0.000822564004920423\n",
      "Epoch 957, Loss: 0.0011267649242654443, Final Batch Loss: 0.00010473176371306181\n",
      "Epoch 958, Loss: 0.002722371253184974, Final Batch Loss: 0.0013489091070368886\n",
      "Epoch 959, Loss: 0.0017885946144815534, Final Batch Loss: 0.00040230582817457616\n",
      "Epoch 960, Loss: 0.027559753565583378, Final Batch Loss: 0.026722222566604614\n",
      "Epoch 961, Loss: 0.0027355734491720796, Final Batch Loss: 0.0018671349389478564\n",
      "Epoch 962, Loss: 0.002712895453441888, Final Batch Loss: 0.00028162827948108315\n",
      "Epoch 963, Loss: 0.003226253087632358, Final Batch Loss: 0.002469685859978199\n",
      "Epoch 964, Loss: 0.0010669480252545327, Final Batch Loss: 0.00023081162362359464\n",
      "Epoch 965, Loss: 0.001483785774325952, Final Batch Loss: 0.00017889690934680402\n",
      "Epoch 966, Loss: 0.0007167354924604297, Final Batch Loss: 0.00016904668882489204\n",
      "Epoch 967, Loss: 0.01152575621381402, Final Batch Loss: 0.001545910257846117\n",
      "Epoch 968, Loss: 0.0008100963605102152, Final Batch Loss: 0.0004767291247844696\n",
      "Epoch 969, Loss: 0.004806569661013782, Final Batch Loss: 0.003299400443211198\n",
      "Epoch 970, Loss: 0.004281166882719845, Final Batch Loss: 0.0003938157460652292\n",
      "Epoch 971, Loss: 0.0025891777768265456, Final Batch Loss: 0.002246120246127248\n",
      "Epoch 972, Loss: 0.0018962405738420784, Final Batch Loss: 0.001205424196086824\n",
      "Epoch 973, Loss: 0.003237216209527105, Final Batch Loss: 0.0007551679736934602\n",
      "Epoch 974, Loss: 0.009645711281336844, Final Batch Loss: 0.0015132311964407563\n",
      "Epoch 975, Loss: 0.0024975732812890783, Final Batch Loss: 0.00016211568436119705\n",
      "Epoch 976, Loss: 0.0023471644963137805, Final Batch Loss: 0.0005041594267822802\n",
      "Epoch 977, Loss: 0.0009164295624941587, Final Batch Loss: 0.00027986010536551476\n",
      "Epoch 978, Loss: 0.0006650741852354258, Final Batch Loss: 0.0001660333655308932\n",
      "Epoch 979, Loss: 0.00033451920899096876, Final Batch Loss: 7.322187593672425e-05\n",
      "Epoch 980, Loss: 0.0016241523553617299, Final Batch Loss: 0.0005760948988609016\n",
      "Epoch 981, Loss: 0.0015162871277425438, Final Batch Loss: 0.0002966505999211222\n",
      "Epoch 982, Loss: 0.006594647420570254, Final Batch Loss: 0.0021253630984574556\n",
      "Epoch 983, Loss: 0.003704026574268937, Final Batch Loss: 0.002527969889342785\n",
      "Epoch 984, Loss: 0.00933046464342624, Final Batch Loss: 0.0010327474446967244\n",
      "Epoch 985, Loss: 0.0012283033865969628, Final Batch Loss: 0.00028774028760381043\n",
      "Epoch 986, Loss: 0.0010963933673338033, Final Batch Loss: 0.000104156591987703\n",
      "Epoch 987, Loss: 0.0022880228352732956, Final Batch Loss: 0.0014038430526852608\n",
      "Epoch 988, Loss: 0.0004050187853863463, Final Batch Loss: 0.00015247180999722332\n",
      "Epoch 989, Loss: 0.005078982328996062, Final Batch Loss: 0.00040334020741283894\n",
      "Epoch 990, Loss: 0.0015510345401708037, Final Batch Loss: 0.0011641229502856731\n",
      "Epoch 991, Loss: 0.0015788938326295465, Final Batch Loss: 0.0011370204156264663\n",
      "Epoch 992, Loss: 0.0009138181339949369, Final Batch Loss: 0.0006140744662843645\n",
      "Epoch 993, Loss: 0.0017573891091160476, Final Batch Loss: 0.0009647569968365133\n",
      "Epoch 994, Loss: 0.0008972167852334678, Final Batch Loss: 0.0003902690368704498\n",
      "Epoch 995, Loss: 0.008038333035074174, Final Batch Loss: 0.001550776301883161\n",
      "Epoch 996, Loss: 0.0008803841919871047, Final Batch Loss: 0.00015570067625958472\n",
      "Epoch 997, Loss: 0.0011041632387787104, Final Batch Loss: 0.0006329974858090281\n",
      "Epoch 998, Loss: 0.001721041917335242, Final Batch Loss: 0.0003097468870691955\n",
      "Epoch 999, Loss: 0.00042689849215094, Final Batch Loss: 0.00014905417629051954\n",
      "Epoch 1000, Loss: 0.0012069613731000572, Final Batch Loss: 8.554491796530783e-05\n",
      "Epoch 1001, Loss: 0.00030373626213986427, Final Batch Loss: 7.48670136090368e-05\n",
      "Epoch 1002, Loss: 0.0018152640550397336, Final Batch Loss: 0.0011536324163898826\n",
      "Epoch 1003, Loss: 0.008733690483495593, Final Batch Loss: 0.0072823925875127316\n",
      "Epoch 1004, Loss: 0.0018709388677962124, Final Batch Loss: 0.0011457388754934072\n",
      "Epoch 1005, Loss: 0.0012830105115426704, Final Batch Loss: 0.00018353415362071246\n",
      "Epoch 1006, Loss: 0.002487338293576613, Final Batch Loss: 0.00027872357168234885\n",
      "Epoch 1007, Loss: 0.0010416739387437701, Final Batch Loss: 0.00048799754586070776\n",
      "Epoch 1008, Loss: 0.004143504425883293, Final Batch Loss: 0.0026496085338294506\n",
      "Epoch 1009, Loss: 0.0007807941874489188, Final Batch Loss: 0.00016720930580049753\n",
      "Epoch 1010, Loss: 0.003327681275550276, Final Batch Loss: 0.0024622364435344934\n",
      "Epoch 1011, Loss: 0.0015733767650090158, Final Batch Loss: 0.001024946104735136\n",
      "Epoch 1012, Loss: 0.0020264904014766216, Final Batch Loss: 0.001303182914853096\n",
      "Epoch 1013, Loss: 0.00459283753298223, Final Batch Loss: 0.0005986925680190325\n",
      "Epoch 1014, Loss: 0.0012142788036726415, Final Batch Loss: 0.0008189782965928316\n",
      "Epoch 1015, Loss: 0.005577029311098158, Final Batch Loss: 0.005109391640871763\n",
      "Epoch 1016, Loss: 0.0011330496927257627, Final Batch Loss: 0.0002843602269422263\n",
      "Epoch 1017, Loss: 0.0008257335139205679, Final Batch Loss: 0.00017093213682528585\n",
      "Epoch 1018, Loss: 0.015111850952962413, Final Batch Loss: 0.014769261702895164\n",
      "Epoch 1019, Loss: 0.0007423201896017417, Final Batch Loss: 0.00016873567074071616\n",
      "Epoch 1020, Loss: 0.008923970337491482, Final Batch Loss: 0.008020867593586445\n",
      "Epoch 1021, Loss: 0.0017867402057163417, Final Batch Loss: 0.0005863255937583745\n",
      "Epoch 1022, Loss: 0.002069905909593217, Final Batch Loss: 0.00018346151045989245\n",
      "Epoch 1023, Loss: 0.0008057413360802457, Final Batch Loss: 0.00020479054364841431\n",
      "Epoch 1024, Loss: 0.003870219108648598, Final Batch Loss: 0.0024237893521785736\n",
      "Epoch 1025, Loss: 0.0008525578596163541, Final Batch Loss: 9.994537685997784e-05\n",
      "Epoch 1026, Loss: 0.0025810577208176255, Final Batch Loss: 0.002380163874477148\n",
      "Epoch 1027, Loss: 0.006250119244214147, Final Batch Loss: 0.0006774905486963689\n",
      "Epoch 1028, Loss: 0.0003359487309353426, Final Batch Loss: 0.00010823264892678708\n",
      "Epoch 1029, Loss: 0.0005864599370397627, Final Batch Loss: 0.0002948306791950017\n",
      "Epoch 1030, Loss: 0.001038234739098698, Final Batch Loss: 0.0003348060417920351\n",
      "Epoch 1031, Loss: 0.0007026410021353513, Final Batch Loss: 0.000464687094790861\n",
      "Epoch 1032, Loss: 0.0023060059174895287, Final Batch Loss: 0.0010756453266367316\n",
      "Epoch 1033, Loss: 0.0006831421633251011, Final Batch Loss: 0.00024997073342092335\n",
      "Epoch 1034, Loss: 0.011739440764358733, Final Batch Loss: 0.011643520556390285\n",
      "Epoch 1035, Loss: 0.017291840631514788, Final Batch Loss: 0.0005784523673355579\n",
      "Epoch 1036, Loss: 0.0030318836797960103, Final Batch Loss: 0.002514533931389451\n",
      "Epoch 1037, Loss: 0.004349796567112207, Final Batch Loss: 0.0006357477977871895\n",
      "Epoch 1038, Loss: 0.0006327482406049967, Final Batch Loss: 0.0004688370390795171\n",
      "Epoch 1039, Loss: 0.022005979815730825, Final Batch Loss: 0.00037962282658554614\n",
      "Epoch 1040, Loss: 0.001630601764190942, Final Batch Loss: 0.0003403025330044329\n",
      "Epoch 1041, Loss: 0.02016746101435274, Final Batch Loss: 0.019711624830961227\n",
      "Epoch 1042, Loss: 0.0007759739310131408, Final Batch Loss: 8.794593304628506e-05\n",
      "Epoch 1043, Loss: 0.0007303089223569259, Final Batch Loss: 9.827337635215372e-05\n",
      "Epoch 1044, Loss: 0.007984201976796612, Final Batch Loss: 0.0003714776539709419\n",
      "Epoch 1045, Loss: 0.0009653866873122752, Final Batch Loss: 0.0003579076146706939\n",
      "Epoch 1046, Loss: 0.000626259163254872, Final Batch Loss: 0.00035441844374872744\n",
      "Epoch 1047, Loss: 0.0007035197704681195, Final Batch Loss: 0.0006241090013645589\n",
      "Epoch 1048, Loss: 0.008944347559008747, Final Batch Loss: 0.00046416284749284387\n",
      "Epoch 1049, Loss: 0.0029995247023180127, Final Batch Loss: 0.0018934194231405854\n",
      "Epoch 1050, Loss: 0.0032314511336153373, Final Batch Loss: 0.00015006282774265856\n",
      "Epoch 1051, Loss: 0.0021826584707014263, Final Batch Loss: 0.000911183247808367\n",
      "Epoch 1052, Loss: 0.0012648202828131616, Final Batch Loss: 0.0005942695424892008\n",
      "Epoch 1053, Loss: 0.0003148316973238252, Final Batch Loss: 7.722124428255484e-05\n",
      "Epoch 1054, Loss: 0.000765558987041004, Final Batch Loss: 0.00018015784735325724\n",
      "Epoch 1055, Loss: 0.05448448285460472, Final Batch Loss: 0.04790555313229561\n",
      "Epoch 1056, Loss: 0.00037023394543211907, Final Batch Loss: 8.43735906528309e-05\n",
      "Epoch 1057, Loss: 0.0016642862174194306, Final Batch Loss: 0.0014327787794172764\n",
      "Epoch 1058, Loss: 0.0012985061621293426, Final Batch Loss: 0.00026468420401215553\n",
      "Epoch 1059, Loss: 0.0011232041870243847, Final Batch Loss: 0.0006478696595877409\n",
      "Epoch 1060, Loss: 0.0007762750901747495, Final Batch Loss: 0.00022825782070867717\n",
      "Epoch 1061, Loss: 0.0008577796979807317, Final Batch Loss: 0.00030671426793560386\n",
      "Epoch 1062, Loss: 0.0005589762222371064, Final Batch Loss: 8.186921331798658e-05\n",
      "Epoch 1063, Loss: 0.000950911249674391, Final Batch Loss: 7.967219426063821e-05\n",
      "Epoch 1064, Loss: 0.0023527298617409542, Final Batch Loss: 0.00010464196384418756\n",
      "Epoch 1065, Loss: 0.005070056184194982, Final Batch Loss: 0.00340816518291831\n",
      "Epoch 1066, Loss: 0.0011754552251659334, Final Batch Loss: 0.0006829913472756743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1067, Loss: 0.00045445799696608447, Final Batch Loss: 4.823770359507762e-05\n",
      "Epoch 1068, Loss: 0.000358584919013083, Final Batch Loss: 0.00017749158723745495\n",
      "Epoch 1069, Loss: 0.002972215414047241, Final Batch Loss: 0.001892301021143794\n",
      "Epoch 1070, Loss: 0.0016891082632355392, Final Batch Loss: 0.00027498119743540883\n",
      "Epoch 1071, Loss: 0.000741233117878437, Final Batch Loss: 0.00029225918115116656\n",
      "Epoch 1072, Loss: 0.03760673552460503, Final Batch Loss: 0.00019660666293930262\n",
      "Epoch 1073, Loss: 0.0005710309924324974, Final Batch Loss: 0.0001288390631088987\n",
      "Epoch 1074, Loss: 0.001576095586642623, Final Batch Loss: 0.0009080289746634662\n",
      "Epoch 1075, Loss: 0.0005841842794325203, Final Batch Loss: 0.0003930577076971531\n",
      "Epoch 1076, Loss: 0.005479418789036572, Final Batch Loss: 0.0006621248321607709\n",
      "Epoch 1077, Loss: 0.013654857379151508, Final Batch Loss: 0.000415920716477558\n",
      "Epoch 1078, Loss: 0.0015073469985509291, Final Batch Loss: 7.670036575291306e-05\n",
      "Epoch 1079, Loss: 0.02386571759416256, Final Batch Loss: 0.02362567000091076\n",
      "Epoch 1080, Loss: 0.0033402334083803, Final Batch Loss: 0.002573787933215499\n",
      "Epoch 1081, Loss: 0.0014938903332222253, Final Batch Loss: 0.0003847637271974236\n",
      "Epoch 1082, Loss: 0.013037278258707374, Final Batch Loss: 0.0009278905927203596\n",
      "Epoch 1083, Loss: 0.00317853398155421, Final Batch Loss: 0.0019403076730668545\n",
      "Epoch 1084, Loss: 0.020058998255990446, Final Batch Loss: 0.01915469579398632\n",
      "Epoch 1085, Loss: 0.004807031247764826, Final Batch Loss: 0.0010070668067783117\n",
      "Epoch 1086, Loss: 0.002489652601070702, Final Batch Loss: 0.0011810738360509276\n",
      "Epoch 1087, Loss: 0.0022680906113237143, Final Batch Loss: 0.00040242879185825586\n",
      "Epoch 1088, Loss: 0.0012566283985506743, Final Batch Loss: 0.0008047521114349365\n",
      "Epoch 1089, Loss: 0.0011916603543795645, Final Batch Loss: 0.0005643477779813111\n",
      "Epoch 1090, Loss: 0.0058772228949237615, Final Batch Loss: 0.00048551990767009556\n",
      "Epoch 1091, Loss: 0.00964920801925473, Final Batch Loss: 0.0002139780845027417\n",
      "Epoch 1092, Loss: 0.0018972180550917983, Final Batch Loss: 0.0005366391269490123\n",
      "Epoch 1093, Loss: 0.0011215103149879724, Final Batch Loss: 0.0004057679616380483\n",
      "Epoch 1094, Loss: 0.0005993290687911212, Final Batch Loss: 0.00023543366114608943\n",
      "Epoch 1095, Loss: 0.013618772034533322, Final Batch Loss: 0.0018514386611059308\n",
      "Epoch 1096, Loss: 0.01186077925376594, Final Batch Loss: 0.010772418230772018\n",
      "Epoch 1097, Loss: 0.0023227195488289, Final Batch Loss: 0.0013815336860716343\n",
      "Epoch 1098, Loss: 0.0007051101420074701, Final Batch Loss: 0.0003484815824776888\n",
      "Epoch 1099, Loss: 0.001206306362291798, Final Batch Loss: 0.00038153273635543883\n",
      "Epoch 1100, Loss: 0.003042657146579586, Final Batch Loss: 0.0028166775591671467\n",
      "Epoch 1101, Loss: 0.009358592535136268, Final Batch Loss: 0.0003667820419650525\n",
      "Epoch 1102, Loss: 0.0013104258687235415, Final Batch Loss: 0.000827639945782721\n",
      "Epoch 1103, Loss: 0.001365984819130972, Final Batch Loss: 0.0009702092502266169\n",
      "Epoch 1104, Loss: 0.0007285040046554059, Final Batch Loss: 0.000333743984811008\n",
      "Epoch 1105, Loss: 0.0011400108633097261, Final Batch Loss: 0.00030439396505244076\n",
      "Epoch 1106, Loss: 0.0038784617208875716, Final Batch Loss: 0.00048854696797207\n",
      "Epoch 1107, Loss: 0.0016720768762752414, Final Batch Loss: 0.0004955222830176353\n",
      "Epoch 1108, Loss: 0.0012628259137272835, Final Batch Loss: 0.00043652724707499146\n",
      "Epoch 1109, Loss: 0.006940617022337392, Final Batch Loss: 0.00039411408943124115\n",
      "Epoch 1110, Loss: 0.001467060879804194, Final Batch Loss: 0.00042435829527676105\n",
      "Epoch 1111, Loss: 0.0006345945876091719, Final Batch Loss: 0.00024573568953201175\n",
      "Epoch 1112, Loss: 0.007485077832825482, Final Batch Loss: 0.0011147918412461877\n",
      "Epoch 1113, Loss: 0.0033472720679128543, Final Batch Loss: 0.00310840574093163\n",
      "Epoch 1114, Loss: 0.0008194185502361506, Final Batch Loss: 0.00039120332803577185\n",
      "Epoch 1115, Loss: 0.0007728938944637775, Final Batch Loss: 0.00036762779927812517\n",
      "Epoch 1116, Loss: 0.004758940543979406, Final Batch Loss: 0.00029565952718257904\n",
      "Epoch 1117, Loss: 0.0020641389419324696, Final Batch Loss: 0.0007065871614031494\n",
      "Epoch 1118, Loss: 0.0067736733763013035, Final Batch Loss: 0.0003919242008123547\n",
      "Epoch 1119, Loss: 0.0007444836955983192, Final Batch Loss: 0.0003292001492809504\n",
      "Epoch 1120, Loss: 0.0015890571303316392, Final Batch Loss: 0.00010685329471016303\n",
      "Epoch 1121, Loss: 0.0007678510155528784, Final Batch Loss: 0.0005821854574605823\n",
      "Epoch 1122, Loss: 0.0013955688336864114, Final Batch Loss: 0.0010898158652707934\n",
      "Epoch 1123, Loss: 0.016978107974864542, Final Batch Loss: 0.01664992794394493\n",
      "Epoch 1124, Loss: 0.0005984798481222242, Final Batch Loss: 0.0003342443669680506\n",
      "Epoch 1125, Loss: 0.0018193548312410712, Final Batch Loss: 0.0011035046773031354\n",
      "Epoch 1126, Loss: 0.006094755604863167, Final Batch Loss: 0.0011751032434403896\n",
      "Epoch 1127, Loss: 0.0009550662944093347, Final Batch Loss: 0.0006519297021441162\n",
      "Epoch 1128, Loss: 0.007189429423306137, Final Batch Loss: 0.0007824600324966013\n",
      "Epoch 1129, Loss: 0.0007584392151329666, Final Batch Loss: 0.0002764092932920903\n",
      "Epoch 1130, Loss: 0.0012090157251805067, Final Batch Loss: 0.00040522729977965355\n",
      "Epoch 1131, Loss: 0.001007318845950067, Final Batch Loss: 0.0003935323329642415\n",
      "Epoch 1132, Loss: 0.0028065714286640286, Final Batch Loss: 0.002431008964776993\n",
      "Epoch 1133, Loss: 0.0009377042879350483, Final Batch Loss: 0.0002675816649571061\n",
      "Epoch 1134, Loss: 0.007625258585903794, Final Batch Loss: 0.0005376865738071501\n",
      "Epoch 1135, Loss: 0.0023322099150391296, Final Batch Loss: 0.0002167279162677005\n",
      "Epoch 1136, Loss: 0.002367098699323833, Final Batch Loss: 0.000807523843832314\n",
      "Epoch 1137, Loss: 0.0038903538370504975, Final Batch Loss: 0.0002725376980379224\n",
      "Epoch 1138, Loss: 0.004404132487252355, Final Batch Loss: 0.001864909427240491\n",
      "Epoch 1139, Loss: 0.00112617458216846, Final Batch Loss: 0.00025540951173752546\n",
      "Epoch 1140, Loss: 0.0016461751656606793, Final Batch Loss: 0.0003047873033210635\n",
      "Epoch 1141, Loss: 0.0008835970656946301, Final Batch Loss: 0.0006682844832539558\n",
      "Epoch 1142, Loss: 0.0011241432512179017, Final Batch Loss: 0.0004929518909193575\n",
      "Epoch 1143, Loss: 0.0007182303816080093, Final Batch Loss: 0.0003431605000514537\n",
      "Epoch 1144, Loss: 0.0005707136660930701, Final Batch Loss: 8.572237129556015e-05\n",
      "Epoch 1145, Loss: 0.0006463311146944761, Final Batch Loss: 0.00012355012586340308\n",
      "Epoch 1146, Loss: 0.0009767577284947038, Final Batch Loss: 0.0004422416095621884\n",
      "Epoch 1147, Loss: 0.0015448007616214454, Final Batch Loss: 0.0005522374412976205\n",
      "Epoch 1148, Loss: 0.004457742616068572, Final Batch Loss: 0.00029819057090207934\n",
      "Epoch 1149, Loss: 0.0004288519121473655, Final Batch Loss: 8.831509330775589e-05\n",
      "Epoch 1150, Loss: 0.015284817636711523, Final Batch Loss: 0.00016550251166336238\n",
      "Epoch 1151, Loss: 0.00506731474888511, Final Batch Loss: 0.0003737628285307437\n",
      "Epoch 1152, Loss: 0.003651709295809269, Final Batch Loss: 0.003296834649518132\n",
      "Epoch 1153, Loss: 0.006555020634550601, Final Batch Loss: 0.00025275658117607236\n",
      "Epoch 1154, Loss: 0.001791950810002163, Final Batch Loss: 0.0004165970312897116\n",
      "Epoch 1155, Loss: 0.0016268925974145532, Final Batch Loss: 0.0009537226869724691\n",
      "Epoch 1156, Loss: 0.0016787195345386863, Final Batch Loss: 0.0010446651140227914\n",
      "Epoch 1157, Loss: 0.0007081778021529317, Final Batch Loss: 0.00030452272039838135\n",
      "Epoch 1158, Loss: 0.002632730931509286, Final Batch Loss: 0.0017991663189604878\n",
      "Epoch 1159, Loss: 0.0008808818529359996, Final Batch Loss: 0.0005202916800044477\n",
      "Epoch 1160, Loss: 0.001825244922656566, Final Batch Loss: 0.001285637030377984\n",
      "Epoch 1161, Loss: 0.0008700085018062964, Final Batch Loss: 0.00013623341510538012\n",
      "Epoch 1162, Loss: 0.000983224148512818, Final Batch Loss: 0.00012660807988140732\n",
      "Epoch 1163, Loss: 0.0006453860842157155, Final Batch Loss: 0.0002539813285693526\n",
      "Epoch 1164, Loss: 0.0016644884017296135, Final Batch Loss: 0.0007773045799694955\n",
      "Epoch 1165, Loss: 0.0028785064350813627, Final Batch Loss: 0.0025988889392465353\n",
      "Epoch 1166, Loss: 0.0011398438218748197, Final Batch Loss: 0.0001839065080275759\n",
      "Epoch 1167, Loss: 0.0005024708225391805, Final Batch Loss: 0.0003639415081124753\n",
      "Epoch 1168, Loss: 0.001216591103002429, Final Batch Loss: 0.0002773585729300976\n",
      "Epoch 1169, Loss: 0.0014686667127534747, Final Batch Loss: 0.0006724846316501498\n",
      "Epoch 1170, Loss: 0.0004913389675493818, Final Batch Loss: 6.0606904298765585e-05\n",
      "Epoch 1171, Loss: 0.0005721455236198381, Final Batch Loss: 0.00034777706605382264\n",
      "Epoch 1172, Loss: 0.0013813810655847192, Final Batch Loss: 0.0008135627722367644\n",
      "Epoch 1173, Loss: 0.006973261653911322, Final Batch Loss: 0.00012766028521582484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1174, Loss: 0.0006846693868283182, Final Batch Loss: 0.00034908053930848837\n",
      "Epoch 1175, Loss: 0.0005444796261144802, Final Batch Loss: 0.00033869469189085066\n",
      "Epoch 1176, Loss: 0.00029393316071946174, Final Batch Loss: 0.00013174806372262537\n",
      "Epoch 1177, Loss: 0.0018251808069180697, Final Batch Loss: 0.00038473631138913333\n",
      "Epoch 1178, Loss: 0.000989899504929781, Final Batch Loss: 0.0005953697254881263\n",
      "Epoch 1179, Loss: 0.007142105489037931, Final Batch Loss: 0.00124251504894346\n",
      "Epoch 1180, Loss: 0.009238270460627973, Final Batch Loss: 0.0008793597808107734\n",
      "Epoch 1181, Loss: 0.001286154962144792, Final Batch Loss: 0.000650080677587539\n",
      "Epoch 1182, Loss: 0.0008375623147003353, Final Batch Loss: 0.0004574157646857202\n",
      "Epoch 1183, Loss: 0.004627445247024298, Final Batch Loss: 0.0006062416359782219\n",
      "Epoch 1184, Loss: 0.0005188506183912978, Final Batch Loss: 0.00028201841632835567\n",
      "Epoch 1185, Loss: 0.0011425614356994629, Final Batch Loss: 0.0005479549872688949\n",
      "Epoch 1186, Loss: 0.0012334692728472874, Final Batch Loss: 0.0010192571207880974\n",
      "Epoch 1187, Loss: 0.00046195687900763005, Final Batch Loss: 7.282591832336038e-05\n",
      "Epoch 1188, Loss: 0.0012982200714759529, Final Batch Loss: 0.00082525669131428\n",
      "Epoch 1189, Loss: 0.01891538134077564, Final Batch Loss: 0.00015772884944453835\n",
      "Epoch 1190, Loss: 0.0005146149196662009, Final Batch Loss: 0.00024693060549907386\n",
      "Epoch 1191, Loss: 0.0008937168458942324, Final Batch Loss: 0.0002843533584382385\n",
      "Epoch 1192, Loss: 0.001227852306328714, Final Batch Loss: 0.0008818602655082941\n",
      "Epoch 1193, Loss: 0.012986423724214546, Final Batch Loss: 6.700986705254763e-05\n",
      "Epoch 1194, Loss: 0.0008104706794256344, Final Batch Loss: 0.00021110819943714887\n",
      "Epoch 1195, Loss: 0.0033065961906686425, Final Batch Loss: 0.0019349231151863933\n",
      "Epoch 1196, Loss: 0.012879129382781684, Final Batch Loss: 0.011507163755595684\n",
      "Epoch 1197, Loss: 0.0008048137824516743, Final Batch Loss: 0.0002739586343523115\n",
      "Epoch 1198, Loss: 0.0034751463099382818, Final Batch Loss: 0.00277354521676898\n",
      "Epoch 1199, Loss: 0.0007496365869883448, Final Batch Loss: 0.0003696721978485584\n",
      "Epoch 1200, Loss: 0.001918312002089806, Final Batch Loss: 0.00022085658565629274\n",
      "Epoch 1201, Loss: 0.012172336224466562, Final Batch Loss: 0.011640333570539951\n",
      "Epoch 1202, Loss: 0.0007447370153386146, Final Batch Loss: 0.00044743833132088184\n",
      "Epoch 1203, Loss: 0.0017084174323827028, Final Batch Loss: 0.0014158330159261823\n",
      "Epoch 1204, Loss: 0.000748917373130098, Final Batch Loss: 0.00041094986954703927\n",
      "Epoch 1205, Loss: 0.0011072815832449123, Final Batch Loss: 0.00022879602329339832\n",
      "Epoch 1206, Loss: 0.000524675939232111, Final Batch Loss: 0.0002559054992161691\n",
      "Epoch 1207, Loss: 0.0012485877959989011, Final Batch Loss: 0.000537517131306231\n",
      "Epoch 1208, Loss: 0.0009675124601926655, Final Batch Loss: 0.0008326027891598642\n",
      "Epoch 1209, Loss: 0.0014472801703959703, Final Batch Loss: 0.0008353153243660927\n",
      "Epoch 1210, Loss: 0.0009752502664923668, Final Batch Loss: 0.00016654818318784237\n",
      "Epoch 1211, Loss: 0.0002893229539040476, Final Batch Loss: 0.00015146384248510003\n",
      "Epoch 1212, Loss: 0.0027757029165513813, Final Batch Loss: 0.0022240406833589077\n",
      "Epoch 1213, Loss: 0.001119391992688179, Final Batch Loss: 0.0005884954007342458\n",
      "Epoch 1214, Loss: 0.0030624397622887045, Final Batch Loss: 0.00037085279473103583\n",
      "Epoch 1215, Loss: 0.0008512298518326133, Final Batch Loss: 0.0004802249022759497\n",
      "Epoch 1216, Loss: 0.007998113171197474, Final Batch Loss: 0.0007512295851483941\n",
      "Epoch 1217, Loss: 0.0015438331756740808, Final Batch Loss: 0.0010430390248075128\n",
      "Epoch 1218, Loss: 0.0002934110671048984, Final Batch Loss: 0.00011474147322587669\n",
      "Epoch 1219, Loss: 0.0018050979124382138, Final Batch Loss: 0.0006867998745292425\n",
      "Epoch 1220, Loss: 0.0009189460251946002, Final Batch Loss: 0.0007824109052307904\n",
      "Epoch 1221, Loss: 0.0013252909120637923, Final Batch Loss: 0.0008415088523179293\n",
      "Epoch 1222, Loss: 0.001278367155464366, Final Batch Loss: 0.0003162884677294642\n",
      "Epoch 1223, Loss: 0.00253322662319988, Final Batch Loss: 0.0005538653349503875\n",
      "Epoch 1224, Loss: 0.0003430662181926891, Final Batch Loss: 0.00016080931527540088\n",
      "Epoch 1225, Loss: 0.00041108498407993466, Final Batch Loss: 0.00020803662482649088\n",
      "Epoch 1226, Loss: 0.0009736673018778674, Final Batch Loss: 5.989369674352929e-05\n",
      "Epoch 1227, Loss: 0.002062798332190141, Final Batch Loss: 0.0002475077926646918\n",
      "Epoch 1228, Loss: 0.0034205091069452465, Final Batch Loss: 0.0031084902584552765\n",
      "Epoch 1229, Loss: 0.010926406714133918, Final Batch Loss: 0.00029032479505985975\n",
      "Epoch 1230, Loss: 0.0009482897003181279, Final Batch Loss: 0.0005885678110644221\n",
      "Epoch 1231, Loss: 0.000706946782884188, Final Batch Loss: 0.0005381584051065147\n",
      "Epoch 1232, Loss: 0.0017809924320317805, Final Batch Loss: 0.0005062686395831406\n",
      "Epoch 1233, Loss: 0.0015947301289997995, Final Batch Loss: 0.0009172463905997574\n",
      "Epoch 1234, Loss: 0.0023040073647280224, Final Batch Loss: 9.9676959507633e-05\n",
      "Epoch 1235, Loss: 0.002053314063232392, Final Batch Loss: 0.000764720665756613\n",
      "Epoch 1236, Loss: 0.0003062524046981707, Final Batch Loss: 0.0001767239737091586\n",
      "Epoch 1237, Loss: 0.0008597798587288707, Final Batch Loss: 0.0004276129766367376\n",
      "Epoch 1238, Loss: 0.0012487776693888009, Final Batch Loss: 0.0009448962518945336\n",
      "Epoch 1239, Loss: 0.0008946254965849221, Final Batch Loss: 0.000523644033819437\n",
      "Epoch 1240, Loss: 0.0017153698718175292, Final Batch Loss: 0.0013494347222149372\n",
      "Epoch 1241, Loss: 0.003450684394920245, Final Batch Loss: 0.0030456220265477896\n",
      "Epoch 1242, Loss: 0.000682457844959572, Final Batch Loss: 0.0004190473700873554\n",
      "Epoch 1243, Loss: 0.016748332884162664, Final Batch Loss: 0.010154303163290024\n",
      "Epoch 1244, Loss: 0.0004019769257865846, Final Batch Loss: 0.00014987794565968215\n",
      "Epoch 1245, Loss: 0.0007016219606157392, Final Batch Loss: 0.00029794490546919405\n",
      "Epoch 1246, Loss: 0.001977962485398166, Final Batch Loss: 0.0001656567183090374\n",
      "Epoch 1247, Loss: 0.02508064277935773, Final Batch Loss: 0.02333630807697773\n",
      "Epoch 1248, Loss: 0.0013499660999514163, Final Batch Loss: 0.0011565623572096229\n",
      "Epoch 1249, Loss: 0.0006857434782432392, Final Batch Loss: 0.00015224645903799683\n",
      "Epoch 1250, Loss: 0.0010115043551195413, Final Batch Loss: 0.0005871885805390775\n",
      "Epoch 1251, Loss: 0.0011646207349258475, Final Batch Loss: 9.274156036553904e-05\n",
      "Epoch 1252, Loss: 0.007164363354604575, Final Batch Loss: 2.9731612812611274e-05\n",
      "Epoch 1253, Loss: 0.0011074517969973385, Final Batch Loss: 0.00047141447430476546\n",
      "Epoch 1254, Loss: 0.0012388735194690526, Final Batch Loss: 0.00044196401722729206\n",
      "Epoch 1255, Loss: 0.0008741198689676821, Final Batch Loss: 0.00021986267529428005\n",
      "Epoch 1256, Loss: 0.0007240224513225257, Final Batch Loss: 0.00042357741040177643\n",
      "Epoch 1257, Loss: 0.0018484714673832059, Final Batch Loss: 0.0007205664878711104\n",
      "Epoch 1258, Loss: 0.004264094459358603, Final Batch Loss: 0.0007907497347332537\n",
      "Epoch 1259, Loss: 0.0010838750895345584, Final Batch Loss: 0.00023546670854557306\n",
      "Epoch 1260, Loss: 0.00043064795318059623, Final Batch Loss: 0.00016062275972217321\n",
      "Epoch 1261, Loss: 0.0008713876086403616, Final Batch Loss: 6.451772787841037e-05\n",
      "Epoch 1262, Loss: 0.0019695750961545855, Final Batch Loss: 0.001610959297977388\n",
      "Epoch 1263, Loss: 0.004667439265176654, Final Batch Loss: 0.0027046091854572296\n",
      "Epoch 1264, Loss: 0.0006452469096984714, Final Batch Loss: 0.0003419280983507633\n",
      "Epoch 1265, Loss: 0.0007505230023525655, Final Batch Loss: 0.0001813831040635705\n",
      "Epoch 1266, Loss: 0.00019141137454425916, Final Batch Loss: 2.2666827135253698e-05\n",
      "Epoch 1267, Loss: 0.0007258049736265093, Final Batch Loss: 0.0003456472768448293\n",
      "Epoch 1268, Loss: 0.000845310409204103, Final Batch Loss: 0.0006093900301493704\n",
      "Epoch 1269, Loss: 0.0003463568391453009, Final Batch Loss: 5.87086942687165e-05\n",
      "Epoch 1270, Loss: 0.0005584337341133505, Final Batch Loss: 0.00029568272293545306\n",
      "Epoch 1271, Loss: 0.011130537081044167, Final Batch Loss: 0.01042307447642088\n",
      "Epoch 1272, Loss: 0.0005788383277831599, Final Batch Loss: 0.00023916193458717316\n",
      "Epoch 1273, Loss: 0.0011726077646017075, Final Batch Loss: 0.0009229692514054477\n",
      "Epoch 1274, Loss: 0.0007887043466325849, Final Batch Loss: 0.00033787009306252003\n",
      "Epoch 1275, Loss: 0.0034631691523827612, Final Batch Loss: 0.003061105264350772\n",
      "Epoch 1276, Loss: 0.009688543737865984, Final Batch Loss: 0.009104224853217602\n",
      "Epoch 1277, Loss: 0.0004619297542376444, Final Batch Loss: 0.0003080496098846197\n",
      "Epoch 1278, Loss: 0.0009973631822504103, Final Batch Loss: 0.0004930261056870222\n",
      "Epoch 1279, Loss: 0.01340503225219436, Final Batch Loss: 0.01301099918782711\n",
      "Epoch 1280, Loss: 0.016613364685326815, Final Batch Loss: 0.010808829218149185\n",
      "Epoch 1281, Loss: 0.004537413828074932, Final Batch Loss: 0.0022246460430324078\n",
      "Epoch 1282, Loss: 0.0035980547618237324, Final Batch Loss: 0.000103550853964407\n",
      "Epoch 1283, Loss: 0.03768103616312146, Final Batch Loss: 0.03162732347846031\n",
      "Epoch 1284, Loss: 0.007635384099557996, Final Batch Loss: 0.0006311044562608004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1285, Loss: 0.00058376943343319, Final Batch Loss: 0.00029957463266327977\n",
      "Epoch 1286, Loss: 0.0003683076211018488, Final Batch Loss: 0.00023873946338426322\n",
      "Epoch 1287, Loss: 0.06390117015689611, Final Batch Loss: 0.06354611366987228\n",
      "Epoch 1288, Loss: 0.02315525757148862, Final Batch Loss: 0.006884774658828974\n",
      "Epoch 1289, Loss: 0.0035403681686148047, Final Batch Loss: 0.00040162692312151194\n",
      "Epoch 1290, Loss: 0.0011785478855017573, Final Batch Loss: 0.00032800869666971266\n",
      "Epoch 1291, Loss: 0.011760147754102945, Final Batch Loss: 0.004568673670291901\n",
      "Epoch 1292, Loss: 0.0004989675362594426, Final Batch Loss: 0.00028313929215073586\n",
      "Epoch 1293, Loss: 0.013610297814011574, Final Batch Loss: 0.01296490803360939\n",
      "Epoch 1294, Loss: 0.0028081605560146272, Final Batch Loss: 0.0025633214972913265\n",
      "Epoch 1295, Loss: 0.007899883872596547, Final Batch Loss: 0.007652470842003822\n",
      "Epoch 1296, Loss: 0.005974193045403808, Final Batch Loss: 0.00035832071444019675\n",
      "Epoch 1297, Loss: 0.000565556445508264, Final Batch Loss: 8.393933239858598e-05\n",
      "Epoch 1298, Loss: 0.001706462528090924, Final Batch Loss: 0.0013769646175205708\n",
      "Epoch 1299, Loss: 0.0010454471630509943, Final Batch Loss: 9.56714793574065e-05\n",
      "Epoch 1300, Loss: 0.0006055772537365556, Final Batch Loss: 0.0002574267564341426\n",
      "Epoch 1301, Loss: 0.0019224885036237538, Final Batch Loss: 0.0007771716336719692\n",
      "Epoch 1302, Loss: 0.0018313105101697147, Final Batch Loss: 0.001014645560644567\n",
      "Epoch 1303, Loss: 0.0012500281154643744, Final Batch Loss: 0.0003575599112082273\n",
      "Epoch 1304, Loss: 0.005673589213984087, Final Batch Loss: 0.000164131197379902\n",
      "Epoch 1305, Loss: 0.005115538166137412, Final Batch Loss: 0.00038558317464776337\n",
      "Epoch 1306, Loss: 0.000950737128732726, Final Batch Loss: 0.0005634842673316598\n",
      "Epoch 1307, Loss: 0.0004841467161895707, Final Batch Loss: 0.00017096764349844307\n",
      "Epoch 1308, Loss: 0.0062527311383746564, Final Batch Loss: 0.005692980717867613\n",
      "Epoch 1309, Loss: 0.0029789222171530128, Final Batch Loss: 0.0005846739513799548\n",
      "Epoch 1310, Loss: 0.00044045729737263173, Final Batch Loss: 9.730608144309372e-05\n",
      "Epoch 1311, Loss: 0.0016937105101533234, Final Batch Loss: 0.0004885735106654465\n",
      "Epoch 1312, Loss: 0.0005240012324065901, Final Batch Loss: 6.435852992581204e-05\n",
      "Epoch 1313, Loss: 0.002306399983353913, Final Batch Loss: 0.0018643016228452325\n",
      "Epoch 1314, Loss: 0.001145910588093102, Final Batch Loss: 0.00036344671389088035\n",
      "Epoch 1315, Loss: 0.0016161015955731273, Final Batch Loss: 0.0006098253652453423\n",
      "Epoch 1316, Loss: 0.00048498350952286273, Final Batch Loss: 0.0003417959960643202\n",
      "Epoch 1317, Loss: 0.0008729943074285984, Final Batch Loss: 0.0002883027773350477\n",
      "Epoch 1318, Loss: 0.0007591469620820135, Final Batch Loss: 0.0004403485800139606\n",
      "Epoch 1319, Loss: 0.007942895288579166, Final Batch Loss: 0.007587944623082876\n",
      "Epoch 1320, Loss: 0.0006654371973127127, Final Batch Loss: 0.0001528692082501948\n",
      "Epoch 1321, Loss: 0.0009664112876635045, Final Batch Loss: 0.0005795167526230216\n",
      "Epoch 1322, Loss: 0.003068471123697236, Final Batch Loss: 0.000373969814972952\n",
      "Epoch 1323, Loss: 0.007688892888836563, Final Batch Loss: 0.00016747170593589544\n",
      "Epoch 1324, Loss: 0.0005853461916558444, Final Batch Loss: 0.00025016182917170227\n",
      "Epoch 1325, Loss: 0.0009631863722461276, Final Batch Loss: 9.16271164896898e-05\n",
      "Epoch 1326, Loss: 0.0005203665496082976, Final Batch Loss: 7.560268568340689e-05\n",
      "Epoch 1327, Loss: 0.0005163024179637432, Final Batch Loss: 0.0002714032307267189\n",
      "Epoch 1328, Loss: 0.0012203898877487518, Final Batch Loss: 0.00011869046284118667\n",
      "Epoch 1329, Loss: 0.002695627335924655, Final Batch Loss: 0.000555580307263881\n",
      "Epoch 1330, Loss: 0.0005470496689667925, Final Batch Loss: 0.0003128819225821644\n",
      "Epoch 1331, Loss: 0.0005088690340926405, Final Batch Loss: 3.116571679129265e-05\n",
      "Epoch 1332, Loss: 0.0008783914672676474, Final Batch Loss: 0.0005665062926709652\n",
      "Epoch 1333, Loss: 0.0005759491468779743, Final Batch Loss: 0.00028782873414456844\n",
      "Epoch 1334, Loss: 0.00031933767604641616, Final Batch Loss: 7.10538006387651e-05\n",
      "Epoch 1335, Loss: 0.010266767116263509, Final Batch Loss: 0.007270796690136194\n",
      "Epoch 1336, Loss: 0.001385632378514856, Final Batch Loss: 0.0006768616149201989\n",
      "Epoch 1337, Loss: 0.005078225280158222, Final Batch Loss: 0.0013971299631521106\n",
      "Epoch 1338, Loss: 0.0005764986563008279, Final Batch Loss: 0.00019756777328439057\n",
      "Epoch 1339, Loss: 0.0009442795562790707, Final Batch Loss: 0.00015948551299516112\n",
      "Epoch 1340, Loss: 0.0005476523947436363, Final Batch Loss: 0.0002166720514651388\n",
      "Epoch 1341, Loss: 0.001862922334112227, Final Batch Loss: 0.00032007601112127304\n",
      "Epoch 1342, Loss: 0.0006146318628452718, Final Batch Loss: 0.00040889819501899183\n",
      "Epoch 1343, Loss: 0.00764905073447153, Final Batch Loss: 0.0005441952380351722\n",
      "Epoch 1344, Loss: 0.004989587527234107, Final Batch Loss: 0.0007902433280833066\n",
      "Epoch 1345, Loss: 0.000612038595136255, Final Batch Loss: 0.00019710749620571733\n",
      "Epoch 1346, Loss: 0.0033989218645729125, Final Batch Loss: 0.00015760218957439065\n",
      "Epoch 1347, Loss: 0.0010392543626949191, Final Batch Loss: 0.00021757528884336352\n",
      "Epoch 1348, Loss: 0.0011139076377730817, Final Batch Loss: 0.0008578954148106277\n",
      "Epoch 1349, Loss: 0.0011948711762670428, Final Batch Loss: 0.00016656031948514283\n",
      "Epoch 1350, Loss: 0.0011149458769068588, Final Batch Loss: 5.75449266762007e-05\n",
      "Epoch 1351, Loss: 0.00048002181574702263, Final Batch Loss: 0.0003223126695957035\n",
      "Epoch 1352, Loss: 0.001439027430023998, Final Batch Loss: 0.0008328030235134065\n",
      "Epoch 1353, Loss: 0.0009570872061885893, Final Batch Loss: 0.00020593800581991673\n",
      "Epoch 1354, Loss: 0.0011220571759622544, Final Batch Loss: 0.000884419190697372\n",
      "Epoch 1355, Loss: 0.0002666787331691012, Final Batch Loss: 0.00014769466361030936\n",
      "Epoch 1356, Loss: 0.00040637393249198794, Final Batch Loss: 0.00014623699826188385\n",
      "Epoch 1357, Loss: 0.0004358606383902952, Final Batch Loss: 7.006559462752193e-05\n",
      "Epoch 1358, Loss: 0.012200060213217512, Final Batch Loss: 0.011930227279663086\n",
      "Epoch 1359, Loss: 0.0003656206390587613, Final Batch Loss: 0.0002040184917859733\n",
      "Epoch 1360, Loss: 0.0007919905983726494, Final Batch Loss: 0.00011207866918994114\n",
      "Epoch 1361, Loss: 0.00990263873245567, Final Batch Loss: 0.009400510229170322\n",
      "Epoch 1362, Loss: 0.004454321344383061, Final Batch Loss: 0.002619335660710931\n",
      "Epoch 1363, Loss: 0.0009201708890032023, Final Batch Loss: 0.0006304520647972822\n",
      "Epoch 1364, Loss: 0.009590645073330961, Final Batch Loss: 0.00023633216915186495\n",
      "Epoch 1365, Loss: 0.0006179296942718793, Final Batch Loss: 4.661090861191042e-05\n",
      "Epoch 1366, Loss: 0.0008152005320880562, Final Batch Loss: 0.0005307312239892781\n",
      "Epoch 1367, Loss: 0.0014884843840263784, Final Batch Loss: 0.0005387864075601101\n",
      "Epoch 1368, Loss: 0.007394974410999566, Final Batch Loss: 0.0002994083915837109\n",
      "Epoch 1369, Loss: 0.0003614653105614707, Final Batch Loss: 0.00021274053142406046\n",
      "Epoch 1370, Loss: 0.002322432235814631, Final Batch Loss: 0.0017029732698574662\n",
      "Epoch 1371, Loss: 0.0006686522683594376, Final Batch Loss: 0.00037157448241487145\n",
      "Epoch 1372, Loss: 0.0006839592388132587, Final Batch Loss: 0.0004563200636766851\n",
      "Epoch 1373, Loss: 0.00031383507302962244, Final Batch Loss: 0.0001552687754156068\n",
      "Epoch 1374, Loss: 0.0004519251233432442, Final Batch Loss: 0.0003139438049402088\n",
      "Epoch 1375, Loss: 0.0011569251801120117, Final Batch Loss: 0.0010214148787781596\n",
      "Epoch 1376, Loss: 0.0006112838163971901, Final Batch Loss: 0.00017669654334895313\n",
      "Epoch 1377, Loss: 0.0009884629107546061, Final Batch Loss: 0.0006411601207219064\n",
      "Epoch 1378, Loss: 0.00037925595097476617, Final Batch Loss: 0.00011947501479880884\n",
      "Epoch 1379, Loss: 0.007582097547128797, Final Batch Loss: 0.00011657853610813618\n",
      "Epoch 1380, Loss: 0.00022005823848303407, Final Batch Loss: 6.709156150463969e-05\n",
      "Epoch 1381, Loss: 0.0005586368424701504, Final Batch Loss: 0.00011715088476194069\n",
      "Epoch 1382, Loss: 0.0027265517273917794, Final Batch Loss: 0.0018967898795381188\n",
      "Epoch 1383, Loss: 0.0005407700809882954, Final Batch Loss: 0.00014303029456641525\n",
      "Epoch 1384, Loss: 0.0004419859978952445, Final Batch Loss: 7.8680990554858e-05\n",
      "Epoch 1385, Loss: 0.0005967674369458109, Final Batch Loss: 0.0003253850736655295\n",
      "Epoch 1386, Loss: 0.002393642920651473, Final Batch Loss: 0.00010646904411260039\n",
      "Epoch 1387, Loss: 0.0003037971691810526, Final Batch Loss: 0.00011187853669980541\n",
      "Epoch 1388, Loss: 0.0009735951534821652, Final Batch Loss: 0.0008741163183003664\n",
      "Epoch 1389, Loss: 0.001700700435321778, Final Batch Loss: 0.001132530509494245\n",
      "Epoch 1390, Loss: 0.00045696985034737736, Final Batch Loss: 0.00023447202693205327\n",
      "Epoch 1391, Loss: 0.008081028292508563, Final Batch Loss: 2.8004924388369545e-05\n",
      "Epoch 1392, Loss: 0.02024909618194215, Final Batch Loss: 0.00028893674607388675\n",
      "Epoch 1393, Loss: 0.0008401556842727587, Final Batch Loss: 0.0006580543122254312\n",
      "Epoch 1394, Loss: 0.00022334931054501794, Final Batch Loss: 4.848444586968981e-05\n",
      "Epoch 1395, Loss: 0.00015012086078058928, Final Batch Loss: 8.06925309007056e-05\n",
      "Epoch 1396, Loss: 0.000154958415805595, Final Batch Loss: 6.041366214049049e-05\n",
      "Epoch 1397, Loss: 0.016579123970586807, Final Batch Loss: 0.0007501196232624352\n",
      "Epoch 1398, Loss: 0.0005648167716572061, Final Batch Loss: 0.0002377217897446826\n",
      "Epoch 1399, Loss: 0.0010503216763027012, Final Batch Loss: 0.0005063854623585939\n",
      "Epoch 1400, Loss: 0.000799559464212507, Final Batch Loss: 0.00032807860407046974\n",
      "Epoch 1401, Loss: 0.0033709043927956372, Final Batch Loss: 8.521720883436501e-05\n",
      "Epoch 1402, Loss: 0.00045173866965342313, Final Batch Loss: 0.00022688390163239092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1403, Loss: 0.018214545212686062, Final Batch Loss: 0.009709314443171024\n",
      "Epoch 1404, Loss: 0.0003445401380304247, Final Batch Loss: 0.0002232699771411717\n",
      "Epoch 1405, Loss: 0.006406383166904561, Final Batch Loss: 0.00016336240514647216\n",
      "Epoch 1406, Loss: 0.0006286478019319475, Final Batch Loss: 0.00038979609962552786\n",
      "Epoch 1407, Loss: 0.0003694833503686823, Final Batch Loss: 0.00010496791946934536\n",
      "Epoch 1408, Loss: 0.008777426643064246, Final Batch Loss: 0.008411712013185024\n",
      "Epoch 1409, Loss: 0.006636622652877122, Final Batch Loss: 0.0007332226377911866\n",
      "Epoch 1410, Loss: 0.00289472215808928, Final Batch Loss: 0.0006976646836847067\n",
      "Epoch 1411, Loss: 0.0014018607616890222, Final Batch Loss: 0.00048115974641405046\n",
      "Epoch 1412, Loss: 0.005559348268434405, Final Batch Loss: 0.0005560519639402628\n",
      "Epoch 1413, Loss: 0.00041103019611909986, Final Batch Loss: 6.939805462025106e-05\n",
      "Epoch 1414, Loss: 0.00033055979292839766, Final Batch Loss: 0.00015966230421327055\n",
      "Epoch 1415, Loss: 0.0015308867732528597, Final Batch Loss: 0.0010861975606530905\n",
      "Epoch 1416, Loss: 0.021964308543829247, Final Batch Loss: 0.02169933170080185\n",
      "Epoch 1417, Loss: 0.0006128269014880061, Final Batch Loss: 0.00017410091822966933\n",
      "Epoch 1418, Loss: 0.0037403357928269543, Final Batch Loss: 8.13833685242571e-05\n",
      "Epoch 1419, Loss: 0.008678798098117113, Final Batch Loss: 0.008133508265018463\n",
      "Epoch 1420, Loss: 0.000999465846689418, Final Batch Loss: 0.0002216766297351569\n",
      "Epoch 1421, Loss: 0.0008738973701838404, Final Batch Loss: 0.00039171913522295654\n",
      "Epoch 1422, Loss: 0.003993156322394498, Final Batch Loss: 0.0038174018263816833\n",
      "Epoch 1423, Loss: 0.0007079642091412097, Final Batch Loss: 0.000398424657760188\n",
      "Epoch 1424, Loss: 0.0008367279369849712, Final Batch Loss: 0.0002752470609266311\n",
      "Epoch 1425, Loss: 0.008205434918636456, Final Batch Loss: 0.000277150102192536\n",
      "Epoch 1426, Loss: 0.002940407779533416, Final Batch Loss: 0.00045360956573858857\n",
      "Epoch 1427, Loss: 0.0012917029671370983, Final Batch Loss: 0.0007264906307682395\n",
      "Epoch 1428, Loss: 0.00894312746822834, Final Batch Loss: 0.008471502922475338\n",
      "Epoch 1429, Loss: 0.0017058368830475956, Final Batch Loss: 0.0013983278768137097\n",
      "Epoch 1430, Loss: 0.0006600956548936665, Final Batch Loss: 0.00038485450204461813\n",
      "Epoch 1431, Loss: 0.0011595890391618013, Final Batch Loss: 0.0008331743301823735\n",
      "Epoch 1432, Loss: 0.0032588668691460043, Final Batch Loss: 0.0002886405272874981\n",
      "Epoch 1433, Loss: 0.0016053314611781389, Final Batch Loss: 0.0002967081090901047\n",
      "Epoch 1434, Loss: 0.0011737296590581536, Final Batch Loss: 0.0003541941987350583\n",
      "Epoch 1435, Loss: 0.0005909307510592043, Final Batch Loss: 0.0002896287478506565\n",
      "Epoch 1436, Loss: 0.0011252017720835283, Final Batch Loss: 0.0009022117010317743\n",
      "Epoch 1437, Loss: 0.001299829047638923, Final Batch Loss: 0.00029919500229880214\n",
      "Epoch 1438, Loss: 0.0019227387965656817, Final Batch Loss: 0.001411063247360289\n",
      "Epoch 1439, Loss: 0.0020471557800192386, Final Batch Loss: 0.0017002123640850186\n",
      "Epoch 1440, Loss: 0.0004468090337468311, Final Batch Loss: 0.0002411451278021559\n",
      "Epoch 1441, Loss: 0.0005297978059388697, Final Batch Loss: 0.00031458368175663054\n",
      "Epoch 1442, Loss: 0.0006904962938278913, Final Batch Loss: 0.00035566085716709495\n",
      "Epoch 1443, Loss: 0.007104816380888224, Final Batch Loss: 0.006728960666805506\n",
      "Epoch 1444, Loss: 0.000839806831208989, Final Batch Loss: 0.00025678498786874115\n",
      "Epoch 1445, Loss: 0.03058438003063202, Final Batch Loss: 0.013081645593047142\n",
      "Epoch 1446, Loss: 0.0006311458273557946, Final Batch Loss: 0.00041230532224290073\n",
      "Epoch 1447, Loss: 0.0010293434315826744, Final Batch Loss: 0.0004516981716733426\n",
      "Epoch 1448, Loss: 0.0005233925330685452, Final Batch Loss: 0.00016446902009192854\n",
      "Epoch 1449, Loss: 0.0007964282121974975, Final Batch Loss: 0.0005413779290392995\n",
      "Epoch 1450, Loss: 0.0006728176376782358, Final Batch Loss: 0.000545262882951647\n",
      "Epoch 1451, Loss: 0.0008458181982859969, Final Batch Loss: 0.00014291383558884263\n",
      "Epoch 1452, Loss: 0.0007271683716680855, Final Batch Loss: 0.00033815918141044676\n",
      "Epoch 1453, Loss: 0.00224687613081187, Final Batch Loss: 0.0017044423148036003\n",
      "Epoch 1454, Loss: 0.00044009345583617687, Final Batch Loss: 0.0002492678177077323\n",
      "Epoch 1455, Loss: 0.00047017482575029135, Final Batch Loss: 0.00017758100875653327\n",
      "Epoch 1456, Loss: 0.0012131571493227966, Final Batch Loss: 0.0010933863231912255\n",
      "Epoch 1457, Loss: 0.000600451254285872, Final Batch Loss: 0.0002703790960367769\n",
      "Epoch 1458, Loss: 0.0006545360665768385, Final Batch Loss: 0.0002977125404868275\n",
      "Epoch 1459, Loss: 0.0008817696507321671, Final Batch Loss: 0.0006616725586354733\n",
      "Epoch 1460, Loss: 0.012007940385956317, Final Batch Loss: 0.011599336750805378\n",
      "Epoch 1461, Loss: 0.0005395752377808094, Final Batch Loss: 0.0002794369065668434\n",
      "Epoch 1462, Loss: 0.004862940666498616, Final Batch Loss: 0.00029102785629220307\n",
      "Epoch 1463, Loss: 0.00016667790259816684, Final Batch Loss: 5.119584602653049e-05\n",
      "Epoch 1464, Loss: 0.0063800388015806675, Final Batch Loss: 0.0009396085515618324\n",
      "Epoch 1465, Loss: 0.0004419208999024704, Final Batch Loss: 8.000571688171476e-05\n",
      "Epoch 1466, Loss: 0.0014749946349184029, Final Batch Loss: 0.0001176492587546818\n",
      "Epoch 1467, Loss: 0.00831659029063303, Final Batch Loss: 0.008091327734291553\n",
      "Epoch 1468, Loss: 0.001595680310856551, Final Batch Loss: 0.000810144585557282\n",
      "Epoch 1469, Loss: 0.0008408356516156346, Final Batch Loss: 0.00036622415063902736\n",
      "Epoch 1470, Loss: 0.003691582882311195, Final Batch Loss: 0.0005609923391602933\n",
      "Epoch 1471, Loss: 0.00314400510978885, Final Batch Loss: 0.00023516130750067532\n",
      "Epoch 1472, Loss: 0.0005638342263409868, Final Batch Loss: 0.00032960681710392237\n",
      "Epoch 1473, Loss: 0.003520149148243945, Final Batch Loss: 6.398429832188413e-05\n",
      "Epoch 1474, Loss: 0.0005509970505954698, Final Batch Loss: 0.0004013755824416876\n",
      "Epoch 1475, Loss: 0.0006550050748046488, Final Batch Loss: 0.00028000352904200554\n",
      "Epoch 1476, Loss: 0.00028731153724947944, Final Batch Loss: 0.00010388794908067212\n",
      "Epoch 1477, Loss: 0.0009160627087112516, Final Batch Loss: 0.00027885290910489857\n",
      "Epoch 1478, Loss: 0.0014452083269134164, Final Batch Loss: 0.0011378846829757094\n",
      "Epoch 1479, Loss: 0.0011648284271359444, Final Batch Loss: 0.0005174393299967051\n",
      "Epoch 1480, Loss: 0.0004567555442918092, Final Batch Loss: 0.00017291901167482138\n",
      "Epoch 1481, Loss: 0.013197396699979436, Final Batch Loss: 0.013087044470012188\n",
      "Epoch 1482, Loss: 0.0002717152747209184, Final Batch Loss: 7.358281436609104e-05\n",
      "Epoch 1483, Loss: 0.0006478634604718536, Final Batch Loss: 0.00040337283280678093\n",
      "Epoch 1484, Loss: 0.0005786932306364179, Final Batch Loss: 0.0001624667493160814\n",
      "Epoch 1485, Loss: 0.00048212139518000185, Final Batch Loss: 0.00022812499082647264\n",
      "Epoch 1486, Loss: 0.0009135068103205413, Final Batch Loss: 0.0006666138651780784\n",
      "Epoch 1487, Loss: 0.0005583974707406014, Final Batch Loss: 0.00015458220150321722\n",
      "Epoch 1488, Loss: 0.004115258503588848, Final Batch Loss: 0.00015178199100773782\n",
      "Epoch 1489, Loss: 0.0005013728368794546, Final Batch Loss: 0.00015728671860415488\n",
      "Epoch 1490, Loss: 0.0006554153078468516, Final Batch Loss: 0.00016693062207195908\n",
      "Epoch 1491, Loss: 0.0006665317778242752, Final Batch Loss: 5.072435305919498e-05\n",
      "Epoch 1492, Loss: 0.0004575749044306576, Final Batch Loss: 0.000130238855490461\n",
      "Epoch 1493, Loss: 0.002167758299037814, Final Batch Loss: 0.0020055552013218403\n",
      "Epoch 1494, Loss: 0.001979437147383578, Final Batch Loss: 0.001784433494322002\n",
      "Epoch 1495, Loss: 0.0008477982046315446, Final Batch Loss: 0.00024356618814636022\n",
      "Epoch 1496, Loss: 0.0010131725794053636, Final Batch Loss: 6.892382953083143e-05\n",
      "Epoch 1497, Loss: 0.0005153741658432409, Final Batch Loss: 0.00012593290011864156\n",
      "Epoch 1498, Loss: 0.0015954377013258636, Final Batch Loss: 0.0007633166969753802\n",
      "Epoch 1499, Loss: 0.0011445692070992664, Final Batch Loss: 0.0002163419412681833\n",
      "Epoch 1500, Loss: 0.0001452364886063151, Final Batch Loss: 2.7533445972949266e-05\n",
      "Epoch 1501, Loss: 0.00019631743634818122, Final Batch Loss: 8.112136129057035e-05\n",
      "Epoch 1502, Loss: 0.0009421851355000399, Final Batch Loss: 0.0008463396807201207\n",
      "Epoch 1503, Loss: 0.001584690238814801, Final Batch Loss: 0.0010581420501694083\n",
      "Epoch 1504, Loss: 0.0004280177381588146, Final Batch Loss: 0.0003234818868804723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1505, Loss: 0.0006281745445448905, Final Batch Loss: 0.0003248606517445296\n",
      "Epoch 1506, Loss: 0.015240910113789141, Final Batch Loss: 0.00012861902359873056\n",
      "Epoch 1507, Loss: 0.0008438252261839807, Final Batch Loss: 0.00010564329568296671\n",
      "Epoch 1508, Loss: 0.0005712646525353193, Final Batch Loss: 0.0002734014706220478\n",
      "Epoch 1509, Loss: 0.0005814945616293699, Final Batch Loss: 0.0001388557138852775\n",
      "Epoch 1510, Loss: 0.0003581858836696483, Final Batch Loss: 0.0002802316448651254\n",
      "Epoch 1511, Loss: 0.0006331921940727625, Final Batch Loss: 5.3358733566710725e-05\n",
      "Epoch 1512, Loss: 0.0002614488039398566, Final Batch Loss: 0.00012448153574950993\n",
      "Epoch 1513, Loss: 0.0003485226188786328, Final Batch Loss: 0.00010472643771208823\n",
      "Epoch 1514, Loss: 0.00021629887851304375, Final Batch Loss: 5.658536611008458e-05\n",
      "Epoch 1515, Loss: 0.00034081799094565213, Final Batch Loss: 1.946830889210105e-05\n",
      "Epoch 1516, Loss: 0.0005358839989639819, Final Batch Loss: 0.00012486529885791242\n",
      "Epoch 1517, Loss: 0.0005870224849786609, Final Batch Loss: 7.479186751879752e-05\n",
      "Epoch 1518, Loss: 0.0007568947912659496, Final Batch Loss: 0.00046595436288043857\n",
      "Epoch 1519, Loss: 0.0009434852108824998, Final Batch Loss: 0.0005686660879291594\n",
      "Epoch 1520, Loss: 0.00026678870926843956, Final Batch Loss: 6.943963671801612e-05\n",
      "Epoch 1521, Loss: 0.00017220149129570927, Final Batch Loss: 1.4996845493442379e-05\n",
      "Epoch 1522, Loss: 0.00017512648628326133, Final Batch Loss: 6.313305493677035e-05\n",
      "Epoch 1523, Loss: 0.0005500578918145038, Final Batch Loss: 7.412510603899136e-05\n",
      "Epoch 1524, Loss: 0.0012582387425936759, Final Batch Loss: 0.00021794409258291125\n",
      "Epoch 1525, Loss: 0.0005252818664303049, Final Batch Loss: 0.00042537556146271527\n",
      "Epoch 1526, Loss: 0.00031669203599449247, Final Batch Loss: 0.00014416644989978522\n",
      "Epoch 1527, Loss: 0.005076099303551018, Final Batch Loss: 0.0017263112822547555\n",
      "Epoch 1528, Loss: 0.00018486253247829154, Final Batch Loss: 4.3178391933906823e-05\n",
      "Epoch 1529, Loss: 0.0002496350134606473, Final Batch Loss: 0.00019557510677259415\n",
      "Epoch 1530, Loss: 0.0004254719824530184, Final Batch Loss: 0.00022643129341304302\n",
      "Epoch 1531, Loss: 0.00044960633385926485, Final Batch Loss: 0.0002981927536893636\n",
      "Epoch 1532, Loss: 0.0011186180054210126, Final Batch Loss: 0.00030565063934773207\n",
      "Epoch 1533, Loss: 0.004113050039450172, Final Batch Loss: 8.437489304924384e-05\n",
      "Epoch 1534, Loss: 0.0005500944098457694, Final Batch Loss: 0.0004108416032977402\n",
      "Epoch 1535, Loss: 0.0005516836972674355, Final Batch Loss: 0.00020712996774818748\n",
      "Epoch 1536, Loss: 0.00036087534681428224, Final Batch Loss: 0.00021888151241000742\n",
      "Epoch 1537, Loss: 0.004561500973068178, Final Batch Loss: 0.00016705214511603117\n",
      "Epoch 1538, Loss: 0.0002767625410342589, Final Batch Loss: 0.00013195586507208645\n",
      "Epoch 1539, Loss: 0.0006648394919466227, Final Batch Loss: 0.0002585391339380294\n",
      "Epoch 1540, Loss: 0.003286125156591879, Final Batch Loss: 5.922980562900193e-05\n",
      "Epoch 1541, Loss: 0.00541313100620755, Final Batch Loss: 4.848526805290021e-05\n",
      "Epoch 1542, Loss: 0.001521999336546287, Final Batch Loss: 6.558708264492452e-05\n",
      "Epoch 1543, Loss: 0.008005310963199008, Final Batch Loss: 0.00792651902884245\n",
      "Epoch 1544, Loss: 0.0015342304250225425, Final Batch Loss: 0.0008312066784128547\n",
      "Epoch 1545, Loss: 0.0006006285548210144, Final Batch Loss: 0.0002528686891309917\n",
      "Epoch 1546, Loss: 0.0015509778750129044, Final Batch Loss: 0.0006276442436501384\n",
      "Epoch 1547, Loss: 0.0005960903290542774, Final Batch Loss: 0.00011941693810513243\n",
      "Epoch 1548, Loss: 0.0013937284820713103, Final Batch Loss: 0.00014792574802413583\n",
      "Epoch 1549, Loss: 0.0018315604247618467, Final Batch Loss: 0.00021252877195365727\n",
      "Epoch 1550, Loss: 0.0010052589059341699, Final Batch Loss: 0.00042049275361932814\n",
      "Epoch 1551, Loss: 0.0003811056667473167, Final Batch Loss: 0.00011198822176083922\n",
      "Epoch 1552, Loss: 0.0006839457055320963, Final Batch Loss: 0.00010664491856005043\n",
      "Epoch 1553, Loss: 0.006293187063420191, Final Batch Loss: 0.00028773178928531706\n",
      "Epoch 1554, Loss: 0.0004718886048067361, Final Batch Loss: 0.0002437601942801848\n",
      "Epoch 1555, Loss: 0.000564168207347393, Final Batch Loss: 0.00013420599862001836\n",
      "Epoch 1556, Loss: 0.0006647064437856898, Final Batch Loss: 0.00020919767848681659\n",
      "Epoch 1557, Loss: 0.0013171281898394227, Final Batch Loss: 0.0009414837695658207\n",
      "Epoch 1558, Loss: 0.007517478257796029, Final Batch Loss: 3.594841473386623e-05\n",
      "Epoch 1559, Loss: 0.0004713177331723273, Final Batch Loss: 0.00021775250206701458\n",
      "Epoch 1560, Loss: 0.00035730068339034915, Final Batch Loss: 0.0001422576024197042\n",
      "Epoch 1561, Loss: 0.0043172817677259445, Final Batch Loss: 0.003944958094507456\n",
      "Epoch 1562, Loss: 0.00017671067325863987, Final Batch Loss: 5.053669156040996e-05\n",
      "Epoch 1563, Loss: 0.0007042678771540523, Final Batch Loss: 0.00020344799850136042\n",
      "Epoch 1564, Loss: 0.0006889190699439496, Final Batch Loss: 0.0005706134252250195\n",
      "Epoch 1565, Loss: 0.009689328580861911, Final Batch Loss: 0.009442158974707127\n",
      "Epoch 1566, Loss: 0.00378734411788173, Final Batch Loss: 0.003475416684523225\n",
      "Epoch 1567, Loss: 0.00029055203776806593, Final Batch Loss: 6.407384353224188e-05\n",
      "Epoch 1568, Loss: 0.006372007374011446, Final Batch Loss: 0.006289277691394091\n",
      "Epoch 1569, Loss: 0.0006033973477315158, Final Batch Loss: 0.00030312148737721145\n",
      "Epoch 1570, Loss: 0.0007230343835544772, Final Batch Loss: 7.535104668932036e-05\n",
      "Epoch 1571, Loss: 0.0008587630873080343, Final Batch Loss: 0.0004640281549654901\n",
      "Epoch 1572, Loss: 0.0005943770374869928, Final Batch Loss: 0.00035673219827003777\n",
      "Epoch 1573, Loss: 0.0007772943354211748, Final Batch Loss: 0.0004910476855002344\n",
      "Epoch 1574, Loss: 0.0003813892253674567, Final Batch Loss: 0.00011711037950590253\n",
      "Epoch 1575, Loss: 0.0007928586128400639, Final Batch Loss: 0.00017725386715028435\n",
      "Epoch 1576, Loss: 0.0016766071785241365, Final Batch Loss: 0.00019770371727645397\n",
      "Epoch 1577, Loss: 0.0013297341211000457, Final Batch Loss: 0.00019767195044551045\n",
      "Epoch 1578, Loss: 0.0003560036711860448, Final Batch Loss: 9.177534957416356e-05\n",
      "Epoch 1579, Loss: 0.0005283659120323136, Final Batch Loss: 8.728216926101595e-05\n",
      "Epoch 1580, Loss: 0.0003269887893111445, Final Batch Loss: 8.905877621145919e-05\n",
      "Epoch 1581, Loss: 0.00022536126925842836, Final Batch Loss: 0.00015129066014196724\n",
      "Epoch 1582, Loss: 0.009919834905304015, Final Batch Loss: 0.009515834972262383\n",
      "Epoch 1583, Loss: 0.0006352985365083441, Final Batch Loss: 0.000139521827804856\n",
      "Epoch 1584, Loss: 0.00035823319922201335, Final Batch Loss: 0.0001974055776372552\n",
      "Epoch 1585, Loss: 0.001231634319992736, Final Batch Loss: 0.0009303638944402337\n",
      "Epoch 1586, Loss: 0.0003904537734342739, Final Batch Loss: 0.0002613262622617185\n",
      "Epoch 1587, Loss: 0.00043699628849935834, Final Batch Loss: 7.430997811752604e-06\n",
      "Epoch 1588, Loss: 0.000446356825705152, Final Batch Loss: 0.00011267538502579555\n",
      "Epoch 1589, Loss: 0.0017516333318781108, Final Batch Loss: 0.001288671395741403\n",
      "Epoch 1590, Loss: 0.00012723344480036758, Final Batch Loss: 5.261145633994602e-05\n",
      "Epoch 1591, Loss: 0.00023643625172553584, Final Batch Loss: 0.00015332632756326348\n",
      "Epoch 1592, Loss: 0.0005004193590139039, Final Batch Loss: 0.0004337230639066547\n",
      "Epoch 1593, Loss: 0.023942403495311737, Final Batch Loss: 0.020881356671452522\n",
      "Epoch 1594, Loss: 0.0029359115287661552, Final Batch Loss: 8.393474854528904e-05\n",
      "Epoch 1595, Loss: 0.00020104384020669386, Final Batch Loss: 7.77887980802916e-05\n",
      "Epoch 1596, Loss: 0.00014555737652699463, Final Batch Loss: 4.32922643085476e-05\n",
      "Epoch 1597, Loss: 0.0037967764219501987, Final Batch Loss: 0.003594094654545188\n",
      "Epoch 1598, Loss: 0.00042633791235857643, Final Batch Loss: 3.792267307289876e-05\n",
      "Epoch 1599, Loss: 0.0005608122955891304, Final Batch Loss: 0.0004889359697699547\n",
      "Epoch 1600, Loss: 0.00666083897522185, Final Batch Loss: 0.00023263170442078263\n",
      "Epoch 1601, Loss: 0.0011126833269372582, Final Batch Loss: 0.0007939746137708426\n",
      "Epoch 1602, Loss: 0.0032734888227423653, Final Batch Loss: 0.0030352429021149874\n",
      "Epoch 1603, Loss: 0.0020081650000065565, Final Batch Loss: 0.0005203112959861755\n",
      "Epoch 1604, Loss: 0.0008185949845938012, Final Batch Loss: 0.00022779345454182476\n",
      "Epoch 1605, Loss: 0.0002634266493259929, Final Batch Loss: 7.729474600637332e-05\n",
      "Epoch 1606, Loss: 0.0015511128876823932, Final Batch Loss: 0.0012647698167711496\n",
      "Epoch 1607, Loss: 0.0006161525525385514, Final Batch Loss: 0.0001851630659075454\n",
      "Epoch 1608, Loss: 0.0006517046767839929, Final Batch Loss: 2.933375617431011e-05\n",
      "Epoch 1609, Loss: 0.0007378195587079972, Final Batch Loss: 0.00014416969497688115\n",
      "Epoch 1610, Loss: 0.004864509719482157, Final Batch Loss: 5.8156940212938935e-05\n",
      "Epoch 1611, Loss: 0.00028629254666157067, Final Batch Loss: 2.9433780582621694e-05\n",
      "Epoch 1612, Loss: 0.000589613919146359, Final Batch Loss: 0.00022283411817625165\n",
      "Epoch 1613, Loss: 0.007562036509625614, Final Batch Loss: 8.514930959790945e-05\n",
      "Epoch 1614, Loss: 0.0003612396903918125, Final Batch Loss: 0.00010740818834165111\n",
      "Epoch 1615, Loss: 0.0015446537036041263, Final Batch Loss: 5.34379250893835e-05\n",
      "Epoch 1616, Loss: 0.007491450145607814, Final Batch Loss: 0.007076667156070471\n",
      "Epoch 1617, Loss: 0.0003695206542033702, Final Batch Loss: 0.00017403168021701276\n",
      "Epoch 1618, Loss: 0.00036689118132926524, Final Batch Loss: 5.040419637225568e-05\n",
      "Epoch 1619, Loss: 0.0014595601242035627, Final Batch Loss: 0.0005709147080779076\n",
      "Epoch 1620, Loss: 0.0004218768881401047, Final Batch Loss: 0.00015945623454172164\n",
      "Epoch 1621, Loss: 0.00020104850409552455, Final Batch Loss: 7.744482718408108e-05\n",
      "Epoch 1622, Loss: 0.00039167332579381764, Final Batch Loss: 0.0001796771102817729\n",
      "Epoch 1623, Loss: 0.00022097674082033336, Final Batch Loss: 6.131982081569731e-05\n",
      "Epoch 1624, Loss: 0.0005394430481828749, Final Batch Loss: 0.00017354905139654875\n",
      "Epoch 1625, Loss: 0.00044480618089437485, Final Batch Loss: 0.0001716931874398142\n",
      "Epoch 1626, Loss: 0.0022630931343883276, Final Batch Loss: 0.0013157195644453168\n",
      "Epoch 1627, Loss: 0.00042544039024505764, Final Batch Loss: 0.00013462147035170346\n",
      "Epoch 1628, Loss: 0.0008243744960054755, Final Batch Loss: 0.0005050835898146033\n",
      "Epoch 1629, Loss: 0.00013729305646847934, Final Batch Loss: 6.074830162106082e-05\n",
      "Epoch 1630, Loss: 0.001154588593635708, Final Batch Loss: 0.00028100807685405016\n",
      "Epoch 1631, Loss: 9.871225847746246e-05, Final Batch Loss: 6.65357947582379e-05\n",
      "Epoch 1632, Loss: 0.0003642703450168483, Final Batch Loss: 6.523014599224553e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1633, Loss: 0.00040094142605084926, Final Batch Loss: 0.00024056276015471667\n",
      "Epoch 1634, Loss: 0.0005767523107351735, Final Batch Loss: 0.00040701290708966553\n",
      "Epoch 1635, Loss: 0.0003289552842034027, Final Batch Loss: 0.00013290475180838257\n",
      "Epoch 1636, Loss: 0.00034883219632320106, Final Batch Loss: 0.00016071907884906977\n",
      "Epoch 1637, Loss: 0.0005772619188064709, Final Batch Loss: 0.00021182587079238147\n",
      "Epoch 1638, Loss: 0.0005544013547478244, Final Batch Loss: 0.0003801135753747076\n",
      "Epoch 1639, Loss: 0.0007821346516720951, Final Batch Loss: 0.00026558799436315894\n",
      "Epoch 1640, Loss: 0.0002712568821152672, Final Batch Loss: 0.0001254029484698549\n",
      "Epoch 1641, Loss: 0.00019939681988034863, Final Batch Loss: 0.0001793998380890116\n",
      "Epoch 1642, Loss: 0.0027144712512381375, Final Batch Loss: 0.002218356356024742\n",
      "Epoch 1643, Loss: 0.00024362852127524093, Final Batch Loss: 0.00016022891213651747\n",
      "Epoch 1644, Loss: 0.00031484243299928494, Final Batch Loss: 5.855707058799453e-05\n",
      "Epoch 1645, Loss: 0.02267604071766982, Final Batch Loss: 1.105789215216646e-05\n",
      "Epoch 1646, Loss: 0.000319432292599231, Final Batch Loss: 0.00012483776663430035\n",
      "Epoch 1647, Loss: 0.0003322227858006954, Final Batch Loss: 0.0001525159168522805\n",
      "Epoch 1648, Loss: 0.005728501157136634, Final Batch Loss: 6.216138717718422e-05\n",
      "Epoch 1649, Loss: 0.014411541866138577, Final Batch Loss: 0.0010262832511216402\n",
      "Epoch 1650, Loss: 0.003936387365683913, Final Batch Loss: 0.00028946506790816784\n",
      "Epoch 1651, Loss: 0.00621979427523911, Final Batch Loss: 0.0009307658765465021\n",
      "Epoch 1652, Loss: 0.0005540087295230478, Final Batch Loss: 0.000183523865416646\n",
      "Epoch 1653, Loss: 0.00029207932675490156, Final Batch Loss: 0.0002153575624106452\n",
      "Epoch 1654, Loss: 0.00042156592826358974, Final Batch Loss: 0.00028750518686138093\n",
      "Epoch 1655, Loss: 0.00030955612601246685, Final Batch Loss: 0.00016710055933799595\n",
      "Epoch 1656, Loss: 0.00018860361888073385, Final Batch Loss: 3.537540032994002e-05\n",
      "Epoch 1657, Loss: 0.004333598277298734, Final Batch Loss: 0.0002634862612467259\n",
      "Epoch 1658, Loss: 0.011844218242913485, Final Batch Loss: 0.010720711201429367\n",
      "Epoch 1659, Loss: 0.0008258078014478087, Final Batch Loss: 0.00033247662940993905\n",
      "Epoch 1660, Loss: 0.0018576598376967013, Final Batch Loss: 0.0016082966467365623\n",
      "Epoch 1661, Loss: 0.007821785387932323, Final Batch Loss: 0.00013141204544808716\n",
      "Epoch 1662, Loss: 0.003023173805559054, Final Batch Loss: 0.00267956405878067\n",
      "Epoch 1663, Loss: 0.0005851493333466351, Final Batch Loss: 0.0003521121689118445\n",
      "Epoch 1664, Loss: 0.0008424474071944132, Final Batch Loss: 0.0006841577123850584\n",
      "Epoch 1665, Loss: 0.00045529288763646036, Final Batch Loss: 0.00023865484399721026\n",
      "Epoch 1666, Loss: 0.00019011344556929544, Final Batch Loss: 8.824272663332522e-05\n",
      "Epoch 1667, Loss: 0.00971471396042034, Final Batch Loss: 0.009546860121190548\n",
      "Epoch 1668, Loss: 0.0007357761496677995, Final Batch Loss: 0.0004047144902870059\n",
      "Epoch 1669, Loss: 0.0035080232773907483, Final Batch Loss: 0.0033431649208068848\n",
      "Epoch 1670, Loss: 0.00019337955018272623, Final Batch Loss: 4.367742076283321e-05\n",
      "Epoch 1671, Loss: 0.00033361342229909496, Final Batch Loss: 1.1688590348057915e-05\n",
      "Epoch 1672, Loss: 0.000362149701686576, Final Batch Loss: 8.62799643073231e-05\n",
      "Epoch 1673, Loss: 0.00045936858805362135, Final Batch Loss: 0.00023747855448164046\n",
      "Epoch 1674, Loss: 0.04114952364761848, Final Batch Loss: 0.040954310446977615\n",
      "Epoch 1675, Loss: 0.0018346826254855841, Final Batch Loss: 0.0014356591273099184\n",
      "Epoch 1676, Loss: 0.0005147454648977146, Final Batch Loss: 0.0001273297384614125\n",
      "Epoch 1677, Loss: 0.0009109130187425762, Final Batch Loss: 0.0002683870552573353\n",
      "Epoch 1678, Loss: 0.0006020404689479619, Final Batch Loss: 0.00015584490029141307\n",
      "Epoch 1679, Loss: 0.00019220640751882456, Final Batch Loss: 5.1163104217266664e-05\n",
      "Epoch 1680, Loss: 0.0014301847259048373, Final Batch Loss: 0.00018807841115631163\n",
      "Epoch 1681, Loss: 0.0002995511385961436, Final Batch Loss: 0.00018384239228907973\n",
      "Epoch 1682, Loss: 0.0017806028481572866, Final Batch Loss: 0.0010217232629656792\n",
      "Epoch 1683, Loss: 0.006353629898512736, Final Batch Loss: 0.00019035875448025763\n",
      "Epoch 1684, Loss: 0.0002651023314683698, Final Batch Loss: 0.00015549271483905613\n",
      "Epoch 1685, Loss: 0.00021929621289018542, Final Batch Loss: 0.00013071685680188239\n",
      "Epoch 1686, Loss: 0.001090147896320559, Final Batch Loss: 0.00011112146603409201\n",
      "Epoch 1687, Loss: 0.0009517352300463244, Final Batch Loss: 0.00019316257385071367\n",
      "Epoch 1688, Loss: 0.001966901298146695, Final Batch Loss: 0.0010263689327985048\n",
      "Epoch 1689, Loss: 0.010600156616419554, Final Batch Loss: 0.009519010782241821\n",
      "Epoch 1690, Loss: 0.0005247266963124275, Final Batch Loss: 0.0001819557510316372\n",
      "Epoch 1691, Loss: 0.0006115799187682569, Final Batch Loss: 0.00025337879196740687\n",
      "Epoch 1692, Loss: 0.007921419542981312, Final Batch Loss: 7.50817998778075e-05\n",
      "Epoch 1693, Loss: 0.001116359926527366, Final Batch Loss: 0.0008468056912533939\n",
      "Epoch 1694, Loss: 0.0003626550897024572, Final Batch Loss: 0.0002062662097159773\n",
      "Epoch 1695, Loss: 0.0003047961181437131, Final Batch Loss: 4.447067840374075e-05\n",
      "Epoch 1696, Loss: 0.0016458899772260338, Final Batch Loss: 0.0015533703844994307\n",
      "Epoch 1697, Loss: 0.00048547680489718914, Final Batch Loss: 0.00015508531942032278\n",
      "Epoch 1698, Loss: 0.0006747529841959476, Final Batch Loss: 0.0002143800084013492\n",
      "Epoch 1699, Loss: 0.00011923341480724048, Final Batch Loss: 1.9218501620343886e-05\n",
      "Epoch 1700, Loss: 0.0002881419059121981, Final Batch Loss: 0.00012385385343804955\n",
      "Epoch 1701, Loss: 0.0004595696664182469, Final Batch Loss: 0.0003605052479542792\n",
      "Epoch 1702, Loss: 0.00026960147624777164, Final Batch Loss: 2.501946255506482e-05\n",
      "Epoch 1703, Loss: 0.00022007096413290128, Final Batch Loss: 6.241250230232254e-05\n",
      "Epoch 1704, Loss: 0.0003561009652912617, Final Batch Loss: 0.00023368246911559254\n",
      "Epoch 1705, Loss: 0.00026052540488308296, Final Batch Loss: 0.00017054616182576865\n",
      "Epoch 1706, Loss: 0.005445273702207487, Final Batch Loss: 0.00011705245560733601\n",
      "Epoch 1707, Loss: 0.0002190212871937547, Final Batch Loss: 5.073033753433265e-05\n",
      "Epoch 1708, Loss: 0.008177305971912574, Final Batch Loss: 0.008076945319771767\n",
      "Epoch 1709, Loss: 0.00015183013601927087, Final Batch Loss: 4.137458745390177e-05\n",
      "Epoch 1710, Loss: 0.001667308053583838, Final Batch Loss: 0.001492399605922401\n",
      "Epoch 1711, Loss: 0.000364642619388178, Final Batch Loss: 0.00013122624659445137\n",
      "Epoch 1712, Loss: 0.001333948181127198, Final Batch Loss: 0.00111945322714746\n",
      "Epoch 1713, Loss: 0.0006923562468728051, Final Batch Loss: 0.00047122998512350023\n",
      "Epoch 1714, Loss: 0.003542134683812037, Final Batch Loss: 0.00012171678827144206\n",
      "Epoch 1715, Loss: 0.000991949491435662, Final Batch Loss: 9.665332618169487e-05\n",
      "Epoch 1716, Loss: 0.0012395637022564188, Final Batch Loss: 0.0002074522344628349\n",
      "Epoch 1717, Loss: 0.0017040359962265939, Final Batch Loss: 0.000268275587586686\n",
      "Epoch 1718, Loss: 0.0029614743252750486, Final Batch Loss: 0.00035200719139538705\n",
      "Epoch 1719, Loss: 0.00023381574283121154, Final Batch Loss: 4.011310375062749e-05\n",
      "Epoch 1720, Loss: 0.0022106689866632223, Final Batch Loss: 0.00017560971900820732\n",
      "Epoch 1721, Loss: 0.0003009539723279886, Final Batch Loss: 0.00010620880493661389\n",
      "Epoch 1722, Loss: 0.0007307227642741054, Final Batch Loss: 0.0004126378917135298\n",
      "Epoch 1723, Loss: 0.0003550726469256915, Final Batch Loss: 0.00025740990531630814\n",
      "Epoch 1724, Loss: 0.00024383937125094235, Final Batch Loss: 4.0428072679787874e-05\n",
      "Epoch 1725, Loss: 0.0003442662346060388, Final Batch Loss: 0.0002528601617086679\n",
      "Epoch 1726, Loss: 0.0001594053228473058, Final Batch Loss: 3.019966788997408e-05\n",
      "Epoch 1727, Loss: 0.0019287054528831504, Final Batch Loss: 4.964260006090626e-05\n",
      "Epoch 1728, Loss: 0.00044437317046686076, Final Batch Loss: 3.399845081730746e-05\n",
      "Epoch 1729, Loss: 0.0008288424578495324, Final Batch Loss: 0.0005101493443362415\n",
      "Epoch 1730, Loss: 0.00025467274826951325, Final Batch Loss: 0.0001672038488322869\n",
      "Epoch 1731, Loss: 0.0016538252821192145, Final Batch Loss: 0.0007160712266340852\n",
      "Epoch 1732, Loss: 0.00030381606484297663, Final Batch Loss: 0.00013025688531342894\n",
      "Epoch 1733, Loss: 0.0008656715508550406, Final Batch Loss: 0.00023525429423898458\n",
      "Epoch 1734, Loss: 0.00026091543622897007, Final Batch Loss: 4.0548318793298677e-05\n",
      "Epoch 1735, Loss: 0.0028109191625844687, Final Batch Loss: 0.00011632379028014839\n",
      "Epoch 1736, Loss: 0.005562523030675948, Final Batch Loss: 0.0001614365028217435\n",
      "Epoch 1737, Loss: 0.007236720295622945, Final Batch Loss: 0.0024103682953864336\n",
      "Epoch 1738, Loss: 0.0003557329619070515, Final Batch Loss: 0.00025287806056439877\n",
      "Epoch 1739, Loss: 0.0015079978038556874, Final Batch Loss: 0.00013105274410918355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1740, Loss: 0.00019131714725517668, Final Batch Loss: 4.976106356480159e-05\n",
      "Epoch 1741, Loss: 0.0007895384333096445, Final Batch Loss: 0.0005083922878839076\n",
      "Epoch 1742, Loss: 0.0004903839690086897, Final Batch Loss: 5.571514702751301e-05\n",
      "Epoch 1743, Loss: 0.00021386131265899166, Final Batch Loss: 0.00010718171688495204\n",
      "Epoch 1744, Loss: 0.000984804457402788, Final Batch Loss: 0.00018781521066557616\n",
      "Epoch 1745, Loss: 0.0007950598374009132, Final Batch Loss: 0.00033608658122830093\n",
      "Epoch 1746, Loss: 0.00022770988289266825, Final Batch Loss: 8.191930828616023e-05\n",
      "Epoch 1747, Loss: 0.0016225019353441894, Final Batch Loss: 0.00036330142756924033\n",
      "Epoch 1748, Loss: 0.003637856229033787, Final Batch Loss: 7.148215809138492e-05\n",
      "Epoch 1749, Loss: 0.0004078455312992446, Final Batch Loss: 3.807682514889166e-05\n",
      "Epoch 1750, Loss: 0.0004860176850343123, Final Batch Loss: 0.00030544339097104967\n",
      "Epoch 1751, Loss: 0.0005227349611232057, Final Batch Loss: 0.00035515037598088384\n",
      "Epoch 1752, Loss: 0.00043534171709325165, Final Batch Loss: 0.0002655632852111012\n",
      "Epoch 1753, Loss: 0.00044000644993502647, Final Batch Loss: 0.00016049678379204124\n",
      "Epoch 1754, Loss: 0.005194962701352779, Final Batch Loss: 7.987229764694348e-05\n",
      "Epoch 1755, Loss: 0.00028626273342524655, Final Batch Loss: 2.2310985514195636e-05\n",
      "Epoch 1756, Loss: 0.00024387868324993178, Final Batch Loss: 8.220028394134715e-05\n",
      "Epoch 1757, Loss: 0.000751056766603142, Final Batch Loss: 0.00013579032383859158\n",
      "Epoch 1758, Loss: 0.00046479499724227935, Final Batch Loss: 0.00020091213809791952\n",
      "Epoch 1759, Loss: 0.003035454334167298, Final Batch Loss: 0.00010560501686995849\n",
      "Epoch 1760, Loss: 0.0003472498356131837, Final Batch Loss: 0.0001374829444102943\n",
      "Epoch 1761, Loss: 0.0008656961508677341, Final Batch Loss: 0.0008093902724795043\n",
      "Epoch 1762, Loss: 0.00018117971194442362, Final Batch Loss: 9.761979163158685e-05\n",
      "Epoch 1763, Loss: 0.0005592438828898594, Final Batch Loss: 0.00039852692862041295\n",
      "Epoch 1764, Loss: 0.00031058851891430095, Final Batch Loss: 7.676253881072626e-05\n",
      "Epoch 1765, Loss: 0.002017091741436161, Final Batch Loss: 0.0018044173484668136\n",
      "Epoch 1766, Loss: 0.0004135597264394164, Final Batch Loss: 4.238064866513014e-05\n",
      "Epoch 1767, Loss: 0.00399389705125941, Final Batch Loss: 0.00011020508100045845\n",
      "Epoch 1768, Loss: 0.0001580717580509372, Final Batch Loss: 5.934527871431783e-05\n",
      "Epoch 1769, Loss: 0.0010466596577316523, Final Batch Loss: 0.0009224856039509177\n",
      "Epoch 1770, Loss: 0.0002155927213607356, Final Batch Loss: 0.00010452231799717993\n",
      "Epoch 1771, Loss: 0.0017788297991501167, Final Batch Loss: 9.769499592948705e-05\n",
      "Epoch 1772, Loss: 0.004229652644426096, Final Batch Loss: 0.004159209318459034\n",
      "Epoch 1773, Loss: 0.0005351245781639591, Final Batch Loss: 0.0001701277942629531\n",
      "Epoch 1774, Loss: 0.00018689100397750735, Final Batch Loss: 7.089081191224977e-05\n",
      "Epoch 1775, Loss: 0.00029739393357886, Final Batch Loss: 0.00020237565331626683\n",
      "Epoch 1776, Loss: 0.00019562425222829916, Final Batch Loss: 5.478355524246581e-05\n",
      "Epoch 1777, Loss: 0.0007523051608586684, Final Batch Loss: 0.0006152180721983314\n",
      "Epoch 1778, Loss: 0.0006419801065931097, Final Batch Loss: 0.00016864344070199877\n",
      "Epoch 1779, Loss: 0.0005508165340870619, Final Batch Loss: 0.0003103728813584894\n",
      "Epoch 1780, Loss: 0.02225043649377767, Final Batch Loss: 0.00024123328330460936\n",
      "Epoch 1781, Loss: 0.005081131063889188, Final Batch Loss: 1.1823080967587885e-05\n",
      "Epoch 1782, Loss: 0.0009209201816702262, Final Batch Loss: 0.00012312801845837384\n",
      "Epoch 1783, Loss: 0.00012099794548703358, Final Batch Loss: 1.7769853002391756e-05\n",
      "Epoch 1784, Loss: 0.0025031937402673066, Final Batch Loss: 0.0023334447760134935\n",
      "Epoch 1785, Loss: 0.005028463572671171, Final Batch Loss: 7.827826630091295e-05\n",
      "Epoch 1786, Loss: 0.0002016861762967892, Final Batch Loss: 0.00011595083924476057\n",
      "Epoch 1787, Loss: 0.023760467767715454, Final Batch Loss: 0.001697765663266182\n",
      "Epoch 1788, Loss: 0.0009971655963454396, Final Batch Loss: 0.0008200012962333858\n",
      "Epoch 1789, Loss: 0.015404920559376478, Final Batch Loss: 0.011297892779111862\n",
      "Epoch 1790, Loss: 0.00045449876779457554, Final Batch Loss: 0.00010670135816326365\n",
      "Epoch 1791, Loss: 0.007422884984407574, Final Batch Loss: 0.0002536583342589438\n",
      "Epoch 1792, Loss: 0.00023327918825089, Final Batch Loss: 5.581904770224355e-05\n",
      "Epoch 1793, Loss: 0.0012902921152999625, Final Batch Loss: 0.0002400070516159758\n",
      "Epoch 1794, Loss: 0.0004931073563056998, Final Batch Loss: 0.00037715956568717957\n",
      "Epoch 1795, Loss: 0.00011455154344730545, Final Batch Loss: 2.2376256310963072e-05\n",
      "Epoch 1796, Loss: 0.000346878994605504, Final Batch Loss: 0.00018484244355931878\n",
      "Epoch 1797, Loss: 0.0001931919287017081, Final Batch Loss: 5.447633520816453e-05\n",
      "Epoch 1798, Loss: 0.0004282603404135443, Final Batch Loss: 7.728339551249519e-05\n",
      "Epoch 1799, Loss: 0.0002099271023325855, Final Batch Loss: 2.3340786356129684e-05\n",
      "Epoch 1800, Loss: 0.005251763737760484, Final Batch Loss: 0.0014329060213640332\n",
      "Epoch 1801, Loss: 0.00032556008954998106, Final Batch Loss: 7.532631570938975e-05\n",
      "Epoch 1802, Loss: 0.01393187885696534, Final Batch Loss: 0.013784651644527912\n",
      "Epoch 1803, Loss: 0.0003930047096218914, Final Batch Loss: 0.00010598293738439679\n",
      "Epoch 1804, Loss: 0.0013565769768320024, Final Batch Loss: 0.0002632573596201837\n",
      "Epoch 1805, Loss: 0.0004710967987193726, Final Batch Loss: 3.7332552892621607e-05\n",
      "Epoch 1806, Loss: 0.00034058182791341096, Final Batch Loss: 0.0001242530852323398\n",
      "Epoch 1807, Loss: 0.00017179692804347724, Final Batch Loss: 6.70372464810498e-05\n",
      "Epoch 1808, Loss: 0.0018771702016238123, Final Batch Loss: 0.0014624242903664708\n",
      "Epoch 1809, Loss: 0.009575190852046944, Final Batch Loss: 0.00934496521949768\n",
      "Epoch 1810, Loss: 0.007014359973254614, Final Batch Loss: 7.618374365847558e-05\n",
      "Epoch 1811, Loss: 0.0025481280172243714, Final Batch Loss: 0.0020699817687273026\n",
      "Epoch 1812, Loss: 0.0004848184180445969, Final Batch Loss: 0.0002449998282827437\n",
      "Epoch 1813, Loss: 0.00019828846416203305, Final Batch Loss: 9.116412547882646e-05\n",
      "Epoch 1814, Loss: 0.00048627768410369754, Final Batch Loss: 0.00024030019994825125\n",
      "Epoch 1815, Loss: 0.0003288388252258301, Final Batch Loss: 0.00014783120423089713\n",
      "Epoch 1816, Loss: 0.000539173386641778, Final Batch Loss: 0.00036325203836895525\n",
      "Epoch 1817, Loss: 0.0013409400271484628, Final Batch Loss: 0.00022049529070500284\n",
      "Epoch 1818, Loss: 0.001322169351624325, Final Batch Loss: 0.000974280119407922\n",
      "Epoch 1819, Loss: 0.0075704779592342675, Final Batch Loss: 0.0003233894822187722\n",
      "Epoch 1820, Loss: 0.0003501014434732497, Final Batch Loss: 0.00026841755607165396\n",
      "Epoch 1821, Loss: 0.003192656353348866, Final Batch Loss: 0.00025899396860040724\n",
      "Epoch 1822, Loss: 0.0004581311150104739, Final Batch Loss: 8.807649282971397e-05\n",
      "Epoch 1823, Loss: 0.00021905081302975304, Final Batch Loss: 4.9176571337739006e-05\n",
      "Epoch 1824, Loss: 0.0009195629245368764, Final Batch Loss: 0.00015545105270575732\n",
      "Epoch 1825, Loss: 0.00023897221944935154, Final Batch Loss: 2.3960847101989202e-05\n",
      "Epoch 1826, Loss: 0.00032112066401168704, Final Batch Loss: 0.00015275689656846225\n",
      "Epoch 1827, Loss: 0.0013164185511413962, Final Batch Loss: 0.0011178076965734363\n",
      "Epoch 1828, Loss: 0.0007020933553576469, Final Batch Loss: 0.0004002253117505461\n",
      "Epoch 1829, Loss: 0.0012846248864661902, Final Batch Loss: 0.0009770808974280953\n",
      "Epoch 1830, Loss: 0.0011472870683064684, Final Batch Loss: 0.0009384370059706271\n",
      "Epoch 1831, Loss: 0.00017378199845552444, Final Batch Loss: 5.7679259043652564e-05\n",
      "Epoch 1832, Loss: 0.00026444336253916845, Final Batch Loss: 0.00012199646880617365\n",
      "Epoch 1833, Loss: 0.006111053691711277, Final Batch Loss: 0.00012580532347783446\n",
      "Epoch 1834, Loss: 0.0005809104914078489, Final Batch Loss: 0.00034216264612041414\n",
      "Epoch 1835, Loss: 0.00017033892800100148, Final Batch Loss: 5.340192001312971e-05\n",
      "Epoch 1836, Loss: 0.002850000746548176, Final Batch Loss: 0.0002458298113197088\n",
      "Epoch 1837, Loss: 0.00037300218900782056, Final Batch Loss: 4.700899080489762e-05\n",
      "Epoch 1838, Loss: 0.0014042391849216074, Final Batch Loss: 0.0011311512207612395\n",
      "Epoch 1839, Loss: 0.010081327389343642, Final Batch Loss: 0.009869428351521492\n",
      "Epoch 1840, Loss: 0.000710960135620553, Final Batch Loss: 0.00010429893882246688\n",
      "Epoch 1841, Loss: 0.0011545178131200373, Final Batch Loss: 0.000278754741884768\n",
      "Epoch 1842, Loss: 0.00037508149398490787, Final Batch Loss: 0.00015949123189784586\n",
      "Epoch 1843, Loss: 0.0002505989068595227, Final Batch Loss: 0.00019956303003709763\n",
      "Epoch 1844, Loss: 0.004059389757458121, Final Batch Loss: 0.00038169935578480363\n",
      "Epoch 1845, Loss: 0.0007228264439618215, Final Batch Loss: 0.0006679565412923694\n",
      "Epoch 1846, Loss: 0.0006632265285588801, Final Batch Loss: 0.00044213730143383145\n",
      "Epoch 1847, Loss: 0.0001648532779654488, Final Batch Loss: 1.7106111044995487e-05\n",
      "Epoch 1848, Loss: 0.0006913270481163636, Final Batch Loss: 0.0005265197833068669\n",
      "Epoch 1849, Loss: 0.00036859292595181614, Final Batch Loss: 0.00020704971393570304\n",
      "Epoch 1850, Loss: 0.003051808016607538, Final Batch Loss: 0.0025663254782557487\n",
      "Epoch 1851, Loss: 0.0008497439412167296, Final Batch Loss: 0.000665297731757164\n",
      "Epoch 1852, Loss: 0.0004929191272822209, Final Batch Loss: 7.357862341450527e-05\n",
      "Epoch 1853, Loss: 0.0002850158343790099, Final Batch Loss: 0.00015817806706763804\n",
      "Epoch 1854, Loss: 0.000474798318464309, Final Batch Loss: 0.00012966032954864204\n",
      "Epoch 1855, Loss: 0.00038452726585092023, Final Batch Loss: 7.554968033218756e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1856, Loss: 0.0005334719899110496, Final Batch Loss: 0.00025344951427541673\n",
      "Epoch 1857, Loss: 0.0003717386643984355, Final Batch Loss: 0.0002566926123108715\n",
      "Epoch 1858, Loss: 0.00047743938921485096, Final Batch Loss: 0.00034699682146310806\n",
      "Epoch 1859, Loss: 0.0031728324247524142, Final Batch Loss: 0.0008063166169449687\n",
      "Epoch 1860, Loss: 0.005421452224254608, Final Batch Loss: 0.00512792868539691\n",
      "Epoch 1861, Loss: 0.0006727214204147458, Final Batch Loss: 6.565876537933946e-05\n",
      "Epoch 1862, Loss: 0.0001649549012654461, Final Batch Loss: 7.544429536210373e-05\n",
      "Epoch 1863, Loss: 0.000703882920788601, Final Batch Loss: 0.0006036630365997553\n",
      "Epoch 1864, Loss: 0.00036691206878458615, Final Batch Loss: 1.5577466911054216e-05\n",
      "Epoch 1865, Loss: 0.0003923953481717035, Final Batch Loss: 0.00032623831066302955\n",
      "Epoch 1866, Loss: 0.00021307514543877915, Final Batch Loss: 8.413701289100572e-05\n",
      "Epoch 1867, Loss: 0.00032999601535266265, Final Batch Loss: 3.273289621574804e-05\n",
      "Epoch 1868, Loss: 0.00029400004859780893, Final Batch Loss: 0.00010391452087787911\n",
      "Epoch 1869, Loss: 0.005623426375677809, Final Batch Loss: 0.0003704233968164772\n",
      "Epoch 1870, Loss: 0.010792711516842246, Final Batch Loss: 0.000189594691619277\n",
      "Epoch 1871, Loss: 0.0002738608163781464, Final Batch Loss: 6.648828275501728e-05\n",
      "Epoch 1872, Loss: 0.000579707557335496, Final Batch Loss: 0.0002451180189382285\n",
      "Epoch 1873, Loss: 0.00028441935137379915, Final Batch Loss: 0.00017307509551756084\n",
      "Epoch 1874, Loss: 0.0021509871148737147, Final Batch Loss: 0.0001497551129432395\n",
      "Epoch 1875, Loss: 0.002278896630741656, Final Batch Loss: 0.0018671201542019844\n",
      "Epoch 1876, Loss: 0.000249943970629829, Final Batch Loss: 2.908815622504335e-05\n",
      "Epoch 1877, Loss: 0.0006155109876999632, Final Batch Loss: 0.0001628301542950794\n",
      "Epoch 1878, Loss: 0.0008272070408565924, Final Batch Loss: 0.0006632157019339502\n",
      "Epoch 1879, Loss: 0.0004742352175526321, Final Batch Loss: 0.00034668846637941897\n",
      "Epoch 1880, Loss: 0.0002655077478266321, Final Batch Loss: 3.3625961805228144e-05\n",
      "Epoch 1881, Loss: 0.00013803498950437643, Final Batch Loss: 7.912320143077523e-05\n",
      "Epoch 1882, Loss: 0.00034796863292285707, Final Batch Loss: 2.4101411327137612e-05\n",
      "Epoch 1883, Loss: 0.0029511600369005464, Final Batch Loss: 2.8077942261006683e-05\n",
      "Epoch 1884, Loss: 0.0035141895968990866, Final Batch Loss: 3.262082827859558e-05\n",
      "Epoch 1885, Loss: 0.0003340689290780574, Final Batch Loss: 0.00013986525300424546\n",
      "Epoch 1886, Loss: 0.0014285203869803809, Final Batch Loss: 9.142580529442057e-05\n",
      "Epoch 1887, Loss: 0.001640036702156067, Final Batch Loss: 0.0010706416796892881\n",
      "Epoch 1888, Loss: 0.00014264381024986506, Final Batch Loss: 1.842677011154592e-05\n",
      "Epoch 1889, Loss: 0.0002670263929758221, Final Batch Loss: 0.0001521191734354943\n",
      "Epoch 1890, Loss: 0.00026090311439475045, Final Batch Loss: 9.302028774982318e-05\n",
      "Epoch 1891, Loss: 0.0007209883333416656, Final Batch Loss: 0.000535608793143183\n",
      "Epoch 1892, Loss: 0.004464785277377814, Final Batch Loss: 0.00022977887419983745\n",
      "Epoch 1893, Loss: 0.0015422926226165146, Final Batch Loss: 0.0012509681982919574\n",
      "Epoch 1894, Loss: 0.0003056392743019387, Final Batch Loss: 6.715919880662113e-05\n",
      "Epoch 1895, Loss: 0.00021032694348832592, Final Batch Loss: 0.00012296343629714102\n",
      "Epoch 1896, Loss: 0.0002986538893310353, Final Batch Loss: 0.00013784274051431566\n",
      "Epoch 1897, Loss: 0.0015470609578187577, Final Batch Loss: 0.0014358091866597533\n",
      "Epoch 1898, Loss: 0.000362009544915054, Final Batch Loss: 2.145776670658961e-05\n",
      "Epoch 1899, Loss: 0.0002413377515040338, Final Batch Loss: 7.496378384530544e-05\n",
      "Epoch 1900, Loss: 0.002155738096917048, Final Batch Loss: 9.282855899073184e-05\n",
      "Epoch 1901, Loss: 0.005758426559623331, Final Batch Loss: 0.00025714602088555694\n",
      "Epoch 1902, Loss: 0.0006392085633706301, Final Batch Loss: 0.00037885818164795637\n",
      "Epoch 1903, Loss: 0.00020811349531868473, Final Batch Loss: 8.711029659025371e-05\n",
      "Epoch 1904, Loss: 0.0003313864872325212, Final Batch Loss: 0.00017872123862616718\n",
      "Epoch 1905, Loss: 0.0015552185068372637, Final Batch Loss: 0.0012314318446442485\n",
      "Epoch 1906, Loss: 0.004259274137439206, Final Batch Loss: 0.00029327141237445176\n",
      "Epoch 1907, Loss: 0.00017962120091397082, Final Batch Loss: 1.0804519661178347e-05\n",
      "Epoch 1908, Loss: 0.0036729691382788587, Final Batch Loss: 3.6013854696648195e-05\n",
      "Epoch 1909, Loss: 0.00018946847558254376, Final Batch Loss: 0.0001276830880669877\n",
      "Epoch 1910, Loss: 0.000516996148689941, Final Batch Loss: 1.3630092325911392e-05\n",
      "Epoch 1911, Loss: 0.00020459866937017068, Final Batch Loss: 5.109204357722774e-05\n",
      "Epoch 1912, Loss: 0.0001940946413014899, Final Batch Loss: 8.5464153016801e-06\n",
      "Epoch 1913, Loss: 0.0005186575872357935, Final Batch Loss: 0.00039068993646651506\n",
      "Epoch 1914, Loss: 0.00024881389072106685, Final Batch Loss: 1.3592629329650663e-05\n",
      "Epoch 1915, Loss: 0.00030977810547483386, Final Batch Loss: 1.3214496902946848e-05\n",
      "Epoch 1916, Loss: 0.018632864361279644, Final Batch Loss: 0.0002397315256530419\n",
      "Epoch 1917, Loss: 0.0008128384615702089, Final Batch Loss: 4.3265779822831973e-05\n",
      "Epoch 1918, Loss: 0.00022656458895653486, Final Batch Loss: 9.093816333916038e-05\n",
      "Epoch 1919, Loss: 0.00022083939256845042, Final Batch Loss: 0.00011612466914812103\n",
      "Epoch 1920, Loss: 0.0001910500977828633, Final Batch Loss: 0.00015426540630869567\n",
      "Epoch 1921, Loss: 0.009570590686053038, Final Batch Loss: 0.009004208259284496\n",
      "Epoch 1922, Loss: 0.0002171646847273223, Final Batch Loss: 0.00010143078543478623\n",
      "Epoch 1923, Loss: 0.0004771124804392457, Final Batch Loss: 0.00022792851086705923\n",
      "Epoch 1924, Loss: 0.003809778834693134, Final Batch Loss: 0.0007956906920298934\n",
      "Epoch 1925, Loss: 0.0006303429836407304, Final Batch Loss: 0.0005481262342073023\n",
      "Epoch 1926, Loss: 0.0004287619813112542, Final Batch Loss: 0.00013313711679074913\n",
      "Epoch 1927, Loss: 0.0002607205060485285, Final Batch Loss: 0.00021062532323412597\n",
      "Epoch 1928, Loss: 0.0006163810758152977, Final Batch Loss: 9.764354035723954e-05\n",
      "Epoch 1929, Loss: 0.0002484713004378136, Final Batch Loss: 3.2406092941528186e-05\n",
      "Epoch 1930, Loss: 0.002627545844006818, Final Batch Loss: 0.0025569687131792307\n",
      "Epoch 1931, Loss: 0.00034740735281957313, Final Batch Loss: 0.0002680668549146503\n",
      "Epoch 1932, Loss: 0.0005771600117441267, Final Batch Loss: 0.0004454987938515842\n",
      "Epoch 1933, Loss: 0.00019392203830648214, Final Batch Loss: 0.00014541600830852985\n",
      "Epoch 1934, Loss: 0.00026120075926883146, Final Batch Loss: 6.908557406859472e-05\n",
      "Epoch 1935, Loss: 0.0007099059585016221, Final Batch Loss: 0.00010420280159451067\n",
      "Epoch 1936, Loss: 0.0006322828012343962, Final Batch Loss: 4.6422403102042153e-05\n",
      "Epoch 1937, Loss: 0.0003155813319608569, Final Batch Loss: 3.539287718012929e-05\n",
      "Epoch 1938, Loss: 0.0012563205091282725, Final Batch Loss: 0.0008732666610740125\n",
      "Epoch 1939, Loss: 7.455885497620329e-05, Final Batch Loss: 3.664410178316757e-05\n",
      "Epoch 1940, Loss: 0.006270355617743917, Final Batch Loss: 0.006140338722616434\n",
      "Epoch 1941, Loss: 0.0004923547094222158, Final Batch Loss: 0.00013936104369349778\n",
      "Epoch 1942, Loss: 0.0005135622923262417, Final Batch Loss: 0.000190606719115749\n",
      "Epoch 1943, Loss: 0.000699140306096524, Final Batch Loss: 0.0005139344139024615\n",
      "Epoch 1944, Loss: 0.0005000757046218496, Final Batch Loss: 5.793118543806486e-05\n",
      "Epoch 1945, Loss: 0.00020124974253121763, Final Batch Loss: 0.0001292233500862494\n",
      "Epoch 1946, Loss: 0.0004043991648359224, Final Batch Loss: 0.00022443833586294204\n",
      "Epoch 1947, Loss: 0.00022838032236904837, Final Batch Loss: 4.810684549738653e-05\n",
      "Epoch 1948, Loss: 0.00020670184312621132, Final Batch Loss: 6.133362330729142e-05\n",
      "Epoch 1949, Loss: 0.0002990867797052488, Final Batch Loss: 0.0001616969530005008\n",
      "Epoch 1950, Loss: 0.0007034854188532336, Final Batch Loss: 2.6552208510111086e-05\n",
      "Epoch 1951, Loss: 0.00022065098892198876, Final Batch Loss: 0.0001292069355258718\n",
      "Epoch 1952, Loss: 0.00019295381935080513, Final Batch Loss: 7.935915346024558e-05\n",
      "Epoch 1953, Loss: 0.00028759763517882675, Final Batch Loss: 0.0001381641923217103\n",
      "Epoch 1954, Loss: 0.0004630217590602115, Final Batch Loss: 0.00028467015363276005\n",
      "Epoch 1955, Loss: 0.0009792799246497452, Final Batch Loss: 0.00010966311674565077\n",
      "Epoch 1956, Loss: 0.00027530951047083363, Final Batch Loss: 0.00017068744637072086\n",
      "Epoch 1957, Loss: 0.0006545586220454425, Final Batch Loss: 0.00021307391580194235\n",
      "Epoch 1958, Loss: 0.00030693823646288365, Final Batch Loss: 0.00011154968524351716\n",
      "Epoch 1959, Loss: 0.0004314721591072157, Final Batch Loss: 9.215391764882952e-05\n",
      "Epoch 1960, Loss: 0.000789737532613799, Final Batch Loss: 0.00026600543060339987\n",
      "Epoch 1961, Loss: 0.0022690083424095064, Final Batch Loss: 0.0022289028856903315\n",
      "Epoch 1962, Loss: 0.0057727537605387624, Final Batch Loss: 3.7789021007483825e-05\n",
      "Epoch 1963, Loss: 0.00031448672234546393, Final Batch Loss: 0.00013063696678727865\n",
      "Epoch 1964, Loss: 0.00038508695433847606, Final Batch Loss: 9.513768600299954e-05\n",
      "Epoch 1965, Loss: 0.00023751061235088855, Final Batch Loss: 0.00013629856402985752\n",
      "Epoch 1966, Loss: 0.0038051193332648836, Final Batch Loss: 5.180530570214614e-05\n",
      "Epoch 1967, Loss: 0.0029365179580054246, Final Batch Loss: 8.043055277084932e-05\n",
      "Epoch 1968, Loss: 0.0011312117130728438, Final Batch Loss: 0.00015559741586912423\n",
      "Epoch 1969, Loss: 0.00017448695143684745, Final Batch Loss: 7.303186430362985e-05\n",
      "Epoch 1970, Loss: 0.0002604101609904319, Final Batch Loss: 0.00018866709433495998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1971, Loss: 0.00016431398398708552, Final Batch Loss: 7.780946179991588e-05\n",
      "Epoch 1972, Loss: 0.004858157699345611, Final Batch Loss: 0.00015262850502040237\n",
      "Epoch 1973, Loss: 0.0034057496777677443, Final Batch Loss: 2.704711732803844e-05\n",
      "Epoch 1974, Loss: 0.00025853211991488934, Final Batch Loss: 0.00016805030463729054\n",
      "Epoch 1975, Loss: 0.0033071741854655556, Final Batch Loss: 0.003217320656403899\n",
      "Epoch 1976, Loss: 0.00045320572098717093, Final Batch Loss: 0.0003864805039484054\n",
      "Epoch 1977, Loss: 0.0002734292938839644, Final Batch Loss: 9.327747102361172e-05\n",
      "Epoch 1978, Loss: 0.00023869429787737317, Final Batch Loss: 4.6073200792307034e-05\n",
      "Epoch 1979, Loss: 0.0003246186097385362, Final Batch Loss: 0.0001249523920705542\n",
      "Epoch 1980, Loss: 0.00047339439333882183, Final Batch Loss: 2.783529635053128e-05\n",
      "Epoch 1981, Loss: 0.00022132758022053167, Final Batch Loss: 6.774362555006519e-05\n",
      "Epoch 1982, Loss: 0.00022359025751939043, Final Batch Loss: 0.00010814076813403517\n",
      "Epoch 1983, Loss: 0.00014438156176765915, Final Batch Loss: 2.4709470380912535e-05\n",
      "Epoch 1984, Loss: 0.00033744909160304815, Final Batch Loss: 0.00015449854254256934\n",
      "Epoch 1985, Loss: 0.009120200644247234, Final Batch Loss: 0.008947387337684631\n",
      "Epoch 1986, Loss: 0.0005068316531833261, Final Batch Loss: 0.00029843408265151083\n",
      "Epoch 1987, Loss: 0.00015854619414312765, Final Batch Loss: 7.458523032255471e-05\n",
      "Epoch 1988, Loss: 0.000150506693898933, Final Batch Loss: 4.849114702665247e-05\n",
      "Epoch 1989, Loss: 0.004789524104126031, Final Batch Loss: 0.0047322483733296394\n",
      "Epoch 1990, Loss: 0.00017987375031225383, Final Batch Loss: 7.704919698880985e-05\n",
      "Epoch 1991, Loss: 0.009410751983523369, Final Batch Loss: 0.0005572540685534477\n",
      "Epoch 1992, Loss: 8.29739001346752e-05, Final Batch Loss: 4.543516843114048e-05\n",
      "Epoch 1993, Loss: 0.00014916565851308405, Final Batch Loss: 4.064194217789918e-05\n",
      "Epoch 1994, Loss: 0.0005398528883233666, Final Batch Loss: 0.00023140542907640338\n",
      "Epoch 1995, Loss: 0.0004621885600499809, Final Batch Loss: 0.0001238797849509865\n",
      "Epoch 1996, Loss: 0.0006144256331026554, Final Batch Loss: 0.00031238977680914104\n",
      "Epoch 1997, Loss: 0.0006665133696515113, Final Batch Loss: 0.00031604390824213624\n",
      "Epoch 1998, Loss: 0.0008306924064527266, Final Batch Loss: 4.4070060539525e-05\n",
      "Epoch 1999, Loss: 0.03137737017823383, Final Batch Loss: 0.03095052018761635\n",
      "Epoch 2000, Loss: 0.00015542240726063028, Final Batch Loss: 8.217561116907746e-05\n",
      "Epoch 2001, Loss: 0.0003262962636654265, Final Batch Loss: 0.00021093979012221098\n",
      "Epoch 2002, Loss: 0.0005086715100333095, Final Batch Loss: 0.00010092527372762561\n",
      "Epoch 2003, Loss: 0.044044378329999745, Final Batch Loss: 5.8489968068897724e-05\n",
      "Epoch 2004, Loss: 0.0007413646962959319, Final Batch Loss: 0.00047994585474953055\n",
      "Epoch 2005, Loss: 0.0008198379182431381, Final Batch Loss: 3.2401479984400794e-05\n",
      "Epoch 2006, Loss: 0.00021533198378165253, Final Batch Loss: 0.0001765340712154284\n",
      "Epoch 2007, Loss: 0.00028770936478395015, Final Batch Loss: 0.00017742611817084253\n",
      "Epoch 2008, Loss: 0.007161631932831369, Final Batch Loss: 0.00013515747559722513\n",
      "Epoch 2009, Loss: 0.0005969293415546417, Final Batch Loss: 0.00019022711785510182\n",
      "Epoch 2010, Loss: 0.003840877820039168, Final Batch Loss: 0.00022274479852057993\n",
      "Epoch 2011, Loss: 0.0005350940191419795, Final Batch Loss: 0.0002030728937825188\n",
      "Epoch 2012, Loss: 0.00041250215872423723, Final Batch Loss: 0.0003376783279236406\n",
      "Epoch 2013, Loss: 0.0009451046571484767, Final Batch Loss: 0.0008426194544881582\n",
      "Epoch 2014, Loss: 0.061191498272819445, Final Batch Loss: 0.06109968200325966\n",
      "Epoch 2015, Loss: 0.00043819994607474655, Final Batch Loss: 0.00035105040296912193\n",
      "Epoch 2016, Loss: 0.0008800690156931523, Final Batch Loss: 0.0008285832009278238\n",
      "Epoch 2017, Loss: 0.004588506126310676, Final Batch Loss: 0.00013865105574950576\n",
      "Epoch 2018, Loss: 0.0014544343066518195, Final Batch Loss: 6.547844532178715e-05\n",
      "Epoch 2019, Loss: 0.00911971105961129, Final Batch Loss: 0.008935347199440002\n",
      "Epoch 2020, Loss: 0.0005731697019655257, Final Batch Loss: 0.00014071044279262424\n",
      "Epoch 2021, Loss: 0.004683233019022737, Final Batch Loss: 9.925678750732914e-05\n",
      "Epoch 2022, Loss: 0.0007351488311542198, Final Batch Loss: 0.00018782079860102385\n",
      "Epoch 2023, Loss: 0.00022605985577683896, Final Batch Loss: 6.219297938514501e-05\n",
      "Epoch 2024, Loss: 0.0011514013312989846, Final Batch Loss: 0.00013169566227588803\n",
      "Epoch 2025, Loss: 0.00021759844821644947, Final Batch Loss: 0.0001073302046279423\n",
      "Epoch 2026, Loss: 0.0007003004429861903, Final Batch Loss: 0.00039495984674431384\n",
      "Epoch 2027, Loss: 0.0004257040563970804, Final Batch Loss: 0.0003079125308431685\n",
      "Epoch 2028, Loss: 0.0002801220107357949, Final Batch Loss: 0.0001779851590981707\n",
      "Epoch 2029, Loss: 0.0006271334423217922, Final Batch Loss: 0.0004850827681366354\n",
      "Epoch 2030, Loss: 0.00025835067935986444, Final Batch Loss: 0.0001746848865877837\n",
      "Epoch 2031, Loss: 0.0008549510966986418, Final Batch Loss: 0.0004679699777625501\n",
      "Epoch 2032, Loss: 0.00075572966306936, Final Batch Loss: 0.00019068153051193804\n",
      "Epoch 2033, Loss: 0.0037704758506151848, Final Batch Loss: 8.55264879646711e-05\n",
      "Epoch 2034, Loss: 0.0013750130019616336, Final Batch Loss: 0.00015969292144291103\n",
      "Epoch 2035, Loss: 0.00040857440035324544, Final Batch Loss: 0.00028574097086675465\n",
      "Epoch 2036, Loss: 0.0008795827307039872, Final Batch Loss: 0.0007739530992694199\n",
      "Epoch 2037, Loss: 0.0004700517310993746, Final Batch Loss: 9.710517770145088e-05\n",
      "Epoch 2038, Loss: 0.015877148674917407, Final Batch Loss: 0.015691982582211494\n",
      "Epoch 2039, Loss: 0.013944129721494392, Final Batch Loss: 0.01347100269049406\n",
      "Epoch 2040, Loss: 0.00031274368484446313, Final Batch Loss: 1.6034819054766558e-05\n",
      "Epoch 2041, Loss: 0.004582659341394901, Final Batch Loss: 0.00042630452662706375\n",
      "Epoch 2042, Loss: 0.0004184114804957062, Final Batch Loss: 0.00028233794728294015\n",
      "Epoch 2043, Loss: 0.00020287690858822316, Final Batch Loss: 6.095200660638511e-05\n",
      "Epoch 2044, Loss: 0.002465737226884812, Final Batch Loss: 0.0016341300215572119\n",
      "Epoch 2045, Loss: 0.0018463140731910244, Final Batch Loss: 0.00018260908836964518\n",
      "Epoch 2046, Loss: 0.0003289063461124897, Final Batch Loss: 0.00016551384760532528\n",
      "Epoch 2047, Loss: 0.0067798844538629055, Final Batch Loss: 0.00034762267023324966\n",
      "Epoch 2048, Loss: 0.0027760332959587686, Final Batch Loss: 0.0026907692663371563\n",
      "Epoch 2049, Loss: 0.0003933815096388571, Final Batch Loss: 0.00010755410039564595\n",
      "Epoch 2050, Loss: 0.0003032617169083096, Final Batch Loss: 0.00023122951097320765\n",
      "Epoch 2051, Loss: 0.0003053924592677504, Final Batch Loss: 0.00010255241068080068\n",
      "Epoch 2052, Loss: 0.033476823577075265, Final Batch Loss: 0.033347126096487045\n",
      "Epoch 2053, Loss: 0.0018678473716136068, Final Batch Loss: 0.0017163666198030114\n",
      "Epoch 2054, Loss: 0.0002920673941844143, Final Batch Loss: 0.00011002719838870689\n",
      "Epoch 2055, Loss: 0.0007491843716707081, Final Batch Loss: 0.0004938720376230776\n",
      "Epoch 2056, Loss: 0.0001967121697816765, Final Batch Loss: 2.997734372911509e-05\n",
      "Epoch 2057, Loss: 0.00032739755988586694, Final Batch Loss: 0.00029082890250720084\n",
      "Epoch 2058, Loss: 0.0008368650451302528, Final Batch Loss: 0.0005435027997009456\n",
      "Epoch 2059, Loss: 0.00011091255873907357, Final Batch Loss: 6.55884068692103e-05\n",
      "Epoch 2060, Loss: 0.0005372028826968744, Final Batch Loss: 0.00038118005613796413\n",
      "Epoch 2061, Loss: 0.0003591041313484311, Final Batch Loss: 0.0001684592862147838\n",
      "Epoch 2062, Loss: 0.00020348162433947437, Final Batch Loss: 0.00017160488641820848\n",
      "Epoch 2063, Loss: 0.14551106746512232, Final Batch Loss: 0.1453908085823059\n",
      "Epoch 2064, Loss: 0.00024030575150391087, Final Batch Loss: 0.00012225002865307033\n",
      "Epoch 2065, Loss: 0.0004073685558978468, Final Batch Loss: 0.00018221206846646965\n",
      "Epoch 2066, Loss: 0.0009778123639989644, Final Batch Loss: 0.0006585001829080284\n",
      "Epoch 2067, Loss: 0.0004469040868571028, Final Batch Loss: 0.00021723189274780452\n",
      "Epoch 2068, Loss: 0.0377675243653357, Final Batch Loss: 0.03726918622851372\n",
      "Epoch 2069, Loss: 0.00024437078536720946, Final Batch Loss: 0.0001365554053336382\n",
      "Epoch 2070, Loss: 0.002702364115975797, Final Batch Loss: 0.0002294272417202592\n",
      "Epoch 2071, Loss: 0.05093075076001696, Final Batch Loss: 0.05069294571876526\n",
      "Epoch 2072, Loss: 0.002288928662892431, Final Batch Loss: 0.0005163285532034934\n",
      "Epoch 2073, Loss: 0.0005263494167593308, Final Batch Loss: 0.00011673820699797943\n",
      "Epoch 2074, Loss: 0.0357562612334732, Final Batch Loss: 0.035467736423015594\n",
      "Epoch 2075, Loss: 0.0030602406477555633, Final Batch Loss: 0.002438640920445323\n",
      "Epoch 2076, Loss: 0.0014209014480002224, Final Batch Loss: 0.0008901331457309425\n",
      "Epoch 2077, Loss: 0.0030624360297224484, Final Batch Loss: 7.5432843004819e-05\n",
      "Epoch 2078, Loss: 0.0005945126904407516, Final Batch Loss: 0.000351810798747465\n",
      "Epoch 2079, Loss: 0.0030370999593287706, Final Batch Loss: 0.002253594109788537\n",
      "Epoch 2080, Loss: 0.0009206738322973251, Final Batch Loss: 0.0002743962104432285\n",
      "Epoch 2081, Loss: 0.0008755414164625108, Final Batch Loss: 0.0004503726668190211\n",
      "Epoch 2082, Loss: 0.0006320450338535011, Final Batch Loss: 0.000152371620060876\n",
      "Epoch 2083, Loss: 0.001305430821957998, Final Batch Loss: 0.00020972049969714135\n",
      "Epoch 2084, Loss: 0.0021710872533731163, Final Batch Loss: 0.0003833982045762241\n",
      "Epoch 2085, Loss: 0.0009980386312236078, Final Batch Loss: 0.0009168270044028759\n",
      "Epoch 2086, Loss: 0.014287419151514769, Final Batch Loss: 0.007631402928382158\n",
      "Epoch 2087, Loss: 0.0004306891351006925, Final Batch Loss: 0.00017529813339933753\n",
      "Epoch 2088, Loss: 0.0010605095158098266, Final Batch Loss: 0.0008996892720460892\n",
      "Epoch 2089, Loss: 0.007835602416889742, Final Batch Loss: 0.0074842143803834915\n",
      "Epoch 2090, Loss: 0.0012471004738472402, Final Batch Loss: 0.000753440021071583\n",
      "Epoch 2091, Loss: 0.0011528101022122428, Final Batch Loss: 0.0009679896174930036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2092, Loss: 0.006367576701450162, Final Batch Loss: 0.0062201907858252525\n",
      "Epoch 2093, Loss: 0.0011312171118333936, Final Batch Loss: 0.0005807791603729129\n",
      "Epoch 2094, Loss: 0.0011055778595618904, Final Batch Loss: 0.00047716882545500994\n",
      "Epoch 2095, Loss: 0.0007122489259927534, Final Batch Loss: 8.866117423167452e-05\n",
      "Epoch 2096, Loss: 0.001473230920964852, Final Batch Loss: 0.0010040306951850653\n",
      "Epoch 2097, Loss: 0.0010607998119667172, Final Batch Loss: 0.0006320144748315215\n",
      "Epoch 2098, Loss: 0.003294985683169216, Final Batch Loss: 0.002499739872291684\n",
      "Epoch 2099, Loss: 0.01492083736229688, Final Batch Loss: 0.013811344280838966\n",
      "Epoch 2100, Loss: 0.0004028829571325332, Final Batch Loss: 0.00013790128286927938\n",
      "Epoch 2101, Loss: 0.0009524911001790315, Final Batch Loss: 0.0005668919766321778\n",
      "Epoch 2102, Loss: 0.009882066980935633, Final Batch Loss: 0.009170261211693287\n",
      "Epoch 2103, Loss: 0.0015399953990709037, Final Batch Loss: 0.0011538856197148561\n",
      "Epoch 2104, Loss: 0.0006076535646570846, Final Batch Loss: 0.00044520446681417525\n",
      "Epoch 2105, Loss: 0.002216060151113197, Final Batch Loss: 0.00019528550910763443\n",
      "Epoch 2106, Loss: 0.0006066328060114756, Final Batch Loss: 0.00017829365970101207\n",
      "Epoch 2107, Loss: 0.0007374775468633743, Final Batch Loss: 2.347112058487255e-05\n",
      "Epoch 2108, Loss: 0.0006730823806719854, Final Batch Loss: 0.0001687425101408735\n",
      "Epoch 2109, Loss: 0.0003413507074583322, Final Batch Loss: 0.00020510809554252774\n",
      "Epoch 2110, Loss: 0.0034015189885394648, Final Batch Loss: 0.00021296316117513925\n",
      "Epoch 2111, Loss: 0.0002914227661676705, Final Batch Loss: 0.00012780807446688414\n",
      "Epoch 2112, Loss: 0.001013767730910331, Final Batch Loss: 0.0005868342122994363\n",
      "Epoch 2113, Loss: 0.0008846880227793008, Final Batch Loss: 0.0005742083885706961\n",
      "Epoch 2114, Loss: 0.0007422733469866216, Final Batch Loss: 0.00023226439952850342\n",
      "Epoch 2115, Loss: 0.004088603003765456, Final Batch Loss: 0.0002068097674055025\n",
      "Epoch 2116, Loss: 0.0003517092627589591, Final Batch Loss: 9.535442950436845e-05\n",
      "Epoch 2117, Loss: 0.005984642572002485, Final Batch Loss: 0.00046129527618177235\n",
      "Epoch 2118, Loss: 0.0009459915454499424, Final Batch Loss: 0.0006863159942440689\n",
      "Epoch 2119, Loss: 0.00850645520404214, Final Batch Loss: 0.008423498831689358\n",
      "Epoch 2120, Loss: 0.00028670836763922125, Final Batch Loss: 0.00016104440146591514\n",
      "Epoch 2121, Loss: 0.0004420209879754111, Final Batch Loss: 0.00015510151570197195\n",
      "Epoch 2122, Loss: 0.00029656697006430477, Final Batch Loss: 8.392776362597942e-05\n",
      "Epoch 2123, Loss: 0.0012454528477974236, Final Batch Loss: 0.0009728764998726547\n",
      "Epoch 2124, Loss: 0.00046524904610123485, Final Batch Loss: 0.00022931420244276524\n",
      "Epoch 2125, Loss: 0.0029354108264669776, Final Batch Loss: 0.0002809740835800767\n",
      "Epoch 2126, Loss: 0.0008671766554471105, Final Batch Loss: 0.0002563477319199592\n",
      "Epoch 2127, Loss: 0.008442670514341444, Final Batch Loss: 0.008165854029357433\n",
      "Epoch 2128, Loss: 0.0011474208440631628, Final Batch Loss: 0.00014174729585647583\n",
      "Epoch 2129, Loss: 0.004327109607402235, Final Batch Loss: 0.00041440321365371346\n",
      "Epoch 2130, Loss: 0.0005841417005285621, Final Batch Loss: 0.0003771662595681846\n",
      "Epoch 2131, Loss: 0.0003077493020100519, Final Batch Loss: 7.591825851704925e-05\n",
      "Epoch 2132, Loss: 0.0007524567772634327, Final Batch Loss: 0.0002728308318182826\n",
      "Epoch 2133, Loss: 0.00741674692108063, Final Batch Loss: 0.007311168126761913\n",
      "Epoch 2134, Loss: 0.0005141883375472389, Final Batch Loss: 8.923056157073006e-05\n",
      "Epoch 2135, Loss: 0.0003781402629101649, Final Batch Loss: 0.00019976907060481608\n",
      "Epoch 2136, Loss: 0.00016461113773402758, Final Batch Loss: 4.813835766981356e-05\n",
      "Epoch 2137, Loss: 0.000527773896465078, Final Batch Loss: 0.00039611192187294364\n",
      "Epoch 2138, Loss: 0.0003106181538896635, Final Batch Loss: 0.00021854820079170167\n",
      "Epoch 2139, Loss: 0.0005054096836829558, Final Batch Loss: 0.00015257800987455994\n",
      "Epoch 2140, Loss: 0.0003558545431587845, Final Batch Loss: 0.00017277264851145446\n",
      "Epoch 2141, Loss: 0.0003889355866704136, Final Batch Loss: 0.0002237850712845102\n",
      "Epoch 2142, Loss: 0.00337823893642053, Final Batch Loss: 0.00045283226063475013\n",
      "Epoch 2143, Loss: 0.0009328659652965143, Final Batch Loss: 0.00018798130622599274\n",
      "Epoch 2144, Loss: 0.0006590063858311623, Final Batch Loss: 0.0002873092598747462\n",
      "Epoch 2145, Loss: 0.0005308336913003586, Final Batch Loss: 7.87381359259598e-05\n",
      "Epoch 2146, Loss: 0.00034690858592512086, Final Batch Loss: 9.150751429842785e-05\n",
      "Epoch 2147, Loss: 0.0003685581250465475, Final Batch Loss: 8.201933087548241e-05\n",
      "Epoch 2148, Loss: 0.0012385651680233423, Final Batch Loss: 5.585045801126398e-05\n",
      "Epoch 2149, Loss: 0.00038447613769676536, Final Batch Loss: 0.00022910349071025848\n",
      "Epoch 2150, Loss: 0.0005122924703755416, Final Batch Loss: 0.00011533953511388972\n",
      "Epoch 2151, Loss: 0.0015338131634052843, Final Batch Loss: 0.0012328646844252944\n",
      "Epoch 2152, Loss: 0.0006583651556866243, Final Batch Loss: 0.0005338182672858238\n",
      "Epoch 2153, Loss: 0.0006373608157446142, Final Batch Loss: 3.5714965633815154e-05\n",
      "Epoch 2154, Loss: 0.000303505683405092, Final Batch Loss: 4.7783130867173895e-05\n",
      "Epoch 2155, Loss: 0.0011437529174145311, Final Batch Loss: 0.0001701155852060765\n",
      "Epoch 2156, Loss: 0.0001859580079326406, Final Batch Loss: 0.00013969918654765934\n",
      "Epoch 2157, Loss: 0.00027270408463664353, Final Batch Loss: 0.00012501112360041589\n",
      "Epoch 2158, Loss: 0.0006467027851613238, Final Batch Loss: 0.00013201661931816489\n",
      "Epoch 2159, Loss: 0.0003626879770308733, Final Batch Loss: 0.00013563626271206886\n",
      "Epoch 2160, Loss: 0.0006007725314702839, Final Batch Loss: 0.00028063770150765777\n",
      "Epoch 2161, Loss: 0.0003513121191645041, Final Batch Loss: 9.899582073558122e-05\n",
      "Epoch 2162, Loss: 0.0006309496093308553, Final Batch Loss: 0.00046127388486638665\n",
      "Epoch 2163, Loss: 0.00417450733948499, Final Batch Loss: 0.0010334820253774524\n",
      "Epoch 2164, Loss: 0.0003066305216634646, Final Batch Loss: 0.0001421515189576894\n",
      "Epoch 2165, Loss: 0.0018575596623122692, Final Batch Loss: 0.0011016662465408444\n",
      "Epoch 2166, Loss: 0.005129904471687041, Final Batch Loss: 0.004989666864275932\n",
      "Epoch 2167, Loss: 0.0002968919216073118, Final Batch Loss: 7.697824185015634e-05\n",
      "Epoch 2168, Loss: 0.0006513466651085764, Final Batch Loss: 0.0005095723900012672\n",
      "Epoch 2169, Loss: 0.0003430824654060416, Final Batch Loss: 0.0002563961606938392\n",
      "Epoch 2170, Loss: 0.0007898241747170687, Final Batch Loss: 0.00038772946572862566\n",
      "Epoch 2171, Loss: 0.00027101945670438, Final Batch Loss: 5.5739747040206566e-05\n",
      "Epoch 2172, Loss: 0.0002958987606689334, Final Batch Loss: 0.00011092516069766134\n",
      "Epoch 2173, Loss: 0.0005784259337815456, Final Batch Loss: 0.00046759829274378717\n",
      "Epoch 2174, Loss: 0.000145788613735931, Final Batch Loss: 0.00011312841525068507\n",
      "Epoch 2175, Loss: 0.0005029680905863643, Final Batch Loss: 0.0003608365950640291\n",
      "Epoch 2176, Loss: 0.0011727850651368499, Final Batch Loss: 0.0007811239338479936\n",
      "Epoch 2177, Loss: 0.0007100026559783146, Final Batch Loss: 0.00013069032866042107\n",
      "Epoch 2178, Loss: 0.0006758198142051697, Final Batch Loss: 0.0005157238338142633\n",
      "Epoch 2179, Loss: 0.0002545577517594211, Final Batch Loss: 0.0001541012607049197\n",
      "Epoch 2180, Loss: 0.0003856151597574353, Final Batch Loss: 0.0002140345168299973\n",
      "Epoch 2181, Loss: 0.00048307243559975177, Final Batch Loss: 0.00013503005902748555\n",
      "Epoch 2182, Loss: 0.000351689019225887, Final Batch Loss: 1.9447228623903356e-05\n",
      "Epoch 2183, Loss: 0.0009527746151434258, Final Batch Loss: 0.0008234212873503566\n",
      "Epoch 2184, Loss: 0.0001546810890431516, Final Batch Loss: 4.720949800685048e-05\n",
      "Epoch 2185, Loss: 0.00034774204686982557, Final Batch Loss: 9.062140452442691e-05\n",
      "Epoch 2186, Loss: 0.000761795603466453, Final Batch Loss: 2.9167498723836616e-05\n",
      "Epoch 2187, Loss: 0.0008259184833150357, Final Batch Loss: 0.00040065747452899814\n",
      "Epoch 2188, Loss: 0.02671782349352725, Final Batch Loss: 0.02656557969748974\n",
      "Epoch 2189, Loss: 0.0003094847343163565, Final Batch Loss: 0.00013757546548731625\n",
      "Epoch 2190, Loss: 0.0009677624620962888, Final Batch Loss: 0.0004116690543014556\n",
      "Epoch 2191, Loss: 0.0003070041420869529, Final Batch Loss: 0.000129202613607049\n",
      "Epoch 2192, Loss: 0.004529889207333326, Final Batch Loss: 0.0011379353236407042\n",
      "Epoch 2193, Loss: 0.00014144781198410783, Final Batch Loss: 1.7838838175521232e-05\n",
      "Epoch 2194, Loss: 0.0001166051224572584, Final Batch Loss: 8.612933015683666e-05\n",
      "Epoch 2195, Loss: 0.008848782294080593, Final Batch Loss: 0.0001896122848847881\n",
      "Epoch 2196, Loss: 0.0004423247337399516, Final Batch Loss: 0.0003841002762783319\n",
      "Epoch 2197, Loss: 0.00022848061780678108, Final Batch Loss: 9.152803249889985e-05\n",
      "Epoch 2198, Loss: 0.0005708003300242126, Final Batch Loss: 0.00032053017639555037\n",
      "Epoch 2199, Loss: 0.0004346258647274226, Final Batch Loss: 0.00028569941059686244\n",
      "Epoch 2200, Loss: 0.0029154480434954166, Final Batch Loss: 6.113736890256405e-05\n",
      "Epoch 2201, Loss: 0.0008579708519391716, Final Batch Loss: 0.00025181262753903866\n",
      "Epoch 2202, Loss: 0.001097936685255263, Final Batch Loss: 0.0010289745405316353\n",
      "Epoch 2203, Loss: 0.00018361741967964917, Final Batch Loss: 9.226192196365446e-05\n",
      "Epoch 2204, Loss: 0.0011904662096640095, Final Batch Loss: 0.0010745879262685776\n",
      "Epoch 2205, Loss: 0.00027630451768345665, Final Batch Loss: 1.6713338482077233e-05\n",
      "Epoch 2206, Loss: 0.0009875711984932423, Final Batch Loss: 0.00014487566659227014\n",
      "Epoch 2207, Loss: 0.0002754584202193655, Final Batch Loss: 0.00020432210294529796\n",
      "Epoch 2208, Loss: 0.01273555145598948, Final Batch Loss: 0.010057124309241772\n",
      "Epoch 2209, Loss: 0.0005723214271711186, Final Batch Loss: 0.00016070179117377847\n",
      "Epoch 2210, Loss: 0.0003236182819819078, Final Batch Loss: 5.7382319937460124e-05\n",
      "Epoch 2211, Loss: 0.0002832901809597388, Final Batch Loss: 0.0001711536751827225\n",
      "Epoch 2212, Loss: 0.006014751415932551, Final Batch Loss: 0.0001465479435864836\n",
      "Epoch 2213, Loss: 0.0006375013908836991, Final Batch Loss: 0.00035171571653336287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2214, Loss: 0.0004988357904949225, Final Batch Loss: 7.529150025220588e-05\n",
      "Epoch 2215, Loss: 0.0023252851678989828, Final Batch Loss: 0.0001681418507359922\n",
      "Epoch 2216, Loss: 0.0005638958828058094, Final Batch Loss: 0.00016473556752316654\n",
      "Epoch 2217, Loss: 0.0007669461483601481, Final Batch Loss: 0.0005966280004940927\n",
      "Epoch 2218, Loss: 0.000889066192030441, Final Batch Loss: 0.0007875290466472507\n",
      "Epoch 2219, Loss: 0.0017349646659567952, Final Batch Loss: 0.00129849708173424\n",
      "Epoch 2220, Loss: 0.0003001126315211877, Final Batch Loss: 5.877584044355899e-05\n",
      "Epoch 2221, Loss: 0.0006898452847963199, Final Batch Loss: 9.994213178288192e-05\n",
      "Epoch 2222, Loss: 0.0005229163543845061, Final Batch Loss: 4.6762408601352945e-05\n",
      "Epoch 2223, Loss: 0.0024661997231305577, Final Batch Loss: 9.141214104602113e-05\n",
      "Epoch 2224, Loss: 0.0003240533696953207, Final Batch Loss: 0.00012176220479886979\n",
      "Epoch 2225, Loss: 0.0002570345168351196, Final Batch Loss: 0.00018424616428092122\n",
      "Epoch 2226, Loss: 0.00015595282457070425, Final Batch Loss: 6.2678984249942e-05\n",
      "Epoch 2227, Loss: 0.00012947210416314192, Final Batch Loss: 3.154811201966368e-05\n",
      "Epoch 2228, Loss: 0.00035519256198313087, Final Batch Loss: 0.00016281438001897186\n",
      "Epoch 2229, Loss: 0.00039132351230364293, Final Batch Loss: 6.715349445585161e-05\n",
      "Epoch 2230, Loss: 0.0040498466696590185, Final Batch Loss: 0.0009830815251916647\n",
      "Epoch 2231, Loss: 0.0007717121625319123, Final Batch Loss: 0.000132183195091784\n",
      "Epoch 2232, Loss: 0.0002445516765874345, Final Batch Loss: 4.4291740778135136e-05\n",
      "Epoch 2233, Loss: 0.062222631022450514, Final Batch Loss: 0.06207773834466934\n",
      "Epoch 2234, Loss: 0.00035077909706160426, Final Batch Loss: 0.00020439243235159665\n",
      "Epoch 2235, Loss: 0.00044240832357900217, Final Batch Loss: 3.4478849556762725e-05\n",
      "Epoch 2236, Loss: 0.017846669361460954, Final Batch Loss: 0.017554838210344315\n",
      "Epoch 2237, Loss: 0.027439825178589672, Final Batch Loss: 0.02726326696574688\n",
      "Epoch 2238, Loss: 0.00019007718947250396, Final Batch Loss: 9.598669566912577e-05\n",
      "Epoch 2239, Loss: 0.0016350389996659942, Final Batch Loss: 0.001558350515551865\n",
      "Epoch 2240, Loss: 0.018892769658123143, Final Batch Loss: 0.00013179048255551606\n",
      "Epoch 2241, Loss: 0.021656932120095007, Final Batch Loss: 0.021574195474386215\n",
      "Epoch 2242, Loss: 0.0005540184356505051, Final Batch Loss: 0.00045608560321852565\n",
      "Epoch 2243, Loss: 0.00023276406864169985, Final Batch Loss: 7.050302519928664e-05\n",
      "Epoch 2244, Loss: 0.0001230121633852832, Final Batch Loss: 3.767362068174407e-05\n",
      "Epoch 2245, Loss: 0.0002953697767225094, Final Batch Loss: 6.02670552325435e-05\n",
      "Epoch 2246, Loss: 0.0005456498729472514, Final Batch Loss: 5.7833382015815005e-05\n",
      "Epoch 2247, Loss: 0.00018156597070628777, Final Batch Loss: 0.00010845780343515798\n",
      "Epoch 2248, Loss: 0.0014189228531904519, Final Batch Loss: 0.0005615682457573712\n",
      "Epoch 2249, Loss: 0.0024656727764522657, Final Batch Loss: 0.0022918079048395157\n",
      "Epoch 2250, Loss: 0.005619833013042808, Final Batch Loss: 0.0019446464721113443\n",
      "Epoch 2251, Loss: 0.0003675757980090566, Final Batch Loss: 8.854855695972219e-05\n",
      "Epoch 2252, Loss: 0.0006872224330436438, Final Batch Loss: 0.0003983057104051113\n",
      "Epoch 2253, Loss: 0.00390688978950493, Final Batch Loss: 0.0035849714186042547\n",
      "Epoch 2254, Loss: 0.005772084521595389, Final Batch Loss: 0.0052341981790959835\n",
      "Epoch 2255, Loss: 0.0006504246266558766, Final Batch Loss: 0.00015009782509878278\n",
      "Epoch 2256, Loss: 0.001550616550957784, Final Batch Loss: 0.0004592870536725968\n",
      "Epoch 2257, Loss: 0.00021931260562269017, Final Batch Loss: 4.537693894235417e-05\n",
      "Epoch 2258, Loss: 0.0005637841677526012, Final Batch Loss: 7.917768380139023e-05\n",
      "Epoch 2259, Loss: 0.005452074226923287, Final Batch Loss: 0.00514037674292922\n",
      "Epoch 2260, Loss: 0.007410083373542875, Final Batch Loss: 0.007083427160978317\n",
      "Epoch 2261, Loss: 0.0015632221184205264, Final Batch Loss: 0.00012357064406387508\n",
      "Epoch 2262, Loss: 0.00023762593991705216, Final Batch Loss: 3.7513109418796375e-05\n",
      "Epoch 2263, Loss: 0.0011198291904293, Final Batch Loss: 0.00017175852553918958\n",
      "Epoch 2264, Loss: 0.0008300785848405212, Final Batch Loss: 0.00043622334487736225\n",
      "Epoch 2265, Loss: 0.00033328387507935986, Final Batch Loss: 0.00022695885854773223\n",
      "Epoch 2266, Loss: 0.0004040061467094347, Final Batch Loss: 0.0001542699901619926\n",
      "Epoch 2267, Loss: 0.001060570328263566, Final Batch Loss: 0.0004822754708584398\n",
      "Epoch 2268, Loss: 0.00030979292932897806, Final Batch Loss: 0.00013298372505232692\n",
      "Epoch 2269, Loss: 0.00034199224319308996, Final Batch Loss: 0.0002346057299291715\n",
      "Epoch 2270, Loss: 0.00048211093235295266, Final Batch Loss: 0.00020290752581786364\n",
      "Epoch 2271, Loss: 0.0003304291640233714, Final Batch Loss: 5.008913649362512e-05\n",
      "Epoch 2272, Loss: 0.000575359576032497, Final Batch Loss: 0.00013574927288573235\n",
      "Epoch 2273, Loss: 0.014023668598383665, Final Batch Loss: 0.01283884048461914\n",
      "Epoch 2274, Loss: 0.00028654298512265086, Final Batch Loss: 9.206334652844816e-05\n",
      "Epoch 2275, Loss: 0.0004698320699390024, Final Batch Loss: 0.00034684795537032187\n",
      "Epoch 2276, Loss: 0.003995927574578673, Final Batch Loss: 0.00010010815458372235\n",
      "Epoch 2277, Loss: 0.0001772147516021505, Final Batch Loss: 6.830628262832761e-05\n",
      "Epoch 2278, Loss: 0.000996407266939059, Final Batch Loss: 0.00013281198334880173\n",
      "Epoch 2279, Loss: 0.013869994203560054, Final Batch Loss: 5.638867150992155e-05\n",
      "Epoch 2280, Loss: 0.0003159631014568731, Final Batch Loss: 0.00017146841855719686\n",
      "Epoch 2281, Loss: 0.005619167000986636, Final Batch Loss: 0.0007199096726253629\n",
      "Epoch 2282, Loss: 0.0010125132102984935, Final Batch Loss: 0.0007502134540118277\n",
      "Epoch 2283, Loss: 0.008057375845964998, Final Batch Loss: 0.007699084933847189\n",
      "Epoch 2284, Loss: 0.00018967514188261703, Final Batch Loss: 5.1845556299667805e-05\n",
      "Epoch 2285, Loss: 0.0003983548012911342, Final Batch Loss: 9.849495108937845e-05\n",
      "Epoch 2286, Loss: 0.0014796232571825385, Final Batch Loss: 0.000866861897520721\n",
      "Epoch 2287, Loss: 0.0007939970528241247, Final Batch Loss: 0.0006178331677801907\n",
      "Epoch 2288, Loss: 0.000362182516255416, Final Batch Loss: 0.00025282116257585585\n",
      "Epoch 2289, Loss: 0.0032639351848047227, Final Batch Loss: 0.00015002695727162063\n",
      "Epoch 2290, Loss: 0.0006580794870387763, Final Batch Loss: 0.00035319148446433246\n",
      "Epoch 2291, Loss: 0.004639353879611008, Final Batch Loss: 0.00022696405358146876\n",
      "Epoch 2292, Loss: 0.002161266515031457, Final Batch Loss: 0.0019837296567857265\n",
      "Epoch 2293, Loss: 0.0010656591912265867, Final Batch Loss: 0.00017137234681285918\n",
      "Epoch 2294, Loss: 0.00012658163177547976, Final Batch Loss: 2.7611276891548187e-05\n",
      "Epoch 2295, Loss: 0.005434587859781459, Final Batch Loss: 0.0003922588948626071\n",
      "Epoch 2296, Loss: 0.00038528470031451434, Final Batch Loss: 0.0001525785046396777\n",
      "Epoch 2297, Loss: 0.000315803088597022, Final Batch Loss: 0.00018079360597766936\n",
      "Epoch 2298, Loss: 0.000243608963501174, Final Batch Loss: 0.0001221984130097553\n",
      "Epoch 2299, Loss: 0.0015951134264469147, Final Batch Loss: 0.0007535814656876028\n",
      "Epoch 2300, Loss: 0.0005726935341954231, Final Batch Loss: 0.0002869999152608216\n",
      "Epoch 2301, Loss: 0.0006152530440886039, Final Batch Loss: 3.268848013249226e-05\n",
      "Epoch 2302, Loss: 0.0004802120820386335, Final Batch Loss: 0.00024885748280212283\n",
      "Epoch 2303, Loss: 0.0004044295856147073, Final Batch Loss: 0.00029367502429522574\n",
      "Epoch 2304, Loss: 0.0025146303960355, Final Batch Loss: 0.0023506965953856707\n",
      "Epoch 2305, Loss: 0.0003403700975468382, Final Batch Loss: 0.00017924538406077772\n",
      "Epoch 2306, Loss: 0.0003715532075148076, Final Batch Loss: 0.00012787414016202092\n",
      "Epoch 2307, Loss: 0.00031127883994486183, Final Batch Loss: 0.00010815338464453816\n",
      "Epoch 2308, Loss: 0.00040680741949472576, Final Batch Loss: 0.00019408896332606673\n",
      "Epoch 2309, Loss: 0.00019884193898178637, Final Batch Loss: 2.021864929702133e-05\n",
      "Epoch 2310, Loss: 0.0005066870216978714, Final Batch Loss: 0.0001853906869655475\n",
      "Epoch 2311, Loss: 0.0024694932071724907, Final Batch Loss: 6.283669790718704e-05\n",
      "Epoch 2312, Loss: 0.00032924213155638427, Final Batch Loss: 0.00013559935905504972\n",
      "Epoch 2313, Loss: 0.0006136662486824207, Final Batch Loss: 0.0005163763999007642\n",
      "Epoch 2314, Loss: 0.00048109808994922787, Final Batch Loss: 0.00012896106636617333\n",
      "Epoch 2315, Loss: 0.0005891034088563174, Final Batch Loss: 0.0003830562636721879\n",
      "Epoch 2316, Loss: 0.0025409351001144387, Final Batch Loss: 0.002467044163495302\n",
      "Epoch 2317, Loss: 0.004101420687220525, Final Batch Loss: 0.00011747696407837793\n",
      "Epoch 2318, Loss: 0.00036454856308409944, Final Batch Loss: 0.000250025448622182\n",
      "Epoch 2319, Loss: 0.00043193598685320467, Final Batch Loss: 0.00029369883122853935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2320, Loss: 0.00023971417977008969, Final Batch Loss: 0.0001243053120560944\n",
      "Epoch 2321, Loss: 0.0005808225905639119, Final Batch Loss: 7.384573837043718e-05\n",
      "Epoch 2322, Loss: 0.0008286369557026774, Final Batch Loss: 0.00044803787022829056\n",
      "Epoch 2323, Loss: 0.0003575970586098265, Final Batch Loss: 3.038627255591564e-05\n",
      "Epoch 2324, Loss: 0.00010829913662746549, Final Batch Loss: 6.707802094751969e-05\n",
      "Epoch 2325, Loss: 0.0002319270497537218, Final Batch Loss: 0.00012991415860597044\n",
      "Epoch 2326, Loss: 0.00029821218049619347, Final Batch Loss: 7.168976298999041e-05\n",
      "Epoch 2327, Loss: 0.0012122745829401538, Final Batch Loss: 0.0010736262192949653\n",
      "Epoch 2328, Loss: 0.00015839636034797877, Final Batch Loss: 6.899299478391185e-05\n",
      "Epoch 2329, Loss: 0.0003526537475408986, Final Batch Loss: 0.00012782143312506378\n",
      "Epoch 2330, Loss: 0.00019905107910744846, Final Batch Loss: 0.00014685057976748794\n",
      "Epoch 2331, Loss: 0.00021211425337241963, Final Batch Loss: 0.00010947826376650482\n",
      "Epoch 2332, Loss: 0.00038640886486973614, Final Batch Loss: 0.00025289980112574995\n",
      "Epoch 2333, Loss: 0.0009689885482657701, Final Batch Loss: 0.00019330778741277754\n",
      "Epoch 2334, Loss: 0.0007148622971726581, Final Batch Loss: 0.00012903059541713446\n",
      "Epoch 2335, Loss: 0.0005536740136449225, Final Batch Loss: 0.0004475919413380325\n",
      "Epoch 2336, Loss: 0.002653523493790999, Final Batch Loss: 7.240232662297785e-05\n",
      "Epoch 2337, Loss: 0.0004556525636871811, Final Batch Loss: 6.015717735863291e-05\n",
      "Epoch 2338, Loss: 0.013677995942998677, Final Batch Loss: 0.0002513400395400822\n",
      "Epoch 2339, Loss: 0.00020683371621998958, Final Batch Loss: 5.260572288534604e-05\n",
      "Epoch 2340, Loss: 0.0003829989072983153, Final Batch Loss: 7.600771641591564e-05\n",
      "Epoch 2341, Loss: 0.0030750504993193317, Final Batch Loss: 3.435237522353418e-05\n",
      "Epoch 2342, Loss: 0.00021730799562647007, Final Batch Loss: 2.567749106674455e-05\n",
      "Epoch 2343, Loss: 0.0006245956319617108, Final Batch Loss: 0.0003804939042311162\n",
      "Epoch 2344, Loss: 0.0001953300743480213, Final Batch Loss: 6.294647027971223e-05\n",
      "Epoch 2345, Loss: 0.008734790259040892, Final Batch Loss: 0.008602847345173359\n",
      "Epoch 2346, Loss: 0.003937614907044917, Final Batch Loss: 0.00010620459215715528\n",
      "Epoch 2347, Loss: 0.0003336625377414748, Final Batch Loss: 3.893267421517521e-05\n",
      "Epoch 2348, Loss: 0.00044184213038533926, Final Batch Loss: 0.00023881408560555428\n",
      "Epoch 2349, Loss: 0.0002570056894910522, Final Batch Loss: 7.355525303864852e-05\n",
      "Epoch 2350, Loss: 0.0002067424129563733, Final Batch Loss: 1.4573909538739827e-05\n",
      "Epoch 2351, Loss: 0.00041296001654700376, Final Batch Loss: 2.8927028324687853e-05\n",
      "Epoch 2352, Loss: 0.022118455643067136, Final Batch Loss: 0.0002484181022737175\n",
      "Epoch 2353, Loss: 0.0005140519206179306, Final Batch Loss: 0.00017967245366889983\n",
      "Epoch 2354, Loss: 0.0005666526994900778, Final Batch Loss: 7.144200208131224e-05\n",
      "Epoch 2355, Loss: 0.0003447292801865842, Final Batch Loss: 6.056739584892057e-05\n",
      "Epoch 2356, Loss: 0.0002451811233186163, Final Batch Loss: 0.00017382667283527553\n",
      "Epoch 2357, Loss: 0.0008159762546711136, Final Batch Loss: 4.30502877861727e-05\n",
      "Epoch 2358, Loss: 0.0002936844393843785, Final Batch Loss: 0.00010514420864637941\n",
      "Epoch 2359, Loss: 0.0008647171780467033, Final Batch Loss: 0.0005516664241440594\n",
      "Epoch 2360, Loss: 0.00019039471771975514, Final Batch Loss: 2.2192898541106842e-05\n",
      "Epoch 2361, Loss: 0.0006407096225302666, Final Batch Loss: 0.00038839670014567673\n",
      "Epoch 2362, Loss: 0.0006078776787035167, Final Batch Loss: 0.0005345732788555324\n",
      "Epoch 2363, Loss: 0.004222960043989588, Final Batch Loss: 0.00010612264304654673\n",
      "Epoch 2364, Loss: 0.00036061336140846834, Final Batch Loss: 8.29139826237224e-05\n",
      "Epoch 2365, Loss: 0.0002705318656808231, Final Batch Loss: 3.6149827792542055e-05\n",
      "Epoch 2366, Loss: 0.0013754653191426769, Final Batch Loss: 0.0011487890733405948\n",
      "Epoch 2367, Loss: 0.0004930965369567275, Final Batch Loss: 0.00025616068160161376\n",
      "Epoch 2368, Loss: 0.0006821480637881905, Final Batch Loss: 0.00036068999907001853\n",
      "Epoch 2369, Loss: 0.0062374857370741665, Final Batch Loss: 0.006003802176564932\n",
      "Epoch 2370, Loss: 0.0004969848741893657, Final Batch Loss: 6.879971624584869e-05\n",
      "Epoch 2371, Loss: 0.00031903937633614987, Final Batch Loss: 9.106854849960655e-05\n",
      "Epoch 2372, Loss: 0.0008451259636785835, Final Batch Loss: 0.0005363526870496571\n",
      "Epoch 2373, Loss: 0.0006377264362527058, Final Batch Loss: 0.00041707640048116446\n",
      "Epoch 2374, Loss: 0.0005162429879419506, Final Batch Loss: 2.7788395527750254e-05\n",
      "Epoch 2375, Loss: 0.0003311537657282315, Final Batch Loss: 5.348573176888749e-05\n",
      "Epoch 2376, Loss: 0.0027212739769311156, Final Batch Loss: 3.642931915237568e-05\n",
      "Epoch 2377, Loss: 0.0005456809449242428, Final Batch Loss: 0.00016950366261880845\n",
      "Epoch 2378, Loss: 0.00027276509354123846, Final Batch Loss: 0.00017483561532571912\n",
      "Epoch 2379, Loss: 0.0004996165371267125, Final Batch Loss: 0.00016101593791972846\n",
      "Epoch 2380, Loss: 0.00035432293952908367, Final Batch Loss: 0.0001426522940164432\n",
      "Epoch 2381, Loss: 0.00023929411327117123, Final Batch Loss: 0.00019541873189155012\n",
      "Epoch 2382, Loss: 0.0003441253793425858, Final Batch Loss: 4.968087887391448e-05\n",
      "Epoch 2383, Loss: 0.0031300291848310735, Final Batch Loss: 2.7453290385892615e-05\n",
      "Epoch 2384, Loss: 0.0003608292099670507, Final Batch Loss: 9.787738235900179e-05\n",
      "Epoch 2385, Loss: 0.0003534359420882538, Final Batch Loss: 0.00020946288714185357\n",
      "Epoch 2386, Loss: 0.00010820992611115798, Final Batch Loss: 4.2090607166755944e-05\n",
      "Epoch 2387, Loss: 0.00017247453797608614, Final Batch Loss: 0.00012082116154488176\n",
      "Epoch 2388, Loss: 0.00046075962018221617, Final Batch Loss: 4.576114588417113e-05\n",
      "Epoch 2389, Loss: 0.00021023552835686132, Final Batch Loss: 0.00012899575813207775\n",
      "Epoch 2390, Loss: 0.00014962736531742848, Final Batch Loss: 9.739305096445605e-05\n",
      "Epoch 2391, Loss: 0.000859345673234202, Final Batch Loss: 0.000631034083198756\n",
      "Epoch 2392, Loss: 0.00037481087201740593, Final Batch Loss: 0.00010785557969938964\n",
      "Epoch 2393, Loss: 0.004186735619441606, Final Batch Loss: 4.74337866762653e-05\n",
      "Epoch 2394, Loss: 0.0006042841268936172, Final Batch Loss: 0.00012595402949955314\n",
      "Epoch 2395, Loss: 0.000953568047407316, Final Batch Loss: 0.0009108872036449611\n",
      "Epoch 2396, Loss: 0.0005835283518536016, Final Batch Loss: 0.0003436924598645419\n",
      "Epoch 2397, Loss: 0.0009121436560235452, Final Batch Loss: 0.0008835456683300436\n",
      "Epoch 2398, Loss: 0.0008885559218470007, Final Batch Loss: 0.00010464389924891293\n",
      "Epoch 2399, Loss: 0.0003428043200983666, Final Batch Loss: 6.302908150246367e-05\n",
      "Epoch 2400, Loss: 0.0011527754395501688, Final Batch Loss: 0.0001339633745374158\n",
      "Epoch 2401, Loss: 0.00016235710063483566, Final Batch Loss: 2.2004518541507423e-05\n",
      "Epoch 2402, Loss: 0.0008222444012062624, Final Batch Loss: 0.0007216898375190794\n",
      "Epoch 2403, Loss: 0.000573716388316825, Final Batch Loss: 0.00051784428069368\n",
      "Epoch 2404, Loss: 0.006585041410289705, Final Batch Loss: 0.0009114592103287578\n",
      "Epoch 2405, Loss: 0.00019514531595632434, Final Batch Loss: 2.778023190330714e-05\n",
      "Epoch 2406, Loss: 0.00022610243468079716, Final Batch Loss: 0.00016172672621905804\n",
      "Epoch 2407, Loss: 0.001399684653733857, Final Batch Loss: 0.0002068255125777796\n",
      "Epoch 2408, Loss: 5.637073172692908e-05, Final Batch Loss: 4.256411921232939e-05\n",
      "Epoch 2409, Loss: 0.00026738665656012017, Final Batch Loss: 2.5550836653565057e-05\n",
      "Epoch 2410, Loss: 0.0009999092144425958, Final Batch Loss: 0.00012960375170223415\n",
      "Epoch 2411, Loss: 0.0004466998507268727, Final Batch Loss: 0.00024611857952550054\n",
      "Epoch 2412, Loss: 9.453406892134808e-05, Final Batch Loss: 4.902085129288025e-05\n",
      "Epoch 2413, Loss: 0.00023977988166734576, Final Batch Loss: 0.00012795859947800636\n",
      "Epoch 2414, Loss: 0.0001247339059773367, Final Batch Loss: 5.200402301852591e-05\n",
      "Epoch 2415, Loss: 0.00042737523108371533, Final Batch Loss: 4.3514217395568267e-05\n",
      "Epoch 2416, Loss: 0.0008672003023093566, Final Batch Loss: 0.0007036200840957463\n",
      "Epoch 2417, Loss: 0.0005842062309966423, Final Batch Loss: 6.109392415964976e-05\n",
      "Epoch 2418, Loss: 0.0005372970481403172, Final Batch Loss: 0.00018818394164554775\n",
      "Epoch 2419, Loss: 0.00018335777349420823, Final Batch Loss: 5.531094575417228e-05\n",
      "Epoch 2420, Loss: 0.0006041938904672861, Final Batch Loss: 0.0004132685426156968\n",
      "Epoch 2421, Loss: 0.00018790784088196233, Final Batch Loss: 6.644445238634944e-05\n",
      "Epoch 2422, Loss: 0.0005237179429968819, Final Batch Loss: 0.00041573913767933846\n",
      "Epoch 2423, Loss: 0.0005823468982271152, Final Batch Loss: 0.0005543949664570391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2424, Loss: 0.0027898341068066657, Final Batch Loss: 0.002721918048337102\n",
      "Epoch 2425, Loss: 0.00021789678794448264, Final Batch Loss: 4.083958992850967e-05\n",
      "Epoch 2426, Loss: 0.00014522957644658163, Final Batch Loss: 4.436191375134513e-05\n",
      "Epoch 2427, Loss: 0.00045954796951264143, Final Batch Loss: 0.00011740293120965362\n",
      "Epoch 2428, Loss: 0.0005825565094710328, Final Batch Loss: 3.4307340683881193e-05\n",
      "Epoch 2429, Loss: 0.00015828774849069305, Final Batch Loss: 0.00010030592966359109\n",
      "Epoch 2430, Loss: 0.0009262746752938256, Final Batch Loss: 0.0008299502660520375\n",
      "Epoch 2431, Loss: 0.0004102202074136585, Final Batch Loss: 0.00010123720858246088\n",
      "Epoch 2432, Loss: 0.0029209986969362944, Final Batch Loss: 0.00021059319260530174\n",
      "Epoch 2433, Loss: 0.0010039348271675408, Final Batch Loss: 0.0007361283642239869\n",
      "Epoch 2434, Loss: 0.0007498716913687531, Final Batch Loss: 3.663756433525123e-05\n",
      "Epoch 2435, Loss: 0.0030367165818461217, Final Batch Loss: 4.32441956945695e-05\n",
      "Epoch 2436, Loss: 0.0003794208314502612, Final Batch Loss: 5.407935532275587e-05\n",
      "Epoch 2437, Loss: 0.00018404472939437255, Final Batch Loss: 8.605499897385016e-05\n",
      "Epoch 2438, Loss: 0.012580077336679096, Final Batch Loss: 0.01255117729306221\n",
      "Epoch 2439, Loss: 0.012210655957460403, Final Batch Loss: 0.009895981289446354\n",
      "Epoch 2440, Loss: 0.00013020667756791227, Final Batch Loss: 3.8591886550420895e-05\n",
      "Epoch 2441, Loss: 4.640314455173211e-05, Final Batch Loss: 1.4925230971130077e-05\n",
      "Epoch 2442, Loss: 6.865673458378296e-05, Final Batch Loss: 1.6750002032495104e-05\n",
      "Epoch 2443, Loss: 0.0002593477474874817, Final Batch Loss: 0.00011797004117397591\n",
      "Epoch 2444, Loss: 0.0105029537990049, Final Batch Loss: 0.010445724241435528\n",
      "Epoch 2445, Loss: 0.0002242810842290055, Final Batch Loss: 1.823022830649279e-05\n",
      "Epoch 2446, Loss: 0.00016410341049777344, Final Batch Loss: 9.546816727379337e-05\n",
      "Epoch 2447, Loss: 0.0002043019594566431, Final Batch Loss: 0.0001598152593942359\n",
      "Epoch 2448, Loss: 0.0010885808733291924, Final Batch Loss: 0.0009495234698988497\n",
      "Epoch 2449, Loss: 0.00013284107626532204, Final Batch Loss: 3.5517408832674846e-05\n",
      "Epoch 2450, Loss: 0.0032186729658860713, Final Batch Loss: 0.00019968583364970982\n",
      "Epoch 2451, Loss: 0.00014666040624433663, Final Batch Loss: 1.9339777281857096e-05\n",
      "Epoch 2452, Loss: 0.0007196430269686971, Final Batch Loss: 2.161879456252791e-05\n",
      "Epoch 2453, Loss: 0.00026201143919024616, Final Batch Loss: 6.870822107885033e-05\n",
      "Epoch 2454, Loss: 0.0035702327513718046, Final Batch Loss: 0.00011933383211726323\n",
      "Epoch 2455, Loss: 0.0006016260158503428, Final Batch Loss: 2.6705340133048594e-05\n",
      "Epoch 2456, Loss: 0.00030519816937157884, Final Batch Loss: 0.00025973370065912604\n",
      "Epoch 2457, Loss: 0.0010343042958993465, Final Batch Loss: 0.00014592657680623233\n",
      "Epoch 2458, Loss: 0.0005528564215637743, Final Batch Loss: 0.0005222535692155361\n",
      "Epoch 2459, Loss: 0.000767510078730993, Final Batch Loss: 0.0006418809061869979\n",
      "Epoch 2460, Loss: 0.001327855745330453, Final Batch Loss: 0.0006572474958375096\n",
      "Epoch 2461, Loss: 0.00019316953694215044, Final Batch Loss: 8.67592025315389e-05\n",
      "Epoch 2462, Loss: 0.00039986234332900494, Final Batch Loss: 6.1553277191706e-05\n",
      "Epoch 2463, Loss: 0.0002954117808258161, Final Batch Loss: 7.755144906695932e-05\n",
      "Epoch 2464, Loss: 0.0002883320048567839, Final Batch Loss: 0.0002080364793073386\n",
      "Epoch 2465, Loss: 0.0006579527835128829, Final Batch Loss: 0.0005513257929123938\n",
      "Epoch 2466, Loss: 0.000363367231329903, Final Batch Loss: 0.0002088229957735166\n",
      "Epoch 2467, Loss: 0.00461029181315098, Final Batch Loss: 0.004482125397771597\n",
      "Epoch 2468, Loss: 0.0006123616331024095, Final Batch Loss: 0.0003866023907903582\n",
      "Epoch 2469, Loss: 0.000490956925204955, Final Batch Loss: 0.0004339138977229595\n",
      "Epoch 2470, Loss: 0.00026173780497629195, Final Batch Loss: 0.00013401768228504807\n",
      "Epoch 2471, Loss: 0.0004209485778119415, Final Batch Loss: 0.00025282727438025177\n",
      "Epoch 2472, Loss: 0.0034032550029223785, Final Batch Loss: 0.000102550009614788\n",
      "Epoch 2473, Loss: 0.00012197455362183973, Final Batch Loss: 3.634180757217109e-05\n",
      "Epoch 2474, Loss: 0.00029559525137301534, Final Batch Loss: 0.00015470624202862382\n",
      "Epoch 2475, Loss: 0.00011675692803692073, Final Batch Loss: 6.023292007739656e-05\n",
      "Epoch 2476, Loss: 0.00037744113069493324, Final Batch Loss: 7.461274799425155e-05\n",
      "Epoch 2477, Loss: 0.00029092036857036874, Final Batch Loss: 0.00019032700220122933\n",
      "Epoch 2478, Loss: 0.0039366805940517224, Final Batch Loss: 3.529489185893908e-05\n",
      "Epoch 2479, Loss: 0.0003563575737643987, Final Batch Loss: 0.00021527968056034297\n",
      "Epoch 2480, Loss: 8.335671373060904e-05, Final Batch Loss: 3.5964883863925934e-05\n",
      "Epoch 2481, Loss: 0.00018926173652289435, Final Batch Loss: 9.472198144067079e-05\n",
      "Epoch 2482, Loss: 0.00023609377240063623, Final Batch Loss: 0.00017665127234067768\n",
      "Epoch 2483, Loss: 0.0026490080999792553, Final Batch Loss: 8.362837979802862e-05\n",
      "Epoch 2484, Loss: 0.00028888805354654323, Final Batch Loss: 2.404604856565129e-05\n",
      "Epoch 2485, Loss: 7.224121145554818e-05, Final Batch Loss: 2.029216193477623e-05\n",
      "Epoch 2486, Loss: 0.00014286374062066898, Final Batch Loss: 7.529531285399571e-05\n",
      "Epoch 2487, Loss: 0.00014485561041510664, Final Batch Loss: 9.332993067800999e-05\n",
      "Epoch 2488, Loss: 0.007180043030530214, Final Batch Loss: 0.00664057582616806\n",
      "Epoch 2489, Loss: 0.016299123119097203, Final Batch Loss: 0.00011326762614771724\n",
      "Epoch 2490, Loss: 6.467015919042751e-05, Final Batch Loss: 2.9881073714932427e-05\n",
      "Epoch 2491, Loss: 0.0005600458098342642, Final Batch Loss: 0.00015340994286816567\n",
      "Epoch 2492, Loss: 0.00023549328761873767, Final Batch Loss: 0.00014159017882775515\n",
      "Epoch 2493, Loss: 0.00028498210303951055, Final Batch Loss: 0.00016997026978060603\n",
      "Epoch 2494, Loss: 0.0007264022133313119, Final Batch Loss: 0.0001943028182722628\n",
      "Epoch 2495, Loss: 0.00023224522010423243, Final Batch Loss: 0.00015354213246610016\n",
      "Epoch 2496, Loss: 0.0002622706706461031, Final Batch Loss: 1.9845294445985928e-05\n",
      "Epoch 2497, Loss: 0.0021682607766706496, Final Batch Loss: 0.0020226386841386557\n",
      "Epoch 2498, Loss: 0.005628071125101997, Final Batch Loss: 0.005567653104662895\n",
      "Epoch 2499, Loss: 0.000203388281079242, Final Batch Loss: 4.283831003704108e-05\n",
      "Epoch 2500, Loss: 0.00018335617551201722, Final Batch Loss: 8.752590474614408e-06\n",
      "Epoch 2501, Loss: 0.0007687047618674114, Final Batch Loss: 0.0007194325444288552\n",
      "Epoch 2502, Loss: 0.00030502478330163285, Final Batch Loss: 8.338252519024536e-05\n",
      "Epoch 2503, Loss: 0.0004627894813893363, Final Batch Loss: 0.00022309014457277954\n",
      "Epoch 2504, Loss: 0.0024901808938011527, Final Batch Loss: 0.002105935011059046\n",
      "Epoch 2505, Loss: 0.000119138470836333, Final Batch Loss: 2.6262116080033593e-05\n",
      "Epoch 2506, Loss: 0.003462759414105676, Final Batch Loss: 1.8988605006597936e-05\n",
      "Epoch 2507, Loss: 0.0005783215565315913, Final Batch Loss: 3.800807098741643e-05\n",
      "Epoch 2508, Loss: 0.0010062851360999048, Final Batch Loss: 0.00015679874923080206\n",
      "Epoch 2509, Loss: 0.0002017589722527191, Final Batch Loss: 0.0001345695782219991\n",
      "Epoch 2510, Loss: 0.00013158388901501894, Final Batch Loss: 4.4288302888162434e-05\n",
      "Epoch 2511, Loss: 0.00017270098032895476, Final Batch Loss: 0.00010601863323245198\n",
      "Epoch 2512, Loss: 0.00011133267253171653, Final Batch Loss: 4.5970162318553776e-05\n",
      "Epoch 2513, Loss: 0.0006866848780191503, Final Batch Loss: 0.0006495103589259088\n",
      "Epoch 2514, Loss: 0.00013340335499378853, Final Batch Loss: 7.665060547878966e-05\n",
      "Epoch 2515, Loss: 0.005325801437720656, Final Batch Loss: 0.00206640362739563\n",
      "Epoch 2516, Loss: 0.00018941792222904041, Final Batch Loss: 0.00010346230556024238\n",
      "Epoch 2517, Loss: 5.404350667959079e-05, Final Batch Loss: 7.827697118045762e-06\n",
      "Epoch 2518, Loss: 0.0002918689206126146, Final Batch Loss: 0.00019397494907025248\n",
      "Epoch 2519, Loss: 0.0009624920312489849, Final Batch Loss: 1.404423892381601e-05\n",
      "Epoch 2520, Loss: 0.0004965431071468629, Final Batch Loss: 6.641530490014702e-06\n",
      "Epoch 2521, Loss: 0.0005666361139446963, Final Batch Loss: 4.089800131623633e-05\n",
      "Epoch 2522, Loss: 0.000630179129075259, Final Batch Loss: 0.0003733619814738631\n",
      "Epoch 2523, Loss: 0.00021682468650396913, Final Batch Loss: 0.0001253926893696189\n",
      "Epoch 2524, Loss: 0.00017270763237320352, Final Batch Loss: 1.175188117485959e-05\n",
      "Epoch 2525, Loss: 5.97926937189186e-05, Final Batch Loss: 1.832111411204096e-05\n",
      "Epoch 2526, Loss: 0.00027065064932685345, Final Batch Loss: 0.00012720483937300742\n",
      "Epoch 2527, Loss: 9.515722922515124e-05, Final Batch Loss: 2.6422625523991883e-05\n",
      "Epoch 2528, Loss: 0.0004120902740396559, Final Batch Loss: 0.0002589606447145343\n",
      "Epoch 2529, Loss: 0.0006357218735502101, Final Batch Loss: 0.0005594419781118631\n",
      "Epoch 2530, Loss: 0.011054159665945917, Final Batch Loss: 0.00011253409320488572\n",
      "Epoch 2531, Loss: 0.00014084485883358866, Final Batch Loss: 6.488024519057944e-05\n",
      "Epoch 2532, Loss: 0.00018141749023925513, Final Batch Loss: 0.00010370701784268022\n",
      "Epoch 2533, Loss: 0.00018206570530310273, Final Batch Loss: 1.8023289158008993e-05\n",
      "Epoch 2534, Loss: 0.00029384488880168647, Final Batch Loss: 0.00014348879631143063\n",
      "Epoch 2535, Loss: 0.0003648629099188838, Final Batch Loss: 4.030985655845143e-05\n",
      "Epoch 2536, Loss: 0.0008325817179866135, Final Batch Loss: 0.0004037451872136444\n",
      "Epoch 2537, Loss: 0.00030996528948890045, Final Batch Loss: 0.00027037214022129774\n",
      "Epoch 2538, Loss: 0.0001857023853517603, Final Batch Loss: 2.5942335923900828e-05\n",
      "Epoch 2539, Loss: 0.005355226981919259, Final Batch Loss: 0.005085516255348921\n",
      "Epoch 2540, Loss: 0.0006567771415575407, Final Batch Loss: 0.0005423806142061949\n",
      "Epoch 2541, Loss: 0.0012872837796749081, Final Batch Loss: 5.323107689036988e-05\n",
      "Epoch 2542, Loss: 0.0015089848166098818, Final Batch Loss: 0.0014872855972498655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2543, Loss: 0.0007735768158454448, Final Batch Loss: 0.0005022751283831894\n",
      "Epoch 2544, Loss: 0.0002482462441548705, Final Batch Loss: 4.436071321833879e-05\n",
      "Epoch 2545, Loss: 0.00022510723647428676, Final Batch Loss: 7.263756560860202e-05\n",
      "Epoch 2546, Loss: 0.0010095139441546053, Final Batch Loss: 0.0007957503548823297\n",
      "Epoch 2547, Loss: 0.00011563876796572004, Final Batch Loss: 9.854885865934193e-05\n",
      "Epoch 2548, Loss: 0.0004324952751630917, Final Batch Loss: 0.00019795117259491235\n",
      "Epoch 2549, Loss: 0.00046581502101616934, Final Batch Loss: 0.0003790791379287839\n",
      "Epoch 2550, Loss: 0.00022114651801530272, Final Batch Loss: 0.00012842947035096586\n",
      "Epoch 2551, Loss: 0.000445106350525748, Final Batch Loss: 0.00035662759910337627\n",
      "Epoch 2552, Loss: 0.004994617193005979, Final Batch Loss: 6.005296017974615e-05\n",
      "Epoch 2553, Loss: 0.0002196860805270262, Final Batch Loss: 0.0001435446465620771\n",
      "Epoch 2554, Loss: 0.00014479150195256807, Final Batch Loss: 5.729575423174538e-05\n",
      "Epoch 2555, Loss: 0.00024011722416616976, Final Batch Loss: 0.00012906255142297596\n",
      "Epoch 2556, Loss: 0.00015390922635560855, Final Batch Loss: 3.8073587347753346e-05\n",
      "Epoch 2557, Loss: 0.00028944234509253874, Final Batch Loss: 0.00020383720402605832\n",
      "Epoch 2558, Loss: 0.0002332154763280414, Final Batch Loss: 0.0001767177600413561\n",
      "Epoch 2559, Loss: 0.0004055384488310665, Final Batch Loss: 0.00031091412529349327\n",
      "Epoch 2560, Loss: 0.0028854636548203416, Final Batch Loss: 6.103027408244088e-05\n",
      "Epoch 2561, Loss: 0.0001914322183438344, Final Batch Loss: 2.773663254629355e-05\n",
      "Epoch 2562, Loss: 4.9474103434477e-05, Final Batch Loss: 3.0844093998894095e-05\n",
      "Epoch 2563, Loss: 0.0002178888644266408, Final Batch Loss: 4.066401379532181e-05\n",
      "Epoch 2564, Loss: 0.00046037691208766773, Final Batch Loss: 2.7966343623120338e-05\n",
      "Epoch 2565, Loss: 0.004793605563463643, Final Batch Loss: 0.004632028751075268\n",
      "Epoch 2566, Loss: 0.0025876004074234515, Final Batch Loss: 0.002381169470027089\n",
      "Epoch 2567, Loss: 0.00011203497524547856, Final Batch Loss: 1.7662341633695178e-05\n",
      "Epoch 2568, Loss: 0.00010066100367112085, Final Batch Loss: 7.009409455349669e-05\n",
      "Epoch 2569, Loss: 0.005655059707351029, Final Batch Loss: 0.005325798410922289\n",
      "Epoch 2570, Loss: 0.00016466592205688357, Final Batch Loss: 0.00010147643479285762\n",
      "Epoch 2571, Loss: 0.00014015425040270202, Final Batch Loss: 0.00010430635302327573\n",
      "Epoch 2572, Loss: 0.0002117545773216989, Final Batch Loss: 0.00019014623831026256\n",
      "Epoch 2573, Loss: 0.045948394312290475, Final Batch Loss: 0.04558876156806946\n",
      "Epoch 2574, Loss: 0.007050507017993368, Final Batch Loss: 0.006842709146440029\n",
      "Epoch 2575, Loss: 0.00019519250690791523, Final Batch Loss: 9.681824849394616e-06\n",
      "Epoch 2576, Loss: 0.0001352266117464751, Final Batch Loss: 4.268402699381113e-05\n",
      "Epoch 2577, Loss: 0.00039903976721689105, Final Batch Loss: 0.0002397331700194627\n",
      "Epoch 2578, Loss: 0.00030780534143559635, Final Batch Loss: 0.00018375822401139885\n",
      "Epoch 2579, Loss: 0.00012806709855794907, Final Batch Loss: 5.270819383440539e-05\n",
      "Epoch 2580, Loss: 0.004963323208357906, Final Batch Loss: 3.755578291020356e-05\n",
      "Epoch 2581, Loss: 0.00027370909447199665, Final Batch Loss: 5.737399260397069e-05\n",
      "Epoch 2582, Loss: 0.006343339569866657, Final Batch Loss: 0.002462750533595681\n",
      "Epoch 2583, Loss: 0.0011152993283758406, Final Batch Loss: 0.0010919146006926894\n",
      "Epoch 2584, Loss: 0.0003427371739235241, Final Batch Loss: 3.564944563549943e-05\n",
      "Epoch 2585, Loss: 0.0003988002390542533, Final Batch Loss: 0.0003647119156084955\n",
      "Epoch 2586, Loss: 0.00023052126016409602, Final Batch Loss: 1.1152229490107857e-05\n",
      "Epoch 2587, Loss: 0.0036388479566085152, Final Batch Loss: 2.1847656171303242e-05\n",
      "Epoch 2588, Loss: 0.00027107525056635495, Final Batch Loss: 3.0513610909110866e-05\n",
      "Epoch 2589, Loss: 0.001024819997837767, Final Batch Loss: 0.00010349784861318767\n",
      "Epoch 2590, Loss: 0.00022590867592953146, Final Batch Loss: 0.00015602064377162606\n",
      "Epoch 2591, Loss: 0.0017524654103908688, Final Batch Loss: 0.0014508962631225586\n",
      "Epoch 2592, Loss: 0.0003438104977249168, Final Batch Loss: 6.04599408688955e-05\n",
      "Epoch 2593, Loss: 0.00010551395280344877, Final Batch Loss: 3.0178032830008306e-05\n",
      "Epoch 2594, Loss: 0.0003558580865501426, Final Batch Loss: 3.599237970774993e-05\n",
      "Epoch 2595, Loss: 0.0024653355358168483, Final Batch Loss: 0.0003269900334998965\n",
      "Epoch 2596, Loss: 6.0892110923305154e-05, Final Batch Loss: 1.566449282108806e-05\n",
      "Epoch 2597, Loss: 8.72836790222209e-05, Final Batch Loss: 3.072389154112898e-05\n",
      "Epoch 2598, Loss: 0.0005506437883013859, Final Batch Loss: 0.00011482460831757635\n",
      "Epoch 2599, Loss: 0.0003026543781743385, Final Batch Loss: 0.00024244435189757496\n",
      "Epoch 2600, Loss: 9.35506759560667e-05, Final Batch Loss: 1.8165701476391405e-05\n",
      "Epoch 2601, Loss: 0.00021896068574278615, Final Batch Loss: 0.0001693707163212821\n",
      "Epoch 2602, Loss: 0.007931235217256472, Final Batch Loss: 0.007770805153995752\n",
      "Epoch 2603, Loss: 0.0002757473266683519, Final Batch Loss: 0.00014856824418529868\n",
      "Epoch 2604, Loss: 0.0031593251405865885, Final Batch Loss: 5.8486162743065506e-05\n",
      "Epoch 2605, Loss: 0.00010973506869049743, Final Batch Loss: 4.332727985456586e-05\n",
      "Epoch 2606, Loss: 0.00019875930229318328, Final Batch Loss: 5.047246304457076e-05\n",
      "Epoch 2607, Loss: 0.0018737415230134502, Final Batch Loss: 9.22640465432778e-05\n",
      "Epoch 2608, Loss: 0.00013254799705464393, Final Batch Loss: 2.130836946889758e-05\n",
      "Epoch 2609, Loss: 0.0001708808558760211, Final Batch Loss: 7.368410297203809e-05\n",
      "Epoch 2610, Loss: 0.00013558788850787096, Final Batch Loss: 5.9957925259368494e-05\n",
      "Epoch 2611, Loss: 0.00016365204646717757, Final Batch Loss: 0.00011589168570935726\n",
      "Epoch 2612, Loss: 0.006693033152259886, Final Batch Loss: 0.006073690950870514\n",
      "Epoch 2613, Loss: 0.00014971651762607507, Final Batch Loss: 0.00011887572327395901\n",
      "Epoch 2614, Loss: 8.307283496833406e-05, Final Batch Loss: 3.8667691114824265e-05\n",
      "Epoch 2615, Loss: 0.0001977534338948317, Final Batch Loss: 7.083806121954694e-05\n",
      "Epoch 2616, Loss: 7.475330130546354e-05, Final Batch Loss: 3.0070095817791298e-05\n",
      "Epoch 2617, Loss: 0.00027047632465837523, Final Batch Loss: 0.0001206935485242866\n",
      "Epoch 2618, Loss: 0.002631430877954699, Final Batch Loss: 0.00017522893904242665\n",
      "Epoch 2619, Loss: 0.0001464421657146886, Final Batch Loss: 3.640631621237844e-05\n",
      "Epoch 2620, Loss: 0.00018972661928273737, Final Batch Loss: 9.328700980404392e-05\n",
      "Epoch 2621, Loss: 0.00040354632801609114, Final Batch Loss: 0.000309036229737103\n",
      "Epoch 2622, Loss: 0.0003235137919546105, Final Batch Loss: 3.748990275198594e-05\n",
      "Epoch 2623, Loss: 0.005123914408613928, Final Batch Loss: 0.004881719592958689\n",
      "Epoch 2624, Loss: 0.0031325708187068813, Final Batch Loss: 6.483546894742176e-05\n",
      "Epoch 2625, Loss: 0.0032353138449252583, Final Batch Loss: 7.245726010296494e-06\n",
      "Epoch 2626, Loss: 0.0002383029495831579, Final Batch Loss: 0.00013590270827990025\n",
      "Epoch 2627, Loss: 0.00011015191557817161, Final Batch Loss: 2.0818362827412784e-05\n",
      "Epoch 2628, Loss: 0.0006412166694644839, Final Batch Loss: 0.0002616845304146409\n",
      "Epoch 2629, Loss: 0.0005143762100487947, Final Batch Loss: 0.00019977873307652771\n",
      "Epoch 2630, Loss: 0.006062459258828312, Final Batch Loss: 0.005852885078638792\n",
      "Epoch 2631, Loss: 0.00036074834497412667, Final Batch Loss: 0.0002713124267756939\n",
      "Epoch 2632, Loss: 0.005064026765467133, Final Batch Loss: 0.0049555329605937\n",
      "Epoch 2633, Loss: 0.0009369877971039386, Final Batch Loss: 3.0373326808330603e-05\n",
      "Epoch 2634, Loss: 0.00011224739864701405, Final Batch Loss: 7.23910634405911e-05\n",
      "Epoch 2635, Loss: 0.0024922363663790748, Final Batch Loss: 0.00013649968605022877\n",
      "Epoch 2636, Loss: 0.006054490542737767, Final Batch Loss: 0.005798200611025095\n",
      "Epoch 2637, Loss: 0.00017107503663282841, Final Batch Loss: 9.29888483369723e-05\n",
      "Epoch 2638, Loss: 8.497347153024748e-05, Final Batch Loss: 4.119928416912444e-05\n",
      "Epoch 2639, Loss: 0.00018868862389354035, Final Batch Loss: 8.706271910341457e-05\n",
      "Epoch 2640, Loss: 0.0007866818050388247, Final Batch Loss: 0.0005166580085642636\n",
      "Epoch 2641, Loss: 0.0024863212602213025, Final Batch Loss: 7.530755829066038e-05\n",
      "Epoch 2642, Loss: 0.00020240008961991407, Final Batch Loss: 3.7100111512700096e-05\n",
      "Epoch 2643, Loss: 0.00020333207794465125, Final Batch Loss: 0.00015830610936973244\n",
      "Epoch 2644, Loss: 0.00028730451595038176, Final Batch Loss: 8.498970419168472e-05\n",
      "Epoch 2645, Loss: 0.0001371379657939542, Final Batch Loss: 3.60389421985019e-05\n",
      "Epoch 2646, Loss: 0.0003542600170476362, Final Batch Loss: 9.574041177984327e-05\n",
      "Epoch 2647, Loss: 0.00032478263892699033, Final Batch Loss: 0.0002461639232933521\n",
      "Epoch 2648, Loss: 0.0001229244953719899, Final Batch Loss: 9.190668060909957e-05\n",
      "Epoch 2649, Loss: 0.00010983617175952531, Final Batch Loss: 5.5352284107357264e-05\n",
      "Epoch 2650, Loss: 0.0001297407980018761, Final Batch Loss: 8.989308844320476e-05\n",
      "Epoch 2651, Loss: 0.0001560832570248749, Final Batch Loss: 0.00010708245099522173\n",
      "Epoch 2652, Loss: 0.0025052054752450204, Final Batch Loss: 2.5557490516803227e-05\n",
      "Epoch 2653, Loss: 0.00010123869105882477, Final Batch Loss: 2.5395389457116835e-05\n",
      "Epoch 2654, Loss: 9.43758204812184e-05, Final Batch Loss: 4.5763390517095104e-05\n",
      "Epoch 2655, Loss: 0.0004751682499772869, Final Batch Loss: 0.0003778454556595534\n",
      "Epoch 2656, Loss: 0.0002843936163117178, Final Batch Loss: 0.0001918653870234266\n",
      "Epoch 2657, Loss: 0.00025706579526740825, Final Batch Loss: 1.2777293704857584e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2658, Loss: 0.00013849800961907022, Final Batch Loss: 4.720894867205061e-05\n",
      "Epoch 2659, Loss: 0.0001619807917450089, Final Batch Loss: 0.00014267412188928574\n",
      "Epoch 2660, Loss: 8.375456127396319e-05, Final Batch Loss: 2.850457349268254e-05\n",
      "Epoch 2661, Loss: 0.00010367937284172513, Final Batch Loss: 2.945465166703798e-05\n",
      "Epoch 2662, Loss: 0.00015435995010193437, Final Batch Loss: 6.255828338908032e-05\n",
      "Epoch 2663, Loss: 9.637790753913578e-05, Final Batch Loss: 2.052174932032358e-05\n",
      "Epoch 2664, Loss: 0.00022898277529748157, Final Batch Loss: 8.48320996738039e-05\n",
      "Epoch 2665, Loss: 0.0002443053508613957, Final Batch Loss: 2.06472886929987e-05\n",
      "Epoch 2666, Loss: 0.0003013116329384502, Final Batch Loss: 4.682293729274534e-05\n",
      "Epoch 2667, Loss: 0.0003068547957809642, Final Batch Loss: 0.00017014096374623477\n",
      "Epoch 2668, Loss: 0.0003688435535877943, Final Batch Loss: 0.0001863468496594578\n",
      "Epoch 2669, Loss: 9.509730261925142e-05, Final Batch Loss: 1.2639049600693397e-05\n",
      "Epoch 2670, Loss: 0.013893369934521616, Final Batch Loss: 0.013807473704218864\n",
      "Epoch 2671, Loss: 0.00013824943380313925, Final Batch Loss: 4.951409573550336e-05\n",
      "Epoch 2672, Loss: 0.0001499896025052294, Final Batch Loss: 0.00010330924123991281\n",
      "Epoch 2673, Loss: 0.0020988559790566796, Final Batch Loss: 2.9264900149428286e-05\n",
      "Epoch 2674, Loss: 0.00028518108592834324, Final Batch Loss: 9.005474566947669e-05\n",
      "Epoch 2675, Loss: 0.00012534670440800255, Final Batch Loss: 1.461050760553917e-05\n",
      "Epoch 2676, Loss: 8.391139090235811e-05, Final Batch Loss: 2.7602576665231027e-05\n",
      "Epoch 2677, Loss: 0.0027097260863229167, Final Batch Loss: 5.857458381797187e-05\n",
      "Epoch 2678, Loss: 8.556421744287945e-05, Final Batch Loss: 6.771263724658638e-05\n",
      "Epoch 2679, Loss: 0.0002683662751223892, Final Batch Loss: 7.941111107356846e-05\n",
      "Epoch 2680, Loss: 0.0005093729560030624, Final Batch Loss: 0.00014450128946918994\n",
      "Epoch 2681, Loss: 0.0008571592625230551, Final Batch Loss: 0.0003348941681906581\n",
      "Epoch 2682, Loss: 0.000514062303409446, Final Batch Loss: 0.00044917146442458034\n",
      "Epoch 2683, Loss: 0.0003862155135720968, Final Batch Loss: 0.0002778326452244073\n",
      "Epoch 2684, Loss: 0.0006790025945520028, Final Batch Loss: 0.0005162279703654349\n",
      "Epoch 2685, Loss: 0.00040091361734084785, Final Batch Loss: 0.00028102161013521254\n",
      "Epoch 2686, Loss: 0.00022895492656971328, Final Batch Loss: 4.4456373871071264e-05\n",
      "Epoch 2687, Loss: 0.00025394450858584605, Final Batch Loss: 3.700644811033271e-05\n",
      "Epoch 2688, Loss: 0.0003663406678242609, Final Batch Loss: 0.00022915360750630498\n",
      "Epoch 2689, Loss: 0.0021563811096712016, Final Batch Loss: 1.1632997484412044e-05\n",
      "Epoch 2690, Loss: 0.0002177729838876985, Final Batch Loss: 0.0001477766636526212\n",
      "Epoch 2691, Loss: 0.0001670249694143422, Final Batch Loss: 6.661121733486652e-05\n",
      "Epoch 2692, Loss: 7.45089473639382e-05, Final Batch Loss: 4.7361329052364454e-05\n",
      "Epoch 2693, Loss: 0.00014823895617155358, Final Batch Loss: 8.153916132869199e-05\n",
      "Epoch 2694, Loss: 0.00043971567356493324, Final Batch Loss: 0.00037166092079132795\n",
      "Epoch 2695, Loss: 0.00013332990783965215, Final Batch Loss: 9.209893323713914e-05\n",
      "Epoch 2696, Loss: 0.0002943828876595944, Final Batch Loss: 0.00018122942128684372\n",
      "Epoch 2697, Loss: 0.00022412049111153465, Final Batch Loss: 1.7567404938745312e-05\n",
      "Epoch 2698, Loss: 0.0002844360569724813, Final Batch Loss: 4.8556888941675425e-05\n",
      "Epoch 2699, Loss: 0.0001990646487683989, Final Batch Loss: 7.240725244628266e-05\n",
      "Epoch 2700, Loss: 0.00014818281852058135, Final Batch Loss: 2.1715033653890714e-05\n",
      "Epoch 2701, Loss: 0.00027615088038146496, Final Batch Loss: 0.00022425658244173974\n",
      "Epoch 2702, Loss: 0.00020625180695788004, Final Batch Loss: 2.0885363483102992e-05\n",
      "Epoch 2703, Loss: 0.00023751898970658658, Final Batch Loss: 1.068503024725942e-05\n",
      "Epoch 2704, Loss: 0.00017117350762418937, Final Batch Loss: 2.698378921195399e-05\n",
      "Epoch 2705, Loss: 0.0001138586721936008, Final Batch Loss: 1.9945893654949032e-05\n",
      "Epoch 2706, Loss: 0.0017693859263090417, Final Batch Loss: 1.746560155879706e-05\n",
      "Epoch 2707, Loss: 0.00011182101661688648, Final Batch Loss: 5.893599154660478e-05\n",
      "Epoch 2708, Loss: 0.00016050567137426697, Final Batch Loss: 3.409049168112688e-05\n",
      "Epoch 2709, Loss: 0.0002945246123999823, Final Batch Loss: 0.00025676851510070264\n",
      "Epoch 2710, Loss: 0.0007089196406013798, Final Batch Loss: 0.0006599811604246497\n",
      "Epoch 2711, Loss: 9.706454875413328e-05, Final Batch Loss: 5.167452763998881e-05\n",
      "Epoch 2712, Loss: 9.213616431225091e-05, Final Batch Loss: 3.31711744365748e-05\n",
      "Epoch 2713, Loss: 0.00040750431799096987, Final Batch Loss: 0.00010100038343807682\n",
      "Epoch 2714, Loss: 0.00020436236081877723, Final Batch Loss: 0.00014050085155759007\n",
      "Epoch 2715, Loss: 9.783837958821096e-05, Final Batch Loss: 4.207532401778735e-05\n",
      "Epoch 2716, Loss: 0.00014054225903237239, Final Batch Loss: 3.640769864432514e-05\n",
      "Epoch 2717, Loss: 7.762519089737907e-05, Final Batch Loss: 3.0554849217878655e-05\n",
      "Epoch 2718, Loss: 0.004822793973289663, Final Batch Loss: 0.004764482844620943\n",
      "Epoch 2719, Loss: 9.446321928407997e-05, Final Batch Loss: 3.879058567690663e-05\n",
      "Epoch 2720, Loss: 0.00463139029670856, Final Batch Loss: 0.004598062019795179\n",
      "Epoch 2721, Loss: 0.00023377672187052667, Final Batch Loss: 9.636048343963921e-05\n",
      "Epoch 2722, Loss: 0.002714899033890106, Final Batch Loss: 0.00017806178948376328\n",
      "Epoch 2723, Loss: 0.00013679298353963532, Final Batch Loss: 9.550725371809676e-05\n",
      "Epoch 2724, Loss: 0.00037687674557673745, Final Batch Loss: 4.284277019905858e-05\n",
      "Epoch 2725, Loss: 0.0005917028247495182, Final Batch Loss: 0.0005196855054236948\n",
      "Epoch 2726, Loss: 0.002320661913472577, Final Batch Loss: 1.6327487173839472e-05\n",
      "Epoch 2727, Loss: 9.851978393271565e-05, Final Batch Loss: 1.2897835404146463e-05\n",
      "Epoch 2728, Loss: 5.982666880299803e-05, Final Batch Loss: 2.0241886886651628e-05\n",
      "Epoch 2729, Loss: 0.0007975520347827114, Final Batch Loss: 0.0007177259540185332\n",
      "Epoch 2730, Loss: 9.989655154640786e-05, Final Batch Loss: 4.338229700806551e-05\n",
      "Epoch 2731, Loss: 7.624365753144957e-05, Final Batch Loss: 1.6926933312788606e-05\n",
      "Epoch 2732, Loss: 0.00010239223047392443, Final Batch Loss: 5.127626718604006e-05\n",
      "Epoch 2733, Loss: 7.760970765957609e-05, Final Batch Loss: 3.4531087294453755e-05\n",
      "Epoch 2734, Loss: 0.0006208543745742645, Final Batch Loss: 4.745093974634074e-05\n",
      "Epoch 2735, Loss: 0.005909064158913679, Final Batch Loss: 0.005873583257198334\n",
      "Epoch 2736, Loss: 0.0003430385168030625, Final Batch Loss: 0.00031749578192830086\n",
      "Epoch 2737, Loss: 0.00011233786426601, Final Batch Loss: 8.535604138160124e-05\n",
      "Epoch 2738, Loss: 0.00035275245318189263, Final Batch Loss: 0.0001538241485832259\n",
      "Epoch 2739, Loss: 0.0004815956635866314, Final Batch Loss: 0.0002608820504974574\n",
      "Epoch 2740, Loss: 0.00015100199016160332, Final Batch Loss: 9.454433165956289e-05\n",
      "Epoch 2741, Loss: 0.0020600476818799507, Final Batch Loss: 5.927947859163396e-05\n",
      "Epoch 2742, Loss: 8.999499914352782e-05, Final Batch Loss: 3.203808591933921e-05\n",
      "Epoch 2743, Loss: 0.0001970181256183423, Final Batch Loss: 0.00011113611253676936\n",
      "Epoch 2744, Loss: 8.951716154115275e-05, Final Batch Loss: 3.179844861733727e-05\n",
      "Epoch 2745, Loss: 0.0032485977571923286, Final Batch Loss: 0.00022658149828203022\n",
      "Epoch 2746, Loss: 6.989182293182239e-05, Final Batch Loss: 3.494311749818735e-05\n",
      "Epoch 2747, Loss: 0.0002726403472479433, Final Batch Loss: 0.00025226216530427337\n",
      "Epoch 2748, Loss: 0.0002171350333810551, Final Batch Loss: 1.69443210324971e-05\n",
      "Epoch 2749, Loss: 0.00010409814422018826, Final Batch Loss: 8.373308810405433e-05\n",
      "Epoch 2750, Loss: 0.006249377911444753, Final Batch Loss: 0.0003335521905682981\n",
      "Epoch 2751, Loss: 0.00020542199581541354, Final Batch Loss: 1.176470050268108e-05\n",
      "Epoch 2752, Loss: 0.00041991697798948735, Final Batch Loss: 0.00013785467308480293\n",
      "Epoch 2753, Loss: 0.00016068511831690557, Final Batch Loss: 0.0001262500009033829\n",
      "Epoch 2754, Loss: 0.01322014507240965, Final Batch Loss: 5.5552165576955304e-05\n",
      "Epoch 2755, Loss: 0.00011712469495250843, Final Batch Loss: 5.585187682299875e-05\n",
      "Epoch 2756, Loss: 0.00035466140434436966, Final Batch Loss: 0.00032661916338838637\n",
      "Epoch 2757, Loss: 0.00012131719631724991, Final Batch Loss: 8.087044989224523e-05\n",
      "Epoch 2758, Loss: 0.008263528474344639, Final Batch Loss: 2.3703218175796792e-05\n",
      "Epoch 2759, Loss: 0.0024261075668619014, Final Batch Loss: 9.511659300187603e-05\n",
      "Epoch 2760, Loss: 9.40396093938034e-05, Final Batch Loss: 6.787427264498547e-05\n",
      "Epoch 2761, Loss: 0.0003628411977842916, Final Batch Loss: 4.0616596379550174e-05\n",
      "Epoch 2762, Loss: 6.275517444009893e-05, Final Batch Loss: 1.9856634025927633e-05\n",
      "Epoch 2763, Loss: 0.005475018610013649, Final Batch Loss: 0.005235475022345781\n",
      "Epoch 2764, Loss: 0.00010535054389038123, Final Batch Loss: 5.6724169553490356e-05\n",
      "Epoch 2765, Loss: 0.0001120513607020257, Final Batch Loss: 3.949904566979967e-06\n",
      "Epoch 2766, Loss: 0.0001316220332228113, Final Batch Loss: 0.00010080639185616747\n",
      "Epoch 2767, Loss: 0.00011987884681730065, Final Batch Loss: 0.00010077759361593053\n",
      "Epoch 2768, Loss: 0.00019762414376600645, Final Batch Loss: 0.0001514795294497162\n",
      "Epoch 2769, Loss: 6.64255530864466e-05, Final Batch Loss: 2.9822142096236348e-05\n",
      "Epoch 2770, Loss: 0.008180281474778894, Final Batch Loss: 3.4015953133348376e-05\n",
      "Epoch 2771, Loss: 0.0001532708411104977, Final Batch Loss: 8.507909660693258e-05\n",
      "Epoch 2772, Loss: 0.0043301606783643365, Final Batch Loss: 0.004248177632689476\n",
      "Epoch 2773, Loss: 0.00021553230908466503, Final Batch Loss: 6.605753878830001e-05\n",
      "Epoch 2774, Loss: 0.0003988499956903979, Final Batch Loss: 0.0002564445312600583\n",
      "Epoch 2775, Loss: 0.00030278060785349226, Final Batch Loss: 1.2367308045213576e-05\n",
      "Epoch 2776, Loss: 0.002999196916789515, Final Batch Loss: 3.4244654671056196e-05\n",
      "Epoch 2777, Loss: 8.528313810529653e-05, Final Batch Loss: 1.9702305507962592e-05\n",
      "Epoch 2778, Loss: 0.00010782195386127569, Final Batch Loss: 7.092128362273797e-05\n",
      "Epoch 2779, Loss: 6.340346681099618e-05, Final Batch Loss: 4.787872057931963e-06\n",
      "Epoch 2780, Loss: 0.0004009089316241443, Final Batch Loss: 0.00020416142069734633\n",
      "Epoch 2781, Loss: 0.0001418118190485984, Final Batch Loss: 3.743451816262677e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2782, Loss: 0.00027930632495554164, Final Batch Loss: 0.0002456478541716933\n",
      "Epoch 2783, Loss: 0.0070329883601516485, Final Batch Loss: 0.002268217271193862\n",
      "Epoch 2784, Loss: 0.0027651609198073857, Final Batch Loss: 2.5009903765749186e-05\n",
      "Epoch 2785, Loss: 0.00019495926244417205, Final Batch Loss: 9.247700654668733e-05\n",
      "Epoch 2786, Loss: 0.00022966997494222596, Final Batch Loss: 0.00016216488438658416\n",
      "Epoch 2787, Loss: 0.0006297984655248001, Final Batch Loss: 0.00038723842590115964\n",
      "Epoch 2788, Loss: 0.00011130119310109876, Final Batch Loss: 6.265523552428931e-05\n",
      "Epoch 2789, Loss: 0.0011741799826268107, Final Batch Loss: 0.0008752400754019618\n",
      "Epoch 2790, Loss: 0.00027170639077667147, Final Batch Loss: 0.00012757112563122064\n",
      "Epoch 2791, Loss: 0.0022937255416763946, Final Batch Loss: 6.019328429829329e-05\n",
      "Epoch 2792, Loss: 8.057822560658678e-05, Final Batch Loss: 3.4482825867598876e-05\n",
      "Epoch 2793, Loss: 0.00010633571491780458, Final Batch Loss: 4.562013600661885e-06\n",
      "Epoch 2794, Loss: 0.00028230481439095456, Final Batch Loss: 2.050773946393747e-05\n",
      "Epoch 2795, Loss: 0.00023334022262133658, Final Batch Loss: 0.00010977029160130769\n",
      "Epoch 2796, Loss: 0.00016023454736568965, Final Batch Loss: 3.151220516883768e-05\n",
      "Epoch 2797, Loss: 0.0001757159989210777, Final Batch Loss: 0.00011280659964540973\n",
      "Epoch 2798, Loss: 0.00014140359053271823, Final Batch Loss: 8.058109233388677e-05\n",
      "Epoch 2799, Loss: 0.00010349359035899397, Final Batch Loss: 1.9072582290391438e-05\n",
      "Epoch 2800, Loss: 7.895239468780346e-05, Final Batch Loss: 4.4680560677079484e-05\n",
      "Epoch 2801, Loss: 0.00033960980363190174, Final Batch Loss: 0.0002466119476594031\n",
      "Epoch 2802, Loss: 0.0001662749818933662, Final Batch Loss: 0.00013412236876320094\n",
      "Epoch 2803, Loss: 0.00011863262625411153, Final Batch Loss: 3.8402300560846925e-05\n",
      "Epoch 2804, Loss: 0.00013530354044632986, Final Batch Loss: 4.3083869968540967e-05\n",
      "Epoch 2805, Loss: 0.0001674560844548978, Final Batch Loss: 0.00010924813250312582\n",
      "Epoch 2806, Loss: 0.002458031609421596, Final Batch Loss: 0.00013914014562033117\n",
      "Epoch 2807, Loss: 0.002584508438303601, Final Batch Loss: 7.713870581937954e-05\n",
      "Epoch 2808, Loss: 0.00024194613615691196, Final Batch Loss: 2.017673796217423e-05\n",
      "Epoch 2809, Loss: 0.00018129617092199624, Final Batch Loss: 0.0001380551839247346\n",
      "Epoch 2810, Loss: 0.0003360632254043594, Final Batch Loss: 0.0002480560215190053\n",
      "Epoch 2811, Loss: 0.0004871238343184814, Final Batch Loss: 0.0002519178669899702\n",
      "Epoch 2812, Loss: 8.254953718278557e-05, Final Batch Loss: 3.580807242542505e-05\n",
      "Epoch 2813, Loss: 0.001915552536956966, Final Batch Loss: 0.00016728939954191446\n",
      "Epoch 2814, Loss: 0.00010512204971746542, Final Batch Loss: 4.617996091837995e-05\n",
      "Epoch 2815, Loss: 0.00016539912758162245, Final Batch Loss: 6.687489076284692e-05\n",
      "Epoch 2816, Loss: 0.0001895407694973983, Final Batch Loss: 0.00016988611605484039\n",
      "Epoch 2817, Loss: 0.0002932037605205551, Final Batch Loss: 0.00024961685994639993\n",
      "Epoch 2818, Loss: 0.00010090917635352525, Final Batch Loss: 3.416430217839661e-06\n",
      "Epoch 2819, Loss: 8.925041402108036e-05, Final Batch Loss: 2.2503973013954237e-05\n",
      "Epoch 2820, Loss: 5.6085922551574185e-05, Final Batch Loss: 2.9647148039657623e-05\n",
      "Epoch 2821, Loss: 0.00014516442479362013, Final Batch Loss: 1.1859684491355438e-05\n",
      "Epoch 2822, Loss: 0.0002467981175868772, Final Batch Loss: 0.00017772296268958598\n",
      "Epoch 2823, Loss: 7.778940562275238e-05, Final Batch Loss: 3.761550033232197e-05\n",
      "Epoch 2824, Loss: 0.0001512295457359869, Final Batch Loss: 0.00010997197387041524\n",
      "Epoch 2825, Loss: 0.002435386682918761, Final Batch Loss: 6.795422086725011e-05\n",
      "Epoch 2826, Loss: 0.00014345272575155832, Final Batch Loss: 8.749494736548513e-05\n",
      "Epoch 2827, Loss: 0.0001784901978680864, Final Batch Loss: 8.792612788965926e-05\n",
      "Epoch 2828, Loss: 8.850780432112515e-05, Final Batch Loss: 3.1049879908096045e-05\n",
      "Epoch 2829, Loss: 0.00024250801652669907, Final Batch Loss: 0.00016845925711095333\n",
      "Epoch 2830, Loss: 9.197414328809828e-05, Final Batch Loss: 5.549084744416177e-05\n",
      "Epoch 2831, Loss: 0.00010624339483911172, Final Batch Loss: 2.5740017008502036e-05\n",
      "Epoch 2832, Loss: 0.002591619828308467, Final Batch Loss: 1.0700059647206217e-05\n",
      "Epoch 2833, Loss: 0.00015585786604788154, Final Batch Loss: 0.00011701085895765573\n",
      "Epoch 2834, Loss: 0.00012692117525148205, Final Batch Loss: 9.451061487197876e-05\n",
      "Epoch 2835, Loss: 0.00011654131958493963, Final Batch Loss: 3.391665086383e-05\n",
      "Epoch 2836, Loss: 0.004200507319183089, Final Batch Loss: 0.0041000572964549065\n",
      "Epoch 2837, Loss: 0.00029120791441528127, Final Batch Loss: 0.0002482461277395487\n",
      "Epoch 2838, Loss: 0.002254965266729414, Final Batch Loss: 9.91976685327245e-06\n",
      "Epoch 2839, Loss: 4.810372047359124e-05, Final Batch Loss: 2.387243694101926e-05\n",
      "Epoch 2840, Loss: 0.0042031994089484215, Final Batch Loss: 0.0011447593569755554\n",
      "Epoch 2841, Loss: 4.683852966991253e-05, Final Batch Loss: 3.299681338830851e-05\n",
      "Epoch 2842, Loss: 0.00013061520076007582, Final Batch Loss: 7.901265780674294e-05\n",
      "Epoch 2843, Loss: 4.40367675764719e-05, Final Batch Loss: 2.387684980931226e-05\n",
      "Epoch 2844, Loss: 0.00010343217218178324, Final Batch Loss: 7.044921221677214e-05\n",
      "Epoch 2845, Loss: 0.0001345085838693194, Final Batch Loss: 6.305145507212728e-05\n",
      "Epoch 2846, Loss: 6.711005153192673e-05, Final Batch Loss: 1.6327792764059268e-05\n",
      "Epoch 2847, Loss: 0.0002635273012856487, Final Batch Loss: 1.496883123763837e-05\n",
      "Epoch 2848, Loss: 5.219718332227785e-05, Final Batch Loss: 3.07400623569265e-05\n",
      "Epoch 2849, Loss: 0.01140785678580869, Final Batch Loss: 0.011326674371957779\n",
      "Epoch 2850, Loss: 0.006952984171221033, Final Batch Loss: 0.006929504685103893\n",
      "Epoch 2851, Loss: 6.133922170192818e-05, Final Batch Loss: 4.22171387981507e-06\n",
      "Epoch 2852, Loss: 0.0002625121996970847, Final Batch Loss: 0.00018108836957253516\n",
      "Epoch 2853, Loss: 0.004354090793640353, Final Batch Loss: 0.004284308757632971\n",
      "Epoch 2854, Loss: 0.00017495201245765202, Final Batch Loss: 3.655258842627518e-05\n",
      "Epoch 2855, Loss: 8.982608414953575e-05, Final Batch Loss: 3.0022805731277913e-05\n",
      "Epoch 2856, Loss: 8.117860488709994e-05, Final Batch Loss: 6.859371933387592e-05\n",
      "Epoch 2857, Loss: 5.883475205337163e-05, Final Batch Loss: 2.4613911591586657e-05\n",
      "Epoch 2858, Loss: 0.0003446204386818863, Final Batch Loss: 2.982360001624329e-06\n",
      "Epoch 2859, Loss: 0.0002027843329415191, Final Batch Loss: 5.9150992456125095e-05\n",
      "Epoch 2860, Loss: 9.19985250220634e-05, Final Batch Loss: 4.005899972980842e-05\n",
      "Epoch 2861, Loss: 0.0006566555020981468, Final Batch Loss: 3.5250828659627587e-05\n",
      "Epoch 2862, Loss: 0.0009946567261067685, Final Batch Loss: 0.0009438067791052163\n",
      "Epoch 2863, Loss: 5.4867853123141686e-05, Final Batch Loss: 5.411703114077682e-06\n",
      "Epoch 2864, Loss: 0.0005512919742614031, Final Batch Loss: 0.0004387499939184636\n",
      "Epoch 2865, Loss: 0.0009679890790721402, Final Batch Loss: 8.389164577238262e-06\n",
      "Epoch 2866, Loss: 5.558359862334328e-05, Final Batch Loss: 1.2119538041588385e-05\n",
      "Epoch 2867, Loss: 0.0003017677299794741, Final Batch Loss: 0.00025330271455459297\n",
      "Epoch 2868, Loss: 0.0004431574634509161, Final Batch Loss: 0.00023126527958083898\n",
      "Epoch 2869, Loss: 0.00032797846506582573, Final Batch Loss: 0.0002942891151178628\n",
      "Epoch 2870, Loss: 0.0002289884887431981, Final Batch Loss: 6.9746911321999505e-06\n",
      "Epoch 2871, Loss: 8.229862214648165e-05, Final Batch Loss: 3.45328044204507e-05\n",
      "Epoch 2872, Loss: 0.00015142046322580427, Final Batch Loss: 6.211666914168745e-05\n",
      "Epoch 2873, Loss: 0.00036718097544508055, Final Batch Loss: 0.00032782272319309413\n",
      "Epoch 2874, Loss: 0.00019046117949983454, Final Batch Loss: 4.3433769860712346e-06\n",
      "Epoch 2875, Loss: 0.00024209357798099518, Final Batch Loss: 0.00020610129286069423\n",
      "Epoch 2876, Loss: 0.0027874581628566375, Final Batch Loss: 1.7010990632115863e-05\n",
      "Epoch 2877, Loss: 0.007730496348813176, Final Batch Loss: 0.006491341162472963\n",
      "Epoch 2878, Loss: 7.54504362703301e-05, Final Batch Loss: 9.106362995225936e-06\n",
      "Epoch 2879, Loss: 0.00010109546110470546, Final Batch Loss: 9.307316940976307e-05\n",
      "Epoch 2880, Loss: 9.584412327967584e-05, Final Batch Loss: 3.451114025665447e-05\n",
      "Epoch 2881, Loss: 0.0020860905860899948, Final Batch Loss: 9.302116086473688e-05\n",
      "Epoch 2882, Loss: 0.0002832079408108257, Final Batch Loss: 0.00022348940547090024\n",
      "Epoch 2883, Loss: 0.0001607769627298694, Final Batch Loss: 0.00011320038174744695\n",
      "Epoch 2884, Loss: 0.0002208427613368258, Final Batch Loss: 0.00010426624794490635\n",
      "Epoch 2885, Loss: 5.133025888426346e-05, Final Batch Loss: 6.600043434445979e-06\n",
      "Epoch 2886, Loss: 0.00018397789244772866, Final Batch Loss: 6.909591320436448e-05\n",
      "Epoch 2887, Loss: 0.00027515475085237995, Final Batch Loss: 0.00017004959227051586\n",
      "Epoch 2888, Loss: 0.004673508708947338, Final Batch Loss: 0.004604460671544075\n",
      "Epoch 2889, Loss: 0.00019458578753983602, Final Batch Loss: 6.294249760685489e-05\n",
      "Epoch 2890, Loss: 5.671725602951483e-05, Final Batch Loss: 5.025854625273496e-05\n",
      "Epoch 2891, Loss: 6.368932099576341e-05, Final Batch Loss: 1.3587015018856619e-05\n",
      "Epoch 2892, Loss: 0.0003330875333631411, Final Batch Loss: 0.00012999835598748177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2893, Loss: 8.829395574139198e-05, Final Batch Loss: 1.3771473277301993e-05\n",
      "Epoch 2894, Loss: 0.00015834387886570767, Final Batch Loss: 0.00012336565123405308\n",
      "Epoch 2895, Loss: 0.0001508989735157229, Final Batch Loss: 2.9485643608495593e-05\n",
      "Epoch 2896, Loss: 0.00010767399726319127, Final Batch Loss: 3.073253537877463e-05\n",
      "Epoch 2897, Loss: 7.958723472256679e-05, Final Batch Loss: 5.20128924108576e-05\n",
      "Epoch 2898, Loss: 5.687859629688319e-05, Final Batch Loss: 1.01594105217373e-05\n",
      "Epoch 2899, Loss: 0.00016574165420024656, Final Batch Loss: 4.342505053500645e-05\n",
      "Epoch 2900, Loss: 9.46089221542934e-05, Final Batch Loss: 2.9035358238616027e-05\n",
      "Epoch 2901, Loss: 0.00018929124235000927, Final Batch Loss: 0.0001661476562730968\n",
      "Epoch 2902, Loss: 0.00014529829059028998, Final Batch Loss: 8.52588054840453e-05\n",
      "Epoch 2903, Loss: 0.00028296373784542084, Final Batch Loss: 0.00015751717728562653\n",
      "Epoch 2904, Loss: 5.6113001164703746e-05, Final Batch Loss: 3.0831226922600763e-06\n",
      "Epoch 2905, Loss: 0.0018346955148444977, Final Batch Loss: 1.3246721209725365e-05\n",
      "Epoch 2906, Loss: 0.005486629881488625, Final Batch Loss: 0.005440745037049055\n",
      "Epoch 2907, Loss: 5.079622224002378e-05, Final Batch Loss: 6.404378837032709e-06\n",
      "Epoch 2908, Loss: 0.00011807787450379692, Final Batch Loss: 4.3205171095905825e-05\n",
      "Epoch 2909, Loss: 0.006276099244132638, Final Batch Loss: 0.004045094829052687\n",
      "Epoch 2910, Loss: 8.41134569782298e-05, Final Batch Loss: 4.915129466098733e-05\n",
      "Epoch 2911, Loss: 0.0005312248467816971, Final Batch Loss: 0.0001024909652187489\n",
      "Epoch 2912, Loss: 0.00024485437097609974, Final Batch Loss: 5.0434526201570407e-05\n",
      "Epoch 2913, Loss: 0.004484791774302721, Final Batch Loss: 0.0006261651869863272\n",
      "Epoch 2914, Loss: 0.0026219572173431516, Final Batch Loss: 0.00017715117428451777\n",
      "Epoch 2915, Loss: 7.759590516798198e-05, Final Batch Loss: 1.1498646927066147e-05\n",
      "Epoch 2916, Loss: 0.0002290023330715485, Final Batch Loss: 7.152680336730555e-05\n",
      "Epoch 2917, Loss: 0.0015892750752755092, Final Batch Loss: 1.5155056644289289e-05\n",
      "Epoch 2918, Loss: 0.0047060246870387346, Final Batch Loss: 0.004639325197786093\n",
      "Epoch 2919, Loss: 0.000360891135642305, Final Batch Loss: 0.00021920062135905027\n",
      "Epoch 2920, Loss: 0.00037775299279019237, Final Batch Loss: 0.00019863329362124205\n",
      "Epoch 2921, Loss: 0.0014762671889911871, Final Batch Loss: 0.0014235953567549586\n",
      "Epoch 2922, Loss: 0.00020584567391779274, Final Batch Loss: 7.064772944431752e-05\n",
      "Epoch 2923, Loss: 4.9819931973615894e-05, Final Batch Loss: 6.9769143919984344e-06\n",
      "Epoch 2924, Loss: 0.0008321415753016481, Final Batch Loss: 9.528035661787726e-06\n",
      "Epoch 2925, Loss: 0.005247219381999457, Final Batch Loss: 0.0052146813832223415\n",
      "Epoch 2926, Loss: 0.0004920597275486216, Final Batch Loss: 0.00027289066929370165\n",
      "Epoch 2927, Loss: 9.506816240900662e-05, Final Batch Loss: 1.164939567388501e-05\n",
      "Epoch 2928, Loss: 0.00013473923172568902, Final Batch Loss: 0.0001124245609389618\n",
      "Epoch 2929, Loss: 7.048574298096355e-05, Final Batch Loss: 4.4620777771342546e-05\n",
      "Epoch 2930, Loss: 0.002288818819579319, Final Batch Loss: 1.8098386135534383e-05\n",
      "Epoch 2931, Loss: 0.0001583903795108199, Final Batch Loss: 8.272138074971735e-05\n",
      "Epoch 2932, Loss: 0.00014360647764988244, Final Batch Loss: 9.625534585211426e-05\n",
      "Epoch 2933, Loss: 0.00013559846229327377, Final Batch Loss: 1.8688193449634127e-05\n",
      "Epoch 2934, Loss: 0.00136793966521509, Final Batch Loss: 0.0012804241850972176\n",
      "Epoch 2935, Loss: 8.035026985453442e-05, Final Batch Loss: 3.4862037864513695e-05\n",
      "Epoch 2936, Loss: 0.00015378763055196032, Final Batch Loss: 3.816271782852709e-05\n",
      "Epoch 2937, Loss: 5.1111902848788304e-05, Final Batch Loss: 6.177254817885114e-06\n",
      "Epoch 2938, Loss: 4.720924061984988e-05, Final Batch Loss: 5.9218773458269425e-06\n",
      "Epoch 2939, Loss: 1.1504009080454125e-05, Final Batch Loss: 1.4281756648415467e-06\n",
      "Epoch 2940, Loss: 0.0001084391878976021, Final Batch Loss: 8.3431790699251e-05\n",
      "Epoch 2941, Loss: 0.0003498685036902316, Final Batch Loss: 0.0002549251657910645\n",
      "Epoch 2942, Loss: 0.0005999749773764051, Final Batch Loss: 0.0004975066403858364\n",
      "Epoch 2943, Loss: 0.00012922286805405747, Final Batch Loss: 8.140848876792006e-06\n",
      "Epoch 2944, Loss: 0.00015435522436746396, Final Batch Loss: 4.9969650717685e-05\n",
      "Epoch 2945, Loss: 2.571903314674273e-05, Final Batch Loss: 8.488465027767234e-06\n",
      "Epoch 2946, Loss: 0.00044377593440003693, Final Batch Loss: 0.00010699289850890636\n",
      "Epoch 2947, Loss: 0.017225287345354445, Final Batch Loss: 0.017066538333892822\n",
      "Epoch 2948, Loss: 0.00010902985104621621, Final Batch Loss: 1.3176632819522638e-05\n",
      "Epoch 2949, Loss: 0.001960174782652757, Final Batch Loss: 2.880233478208538e-05\n",
      "Epoch 2950, Loss: 0.00047880008423817344, Final Batch Loss: 5.910678373766132e-05\n",
      "Epoch 2951, Loss: 0.00027633549325400963, Final Batch Loss: 0.00018656911561265588\n",
      "Epoch 2952, Loss: 0.0006382739520631731, Final Batch Loss: 0.00035802958882413805\n",
      "Epoch 2953, Loss: 0.0005261838814476505, Final Batch Loss: 9.197667532134801e-05\n",
      "Epoch 2954, Loss: 0.002171701460611075, Final Batch Loss: 0.002033042488619685\n",
      "Epoch 2955, Loss: 0.001306723293964751, Final Batch Loss: 0.0011123836738988757\n",
      "Epoch 2956, Loss: 0.011079857697041007, Final Batch Loss: 4.442000135895796e-05\n",
      "Epoch 2957, Loss: 0.0003897348578902893, Final Batch Loss: 5.017787771066651e-05\n",
      "Epoch 2958, Loss: 0.005951268729404546, Final Batch Loss: 0.005784991197288036\n",
      "Epoch 2959, Loss: 0.000537270272616297, Final Batch Loss: 0.0003510783426463604\n",
      "Epoch 2960, Loss: 0.000346713000908494, Final Batch Loss: 0.00028291912167333066\n",
      "Epoch 2961, Loss: 7.452337194990832e-05, Final Batch Loss: 1.72065101651242e-05\n",
      "Epoch 2962, Loss: 0.0030114092223811895, Final Batch Loss: 0.0003228974819649011\n",
      "Epoch 2963, Loss: 0.00040560557681601495, Final Batch Loss: 0.0002909442991949618\n",
      "Epoch 2964, Loss: 0.00025597708190616686, Final Batch Loss: 2.687763662834186e-05\n",
      "Epoch 2965, Loss: 0.0001655216074141208, Final Batch Loss: 3.2074593036668375e-05\n",
      "Epoch 2966, Loss: 0.0004268495977157727, Final Batch Loss: 0.00021285467664711177\n",
      "Epoch 2967, Loss: 0.009135270025581121, Final Batch Loss: 0.006790759041905403\n",
      "Epoch 2968, Loss: 0.00014990142881288193, Final Batch Loss: 2.9215781978564337e-05\n",
      "Epoch 2969, Loss: 0.0026269768068232224, Final Batch Loss: 1.4774611372558866e-05\n",
      "Epoch 2970, Loss: 0.001296786740567768, Final Batch Loss: 0.0012681902153417468\n",
      "Epoch 2971, Loss: 0.0012731172027997673, Final Batch Loss: 0.000286391528788954\n",
      "Epoch 2972, Loss: 0.00010072250915982295, Final Batch Loss: 2.0134213627898134e-05\n",
      "Epoch 2973, Loss: 0.051664120921486756, Final Batch Loss: 0.05160802975296974\n",
      "Epoch 2974, Loss: 0.00017510890666017076, Final Batch Loss: 1.2132287338317838e-05\n",
      "Epoch 2975, Loss: 0.0018009598716162145, Final Batch Loss: 0.0012066590134054422\n",
      "Epoch 2976, Loss: 0.0006197224574862048, Final Batch Loss: 0.00037961130146868527\n",
      "Epoch 2977, Loss: 0.005929472856223583, Final Batch Loss: 0.002597565995529294\n",
      "Epoch 2978, Loss: 0.010651980788679793, Final Batch Loss: 0.0002803665411192924\n",
      "Epoch 2979, Loss: 0.0003311412292532623, Final Batch Loss: 0.0002037256199400872\n",
      "Epoch 2980, Loss: 0.0010596761421766132, Final Batch Loss: 0.0008247131481766701\n",
      "Epoch 2981, Loss: 0.04574299130763393, Final Batch Loss: 0.04561265558004379\n",
      "Epoch 2982, Loss: 0.00035000047864741646, Final Batch Loss: 9.187784598907456e-06\n",
      "Epoch 2983, Loss: 4.0453145857100026e-05, Final Batch Loss: 1.4964282399887452e-06\n",
      "Epoch 2984, Loss: 0.0001119801581808133, Final Batch Loss: 8.19681808934547e-05\n",
      "Epoch 2985, Loss: 0.00044291754875303013, Final Batch Loss: 8.979844096757006e-06\n",
      "Epoch 2986, Loss: 0.00037729822724941187, Final Batch Loss: 6.006510739098303e-05\n",
      "Epoch 2987, Loss: 0.00016285352467093617, Final Batch Loss: 2.4434804799966514e-05\n",
      "Epoch 2988, Loss: 0.0010250818158965558, Final Batch Loss: 0.0004841464979108423\n",
      "Epoch 2989, Loss: 0.028373959270538762, Final Batch Loss: 0.02808850258588791\n",
      "Epoch 2990, Loss: 3.0428619538724888e-05, Final Batch Loss: 1.9549004719010554e-05\n",
      "Epoch 2991, Loss: 0.00012897917258669622, Final Batch Loss: 9.264107211492956e-05\n",
      "Epoch 2992, Loss: 0.0013049188710283488, Final Batch Loss: 0.001174596487544477\n",
      "Epoch 2993, Loss: 0.06475936807692051, Final Batch Loss: 0.05101817846298218\n",
      "Epoch 2994, Loss: 0.009011018446472008, Final Batch Loss: 5.247200169833377e-05\n",
      "Epoch 2995, Loss: 0.005032164881413337, Final Batch Loss: 0.004972582217305899\n",
      "Epoch 2996, Loss: 0.001981686735234689, Final Batch Loss: 4.918692138744518e-05\n",
      "Epoch 2997, Loss: 0.00021759260562248528, Final Batch Loss: 0.00012858660193160176\n",
      "Epoch 2998, Loss: 0.007627678889548406, Final Batch Loss: 0.0074007692746818066\n",
      "Epoch 2999, Loss: 0.0380524984539079, Final Batch Loss: 3.623133306973614e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3000, Loss: 0.04576074055330537, Final Batch Loss: 3.0272667572717182e-05\n",
      "Epoch 3001, Loss: 0.04269818795728497, Final Batch Loss: 0.04255806282162666\n",
      "Epoch 3002, Loss: 0.0004110174559173174, Final Batch Loss: 0.00011519777035573497\n",
      "Epoch 3003, Loss: 4.238215296936687e-05, Final Batch Loss: 1.986341885640286e-05\n",
      "Epoch 3004, Loss: 0.00020719213898701128, Final Batch Loss: 8.926004738896154e-06\n",
      "Epoch 3005, Loss: 0.00015851596253924072, Final Batch Loss: 8.685779175721109e-05\n",
      "Epoch 3006, Loss: 0.0002753549488261342, Final Batch Loss: 0.00012850180792156607\n",
      "Epoch 3007, Loss: 0.00027833334752358496, Final Batch Loss: 0.00015613817959092557\n",
      "Epoch 3008, Loss: 0.00045850902097299695, Final Batch Loss: 0.0003645126416813582\n",
      "Epoch 3009, Loss: 0.0003325129800941795, Final Batch Loss: 0.00010876866872422397\n",
      "Epoch 3010, Loss: 0.0009281693310185801, Final Batch Loss: 5.447984949569218e-05\n",
      "Epoch 3011, Loss: 0.0027953611133852974, Final Batch Loss: 0.002697751158848405\n",
      "Epoch 3012, Loss: 0.04752874281257391, Final Batch Loss: 0.04447596147656441\n",
      "Epoch 3013, Loss: 0.0002767620899248868, Final Batch Loss: 3.487651702016592e-05\n",
      "Epoch 3014, Loss: 0.000408340958529152, Final Batch Loss: 0.00019804618204943836\n",
      "Epoch 3015, Loss: 0.0001004974874376785, Final Batch Loss: 3.333260610816069e-05\n",
      "Epoch 3016, Loss: 0.0013048892724327743, Final Batch Loss: 0.00029916403582319617\n",
      "Epoch 3017, Loss: 0.0005137394455232425, Final Batch Loss: 2.0793433577637188e-05\n",
      "Epoch 3018, Loss: 0.010207413273747079, Final Batch Loss: 5.82081702305004e-05\n",
      "Epoch 3019, Loss: 0.007272062823176384, Final Batch Loss: 0.005891310982406139\n",
      "Epoch 3020, Loss: 0.0013185294810682535, Final Batch Loss: 0.0003712834441103041\n",
      "Epoch 3021, Loss: 0.009836376426392235, Final Batch Loss: 3.7827310734428465e-05\n",
      "Epoch 3022, Loss: 0.0069338250905275345, Final Batch Loss: 0.004482838790863752\n",
      "Epoch 3023, Loss: 0.0002459014649502933, Final Batch Loss: 0.00018425224698148668\n",
      "Epoch 3024, Loss: 0.004598077081027441, Final Batch Loss: 0.00444389833137393\n",
      "Epoch 3025, Loss: 0.0002647564688231796, Final Batch Loss: 4.453097062651068e-05\n",
      "Epoch 3026, Loss: 0.0003408652264624834, Final Batch Loss: 3.5048724384978414e-05\n",
      "Epoch 3027, Loss: 0.0040828934579622, Final Batch Loss: 0.00045519295963458717\n",
      "Epoch 3028, Loss: 0.0002616074780235067, Final Batch Loss: 0.00013368309009820223\n",
      "Epoch 3029, Loss: 0.01786982458725106, Final Batch Loss: 0.00014132265641819686\n",
      "Epoch 3030, Loss: 0.0006303519985522144, Final Batch Loss: 0.0005414214683696628\n",
      "Epoch 3031, Loss: 0.0002894157951232046, Final Batch Loss: 0.00016724209126550704\n",
      "Epoch 3032, Loss: 0.00035398431646171957, Final Batch Loss: 7.639334944542497e-05\n",
      "Epoch 3033, Loss: 0.00021655757154803723, Final Batch Loss: 8.0375190009363e-05\n",
      "Epoch 3034, Loss: 0.0012364009453449398, Final Batch Loss: 0.0007654707878828049\n",
      "Epoch 3035, Loss: 0.00017767143435776234, Final Batch Loss: 9.752970800036564e-05\n",
      "Epoch 3036, Loss: 0.00040086954686557874, Final Batch Loss: 0.0003389926569070667\n",
      "Epoch 3037, Loss: 0.00027641814267553855, Final Batch Loss: 0.00025518742040731013\n",
      "Epoch 3038, Loss: 0.005588965606875718, Final Batch Loss: 0.004936995450407267\n",
      "Epoch 3039, Loss: 0.00017012082389555871, Final Batch Loss: 6.22453007963486e-05\n",
      "Epoch 3040, Loss: 0.0003523053019307554, Final Batch Loss: 0.0001388243690598756\n",
      "Epoch 3041, Loss: 0.0009314377966802567, Final Batch Loss: 0.00026520874234847724\n",
      "Epoch 3042, Loss: 0.0001989693846553564, Final Batch Loss: 0.00011128637561341748\n",
      "Epoch 3043, Loss: 0.0008331281860591844, Final Batch Loss: 0.0005998955457471311\n",
      "Epoch 3044, Loss: 0.00017417089111404493, Final Batch Loss: 8.576997788622975e-05\n",
      "Epoch 3045, Loss: 0.00037822590820724145, Final Batch Loss: 6.1749953601975e-05\n",
      "Epoch 3046, Loss: 0.0006352078053168952, Final Batch Loss: 0.00031577792833559215\n",
      "Epoch 3047, Loss: 0.0008905298018362373, Final Batch Loss: 0.0003525878710206598\n",
      "Epoch 3048, Loss: 0.00045753085578326136, Final Batch Loss: 0.00033596003777347505\n",
      "Epoch 3049, Loss: 0.0002496722445357591, Final Batch Loss: 0.00018428250041324645\n",
      "Epoch 3050, Loss: 8.931888078222983e-05, Final Batch Loss: 4.075316246598959e-05\n",
      "Epoch 3051, Loss: 0.0005907907725486439, Final Batch Loss: 0.0005491838674061\n",
      "Epoch 3052, Loss: 0.025950804571039043, Final Batch Loss: 0.02577923983335495\n",
      "Epoch 3053, Loss: 0.00020499340462265536, Final Batch Loss: 0.00012706989946309477\n",
      "Epoch 3054, Loss: 0.00010904291048063897, Final Batch Loss: 4.8558464186498895e-05\n",
      "Epoch 3055, Loss: 0.024084603850496933, Final Batch Loss: 0.0001593907072674483\n",
      "Epoch 3056, Loss: 0.0005072181374998763, Final Batch Loss: 8.013744081836194e-05\n",
      "Epoch 3057, Loss: 0.0021419533586595207, Final Batch Loss: 2.5869725504890084e-05\n",
      "Epoch 3058, Loss: 8.091790732578374e-05, Final Batch Loss: 1.6910769772948697e-05\n",
      "Epoch 3059, Loss: 0.0027325572809786536, Final Batch Loss: 7.422644557664171e-05\n",
      "Epoch 3060, Loss: 0.0003574062866391614, Final Batch Loss: 0.00027157398290000856\n",
      "Epoch 3061, Loss: 0.00034504001087043434, Final Batch Loss: 0.00015607908426318318\n",
      "Epoch 3062, Loss: 9.55035247898195e-05, Final Batch Loss: 5.173139652470127e-05\n",
      "Epoch 3063, Loss: 0.0002506605815142393, Final Batch Loss: 0.00010613280755933374\n",
      "Epoch 3064, Loss: 0.00017753030988387764, Final Batch Loss: 7.675642700633034e-05\n",
      "Epoch 3065, Loss: 0.0002887558439397253, Final Batch Loss: 0.00022573163732886314\n",
      "Epoch 3066, Loss: 0.0003945765638491139, Final Batch Loss: 0.0002904197317548096\n",
      "Epoch 3067, Loss: 0.00036821957837673835, Final Batch Loss: 4.8186058847932145e-05\n",
      "Epoch 3068, Loss: 0.0004927108020638116, Final Batch Loss: 0.0003766571171581745\n",
      "Epoch 3069, Loss: 0.00020306061924202368, Final Batch Loss: 5.8384153817314655e-05\n",
      "Epoch 3070, Loss: 0.0001598046364961192, Final Batch Loss: 8.512796193826944e-05\n",
      "Epoch 3071, Loss: 6.901316191942897e-05, Final Batch Loss: 3.949458914576098e-05\n",
      "Epoch 3072, Loss: 0.0005197559912630823, Final Batch Loss: 5.610216976492666e-05\n",
      "Epoch 3073, Loss: 0.000140675021611969, Final Batch Loss: 1.5873707525315695e-05\n",
      "Epoch 3074, Loss: 0.0006383130166796036, Final Batch Loss: 4.778238508151844e-05\n",
      "Epoch 3075, Loss: 0.0019570249132812023, Final Batch Loss: 7.53059284761548e-05\n",
      "Epoch 3076, Loss: 0.00019430511019891128, Final Batch Loss: 7.78794419602491e-05\n",
      "Epoch 3077, Loss: 0.00022584086400456727, Final Batch Loss: 9.631350985728204e-05\n",
      "Epoch 3078, Loss: 0.0002589060313766822, Final Batch Loss: 0.00019649577734526247\n",
      "Epoch 3079, Loss: 0.000201117574761156, Final Batch Loss: 5.668072117259726e-05\n",
      "Epoch 3080, Loss: 0.0005053670174675062, Final Batch Loss: 6.82013196637854e-05\n",
      "Epoch 3081, Loss: 0.00265725095232483, Final Batch Loss: 0.0001446418318664655\n",
      "Epoch 3082, Loss: 0.00019469820836093277, Final Batch Loss: 8.303221693495288e-05\n",
      "Epoch 3083, Loss: 0.00010202566409134306, Final Batch Loss: 6.370805931510404e-05\n",
      "Epoch 3084, Loss: 0.0006108435627538711, Final Batch Loss: 0.000336334080202505\n",
      "Epoch 3085, Loss: 0.00023166242317529395, Final Batch Loss: 0.00013113993918523192\n",
      "Epoch 3086, Loss: 5.83346745770541e-05, Final Batch Loss: 4.37160961155314e-05\n",
      "Epoch 3087, Loss: 0.00018761420687951613, Final Batch Loss: 2.0933775886078365e-05\n",
      "Epoch 3088, Loss: 0.0004617848444468109, Final Batch Loss: 2.7998072255286388e-05\n",
      "Epoch 3089, Loss: 0.00012292442625039257, Final Batch Loss: 5.388555655372329e-05\n",
      "Epoch 3090, Loss: 0.00022875582726555876, Final Batch Loss: 2.9108570743119344e-05\n",
      "Epoch 3091, Loss: 0.0005575274917646311, Final Batch Loss: 0.00048321668873541057\n",
      "Epoch 3092, Loss: 0.00012317604523559567, Final Batch Loss: 9.332367335446179e-05\n",
      "Epoch 3093, Loss: 0.004517042654697434, Final Batch Loss: 0.004489007405936718\n",
      "Epoch 3094, Loss: 0.00020370435595395975, Final Batch Loss: 5.207102731219493e-05\n",
      "Epoch 3095, Loss: 0.002984781087434385, Final Batch Loss: 0.00011369473213562742\n",
      "Epoch 3096, Loss: 0.0002595527039375156, Final Batch Loss: 0.000228058997890912\n",
      "Epoch 3097, Loss: 0.001527524451375939, Final Batch Loss: 7.79864058131352e-05\n",
      "Epoch 3098, Loss: 0.002420458575215889, Final Batch Loss: 3.262456084485166e-05\n",
      "Epoch 3099, Loss: 6.807569297961891e-05, Final Batch Loss: 4.0614268073113635e-05\n",
      "Epoch 3100, Loss: 9.389885053678881e-05, Final Batch Loss: 1.8697026462177746e-05\n",
      "Epoch 3101, Loss: 0.0007320146287383977, Final Batch Loss: 5.457227598526515e-05\n",
      "Epoch 3102, Loss: 0.000565349735552445, Final Batch Loss: 0.00025473744608461857\n",
      "Epoch 3103, Loss: 0.00021699872013414279, Final Batch Loss: 4.707866901298985e-05\n",
      "Epoch 3104, Loss: 0.0011863557592732832, Final Batch Loss: 0.00011599149729590863\n",
      "Epoch 3105, Loss: 0.0007711931830272079, Final Batch Loss: 0.00045512645738199353\n",
      "Epoch 3106, Loss: 0.0007340584779740311, Final Batch Loss: 0.0006843798328191042\n",
      "Epoch 3107, Loss: 0.002476362365996465, Final Batch Loss: 0.0002982144651468843\n",
      "Epoch 3108, Loss: 0.00010429929170641117, Final Batch Loss: 7.918547635199502e-05\n",
      "Epoch 3109, Loss: 0.0005137732659932226, Final Batch Loss: 0.00037028800579719245\n",
      "Epoch 3110, Loss: 0.002182492178690154, Final Batch Loss: 4.403817729325965e-05\n",
      "Epoch 3111, Loss: 0.002366228203754872, Final Batch Loss: 0.00020599731942638755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3112, Loss: 0.00019920659542549402, Final Batch Loss: 0.00011534930672496557\n",
      "Epoch 3113, Loss: 0.00018877912225434557, Final Batch Loss: 6.725370622007176e-05\n",
      "Epoch 3114, Loss: 0.0002731770073296502, Final Batch Loss: 0.00010735305841080844\n",
      "Epoch 3115, Loss: 0.00026593544316710904, Final Batch Loss: 0.00020798543118871748\n",
      "Epoch 3116, Loss: 0.002176023328502197, Final Batch Loss: 2.9293129045981914e-05\n",
      "Epoch 3117, Loss: 0.0005138799242558889, Final Batch Loss: 0.0004428628017194569\n",
      "Epoch 3118, Loss: 0.00242295963835204, Final Batch Loss: 0.00012020240683341399\n",
      "Epoch 3119, Loss: 0.0005487531816470437, Final Batch Loss: 0.0001004638834274374\n",
      "Epoch 3120, Loss: 0.0005756471364293247, Final Batch Loss: 0.000374763214495033\n",
      "Epoch 3121, Loss: 0.00020112844140385278, Final Batch Loss: 5.7448243751423433e-05\n",
      "Epoch 3122, Loss: 0.0021104651750647463, Final Batch Loss: 8.406883716816083e-05\n",
      "Epoch 3123, Loss: 8.283906936412677e-05, Final Batch Loss: 4.1008875996340066e-05\n",
      "Epoch 3124, Loss: 0.00023906637215986848, Final Batch Loss: 4.3089588871225715e-05\n",
      "Epoch 3125, Loss: 0.00022458648891188204, Final Batch Loss: 7.266626926138997e-05\n",
      "Epoch 3126, Loss: 0.00031523384313913994, Final Batch Loss: 0.00029078175430186093\n",
      "Epoch 3127, Loss: 0.00019272560348326806, Final Batch Loss: 1.766910463629756e-05\n",
      "Epoch 3128, Loss: 0.00020254524133633822, Final Batch Loss: 8.718329627299681e-05\n",
      "Epoch 3129, Loss: 0.00045390930608846247, Final Batch Loss: 0.00032930404995568097\n",
      "Epoch 3130, Loss: 2.9057728170300834e-05, Final Batch Loss: 5.0262042350368574e-06\n",
      "Epoch 3131, Loss: 0.0029667862108908594, Final Batch Loss: 0.00012683233944699168\n",
      "Epoch 3132, Loss: 0.00020125925220781937, Final Batch Loss: 8.134247036650777e-05\n",
      "Epoch 3133, Loss: 0.00027549003789317794, Final Batch Loss: 3.40697770297993e-05\n",
      "Epoch 3134, Loss: 0.00023507604510086821, Final Batch Loss: 1.3103895071253646e-05\n",
      "Epoch 3135, Loss: 0.0022213610500330105, Final Batch Loss: 6.562915223184973e-05\n",
      "Epoch 3136, Loss: 0.00010670801202650182, Final Batch Loss: 3.322578777442686e-05\n",
      "Epoch 3137, Loss: 0.0003143243520753458, Final Batch Loss: 0.00018305450794287026\n",
      "Epoch 3138, Loss: 0.00021220356757112313, Final Batch Loss: 0.00018457537225913256\n",
      "Epoch 3139, Loss: 0.00014787929831072688, Final Batch Loss: 3.718699008459225e-05\n",
      "Epoch 3140, Loss: 0.00021603484492516145, Final Batch Loss: 8.469785825582221e-05\n",
      "Epoch 3141, Loss: 0.0003734448546310887, Final Batch Loss: 0.00012832276115659624\n",
      "Epoch 3142, Loss: 9.294071242038626e-05, Final Batch Loss: 1.8507113054511137e-05\n",
      "Epoch 3143, Loss: 0.00012301075912546366, Final Batch Loss: 8.908954623620957e-05\n",
      "Epoch 3144, Loss: 0.0006971114271436818, Final Batch Loss: 0.0005945584853179753\n",
      "Epoch 3145, Loss: 5.122243601363152e-05, Final Batch Loss: 1.192439958686009e-05\n",
      "Epoch 3146, Loss: 0.00016445523579022847, Final Batch Loss: 5.0684644520515576e-05\n",
      "Epoch 3147, Loss: 0.0002829784352798015, Final Batch Loss: 7.973804895300418e-05\n",
      "Epoch 3148, Loss: 0.00030090117070358247, Final Batch Loss: 0.00012178815086372197\n",
      "Epoch 3149, Loss: 0.004186809252132662, Final Batch Loss: 0.004125399515032768\n",
      "Epoch 3150, Loss: 6.83783528074855e-05, Final Batch Loss: 7.3055507527897134e-06\n",
      "Epoch 3151, Loss: 0.0001771093866409501, Final Batch Loss: 2.5631647076806985e-05\n",
      "Epoch 3152, Loss: 0.00022649434686172754, Final Batch Loss: 9.840358688961715e-05\n",
      "Epoch 3153, Loss: 0.00010740047218860127, Final Batch Loss: 6.611227581743151e-05\n",
      "Epoch 3154, Loss: 0.00015730210725450888, Final Batch Loss: 6.118460441939533e-05\n",
      "Epoch 3155, Loss: 0.00013069446868030354, Final Batch Loss: 7.279026613105088e-05\n",
      "Epoch 3156, Loss: 0.0002828033539117314, Final Batch Loss: 0.00017777552420739084\n",
      "Epoch 3157, Loss: 6.662307714577764e-05, Final Batch Loss: 4.977388016413897e-05\n",
      "Epoch 3158, Loss: 3.277395353507018e-05, Final Batch Loss: 8.715110197954345e-06\n",
      "Epoch 3159, Loss: 0.00011196825334991445, Final Batch Loss: 7.299164735741215e-06\n",
      "Epoch 3160, Loss: 0.0008120617567328736, Final Batch Loss: 0.0007914815214462578\n",
      "Epoch 3161, Loss: 7.353160253842361e-05, Final Batch Loss: 2.7430945920059457e-05\n",
      "Epoch 3162, Loss: 0.006224932731129229, Final Batch Loss: 0.006019897758960724\n",
      "Epoch 3163, Loss: 0.00019315718964207917, Final Batch Loss: 0.00015818729298189282\n",
      "Epoch 3164, Loss: 0.007472255565517116, Final Batch Loss: 0.007381151430308819\n",
      "Epoch 3165, Loss: 0.0001887661564978771, Final Batch Loss: 3.001337609020993e-05\n",
      "Epoch 3166, Loss: 0.00026196146791335195, Final Batch Loss: 6.219011265784502e-05\n",
      "Epoch 3167, Loss: 0.0001256129689863883, Final Batch Loss: 5.032486660638824e-05\n",
      "Epoch 3168, Loss: 0.005206833990087034, Final Batch Loss: 0.0051579903811216354\n",
      "Epoch 3169, Loss: 0.0001987397190532647, Final Batch Loss: 0.00012134690769016743\n",
      "Epoch 3170, Loss: 0.00044057432023691945, Final Batch Loss: 0.0003952727129217237\n",
      "Epoch 3171, Loss: 0.0013459043620969169, Final Batch Loss: 0.00011082056880695745\n",
      "Epoch 3172, Loss: 7.546996130258776e-05, Final Batch Loss: 2.556810068199411e-05\n",
      "Epoch 3173, Loss: 6.377429235726595e-05, Final Batch Loss: 1.7463516996940598e-05\n",
      "Epoch 3174, Loss: 0.005341099349607248, Final Batch Loss: 0.005304832011461258\n",
      "Epoch 3175, Loss: 0.0005584656246355735, Final Batch Loss: 0.00010093382297782227\n",
      "Epoch 3176, Loss: 0.0005237008299445733, Final Batch Loss: 0.0004836666048504412\n",
      "Epoch 3177, Loss: 0.0003032921886187978, Final Batch Loss: 0.00026122949202544987\n",
      "Epoch 3178, Loss: 0.00028934970396221615, Final Batch Loss: 2.676505027920939e-05\n",
      "Epoch 3179, Loss: 0.00028974096130696125, Final Batch Loss: 0.00023289928503800184\n",
      "Epoch 3180, Loss: 7.904676749603823e-05, Final Batch Loss: 3.325695433886722e-05\n",
      "Epoch 3181, Loss: 9.693611173133831e-05, Final Batch Loss: 8.087838796200231e-05\n",
      "Epoch 3182, Loss: 0.0014630844270868693, Final Batch Loss: 3.381324131623842e-05\n",
      "Epoch 3183, Loss: 0.00014105470472713932, Final Batch Loss: 3.654728061519563e-05\n",
      "Epoch 3184, Loss: 0.00021081542217871174, Final Batch Loss: 0.00017748466052580625\n",
      "Epoch 3185, Loss: 0.010402034524304327, Final Batch Loss: 0.010391398333013058\n",
      "Epoch 3186, Loss: 0.0003037038550246507, Final Batch Loss: 8.511103806085885e-05\n",
      "Epoch 3187, Loss: 0.0005277142736304086, Final Batch Loss: 0.0005002252873964608\n",
      "Epoch 3188, Loss: 0.0002415117050986737, Final Batch Loss: 7.428928802255541e-05\n",
      "Epoch 3189, Loss: 0.00013071827197563834, Final Batch Loss: 4.5156553824199364e-05\n",
      "Epoch 3190, Loss: 0.0009782274719327688, Final Batch Loss: 0.0008899200474843383\n",
      "Epoch 3191, Loss: 4.2191168176941574e-05, Final Batch Loss: 1.1107531463494524e-05\n",
      "Epoch 3192, Loss: 0.00010267241668771021, Final Batch Loss: 6.049042349332012e-05\n",
      "Epoch 3193, Loss: 0.0001052570059982827, Final Batch Loss: 8.239199087256566e-05\n",
      "Epoch 3194, Loss: 0.00018328159058000892, Final Batch Loss: 0.0001353217667201534\n",
      "Epoch 3195, Loss: 6.379320529958932e-05, Final Batch Loss: 1.1230577911192086e-05\n",
      "Epoch 3196, Loss: 0.00017989821935771033, Final Batch Loss: 8.351866563316435e-05\n",
      "Epoch 3197, Loss: 0.00012528956540336367, Final Batch Loss: 9.51374095166102e-05\n",
      "Epoch 3198, Loss: 0.005667168530635536, Final Batch Loss: 6.260292138904333e-05\n",
      "Epoch 3199, Loss: 5.8455690123082604e-05, Final Batch Loss: 6.951885552552994e-06\n",
      "Epoch 3200, Loss: 0.00016990338554023765, Final Batch Loss: 1.630675615160726e-05\n",
      "Epoch 3201, Loss: 0.0001340330818493385, Final Batch Loss: 7.322961027966812e-05\n",
      "Epoch 3202, Loss: 0.0006100703758420423, Final Batch Loss: 0.00023839612549636513\n",
      "Epoch 3203, Loss: 0.0003245991756557487, Final Batch Loss: 3.603021468734369e-05\n",
      "Epoch 3204, Loss: 0.0017934805546246935, Final Batch Loss: 3.185223977197893e-05\n",
      "Epoch 3205, Loss: 0.006775603775167838, Final Batch Loss: 0.006672339513897896\n",
      "Epoch 3206, Loss: 0.00011079790056101047, Final Batch Loss: 4.3323856516508386e-05\n",
      "Epoch 3207, Loss: 0.00023753057757858187, Final Batch Loss: 0.0001342988107353449\n",
      "Epoch 3208, Loss: 0.0006410930946003646, Final Batch Loss: 0.00032746593933552504\n",
      "Epoch 3209, Loss: 0.00016847936785779893, Final Batch Loss: 3.05287103401497e-05\n",
      "Epoch 3210, Loss: 8.460538447252475e-05, Final Batch Loss: 5.2732233598362654e-05\n",
      "Epoch 3211, Loss: 0.0006992809649091214, Final Batch Loss: 0.0005288508255034685\n",
      "Epoch 3212, Loss: 0.0003078190784435719, Final Batch Loss: 0.00017796004249248654\n",
      "Epoch 3213, Loss: 0.00018304737022845075, Final Batch Loss: 9.101576142711565e-05\n",
      "Epoch 3214, Loss: 6.317440056591295e-05, Final Batch Loss: 3.5275923437438905e-05\n",
      "Epoch 3215, Loss: 0.0006302334513748065, Final Batch Loss: 0.0004954274627380073\n",
      "Epoch 3216, Loss: 0.00012193813381600194, Final Batch Loss: 6.485517224064097e-05\n",
      "Epoch 3217, Loss: 0.00044240794522920623, Final Batch Loss: 0.0003230101428925991\n",
      "Epoch 3218, Loss: 0.0002081073289446067, Final Batch Loss: 0.00016685863374732435\n",
      "Epoch 3219, Loss: 0.00012049075303366408, Final Batch Loss: 8.513574721291661e-05\n",
      "Epoch 3220, Loss: 0.0006793809588998556, Final Batch Loss: 0.00015600741608068347\n",
      "Epoch 3221, Loss: 0.0018166695126637933, Final Batch Loss: 1.3544374269258697e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3222, Loss: 0.00012445219181245193, Final Batch Loss: 3.5583630960900337e-05\n",
      "Epoch 3223, Loss: 0.0016607075594947673, Final Batch Loss: 0.001610578503459692\n",
      "Epoch 3224, Loss: 0.0007077594091242645, Final Batch Loss: 1.022842843667604e-05\n",
      "Epoch 3225, Loss: 9.681107621872798e-05, Final Batch Loss: 5.43593596376013e-05\n",
      "Epoch 3226, Loss: 0.0008938813771237619, Final Batch Loss: 0.0008777564507909119\n",
      "Epoch 3227, Loss: 5.3386373110697605e-05, Final Batch Loss: 2.640430466271937e-05\n",
      "Epoch 3228, Loss: 0.0001614111642993521, Final Batch Loss: 0.0001277603441849351\n",
      "Epoch 3229, Loss: 0.000342524544976186, Final Batch Loss: 0.0003109332756139338\n",
      "Epoch 3230, Loss: 0.001431577511539217, Final Batch Loss: 0.00010327740892535076\n",
      "Epoch 3231, Loss: 0.0068963884841650724, Final Batch Loss: 0.003962683491408825\n",
      "Epoch 3232, Loss: 2.8212095458002295e-05, Final Batch Loss: 1.834563590819016e-05\n",
      "Epoch 3233, Loss: 0.00018845542945200577, Final Batch Loss: 0.0001355738058919087\n",
      "Epoch 3234, Loss: 3.283422574895667e-05, Final Batch Loss: 1.5211805475701112e-05\n",
      "Epoch 3235, Loss: 0.0015422900814883178, Final Batch Loss: 1.0290057616657577e-05\n",
      "Epoch 3236, Loss: 0.00015000255007180385, Final Batch Loss: 3.770406692638062e-05\n",
      "Epoch 3237, Loss: 0.0009112854168051854, Final Batch Loss: 0.0008396523189730942\n",
      "Epoch 3238, Loss: 0.0017740538096404634, Final Batch Loss: 2.0419851352926344e-05\n",
      "Epoch 3239, Loss: 0.000153321980178589, Final Batch Loss: 5.5323926062555984e-05\n",
      "Epoch 3240, Loss: 0.0002270234253956005, Final Batch Loss: 0.00019168935250490904\n",
      "Epoch 3241, Loss: 8.414915282628499e-05, Final Batch Loss: 5.032669650972821e-05\n",
      "Epoch 3242, Loss: 8.532088759238832e-05, Final Batch Loss: 5.363751552067697e-05\n",
      "Epoch 3243, Loss: 0.0016409787567681633, Final Batch Loss: 0.0001039903363562189\n",
      "Epoch 3244, Loss: 0.0009494554251432419, Final Batch Loss: 0.0008201359887607396\n",
      "Epoch 3245, Loss: 0.0002722175522649195, Final Batch Loss: 0.00024371342442464083\n",
      "Epoch 3246, Loss: 0.00013737704648519866, Final Batch Loss: 8.229289232986048e-05\n",
      "Epoch 3247, Loss: 0.000173920787347015, Final Batch Loss: 4.45012774434872e-05\n",
      "Epoch 3248, Loss: 0.00011555468154256232, Final Batch Loss: 7.037545583443716e-05\n",
      "Epoch 3249, Loss: 9.67996493272949e-05, Final Batch Loss: 3.553655915311538e-05\n",
      "Epoch 3250, Loss: 0.0017152359273495676, Final Batch Loss: 5.621046966552967e-06\n",
      "Epoch 3251, Loss: 0.004501059473113855, Final Batch Loss: 0.004446835722774267\n",
      "Epoch 3252, Loss: 0.000343757143127732, Final Batch Loss: 0.00018221554637420923\n",
      "Epoch 3253, Loss: 4.2696356103988364e-05, Final Batch Loss: 2.6562422135611996e-05\n",
      "Epoch 3254, Loss: 0.00499786737782415, Final Batch Loss: 0.004851055331528187\n",
      "Epoch 3255, Loss: 4.987028114555869e-05, Final Batch Loss: 2.0496563593042083e-05\n",
      "Epoch 3256, Loss: 0.00022811382586951368, Final Batch Loss: 2.1378418750828132e-05\n",
      "Epoch 3257, Loss: 0.00024569777451688424, Final Batch Loss: 9.340450196759775e-05\n",
      "Epoch 3258, Loss: 0.0026615106471581385, Final Batch Loss: 0.00018689296848606318\n",
      "Epoch 3259, Loss: 5.38461645192001e-05, Final Batch Loss: 1.4429115253733471e-05\n",
      "Epoch 3260, Loss: 0.002156320355425123, Final Batch Loss: 0.00011040303070330992\n",
      "Epoch 3261, Loss: 0.0001197133824462071, Final Batch Loss: 8.062283450271934e-05\n",
      "Epoch 3262, Loss: 0.00010446686792420223, Final Batch Loss: 9.039188444148749e-05\n",
      "Epoch 3263, Loss: 0.00018048118545266334, Final Batch Loss: 2.9130716939107515e-05\n",
      "Epoch 3264, Loss: 0.0003778632963076234, Final Batch Loss: 0.0003140908956993371\n",
      "Epoch 3265, Loss: 0.0021079000489407917, Final Batch Loss: 1.4607509001507424e-05\n",
      "Epoch 3266, Loss: 0.00017367950204061344, Final Batch Loss: 0.00010695688251871616\n",
      "Epoch 3267, Loss: 9.436119762540329e-05, Final Batch Loss: 1.85027329280274e-05\n",
      "Epoch 3268, Loss: 6.49567573418608e-05, Final Batch Loss: 1.1933969290112145e-05\n",
      "Epoch 3269, Loss: 0.00017225118790520355, Final Batch Loss: 5.635089473798871e-05\n",
      "Epoch 3270, Loss: 7.128138531697914e-05, Final Batch Loss: 8.171729859896004e-06\n",
      "Epoch 3271, Loss: 0.00020873936955467798, Final Batch Loss: 0.00018615444423630834\n",
      "Epoch 3272, Loss: 9.329877411801135e-05, Final Batch Loss: 1.3329531611816492e-05\n",
      "Epoch 3273, Loss: 7.04424692230532e-05, Final Batch Loss: 2.4294144168379717e-05\n",
      "Epoch 3274, Loss: 0.0018872937944252044, Final Batch Loss: 0.00012270364095456898\n",
      "Epoch 3275, Loss: 0.0026034982220153324, Final Batch Loss: 0.00010927271068794653\n",
      "Epoch 3276, Loss: 0.00017513133207103238, Final Batch Loss: 3.0842442356515676e-05\n",
      "Epoch 3277, Loss: 0.00010341090819565579, Final Batch Loss: 5.098771725897677e-05\n",
      "Epoch 3278, Loss: 0.00012876925438831677, Final Batch Loss: 6.486702204711037e-06\n",
      "Epoch 3279, Loss: 0.0002701795383472927, Final Batch Loss: 4.9111687985714525e-05\n",
      "Epoch 3280, Loss: 4.144327886024257e-05, Final Batch Loss: 1.186678036901867e-05\n",
      "Epoch 3281, Loss: 0.0011927096857107244, Final Batch Loss: 2.3283086193259805e-05\n",
      "Epoch 3282, Loss: 8.652757605887018e-05, Final Batch Loss: 6.544881034642458e-05\n",
      "Epoch 3283, Loss: 8.038604028115515e-05, Final Batch Loss: 3.0275617973529734e-05\n",
      "Epoch 3284, Loss: 0.00021629661205224693, Final Batch Loss: 0.00017894862685352564\n",
      "Epoch 3285, Loss: 0.00023447570174539578, Final Batch Loss: 6.726019364577951e-06\n",
      "Epoch 3286, Loss: 8.797287227935158e-05, Final Batch Loss: 5.574850729317404e-05\n",
      "Epoch 3287, Loss: 0.00024915450194384903, Final Batch Loss: 8.029320451896638e-05\n",
      "Epoch 3288, Loss: 0.0002148820822185371, Final Batch Loss: 0.0001675460662227124\n",
      "Epoch 3289, Loss: 0.00011881349928444251, Final Batch Loss: 1.8875172827392817e-05\n",
      "Epoch 3290, Loss: 0.00015604776854161173, Final Batch Loss: 0.00011823941167676821\n",
      "Epoch 3291, Loss: 0.00048064321163110435, Final Batch Loss: 0.00024448323529213667\n",
      "Epoch 3292, Loss: 0.00025838320652837865, Final Batch Loss: 4.380361860967241e-05\n",
      "Epoch 3293, Loss: 6.532871020681341e-05, Final Batch Loss: 6.409053185052471e-06\n",
      "Epoch 3294, Loss: 0.0015015806920928298, Final Batch Loss: 9.622533070796635e-06\n",
      "Epoch 3295, Loss: 0.0004953278548782691, Final Batch Loss: 0.00014900807582307607\n",
      "Epoch 3296, Loss: 0.0016819549709907733, Final Batch Loss: 5.946066085016355e-05\n",
      "Epoch 3297, Loss: 2.2789741706219502e-05, Final Batch Loss: 1.5070029803609941e-05\n",
      "Epoch 3298, Loss: 6.686473352601752e-05, Final Batch Loss: 2.659036181285046e-05\n",
      "Epoch 3299, Loss: 0.026739309207187034, Final Batch Loss: 0.026685496792197227\n",
      "Epoch 3300, Loss: 0.00012668034105445258, Final Batch Loss: 7.106998236849904e-05\n",
      "Epoch 3301, Loss: 0.00019342213636264205, Final Batch Loss: 0.00012590205005835742\n",
      "Epoch 3302, Loss: 0.0024800681858323514, Final Batch Loss: 2.268626121804118e-05\n",
      "Epoch 3303, Loss: 0.00011207037232452421, Final Batch Loss: 6.068881248211255e-06\n",
      "Epoch 3304, Loss: 0.0001526372361695394, Final Batch Loss: 9.8432443337515e-05\n",
      "Epoch 3305, Loss: 8.869589328242e-05, Final Batch Loss: 2.0752986529259942e-05\n",
      "Epoch 3306, Loss: 0.00045786891132593155, Final Batch Loss: 0.0003784654545597732\n",
      "Epoch 3307, Loss: 0.000546993065654533, Final Batch Loss: 0.000492551364004612\n",
      "Epoch 3308, Loss: 0.00024608400417491794, Final Batch Loss: 2.884608693420887e-05\n",
      "Epoch 3309, Loss: 0.00018199754958914127, Final Batch Loss: 0.00015886813343968242\n",
      "Epoch 3310, Loss: 0.003487671841867268, Final Batch Loss: 0.0017284925561398268\n",
      "Epoch 3311, Loss: 9.694219443190377e-05, Final Batch Loss: 3.0192377380444668e-05\n",
      "Epoch 3312, Loss: 3.2216295949183404e-05, Final Batch Loss: 1.291418811888434e-05\n",
      "Epoch 3313, Loss: 0.00014599179121432826, Final Batch Loss: 5.348726699594408e-05\n",
      "Epoch 3314, Loss: 0.00030773794424021617, Final Batch Loss: 0.00012122779298806563\n",
      "Epoch 3315, Loss: 0.00011625532715697773, Final Batch Loss: 5.325579331838526e-05\n",
      "Epoch 3316, Loss: 5.545581552723888e-05, Final Batch Loss: 2.2240177713683806e-05\n",
      "Epoch 3317, Loss: 0.00010538215428823605, Final Batch Loss: 1.814492861740291e-05\n",
      "Epoch 3318, Loss: 0.00018607300080475397, Final Batch Loss: 0.0001415497827110812\n",
      "Epoch 3319, Loss: 0.003659539492218755, Final Batch Loss: 0.0036321680527180433\n",
      "Epoch 3320, Loss: 0.0002848532276402693, Final Batch Loss: 2.9163096769480035e-05\n",
      "Epoch 3321, Loss: 0.00019733572844415903, Final Batch Loss: 3.1294330256059766e-05\n",
      "Epoch 3322, Loss: 0.0003249876208428759, Final Batch Loss: 5.287611929816194e-05\n",
      "Epoch 3323, Loss: 0.00013615616262541153, Final Batch Loss: 2.3881857487140223e-05\n",
      "Epoch 3324, Loss: 0.004168988763922243, Final Batch Loss: 0.004143434576690197\n",
      "Epoch 3325, Loss: 6.69472638037405e-05, Final Batch Loss: 1.3766500160272699e-05\n",
      "Epoch 3326, Loss: 0.0002139919961337, Final Batch Loss: 0.00013710865459870547\n",
      "Epoch 3327, Loss: 0.00023015598708298057, Final Batch Loss: 1.3801021850667894e-05\n",
      "Epoch 3328, Loss: 0.0007861089902689855, Final Batch Loss: 2.9454599825839978e-06\n",
      "Epoch 3329, Loss: 0.00014807098705205135, Final Batch Loss: 0.00011045415158150718\n",
      "Epoch 3330, Loss: 6.756125003448687e-05, Final Batch Loss: 3.108347300440073e-05\n",
      "Epoch 3331, Loss: 0.00021762404503533617, Final Batch Loss: 3.67254760931246e-05\n",
      "Epoch 3332, Loss: 0.00016196747128560673, Final Batch Loss: 0.00013224771828390658\n",
      "Epoch 3333, Loss: 0.00015260580221365672, Final Batch Loss: 1.6438074453617446e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3334, Loss: 0.021528004843275994, Final Batch Loss: 0.00012619345216080546\n",
      "Epoch 3335, Loss: 9.424113886780106e-05, Final Batch Loss: 3.955846841563471e-05\n",
      "Epoch 3336, Loss: 0.00020187691552564502, Final Batch Loss: 6.340292748063803e-05\n",
      "Epoch 3337, Loss: 5.3221370762912557e-05, Final Batch Loss: 2.65026101260446e-05\n",
      "Epoch 3338, Loss: 0.00019777910347329453, Final Batch Loss: 0.0001060390131897293\n",
      "Epoch 3339, Loss: 0.00036984668986406177, Final Batch Loss: 0.00024146077339537442\n",
      "Epoch 3340, Loss: 0.00011260362134635216, Final Batch Loss: 9.955123823601753e-05\n",
      "Epoch 3341, Loss: 0.0003210602080798708, Final Batch Loss: 6.878267595311627e-05\n",
      "Epoch 3342, Loss: 9.076838614419103e-05, Final Batch Loss: 5.567726111621596e-05\n",
      "Epoch 3343, Loss: 0.002658293364220299, Final Batch Loss: 0.0001388772070640698\n",
      "Epoch 3344, Loss: 0.0014582329895347357, Final Batch Loss: 0.0010951856384053826\n",
      "Epoch 3345, Loss: 0.00016352816237485968, Final Batch Loss: 5.352694643079303e-05\n",
      "Epoch 3346, Loss: 0.0018048562342301011, Final Batch Loss: 9.71044646576047e-05\n",
      "Epoch 3347, Loss: 0.0016320142149197636, Final Batch Loss: 1.6137533748405986e-05\n",
      "Epoch 3348, Loss: 0.00018872309283324284, Final Batch Loss: 1.0989681868522894e-05\n",
      "Epoch 3349, Loss: 0.00030829421848466154, Final Batch Loss: 9.47357875702437e-06\n",
      "Epoch 3350, Loss: 0.00015406373495352454, Final Batch Loss: 5.333582157618366e-05\n",
      "Epoch 3351, Loss: 0.005587046271102736, Final Batch Loss: 5.497993333847262e-05\n",
      "Epoch 3352, Loss: 0.0004593676785589196, Final Batch Loss: 0.0003943436895497143\n",
      "Epoch 3353, Loss: 8.185215665434953e-05, Final Batch Loss: 2.968883745779749e-05\n",
      "Epoch 3354, Loss: 0.00016950674762483686, Final Batch Loss: 5.021374818170443e-05\n",
      "Epoch 3355, Loss: 0.0002215444328612648, Final Batch Loss: 2.3996013624127954e-05\n",
      "Epoch 3356, Loss: 0.00047736658598296344, Final Batch Loss: 0.00031085984664969146\n",
      "Epoch 3357, Loss: 8.768593079366838e-05, Final Batch Loss: 3.5229791137680877e-06\n",
      "Epoch 3358, Loss: 7.498958802898414e-05, Final Batch Loss: 3.2843359804246575e-05\n",
      "Epoch 3359, Loss: 7.274820018210448e-05, Final Batch Loss: 3.935993299819529e-05\n",
      "Epoch 3360, Loss: 0.0009281691018259153, Final Batch Loss: 0.00017136246606241912\n",
      "Epoch 3361, Loss: 0.00022400137822842225, Final Batch Loss: 9.442406735615805e-05\n",
      "Epoch 3362, Loss: 0.00036286841350374743, Final Batch Loss: 3.232980816392228e-05\n",
      "Epoch 3363, Loss: 0.00012473244714783505, Final Batch Loss: 8.155607065418735e-05\n",
      "Epoch 3364, Loss: 0.00015777603402966633, Final Batch Loss: 2.9435577744152397e-05\n",
      "Epoch 3365, Loss: 0.0012766988584189676, Final Batch Loss: 0.00010895096784224734\n",
      "Epoch 3366, Loss: 0.00015868654008954763, Final Batch Loss: 8.007838914636523e-05\n",
      "Epoch 3367, Loss: 7.813354022800922e-05, Final Batch Loss: 1.9556919141905382e-05\n",
      "Epoch 3368, Loss: 0.0001485909306211397, Final Batch Loss: 6.975844007683918e-05\n",
      "Epoch 3369, Loss: 0.00043457782521727495, Final Batch Loss: 5.8730929595185444e-05\n",
      "Epoch 3370, Loss: 8.976059689302929e-05, Final Batch Loss: 2.5305202143499628e-05\n",
      "Epoch 3371, Loss: 5.743674591940362e-05, Final Batch Loss: 2.3050009986036457e-05\n",
      "Epoch 3372, Loss: 0.0002756392059382051, Final Batch Loss: 0.0002175802510464564\n",
      "Epoch 3373, Loss: 0.00015548139344900846, Final Batch Loss: 0.000101707577414345\n",
      "Epoch 3374, Loss: 0.002913007027018466, Final Batch Loss: 2.8526623282232322e-05\n",
      "Epoch 3375, Loss: 8.245472417911515e-05, Final Batch Loss: 5.009816595702432e-05\n",
      "Epoch 3376, Loss: 0.0001463419830542989, Final Batch Loss: 6.767649756511673e-05\n",
      "Epoch 3377, Loss: 0.00028210987511556596, Final Batch Loss: 0.00012297167268116027\n",
      "Epoch 3378, Loss: 0.0012852887375629507, Final Batch Loss: 0.001212580013088882\n",
      "Epoch 3379, Loss: 0.0001767316734913038, Final Batch Loss: 1.665669151407201e-05\n",
      "Epoch 3380, Loss: 0.0008514954733982449, Final Batch Loss: 0.0008285130024887621\n",
      "Epoch 3381, Loss: 0.00020948042219970375, Final Batch Loss: 8.294130384456366e-05\n",
      "Epoch 3382, Loss: 0.00018113162514055148, Final Batch Loss: 7.110739534255117e-05\n",
      "Epoch 3383, Loss: 0.00011093912735304912, Final Batch Loss: 6.131540885689901e-06\n",
      "Epoch 3384, Loss: 0.002818714885506779, Final Batch Loss: 0.00042784406105056405\n",
      "Epoch 3385, Loss: 0.00021104298139107414, Final Batch Loss: 1.6366484487662092e-05\n",
      "Epoch 3386, Loss: 0.002477696238202043, Final Batch Loss: 0.00010256779205519706\n",
      "Epoch 3387, Loss: 0.0005494006763910875, Final Batch Loss: 0.00022763163724448532\n",
      "Epoch 3388, Loss: 0.00475686346180737, Final Batch Loss: 0.0027554514817893505\n",
      "Epoch 3389, Loss: 7.36725651222514e-05, Final Batch Loss: 2.3736656658002175e-05\n",
      "Epoch 3390, Loss: 3.735219070222229e-05, Final Batch Loss: 6.547870725626126e-06\n",
      "Epoch 3391, Loss: 0.00010055448365164921, Final Batch Loss: 3.8729849620722234e-05\n",
      "Epoch 3392, Loss: 0.0029034864874120103, Final Batch Loss: 0.0028748097829520702\n",
      "Epoch 3393, Loss: 0.0064469734497834, Final Batch Loss: 0.00640094606205821\n",
      "Epoch 3394, Loss: 0.00013860630315321032, Final Batch Loss: 1.4061335605219938e-05\n",
      "Epoch 3395, Loss: 0.0004204169235890731, Final Batch Loss: 7.497343176510185e-05\n",
      "Epoch 3396, Loss: 0.0005427230207715183, Final Batch Loss: 0.0003582205972634256\n",
      "Epoch 3397, Loss: 0.0002913262724177912, Final Batch Loss: 0.00023987509484868497\n",
      "Epoch 3398, Loss: 0.008558386703953147, Final Batch Loss: 0.0037697383668273687\n",
      "Epoch 3399, Loss: 0.0006128762342996197, Final Batch Loss: 1.1737838576664217e-05\n",
      "Epoch 3400, Loss: 0.00015400749543914571, Final Batch Loss: 0.00012540149327833205\n",
      "Epoch 3401, Loss: 0.026907015562755987, Final Batch Loss: 0.000252556026680395\n",
      "Epoch 3402, Loss: 0.002506485634512501, Final Batch Loss: 4.806807919521816e-05\n",
      "Epoch 3403, Loss: 0.00044166257430333644, Final Batch Loss: 0.00019721708667930216\n",
      "Epoch 3404, Loss: 0.00016876943118404597, Final Batch Loss: 8.991432696348056e-05\n",
      "Epoch 3405, Loss: 0.00010650711919879541, Final Batch Loss: 3.742217813851312e-05\n",
      "Epoch 3406, Loss: 0.002390246489085257, Final Batch Loss: 0.0005342239746823907\n",
      "Epoch 3407, Loss: 0.00018174417346017435, Final Batch Loss: 0.00011517282837303355\n",
      "Epoch 3408, Loss: 0.00011407752390368842, Final Batch Loss: 4.254788291291334e-05\n",
      "Epoch 3409, Loss: 0.004420488548930734, Final Batch Loss: 0.0042557911947369576\n",
      "Epoch 3410, Loss: 0.00024160552129615098, Final Batch Loss: 2.986336767207831e-05\n",
      "Epoch 3411, Loss: 0.0017933838025783189, Final Batch Loss: 8.663122571306303e-05\n",
      "Epoch 3412, Loss: 0.00016996791237033904, Final Batch Loss: 1.888611586764455e-05\n",
      "Epoch 3413, Loss: 0.0006062571483198553, Final Batch Loss: 0.00017097839736379683\n",
      "Epoch 3414, Loss: 0.0016220815887209028, Final Batch Loss: 0.00047404583892785013\n",
      "Epoch 3415, Loss: 6.362310796248494e-05, Final Batch Loss: 1.1794631973316427e-05\n",
      "Epoch 3416, Loss: 0.00028690464387182146, Final Batch Loss: 3.0268638511188328e-05\n",
      "Epoch 3417, Loss: 0.0015190179565252038, Final Batch Loss: 2.2626934878644533e-05\n",
      "Epoch 3418, Loss: 0.00020580995987984352, Final Batch Loss: 0.0001482032093917951\n",
      "Epoch 3419, Loss: 5.203932505537523e-05, Final Batch Loss: 8.435220479441341e-06\n",
      "Epoch 3420, Loss: 0.0002119302880601026, Final Batch Loss: 8.466885628877208e-05\n",
      "Epoch 3421, Loss: 0.0003161750137223862, Final Batch Loss: 6.59053839626722e-05\n",
      "Epoch 3422, Loss: 0.00032141055271495134, Final Batch Loss: 0.00025575931067578495\n",
      "Epoch 3423, Loss: 0.0001118359568863525, Final Batch Loss: 1.2821327800338622e-05\n",
      "Epoch 3424, Loss: 0.00019676768715726212, Final Batch Loss: 0.000131346401758492\n",
      "Epoch 3425, Loss: 0.00010207677405560389, Final Batch Loss: 6.31660150247626e-05\n",
      "Epoch 3426, Loss: 0.000740461444365792, Final Batch Loss: 6.537493027281016e-05\n",
      "Epoch 3427, Loss: 6.811751336499583e-05, Final Batch Loss: 4.608788003679365e-05\n",
      "Epoch 3428, Loss: 0.002032421005424112, Final Batch Loss: 0.00019830703968182206\n",
      "Epoch 3429, Loss: 0.00013784708426101133, Final Batch Loss: 3.6142024328000844e-05\n",
      "Epoch 3430, Loss: 0.002467656886437908, Final Batch Loss: 0.00037682699621655047\n",
      "Epoch 3431, Loss: 0.0002026990205195034, Final Batch Loss: 1.4835322872386314e-05\n",
      "Epoch 3432, Loss: 0.00012017141489195637, Final Batch Loss: 2.4855715309968218e-05\n",
      "Epoch 3433, Loss: 8.921631706471089e-05, Final Batch Loss: 2.370266338402871e-05\n",
      "Epoch 3434, Loss: 0.00047047840780578554, Final Batch Loss: 9.770170436240733e-05\n",
      "Epoch 3435, Loss: 0.00037382691516540945, Final Batch Loss: 0.00013095984468236566\n",
      "Epoch 3436, Loss: 0.0020533833012450486, Final Batch Loss: 0.00017429774743504822\n",
      "Epoch 3437, Loss: 0.0010170994937652722, Final Batch Loss: 6.802230200264603e-05\n",
      "Epoch 3438, Loss: 0.00023723581216472667, Final Batch Loss: 2.026860420301091e-05\n",
      "Epoch 3439, Loss: 0.0001630802380532259, Final Batch Loss: 1.771722781995777e-05\n",
      "Epoch 3440, Loss: 0.00017507150550954975, Final Batch Loss: 0.00013655719521921128\n",
      "Epoch 3441, Loss: 0.00030846611480228603, Final Batch Loss: 0.00016750050417613238\n",
      "Epoch 3442, Loss: 0.0041681345901452005, Final Batch Loss: 0.003807626897469163\n",
      "Epoch 3443, Loss: 0.0016155871853698045, Final Batch Loss: 0.00011408506543375552\n",
      "Epoch 3444, Loss: 0.0004215408607706195, Final Batch Loss: 0.00039413798367604613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3445, Loss: 0.00042576259875204414, Final Batch Loss: 0.00032192605431191623\n",
      "Epoch 3446, Loss: 0.0004960374280926771, Final Batch Loss: 0.00011132271174574271\n",
      "Epoch 3447, Loss: 3.844307002509595e-05, Final Batch Loss: 3.6328624446468893e-06\n",
      "Epoch 3448, Loss: 0.0001877613176475279, Final Batch Loss: 6.493107503047213e-05\n",
      "Epoch 3449, Loss: 7.217126949399244e-05, Final Batch Loss: 2.6984935175278224e-05\n",
      "Epoch 3450, Loss: 0.0022086085859882587, Final Batch Loss: 3.947561253880849e-06\n",
      "Epoch 3451, Loss: 0.0004247477772878483, Final Batch Loss: 2.8140013455413282e-05\n",
      "Epoch 3452, Loss: 0.00011529929543030448, Final Batch Loss: 8.355225145351142e-05\n",
      "Epoch 3453, Loss: 0.00011326352614560165, Final Batch Loss: 4.654381700675003e-05\n",
      "Epoch 3454, Loss: 0.00014001058298163116, Final Batch Loss: 8.967291068984196e-05\n",
      "Epoch 3455, Loss: 0.000611295274211443, Final Batch Loss: 0.0005814042524434626\n",
      "Epoch 3456, Loss: 0.00012107289512641728, Final Batch Loss: 9.242497617378831e-05\n",
      "Epoch 3457, Loss: 5.685888208972756e-05, Final Batch Loss: 2.4556835342082195e-05\n",
      "Epoch 3458, Loss: 7.109855141607113e-05, Final Batch Loss: 2.2030661057215184e-05\n",
      "Epoch 3459, Loss: 0.00013862295418221038, Final Batch Loss: 0.00011989938502665609\n",
      "Epoch 3460, Loss: 0.001451996125979349, Final Batch Loss: 0.0014330946141853929\n",
      "Epoch 3461, Loss: 0.0003101750698988326, Final Batch Loss: 4.603446723194793e-05\n",
      "Epoch 3462, Loss: 0.0004936033437843435, Final Batch Loss: 9.212848817696795e-05\n",
      "Epoch 3463, Loss: 6.214843051566277e-05, Final Batch Loss: 2.13560870179208e-05\n",
      "Epoch 3464, Loss: 9.265236076316796e-05, Final Batch Loss: 4.7547197027597576e-05\n",
      "Epoch 3465, Loss: 0.00018187866953667253, Final Batch Loss: 7.389856909867376e-05\n",
      "Epoch 3466, Loss: 0.0015737496560177533, Final Batch Loss: 2.2776262994739227e-05\n",
      "Epoch 3467, Loss: 9.537407277093735e-05, Final Batch Loss: 2.585281436040532e-05\n",
      "Epoch 3468, Loss: 0.0001458828483009711, Final Batch Loss: 9.427995246369392e-05\n",
      "Epoch 3469, Loss: 0.0007099852664396167, Final Batch Loss: 0.00027238260372541845\n",
      "Epoch 3470, Loss: 8.194175416065264e-05, Final Batch Loss: 6.487774498964427e-06\n",
      "Epoch 3471, Loss: 0.00022425950737670064, Final Batch Loss: 0.00015996098227333277\n",
      "Epoch 3472, Loss: 0.005198967148317024, Final Batch Loss: 0.005138959735631943\n",
      "Epoch 3473, Loss: 0.00021524418843910098, Final Batch Loss: 5.647208308801055e-05\n",
      "Epoch 3474, Loss: 0.0009685000413810485, Final Batch Loss: 1.267658171855146e-05\n",
      "Epoch 3475, Loss: 7.182420949902735e-05, Final Batch Loss: 2.4558626137149986e-06\n",
      "Epoch 3476, Loss: 6.688691519229906e-05, Final Batch Loss: 1.4213955182640348e-05\n",
      "Epoch 3477, Loss: 0.0003184408315064502, Final Batch Loss: 1.3241330634627957e-05\n",
      "Epoch 3478, Loss: 4.3130223275511526e-05, Final Batch Loss: 2.798969035211485e-05\n",
      "Epoch 3479, Loss: 0.000128208444948541, Final Batch Loss: 1.0950618161587045e-05\n",
      "Epoch 3480, Loss: 0.00019641988910734653, Final Batch Loss: 9.822903666645288e-05\n",
      "Epoch 3481, Loss: 9.080986455956008e-05, Final Batch Loss: 2.096899515890982e-05\n",
      "Epoch 3482, Loss: 6.642952939728275e-05, Final Batch Loss: 4.0749269828666e-05\n",
      "Epoch 3483, Loss: 3.548875156411668e-05, Final Batch Loss: 1.1150436876050662e-05\n",
      "Epoch 3484, Loss: 0.0013831684900651453, Final Batch Loss: 2.277873682032805e-05\n",
      "Epoch 3485, Loss: 0.00015483260176551994, Final Batch Loss: 2.008768751693424e-05\n",
      "Epoch 3486, Loss: 0.0003129239375994075, Final Batch Loss: 4.3678435758920386e-05\n",
      "Epoch 3487, Loss: 6.753869820386171e-05, Final Batch Loss: 4.4785771024180576e-05\n",
      "Epoch 3488, Loss: 0.00038368536661437247, Final Batch Loss: 1.1244201232329942e-05\n",
      "Epoch 3489, Loss: 8.967882604338229e-05, Final Batch Loss: 3.2831725548021495e-05\n",
      "Epoch 3490, Loss: 0.0002910681942012161, Final Batch Loss: 0.0002067986933980137\n",
      "Epoch 3491, Loss: 8.052733392105438e-05, Final Batch Loss: 1.6356247215298936e-05\n",
      "Epoch 3492, Loss: 6.393838521034922e-05, Final Batch Loss: 1.253385744348634e-05\n",
      "Epoch 3493, Loss: 0.00036428847306524403, Final Batch Loss: 0.0003152838035020977\n",
      "Epoch 3494, Loss: 0.00016237011550401803, Final Batch Loss: 0.00014352219295687973\n",
      "Epoch 3495, Loss: 0.005249087577794853, Final Batch Loss: 0.0052359323017299175\n",
      "Epoch 3496, Loss: 4.764434379467275e-05, Final Batch Loss: 2.2583439204026945e-05\n",
      "Epoch 3497, Loss: 5.445968508865917e-05, Final Batch Loss: 1.3207242773205508e-05\n",
      "Epoch 3498, Loss: 0.00024895074420783203, Final Batch Loss: 0.00022249184257816523\n",
      "Epoch 3499, Loss: 0.00015089781663846225, Final Batch Loss: 1.554765913169831e-05\n",
      "Epoch 3500, Loss: 0.00011728607933036983, Final Batch Loss: 1.8517843273002654e-05\n",
      "Epoch 3501, Loss: 6.22676661805599e-05, Final Batch Loss: 9.448415767110419e-06\n",
      "Epoch 3502, Loss: 0.00048614435399940703, Final Batch Loss: 0.00047411711420863867\n",
      "Epoch 3503, Loss: 0.00014505302533507347, Final Batch Loss: 6.0550788475666195e-05\n",
      "Epoch 3504, Loss: 6.128525092208292e-05, Final Batch Loss: 2.332790791115258e-05\n",
      "Epoch 3505, Loss: 9.122053597820923e-05, Final Batch Loss: 3.2159667171072215e-05\n",
      "Epoch 3506, Loss: 0.0015454517706530169, Final Batch Loss: 8.879679080564529e-05\n",
      "Epoch 3507, Loss: 0.0018540025994298048, Final Batch Loss: 3.228430432500318e-05\n",
      "Epoch 3508, Loss: 0.0001678552434896119, Final Batch Loss: 6.780242983950302e-05\n",
      "Epoch 3509, Loss: 0.00018389328761259094, Final Batch Loss: 3.467704664217308e-05\n",
      "Epoch 3510, Loss: 0.0014144973320071585, Final Batch Loss: 6.087934161769226e-05\n",
      "Epoch 3511, Loss: 0.00012945800335728563, Final Batch Loss: 0.00010925396782113239\n",
      "Epoch 3512, Loss: 2.741167463682359e-05, Final Batch Loss: 9.667700396676082e-06\n",
      "Epoch 3513, Loss: 6.491087515314575e-05, Final Batch Loss: 5.4904445278225467e-05\n",
      "Epoch 3514, Loss: 0.0016937825712375343, Final Batch Loss: 3.9812352042645216e-05\n",
      "Epoch 3515, Loss: 0.00042932265205308795, Final Batch Loss: 0.00016423524357378483\n",
      "Epoch 3516, Loss: 3.958076467824867e-05, Final Batch Loss: 2.7163338017999195e-05\n",
      "Epoch 3517, Loss: 0.0003427324163567391, Final Batch Loss: 9.68642871157499e-06\n",
      "Epoch 3518, Loss: 0.00011997429828625172, Final Batch Loss: 7.759418076602742e-05\n",
      "Epoch 3519, Loss: 0.0015648862081434345, Final Batch Loss: 1.607802369107958e-05\n",
      "Epoch 3520, Loss: 0.0001190804532598122, Final Batch Loss: 1.084534505935153e-05\n",
      "Epoch 3521, Loss: 5.2548470193869434e-05, Final Batch Loss: 3.0235964004532434e-05\n",
      "Epoch 3522, Loss: 0.006038484796590637, Final Batch Loss: 0.006002921611070633\n",
      "Epoch 3523, Loss: 5.873112786503043e-05, Final Batch Loss: 8.929417163017206e-06\n",
      "Epoch 3524, Loss: 7.541756349382922e-05, Final Batch Loss: 4.133413312956691e-05\n",
      "Epoch 3525, Loss: 0.00029527304286602885, Final Batch Loss: 0.00014944467693567276\n",
      "Epoch 3526, Loss: 5.0781265599653125e-05, Final Batch Loss: 1.4153927622828633e-05\n",
      "Epoch 3527, Loss: 0.00018457812620908953, Final Batch Loss: 0.00014152297808323056\n",
      "Epoch 3528, Loss: 0.0001513522511231713, Final Batch Loss: 2.5797424314077944e-05\n",
      "Epoch 3529, Loss: 0.00011616167830652557, Final Batch Loss: 3.045436824322678e-05\n",
      "Epoch 3530, Loss: 2.564511487435084e-05, Final Batch Loss: 1.3769393262919039e-05\n",
      "Epoch 3531, Loss: 0.00019389802764635533, Final Batch Loss: 6.216068868525326e-05\n",
      "Epoch 3532, Loss: 6.330346241156803e-05, Final Batch Loss: 3.8919979488127865e-06\n",
      "Epoch 3533, Loss: 0.0016581771305936854, Final Batch Loss: 3.7848378269700333e-05\n",
      "Epoch 3534, Loss: 0.0010344765323679894, Final Batch Loss: 0.0007733652018941939\n",
      "Epoch 3535, Loss: 9.797694019653136e-05, Final Batch Loss: 5.120754394738469e-06\n",
      "Epoch 3536, Loss: 0.0019961927796430246, Final Batch Loss: 2.1885393834963907e-06\n",
      "Epoch 3537, Loss: 2.210647676292865e-05, Final Batch Loss: 3.228973810109892e-06\n",
      "Epoch 3538, Loss: 4.318159199101501e-05, Final Batch Loss: 4.227697445458034e-06\n",
      "Epoch 3539, Loss: 0.0002124689235643018, Final Batch Loss: 5.893160778214224e-05\n",
      "Epoch 3540, Loss: 0.0016568173923587892, Final Batch Loss: 1.0319174180040136e-05\n",
      "Epoch 3541, Loss: 0.0020421674471435836, Final Batch Loss: 2.42852602241328e-05\n",
      "Epoch 3542, Loss: 6.422162005037535e-05, Final Batch Loss: 2.55268005275866e-05\n",
      "Epoch 3543, Loss: 2.7185905310034286e-05, Final Batch Loss: 1.1252414878981654e-05\n",
      "Epoch 3544, Loss: 0.00017922458027896937, Final Batch Loss: 1.9413555492064916e-05\n",
      "Epoch 3545, Loss: 4.936651384923607e-05, Final Batch Loss: 7.196969818323851e-06\n",
      "Epoch 3546, Loss: 6.46506096018129e-05, Final Batch Loss: 1.4292248124547768e-05\n",
      "Epoch 3547, Loss: 3.0462556878774194e-05, Final Batch Loss: 7.508338512707269e-06\n",
      "Epoch 3548, Loss: 0.00018132829791284166, Final Batch Loss: 5.113353472552262e-05\n",
      "Epoch 3549, Loss: 0.00019381404490559362, Final Batch Loss: 3.691778329084627e-05\n",
      "Epoch 3550, Loss: 7.125640513550024e-05, Final Batch Loss: 2.05867054319242e-05\n",
      "Epoch 3551, Loss: 0.004174342211626936, Final Batch Loss: 0.0041031441651284695\n",
      "Epoch 3552, Loss: 8.492180859320797e-05, Final Batch Loss: 1.1412910680519417e-05\n",
      "Epoch 3553, Loss: 6.468329343078949e-05, Final Batch Loss: 6.133466376923025e-05\n",
      "Epoch 3554, Loss: 0.00017387063871865394, Final Batch Loss: 3.5088205549982376e-06\n",
      "Epoch 3555, Loss: 9.481341294304002e-05, Final Batch Loss: 2.3674527255934663e-05\n",
      "Epoch 3556, Loss: 0.00039873752393759787, Final Batch Loss: 0.0002508123288862407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3557, Loss: 4.2811123421415687e-05, Final Batch Loss: 1.297321250604e-05\n",
      "Epoch 3558, Loss: 6.843435585324187e-05, Final Batch Loss: 4.970349255017936e-05\n",
      "Epoch 3559, Loss: 0.002078631883705384, Final Batch Loss: 2.641881837917026e-05\n",
      "Epoch 3560, Loss: 0.00010673581346054561, Final Batch Loss: 6.818216934334487e-05\n",
      "Epoch 3561, Loss: 0.0007123138639144599, Final Batch Loss: 0.0002589360810816288\n",
      "Epoch 3562, Loss: 0.00027654936639009975, Final Batch Loss: 0.0002501642447896302\n",
      "Epoch 3563, Loss: 0.0005966925755274133, Final Batch Loss: 1.4016602108313236e-05\n",
      "Epoch 3564, Loss: 0.0006972406572458567, Final Batch Loss: 2.710808075789828e-05\n",
      "Epoch 3565, Loss: 0.001466568690375425, Final Batch Loss: 7.874812581576407e-06\n",
      "Epoch 3566, Loss: 8.017105756152887e-05, Final Batch Loss: 2.4947255951701663e-05\n",
      "Epoch 3567, Loss: 0.0015734812041046098, Final Batch Loss: 3.643189847934991e-05\n",
      "Epoch 3568, Loss: 2.6437468932272168e-05, Final Batch Loss: 6.214799668669002e-06\n",
      "Epoch 3569, Loss: 8.93265096237883e-05, Final Batch Loss: 5.632103784591891e-05\n",
      "Epoch 3570, Loss: 0.00010529525752644986, Final Batch Loss: 5.1500021072570235e-05\n",
      "Epoch 3571, Loss: 0.0033853046625154093, Final Batch Loss: 0.0033061255235224962\n",
      "Epoch 3572, Loss: 0.00017454272938266513, Final Batch Loss: 5.189271632843884e-06\n",
      "Epoch 3573, Loss: 3.001647473865887e-05, Final Batch Loss: 5.214681550569367e-06\n",
      "Epoch 3574, Loss: 0.0016033832944231108, Final Batch Loss: 0.00019807084754575044\n",
      "Epoch 3575, Loss: 3.168493458360899e-05, Final Batch Loss: 1.9811026504612528e-05\n",
      "Epoch 3576, Loss: 0.00018954474762722384, Final Batch Loss: 0.00016431634139735252\n",
      "Epoch 3577, Loss: 0.004127307889575604, Final Batch Loss: 0.0040533593855798244\n",
      "Epoch 3578, Loss: 0.00020164752640994266, Final Batch Loss: 1.814703136915341e-05\n",
      "Epoch 3579, Loss: 0.0007956388180900831, Final Batch Loss: 2.82316941593308e-05\n",
      "Epoch 3580, Loss: 8.678955782670528e-05, Final Batch Loss: 3.275280323578045e-05\n",
      "Epoch 3581, Loss: 8.103100299194921e-05, Final Batch Loss: 6.7593009589472786e-06\n",
      "Epoch 3582, Loss: 0.030163864976202603, Final Batch Loss: 5.9844365750905126e-05\n",
      "Epoch 3583, Loss: 0.005066001984232571, Final Batch Loss: 0.005051571875810623\n",
      "Epoch 3584, Loss: 6.823188778071199e-05, Final Batch Loss: 6.4136420405702665e-06\n",
      "Epoch 3585, Loss: 0.000209617104701465, Final Batch Loss: 0.00016981644148472697\n",
      "Epoch 3586, Loss: 6.272623249969911e-05, Final Batch Loss: 4.172609988017939e-05\n",
      "Epoch 3587, Loss: 0.00017102946367231198, Final Batch Loss: 0.0001350415259366855\n",
      "Epoch 3588, Loss: 7.047269900795072e-05, Final Batch Loss: 3.081563409068622e-05\n",
      "Epoch 3589, Loss: 0.00035285342164570466, Final Batch Loss: 0.00027530966326594353\n",
      "Epoch 3590, Loss: 3.609247778513236e-05, Final Batch Loss: 1.2609377336048055e-05\n",
      "Epoch 3591, Loss: 0.001973534752323758, Final Batch Loss: 6.359611143125221e-05\n",
      "Epoch 3592, Loss: 3.768048554775305e-05, Final Batch Loss: 1.3095208487357013e-05\n",
      "Epoch 3593, Loss: 0.0001659834015299566, Final Batch Loss: 3.571375418687239e-05\n",
      "Epoch 3594, Loss: 0.00011365999762347201, Final Batch Loss: 1.2867575605923776e-05\n",
      "Epoch 3595, Loss: 0.00025140571233350784, Final Batch Loss: 1.0065385140478611e-05\n",
      "Epoch 3596, Loss: 4.1418370528845116e-05, Final Batch Loss: 2.6545061700744554e-05\n",
      "Epoch 3597, Loss: 0.00031928006501402706, Final Batch Loss: 6.34852476650849e-05\n",
      "Epoch 3598, Loss: 0.004498295471421443, Final Batch Loss: 5.713649443350732e-06\n",
      "Epoch 3599, Loss: 4.596763028530404e-05, Final Batch Loss: 2.1746947822975926e-05\n",
      "Epoch 3600, Loss: 0.003197939361371027, Final Batch Loss: 3.2787145300972043e-06\n",
      "Epoch 3601, Loss: 6.845220559625886e-05, Final Batch Loss: 3.529815512592904e-05\n",
      "Epoch 3602, Loss: 1.4872111933073029e-05, Final Batch Loss: 7.559269761259202e-06\n",
      "Epoch 3603, Loss: 0.0007130929552658927, Final Batch Loss: 0.000656452146358788\n",
      "Epoch 3604, Loss: 0.00014777738761040382, Final Batch Loss: 1.7350390407955274e-05\n",
      "Epoch 3605, Loss: 3.91416106140241e-05, Final Batch Loss: 9.385788871441036e-06\n",
      "Epoch 3606, Loss: 0.00021647218090947717, Final Batch Loss: 6.624813249800354e-05\n",
      "Epoch 3607, Loss: 0.00030651097040390596, Final Batch Loss: 0.00020244764164090157\n",
      "Epoch 3608, Loss: 0.02770496578887105, Final Batch Loss: 0.02106008678674698\n",
      "Epoch 3609, Loss: 2.8673539418377914e-05, Final Batch Loss: 1.414834969182266e-05\n",
      "Epoch 3610, Loss: 0.0016345970070688054, Final Batch Loss: 0.0001466308458475396\n",
      "Epoch 3611, Loss: 5.669015990861226e-05, Final Batch Loss: 3.948103039874695e-05\n",
      "Epoch 3612, Loss: 0.00012666495240409859, Final Batch Loss: 9.582423808751628e-05\n",
      "Epoch 3613, Loss: 0.00022403954426408745, Final Batch Loss: 3.348205427755602e-05\n",
      "Epoch 3614, Loss: 0.00012515478738350794, Final Batch Loss: 1.9855164282489568e-05\n",
      "Epoch 3615, Loss: 1.315507824983797e-05, Final Batch Loss: 2.9037705644441303e-06\n",
      "Epoch 3616, Loss: 6.366062916640658e-05, Final Batch Loss: 9.28247936826665e-06\n",
      "Epoch 3617, Loss: 5.9020898333983496e-05, Final Batch Loss: 3.937285509891808e-05\n",
      "Epoch 3618, Loss: 0.0004675569216487929, Final Batch Loss: 9.911991946864873e-05\n",
      "Epoch 3619, Loss: 0.004209449689369649, Final Batch Loss: 0.003591911867260933\n",
      "Epoch 3620, Loss: 8.617423009127378e-05, Final Batch Loss: 1.6294543456751853e-05\n",
      "Epoch 3621, Loss: 0.020065369884832762, Final Batch Loss: 0.020035380497574806\n",
      "Epoch 3622, Loss: 6.598741492780391e-05, Final Batch Loss: 3.00362389680231e-05\n",
      "Epoch 3623, Loss: 0.000378611253836425, Final Batch Loss: 0.0003389437042642385\n",
      "Epoch 3624, Loss: 7.144078335841186e-05, Final Batch Loss: 1.6409161617048085e-05\n",
      "Epoch 3625, Loss: 8.49250018291059e-05, Final Batch Loss: 6.087185283831786e-06\n",
      "Epoch 3626, Loss: 0.00011179087596246973, Final Batch Loss: 3.564189682947472e-05\n",
      "Epoch 3627, Loss: 0.00017740752628014889, Final Batch Loss: 1.7202843082486652e-05\n",
      "Epoch 3628, Loss: 0.0005498150276253, Final Batch Loss: 9.609990229364485e-05\n",
      "Epoch 3629, Loss: 0.00015303735199267976, Final Batch Loss: 9.480625158175826e-05\n",
      "Epoch 3630, Loss: 0.001552222132886527, Final Batch Loss: 4.90295460622292e-05\n",
      "Epoch 3631, Loss: 0.00013208734708314296, Final Batch Loss: 0.00010359146108385175\n",
      "Epoch 3632, Loss: 0.023353248414423433, Final Batch Loss: 2.615298035379965e-05\n",
      "Epoch 3633, Loss: 0.00018364027346251532, Final Batch Loss: 9.40572572289966e-05\n",
      "Epoch 3634, Loss: 0.0016714524026610889, Final Batch Loss: 8.181363955372944e-05\n",
      "Epoch 3635, Loss: 0.00038635417877230793, Final Batch Loss: 0.00016974270693026483\n",
      "Epoch 3636, Loss: 0.0003933025709557114, Final Batch Loss: 1.608802813279908e-05\n",
      "Epoch 3637, Loss: 0.008300313958898187, Final Batch Loss: 0.004866851028054953\n",
      "Epoch 3638, Loss: 0.036380899597133975, Final Batch Loss: 6.789480539737269e-05\n",
      "Epoch 3639, Loss: 0.021836634979990777, Final Batch Loss: 0.02177145890891552\n",
      "Epoch 3640, Loss: 4.499949295677652e-05, Final Batch Loss: 3.654798774732626e-06\n",
      "Epoch 3641, Loss: 6.161492910905508e-05, Final Batch Loss: 4.706716208602302e-05\n",
      "Epoch 3642, Loss: 0.0020741913322126493, Final Batch Loss: 0.00018017120601143688\n",
      "Epoch 3643, Loss: 0.0022150453296490014, Final Batch Loss: 0.0017204944742843509\n",
      "Epoch 3644, Loss: 0.00012190032066428103, Final Batch Loss: 6.333207420539111e-05\n",
      "Epoch 3645, Loss: 0.000576913109398447, Final Batch Loss: 0.00046398001722991467\n",
      "Epoch 3646, Loss: 0.0007260946731548756, Final Batch Loss: 0.0005954306689091027\n",
      "Epoch 3647, Loss: 0.015753817628137767, Final Batch Loss: 0.0018472716910764575\n",
      "Epoch 3648, Loss: 0.0003198949998477474, Final Batch Loss: 0.0001768410438671708\n",
      "Epoch 3649, Loss: 0.0003745500507648103, Final Batch Loss: 0.00010890940757235512\n",
      "Epoch 3650, Loss: 0.00024390903490711935, Final Batch Loss: 0.00019672686175908893\n",
      "Epoch 3651, Loss: 0.00021628848480759189, Final Batch Loss: 0.00013483857037499547\n",
      "Epoch 3652, Loss: 0.00036854451172985137, Final Batch Loss: 0.00017291375843342394\n",
      "Epoch 3653, Loss: 0.00027881632559001446, Final Batch Loss: 0.00012838238035328686\n",
      "Epoch 3654, Loss: 0.0005849055487487931, Final Batch Loss: 0.0005311419372446835\n",
      "Epoch 3655, Loss: 0.012040144523780327, Final Batch Loss: 0.01194501481950283\n",
      "Epoch 3656, Loss: 0.0002627775684231892, Final Batch Loss: 0.00013803332694806159\n",
      "Epoch 3657, Loss: 0.0001270627781195799, Final Batch Loss: 1.4289618775364943e-05\n",
      "Epoch 3658, Loss: 0.0006218041526153684, Final Batch Loss: 7.218430982902646e-05\n",
      "Epoch 3659, Loss: 0.00015679305033700075, Final Batch Loss: 1.3341958037926815e-05\n",
      "Epoch 3660, Loss: 0.00012949802112416364, Final Batch Loss: 8.681736653670669e-05\n",
      "Epoch 3661, Loss: 0.00010304239003744442, Final Batch Loss: 8.01780479378067e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3662, Loss: 0.0003150622796965763, Final Batch Loss: 2.4396824301220477e-05\n",
      "Epoch 3663, Loss: 0.001185556895507034, Final Batch Loss: 1.6691417840775102e-05\n",
      "Epoch 3664, Loss: 0.00010135707998415455, Final Batch Loss: 4.067452027811669e-05\n",
      "Epoch 3665, Loss: 0.00043112520506838337, Final Batch Loss: 3.872215893352404e-05\n",
      "Epoch 3666, Loss: 0.00024692712031537667, Final Batch Loss: 7.806698704371229e-05\n",
      "Epoch 3667, Loss: 0.000230630008445587, Final Batch Loss: 0.0001201072009280324\n",
      "Epoch 3668, Loss: 0.0001061970124283107, Final Batch Loss: 7.693956285947934e-05\n",
      "Epoch 3669, Loss: 0.0017433856237403234, Final Batch Loss: 1.0251821549900342e-05\n",
      "Epoch 3670, Loss: 9.883114580588881e-05, Final Batch Loss: 7.88718753028661e-05\n",
      "Epoch 3671, Loss: 0.001983310252398951, Final Batch Loss: 4.292481389711611e-05\n",
      "Epoch 3672, Loss: 0.000320598206599243, Final Batch Loss: 0.00022238648671191186\n",
      "Epoch 3673, Loss: 0.00022748487390344962, Final Batch Loss: 5.519483966054395e-05\n",
      "Epoch 3674, Loss: 0.00011658411312964745, Final Batch Loss: 6.796497473260388e-05\n",
      "Epoch 3675, Loss: 0.00012848883488913998, Final Batch Loss: 0.00010809515515575185\n",
      "Epoch 3676, Loss: 0.0010774262336781248, Final Batch Loss: 0.00022986081603448838\n",
      "Epoch 3677, Loss: 0.00043308697058819234, Final Batch Loss: 0.00023282297479454428\n",
      "Epoch 3678, Loss: 0.0001732527271087747, Final Batch Loss: 0.0001279715506825596\n",
      "Epoch 3679, Loss: 5.1355020332266577e-05, Final Batch Loss: 1.8513694158173166e-05\n",
      "Epoch 3680, Loss: 0.00011857713980134577, Final Batch Loss: 1.7246675270143896e-05\n",
      "Epoch 3681, Loss: 0.0001644785370444879, Final Batch Loss: 5.496980156749487e-05\n",
      "Epoch 3682, Loss: 9.796273661777377e-05, Final Batch Loss: 4.9396068789064884e-05\n",
      "Epoch 3683, Loss: 0.0013170729507692158, Final Batch Loss: 0.00043441104935482144\n",
      "Epoch 3684, Loss: 0.0005926095909671858, Final Batch Loss: 7.652946806047112e-05\n",
      "Epoch 3685, Loss: 0.0004800056340172887, Final Batch Loss: 0.00013812328688800335\n",
      "Epoch 3686, Loss: 9.488846990279853e-05, Final Batch Loss: 1.844134385464713e-05\n",
      "Epoch 3687, Loss: 0.00017931378897628747, Final Batch Loss: 5.427407086244784e-05\n",
      "Epoch 3688, Loss: 0.0004172758126514964, Final Batch Loss: 0.00033160715247504413\n",
      "Epoch 3689, Loss: 0.0056386193027719855, Final Batch Loss: 0.004139149561524391\n",
      "Epoch 3690, Loss: 0.00034543598303571343, Final Batch Loss: 0.00019149169384036213\n",
      "Epoch 3691, Loss: 0.0006507412308565108, Final Batch Loss: 2.5914761863532476e-05\n",
      "Epoch 3692, Loss: 0.0010910815326496959, Final Batch Loss: 0.0010246167657896876\n",
      "Epoch 3693, Loss: 0.004493016043852549, Final Batch Loss: 0.004395284689962864\n",
      "Epoch 3694, Loss: 0.0002577474879217334, Final Batch Loss: 4.349805385572836e-05\n",
      "Epoch 3695, Loss: 0.001786881941370666, Final Batch Loss: 0.00034103216603398323\n",
      "Epoch 3696, Loss: 0.004858550993958488, Final Batch Loss: 4.859446198679507e-05\n",
      "Epoch 3697, Loss: 0.0002132842746505048, Final Batch Loss: 0.00016257532115560025\n",
      "Epoch 3698, Loss: 0.0001162961962108966, Final Batch Loss: 7.394303247565404e-05\n",
      "Epoch 3699, Loss: 0.003386321128346026, Final Batch Loss: 0.0005299175390973687\n",
      "Epoch 3700, Loss: 9.019780372909736e-05, Final Batch Loss: 2.9128937967470847e-05\n",
      "Epoch 3701, Loss: 5.005039201932959e-05, Final Batch Loss: 4.108504072064534e-06\n",
      "Epoch 3702, Loss: 0.003537008667990449, Final Batch Loss: 1.1657959475996904e-05\n",
      "Epoch 3703, Loss: 4.126465864828788e-05, Final Batch Loss: 2.9569964681286365e-06\n",
      "Epoch 3704, Loss: 5.393256651586853e-05, Final Batch Loss: 2.6096302462974563e-05\n",
      "Epoch 3705, Loss: 0.00045749838318442926, Final Batch Loss: 0.00038913043681532145\n",
      "Epoch 3706, Loss: 0.0001129787906393176, Final Batch Loss: 1.786520988389384e-05\n",
      "Epoch 3707, Loss: 6.222461524885148e-05, Final Batch Loss: 1.8002112483372912e-05\n",
      "Epoch 3708, Loss: 0.0009274684271076694, Final Batch Loss: 0.0008841955568641424\n",
      "Epoch 3709, Loss: 0.0003394780069356784, Final Batch Loss: 0.0001835046714404598\n",
      "Epoch 3710, Loss: 8.491333665006096e-05, Final Batch Loss: 3.8597072489210404e-06\n",
      "Epoch 3711, Loss: 3.4563949157018214e-05, Final Batch Loss: 1.3063250662526116e-05\n",
      "Epoch 3712, Loss: 0.00452492826480011, Final Batch Loss: 0.004498384427279234\n",
      "Epoch 3713, Loss: 0.0007826739965821616, Final Batch Loss: 0.000668681226670742\n",
      "Epoch 3714, Loss: 0.004967036147718318, Final Batch Loss: 0.004927477333694696\n",
      "Epoch 3715, Loss: 0.0005188840805203654, Final Batch Loss: 0.0004276390827726573\n",
      "Epoch 3716, Loss: 1.9557312043616548e-05, Final Batch Loss: 4.503074706008192e-06\n",
      "Epoch 3717, Loss: 0.0002420744494884275, Final Batch Loss: 7.076112524373457e-05\n",
      "Epoch 3718, Loss: 0.0005666875804308802, Final Batch Loss: 0.00027107555069960654\n",
      "Epoch 3719, Loss: 8.13536180430674e-05, Final Batch Loss: 1.2934441656398121e-05\n",
      "Epoch 3720, Loss: 0.00017297163867624477, Final Batch Loss: 4.0008693758863956e-05\n",
      "Epoch 3721, Loss: 0.0005231514951447025, Final Batch Loss: 0.0001961707166628912\n",
      "Epoch 3722, Loss: 0.00024011687128222547, Final Batch Loss: 0.00018552161054685712\n",
      "Epoch 3723, Loss: 0.00010729027417255566, Final Batch Loss: 5.7229935919167474e-05\n",
      "Epoch 3724, Loss: 0.00045641361793968827, Final Batch Loss: 0.00021237207693047822\n",
      "Epoch 3725, Loss: 0.00025515572633594275, Final Batch Loss: 4.993207403458655e-05\n",
      "Epoch 3726, Loss: 0.00010190448119828943, Final Batch Loss: 2.029285860771779e-05\n",
      "Epoch 3727, Loss: 6.963737359910738e-05, Final Batch Loss: 4.8179230361711234e-05\n",
      "Epoch 3728, Loss: 0.0011873973835463403, Final Batch Loss: 1.8147968148696236e-05\n",
      "Epoch 3729, Loss: 0.0001917193876579404, Final Batch Loss: 0.00016280463023576885\n",
      "Epoch 3730, Loss: 0.00017393627058481798, Final Batch Loss: 4.969489964423701e-05\n",
      "Epoch 3731, Loss: 8.238469399657333e-05, Final Batch Loss: 6.914692676218692e-06\n",
      "Epoch 3732, Loss: 0.00015531700773863122, Final Batch Loss: 3.289053711341694e-05\n",
      "Epoch 3733, Loss: 7.303950405912474e-05, Final Batch Loss: 5.542948565562256e-05\n",
      "Epoch 3734, Loss: 0.00010332604142604396, Final Batch Loss: 7.822016777936369e-05\n",
      "Epoch 3735, Loss: 0.004611241070961114, Final Batch Loss: 5.564363527810201e-05\n",
      "Epoch 3736, Loss: 0.0005448260562843643, Final Batch Loss: 0.00043534854194149375\n",
      "Epoch 3737, Loss: 0.00015721697127446532, Final Batch Loss: 6.930571544216946e-05\n",
      "Epoch 3738, Loss: 0.00015826787966943812, Final Batch Loss: 0.00012917484855279326\n",
      "Epoch 3739, Loss: 9.36809756240109e-05, Final Batch Loss: 1.9471373889246024e-05\n",
      "Epoch 3740, Loss: 0.005264522649667924, Final Batch Loss: 0.005247080698609352\n",
      "Epoch 3741, Loss: 0.0001209380934596993, Final Batch Loss: 7.582813850603998e-05\n",
      "Epoch 3742, Loss: 0.0014154375548969256, Final Batch Loss: 2.3522881747339852e-05\n",
      "Epoch 3743, Loss: 0.0001028085571306292, Final Batch Loss: 5.1840990636264905e-05\n",
      "Epoch 3744, Loss: 0.0004925207504129503, Final Batch Loss: 2.5768913474166766e-05\n",
      "Epoch 3745, Loss: 0.00029870167782064527, Final Batch Loss: 6.142593338154256e-05\n",
      "Epoch 3746, Loss: 7.164308408391662e-05, Final Batch Loss: 4.057344631291926e-05\n",
      "Epoch 3747, Loss: 0.010317176594980992, Final Batch Loss: 0.010239839553833008\n",
      "Epoch 3748, Loss: 4.171939144725911e-05, Final Batch Loss: 2.3910313757369295e-05\n",
      "Epoch 3749, Loss: 0.00011973741857218556, Final Batch Loss: 4.3667892896337435e-05\n",
      "Epoch 3750, Loss: 0.00024330133601324633, Final Batch Loss: 0.0001526193373138085\n",
      "Epoch 3751, Loss: 0.0013345397273951676, Final Batch Loss: 3.299233139841817e-05\n",
      "Epoch 3752, Loss: 0.00011843486572615802, Final Batch Loss: 5.89312803640496e-05\n",
      "Epoch 3753, Loss: 0.0007998005567060318, Final Batch Loss: 0.0007567911525256932\n",
      "Epoch 3754, Loss: 0.000258513984590536, Final Batch Loss: 4.985223858966492e-05\n",
      "Epoch 3755, Loss: 0.00010983957326970994, Final Batch Loss: 1.6162732208613306e-05\n",
      "Epoch 3756, Loss: 6.90521424075996e-05, Final Batch Loss: 5.984469225950306e-06\n",
      "Epoch 3757, Loss: 0.00014889237354509532, Final Batch Loss: 9.87422390608117e-05\n",
      "Epoch 3758, Loss: 9.13481526367832e-05, Final Batch Loss: 5.76648126298096e-05\n",
      "Epoch 3759, Loss: 0.00023216904082801193, Final Batch Loss: 4.3672756874002516e-05\n",
      "Epoch 3760, Loss: 7.47289668652229e-05, Final Batch Loss: 3.074013875448145e-05\n",
      "Epoch 3761, Loss: 0.00013563450193032622, Final Batch Loss: 1.883816730696708e-05\n",
      "Epoch 3762, Loss: 7.619910320499912e-05, Final Batch Loss: 4.005379742011428e-05\n",
      "Epoch 3763, Loss: 8.16973715700442e-05, Final Batch Loss: 5.490634066518396e-05\n",
      "Epoch 3764, Loss: 0.00010160712554352358, Final Batch Loss: 4.507762787397951e-05\n",
      "Epoch 3765, Loss: 3.7814787901879754e-05, Final Batch Loss: 1.4010937775310595e-05\n",
      "Epoch 3766, Loss: 0.00024841817594278837, Final Batch Loss: 9.94111269392306e-06\n",
      "Epoch 3767, Loss: 8.370728392037563e-05, Final Batch Loss: 5.466688526212238e-05\n",
      "Epoch 3768, Loss: 0.000491201069962699, Final Batch Loss: 0.00040447176434099674\n",
      "Epoch 3769, Loss: 0.00011864243515447015, Final Batch Loss: 7.004725375736598e-06\n",
      "Epoch 3770, Loss: 9.858907833404373e-05, Final Batch Loss: 1.7579126506461762e-05\n",
      "Epoch 3771, Loss: 0.0006632076256209984, Final Batch Loss: 0.0005113885854370892\n",
      "Epoch 3772, Loss: 0.002015302779909689, Final Batch Loss: 5.0129259761888534e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3773, Loss: 0.00029676758640562184, Final Batch Loss: 0.00024653133004903793\n",
      "Epoch 3774, Loss: 0.002563354260928463, Final Batch Loss: 4.1751824028324336e-05\n",
      "Epoch 3775, Loss: 6.875046528875828e-05, Final Batch Loss: 5.732443605666049e-05\n",
      "Epoch 3776, Loss: 0.0002099114144584746, Final Batch Loss: 5.641873030981515e-06\n",
      "Epoch 3777, Loss: 0.0016559540963498875, Final Batch Loss: 1.5892830560915172e-05\n",
      "Epoch 3778, Loss: 9.910471271723509e-05, Final Batch Loss: 7.14743509888649e-06\n",
      "Epoch 3779, Loss: 0.0009270894224755466, Final Batch Loss: 7.311231456696987e-05\n",
      "Epoch 3780, Loss: 0.00018991071738128085, Final Batch Loss: 2.7862728529726155e-05\n",
      "Epoch 3781, Loss: 0.00012987836453248747, Final Batch Loss: 3.624205055530183e-05\n",
      "Epoch 3782, Loss: 0.00017289110837737098, Final Batch Loss: 3.6138306313659996e-05\n",
      "Epoch 3783, Loss: 8.814405191515107e-05, Final Batch Loss: 1.0293597370036878e-05\n",
      "Epoch 3784, Loss: 0.00018141908185498323, Final Batch Loss: 2.4317434508702718e-05\n",
      "Epoch 3785, Loss: 8.507549136993475e-05, Final Batch Loss: 5.280950426822528e-05\n",
      "Epoch 3786, Loss: 0.0025809981125348713, Final Batch Loss: 2.900685285567306e-05\n",
      "Epoch 3787, Loss: 7.483339140890166e-05, Final Batch Loss: 1.9139442883897573e-05\n",
      "Epoch 3788, Loss: 0.00040711941983317956, Final Batch Loss: 0.0003340502444189042\n",
      "Epoch 3789, Loss: 0.0020475769929362286, Final Batch Loss: 5.1500323934305925e-06\n",
      "Epoch 3790, Loss: 0.0017850565272965468, Final Batch Loss: 5.9914404118899256e-05\n",
      "Epoch 3791, Loss: 0.004398455228511011, Final Batch Loss: 0.004374194890260696\n",
      "Epoch 3792, Loss: 5.281824360281462e-05, Final Batch Loss: 3.795112206717022e-05\n",
      "Epoch 3793, Loss: 6.418981502065435e-05, Final Batch Loss: 3.6168690712656826e-05\n",
      "Epoch 3794, Loss: 5.140424946148414e-05, Final Batch Loss: 1.5707371858297847e-05\n",
      "Epoch 3795, Loss: 0.00014623703464167193, Final Batch Loss: 3.495771670714021e-05\n",
      "Epoch 3796, Loss: 0.0004314716497901827, Final Batch Loss: 0.00036090941284783185\n",
      "Epoch 3797, Loss: 0.0004320126572565641, Final Batch Loss: 3.2213018130278215e-05\n",
      "Epoch 3798, Loss: 8.9455708348396e-05, Final Batch Loss: 4.18259833168122e-06\n",
      "Epoch 3799, Loss: 0.00029040404115221463, Final Batch Loss: 0.0002614219265524298\n",
      "Epoch 3800, Loss: 0.00022139414068078622, Final Batch Loss: 1.3055243471171707e-05\n",
      "Epoch 3801, Loss: 0.0016787337081041187, Final Batch Loss: 0.00016291913925670087\n",
      "Epoch 3802, Loss: 0.0018722350232565077, Final Batch Loss: 2.9713775802520104e-05\n",
      "Epoch 3803, Loss: 0.001259980086615542, Final Batch Loss: 2.4730517907300964e-05\n",
      "Epoch 3804, Loss: 3.3761637951101875e-05, Final Batch Loss: 2.7878999389940873e-05\n",
      "Epoch 3805, Loss: 5.298032192513347e-05, Final Batch Loss: 3.357056266395375e-05\n",
      "Epoch 3806, Loss: 0.00012390632036840543, Final Batch Loss: 7.187015580711886e-05\n",
      "Epoch 3807, Loss: 5.24560637131799e-05, Final Batch Loss: 2.2682277631247416e-05\n",
      "Epoch 3808, Loss: 7.631865810253657e-05, Final Batch Loss: 1.7703529010759667e-05\n",
      "Epoch 3809, Loss: 0.0021065585024189204, Final Batch Loss: 0.0019583890680223703\n",
      "Epoch 3810, Loss: 0.00365332089131698, Final Batch Loss: 0.0033874937798827887\n",
      "Epoch 3811, Loss: 0.0002500080963727669, Final Batch Loss: 0.00023629498900845647\n",
      "Epoch 3812, Loss: 9.073676665138919e-05, Final Batch Loss: 6.39147765468806e-05\n",
      "Epoch 3813, Loss: 4.123316330151283e-05, Final Batch Loss: 5.760603471571812e-06\n",
      "Epoch 3814, Loss: 0.0011349947767484991, Final Batch Loss: 3.975338131567696e-06\n",
      "Epoch 3815, Loss: 0.00017399255455075036, Final Batch Loss: 1.7256141973120975e-06\n",
      "Epoch 3816, Loss: 2.5729855224199127e-05, Final Batch Loss: 7.891233508416917e-06\n",
      "Epoch 3817, Loss: 0.0018221306672785431, Final Batch Loss: 0.00027026425232179463\n",
      "Epoch 3818, Loss: 0.00010071456927107647, Final Batch Loss: 1.4560951967723668e-05\n",
      "Epoch 3819, Loss: 0.00018338712106924504, Final Batch Loss: 0.00011011216702172533\n",
      "Epoch 3820, Loss: 0.0021899661514908075, Final Batch Loss: 0.0004086567787453532\n",
      "Epoch 3821, Loss: 0.001209686161018908, Final Batch Loss: 0.0002751029096543789\n",
      "Epoch 3822, Loss: 1.520109299235628e-05, Final Batch Loss: 5.729631538997637e-06\n",
      "Epoch 3823, Loss: 5.901375516259577e-05, Final Batch Loss: 2.2050071493140422e-05\n",
      "Epoch 3824, Loss: 8.943612192524597e-05, Final Batch Loss: 3.283574915258214e-05\n",
      "Epoch 3825, Loss: 0.0001399071370542515, Final Batch Loss: 5.0836079026339576e-05\n",
      "Epoch 3826, Loss: 0.0001064962898453814, Final Batch Loss: 1.1712731975421775e-05\n",
      "Epoch 3827, Loss: 4.5906637751613744e-05, Final Batch Loss: 1.8632796127349138e-05\n",
      "Epoch 3828, Loss: 0.00033214713039342314, Final Batch Loss: 0.00023029423027765006\n",
      "Epoch 3829, Loss: 3.988831053902686e-05, Final Batch Loss: 2.1480129817064153e-06\n",
      "Epoch 3830, Loss: 0.0003050802224606741, Final Batch Loss: 5.679105015587993e-05\n",
      "Epoch 3831, Loss: 7.503312599510537e-05, Final Batch Loss: 1.4883430594636593e-06\n",
      "Epoch 3832, Loss: 5.155410190127441e-05, Final Batch Loss: 5.647567832056666e-06\n",
      "Epoch 3833, Loss: 0.00411879568855511, Final Batch Loss: 0.004032473545521498\n",
      "Epoch 3834, Loss: 0.002036776870227186, Final Batch Loss: 2.057828169199638e-05\n",
      "Epoch 3835, Loss: 4.676506887335563e-05, Final Batch Loss: 3.381966962479055e-05\n",
      "Epoch 3836, Loss: 0.003366729579283856, Final Batch Loss: 0.0032957543153315783\n",
      "Epoch 3837, Loss: 0.00011448889199527912, Final Batch Loss: 4.6840254071867093e-05\n",
      "Epoch 3838, Loss: 0.0018465434077370446, Final Batch Loss: 4.016911771032028e-05\n",
      "Epoch 3839, Loss: 0.00013911181395087624, Final Batch Loss: 1.4813937923463527e-05\n",
      "Epoch 3840, Loss: 0.00016427589980594348, Final Batch Loss: 0.00014216371346265078\n",
      "Epoch 3841, Loss: 0.0027490742068039253, Final Batch Loss: 0.0025958362966775894\n",
      "Epoch 3842, Loss: 9.602612044545822e-05, Final Batch Loss: 5.182597305974923e-05\n",
      "Epoch 3843, Loss: 2.733688552325475e-05, Final Batch Loss: 2.125574064848479e-05\n",
      "Epoch 3844, Loss: 0.0016650421221129363, Final Batch Loss: 0.0016400141175836325\n",
      "Epoch 3845, Loss: 0.0001423245957994368, Final Batch Loss: 5.197899372433312e-05\n",
      "Epoch 3846, Loss: 1.818207829273888e-05, Final Batch Loss: 6.799797574785771e-06\n",
      "Epoch 3847, Loss: 8.825693475955632e-05, Final Batch Loss: 4.570027158479206e-06\n",
      "Epoch 3848, Loss: 3.892704080499243e-05, Final Batch Loss: 1.4760838894289918e-05\n",
      "Epoch 3849, Loss: 6.0069885876146145e-05, Final Batch Loss: 3.907611608156003e-05\n",
      "Epoch 3850, Loss: 0.00014792829097132199, Final Batch Loss: 0.00012360209075268358\n",
      "Epoch 3851, Loss: 5.410308540376718e-05, Final Batch Loss: 5.124227300257189e-06\n",
      "Epoch 3852, Loss: 3.1880323149380274e-05, Final Batch Loss: 2.242078335257247e-05\n",
      "Epoch 3853, Loss: 0.0018068845693051117, Final Batch Loss: 2.4369715902139433e-05\n",
      "Epoch 3854, Loss: 8.952312509791227e-05, Final Batch Loss: 8.653701115690637e-06\n",
      "Epoch 3855, Loss: 4.958033241564408e-05, Final Batch Loss: 3.975359140895307e-05\n",
      "Epoch 3856, Loss: 7.5890427979175e-05, Final Batch Loss: 3.6853725760011e-05\n",
      "Epoch 3857, Loss: 5.7243869377998635e-05, Final Batch Loss: 3.750865289475769e-06\n",
      "Epoch 3858, Loss: 0.00024319752265000716, Final Batch Loss: 0.00017094436043407768\n",
      "Epoch 3859, Loss: 9.910429434967227e-05, Final Batch Loss: 6.968394154682755e-05\n",
      "Epoch 3860, Loss: 0.0010371602838858962, Final Batch Loss: 0.0009994145948439837\n",
      "Epoch 3861, Loss: 0.00035406847746344283, Final Batch Loss: 8.047332084970549e-05\n",
      "Epoch 3862, Loss: 5.7421061683271546e-05, Final Batch Loss: 6.798823051212821e-06\n",
      "Epoch 3863, Loss: 7.737530177109875e-05, Final Batch Loss: 1.7058115190593526e-05\n",
      "Epoch 3864, Loss: 4.140484452364035e-05, Final Batch Loss: 3.90017157769762e-06\n",
      "Epoch 3865, Loss: 0.0004667564817282255, Final Batch Loss: 0.00045510922791436315\n",
      "Epoch 3866, Loss: 3.117557480436517e-05, Final Batch Loss: 1.730007352307439e-05\n",
      "Epoch 3867, Loss: 5.2153180149616674e-05, Final Batch Loss: 1.7975136870518327e-05\n",
      "Epoch 3868, Loss: 0.00013496372775989585, Final Batch Loss: 4.316470949561335e-05\n",
      "Epoch 3869, Loss: 0.0032988577731885016, Final Batch Loss: 0.0031343246810138226\n",
      "Epoch 3870, Loss: 0.0002289767871843651, Final Batch Loss: 3.431540972087532e-05\n",
      "Epoch 3871, Loss: 2.475259952916531e-05, Final Batch Loss: 6.934521479706746e-06\n",
      "Epoch 3872, Loss: 0.0001621845549379941, Final Batch Loss: 0.00012505028280429542\n",
      "Epoch 3873, Loss: 0.00025629909214330837, Final Batch Loss: 0.0001365682401228696\n",
      "Epoch 3874, Loss: 0.00162119886954315, Final Batch Loss: 0.0003312663466203958\n",
      "Epoch 3875, Loss: 0.00013478505934472196, Final Batch Loss: 4.417723175720312e-05\n",
      "Epoch 3876, Loss: 9.129399768426083e-05, Final Batch Loss: 3.490756716928445e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3877, Loss: 4.89121230202727e-05, Final Batch Loss: 3.46156521118246e-05\n",
      "Epoch 3878, Loss: 6.575388761120848e-05, Final Batch Loss: 2.7862850402016193e-05\n",
      "Epoch 3879, Loss: 0.00014449850641540252, Final Batch Loss: 0.00012411638454068452\n",
      "Epoch 3880, Loss: 0.0013994168402859941, Final Batch Loss: 5.1879469538107514e-06\n",
      "Epoch 3881, Loss: 6.621867760259192e-05, Final Batch Loss: 8.90833507583011e-06\n",
      "Epoch 3882, Loss: 0.0007284266030183062, Final Batch Loss: 0.0006834475207142532\n",
      "Epoch 3883, Loss: 0.00010766861623778823, Final Batch Loss: 0.00010004753858083859\n",
      "Epoch 3884, Loss: 0.002956522352178581, Final Batch Loss: 0.0029086689464747906\n",
      "Epoch 3885, Loss: 0.00014682929031550884, Final Batch Loss: 6.618357292609289e-05\n",
      "Epoch 3886, Loss: 0.0012543266130933262, Final Batch Loss: 1.5299957567549427e-06\n",
      "Epoch 3887, Loss: 9.247649268218083e-05, Final Batch Loss: 8.313998114317656e-05\n",
      "Epoch 3888, Loss: 0.0014330983758554794, Final Batch Loss: 5.205386696616188e-05\n",
      "Epoch 3889, Loss: 1.1117149824713124e-05, Final Batch Loss: 7.086124696797924e-06\n",
      "Epoch 3890, Loss: 4.013048601336777e-05, Final Batch Loss: 2.3877200874267146e-05\n",
      "Epoch 3891, Loss: 7.904815356596373e-05, Final Batch Loss: 4.160830212640576e-05\n",
      "Epoch 3892, Loss: 8.748002801439725e-05, Final Batch Loss: 7.14444468030706e-05\n",
      "Epoch 3893, Loss: 0.0004139777629461605, Final Batch Loss: 5.865480125066824e-05\n",
      "Epoch 3894, Loss: 0.00011458210428827442, Final Batch Loss: 9.618474723538384e-05\n",
      "Epoch 3895, Loss: 0.0001545590714613354, Final Batch Loss: 2.948822157122777e-06\n",
      "Epoch 3896, Loss: 0.00010978551563312067, Final Batch Loss: 1.046467059495626e-05\n",
      "Epoch 3897, Loss: 0.00029394921875791624, Final Batch Loss: 0.000254770100582391\n",
      "Epoch 3898, Loss: 0.0018443535309415893, Final Batch Loss: 1.4095939150138292e-05\n",
      "Epoch 3899, Loss: 4.633185835700715e-05, Final Batch Loss: 9.158939974440727e-06\n",
      "Epoch 3900, Loss: 0.00022447964147431776, Final Batch Loss: 3.851742803817615e-05\n",
      "Epoch 3901, Loss: 4.1020823573489906e-05, Final Batch Loss: 4.291196546546416e-06\n",
      "Epoch 3902, Loss: 9.038124608196085e-05, Final Batch Loss: 1.074092051567277e-05\n",
      "Epoch 3903, Loss: 6.693507111776853e-05, Final Batch Loss: 5.211917232372798e-05\n",
      "Epoch 3904, Loss: 0.00019002578119398095, Final Batch Loss: 0.00014943612040951848\n",
      "Epoch 3905, Loss: 0.00011820319332400686, Final Batch Loss: 0.00011270870891166851\n",
      "Epoch 3906, Loss: 3.7485340271814493e-05, Final Batch Loss: 3.142573405057192e-05\n",
      "Epoch 3907, Loss: 7.940893806335225e-05, Final Batch Loss: 1.1781837656599237e-06\n",
      "Epoch 3908, Loss: 4.443139005161356e-05, Final Batch Loss: 2.8313725124462508e-05\n",
      "Epoch 3909, Loss: 0.0003545375802787021, Final Batch Loss: 4.5993030653335154e-05\n",
      "Epoch 3910, Loss: 1.8155225006921683e-05, Final Batch Loss: 1.4223942343960516e-06\n",
      "Epoch 3911, Loss: 0.001317795817158185, Final Batch Loss: 9.25577332964167e-05\n",
      "Epoch 3912, Loss: 0.00010722235310822725, Final Batch Loss: 6.265812407946214e-05\n",
      "Epoch 3913, Loss: 3.103042399743572e-05, Final Batch Loss: 1.6332849554601125e-05\n",
      "Epoch 3914, Loss: 6.11651994404383e-05, Final Batch Loss: 4.1150065953843296e-05\n",
      "Epoch 3915, Loss: 0.0033376855881215306, Final Batch Loss: 0.003313337219879031\n",
      "Epoch 3916, Loss: 0.0012245450297996285, Final Batch Loss: 8.837751920509618e-06\n",
      "Epoch 3917, Loss: 0.00014762916180188768, Final Batch Loss: 8.958477701526135e-05\n",
      "Epoch 3918, Loss: 8.63853874761844e-05, Final Batch Loss: 1.6159059669007547e-05\n",
      "Epoch 3919, Loss: 3.3969121432164684e-05, Final Batch Loss: 9.830953786149621e-06\n",
      "Epoch 3920, Loss: 2.4389036298089195e-05, Final Batch Loss: 1.4973408724472392e-05\n",
      "Epoch 3921, Loss: 4.993363563698949e-05, Final Batch Loss: 9.296128155256156e-06\n",
      "Epoch 3922, Loss: 6.037223465682473e-05, Final Batch Loss: 3.360604387125932e-05\n",
      "Epoch 3923, Loss: 7.863390783313662e-05, Final Batch Loss: 3.350391489220783e-05\n",
      "Epoch 3924, Loss: 0.0001468065893277526, Final Batch Loss: 6.944817141629755e-05\n",
      "Epoch 3925, Loss: 7.3757417339948e-05, Final Batch Loss: 4.9293019401375204e-05\n",
      "Epoch 3926, Loss: 6.075923374737613e-05, Final Batch Loss: 3.299782474641688e-05\n",
      "Epoch 3927, Loss: 9.813934593694285e-05, Final Batch Loss: 4.7103931137826294e-05\n",
      "Epoch 3928, Loss: 6.810584363847738e-05, Final Batch Loss: 1.1809587704192381e-05\n",
      "Epoch 3929, Loss: 2.3309193238674197e-05, Final Batch Loss: 9.954917914001271e-06\n",
      "Epoch 3930, Loss: 0.00038156820664880797, Final Batch Loss: 0.00012098505249014124\n",
      "Epoch 3931, Loss: 0.0002426863948130631, Final Batch Loss: 1.4076534171181265e-05\n",
      "Epoch 3932, Loss: 1.9678143871715292e-05, Final Batch Loss: 2.1897085389355198e-06\n",
      "Epoch 3933, Loss: 2.511089314793935e-05, Final Batch Loss: 1.652784521866124e-05\n",
      "Epoch 3934, Loss: 0.00014394207755685784, Final Batch Loss: 0.0001205807930091396\n",
      "Epoch 3935, Loss: 3.852382906188723e-05, Final Batch Loss: 2.5790848667384125e-05\n",
      "Epoch 3936, Loss: 5.630949840451649e-05, Final Batch Loss: 3.4221486657770583e-06\n",
      "Epoch 3937, Loss: 2.7317470085108653e-05, Final Batch Loss: 1.1653537512756884e-05\n",
      "Epoch 3938, Loss: 0.0007793427485012216, Final Batch Loss: 0.0007712152437306941\n",
      "Epoch 3939, Loss: 0.00013630484954774147, Final Batch Loss: 4.5111801227903925e-06\n",
      "Epoch 3940, Loss: 0.00027066280017606914, Final Batch Loss: 0.00021860112610738724\n",
      "Epoch 3941, Loss: 3.365432803548174e-05, Final Batch Loss: 1.4785043276788201e-05\n",
      "Epoch 3942, Loss: 0.00012716730998363346, Final Batch Loss: 8.163295569829643e-05\n",
      "Epoch 3943, Loss: 2.2745560272596776e-05, Final Batch Loss: 1.2121281542931683e-05\n",
      "Epoch 3944, Loss: 0.00042161878081969917, Final Batch Loss: 0.00014907060540281236\n",
      "Epoch 3945, Loss: 0.0003442036743308563, Final Batch Loss: 2.5334068141091848e-06\n",
      "Epoch 3946, Loss: 8.37425363897637e-06, Final Batch Loss: 1.5335028820118168e-06\n",
      "Epoch 3947, Loss: 0.00014796864525123965, Final Batch Loss: 2.8065622245776467e-05\n",
      "Epoch 3948, Loss: 9.006074105855078e-05, Final Batch Loss: 3.1577736081089824e-05\n",
      "Epoch 3949, Loss: 5.913851418881677e-05, Final Batch Loss: 2.2961041395319626e-05\n",
      "Epoch 3950, Loss: 0.0008688705802342156, Final Batch Loss: 0.0008478424861095846\n",
      "Epoch 3951, Loss: 6.279459739744198e-05, Final Batch Loss: 1.5421255739056505e-05\n",
      "Epoch 3952, Loss: 0.00017255076636502054, Final Batch Loss: 0.00014476077922154218\n",
      "Epoch 3953, Loss: 2.2396115127776284e-05, Final Batch Loss: 4.0391014408669434e-06\n",
      "Epoch 3954, Loss: 7.170718163251877e-05, Final Batch Loss: 3.825606472673826e-05\n",
      "Epoch 3955, Loss: 5.397591303335503e-05, Final Batch Loss: 1.565296042826958e-05\n",
      "Epoch 3956, Loss: 9.217106810410769e-05, Final Batch Loss: 1.7198118484884617e-06\n",
      "Epoch 3957, Loss: 0.0014077844971325248, Final Batch Loss: 0.0003239672805648297\n",
      "Epoch 3958, Loss: 4.449161497177556e-05, Final Batch Loss: 1.5591225746902637e-05\n",
      "Epoch 3959, Loss: 0.00011310952322673984, Final Batch Loss: 3.3690532291075215e-05\n",
      "Epoch 3960, Loss: 1.1598636660892225e-05, Final Batch Loss: 9.852031325863209e-06\n",
      "Epoch 3961, Loss: 4.432393325259909e-05, Final Batch Loss: 1.767814319464378e-05\n",
      "Epoch 3962, Loss: 4.443571287993109e-05, Final Batch Loss: 3.796444070758298e-05\n",
      "Epoch 3963, Loss: 7.400587855954655e-05, Final Batch Loss: 4.9020221922546625e-05\n",
      "Epoch 3964, Loss: 0.00011248746704950463, Final Batch Loss: 2.5714578441693448e-05\n",
      "Epoch 3965, Loss: 2.980124827445252e-05, Final Batch Loss: 9.443020644539502e-06\n",
      "Epoch 3966, Loss: 2.644152345965267e-05, Final Batch Loss: 2.490598944859812e-06\n",
      "Epoch 3967, Loss: 5.053457471149159e-05, Final Batch Loss: 7.561452093796106e-06\n",
      "Epoch 3968, Loss: 4.407665164762875e-05, Final Batch Loss: 3.092816041316837e-05\n",
      "Epoch 3969, Loss: 1.272217059522518e-05, Final Batch Loss: 1.0713314622989856e-05\n",
      "Epoch 3970, Loss: 2.207522766184411e-05, Final Batch Loss: 2.8400531846273225e-06\n",
      "Epoch 3971, Loss: 9.185868657368701e-05, Final Batch Loss: 6.711695459671319e-05\n",
      "Epoch 3972, Loss: 0.0014889495869283564, Final Batch Loss: 6.542792107211426e-05\n",
      "Epoch 3973, Loss: 0.005619110641418956, Final Batch Loss: 0.005610623862594366\n",
      "Epoch 3974, Loss: 7.799054674251238e-05, Final Batch Loss: 6.367605965351686e-05\n",
      "Epoch 3975, Loss: 0.0035093223996227607, Final Batch Loss: 0.003441885579377413\n",
      "Epoch 3976, Loss: 0.00032864454988157377, Final Batch Loss: 0.0002934725780505687\n",
      "Epoch 3977, Loss: 1.8426329916110262e-05, Final Batch Loss: 8.87332407728536e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3978, Loss: 2.3549979232484475e-05, Final Batch Loss: 1.2152750969107728e-05\n",
      "Epoch 3979, Loss: 1.2619614608411212e-05, Final Batch Loss: 5.928404334554216e-06\n",
      "Epoch 3980, Loss: 3.175401252519805e-05, Final Batch Loss: 5.863750629941933e-06\n",
      "Epoch 3981, Loss: 0.00010363868932472542, Final Batch Loss: 5.804605461889878e-05\n",
      "Epoch 3982, Loss: 1.9533978047547862e-05, Final Batch Loss: 5.609811523754615e-06\n",
      "Epoch 3983, Loss: 0.00011073827590735164, Final Batch Loss: 2.7355059501132928e-05\n",
      "Epoch 3984, Loss: 5.577259571509785e-06, Final Batch Loss: 2.036910018432536e-06\n",
      "Epoch 3985, Loss: 0.0002120103035849752, Final Batch Loss: 0.00020062072144355625\n",
      "Epoch 3986, Loss: 3.9007931263768114e-05, Final Batch Loss: 1.3143035175744444e-05\n",
      "Epoch 3987, Loss: 0.00017544589991302928, Final Batch Loss: 0.0001675437524681911\n",
      "Epoch 3988, Loss: 3.8514634979947004e-05, Final Batch Loss: 4.4344824345898814e-06\n",
      "Epoch 3989, Loss: 9.636926552047953e-05, Final Batch Loss: 7.204020221251994e-06\n",
      "Epoch 3990, Loss: 0.0002533747156121535, Final Batch Loss: 0.0002497416571713984\n",
      "Epoch 3991, Loss: 5.905935904593207e-05, Final Batch Loss: 1.3834494893671945e-05\n",
      "Epoch 3992, Loss: 0.0003807605753536336, Final Batch Loss: 0.0003182792861480266\n",
      "Epoch 3993, Loss: 3.543270577210933e-05, Final Batch Loss: 1.49948045873316e-05\n",
      "Epoch 3994, Loss: 6.0816450968559366e-06, Final Batch Loss: 3.131624680463574e-06\n",
      "Epoch 3995, Loss: 3.373557956365403e-05, Final Batch Loss: 2.0484385458985344e-05\n",
      "Epoch 3996, Loss: 1.0360166470491095e-05, Final Batch Loss: 1.7730194485920947e-06\n",
      "Epoch 3997, Loss: 2.8203040528751444e-05, Final Batch Loss: 1.6774138202890754e-05\n",
      "Epoch 3998, Loss: 5.728158066631295e-05, Final Batch Loss: 1.1640102457022294e-05\n",
      "Epoch 3999, Loss: 0.00017112822018816587, Final Batch Loss: 9.154718441095611e-07\n",
      "Epoch 4000, Loss: 0.0016205429560613993, Final Batch Loss: 4.1926973608497065e-06\n",
      "Epoch 4001, Loss: 2.6571788112050854e-05, Final Batch Loss: 1.390766010445077e-05\n",
      "Epoch 4002, Loss: 0.0002488567888576654, Final Batch Loss: 0.00023855089966673404\n",
      "Epoch 4003, Loss: 9.029348439071327e-05, Final Batch Loss: 4.779689697897993e-05\n",
      "Epoch 4004, Loss: 2.1360209302656585e-05, Final Batch Loss: 3.704430582729401e-06\n",
      "Epoch 4005, Loss: 8.589480785303749e-06, Final Batch Loss: 1.239529865415534e-06\n",
      "Epoch 4006, Loss: 0.000510803491124534, Final Batch Loss: 0.00048109772615134716\n",
      "Epoch 4007, Loss: 1.3201895853853785e-05, Final Batch Loss: 6.209740149643039e-06\n",
      "Epoch 4008, Loss: 0.002268267593535711, Final Batch Loss: 2.3015572878648527e-05\n",
      "Epoch 4009, Loss: 0.00015296187848434784, Final Batch Loss: 0.00010002157796407118\n",
      "Epoch 4010, Loss: 9.776302613317966e-05, Final Batch Loss: 7.687742618145421e-05\n",
      "Epoch 4011, Loss: 2.2584974431083538e-05, Final Batch Loss: 8.908445124689024e-06\n",
      "Epoch 4012, Loss: 5.312142002367182e-05, Final Batch Loss: 9.602025784261059e-06\n",
      "Epoch 4013, Loss: 1.0525452580623096e-05, Final Batch Loss: 2.094781393680023e-06\n",
      "Epoch 4014, Loss: 0.00015224132221192122, Final Batch Loss: 8.975646051112562e-05\n",
      "Epoch 4015, Loss: 7.589106462546624e-05, Final Batch Loss: 6.961277540540323e-05\n",
      "Epoch 4016, Loss: 0.0001559200727569987, Final Batch Loss: 8.473795787722338e-06\n",
      "Epoch 4017, Loss: 9.138369932770729e-05, Final Batch Loss: 3.7935362342977896e-05\n",
      "Epoch 4018, Loss: 0.0001040453503264871, Final Batch Loss: 9.735085041029379e-05\n",
      "Epoch 4019, Loss: 7.634725625393912e-05, Final Batch Loss: 5.013389454688877e-06\n",
      "Epoch 4020, Loss: 0.00015153397544054314, Final Batch Loss: 0.00010853796266019344\n",
      "Epoch 4021, Loss: 3.096234650001861e-05, Final Batch Loss: 2.1802998162456788e-05\n",
      "Epoch 4022, Loss: 8.717840046301717e-05, Final Batch Loss: 8.024167073017452e-06\n",
      "Epoch 4023, Loss: 3.157646824547555e-05, Final Batch Loss: 1.043908741849009e-05\n",
      "Epoch 4024, Loss: 0.0009020628785947338, Final Batch Loss: 8.2940241554752e-06\n",
      "Epoch 4025, Loss: 3.592289249354508e-05, Final Batch Loss: 3.263457983848639e-06\n",
      "Epoch 4026, Loss: 7.786289825162385e-05, Final Batch Loss: 5.1101469580316916e-05\n",
      "Epoch 4027, Loss: 0.00010642848019415396, Final Batch Loss: 4.842083853873191e-06\n",
      "Epoch 4028, Loss: 3.2451127481181175e-05, Final Batch Loss: 7.054295565467328e-06\n",
      "Epoch 4029, Loss: 6.426790423574857e-05, Final Batch Loss: 8.952480129664764e-06\n",
      "Epoch 4030, Loss: 9.386429701407906e-05, Final Batch Loss: 6.518203008454293e-05\n",
      "Epoch 4031, Loss: 1.248066018888494e-05, Final Batch Loss: 6.52750713925343e-07\n",
      "Epoch 4032, Loss: 9.679943605078734e-05, Final Batch Loss: 8.924551366362721e-05\n",
      "Epoch 4033, Loss: 0.00012183379749330925, Final Batch Loss: 0.00011352329602232203\n",
      "Epoch 4034, Loss: 0.0028262967889531865, Final Batch Loss: 1.1012255527020898e-05\n",
      "Epoch 4035, Loss: 0.00010838887101272121, Final Batch Loss: 2.2463274945039302e-05\n",
      "Epoch 4036, Loss: 1.5143379187065875e-05, Final Batch Loss: 5.010440418118378e-06\n",
      "Epoch 4037, Loss: 0.00012475018957047723, Final Batch Loss: 8.786712714936584e-05\n",
      "Epoch 4038, Loss: 4.004696893389337e-05, Final Batch Loss: 1.4072131307329983e-05\n",
      "Epoch 4039, Loss: 6.355870073093683e-05, Final Batch Loss: 4.805579465028131e-06\n",
      "Epoch 4040, Loss: 0.0015723582455393625, Final Batch Loss: 2.710014632612001e-05\n",
      "Epoch 4041, Loss: 3.0054166472837096e-05, Final Batch Loss: 2.9280267881404143e-06\n",
      "Epoch 4042, Loss: 1.3793752714263974e-05, Final Batch Loss: 6.9339930632850155e-06\n",
      "Epoch 4043, Loss: 1.6658796994306613e-05, Final Batch Loss: 9.629051419324242e-06\n",
      "Epoch 4044, Loss: 1.8041485873254715e-05, Final Batch Loss: 5.139449513080763e-06\n",
      "Epoch 4045, Loss: 0.0017985756994676194, Final Batch Loss: 3.4707618397078477e-06\n",
      "Epoch 4046, Loss: 1.7384739294357132e-05, Final Batch Loss: 1.2776021321769804e-05\n",
      "Epoch 4047, Loss: 0.00031572523585055023, Final Batch Loss: 0.00017371357535012066\n",
      "Epoch 4048, Loss: 0.00023150779998104554, Final Batch Loss: 0.000203360163141042\n",
      "Epoch 4049, Loss: 5.749156480305828e-05, Final Batch Loss: 2.0566290913848206e-05\n",
      "Epoch 4050, Loss: 3.525862302922178e-05, Final Batch Loss: 2.16175067180302e-05\n",
      "Epoch 4051, Loss: 5.811279424960958e-05, Final Batch Loss: 7.4177996793878265e-06\n",
      "Epoch 4052, Loss: 0.0013875515505787916, Final Batch Loss: 6.535801367135718e-05\n",
      "Epoch 4053, Loss: 0.001069180048943963, Final Batch Loss: 0.0010046610841527581\n",
      "Epoch 4054, Loss: 4.57962705695536e-05, Final Batch Loss: 3.8834274164400995e-05\n",
      "Epoch 4055, Loss: 0.0014965524896979332, Final Batch Loss: 0.001412041368894279\n",
      "Epoch 4056, Loss: 0.0002109630440827459, Final Batch Loss: 4.9325768486596644e-05\n",
      "Epoch 4057, Loss: 0.0002168743303627707, Final Batch Loss: 7.823203486623242e-05\n",
      "Epoch 4058, Loss: 0.0002240607609564904, Final Batch Loss: 0.00020471079915296286\n",
      "Epoch 4059, Loss: 0.005188761977478862, Final Batch Loss: 0.003431458491832018\n",
      "Epoch 4060, Loss: 4.9539265091880225e-05, Final Batch Loss: 2.392767601122614e-05\n",
      "Epoch 4061, Loss: 0.005802636987937149, Final Batch Loss: 0.0057878391817212105\n",
      "Epoch 4062, Loss: 3.21847654731755e-05, Final Batch Loss: 5.890977945455234e-07\n",
      "Epoch 4063, Loss: 0.00045209320887806825, Final Batch Loss: 1.043938027578406e-05\n",
      "Epoch 4064, Loss: 3.208873749827035e-05, Final Batch Loss: 1.9246095689595677e-05\n",
      "Epoch 4065, Loss: 2.781486955427681e-05, Final Batch Loss: 2.3101210899767466e-05\n",
      "Epoch 4066, Loss: 2.654186391737312e-05, Final Batch Loss: 8.497770977555774e-06\n",
      "Epoch 4067, Loss: 6.633497469010763e-05, Final Batch Loss: 2.0051797037012875e-05\n",
      "Epoch 4068, Loss: 4.83459853057866e-05, Final Batch Loss: 8.79104572959477e-06\n",
      "Epoch 4069, Loss: 0.00016220785073528532, Final Batch Loss: 0.00013760640285909176\n",
      "Epoch 4070, Loss: 4.249530229571974e-05, Final Batch Loss: 1.2571969818964135e-05\n",
      "Epoch 4071, Loss: 0.00011197329786227783, Final Batch Loss: 9.047179446497466e-06\n",
      "Epoch 4072, Loss: 1.350195134364185e-05, Final Batch Loss: 5.045542366133304e-06\n",
      "Epoch 4073, Loss: 7.785590969433542e-05, Final Batch Loss: 1.5224211892927997e-05\n",
      "Epoch 4074, Loss: 5.295903338264907e-05, Final Batch Loss: 3.799458499997854e-05\n",
      "Epoch 4075, Loss: 0.00019196754692529794, Final Batch Loss: 0.00017872329044621438\n",
      "Epoch 4076, Loss: 0.00010917633153439965, Final Batch Loss: 8.714832074474543e-05\n",
      "Epoch 4077, Loss: 3.909801671397872e-05, Final Batch Loss: 1.0508083505555987e-05\n",
      "Epoch 4078, Loss: 0.003198194352989958, Final Batch Loss: 6.705790838168468e-06\n",
      "Epoch 4079, Loss: 0.0001298580718867015, Final Batch Loss: 4.5097196561982855e-05\n",
      "Epoch 4080, Loss: 7.818502854206599e-05, Final Batch Loss: 6.995560397626832e-06\n",
      "Epoch 4081, Loss: 1.5016967154224403e-05, Final Batch Loss: 8.14722716313554e-06\n",
      "Epoch 4082, Loss: 1.2921394045406487e-05, Final Batch Loss: 4.4010821511619724e-06\n",
      "Epoch 4083, Loss: 0.00032925222330959514, Final Batch Loss: 0.0002886154397856444\n",
      "Epoch 4084, Loss: 2.524023875594139e-05, Final Batch Loss: 1.8112459656549618e-06\n",
      "Epoch 4085, Loss: 5.223811240284704e-05, Final Batch Loss: 3.688369179144502e-05\n",
      "Epoch 4086, Loss: 0.0015512804848185624, Final Batch Loss: 0.0015480763977393508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4087, Loss: 2.0604170458682347e-05, Final Batch Loss: 2.380637852184009e-06\n",
      "Epoch 4088, Loss: 0.0005722592059100862, Final Batch Loss: 1.0362319699197542e-05\n",
      "Epoch 4089, Loss: 0.0001304653924307786, Final Batch Loss: 9.982350456994027e-05\n",
      "Epoch 4090, Loss: 9.939679694070946e-05, Final Batch Loss: 1.1476227882667445e-05\n",
      "Epoch 4091, Loss: 9.361913726024795e-06, Final Batch Loss: 4.87110810354352e-06\n",
      "Epoch 4092, Loss: 5.020035359848407e-06, Final Batch Loss: 2.603957000246737e-06\n",
      "Epoch 4093, Loss: 0.00012531911124824546, Final Batch Loss: 9.07715002540499e-05\n",
      "Epoch 4094, Loss: 0.0028648716872794466, Final Batch Loss: 2.5437223030166933e-06\n",
      "Epoch 4095, Loss: 3.260233461332973e-05, Final Batch Loss: 1.5760066162329167e-05\n",
      "Epoch 4096, Loss: 1.5106014870980289e-05, Final Batch Loss: 9.973891792469658e-06\n",
      "Epoch 4097, Loss: 3.1543801924271975e-05, Final Batch Loss: 7.533581992902327e-06\n",
      "Epoch 4098, Loss: 6.0058739109081216e-05, Final Batch Loss: 2.4620943804620765e-05\n",
      "Epoch 4099, Loss: 0.00014929817234587972, Final Batch Loss: 7.574523351649987e-06\n",
      "Epoch 4100, Loss: 5.308497338774032e-05, Final Batch Loss: 4.735255424748175e-05\n",
      "Epoch 4101, Loss: 3.188840128132142e-05, Final Batch Loss: 1.8969933080370538e-05\n",
      "Epoch 4102, Loss: 9.787441484832016e-06, Final Batch Loss: 2.951289559405268e-07\n",
      "Epoch 4103, Loss: 4.733556852443144e-05, Final Batch Loss: 1.076045009540394e-05\n",
      "Epoch 4104, Loss: 0.00012532602704595774, Final Batch Loss: 5.237660661805421e-05\n",
      "Epoch 4105, Loss: 0.00011476762483653147, Final Batch Loss: 1.843100653786678e-05\n",
      "Epoch 4106, Loss: 2.3185616555565502e-05, Final Batch Loss: 1.3888742614653893e-05\n",
      "Epoch 4107, Loss: 2.0919999428770097e-05, Final Batch Loss: 1.243005158357846e-06\n",
      "Epoch 4108, Loss: 3.4817818232113495e-05, Final Batch Loss: 1.518728822702542e-05\n",
      "Epoch 4109, Loss: 8.984712985693477e-05, Final Batch Loss: 1.5470399375772104e-05\n",
      "Epoch 4110, Loss: 5.896587458664726e-05, Final Batch Loss: 2.5356901005579857e-06\n",
      "Epoch 4111, Loss: 3.494781776680611e-05, Final Batch Loss: 2.6478830477572046e-05\n",
      "Epoch 4112, Loss: 0.0020069368210897665, Final Batch Loss: 5.107142897031736e-06\n",
      "Epoch 4113, Loss: 4.3005027691833675e-05, Final Batch Loss: 2.033515920629725e-05\n",
      "Epoch 4114, Loss: 2.9424882086459547e-05, Final Batch Loss: 2.125594619428739e-05\n",
      "Epoch 4115, Loss: 0.00029974783569741703, Final Batch Loss: 1.922314140756498e-06\n",
      "Epoch 4116, Loss: 0.0001241204809048213, Final Batch Loss: 9.18745863600634e-05\n",
      "Epoch 4117, Loss: 0.00019507166143739596, Final Batch Loss: 4.26342521677725e-05\n",
      "Epoch 4118, Loss: 2.9139345315343235e-05, Final Batch Loss: 9.480007975071203e-06\n",
      "Epoch 4119, Loss: 6.347497128444957e-05, Final Batch Loss: 4.8245114157907665e-05\n",
      "Epoch 4120, Loss: 6.972807523197844e-05, Final Batch Loss: 3.905659013980767e-06\n",
      "Epoch 4121, Loss: 7.385898061329499e-05, Final Batch Loss: 3.566529994714074e-05\n",
      "Epoch 4122, Loss: 0.0027429475521785207, Final Batch Loss: 0.0027341083623468876\n",
      "Epoch 4123, Loss: 5.063420394435525e-05, Final Batch Loss: 1.3381504686549306e-05\n",
      "Epoch 4124, Loss: 3.456811441537866e-05, Final Batch Loss: 3.3387766507075867e-06\n",
      "Epoch 4125, Loss: 0.001013867324218154, Final Batch Loss: 0.0002137643750756979\n",
      "Epoch 4126, Loss: 0.00015907981651253067, Final Batch Loss: 6.158032192615792e-06\n",
      "Epoch 4127, Loss: 2.711619754336425e-05, Final Batch Loss: 6.6538291321194265e-06\n",
      "Epoch 4128, Loss: 3.5097946238238364e-05, Final Batch Loss: 2.171531377825886e-05\n",
      "Epoch 4129, Loss: 0.00011907129373867065, Final Batch Loss: 5.481591506395489e-05\n",
      "Epoch 4130, Loss: 3.472174148555496e-05, Final Batch Loss: 1.349459580524126e-06\n",
      "Epoch 4131, Loss: 6.013481288391631e-05, Final Batch Loss: 2.6279265512130223e-05\n",
      "Epoch 4132, Loss: 0.0006128750210336875, Final Batch Loss: 0.000580181775148958\n",
      "Epoch 4133, Loss: 0.00024634220972075127, Final Batch Loss: 0.0001898827904369682\n",
      "Epoch 4134, Loss: 0.00023820668502594344, Final Batch Loss: 0.00018941034795716405\n",
      "Epoch 4135, Loss: 3.109081444563344e-05, Final Batch Loss: 2.697246236493811e-05\n",
      "Epoch 4136, Loss: 0.0004180454998277128, Final Batch Loss: 0.00029165614978410304\n",
      "Epoch 4137, Loss: 1.0795909474836662e-05, Final Batch Loss: 3.8003968256816734e-06\n",
      "Epoch 4138, Loss: 5.137092921358999e-05, Final Batch Loss: 2.824033799697645e-05\n",
      "Epoch 4139, Loss: 0.0005903920537093654, Final Batch Loss: 0.0004470641433726996\n",
      "Epoch 4140, Loss: 4.308838197175646e-05, Final Batch Loss: 1.2744626474159304e-05\n",
      "Epoch 4141, Loss: 0.00011441830474723247, Final Batch Loss: 6.406546617654385e-06\n",
      "Epoch 4142, Loss: 0.0015678616182412952, Final Batch Loss: 0.0002571267250459641\n",
      "Epoch 4143, Loss: 2.3362874799204292e-05, Final Batch Loss: 2.646833763719769e-06\n",
      "Epoch 4144, Loss: 6.722093894495629e-05, Final Batch Loss: 1.646028977120295e-05\n",
      "Epoch 4145, Loss: 1.7679063603281975e-05, Final Batch Loss: 6.855811989225913e-06\n",
      "Epoch 4146, Loss: 0.00010528121310926508, Final Batch Loss: 1.6640506146359257e-05\n",
      "Epoch 4147, Loss: 0.002803904094889731, Final Batch Loss: 0.0027996425051242113\n",
      "Epoch 4148, Loss: 2.4019107968342723e-05, Final Batch Loss: 4.427566182130249e-06\n",
      "Epoch 4149, Loss: 0.0014830693253315985, Final Batch Loss: 0.0012182784266769886\n",
      "Epoch 4150, Loss: 0.0001115838167606853, Final Batch Loss: 3.796080272877589e-05\n",
      "Epoch 4151, Loss: 0.0014810703805778758, Final Batch Loss: 6.307113835646305e-06\n",
      "Epoch 4152, Loss: 0.0001259114833374042, Final Batch Loss: 1.792304465197958e-05\n",
      "Epoch 4153, Loss: 2.456748279655585e-05, Final Batch Loss: 7.70570204622345e-06\n",
      "Epoch 4154, Loss: 6.212003427208401e-05, Final Batch Loss: 1.055426400853321e-05\n",
      "Epoch 4155, Loss: 0.0003573112699086778, Final Batch Loss: 2.916529047070071e-05\n",
      "Epoch 4156, Loss: 0.0011419901939007104, Final Batch Loss: 1.1524310139066074e-05\n",
      "Epoch 4157, Loss: 0.0001859598930877837, Final Batch Loss: 2.475492465237039e-06\n",
      "Epoch 4158, Loss: 0.00011418460053391755, Final Batch Loss: 3.3949829230550677e-05\n",
      "Epoch 4159, Loss: 0.0009017494121508207, Final Batch Loss: 4.342995453043841e-05\n",
      "Epoch 4160, Loss: 7.373901598839439e-05, Final Batch Loss: 6.712268077535555e-05\n",
      "Epoch 4161, Loss: 0.004226430820835958, Final Batch Loss: 0.0042197806760668755\n",
      "Epoch 4162, Loss: 0.0002941216025647009, Final Batch Loss: 0.00028768228366971016\n",
      "Epoch 4163, Loss: 0.000632953302556416, Final Batch Loss: 3.525445572449826e-05\n",
      "Epoch 4164, Loss: 5.135620631335769e-05, Final Batch Loss: 2.3830378268030472e-05\n",
      "Epoch 4165, Loss: 5.916503505432047e-05, Final Batch Loss: 2.6324138161726296e-05\n",
      "Epoch 4166, Loss: 4.269315923011163e-05, Final Batch Loss: 1.0344535439799074e-05\n",
      "Epoch 4167, Loss: 0.0003587468254409032, Final Batch Loss: 1.975312079594005e-05\n",
      "Epoch 4168, Loss: 0.0002791629249259131, Final Batch Loss: 0.0002489067264832556\n",
      "Epoch 4169, Loss: 0.00013929623310104944, Final Batch Loss: 8.218536822823808e-05\n",
      "Epoch 4170, Loss: 0.00012673515271899305, Final Batch Loss: 8.425468536188419e-07\n",
      "Epoch 4171, Loss: 2.5918049232132034e-05, Final Batch Loss: 3.042596745217452e-06\n",
      "Epoch 4172, Loss: 4.3767121042037616e-05, Final Batch Loss: 7.106873908924172e-06\n",
      "Epoch 4173, Loss: 0.0004031652515550377, Final Batch Loss: 8.281162081402726e-06\n",
      "Epoch 4174, Loss: 0.0012002520306850784, Final Batch Loss: 0.00011395703040761873\n",
      "Epoch 4175, Loss: 0.00017072463379008695, Final Batch Loss: 4.038113547721878e-05\n",
      "Epoch 4176, Loss: 4.3664251279551536e-05, Final Batch Loss: 2.3956878067110665e-05\n",
      "Epoch 4177, Loss: 8.628822115497314e-05, Final Batch Loss: 8.399337821174413e-05\n",
      "Epoch 4178, Loss: 0.0015346813452197239, Final Batch Loss: 4.758364229928702e-05\n",
      "Epoch 4179, Loss: 2.8052606467099395e-05, Final Batch Loss: 1.2399753359204624e-05\n",
      "Epoch 4180, Loss: 0.0011859427941089962, Final Batch Loss: 1.5951347450027242e-05\n",
      "Epoch 4181, Loss: 3.5341669217814342e-06, Final Batch Loss: 7.314546337511274e-07\n",
      "Epoch 4182, Loss: 0.00016963619441412447, Final Batch Loss: 2.478969918229268e-06\n",
      "Epoch 4183, Loss: 0.0010707741021178663, Final Batch Loss: 0.00011511205229908228\n",
      "Epoch 4184, Loss: 0.0003263675403104571, Final Batch Loss: 6.281401056185132e-06\n",
      "Epoch 4185, Loss: 4.2800000301213004e-05, Final Batch Loss: 1.2843156582675874e-05\n",
      "Epoch 4186, Loss: 4.606564152709325e-05, Final Batch Loss: 4.421946141519584e-05\n",
      "Epoch 4187, Loss: 0.0002848795884347055, Final Batch Loss: 0.00023695669369772077\n",
      "Epoch 4188, Loss: 1.0245712928735884e-05, Final Batch Loss: 4.530360001808731e-06\n",
      "Epoch 4189, Loss: 4.413176088746695e-05, Final Batch Loss: 1.7302229480264941e-06\n",
      "Epoch 4190, Loss: 4.2110141293960623e-05, Final Batch Loss: 1.6969730495475233e-05\n",
      "Epoch 4191, Loss: 3.0327456443046685e-05, Final Batch Loss: 1.845068072725553e-05\n",
      "Epoch 4192, Loss: 4.146082392253447e-05, Final Batch Loss: 3.0769166187383235e-05\n",
      "Epoch 4193, Loss: 2.3401298676617444e-05, Final Batch Loss: 1.8231678041047417e-05\n",
      "Epoch 4194, Loss: 0.0014465627427853178, Final Batch Loss: 3.826773536275141e-05\n",
      "Epoch 4195, Loss: 1.735868022478826e-05, Final Batch Loss: 1.4533545254380442e-05\n",
      "Epoch 4196, Loss: 7.728097989456728e-05, Final Batch Loss: 4.9240104999626055e-05\n",
      "Epoch 4197, Loss: 5.87745574875953e-06, Final Batch Loss: 8.622318432571774e-07\n",
      "Epoch 4198, Loss: 3.6446551803237526e-05, Final Batch Loss: 3.9649307836953085e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4199, Loss: 2.7414563874117448e-05, Final Batch Loss: 3.460328798610135e-06\n",
      "Epoch 4200, Loss: 9.31622380448971e-05, Final Batch Loss: 5.272296766634099e-05\n",
      "Epoch 4201, Loss: 0.0001371303187625017, Final Batch Loss: 0.00010637694504112005\n",
      "Epoch 4202, Loss: 0.0029476909689947206, Final Batch Loss: 0.002940299455076456\n",
      "Epoch 4203, Loss: 0.027397678378292767, Final Batch Loss: 1.1596041986194905e-05\n",
      "Epoch 4204, Loss: 7.374870676812861e-06, Final Batch Loss: 6.710166871926049e-06\n",
      "Epoch 4205, Loss: 0.0064349390304414555, Final Batch Loss: 0.0002072995266644284\n",
      "Epoch 4206, Loss: 3.840927502096747e-05, Final Batch Loss: 2.1293567442626227e-06\n",
      "Epoch 4207, Loss: 0.0002972857764689252, Final Batch Loss: 0.00023157465329859406\n",
      "Epoch 4208, Loss: 1.1372049357305514e-05, Final Batch Loss: 5.049081210017903e-06\n",
      "Epoch 4209, Loss: 4.217125569994096e-05, Final Batch Loss: 2.077647513942793e-05\n",
      "Epoch 4210, Loss: 0.0015535163565800758, Final Batch Loss: 1.82445965037914e-05\n",
      "Epoch 4211, Loss: 7.11797447365825e-05, Final Batch Loss: 6.806633791711647e-06\n",
      "Epoch 4212, Loss: 7.254986576299416e-05, Final Batch Loss: 1.0413609743409324e-05\n",
      "Epoch 4213, Loss: 9.589281035005115e-05, Final Batch Loss: 3.356096931383945e-05\n",
      "Epoch 4214, Loss: 0.000277473230198666, Final Batch Loss: 0.00027314244653098285\n",
      "Epoch 4215, Loss: 1.0511717391636921e-05, Final Batch Loss: 4.5618835429195315e-06\n",
      "Epoch 4216, Loss: 1.7003465018206043e-05, Final Batch Loss: 1.1876029020640999e-05\n",
      "Epoch 4217, Loss: 0.00027616201259661466, Final Batch Loss: 9.841765859164298e-06\n",
      "Epoch 4218, Loss: 4.466131031222176e-05, Final Batch Loss: 1.0608024240355007e-05\n",
      "Epoch 4219, Loss: 0.00016162063548108563, Final Batch Loss: 0.00011180996807524934\n",
      "Epoch 4220, Loss: 0.00016167405556188896, Final Batch Loss: 9.32812035898678e-05\n",
      "Epoch 4221, Loss: 3.755342345357349e-05, Final Batch Loss: 2.820362851707614e-06\n",
      "Epoch 4222, Loss: 0.00011887416167155607, Final Batch Loss: 1.1466933756310027e-05\n",
      "Epoch 4223, Loss: 2.5263811949116644e-05, Final Batch Loss: 1.6888940081116743e-05\n",
      "Epoch 4224, Loss: 0.00024260882855742238, Final Batch Loss: 5.759775740443729e-05\n",
      "Epoch 4225, Loss: 0.0038709704895154573, Final Batch Loss: 0.00012129583774367347\n",
      "Epoch 4226, Loss: 0.00015058232929732185, Final Batch Loss: 0.00012031007645418867\n",
      "Epoch 4227, Loss: 0.001954931161890272, Final Batch Loss: 0.00011544148583197966\n",
      "Epoch 4228, Loss: 3.926768022211036e-05, Final Batch Loss: 2.4827078959788196e-05\n",
      "Epoch 4229, Loss: 0.000264409196915949, Final Batch Loss: 0.0002569802454672754\n",
      "Epoch 4230, Loss: 3.086911965510808e-05, Final Batch Loss: 2.457098162267357e-05\n",
      "Epoch 4231, Loss: 0.00025192733664880507, Final Batch Loss: 3.44579566444736e-05\n",
      "Epoch 4232, Loss: 4.347352478362154e-05, Final Batch Loss: 2.1015433958382346e-05\n",
      "Epoch 4233, Loss: 0.01566620912944927, Final Batch Loss: 0.015657547861337662\n",
      "Epoch 4234, Loss: 0.0018697944469749928, Final Batch Loss: 5.270203109830618e-05\n",
      "Epoch 4235, Loss: 2.6248553695040755e-05, Final Batch Loss: 5.847416105098091e-06\n",
      "Epoch 4236, Loss: 3.7617773500642215e-05, Final Batch Loss: 7.638585657332442e-07\n",
      "Epoch 4237, Loss: 1.0374539670010563e-05, Final Batch Loss: 3.6175815694150515e-06\n",
      "Epoch 4238, Loss: 0.00017337227473035455, Final Batch Loss: 1.3884113286621869e-05\n",
      "Epoch 4239, Loss: 0.00034087499625456985, Final Batch Loss: 0.00032899464713409543\n",
      "Epoch 4240, Loss: 0.00017301314437645487, Final Batch Loss: 0.00012932198296766728\n",
      "Epoch 4241, Loss: 0.000692809720931109, Final Batch Loss: 0.0006483966135419905\n",
      "Epoch 4242, Loss: 0.00010896780349867186, Final Batch Loss: 6.403802217391785e-06\n",
      "Epoch 4243, Loss: 0.00035089445373159833, Final Batch Loss: 0.00029743919731117785\n",
      "Epoch 4244, Loss: 1.5822030036360957e-05, Final Batch Loss: 8.153148883138783e-06\n",
      "Epoch 4245, Loss: 5.4356253713194747e-05, Final Batch Loss: 1.3565801964432467e-05\n",
      "Epoch 4246, Loss: 3.2070392080640886e-05, Final Batch Loss: 2.4440285415039398e-05\n",
      "Epoch 4247, Loss: 9.238050324711367e-06, Final Batch Loss: 6.13652127867681e-06\n",
      "Epoch 4248, Loss: 0.0001347151592199225, Final Batch Loss: 4.236829772708006e-05\n",
      "Epoch 4249, Loss: 1.6808322925498942e-05, Final Batch Loss: 4.478256869333563e-06\n",
      "Epoch 4250, Loss: 3.0617003176303115e-05, Final Batch Loss: 1.428827363270102e-05\n",
      "Epoch 4251, Loss: 3.4868789498432307e-05, Final Batch Loss: 2.9237808121251874e-05\n",
      "Epoch 4252, Loss: 7.59850875056145e-05, Final Batch Loss: 2.2892120341566624e-06\n",
      "Epoch 4253, Loss: 0.0006360871193464845, Final Batch Loss: 1.4082965208217502e-05\n",
      "Epoch 4254, Loss: 0.0023290306053240784, Final Batch Loss: 2.305029920535162e-05\n",
      "Epoch 4255, Loss: 6.024406320648268e-05, Final Batch Loss: 4.082799205207266e-05\n",
      "Epoch 4256, Loss: 0.00030818383675068617, Final Batch Loss: 6.564392242580652e-05\n",
      "Epoch 4257, Loss: 1.2370335525702103e-05, Final Batch Loss: 1.946634029081906e-06\n",
      "Epoch 4258, Loss: 4.6539096501874155e-05, Final Batch Loss: 3.6165745314065134e-06\n",
      "Epoch 4259, Loss: 3.091499729634961e-05, Final Batch Loss: 1.6330059224856086e-05\n",
      "Epoch 4260, Loss: 0.002819732968646349, Final Batch Loss: 0.0028161811642348766\n",
      "Epoch 4261, Loss: 9.683674534244346e-05, Final Batch Loss: 5.515728389582364e-06\n",
      "Epoch 4262, Loss: 0.0018631270504556596, Final Batch Loss: 0.000681174045894295\n",
      "Epoch 4263, Loss: 4.779069058713503e-05, Final Batch Loss: 3.0488772608805448e-05\n",
      "Epoch 4264, Loss: 0.0005684363277396187, Final Batch Loss: 0.00015211787831503898\n",
      "Epoch 4265, Loss: 0.0011758997443394037, Final Batch Loss: 2.3096321456250735e-05\n",
      "Epoch 4266, Loss: 4.7088454266486224e-05, Final Batch Loss: 3.743130946531892e-05\n",
      "Epoch 4267, Loss: 2.5898215881170472e-05, Final Batch Loss: 6.148594820842845e-06\n",
      "Epoch 4268, Loss: 0.0009915527416524128, Final Batch Loss: 5.397619133873377e-06\n",
      "Epoch 4269, Loss: 0.00018468239818503207, Final Batch Loss: 0.000181303228600882\n",
      "Epoch 4270, Loss: 1.1751635838663788e-05, Final Batch Loss: 2.3851901005400578e-06\n",
      "Epoch 4271, Loss: 4.099856073480623e-05, Final Batch Loss: 3.4673596474021906e-06\n",
      "Epoch 4272, Loss: 0.0013868348905816674, Final Batch Loss: 0.0003184308297932148\n",
      "Epoch 4273, Loss: 1.88060389518796e-05, Final Batch Loss: 1.5117454495339189e-05\n",
      "Epoch 4274, Loss: 0.00022812264796812087, Final Batch Loss: 0.00011514381185406819\n",
      "Epoch 4275, Loss: 0.00112952778727049, Final Batch Loss: 5.360131763154641e-05\n",
      "Epoch 4276, Loss: 7.463500696758274e-05, Final Batch Loss: 2.7197402232559398e-06\n",
      "Epoch 4277, Loss: 3.885954811266856e-05, Final Batch Loss: 2.5753322915988974e-05\n",
      "Epoch 4278, Loss: 5.165088805370033e-05, Final Batch Loss: 1.6241887351498008e-05\n",
      "Epoch 4279, Loss: 4.889641422778368e-05, Final Batch Loss: 1.9617174984887242e-05\n",
      "Epoch 4280, Loss: 0.00029236053342174273, Final Batch Loss: 3.5390676202951e-06\n",
      "Epoch 4281, Loss: 0.0008139592337101931, Final Batch Loss: 1.692243131401483e-05\n",
      "Epoch 4282, Loss: 9.894617323880084e-05, Final Batch Loss: 5.237069126451388e-05\n",
      "Epoch 4283, Loss: 0.00016223342026933096, Final Batch Loss: 0.0001495546312071383\n",
      "Epoch 4284, Loss: 4.202142918074969e-05, Final Batch Loss: 2.6138024622923695e-05\n",
      "Epoch 4285, Loss: 7.507162081310526e-05, Final Batch Loss: 3.6929690395481884e-05\n",
      "Epoch 4286, Loss: 0.00034619055350049166, Final Batch Loss: 0.00033495944808237255\n",
      "Epoch 4287, Loss: 5.6682073591218796e-05, Final Batch Loss: 4.5103512093191966e-05\n",
      "Epoch 4288, Loss: 0.00031272981004804024, Final Batch Loss: 0.000310289062326774\n",
      "Epoch 4289, Loss: 1.4405234196601668e-05, Final Batch Loss: 4.213611191516975e-06\n",
      "Epoch 4290, Loss: 1.612457754163188e-05, Final Batch Loss: 1.7418183233530726e-06\n",
      "Epoch 4291, Loss: 5.2733377742697485e-05, Final Batch Loss: 1.036298090184573e-05\n",
      "Epoch 4292, Loss: 7.278455450432375e-05, Final Batch Loss: 6.493151158792898e-05\n",
      "Epoch 4293, Loss: 2.528236927901162e-05, Final Batch Loss: 1.1469499440863729e-05\n",
      "Epoch 4294, Loss: 3.6403229387360625e-05, Final Batch Loss: 7.3779428930720314e-06\n",
      "Epoch 4295, Loss: 0.00039392112421410275, Final Batch Loss: 0.00038745702477172017\n",
      "Epoch 4296, Loss: 0.00097134294856005, Final Batch Loss: 4.771560725203017e-06\n",
      "Epoch 4297, Loss: 0.0001794177333067637, Final Batch Loss: 0.0001383243507007137\n",
      "Epoch 4298, Loss: 6.930580275366083e-05, Final Batch Loss: 2.273412246722728e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4299, Loss: 2.2481576024802052e-05, Final Batch Loss: 2.1185145669733174e-05\n",
      "Epoch 4300, Loss: 2.598160608613398e-05, Final Batch Loss: 2.3222444724524394e-05\n",
      "Epoch 4301, Loss: 3.2810784432513174e-05, Final Batch Loss: 8.264026291726623e-06\n",
      "Epoch 4302, Loss: 1.5068453649291769e-05, Final Batch Loss: 3.1571389627060853e-06\n",
      "Epoch 4303, Loss: 1.7107008716266137e-05, Final Batch Loss: 1.5890027498244308e-06\n",
      "Epoch 4304, Loss: 1.1686408356581524e-05, Final Batch Loss: 1.5045287682369235e-06\n",
      "Epoch 4305, Loss: 4.4027607145835645e-05, Final Batch Loss: 2.7889071134268306e-05\n",
      "Epoch 4306, Loss: 1.0862197541428031e-05, Final Batch Loss: 4.854863163927803e-06\n",
      "Epoch 4307, Loss: 1.5260429336194647e-05, Final Batch Loss: 6.372838015522575e-06\n",
      "Epoch 4308, Loss: 0.00011274315329501405, Final Batch Loss: 3.090182144660503e-05\n",
      "Epoch 4309, Loss: 7.125124602680444e-05, Final Batch Loss: 6.836615648353472e-05\n",
      "Epoch 4310, Loss: 0.0005707366644855938, Final Batch Loss: 4.802669536729809e-06\n",
      "Epoch 4311, Loss: 9.198813131661154e-05, Final Batch Loss: 1.714783502393402e-05\n",
      "Epoch 4312, Loss: 0.000563600282475818, Final Batch Loss: 3.1299721740651876e-05\n",
      "Epoch 4313, Loss: 1.6614543255855097e-05, Final Batch Loss: 9.736212632560637e-06\n",
      "Epoch 4314, Loss: 0.0002652094990480691, Final Batch Loss: 0.0001810653047868982\n",
      "Epoch 4315, Loss: 0.0015433860608027317, Final Batch Loss: 0.0015337211079895496\n",
      "Epoch 4316, Loss: 1.8429606484460237e-05, Final Batch Loss: 9.68701556303131e-07\n",
      "Epoch 4317, Loss: 0.00013752186168858316, Final Batch Loss: 5.874293492524885e-06\n",
      "Epoch 4318, Loss: 0.00020509778369159903, Final Batch Loss: 1.9472709027468227e-05\n",
      "Epoch 4319, Loss: 0.0014304136493592523, Final Batch Loss: 0.00010602999100228772\n",
      "Epoch 4320, Loss: 0.0009689017970231362, Final Batch Loss: 1.211633934872225e-05\n",
      "Epoch 4321, Loss: 1.837024808537535e-05, Final Batch Loss: 1.8864842559196404e-06\n",
      "Epoch 4322, Loss: 0.006775562465918483, Final Batch Loss: 3.7846435589017347e-05\n",
      "Epoch 4323, Loss: 0.0001721485095913522, Final Batch Loss: 0.00012835445522796363\n",
      "Epoch 4324, Loss: 2.328303003196197e-05, Final Batch Loss: 1.4559375358658144e-06\n",
      "Epoch 4325, Loss: 4.7231958888005465e-05, Final Batch Loss: 2.704522921703756e-05\n",
      "Epoch 4326, Loss: 1.3584289263235405e-05, Final Batch Loss: 7.0346550273825414e-06\n",
      "Epoch 4327, Loss: 0.0010974873307532107, Final Batch Loss: 0.0010938941268250346\n",
      "Epoch 4328, Loss: 1.9323601918586064e-05, Final Batch Loss: 9.81777429842623e-06\n",
      "Epoch 4329, Loss: 1.7824593214754714e-05, Final Batch Loss: 1.2525575584731996e-05\n",
      "Epoch 4330, Loss: 3.267953570684767e-05, Final Batch Loss: 2.8651611501118168e-05\n",
      "Epoch 4331, Loss: 0.0019490219310682733, Final Batch Loss: 3.738805025932379e-05\n",
      "Epoch 4332, Loss: 1.3413698525255313e-05, Final Batch Loss: 2.4071391635516193e-06\n",
      "Epoch 4333, Loss: 4.81315546494443e-05, Final Batch Loss: 1.917526788020041e-05\n",
      "Epoch 4334, Loss: 6.806921555835288e-05, Final Batch Loss: 8.308799806400202e-06\n",
      "Epoch 4335, Loss: 2.0267025774955982e-05, Final Batch Loss: 3.939191174140433e-06\n",
      "Epoch 4336, Loss: 0.00018086766249325592, Final Batch Loss: 0.00015924242325127125\n",
      "Epoch 4337, Loss: 4.807919549421058e-05, Final Batch Loss: 3.4195677471871022e-06\n",
      "Epoch 4338, Loss: 1.5850491308810888e-05, Final Batch Loss: 3.5876942092727404e-06\n",
      "Epoch 4339, Loss: 0.00022760097223795128, Final Batch Loss: 3.333220490731037e-07\n",
      "Epoch 4340, Loss: 3.67313250535517e-05, Final Batch Loss: 2.5383746105944738e-05\n",
      "Epoch 4341, Loss: 2.567940919107059e-05, Final Batch Loss: 8.448477274214383e-06\n",
      "Epoch 4342, Loss: 1.9053601590712788e-05, Final Batch Loss: 1.5231853467412293e-05\n",
      "Epoch 4343, Loss: 0.0016685994851286523, Final Batch Loss: 3.142042987747118e-05\n",
      "Epoch 4344, Loss: 9.06118075363338e-05, Final Batch Loss: 3.2898777135415e-05\n",
      "Epoch 4345, Loss: 0.0001191279570775805, Final Batch Loss: 1.7177348127006553e-05\n",
      "Epoch 4346, Loss: 0.0014929230101188296, Final Batch Loss: 0.0014845805708318949\n",
      "Epoch 4347, Loss: 2.807206101351767e-06, Final Batch Loss: 1.5750941884107306e-06\n",
      "Epoch 4348, Loss: 6.944176811884972e-05, Final Batch Loss: 6.248572753975168e-05\n",
      "Epoch 4349, Loss: 1.4583434676751494e-05, Final Batch Loss: 1.0999612641171552e-05\n",
      "Epoch 4350, Loss: 0.00021773848857264966, Final Batch Loss: 6.42831000732258e-05\n",
      "Epoch 4351, Loss: 2.9401251595118083e-05, Final Batch Loss: 2.5907203962560743e-05\n",
      "Epoch 4352, Loss: 2.1940915416962525e-05, Final Batch Loss: 1.526513756289205e-06\n",
      "Epoch 4353, Loss: 4.067969257448567e-05, Final Batch Loss: 9.511032658338081e-06\n",
      "Epoch 4354, Loss: 2.3314276404562406e-05, Final Batch Loss: 1.3484876035363413e-05\n",
      "Epoch 4355, Loss: 5.223846164881252e-05, Final Batch Loss: 4.785725468536839e-05\n",
      "Epoch 4356, Loss: 1.6254297065643186e-05, Final Batch Loss: 1.116841872317309e-06\n",
      "Epoch 4357, Loss: 6.068114998925012e-06, Final Batch Loss: 4.624285793397576e-06\n",
      "Epoch 4358, Loss: 9.913533722283319e-05, Final Batch Loss: 6.58364879200235e-05\n",
      "Epoch 4359, Loss: 0.00010489640135347145, Final Batch Loss: 9.322389087174088e-05\n",
      "Epoch 4360, Loss: 0.0012539761163452567, Final Batch Loss: 1.2730969274343806e-06\n",
      "Epoch 4361, Loss: 1.6549838349533275e-05, Final Batch Loss: 1.319401263799591e-07\n",
      "Epoch 4362, Loss: 6.570937330252491e-05, Final Batch Loss: 3.0077229894232005e-05\n",
      "Epoch 4363, Loss: 1.1936151395275374e-05, Final Batch Loss: 1.048184003593633e-05\n",
      "Epoch 4364, Loss: 0.000768938240071293, Final Batch Loss: 2.0742903870996088e-05\n",
      "Epoch 4365, Loss: 0.0003033684224647004, Final Batch Loss: 0.00027206121012568474\n",
      "Epoch 4366, Loss: 3.602531069191173e-05, Final Batch Loss: 2.6201985747320578e-05\n",
      "Epoch 4367, Loss: 0.00036119310243520886, Final Batch Loss: 1.1970681953243911e-05\n",
      "Epoch 4368, Loss: 4.141067256568931e-05, Final Batch Loss: 2.2263498976826668e-05\n",
      "Epoch 4369, Loss: 2.4291703084600158e-05, Final Batch Loss: 6.1664541135542095e-06\n",
      "Epoch 4370, Loss: 8.745500053919386e-05, Final Batch Loss: 5.894093555980362e-05\n",
      "Epoch 4371, Loss: 1.4659613952971995e-05, Final Batch Loss: 4.8977572078001685e-06\n",
      "Epoch 4372, Loss: 0.00032328717770724325, Final Batch Loss: 1.098040502256481e-05\n",
      "Epoch 4373, Loss: 2.160932893957579e-05, Final Batch Loss: 5.208116249377781e-07\n",
      "Epoch 4374, Loss: 3.5717576793103945e-05, Final Batch Loss: 1.2591083759616595e-05\n",
      "Epoch 4375, Loss: 0.00012810284556508122, Final Batch Loss: 2.9002187602600316e-06\n",
      "Epoch 4376, Loss: 5.146220973983873e-05, Final Batch Loss: 3.8406251405831426e-05\n",
      "Epoch 4377, Loss: 0.0028061685152351856, Final Batch Loss: 0.0012068755459040403\n",
      "Epoch 4378, Loss: 2.291381770191947e-05, Final Batch Loss: 6.869741810078267e-06\n",
      "Epoch 4379, Loss: 7.441927436957485e-06, Final Batch Loss: 2.8943384222657187e-06\n",
      "Epoch 4380, Loss: 5.11040891524317e-05, Final Batch Loss: 4.798666850547306e-05\n",
      "Epoch 4381, Loss: 1.3589004993264098e-05, Final Batch Loss: 4.981541678716894e-06\n",
      "Epoch 4382, Loss: 0.00581535844685277, Final Batch Loss: 0.005806287284940481\n",
      "Epoch 4383, Loss: 6.806108103774022e-06, Final Batch Loss: 1.9905492081306875e-06\n",
      "Epoch 4384, Loss: 6.195111927809194e-05, Final Batch Loss: 3.8684742321493104e-05\n",
      "Epoch 4385, Loss: 5.8913847169606015e-06, Final Batch Loss: 3.312106400699122e-06\n",
      "Epoch 4386, Loss: 6.61743943055626e-05, Final Batch Loss: 1.994016201933846e-06\n",
      "Epoch 4387, Loss: 4.5625165512319654e-05, Final Batch Loss: 2.423608020762913e-05\n",
      "Epoch 4388, Loss: 0.001415803213376421, Final Batch Loss: 1.461710553485318e-06\n",
      "Epoch 4389, Loss: 1.4310298411146505e-05, Final Batch Loss: 9.653103006712627e-06\n",
      "Epoch 4390, Loss: 2.111616436195618e-05, Final Batch Loss: 1.4362724414240802e-06\n",
      "Epoch 4391, Loss: 0.0008054450777308375, Final Batch Loss: 0.0007997459615580738\n",
      "Epoch 4392, Loss: 0.00012160569099251006, Final Batch Loss: 2.006722979785991e-06\n",
      "Epoch 4393, Loss: 0.0003610278401993128, Final Batch Loss: 5.948861598881194e-07\n",
      "Epoch 4394, Loss: 0.00011663616896839812, Final Batch Loss: 9.13474359549582e-05\n",
      "Epoch 4395, Loss: 1.4906410342518939e-05, Final Batch Loss: 1.416584836988477e-06\n",
      "Epoch 4396, Loss: 4.568190263398719e-06, Final Batch Loss: 4.791448304786172e-07\n",
      "Epoch 4397, Loss: 5.0989412102353526e-05, Final Batch Loss: 4.565640847431496e-05\n",
      "Epoch 4398, Loss: 5.462776846343331e-05, Final Batch Loss: 1.4536150274579995e-06\n",
      "Epoch 4399, Loss: 1.630712631595088e-05, Final Batch Loss: 2.847127689165063e-07\n",
      "Epoch 4400, Loss: 0.00021220050939518842, Final Batch Loss: 5.625857284030644e-06\n",
      "Epoch 4401, Loss: 1.5507110674661817e-05, Final Batch Loss: 8.540670933143701e-06\n",
      "Epoch 4402, Loss: 1.405655575581477e-05, Final Batch Loss: 5.316427177604055e-06\n",
      "Epoch 4403, Loss: 5.573538874159567e-05, Final Batch Loss: 4.635622099158354e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4404, Loss: 0.002211496961535886, Final Batch Loss: 0.00012979379971511662\n",
      "Epoch 4405, Loss: 4.1179809159075376e-05, Final Batch Loss: 1.2689465620496776e-05\n",
      "Epoch 4406, Loss: 0.00041499771577946376, Final Batch Loss: 9.74922841123771e-06\n",
      "Epoch 4407, Loss: 0.003274376912486332, Final Batch Loss: 0.0032696768175810575\n",
      "Epoch 4408, Loss: 2.195193417264818e-05, Final Batch Loss: 2.025446156039834e-05\n",
      "Epoch 4409, Loss: 1.4058695342100691e-05, Final Batch Loss: 8.18833359517157e-06\n",
      "Epoch 4410, Loss: 0.0030806352879153565, Final Batch Loss: 0.0029181011486798525\n",
      "Epoch 4411, Loss: 0.0007707832919550128, Final Batch Loss: 7.02066536177881e-05\n",
      "Epoch 4412, Loss: 0.0010654491222794604, Final Batch Loss: 2.2232150058698608e-06\n",
      "Epoch 4413, Loss: 0.001414856846395196, Final Batch Loss: 2.5228093818441266e-06\n",
      "Epoch 4414, Loss: 2.629701793921413e-05, Final Batch Loss: 1.3877642231818754e-05\n",
      "Epoch 4415, Loss: 1.121805530601705e-05, Final Batch Loss: 7.515552624681732e-06\n",
      "Epoch 4416, Loss: 0.001097542514116867, Final Batch Loss: 2.8365068374114344e-06\n",
      "Epoch 4417, Loss: 5.461709497467382e-05, Final Batch Loss: 5.029646672483068e-06\n",
      "Epoch 4418, Loss: 9.767941969585081e-05, Final Batch Loss: 2.4591442979726708e-06\n",
      "Epoch 4419, Loss: 0.002027531411840755, Final Batch Loss: 1.0441081940371078e-05\n",
      "Epoch 4420, Loss: 6.705612986479537e-05, Final Batch Loss: 2.8897507036163006e-06\n",
      "Epoch 4421, Loss: 6.875130793559947e-06, Final Batch Loss: 2.7579628749663243e-06\n",
      "Epoch 4422, Loss: 1.1985821402049623e-05, Final Batch Loss: 2.5923973225872032e-06\n",
      "Epoch 4423, Loss: 0.0010193693578912644, Final Batch Loss: 8.394605174544267e-06\n",
      "Epoch 4424, Loss: 0.00016205289830395486, Final Batch Loss: 1.720320688036736e-05\n",
      "Epoch 4425, Loss: 0.0001313959944582166, Final Batch Loss: 0.0001299264986300841\n",
      "Epoch 4426, Loss: 0.0002685080608557655, Final Batch Loss: 6.064574904485198e-07\n",
      "Epoch 4427, Loss: 0.0004579891374305589, Final Batch Loss: 4.257743057678454e-06\n",
      "Epoch 4428, Loss: 8.221146549658442e-05, Final Batch Loss: 1.249949718840071e-06\n",
      "Epoch 4429, Loss: 0.0009851650829659775, Final Batch Loss: 0.00019407413492444903\n",
      "Epoch 4430, Loss: 8.682089355716016e-05, Final Batch Loss: 6.55748590361327e-05\n",
      "Epoch 4431, Loss: 7.94270420101384e-06, Final Batch Loss: 1.6735103827159037e-06\n",
      "Epoch 4432, Loss: 2.462711194084477e-05, Final Batch Loss: 8.876904189492052e-07\n",
      "Epoch 4433, Loss: 5.6348486850765767e-05, Final Batch Loss: 3.3628462006163318e-06\n",
      "Epoch 4434, Loss: 2.797147794808552e-05, Final Batch Loss: 2.549488090153318e-05\n",
      "Epoch 4435, Loss: 1.0796839433169225e-05, Final Batch Loss: 2.057713118119864e-06\n",
      "Epoch 4436, Loss: 1.9844338567054365e-05, Final Batch Loss: 1.938494278874714e-06\n",
      "Epoch 4437, Loss: 0.0049339019460603595, Final Batch Loss: 0.003684158669784665\n",
      "Epoch 4438, Loss: 1.673441056482261e-05, Final Batch Loss: 1.0226741324004252e-05\n",
      "Epoch 4439, Loss: 2.79078819858114e-05, Final Batch Loss: 3.7230354337225435e-06\n",
      "Epoch 4440, Loss: 0.25199922276760844, Final Batch Loss: 0.25199586153030396\n",
      "Epoch 4441, Loss: 0.003452291736721236, Final Batch Loss: 1.0413840755063575e-05\n",
      "Epoch 4442, Loss: 8.280700421892107e-05, Final Batch Loss: 8.322851499542594e-06\n",
      "Epoch 4443, Loss: 0.0011812953616754385, Final Batch Loss: 2.3247777789947577e-05\n",
      "Epoch 4444, Loss: 2.9489554435713217e-05, Final Batch Loss: 6.363710781442933e-06\n",
      "Epoch 4445, Loss: 3.795453994825948e-05, Final Batch Loss: 2.174449764424935e-05\n",
      "Epoch 4446, Loss: 0.00011175506188010331, Final Batch Loss: 0.00010350764932809398\n",
      "Epoch 4447, Loss: 0.0001891759857244324, Final Batch Loss: 0.00016541933291591704\n",
      "Epoch 4448, Loss: 0.001978183513529075, Final Batch Loss: 1.24083589980728e-05\n",
      "Epoch 4449, Loss: 0.00011998933132417733, Final Batch Loss: 1.085593339666957e-05\n",
      "Epoch 4450, Loss: 0.002379321167609305, Final Batch Loss: 7.26655161997769e-06\n",
      "Epoch 4451, Loss: 9.088322258321568e-05, Final Batch Loss: 6.185297388583422e-05\n",
      "Epoch 4452, Loss: 3.828926128335297e-05, Final Batch Loss: 3.6292294680606574e-06\n",
      "Epoch 4453, Loss: 0.0001321473318967037, Final Batch Loss: 1.8035760149359703e-05\n",
      "Epoch 4454, Loss: 8.21959251879889e-05, Final Batch Loss: 5.48417256140965e-06\n",
      "Epoch 4455, Loss: 0.00011214090955036227, Final Batch Loss: 1.724434878269676e-05\n",
      "Epoch 4456, Loss: 7.231341623992193e-05, Final Batch Loss: 4.7655099479015917e-05\n",
      "Epoch 4457, Loss: 6.799615221098065e-05, Final Batch Loss: 3.640307841124013e-05\n",
      "Epoch 4458, Loss: 0.0001178756428998895, Final Batch Loss: 3.868342173518613e-05\n",
      "Epoch 4459, Loss: 7.708536577410996e-05, Final Batch Loss: 3.0452098144451156e-05\n",
      "Epoch 4460, Loss: 0.0001761763105605496, Final Batch Loss: 0.0001593537162989378\n",
      "Epoch 4461, Loss: 0.00013115811361785745, Final Batch Loss: 6.524786840600427e-06\n",
      "Epoch 4462, Loss: 0.002555481842136942, Final Batch Loss: 0.002438801573589444\n",
      "Epoch 4463, Loss: 4.10847633247613e-05, Final Batch Loss: 7.357400136243086e-06\n",
      "Epoch 4464, Loss: 2.0187958853057353e-05, Final Batch Loss: 3.524115072650602e-06\n",
      "Epoch 4465, Loss: 0.00013907160246162675, Final Batch Loss: 0.00010778952128021047\n",
      "Epoch 4466, Loss: 0.0004156689374212874, Final Batch Loss: 0.0003887442289851606\n",
      "Epoch 4467, Loss: 6.89245880494127e-05, Final Batch Loss: 2.05029846256366e-05\n",
      "Epoch 4468, Loss: 0.00031993736320146127, Final Batch Loss: 6.2031349443714134e-06\n",
      "Epoch 4469, Loss: 3.976516018155962e-05, Final Batch Loss: 1.074353167496156e-05\n",
      "Epoch 4470, Loss: 5.379178219300229e-05, Final Batch Loss: 2.24946688831551e-05\n",
      "Epoch 4471, Loss: 0.002211257175076753, Final Batch Loss: 0.001956910826265812\n",
      "Epoch 4472, Loss: 0.0005354289951355895, Final Batch Loss: 0.0005250961403362453\n",
      "Epoch 4473, Loss: 2.7834928914671764e-05, Final Batch Loss: 1.0684905646485277e-05\n",
      "Epoch 4474, Loss: 2.7463428523333278e-05, Final Batch Loss: 1.6012347259675153e-05\n",
      "Epoch 4475, Loss: 3.864463542413432e-05, Final Batch Loss: 1.6823274563648738e-05\n",
      "Epoch 4476, Loss: 6.038255560270045e-05, Final Batch Loss: 4.4960899685975164e-05\n",
      "Epoch 4477, Loss: 0.0018622006973600946, Final Batch Loss: 8.387144043808803e-05\n",
      "Epoch 4478, Loss: 0.0004412451235111803, Final Batch Loss: 0.00038711237721145153\n",
      "Epoch 4479, Loss: 9.079021219804417e-05, Final Batch Loss: 2.415835297142621e-05\n",
      "Epoch 4480, Loss: 6.415277312044054e-05, Final Batch Loss: 3.5629902413347736e-05\n",
      "Epoch 4481, Loss: 4.83100784549606e-05, Final Batch Loss: 5.919472641835455e-06\n",
      "Epoch 4482, Loss: 0.0001854753504630935, Final Batch Loss: 0.00017984832811634988\n",
      "Epoch 4483, Loss: 0.00012932525169162545, Final Batch Loss: 8.0919580796035e-06\n",
      "Epoch 4484, Loss: 0.00016705081361578777, Final Batch Loss: 3.5210199712309986e-05\n",
      "Epoch 4485, Loss: 0.001442763372324407, Final Batch Loss: 0.0002892854390665889\n",
      "Epoch 4486, Loss: 0.00011614553659455851, Final Batch Loss: 5.040621181251481e-05\n",
      "Epoch 4487, Loss: 0.002927700221334817, Final Batch Loss: 0.00289160362444818\n",
      "Epoch 4488, Loss: 4.046842332172673e-05, Final Batch Loss: 6.3661191234132275e-06\n",
      "Epoch 4489, Loss: 0.001372271672153147, Final Batch Loss: 4.3303578422637656e-05\n",
      "Epoch 4490, Loss: 0.00016986091577564366, Final Batch Loss: 1.653873550822027e-05\n",
      "Epoch 4491, Loss: 6.594429760298226e-05, Final Batch Loss: 4.38040733570233e-05\n",
      "Epoch 4492, Loss: 0.00021220811095190584, Final Batch Loss: 4.432285550137749e-06\n",
      "Epoch 4493, Loss: 0.001114190366024559, Final Batch Loss: 1.4242526049201842e-05\n",
      "Epoch 4494, Loss: 0.00010389487579232082, Final Batch Loss: 8.803791570244357e-05\n",
      "Epoch 4495, Loss: 3.732119239430176e-05, Final Batch Loss: 1.1962288226641249e-05\n",
      "Epoch 4496, Loss: 0.0001498312524290668, Final Batch Loss: 3.2116115562530467e-06\n",
      "Epoch 4497, Loss: 0.000229921151913004, Final Batch Loss: 0.00020617096743080765\n",
      "Epoch 4498, Loss: 4.881068753093132e-05, Final Batch Loss: 4.5378787035588175e-05\n",
      "Epoch 4499, Loss: 9.426939340073659e-05, Final Batch Loss: 4.2591108240230824e-07\n",
      "Epoch 4500, Loss: 0.0006230512153706513, Final Batch Loss: 4.308475035941228e-05\n",
      "Epoch 4501, Loss: 8.932237733461079e-05, Final Batch Loss: 8.506045560352504e-05\n",
      "Epoch 4502, Loss: 2.7117805075249635e-05, Final Batch Loss: 7.731663572485559e-06\n",
      "Epoch 4503, Loss: 2.3787066311342642e-05, Final Batch Loss: 4.762037860928103e-06\n",
      "Epoch 4504, Loss: 0.0013880703854738385, Final Batch Loss: 3.438422027102206e-06\n",
      "Epoch 4505, Loss: 0.0014739870821358636, Final Batch Loss: 0.0002093336806865409\n",
      "Epoch 4506, Loss: 3.44153286278015e-05, Final Batch Loss: 2.874527854146436e-05\n",
      "Epoch 4507, Loss: 0.00019081777827523183, Final Batch Loss: 5.768872142652981e-06\n",
      "Epoch 4508, Loss: 0.00013872374984202906, Final Batch Loss: 5.499408871401101e-06\n",
      "Epoch 4509, Loss: 1.611554898772738e-05, Final Batch Loss: 5.084397798782447e-06\n",
      "Epoch 4510, Loss: 8.664965571369976e-05, Final Batch Loss: 1.340196467936039e-05\n",
      "Epoch 4511, Loss: 5.516257260751445e-05, Final Batch Loss: 4.651213748729788e-05\n",
      "Epoch 4512, Loss: 9.921072796714725e-05, Final Batch Loss: 1.1612687558226753e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4513, Loss: 4.602713670465164e-05, Final Batch Loss: 1.7611930161365308e-05\n",
      "Epoch 4514, Loss: 8.618882475275313e-06, Final Batch Loss: 5.994747880322393e-06\n",
      "Epoch 4515, Loss: 0.00010216081864200532, Final Batch Loss: 4.406616426422261e-05\n",
      "Epoch 4516, Loss: 6.0604877944570035e-05, Final Batch Loss: 2.2407533833757043e-05\n",
      "Epoch 4517, Loss: 0.0013258337839943124, Final Batch Loss: 0.0013061584904789925\n",
      "Epoch 4518, Loss: 0.00018780377922666958, Final Batch Loss: 4.998356416763272e-06\n",
      "Epoch 4519, Loss: 0.00018712723976932466, Final Batch Loss: 9.347173909191042e-05\n",
      "Epoch 4520, Loss: 0.0012186202307020721, Final Batch Loss: 4.9333407332596835e-06\n",
      "Epoch 4521, Loss: 0.00133447464031633, Final Batch Loss: 0.00017281399050261825\n",
      "Epoch 4522, Loss: 7.663568430871237e-05, Final Batch Loss: 4.90682759846095e-05\n",
      "Epoch 4523, Loss: 3.806185668508988e-05, Final Batch Loss: 1.3047585525782779e-05\n",
      "Epoch 4524, Loss: 0.00044647077265835833, Final Batch Loss: 0.00043957424350082874\n",
      "Epoch 4525, Loss: 3.0101628908596467e-05, Final Batch Loss: 5.163729838386644e-06\n",
      "Epoch 4526, Loss: 5.569433960772585e-05, Final Batch Loss: 2.5748297048266977e-05\n",
      "Epoch 4527, Loss: 2.4489022507623304e-05, Final Batch Loss: 5.300033990351949e-06\n",
      "Epoch 4528, Loss: 1.3145879734111077e-05, Final Batch Loss: 1.1550424687811756e-06\n",
      "Epoch 4529, Loss: 0.00359791535356635, Final Batch Loss: 9.728543773235288e-06\n",
      "Epoch 4530, Loss: 3.921184179489501e-05, Final Batch Loss: 8.857761713443324e-06\n",
      "Epoch 4531, Loss: 0.00029300110418262193, Final Batch Loss: 0.00028583069797605276\n",
      "Epoch 4532, Loss: 0.0002612571347526682, Final Batch Loss: 0.00025593029567971826\n",
      "Epoch 4533, Loss: 0.0014468670196947642, Final Batch Loss: 4.59859220427461e-05\n",
      "Epoch 4534, Loss: 3.499112881399924e-05, Final Batch Loss: 1.4915917745383922e-05\n",
      "Epoch 4535, Loss: 3.629880666267127e-05, Final Batch Loss: 2.6964888093061745e-05\n",
      "Epoch 4536, Loss: 3.817016931861872e-05, Final Batch Loss: 9.120073627855163e-06\n",
      "Epoch 4537, Loss: 2.3717227350061876e-05, Final Batch Loss: 2.0462081010919064e-05\n",
      "Epoch 4538, Loss: 0.008881133704562671, Final Batch Loss: 0.008738631382584572\n",
      "Epoch 4539, Loss: 0.0001029268560159835, Final Batch Loss: 9.09487935132347e-05\n",
      "Epoch 4540, Loss: 2.0237375792930834e-05, Final Batch Loss: 8.240898750955239e-06\n",
      "Epoch 4541, Loss: 0.00019072663235419895, Final Batch Loss: 7.836153599782847e-06\n",
      "Epoch 4542, Loss: 0.00015592096497130115, Final Batch Loss: 0.00012626034731511027\n",
      "Epoch 4543, Loss: 2.166677745663037e-05, Final Batch Loss: 1.7499221485195449e-06\n",
      "Epoch 4544, Loss: 1.353805055259727e-05, Final Batch Loss: 4.958805220667273e-06\n",
      "Epoch 4545, Loss: 0.00011964677651121747, Final Batch Loss: 9.834435331868008e-05\n",
      "Epoch 4546, Loss: 6.579168439202476e-05, Final Batch Loss: 4.198746682959609e-05\n",
      "Epoch 4547, Loss: 9.799887175176991e-05, Final Batch Loss: 1.0776881936180871e-05\n",
      "Epoch 4548, Loss: 3.750115502043627e-05, Final Batch Loss: 2.409604348940775e-06\n",
      "Epoch 4549, Loss: 1.9447211798251374e-05, Final Batch Loss: 1.3977033631817903e-05\n",
      "Epoch 4550, Loss: 9.838236110226717e-05, Final Batch Loss: 9.946188583853655e-06\n",
      "Epoch 4551, Loss: 4.0639326925884234e-05, Final Batch Loss: 3.338296664878726e-05\n",
      "Epoch 4552, Loss: 0.00045590841909870505, Final Batch Loss: 0.000318589765811339\n",
      "Epoch 4553, Loss: 2.7592309379542712e-05, Final Batch Loss: 2.810015757859219e-06\n",
      "Epoch 4554, Loss: 2.1970626221445855e-05, Final Batch Loss: 1.2782537851308007e-05\n",
      "Epoch 4555, Loss: 8.509746294294018e-05, Final Batch Loss: 6.455323455156758e-05\n",
      "Epoch 4556, Loss: 3.594348072510911e-05, Final Batch Loss: 1.2256931768206414e-05\n",
      "Epoch 4557, Loss: 5.342821077647386e-05, Final Batch Loss: 9.945501915353816e-06\n",
      "Epoch 4558, Loss: 3.9241117065103026e-05, Final Batch Loss: 6.542639766848879e-06\n",
      "Epoch 4559, Loss: 8.477657866023947e-05, Final Batch Loss: 4.7576195356668904e-06\n",
      "Epoch 4560, Loss: 7.54738812247524e-06, Final Batch Loss: 4.234522748447489e-06\n",
      "Epoch 4561, Loss: 0.00014470993937720777, Final Batch Loss: 1.2494759175751824e-05\n",
      "Epoch 4562, Loss: 3.981166378252965e-05, Final Batch Loss: 1.128420308305067e-06\n",
      "Epoch 4563, Loss: 1.1640769571386045e-05, Final Batch Loss: 3.821370682999259e-06\n",
      "Epoch 4564, Loss: 2.546110135881463e-05, Final Batch Loss: 5.331509782990906e-06\n",
      "Epoch 4565, Loss: 5.550572950596688e-06, Final Batch Loss: 2.30648834076419e-06\n",
      "Epoch 4566, Loss: 5.2463394467849866e-05, Final Batch Loss: 3.215027618352906e-06\n",
      "Epoch 4567, Loss: 2.398527431068942e-05, Final Batch Loss: 9.27477958612144e-06\n",
      "Epoch 4568, Loss: 9.814927034312859e-05, Final Batch Loss: 3.410199860809371e-05\n",
      "Epoch 4569, Loss: 3.979727853220538e-05, Final Batch Loss: 5.103340754430974e-06\n",
      "Epoch 4570, Loss: 0.00012866101724284817, Final Batch Loss: 2.10402913580765e-06\n",
      "Epoch 4571, Loss: 2.0361387214506976e-05, Final Batch Loss: 5.596419214271009e-06\n",
      "Epoch 4572, Loss: 3.0078529107413488e-05, Final Batch Loss: 5.983849860058399e-06\n",
      "Epoch 4573, Loss: 4.487021169552463e-05, Final Batch Loss: 7.486930826416938e-06\n",
      "Epoch 4574, Loss: 6.389083682734054e-05, Final Batch Loss: 3.340189141454175e-05\n",
      "Epoch 4575, Loss: 0.00024985644267871976, Final Batch Loss: 1.778530713636428e-05\n",
      "Epoch 4576, Loss: 0.00015203978909994476, Final Batch Loss: 0.00011347360123181716\n",
      "Epoch 4577, Loss: 3.228958939871518e-05, Final Batch Loss: 1.3433055755740497e-05\n",
      "Epoch 4578, Loss: 1.3959269153929199e-05, Final Batch Loss: 2.914030801548506e-06\n",
      "Epoch 4579, Loss: 0.0012361814060568577, Final Batch Loss: 0.0012318074004724622\n",
      "Epoch 4580, Loss: 0.0003720029617397813, Final Batch Loss: 9.360794138046913e-06\n",
      "Epoch 4581, Loss: 0.0002052694617304951, Final Batch Loss: 0.0001884182565845549\n",
      "Epoch 4582, Loss: 0.004289187827453134, Final Batch Loss: 0.004280639812350273\n",
      "Epoch 4583, Loss: 6.340773802548938e-05, Final Batch Loss: 6.085205313866027e-05\n",
      "Epoch 4584, Loss: 0.0004531812446657568, Final Batch Loss: 0.0004196740628685802\n",
      "Epoch 4585, Loss: 6.362800741044339e-05, Final Batch Loss: 2.3498394511989318e-05\n",
      "Epoch 4586, Loss: 8.716364072824945e-05, Final Batch Loss: 3.137462499580579e-06\n",
      "Epoch 4587, Loss: 2.772294647002127e-05, Final Batch Loss: 2.002875589823816e-05\n",
      "Epoch 4588, Loss: 1.7309767827100586e-05, Final Batch Loss: 4.018203981104307e-06\n",
      "Epoch 4589, Loss: 4.381779035611544e-05, Final Batch Loss: 1.5338791854446754e-05\n",
      "Epoch 4590, Loss: 1.1438542742325808e-05, Final Batch Loss: 7.648541213711724e-06\n",
      "Epoch 4591, Loss: 5.031414002587553e-05, Final Batch Loss: 2.4704253519303165e-05\n",
      "Epoch 4592, Loss: 0.0011065453436458483, Final Batch Loss: 0.00012676978076342493\n",
      "Epoch 4593, Loss: 5.4022435506340116e-05, Final Batch Loss: 3.8016645703464746e-05\n",
      "Epoch 4594, Loss: 4.139060547458939e-05, Final Batch Loss: 1.5983539924491197e-05\n",
      "Epoch 4595, Loss: 0.00034749544647638686, Final Batch Loss: 2.486766970832832e-05\n",
      "Epoch 4596, Loss: 4.976235800313589e-05, Final Batch Loss: 3.0703442917001667e-06\n",
      "Epoch 4597, Loss: 1.731597052412326e-05, Final Batch Loss: 2.9049891736576683e-07\n",
      "Epoch 4598, Loss: 0.0006063038640604645, Final Batch Loss: 3.973026196035789e-06\n",
      "Epoch 4599, Loss: 0.003294305100098427, Final Batch Loss: 0.003280649660155177\n",
      "Epoch 4600, Loss: 6.338809953376767e-06, Final Batch Loss: 2.8968067908863304e-06\n",
      "Epoch 4601, Loss: 2.8933754038007464e-05, Final Batch Loss: 1.0396995094197337e-05\n",
      "Epoch 4602, Loss: 2.1610226895063533e-05, Final Batch Loss: 2.3736354251013836e-06\n",
      "Epoch 4603, Loss: 7.532729068771005e-05, Final Batch Loss: 2.7679630875354633e-05\n",
      "Epoch 4604, Loss: 3.326647220092127e-05, Final Batch Loss: 2.6174324375460856e-05\n",
      "Epoch 4605, Loss: 0.0023741543834603362, Final Batch Loss: 0.002370756585150957\n",
      "Epoch 4606, Loss: 0.0014687414386571618, Final Batch Loss: 2.3723800040897913e-05\n",
      "Epoch 4607, Loss: 6.170655069581699e-05, Final Batch Loss: 1.6006228179321624e-05\n",
      "Epoch 4608, Loss: 0.0003742893577509676, Final Batch Loss: 0.0003681123780552298\n",
      "Epoch 4609, Loss: 2.6402998173580272e-05, Final Batch Loss: 6.889882115501678e-06\n",
      "Epoch 4610, Loss: 0.00014208122229319997, Final Batch Loss: 0.00012676094775088131\n",
      "Epoch 4611, Loss: 0.002114786380843725, Final Batch Loss: 0.0020411734003573656\n",
      "Epoch 4612, Loss: 8.435446829935245e-06, Final Batch Loss: 6.972165465413127e-06\n",
      "Epoch 4613, Loss: 0.006719927107496915, Final Batch Loss: 5.367481662688078e-06\n",
      "Epoch 4614, Loss: 4.587922603604966e-05, Final Batch Loss: 4.981977781426394e-06\n",
      "Epoch 4615, Loss: 0.00010828947051777504, Final Batch Loss: 7.761806773487478e-05\n",
      "Epoch 4616, Loss: 6.232037048903294e-05, Final Batch Loss: 2.3130090994527563e-05\n",
      "Epoch 4617, Loss: 0.0020997689043724677, Final Batch Loss: 1.3724382370128296e-05\n",
      "Epoch 4618, Loss: 0.0001557997275085654, Final Batch Loss: 0.0001253484224434942\n",
      "Epoch 4619, Loss: 2.820795066327264e-05, Final Batch Loss: 3.561066250767908e-06\n",
      "Epoch 4620, Loss: 3.69643239537254e-05, Final Batch Loss: 8.98302641871851e-06\n",
      "Epoch 4621, Loss: 0.003342438329127617, Final Batch Loss: 0.003280662465840578\n",
      "Epoch 4622, Loss: 3.680538611661177e-05, Final Batch Loss: 2.1002704670536332e-05\n",
      "Epoch 4623, Loss: 0.0015109764281078242, Final Batch Loss: 0.00010025707160821185\n",
      "Epoch 4624, Loss: 1.9837055333482567e-05, Final Batch Loss: 1.041955329128541e-05\n",
      "Epoch 4625, Loss: 0.0011573616793612018, Final Batch Loss: 0.0001497891644248739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4626, Loss: 0.0010162086691707373, Final Batch Loss: 0.000999553594738245\n",
      "Epoch 4627, Loss: 0.0001393161146552302, Final Batch Loss: 2.5205634301528335e-05\n",
      "Epoch 4628, Loss: 1.586081452842336e-05, Final Batch Loss: 6.2722101574763656e-06\n",
      "Epoch 4629, Loss: 1.790584428817965e-05, Final Batch Loss: 8.275054824480321e-06\n",
      "Epoch 4630, Loss: 0.0006177052255225135, Final Batch Loss: 6.761982149328105e-06\n",
      "Epoch 4631, Loss: 0.0002481902283761883, Final Batch Loss: 0.0002280553599121049\n",
      "Epoch 4632, Loss: 4.262460652171285e-05, Final Batch Loss: 3.7215118936728686e-05\n",
      "Epoch 4633, Loss: 7.11096126906341e-05, Final Batch Loss: 2.9406126486719586e-05\n",
      "Epoch 4634, Loss: 0.00025723626094986685, Final Batch Loss: 0.00020007217244710773\n",
      "Epoch 4635, Loss: 0.00023588723138345813, Final Batch Loss: 1.936192120410851e-06\n",
      "Epoch 4636, Loss: 5.5825334129622206e-05, Final Batch Loss: 1.0439151083119214e-05\n",
      "Epoch 4637, Loss: 5.121950925968122e-05, Final Batch Loss: 2.277834209962748e-05\n",
      "Epoch 4638, Loss: 0.022815075762537163, Final Batch Loss: 3.3537521630933043e-06\n",
      "Epoch 4639, Loss: 7.592768815811723e-05, Final Batch Loss: 2.501784183550626e-05\n",
      "Epoch 4640, Loss: 4.3317993004166055e-05, Final Batch Loss: 9.8330465334584e-06\n",
      "Epoch 4641, Loss: 0.052302916329608706, Final Batch Loss: 5.733948455599602e-06\n",
      "Epoch 4642, Loss: 0.0021541991154663265, Final Batch Loss: 0.0021283109672367573\n",
      "Epoch 4643, Loss: 3.841695524897659e-05, Final Batch Loss: 8.099920705717523e-06\n",
      "Epoch 4644, Loss: 3.68229448213242e-05, Final Batch Loss: 1.7307829693891108e-05\n",
      "Epoch 4645, Loss: 0.0005032698454670026, Final Batch Loss: 0.0004908386617898941\n",
      "Epoch 4646, Loss: 6.36616623523878e-05, Final Batch Loss: 5.10157406097278e-05\n",
      "Epoch 4647, Loss: 9.547355739414343e-05, Final Batch Loss: 7.171619017753983e-06\n",
      "Epoch 4648, Loss: 0.0507154869446822, Final Batch Loss: 0.05070073530077934\n",
      "Epoch 4649, Loss: 0.0013860375329386443, Final Batch Loss: 4.185162833891809e-05\n",
      "Epoch 4650, Loss: 0.00011704099506459897, Final Batch Loss: 2.7764608603320085e-06\n",
      "Epoch 4651, Loss: 0.0008785954778431915, Final Batch Loss: 1.2423981388565153e-05\n",
      "Epoch 4652, Loss: 0.005013730842620134, Final Batch Loss: 0.002522762631997466\n",
      "Epoch 4653, Loss: 0.0067549244267866015, Final Batch Loss: 0.005006949882954359\n",
      "Epoch 4654, Loss: 0.0002448872428431059, Final Batch Loss: 1.1971150343015324e-05\n",
      "Epoch 4655, Loss: 0.00015516576149821049, Final Batch Loss: 0.00014416978228837252\n",
      "Epoch 4656, Loss: 0.00011656504648271948, Final Batch Loss: 3.837389522232115e-05\n",
      "Epoch 4657, Loss: 0.00010361529893998522, Final Batch Loss: 8.575909305363894e-05\n",
      "Epoch 4658, Loss: 0.0001107773246076249, Final Batch Loss: 6.501341431430774e-06\n",
      "Epoch 4659, Loss: 4.0351468669541646e-05, Final Batch Loss: 1.5178761714196298e-05\n",
      "Epoch 4660, Loss: 1.4142703435027215e-05, Final Batch Loss: 1.8008421420745435e-06\n",
      "Epoch 4661, Loss: 0.000788287376963126, Final Batch Loss: 0.0007751541561447084\n",
      "Epoch 4662, Loss: 2.4880690943973605e-05, Final Batch Loss: 1.3350340850593057e-05\n",
      "Epoch 4663, Loss: 0.0002329923263459932, Final Batch Loss: 0.00020607271289918572\n",
      "Epoch 4664, Loss: 0.0018514933981350623, Final Batch Loss: 0.0017553373472765088\n",
      "Epoch 4665, Loss: 0.01713333351131041, Final Batch Loss: 2.006791191888624e-06\n",
      "Epoch 4666, Loss: 0.0012055989591317484, Final Batch Loss: 1.7389795175404288e-05\n",
      "Epoch 4667, Loss: 3.8825696719868574e-05, Final Batch Loss: 3.1155581382336095e-05\n",
      "Epoch 4668, Loss: 4.840690417040605e-05, Final Batch Loss: 2.187308928114362e-05\n",
      "Epoch 4669, Loss: 2.3189663181710785e-05, Final Batch Loss: 5.497498136719514e-07\n",
      "Epoch 4670, Loss: 0.00010761101475509349, Final Batch Loss: 1.1449303201516159e-05\n",
      "Epoch 4671, Loss: 8.142084698192775e-05, Final Batch Loss: 1.7885708075482398e-05\n",
      "Epoch 4672, Loss: 0.00027468012558529153, Final Batch Loss: 0.00022935218294151127\n",
      "Epoch 4673, Loss: 9.231979129253887e-05, Final Batch Loss: 5.340110510587692e-05\n",
      "Epoch 4674, Loss: 8.212989132516668e-05, Final Batch Loss: 5.101096121506998e-06\n",
      "Epoch 4675, Loss: 0.0001785651456884807, Final Batch Loss: 2.6566243832348846e-05\n",
      "Epoch 4676, Loss: 9.824401604419108e-05, Final Batch Loss: 8.966391033027321e-05\n",
      "Epoch 4677, Loss: 3.5734920857066754e-05, Final Batch Loss: 9.64496848609997e-06\n",
      "Epoch 4678, Loss: 6.912862590979785e-05, Final Batch Loss: 3.6297460610512644e-05\n",
      "Epoch 4679, Loss: 0.0004931055630095216, Final Batch Loss: 3.322497150293202e-06\n",
      "Epoch 4680, Loss: 0.007787086145071953, Final Batch Loss: 1.3045576451986562e-05\n",
      "Epoch 4681, Loss: 6.781085176044144e-05, Final Batch Loss: 2.8828668291680515e-05\n",
      "Epoch 4682, Loss: 1.9035846889892127e-05, Final Batch Loss: 1.1028516382793896e-05\n",
      "Epoch 4683, Loss: 0.0002652754010341596, Final Batch Loss: 0.00021058690617792308\n",
      "Epoch 4684, Loss: 0.0001644818257773295, Final Batch Loss: 0.0001086672127712518\n",
      "Epoch 4685, Loss: 2.75463398793363e-05, Final Batch Loss: 5.728385986003559e-06\n",
      "Epoch 4686, Loss: 5.176204740564572e-05, Final Batch Loss: 1.2833036635129247e-05\n",
      "Epoch 4687, Loss: 7.09367386662052e-05, Final Batch Loss: 8.850955964589957e-06\n",
      "Epoch 4688, Loss: 9.528553891868796e-05, Final Batch Loss: 7.991610618773848e-05\n",
      "Epoch 4689, Loss: 0.0004074542102898704, Final Batch Loss: 0.0003973393468186259\n",
      "Epoch 4690, Loss: 4.861529487243388e-05, Final Batch Loss: 1.8738022845354863e-05\n",
      "Epoch 4691, Loss: 6.649108672718285e-05, Final Batch Loss: 1.0273593034071382e-05\n",
      "Epoch 4692, Loss: 0.0010923740956059191, Final Batch Loss: 0.0010633505880832672\n",
      "Epoch 4693, Loss: 0.00015201678615994751, Final Batch Loss: 0.00014147070760373026\n",
      "Epoch 4694, Loss: 1.1007500688720029e-05, Final Batch Loss: 5.546693500946276e-06\n",
      "Epoch 4695, Loss: 0.00024503505119355395, Final Batch Loss: 0.00021107911015860736\n",
      "Epoch 4696, Loss: 4.153713507548673e-05, Final Batch Loss: 1.117189367505489e-05\n",
      "Epoch 4697, Loss: 0.0032536533817619784, Final Batch Loss: 1.7465526980231516e-05\n",
      "Epoch 4698, Loss: 7.832727169443388e-05, Final Batch Loss: 4.976067066309042e-05\n",
      "Epoch 4699, Loss: 0.00035032210871577263, Final Batch Loss: 0.0002627175999805331\n",
      "Epoch 4700, Loss: 0.00011737189743143972, Final Batch Loss: 1.2924732800456695e-05\n",
      "Epoch 4701, Loss: 0.0013165727548880568, Final Batch Loss: 7.372407822003879e-07\n",
      "Epoch 4702, Loss: 7.615740446453856e-05, Final Batch Loss: 3.1166271128313383e-06\n",
      "Epoch 4703, Loss: 5.141129622643348e-05, Final Batch Loss: 3.208023917977698e-05\n",
      "Epoch 4704, Loss: 3.9107038219299284e-05, Final Batch Loss: 3.235643134757993e-06\n",
      "Epoch 4705, Loss: 0.0001573741865286138, Final Batch Loss: 3.50004956999328e-05\n",
      "Epoch 4706, Loss: 0.000648839046334615, Final Batch Loss: 0.0006011179648339748\n",
      "Epoch 4707, Loss: 9.927580867952202e-05, Final Batch Loss: 1.9408706066315062e-05\n",
      "Epoch 4708, Loss: 0.002702031280932715, Final Batch Loss: 0.0026831969153136015\n",
      "Epoch 4709, Loss: 0.00025078264116018545, Final Batch Loss: 1.617510679352563e-05\n",
      "Epoch 4710, Loss: 3.757625563594047e-05, Final Batch Loss: 1.2103198969271034e-05\n",
      "Epoch 4711, Loss: 5.957486246188637e-05, Final Batch Loss: 1.1787751645897515e-05\n",
      "Epoch 4712, Loss: 0.00034534678161435295, Final Batch Loss: 2.0827372281928547e-05\n",
      "Epoch 4713, Loss: 0.0011800544161815196, Final Batch Loss: 0.00014073544298298657\n",
      "Epoch 4714, Loss: 2.3809423964848975e-05, Final Batch Loss: 4.3092918531328905e-06\n",
      "Epoch 4715, Loss: 0.003225022184778936, Final Batch Loss: 0.0030442294664680958\n",
      "Epoch 4716, Loss: 8.759418960835319e-05, Final Batch Loss: 2.0943871277268045e-05\n",
      "Epoch 4717, Loss: 0.0012051226016183136, Final Batch Loss: 1.0636080105541623e-06\n",
      "Epoch 4718, Loss: 0.00017094466784328688, Final Batch Loss: 0.00014319998444989324\n",
      "Epoch 4719, Loss: 5.9487975704541896e-05, Final Batch Loss: 8.551393875677604e-06\n",
      "Epoch 4720, Loss: 5.518216858035885e-05, Final Batch Loss: 3.1650499295210466e-05\n",
      "Epoch 4721, Loss: 8.095523662632331e-05, Final Batch Loss: 3.3219894248759374e-05\n",
      "Epoch 4722, Loss: 0.0008322450739797205, Final Batch Loss: 0.0007951209554448724\n",
      "Epoch 4723, Loss: 8.133565825119149e-05, Final Batch Loss: 2.9851698855054565e-05\n",
      "Epoch 4724, Loss: 5.2611938372137956e-05, Final Batch Loss: 2.712188143050298e-05\n",
      "Epoch 4725, Loss: 0.00037331176281441003, Final Batch Loss: 0.00012995570432394743\n",
      "Epoch 4726, Loss: 7.781914496263198e-05, Final Batch Loss: 3.053027057831059e-06\n",
      "Epoch 4727, Loss: 8.413021555497835e-05, Final Batch Loss: 3.771745696212747e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4728, Loss: 1.3912713711761171e-05, Final Batch Loss: 2.242929895146517e-06\n",
      "Epoch 4729, Loss: 5.224897904554382e-05, Final Batch Loss: 3.58839170075953e-05\n",
      "Epoch 4730, Loss: 3.951576218241826e-05, Final Batch Loss: 1.5555942809442058e-05\n",
      "Epoch 4731, Loss: 0.0005027928364143008, Final Batch Loss: 2.3518174202763475e-05\n",
      "Epoch 4732, Loss: 0.005701682117432938, Final Batch Loss: 2.0999048501835205e-05\n",
      "Epoch 4733, Loss: 0.00047650201167925843, Final Batch Loss: 0.0004705707833636552\n",
      "Epoch 4734, Loss: 5.327230633156432e-05, Final Batch Loss: 1.6156047877302626e-06\n",
      "Epoch 4735, Loss: 0.0015703699257301196, Final Batch Loss: 3.3641638310655253e-06\n",
      "Epoch 4736, Loss: 2.9457638675012277e-05, Final Batch Loss: 3.4890965707745636e-06\n",
      "Epoch 4737, Loss: 8.098452553895186e-06, Final Batch Loss: 2.5819833808782278e-06\n",
      "Epoch 4738, Loss: 4.0491688196198083e-05, Final Batch Loss: 1.6703739674994722e-05\n",
      "Epoch 4739, Loss: 0.00016481966758874478, Final Batch Loss: 7.223764441732783e-06\n",
      "Epoch 4740, Loss: 3.219926747988211e-05, Final Batch Loss: 8.536740097042639e-06\n",
      "Epoch 4741, Loss: 4.196797954136855e-05, Final Batch Loss: 4.471692136576166e-06\n",
      "Epoch 4742, Loss: 4.086256194568705e-05, Final Batch Loss: 2.617094105517026e-05\n",
      "Epoch 4743, Loss: 0.000578390132432105, Final Batch Loss: 1.2880180292995647e-05\n",
      "Epoch 4744, Loss: 2.3329520900006173e-05, Final Batch Loss: 1.5908322893665172e-05\n",
      "Epoch 4745, Loss: 0.0015668504383938853, Final Batch Loss: 7.805738277966157e-06\n",
      "Epoch 4746, Loss: 0.00010811700394697255, Final Batch Loss: 9.806703747017309e-05\n",
      "Epoch 4747, Loss: 9.515452074992936e-05, Final Batch Loss: 1.6333548046532087e-05\n",
      "Epoch 4748, Loss: 0.0001342286280987537, Final Batch Loss: 9.015797104439116e-07\n",
      "Epoch 4749, Loss: 2.985042465297738e-05, Final Batch Loss: 2.208224941568915e-06\n",
      "Epoch 4750, Loss: 5.1007089496124536e-05, Final Batch Loss: 1.767597859725356e-05\n",
      "Epoch 4751, Loss: 0.0008514465052940068, Final Batch Loss: 8.075124242168386e-06\n",
      "Epoch 4752, Loss: 4.643007605409366e-05, Final Batch Loss: 4.434503807715373e-06\n",
      "Epoch 4753, Loss: 9.171613601210993e-05, Final Batch Loss: 2.841117930074688e-05\n",
      "Epoch 4754, Loss: 0.00016767680153861875, Final Batch Loss: 0.0001580169191583991\n",
      "Epoch 4755, Loss: 0.00020950847829226404, Final Batch Loss: 6.44191459286958e-05\n",
      "Epoch 4756, Loss: 3.176621248712763e-05, Final Batch Loss: 1.4943116184440441e-05\n",
      "Epoch 4757, Loss: 7.970750812091865e-05, Final Batch Loss: 4.786100180353969e-05\n",
      "Epoch 4758, Loss: 3.346258836245397e-05, Final Batch Loss: 6.361578016367275e-06\n",
      "Epoch 4759, Loss: 5.7271360674349125e-05, Final Batch Loss: 5.317903560353443e-05\n",
      "Epoch 4760, Loss: 1.8821137928171083e-05, Final Batch Loss: 5.8380701375426725e-06\n",
      "Epoch 4761, Loss: 3.8271662560873665e-05, Final Batch Loss: 2.8463384296628647e-05\n",
      "Epoch 4762, Loss: 6.199468134582276e-05, Final Batch Loss: 1.1971694220846985e-05\n",
      "Epoch 4763, Loss: 0.001095223776246712, Final Batch Loss: 1.2533110748336185e-05\n",
      "Epoch 4764, Loss: 2.129008589690784e-05, Final Batch Loss: 1.1461496796982829e-05\n",
      "Epoch 4765, Loss: 1.8099568023899337e-05, Final Batch Loss: 4.845482635573717e-06\n",
      "Epoch 4766, Loss: 1.3858977411018714e-05, Final Batch Loss: 1.2942989997100085e-05\n",
      "Epoch 4767, Loss: 0.00757165543109295, Final Batch Loss: 0.007547801360487938\n",
      "Epoch 4768, Loss: 6.692404986097245e-05, Final Batch Loss: 1.381324454996502e-05\n",
      "Epoch 4769, Loss: 3.420769007789204e-05, Final Batch Loss: 7.28693248674972e-06\n",
      "Epoch 4770, Loss: 6.340613072097767e-05, Final Batch Loss: 2.1058169295429252e-05\n",
      "Epoch 4771, Loss: 6.539987748510612e-05, Final Batch Loss: 2.0403729195095366e-06\n",
      "Epoch 4772, Loss: 0.00013740628855885006, Final Batch Loss: 0.0001038818882079795\n",
      "Epoch 4773, Loss: 1.8569929125078488e-05, Final Batch Loss: 1.3997131645737682e-05\n",
      "Epoch 4774, Loss: 0.0003176254977006465, Final Batch Loss: 0.00014693252160213888\n",
      "Epoch 4775, Loss: 4.436094422999304e-05, Final Batch Loss: 2.6949386665364727e-05\n",
      "Epoch 4776, Loss: 4.0786288423078076e-05, Final Batch Loss: 1.6642610489725485e-06\n",
      "Epoch 4777, Loss: 0.00013335391031432664, Final Batch Loss: 2.7474588932818733e-06\n",
      "Epoch 4778, Loss: 3.0729727768630255e-05, Final Batch Loss: 1.2030840480292682e-05\n",
      "Epoch 4779, Loss: 8.655022793391254e-05, Final Batch Loss: 6.471973756561056e-05\n",
      "Epoch 4780, Loss: 1.6205708561756182e-05, Final Batch Loss: 1.0585140444163699e-05\n",
      "Epoch 4781, Loss: 7.179012027336285e-05, Final Batch Loss: 3.264542101533152e-05\n",
      "Epoch 4782, Loss: 2.0708523152279668e-05, Final Batch Loss: 8.432631148025393e-06\n",
      "Epoch 4783, Loss: 5.764732304669451e-05, Final Batch Loss: 2.6755855287774466e-05\n",
      "Epoch 4784, Loss: 3.435711278143572e-05, Final Batch Loss: 2.1548796212300658e-05\n",
      "Epoch 4785, Loss: 6.87073879817035e-05, Final Batch Loss: 1.99706555576995e-05\n",
      "Epoch 4786, Loss: 1.626088942430215e-05, Final Batch Loss: 4.097936653124634e-06\n",
      "Epoch 4787, Loss: 1.2770403145623277e-05, Final Batch Loss: 2.587786866570241e-06\n",
      "Epoch 4788, Loss: 1.9880926174664637e-05, Final Batch Loss: 1.3931438843428623e-05\n",
      "Epoch 4789, Loss: 0.0010976679131999845, Final Batch Loss: 2.3526206859969534e-05\n",
      "Epoch 4790, Loss: 2.604691053420538e-05, Final Batch Loss: 1.624994729354512e-05\n",
      "Epoch 4791, Loss: 9.716896192912827e-05, Final Batch Loss: 9.13935509743169e-05\n",
      "Epoch 4792, Loss: 0.00014904229374224087, Final Batch Loss: 0.0001338576403213665\n",
      "Epoch 4793, Loss: 6.994926116021816e-05, Final Batch Loss: 2.488861900928896e-05\n",
      "Epoch 4794, Loss: 7.439195996994385e-05, Final Batch Loss: 1.0884586117754225e-05\n",
      "Epoch 4795, Loss: 0.0001508902059867978, Final Batch Loss: 2.7311965823173523e-05\n",
      "Epoch 4796, Loss: 0.0006658911242993781, Final Batch Loss: 4.2426636355230585e-06\n",
      "Epoch 4797, Loss: 7.821989856893197e-05, Final Batch Loss: 3.9498525438830256e-05\n",
      "Epoch 4798, Loss: 1.791383101590327e-05, Final Batch Loss: 5.4809920584375504e-06\n",
      "Epoch 4799, Loss: 1.2643390846278635e-05, Final Batch Loss: 2.6815398541657487e-06\n",
      "Epoch 4800, Loss: 5.0440377890481614e-05, Final Batch Loss: 2.5675893994048238e-05\n",
      "Epoch 4801, Loss: 2.36483829212375e-05, Final Batch Loss: 1.4602009287045803e-05\n",
      "Epoch 4802, Loss: 0.00013885953467251966, Final Batch Loss: 9.537217010802124e-06\n",
      "Epoch 4803, Loss: 0.00012486027844715863, Final Batch Loss: 8.62188171595335e-05\n",
      "Epoch 4804, Loss: 4.692107222581399e-05, Final Batch Loss: 7.319886663026409e-06\n",
      "Epoch 4805, Loss: 2.5906389055307955e-05, Final Batch Loss: 9.236140613211319e-06\n",
      "Epoch 4806, Loss: 6.643718006671406e-05, Final Batch Loss: 1.1833628377644345e-05\n",
      "Epoch 4807, Loss: 0.00011379955412849085, Final Batch Loss: 7.606712642882485e-06\n",
      "Epoch 4808, Loss: 5.62847635592334e-05, Final Batch Loss: 4.324230758356862e-05\n",
      "Epoch 4809, Loss: 4.602919034368824e-05, Final Batch Loss: 1.3828435839968733e-05\n",
      "Epoch 4810, Loss: 0.00010324205140932463, Final Batch Loss: 5.076348679722287e-05\n",
      "Epoch 4811, Loss: 0.000447188886028016, Final Batch Loss: 4.8375895858043805e-05\n",
      "Epoch 4812, Loss: 5.81539729864744e-05, Final Batch Loss: 5.411501842900179e-05\n",
      "Epoch 4813, Loss: 1.2250186046003364e-05, Final Batch Loss: 2.2463964342023246e-06\n",
      "Epoch 4814, Loss: 0.0023755296688250382, Final Batch Loss: 0.0023634769022464752\n",
      "Epoch 4815, Loss: 0.0003290998065494932, Final Batch Loss: 5.931463238084689e-05\n",
      "Epoch 4816, Loss: 8.880912355380133e-05, Final Batch Loss: 3.56011041731108e-05\n",
      "Epoch 4817, Loss: 6.362174985952151e-05, Final Batch Loss: 2.1121211375429993e-06\n",
      "Epoch 4818, Loss: 8.540021099179285e-05, Final Batch Loss: 1.1852641364384908e-05\n",
      "Epoch 4819, Loss: 3.131188168481458e-05, Final Batch Loss: 2.1026033209636807e-05\n",
      "Epoch 4820, Loss: 4.212364729028195e-05, Final Batch Loss: 1.8511431335355155e-05\n",
      "Epoch 4821, Loss: 4.650283699447755e-05, Final Batch Loss: 2.809348370647058e-05\n",
      "Epoch 4822, Loss: 3.9183530361697194e-05, Final Batch Loss: 3.670829073598725e-06\n",
      "Epoch 4823, Loss: 0.00024338541152246762, Final Batch Loss: 2.504319309082348e-05\n",
      "Epoch 4824, Loss: 1.946777092598495e-05, Final Batch Loss: 1.284652989852475e-05\n",
      "Epoch 4825, Loss: 0.0008453384575659584, Final Batch Loss: 6.533642135764239e-06\n",
      "Epoch 4826, Loss: 0.0005751954740844667, Final Batch Loss: 0.00013510265853255987\n",
      "Epoch 4827, Loss: 0.00012579838949022815, Final Batch Loss: 6.778227543691173e-05\n",
      "Epoch 4828, Loss: 0.0010218065904155083, Final Batch Loss: 2.727817900449736e-06\n",
      "Epoch 4829, Loss: 0.00011705150609486736, Final Batch Loss: 5.724817674490623e-05\n",
      "Epoch 4830, Loss: 0.0024246767279691994, Final Batch Loss: 2.2838881704956293e-05\n",
      "Epoch 4831, Loss: 1.917310714816267e-05, Final Batch Loss: 2.528682898628176e-06\n",
      "Epoch 4832, Loss: 0.00014287861449702177, Final Batch Loss: 0.00011937408271478489\n",
      "Epoch 4833, Loss: 0.00013964962090540212, Final Batch Loss: 1.9893710486940108e-05\n",
      "Epoch 4834, Loss: 1.800356312742224e-05, Final Batch Loss: 1.498214351158822e-05\n",
      "Epoch 4835, Loss: 3.5109939744870644e-05, Final Batch Loss: 2.680595025594812e-05\n",
      "Epoch 4836, Loss: 7.916119557194179e-05, Final Batch Loss: 6.724604463670403e-05\n",
      "Epoch 4837, Loss: 0.00010756319625215838, Final Batch Loss: 1.3858539205102716e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4838, Loss: 0.001229279918334214, Final Batch Loss: 1.7966620362130925e-05\n",
      "Epoch 4839, Loss: 4.612409793480765e-05, Final Batch Loss: 1.6281159332720563e-05\n",
      "Epoch 4840, Loss: 0.0001688048866981262, Final Batch Loss: 2.7127459816256305e-06\n",
      "Epoch 4841, Loss: 0.0009775053295015823, Final Batch Loss: 4.08830055675935e-05\n",
      "Epoch 4842, Loss: 5.433895239548292e-05, Final Batch Loss: 4.151938992436044e-05\n",
      "Epoch 4843, Loss: 3.517381537676556e-05, Final Batch Loss: 1.0230923180643003e-05\n",
      "Epoch 4844, Loss: 4.940663029628922e-05, Final Batch Loss: 3.511253908072831e-06\n",
      "Epoch 4845, Loss: 7.223311058623949e-05, Final Batch Loss: 6.381468119798228e-05\n",
      "Epoch 4846, Loss: 4.050437200930901e-05, Final Batch Loss: 1.723978311929386e-05\n",
      "Epoch 4847, Loss: 8.088826916718972e-06, Final Batch Loss: 2.284487209180952e-06\n",
      "Epoch 4848, Loss: 0.0005407727439887822, Final Batch Loss: 1.4687771908938885e-05\n",
      "Epoch 4849, Loss: 7.050261365293409e-05, Final Batch Loss: 6.617753388127312e-05\n",
      "Epoch 4850, Loss: 9.160361514659598e-05, Final Batch Loss: 8.185976184904575e-05\n",
      "Epoch 4851, Loss: 0.00019763111413340084, Final Batch Loss: 0.00016691653581801802\n",
      "Epoch 4852, Loss: 3.189378094248241e-05, Final Batch Loss: 1.889302075142041e-05\n",
      "Epoch 4853, Loss: 5.990177760395454e-05, Final Batch Loss: 5.1088874897686765e-05\n",
      "Epoch 4854, Loss: 4.338235476097907e-05, Final Batch Loss: 4.165157861280022e-06\n",
      "Epoch 4855, Loss: 2.903579661506228e-05, Final Batch Loss: 8.931339834816754e-06\n",
      "Epoch 4856, Loss: 5.260285911390383e-05, Final Batch Loss: 3.8071223116276087e-06\n",
      "Epoch 4857, Loss: 0.0006610290383832762, Final Batch Loss: 1.3304083040566184e-05\n",
      "Epoch 4858, Loss: 2.1078305962873856e-05, Final Batch Loss: 4.626958343578735e-06\n",
      "Epoch 4859, Loss: 5.8266849009669386e-05, Final Batch Loss: 2.650858550623525e-05\n",
      "Epoch 4860, Loss: 0.00013653634232468903, Final Batch Loss: 9.539841266814619e-05\n",
      "Epoch 4861, Loss: 2.7989568934572162e-05, Final Batch Loss: 3.2798056963656563e-06\n",
      "Epoch 4862, Loss: 4.508338497544173e-05, Final Batch Loss: 1.4614428437198512e-05\n",
      "Epoch 4863, Loss: 2.5935953090083785e-05, Final Batch Loss: 8.641100066597573e-06\n",
      "Epoch 4864, Loss: 5.071126179245766e-05, Final Batch Loss: 3.312374246888794e-05\n",
      "Epoch 4865, Loss: 3.406069481570739e-05, Final Batch Loss: 2.468184902681969e-05\n",
      "Epoch 4866, Loss: 0.0002443765147290833, Final Batch Loss: 3.772805484913988e-06\n",
      "Epoch 4867, Loss: 8.103471554932185e-05, Final Batch Loss: 2.2472740965895355e-05\n",
      "Epoch 4868, Loss: 8.296044325106777e-05, Final Batch Loss: 4.27815830335021e-05\n",
      "Epoch 4869, Loss: 0.00010702268900786294, Final Batch Loss: 0.00010103836393682286\n",
      "Epoch 4870, Loss: 2.0307880731706973e-05, Final Batch Loss: 1.3961804143036716e-05\n",
      "Epoch 4871, Loss: 0.00018558120063971728, Final Batch Loss: 6.779097020626068e-06\n",
      "Epoch 4872, Loss: 2.0571194568219653e-05, Final Batch Loss: 1.1538865010152222e-06\n",
      "Epoch 4873, Loss: 0.0005510229166247882, Final Batch Loss: 4.2509731429163367e-05\n",
      "Epoch 4874, Loss: 4.714544047601521e-05, Final Batch Loss: 2.0708619558718055e-05\n",
      "Epoch 4875, Loss: 4.561792593449354e-05, Final Batch Loss: 2.265958028146997e-05\n",
      "Epoch 4876, Loss: 0.00044014668674208224, Final Batch Loss: 1.3032578863203526e-05\n",
      "Epoch 4877, Loss: 0.0001645098818698898, Final Batch Loss: 7.438694592565298e-05\n",
      "Epoch 4878, Loss: 2.196914192609256e-05, Final Batch Loss: 1.0264068805554416e-05\n",
      "Epoch 4879, Loss: 0.00010100424242409645, Final Batch Loss: 1.0117389138031285e-05\n",
      "Epoch 4880, Loss: 9.830622252593457e-05, Final Batch Loss: 1.1261097370152129e-06\n",
      "Epoch 4881, Loss: 0.00020167039110674523, Final Batch Loss: 1.849753243732266e-05\n",
      "Epoch 4882, Loss: 1.6384967693738872e-05, Final Batch Loss: 4.66739993498777e-06\n",
      "Epoch 4883, Loss: 2.731327185756527e-05, Final Batch Loss: 1.423187040927587e-05\n",
      "Epoch 4884, Loss: 2.597853381303139e-05, Final Batch Loss: 1.5153368622122798e-05\n",
      "Epoch 4885, Loss: 4.486011130211409e-05, Final Batch Loss: 1.685740426182747e-05\n",
      "Epoch 4886, Loss: 0.0013837199439876713, Final Batch Loss: 2.263961505377665e-05\n",
      "Epoch 4887, Loss: 1.9477222338082356e-05, Final Batch Loss: 2.8702783083645045e-07\n",
      "Epoch 4888, Loss: 8.192640962079167e-05, Final Batch Loss: 4.3267024011584e-05\n",
      "Epoch 4889, Loss: 1.958449695393938e-05, Final Batch Loss: 1.1261091685810243e-06\n",
      "Epoch 4890, Loss: 3.144574816360546e-05, Final Batch Loss: 1.4755948996025836e-06\n",
      "Epoch 4891, Loss: 5.118015906191431e-05, Final Batch Loss: 7.914251909824088e-06\n",
      "Epoch 4892, Loss: 0.0007073583583405707, Final Batch Loss: 1.8061549781123176e-05\n",
      "Epoch 4893, Loss: 1.5061274780237e-05, Final Batch Loss: 3.284508011347498e-06\n",
      "Epoch 4894, Loss: 0.00012014048115815967, Final Batch Loss: 9.103787306230515e-06\n",
      "Epoch 4895, Loss: 0.0004229751530147041, Final Batch Loss: 6.332399607344996e-06\n",
      "Epoch 4896, Loss: 6.64617164147785e-05, Final Batch Loss: 4.19821371906437e-05\n",
      "Epoch 4897, Loss: 0.0010483616570127197, Final Batch Loss: 2.275163569720462e-05\n",
      "Epoch 4898, Loss: 0.0003412869591556955, Final Batch Loss: 4.696623727795668e-05\n",
      "Epoch 4899, Loss: 0.0001293240966333542, Final Batch Loss: 3.3136657293653116e-05\n",
      "Epoch 4900, Loss: 7.369073318841401e-05, Final Batch Loss: 1.6657506421324797e-05\n",
      "Epoch 4901, Loss: 0.0003594283443817403, Final Batch Loss: 1.7232927348231897e-05\n",
      "Epoch 4902, Loss: 0.00016575847075728234, Final Batch Loss: 0.0001404653739882633\n",
      "Epoch 4903, Loss: 4.24105865022284e-05, Final Batch Loss: 2.9273967811604962e-05\n",
      "Epoch 4904, Loss: 0.0008789506191533292, Final Batch Loss: 1.0061581633635797e-05\n",
      "Epoch 4905, Loss: 1.0260997669320204e-05, Final Batch Loss: 2.2069555143389152e-06\n",
      "Epoch 4906, Loss: 2.0207988654874498e-05, Final Batch Loss: 2.901332209148677e-06\n",
      "Epoch 4907, Loss: 0.00013165524796932004, Final Batch Loss: 3.251949601690285e-05\n",
      "Epoch 4908, Loss: 0.00014162317984300898, Final Batch Loss: 0.00012744801642838866\n",
      "Epoch 4909, Loss: 2.5127490516752005e-05, Final Batch Loss: 2.1213909349171445e-06\n",
      "Epoch 4910, Loss: 6.747455336153507e-05, Final Batch Loss: 2.5069799448829144e-05\n",
      "Epoch 4911, Loss: 0.00034830663207685575, Final Batch Loss: 1.701612927718088e-05\n",
      "Epoch 4912, Loss: 0.0014556373052982963, Final Batch Loss: 8.713715033081826e-06\n",
      "Epoch 4913, Loss: 1.3691915455638082e-05, Final Batch Loss: 1.108332162402803e-05\n",
      "Epoch 4914, Loss: 3.2356138035538606e-05, Final Batch Loss: 2.1548959921346977e-05\n",
      "Epoch 4915, Loss: 1.2091444318684808e-05, Final Batch Loss: 1.6515392644578242e-06\n",
      "Epoch 4916, Loss: 5.28197724634083e-05, Final Batch Loss: 1.2396716556395404e-05\n",
      "Epoch 4917, Loss: 2.2297328314380138e-05, Final Batch Loss: 1.3876303910365095e-06\n",
      "Epoch 4918, Loss: 3.1387463423016015e-05, Final Batch Loss: 1.6340871297870763e-05\n",
      "Epoch 4919, Loss: 4.947075376549037e-05, Final Batch Loss: 4.426360465004109e-05\n",
      "Epoch 4920, Loss: 0.00010310070388186432, Final Batch Loss: 2.2927040390641196e-06\n",
      "Epoch 4921, Loss: 2.3198212147690356e-05, Final Batch Loss: 1.2771858564519789e-05\n",
      "Epoch 4922, Loss: 5.171487032384903e-06, Final Batch Loss: 3.7829822758794762e-06\n",
      "Epoch 4923, Loss: 7.839608809945275e-05, Final Batch Loss: 4.1665265371193527e-07\n",
      "Epoch 4924, Loss: 1.988038820854854e-05, Final Batch Loss: 1.6116717233671807e-05\n",
      "Epoch 4925, Loss: 0.0011170823599968571, Final Batch Loss: 3.3264212106587365e-05\n",
      "Epoch 4926, Loss: 1.3830692068950157e-05, Final Batch Loss: 1.1479068234621082e-05\n",
      "Epoch 4927, Loss: 0.00017693533936835593, Final Batch Loss: 9.458292879571673e-06\n",
      "Epoch 4928, Loss: 0.0002473739441484213, Final Batch Loss: 1.8201681086793542e-05\n",
      "Epoch 4929, Loss: 2.1386214712038054e-05, Final Batch Loss: 2.7913717985939e-06\n",
      "Epoch 4930, Loss: 8.680273776917602e-05, Final Batch Loss: 8.211895328713581e-05\n",
      "Epoch 4931, Loss: 1.576911751044463e-05, Final Batch Loss: 8.84221719843481e-07\n",
      "Epoch 4932, Loss: 1.2443084870028542e-05, Final Batch Loss: 9.978952220990323e-06\n",
      "Epoch 4933, Loss: 2.5520913368382026e-05, Final Batch Loss: 1.671580866968725e-05\n",
      "Epoch 4934, Loss: 0.00013485709860106, Final Batch Loss: 3.51475719071459e-05\n",
      "Epoch 4935, Loss: 0.00014535765399159573, Final Batch Loss: 3.7347188026615186e-06\n",
      "Epoch 4936, Loss: 5.3759183174406644e-05, Final Batch Loss: 4.4610660552280024e-05\n",
      "Epoch 4937, Loss: 2.0160531676083338e-05, Final Batch Loss: 8.587217962485738e-06\n",
      "Epoch 4938, Loss: 4.1161253648169804e-05, Final Batch Loss: 5.795359356852714e-06\n",
      "Epoch 4939, Loss: 2.2758890736440662e-05, Final Batch Loss: 4.135014933126513e-06\n",
      "Epoch 4940, Loss: 0.0002623656127980212, Final Batch Loss: 2.264232352899853e-05\n",
      "Epoch 4941, Loss: 3.9441350963898e-05, Final Batch Loss: 1.3048495020484552e-05\n",
      "Epoch 4942, Loss: 1.3218958429206396e-05, Final Batch Loss: 8.34675483929459e-06\n",
      "Epoch 4943, Loss: 0.004709782890131464, Final Batch Loss: 0.004696373362094164\n",
      "Epoch 4944, Loss: 0.00037097756467119325, Final Batch Loss: 0.00034274812787771225\n",
      "Epoch 4945, Loss: 8.17321570139029e-05, Final Batch Loss: 8.717383934708778e-06\n",
      "Epoch 4946, Loss: 8.084177170530893e-05, Final Batch Loss: 1.0313106031389907e-05\n",
      "Epoch 4947, Loss: 0.0015528980875387788, Final Batch Loss: 0.0006380316335707903\n",
      "Epoch 4948, Loss: 5.3674530136049725e-05, Final Batch Loss: 2.9133118005120195e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4949, Loss: 5.4614312830381095e-05, Final Batch Loss: 2.8911599656566978e-05\n",
      "Epoch 4950, Loss: 7.066733815008774e-05, Final Batch Loss: 2.8026886866427958e-05\n",
      "Epoch 4951, Loss: 5.909260471526068e-05, Final Batch Loss: 2.6516770958551206e-05\n",
      "Epoch 4952, Loss: 9.869483437796589e-05, Final Batch Loss: 6.436775947804563e-06\n",
      "Epoch 4953, Loss: 1.241203790414147e-05, Final Batch Loss: 6.087212113925489e-06\n",
      "Epoch 4954, Loss: 2.1496817225852283e-05, Final Batch Loss: 5.488699116540374e-06\n",
      "Epoch 4955, Loss: 0.0005947577592451125, Final Batch Loss: 0.0004402088525239378\n",
      "Epoch 4956, Loss: 4.5193228288553655e-05, Final Batch Loss: 9.464085451327264e-06\n",
      "Epoch 4957, Loss: 0.002623784950174013, Final Batch Loss: 0.002621275605633855\n",
      "Epoch 4958, Loss: 5.449421769299079e-05, Final Batch Loss: 7.959823051351123e-06\n",
      "Epoch 4959, Loss: 1.850173248385545e-05, Final Batch Loss: 7.759823347441852e-06\n",
      "Epoch 4960, Loss: 0.00015461310249520466, Final Batch Loss: 0.00012310284364502877\n",
      "Epoch 4961, Loss: 1.7558260424266336e-05, Final Batch Loss: 1.947798864421202e-06\n",
      "Epoch 4962, Loss: 7.942982392705744e-06, Final Batch Loss: 5.0741155064315535e-06\n",
      "Epoch 4963, Loss: 3.9492128053097986e-05, Final Batch Loss: 2.199740265496075e-05\n",
      "Epoch 4964, Loss: 2.7665274501487147e-05, Final Batch Loss: 1.8861264834413305e-05\n",
      "Epoch 4965, Loss: 1.883767777144385e-05, Final Batch Loss: 1.6311576473526657e-05\n",
      "Epoch 4966, Loss: 1.9562945340112492e-05, Final Batch Loss: 9.513531722404878e-07\n",
      "Epoch 4967, Loss: 0.0002451917389407754, Final Batch Loss: 5.4205956985242665e-05\n",
      "Epoch 4968, Loss: 3.3920729720193776e-05, Final Batch Loss: 1.4628901681135176e-06\n",
      "Epoch 4969, Loss: 0.0008788384047875297, Final Batch Loss: 8.643885848869104e-06\n",
      "Epoch 4970, Loss: 5.8334723689768e-05, Final Batch Loss: 1.1860908671224024e-05\n",
      "Epoch 4971, Loss: 5.0631933845579624e-05, Final Batch Loss: 2.8250589821254835e-05\n",
      "Epoch 4972, Loss: 4.608986580478813e-05, Final Batch Loss: 1.170078917311912e-06\n",
      "Epoch 4973, Loss: 4.9992142521659844e-05, Final Batch Loss: 1.3756229236605577e-05\n",
      "Epoch 4974, Loss: 8.739870281715412e-06, Final Batch Loss: 5.457079168991186e-06\n",
      "Epoch 4975, Loss: 4.772216561832465e-05, Final Batch Loss: 4.118327342439443e-05\n",
      "Epoch 4976, Loss: 0.0016445858491351828, Final Batch Loss: 0.0016293071676045656\n",
      "Epoch 4977, Loss: 7.3304215675307205e-06, Final Batch Loss: 2.38405232266814e-06\n",
      "Epoch 4978, Loss: 3.56051837115956e-05, Final Batch Loss: 2.815786046994617e-06\n",
      "Epoch 4979, Loss: 8.31455436127726e-05, Final Batch Loss: 1.681829962763004e-05\n",
      "Epoch 4980, Loss: 1.6918588926273515e-05, Final Batch Loss: 2.4800967821647646e-06\n",
      "Epoch 4981, Loss: 0.001282934737901087, Final Batch Loss: 9.24168671190273e-06\n",
      "Epoch 4982, Loss: 0.0034147887727158377, Final Batch Loss: 0.0033967960625886917\n",
      "Epoch 4983, Loss: 3.2110840038512833e-05, Final Batch Loss: 2.5495413865428418e-05\n",
      "Epoch 4984, Loss: 3.582590625228477e-05, Final Batch Loss: 2.817949734890135e-06\n",
      "Epoch 4985, Loss: 9.99597696136334e-05, Final Batch Loss: 4.232971150486264e-06\n",
      "Epoch 4986, Loss: 5.241236613073852e-05, Final Batch Loss: 2.5629939045757055e-05\n",
      "Epoch 4987, Loss: 3.9626849684282206e-05, Final Batch Loss: 2.504390067770146e-05\n",
      "Epoch 4988, Loss: 2.0231641883583507e-05, Final Batch Loss: 5.375875389290741e-06\n",
      "Epoch 4989, Loss: 3.956639966418152e-05, Final Batch Loss: 3.2598534744465724e-05\n",
      "Epoch 4990, Loss: 7.791978714521974e-05, Final Batch Loss: 7.410787657136098e-05\n",
      "Epoch 4991, Loss: 8.188599167624488e-05, Final Batch Loss: 1.7386453691869974e-05\n",
      "Epoch 4992, Loss: 2.292023850714031e-06, Final Batch Loss: 8.344413799932227e-07\n",
      "Epoch 4993, Loss: 0.0001971248739209841, Final Batch Loss: 0.0001926392433233559\n",
      "Epoch 4994, Loss: 7.5507944075070554e-06, Final Batch Loss: 1.4756071777810575e-06\n",
      "Epoch 4995, Loss: 1.3747525940743799e-05, Final Batch Loss: 1.7441103636883781e-06\n",
      "Epoch 4996, Loss: 8.880891527951462e-06, Final Batch Loss: 4.988857199350605e-06\n",
      "Epoch 4997, Loss: 3.6049781897418143e-06, Final Batch Loss: 1.620316538719635e-07\n",
      "Epoch 4998, Loss: 1.388153850712115e-05, Final Batch Loss: 2.8793765523005277e-06\n",
      "Epoch 4999, Loss: 4.754431211040355e-05, Final Batch Loss: 1.839456490415614e-05\n",
      "Epoch 5000, Loss: 0.0001422415443812497, Final Batch Loss: 1.093188620870933e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39  0  0]\n",
      " [ 0 23  0]\n",
      " [ 0  0 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        39\n",
      "           1    1.00000   1.00000   1.00000        23\n",
      "           2    1.00000   1.00000   1.00000        27\n",
      "\n",
      "    accuracy                        1.00000        89\n",
      "   macro avg    1.00000   1.00000   1.00000        89\n",
      "weighted avg    1.00000   1.00000   1.00000        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (gen): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=106, out_features=80, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=80, out_features=60, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=60, out_features=50, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Linear(in_features=50, out_features=46, bias=True)\n",
       "    (4): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = Generator(z_dim = 106)\n",
    "load_model(gen, \"cGAN_UCI_Group_2_gen.param\")\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(X_test)\n",
    "latent_vectors = get_noise(size, 100)\n",
    "act_vectors = get_act_matrix(size, 3)\n",
    "usr_vectors = get_usr_matrix(size, 3)\n",
    "\n",
    "to_gen = torch.cat((latent_vectors, act_vectors[1], usr_vectors[1]), 1)\n",
    "fake_features = gen(to_gen).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26  0  0]\n",
      " [ 0 34  0]\n",
      " [ 0  0 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        26\n",
      "           1    1.00000   1.00000   1.00000        34\n",
      "           2    1.00000   1.00000   1.00000        29\n",
      "\n",
      "    accuracy                        1.00000        89\n",
      "   macro avg    1.00000   1.00000   1.00000        89\n",
      "weighted avg    1.00000   1.00000   1.00000        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(act_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(act_vectors[0], preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [7, 8, 11]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 7:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 8:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2510942220687866, Final Batch Loss: 1.0841840505599976\n",
      "Epoch 2, Loss: 2.2959787845611572, Final Batch Loss: 1.1698410511016846\n",
      "Epoch 3, Loss: 2.281762957572937, Final Batch Loss: 1.1564549207687378\n",
      "Epoch 4, Loss: 2.2604804039001465, Final Batch Loss: 1.1193715333938599\n",
      "Epoch 5, Loss: 2.260292172431946, Final Batch Loss: 1.132501482963562\n",
      "Epoch 6, Loss: 2.2591344118118286, Final Batch Loss: 1.1318106651306152\n",
      "Epoch 7, Loss: 2.2493975162506104, Final Batch Loss: 1.1259241104125977\n",
      "Epoch 8, Loss: 2.2487409114837646, Final Batch Loss: 1.1266247034072876\n",
      "Epoch 9, Loss: 2.243160367012024, Final Batch Loss: 1.1294907331466675\n",
      "Epoch 10, Loss: 2.2435139417648315, Final Batch Loss: 1.1306999921798706\n",
      "Epoch 11, Loss: 2.2192611694335938, Final Batch Loss: 1.0988774299621582\n",
      "Epoch 12, Loss: 2.2338547706604004, Final Batch Loss: 1.1275932788848877\n",
      "Epoch 13, Loss: 2.203971028327942, Final Batch Loss: 1.0928239822387695\n",
      "Epoch 14, Loss: 2.2088714838027954, Final Batch Loss: 1.1045339107513428\n",
      "Epoch 15, Loss: 2.2064894437789917, Final Batch Loss: 1.107674479484558\n",
      "Epoch 16, Loss: 2.1903600692749023, Final Batch Loss: 1.0888452529907227\n",
      "Epoch 17, Loss: 2.197905659675598, Final Batch Loss: 1.099987268447876\n",
      "Epoch 18, Loss: 2.173821806907654, Final Batch Loss: 1.0766545534133911\n",
      "Epoch 19, Loss: 2.164422035217285, Final Batch Loss: 1.072040319442749\n",
      "Epoch 20, Loss: 2.157514214515686, Final Batch Loss: 1.0726680755615234\n",
      "Epoch 21, Loss: 2.16114342212677, Final Batch Loss: 1.0820765495300293\n",
      "Epoch 22, Loss: 2.1611289978027344, Final Batch Loss: 1.0985718965530396\n",
      "Epoch 23, Loss: 2.1517146825790405, Final Batch Loss: 1.0680060386657715\n",
      "Epoch 24, Loss: 2.135630488395691, Final Batch Loss: 1.066847801208496\n",
      "Epoch 25, Loss: 2.108185291290283, Final Batch Loss: 1.0503425598144531\n",
      "Epoch 26, Loss: 2.130050539970398, Final Batch Loss: 1.0786566734313965\n",
      "Epoch 27, Loss: 2.1178574562072754, Final Batch Loss: 1.037858247756958\n",
      "Epoch 28, Loss: 2.1358309984207153, Final Batch Loss: 1.0695316791534424\n",
      "Epoch 29, Loss: 2.1351293325424194, Final Batch Loss: 1.070583462715149\n",
      "Epoch 30, Loss: 2.143843650817871, Final Batch Loss: 1.0918091535568237\n",
      "Epoch 31, Loss: 2.0887176990509033, Final Batch Loss: 1.0433698892593384\n",
      "Epoch 32, Loss: 2.119878649711609, Final Batch Loss: 1.064429521560669\n",
      "Epoch 33, Loss: 2.1202633380889893, Final Batch Loss: 1.0797626972198486\n",
      "Epoch 34, Loss: 2.0783954858779907, Final Batch Loss: 1.0352176427841187\n",
      "Epoch 35, Loss: 2.0595924854278564, Final Batch Loss: 1.0214134454727173\n",
      "Epoch 36, Loss: 2.0672906637191772, Final Batch Loss: 1.026411771774292\n",
      "Epoch 37, Loss: 2.0934091806411743, Final Batch Loss: 1.0681127309799194\n",
      "Epoch 38, Loss: 2.0654714107513428, Final Batch Loss: 1.0354775190353394\n",
      "Epoch 39, Loss: 2.0472171306610107, Final Batch Loss: 1.0316253900527954\n",
      "Epoch 40, Loss: 2.0256069898605347, Final Batch Loss: 1.0106923580169678\n",
      "Epoch 41, Loss: 1.9921038150787354, Final Batch Loss: 0.9780168533325195\n",
      "Epoch 42, Loss: 1.985128104686737, Final Batch Loss: 0.9758105874061584\n",
      "Epoch 43, Loss: 1.9951022863388062, Final Batch Loss: 1.0088433027267456\n",
      "Epoch 44, Loss: 1.919383466243744, Final Batch Loss: 0.9318838119506836\n",
      "Epoch 45, Loss: 1.8977506756782532, Final Batch Loss: 0.9277446866035461\n",
      "Epoch 46, Loss: 1.9411023259162903, Final Batch Loss: 0.9809941649436951\n",
      "Epoch 47, Loss: 1.8964866995811462, Final Batch Loss: 0.9549810886383057\n",
      "Epoch 48, Loss: 1.9115692377090454, Final Batch Loss: 0.9783036112785339\n",
      "Epoch 49, Loss: 1.8044044971466064, Final Batch Loss: 0.878054141998291\n",
      "Epoch 50, Loss: 1.7974340915679932, Final Batch Loss: 0.8561499714851379\n",
      "Epoch 51, Loss: 1.799042284488678, Final Batch Loss: 0.914021909236908\n",
      "Epoch 52, Loss: 1.7490305304527283, Final Batch Loss: 0.8321112394332886\n",
      "Epoch 53, Loss: 1.7745569944381714, Final Batch Loss: 0.9193885326385498\n",
      "Epoch 54, Loss: 1.7427515387535095, Final Batch Loss: 0.8765024542808533\n",
      "Epoch 55, Loss: 1.7224157452583313, Final Batch Loss: 0.8971657156944275\n",
      "Epoch 56, Loss: 1.6709682941436768, Final Batch Loss: 0.8453137874603271\n",
      "Epoch 57, Loss: 1.671514093875885, Final Batch Loss: 0.8319766521453857\n",
      "Epoch 58, Loss: 1.611641526222229, Final Batch Loss: 0.820957601070404\n",
      "Epoch 59, Loss: 1.6413955688476562, Final Batch Loss: 0.8281099796295166\n",
      "Epoch 60, Loss: 1.6320240497589111, Final Batch Loss: 0.8448140621185303\n",
      "Epoch 61, Loss: 1.5632503628730774, Final Batch Loss: 0.8014510869979858\n",
      "Epoch 62, Loss: 1.530169665813446, Final Batch Loss: 0.7709200382232666\n",
      "Epoch 63, Loss: 1.5964770913124084, Final Batch Loss: 0.7940313220024109\n",
      "Epoch 64, Loss: 1.5797613859176636, Final Batch Loss: 0.8083999156951904\n",
      "Epoch 65, Loss: 1.515174686908722, Final Batch Loss: 0.7620686888694763\n",
      "Epoch 66, Loss: 1.493453562259674, Final Batch Loss: 0.7031339406967163\n",
      "Epoch 67, Loss: 1.4842895865440369, Final Batch Loss: 0.7249416708946228\n",
      "Epoch 68, Loss: 1.5050283074378967, Final Batch Loss: 0.7672504186630249\n",
      "Epoch 69, Loss: 1.4319996237754822, Final Batch Loss: 0.6844860315322876\n",
      "Epoch 70, Loss: 1.4835737347602844, Final Batch Loss: 0.726704478263855\n",
      "Epoch 71, Loss: 1.4619344472885132, Final Batch Loss: 0.720066249370575\n",
      "Epoch 72, Loss: 1.4289122819900513, Final Batch Loss: 0.7223398685455322\n",
      "Epoch 73, Loss: 1.4372339248657227, Final Batch Loss: 0.7030581831932068\n",
      "Epoch 74, Loss: 1.4019723534584045, Final Batch Loss: 0.6772098541259766\n",
      "Epoch 75, Loss: 1.4071143865585327, Final Batch Loss: 0.6980867981910706\n",
      "Epoch 76, Loss: 1.3758056163787842, Final Batch Loss: 0.6868377923965454\n",
      "Epoch 77, Loss: 1.3864943385124207, Final Batch Loss: 0.7139373421669006\n",
      "Epoch 78, Loss: 1.38344806432724, Final Batch Loss: 0.6781487464904785\n",
      "Epoch 79, Loss: 1.3568207621574402, Final Batch Loss: 0.6481059789657593\n",
      "Epoch 80, Loss: 1.4289485216140747, Final Batch Loss: 0.7874834537506104\n",
      "Epoch 81, Loss: 1.2984219789505005, Final Batch Loss: 0.6011962294578552\n",
      "Epoch 82, Loss: 1.3202300667762756, Final Batch Loss: 0.6353951692581177\n",
      "Epoch 83, Loss: 1.3484981656074524, Final Batch Loss: 0.7051063179969788\n",
      "Epoch 84, Loss: 1.276330292224884, Final Batch Loss: 0.5853964686393738\n",
      "Epoch 85, Loss: 1.309236466884613, Final Batch Loss: 0.6439458131790161\n",
      "Epoch 86, Loss: 1.3459222316741943, Final Batch Loss: 0.6865227818489075\n",
      "Epoch 87, Loss: 1.3184999823570251, Final Batch Loss: 0.6699234247207642\n",
      "Epoch 88, Loss: 1.326366126537323, Final Batch Loss: 0.6846036314964294\n",
      "Epoch 89, Loss: 1.3264555931091309, Final Batch Loss: 0.6955490708351135\n",
      "Epoch 90, Loss: 1.3398471474647522, Final Batch Loss: 0.6806789636611938\n",
      "Epoch 91, Loss: 1.270378589630127, Final Batch Loss: 0.6271477341651917\n",
      "Epoch 92, Loss: 1.2918330430984497, Final Batch Loss: 0.6526490449905396\n",
      "Epoch 93, Loss: 1.2585320472717285, Final Batch Loss: 0.6246052980422974\n",
      "Epoch 94, Loss: 1.270780324935913, Final Batch Loss: 0.6494037508964539\n",
      "Epoch 95, Loss: 1.3100929260253906, Final Batch Loss: 0.723089337348938\n",
      "Epoch 96, Loss: 1.2166742086410522, Final Batch Loss: 0.5697979927062988\n",
      "Epoch 97, Loss: 1.335832953453064, Final Batch Loss: 0.7229366898536682\n",
      "Epoch 98, Loss: 1.2351799011230469, Final Batch Loss: 0.5967963337898254\n",
      "Epoch 99, Loss: 1.2289695739746094, Final Batch Loss: 0.5791782140731812\n",
      "Epoch 100, Loss: 1.2721754908561707, Final Batch Loss: 0.6536447405815125\n",
      "Epoch 101, Loss: 1.2604615092277527, Final Batch Loss: 0.6571117639541626\n",
      "Epoch 102, Loss: 1.2496967911720276, Final Batch Loss: 0.6140305995941162\n",
      "Epoch 103, Loss: 1.2287245988845825, Final Batch Loss: 0.5992974638938904\n",
      "Epoch 104, Loss: 1.215710997581482, Final Batch Loss: 0.591216504573822\n",
      "Epoch 105, Loss: 1.2505281567573547, Final Batch Loss: 0.6390761733055115\n",
      "Epoch 106, Loss: 1.2506487369537354, Final Batch Loss: 0.657524824142456\n",
      "Epoch 107, Loss: 1.1785839796066284, Final Batch Loss: 0.5451242923736572\n",
      "Epoch 108, Loss: 1.2030127048492432, Final Batch Loss: 0.5756531357765198\n",
      "Epoch 109, Loss: 1.1783841848373413, Final Batch Loss: 0.5851765871047974\n",
      "Epoch 110, Loss: 1.1471241116523743, Final Batch Loss: 0.5305531024932861\n",
      "Epoch 111, Loss: 1.1732352375984192, Final Batch Loss: 0.5372976660728455\n",
      "Epoch 112, Loss: 1.163292109966278, Final Batch Loss: 0.5781603455543518\n",
      "Epoch 113, Loss: 1.168066382408142, Final Batch Loss: 0.5881469249725342\n",
      "Epoch 114, Loss: 1.1817734241485596, Final Batch Loss: 0.5704420208930969\n",
      "Epoch 115, Loss: 1.1891610622406006, Final Batch Loss: 0.6180102229118347\n",
      "Epoch 116, Loss: 1.1902520656585693, Final Batch Loss: 0.5927861928939819\n",
      "Epoch 117, Loss: 1.1659945249557495, Final Batch Loss: 0.5704419612884521\n",
      "Epoch 118, Loss: 1.169507384300232, Final Batch Loss: 0.6134528517723083\n",
      "Epoch 119, Loss: 1.1489903330802917, Final Batch Loss: 0.5723649859428406\n",
      "Epoch 120, Loss: 1.1426517963409424, Final Batch Loss: 0.5407358407974243\n",
      "Epoch 121, Loss: 1.209280252456665, Final Batch Loss: 0.6403141021728516\n",
      "Epoch 122, Loss: 1.1673001050949097, Final Batch Loss: 0.5871627330780029\n",
      "Epoch 123, Loss: 1.1442053318023682, Final Batch Loss: 0.5771002769470215\n",
      "Epoch 124, Loss: 1.191072165966034, Final Batch Loss: 0.6069515943527222\n",
      "Epoch 125, Loss: 1.2250598073005676, Final Batch Loss: 0.6518988013267517\n",
      "Epoch 126, Loss: 1.1240169405937195, Final Batch Loss: 0.5333920121192932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127, Loss: 1.1624908447265625, Final Batch Loss: 0.5936018824577332\n",
      "Epoch 128, Loss: 1.1042536497116089, Final Batch Loss: 0.5259116291999817\n",
      "Epoch 129, Loss: 1.1246260404586792, Final Batch Loss: 0.5408570170402527\n",
      "Epoch 130, Loss: 1.1036645770072937, Final Batch Loss: 0.5110021233558655\n",
      "Epoch 131, Loss: 1.1107389330863953, Final Batch Loss: 0.5481696128845215\n",
      "Epoch 132, Loss: 1.1442975401878357, Final Batch Loss: 0.536227822303772\n",
      "Epoch 133, Loss: 1.1308058500289917, Final Batch Loss: 0.5440545082092285\n",
      "Epoch 134, Loss: 1.1311856508255005, Final Batch Loss: 0.562324047088623\n",
      "Epoch 135, Loss: 1.1368414163589478, Final Batch Loss: 0.5903642773628235\n",
      "Epoch 136, Loss: 1.1383953094482422, Final Batch Loss: 0.5716593265533447\n",
      "Epoch 137, Loss: 1.0764418244361877, Final Batch Loss: 0.5028005838394165\n",
      "Epoch 138, Loss: 1.1519526243209839, Final Batch Loss: 0.6086592674255371\n",
      "Epoch 139, Loss: 1.1045037508010864, Final Batch Loss: 0.5481641888618469\n",
      "Epoch 140, Loss: 1.2076791524887085, Final Batch Loss: 0.6586905121803284\n",
      "Epoch 141, Loss: 1.108005166053772, Final Batch Loss: 0.5325397253036499\n",
      "Epoch 142, Loss: 1.134484350681305, Final Batch Loss: 0.5849714279174805\n",
      "Epoch 143, Loss: 1.1341336965560913, Final Batch Loss: 0.5736874938011169\n",
      "Epoch 144, Loss: 1.1117464303970337, Final Batch Loss: 0.5500219464302063\n",
      "Epoch 145, Loss: 1.0838913917541504, Final Batch Loss: 0.5073290467262268\n",
      "Epoch 146, Loss: 1.0930410027503967, Final Batch Loss: 0.5198782682418823\n",
      "Epoch 147, Loss: 1.1184527277946472, Final Batch Loss: 0.5384147763252258\n",
      "Epoch 148, Loss: 1.089245319366455, Final Batch Loss: 0.5591347217559814\n",
      "Epoch 149, Loss: 1.1280158162117004, Final Batch Loss: 0.5551491379737854\n",
      "Epoch 150, Loss: 1.0985196232795715, Final Batch Loss: 0.5458980202674866\n",
      "Epoch 151, Loss: 1.0638927221298218, Final Batch Loss: 0.48885953426361084\n",
      "Epoch 152, Loss: 1.081164538860321, Final Batch Loss: 0.5022154450416565\n",
      "Epoch 153, Loss: 1.097050130367279, Final Batch Loss: 0.5515380501747131\n",
      "Epoch 154, Loss: 1.0449186861515045, Final Batch Loss: 0.4862106740474701\n",
      "Epoch 155, Loss: 1.0888559818267822, Final Batch Loss: 0.547431230545044\n",
      "Epoch 156, Loss: 1.087094783782959, Final Batch Loss: 0.5403414368629456\n",
      "Epoch 157, Loss: 1.1060057282447815, Final Batch Loss: 0.5534402132034302\n",
      "Epoch 158, Loss: 1.0928252935409546, Final Batch Loss: 0.5437817573547363\n",
      "Epoch 159, Loss: 1.1088552474975586, Final Batch Loss: 0.5817995071411133\n",
      "Epoch 160, Loss: 1.0719387531280518, Final Batch Loss: 0.507696270942688\n",
      "Epoch 161, Loss: 1.0658405423164368, Final Batch Loss: 0.5389124155044556\n",
      "Epoch 162, Loss: 1.0917076468467712, Final Batch Loss: 0.5683131814002991\n",
      "Epoch 163, Loss: 1.1233185529708862, Final Batch Loss: 0.5781001448631287\n",
      "Epoch 164, Loss: 1.122815191745758, Final Batch Loss: 0.5793482661247253\n",
      "Epoch 165, Loss: 1.1213277578353882, Final Batch Loss: 0.5658433437347412\n",
      "Epoch 166, Loss: 1.0696683526039124, Final Batch Loss: 0.5071796178817749\n",
      "Epoch 167, Loss: 1.101483166217804, Final Batch Loss: 0.5665988326072693\n",
      "Epoch 168, Loss: 1.078139841556549, Final Batch Loss: 0.5259012579917908\n",
      "Epoch 169, Loss: 1.0445818305015564, Final Batch Loss: 0.507482647895813\n",
      "Epoch 170, Loss: 1.0667766332626343, Final Batch Loss: 0.553490161895752\n",
      "Epoch 171, Loss: 1.0192866027355194, Final Batch Loss: 0.49582716822624207\n",
      "Epoch 172, Loss: 1.0863930583000183, Final Batch Loss: 0.5473583340644836\n",
      "Epoch 173, Loss: 1.0954055786132812, Final Batch Loss: 0.5694453716278076\n",
      "Epoch 174, Loss: 1.0308358073234558, Final Batch Loss: 0.5072243809700012\n",
      "Epoch 175, Loss: 1.0700471997261047, Final Batch Loss: 0.565131664276123\n",
      "Epoch 176, Loss: 1.0207215547561646, Final Batch Loss: 0.5016497373580933\n",
      "Epoch 177, Loss: 1.0248713493347168, Final Batch Loss: 0.5002831220626831\n",
      "Epoch 178, Loss: 1.0142816305160522, Final Batch Loss: 0.4960126280784607\n",
      "Epoch 179, Loss: 1.0734093189239502, Final Batch Loss: 0.5444852709770203\n",
      "Epoch 180, Loss: 1.0402703881263733, Final Batch Loss: 0.536782443523407\n",
      "Epoch 181, Loss: 1.039545327425003, Final Batch Loss: 0.4897553026676178\n",
      "Epoch 182, Loss: 1.0694084763526917, Final Batch Loss: 0.5289468169212341\n",
      "Epoch 183, Loss: 1.0875597596168518, Final Batch Loss: 0.5632539987564087\n",
      "Epoch 184, Loss: 1.0426979064941406, Final Batch Loss: 0.5296186804771423\n",
      "Epoch 185, Loss: 1.0062872171401978, Final Batch Loss: 0.5026479363441467\n",
      "Epoch 186, Loss: 1.0137948989868164, Final Batch Loss: 0.49451297521591187\n",
      "Epoch 187, Loss: 1.0248704254627228, Final Batch Loss: 0.4755193889141083\n",
      "Epoch 188, Loss: 0.981880247592926, Final Batch Loss: 0.46133679151535034\n",
      "Epoch 189, Loss: 1.0285577178001404, Final Batch Loss: 0.4966743588447571\n",
      "Epoch 190, Loss: 1.0761844515800476, Final Batch Loss: 0.5829344987869263\n",
      "Epoch 191, Loss: 1.0089056491851807, Final Batch Loss: 0.5079663991928101\n",
      "Epoch 192, Loss: 1.0219603776931763, Final Batch Loss: 0.49895352125167847\n",
      "Epoch 193, Loss: 1.0392629206180573, Final Batch Loss: 0.48164913058280945\n",
      "Epoch 194, Loss: 1.0121365189552307, Final Batch Loss: 0.5012719631195068\n",
      "Epoch 195, Loss: 0.9817927181720734, Final Batch Loss: 0.44523224234580994\n",
      "Epoch 196, Loss: 0.9836764335632324, Final Batch Loss: 0.49142029881477356\n",
      "Epoch 197, Loss: 0.9600405991077423, Final Batch Loss: 0.4408993422985077\n",
      "Epoch 198, Loss: 1.1439449787139893, Final Batch Loss: 0.6341729760169983\n",
      "Epoch 199, Loss: 1.0436536073684692, Final Batch Loss: 0.5228716135025024\n",
      "Epoch 200, Loss: 1.048941433429718, Final Batch Loss: 0.5291318297386169\n",
      "Epoch 201, Loss: 0.9808522462844849, Final Batch Loss: 0.47542238235473633\n",
      "Epoch 202, Loss: 1.021199256181717, Final Batch Loss: 0.5296555757522583\n",
      "Epoch 203, Loss: 1.025001347064972, Final Batch Loss: 0.5279853940010071\n",
      "Epoch 204, Loss: 1.0326129794120789, Final Batch Loss: 0.5317940711975098\n",
      "Epoch 205, Loss: 1.0173312723636627, Final Batch Loss: 0.5582760572433472\n",
      "Epoch 206, Loss: 1.0071925222873688, Final Batch Loss: 0.5320723056793213\n",
      "Epoch 207, Loss: 0.923667699098587, Final Batch Loss: 0.40930768847465515\n",
      "Epoch 208, Loss: 0.9782951176166534, Final Batch Loss: 0.47336283326148987\n",
      "Epoch 209, Loss: 0.9794276356697083, Final Batch Loss: 0.4732867479324341\n",
      "Epoch 210, Loss: 1.0370970666408539, Final Batch Loss: 0.5593984723091125\n",
      "Epoch 211, Loss: 0.9789419174194336, Final Batch Loss: 0.496986448764801\n",
      "Epoch 212, Loss: 0.9497491717338562, Final Batch Loss: 0.4662921130657196\n",
      "Epoch 213, Loss: 0.946044921875, Final Batch Loss: 0.440762996673584\n",
      "Epoch 214, Loss: 1.0101604759693146, Final Batch Loss: 0.5345967411994934\n",
      "Epoch 215, Loss: 0.9608392119407654, Final Batch Loss: 0.458995521068573\n",
      "Epoch 216, Loss: 1.003845900297165, Final Batch Loss: 0.49796512722969055\n",
      "Epoch 217, Loss: 0.9527412354946136, Final Batch Loss: 0.5101951956748962\n",
      "Epoch 218, Loss: 0.9847403466701508, Final Batch Loss: 0.493339866399765\n",
      "Epoch 219, Loss: 0.9618512392044067, Final Batch Loss: 0.5088537931442261\n",
      "Epoch 220, Loss: 0.9682430028915405, Final Batch Loss: 0.5019122958183289\n",
      "Epoch 221, Loss: 0.9624274969100952, Final Batch Loss: 0.4665524661540985\n",
      "Epoch 222, Loss: 0.9368906021118164, Final Batch Loss: 0.4285009503364563\n",
      "Epoch 223, Loss: 0.966351717710495, Final Batch Loss: 0.46783313155174255\n",
      "Epoch 224, Loss: 0.9630739390850067, Final Batch Loss: 0.4563658535480499\n",
      "Epoch 225, Loss: 0.9461482167243958, Final Batch Loss: 0.4634677469730377\n",
      "Epoch 226, Loss: 0.9536193609237671, Final Batch Loss: 0.5032778978347778\n",
      "Epoch 227, Loss: 0.9398084282875061, Final Batch Loss: 0.45882919430732727\n",
      "Epoch 228, Loss: 0.9603164494037628, Final Batch Loss: 0.5139333605766296\n",
      "Epoch 229, Loss: 0.9634865820407867, Final Batch Loss: 0.5096172094345093\n",
      "Epoch 230, Loss: 0.9396181106567383, Final Batch Loss: 0.4590676426887512\n",
      "Epoch 231, Loss: 0.9749409258365631, Final Batch Loss: 0.4894745945930481\n",
      "Epoch 232, Loss: 0.9374132454395294, Final Batch Loss: 0.49877458810806274\n",
      "Epoch 233, Loss: 0.8832466304302216, Final Batch Loss: 0.42193806171417236\n",
      "Epoch 234, Loss: 0.9192683398723602, Final Batch Loss: 0.4775886535644531\n",
      "Epoch 235, Loss: 0.9110936224460602, Final Batch Loss: 0.3990931212902069\n",
      "Epoch 236, Loss: 0.9204773902893066, Final Batch Loss: 0.4372134804725647\n",
      "Epoch 237, Loss: 0.9210109114646912, Final Batch Loss: 0.4574459493160248\n",
      "Epoch 238, Loss: 0.8941430747509003, Final Batch Loss: 0.40372174978256226\n",
      "Epoch 239, Loss: 0.9105799198150635, Final Batch Loss: 0.4733656346797943\n",
      "Epoch 240, Loss: 0.9024278521537781, Final Batch Loss: 0.4351901412010193\n",
      "Epoch 241, Loss: 0.8810709118843079, Final Batch Loss: 0.4213370680809021\n",
      "Epoch 242, Loss: 0.9150296151638031, Final Batch Loss: 0.4453480839729309\n",
      "Epoch 243, Loss: 0.8991870582103729, Final Batch Loss: 0.45890048146247864\n",
      "Epoch 244, Loss: 0.8864698112010956, Final Batch Loss: 0.4285293221473694\n",
      "Epoch 245, Loss: 0.8967340886592865, Final Batch Loss: 0.4367744028568268\n",
      "Epoch 246, Loss: 0.8861394822597504, Final Batch Loss: 0.42725038528442383\n",
      "Epoch 247, Loss: 0.8444179594516754, Final Batch Loss: 0.40175870060920715\n",
      "Epoch 248, Loss: 0.8733235895633698, Final Batch Loss: 0.37658050656318665\n",
      "Epoch 249, Loss: 0.8505497872829437, Final Batch Loss: 0.4092468023300171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250, Loss: 0.8679121732711792, Final Batch Loss: 0.43086349964141846\n",
      "Epoch 251, Loss: 0.8672917187213898, Final Batch Loss: 0.4553251564502716\n",
      "Epoch 252, Loss: 0.90122190117836, Final Batch Loss: 0.47165951132774353\n",
      "Epoch 253, Loss: 0.8512239754199982, Final Batch Loss: 0.4356773793697357\n",
      "Epoch 254, Loss: 0.9199870526790619, Final Batch Loss: 0.4986361861228943\n",
      "Epoch 255, Loss: 0.8515042960643768, Final Batch Loss: 0.46224185824394226\n",
      "Epoch 256, Loss: 0.8343904316425323, Final Batch Loss: 0.417363703250885\n",
      "Epoch 257, Loss: 0.8723017275333405, Final Batch Loss: 0.46541017293930054\n",
      "Epoch 258, Loss: 0.9159546196460724, Final Batch Loss: 0.4733591079711914\n",
      "Epoch 259, Loss: 0.7927674055099487, Final Batch Loss: 0.365781307220459\n",
      "Epoch 260, Loss: 0.8197609782218933, Final Batch Loss: 0.3965409994125366\n",
      "Epoch 261, Loss: 0.795908123254776, Final Batch Loss: 0.37235715985298157\n",
      "Epoch 262, Loss: 0.8320090174674988, Final Batch Loss: 0.4373854100704193\n",
      "Epoch 263, Loss: 0.8276866376399994, Final Batch Loss: 0.4011012017726898\n",
      "Epoch 264, Loss: 0.7747560739517212, Final Batch Loss: 0.3751489222049713\n",
      "Epoch 265, Loss: 0.8314113616943359, Final Batch Loss: 0.45092150568962097\n",
      "Epoch 266, Loss: 0.8188518583774567, Final Batch Loss: 0.41788235306739807\n",
      "Epoch 267, Loss: 0.8283328413963318, Final Batch Loss: 0.4038817286491394\n",
      "Epoch 268, Loss: 0.8307530581951141, Final Batch Loss: 0.39512723684310913\n",
      "Epoch 269, Loss: 0.8012685775756836, Final Batch Loss: 0.4132925868034363\n",
      "Epoch 270, Loss: 0.7838765382766724, Final Batch Loss: 0.38616129755973816\n",
      "Epoch 271, Loss: 0.7981129884719849, Final Batch Loss: 0.36197295784950256\n",
      "Epoch 272, Loss: 0.6845958232879639, Final Batch Loss: 0.30524203181266785\n",
      "Epoch 273, Loss: 0.8175833225250244, Final Batch Loss: 0.435975044965744\n",
      "Epoch 274, Loss: 0.7829263508319855, Final Batch Loss: 0.3900895416736603\n",
      "Epoch 275, Loss: 0.7040559351444244, Final Batch Loss: 0.3386397063732147\n",
      "Epoch 276, Loss: 0.7258728444576263, Final Batch Loss: 0.3580917418003082\n",
      "Epoch 277, Loss: 0.7555088698863983, Final Batch Loss: 0.3379196524620056\n",
      "Epoch 278, Loss: 0.688900887966156, Final Batch Loss: 0.32631245255470276\n",
      "Epoch 279, Loss: 0.7115626931190491, Final Batch Loss: 0.3380252420902252\n",
      "Epoch 280, Loss: 0.6944995224475861, Final Batch Loss: 0.3426060676574707\n",
      "Epoch 281, Loss: 0.7311279773712158, Final Batch Loss: 0.36668258905410767\n",
      "Epoch 282, Loss: 0.7780008614063263, Final Batch Loss: 0.4393137991428375\n",
      "Epoch 283, Loss: 0.6983849108219147, Final Batch Loss: 0.35320496559143066\n",
      "Epoch 284, Loss: 0.6770041286945343, Final Batch Loss: 0.3312034606933594\n",
      "Epoch 285, Loss: 0.6591373682022095, Final Batch Loss: 0.32363662123680115\n",
      "Epoch 286, Loss: 0.7210190892219543, Final Batch Loss: 0.36938613653182983\n",
      "Epoch 287, Loss: 0.7104051411151886, Final Batch Loss: 0.3712894916534424\n",
      "Epoch 288, Loss: 0.6944751739501953, Final Batch Loss: 0.3557611405849457\n",
      "Epoch 289, Loss: 0.64316126704216, Final Batch Loss: 0.3211161494255066\n",
      "Epoch 290, Loss: 0.6763452291488647, Final Batch Loss: 0.3390234410762787\n",
      "Epoch 291, Loss: 0.6207314133644104, Final Batch Loss: 0.30586564540863037\n",
      "Epoch 292, Loss: 0.7114974558353424, Final Batch Loss: 0.34995362162590027\n",
      "Epoch 293, Loss: 0.5423534214496613, Final Batch Loss: 0.22421351075172424\n",
      "Epoch 294, Loss: 0.6234099566936493, Final Batch Loss: 0.3120141327381134\n",
      "Epoch 295, Loss: 0.6197284460067749, Final Batch Loss: 0.31612932682037354\n",
      "Epoch 296, Loss: 0.6579359769821167, Final Batch Loss: 0.3470025062561035\n",
      "Epoch 297, Loss: 0.5644775629043579, Final Batch Loss: 0.2546757757663727\n",
      "Epoch 298, Loss: 0.5668668746948242, Final Batch Loss: 0.27991676330566406\n",
      "Epoch 299, Loss: 0.652297168970108, Final Batch Loss: 0.34253865480422974\n",
      "Epoch 300, Loss: 0.6555658280849457, Final Batch Loss: 0.35027995705604553\n",
      "Epoch 301, Loss: 0.5640105605125427, Final Batch Loss: 0.28819945454597473\n",
      "Epoch 302, Loss: 0.548758253455162, Final Batch Loss: 0.305942177772522\n",
      "Epoch 303, Loss: 0.5465410053730011, Final Batch Loss: 0.2545897960662842\n",
      "Epoch 304, Loss: 0.5486252009868622, Final Batch Loss: 0.2940283715724945\n",
      "Epoch 305, Loss: 0.5765709280967712, Final Batch Loss: 0.3217397630214691\n",
      "Epoch 306, Loss: 0.5085314810276031, Final Batch Loss: 0.2511638402938843\n",
      "Epoch 307, Loss: 0.5668048858642578, Final Batch Loss: 0.27499982714653015\n",
      "Epoch 308, Loss: 0.578255906701088, Final Batch Loss: 0.33360904455184937\n",
      "Epoch 309, Loss: 0.5285099148750305, Final Batch Loss: 0.3383154571056366\n",
      "Epoch 310, Loss: 0.4841337651014328, Final Batch Loss: 0.21878881752490997\n",
      "Epoch 311, Loss: 0.5836374461650848, Final Batch Loss: 0.30915990471839905\n",
      "Epoch 312, Loss: 0.4800327718257904, Final Batch Loss: 0.23767511546611786\n",
      "Epoch 313, Loss: 0.5310144126415253, Final Batch Loss: 0.2530559301376343\n",
      "Epoch 314, Loss: 0.5094738751649857, Final Batch Loss: 0.23594029247760773\n",
      "Epoch 315, Loss: 0.5300407260656357, Final Batch Loss: 0.291851669549942\n",
      "Epoch 316, Loss: 0.5307954698801041, Final Batch Loss: 0.29649364948272705\n",
      "Epoch 317, Loss: 0.5386930704116821, Final Batch Loss: 0.31387248635292053\n",
      "Epoch 318, Loss: 0.4756866544485092, Final Batch Loss: 0.2122151106595993\n",
      "Epoch 319, Loss: 0.4535180479288101, Final Batch Loss: 0.20135433971881866\n",
      "Epoch 320, Loss: 0.4687732607126236, Final Batch Loss: 0.25362569093704224\n",
      "Epoch 321, Loss: 0.5285606682300568, Final Batch Loss: 0.3471246361732483\n",
      "Epoch 322, Loss: 0.4501239061355591, Final Batch Loss: 0.25460562109947205\n",
      "Epoch 323, Loss: 0.500855952501297, Final Batch Loss: 0.2314600646495819\n",
      "Epoch 324, Loss: 0.49124401807785034, Final Batch Loss: 0.2341879904270172\n",
      "Epoch 325, Loss: 0.43660449981689453, Final Batch Loss: 0.18073907494544983\n",
      "Epoch 326, Loss: 0.44632983207702637, Final Batch Loss: 0.2134644240140915\n",
      "Epoch 327, Loss: 0.48568037152290344, Final Batch Loss: 0.2375144213438034\n",
      "Epoch 328, Loss: 0.5209497660398483, Final Batch Loss: 0.30330923199653625\n",
      "Epoch 329, Loss: 0.41550157964229584, Final Batch Loss: 0.21912947297096252\n",
      "Epoch 330, Loss: 0.4180748015642166, Final Batch Loss: 0.19332337379455566\n",
      "Epoch 331, Loss: 0.4416046589612961, Final Batch Loss: 0.2551339566707611\n",
      "Epoch 332, Loss: 0.4838576018810272, Final Batch Loss: 0.23743963241577148\n",
      "Epoch 333, Loss: 0.45066942274570465, Final Batch Loss: 0.20584815740585327\n",
      "Epoch 334, Loss: 0.49133871495723724, Final Batch Loss: 0.27152636647224426\n",
      "Epoch 335, Loss: 0.4460219144821167, Final Batch Loss: 0.2692718207836151\n",
      "Epoch 336, Loss: 0.4638839513063431, Final Batch Loss: 0.23079942166805267\n",
      "Epoch 337, Loss: 0.40871305763721466, Final Batch Loss: 0.19415250420570374\n",
      "Epoch 338, Loss: 0.4991346448659897, Final Batch Loss: 0.28908076882362366\n",
      "Epoch 339, Loss: 0.4172466844320297, Final Batch Loss: 0.23426644504070282\n",
      "Epoch 340, Loss: 0.4651118367910385, Final Batch Loss: 0.1973021775484085\n",
      "Epoch 341, Loss: 0.4519615173339844, Final Batch Loss: 0.20421358942985535\n",
      "Epoch 342, Loss: 0.4929560273885727, Final Batch Loss: 0.2768966853618622\n",
      "Epoch 343, Loss: 0.45604366064071655, Final Batch Loss: 0.19234639406204224\n",
      "Epoch 344, Loss: 0.38625864684581757, Final Batch Loss: 0.1836947649717331\n",
      "Epoch 345, Loss: 0.39654381573200226, Final Batch Loss: 0.19315402209758759\n",
      "Epoch 346, Loss: 0.4870987832546234, Final Batch Loss: 0.271558940410614\n",
      "Epoch 347, Loss: 0.4327481836080551, Final Batch Loss: 0.2021302878856659\n",
      "Epoch 348, Loss: 0.42500224709510803, Final Batch Loss: 0.21819636225700378\n",
      "Epoch 349, Loss: 0.38372477889060974, Final Batch Loss: 0.20858518779277802\n",
      "Epoch 350, Loss: 0.34845511615276337, Final Batch Loss: 0.14338476955890656\n",
      "Epoch 351, Loss: 0.42341265082359314, Final Batch Loss: 0.20105941593647003\n",
      "Epoch 352, Loss: 0.4103597402572632, Final Batch Loss: 0.19456763565540314\n",
      "Epoch 353, Loss: 0.46073949337005615, Final Batch Loss: 0.23443083465099335\n",
      "Epoch 354, Loss: 0.42375583946704865, Final Batch Loss: 0.2070411890745163\n",
      "Epoch 355, Loss: 0.4622737467288971, Final Batch Loss: 0.25976407527923584\n",
      "Epoch 356, Loss: 0.3678123354911804, Final Batch Loss: 0.1868307739496231\n",
      "Epoch 357, Loss: 0.3348018079996109, Final Batch Loss: 0.1549050658941269\n",
      "Epoch 358, Loss: 0.35931235551834106, Final Batch Loss: 0.2054150551557541\n",
      "Epoch 359, Loss: 0.49697640538215637, Final Batch Loss: 0.2845965027809143\n",
      "Epoch 360, Loss: 0.4527682214975357, Final Batch Loss: 0.22208264470100403\n",
      "Epoch 361, Loss: 0.36786527931690216, Final Batch Loss: 0.11402691900730133\n",
      "Epoch 362, Loss: 0.3964480459690094, Final Batch Loss: 0.1795380562543869\n",
      "Epoch 363, Loss: 0.445407435297966, Final Batch Loss: 0.24189652502536774\n",
      "Epoch 364, Loss: 0.48676422238349915, Final Batch Loss: 0.2813011407852173\n",
      "Epoch 365, Loss: 0.4683656245470047, Final Batch Loss: 0.2567799985408783\n",
      "Epoch 366, Loss: 0.3543805032968521, Final Batch Loss: 0.14721664786338806\n",
      "Epoch 367, Loss: 0.3671889007091522, Final Batch Loss: 0.20127670466899872\n",
      "Epoch 368, Loss: 0.41303449869155884, Final Batch Loss: 0.22200487554073334\n",
      "Epoch 369, Loss: 0.41712215542793274, Final Batch Loss: 0.22250884771347046\n",
      "Epoch 370, Loss: 0.35068707168102264, Final Batch Loss: 0.17556658387184143\n",
      "Epoch 371, Loss: 0.3889896869659424, Final Batch Loss: 0.19348615407943726\n",
      "Epoch 372, Loss: 0.41063280403614044, Final Batch Loss: 0.23045015335083008\n",
      "Epoch 373, Loss: 0.3847275823354721, Final Batch Loss: 0.17837074398994446\n",
      "Epoch 374, Loss: 0.35054628551006317, Final Batch Loss: 0.18085350096225739\n",
      "Epoch 375, Loss: 0.4045390635728836, Final Batch Loss: 0.18048825860023499\n",
      "Epoch 376, Loss: 0.3253096789121628, Final Batch Loss: 0.151436910033226\n",
      "Epoch 377, Loss: 0.3678124248981476, Final Batch Loss: 0.1806495636701584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378, Loss: 0.3643789291381836, Final Batch Loss: 0.16385409235954285\n",
      "Epoch 379, Loss: 0.4345874786376953, Final Batch Loss: 0.21674621105194092\n",
      "Epoch 380, Loss: 0.3762754946947098, Final Batch Loss: 0.1863587200641632\n",
      "Epoch 381, Loss: 0.37431128323078156, Final Batch Loss: 0.18674233555793762\n",
      "Epoch 382, Loss: 0.3683106005191803, Final Batch Loss: 0.18573066592216492\n",
      "Epoch 383, Loss: 0.4150029718875885, Final Batch Loss: 0.20814916491508484\n",
      "Epoch 384, Loss: 0.3118809461593628, Final Batch Loss: 0.14526918530464172\n",
      "Epoch 385, Loss: 0.43561387062072754, Final Batch Loss: 0.2780410349369049\n",
      "Epoch 386, Loss: 0.39130300283432007, Final Batch Loss: 0.19379687309265137\n",
      "Epoch 387, Loss: 0.38751381635665894, Final Batch Loss: 0.19259124994277954\n",
      "Epoch 388, Loss: 0.30822083353996277, Final Batch Loss: 0.13041174411773682\n",
      "Epoch 389, Loss: 0.3985576927661896, Final Batch Loss: 0.23561204969882965\n",
      "Epoch 390, Loss: 0.4248001277446747, Final Batch Loss: 0.22085458040237427\n",
      "Epoch 391, Loss: 0.30702200531959534, Final Batch Loss: 0.16652345657348633\n",
      "Epoch 392, Loss: 0.3860444575548172, Final Batch Loss: 0.18783263862133026\n",
      "Epoch 393, Loss: 0.3130291849374771, Final Batch Loss: 0.1534881442785263\n",
      "Epoch 394, Loss: 0.35961100459098816, Final Batch Loss: 0.18220895528793335\n",
      "Epoch 395, Loss: 0.3734215795993805, Final Batch Loss: 0.20401336252689362\n",
      "Epoch 396, Loss: 0.4031212329864502, Final Batch Loss: 0.21735846996307373\n",
      "Epoch 397, Loss: 0.40582065284252167, Final Batch Loss: 0.19647225737571716\n",
      "Epoch 398, Loss: 0.31666556000709534, Final Batch Loss: 0.12258908152580261\n",
      "Epoch 399, Loss: 0.4254857301712036, Final Batch Loss: 0.23810403048992157\n",
      "Epoch 400, Loss: 0.3145361542701721, Final Batch Loss: 0.1588674783706665\n",
      "Epoch 401, Loss: 0.3186919242143631, Final Batch Loss: 0.1751103401184082\n",
      "Epoch 402, Loss: 0.318003311753273, Final Batch Loss: 0.14080937206745148\n",
      "Epoch 403, Loss: 0.3375188410282135, Final Batch Loss: 0.180647075176239\n",
      "Epoch 404, Loss: 0.3019469529390335, Final Batch Loss: 0.1280328631401062\n",
      "Epoch 405, Loss: 0.3603266626596451, Final Batch Loss: 0.18475985527038574\n",
      "Epoch 406, Loss: 0.3714491277933121, Final Batch Loss: 0.20954002439975739\n",
      "Epoch 407, Loss: 0.332040399312973, Final Batch Loss: 0.1579306572675705\n",
      "Epoch 408, Loss: 0.37565021216869354, Final Batch Loss: 0.1818923056125641\n",
      "Epoch 409, Loss: 0.3223051279783249, Final Batch Loss: 0.14715783298015594\n",
      "Epoch 410, Loss: 0.37961217761039734, Final Batch Loss: 0.20500952005386353\n",
      "Epoch 411, Loss: 0.33680500090122223, Final Batch Loss: 0.15667104721069336\n",
      "Epoch 412, Loss: 0.35603857040405273, Final Batch Loss: 0.164520263671875\n",
      "Epoch 413, Loss: 0.29929685592651367, Final Batch Loss: 0.14544937014579773\n",
      "Epoch 414, Loss: 0.4149528741836548, Final Batch Loss: 0.2503279745578766\n",
      "Epoch 415, Loss: 0.3236309885978699, Final Batch Loss: 0.15009164810180664\n",
      "Epoch 416, Loss: 0.30156153440475464, Final Batch Loss: 0.13964331150054932\n",
      "Epoch 417, Loss: 0.315482035279274, Final Batch Loss: 0.11983335018157959\n",
      "Epoch 418, Loss: 0.3752327412366867, Final Batch Loss: 0.1698511689901352\n",
      "Epoch 419, Loss: 0.29131364822387695, Final Batch Loss: 0.14595246315002441\n",
      "Epoch 420, Loss: 0.41554243862628937, Final Batch Loss: 0.21057236194610596\n",
      "Epoch 421, Loss: 0.31177544593811035, Final Batch Loss: 0.14917485415935516\n",
      "Epoch 422, Loss: 0.4100961983203888, Final Batch Loss: 0.23873861134052277\n",
      "Epoch 423, Loss: 0.3220805823802948, Final Batch Loss: 0.11056242883205414\n",
      "Epoch 424, Loss: 0.2759250998497009, Final Batch Loss: 0.1147126853466034\n",
      "Epoch 425, Loss: 0.3542792648077011, Final Batch Loss: 0.1750599443912506\n",
      "Epoch 426, Loss: 0.32150572538375854, Final Batch Loss: 0.17651337385177612\n",
      "Epoch 427, Loss: 0.32108891010284424, Final Batch Loss: 0.16617991030216217\n",
      "Epoch 428, Loss: 0.3593069165945053, Final Batch Loss: 0.16535650193691254\n",
      "Epoch 429, Loss: 0.32736071944236755, Final Batch Loss: 0.1582040935754776\n",
      "Epoch 430, Loss: 0.24380970746278763, Final Batch Loss: 0.10166468471288681\n",
      "Epoch 431, Loss: 0.32417407631874084, Final Batch Loss: 0.1750747561454773\n",
      "Epoch 432, Loss: 0.36077550053596497, Final Batch Loss: 0.2101237028837204\n",
      "Epoch 433, Loss: 0.45012280344963074, Final Batch Loss: 0.29228100180625916\n",
      "Epoch 434, Loss: 0.3290752246975899, Final Batch Loss: 0.2189246565103531\n",
      "Epoch 435, Loss: 0.2989125996828079, Final Batch Loss: 0.11912322044372559\n",
      "Epoch 436, Loss: 0.43028998374938965, Final Batch Loss: 0.2567719519138336\n",
      "Epoch 437, Loss: 0.31307972967624664, Final Batch Loss: 0.13902531564235687\n",
      "Epoch 438, Loss: 0.2597646862268448, Final Batch Loss: 0.135304793715477\n",
      "Epoch 439, Loss: 0.32690198719501495, Final Batch Loss: 0.16140435636043549\n",
      "Epoch 440, Loss: 0.2841443717479706, Final Batch Loss: 0.13583798706531525\n",
      "Epoch 441, Loss: 0.29611606895923615, Final Batch Loss: 0.14276903867721558\n",
      "Epoch 442, Loss: 0.4066404104232788, Final Batch Loss: 0.2430427521467209\n",
      "Epoch 443, Loss: 0.3707403391599655, Final Batch Loss: 0.18476076424121857\n",
      "Epoch 444, Loss: 0.3512079566717148, Final Batch Loss: 0.15378442406654358\n",
      "Epoch 445, Loss: 0.25323793292045593, Final Batch Loss: 0.08771717548370361\n",
      "Epoch 446, Loss: 0.344417542219162, Final Batch Loss: 0.19442977011203766\n",
      "Epoch 447, Loss: 0.29005154967308044, Final Batch Loss: 0.12957541644573212\n",
      "Epoch 448, Loss: 0.3042983114719391, Final Batch Loss: 0.11380207538604736\n",
      "Epoch 449, Loss: 0.30122656375169754, Final Batch Loss: 0.11173247545957565\n",
      "Epoch 450, Loss: 0.30276623368263245, Final Batch Loss: 0.1673828363418579\n",
      "Epoch 451, Loss: 0.3312246948480606, Final Batch Loss: 0.1825648695230484\n",
      "Epoch 452, Loss: 0.36240531504154205, Final Batch Loss: 0.1954740732908249\n",
      "Epoch 453, Loss: 0.3092260807752609, Final Batch Loss: 0.15355940163135529\n",
      "Epoch 454, Loss: 0.3159245252609253, Final Batch Loss: 0.14580696821212769\n",
      "Epoch 455, Loss: 0.3076075464487076, Final Batch Loss: 0.15455442667007446\n",
      "Epoch 456, Loss: 0.329066663980484, Final Batch Loss: 0.1651725471019745\n",
      "Epoch 457, Loss: 0.3184841573238373, Final Batch Loss: 0.15378905832767487\n",
      "Epoch 458, Loss: 0.3407948762178421, Final Batch Loss: 0.218843013048172\n",
      "Epoch 459, Loss: 0.3765112906694412, Final Batch Loss: 0.24010857939720154\n",
      "Epoch 460, Loss: 0.3265724331140518, Final Batch Loss: 0.17439496517181396\n",
      "Epoch 461, Loss: 0.3303987681865692, Final Batch Loss: 0.16858838498592377\n",
      "Epoch 462, Loss: 0.30385178327560425, Final Batch Loss: 0.1471736580133438\n",
      "Epoch 463, Loss: 0.2694166600704193, Final Batch Loss: 0.11687338352203369\n",
      "Epoch 464, Loss: 0.36207787692546844, Final Batch Loss: 0.17666848003864288\n",
      "Epoch 465, Loss: 0.3331516236066818, Final Batch Loss: 0.1728847473859787\n",
      "Epoch 466, Loss: 0.24489694833755493, Final Batch Loss: 0.10989274084568024\n",
      "Epoch 467, Loss: 0.3390588164329529, Final Batch Loss: 0.18961288034915924\n",
      "Epoch 468, Loss: 0.326927050948143, Final Batch Loss: 0.1602715253829956\n",
      "Epoch 469, Loss: 0.3758842647075653, Final Batch Loss: 0.23872403800487518\n",
      "Epoch 470, Loss: 0.3566994369029999, Final Batch Loss: 0.16476348042488098\n",
      "Epoch 471, Loss: 0.37524306774139404, Final Batch Loss: 0.15804296731948853\n",
      "Epoch 472, Loss: 0.2925480902194977, Final Batch Loss: 0.1274261176586151\n",
      "Epoch 473, Loss: 0.20633564889431, Final Batch Loss: 0.06465484201908112\n",
      "Epoch 474, Loss: 0.3199579566717148, Final Batch Loss: 0.16636773943901062\n",
      "Epoch 475, Loss: 0.32759349048137665, Final Batch Loss: 0.15939103066921234\n",
      "Epoch 476, Loss: 0.28950706124305725, Final Batch Loss: 0.1260804980993271\n",
      "Epoch 477, Loss: 0.3132264167070389, Final Batch Loss: 0.14732757210731506\n",
      "Epoch 478, Loss: 0.28674787282943726, Final Batch Loss: 0.13896019756793976\n",
      "Epoch 479, Loss: 0.3028567507863045, Final Batch Loss: 0.18093131482601166\n",
      "Epoch 480, Loss: 0.31293468177318573, Final Batch Loss: 0.15657201409339905\n",
      "Epoch 481, Loss: 0.23476867377758026, Final Batch Loss: 0.09431864321231842\n",
      "Epoch 482, Loss: 0.3326673209667206, Final Batch Loss: 0.16587555408477783\n",
      "Epoch 483, Loss: 0.3151019811630249, Final Batch Loss: 0.15817026793956757\n",
      "Epoch 484, Loss: 0.2891705706715584, Final Batch Loss: 0.09070118516683578\n",
      "Epoch 485, Loss: 0.2832806259393692, Final Batch Loss: 0.13342474400997162\n",
      "Epoch 486, Loss: 0.2684789374470711, Final Batch Loss: 0.09461402148008347\n",
      "Epoch 487, Loss: 0.3052474856376648, Final Batch Loss: 0.12533751130104065\n",
      "Epoch 488, Loss: 0.25615686923265457, Final Batch Loss: 0.10375384241342545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489, Loss: 0.28437216579914093, Final Batch Loss: 0.13627001643180847\n",
      "Epoch 490, Loss: 0.28155621886253357, Final Batch Loss: 0.13504379987716675\n",
      "Epoch 491, Loss: 0.3152358680963516, Final Batch Loss: 0.1462816596031189\n",
      "Epoch 492, Loss: 0.3253253400325775, Final Batch Loss: 0.16905079782009125\n",
      "Epoch 493, Loss: 0.31409014761447906, Final Batch Loss: 0.17754115164279938\n",
      "Epoch 494, Loss: 0.3547675609588623, Final Batch Loss: 0.19936524331569672\n",
      "Epoch 495, Loss: 0.2314099296927452, Final Batch Loss: 0.10375276952981949\n",
      "Epoch 496, Loss: 0.30174168199300766, Final Batch Loss: 0.18022973835468292\n",
      "Epoch 497, Loss: 0.28590138256549835, Final Batch Loss: 0.1298711895942688\n",
      "Epoch 498, Loss: 0.3097292333841324, Final Batch Loss: 0.19002652168273926\n",
      "Epoch 499, Loss: 0.24101264774799347, Final Batch Loss: 0.08157339692115784\n",
      "Epoch 500, Loss: 0.3108999505639076, Final Batch Loss: 0.18640395998954773\n",
      "Epoch 501, Loss: 0.28922851383686066, Final Batch Loss: 0.1417754739522934\n",
      "Epoch 502, Loss: 0.2804480493068695, Final Batch Loss: 0.1432112157344818\n",
      "Epoch 503, Loss: 0.29123108088970184, Final Batch Loss: 0.15496034920215607\n",
      "Epoch 504, Loss: 0.3151211440563202, Final Batch Loss: 0.2058369517326355\n",
      "Epoch 505, Loss: 0.25631698220968246, Final Batch Loss: 0.13344374299049377\n",
      "Epoch 506, Loss: 0.2265109047293663, Final Batch Loss: 0.08424500375986099\n",
      "Epoch 507, Loss: 0.26603878289461136, Final Batch Loss: 0.12415536493062973\n",
      "Epoch 508, Loss: 0.25944382697343826, Final Batch Loss: 0.11366420239210129\n",
      "Epoch 509, Loss: 0.3418753147125244, Final Batch Loss: 0.22040677070617676\n",
      "Epoch 510, Loss: 0.27086547762155533, Final Batch Loss: 0.12412174791097641\n",
      "Epoch 511, Loss: 0.31133902072906494, Final Batch Loss: 0.181115061044693\n",
      "Epoch 512, Loss: 0.3483981192111969, Final Batch Loss: 0.17016935348510742\n",
      "Epoch 513, Loss: 0.3221036195755005, Final Batch Loss: 0.19691923260688782\n",
      "Epoch 514, Loss: 0.33771878480911255, Final Batch Loss: 0.19117148220539093\n",
      "Epoch 515, Loss: 0.2758335694670677, Final Batch Loss: 0.10586468130350113\n",
      "Epoch 516, Loss: 0.3046969622373581, Final Batch Loss: 0.16112229228019714\n",
      "Epoch 517, Loss: 0.26272955536842346, Final Batch Loss: 0.13135218620300293\n",
      "Epoch 518, Loss: 0.30074672400951385, Final Batch Loss: 0.12455013394355774\n",
      "Epoch 519, Loss: 0.2418408766388893, Final Batch Loss: 0.1031680628657341\n",
      "Epoch 520, Loss: 0.3547539561986923, Final Batch Loss: 0.16209626197814941\n",
      "Epoch 521, Loss: 0.2411160096526146, Final Batch Loss: 0.12377528846263885\n",
      "Epoch 522, Loss: 0.3424035608768463, Final Batch Loss: 0.1824640929698944\n",
      "Epoch 523, Loss: 0.28426413983106613, Final Batch Loss: 0.19956640899181366\n",
      "Epoch 524, Loss: 0.3135997951030731, Final Batch Loss: 0.18693892657756805\n",
      "Epoch 525, Loss: 0.31444838643074036, Final Batch Loss: 0.13379719853401184\n",
      "Epoch 526, Loss: 0.2713986039161682, Final Batch Loss: 0.10353526473045349\n",
      "Epoch 527, Loss: 0.2811689153313637, Final Batch Loss: 0.16663910448551178\n",
      "Epoch 528, Loss: 0.25558365136384964, Final Batch Loss: 0.1226285919547081\n",
      "Epoch 529, Loss: 0.24418698996305466, Final Batch Loss: 0.12996450066566467\n",
      "Epoch 530, Loss: 0.1979854851961136, Final Batch Loss: 0.06985028088092804\n",
      "Epoch 531, Loss: 0.26236365735530853, Final Batch Loss: 0.1389160305261612\n",
      "Epoch 532, Loss: 0.3217729181051254, Final Batch Loss: 0.17491570115089417\n",
      "Epoch 533, Loss: 0.29857439547777176, Final Batch Loss: 0.08708523958921432\n",
      "Epoch 534, Loss: 0.26183266937732697, Final Batch Loss: 0.1330244541168213\n",
      "Epoch 535, Loss: 0.36995795369148254, Final Batch Loss: 0.23124663531780243\n",
      "Epoch 536, Loss: 0.2589821219444275, Final Batch Loss: 0.12934575974941254\n",
      "Epoch 537, Loss: 0.3133307993412018, Final Batch Loss: 0.17404425144195557\n",
      "Epoch 538, Loss: 0.31082892417907715, Final Batch Loss: 0.15665321052074432\n",
      "Epoch 539, Loss: 0.30972594022750854, Final Batch Loss: 0.17544396221637726\n",
      "Epoch 540, Loss: 0.3219400644302368, Final Batch Loss: 0.17965391278266907\n",
      "Epoch 541, Loss: 0.22799943387508392, Final Batch Loss: 0.11665019392967224\n",
      "Epoch 542, Loss: 0.27804287523031235, Final Batch Loss: 0.16943185031414032\n",
      "Epoch 543, Loss: 0.24775312095880508, Final Batch Loss: 0.1066218689084053\n",
      "Epoch 544, Loss: 0.23072926700115204, Final Batch Loss: 0.1123763769865036\n",
      "Epoch 545, Loss: 0.23379091173410416, Final Batch Loss: 0.12037346512079239\n",
      "Epoch 546, Loss: 0.2300959974527359, Final Batch Loss: 0.10783803462982178\n",
      "Epoch 547, Loss: 0.2821507304906845, Final Batch Loss: 0.13826188445091248\n",
      "Epoch 548, Loss: 0.19461803883314133, Final Batch Loss: 0.09191340208053589\n",
      "Epoch 549, Loss: 0.25768422335386276, Final Batch Loss: 0.11173895746469498\n",
      "Epoch 550, Loss: 0.24501648545265198, Final Batch Loss: 0.10965596139431\n",
      "Epoch 551, Loss: 0.2045287862420082, Final Batch Loss: 0.08363297581672668\n",
      "Epoch 552, Loss: 0.2444211170077324, Final Batch Loss: 0.13428156077861786\n",
      "Epoch 553, Loss: 0.28782156109809875, Final Batch Loss: 0.1571633368730545\n",
      "Epoch 554, Loss: 0.24590323865413666, Final Batch Loss: 0.13288992643356323\n",
      "Epoch 555, Loss: 0.20823436975479126, Final Batch Loss: 0.09150267392396927\n",
      "Epoch 556, Loss: 0.252474881708622, Final Batch Loss: 0.10030537098646164\n",
      "Epoch 557, Loss: 0.29067471623420715, Final Batch Loss: 0.17482222616672516\n",
      "Epoch 558, Loss: 0.20740288496017456, Final Batch Loss: 0.08094276487827301\n",
      "Epoch 559, Loss: 0.25037430226802826, Final Batch Loss: 0.11449873447418213\n",
      "Epoch 560, Loss: 0.2672290951013565, Final Batch Loss: 0.1548103392124176\n",
      "Epoch 561, Loss: 0.3038368374109268, Final Batch Loss: 0.13850338757038116\n",
      "Epoch 562, Loss: 0.33568352460861206, Final Batch Loss: 0.16639328002929688\n",
      "Epoch 563, Loss: 0.314881294965744, Final Batch Loss: 0.1854856163263321\n",
      "Epoch 564, Loss: 0.2524201422929764, Final Batch Loss: 0.12749634683132172\n",
      "Epoch 565, Loss: 0.2088654264807701, Final Batch Loss: 0.08880671858787537\n",
      "Epoch 566, Loss: 0.24190007895231247, Final Batch Loss: 0.14807462692260742\n",
      "Epoch 567, Loss: 0.26797353476285934, Final Batch Loss: 0.14756901562213898\n",
      "Epoch 568, Loss: 0.2644148990511894, Final Batch Loss: 0.12261191755533218\n",
      "Epoch 569, Loss: 0.2589774429798126, Final Batch Loss: 0.11192813515663147\n",
      "Epoch 570, Loss: 0.28876201808452606, Final Batch Loss: 0.1508764624595642\n",
      "Epoch 571, Loss: 0.22641902416944504, Final Batch Loss: 0.09223050624132156\n",
      "Epoch 572, Loss: 0.268613338470459, Final Batch Loss: 0.16237342357635498\n",
      "Epoch 573, Loss: 0.2013692557811737, Final Batch Loss: 0.08217491209506989\n",
      "Epoch 574, Loss: 0.2799333557486534, Final Batch Loss: 0.17982572317123413\n",
      "Epoch 575, Loss: 0.21859557926654816, Final Batch Loss: 0.08372177183628082\n",
      "Epoch 576, Loss: 0.2702426239848137, Final Batch Loss: 0.16081219911575317\n",
      "Epoch 577, Loss: 0.29112574458122253, Final Batch Loss: 0.16351117193698883\n",
      "Epoch 578, Loss: 0.19270441681146622, Final Batch Loss: 0.07078627496957779\n",
      "Epoch 579, Loss: 0.2623274326324463, Final Batch Loss: 0.11974908411502838\n",
      "Epoch 580, Loss: 0.25819748640060425, Final Batch Loss: 0.11216530203819275\n",
      "Epoch 581, Loss: 0.21283640712499619, Final Batch Loss: 0.09456736594438553\n",
      "Epoch 582, Loss: 0.30550388991832733, Final Batch Loss: 0.1595855951309204\n",
      "Epoch 583, Loss: 0.2219778522849083, Final Batch Loss: 0.0825178250670433\n",
      "Epoch 584, Loss: 0.25022508949041367, Final Batch Loss: 0.12938643991947174\n",
      "Epoch 585, Loss: 0.24700935184955597, Final Batch Loss: 0.1304112821817398\n",
      "Epoch 586, Loss: 0.28184138983488083, Final Batch Loss: 0.16488175094127655\n",
      "Epoch 587, Loss: 0.22550804913043976, Final Batch Loss: 0.1271706521511078\n",
      "Epoch 588, Loss: 0.2017139047384262, Final Batch Loss: 0.06751330196857452\n",
      "Epoch 589, Loss: 0.3034764528274536, Final Batch Loss: 0.15747827291488647\n",
      "Epoch 590, Loss: 0.27222296595573425, Final Batch Loss: 0.14588303864002228\n",
      "Epoch 591, Loss: 0.3065139204263687, Final Batch Loss: 0.17868857085704803\n",
      "Epoch 592, Loss: 0.24122003465890884, Final Batch Loss: 0.11199962347745895\n",
      "Epoch 593, Loss: 0.3017400726675987, Final Batch Loss: 0.18748091161251068\n",
      "Epoch 594, Loss: 0.29241982102394104, Final Batch Loss: 0.1428506076335907\n",
      "Epoch 595, Loss: 0.2566536217927933, Final Batch Loss: 0.11338905990123749\n",
      "Epoch 596, Loss: 0.22408664971590042, Final Batch Loss: 0.11513103544712067\n",
      "Epoch 597, Loss: 0.2679043263196945, Final Batch Loss: 0.1331646591424942\n",
      "Epoch 598, Loss: 0.24814147502183914, Final Batch Loss: 0.1314663589000702\n",
      "Epoch 599, Loss: 0.21154798567295074, Final Batch Loss: 0.08951417356729507\n",
      "Epoch 600, Loss: 0.30662794411182404, Final Batch Loss: 0.17711320519447327\n",
      "Epoch 601, Loss: 0.21922270953655243, Final Batch Loss: 0.08440902829170227\n",
      "Epoch 602, Loss: 0.23380448669195175, Final Batch Loss: 0.1209341362118721\n",
      "Epoch 603, Loss: 0.24311935156583786, Final Batch Loss: 0.12857124209403992\n",
      "Epoch 604, Loss: 0.21854272484779358, Final Batch Loss: 0.0985112413764\n",
      "Epoch 605, Loss: 0.2623240053653717, Final Batch Loss: 0.13294707238674164\n",
      "Epoch 606, Loss: 0.21706657111644745, Final Batch Loss: 0.0695977658033371\n",
      "Epoch 607, Loss: 0.24750429391860962, Final Batch Loss: 0.1022530049085617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 608, Loss: 0.28791071474552155, Final Batch Loss: 0.14793463051319122\n",
      "Epoch 609, Loss: 0.21279018372297287, Final Batch Loss: 0.06573290377855301\n",
      "Epoch 610, Loss: 0.2907107174396515, Final Batch Loss: 0.15042409300804138\n",
      "Epoch 611, Loss: 0.26042040437459946, Final Batch Loss: 0.11711982637643814\n",
      "Epoch 612, Loss: 0.19691123068332672, Final Batch Loss: 0.07357227057218552\n",
      "Epoch 613, Loss: 0.29192057251930237, Final Batch Loss: 0.12865887582302094\n",
      "Epoch 614, Loss: 0.32969536632299423, Final Batch Loss: 0.2063342183828354\n",
      "Epoch 615, Loss: 0.22929952293634415, Final Batch Loss: 0.11326348781585693\n",
      "Epoch 616, Loss: 0.22862759977579117, Final Batch Loss: 0.08129052072763443\n",
      "Epoch 617, Loss: 0.3275911211967468, Final Batch Loss: 0.18520665168762207\n",
      "Epoch 618, Loss: 0.20307888835668564, Final Batch Loss: 0.1077364832162857\n",
      "Epoch 619, Loss: 0.2383471578359604, Final Batch Loss: 0.13489507138729095\n",
      "Epoch 620, Loss: 0.21560115367174149, Final Batch Loss: 0.07058105617761612\n",
      "Epoch 621, Loss: 0.30247870087623596, Final Batch Loss: 0.1583295464515686\n",
      "Epoch 622, Loss: 0.211085706949234, Final Batch Loss: 0.11937122046947479\n",
      "Epoch 623, Loss: 0.1901533529162407, Final Batch Loss: 0.06625757366418839\n",
      "Epoch 624, Loss: 0.1995980590581894, Final Batch Loss: 0.09541644155979156\n",
      "Epoch 625, Loss: 0.2230604812502861, Final Batch Loss: 0.10061875730752945\n",
      "Epoch 626, Loss: 0.21542194485664368, Final Batch Loss: 0.10710622370243073\n",
      "Epoch 627, Loss: 0.255777470767498, Final Batch Loss: 0.12364467233419418\n",
      "Epoch 628, Loss: 0.19316314160823822, Final Batch Loss: 0.0710241049528122\n",
      "Epoch 629, Loss: 0.23002851009368896, Final Batch Loss: 0.11490978300571442\n",
      "Epoch 630, Loss: 0.2884282246232033, Final Batch Loss: 0.18615849316120148\n",
      "Epoch 631, Loss: 0.32322458922863007, Final Batch Loss: 0.19786521792411804\n",
      "Epoch 632, Loss: 0.21955496817827225, Final Batch Loss: 0.11063621193170547\n",
      "Epoch 633, Loss: 0.23935066163539886, Final Batch Loss: 0.14076527953147888\n",
      "Epoch 634, Loss: 0.25422000885009766, Final Batch Loss: 0.1510709673166275\n",
      "Epoch 635, Loss: 0.2048838809132576, Final Batch Loss: 0.10707802325487137\n",
      "Epoch 636, Loss: 0.24565750360488892, Final Batch Loss: 0.13247281312942505\n",
      "Epoch 637, Loss: 0.23400834202766418, Final Batch Loss: 0.11271969974040985\n",
      "Epoch 638, Loss: 0.26398391276597977, Final Batch Loss: 0.14433592557907104\n",
      "Epoch 639, Loss: 0.19431844726204872, Final Batch Loss: 0.061374325305223465\n",
      "Epoch 640, Loss: 0.25950662791728973, Final Batch Loss: 0.13393740355968475\n",
      "Epoch 641, Loss: 0.21408122032880783, Final Batch Loss: 0.10592886805534363\n",
      "Epoch 642, Loss: 0.1975822150707245, Final Batch Loss: 0.06014907360076904\n",
      "Epoch 643, Loss: 0.16800810396671295, Final Batch Loss: 0.06451115757226944\n",
      "Epoch 644, Loss: 0.21586906909942627, Final Batch Loss: 0.13008244335651398\n",
      "Epoch 645, Loss: 0.2494785189628601, Final Batch Loss: 0.12231238186359406\n",
      "Epoch 646, Loss: 0.3210042640566826, Final Batch Loss: 0.2588176131248474\n",
      "Epoch 647, Loss: 0.2126457616686821, Final Batch Loss: 0.11111999303102493\n",
      "Epoch 648, Loss: 0.20684412866830826, Final Batch Loss: 0.09139139950275421\n",
      "Epoch 649, Loss: 0.2415282279253006, Final Batch Loss: 0.14764243364334106\n",
      "Epoch 650, Loss: 0.18161192536354065, Final Batch Loss: 0.0623730793595314\n",
      "Epoch 651, Loss: 0.20932327210903168, Final Batch Loss: 0.0945809930562973\n",
      "Epoch 652, Loss: 0.22021406143903732, Final Batch Loss: 0.11134281009435654\n",
      "Epoch 653, Loss: 0.23954316228628159, Final Batch Loss: 0.11338716000318527\n",
      "Epoch 654, Loss: 0.24719182401895523, Final Batch Loss: 0.0987645760178566\n",
      "Epoch 655, Loss: 0.1635228395462036, Final Batch Loss: 0.05282718688249588\n",
      "Epoch 656, Loss: 0.29243920743465424, Final Batch Loss: 0.1411958485841751\n",
      "Epoch 657, Loss: 0.18819211423397064, Final Batch Loss: 0.06697851419448853\n",
      "Epoch 658, Loss: 0.23930129408836365, Final Batch Loss: 0.13918112218379974\n",
      "Epoch 659, Loss: 0.18965238332748413, Final Batch Loss: 0.0858965590596199\n",
      "Epoch 660, Loss: 0.19306306540966034, Final Batch Loss: 0.09019934386014938\n",
      "Epoch 661, Loss: 0.26328298449516296, Final Batch Loss: 0.14061753451824188\n",
      "Epoch 662, Loss: 0.2325097918510437, Final Batch Loss: 0.09917820990085602\n",
      "Epoch 663, Loss: 0.2715395838022232, Final Batch Loss: 0.15895773470401764\n",
      "Epoch 664, Loss: 0.24541442096233368, Final Batch Loss: 0.12609697878360748\n",
      "Epoch 665, Loss: 0.24655484408140182, Final Batch Loss: 0.12277732044458389\n",
      "Epoch 666, Loss: 0.22680246829986572, Final Batch Loss: 0.0699286162853241\n",
      "Epoch 667, Loss: 0.20905701816082, Final Batch Loss: 0.0959886834025383\n",
      "Epoch 668, Loss: 0.2718435078859329, Final Batch Loss: 0.11958861351013184\n",
      "Epoch 669, Loss: 0.18472211062908173, Final Batch Loss: 0.09767605364322662\n",
      "Epoch 670, Loss: 0.2253694087266922, Final Batch Loss: 0.1378559023141861\n",
      "Epoch 671, Loss: 0.20756371319293976, Final Batch Loss: 0.0896221250295639\n",
      "Epoch 672, Loss: 0.2154761105775833, Final Batch Loss: 0.11190753430128098\n",
      "Epoch 673, Loss: 0.2520953416824341, Final Batch Loss: 0.1477702111005783\n",
      "Epoch 674, Loss: 0.2724831774830818, Final Batch Loss: 0.16528218984603882\n",
      "Epoch 675, Loss: 0.2283235490322113, Final Batch Loss: 0.1458316594362259\n",
      "Epoch 676, Loss: 0.2282238006591797, Final Batch Loss: 0.14220809936523438\n",
      "Epoch 677, Loss: 0.20435205847024918, Final Batch Loss: 0.08609839528799057\n",
      "Epoch 678, Loss: 0.1898564025759697, Final Batch Loss: 0.07176101207733154\n",
      "Epoch 679, Loss: 0.2379710078239441, Final Batch Loss: 0.13258305191993713\n",
      "Epoch 680, Loss: 0.1869879513978958, Final Batch Loss: 0.11331459879875183\n",
      "Epoch 681, Loss: 0.24565159529447556, Final Batch Loss: 0.11598502844572067\n",
      "Epoch 682, Loss: 0.25815771520137787, Final Batch Loss: 0.1376875787973404\n",
      "Epoch 683, Loss: 0.1893119513988495, Final Batch Loss: 0.10596535354852676\n",
      "Epoch 684, Loss: 0.2339697852730751, Final Batch Loss: 0.1417754888534546\n",
      "Epoch 685, Loss: 0.15606904029846191, Final Batch Loss: 0.06333170086145401\n",
      "Epoch 686, Loss: 0.2840702012181282, Final Batch Loss: 0.20463910698890686\n",
      "Epoch 687, Loss: 0.16465478390455246, Final Batch Loss: 0.06665623188018799\n",
      "Epoch 688, Loss: 0.2273426353931427, Final Batch Loss: 0.11834405362606049\n",
      "Epoch 689, Loss: 0.27464835345745087, Final Batch Loss: 0.12240761518478394\n",
      "Epoch 690, Loss: 0.21180332452058792, Final Batch Loss: 0.07998289912939072\n",
      "Epoch 691, Loss: 0.21697724610567093, Final Batch Loss: 0.0852620080113411\n",
      "Epoch 692, Loss: 0.17208388447761536, Final Batch Loss: 0.08097173273563385\n",
      "Epoch 693, Loss: 0.21913637965917587, Final Batch Loss: 0.09128215163946152\n",
      "Epoch 694, Loss: 0.24890531599521637, Final Batch Loss: 0.14228154718875885\n",
      "Epoch 695, Loss: 0.267709881067276, Final Batch Loss: 0.13049843907356262\n",
      "Epoch 696, Loss: 0.21013257652521133, Final Batch Loss: 0.1282511055469513\n",
      "Epoch 697, Loss: 0.23634646832942963, Final Batch Loss: 0.1345033496618271\n",
      "Epoch 698, Loss: 0.19627713412046432, Final Batch Loss: 0.09355037659406662\n",
      "Epoch 699, Loss: 0.17443521320819855, Final Batch Loss: 0.10462435334920883\n",
      "Epoch 700, Loss: 0.2149578407406807, Final Batch Loss: 0.06840480118989944\n",
      "Epoch 701, Loss: 0.18571265041828156, Final Batch Loss: 0.07354394346475601\n",
      "Epoch 702, Loss: 0.18757881224155426, Final Batch Loss: 0.0859379693865776\n",
      "Epoch 703, Loss: 0.1905955821275711, Final Batch Loss: 0.11192469298839569\n",
      "Epoch 704, Loss: 0.15964888781309128, Final Batch Loss: 0.08197639882564545\n",
      "Epoch 705, Loss: 0.18499011546373367, Final Batch Loss: 0.09986484050750732\n",
      "Epoch 706, Loss: 0.20582564175128937, Final Batch Loss: 0.08969555795192719\n",
      "Epoch 707, Loss: 0.17740941047668457, Final Batch Loss: 0.07114528119564056\n",
      "Epoch 708, Loss: 0.19028735160827637, Final Batch Loss: 0.10751562565565109\n",
      "Epoch 709, Loss: 0.22896767407655716, Final Batch Loss: 0.13761891424655914\n",
      "Epoch 710, Loss: 0.20319946855306625, Final Batch Loss: 0.0702083632349968\n",
      "Epoch 711, Loss: 0.17558583617210388, Final Batch Loss: 0.08727845549583435\n",
      "Epoch 712, Loss: 0.17509081214666367, Final Batch Loss: 0.09718569368124008\n",
      "Epoch 713, Loss: 0.1837075799703598, Final Batch Loss: 0.10495872795581818\n",
      "Epoch 714, Loss: 0.19265170395374298, Final Batch Loss: 0.12110977619886398\n",
      "Epoch 715, Loss: 0.2244037687778473, Final Batch Loss: 0.1524675488471985\n",
      "Epoch 716, Loss: 0.18675611913204193, Final Batch Loss: 0.07934439182281494\n",
      "Epoch 717, Loss: 0.23624475300312042, Final Batch Loss: 0.13708369433879852\n",
      "Epoch 718, Loss: 0.21164030581712723, Final Batch Loss: 0.09681568294763565\n",
      "Epoch 719, Loss: 0.1926349699497223, Final Batch Loss: 0.07824589312076569\n",
      "Epoch 720, Loss: 0.19357070326805115, Final Batch Loss: 0.09909798204898834\n",
      "Epoch 721, Loss: 0.16930697113275528, Final Batch Loss: 0.07199478894472122\n",
      "Epoch 722, Loss: 0.2039722576737404, Final Batch Loss: 0.07511498779058456\n",
      "Epoch 723, Loss: 0.1705891117453575, Final Batch Loss: 0.072785384953022\n",
      "Epoch 724, Loss: 0.19754812493920326, Final Batch Loss: 0.054113585501909256\n",
      "Epoch 725, Loss: 0.2259586974978447, Final Batch Loss: 0.08804628998041153\n",
      "Epoch 726, Loss: 0.14838294312357903, Final Batch Loss: 0.05906428024172783\n",
      "Epoch 727, Loss: 0.19495391100645065, Final Batch Loss: 0.046330563724040985\n",
      "Epoch 728, Loss: 0.18907895684242249, Final Batch Loss: 0.07183308899402618\n",
      "Epoch 729, Loss: 0.15733838081359863, Final Batch Loss: 0.08726833015680313\n",
      "Epoch 730, Loss: 0.1922471523284912, Final Batch Loss: 0.11309558153152466\n",
      "Epoch 731, Loss: 0.1858922466635704, Final Batch Loss: 0.10623350739479065\n",
      "Epoch 732, Loss: 0.22189722955226898, Final Batch Loss: 0.14505551755428314\n",
      "Epoch 733, Loss: 0.18434110283851624, Final Batch Loss: 0.076609767973423\n",
      "Epoch 734, Loss: 0.13578250631690025, Final Batch Loss: 0.051144275814294815\n",
      "Epoch 735, Loss: 0.1846529170870781, Final Batch Loss: 0.09924457967281342\n",
      "Epoch 736, Loss: 0.19565191864967346, Final Batch Loss: 0.1109922006726265\n",
      "Epoch 737, Loss: 0.18528002500534058, Final Batch Loss: 0.0794612243771553\n",
      "Epoch 738, Loss: 0.20018810778856277, Final Batch Loss: 0.09476368874311447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 739, Loss: 0.11609809100627899, Final Batch Loss: 0.046586208045482635\n",
      "Epoch 740, Loss: 0.177471362054348, Final Batch Loss: 0.09771961718797684\n",
      "Epoch 741, Loss: 0.17367294430732727, Final Batch Loss: 0.09784306585788727\n",
      "Epoch 742, Loss: 0.1604866310954094, Final Batch Loss: 0.05479249358177185\n",
      "Epoch 743, Loss: 0.15100551396608353, Final Batch Loss: 0.05828399211168289\n",
      "Epoch 744, Loss: 0.18897947669029236, Final Batch Loss: 0.11074500530958176\n",
      "Epoch 745, Loss: 0.2415316328406334, Final Batch Loss: 0.10321488231420517\n",
      "Epoch 746, Loss: 0.21042978763580322, Final Batch Loss: 0.07896685600280762\n",
      "Epoch 747, Loss: 0.17886803299188614, Final Batch Loss: 0.10112296789884567\n",
      "Epoch 748, Loss: 0.22977671027183533, Final Batch Loss: 0.08950570225715637\n",
      "Epoch 749, Loss: 0.19898588955402374, Final Batch Loss: 0.0979665145277977\n",
      "Epoch 750, Loss: 0.18794366717338562, Final Batch Loss: 0.06374386698007584\n",
      "Epoch 751, Loss: 0.29391591250896454, Final Batch Loss: 0.15211454033851624\n",
      "Epoch 752, Loss: 0.2938128039240837, Final Batch Loss: 0.17650756239891052\n",
      "Epoch 753, Loss: 0.21886832267045975, Final Batch Loss: 0.12263699620962143\n",
      "Epoch 754, Loss: 0.22516848891973495, Final Batch Loss: 0.1501513421535492\n",
      "Epoch 755, Loss: 0.2675049602985382, Final Batch Loss: 0.1309811919927597\n",
      "Epoch 756, Loss: 0.17972585558891296, Final Batch Loss: 0.10950718075037003\n",
      "Epoch 757, Loss: 0.15303775668144226, Final Batch Loss: 0.049694158136844635\n",
      "Epoch 758, Loss: 0.19800137728452682, Final Batch Loss: 0.10445985198020935\n",
      "Epoch 759, Loss: 0.25816621631383896, Final Batch Loss: 0.09299366921186447\n",
      "Epoch 760, Loss: 0.1623232513666153, Final Batch Loss: 0.0884447917342186\n",
      "Epoch 761, Loss: 0.2125770002603531, Final Batch Loss: 0.11391791701316833\n",
      "Epoch 762, Loss: 0.14680331572890282, Final Batch Loss: 0.05648950859904289\n",
      "Epoch 763, Loss: 0.17596247792243958, Final Batch Loss: 0.08828918635845184\n",
      "Epoch 764, Loss: 0.1758064106106758, Final Batch Loss: 0.06405537575483322\n",
      "Epoch 765, Loss: 0.13927994668483734, Final Batch Loss: 0.07630693912506104\n",
      "Epoch 766, Loss: 0.14983674883842468, Final Batch Loss: 0.0819326862692833\n",
      "Epoch 767, Loss: 0.14274171739816666, Final Batch Loss: 0.046640440821647644\n",
      "Epoch 768, Loss: 0.1177433468401432, Final Batch Loss: 0.041524242609739304\n",
      "Epoch 769, Loss: 0.1872425451874733, Final Batch Loss: 0.08861874043941498\n",
      "Epoch 770, Loss: 0.16097593307495117, Final Batch Loss: 0.07993801683187485\n",
      "Epoch 771, Loss: 0.1663970723748207, Final Batch Loss: 0.08976460248231888\n",
      "Epoch 772, Loss: 0.15709850937128067, Final Batch Loss: 0.07857188582420349\n",
      "Epoch 773, Loss: 0.13174587488174438, Final Batch Loss: 0.03586210310459137\n",
      "Epoch 774, Loss: 0.1309932954609394, Final Batch Loss: 0.037742625921964645\n",
      "Epoch 775, Loss: 0.1704765260219574, Final Batch Loss: 0.04989641159772873\n",
      "Epoch 776, Loss: 0.11371156573295593, Final Batch Loss: 0.036046192049980164\n",
      "Epoch 777, Loss: 0.23061372339725494, Final Batch Loss: 0.15913991630077362\n",
      "Epoch 778, Loss: 0.15929820388555527, Final Batch Loss: 0.08205853402614594\n",
      "Epoch 779, Loss: 0.21204248070716858, Final Batch Loss: 0.12099512666463852\n",
      "Epoch 780, Loss: 0.13837572187185287, Final Batch Loss: 0.03978683054447174\n",
      "Epoch 781, Loss: 0.1635618582367897, Final Batch Loss: 0.08742626756429672\n",
      "Epoch 782, Loss: 0.18242856860160828, Final Batch Loss: 0.11681731790304184\n",
      "Epoch 783, Loss: 0.18909721076488495, Final Batch Loss: 0.10922761261463165\n",
      "Epoch 784, Loss: 0.17110545933246613, Final Batch Loss: 0.09717704355716705\n",
      "Epoch 785, Loss: 0.1903870776295662, Final Batch Loss: 0.13655756413936615\n",
      "Epoch 786, Loss: 0.13380302116274834, Final Batch Loss: 0.04637378081679344\n",
      "Epoch 787, Loss: 0.17749371379613876, Final Batch Loss: 0.10447410494089127\n",
      "Epoch 788, Loss: 0.17001356929540634, Final Batch Loss: 0.10228203982114792\n",
      "Epoch 789, Loss: 0.20942912250757217, Final Batch Loss: 0.10020666569471359\n",
      "Epoch 790, Loss: 0.22029129415750504, Final Batch Loss: 0.08739510923624039\n",
      "Epoch 791, Loss: 0.14482473582029343, Final Batch Loss: 0.08469435572624207\n",
      "Epoch 792, Loss: 0.13949350267648697, Final Batch Loss: 0.09165675193071365\n",
      "Epoch 793, Loss: 0.1636771261692047, Final Batch Loss: 0.08655071258544922\n",
      "Epoch 794, Loss: 0.18744806200265884, Final Batch Loss: 0.11136173456907272\n",
      "Epoch 795, Loss: 0.20308878272771835, Final Batch Loss: 0.11325804889202118\n",
      "Epoch 796, Loss: 0.176809623837471, Final Batch Loss: 0.08989487588405609\n",
      "Epoch 797, Loss: 0.1459432989358902, Final Batch Loss: 0.07653456181287766\n",
      "Epoch 798, Loss: 0.21273130178451538, Final Batch Loss: 0.1257823258638382\n",
      "Epoch 799, Loss: 0.12554878741502762, Final Batch Loss: 0.02458234131336212\n",
      "Epoch 800, Loss: 0.1626281589269638, Final Batch Loss: 0.07556276768445969\n",
      "Epoch 801, Loss: 0.15445000678300858, Final Batch Loss: 0.07777680456638336\n",
      "Epoch 802, Loss: 0.15792682021856308, Final Batch Loss: 0.07088757306337357\n",
      "Epoch 803, Loss: 0.1355818435549736, Final Batch Loss: 0.06066405028104782\n",
      "Epoch 804, Loss: 0.18708065897226334, Final Batch Loss: 0.0726388543844223\n",
      "Epoch 805, Loss: 0.18570894747972488, Final Batch Loss: 0.09561123698949814\n",
      "Epoch 806, Loss: 0.16820690780878067, Final Batch Loss: 0.0604449063539505\n",
      "Epoch 807, Loss: 0.20306702703237534, Final Batch Loss: 0.10119900107383728\n",
      "Epoch 808, Loss: 0.18167846649885178, Final Batch Loss: 0.10997062921524048\n",
      "Epoch 809, Loss: 0.20078468322753906, Final Batch Loss: 0.0971132218837738\n",
      "Epoch 810, Loss: 0.13402491435408592, Final Batch Loss: 0.07418470829725266\n",
      "Epoch 811, Loss: 0.12770172208547592, Final Batch Loss: 0.06234470754861832\n",
      "Epoch 812, Loss: 0.18430857360363007, Final Batch Loss: 0.0882372334599495\n",
      "Epoch 813, Loss: 0.1473577655851841, Final Batch Loss: 0.05916599556803703\n",
      "Epoch 814, Loss: 0.14277169853448868, Final Batch Loss: 0.06533823907375336\n",
      "Epoch 815, Loss: 0.13710106909275055, Final Batch Loss: 0.053830504417419434\n",
      "Epoch 816, Loss: 0.13035206124186516, Final Batch Loss: 0.04142818972468376\n",
      "Epoch 817, Loss: 0.16321471333503723, Final Batch Loss: 0.08978474885225296\n",
      "Epoch 818, Loss: 0.16185837239027023, Final Batch Loss: 0.06437787413597107\n",
      "Epoch 819, Loss: 0.1312342993915081, Final Batch Loss: 0.07299789041280746\n",
      "Epoch 820, Loss: 0.13609163835644722, Final Batch Loss: 0.07384524494409561\n",
      "Epoch 821, Loss: 0.14490021765232086, Final Batch Loss: 0.07225216180086136\n",
      "Epoch 822, Loss: 0.11166948080062866, Final Batch Loss: 0.03366990387439728\n",
      "Epoch 823, Loss: 0.1666087508201599, Final Batch Loss: 0.05910683423280716\n",
      "Epoch 824, Loss: 0.1461995430290699, Final Batch Loss: 0.061225298792123795\n",
      "Epoch 825, Loss: 0.1714601218700409, Final Batch Loss: 0.10040625184774399\n",
      "Epoch 826, Loss: 0.13478251546621323, Final Batch Loss: 0.06151845306158066\n",
      "Epoch 827, Loss: 0.1463441513478756, Final Batch Loss: 0.09777939319610596\n",
      "Epoch 828, Loss: 0.1394328474998474, Final Batch Loss: 0.06587731838226318\n",
      "Epoch 829, Loss: 0.1796552874147892, Final Batch Loss: 0.13157808780670166\n",
      "Epoch 830, Loss: 0.14306603372097015, Final Batch Loss: 0.07474812120199203\n",
      "Epoch 831, Loss: 0.1474694237112999, Final Batch Loss: 0.07018455117940903\n",
      "Epoch 832, Loss: 0.13713885843753815, Final Batch Loss: 0.06424181908369064\n",
      "Epoch 833, Loss: 0.12538899667561054, Final Batch Loss: 0.028187835589051247\n",
      "Epoch 834, Loss: 0.16277536377310753, Final Batch Loss: 0.05959205701947212\n",
      "Epoch 835, Loss: 0.16005699709057808, Final Batch Loss: 0.10491739958524704\n",
      "Epoch 836, Loss: 0.12788139283657074, Final Batch Loss: 0.05775729566812515\n",
      "Epoch 837, Loss: 0.13824710622429848, Final Batch Loss: 0.058401282876729965\n",
      "Epoch 838, Loss: 0.151713028550148, Final Batch Loss: 0.0626823678612709\n",
      "Epoch 839, Loss: 0.1986141875386238, Final Batch Loss: 0.10848529636859894\n",
      "Epoch 840, Loss: 0.15786857157945633, Final Batch Loss: 0.03208359330892563\n",
      "Epoch 841, Loss: 0.11602816358208656, Final Batch Loss: 0.045845139771699905\n",
      "Epoch 842, Loss: 0.12683068215847015, Final Batch Loss: 0.05784178525209427\n",
      "Epoch 843, Loss: 0.200314961373806, Final Batch Loss: 0.16696813702583313\n",
      "Epoch 844, Loss: 0.13663386553525925, Final Batch Loss: 0.07268618047237396\n",
      "Epoch 845, Loss: 0.14045032113790512, Final Batch Loss: 0.07152419537305832\n",
      "Epoch 846, Loss: 0.1376013159751892, Final Batch Loss: 0.06105196475982666\n",
      "Epoch 847, Loss: 0.14963147789239883, Final Batch Loss: 0.08336463570594788\n",
      "Epoch 848, Loss: 0.11909024603664875, Final Batch Loss: 0.028138751164078712\n",
      "Epoch 849, Loss: 0.13360564410686493, Final Batch Loss: 0.04788164794445038\n",
      "Epoch 850, Loss: 0.12533586844801903, Final Batch Loss: 0.04985466226935387\n",
      "Epoch 851, Loss: 0.16248828545212746, Final Batch Loss: 0.115641288459301\n",
      "Epoch 852, Loss: 0.14855503290891647, Final Batch Loss: 0.07501348108053207\n",
      "Epoch 853, Loss: 0.13273733481764793, Final Batch Loss: 0.09393744170665741\n",
      "Epoch 854, Loss: 0.1945485770702362, Final Batch Loss: 0.07892705500125885\n",
      "Epoch 855, Loss: 0.09810623712837696, Final Batch Loss: 0.027252184227108955\n",
      "Epoch 856, Loss: 0.14091651141643524, Final Batch Loss: 0.06653432548046112\n",
      "Epoch 857, Loss: 0.17101329565048218, Final Batch Loss: 0.06574759632349014\n",
      "Epoch 858, Loss: 0.11608826741576195, Final Batch Loss: 0.05053390935063362\n",
      "Epoch 859, Loss: 0.10345643758773804, Final Batch Loss: 0.03282104432582855\n",
      "Epoch 860, Loss: 0.15907692909240723, Final Batch Loss: 0.08438870310783386\n",
      "Epoch 861, Loss: 0.1461797170341015, Final Batch Loss: 0.052702177315950394\n",
      "Epoch 862, Loss: 0.1756383255124092, Final Batch Loss: 0.12107858061790466\n",
      "Epoch 863, Loss: 0.15734514221549034, Final Batch Loss: 0.09582198411226273\n",
      "Epoch 864, Loss: 0.1609230935573578, Final Batch Loss: 0.09279080480337143\n",
      "Epoch 865, Loss: 0.0879464391618967, Final Batch Loss: 0.023718396201729774\n",
      "Epoch 866, Loss: 0.135615773499012, Final Batch Loss: 0.06400131434202194\n",
      "Epoch 867, Loss: 0.1596945896744728, Final Batch Loss: 0.06479689478874207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 868, Loss: 0.14199109375476837, Final Batch Loss: 0.07596904039382935\n",
      "Epoch 869, Loss: 0.12083731964230537, Final Batch Loss: 0.06275708228349686\n",
      "Epoch 870, Loss: 0.11709782108664513, Final Batch Loss: 0.043133895844221115\n",
      "Epoch 871, Loss: 0.13046424463391304, Final Batch Loss: 0.07356608659029007\n",
      "Epoch 872, Loss: 0.13681475818157196, Final Batch Loss: 0.050956547260284424\n",
      "Epoch 873, Loss: 0.149415772408247, Final Batch Loss: 0.046771395951509476\n",
      "Epoch 874, Loss: 0.13721860945224762, Final Batch Loss: 0.06611859798431396\n",
      "Epoch 875, Loss: 0.10876278020441532, Final Batch Loss: 0.02926957793533802\n",
      "Epoch 876, Loss: 0.10621137171983719, Final Batch Loss: 0.04301023483276367\n",
      "Epoch 877, Loss: 0.11762482300400734, Final Batch Loss: 0.05679696425795555\n",
      "Epoch 878, Loss: 0.13279272988438606, Final Batch Loss: 0.05757833644747734\n",
      "Epoch 879, Loss: 0.13892942294478416, Final Batch Loss: 0.08201083540916443\n",
      "Epoch 880, Loss: 0.18326108157634735, Final Batch Loss: 0.11180039495229721\n",
      "Epoch 881, Loss: 0.1668606773018837, Final Batch Loss: 0.10378173738718033\n",
      "Epoch 882, Loss: 0.13573162257671356, Final Batch Loss: 0.06493376940488815\n",
      "Epoch 883, Loss: 0.18355852365493774, Final Batch Loss: 0.052200332283973694\n",
      "Epoch 884, Loss: 0.15959246084094048, Final Batch Loss: 0.09838845580816269\n",
      "Epoch 885, Loss: 0.12103382498025894, Final Batch Loss: 0.06911613047122955\n",
      "Epoch 886, Loss: 0.12568724527955055, Final Batch Loss: 0.07208900898694992\n",
      "Epoch 887, Loss: 0.14004264771938324, Final Batch Loss: 0.08126719295978546\n",
      "Epoch 888, Loss: 0.13979361206293106, Final Batch Loss: 0.06580022722482681\n",
      "Epoch 889, Loss: 0.2184709683060646, Final Batch Loss: 0.11246021091938019\n",
      "Epoch 890, Loss: 0.0999574325978756, Final Batch Loss: 0.052098553627729416\n",
      "Epoch 891, Loss: 0.1086292564868927, Final Batch Loss: 0.041814133524894714\n",
      "Epoch 892, Loss: 0.08776186779141426, Final Batch Loss: 0.04932035133242607\n",
      "Epoch 893, Loss: 0.11287687346339226, Final Batch Loss: 0.035068120807409286\n",
      "Epoch 894, Loss: 0.16157425194978714, Final Batch Loss: 0.0945945456624031\n",
      "Epoch 895, Loss: 0.11013809312134981, Final Batch Loss: 0.01236369926482439\n",
      "Epoch 896, Loss: 0.185484167188406, Final Batch Loss: 0.036381419748067856\n",
      "Epoch 897, Loss: 0.20160016417503357, Final Batch Loss: 0.0826599970459938\n",
      "Epoch 898, Loss: 0.18669044971466064, Final Batch Loss: 0.11842821538448334\n",
      "Epoch 899, Loss: 0.13653763756155968, Final Batch Loss: 0.09666916728019714\n",
      "Epoch 900, Loss: 0.12640045583248138, Final Batch Loss: 0.06425508111715317\n",
      "Epoch 901, Loss: 0.12870534136891365, Final Batch Loss: 0.05271412059664726\n",
      "Epoch 902, Loss: 0.20786921679973602, Final Batch Loss: 0.10088858753442764\n",
      "Epoch 903, Loss: 0.12565140426158905, Final Batch Loss: 0.051500916481018066\n",
      "Epoch 904, Loss: 0.20989610254764557, Final Batch Loss: 0.11673134565353394\n",
      "Epoch 905, Loss: 0.12691839039325714, Final Batch Loss: 0.051149845123291016\n",
      "Epoch 906, Loss: 0.11459452286362648, Final Batch Loss: 0.06855268776416779\n",
      "Epoch 907, Loss: 0.1892818883061409, Final Batch Loss: 0.10122880339622498\n",
      "Epoch 908, Loss: 0.13081584125757217, Final Batch Loss: 0.0752243772149086\n",
      "Epoch 909, Loss: 0.12689484283328056, Final Batch Loss: 0.056514885276556015\n",
      "Epoch 910, Loss: 0.17566058039665222, Final Batch Loss: 0.0989060178399086\n",
      "Epoch 911, Loss: 0.11025639995932579, Final Batch Loss: 0.0634121373295784\n",
      "Epoch 912, Loss: 0.14021051675081253, Final Batch Loss: 0.06406578421592712\n",
      "Epoch 913, Loss: 0.1303335800766945, Final Batch Loss: 0.044431157410144806\n",
      "Epoch 914, Loss: 0.1577540971338749, Final Batch Loss: 0.058085668832063675\n",
      "Epoch 915, Loss: 0.20093751698732376, Final Batch Loss: 0.14818459749221802\n",
      "Epoch 916, Loss: 0.14098845422267914, Final Batch Loss: 0.04033171385526657\n",
      "Epoch 917, Loss: 0.10182573273777962, Final Batch Loss: 0.062445227056741714\n",
      "Epoch 918, Loss: 0.15685929358005524, Final Batch Loss: 0.07058216631412506\n",
      "Epoch 919, Loss: 0.10919199883937836, Final Batch Loss: 0.04059615731239319\n",
      "Epoch 920, Loss: 0.14568698406219482, Final Batch Loss: 0.06819147616624832\n",
      "Epoch 921, Loss: 0.13849500566720963, Final Batch Loss: 0.06557516753673553\n",
      "Epoch 922, Loss: 0.19712896645069122, Final Batch Loss: 0.1294739991426468\n",
      "Epoch 923, Loss: 0.12656350061297417, Final Batch Loss: 0.03510637208819389\n",
      "Epoch 924, Loss: 0.1889609470963478, Final Batch Loss: 0.11374061554670334\n",
      "Epoch 925, Loss: 0.1494826190173626, Final Batch Loss: 0.029231678694486618\n",
      "Epoch 926, Loss: 0.1016390509903431, Final Batch Loss: 0.03780324384570122\n",
      "Epoch 927, Loss: 0.09425878524780273, Final Batch Loss: 0.042242471128702164\n",
      "Epoch 928, Loss: 0.15902550891041756, Final Batch Loss: 0.10389245301485062\n",
      "Epoch 929, Loss: 0.17111162096261978, Final Batch Loss: 0.11213989555835724\n",
      "Epoch 930, Loss: 0.12103426828980446, Final Batch Loss: 0.05818769708275795\n",
      "Epoch 931, Loss: 0.21330929547548294, Final Batch Loss: 0.15553347766399384\n",
      "Epoch 932, Loss: 0.1374744400382042, Final Batch Loss: 0.07344023883342743\n",
      "Epoch 933, Loss: 0.18090425431728363, Final Batch Loss: 0.12393688410520554\n",
      "Epoch 934, Loss: 0.14533085376024246, Final Batch Loss: 0.06868606805801392\n",
      "Epoch 935, Loss: 0.12353420630097389, Final Batch Loss: 0.06088532879948616\n",
      "Epoch 936, Loss: 0.1135152243077755, Final Batch Loss: 0.06817886978387833\n",
      "Epoch 937, Loss: 0.1425030156970024, Final Batch Loss: 0.06276754289865494\n",
      "Epoch 938, Loss: 0.1326414756476879, Final Batch Loss: 0.046398092061281204\n",
      "Epoch 939, Loss: 0.13245121017098427, Final Batch Loss: 0.07440254837274551\n",
      "Epoch 940, Loss: 0.15473392233252525, Final Batch Loss: 0.11114955693483353\n",
      "Epoch 941, Loss: 0.13491396233439445, Final Batch Loss: 0.0414268858730793\n",
      "Epoch 942, Loss: 0.15578896552324295, Final Batch Loss: 0.07344581931829453\n",
      "Epoch 943, Loss: 0.11905048042535782, Final Batch Loss: 0.054465897381305695\n",
      "Epoch 944, Loss: 0.15641837567090988, Final Batch Loss: 0.08426923304796219\n",
      "Epoch 945, Loss: 0.11286298930644989, Final Batch Loss: 0.06435583531856537\n",
      "Epoch 946, Loss: 0.08844037726521492, Final Batch Loss: 0.043379440903663635\n",
      "Epoch 947, Loss: 0.0932486392557621, Final Batch Loss: 0.053904611617326736\n",
      "Epoch 948, Loss: 0.1300615631043911, Final Batch Loss: 0.052681852132081985\n",
      "Epoch 949, Loss: 0.10688701644539833, Final Batch Loss: 0.036314260214567184\n",
      "Epoch 950, Loss: 0.1435285247862339, Final Batch Loss: 0.09058821946382523\n",
      "Epoch 951, Loss: 0.18081852048635483, Final Batch Loss: 0.12230774760246277\n",
      "Epoch 952, Loss: 0.1528066024184227, Final Batch Loss: 0.07339772582054138\n",
      "Epoch 953, Loss: 0.08744143322110176, Final Batch Loss: 0.03850022703409195\n",
      "Epoch 954, Loss: 0.2026735320687294, Final Batch Loss: 0.12547573447227478\n",
      "Epoch 955, Loss: 0.12007348611950874, Final Batch Loss: 0.06874742358922958\n",
      "Epoch 956, Loss: 0.09360851719975471, Final Batch Loss: 0.0363217294216156\n",
      "Epoch 957, Loss: 0.10822011902928352, Final Batch Loss: 0.06998112052679062\n",
      "Epoch 958, Loss: 0.12009713798761368, Final Batch Loss: 0.0769537165760994\n",
      "Epoch 959, Loss: 0.18188278377056122, Final Batch Loss: 0.10919443517923355\n",
      "Epoch 960, Loss: 0.14291970804333687, Final Batch Loss: 0.10386031866073608\n",
      "Epoch 961, Loss: 0.1448482647538185, Final Batch Loss: 0.07660879194736481\n",
      "Epoch 962, Loss: 0.10044171288609505, Final Batch Loss: 0.03127587214112282\n",
      "Epoch 963, Loss: 0.14271117374300957, Final Batch Loss: 0.09058137238025665\n",
      "Epoch 964, Loss: 0.1453450508415699, Final Batch Loss: 0.061403047293424606\n",
      "Epoch 965, Loss: 0.13010021299123764, Final Batch Loss: 0.0551535040140152\n",
      "Epoch 966, Loss: 0.13954061642289162, Final Batch Loss: 0.03197783604264259\n",
      "Epoch 967, Loss: 0.18154054880142212, Final Batch Loss: 0.14141756296157837\n",
      "Epoch 968, Loss: 0.09022495150566101, Final Batch Loss: 0.029691621661186218\n",
      "Epoch 969, Loss: 0.1556306667625904, Final Batch Loss: 0.11791690438985825\n",
      "Epoch 970, Loss: 0.18593375757336617, Final Batch Loss: 0.13504192233085632\n",
      "Epoch 971, Loss: 0.17120134085416794, Final Batch Loss: 0.1160656064748764\n",
      "Epoch 972, Loss: 0.09482959657907486, Final Batch Loss: 0.051870524883270264\n",
      "Epoch 973, Loss: 0.18728884309530258, Final Batch Loss: 0.10068405419588089\n",
      "Epoch 974, Loss: 0.14176922291517258, Final Batch Loss: 0.06020289659500122\n",
      "Epoch 975, Loss: 0.13218222558498383, Final Batch Loss: 0.07254652678966522\n",
      "Epoch 976, Loss: 0.0960131399333477, Final Batch Loss: 0.03207264468073845\n",
      "Epoch 977, Loss: 0.11071637645363808, Final Batch Loss: 0.06445709615945816\n",
      "Epoch 978, Loss: 0.10687793605029583, Final Batch Loss: 0.025407394394278526\n",
      "Epoch 979, Loss: 0.10391024127602577, Final Batch Loss: 0.04492603614926338\n",
      "Epoch 980, Loss: 0.12639131397008896, Final Batch Loss: 0.06635084748268127\n",
      "Epoch 981, Loss: 0.0888864491134882, Final Batch Loss: 0.01877577044069767\n",
      "Epoch 982, Loss: 0.12412187457084656, Final Batch Loss: 0.06302656978368759\n",
      "Epoch 983, Loss: 0.0841054730117321, Final Batch Loss: 0.02333180233836174\n",
      "Epoch 984, Loss: 0.09662254713475704, Final Batch Loss: 0.024525722488760948\n",
      "Epoch 985, Loss: 0.15751458331942558, Final Batch Loss: 0.11015046387910843\n",
      "Epoch 986, Loss: 0.14525459706783295, Final Batch Loss: 0.06930436193943024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 987, Loss: 0.0762393157929182, Final Batch Loss: 0.022170154377818108\n",
      "Epoch 988, Loss: 0.23277156800031662, Final Batch Loss: 0.13889966905117035\n",
      "Epoch 989, Loss: 0.13307160884141922, Final Batch Loss: 0.09024539589881897\n",
      "Epoch 990, Loss: 0.09533994644880295, Final Batch Loss: 0.03710738569498062\n",
      "Epoch 991, Loss: 0.10312200151383877, Final Batch Loss: 0.029356619343161583\n",
      "Epoch 992, Loss: 0.1574891284108162, Final Batch Loss: 0.06166120618581772\n",
      "Epoch 993, Loss: 0.12410340085625648, Final Batch Loss: 0.06779773533344269\n",
      "Epoch 994, Loss: 0.123899444937706, Final Batch Loss: 0.06375241279602051\n",
      "Epoch 995, Loss: 0.16724111884832382, Final Batch Loss: 0.13209564983844757\n",
      "Epoch 996, Loss: 0.14114994928240776, Final Batch Loss: 0.08929155766963959\n",
      "Epoch 997, Loss: 0.08843300119042397, Final Batch Loss: 0.041330743581056595\n",
      "Epoch 998, Loss: 0.08797802776098251, Final Batch Loss: 0.0433620885014534\n",
      "Epoch 999, Loss: 0.12374496832489967, Final Batch Loss: 0.05602702870965004\n",
      "Epoch 1000, Loss: 0.11581092327833176, Final Batch Loss: 0.07401096820831299\n",
      "Epoch 1001, Loss: 0.10768375545740128, Final Batch Loss: 0.038661181926727295\n",
      "Epoch 1002, Loss: 0.12804453447461128, Final Batch Loss: 0.07499005645513535\n",
      "Epoch 1003, Loss: 0.10245910659432411, Final Batch Loss: 0.055547118186950684\n",
      "Epoch 1004, Loss: 0.10008586943149567, Final Batch Loss: 0.06256584078073502\n",
      "Epoch 1005, Loss: 0.1386842280626297, Final Batch Loss: 0.058579325675964355\n",
      "Epoch 1006, Loss: 0.0952252596616745, Final Batch Loss: 0.046549562364816666\n",
      "Epoch 1007, Loss: 0.10052070766687393, Final Batch Loss: 0.050277162343263626\n",
      "Epoch 1008, Loss: 0.0741494633257389, Final Batch Loss: 0.0328783243894577\n",
      "Epoch 1009, Loss: 0.2241264060139656, Final Batch Loss: 0.15862075984477997\n",
      "Epoch 1010, Loss: 0.13253358751535416, Final Batch Loss: 0.06618817150592804\n",
      "Epoch 1011, Loss: 0.07984097301959991, Final Batch Loss: 0.03803766518831253\n",
      "Epoch 1012, Loss: 0.08518689498305321, Final Batch Loss: 0.03682716563344002\n",
      "Epoch 1013, Loss: 0.1401352360844612, Final Batch Loss: 0.04286651313304901\n",
      "Epoch 1014, Loss: 0.0922049731016159, Final Batch Loss: 0.04304245486855507\n",
      "Epoch 1015, Loss: 0.1300862692296505, Final Batch Loss: 0.039135415107011795\n",
      "Epoch 1016, Loss: 0.1883150041103363, Final Batch Loss: 0.11023896187543869\n",
      "Epoch 1017, Loss: 0.13655559718608856, Final Batch Loss: 0.03926381468772888\n",
      "Epoch 1018, Loss: 0.1661185622215271, Final Batch Loss: 0.07924827188253403\n",
      "Epoch 1019, Loss: 0.11025242879986763, Final Batch Loss: 0.048572346568107605\n",
      "Epoch 1020, Loss: 0.09809478372335434, Final Batch Loss: 0.019253402948379517\n",
      "Epoch 1021, Loss: 0.16671506315469742, Final Batch Loss: 0.12757165729999542\n",
      "Epoch 1022, Loss: 0.11501111276447773, Final Batch Loss: 0.01814034767448902\n",
      "Epoch 1023, Loss: 0.09638595953583717, Final Batch Loss: 0.04160967096686363\n",
      "Epoch 1024, Loss: 0.07794877514243126, Final Batch Loss: 0.019514750689268112\n",
      "Epoch 1025, Loss: 0.14998669549822807, Final Batch Loss: 0.049778398126363754\n",
      "Epoch 1026, Loss: 0.06493143178522587, Final Batch Loss: 0.026865994557738304\n",
      "Epoch 1027, Loss: 0.10460332781076431, Final Batch Loss: 0.05249889940023422\n",
      "Epoch 1028, Loss: 0.1235966868698597, Final Batch Loss: 0.05778459087014198\n",
      "Epoch 1029, Loss: 0.15655283629894257, Final Batch Loss: 0.0912497416138649\n",
      "Epoch 1030, Loss: 0.1367100030183792, Final Batch Loss: 0.10056756436824799\n",
      "Epoch 1031, Loss: 0.10406892374157906, Final Batch Loss: 0.05537615343928337\n",
      "Epoch 1032, Loss: 0.14182575419545174, Final Batch Loss: 0.10692654550075531\n",
      "Epoch 1033, Loss: 0.129359383136034, Final Batch Loss: 0.07037676870822906\n",
      "Epoch 1034, Loss: 0.19497960060834885, Final Batch Loss: 0.11654197424650192\n",
      "Epoch 1035, Loss: 0.2307996153831482, Final Batch Loss: 0.1538715660572052\n",
      "Epoch 1036, Loss: 0.11846880242228508, Final Batch Loss: 0.06244955211877823\n",
      "Epoch 1037, Loss: 0.17505233362317085, Final Batch Loss: 0.13586722314357758\n",
      "Epoch 1038, Loss: 0.10821386054158211, Final Batch Loss: 0.07535943388938904\n",
      "Epoch 1039, Loss: 0.09782847762107849, Final Batch Loss: 0.055993515998125076\n",
      "Epoch 1040, Loss: 0.1853427216410637, Final Batch Loss: 0.10061503201723099\n",
      "Epoch 1041, Loss: 0.16910433769226074, Final Batch Loss: 0.1062430813908577\n",
      "Epoch 1042, Loss: 0.17148716747760773, Final Batch Loss: 0.07453934848308563\n",
      "Epoch 1043, Loss: 0.145103819668293, Final Batch Loss: 0.03777927905321121\n",
      "Epoch 1044, Loss: 0.08786466903984547, Final Batch Loss: 0.02493109740316868\n",
      "Epoch 1045, Loss: 0.09647762030363083, Final Batch Loss: 0.03686412423849106\n",
      "Epoch 1046, Loss: 0.15372363105416298, Final Batch Loss: 0.04095384106040001\n",
      "Epoch 1047, Loss: 0.09726559370756149, Final Batch Loss: 0.06479780375957489\n",
      "Epoch 1048, Loss: 0.11623767018318176, Final Batch Loss: 0.050767309963703156\n",
      "Epoch 1049, Loss: 0.1108921468257904, Final Batch Loss: 0.04365800321102142\n",
      "Epoch 1050, Loss: 0.09424732998013496, Final Batch Loss: 0.05853404849767685\n",
      "Epoch 1051, Loss: 0.11029652878642082, Final Batch Loss: 0.05008764937520027\n",
      "Epoch 1052, Loss: 0.1080193892121315, Final Batch Loss: 0.06377238035202026\n",
      "Epoch 1053, Loss: 0.07064105942845345, Final Batch Loss: 0.030167821794748306\n",
      "Epoch 1054, Loss: 0.11310160905122757, Final Batch Loss: 0.047455981373786926\n",
      "Epoch 1055, Loss: 0.09321152791380882, Final Batch Loss: 0.033687006682157516\n",
      "Epoch 1056, Loss: 0.09728492796421051, Final Batch Loss: 0.05536548048257828\n",
      "Epoch 1057, Loss: 0.11309193819761276, Final Batch Loss: 0.03549410402774811\n",
      "Epoch 1058, Loss: 0.17150644212961197, Final Batch Loss: 0.08542130887508392\n",
      "Epoch 1059, Loss: 0.11274675093591213, Final Batch Loss: 0.027925221249461174\n",
      "Epoch 1060, Loss: 0.09320567548274994, Final Batch Loss: 0.0116090327501297\n",
      "Epoch 1061, Loss: 0.12674281373620033, Final Batch Loss: 0.08082972466945648\n",
      "Epoch 1062, Loss: 0.14246997982263565, Final Batch Loss: 0.10596737265586853\n",
      "Epoch 1063, Loss: 0.15161462873220444, Final Batch Loss: 0.07088687270879745\n",
      "Epoch 1064, Loss: 0.11613411083817482, Final Batch Loss: 0.07487507164478302\n",
      "Epoch 1065, Loss: 0.16992966085672379, Final Batch Loss: 0.11308587342500687\n",
      "Epoch 1066, Loss: 0.1042473278939724, Final Batch Loss: 0.058012351393699646\n",
      "Epoch 1067, Loss: 0.10001458786427975, Final Batch Loss: 0.027583545073866844\n",
      "Epoch 1068, Loss: 0.08794429898262024, Final Batch Loss: 0.05256060138344765\n",
      "Epoch 1069, Loss: 0.17992008477449417, Final Batch Loss: 0.11596855521202087\n",
      "Epoch 1070, Loss: 0.09173467010259628, Final Batch Loss: 0.039553675800561905\n",
      "Epoch 1071, Loss: 0.11077835038304329, Final Batch Loss: 0.05291416868567467\n",
      "Epoch 1072, Loss: 0.09675616025924683, Final Batch Loss: 0.052104584872722626\n",
      "Epoch 1073, Loss: 0.0791885033249855, Final Batch Loss: 0.03709643706679344\n",
      "Epoch 1074, Loss: 0.10847794264554977, Final Batch Loss: 0.03878168761730194\n",
      "Epoch 1075, Loss: 0.08323846012353897, Final Batch Loss: 0.04360882565379143\n",
      "Epoch 1076, Loss: 0.11326637864112854, Final Batch Loss: 0.05491763353347778\n",
      "Epoch 1077, Loss: 0.05737701617181301, Final Batch Loss: 0.028326669707894325\n",
      "Epoch 1078, Loss: 0.06628639809787273, Final Batch Loss: 0.016008814796805382\n",
      "Epoch 1079, Loss: 0.1235734187066555, Final Batch Loss: 0.07475405931472778\n",
      "Epoch 1080, Loss: 0.14622291550040245, Final Batch Loss: 0.08559739589691162\n",
      "Epoch 1081, Loss: 0.09082820825278759, Final Batch Loss: 0.028823813423514366\n",
      "Epoch 1082, Loss: 0.1018679179251194, Final Batch Loss: 0.044368404895067215\n",
      "Epoch 1083, Loss: 0.07787841185927391, Final Batch Loss: 0.043776996433734894\n",
      "Epoch 1084, Loss: 0.07459041103720665, Final Batch Loss: 0.03592479228973389\n",
      "Epoch 1085, Loss: 0.10836109891533852, Final Batch Loss: 0.06163880601525307\n",
      "Epoch 1086, Loss: 0.12146006897091866, Final Batch Loss: 0.059566084295511246\n",
      "Epoch 1087, Loss: 0.08093510568141937, Final Batch Loss: 0.03479380160570145\n",
      "Epoch 1088, Loss: 0.1139182522892952, Final Batch Loss: 0.08154423534870148\n",
      "Epoch 1089, Loss: 0.06852062605321407, Final Batch Loss: 0.012812091037631035\n",
      "Epoch 1090, Loss: 0.07847971096634865, Final Batch Loss: 0.04060754179954529\n",
      "Epoch 1091, Loss: 0.07338131219148636, Final Batch Loss: 0.01763100177049637\n",
      "Epoch 1092, Loss: 0.09037588909268379, Final Batch Loss: 0.044807933270931244\n",
      "Epoch 1093, Loss: 0.10355309769511223, Final Batch Loss: 0.06546346098184586\n",
      "Epoch 1094, Loss: 0.06911884807050228, Final Batch Loss: 0.02201933227479458\n",
      "Epoch 1095, Loss: 0.09201332740485668, Final Batch Loss: 0.02101827971637249\n",
      "Epoch 1096, Loss: 0.10644973441958427, Final Batch Loss: 0.04227932170033455\n",
      "Epoch 1097, Loss: 0.07600009441375732, Final Batch Loss: 0.03361615538597107\n",
      "Epoch 1098, Loss: 0.15701141208410263, Final Batch Loss: 0.07296640425920486\n",
      "Epoch 1099, Loss: 0.0715316403657198, Final Batch Loss: 0.030037952587008476\n",
      "Epoch 1100, Loss: 0.09993790462613106, Final Batch Loss: 0.03100774809718132\n",
      "Epoch 1101, Loss: 0.08506143465638161, Final Batch Loss: 0.03256949782371521\n",
      "Epoch 1102, Loss: 0.09495940804481506, Final Batch Loss: 0.04117369279265404\n",
      "Epoch 1103, Loss: 0.08631697110831738, Final Batch Loss: 0.020147768780589104\n",
      "Epoch 1104, Loss: 0.13771190494298935, Final Batch Loss: 0.07194729894399643\n",
      "Epoch 1105, Loss: 0.18147385492920876, Final Batch Loss: 0.1255529224872589\n",
      "Epoch 1106, Loss: 0.10534233413636684, Final Batch Loss: 0.009198194369673729\n",
      "Epoch 1107, Loss: 0.11830679327249527, Final Batch Loss: 0.07092799991369247\n",
      "Epoch 1108, Loss: 0.1227601133286953, Final Batch Loss: 0.06053799390792847\n",
      "Epoch 1109, Loss: 0.13923614472150803, Final Batch Loss: 0.07504326850175858\n",
      "Epoch 1110, Loss: 0.07912379130721092, Final Batch Loss: 0.030114520341157913\n",
      "Epoch 1111, Loss: 0.11059055477380753, Final Batch Loss: 0.05998820811510086\n",
      "Epoch 1112, Loss: 0.06367134675383568, Final Batch Loss: 0.024356048554182053\n",
      "Epoch 1113, Loss: 0.1323828622698784, Final Batch Loss: 0.048527300357818604\n",
      "Epoch 1114, Loss: 0.09371408820152283, Final Batch Loss: 0.04846816509962082\n",
      "Epoch 1115, Loss: 0.07344241440296173, Final Batch Loss: 0.0320545919239521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1116, Loss: 0.13353820890188217, Final Batch Loss: 0.08043308556079865\n",
      "Epoch 1117, Loss: 0.07608068734407425, Final Batch Loss: 0.027903325855731964\n",
      "Epoch 1118, Loss: 0.11512399092316628, Final Batch Loss: 0.08863548934459686\n",
      "Epoch 1119, Loss: 0.06563109159469604, Final Batch Loss: 0.0140458382666111\n",
      "Epoch 1120, Loss: 0.09516850858926773, Final Batch Loss: 0.03622233495116234\n",
      "Epoch 1121, Loss: 0.061404868960380554, Final Batch Loss: 0.03522613272070885\n",
      "Epoch 1122, Loss: 0.144171554595232, Final Batch Loss: 0.09803871810436249\n",
      "Epoch 1123, Loss: 0.11942153796553612, Final Batch Loss: 0.05294669792056084\n",
      "Epoch 1124, Loss: 0.10190151259303093, Final Batch Loss: 0.04130440950393677\n",
      "Epoch 1125, Loss: 0.18829812854528427, Final Batch Loss: 0.13313767313957214\n",
      "Epoch 1126, Loss: 0.16198651865124702, Final Batch Loss: 0.10746324062347412\n",
      "Epoch 1127, Loss: 0.1728503555059433, Final Batch Loss: 0.10126744210720062\n",
      "Epoch 1128, Loss: 0.191245935857296, Final Batch Loss: 0.06250741332769394\n",
      "Epoch 1129, Loss: 0.09991268068552017, Final Batch Loss: 0.04526761546730995\n",
      "Epoch 1130, Loss: 0.12608371675014496, Final Batch Loss: 0.0646231397986412\n",
      "Epoch 1131, Loss: 0.10261746123433113, Final Batch Loss: 0.0305042527616024\n",
      "Epoch 1132, Loss: 0.08585539273917675, Final Batch Loss: 0.02398969791829586\n",
      "Epoch 1133, Loss: 0.09154732897877693, Final Batch Loss: 0.031968727707862854\n",
      "Epoch 1134, Loss: 0.10517684742808342, Final Batch Loss: 0.03512447699904442\n",
      "Epoch 1135, Loss: 0.11993088573217392, Final Batch Loss: 0.0877348780632019\n",
      "Epoch 1136, Loss: 0.10009651258587837, Final Batch Loss: 0.052986789494752884\n",
      "Epoch 1137, Loss: 0.08333208784461021, Final Batch Loss: 0.035625144839286804\n",
      "Epoch 1138, Loss: 0.10205351933836937, Final Batch Loss: 0.04104815050959587\n",
      "Epoch 1139, Loss: 0.09974881261587143, Final Batch Loss: 0.048790376633405685\n",
      "Epoch 1140, Loss: 0.09297272562980652, Final Batch Loss: 0.04035321623086929\n",
      "Epoch 1141, Loss: 0.04892471991479397, Final Batch Loss: 0.016618212684988976\n",
      "Epoch 1142, Loss: 0.15290316194295883, Final Batch Loss: 0.0641242191195488\n",
      "Epoch 1143, Loss: 0.11621439829468727, Final Batch Loss: 0.0500313825905323\n",
      "Epoch 1144, Loss: 0.19573592394590378, Final Batch Loss: 0.10216689109802246\n",
      "Epoch 1145, Loss: 0.14917223528027534, Final Batch Loss: 0.0430595763027668\n",
      "Epoch 1146, Loss: 0.11874333024024963, Final Batch Loss: 0.06647209823131561\n",
      "Epoch 1147, Loss: 0.058051325380802155, Final Batch Loss: 0.027192803099751472\n",
      "Epoch 1148, Loss: 0.10483867675065994, Final Batch Loss: 0.0585021898150444\n",
      "Epoch 1149, Loss: 0.11227172240614891, Final Batch Loss: 0.05804092809557915\n",
      "Epoch 1150, Loss: 0.15430359169840813, Final Batch Loss: 0.10644226521253586\n",
      "Epoch 1151, Loss: 0.061281319707632065, Final Batch Loss: 0.016909148544073105\n",
      "Epoch 1152, Loss: 0.10515497624874115, Final Batch Loss: 0.04106738418340683\n",
      "Epoch 1153, Loss: 0.10965664684772491, Final Batch Loss: 0.06131718307733536\n",
      "Epoch 1154, Loss: 0.0975920595228672, Final Batch Loss: 0.054773904383182526\n",
      "Epoch 1155, Loss: 0.10455295816063881, Final Batch Loss: 0.051565591245889664\n",
      "Epoch 1156, Loss: 0.1657801754772663, Final Batch Loss: 0.1120740994811058\n",
      "Epoch 1157, Loss: 0.06945578008890152, Final Batch Loss: 0.020415667444467545\n",
      "Epoch 1158, Loss: 0.1097869798541069, Final Batch Loss: 0.05721883103251457\n",
      "Epoch 1159, Loss: 0.11068729683756828, Final Batch Loss: 0.06513851881027222\n",
      "Epoch 1160, Loss: 0.07750975899398327, Final Batch Loss: 0.02480299212038517\n",
      "Epoch 1161, Loss: 0.10386404395103455, Final Batch Loss: 0.05733446031808853\n",
      "Epoch 1162, Loss: 0.2387649454176426, Final Batch Loss: 0.18917091190814972\n",
      "Epoch 1163, Loss: 0.07004263810813427, Final Batch Loss: 0.029970483854413033\n",
      "Epoch 1164, Loss: 0.06702457554638386, Final Batch Loss: 0.04119051620364189\n",
      "Epoch 1165, Loss: 0.14216606691479683, Final Batch Loss: 0.10775630176067352\n",
      "Epoch 1166, Loss: 0.11412792652845383, Final Batch Loss: 0.06186208128929138\n",
      "Epoch 1167, Loss: 0.06902637518942356, Final Batch Loss: 0.012426482513546944\n",
      "Epoch 1168, Loss: 0.12384277209639549, Final Batch Loss: 0.03874314948916435\n",
      "Epoch 1169, Loss: 0.06558306328952312, Final Batch Loss: 0.017422696575522423\n",
      "Epoch 1170, Loss: 0.11362934485077858, Final Batch Loss: 0.06626377999782562\n",
      "Epoch 1171, Loss: 0.07526092045009136, Final Batch Loss: 0.0212154071778059\n",
      "Epoch 1172, Loss: 0.09096801653504372, Final Batch Loss: 0.05721558257937431\n",
      "Epoch 1173, Loss: 0.07071429118514061, Final Batch Loss: 0.047301191836595535\n",
      "Epoch 1174, Loss: 0.11361273005604744, Final Batch Loss: 0.05826861783862114\n",
      "Epoch 1175, Loss: 0.09928998351097107, Final Batch Loss: 0.04778135195374489\n",
      "Epoch 1176, Loss: 0.12233498319983482, Final Batch Loss: 0.042543310672044754\n",
      "Epoch 1177, Loss: 0.109734445810318, Final Batch Loss: 0.06786128878593445\n",
      "Epoch 1178, Loss: 0.11749667674303055, Final Batch Loss: 0.06874313950538635\n",
      "Epoch 1179, Loss: 0.15791824460029602, Final Batch Loss: 0.061999037861824036\n",
      "Epoch 1180, Loss: 0.08781036362051964, Final Batch Loss: 0.056170858442783356\n",
      "Epoch 1181, Loss: 0.09396182000637054, Final Batch Loss: 0.05445269122719765\n",
      "Epoch 1182, Loss: 0.04324648156762123, Final Batch Loss: 0.008073356002569199\n",
      "Epoch 1183, Loss: 0.07131901383399963, Final Batch Loss: 0.03751632943749428\n",
      "Epoch 1184, Loss: 0.10316365584731102, Final Batch Loss: 0.04968506097793579\n",
      "Epoch 1185, Loss: 0.10572421923279762, Final Batch Loss: 0.027055922895669937\n",
      "Epoch 1186, Loss: 0.09964188374578953, Final Batch Loss: 0.06887155771255493\n",
      "Epoch 1187, Loss: 0.09945331886410713, Final Batch Loss: 0.024056199938058853\n",
      "Epoch 1188, Loss: 0.09078900516033173, Final Batch Loss: 0.06324782967567444\n",
      "Epoch 1189, Loss: 0.2709360159933567, Final Batch Loss: 0.22338560223579407\n",
      "Epoch 1190, Loss: 0.12635628506541252, Final Batch Loss: 0.08234930783510208\n",
      "Epoch 1191, Loss: 0.09588073194026947, Final Batch Loss: 0.03903082385659218\n",
      "Epoch 1192, Loss: 0.15041299536824226, Final Batch Loss: 0.05926297977566719\n",
      "Epoch 1193, Loss: 0.10406224057078362, Final Batch Loss: 0.06500352174043655\n",
      "Epoch 1194, Loss: 0.09319363534450531, Final Batch Loss: 0.04979328438639641\n",
      "Epoch 1195, Loss: 0.08728063479065895, Final Batch Loss: 0.03643389791250229\n",
      "Epoch 1196, Loss: 0.07226928137242794, Final Batch Loss: 0.02072952128946781\n",
      "Epoch 1197, Loss: 0.06061625853180885, Final Batch Loss: 0.03451579436659813\n",
      "Epoch 1198, Loss: 0.09015849605202675, Final Batch Loss: 0.030447855591773987\n",
      "Epoch 1199, Loss: 0.20381366461515427, Final Batch Loss: 0.14166781306266785\n",
      "Epoch 1200, Loss: 0.10359268635511398, Final Batch Loss: 0.03374373912811279\n",
      "Epoch 1201, Loss: 0.1298363283276558, Final Batch Loss: 0.08163025230169296\n",
      "Epoch 1202, Loss: 0.0727766565978527, Final Batch Loss: 0.0367441400885582\n",
      "Epoch 1203, Loss: 0.0821370892226696, Final Batch Loss: 0.04193636402487755\n",
      "Epoch 1204, Loss: 0.07254304550588131, Final Batch Loss: 0.026438439264893532\n",
      "Epoch 1205, Loss: 0.07649700529873371, Final Batch Loss: 0.025193022564053535\n",
      "Epoch 1206, Loss: 0.05199343524873257, Final Batch Loss: 0.020288122817873955\n",
      "Epoch 1207, Loss: 0.09098624810576439, Final Batch Loss: 0.049818843603134155\n",
      "Epoch 1208, Loss: 0.09719085320830345, Final Batch Loss: 0.04620226472616196\n",
      "Epoch 1209, Loss: 0.13014540821313858, Final Batch Loss: 0.0532124862074852\n",
      "Epoch 1210, Loss: 0.124555304646492, Final Batch Loss: 0.08638355880975723\n",
      "Epoch 1211, Loss: 0.16041389480233192, Final Batch Loss: 0.10656630992889404\n",
      "Epoch 1212, Loss: 0.10620968416333199, Final Batch Loss: 0.04799572005867958\n",
      "Epoch 1213, Loss: 0.14908117800951004, Final Batch Loss: 0.09948412328958511\n",
      "Epoch 1214, Loss: 0.07574238069355488, Final Batch Loss: 0.025249002501368523\n",
      "Epoch 1215, Loss: 0.11111225187778473, Final Batch Loss: 0.046825043857097626\n",
      "Epoch 1216, Loss: 0.17603500373661518, Final Batch Loss: 0.1502314656972885\n",
      "Epoch 1217, Loss: 0.08800247311592102, Final Batch Loss: 0.04128849506378174\n",
      "Epoch 1218, Loss: 0.05961696431040764, Final Batch Loss: 0.01874696835875511\n",
      "Epoch 1219, Loss: 0.1885545700788498, Final Batch Loss: 0.14719504117965698\n",
      "Epoch 1220, Loss: 0.07133698835968971, Final Batch Loss: 0.029472440481185913\n",
      "Epoch 1221, Loss: 0.15854066610336304, Final Batch Loss: 0.08100485801696777\n",
      "Epoch 1222, Loss: 0.08116121590137482, Final Batch Loss: 0.03281553462147713\n",
      "Epoch 1223, Loss: 0.06845288723707199, Final Batch Loss: 0.03683518245816231\n",
      "Epoch 1224, Loss: 0.10412511229515076, Final Batch Loss: 0.04260757938027382\n",
      "Epoch 1225, Loss: 0.12903627753257751, Final Batch Loss: 0.08901660889387131\n",
      "Epoch 1226, Loss: 0.05625002831220627, Final Batch Loss: 0.018739167600870132\n",
      "Epoch 1227, Loss: 0.07835888862609863, Final Batch Loss: 0.030843984335660934\n",
      "Epoch 1228, Loss: 0.08501182496547699, Final Batch Loss: 0.04210073500871658\n",
      "Epoch 1229, Loss: 0.12990375235676765, Final Batch Loss: 0.09681064635515213\n",
      "Epoch 1230, Loss: 0.12520462647080421, Final Batch Loss: 0.0702715590596199\n",
      "Epoch 1231, Loss: 0.1212584525346756, Final Batch Loss: 0.08568398654460907\n",
      "Epoch 1232, Loss: 0.10725212842226028, Final Batch Loss: 0.04996075853705406\n",
      "Epoch 1233, Loss: 0.16675833612680435, Final Batch Loss: 0.10475020855665207\n",
      "Epoch 1234, Loss: 0.0891050212085247, Final Batch Loss: 0.03429355472326279\n",
      "Epoch 1235, Loss: 0.18235249817371368, Final Batch Loss: 0.12794116139411926\n",
      "Epoch 1236, Loss: 0.08631666377186775, Final Batch Loss: 0.026154428720474243\n",
      "Epoch 1237, Loss: 0.07647264748811722, Final Batch Loss: 0.024453572928905487\n",
      "Epoch 1238, Loss: 0.14670756459236145, Final Batch Loss: 0.08665148913860321\n",
      "Epoch 1239, Loss: 0.06550711579620838, Final Batch Loss: 0.024733906611800194\n",
      "Epoch 1240, Loss: 0.14541347324848175, Final Batch Loss: 0.10102113336324692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1241, Loss: 0.09459858760237694, Final Batch Loss: 0.046547580510377884\n",
      "Epoch 1242, Loss: 0.09533939324319363, Final Batch Loss: 0.02459665946662426\n",
      "Epoch 1243, Loss: 0.09217649511992931, Final Batch Loss: 0.07326202839612961\n",
      "Epoch 1244, Loss: 0.08645656332373619, Final Batch Loss: 0.04723000153899193\n",
      "Epoch 1245, Loss: 0.07134972885251045, Final Batch Loss: 0.03896743059158325\n",
      "Epoch 1246, Loss: 0.1233319379389286, Final Batch Loss: 0.05788453295826912\n",
      "Epoch 1247, Loss: 0.07280564680695534, Final Batch Loss: 0.02379797026515007\n",
      "Epoch 1248, Loss: 0.10651104897260666, Final Batch Loss: 0.06871824711561203\n",
      "Epoch 1249, Loss: 0.12792812287807465, Final Batch Loss: 0.09257430583238602\n",
      "Epoch 1250, Loss: 0.06748832762241364, Final Batch Loss: 0.019217655062675476\n",
      "Epoch 1251, Loss: 0.08575722575187683, Final Batch Loss: 0.027933675795793533\n",
      "Epoch 1252, Loss: 0.09095361456274986, Final Batch Loss: 0.041035715490579605\n",
      "Epoch 1253, Loss: 0.1230459064245224, Final Batch Loss: 0.09158483892679214\n",
      "Epoch 1254, Loss: 0.15237092599272728, Final Batch Loss: 0.09062636643648148\n",
      "Epoch 1255, Loss: 0.11149860545992851, Final Batch Loss: 0.05644294619560242\n",
      "Epoch 1256, Loss: 0.10422682017087936, Final Batch Loss: 0.059152811765670776\n",
      "Epoch 1257, Loss: 0.10355791449546814, Final Batch Loss: 0.05513656884431839\n",
      "Epoch 1258, Loss: 0.08842446282505989, Final Batch Loss: 0.050899699330329895\n",
      "Epoch 1259, Loss: 0.11983980983495712, Final Batch Loss: 0.05074119567871094\n",
      "Epoch 1260, Loss: 0.07812085747718811, Final Batch Loss: 0.0321524515748024\n",
      "Epoch 1261, Loss: 0.22577257826924324, Final Batch Loss: 0.17857231199741364\n",
      "Epoch 1262, Loss: 0.15768612921237946, Final Batch Loss: 0.09419791400432587\n",
      "Epoch 1263, Loss: 0.0807964839041233, Final Batch Loss: 0.047394316643476486\n",
      "Epoch 1264, Loss: 0.12232853844761848, Final Batch Loss: 0.08438046276569366\n",
      "Epoch 1265, Loss: 0.0924924947321415, Final Batch Loss: 0.03196464106440544\n",
      "Epoch 1266, Loss: 0.10884010791778564, Final Batch Loss: 0.05009818822145462\n",
      "Epoch 1267, Loss: 0.08371878042817116, Final Batch Loss: 0.028481487184762955\n",
      "Epoch 1268, Loss: 0.11651898920536041, Final Batch Loss: 0.060299839824438095\n",
      "Epoch 1269, Loss: 0.10283979400992393, Final Batch Loss: 0.057789213955402374\n",
      "Epoch 1270, Loss: 0.0791343692690134, Final Batch Loss: 0.024658391252160072\n",
      "Epoch 1271, Loss: 0.07108452543616295, Final Batch Loss: 0.029091879725456238\n",
      "Epoch 1272, Loss: 0.09271425381302834, Final Batch Loss: 0.0525536872446537\n",
      "Epoch 1273, Loss: 0.06079539842903614, Final Batch Loss: 0.0171761903911829\n",
      "Epoch 1274, Loss: 0.08739965781569481, Final Batch Loss: 0.04055771231651306\n",
      "Epoch 1275, Loss: 0.10357357561588287, Final Batch Loss: 0.06506938487291336\n",
      "Epoch 1276, Loss: 0.12901607528328896, Final Batch Loss: 0.08809848874807358\n",
      "Epoch 1277, Loss: 0.061073340475559235, Final Batch Loss: 0.029493391513824463\n",
      "Epoch 1278, Loss: 0.05517796892672777, Final Batch Loss: 0.015416593290865421\n",
      "Epoch 1279, Loss: 0.15342076122760773, Final Batch Loss: 0.07253943383693695\n",
      "Epoch 1280, Loss: 0.0767345242202282, Final Batch Loss: 0.05828774720430374\n",
      "Epoch 1281, Loss: 0.0830041952431202, Final Batch Loss: 0.0485089085996151\n",
      "Epoch 1282, Loss: 0.15314437448978424, Final Batch Loss: 0.08589821308851242\n",
      "Epoch 1283, Loss: 0.14564523845911026, Final Batch Loss: 0.0513448640704155\n",
      "Epoch 1284, Loss: 0.12948864325881004, Final Batch Loss: 0.07797211408615112\n",
      "Epoch 1285, Loss: 0.1056154053658247, Final Batch Loss: 0.0235383789986372\n",
      "Epoch 1286, Loss: 0.07103776186704636, Final Batch Loss: 0.030969616025686264\n",
      "Epoch 1287, Loss: 0.09249162022024393, Final Batch Loss: 0.015333049930632114\n",
      "Epoch 1288, Loss: 0.09703019261360168, Final Batch Loss: 0.04354632645845413\n",
      "Epoch 1289, Loss: 0.05076237674802542, Final Batch Loss: 0.014157201163470745\n",
      "Epoch 1290, Loss: 0.08007351867854595, Final Batch Loss: 0.026488171890378\n",
      "Epoch 1291, Loss: 0.07714922167360783, Final Batch Loss: 0.02543969266116619\n",
      "Epoch 1292, Loss: 0.18219975382089615, Final Batch Loss: 0.10043586045503616\n",
      "Epoch 1293, Loss: 0.0659156609326601, Final Batch Loss: 0.038859933614730835\n",
      "Epoch 1294, Loss: 0.07741477340459824, Final Batch Loss: 0.03703763335943222\n",
      "Epoch 1295, Loss: 0.06541860476136208, Final Batch Loss: 0.026573341339826584\n",
      "Epoch 1296, Loss: 0.06524091586470604, Final Batch Loss: 0.04157811775803566\n",
      "Epoch 1297, Loss: 0.07493184600025415, Final Batch Loss: 0.01119952742010355\n",
      "Epoch 1298, Loss: 0.06630113907158375, Final Batch Loss: 0.029602358117699623\n",
      "Epoch 1299, Loss: 0.0905146487057209, Final Batch Loss: 0.05679783225059509\n",
      "Epoch 1300, Loss: 0.06911436654627323, Final Batch Loss: 0.05204326659440994\n",
      "Epoch 1301, Loss: 0.09076299518346786, Final Batch Loss: 0.03935566544532776\n",
      "Epoch 1302, Loss: 0.09646868705749512, Final Batch Loss: 0.04440481588244438\n",
      "Epoch 1303, Loss: 0.0903288759291172, Final Batch Loss: 0.03989685699343681\n",
      "Epoch 1304, Loss: 0.1329229399561882, Final Batch Loss: 0.0829237774014473\n",
      "Epoch 1305, Loss: 0.087987519800663, Final Batch Loss: 0.0489434190094471\n",
      "Epoch 1306, Loss: 0.12132799997925758, Final Batch Loss: 0.05381782725453377\n",
      "Epoch 1307, Loss: 0.17826838046312332, Final Batch Loss: 0.11460793018341064\n",
      "Epoch 1308, Loss: 0.09527628496289253, Final Batch Loss: 0.05475137382745743\n",
      "Epoch 1309, Loss: 0.07637066952884197, Final Batch Loss: 0.017560740932822227\n",
      "Epoch 1310, Loss: 0.0430685356259346, Final Batch Loss: 0.018298529088497162\n",
      "Epoch 1311, Loss: 0.06065757013857365, Final Batch Loss: 0.02045341394841671\n",
      "Epoch 1312, Loss: 0.13192128017544746, Final Batch Loss: 0.08424026519060135\n",
      "Epoch 1313, Loss: 0.08502156008034945, Final Batch Loss: 0.012544435448944569\n",
      "Epoch 1314, Loss: 0.06394932698458433, Final Batch Loss: 0.011327962391078472\n",
      "Epoch 1315, Loss: 0.09007024765014648, Final Batch Loss: 0.05405466631054878\n",
      "Epoch 1316, Loss: 0.1033785492181778, Final Batch Loss: 0.05755903571844101\n",
      "Epoch 1317, Loss: 0.0664506945759058, Final Batch Loss: 0.020291471853852272\n",
      "Epoch 1318, Loss: 0.08026149123907089, Final Batch Loss: 0.04059053584933281\n",
      "Epoch 1319, Loss: 0.0779111385345459, Final Batch Loss: 0.037225402891635895\n",
      "Epoch 1320, Loss: 0.06408888474106789, Final Batch Loss: 0.014036063104867935\n",
      "Epoch 1321, Loss: 0.08599879592657089, Final Batch Loss: 0.034819889813661575\n",
      "Epoch 1322, Loss: 0.09131628274917603, Final Batch Loss: 0.03967949002981186\n",
      "Epoch 1323, Loss: 0.07054160535335541, Final Batch Loss: 0.03710655868053436\n",
      "Epoch 1324, Loss: 0.05871864780783653, Final Batch Loss: 0.024951722472906113\n",
      "Epoch 1325, Loss: 0.10968677699565887, Final Batch Loss: 0.039692990481853485\n",
      "Epoch 1326, Loss: 0.07852644473314285, Final Batch Loss: 0.03521167114377022\n",
      "Epoch 1327, Loss: 0.09551520273089409, Final Batch Loss: 0.04430651292204857\n",
      "Epoch 1328, Loss: 0.11851759627461433, Final Batch Loss: 0.04364374652504921\n",
      "Epoch 1329, Loss: 0.19682256132364273, Final Batch Loss: 0.11677758395671844\n",
      "Epoch 1330, Loss: 0.06843559630215168, Final Batch Loss: 0.016545047983527184\n",
      "Epoch 1331, Loss: 0.10455968603491783, Final Batch Loss: 0.061915915459394455\n",
      "Epoch 1332, Loss: 0.10092745162546635, Final Batch Loss: 0.029500076547265053\n",
      "Epoch 1333, Loss: 0.08638211898505688, Final Batch Loss: 0.06574948877096176\n",
      "Epoch 1334, Loss: 0.11859041079878807, Final Batch Loss: 0.08120470494031906\n",
      "Epoch 1335, Loss: 0.07667601853609085, Final Batch Loss: 0.03536900505423546\n",
      "Epoch 1336, Loss: 0.12318183854222298, Final Batch Loss: 0.0869012102484703\n",
      "Epoch 1337, Loss: 0.11040361225605011, Final Batch Loss: 0.058409228920936584\n",
      "Epoch 1338, Loss: 0.14989185333251953, Final Batch Loss: 0.0817343145608902\n",
      "Epoch 1339, Loss: 0.0795210562646389, Final Batch Loss: 0.03125492483377457\n",
      "Epoch 1340, Loss: 0.13606983423233032, Final Batch Loss: 0.04193958640098572\n",
      "Epoch 1341, Loss: 0.09278622642159462, Final Batch Loss: 0.04342031106352806\n",
      "Epoch 1342, Loss: 0.0748133696615696, Final Batch Loss: 0.025104600936174393\n",
      "Epoch 1343, Loss: 0.049556830897927284, Final Batch Loss: 0.02688543125987053\n",
      "Epoch 1344, Loss: 0.11558173224329948, Final Batch Loss: 0.04449712112545967\n",
      "Epoch 1345, Loss: 0.04930049553513527, Final Batch Loss: 0.016262128949165344\n",
      "Epoch 1346, Loss: 0.10703979805111885, Final Batch Loss: 0.060512714087963104\n",
      "Epoch 1347, Loss: 0.114423967897892, Final Batch Loss: 0.055010683834552765\n",
      "Epoch 1348, Loss: 0.08876540511846542, Final Batch Loss: 0.049083542078733444\n",
      "Epoch 1349, Loss: 0.06064222566783428, Final Batch Loss: 0.019754918292164803\n",
      "Epoch 1350, Loss: 0.0682449508458376, Final Batch Loss: 0.029059095308184624\n",
      "Epoch 1351, Loss: 0.06019031070172787, Final Batch Loss: 0.013847166672348976\n",
      "Epoch 1352, Loss: 0.10063030198216438, Final Batch Loss: 0.06309378147125244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1353, Loss: 0.13033736124634743, Final Batch Loss: 0.03960886225104332\n",
      "Epoch 1354, Loss: 0.09987989440560341, Final Batch Loss: 0.061548370867967606\n",
      "Epoch 1355, Loss: 0.0977933444082737, Final Batch Loss: 0.05157541483640671\n",
      "Epoch 1356, Loss: 0.08085972443223, Final Batch Loss: 0.037283726036548615\n",
      "Epoch 1357, Loss: 0.09426495432853699, Final Batch Loss: 0.054818250238895416\n",
      "Epoch 1358, Loss: 0.13320143520832062, Final Batch Loss: 0.09377548098564148\n",
      "Epoch 1359, Loss: 0.10218667425215244, Final Batch Loss: 0.029460551217198372\n",
      "Epoch 1360, Loss: 0.09096844866871834, Final Batch Loss: 0.028656303882598877\n",
      "Epoch 1361, Loss: 0.06421251781284809, Final Batch Loss: 0.033128585666418076\n",
      "Epoch 1362, Loss: 0.09320239722728729, Final Batch Loss: 0.06883292645215988\n",
      "Epoch 1363, Loss: 0.10043402761220932, Final Batch Loss: 0.05298334360122681\n",
      "Epoch 1364, Loss: 0.10570972226560116, Final Batch Loss: 0.019484838470816612\n",
      "Epoch 1365, Loss: 0.0781264416873455, Final Batch Loss: 0.028962112963199615\n",
      "Epoch 1366, Loss: 0.08557466883212328, Final Batch Loss: 0.012521189637482166\n",
      "Epoch 1367, Loss: 0.06395182386040688, Final Batch Loss: 0.026683378964662552\n",
      "Epoch 1368, Loss: 0.08877116907387972, Final Batch Loss: 0.015053358860313892\n",
      "Epoch 1369, Loss: 0.04503043834120035, Final Batch Loss: 0.014661283232271671\n",
      "Epoch 1370, Loss: 0.07599405571818352, Final Batch Loss: 0.03738422691822052\n",
      "Epoch 1371, Loss: 0.06446346640586853, Final Batch Loss: 0.014860037714242935\n",
      "Epoch 1372, Loss: 0.05413791164755821, Final Batch Loss: 0.010302171111106873\n",
      "Epoch 1373, Loss: 0.06889640726149082, Final Batch Loss: 0.03027949668467045\n",
      "Epoch 1374, Loss: 0.0952315591275692, Final Batch Loss: 0.034759823232889175\n",
      "Epoch 1375, Loss: 0.0662668589502573, Final Batch Loss: 0.029413850978016853\n",
      "Epoch 1376, Loss: 0.10400522500276566, Final Batch Loss: 0.04859894514083862\n",
      "Epoch 1377, Loss: 0.0799979493021965, Final Batch Loss: 0.037968482822179794\n",
      "Epoch 1378, Loss: 0.08231569826602936, Final Batch Loss: 0.019093751907348633\n",
      "Epoch 1379, Loss: 0.0960488710552454, Final Batch Loss: 0.017043599858880043\n",
      "Epoch 1380, Loss: 0.07028712704777718, Final Batch Loss: 0.025298185646533966\n",
      "Epoch 1381, Loss: 0.06438462994992733, Final Batch Loss: 0.023100385442376137\n",
      "Epoch 1382, Loss: 0.11556890606880188, Final Batch Loss: 0.0821225717663765\n",
      "Epoch 1383, Loss: 0.08932565897703171, Final Batch Loss: 0.039451051503419876\n",
      "Epoch 1384, Loss: 0.09394496306777, Final Batch Loss: 0.05931608006358147\n",
      "Epoch 1385, Loss: 0.10982086136937141, Final Batch Loss: 0.0580468587577343\n",
      "Epoch 1386, Loss: 0.07898013852536678, Final Batch Loss: 0.049282707273960114\n",
      "Epoch 1387, Loss: 0.075599305331707, Final Batch Loss: 0.03301088884472847\n",
      "Epoch 1388, Loss: 0.05205016862601042, Final Batch Loss: 0.009226596914231777\n",
      "Epoch 1389, Loss: 0.16550662368535995, Final Batch Loss: 0.039045922458171844\n",
      "Epoch 1390, Loss: 0.08025961928069592, Final Batch Loss: 0.02988322637975216\n",
      "Epoch 1391, Loss: 0.11556286178529263, Final Batch Loss: 0.026724567636847496\n",
      "Epoch 1392, Loss: 0.07493516802787781, Final Batch Loss: 0.043636344373226166\n",
      "Epoch 1393, Loss: 0.042155818082392216, Final Batch Loss: 0.010037646628916264\n",
      "Epoch 1394, Loss: 0.10323378816246986, Final Batch Loss: 0.06081657111644745\n",
      "Epoch 1395, Loss: 0.06568364053964615, Final Batch Loss: 0.010156489908695221\n",
      "Epoch 1396, Loss: 0.07249932177364826, Final Batch Loss: 0.04860794544219971\n",
      "Epoch 1397, Loss: 0.15832561068236828, Final Batch Loss: 0.12818112969398499\n",
      "Epoch 1398, Loss: 0.08751056715846062, Final Batch Loss: 0.04105230048298836\n",
      "Epoch 1399, Loss: 0.08990100398659706, Final Batch Loss: 0.034296534955501556\n",
      "Epoch 1400, Loss: 0.062191316857934, Final Batch Loss: 0.029354775324463844\n",
      "Epoch 1401, Loss: 0.057499540504068136, Final Batch Loss: 0.007467770483344793\n",
      "Epoch 1402, Loss: 0.0899563878774643, Final Batch Loss: 0.05565793439745903\n",
      "Epoch 1403, Loss: 0.05209010373800993, Final Batch Loss: 0.011325969360768795\n",
      "Epoch 1404, Loss: 0.05590040609240532, Final Batch Loss: 0.019081801176071167\n",
      "Epoch 1405, Loss: 0.07897314801812172, Final Batch Loss: 0.02321462705731392\n",
      "Epoch 1406, Loss: 0.11489137262105942, Final Batch Loss: 0.07989834994077682\n",
      "Epoch 1407, Loss: 0.1150507815182209, Final Batch Loss: 0.06622721999883652\n",
      "Epoch 1408, Loss: 0.0983019508421421, Final Batch Loss: 0.03345048055052757\n",
      "Epoch 1409, Loss: 0.06066551059484482, Final Batch Loss: 0.01955254375934601\n",
      "Epoch 1410, Loss: 0.10236708074808121, Final Batch Loss: 0.056062519550323486\n",
      "Epoch 1411, Loss: 0.09536331705749035, Final Batch Loss: 0.01819602958858013\n",
      "Epoch 1412, Loss: 0.06784864887595177, Final Batch Loss: 0.022399690002202988\n",
      "Epoch 1413, Loss: 0.06324694491922855, Final Batch Loss: 0.03789488971233368\n",
      "Epoch 1414, Loss: 0.08788969740271568, Final Batch Loss: 0.023000258952379227\n",
      "Epoch 1415, Loss: 0.09682018682360649, Final Batch Loss: 0.05144866928458214\n",
      "Epoch 1416, Loss: 0.0588308647274971, Final Batch Loss: 0.027308054268360138\n",
      "Epoch 1417, Loss: 0.07336732558906078, Final Batch Loss: 0.029839133843779564\n",
      "Epoch 1418, Loss: 0.13778352364897728, Final Batch Loss: 0.05555601045489311\n",
      "Epoch 1419, Loss: 0.1400948315858841, Final Batch Loss: 0.1038394644856453\n",
      "Epoch 1420, Loss: 0.05603786837309599, Final Batch Loss: 0.015315975062549114\n",
      "Epoch 1421, Loss: 0.08217805251479149, Final Batch Loss: 0.02196834236383438\n",
      "Epoch 1422, Loss: 0.08040796779096127, Final Batch Loss: 0.05957731604576111\n",
      "Epoch 1423, Loss: 0.10667700693011284, Final Batch Loss: 0.0566132478415966\n",
      "Epoch 1424, Loss: 0.13260535895824432, Final Batch Loss: 0.0670655146241188\n",
      "Epoch 1425, Loss: 0.08680583909153938, Final Batch Loss: 0.053310662508010864\n",
      "Epoch 1426, Loss: 0.12254609912633896, Final Batch Loss: 0.09573382884263992\n",
      "Epoch 1427, Loss: 0.06298171356320381, Final Batch Loss: 0.040168892592191696\n",
      "Epoch 1428, Loss: 0.09457752108573914, Final Batch Loss: 0.03750348836183548\n",
      "Epoch 1429, Loss: 0.11665287613868713, Final Batch Loss: 0.06368639320135117\n",
      "Epoch 1430, Loss: 0.0751410499215126, Final Batch Loss: 0.03363924100995064\n",
      "Epoch 1431, Loss: 0.045489924028515816, Final Batch Loss: 0.008314916864037514\n",
      "Epoch 1432, Loss: 0.11892379447817802, Final Batch Loss: 0.05018522962927818\n",
      "Epoch 1433, Loss: 0.0766610149294138, Final Batch Loss: 0.02882418967783451\n",
      "Epoch 1434, Loss: 0.09189648181200027, Final Batch Loss: 0.06821175664663315\n",
      "Epoch 1435, Loss: 0.09415208920836449, Final Batch Loss: 0.022545386105775833\n",
      "Epoch 1436, Loss: 0.10023387894034386, Final Batch Loss: 0.059216924011707306\n",
      "Epoch 1437, Loss: 0.14458943903446198, Final Batch Loss: 0.06927718222141266\n",
      "Epoch 1438, Loss: 0.08616610988974571, Final Batch Loss: 0.045768093317747116\n",
      "Epoch 1439, Loss: 0.1131471898406744, Final Batch Loss: 0.016633233055472374\n",
      "Epoch 1440, Loss: 0.0977353360503912, Final Batch Loss: 0.0730874165892601\n",
      "Epoch 1441, Loss: 0.054296886548399925, Final Batch Loss: 0.034377556294202805\n",
      "Epoch 1442, Loss: 0.05378912482410669, Final Batch Loss: 0.015359071083366871\n",
      "Epoch 1443, Loss: 0.10475113242864609, Final Batch Loss: 0.06210720166563988\n",
      "Epoch 1444, Loss: 0.07639782503247261, Final Batch Loss: 0.05078044533729553\n",
      "Epoch 1445, Loss: 0.18252901919186115, Final Batch Loss: 0.15191859006881714\n",
      "Epoch 1446, Loss: 0.0696039292961359, Final Batch Loss: 0.021573146805167198\n",
      "Epoch 1447, Loss: 0.1089160107076168, Final Batch Loss: 0.07641652971506119\n",
      "Epoch 1448, Loss: 0.0458372188732028, Final Batch Loss: 0.010441864840686321\n",
      "Epoch 1449, Loss: 0.07709473557770252, Final Batch Loss: 0.01758054830133915\n",
      "Epoch 1450, Loss: 0.08241903223097324, Final Batch Loss: 0.026725051924586296\n",
      "Epoch 1451, Loss: 0.06618727277964354, Final Batch Loss: 0.014232187531888485\n",
      "Epoch 1452, Loss: 0.043754441663622856, Final Batch Loss: 0.018772456794977188\n",
      "Epoch 1453, Loss: 0.037213034927845, Final Batch Loss: 0.008566660806536674\n",
      "Epoch 1454, Loss: 0.10685693472623825, Final Batch Loss: 0.0699494332075119\n",
      "Epoch 1455, Loss: 0.05543599370867014, Final Batch Loss: 0.014578131027519703\n",
      "Epoch 1456, Loss: 0.10086162388324738, Final Batch Loss: 0.04734952747821808\n",
      "Epoch 1457, Loss: 0.06324936728924513, Final Batch Loss: 0.01505217980593443\n",
      "Epoch 1458, Loss: 0.10717531479895115, Final Batch Loss: 0.08039058744907379\n",
      "Epoch 1459, Loss: 0.135158259421587, Final Batch Loss: 0.09752155095338821\n",
      "Epoch 1460, Loss: 0.12319102138280869, Final Batch Loss: 0.0791996419429779\n",
      "Epoch 1461, Loss: 0.050414929166436195, Final Batch Loss: 0.027682913467288017\n",
      "Epoch 1462, Loss: 0.09117617458105087, Final Batch Loss: 0.03557240217924118\n",
      "Epoch 1463, Loss: 0.08969305828213692, Final Batch Loss: 0.04551341384649277\n",
      "Epoch 1464, Loss: 0.10080959275364876, Final Batch Loss: 0.04480025917291641\n",
      "Epoch 1465, Loss: 0.14014020562171936, Final Batch Loss: 0.059274621307849884\n",
      "Epoch 1466, Loss: 0.10928213968873024, Final Batch Loss: 0.05209188163280487\n",
      "Epoch 1467, Loss: 0.11480262130498886, Final Batch Loss: 0.028406545519828796\n",
      "Epoch 1468, Loss: 0.09825881198048592, Final Batch Loss: 0.05874824896454811\n",
      "Epoch 1469, Loss: 0.10872624069452286, Final Batch Loss: 0.06845084577798843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1470, Loss: 0.05787672661244869, Final Batch Loss: 0.029673540964722633\n",
      "Epoch 1471, Loss: 0.1886911652982235, Final Batch Loss: 0.1533178836107254\n",
      "Epoch 1472, Loss: 0.08302922360599041, Final Batch Loss: 0.06006333976984024\n",
      "Epoch 1473, Loss: 0.08339579030871391, Final Batch Loss: 0.03243851289153099\n",
      "Epoch 1474, Loss: 0.09199222177267075, Final Batch Loss: 0.05595456436276436\n",
      "Epoch 1475, Loss: 0.10264305770397186, Final Batch Loss: 0.07730445265769958\n",
      "Epoch 1476, Loss: 0.07652991637587547, Final Batch Loss: 0.02294773980975151\n",
      "Epoch 1477, Loss: 0.10112284496426582, Final Batch Loss: 0.03838634863495827\n",
      "Epoch 1478, Loss: 0.08695863373577595, Final Batch Loss: 0.020100632682442665\n",
      "Epoch 1479, Loss: 0.09305251389741898, Final Batch Loss: 0.038184523582458496\n",
      "Epoch 1480, Loss: 0.04719879664480686, Final Batch Loss: 0.011627068743109703\n",
      "Epoch 1481, Loss: 0.11649049818515778, Final Batch Loss: 0.03818046301603317\n",
      "Epoch 1482, Loss: 0.0639778133481741, Final Batch Loss: 0.01612926833331585\n",
      "Epoch 1483, Loss: 0.0767653826624155, Final Batch Loss: 0.01569361798465252\n",
      "Epoch 1484, Loss: 0.06616180017590523, Final Batch Loss: 0.017357736825942993\n",
      "Epoch 1485, Loss: 0.0992484837770462, Final Batch Loss: 0.06169511377811432\n",
      "Epoch 1486, Loss: 0.15310265123844147, Final Batch Loss: 0.13434720039367676\n",
      "Epoch 1487, Loss: 0.07049213722348213, Final Batch Loss: 0.05425312742590904\n",
      "Epoch 1488, Loss: 0.048007071018218994, Final Batch Loss: 0.02175295539200306\n",
      "Epoch 1489, Loss: 0.09355451911687851, Final Batch Loss: 0.03373747318983078\n",
      "Epoch 1490, Loss: 0.07352562434971333, Final Batch Loss: 0.012789176777005196\n",
      "Epoch 1491, Loss: 0.07538723945617676, Final Batch Loss: 0.03864101693034172\n",
      "Epoch 1492, Loss: 0.06754948385059834, Final Batch Loss: 0.0200513768941164\n",
      "Epoch 1493, Loss: 0.13015959411859512, Final Batch Loss: 0.05407501757144928\n",
      "Epoch 1494, Loss: 0.134999081492424, Final Batch Loss: 0.06255056709051132\n",
      "Epoch 1495, Loss: 0.06273302622139454, Final Batch Loss: 0.04046980291604996\n",
      "Epoch 1496, Loss: 0.09888060763478279, Final Batch Loss: 0.06196069344878197\n",
      "Epoch 1497, Loss: 0.11833829432725906, Final Batch Loss: 0.08463047444820404\n",
      "Epoch 1498, Loss: 0.10566791146993637, Final Batch Loss: 0.0655488669872284\n",
      "Epoch 1499, Loss: 0.11330245994031429, Final Batch Loss: 0.09764327853918076\n",
      "Epoch 1500, Loss: 0.04760515270754695, Final Batch Loss: 0.005515876691788435\n",
      "Epoch 1501, Loss: 0.05647246167063713, Final Batch Loss: 0.038134630769491196\n",
      "Epoch 1502, Loss: 0.05113852210342884, Final Batch Loss: 0.022333567962050438\n",
      "Epoch 1503, Loss: 0.07522203680127859, Final Batch Loss: 0.01506356056779623\n",
      "Epoch 1504, Loss: 0.11770210601389408, Final Batch Loss: 0.09145455807447433\n",
      "Epoch 1505, Loss: 0.09181118756532669, Final Batch Loss: 0.05349574610590935\n",
      "Epoch 1506, Loss: 0.06615563482046127, Final Batch Loss: 0.01705554500222206\n",
      "Epoch 1507, Loss: 0.06500667706131935, Final Batch Loss: 0.032996781170368195\n",
      "Epoch 1508, Loss: 0.07514600455760956, Final Batch Loss: 0.03821534663438797\n",
      "Epoch 1509, Loss: 0.0742675568908453, Final Batch Loss: 0.044896163046360016\n",
      "Epoch 1510, Loss: 0.0773186944425106, Final Batch Loss: 0.016215234994888306\n",
      "Epoch 1511, Loss: 0.0711444653570652, Final Batch Loss: 0.024359233677387238\n",
      "Epoch 1512, Loss: 0.06086151674389839, Final Batch Loss: 0.03136070817708969\n",
      "Epoch 1513, Loss: 0.07476423494517803, Final Batch Loss: 0.029268959537148476\n",
      "Epoch 1514, Loss: 0.08275826275348663, Final Batch Loss: 0.043360915035009384\n",
      "Epoch 1515, Loss: 0.057401346042752266, Final Batch Loss: 0.025223856791853905\n",
      "Epoch 1516, Loss: 0.10464897379279137, Final Batch Loss: 0.037089522927999496\n",
      "Epoch 1517, Loss: 0.07589559443295002, Final Batch Loss: 0.023497873917222023\n",
      "Epoch 1518, Loss: 0.1943592093884945, Final Batch Loss: 0.15220056474208832\n",
      "Epoch 1519, Loss: 0.11514324694871902, Final Batch Loss: 0.07766871899366379\n",
      "Epoch 1520, Loss: 0.11527984961867332, Final Batch Loss: 0.07005190849304199\n",
      "Epoch 1521, Loss: 0.07565906457602978, Final Batch Loss: 0.021629607304930687\n",
      "Epoch 1522, Loss: 0.15717291459441185, Final Batch Loss: 0.09925520420074463\n",
      "Epoch 1523, Loss: 0.06044800765812397, Final Batch Loss: 0.02867813967168331\n",
      "Epoch 1524, Loss: 0.12911415100097656, Final Batch Loss: 0.07768020033836365\n",
      "Epoch 1525, Loss: 0.09426488541066647, Final Batch Loss: 0.023125549778342247\n",
      "Epoch 1526, Loss: 0.10796200856566429, Final Batch Loss: 0.06925198435783386\n",
      "Epoch 1527, Loss: 0.05122215999290347, Final Batch Loss: 0.006994116585701704\n",
      "Epoch 1528, Loss: 0.10783985629677773, Final Batch Loss: 0.04480352625250816\n",
      "Epoch 1529, Loss: 0.11753793060779572, Final Batch Loss: 0.07631894946098328\n",
      "Epoch 1530, Loss: 0.09842499904334545, Final Batch Loss: 0.02094179205596447\n",
      "Epoch 1531, Loss: 0.06498397327959538, Final Batch Loss: 0.04822530597448349\n",
      "Epoch 1532, Loss: 0.19210681691765785, Final Batch Loss: 0.15716338157653809\n",
      "Epoch 1533, Loss: 0.23589516058564186, Final Batch Loss: 0.19611603021621704\n",
      "Epoch 1534, Loss: 0.08102897182106972, Final Batch Loss: 0.041049759835004807\n",
      "Epoch 1535, Loss: 0.056702954694628716, Final Batch Loss: 0.0378357470035553\n",
      "Epoch 1536, Loss: 0.05831320583820343, Final Batch Loss: 0.021172616630792618\n",
      "Epoch 1537, Loss: 0.11752913519740105, Final Batch Loss: 0.07482852041721344\n",
      "Epoch 1538, Loss: 0.06768731400370598, Final Batch Loss: 0.03508339449763298\n",
      "Epoch 1539, Loss: 0.10472705028951168, Final Batch Loss: 0.07513082027435303\n",
      "Epoch 1540, Loss: 0.057832811027765274, Final Batch Loss: 0.016053665429353714\n",
      "Epoch 1541, Loss: 0.07864006981253624, Final Batch Loss: 0.06473757326602936\n",
      "Epoch 1542, Loss: 0.06025377195328474, Final Batch Loss: 0.008111453615128994\n",
      "Epoch 1543, Loss: 0.06694123148918152, Final Batch Loss: 0.04262828081846237\n",
      "Epoch 1544, Loss: 0.08721113577485085, Final Batch Loss: 0.06829426437616348\n",
      "Epoch 1545, Loss: 0.051054004579782486, Final Batch Loss: 0.023826491087675095\n",
      "Epoch 1546, Loss: 0.10499894991517067, Final Batch Loss: 0.04832908511161804\n",
      "Epoch 1547, Loss: 0.09646890684962273, Final Batch Loss: 0.06653054803609848\n",
      "Epoch 1548, Loss: 0.0884111300110817, Final Batch Loss: 0.04647647961974144\n",
      "Epoch 1549, Loss: 0.0584817286580801, Final Batch Loss: 0.0359511561691761\n",
      "Epoch 1550, Loss: 0.10503530129790306, Final Batch Loss: 0.038063716143369675\n",
      "Epoch 1551, Loss: 0.07726673036813736, Final Batch Loss: 0.057271964848041534\n",
      "Epoch 1552, Loss: 0.06939138472080231, Final Batch Loss: 0.029626261442899704\n",
      "Epoch 1553, Loss: 0.047130512073636055, Final Batch Loss: 0.020957762375473976\n",
      "Epoch 1554, Loss: 0.059945736080408096, Final Batch Loss: 0.028376523405313492\n",
      "Epoch 1555, Loss: 0.0985499955713749, Final Batch Loss: 0.06217683479189873\n",
      "Epoch 1556, Loss: 0.05125093646347523, Final Batch Loss: 0.027559634298086166\n",
      "Epoch 1557, Loss: 0.05185845121741295, Final Batch Loss: 0.03264990448951721\n",
      "Epoch 1558, Loss: 0.08158722892403603, Final Batch Loss: 0.030328042805194855\n",
      "Epoch 1559, Loss: 0.06023054849356413, Final Batch Loss: 0.007939442060887814\n",
      "Epoch 1560, Loss: 0.06751058995723724, Final Batch Loss: 0.026516571640968323\n",
      "Epoch 1561, Loss: 0.0716998502612114, Final Batch Loss: 0.03803754225373268\n",
      "Epoch 1562, Loss: 0.05589591711759567, Final Batch Loss: 0.02230948582291603\n",
      "Epoch 1563, Loss: 0.0583347138017416, Final Batch Loss: 0.04693680256605148\n",
      "Epoch 1564, Loss: 0.08898819983005524, Final Batch Loss: 0.04633578658103943\n",
      "Epoch 1565, Loss: 0.08417412638664246, Final Batch Loss: 0.03636686131358147\n",
      "Epoch 1566, Loss: 0.044196607545018196, Final Batch Loss: 0.018780400976538658\n",
      "Epoch 1567, Loss: 0.07077967748045921, Final Batch Loss: 0.018939204514026642\n",
      "Epoch 1568, Loss: 0.03615656029433012, Final Batch Loss: 0.015433602966368198\n",
      "Epoch 1569, Loss: 0.051740145310759544, Final Batch Loss: 0.01624218188226223\n",
      "Epoch 1570, Loss: 0.11803068593144417, Final Batch Loss: 0.07356981188058853\n",
      "Epoch 1571, Loss: 0.11510570347309113, Final Batch Loss: 0.07190567255020142\n",
      "Epoch 1572, Loss: 0.0527143906801939, Final Batch Loss: 0.024295680224895477\n",
      "Epoch 1573, Loss: 0.07731547020375729, Final Batch Loss: 0.024845244362950325\n",
      "Epoch 1574, Loss: 0.14037291705608368, Final Batch Loss: 0.10013892501592636\n",
      "Epoch 1575, Loss: 0.07423042505979538, Final Batch Loss: 0.02100883424282074\n",
      "Epoch 1576, Loss: 0.050015851855278015, Final Batch Loss: 0.024983955547213554\n",
      "Epoch 1577, Loss: 0.046959700994193554, Final Batch Loss: 0.012192449532449245\n",
      "Epoch 1578, Loss: 0.04551715962588787, Final Batch Loss: 0.01622796803712845\n",
      "Epoch 1579, Loss: 0.10784322023391724, Final Batch Loss: 0.04419093579053879\n",
      "Epoch 1580, Loss: 0.05470093805342913, Final Batch Loss: 0.013703902252018452\n",
      "Epoch 1581, Loss: 0.06602467224001884, Final Batch Loss: 0.03337286785244942\n",
      "Epoch 1582, Loss: 0.0871206484735012, Final Batch Loss: 0.05796819552779198\n",
      "Epoch 1583, Loss: 0.08514989912509918, Final Batch Loss: 0.04138560965657234\n",
      "Epoch 1584, Loss: 0.12572574988007545, Final Batch Loss: 0.11243359744548798\n",
      "Epoch 1585, Loss: 0.09759875759482384, Final Batch Loss: 0.07462605834007263\n",
      "Epoch 1586, Loss: 0.04511918406933546, Final Batch Loss: 0.011489315889775753\n",
      "Epoch 1587, Loss: 0.07482198067009449, Final Batch Loss: 0.050535332411527634\n",
      "Epoch 1588, Loss: 0.07559669576585293, Final Batch Loss: 0.056829486042261124\n",
      "Epoch 1589, Loss: 0.08253771439194679, Final Batch Loss: 0.06872369349002838\n",
      "Epoch 1590, Loss: 0.08311985433101654, Final Batch Loss: 0.041570551693439484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1591, Loss: 0.05876798555254936, Final Batch Loss: 0.020011208951473236\n",
      "Epoch 1592, Loss: 0.07450888678431511, Final Batch Loss: 0.045983295887708664\n",
      "Epoch 1593, Loss: 0.06180951185524464, Final Batch Loss: 0.030508482828736305\n",
      "Epoch 1594, Loss: 0.07442612946033478, Final Batch Loss: 0.041694190353155136\n",
      "Epoch 1595, Loss: 0.09397954493761063, Final Batch Loss: 0.06160290911793709\n",
      "Epoch 1596, Loss: 0.08741942048072815, Final Batch Loss: 0.024794571101665497\n",
      "Epoch 1597, Loss: 0.11265011131763458, Final Batch Loss: 0.07578122615814209\n",
      "Epoch 1598, Loss: 0.09267235547304153, Final Batch Loss: 0.028188228607177734\n",
      "Epoch 1599, Loss: 0.049151523038744926, Final Batch Loss: 0.018275635316967964\n",
      "Epoch 1600, Loss: 0.054494697600603104, Final Batch Loss: 0.015902865678071976\n",
      "Epoch 1601, Loss: 0.09232830628752708, Final Batch Loss: 0.04762238264083862\n",
      "Epoch 1602, Loss: 0.038207344710826874, Final Batch Loss: 0.009159013628959656\n",
      "Epoch 1603, Loss: 0.05252197105437517, Final Batch Loss: 0.010014315135776997\n",
      "Epoch 1604, Loss: 0.08073215931653976, Final Batch Loss: 0.023956898599863052\n",
      "Epoch 1605, Loss: 0.10383243300020695, Final Batch Loss: 0.021415160968899727\n",
      "Epoch 1606, Loss: 0.033189764246344566, Final Batch Loss: 0.004550617188215256\n",
      "Epoch 1607, Loss: 0.13313095644116402, Final Batch Loss: 0.1064910814166069\n",
      "Epoch 1608, Loss: 0.05519355833530426, Final Batch Loss: 0.018067870289087296\n",
      "Epoch 1609, Loss: 0.05700673349201679, Final Batch Loss: 0.018612178042531013\n",
      "Epoch 1610, Loss: 0.0758308619260788, Final Batch Loss: 0.03780510649085045\n",
      "Epoch 1611, Loss: 0.04875908140093088, Final Batch Loss: 0.008992892690002918\n",
      "Epoch 1612, Loss: 0.06351078674197197, Final Batch Loss: 0.045528851449489594\n",
      "Epoch 1613, Loss: 0.10008867084980011, Final Batch Loss: 0.061942584812641144\n",
      "Epoch 1614, Loss: 0.04853263217955828, Final Batch Loss: 0.014724873937666416\n",
      "Epoch 1615, Loss: 0.036532001569867134, Final Batch Loss: 0.019063590094447136\n",
      "Epoch 1616, Loss: 0.06709589809179306, Final Batch Loss: 0.031494103372097015\n",
      "Epoch 1617, Loss: 0.15667210146784782, Final Batch Loss: 0.13054558634757996\n",
      "Epoch 1618, Loss: 0.06314793042838573, Final Batch Loss: 0.0280004795640707\n",
      "Epoch 1619, Loss: 0.09373006410896778, Final Batch Loss: 0.023058878257870674\n",
      "Epoch 1620, Loss: 0.08803959004580975, Final Batch Loss: 0.023880435153841972\n",
      "Epoch 1621, Loss: 0.046963268890976906, Final Batch Loss: 0.03438861295580864\n",
      "Epoch 1622, Loss: 0.08901854231953621, Final Batch Loss: 0.04310443997383118\n",
      "Epoch 1623, Loss: 0.06254678405821323, Final Batch Loss: 0.024695949628949165\n",
      "Epoch 1624, Loss: 0.1689291000366211, Final Batch Loss: 0.037131428718566895\n",
      "Epoch 1625, Loss: 0.06868511997163296, Final Batch Loss: 0.027769597247242928\n",
      "Epoch 1626, Loss: 0.10461217910051346, Final Batch Loss: 0.06622125953435898\n",
      "Epoch 1627, Loss: 0.08393672853708267, Final Batch Loss: 0.055447425693273544\n",
      "Epoch 1628, Loss: 0.04764748550951481, Final Batch Loss: 0.018737919628620148\n",
      "Epoch 1629, Loss: 0.17564598470926285, Final Batch Loss: 0.09714020043611526\n",
      "Epoch 1630, Loss: 0.07218246348202229, Final Batch Loss: 0.026760632172226906\n",
      "Epoch 1631, Loss: 0.09882383793592453, Final Batch Loss: 0.06938180327415466\n",
      "Epoch 1632, Loss: 0.07934300974011421, Final Batch Loss: 0.022359449416399002\n",
      "Epoch 1633, Loss: 0.08489580452442169, Final Batch Loss: 0.036877673119306564\n",
      "Epoch 1634, Loss: 0.054488303139805794, Final Batch Loss: 0.029615184292197227\n",
      "Epoch 1635, Loss: 0.0825817696750164, Final Batch Loss: 0.049503225833177567\n",
      "Epoch 1636, Loss: 0.05246925447136164, Final Batch Loss: 0.01239259634166956\n",
      "Epoch 1637, Loss: 0.10720228590071201, Final Batch Loss: 0.08267401903867722\n",
      "Epoch 1638, Loss: 0.11347939446568489, Final Batch Loss: 0.047438111156225204\n",
      "Epoch 1639, Loss: 0.08207454904913902, Final Batch Loss: 0.05403083562850952\n",
      "Epoch 1640, Loss: 0.16372589021921158, Final Batch Loss: 0.13845790922641754\n",
      "Epoch 1641, Loss: 0.09493578597903252, Final Batch Loss: 0.04769445210695267\n",
      "Epoch 1642, Loss: 0.09601728245615959, Final Batch Loss: 0.05720267817378044\n",
      "Epoch 1643, Loss: 0.15481385961174965, Final Batch Loss: 0.1118922159075737\n",
      "Epoch 1644, Loss: 0.11110762879252434, Final Batch Loss: 0.06267524510622025\n",
      "Epoch 1645, Loss: 0.05480678752064705, Final Batch Loss: 0.012867651879787445\n",
      "Epoch 1646, Loss: 0.05418263003230095, Final Batch Loss: 0.01808784157037735\n",
      "Epoch 1647, Loss: 0.07841385528445244, Final Batch Loss: 0.03817782923579216\n",
      "Epoch 1648, Loss: 0.15344289503991604, Final Batch Loss: 0.12644553184509277\n",
      "Epoch 1649, Loss: 0.08848954364657402, Final Batch Loss: 0.0502014234662056\n",
      "Epoch 1650, Loss: 0.08464155346155167, Final Batch Loss: 0.036626286804676056\n",
      "Epoch 1651, Loss: 0.170286126434803, Final Batch Loss: 0.13239338994026184\n",
      "Epoch 1652, Loss: 0.046694112941622734, Final Batch Loss: 0.024472611024975777\n",
      "Epoch 1653, Loss: 0.08885860443115234, Final Batch Loss: 0.03213832527399063\n",
      "Epoch 1654, Loss: 0.05219477415084839, Final Batch Loss: 0.01813526824116707\n",
      "Epoch 1655, Loss: 0.09423370286822319, Final Batch Loss: 0.04749322310090065\n",
      "Epoch 1656, Loss: 0.09496303088963032, Final Batch Loss: 0.021286653354763985\n",
      "Epoch 1657, Loss: 0.06389019265770912, Final Batch Loss: 0.021039791405200958\n",
      "Epoch 1658, Loss: 0.10202555730938911, Final Batch Loss: 0.045630697160959244\n",
      "Epoch 1659, Loss: 0.05393096059560776, Final Batch Loss: 0.026038600131869316\n",
      "Epoch 1660, Loss: 0.05141761526465416, Final Batch Loss: 0.02054060809314251\n",
      "Epoch 1661, Loss: 0.09187908470630646, Final Batch Loss: 0.04606812819838524\n",
      "Epoch 1662, Loss: 0.16868100501596928, Final Batch Loss: 0.02619401551783085\n",
      "Epoch 1663, Loss: 0.050752993673086166, Final Batch Loss: 0.02632647380232811\n",
      "Epoch 1664, Loss: 0.04625727981328964, Final Batch Loss: 0.01609201356768608\n",
      "Epoch 1665, Loss: 0.040244788862764835, Final Batch Loss: 0.007583186961710453\n",
      "Epoch 1666, Loss: 0.11505265161395073, Final Batch Loss: 0.0678897425532341\n",
      "Epoch 1667, Loss: 0.20804011449217796, Final Batch Loss: 0.15762878954410553\n",
      "Epoch 1668, Loss: 0.11085217446088791, Final Batch Loss: 0.040892213582992554\n",
      "Epoch 1669, Loss: 0.07560336217284203, Final Batch Loss: 0.01626979187130928\n",
      "Epoch 1670, Loss: 0.07246071100234985, Final Batch Loss: 0.051793329417705536\n",
      "Epoch 1671, Loss: 0.043740141205489635, Final Batch Loss: 0.008693299256265163\n",
      "Epoch 1672, Loss: 0.11817483603954315, Final Batch Loss: 0.04114653915166855\n",
      "Epoch 1673, Loss: 0.09175552241504192, Final Batch Loss: 0.026873109862208366\n",
      "Epoch 1674, Loss: 0.09405416622757912, Final Batch Loss: 0.048688795417547226\n",
      "Epoch 1675, Loss: 0.0750871542841196, Final Batch Loss: 0.0306453388184309\n",
      "Epoch 1676, Loss: 0.05975145101547241, Final Batch Loss: 0.02117006480693817\n",
      "Epoch 1677, Loss: 0.09640874713659286, Final Batch Loss: 0.07261490821838379\n",
      "Epoch 1678, Loss: 0.124549001455307, Final Batch Loss: 0.08701927214860916\n",
      "Epoch 1679, Loss: 0.0915110893547535, Final Batch Loss: 0.04085800424218178\n",
      "Epoch 1680, Loss: 0.11305327713489532, Final Batch Loss: 0.04169420897960663\n",
      "Epoch 1681, Loss: 0.09900633618235588, Final Batch Loss: 0.049733180552721024\n",
      "Epoch 1682, Loss: 0.1375092100352049, Final Batch Loss: 0.027176452800631523\n",
      "Epoch 1683, Loss: 0.07229792606085539, Final Batch Loss: 0.014548520557582378\n",
      "Epoch 1684, Loss: 0.09539607167243958, Final Batch Loss: 0.05569230765104294\n",
      "Epoch 1685, Loss: 0.07416324317455292, Final Batch Loss: 0.06134728714823723\n",
      "Epoch 1686, Loss: 0.034454005770385265, Final Batch Loss: 0.014451944269239902\n",
      "Epoch 1687, Loss: 0.15051186084747314, Final Batch Loss: 0.10719933360815048\n",
      "Epoch 1688, Loss: 0.08246375247836113, Final Batch Loss: 0.04279787093400955\n",
      "Epoch 1689, Loss: 0.12505922093987465, Final Batch Loss: 0.08499577641487122\n",
      "Epoch 1690, Loss: 0.05383208394050598, Final Batch Loss: 0.03086995705962181\n",
      "Epoch 1691, Loss: 0.08430669084191322, Final Batch Loss: 0.015042964369058609\n",
      "Epoch 1692, Loss: 0.10681547224521637, Final Batch Loss: 0.05226961150765419\n",
      "Epoch 1693, Loss: 0.16324269399046898, Final Batch Loss: 0.12056517601013184\n",
      "Epoch 1694, Loss: 0.14916235208511353, Final Batch Loss: 0.06315144151449203\n",
      "Epoch 1695, Loss: 0.06202986091375351, Final Batch Loss: 0.030255120247602463\n",
      "Epoch 1696, Loss: 0.06321170926094055, Final Batch Loss: 0.01593194529414177\n",
      "Epoch 1697, Loss: 0.07628382463008165, Final Batch Loss: 0.06214692443609238\n",
      "Epoch 1698, Loss: 0.07683979719877243, Final Batch Loss: 0.03842991963028908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1699, Loss: 0.049684700556099415, Final Batch Loss: 0.015029591508209705\n",
      "Epoch 1700, Loss: 0.05517617240548134, Final Batch Loss: 0.017489131540060043\n",
      "Epoch 1701, Loss: 0.08172874711453915, Final Batch Loss: 0.051760103553533554\n",
      "Epoch 1702, Loss: 0.1649298369884491, Final Batch Loss: 0.045280344784259796\n",
      "Epoch 1703, Loss: 0.063727717846632, Final Batch Loss: 0.022953946143388748\n",
      "Epoch 1704, Loss: 0.06668773852288723, Final Batch Loss: 0.02597896195948124\n",
      "Epoch 1705, Loss: 0.0480168629437685, Final Batch Loss: 0.010107936337590218\n",
      "Epoch 1706, Loss: 0.04341266956180334, Final Batch Loss: 0.01349994633346796\n",
      "Epoch 1707, Loss: 0.0375704076141119, Final Batch Loss: 0.012172937393188477\n",
      "Epoch 1708, Loss: 0.04072319716215134, Final Batch Loss: 0.01137830875813961\n",
      "Epoch 1709, Loss: 0.07344270125031471, Final Batch Loss: 0.04573819786310196\n",
      "Epoch 1710, Loss: 0.06657198071479797, Final Batch Loss: 0.04032913222908974\n",
      "Epoch 1711, Loss: 0.049404822289943695, Final Batch Loss: 0.01672588288784027\n",
      "Epoch 1712, Loss: 0.06573620811104774, Final Batch Loss: 0.03548738360404968\n",
      "Epoch 1713, Loss: 0.07856588996946812, Final Batch Loss: 0.0610349103808403\n",
      "Epoch 1714, Loss: 0.09099560976028442, Final Batch Loss: 0.05027414485812187\n",
      "Epoch 1715, Loss: 0.0708566065877676, Final Batch Loss: 0.04047343507409096\n",
      "Epoch 1716, Loss: 0.08863656595349312, Final Batch Loss: 0.0476561039686203\n",
      "Epoch 1717, Loss: 0.11481142789125443, Final Batch Loss: 0.09624995291233063\n",
      "Epoch 1718, Loss: 0.06189180165529251, Final Batch Loss: 0.0336821973323822\n",
      "Epoch 1719, Loss: 0.11658326536417007, Final Batch Loss: 0.06204862520098686\n",
      "Epoch 1720, Loss: 0.045987341552972794, Final Batch Loss: 0.01719740219414234\n",
      "Epoch 1721, Loss: 0.09770172834396362, Final Batch Loss: 0.06215820461511612\n",
      "Epoch 1722, Loss: 0.07129818759858608, Final Batch Loss: 0.04066341370344162\n",
      "Epoch 1723, Loss: 0.04574738349765539, Final Batch Loss: 0.010750426910817623\n",
      "Epoch 1724, Loss: 0.13013641349971294, Final Batch Loss: 0.10432898253202438\n",
      "Epoch 1725, Loss: 0.04699419625103474, Final Batch Loss: 0.01972110942006111\n",
      "Epoch 1726, Loss: 0.06401845067739487, Final Batch Loss: 0.023034971207380295\n",
      "Epoch 1727, Loss: 0.04799693450331688, Final Batch Loss: 0.02987205795943737\n",
      "Epoch 1728, Loss: 0.07605882547795773, Final Batch Loss: 0.05855420604348183\n",
      "Epoch 1729, Loss: 0.10728016123175621, Final Batch Loss: 0.07393071800470352\n",
      "Epoch 1730, Loss: 0.045656388625502586, Final Batch Loss: 0.015266742557287216\n",
      "Epoch 1731, Loss: 0.05596194416284561, Final Batch Loss: 0.019716739654541016\n",
      "Epoch 1732, Loss: 0.07347510382533073, Final Batch Loss: 0.043844908475875854\n",
      "Epoch 1733, Loss: 0.11257964745163918, Final Batch Loss: 0.03788004443049431\n",
      "Epoch 1734, Loss: 0.061478907242417336, Final Batch Loss: 0.027983447536826134\n",
      "Epoch 1735, Loss: 0.10266486741602421, Final Batch Loss: 0.08210810273885727\n",
      "Epoch 1736, Loss: 0.10182653367519379, Final Batch Loss: 0.06872238963842392\n",
      "Epoch 1737, Loss: 0.098048260435462, Final Batch Loss: 0.008536478504538536\n",
      "Epoch 1738, Loss: 0.08993574045598507, Final Batch Loss: 0.06105642020702362\n",
      "Epoch 1739, Loss: 0.08320658840239048, Final Batch Loss: 0.05443044379353523\n",
      "Epoch 1740, Loss: 0.05670708045363426, Final Batch Loss: 0.0237598717212677\n",
      "Epoch 1741, Loss: 0.09812404587864876, Final Batch Loss: 0.05475877225399017\n",
      "Epoch 1742, Loss: 0.05434880405664444, Final Batch Loss: 0.03858675807714462\n",
      "Epoch 1743, Loss: 0.04062436521053314, Final Batch Loss: 0.020099688321352005\n",
      "Epoch 1744, Loss: 0.06253713369369507, Final Batch Loss: 0.01868332549929619\n",
      "Epoch 1745, Loss: 0.056314594112336636, Final Batch Loss: 0.013946245424449444\n",
      "Epoch 1746, Loss: 0.040732305496931076, Final Batch Loss: 0.015885895118117332\n",
      "Epoch 1747, Loss: 0.11958697810769081, Final Batch Loss: 0.042349908500909805\n",
      "Epoch 1748, Loss: 0.08469253405928612, Final Batch Loss: 0.05538744106888771\n",
      "Epoch 1749, Loss: 0.04780155047774315, Final Batch Loss: 0.012962982058525085\n",
      "Epoch 1750, Loss: 0.08166077733039856, Final Batch Loss: 0.042003560811281204\n",
      "Epoch 1751, Loss: 0.033191404305398464, Final Batch Loss: 0.008456169627606869\n",
      "Epoch 1752, Loss: 0.049605902284383774, Final Batch Loss: 0.013698283582925797\n",
      "Epoch 1753, Loss: 0.046643611043691635, Final Batch Loss: 0.021472791209816933\n",
      "Epoch 1754, Loss: 0.04325514193624258, Final Batch Loss: 0.009285314939916134\n",
      "Epoch 1755, Loss: 0.037458092905581, Final Batch Loss: 0.007514880038797855\n",
      "Epoch 1756, Loss: 0.0741735827177763, Final Batch Loss: 0.05818769335746765\n",
      "Epoch 1757, Loss: 0.03158268611878157, Final Batch Loss: 0.009082757867872715\n",
      "Epoch 1758, Loss: 0.0494717713445425, Final Batch Loss: 0.030899912118911743\n",
      "Epoch 1759, Loss: 0.07398650236427784, Final Batch Loss: 0.04725011810660362\n",
      "Epoch 1760, Loss: 0.05074867606163025, Final Batch Loss: 0.021233322098851204\n",
      "Epoch 1761, Loss: 0.08349974639713764, Final Batch Loss: 0.0600610189139843\n",
      "Epoch 1762, Loss: 0.059543734416365623, Final Batch Loss: 0.04440959542989731\n",
      "Epoch 1763, Loss: 0.0671585462987423, Final Batch Loss: 0.023470770567655563\n",
      "Epoch 1764, Loss: 0.07607358321547508, Final Batch Loss: 0.042539212852716446\n",
      "Epoch 1765, Loss: 0.12858964502811432, Final Batch Loss: 0.08240706473588943\n",
      "Epoch 1766, Loss: 0.027310028672218323, Final Batch Loss: 0.011217951774597168\n",
      "Epoch 1767, Loss: 0.0737559124827385, Final Batch Loss: 0.041639670729637146\n",
      "Epoch 1768, Loss: 0.03548810817301273, Final Batch Loss: 0.006691267713904381\n",
      "Epoch 1769, Loss: 0.02897525765001774, Final Batch Loss: 0.007525596767663956\n",
      "Epoch 1770, Loss: 0.05681023932993412, Final Batch Loss: 0.036348823457956314\n",
      "Epoch 1771, Loss: 0.10171537846326828, Final Batch Loss: 0.08233009278774261\n",
      "Epoch 1772, Loss: 0.13130251690745354, Final Batch Loss: 0.08151499181985855\n",
      "Epoch 1773, Loss: 0.07996664335951209, Final Batch Loss: 0.006164455320686102\n",
      "Epoch 1774, Loss: 0.06444110721349716, Final Batch Loss: 0.03097422793507576\n",
      "Epoch 1775, Loss: 0.06123790517449379, Final Batch Loss: 0.010183557868003845\n",
      "Epoch 1776, Loss: 0.055505696684122086, Final Batch Loss: 0.038363855332136154\n",
      "Epoch 1777, Loss: 0.0718122273683548, Final Batch Loss: 0.04037275165319443\n",
      "Epoch 1778, Loss: 0.03859147056937218, Final Batch Loss: 0.012936504557728767\n",
      "Epoch 1779, Loss: 0.06346835661679506, Final Batch Loss: 0.009354074485599995\n",
      "Epoch 1780, Loss: 0.03896298632025719, Final Batch Loss: 0.016481872648000717\n",
      "Epoch 1781, Loss: 0.07860294356942177, Final Batch Loss: 0.04756181687116623\n",
      "Epoch 1782, Loss: 0.05795917101204395, Final Batch Loss: 0.03913705796003342\n",
      "Epoch 1783, Loss: 0.05338659510016441, Final Batch Loss: 0.0224345363676548\n",
      "Epoch 1784, Loss: 0.03430215269327164, Final Batch Loss: 0.015675771981477737\n",
      "Epoch 1785, Loss: 0.06414732150733471, Final Batch Loss: 0.039649009704589844\n",
      "Epoch 1786, Loss: 0.041689127683639526, Final Batch Loss: 0.024601751938462257\n",
      "Epoch 1787, Loss: 0.03462536912411451, Final Batch Loss: 0.009588985703885555\n",
      "Epoch 1788, Loss: 0.04171731695532799, Final Batch Loss: 0.017786743119359016\n",
      "Epoch 1789, Loss: 0.08491828665137291, Final Batch Loss: 0.032837625592947006\n",
      "Epoch 1790, Loss: 0.05868948623538017, Final Batch Loss: 0.022838428616523743\n",
      "Epoch 1791, Loss: 0.030028240755200386, Final Batch Loss: 0.007987190037965775\n",
      "Epoch 1792, Loss: 0.05250258557498455, Final Batch Loss: 0.034463413059711456\n",
      "Epoch 1793, Loss: 0.04253975860774517, Final Batch Loss: 0.02657410502433777\n",
      "Epoch 1794, Loss: 0.06732067838311195, Final Batch Loss: 0.048380833119153976\n",
      "Epoch 1795, Loss: 0.06342166848480701, Final Batch Loss: 0.009669104591012001\n",
      "Epoch 1796, Loss: 0.08398567885160446, Final Batch Loss: 0.05185215547680855\n",
      "Epoch 1797, Loss: 0.09666956961154938, Final Batch Loss: 0.04042734578251839\n",
      "Epoch 1798, Loss: 0.049877954646945, Final Batch Loss: 0.021766846999526024\n",
      "Epoch 1799, Loss: 0.09880494698882103, Final Batch Loss: 0.04029737785458565\n",
      "Epoch 1800, Loss: 0.1108977384865284, Final Batch Loss: 0.05843982845544815\n",
      "Epoch 1801, Loss: 0.08540730364620686, Final Batch Loss: 0.024396775290369987\n",
      "Epoch 1802, Loss: 0.03224960993975401, Final Batch Loss: 0.013765306212008\n",
      "Epoch 1803, Loss: 0.052544403821229935, Final Batch Loss: 0.02281971089541912\n",
      "Epoch 1804, Loss: 0.034037006087601185, Final Batch Loss: 0.010672996751964092\n",
      "Epoch 1805, Loss: 0.08810682967305183, Final Batch Loss: 0.02833208441734314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1806, Loss: 0.039770876057446, Final Batch Loss: 0.008530602790415287\n",
      "Epoch 1807, Loss: 0.04211989603936672, Final Batch Loss: 0.01827479898929596\n",
      "Epoch 1808, Loss: 0.031106356997042894, Final Batch Loss: 0.005560186225920916\n",
      "Epoch 1809, Loss: 0.06477683596313, Final Batch Loss: 0.024453116580843925\n",
      "Epoch 1810, Loss: 0.026831998489797115, Final Batch Loss: 0.005416630767285824\n",
      "Epoch 1811, Loss: 0.04152161814272404, Final Batch Loss: 0.010870261117815971\n",
      "Epoch 1812, Loss: 0.07558895740658045, Final Batch Loss: 0.061075787991285324\n",
      "Epoch 1813, Loss: 0.09494559466838837, Final Batch Loss: 0.04772688075900078\n",
      "Epoch 1814, Loss: 0.04609661363065243, Final Batch Loss: 0.015737323090434074\n",
      "Epoch 1815, Loss: 0.07343731820583344, Final Batch Loss: 0.056408029049634933\n",
      "Epoch 1816, Loss: 0.06552225537598133, Final Batch Loss: 0.040614694356918335\n",
      "Epoch 1817, Loss: 0.028185861185193062, Final Batch Loss: 0.013206837698817253\n",
      "Epoch 1818, Loss: 0.046525243669748306, Final Batch Loss: 0.009056426584720612\n",
      "Epoch 1819, Loss: 0.04268609546124935, Final Batch Loss: 0.01179654709994793\n",
      "Epoch 1820, Loss: 0.04485117644071579, Final Batch Loss: 0.02638973854482174\n",
      "Epoch 1821, Loss: 0.0975433997809887, Final Batch Loss: 0.0572279617190361\n",
      "Epoch 1822, Loss: 0.0344696925021708, Final Batch Loss: 0.007170524913817644\n",
      "Epoch 1823, Loss: 0.046891575679183006, Final Batch Loss: 0.03132380172610283\n",
      "Epoch 1824, Loss: 0.03306553792208433, Final Batch Loss: 0.012292607687413692\n",
      "Epoch 1825, Loss: 0.04972684755921364, Final Batch Loss: 0.012277837842702866\n",
      "Epoch 1826, Loss: 0.08546094596385956, Final Batch Loss: 0.044368285685777664\n",
      "Epoch 1827, Loss: 0.08252665773034096, Final Batch Loss: 0.05151548981666565\n",
      "Epoch 1828, Loss: 0.048216281458735466, Final Batch Loss: 0.015732085332274437\n",
      "Epoch 1829, Loss: 0.08024036698043346, Final Batch Loss: 0.022664038464426994\n",
      "Epoch 1830, Loss: 0.029220801778137684, Final Batch Loss: 0.014128333888947964\n",
      "Epoch 1831, Loss: 0.04701916640624404, Final Batch Loss: 0.006175061222165823\n",
      "Epoch 1832, Loss: 0.07047625258564949, Final Batch Loss: 0.031390588730573654\n",
      "Epoch 1833, Loss: 0.04569288529455662, Final Batch Loss: 0.020572969689965248\n",
      "Epoch 1834, Loss: 0.04375338926911354, Final Batch Loss: 0.018073249608278275\n",
      "Epoch 1835, Loss: 0.050186121836304665, Final Batch Loss: 0.010806428268551826\n",
      "Epoch 1836, Loss: 0.1507286410778761, Final Batch Loss: 0.122137650847435\n",
      "Epoch 1837, Loss: 0.1459465827792883, Final Batch Loss: 0.12733526527881622\n",
      "Epoch 1838, Loss: 0.058630380779504776, Final Batch Loss: 0.010418333113193512\n",
      "Epoch 1839, Loss: 0.06642964482307434, Final Batch Loss: 0.033339545130729675\n",
      "Epoch 1840, Loss: 0.05820767767727375, Final Batch Loss: 0.02689908631145954\n",
      "Epoch 1841, Loss: 0.1596771404147148, Final Batch Loss: 0.08722139894962311\n",
      "Epoch 1842, Loss: 0.20307156443595886, Final Batch Loss: 0.13035954535007477\n",
      "Epoch 1843, Loss: 0.07508073002099991, Final Batch Loss: 0.03842804953455925\n",
      "Epoch 1844, Loss: 0.08423365838825703, Final Batch Loss: 0.01860053278505802\n",
      "Epoch 1845, Loss: 0.06370118819177151, Final Batch Loss: 0.024227449670433998\n",
      "Epoch 1846, Loss: 0.106654342263937, Final Batch Loss: 0.04742636904120445\n",
      "Epoch 1847, Loss: 0.11998634785413742, Final Batch Loss: 0.06860998272895813\n",
      "Epoch 1848, Loss: 0.05065453052520752, Final Batch Loss: 0.017732687294483185\n",
      "Epoch 1849, Loss: 0.05662100948393345, Final Batch Loss: 0.04568322375416756\n",
      "Epoch 1850, Loss: 0.08359260857105255, Final Batch Loss: 0.05826065316796303\n",
      "Epoch 1851, Loss: 0.0767432413995266, Final Batch Loss: 0.05120009928941727\n",
      "Epoch 1852, Loss: 0.11349129676818848, Final Batch Loss: 0.07554896175861359\n",
      "Epoch 1853, Loss: 0.13262027129530907, Final Batch Loss: 0.07640107721090317\n",
      "Epoch 1854, Loss: 0.09659502655267715, Final Batch Loss: 0.070750892162323\n",
      "Epoch 1855, Loss: 0.06953145191073418, Final Batch Loss: 0.03707316145300865\n",
      "Epoch 1856, Loss: 0.16876452416181564, Final Batch Loss: 0.14811167120933533\n",
      "Epoch 1857, Loss: 0.0813846979290247, Final Batch Loss: 0.026942605152726173\n",
      "Epoch 1858, Loss: 0.1361352801322937, Final Batch Loss: 0.06950629502534866\n",
      "Epoch 1859, Loss: 0.13136644288897514, Final Batch Loss: 0.03780465945601463\n",
      "Epoch 1860, Loss: 0.10490229353308678, Final Batch Loss: 0.02892981842160225\n",
      "Epoch 1861, Loss: 0.10052365064620972, Final Batch Loss: 0.053844962269067764\n",
      "Epoch 1862, Loss: 0.09142959490418434, Final Batch Loss: 0.04134763777256012\n",
      "Epoch 1863, Loss: 0.12064944952726364, Final Batch Loss: 0.08764687180519104\n",
      "Epoch 1864, Loss: 0.04588382504880428, Final Batch Loss: 0.012871822342276573\n",
      "Epoch 1865, Loss: 0.06995735689997673, Final Batch Loss: 0.02381587028503418\n",
      "Epoch 1866, Loss: 0.144290953874588, Final Batch Loss: 0.09350501000881195\n",
      "Epoch 1867, Loss: 0.08184625580906868, Final Batch Loss: 0.03635602071881294\n",
      "Epoch 1868, Loss: 0.13259337656199932, Final Batch Loss: 0.10433164983987808\n",
      "Epoch 1869, Loss: 0.10028399899601936, Final Batch Loss: 0.036168161779642105\n",
      "Epoch 1870, Loss: 0.0883059948682785, Final Batch Loss: 0.024792499840259552\n",
      "Epoch 1871, Loss: 0.12739839777350426, Final Batch Loss: 0.07601353526115417\n",
      "Epoch 1872, Loss: 0.11199380084872246, Final Batch Loss: 0.07847390323877335\n",
      "Epoch 1873, Loss: 0.09383676573634148, Final Batch Loss: 0.06146037578582764\n",
      "Epoch 1874, Loss: 0.1409360095858574, Final Batch Loss: 0.06331688910722733\n",
      "Epoch 1875, Loss: 0.06407249066978693, Final Batch Loss: 0.008997955359518528\n",
      "Epoch 1876, Loss: 0.10089732334017754, Final Batch Loss: 0.05875773727893829\n",
      "Epoch 1877, Loss: 0.058323927223682404, Final Batch Loss: 0.016196776181459427\n",
      "Epoch 1878, Loss: 0.07627860084176064, Final Batch Loss: 0.028864406049251556\n",
      "Epoch 1879, Loss: 0.11975660175085068, Final Batch Loss: 0.05228372663259506\n",
      "Epoch 1880, Loss: 0.14403760433197021, Final Batch Loss: 0.09626150876283646\n",
      "Epoch 1881, Loss: 0.06201462261378765, Final Batch Loss: 0.01670813001692295\n",
      "Epoch 1882, Loss: 0.07800648547708988, Final Batch Loss: 0.019041193649172783\n",
      "Epoch 1883, Loss: 0.08978493139147758, Final Batch Loss: 0.047329556196928024\n",
      "Epoch 1884, Loss: 0.07459399662911892, Final Batch Loss: 0.05100652202963829\n",
      "Epoch 1885, Loss: 0.07334560342133045, Final Batch Loss: 0.053466010838747025\n",
      "Epoch 1886, Loss: 0.07995386607944965, Final Batch Loss: 0.027937615290284157\n",
      "Epoch 1887, Loss: 0.09559342637658119, Final Batch Loss: 0.05038365721702576\n",
      "Epoch 1888, Loss: 0.15149586275219917, Final Batch Loss: 0.09640519320964813\n",
      "Epoch 1889, Loss: 0.08617913350462914, Final Batch Loss: 0.04101581126451492\n",
      "Epoch 1890, Loss: 0.058736274018883705, Final Batch Loss: 0.017808498814702034\n",
      "Epoch 1891, Loss: 0.09291544929146767, Final Batch Loss: 0.06479808688163757\n",
      "Epoch 1892, Loss: 0.0652898233383894, Final Batch Loss: 0.019203828647732735\n",
      "Epoch 1893, Loss: 0.09854881092905998, Final Batch Loss: 0.056000519543886185\n",
      "Epoch 1894, Loss: 0.07381699047982693, Final Batch Loss: 0.05548772215843201\n",
      "Epoch 1895, Loss: 0.058318860828876495, Final Batch Loss: 0.012876328080892563\n",
      "Epoch 1896, Loss: 0.11025324929505587, Final Batch Loss: 0.008518916554749012\n",
      "Epoch 1897, Loss: 0.06004618480801582, Final Batch Loss: 0.030123751610517502\n",
      "Epoch 1898, Loss: 0.05165698751807213, Final Batch Loss: 0.03182637691497803\n",
      "Epoch 1899, Loss: 0.07016954384744167, Final Batch Loss: 0.04502033442258835\n",
      "Epoch 1900, Loss: 0.09537550434470177, Final Batch Loss: 0.05664151534438133\n",
      "Epoch 1901, Loss: 0.07270960416644812, Final Batch Loss: 0.005176610313355923\n",
      "Epoch 1902, Loss: 0.04546073265373707, Final Batch Loss: 0.03002554178237915\n",
      "Epoch 1903, Loss: 0.0452898433431983, Final Batch Loss: 0.008000544272363186\n",
      "Epoch 1904, Loss: 0.05132001917809248, Final Batch Loss: 0.011419224552810192\n",
      "Epoch 1905, Loss: 0.061703069135546684, Final Batch Loss: 0.01746702380478382\n",
      "Epoch 1906, Loss: 0.08477012999355793, Final Batch Loss: 0.014946626499295235\n",
      "Epoch 1907, Loss: 0.06814026087522507, Final Batch Loss: 0.03502886742353439\n",
      "Epoch 1908, Loss: 0.04287145845592022, Final Batch Loss: 0.016052180901169777\n",
      "Epoch 1909, Loss: 0.06641659885644913, Final Batch Loss: 0.03310074657201767\n",
      "Epoch 1910, Loss: 0.04527194704860449, Final Batch Loss: 0.03292245790362358\n",
      "Epoch 1911, Loss: 0.042419662699103355, Final Batch Loss: 0.018867766484618187\n",
      "Epoch 1912, Loss: 0.059381574392318726, Final Batch Loss: 0.01928822323679924\n",
      "Epoch 1913, Loss: 0.046347422525286674, Final Batch Loss: 0.021056365221738815\n",
      "Epoch 1914, Loss: 0.12170317396521568, Final Batch Loss: 0.016913454979658127\n",
      "Epoch 1915, Loss: 0.060895660892128944, Final Batch Loss: 0.026805145666003227\n",
      "Epoch 1916, Loss: 0.06817536801099777, Final Batch Loss: 0.048502445220947266\n",
      "Epoch 1917, Loss: 0.08180109411478043, Final Batch Loss: 0.04813549295067787\n",
      "Epoch 1918, Loss: 0.19294659048318863, Final Batch Loss: 0.14999288320541382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1919, Loss: 0.08124800585210323, Final Batch Loss: 0.050980303436517715\n",
      "Epoch 1920, Loss: 0.07580313086509705, Final Batch Loss: 0.03266783058643341\n",
      "Epoch 1921, Loss: 0.030362197197973728, Final Batch Loss: 0.009386998601257801\n",
      "Epoch 1922, Loss: 0.04171196464449167, Final Batch Loss: 0.01268982794135809\n",
      "Epoch 1923, Loss: 0.034102048724889755, Final Batch Loss: 0.006962129846215248\n",
      "Epoch 1924, Loss: 0.06233723647892475, Final Batch Loss: 0.03635699301958084\n",
      "Epoch 1925, Loss: 0.05041223857551813, Final Batch Loss: 0.006861389614641666\n",
      "Epoch 1926, Loss: 0.08597549423575401, Final Batch Loss: 0.054286401718854904\n",
      "Epoch 1927, Loss: 0.04025790747255087, Final Batch Loss: 0.025601908564567566\n",
      "Epoch 1928, Loss: 0.03293792251497507, Final Batch Loss: 0.013560541905462742\n",
      "Epoch 1929, Loss: 0.060866961255669594, Final Batch Loss: 0.03799848258495331\n",
      "Epoch 1930, Loss: 0.045812548603862524, Final Batch Loss: 0.006199853029102087\n",
      "Epoch 1931, Loss: 0.029051024466753006, Final Batch Loss: 0.010697022080421448\n",
      "Epoch 1932, Loss: 0.05629399232566357, Final Batch Loss: 0.029289331287145615\n",
      "Epoch 1933, Loss: 0.060433617793023586, Final Batch Loss: 0.009271717630326748\n",
      "Epoch 1934, Loss: 0.04324376583099365, Final Batch Loss: 0.020527096465229988\n",
      "Epoch 1935, Loss: 0.04882828611880541, Final Batch Loss: 0.014375009573996067\n",
      "Epoch 1936, Loss: 0.07254382967948914, Final Batch Loss: 0.03901025280356407\n",
      "Epoch 1937, Loss: 0.030425718054175377, Final Batch Loss: 0.00556858628988266\n",
      "Epoch 1938, Loss: 0.08543050661683083, Final Batch Loss: 0.04399940371513367\n",
      "Epoch 1939, Loss: 0.04497234243899584, Final Batch Loss: 0.012572993524372578\n",
      "Epoch 1940, Loss: 0.10093766078352928, Final Batch Loss: 0.06186879426240921\n",
      "Epoch 1941, Loss: 0.16008050926029682, Final Batch Loss: 0.13216103613376617\n",
      "Epoch 1942, Loss: 0.050070120953023434, Final Batch Loss: 0.009297690354287624\n",
      "Epoch 1943, Loss: 0.08171896263957024, Final Batch Loss: 0.06153840944170952\n",
      "Epoch 1944, Loss: 0.044610532000660896, Final Batch Loss: 0.03464469313621521\n",
      "Epoch 1945, Loss: 0.046378825791180134, Final Batch Loss: 0.03352736681699753\n",
      "Epoch 1946, Loss: 0.03948257677257061, Final Batch Loss: 0.014413952827453613\n",
      "Epoch 1947, Loss: 0.06724350526928902, Final Batch Loss: 0.02010798454284668\n",
      "Epoch 1948, Loss: 0.1215423196554184, Final Batch Loss: 0.0142640620470047\n",
      "Epoch 1949, Loss: 0.1603375393897295, Final Batch Loss: 0.14182217419147491\n",
      "Epoch 1950, Loss: 0.03509929217398167, Final Batch Loss: 0.009591838344931602\n",
      "Epoch 1951, Loss: 0.04311520978808403, Final Batch Loss: 0.01621631719172001\n",
      "Epoch 1952, Loss: 0.06352214515209198, Final Batch Loss: 0.03658735752105713\n",
      "Epoch 1953, Loss: 0.03413291089236736, Final Batch Loss: 0.01029161550104618\n",
      "Epoch 1954, Loss: 0.056062756571918726, Final Batch Loss: 0.006852178368717432\n",
      "Epoch 1955, Loss: 0.06954727694392204, Final Batch Loss: 0.04635973647236824\n",
      "Epoch 1956, Loss: 0.04962992109358311, Final Batch Loss: 0.019147370010614395\n",
      "Epoch 1957, Loss: 0.08516075741499662, Final Batch Loss: 0.015041629783809185\n",
      "Epoch 1958, Loss: 0.049758318811655045, Final Batch Loss: 0.009700875729322433\n",
      "Epoch 1959, Loss: 0.04186301305890083, Final Batch Loss: 0.009510401636362076\n",
      "Epoch 1960, Loss: 0.1268225759267807, Final Batch Loss: 0.11851435899734497\n",
      "Epoch 1961, Loss: 0.061054449528455734, Final Batch Loss: 0.03802871331572533\n",
      "Epoch 1962, Loss: 0.03973407670855522, Final Batch Loss: 0.021793173626065254\n",
      "Epoch 1963, Loss: 0.060406241565942764, Final Batch Loss: 0.037553753703832626\n",
      "Epoch 1964, Loss: 0.055306216701865196, Final Batch Loss: 0.00990290753543377\n",
      "Epoch 1965, Loss: 0.05144902504980564, Final Batch Loss: 0.02034081518650055\n",
      "Epoch 1966, Loss: 0.05681588780134916, Final Batch Loss: 0.04425019025802612\n",
      "Epoch 1967, Loss: 0.05416104895994067, Final Batch Loss: 0.006114497315138578\n",
      "Epoch 1968, Loss: 0.06828282214701176, Final Batch Loss: 0.030994942411780357\n",
      "Epoch 1969, Loss: 0.07601673901081085, Final Batch Loss: 0.05230102688074112\n",
      "Epoch 1970, Loss: 0.03755710832774639, Final Batch Loss: 0.02138887532055378\n",
      "Epoch 1971, Loss: 0.023714618757367134, Final Batch Loss: 0.008987079374492168\n",
      "Epoch 1972, Loss: 0.03726506233215332, Final Batch Loss: 0.018209945410490036\n",
      "Epoch 1973, Loss: 0.03823655750602484, Final Batch Loss: 0.014756173826754093\n",
      "Epoch 1974, Loss: 0.06373356003314257, Final Batch Loss: 0.05212922394275665\n",
      "Epoch 1975, Loss: 0.07116195186972618, Final Batch Loss: 0.05227359011769295\n",
      "Epoch 1976, Loss: 0.11400121822953224, Final Batch Loss: 0.07092275470495224\n",
      "Epoch 1977, Loss: 0.029523270670324564, Final Batch Loss: 0.004113514441996813\n",
      "Epoch 1978, Loss: 0.03076896443963051, Final Batch Loss: 0.004679346457123756\n",
      "Epoch 1979, Loss: 0.05162480752915144, Final Batch Loss: 0.036351654678583145\n",
      "Epoch 1980, Loss: 0.08620350807905197, Final Batch Loss: 0.045015495270490646\n",
      "Epoch 1981, Loss: 0.03261964721605182, Final Batch Loss: 0.0032192091457545757\n",
      "Epoch 1982, Loss: 0.0849483422935009, Final Batch Loss: 0.03917734697461128\n",
      "Epoch 1983, Loss: 0.03242106083780527, Final Batch Loss: 0.017016900703310966\n",
      "Epoch 1984, Loss: 0.09849271178245544, Final Batch Loss: 0.06002475321292877\n",
      "Epoch 1985, Loss: 0.035605101846158504, Final Batch Loss: 0.014333597384393215\n",
      "Epoch 1986, Loss: 0.062247540801763535, Final Batch Loss: 0.03771306946873665\n",
      "Epoch 1987, Loss: 0.047952624037861824, Final Batch Loss: 0.026780160143971443\n",
      "Epoch 1988, Loss: 0.03758783359080553, Final Batch Loss: 0.01038361992686987\n",
      "Epoch 1989, Loss: 0.0396926449611783, Final Batch Loss: 0.009860982187092304\n",
      "Epoch 1990, Loss: 0.03444784693419933, Final Batch Loss: 0.01800551638007164\n",
      "Epoch 1991, Loss: 0.03911088965833187, Final Batch Loss: 0.017192324623465538\n",
      "Epoch 1992, Loss: 0.04798358678817749, Final Batch Loss: 0.03462694585323334\n",
      "Epoch 1993, Loss: 0.041422655805945396, Final Batch Loss: 0.02004055120050907\n",
      "Epoch 1994, Loss: 0.043411506339907646, Final Batch Loss: 0.015246005728840828\n",
      "Epoch 1995, Loss: 0.10900031495839357, Final Batch Loss: 0.011166763491928577\n",
      "Epoch 1996, Loss: 0.07064930163323879, Final Batch Loss: 0.057926762849092484\n",
      "Epoch 1997, Loss: 0.062362879514694214, Final Batch Loss: 0.04714898392558098\n",
      "Epoch 1998, Loss: 0.06159125827252865, Final Batch Loss: 0.04113639146089554\n",
      "Epoch 1999, Loss: 0.04743267688900232, Final Batch Loss: 0.0348028726875782\n",
      "Epoch 2000, Loss: 0.05245787277817726, Final Batch Loss: 0.03839384391903877\n",
      "Epoch 2001, Loss: 0.037281558848917484, Final Batch Loss: 0.02313016541302204\n",
      "Epoch 2002, Loss: 0.04166154004633427, Final Batch Loss: 0.027634602040052414\n",
      "Epoch 2003, Loss: 0.06380618177354336, Final Batch Loss: 0.019165175035595894\n",
      "Epoch 2004, Loss: 0.04982607625424862, Final Batch Loss: 0.02295384183526039\n",
      "Epoch 2005, Loss: 0.03375262673944235, Final Batch Loss: 0.013653707690536976\n",
      "Epoch 2006, Loss: 0.03492974769324064, Final Batch Loss: 0.012156042270362377\n",
      "Epoch 2007, Loss: 0.08493084087967873, Final Batch Loss: 0.05209445208311081\n",
      "Epoch 2008, Loss: 0.027404841035604477, Final Batch Loss: 0.004284979775547981\n",
      "Epoch 2009, Loss: 0.04292241670191288, Final Batch Loss: 0.010100802406668663\n",
      "Epoch 2010, Loss: 0.06621683668345213, Final Batch Loss: 0.010876662097871304\n",
      "Epoch 2011, Loss: 0.058406601659953594, Final Batch Loss: 0.009504630230367184\n",
      "Epoch 2012, Loss: 0.04501979053020477, Final Batch Loss: 0.006784949451684952\n",
      "Epoch 2013, Loss: 0.0345435319468379, Final Batch Loss: 0.01324519608169794\n",
      "Epoch 2014, Loss: 0.08981427364051342, Final Batch Loss: 0.06306588649749756\n",
      "Epoch 2015, Loss: 0.027777683455497026, Final Batch Loss: 0.005867178086191416\n",
      "Epoch 2016, Loss: 0.03172309044748545, Final Batch Loss: 0.010626873932778835\n",
      "Epoch 2017, Loss: 0.037383243441581726, Final Batch Loss: 0.00612722709774971\n",
      "Epoch 2018, Loss: 0.038748749531805515, Final Batch Loss: 0.01498096901923418\n",
      "Epoch 2019, Loss: 0.08511877246201038, Final Batch Loss: 0.06997276842594147\n",
      "Epoch 2020, Loss: 0.02970831375569105, Final Batch Loss: 0.008521073497831821\n",
      "Epoch 2021, Loss: 0.07755731046199799, Final Batch Loss: 0.03485599905252457\n",
      "Epoch 2022, Loss: 0.05470721051096916, Final Batch Loss: 0.01506631076335907\n",
      "Epoch 2023, Loss: 0.04645236395299435, Final Batch Loss: 0.01790883019566536\n",
      "Epoch 2024, Loss: 0.035973100923001766, Final Batch Loss: 0.00940911378711462\n",
      "Epoch 2025, Loss: 0.07949952222406864, Final Batch Loss: 0.0530133955180645\n",
      "Epoch 2026, Loss: 0.06813059002161026, Final Batch Loss: 0.03641849011182785\n",
      "Epoch 2027, Loss: 0.050500815734267235, Final Batch Loss: 0.03225965052843094\n",
      "Epoch 2028, Loss: 0.06338127516210079, Final Batch Loss: 0.0290606040507555\n",
      "Epoch 2029, Loss: 0.08098283782601357, Final Batch Loss: 0.05526202917098999\n",
      "Epoch 2030, Loss: 0.08382032439112663, Final Batch Loss: 0.0655403733253479\n",
      "Epoch 2031, Loss: 0.036050659604370594, Final Batch Loss: 0.024521678686141968\n",
      "Epoch 2032, Loss: 0.07461969740688801, Final Batch Loss: 0.030820513144135475\n",
      "Epoch 2033, Loss: 0.04167793598026037, Final Batch Loss: 0.029428310692310333\n",
      "Epoch 2034, Loss: 0.03864782303571701, Final Batch Loss: 0.016768241301178932\n",
      "Epoch 2035, Loss: 0.11059348843991756, Final Batch Loss: 0.021037956699728966\n",
      "Epoch 2036, Loss: 0.04471882898360491, Final Batch Loss: 0.011991688050329685\n",
      "Epoch 2037, Loss: 0.09930866118520498, Final Batch Loss: 0.08561471104621887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2038, Loss: 0.05136854760348797, Final Batch Loss: 0.012932626530528069\n",
      "Epoch 2039, Loss: 0.06953294947743416, Final Batch Loss: 0.0341508723795414\n",
      "Epoch 2040, Loss: 0.04272639751434326, Final Batch Loss: 0.01056041568517685\n",
      "Epoch 2041, Loss: 0.14799074083566666, Final Batch Loss: 0.11153946071863174\n",
      "Epoch 2042, Loss: 0.0241836067289114, Final Batch Loss: 0.007835423573851585\n",
      "Epoch 2043, Loss: 0.1840762458741665, Final Batch Loss: 0.13365846872329712\n",
      "Epoch 2044, Loss: 0.03474585013464093, Final Batch Loss: 0.007376024965196848\n",
      "Epoch 2045, Loss: 0.05170501954853535, Final Batch Loss: 0.017943380400538445\n",
      "Epoch 2046, Loss: 0.07749157585203648, Final Batch Loss: 0.0504692867398262\n",
      "Epoch 2047, Loss: 0.08672141656279564, Final Batch Loss: 0.057308707386255264\n",
      "Epoch 2048, Loss: 0.02712951321154833, Final Batch Loss: 0.014315108768641949\n",
      "Epoch 2049, Loss: 0.07703847996890545, Final Batch Loss: 0.053673651069402695\n",
      "Epoch 2050, Loss: 0.057805025950074196, Final Batch Loss: 0.041440606117248535\n",
      "Epoch 2051, Loss: 0.04661787673830986, Final Batch Loss: 0.021899551153182983\n",
      "Epoch 2052, Loss: 0.04966471716761589, Final Batch Loss: 0.03782067447900772\n",
      "Epoch 2053, Loss: 0.10208624228835106, Final Batch Loss: 0.03742915764451027\n",
      "Epoch 2054, Loss: 0.11791804246604443, Final Batch Loss: 0.1006096675992012\n",
      "Epoch 2055, Loss: 0.09272648766636848, Final Batch Loss: 0.031265486031770706\n",
      "Epoch 2056, Loss: 0.09632047265768051, Final Batch Loss: 0.05395442247390747\n",
      "Epoch 2057, Loss: 0.0909789428114891, Final Batch Loss: 0.05077631399035454\n",
      "Epoch 2058, Loss: 0.07429969869554043, Final Batch Loss: 0.05030393972992897\n",
      "Epoch 2059, Loss: 0.0579705648124218, Final Batch Loss: 0.009405441582202911\n",
      "Epoch 2060, Loss: 0.03760275058448315, Final Batch Loss: 0.008788060396909714\n",
      "Epoch 2061, Loss: 0.036229626275599, Final Batch Loss: 0.022958580404520035\n",
      "Epoch 2062, Loss: 0.06692172773182392, Final Batch Loss: 0.02672635205090046\n",
      "Epoch 2063, Loss: 0.05849217809736729, Final Batch Loss: 0.0439707450568676\n",
      "Epoch 2064, Loss: 0.0595985259860754, Final Batch Loss: 0.0322108194231987\n",
      "Epoch 2065, Loss: 0.052474741358309984, Final Batch Loss: 0.005610988009721041\n",
      "Epoch 2066, Loss: 0.07296389900147915, Final Batch Loss: 0.05726458877325058\n",
      "Epoch 2067, Loss: 0.051259033381938934, Final Batch Loss: 0.01987461745738983\n",
      "Epoch 2068, Loss: 0.09482364170253277, Final Batch Loss: 0.0787564367055893\n",
      "Epoch 2069, Loss: 0.05886395741254091, Final Batch Loss: 0.01517100352793932\n",
      "Epoch 2070, Loss: 0.0785556212067604, Final Batch Loss: 0.03915570676326752\n",
      "Epoch 2071, Loss: 0.05088293645530939, Final Batch Loss: 0.012270052917301655\n",
      "Epoch 2072, Loss: 0.049211577512323856, Final Batch Loss: 0.04038822650909424\n",
      "Epoch 2073, Loss: 0.07154862210154533, Final Batch Loss: 0.0192609541118145\n",
      "Epoch 2074, Loss: 0.03697119792923331, Final Batch Loss: 0.007762966211885214\n",
      "Epoch 2075, Loss: 0.03779952507466078, Final Batch Loss: 0.029464248567819595\n",
      "Epoch 2076, Loss: 0.029403814114630222, Final Batch Loss: 0.019596822559833527\n",
      "Epoch 2077, Loss: 0.03381653502583504, Final Batch Loss: 0.010214025154709816\n",
      "Epoch 2078, Loss: 0.04967158380895853, Final Batch Loss: 0.012096458114683628\n",
      "Epoch 2079, Loss: 0.06862894166260958, Final Batch Loss: 0.05899575725197792\n",
      "Epoch 2080, Loss: 0.07138392888009548, Final Batch Loss: 0.05305694416165352\n",
      "Epoch 2081, Loss: 0.06936262547969818, Final Batch Loss: 0.036669593304395676\n",
      "Epoch 2082, Loss: 0.024182124994695187, Final Batch Loss: 0.009117454290390015\n",
      "Epoch 2083, Loss: 0.031469229608774185, Final Batch Loss: 0.015668796375393867\n",
      "Epoch 2084, Loss: 0.05803339183330536, Final Batch Loss: 0.028417587280273438\n",
      "Epoch 2085, Loss: 0.0400834446772933, Final Batch Loss: 0.008486202917993069\n",
      "Epoch 2086, Loss: 0.06057031266391277, Final Batch Loss: 0.03533289581537247\n",
      "Epoch 2087, Loss: 0.0746756624430418, Final Batch Loss: 0.06255684792995453\n",
      "Epoch 2088, Loss: 0.06585932336747646, Final Batch Loss: 0.048624686896800995\n",
      "Epoch 2089, Loss: 0.07005874626338482, Final Batch Loss: 0.05318073928356171\n",
      "Epoch 2090, Loss: 0.0392528020311147, Final Batch Loss: 0.003494373755529523\n",
      "Epoch 2091, Loss: 0.1962328962981701, Final Batch Loss: 0.15546663105487823\n",
      "Epoch 2092, Loss: 0.04069836251437664, Final Batch Loss: 0.017957456409931183\n",
      "Epoch 2093, Loss: 0.0539091881364584, Final Batch Loss: 0.009199639782309532\n",
      "Epoch 2094, Loss: 0.039245983585715294, Final Batch Loss: 0.02338583581149578\n",
      "Epoch 2095, Loss: 0.03857334516942501, Final Batch Loss: 0.013599392026662827\n",
      "Epoch 2096, Loss: 0.03607576433569193, Final Batch Loss: 0.013082326389849186\n",
      "Epoch 2097, Loss: 0.03662969917058945, Final Batch Loss: 0.01650839112699032\n",
      "Epoch 2098, Loss: 0.045005567371845245, Final Batch Loss: 0.018869996070861816\n",
      "Epoch 2099, Loss: 0.062405725941061974, Final Batch Loss: 0.04297304525971413\n",
      "Epoch 2100, Loss: 0.056112684309482574, Final Batch Loss: 0.02312036231160164\n",
      "Epoch 2101, Loss: 0.070867576636374, Final Batch Loss: 0.06175047159194946\n",
      "Epoch 2102, Loss: 0.0894075520336628, Final Batch Loss: 0.05770273134112358\n",
      "Epoch 2103, Loss: 0.0559023879468441, Final Batch Loss: 0.02339710295200348\n",
      "Epoch 2104, Loss: 0.05146907828748226, Final Batch Loss: 0.018834220245480537\n",
      "Epoch 2105, Loss: 0.05742642469704151, Final Batch Loss: 0.0234293844550848\n",
      "Epoch 2106, Loss: 0.02604141552001238, Final Batch Loss: 0.010152875445783138\n",
      "Epoch 2107, Loss: 0.04993334412574768, Final Batch Loss: 0.023201821371912956\n",
      "Epoch 2108, Loss: 0.12325606122612953, Final Batch Loss: 0.07270690053701401\n",
      "Epoch 2109, Loss: 0.05634627304971218, Final Batch Loss: 0.006669135764241219\n",
      "Epoch 2110, Loss: 0.046491557732224464, Final Batch Loss: 0.023127183318138123\n",
      "Epoch 2111, Loss: 0.11225233972072601, Final Batch Loss: 0.0641467347741127\n",
      "Epoch 2112, Loss: 0.07398893684148788, Final Batch Loss: 0.009999066591262817\n",
      "Epoch 2113, Loss: 0.09604175388813019, Final Batch Loss: 0.051437340676784515\n",
      "Epoch 2114, Loss: 0.07699288055300713, Final Batch Loss: 0.013203602284193039\n",
      "Epoch 2115, Loss: 0.04778480529785156, Final Batch Loss: 0.033265117555856705\n",
      "Epoch 2116, Loss: 0.04281735606491566, Final Batch Loss: 0.010611055418848991\n",
      "Epoch 2117, Loss: 0.05802024807780981, Final Batch Loss: 0.04372679442167282\n",
      "Epoch 2118, Loss: 0.06010391376912594, Final Batch Loss: 0.035116713494062424\n",
      "Epoch 2119, Loss: 0.05830904841423035, Final Batch Loss: 0.02149295061826706\n",
      "Epoch 2120, Loss: 0.04120103269815445, Final Batch Loss: 0.018935304135084152\n",
      "Epoch 2121, Loss: 0.05365046672523022, Final Batch Loss: 0.009192032739520073\n",
      "Epoch 2122, Loss: 0.04547204077243805, Final Batch Loss: 0.020745184272527695\n",
      "Epoch 2123, Loss: 0.07495762500911951, Final Batch Loss: 0.010915354825556278\n",
      "Epoch 2124, Loss: 0.04118436947464943, Final Batch Loss: 0.01933285966515541\n",
      "Epoch 2125, Loss: 0.09505356661975384, Final Batch Loss: 0.016774600371718407\n",
      "Epoch 2126, Loss: 0.10134307295084, Final Batch Loss: 0.06389863044023514\n",
      "Epoch 2127, Loss: 0.030711437575519085, Final Batch Loss: 0.010706276632845402\n",
      "Epoch 2128, Loss: 0.11734848469495773, Final Batch Loss: 0.06780651956796646\n",
      "Epoch 2129, Loss: 0.0537457917816937, Final Batch Loss: 0.00516262324526906\n",
      "Epoch 2130, Loss: 0.04730851389467716, Final Batch Loss: 0.018104970455169678\n",
      "Epoch 2131, Loss: 0.145058061927557, Final Batch Loss: 0.05019906535744667\n",
      "Epoch 2132, Loss: 0.13697469234466553, Final Batch Loss: 0.07145748287439346\n",
      "Epoch 2133, Loss: 0.12985718995332718, Final Batch Loss: 0.08377456665039062\n",
      "Epoch 2134, Loss: 0.11807980015873909, Final Batch Loss: 0.04238598421216011\n",
      "Epoch 2135, Loss: 0.09946946427226067, Final Batch Loss: 0.0579531230032444\n",
      "Epoch 2136, Loss: 0.040294152684509754, Final Batch Loss: 0.01515029463917017\n",
      "Epoch 2137, Loss: 0.05909510049968958, Final Batch Loss: 0.0066068219020962715\n",
      "Epoch 2138, Loss: 0.12536653503775597, Final Batch Loss: 0.06736744940280914\n",
      "Epoch 2139, Loss: 0.06915725953876972, Final Batch Loss: 0.01718004234135151\n",
      "Epoch 2140, Loss: 0.13869812339544296, Final Batch Loss: 0.0102219358086586\n",
      "Epoch 2141, Loss: 0.12825237587094307, Final Batch Loss: 0.08625777065753937\n",
      "Epoch 2142, Loss: 0.05621716845780611, Final Batch Loss: 0.04064185544848442\n",
      "Epoch 2143, Loss: 0.06258825585246086, Final Batch Loss: 0.031160805374383926\n",
      "Epoch 2144, Loss: 0.09238884225487709, Final Batch Loss: 0.046814024448394775\n",
      "Epoch 2145, Loss: 0.054512377828359604, Final Batch Loss: 0.026558639481663704\n",
      "Epoch 2146, Loss: 0.036978373071178794, Final Batch Loss: 0.002502226969227195\n",
      "Epoch 2147, Loss: 0.05303300078958273, Final Batch Loss: 0.015063933096826077\n",
      "Epoch 2148, Loss: 0.05427367612719536, Final Batch Loss: 0.03538498282432556\n",
      "Epoch 2149, Loss: 0.04680944047868252, Final Batch Loss: 0.018957041203975677\n",
      "Epoch 2150, Loss: 0.0833091288805008, Final Batch Loss: 0.026215936988592148\n",
      "Epoch 2151, Loss: 0.08041088841855526, Final Batch Loss: 0.06499125808477402\n",
      "Epoch 2152, Loss: 0.0926716048270464, Final Batch Loss: 0.017975838854908943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2153, Loss: 0.14526737481355667, Final Batch Loss: 0.09667305648326874\n",
      "Epoch 2154, Loss: 0.07249237783253193, Final Batch Loss: 0.05987978354096413\n",
      "Epoch 2155, Loss: 0.03547103516757488, Final Batch Loss: 0.02016952633857727\n",
      "Epoch 2156, Loss: 0.07161666825413704, Final Batch Loss: 0.05464863404631615\n",
      "Epoch 2157, Loss: 0.06202389486134052, Final Batch Loss: 0.02757846750319004\n",
      "Epoch 2158, Loss: 0.033814056776463985, Final Batch Loss: 0.022327089682221413\n",
      "Epoch 2159, Loss: 0.07340962998569012, Final Batch Loss: 0.05692150443792343\n",
      "Epoch 2160, Loss: 0.09203122556209564, Final Batch Loss: 0.03376191109418869\n",
      "Epoch 2161, Loss: 0.08364311791956425, Final Batch Loss: 0.070027194917202\n",
      "Epoch 2162, Loss: 0.04142453707754612, Final Batch Loss: 0.017830442637205124\n",
      "Epoch 2163, Loss: 0.08360457420349121, Final Batch Loss: 0.05036546289920807\n",
      "Epoch 2164, Loss: 0.058018021285533905, Final Batch Loss: 0.035834044218063354\n",
      "Epoch 2165, Loss: 0.09984013251960278, Final Batch Loss: 0.07971413433551788\n",
      "Epoch 2166, Loss: 0.02959100343286991, Final Batch Loss: 0.009901128709316254\n",
      "Epoch 2167, Loss: 0.06723728030920029, Final Batch Loss: 0.018671616911888123\n",
      "Epoch 2168, Loss: 0.10899320989847183, Final Batch Loss: 0.030399300158023834\n",
      "Epoch 2169, Loss: 0.08989358320832253, Final Batch Loss: 0.05880589038133621\n",
      "Epoch 2170, Loss: 0.07305050082504749, Final Batch Loss: 0.020275896415114403\n",
      "Epoch 2171, Loss: 0.07999187707901001, Final Batch Loss: 0.02697339653968811\n",
      "Epoch 2172, Loss: 0.05374789051711559, Final Batch Loss: 0.027347074821591377\n",
      "Epoch 2173, Loss: 0.037672124803066254, Final Batch Loss: 0.01391683891415596\n",
      "Epoch 2174, Loss: 0.09433910995721817, Final Batch Loss: 0.07438056170940399\n",
      "Epoch 2175, Loss: 0.04800955019891262, Final Batch Loss: 0.022417055442929268\n",
      "Epoch 2176, Loss: 0.04832695331424475, Final Batch Loss: 0.008410210721194744\n",
      "Epoch 2177, Loss: 0.04924804996699095, Final Batch Loss: 0.011525816284120083\n",
      "Epoch 2178, Loss: 0.038350784219801426, Final Batch Loss: 0.011880096979439259\n",
      "Epoch 2179, Loss: 0.04951784387230873, Final Batch Loss: 0.028023740276694298\n",
      "Epoch 2180, Loss: 0.058312395587563515, Final Batch Loss: 0.03797825425863266\n",
      "Epoch 2181, Loss: 0.04129793168976903, Final Batch Loss: 0.0030961637385189533\n",
      "Epoch 2182, Loss: 0.06559951603412628, Final Batch Loss: 0.03637496381998062\n",
      "Epoch 2183, Loss: 0.03439363185316324, Final Batch Loss: 0.023593023419380188\n",
      "Epoch 2184, Loss: 0.06245715729892254, Final Batch Loss: 0.048437755554914474\n",
      "Epoch 2185, Loss: 0.0464777797460556, Final Batch Loss: 0.02939622849225998\n",
      "Epoch 2186, Loss: 0.021226140670478344, Final Batch Loss: 0.009624214842915535\n",
      "Epoch 2187, Loss: 0.042233023792505264, Final Batch Loss: 0.02026296965777874\n",
      "Epoch 2188, Loss: 0.04264254681766033, Final Batch Loss: 0.021116286516189575\n",
      "Epoch 2189, Loss: 0.07104701921343803, Final Batch Loss: 0.05312218889594078\n",
      "Epoch 2190, Loss: 0.050093384459614754, Final Batch Loss: 0.042014408856630325\n",
      "Epoch 2191, Loss: 0.04775382578372955, Final Batch Loss: 0.02067430689930916\n",
      "Epoch 2192, Loss: 0.0625814963132143, Final Batch Loss: 0.017918439581990242\n",
      "Epoch 2193, Loss: 0.048030853271484375, Final Batch Loss: 0.031244628131389618\n",
      "Epoch 2194, Loss: 0.020536336116492748, Final Batch Loss: 0.01013671513646841\n",
      "Epoch 2195, Loss: 0.04485618323087692, Final Batch Loss: 0.025357063859701157\n",
      "Epoch 2196, Loss: 0.06275460310280323, Final Batch Loss: 0.03513927012681961\n",
      "Epoch 2197, Loss: 0.05364301986992359, Final Batch Loss: 0.04698016494512558\n",
      "Epoch 2198, Loss: 0.058958024717867374, Final Batch Loss: 0.04360484704375267\n",
      "Epoch 2199, Loss: 0.05180856212973595, Final Batch Loss: 0.037824518978595734\n",
      "Epoch 2200, Loss: 0.054855856113135815, Final Batch Loss: 0.015109009109437466\n",
      "Epoch 2201, Loss: 0.04724398534744978, Final Batch Loss: 0.03372548893094063\n",
      "Epoch 2202, Loss: 0.11433157324790955, Final Batch Loss: 0.034489117562770844\n",
      "Epoch 2203, Loss: 0.07646587491035461, Final Batch Loss: 0.04346031695604324\n",
      "Epoch 2204, Loss: 0.15026959218084812, Final Batch Loss: 0.12127386778593063\n",
      "Epoch 2205, Loss: 0.05252552218735218, Final Batch Loss: 0.032740406692028046\n",
      "Epoch 2206, Loss: 0.07343564182519913, Final Batch Loss: 0.04007328674197197\n",
      "Epoch 2207, Loss: 0.037359788082540035, Final Batch Loss: 0.005525152198970318\n",
      "Epoch 2208, Loss: 0.046467000618577003, Final Batch Loss: 0.007463378831744194\n",
      "Epoch 2209, Loss: 0.033669562079012394, Final Batch Loss: 0.01870189607143402\n",
      "Epoch 2210, Loss: 0.05009433813393116, Final Batch Loss: 0.0349435955286026\n",
      "Epoch 2211, Loss: 0.03530185343697667, Final Batch Loss: 0.005932920146733522\n",
      "Epoch 2212, Loss: 0.03393371868878603, Final Batch Loss: 0.007561809383332729\n",
      "Epoch 2213, Loss: 0.060555242002010345, Final Batch Loss: 0.02105385810136795\n",
      "Epoch 2214, Loss: 0.02225328702479601, Final Batch Loss: 0.011173238977789879\n",
      "Epoch 2215, Loss: 0.028930528089404106, Final Batch Loss: 0.01670931838452816\n",
      "Epoch 2216, Loss: 0.09949571080505848, Final Batch Loss: 0.07265176624059677\n",
      "Epoch 2217, Loss: 0.10159635543823242, Final Batch Loss: 0.04853839799761772\n",
      "Epoch 2218, Loss: 0.0326470946893096, Final Batch Loss: 0.01134395133703947\n",
      "Epoch 2219, Loss: 0.1026683934032917, Final Batch Loss: 0.05100042000412941\n",
      "Epoch 2220, Loss: 0.041896918788552284, Final Batch Loss: 0.008466141298413277\n",
      "Epoch 2221, Loss: 0.046890982426702976, Final Batch Loss: 0.032919298857450485\n",
      "Epoch 2222, Loss: 0.025351263117045164, Final Batch Loss: 0.007168069016188383\n",
      "Epoch 2223, Loss: 0.018276081420481205, Final Batch Loss: 0.010312576778233051\n",
      "Epoch 2224, Loss: 0.04003889672458172, Final Batch Loss: 0.029691575095057487\n",
      "Epoch 2225, Loss: 0.04031533934175968, Final Batch Loss: 0.018300430849194527\n",
      "Epoch 2226, Loss: 0.019962509162724018, Final Batch Loss: 0.011402766220271587\n",
      "Epoch 2227, Loss: 0.04632978141307831, Final Batch Loss: 0.02827577292919159\n",
      "Epoch 2228, Loss: 0.02806322555989027, Final Batch Loss: 0.014381242915987968\n",
      "Epoch 2229, Loss: 0.031548429280519485, Final Batch Loss: 0.0073911529034376144\n",
      "Epoch 2230, Loss: 0.07707711961120367, Final Batch Loss: 0.01370417233556509\n",
      "Epoch 2231, Loss: 0.059251902624964714, Final Batch Loss: 0.020472297444939613\n",
      "Epoch 2232, Loss: 0.09723243769258261, Final Batch Loss: 0.08807162940502167\n",
      "Epoch 2233, Loss: 0.037472961470484734, Final Batch Loss: 0.020247571170330048\n",
      "Epoch 2234, Loss: 0.053370038978755474, Final Batch Loss: 0.012093543075025082\n",
      "Epoch 2235, Loss: 0.056692883372306824, Final Batch Loss: 0.00946543738245964\n",
      "Epoch 2236, Loss: 0.06571085378527641, Final Batch Loss: 0.02938474342226982\n",
      "Epoch 2237, Loss: 0.06134608946740627, Final Batch Loss: 0.03265112638473511\n",
      "Epoch 2238, Loss: 0.05344115011394024, Final Batch Loss: 0.028402306139469147\n",
      "Epoch 2239, Loss: 0.0394411226734519, Final Batch Loss: 0.02917969599366188\n",
      "Epoch 2240, Loss: 0.03310872195288539, Final Batch Loss: 0.007092330139130354\n",
      "Epoch 2241, Loss: 0.04838717542588711, Final Batch Loss: 0.03582948073744774\n",
      "Epoch 2242, Loss: 0.028576284646987915, Final Batch Loss: 0.009722171351313591\n",
      "Epoch 2243, Loss: 0.02698669768869877, Final Batch Loss: 0.010932788252830505\n",
      "Epoch 2244, Loss: 0.12803073599934578, Final Batch Loss: 0.09573500603437424\n",
      "Epoch 2245, Loss: 0.02579459361732006, Final Batch Loss: 0.008753091096878052\n",
      "Epoch 2246, Loss: 0.03043340891599655, Final Batch Loss: 0.005808722227811813\n",
      "Epoch 2247, Loss: 0.06813903339207172, Final Batch Loss: 0.049883924424648285\n",
      "Epoch 2248, Loss: 0.0365425581112504, Final Batch Loss: 0.005868115462362766\n",
      "Epoch 2249, Loss: 0.04939833655953407, Final Batch Loss: 0.030359074473381042\n",
      "Epoch 2250, Loss: 0.03842918388545513, Final Batch Loss: 0.011095710098743439\n",
      "Epoch 2251, Loss: 0.03282013442367315, Final Batch Loss: 0.02060523070394993\n",
      "Epoch 2252, Loss: 0.09552102722227573, Final Batch Loss: 0.0684528723359108\n",
      "Epoch 2253, Loss: 0.19752610754221678, Final Batch Loss: 0.18405267596244812\n",
      "Epoch 2254, Loss: 0.05208324268460274, Final Batch Loss: 0.02912158891558647\n",
      "Epoch 2255, Loss: 0.13137796334922314, Final Batch Loss: 0.12013453245162964\n",
      "Epoch 2256, Loss: 0.027338451705873013, Final Batch Loss: 0.010910517536103725\n",
      "Epoch 2257, Loss: 0.045793987810611725, Final Batch Loss: 0.021459490060806274\n",
      "Epoch 2258, Loss: 0.03352951630949974, Final Batch Loss: 0.016330642625689507\n",
      "Epoch 2259, Loss: 0.06293843686580658, Final Batch Loss: 0.005134403705596924\n",
      "Epoch 2260, Loss: 0.029602007009088993, Final Batch Loss: 0.010074655525386333\n",
      "Epoch 2261, Loss: 0.03660019487142563, Final Batch Loss: 0.016825618222355843\n",
      "Epoch 2262, Loss: 0.06565802544355392, Final Batch Loss: 0.04633595049381256\n",
      "Epoch 2263, Loss: 0.16462859511375427, Final Batch Loss: 0.11319718509912491\n",
      "Epoch 2264, Loss: 0.06371392868459225, Final Batch Loss: 0.022549310699105263\n",
      "Epoch 2265, Loss: 0.07721114717423916, Final Batch Loss: 0.02685929648578167\n",
      "Epoch 2266, Loss: 0.056571489199995995, Final Batch Loss: 0.021700972691178322\n",
      "Epoch 2267, Loss: 0.055450260639190674, Final Batch Loss: 0.01588323712348938\n",
      "Epoch 2268, Loss: 0.03831527382135391, Final Batch Loss: 0.009739145636558533\n",
      "Epoch 2269, Loss: 0.05850262753665447, Final Batch Loss: 0.0388701893389225\n",
      "Epoch 2270, Loss: 0.04160434007644653, Final Batch Loss: 0.01488029956817627\n",
      "Epoch 2271, Loss: 0.030361324083060026, Final Batch Loss: 0.004602731671184301\n",
      "Epoch 2272, Loss: 0.041813177056610584, Final Batch Loss: 0.009733726270496845\n",
      "Epoch 2273, Loss: 0.028136011213064194, Final Batch Loss: 0.01174473948776722\n",
      "Epoch 2274, Loss: 0.048251500353217125, Final Batch Loss: 0.03587059676647186\n",
      "Epoch 2275, Loss: 0.03949063364416361, Final Batch Loss: 0.006736204959452152\n",
      "Epoch 2276, Loss: 0.03967259172350168, Final Batch Loss: 0.029193131253123283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2277, Loss: 0.03165984759107232, Final Batch Loss: 0.007266490254551172\n",
      "Epoch 2278, Loss: 0.02565741539001465, Final Batch Loss: 0.004559028893709183\n",
      "Epoch 2279, Loss: 0.034684271551668644, Final Batch Loss: 0.021184759214520454\n",
      "Epoch 2280, Loss: 0.048633772879838943, Final Batch Loss: 0.02236022800207138\n",
      "Epoch 2281, Loss: 0.07239323109388351, Final Batch Loss: 0.034998998045921326\n",
      "Epoch 2282, Loss: 0.03732821252197027, Final Batch Loss: 0.028003262355923653\n",
      "Epoch 2283, Loss: 0.02238992555066943, Final Batch Loss: 0.015066646970808506\n",
      "Epoch 2284, Loss: 0.035307164303958416, Final Batch Loss: 0.022084128111600876\n",
      "Epoch 2285, Loss: 0.04184911400079727, Final Batch Loss: 0.019210850819945335\n",
      "Epoch 2286, Loss: 0.024195000529289246, Final Batch Loss: 0.010515943169593811\n",
      "Epoch 2287, Loss: 0.07464074343442917, Final Batch Loss: 0.040208760648965836\n",
      "Epoch 2288, Loss: 0.02552016917616129, Final Batch Loss: 0.008799196220934391\n",
      "Epoch 2289, Loss: 0.06613701581954956, Final Batch Loss: 0.01832076907157898\n",
      "Epoch 2290, Loss: 0.08951927907764912, Final Batch Loss: 0.07614771276712418\n",
      "Epoch 2291, Loss: 0.042866640724241734, Final Batch Loss: 0.009612360037863255\n",
      "Epoch 2292, Loss: 0.03494352474808693, Final Batch Loss: 0.015430880710482597\n",
      "Epoch 2293, Loss: 0.16214675828814507, Final Batch Loss: 0.11148770898580551\n",
      "Epoch 2294, Loss: 0.060468100011348724, Final Batch Loss: 0.03951076418161392\n",
      "Epoch 2295, Loss: 0.052779585123062134, Final Batch Loss: 0.011079750955104828\n",
      "Epoch 2296, Loss: 0.06121777929365635, Final Batch Loss: 0.017932234331965446\n",
      "Epoch 2297, Loss: 0.16284027229994535, Final Batch Loss: 0.15172597765922546\n",
      "Epoch 2298, Loss: 0.055512117221951485, Final Batch Loss: 0.032970547676086426\n",
      "Epoch 2299, Loss: 0.0925243329256773, Final Batch Loss: 0.07401684671640396\n",
      "Epoch 2300, Loss: 0.10692493990063667, Final Batch Loss: 0.0628998875617981\n",
      "Epoch 2301, Loss: 0.28184302151203156, Final Batch Loss: 0.20166648924350739\n",
      "Epoch 2302, Loss: 0.08094226196408272, Final Batch Loss: 0.025392960757017136\n",
      "Epoch 2303, Loss: 0.09684128314256668, Final Batch Loss: 0.08505801856517792\n",
      "Epoch 2304, Loss: 0.11260613799095154, Final Batch Loss: 0.037822701036930084\n",
      "Epoch 2305, Loss: 0.12498234212398529, Final Batch Loss: 0.09197992831468582\n",
      "Epoch 2306, Loss: 0.03615969547536224, Final Batch Loss: 0.0016646807780489326\n",
      "Epoch 2307, Loss: 0.04570465721189976, Final Batch Loss: 0.016979573294520378\n",
      "Epoch 2308, Loss: 0.04912061523646116, Final Batch Loss: 0.011930125765502453\n",
      "Epoch 2309, Loss: 0.1127268634736538, Final Batch Loss: 0.07748731225728989\n",
      "Epoch 2310, Loss: 0.10802043229341507, Final Batch Loss: 0.07664930075407028\n",
      "Epoch 2311, Loss: 0.06201557628810406, Final Batch Loss: 0.029620328918099403\n",
      "Epoch 2312, Loss: 0.07041592104360461, Final Batch Loss: 0.006062872242182493\n",
      "Epoch 2313, Loss: 0.09513811022043228, Final Batch Loss: 0.05007297545671463\n",
      "Epoch 2314, Loss: 0.037504106760025024, Final Batch Loss: 0.011480474844574928\n",
      "Epoch 2315, Loss: 0.11754912696778774, Final Batch Loss: 0.0922718346118927\n",
      "Epoch 2316, Loss: 0.09638211689889431, Final Batch Loss: 0.06664891541004181\n",
      "Epoch 2317, Loss: 0.1183059811592102, Final Batch Loss: 0.0676494911313057\n",
      "Epoch 2318, Loss: 0.07712498866021633, Final Batch Loss: 0.023441115394234657\n",
      "Epoch 2319, Loss: 0.06650933623313904, Final Batch Loss: 0.046071723103523254\n",
      "Epoch 2320, Loss: 0.08258145675063133, Final Batch Loss: 0.05414331331849098\n",
      "Epoch 2321, Loss: 0.07088354043662548, Final Batch Loss: 0.017687836661934853\n",
      "Epoch 2322, Loss: 0.11765452474355698, Final Batch Loss: 0.050806641578674316\n",
      "Epoch 2323, Loss: 0.046137845143675804, Final Batch Loss: 0.018678264692425728\n",
      "Epoch 2324, Loss: 0.07842456921935081, Final Batch Loss: 0.03149000555276871\n",
      "Epoch 2325, Loss: 0.09972026012837887, Final Batch Loss: 0.0791567713022232\n",
      "Epoch 2326, Loss: 0.10434892028570175, Final Batch Loss: 0.057954978197813034\n",
      "Epoch 2327, Loss: 0.07037175074219704, Final Batch Loss: 0.030293606221675873\n",
      "Epoch 2328, Loss: 0.06663647945970297, Final Batch Loss: 0.01292621623724699\n",
      "Epoch 2329, Loss: 0.10226808115839958, Final Batch Loss: 0.06094588711857796\n",
      "Epoch 2330, Loss: 0.08568823337554932, Final Batch Loss: 0.03387530520558357\n",
      "Epoch 2331, Loss: 0.062312304973602295, Final Batch Loss: 0.019466616213321686\n",
      "Epoch 2332, Loss: 0.07029230892658234, Final Batch Loss: 0.03655783832073212\n",
      "Epoch 2333, Loss: 0.050483972765505314, Final Batch Loss: 0.011562620289623737\n",
      "Epoch 2334, Loss: 0.11963668838143349, Final Batch Loss: 0.06959784030914307\n",
      "Epoch 2335, Loss: 0.10566206648945808, Final Batch Loss: 0.047319523990154266\n",
      "Epoch 2336, Loss: 0.10257972776889801, Final Batch Loss: 0.06578225642442703\n",
      "Epoch 2337, Loss: 0.05386918783187866, Final Batch Loss: 0.02405523881316185\n",
      "Epoch 2338, Loss: 0.06243901140987873, Final Batch Loss: 0.024297358468174934\n",
      "Epoch 2339, Loss: 0.10462329164147377, Final Batch Loss: 0.06299704313278198\n",
      "Epoch 2340, Loss: 0.08857966214418411, Final Batch Loss: 0.05162712186574936\n",
      "Epoch 2341, Loss: 0.04763525165617466, Final Batch Loss: 0.017125733196735382\n",
      "Epoch 2342, Loss: 0.039627235382795334, Final Batch Loss: 0.012168038636446\n",
      "Epoch 2343, Loss: 0.03432486392557621, Final Batch Loss: 0.016963327303528786\n",
      "Epoch 2344, Loss: 0.1344214491546154, Final Batch Loss: 0.08881278336048126\n",
      "Epoch 2345, Loss: 0.06794445030391216, Final Batch Loss: 0.04003210738301277\n",
      "Epoch 2346, Loss: 0.12672800943255424, Final Batch Loss: 0.10527642071247101\n",
      "Epoch 2347, Loss: 0.05653121881186962, Final Batch Loss: 0.016517778858542442\n",
      "Epoch 2348, Loss: 0.14687208458781242, Final Batch Loss: 0.09864939749240875\n",
      "Epoch 2349, Loss: 0.1263246349990368, Final Batch Loss: 0.060324255377054214\n",
      "Epoch 2350, Loss: 0.1283051073551178, Final Batch Loss: 0.08210247755050659\n",
      "Epoch 2351, Loss: 0.06088658608496189, Final Batch Loss: 0.03854473680257797\n",
      "Epoch 2352, Loss: 0.07411409541964531, Final Batch Loss: 0.05418916046619415\n",
      "Epoch 2353, Loss: 0.07572907954454422, Final Batch Loss: 0.04094402492046356\n",
      "Epoch 2354, Loss: 0.07668405305594206, Final Batch Loss: 0.008842895738780499\n",
      "Epoch 2355, Loss: 0.05806695483624935, Final Batch Loss: 0.02548414282500744\n",
      "Epoch 2356, Loss: 0.062477017752826214, Final Batch Loss: 0.013274411670863628\n",
      "Epoch 2357, Loss: 0.08977774158120155, Final Batch Loss: 0.04682600498199463\n",
      "Epoch 2358, Loss: 0.07391752768307924, Final Batch Loss: 0.009332922287285328\n",
      "Epoch 2359, Loss: 0.07323736604303122, Final Batch Loss: 0.06136908754706383\n",
      "Epoch 2360, Loss: 0.07291342504322529, Final Batch Loss: 0.0162795577198267\n",
      "Epoch 2361, Loss: 0.04995476268231869, Final Batch Loss: 0.02585439383983612\n",
      "Epoch 2362, Loss: 0.027294750325381756, Final Batch Loss: 0.010977591387927532\n",
      "Epoch 2363, Loss: 0.05514553748071194, Final Batch Loss: 0.01858893223106861\n",
      "Epoch 2364, Loss: 0.06186617538332939, Final Batch Loss: 0.016916897147893906\n",
      "Epoch 2365, Loss: 0.05791402421891689, Final Batch Loss: 0.03470960259437561\n",
      "Epoch 2366, Loss: 0.050207214429974556, Final Batch Loss: 0.017947977408766747\n",
      "Epoch 2367, Loss: 0.03079118300229311, Final Batch Loss: 0.011052952148020267\n",
      "Epoch 2368, Loss: 0.04951079096645117, Final Batch Loss: 0.03436695411801338\n",
      "Epoch 2369, Loss: 0.06245228415355086, Final Batch Loss: 0.00651805242523551\n",
      "Epoch 2370, Loss: 0.1250197719782591, Final Batch Loss: 0.10609431564807892\n",
      "Epoch 2371, Loss: 0.0699261911213398, Final Batch Loss: 0.018404457718133926\n",
      "Epoch 2372, Loss: 0.030388065613806248, Final Batch Loss: 0.01110053900629282\n",
      "Epoch 2373, Loss: 0.050700629130005836, Final Batch Loss: 0.010814892128109932\n",
      "Epoch 2374, Loss: 0.03406468220055103, Final Batch Loss: 0.007526848465204239\n",
      "Epoch 2375, Loss: 0.04646242596209049, Final Batch Loss: 0.021343639120459557\n",
      "Epoch 2376, Loss: 0.02987609338015318, Final Batch Loss: 0.007405743934214115\n",
      "Epoch 2377, Loss: 0.04464027099311352, Final Batch Loss: 0.02203933335840702\n",
      "Epoch 2378, Loss: 0.02809211704879999, Final Batch Loss: 0.015346793457865715\n",
      "Epoch 2379, Loss: 0.05610407888889313, Final Batch Loss: 0.022834084928035736\n",
      "Epoch 2380, Loss: 0.045581087470054626, Final Batch Loss: 0.029888201504945755\n",
      "Epoch 2381, Loss: 0.05522272223606706, Final Batch Loss: 0.04741763323545456\n",
      "Epoch 2382, Loss: 0.13288789428770542, Final Batch Loss: 0.01689225621521473\n",
      "Epoch 2383, Loss: 0.08531192131340504, Final Batch Loss: 0.05473480746150017\n",
      "Epoch 2384, Loss: 0.06892019510269165, Final Batch Loss: 0.039500027894973755\n",
      "Epoch 2385, Loss: 0.07719183899462223, Final Batch Loss: 0.016303500160574913\n",
      "Epoch 2386, Loss: 0.04439877066761255, Final Batch Loss: 0.011330929584801197\n",
      "Epoch 2387, Loss: 0.048425981774926186, Final Batch Loss: 0.023294400423765182\n",
      "Epoch 2388, Loss: 0.12543349713087082, Final Batch Loss: 0.06251391023397446\n",
      "Epoch 2389, Loss: 0.1317634992301464, Final Batch Loss: 0.0950697585940361\n",
      "Epoch 2390, Loss: 0.05941586010158062, Final Batch Loss: 0.03752383962273598\n",
      "Epoch 2391, Loss: 0.03231670241802931, Final Batch Loss: 0.014614897780120373\n",
      "Epoch 2392, Loss: 0.10774437338113785, Final Batch Loss: 0.06430565565824509\n",
      "Epoch 2393, Loss: 0.04161873832345009, Final Batch Loss: 0.013423770666122437\n",
      "Epoch 2394, Loss: 0.08486325480043888, Final Batch Loss: 0.07013276219367981\n",
      "Epoch 2395, Loss: 0.11693358793854713, Final Batch Loss: 0.04753223434090614\n",
      "Epoch 2396, Loss: 0.057406120002269745, Final Batch Loss: 0.03847736865282059\n",
      "Epoch 2397, Loss: 0.052219205535948277, Final Batch Loss: 0.005658828653395176\n",
      "Epoch 2398, Loss: 0.0493546724319458, Final Batch Loss: 0.025923892855644226\n",
      "Epoch 2399, Loss: 0.046636695973575115, Final Batch Loss: 0.008862915448844433\n",
      "Epoch 2400, Loss: 0.05569286458194256, Final Batch Loss: 0.03809954598546028\n",
      "Epoch 2401, Loss: 0.05765416473150253, Final Batch Loss: 0.025103997439146042\n",
      "Epoch 2402, Loss: 0.053157739341259, Final Batch Loss: 0.030780747532844543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2403, Loss: 0.0488998144865036, Final Batch Loss: 0.023553516715765\n",
      "Epoch 2404, Loss: 0.03598357457667589, Final Batch Loss: 0.023896902799606323\n",
      "Epoch 2405, Loss: 0.026494338177144527, Final Batch Loss: 0.008449793793261051\n",
      "Epoch 2406, Loss: 0.03489557094871998, Final Batch Loss: 0.018651217222213745\n",
      "Epoch 2407, Loss: 0.03109684307128191, Final Batch Loss: 0.010054194368422031\n",
      "Epoch 2408, Loss: 0.08804550021886826, Final Batch Loss: 0.010942123830318451\n",
      "Epoch 2409, Loss: 0.09117312263697386, Final Batch Loss: 0.0760045200586319\n",
      "Epoch 2410, Loss: 0.03902115672826767, Final Batch Loss: 0.0080270916223526\n",
      "Epoch 2411, Loss: 0.03686704859137535, Final Batch Loss: 0.02301141619682312\n",
      "Epoch 2412, Loss: 0.04729064833372831, Final Batch Loss: 0.011929801665246487\n",
      "Epoch 2413, Loss: 0.05477720033377409, Final Batch Loss: 0.010055883787572384\n",
      "Epoch 2414, Loss: 0.051229861564934254, Final Batch Loss: 0.0383063368499279\n",
      "Epoch 2415, Loss: 0.03869046550244093, Final Batch Loss: 0.015574092976748943\n",
      "Epoch 2416, Loss: 0.053683238103985786, Final Batch Loss: 0.04463984817266464\n",
      "Epoch 2417, Loss: 0.05177797004580498, Final Batch Loss: 0.040391869843006134\n",
      "Epoch 2418, Loss: 0.055952101945877075, Final Batch Loss: 0.0343693308532238\n",
      "Epoch 2419, Loss: 0.05201059766113758, Final Batch Loss: 0.03147188946604729\n",
      "Epoch 2420, Loss: 0.030222775880247355, Final Batch Loss: 0.006875031162053347\n",
      "Epoch 2421, Loss: 0.03491663374006748, Final Batch Loss: 0.016077708452939987\n",
      "Epoch 2422, Loss: 0.06243797577917576, Final Batch Loss: 0.020727666094899178\n",
      "Epoch 2423, Loss: 0.05736194644123316, Final Batch Loss: 0.049274079501628876\n",
      "Epoch 2424, Loss: 0.030454259365797043, Final Batch Loss: 0.008051512762904167\n",
      "Epoch 2425, Loss: 0.03868900425732136, Final Batch Loss: 0.010860299691557884\n",
      "Epoch 2426, Loss: 0.07760526612401009, Final Batch Loss: 0.036641065031290054\n",
      "Epoch 2427, Loss: 0.07237453386187553, Final Batch Loss: 0.03229881078004837\n",
      "Epoch 2428, Loss: 0.07009203173220158, Final Batch Loss: 0.060370489954948425\n",
      "Epoch 2429, Loss: 0.07343415357172489, Final Batch Loss: 0.052896592766046524\n",
      "Epoch 2430, Loss: 0.15625754557549953, Final Batch Loss: 0.13380932807922363\n",
      "Epoch 2431, Loss: 0.03539648558944464, Final Batch Loss: 0.01027622725814581\n",
      "Epoch 2432, Loss: 0.06756030395627022, Final Batch Loss: 0.04471326619386673\n",
      "Epoch 2433, Loss: 0.13204915076494217, Final Batch Loss: 0.07390480488538742\n",
      "Epoch 2434, Loss: 0.13751504942774773, Final Batch Loss: 0.11318646371364594\n",
      "Epoch 2435, Loss: 0.23839523643255234, Final Batch Loss: 0.20799468457698822\n",
      "Epoch 2436, Loss: 0.12972554937005043, Final Batch Loss: 0.08556173741817474\n",
      "Epoch 2437, Loss: 0.1049070879817009, Final Batch Loss: 0.0670943334698677\n",
      "Epoch 2438, Loss: 0.14005838334560394, Final Batch Loss: 0.06785839796066284\n",
      "Epoch 2439, Loss: 0.10089910961687565, Final Batch Loss: 0.012197623029351234\n",
      "Epoch 2440, Loss: 0.0905262790620327, Final Batch Loss: 0.025842618197202682\n",
      "Epoch 2441, Loss: 0.07195111364126205, Final Batch Loss: 0.029102057218551636\n",
      "Epoch 2442, Loss: 0.09293663501739502, Final Batch Loss: 0.05157245695590973\n",
      "Epoch 2443, Loss: 0.0802417853847146, Final Batch Loss: 0.010658339597284794\n",
      "Epoch 2444, Loss: 0.07386726140975952, Final Batch Loss: 0.03361602500081062\n",
      "Epoch 2445, Loss: 0.03768320009112358, Final Batch Loss: 0.0233754999935627\n",
      "Epoch 2446, Loss: 0.08710433728992939, Final Batch Loss: 0.0626586377620697\n",
      "Epoch 2447, Loss: 0.07071289233863354, Final Batch Loss: 0.025975840166211128\n",
      "Epoch 2448, Loss: 0.067293556407094, Final Batch Loss: 0.009432012215256691\n",
      "Epoch 2449, Loss: 0.08290277421474457, Final Batch Loss: 0.031687695533037186\n",
      "Epoch 2450, Loss: 0.06206412985920906, Final Batch Loss: 0.031642623245716095\n",
      "Epoch 2451, Loss: 0.07380693219602108, Final Batch Loss: 0.012084206566214561\n",
      "Epoch 2452, Loss: 0.06654984876513481, Final Batch Loss: 0.03216753154993057\n",
      "Epoch 2453, Loss: 0.03643318451941013, Final Batch Loss: 0.017114222049713135\n",
      "Epoch 2454, Loss: 0.0701677706092596, Final Batch Loss: 0.04454083740711212\n",
      "Epoch 2455, Loss: 0.05203738249838352, Final Batch Loss: 0.01778046227991581\n",
      "Epoch 2456, Loss: 0.07989439368247986, Final Batch Loss: 0.05073971301317215\n",
      "Epoch 2457, Loss: 0.04819648526608944, Final Batch Loss: 0.030446842312812805\n",
      "Epoch 2458, Loss: 0.04976794961839914, Final Batch Loss: 0.013881620950996876\n",
      "Epoch 2459, Loss: 0.052513811737298965, Final Batch Loss: 0.02020685002207756\n",
      "Epoch 2460, Loss: 0.027708979323506355, Final Batch Loss: 0.013283434323966503\n",
      "Epoch 2461, Loss: 0.062112003564834595, Final Batch Loss: 0.011474475264549255\n",
      "Epoch 2462, Loss: 0.03893720172345638, Final Batch Loss: 0.009876606985926628\n",
      "Epoch 2463, Loss: 0.035771967843174934, Final Batch Loss: 0.01670023798942566\n",
      "Epoch 2464, Loss: 0.057067397981882095, Final Batch Loss: 0.02184707671403885\n",
      "Epoch 2465, Loss: 0.06893669348210096, Final Batch Loss: 0.015176697634160519\n",
      "Epoch 2466, Loss: 0.053841933608055115, Final Batch Loss: 0.02789551392197609\n",
      "Epoch 2467, Loss: 0.020281443372368813, Final Batch Loss: 0.009146932512521744\n",
      "Epoch 2468, Loss: 0.04128240421414375, Final Batch Loss: 0.024995306506752968\n",
      "Epoch 2469, Loss: 0.056274727918207645, Final Batch Loss: 0.04223821312189102\n",
      "Epoch 2470, Loss: 0.05683302320539951, Final Batch Loss: 0.040416061878204346\n",
      "Epoch 2471, Loss: 0.0837802104651928, Final Batch Loss: 0.06572171300649643\n",
      "Epoch 2472, Loss: 0.04568794276565313, Final Batch Loss: 0.034644197672605515\n",
      "Epoch 2473, Loss: 0.059394496493041515, Final Batch Loss: 0.050832219421863556\n",
      "Epoch 2474, Loss: 0.1000297125428915, Final Batch Loss: 0.013341313228011131\n",
      "Epoch 2475, Loss: 0.10670658946037292, Final Batch Loss: 0.09235560148954391\n",
      "Epoch 2476, Loss: 0.16405626386404037, Final Batch Loss: 0.10644754022359848\n",
      "Epoch 2477, Loss: 0.04593783617019653, Final Batch Loss: 0.02206893265247345\n",
      "Epoch 2478, Loss: 0.03581985644996166, Final Batch Loss: 0.01647738553583622\n",
      "Epoch 2479, Loss: 0.045763641595840454, Final Batch Loss: 0.009014889597892761\n",
      "Epoch 2480, Loss: 0.04552152846008539, Final Batch Loss: 0.015578662045300007\n",
      "Epoch 2481, Loss: 0.04332559695467353, Final Batch Loss: 0.005938240792602301\n",
      "Epoch 2482, Loss: 0.08503323793411255, Final Batch Loss: 0.04441192001104355\n",
      "Epoch 2483, Loss: 0.02858205884695053, Final Batch Loss: 0.009015679359436035\n",
      "Epoch 2484, Loss: 0.0504732932895422, Final Batch Loss: 0.029486963525414467\n",
      "Epoch 2485, Loss: 0.019221549853682518, Final Batch Loss: 0.007134919986128807\n",
      "Epoch 2486, Loss: 0.028028658591210842, Final Batch Loss: 0.009716981090605259\n",
      "Epoch 2487, Loss: 0.11537227779626846, Final Batch Loss: 0.09957162290811539\n",
      "Epoch 2488, Loss: 0.04091437719762325, Final Batch Loss: 0.01567489467561245\n",
      "Epoch 2489, Loss: 0.03508223686367273, Final Batch Loss: 0.02861529029905796\n",
      "Epoch 2490, Loss: 0.09768226183950901, Final Batch Loss: 0.0773550346493721\n",
      "Epoch 2491, Loss: 0.05376491881906986, Final Batch Loss: 0.04623660445213318\n",
      "Epoch 2492, Loss: 0.04868283402174711, Final Batch Loss: 0.03603266924619675\n",
      "Epoch 2493, Loss: 0.03749348223209381, Final Batch Loss: 0.017669009044766426\n",
      "Epoch 2494, Loss: 0.05355275794863701, Final Batch Loss: 0.03257961571216583\n",
      "Epoch 2495, Loss: 0.019280106760561466, Final Batch Loss: 0.005683564580976963\n",
      "Epoch 2496, Loss: 0.04266342148184776, Final Batch Loss: 0.029199590906500816\n",
      "Epoch 2497, Loss: 0.03416929207742214, Final Batch Loss: 0.015023438259959221\n",
      "Epoch 2498, Loss: 0.04262956324964762, Final Batch Loss: 0.012187005020678043\n",
      "Epoch 2499, Loss: 0.04611630644649267, Final Batch Loss: 0.002903933636844158\n",
      "Epoch 2500, Loss: 0.028510553762316704, Final Batch Loss: 0.011693330481648445\n",
      "Epoch 2501, Loss: 0.02974239643663168, Final Batch Loss: 0.014685272239148617\n",
      "Epoch 2502, Loss: 0.030623349361121655, Final Batch Loss: 0.003861573524773121\n",
      "Epoch 2503, Loss: 0.0908962320536375, Final Batch Loss: 0.06992797553539276\n",
      "Epoch 2504, Loss: 0.07102678529918194, Final Batch Loss: 0.04641756787896156\n",
      "Epoch 2505, Loss: 0.030710494145751, Final Batch Loss: 0.005835928022861481\n",
      "Epoch 2506, Loss: 0.09282183274626732, Final Batch Loss: 0.044353730976581573\n",
      "Epoch 2507, Loss: 0.08368769846856594, Final Batch Loss: 0.025668000802397728\n",
      "Epoch 2508, Loss: 0.05997716635465622, Final Batch Loss: 0.03939216583967209\n",
      "Epoch 2509, Loss: 0.05506972037255764, Final Batch Loss: 0.015691624954342842\n",
      "Epoch 2510, Loss: 0.06463082134723663, Final Batch Loss: 0.03229367733001709\n",
      "Epoch 2511, Loss: 0.027060666121542454, Final Batch Loss: 0.007960795424878597\n",
      "Epoch 2512, Loss: 0.03850743733346462, Final Batch Loss: 0.009831009432673454\n",
      "Epoch 2513, Loss: 0.06119858659803867, Final Batch Loss: 0.028256455436348915\n",
      "Epoch 2514, Loss: 0.04824049677699804, Final Batch Loss: 0.012271533720195293\n",
      "Epoch 2515, Loss: 0.09513029083609581, Final Batch Loss: 0.07809361070394516\n",
      "Epoch 2516, Loss: 0.029080222360789776, Final Batch Loss: 0.0075342683121562\n",
      "Epoch 2517, Loss: 0.04545232467353344, Final Batch Loss: 0.02286999486386776\n",
      "Epoch 2518, Loss: 0.06998641043901443, Final Batch Loss: 0.043868519365787506\n",
      "Epoch 2519, Loss: 0.05512818321585655, Final Batch Loss: 0.037215933203697205\n",
      "Epoch 2520, Loss: 0.025112292729318142, Final Batch Loss: 0.006657768972218037\n",
      "Epoch 2521, Loss: 0.03822341188788414, Final Batch Loss: 0.017748625949025154\n",
      "Epoch 2522, Loss: 0.041565487161278725, Final Batch Loss: 0.019115500152111053\n",
      "Epoch 2523, Loss: 0.03852000553160906, Final Batch Loss: 0.02703155390918255\n",
      "Epoch 2524, Loss: 0.03188804071396589, Final Batch Loss: 0.007123102433979511\n",
      "Epoch 2525, Loss: 0.036916136741638184, Final Batch Loss: 0.008166562765836716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2526, Loss: 0.07826827466487885, Final Batch Loss: 0.0453471764922142\n",
      "Epoch 2527, Loss: 0.027579051442444324, Final Batch Loss: 0.013369068503379822\n",
      "Epoch 2528, Loss: 0.033636719919741154, Final Batch Loss: 0.014353099279105663\n",
      "Epoch 2529, Loss: 0.0619624312967062, Final Batch Loss: 0.012785432860255241\n",
      "Epoch 2530, Loss: 0.04635683447122574, Final Batch Loss: 0.025040408596396446\n",
      "Epoch 2531, Loss: 0.08181976526975632, Final Batch Loss: 0.05016631633043289\n",
      "Epoch 2532, Loss: 0.08015191927552223, Final Batch Loss: 0.0556778647005558\n",
      "Epoch 2533, Loss: 0.03298813011497259, Final Batch Loss: 0.02643020823597908\n",
      "Epoch 2534, Loss: 0.03331347228959203, Final Batch Loss: 0.005622506607323885\n",
      "Epoch 2535, Loss: 0.10562857612967491, Final Batch Loss: 0.06532197445631027\n",
      "Epoch 2536, Loss: 0.04660736210644245, Final Batch Loss: 0.02052280120551586\n",
      "Epoch 2537, Loss: 0.03605643846094608, Final Batch Loss: 0.011664031073451042\n",
      "Epoch 2538, Loss: 0.0997809823602438, Final Batch Loss: 0.07709082961082458\n",
      "Epoch 2539, Loss: 0.026025223545730114, Final Batch Loss: 0.010413766838610172\n",
      "Epoch 2540, Loss: 0.04991074837744236, Final Batch Loss: 0.03238813206553459\n",
      "Epoch 2541, Loss: 0.030308198183774948, Final Batch Loss: 0.012876512482762337\n",
      "Epoch 2542, Loss: 0.10730930790305138, Final Batch Loss: 0.0755765289068222\n",
      "Epoch 2543, Loss: 0.05267797224223614, Final Batch Loss: 0.024950847029685974\n",
      "Epoch 2544, Loss: 0.014071708545088768, Final Batch Loss: 0.005223982967436314\n",
      "Epoch 2545, Loss: 0.06293163821101189, Final Batch Loss: 0.045331574976444244\n",
      "Epoch 2546, Loss: 0.042088160291314125, Final Batch Loss: 0.005826616659760475\n",
      "Epoch 2547, Loss: 0.024066117592155933, Final Batch Loss: 0.006703081540763378\n",
      "Epoch 2548, Loss: 0.05204460024833679, Final Batch Loss: 0.013748154044151306\n",
      "Epoch 2549, Loss: 0.04735447093844414, Final Batch Loss: 0.03149090334773064\n",
      "Epoch 2550, Loss: 0.025752064771950245, Final Batch Loss: 0.004780822433531284\n",
      "Epoch 2551, Loss: 0.12869334407150745, Final Batch Loss: 0.11428217589855194\n",
      "Epoch 2552, Loss: 0.04176593944430351, Final Batch Loss: 0.02025737427175045\n",
      "Epoch 2553, Loss: 0.042242396622896194, Final Batch Loss: 0.014435239136219025\n",
      "Epoch 2554, Loss: 0.036438158713281155, Final Batch Loss: 0.030318479984998703\n",
      "Epoch 2555, Loss: 0.06976306438446045, Final Batch Loss: 0.03610916808247566\n",
      "Epoch 2556, Loss: 0.051425229758024216, Final Batch Loss: 0.03903381898999214\n",
      "Epoch 2557, Loss: 0.022238914854824543, Final Batch Loss: 0.008583026938140392\n",
      "Epoch 2558, Loss: 0.025817760732024908, Final Batch Loss: 0.004237124230712652\n",
      "Epoch 2559, Loss: 0.025623682886362076, Final Batch Loss: 0.010969915427267551\n",
      "Epoch 2560, Loss: 0.0704259080812335, Final Batch Loss: 0.05704931169748306\n",
      "Epoch 2561, Loss: 0.059039998799562454, Final Batch Loss: 0.030005300417542458\n",
      "Epoch 2562, Loss: 0.056385960429906845, Final Batch Loss: 0.04272622987627983\n",
      "Epoch 2563, Loss: 0.052227968350052834, Final Batch Loss: 0.031061338260769844\n",
      "Epoch 2564, Loss: 0.05068953474983573, Final Batch Loss: 0.007510797586292028\n",
      "Epoch 2565, Loss: 0.050767144188284874, Final Batch Loss: 0.03021237626671791\n",
      "Epoch 2566, Loss: 0.08132610097527504, Final Batch Loss: 0.04821073263883591\n",
      "Epoch 2567, Loss: 0.036951759830117226, Final Batch Loss: 0.008955013006925583\n",
      "Epoch 2568, Loss: 0.02503966446965933, Final Batch Loss: 0.008336194790899754\n",
      "Epoch 2569, Loss: 0.029345220886170864, Final Batch Loss: 0.012874803505837917\n",
      "Epoch 2570, Loss: 0.04840760678052902, Final Batch Loss: 0.02446189522743225\n",
      "Epoch 2571, Loss: 0.02649799082428217, Final Batch Loss: 0.009060344658792019\n",
      "Epoch 2572, Loss: 0.016932638827711344, Final Batch Loss: 0.0071708508767187595\n",
      "Epoch 2573, Loss: 0.10218346677720547, Final Batch Loss: 0.07889340817928314\n",
      "Epoch 2574, Loss: 0.018464187160134315, Final Batch Loss: 0.008984493091702461\n",
      "Epoch 2575, Loss: 0.03232005564495921, Final Batch Loss: 0.004928074311465025\n",
      "Epoch 2576, Loss: 0.02212404226884246, Final Batch Loss: 0.01641598902642727\n",
      "Epoch 2577, Loss: 0.05523369088768959, Final Batch Loss: 0.042297590523958206\n",
      "Epoch 2578, Loss: 0.019264670554548502, Final Batch Loss: 0.006431604269891977\n",
      "Epoch 2579, Loss: 0.06560459826141596, Final Batch Loss: 0.05648619309067726\n",
      "Epoch 2580, Loss: 0.03146159974858165, Final Batch Loss: 0.02374589815735817\n",
      "Epoch 2581, Loss: 0.038445073179900646, Final Batch Loss: 0.009755249135196209\n",
      "Epoch 2582, Loss: 0.049426060169935226, Final Batch Loss: 0.03140109404921532\n",
      "Epoch 2583, Loss: 0.06895874626934528, Final Batch Loss: 0.027129439637064934\n",
      "Epoch 2584, Loss: 0.03238371200859547, Final Batch Loss: 0.02113511972129345\n",
      "Epoch 2585, Loss: 0.045675456523895264, Final Batch Loss: 0.021089203655719757\n",
      "Epoch 2586, Loss: 0.04616251587867737, Final Batch Loss: 0.03131626173853874\n",
      "Epoch 2587, Loss: 0.04637036472558975, Final Batch Loss: 0.013411298394203186\n",
      "Epoch 2588, Loss: 0.045218291226774454, Final Batch Loss: 0.03846318647265434\n",
      "Epoch 2589, Loss: 0.06934364046901464, Final Batch Loss: 0.0550367534160614\n",
      "Epoch 2590, Loss: 0.03295534988865256, Final Batch Loss: 0.004173589404672384\n",
      "Epoch 2591, Loss: 0.050413498654961586, Final Batch Loss: 0.026303943246603012\n",
      "Epoch 2592, Loss: 0.05855676345527172, Final Batch Loss: 0.014992689713835716\n",
      "Epoch 2593, Loss: 0.028154632775112987, Final Batch Loss: 0.0027310035657137632\n",
      "Epoch 2594, Loss: 0.02371986908838153, Final Batch Loss: 0.017311546951532364\n",
      "Epoch 2595, Loss: 0.05058585852384567, Final Batch Loss: 0.0050778500735759735\n",
      "Epoch 2596, Loss: 0.030390999279916286, Final Batch Loss: 0.005374426953494549\n",
      "Epoch 2597, Loss: 0.032506671734154224, Final Batch Loss: 0.009201745502650738\n",
      "Epoch 2598, Loss: 0.04283101949840784, Final Batch Loss: 0.014349409379065037\n",
      "Epoch 2599, Loss: 0.01712850946933031, Final Batch Loss: 0.005707919597625732\n",
      "Epoch 2600, Loss: 0.014911018311977386, Final Batch Loss: 0.009841918013989925\n",
      "Epoch 2601, Loss: 0.05165350157767534, Final Batch Loss: 0.041855588555336\n",
      "Epoch 2602, Loss: 0.03056811075657606, Final Batch Loss: 0.012713600881397724\n",
      "Epoch 2603, Loss: 0.06771945022046566, Final Batch Loss: 0.04152524843811989\n",
      "Epoch 2604, Loss: 0.04032487515360117, Final Batch Loss: 0.013918868266046047\n",
      "Epoch 2605, Loss: 0.02017233707010746, Final Batch Loss: 0.00655252393335104\n",
      "Epoch 2606, Loss: 0.09029153175652027, Final Batch Loss: 0.06611336767673492\n",
      "Epoch 2607, Loss: 0.034237307496368885, Final Batch Loss: 0.013013550080358982\n",
      "Epoch 2608, Loss: 0.012079789070412517, Final Batch Loss: 0.0036310616414994\n",
      "Epoch 2609, Loss: 0.05905289761722088, Final Batch Loss: 0.03795333951711655\n",
      "Epoch 2610, Loss: 0.025303050875663757, Final Batch Loss: 0.011049585416913033\n",
      "Epoch 2611, Loss: 0.030161836417391896, Final Batch Loss: 0.003204562934115529\n",
      "Epoch 2612, Loss: 0.0648677758872509, Final Batch Loss: 0.003318633884191513\n",
      "Epoch 2613, Loss: 0.06112546660006046, Final Batch Loss: 0.0317043736577034\n",
      "Epoch 2614, Loss: 0.019583368208259344, Final Batch Loss: 0.012251382693648338\n",
      "Epoch 2615, Loss: 0.05729667656123638, Final Batch Loss: 0.029564930126070976\n",
      "Epoch 2616, Loss: 0.04727432411164045, Final Batch Loss: 0.011643472127616405\n",
      "Epoch 2617, Loss: 0.021651449147611856, Final Batch Loss: 0.005351936910301447\n",
      "Epoch 2618, Loss: 0.019476276822388172, Final Batch Loss: 0.009181180968880653\n",
      "Epoch 2619, Loss: 0.07866423856467009, Final Batch Loss: 0.0072991205379366875\n",
      "Epoch 2620, Loss: 0.07069976069033146, Final Batch Loss: 0.04566291347146034\n",
      "Epoch 2621, Loss: 0.04295129980891943, Final Batch Loss: 0.03057337924838066\n",
      "Epoch 2622, Loss: 0.02202176069840789, Final Batch Loss: 0.015936229377985\n",
      "Epoch 2623, Loss: 0.038000745233148336, Final Batch Loss: 0.031647294759750366\n",
      "Epoch 2624, Loss: 0.040093837305903435, Final Batch Loss: 0.024941567331552505\n",
      "Epoch 2625, Loss: 0.09120941907167435, Final Batch Loss: 0.08372464030981064\n",
      "Epoch 2626, Loss: 0.033528413623571396, Final Batch Loss: 0.01662520505487919\n",
      "Epoch 2627, Loss: 0.04661030787974596, Final Batch Loss: 0.032793689519166946\n",
      "Epoch 2628, Loss: 0.05613084323704243, Final Batch Loss: 0.03107164241373539\n",
      "Epoch 2629, Loss: 0.02902511414140463, Final Batch Loss: 0.009202524088323116\n",
      "Epoch 2630, Loss: 0.05615178309381008, Final Batch Loss: 0.028436021879315376\n",
      "Epoch 2631, Loss: 0.02542884647846222, Final Batch Loss: 0.011036391369998455\n",
      "Epoch 2632, Loss: 0.04095631465315819, Final Batch Loss: 0.02333982102572918\n",
      "Epoch 2633, Loss: 0.0187741806730628, Final Batch Loss: 0.010909444652497768\n",
      "Epoch 2634, Loss: 0.02071242779493332, Final Batch Loss: 0.006350710988044739\n",
      "Epoch 2635, Loss: 0.025147965643554926, Final Batch Loss: 0.0061698355711996555\n",
      "Epoch 2636, Loss: 0.07260573282837868, Final Batch Loss: 0.024401839822530746\n",
      "Epoch 2637, Loss: 0.0643779980018735, Final Batch Loss: 0.057741183787584305\n",
      "Epoch 2638, Loss: 0.05320948548614979, Final Batch Loss: 0.026056239381432533\n",
      "Epoch 2639, Loss: 0.03941615577787161, Final Batch Loss: 0.007305431179702282\n",
      "Epoch 2640, Loss: 0.026020140387117863, Final Batch Loss: 0.009640113450586796\n",
      "Epoch 2641, Loss: 0.015783763490617275, Final Batch Loss: 0.0036773495376110077\n",
      "Epoch 2642, Loss: 0.022936430294066668, Final Batch Loss: 0.005203476641327143\n",
      "Epoch 2643, Loss: 0.028762752190232277, Final Batch Loss: 0.015981119126081467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2644, Loss: 0.019139401614665985, Final Batch Loss: 0.004238291643559933\n",
      "Epoch 2645, Loss: 0.03923217300325632, Final Batch Loss: 0.008033554069697857\n",
      "Epoch 2646, Loss: 0.06435928121209145, Final Batch Loss: 0.04023462161421776\n",
      "Epoch 2647, Loss: 0.04872117191553116, Final Batch Loss: 0.0052856579422950745\n",
      "Epoch 2648, Loss: 0.011733049061149359, Final Batch Loss: 0.0034132287837564945\n",
      "Epoch 2649, Loss: 0.06949003040790558, Final Batch Loss: 0.021256297826766968\n",
      "Epoch 2650, Loss: 0.029464025981724262, Final Batch Loss: 0.009490990079939365\n",
      "Epoch 2651, Loss: 0.02719752350822091, Final Batch Loss: 0.006597141269594431\n",
      "Epoch 2652, Loss: 0.055315546691417694, Final Batch Loss: 0.027875186875462532\n",
      "Epoch 2653, Loss: 0.07481895759701729, Final Batch Loss: 0.03382907435297966\n",
      "Epoch 2654, Loss: 0.07134480401873589, Final Batch Loss: 0.031603310257196426\n",
      "Epoch 2655, Loss: 0.0159431966021657, Final Batch Loss: 0.004477064125239849\n",
      "Epoch 2656, Loss: 0.043563300743699074, Final Batch Loss: 0.030397459864616394\n",
      "Epoch 2657, Loss: 0.06429527327418327, Final Batch Loss: 0.0470108725130558\n",
      "Epoch 2658, Loss: 0.055259610060602427, Final Batch Loss: 0.00702821696177125\n",
      "Epoch 2659, Loss: 0.08759287372231483, Final Batch Loss: 0.04294948652386665\n",
      "Epoch 2660, Loss: 0.09679405763745308, Final Batch Loss: 0.036228496581315994\n",
      "Epoch 2661, Loss: 0.036514109931886196, Final Batch Loss: 0.012207037769258022\n",
      "Epoch 2662, Loss: 0.014493954833596945, Final Batch Loss: 0.004932553973048925\n",
      "Epoch 2663, Loss: 0.033152369782328606, Final Batch Loss: 0.006522264331579208\n",
      "Epoch 2664, Loss: 0.08537797629833221, Final Batch Loss: 0.037121254950761795\n",
      "Epoch 2665, Loss: 0.055427202954888344, Final Batch Loss: 0.030599385499954224\n",
      "Epoch 2666, Loss: 0.02725103683769703, Final Batch Loss: 0.008678950369358063\n",
      "Epoch 2667, Loss: 0.02185295708477497, Final Batch Loss: 0.009318370372056961\n",
      "Epoch 2668, Loss: 0.048613544553518295, Final Batch Loss: 0.03247500956058502\n",
      "Epoch 2669, Loss: 0.07017514761537313, Final Batch Loss: 0.01405151467770338\n",
      "Epoch 2670, Loss: 0.046972756274044514, Final Batch Loss: 0.01068869698792696\n",
      "Epoch 2671, Loss: 0.06847186852246523, Final Batch Loss: 0.055205460637807846\n",
      "Epoch 2672, Loss: 0.027081318199634552, Final Batch Loss: 0.016110021620988846\n",
      "Epoch 2673, Loss: 0.02876899391412735, Final Batch Loss: 0.013165050186216831\n",
      "Epoch 2674, Loss: 0.06415428593754768, Final Batch Loss: 0.04664529114961624\n",
      "Epoch 2675, Loss: 0.05131568945944309, Final Batch Loss: 0.03049742430448532\n",
      "Epoch 2676, Loss: 0.04899053554981947, Final Batch Loss: 0.03946937620639801\n",
      "Epoch 2677, Loss: 0.016727343201637268, Final Batch Loss: 0.005656658671796322\n",
      "Epoch 2678, Loss: 0.046752093359827995, Final Batch Loss: 0.027716247364878654\n",
      "Epoch 2679, Loss: 0.034748710226267576, Final Batch Loss: 0.005580812226980925\n",
      "Epoch 2680, Loss: 0.03200279548764229, Final Batch Loss: 0.01569841057062149\n",
      "Epoch 2681, Loss: 0.026130739599466324, Final Batch Loss: 0.004210304468870163\n",
      "Epoch 2682, Loss: 0.04428417538292706, Final Batch Loss: 0.003596379654482007\n",
      "Epoch 2683, Loss: 0.05886959284543991, Final Batch Loss: 0.024049006402492523\n",
      "Epoch 2684, Loss: 0.05781812220811844, Final Batch Loss: 0.039001449942588806\n",
      "Epoch 2685, Loss: 0.02617361769080162, Final Batch Loss: 0.008039146661758423\n",
      "Epoch 2686, Loss: 0.04201168054714799, Final Batch Loss: 0.0047873989678919315\n",
      "Epoch 2687, Loss: 0.07650982774794102, Final Batch Loss: 0.05619211867451668\n",
      "Epoch 2688, Loss: 0.01624219212681055, Final Batch Loss: 0.012024282477796078\n",
      "Epoch 2689, Loss: 0.09225630015134811, Final Batch Loss: 0.06856083869934082\n",
      "Epoch 2690, Loss: 0.05967227183282375, Final Batch Loss: 0.014959568157792091\n",
      "Epoch 2691, Loss: 0.022756585851311684, Final Batch Loss: 0.013120032846927643\n",
      "Epoch 2692, Loss: 0.04249035753309727, Final Batch Loss: 0.009183583781123161\n",
      "Epoch 2693, Loss: 0.1183935645967722, Final Batch Loss: 0.08750569820404053\n",
      "Epoch 2694, Loss: 0.02410172182135284, Final Batch Loss: 0.001805417938157916\n",
      "Epoch 2695, Loss: 0.052394866943359375, Final Batch Loss: 0.03824504092335701\n",
      "Epoch 2696, Loss: 0.06905320822261274, Final Batch Loss: 0.0033487805631011724\n",
      "Epoch 2697, Loss: 0.03624558914452791, Final Batch Loss: 0.026491448283195496\n",
      "Epoch 2698, Loss: 0.042894648388028145, Final Batch Loss: 0.00960606150329113\n",
      "Epoch 2699, Loss: 0.03301359247416258, Final Batch Loss: 0.0193525068461895\n",
      "Epoch 2700, Loss: 0.02470039576292038, Final Batch Loss: 0.016538795083761215\n",
      "Epoch 2701, Loss: 0.05833758972585201, Final Batch Loss: 0.041321251541376114\n",
      "Epoch 2702, Loss: 0.05545354261994362, Final Batch Loss: 0.028792187571525574\n",
      "Epoch 2703, Loss: 0.027700262144207954, Final Batch Loss: 0.013944598846137524\n",
      "Epoch 2704, Loss: 0.07407985534518957, Final Batch Loss: 0.06188049167394638\n",
      "Epoch 2705, Loss: 0.04390087258070707, Final Batch Loss: 0.010105143301188946\n",
      "Epoch 2706, Loss: 0.07268165983259678, Final Batch Loss: 0.05588724464178085\n",
      "Epoch 2707, Loss: 0.010581213980913162, Final Batch Loss: 0.005859226454049349\n",
      "Epoch 2708, Loss: 0.08619710244238377, Final Batch Loss: 0.05722683668136597\n",
      "Epoch 2709, Loss: 0.09309741854667664, Final Batch Loss: 0.040813006460666656\n",
      "Epoch 2710, Loss: 0.03333787899464369, Final Batch Loss: 0.004712405614554882\n",
      "Epoch 2711, Loss: 0.03062396962195635, Final Batch Loss: 0.0071828411892056465\n",
      "Epoch 2712, Loss: 0.034982020035386086, Final Batch Loss: 0.009259222075343132\n",
      "Epoch 2713, Loss: 0.04597503412514925, Final Batch Loss: 0.03346943110227585\n",
      "Epoch 2714, Loss: 0.03244509734213352, Final Batch Loss: 0.010074419900774956\n",
      "Epoch 2715, Loss: 0.04640231654047966, Final Batch Loss: 0.023075805976986885\n",
      "Epoch 2716, Loss: 0.04340979643166065, Final Batch Loss: 0.01972315087914467\n",
      "Epoch 2717, Loss: 0.05167113710194826, Final Batch Loss: 0.010338985361158848\n",
      "Epoch 2718, Loss: 0.06920844782143831, Final Batch Loss: 0.01378947589546442\n",
      "Epoch 2719, Loss: 0.026840147329494357, Final Batch Loss: 0.0013398609589785337\n",
      "Epoch 2720, Loss: 0.05303027015179396, Final Batch Loss: 0.04128221049904823\n",
      "Epoch 2721, Loss: 0.01645682705566287, Final Batch Loss: 0.01009290385991335\n",
      "Epoch 2722, Loss: 0.09979643300175667, Final Batch Loss: 0.0330856554210186\n",
      "Epoch 2723, Loss: 0.16119276452809572, Final Batch Loss: 0.1504274159669876\n",
      "Epoch 2724, Loss: 0.04555770196020603, Final Batch Loss: 0.02192126214504242\n",
      "Epoch 2725, Loss: 0.05857465974986553, Final Batch Loss: 0.01676364056766033\n",
      "Epoch 2726, Loss: 0.17608977295458317, Final Batch Loss: 0.14946207404136658\n",
      "Epoch 2727, Loss: 0.031264119781553745, Final Batch Loss: 0.006138336844742298\n",
      "Epoch 2728, Loss: 0.05456020310521126, Final Batch Loss: 0.0186600461602211\n",
      "Epoch 2729, Loss: 0.06646656803786755, Final Batch Loss: 0.030902406200766563\n",
      "Epoch 2730, Loss: 0.023519445210695267, Final Batch Loss: 0.008424309082329273\n",
      "Epoch 2731, Loss: 0.019596857018768787, Final Batch Loss: 0.007732899859547615\n",
      "Epoch 2732, Loss: 0.04007091419771314, Final Batch Loss: 0.006825432647019625\n",
      "Epoch 2733, Loss: 0.041205707006156445, Final Batch Loss: 0.027022257447242737\n",
      "Epoch 2734, Loss: 0.04084498155862093, Final Batch Loss: 0.01222089771181345\n",
      "Epoch 2735, Loss: 0.018995349761098623, Final Batch Loss: 0.007051222492009401\n",
      "Epoch 2736, Loss: 0.016059620305895805, Final Batch Loss: 0.00818818248808384\n",
      "Epoch 2737, Loss: 0.036263263784348965, Final Batch Loss: 0.011592402122914791\n",
      "Epoch 2738, Loss: 0.052909333258867264, Final Batch Loss: 0.018571708351373672\n",
      "Epoch 2739, Loss: 0.013512378558516502, Final Batch Loss: 0.004941113293170929\n",
      "Epoch 2740, Loss: 0.03916637413203716, Final Batch Loss: 0.025174671784043312\n",
      "Epoch 2741, Loss: 0.042587628588080406, Final Batch Loss: 0.026075122877955437\n",
      "Epoch 2742, Loss: 0.027777732349932194, Final Batch Loss: 0.012919163331389427\n",
      "Epoch 2743, Loss: 0.04032415896654129, Final Batch Loss: 0.021081244572997093\n",
      "Epoch 2744, Loss: 0.02011661371216178, Final Batch Loss: 0.007774150464683771\n",
      "Epoch 2745, Loss: 0.026015962474048138, Final Batch Loss: 0.00676493626087904\n",
      "Epoch 2746, Loss: 0.06444475473836064, Final Batch Loss: 0.0029880483634769917\n",
      "Epoch 2747, Loss: 0.020930487662553787, Final Batch Loss: 0.010495597496628761\n",
      "Epoch 2748, Loss: 0.06974667869508266, Final Batch Loss: 0.04404713213443756\n",
      "Epoch 2749, Loss: 0.046757105737924576, Final Batch Loss: 0.03184870257973671\n",
      "Epoch 2750, Loss: 0.10284201800823212, Final Batch Loss: 0.06321211904287338\n",
      "Epoch 2751, Loss: 0.016615106724202633, Final Batch Loss: 0.008168069645762444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2752, Loss: 0.008565724827349186, Final Batch Loss: 0.004370394162833691\n",
      "Epoch 2753, Loss: 0.03200475871562958, Final Batch Loss: 0.02423909865319729\n",
      "Epoch 2754, Loss: 0.09365943633019924, Final Batch Loss: 0.023593565449118614\n",
      "Epoch 2755, Loss: 0.041222430765628815, Final Batch Loss: 0.030686520040035248\n",
      "Epoch 2756, Loss: 0.02282431349158287, Final Batch Loss: 0.008953281678259373\n",
      "Epoch 2757, Loss: 0.04707339871674776, Final Batch Loss: 0.042139798402786255\n",
      "Epoch 2758, Loss: 0.06555837392807007, Final Batch Loss: 0.04212171956896782\n",
      "Epoch 2759, Loss: 0.0510032563470304, Final Batch Loss: 0.04452603682875633\n",
      "Epoch 2760, Loss: 0.03211205033585429, Final Batch Loss: 0.007417937275022268\n",
      "Epoch 2761, Loss: 0.056063733994960785, Final Batch Loss: 0.027294032275676727\n",
      "Epoch 2762, Loss: 0.04238339699804783, Final Batch Loss: 0.009933000430464745\n",
      "Epoch 2763, Loss: 0.03686971007846296, Final Batch Loss: 0.002648131689056754\n",
      "Epoch 2764, Loss: 0.028452101163566113, Final Batch Loss: 0.015071519650518894\n",
      "Epoch 2765, Loss: 0.05324208550155163, Final Batch Loss: 0.03701365739107132\n",
      "Epoch 2766, Loss: 0.01595839043147862, Final Batch Loss: 0.0037449311930686235\n",
      "Epoch 2767, Loss: 0.031009143218398094, Final Batch Loss: 0.011748088523745537\n",
      "Epoch 2768, Loss: 0.019150458043441176, Final Batch Loss: 0.003891631728038192\n",
      "Epoch 2769, Loss: 0.02588616218417883, Final Batch Loss: 0.011369194835424423\n",
      "Epoch 2770, Loss: 0.018728021532297134, Final Batch Loss: 0.008418201468884945\n",
      "Epoch 2771, Loss: 0.017609764356166124, Final Batch Loss: 0.012329594232141972\n",
      "Epoch 2772, Loss: 0.030621625017374754, Final Batch Loss: 0.007627639453858137\n",
      "Epoch 2773, Loss: 0.027252530679106712, Final Batch Loss: 0.00631958432495594\n",
      "Epoch 2774, Loss: 0.0296179186552763, Final Batch Loss: 0.0057935770601034164\n",
      "Epoch 2775, Loss: 0.051581982523202896, Final Batch Loss: 0.02524922415614128\n",
      "Epoch 2776, Loss: 0.029792829416692257, Final Batch Loss: 0.003891470842063427\n",
      "Epoch 2777, Loss: 0.007704497664235532, Final Batch Loss: 0.001541533856652677\n",
      "Epoch 2778, Loss: 0.02365410211496055, Final Batch Loss: 0.0026343713980168104\n",
      "Epoch 2779, Loss: 0.029246295802295208, Final Batch Loss: 0.022868216037750244\n",
      "Epoch 2780, Loss: 0.03015157673507929, Final Batch Loss: 0.014550300315022469\n",
      "Epoch 2781, Loss: 0.01797038596123457, Final Batch Loss: 0.012588486075401306\n",
      "Epoch 2782, Loss: 0.010699872858822346, Final Batch Loss: 0.002646620385348797\n",
      "Epoch 2783, Loss: 0.030642612837255, Final Batch Loss: 0.018079673871397972\n",
      "Epoch 2784, Loss: 0.07826754963025451, Final Batch Loss: 0.07425656169652939\n",
      "Epoch 2785, Loss: 0.01603730535134673, Final Batch Loss: 0.007610099855810404\n",
      "Epoch 2786, Loss: 0.0356524707749486, Final Batch Loss: 0.02771911397576332\n",
      "Epoch 2787, Loss: 0.016308682039380074, Final Batch Loss: 0.007508942857384682\n",
      "Epoch 2788, Loss: 0.018620602320879698, Final Batch Loss: 0.003340544644743204\n",
      "Epoch 2789, Loss: 0.034371661487966776, Final Batch Loss: 0.02899816259741783\n",
      "Epoch 2790, Loss: 0.08765220083296299, Final Batch Loss: 0.06631972640752792\n",
      "Epoch 2791, Loss: 0.0691126361489296, Final Batch Loss: 0.046156540513038635\n",
      "Epoch 2792, Loss: 0.01668473519384861, Final Batch Loss: 0.010225075297057629\n",
      "Epoch 2793, Loss: 0.016137390863150358, Final Batch Loss: 0.009839667938649654\n",
      "Epoch 2794, Loss: 0.029358507599681616, Final Batch Loss: 0.007704812567681074\n",
      "Epoch 2795, Loss: 0.022618773393332958, Final Batch Loss: 0.010669193230569363\n",
      "Epoch 2796, Loss: 0.04927307367324829, Final Batch Loss: 0.03472084179520607\n",
      "Epoch 2797, Loss: 0.023286890238523483, Final Batch Loss: 0.01819501630961895\n",
      "Epoch 2798, Loss: 0.015870027244091034, Final Batch Loss: 0.011457813903689384\n",
      "Epoch 2799, Loss: 0.01883009308949113, Final Batch Loss: 0.006398350466042757\n",
      "Epoch 2800, Loss: 0.04316427558660507, Final Batch Loss: 0.022185897454619408\n",
      "Epoch 2801, Loss: 0.0763874240219593, Final Batch Loss: 0.045626163482666016\n",
      "Epoch 2802, Loss: 0.019255314022302628, Final Batch Loss: 0.01432978268712759\n",
      "Epoch 2803, Loss: 0.02920831856317818, Final Batch Loss: 0.003649073885753751\n",
      "Epoch 2804, Loss: 0.013724285177886486, Final Batch Loss: 0.0035158004611730576\n",
      "Epoch 2805, Loss: 0.03288341127336025, Final Batch Loss: 0.017220403999090195\n",
      "Epoch 2806, Loss: 0.04364977590739727, Final Batch Loss: 0.03450696915388107\n",
      "Epoch 2807, Loss: 0.04550527594983578, Final Batch Loss: 0.03492800146341324\n",
      "Epoch 2808, Loss: 0.041579721961170435, Final Batch Loss: 0.004085714463144541\n",
      "Epoch 2809, Loss: 0.027244602097198367, Final Batch Loss: 0.0017937261145561934\n",
      "Epoch 2810, Loss: 0.030384480953216553, Final Batch Loss: 0.01540988776832819\n",
      "Epoch 2811, Loss: 0.07113758474588394, Final Batch Loss: 0.03402272239327431\n",
      "Epoch 2812, Loss: 0.010760696604847908, Final Batch Loss: 0.002373766154050827\n",
      "Epoch 2813, Loss: 0.04118000529706478, Final Batch Loss: 0.023111654445528984\n",
      "Epoch 2814, Loss: 0.03788445703685284, Final Batch Loss: 0.01849755272269249\n",
      "Epoch 2815, Loss: 0.12774336710572243, Final Batch Loss: 0.1068359762430191\n",
      "Epoch 2816, Loss: 0.014232878340408206, Final Batch Loss: 0.003519120393320918\n",
      "Epoch 2817, Loss: 0.036334977485239506, Final Batch Loss: 0.027577629312872887\n",
      "Epoch 2818, Loss: 0.022882241988554597, Final Batch Loss: 0.0035053810570389032\n",
      "Epoch 2819, Loss: 0.01282624457962811, Final Batch Loss: 0.0034245236311107874\n",
      "Epoch 2820, Loss: 0.031334967352449894, Final Batch Loss: 0.020097754895687103\n",
      "Epoch 2821, Loss: 0.04778682300820947, Final Batch Loss: 0.04224502295255661\n",
      "Epoch 2822, Loss: 0.05964494030922651, Final Batch Loss: 0.012626457028090954\n",
      "Epoch 2823, Loss: 0.01813354901969433, Final Batch Loss: 0.010573869571089745\n",
      "Epoch 2824, Loss: 0.013625525403767824, Final Batch Loss: 0.003303287085145712\n",
      "Epoch 2825, Loss: 0.03227025084197521, Final Batch Loss: 0.0117152389138937\n",
      "Epoch 2826, Loss: 0.012915873434394598, Final Batch Loss: 0.004728850442916155\n",
      "Epoch 2827, Loss: 0.016478955280035734, Final Batch Loss: 0.0063065714202821255\n",
      "Epoch 2828, Loss: 0.07460996694862843, Final Batch Loss: 0.018987728282809258\n",
      "Epoch 2829, Loss: 0.03623290825635195, Final Batch Loss: 0.026086851954460144\n",
      "Epoch 2830, Loss: 0.026577092707157135, Final Batch Loss: 0.009658491238951683\n",
      "Epoch 2831, Loss: 0.06571183167397976, Final Batch Loss: 0.04802624136209488\n",
      "Epoch 2832, Loss: 0.04564907215535641, Final Batch Loss: 0.025885658338665962\n",
      "Epoch 2833, Loss: 0.015559413470327854, Final Batch Loss: 0.004306434653699398\n",
      "Epoch 2834, Loss: 0.028934174217283726, Final Batch Loss: 0.008504546247422695\n",
      "Epoch 2835, Loss: 0.05134214647114277, Final Batch Loss: 0.029778478667140007\n",
      "Epoch 2836, Loss: 0.01999685214832425, Final Batch Loss: 0.007756391074508429\n",
      "Epoch 2837, Loss: 0.03361047292128205, Final Batch Loss: 0.029237845912575722\n",
      "Epoch 2838, Loss: 0.04564238805323839, Final Batch Loss: 0.012003914453089237\n",
      "Epoch 2839, Loss: 0.02377740724477917, Final Batch Loss: 0.0016416708240285516\n",
      "Epoch 2840, Loss: 0.020164383575320244, Final Batch Loss: 0.0035181697458028793\n",
      "Epoch 2841, Loss: 0.07931739464402199, Final Batch Loss: 0.050625503063201904\n",
      "Epoch 2842, Loss: 0.02282577659934759, Final Batch Loss: 0.0038433698937296867\n",
      "Epoch 2843, Loss: 0.052240459248423576, Final Batch Loss: 0.008998153731226921\n",
      "Epoch 2844, Loss: 0.010818729409947991, Final Batch Loss: 0.002562165493145585\n",
      "Epoch 2845, Loss: 0.052891047671437263, Final Batch Loss: 0.044796790927648544\n",
      "Epoch 2846, Loss: 0.07303475588560104, Final Batch Loss: 0.027483616024255753\n",
      "Epoch 2847, Loss: 0.023539820685982704, Final Batch Loss: 0.009378904476761818\n",
      "Epoch 2848, Loss: 0.04105444997549057, Final Batch Loss: 0.0076660290360450745\n",
      "Epoch 2849, Loss: 0.005798754282295704, Final Batch Loss: 0.002679515164345503\n",
      "Epoch 2850, Loss: 0.06380567699670792, Final Batch Loss: 0.05066151171922684\n",
      "Epoch 2851, Loss: 0.12481897324323654, Final Batch Loss: 0.11586582660675049\n",
      "Epoch 2852, Loss: 0.036866217851638794, Final Batch Loss: 0.030744381248950958\n",
      "Epoch 2853, Loss: 0.09049103781580925, Final Batch Loss: 0.052012231200933456\n",
      "Epoch 2854, Loss: 0.21233613416552544, Final Batch Loss: 0.15231981873512268\n",
      "Epoch 2855, Loss: 0.07222158648073673, Final Batch Loss: 0.022513801231980324\n",
      "Epoch 2856, Loss: 0.0503485007211566, Final Batch Loss: 0.011234345845878124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2857, Loss: 0.02804203238338232, Final Batch Loss: 0.010622118599712849\n",
      "Epoch 2858, Loss: 0.16379349306225777, Final Batch Loss: 0.11633998155593872\n",
      "Epoch 2859, Loss: 0.037608212791383266, Final Batch Loss: 0.006504788063466549\n",
      "Epoch 2860, Loss: 0.021777329966425896, Final Batch Loss: 0.011197177693247795\n",
      "Epoch 2861, Loss: 0.05698373727500439, Final Batch Loss: 0.03899126127362251\n",
      "Epoch 2862, Loss: 0.048390207812190056, Final Batch Loss: 0.028374359011650085\n",
      "Epoch 2863, Loss: 0.03995001735165715, Final Batch Loss: 0.034792833030223846\n",
      "Epoch 2864, Loss: 0.07606813311576843, Final Batch Loss: 0.02826032042503357\n",
      "Epoch 2865, Loss: 0.05648829787969589, Final Batch Loss: 0.02851652167737484\n",
      "Epoch 2866, Loss: 0.062317781150341034, Final Batch Loss: 0.044672951102256775\n",
      "Epoch 2867, Loss: 0.021510642021894455, Final Batch Loss: 0.009127847850322723\n",
      "Epoch 2868, Loss: 0.03831846220418811, Final Batch Loss: 0.004533383529633284\n",
      "Epoch 2869, Loss: 0.052436383441090584, Final Batch Loss: 0.017123466357588768\n",
      "Epoch 2870, Loss: 0.10771051794290543, Final Batch Loss: 0.02728823572397232\n",
      "Epoch 2871, Loss: 0.035028289537876844, Final Batch Loss: 0.003846652340143919\n",
      "Epoch 2872, Loss: 0.025075986981391907, Final Batch Loss: 0.011346778832376003\n",
      "Epoch 2873, Loss: 0.03721585590392351, Final Batch Loss: 0.0022766748443245888\n",
      "Epoch 2874, Loss: 0.03215582063421607, Final Batch Loss: 0.0030130851082503796\n",
      "Epoch 2875, Loss: 0.0492002684623003, Final Batch Loss: 0.021546833217144012\n",
      "Epoch 2876, Loss: 0.03622614126652479, Final Batch Loss: 0.00809068325906992\n",
      "Epoch 2877, Loss: 0.05467658210545778, Final Batch Loss: 0.003895801492035389\n",
      "Epoch 2878, Loss: 0.07050874456763268, Final Batch Loss: 0.043135203421115875\n",
      "Epoch 2879, Loss: 0.07152306847274303, Final Batch Loss: 0.04852115735411644\n",
      "Epoch 2880, Loss: 0.018540298100560904, Final Batch Loss: 0.011194615624845028\n",
      "Epoch 2881, Loss: 0.04316965863108635, Final Batch Loss: 0.0196573156863451\n",
      "Epoch 2882, Loss: 0.013640137854963541, Final Batch Loss: 0.006697655655443668\n",
      "Epoch 2883, Loss: 0.027733025141060352, Final Batch Loss: 0.009399241767823696\n",
      "Epoch 2884, Loss: 0.04601827822625637, Final Batch Loss: 0.021003669127821922\n",
      "Epoch 2885, Loss: 0.06336237490177155, Final Batch Loss: 0.003544241189956665\n",
      "Epoch 2886, Loss: 0.025057436898350716, Final Batch Loss: 0.007372098043560982\n",
      "Epoch 2887, Loss: 0.029415049590170383, Final Batch Loss: 0.011348978616297245\n",
      "Epoch 2888, Loss: 0.03651587851345539, Final Batch Loss: 0.018732497468590736\n",
      "Epoch 2889, Loss: 0.07434600591659546, Final Batch Loss: 0.05027136579155922\n",
      "Epoch 2890, Loss: 0.05346278287470341, Final Batch Loss: 0.03556237742304802\n",
      "Epoch 2891, Loss: 0.02324172528460622, Final Batch Loss: 0.0040761628188192844\n",
      "Epoch 2892, Loss: 0.0452125845476985, Final Batch Loss: 0.015505493618547916\n",
      "Epoch 2893, Loss: 0.012638872722163796, Final Batch Loss: 0.0026324514765292406\n",
      "Epoch 2894, Loss: 0.03483034856617451, Final Batch Loss: 0.01595771126449108\n",
      "Epoch 2895, Loss: 0.0383998267352581, Final Batch Loss: 0.01959093287587166\n",
      "Epoch 2896, Loss: 0.06124358996748924, Final Batch Loss: 0.05128968507051468\n",
      "Epoch 2897, Loss: 0.026838048361241817, Final Batch Loss: 0.012184877879917622\n",
      "Epoch 2898, Loss: 0.034235212020576, Final Batch Loss: 0.02807108871638775\n",
      "Epoch 2899, Loss: 0.033101691864430904, Final Batch Loss: 0.02235836163163185\n",
      "Epoch 2900, Loss: 0.03418656438589096, Final Batch Loss: 0.007976362481713295\n",
      "Epoch 2901, Loss: 0.08123652823269367, Final Batch Loss: 0.05902035906910896\n",
      "Epoch 2902, Loss: 0.05392498802393675, Final Batch Loss: 0.04934839904308319\n",
      "Epoch 2903, Loss: 0.07023759558796883, Final Batch Loss: 0.049005258828401566\n",
      "Epoch 2904, Loss: 0.04841570509597659, Final Batch Loss: 0.0043471637181937695\n",
      "Epoch 2905, Loss: 0.027104507200419903, Final Batch Loss: 0.01030938234180212\n",
      "Epoch 2906, Loss: 0.059723226353526115, Final Batch Loss: 0.026600731536746025\n",
      "Epoch 2907, Loss: 0.07527463417500257, Final Batch Loss: 0.007606807164847851\n",
      "Epoch 2908, Loss: 0.03161395760253072, Final Batch Loss: 0.0069941324181854725\n",
      "Epoch 2909, Loss: 0.1003183089196682, Final Batch Loss: 0.06632143259048462\n",
      "Epoch 2910, Loss: 0.0437596058472991, Final Batch Loss: 0.00371535774320364\n",
      "Epoch 2911, Loss: 0.0373914735391736, Final Batch Loss: 0.021884242072701454\n",
      "Epoch 2912, Loss: 0.03613332472741604, Final Batch Loss: 0.01749786175787449\n",
      "Epoch 2913, Loss: 0.06102403439581394, Final Batch Loss: 0.035450953990221024\n",
      "Epoch 2914, Loss: 0.02776084467768669, Final Batch Loss: 0.013115216046571732\n",
      "Epoch 2915, Loss: 0.08821073174476624, Final Batch Loss: 0.07099515199661255\n",
      "Epoch 2916, Loss: 0.15909531340003014, Final Batch Loss: 0.14107193052768707\n",
      "Epoch 2917, Loss: 0.08799226954579353, Final Batch Loss: 0.0568675734102726\n",
      "Epoch 2918, Loss: 0.04166121827438474, Final Batch Loss: 0.03641136363148689\n",
      "Epoch 2919, Loss: 0.07756448909640312, Final Batch Loss: 0.0450127013027668\n",
      "Epoch 2920, Loss: 0.029025468043982983, Final Batch Loss: 0.0077533358708024025\n",
      "Epoch 2921, Loss: 0.06904879771173, Final Batch Loss: 0.020522648468613625\n",
      "Epoch 2922, Loss: 0.04160895384848118, Final Batch Loss: 0.03022017516195774\n",
      "Epoch 2923, Loss: 0.09492903389036655, Final Batch Loss: 0.06645333766937256\n",
      "Epoch 2924, Loss: 0.07484165951609612, Final Batch Loss: 0.03198288753628731\n",
      "Epoch 2925, Loss: 0.1030251756310463, Final Batch Loss: 0.07023102790117264\n",
      "Epoch 2926, Loss: 0.03933944134041667, Final Batch Loss: 0.006045571994036436\n",
      "Epoch 2927, Loss: 0.10270536690950394, Final Batch Loss: 0.061243414878845215\n",
      "Epoch 2928, Loss: 0.12802615016698837, Final Batch Loss: 0.10454504936933517\n",
      "Epoch 2929, Loss: 0.0975948367267847, Final Batch Loss: 0.08833972364664078\n",
      "Epoch 2930, Loss: 0.027429789304733276, Final Batch Loss: 0.012286100536584854\n",
      "Epoch 2931, Loss: 0.06540005980059505, Final Batch Loss: 0.05900401994585991\n",
      "Epoch 2932, Loss: 0.08085020072758198, Final Batch Loss: 0.022688647732138634\n",
      "Epoch 2933, Loss: 0.059153467416763306, Final Batch Loss: 0.045374587178230286\n",
      "Epoch 2934, Loss: 0.0924476757645607, Final Batch Loss: 0.04751846194267273\n",
      "Epoch 2935, Loss: 0.07264884002506733, Final Batch Loss: 0.04979381710290909\n",
      "Epoch 2936, Loss: 0.06956079415977001, Final Batch Loss: 0.013093838468194008\n",
      "Epoch 2937, Loss: 0.062479715794324875, Final Batch Loss: 0.026142694056034088\n",
      "Epoch 2938, Loss: 0.0576489819213748, Final Batch Loss: 0.012899025343358517\n",
      "Epoch 2939, Loss: 0.01777618145570159, Final Batch Loss: 0.0074151488952338696\n",
      "Epoch 2940, Loss: 0.097025066614151, Final Batch Loss: 0.057704292237758636\n",
      "Epoch 2941, Loss: 0.03158526308834553, Final Batch Loss: 0.020242054015398026\n",
      "Epoch 2942, Loss: 0.0830216035246849, Final Batch Loss: 0.023754745721817017\n",
      "Epoch 2943, Loss: 0.039735447615385056, Final Batch Loss: 0.018887242302298546\n",
      "Epoch 2944, Loss: 0.016379181761294603, Final Batch Loss: 0.010218457318842411\n",
      "Epoch 2945, Loss: 0.037018115632236004, Final Batch Loss: 0.02222471497952938\n",
      "Epoch 2946, Loss: 0.023893224075436592, Final Batch Loss: 0.00716678611934185\n",
      "Epoch 2947, Loss: 0.028825754299759865, Final Batch Loss: 0.01191040500998497\n",
      "Epoch 2948, Loss: 0.028832131065428257, Final Batch Loss: 0.017926223576068878\n",
      "Epoch 2949, Loss: 0.019747593440115452, Final Batch Loss: 0.009056474082171917\n",
      "Epoch 2950, Loss: 0.028996335342526436, Final Batch Loss: 0.009655546396970749\n",
      "Epoch 2951, Loss: 0.027930045500397682, Final Batch Loss: 0.019819043576717377\n",
      "Epoch 2952, Loss: 0.045920589938759804, Final Batch Loss: 0.010920552536845207\n",
      "Epoch 2953, Loss: 0.033895937725901604, Final Batch Loss: 0.01820806786417961\n",
      "Epoch 2954, Loss: 0.043756750877946615, Final Batch Loss: 0.005997882690280676\n",
      "Epoch 2955, Loss: 0.051210446283221245, Final Batch Loss: 0.014586394652724266\n",
      "Epoch 2956, Loss: 0.03598127141594887, Final Batch Loss: 0.01253112405538559\n",
      "Epoch 2957, Loss: 0.014752694871276617, Final Batch Loss: 0.003769062925130129\n",
      "Epoch 2958, Loss: 0.02072826074436307, Final Batch Loss: 0.0068353391252458096\n",
      "Epoch 2959, Loss: 0.034498457331210375, Final Batch Loss: 0.004388843197375536\n",
      "Epoch 2960, Loss: 0.02458552923053503, Final Batch Loss: 0.004134281538426876\n",
      "Epoch 2961, Loss: 0.04583749361336231, Final Batch Loss: 0.016636760905385017\n",
      "Epoch 2962, Loss: 0.047203699592500925, Final Batch Loss: 0.040371425449848175\n",
      "Epoch 2963, Loss: 0.012146760011091828, Final Batch Loss: 0.0037383802700787783\n",
      "Epoch 2964, Loss: 0.0392360407859087, Final Batch Loss: 0.015625685453414917\n",
      "Epoch 2965, Loss: 0.017187259159982204, Final Batch Loss: 0.01346180122345686\n",
      "Epoch 2966, Loss: 0.0671910597011447, Final Batch Loss: 0.058021366596221924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2967, Loss: 0.019092923030257225, Final Batch Loss: 0.008736091665923595\n",
      "Epoch 2968, Loss: 0.04196987999603152, Final Batch Loss: 0.002115610521286726\n",
      "Epoch 2969, Loss: 0.07042255252599716, Final Batch Loss: 0.00524362176656723\n",
      "Epoch 2970, Loss: 0.012470236513763666, Final Batch Loss: 0.00816472340375185\n",
      "Epoch 2971, Loss: 0.02001083269715309, Final Batch Loss: 0.010344610549509525\n",
      "Epoch 2972, Loss: 0.05870442371815443, Final Batch Loss: 0.05060122162103653\n",
      "Epoch 2973, Loss: 0.02531985961832106, Final Batch Loss: 0.0028011540416628122\n",
      "Epoch 2974, Loss: 0.01829790137708187, Final Batch Loss: 0.003994951024651527\n",
      "Epoch 2975, Loss: 0.009409385733306408, Final Batch Loss: 0.003237797413021326\n",
      "Epoch 2976, Loss: 0.04328707046806812, Final Batch Loss: 0.008935624733567238\n",
      "Epoch 2977, Loss: 0.011569981463253498, Final Batch Loss: 0.005565429572016001\n",
      "Epoch 2978, Loss: 0.02804654184728861, Final Batch Loss: 0.006759182550013065\n",
      "Epoch 2979, Loss: 0.00787280430085957, Final Batch Loss: 0.002641396364197135\n",
      "Epoch 2980, Loss: 0.017306581139564514, Final Batch Loss: 0.007472465746104717\n",
      "Epoch 2981, Loss: 0.010516233742237091, Final Batch Loss: 0.005608230363577604\n",
      "Epoch 2982, Loss: 0.07674588914960623, Final Batch Loss: 0.0652383416891098\n",
      "Epoch 2983, Loss: 0.030885093845427036, Final Batch Loss: 0.005920174531638622\n",
      "Epoch 2984, Loss: 0.030953438952565193, Final Batch Loss: 0.020687052980065346\n",
      "Epoch 2985, Loss: 0.03167339600622654, Final Batch Loss: 0.02204817160964012\n",
      "Epoch 2986, Loss: 0.03269099001772702, Final Batch Loss: 0.0021107096690684557\n",
      "Epoch 2987, Loss: 0.02162980381399393, Final Batch Loss: 0.004964503459632397\n",
      "Epoch 2988, Loss: 0.014840624295175076, Final Batch Loss: 0.004966039210557938\n",
      "Epoch 2989, Loss: 0.01346433162689209, Final Batch Loss: 0.006615650840103626\n",
      "Epoch 2990, Loss: 0.021591241471469402, Final Batch Loss: 0.006105764769017696\n",
      "Epoch 2991, Loss: 0.03681736905127764, Final Batch Loss: 0.026660040020942688\n",
      "Epoch 2992, Loss: 0.017216105945408344, Final Batch Loss: 0.012779411859810352\n",
      "Epoch 2993, Loss: 0.026316581293940544, Final Batch Loss: 0.01533463504165411\n",
      "Epoch 2994, Loss: 0.03397437185049057, Final Batch Loss: 0.008185919374227524\n",
      "Epoch 2995, Loss: 0.04435351025313139, Final Batch Loss: 0.03615811839699745\n",
      "Epoch 2996, Loss: 0.009672097163274884, Final Batch Loss: 0.0058275675401091576\n",
      "Epoch 2997, Loss: 0.05602363124489784, Final Batch Loss: 0.01727372035384178\n",
      "Epoch 2998, Loss: 0.05347582884132862, Final Batch Loss: 0.023526860401034355\n",
      "Epoch 2999, Loss: 0.061899673426523805, Final Batch Loss: 0.0030227790120989084\n",
      "Epoch 3000, Loss: 0.01887651812285185, Final Batch Loss: 0.010129626840353012\n",
      "Epoch 3001, Loss: 0.08733182027935982, Final Batch Loss: 0.043780211359262466\n",
      "Epoch 3002, Loss: 0.01902583008632064, Final Batch Loss: 0.0034509715624153614\n",
      "Epoch 3003, Loss: 0.05880470387637615, Final Batch Loss: 0.012375911697745323\n",
      "Epoch 3004, Loss: 0.026640436612069607, Final Batch Loss: 0.01284161675721407\n",
      "Epoch 3005, Loss: 0.010728942696005106, Final Batch Loss: 0.00676599470898509\n",
      "Epoch 3006, Loss: 0.038785528391599655, Final Batch Loss: 0.018174855038523674\n",
      "Epoch 3007, Loss: 0.03324785828590393, Final Batch Loss: 0.007071748375892639\n",
      "Epoch 3008, Loss: 0.06676844786852598, Final Batch Loss: 0.006735782139003277\n",
      "Epoch 3009, Loss: 0.030540114268660545, Final Batch Loss: 0.01747344247996807\n",
      "Epoch 3010, Loss: 0.014837272465229034, Final Batch Loss: 0.0020971130579710007\n",
      "Epoch 3011, Loss: 0.03226462844759226, Final Batch Loss: 0.01363061461597681\n",
      "Epoch 3012, Loss: 0.061093058437108994, Final Batch Loss: 0.049423471093177795\n",
      "Epoch 3013, Loss: 0.023361786268651485, Final Batch Loss: 0.018141888082027435\n",
      "Epoch 3014, Loss: 0.050641472451388836, Final Batch Loss: 0.04144901782274246\n",
      "Epoch 3015, Loss: 0.014993419870734215, Final Batch Loss: 0.0060294196009635925\n",
      "Epoch 3016, Loss: 0.018109020311385393, Final Batch Loss: 0.007574085611850023\n",
      "Epoch 3017, Loss: 0.023166550090536475, Final Batch Loss: 0.0010852271225303411\n",
      "Epoch 3018, Loss: 0.01769406907260418, Final Batch Loss: 0.004513844847679138\n",
      "Epoch 3019, Loss: 0.01202959893271327, Final Batch Loss: 0.004587498493492603\n",
      "Epoch 3020, Loss: 0.02489974582567811, Final Batch Loss: 0.0048761372454464436\n",
      "Epoch 3021, Loss: 0.03396525140851736, Final Batch Loss: 0.026199867948889732\n",
      "Epoch 3022, Loss: 0.022666467120870948, Final Batch Loss: 0.002497978275641799\n",
      "Epoch 3023, Loss: 0.01438931911252439, Final Batch Loss: 0.0026916859205812216\n",
      "Epoch 3024, Loss: 0.024817219004034996, Final Batch Loss: 0.007615409791469574\n",
      "Epoch 3025, Loss: 0.029096147511154413, Final Batch Loss: 0.006480152253061533\n",
      "Epoch 3026, Loss: 0.03787521552294493, Final Batch Loss: 0.014150380156934261\n",
      "Epoch 3027, Loss: 0.022777915466576815, Final Batch Loss: 0.019233273342251778\n",
      "Epoch 3028, Loss: 0.026682729367166758, Final Batch Loss: 0.0045502991415560246\n",
      "Epoch 3029, Loss: 0.07157188327983022, Final Batch Loss: 0.06488646566867828\n",
      "Epoch 3030, Loss: 0.025250289821997285, Final Batch Loss: 0.0038800521288067102\n",
      "Epoch 3031, Loss: 0.047674243338406086, Final Batch Loss: 0.039022039622068405\n",
      "Epoch 3032, Loss: 0.011260445695370436, Final Batch Loss: 0.006941617000848055\n",
      "Epoch 3033, Loss: 0.0357332332059741, Final Batch Loss: 0.011056543327867985\n",
      "Epoch 3034, Loss: 0.045204076915979385, Final Batch Loss: 0.016670024022459984\n",
      "Epoch 3035, Loss: 0.05656988546252251, Final Batch Loss: 0.029132554307579994\n",
      "Epoch 3036, Loss: 0.05612412840127945, Final Batch Loss: 0.04889138787984848\n",
      "Epoch 3037, Loss: 0.09412428736686707, Final Batch Loss: 0.052675340324640274\n",
      "Epoch 3038, Loss: 0.0676370463334024, Final Batch Loss: 0.0042365617118775845\n",
      "Epoch 3039, Loss: 0.0593769948463887, Final Batch Loss: 0.003154660342261195\n",
      "Epoch 3040, Loss: 0.02199760638177395, Final Batch Loss: 0.013067842461168766\n",
      "Epoch 3041, Loss: 0.06419538054615259, Final Batch Loss: 0.049607932567596436\n",
      "Epoch 3042, Loss: 0.021259960019961, Final Batch Loss: 0.003175990888848901\n",
      "Epoch 3043, Loss: 0.05001983651891351, Final Batch Loss: 0.006743425969034433\n",
      "Epoch 3044, Loss: 0.020686439238488674, Final Batch Loss: 0.009976196102797985\n",
      "Epoch 3045, Loss: 0.05751503445208073, Final Batch Loss: 0.051469676196575165\n",
      "Epoch 3046, Loss: 0.03655763249844313, Final Batch Loss: 0.026593416929244995\n",
      "Epoch 3047, Loss: 0.056053273379802704, Final Batch Loss: 0.047641366720199585\n",
      "Epoch 3048, Loss: 0.04380788467824459, Final Batch Loss: 0.02489442192018032\n",
      "Epoch 3049, Loss: 0.012757976073771715, Final Batch Loss: 0.007422010879963636\n",
      "Epoch 3050, Loss: 0.06096881255507469, Final Batch Loss: 0.05591091513633728\n",
      "Epoch 3051, Loss: 0.029950128868222237, Final Batch Loss: 0.008373280987143517\n",
      "Epoch 3052, Loss: 0.03068386297672987, Final Batch Loss: 0.0025078384205698967\n",
      "Epoch 3053, Loss: 0.015206767246127129, Final Batch Loss: 0.00945355650037527\n",
      "Epoch 3054, Loss: 0.012096862774342299, Final Batch Loss: 0.008935709483921528\n",
      "Epoch 3055, Loss: 0.12407969310879707, Final Batch Loss: 0.08976729214191437\n",
      "Epoch 3056, Loss: 0.014373858226463199, Final Batch Loss: 0.011155139654874802\n",
      "Epoch 3057, Loss: 0.026994146406650543, Final Batch Loss: 0.018688691779971123\n",
      "Epoch 3058, Loss: 0.0536494255065918, Final Batch Loss: 0.025076862424612045\n",
      "Epoch 3059, Loss: 0.11096049100160599, Final Batch Loss: 0.07291918992996216\n",
      "Epoch 3060, Loss: 0.02630568388849497, Final Batch Loss: 0.01629261113703251\n",
      "Epoch 3061, Loss: 0.04145588865503669, Final Batch Loss: 0.005258460994809866\n",
      "Epoch 3062, Loss: 0.01895939838141203, Final Batch Loss: 0.015241580083966255\n",
      "Epoch 3063, Loss: 0.02316167624667287, Final Batch Loss: 0.004214430693536997\n",
      "Epoch 3064, Loss: 0.03919394500553608, Final Batch Loss: 0.016121400520205498\n",
      "Epoch 3065, Loss: 0.06875875918194652, Final Batch Loss: 0.004782992880791426\n",
      "Epoch 3066, Loss: 0.0187733038328588, Final Batch Loss: 0.011451524682343006\n",
      "Epoch 3067, Loss: 0.026700809597969055, Final Batch Loss: 0.019872933626174927\n",
      "Epoch 3068, Loss: 0.03143724240362644, Final Batch Loss: 0.016422901302576065\n",
      "Epoch 3069, Loss: 0.06694046407938004, Final Batch Loss: 0.047849833965301514\n",
      "Epoch 3070, Loss: 0.038473768159747124, Final Batch Loss: 0.02702622301876545\n",
      "Epoch 3071, Loss: 0.049707391764968634, Final Batch Loss: 0.0035865618847310543\n",
      "Epoch 3072, Loss: 0.027015102561563253, Final Batch Loss: 0.0039826626889407635\n",
      "Epoch 3073, Loss: 0.044405960477888584, Final Batch Loss: 0.03146110102534294\n",
      "Epoch 3074, Loss: 0.036639098078012466, Final Batch Loss: 0.008151069283485413\n",
      "Epoch 3075, Loss: 0.03602005774155259, Final Batch Loss: 0.030338581651449203\n",
      "Epoch 3076, Loss: 0.05377837084233761, Final Batch Loss: 0.022825080901384354\n",
      "Epoch 3077, Loss: 0.02284671738743782, Final Batch Loss: 0.0053873565047979355\n",
      "Epoch 3078, Loss: 0.011784730013459921, Final Batch Loss: 0.0013226275332272053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3079, Loss: 0.05778541788458824, Final Batch Loss: 0.03641771525144577\n",
      "Epoch 3080, Loss: 0.03945966809988022, Final Batch Loss: 0.022287284955382347\n",
      "Epoch 3081, Loss: 0.03537875600159168, Final Batch Loss: 0.020277509465813637\n",
      "Epoch 3082, Loss: 0.017549284268170595, Final Batch Loss: 0.004899969790130854\n",
      "Epoch 3083, Loss: 0.07766239903867245, Final Batch Loss: 0.04735667631030083\n",
      "Epoch 3084, Loss: 0.024298100266605616, Final Batch Loss: 0.005548669490963221\n",
      "Epoch 3085, Loss: 0.04214170062914491, Final Batch Loss: 0.0057211280800402164\n",
      "Epoch 3086, Loss: 0.14693111926317215, Final Batch Loss: 0.07382380962371826\n",
      "Epoch 3087, Loss: 0.051382170990109444, Final Batch Loss: 0.022499533370137215\n",
      "Epoch 3088, Loss: 0.010891208425164223, Final Batch Loss: 0.00406653480604291\n",
      "Epoch 3089, Loss: 0.020819831639528275, Final Batch Loss: 0.011917372234165668\n",
      "Epoch 3090, Loss: 0.05011223116889596, Final Batch Loss: 0.005693534854799509\n",
      "Epoch 3091, Loss: 0.04409432038664818, Final Batch Loss: 0.008307289332151413\n",
      "Epoch 3092, Loss: 0.032914491603150964, Final Batch Loss: 0.0038545301649719477\n",
      "Epoch 3093, Loss: 0.03140945266932249, Final Batch Loss: 0.007771139033138752\n",
      "Epoch 3094, Loss: 0.020356175024062395, Final Batch Loss: 0.01611085794866085\n",
      "Epoch 3095, Loss: 0.022550996858626604, Final Batch Loss: 0.006444858852773905\n",
      "Epoch 3096, Loss: 0.09219378605484962, Final Batch Loss: 0.05577781796455383\n",
      "Epoch 3097, Loss: 0.05982785485684872, Final Batch Loss: 0.0453818179666996\n",
      "Epoch 3098, Loss: 0.016305320430547, Final Batch Loss: 0.005855765659362078\n",
      "Epoch 3099, Loss: 0.03151039034128189, Final Batch Loss: 0.020893726497888565\n",
      "Epoch 3100, Loss: 0.043782403226941824, Final Batch Loss: 0.036279208958148956\n",
      "Epoch 3101, Loss: 0.02127573173493147, Final Batch Loss: 0.010308537632226944\n",
      "Epoch 3102, Loss: 0.031309652142226696, Final Batch Loss: 0.01951190084218979\n",
      "Epoch 3103, Loss: 0.021871443837881088, Final Batch Loss: 0.005650807172060013\n",
      "Epoch 3104, Loss: 0.01904526725411415, Final Batch Loss: 0.004835706204175949\n",
      "Epoch 3105, Loss: 0.031118583865463734, Final Batch Loss: 0.0254808496683836\n",
      "Epoch 3106, Loss: 0.06640025414526463, Final Batch Loss: 0.042627330869436264\n",
      "Epoch 3107, Loss: 0.020959561225026846, Final Batch Loss: 0.013413717038929462\n",
      "Epoch 3108, Loss: 0.01153082586824894, Final Batch Loss: 0.006357172038406134\n",
      "Epoch 3109, Loss: 0.01573520223610103, Final Batch Loss: 0.003503542160615325\n",
      "Epoch 3110, Loss: 0.07606863602995872, Final Batch Loss: 0.056936170905828476\n",
      "Epoch 3111, Loss: 0.05047520715743303, Final Batch Loss: 0.035271380096673965\n",
      "Epoch 3112, Loss: 0.01665208744816482, Final Batch Loss: 0.0022574958857148886\n",
      "Epoch 3113, Loss: 0.028588798828423023, Final Batch Loss: 0.014229336753487587\n",
      "Epoch 3114, Loss: 0.025333219207823277, Final Batch Loss: 0.00785986240953207\n",
      "Epoch 3115, Loss: 0.019763351418077946, Final Batch Loss: 0.0056173186749219894\n",
      "Epoch 3116, Loss: 0.019787161145359278, Final Batch Loss: 0.012638326734304428\n",
      "Epoch 3117, Loss: 0.02537496294826269, Final Batch Loss: 0.0041706254705786705\n",
      "Epoch 3118, Loss: 0.02982078678905964, Final Batch Loss: 0.019505290314555168\n",
      "Epoch 3119, Loss: 0.052777052856981754, Final Batch Loss: 0.005786594934761524\n",
      "Epoch 3120, Loss: 0.010756380390375853, Final Batch Loss: 0.005270634312182665\n",
      "Epoch 3121, Loss: 0.03240849357098341, Final Batch Loss: 0.025351669639348984\n",
      "Epoch 3122, Loss: 0.06393340788781643, Final Batch Loss: 0.057330016046762466\n",
      "Epoch 3123, Loss: 0.04336162097752094, Final Batch Loss: 0.020472701638936996\n",
      "Epoch 3124, Loss: 0.03740438632667065, Final Batch Loss: 0.017179157584905624\n",
      "Epoch 3125, Loss: 0.027146832086145878, Final Batch Loss: 0.01272533368319273\n",
      "Epoch 3126, Loss: 0.03517111798282713, Final Batch Loss: 0.0019296895479783416\n",
      "Epoch 3127, Loss: 0.06179334409534931, Final Batch Loss: 0.023455144837498665\n",
      "Epoch 3128, Loss: 0.07527393661439419, Final Batch Loss: 0.04428882896900177\n",
      "Epoch 3129, Loss: 0.018319697584956884, Final Batch Loss: 0.012098724022507668\n",
      "Epoch 3130, Loss: 0.03520261216908693, Final Batch Loss: 0.009039574302732944\n",
      "Epoch 3131, Loss: 0.03361984435468912, Final Batch Loss: 0.008865308947861195\n",
      "Epoch 3132, Loss: 0.0354809476993978, Final Batch Loss: 0.004028783645480871\n",
      "Epoch 3133, Loss: 0.01196030410937965, Final Batch Loss: 0.008588911965489388\n",
      "Epoch 3134, Loss: 0.04374499060213566, Final Batch Loss: 0.015366747975349426\n",
      "Epoch 3135, Loss: 0.013582940911874175, Final Batch Loss: 0.0020109533797949553\n",
      "Epoch 3136, Loss: 0.02677544578909874, Final Batch Loss: 0.004037521779537201\n",
      "Epoch 3137, Loss: 0.030389632564038038, Final Batch Loss: 0.004987099673599005\n",
      "Epoch 3138, Loss: 0.06158189009875059, Final Batch Loss: 0.051568664610385895\n",
      "Epoch 3139, Loss: 0.05019293399527669, Final Batch Loss: 0.04536553844809532\n",
      "Epoch 3140, Loss: 0.012957918457686901, Final Batch Loss: 0.006027435418218374\n",
      "Epoch 3141, Loss: 0.029484709142707288, Final Batch Loss: 0.0013658342650160193\n",
      "Epoch 3142, Loss: 0.022788405418395996, Final Batch Loss: 0.0126300984993577\n",
      "Epoch 3143, Loss: 0.016140779945999384, Final Batch Loss: 0.011823638342320919\n",
      "Epoch 3144, Loss: 0.013824136927723885, Final Batch Loss: 0.007092173211276531\n",
      "Epoch 3145, Loss: 0.060826282016932964, Final Batch Loss: 0.0025344109162688255\n",
      "Epoch 3146, Loss: 0.02069793501868844, Final Batch Loss: 0.006529251579195261\n",
      "Epoch 3147, Loss: 0.0157832452096045, Final Batch Loss: 0.006831242237240076\n",
      "Epoch 3148, Loss: 0.01955692144110799, Final Batch Loss: 0.004667224828153849\n",
      "Epoch 3149, Loss: 0.04283782187849283, Final Batch Loss: 0.037645287811756134\n",
      "Epoch 3150, Loss: 0.10839634761214256, Final Batch Loss: 0.07142609357833862\n",
      "Epoch 3151, Loss: 0.06195772811770439, Final Batch Loss: 0.04059496149420738\n",
      "Epoch 3152, Loss: 0.020436787977814674, Final Batch Loss: 0.010300458408892155\n",
      "Epoch 3153, Loss: 0.029279221780598164, Final Batch Loss: 0.00354598555713892\n",
      "Epoch 3154, Loss: 0.016522220335900784, Final Batch Loss: 0.0025461148470640182\n",
      "Epoch 3155, Loss: 0.013368682004511356, Final Batch Loss: 0.009200260043144226\n",
      "Epoch 3156, Loss: 0.03216435667127371, Final Batch Loss: 0.004804654978215694\n",
      "Epoch 3157, Loss: 0.04753612820059061, Final Batch Loss: 0.03745633736252785\n",
      "Epoch 3158, Loss: 0.012936955317854881, Final Batch Loss: 0.006153217051178217\n",
      "Epoch 3159, Loss: 0.025689590722322464, Final Batch Loss: 0.004768406972289085\n",
      "Epoch 3160, Loss: 0.042640530969947577, Final Batch Loss: 0.0361303947865963\n",
      "Epoch 3161, Loss: 0.03780369460582733, Final Batch Loss: 0.01203201711177826\n",
      "Epoch 3162, Loss: 0.020730746444314718, Final Batch Loss: 0.005703614559024572\n",
      "Epoch 3163, Loss: 0.0747977253049612, Final Batch Loss: 0.05013912543654442\n",
      "Epoch 3164, Loss: 0.02265819674357772, Final Batch Loss: 0.014956656843423843\n",
      "Epoch 3165, Loss: 0.0648691114038229, Final Batch Loss: 0.04112796485424042\n",
      "Epoch 3166, Loss: 0.05108705908060074, Final Batch Loss: 0.03294704109430313\n",
      "Epoch 3167, Loss: 0.10278384573757648, Final Batch Loss: 0.07283246517181396\n",
      "Epoch 3168, Loss: 0.027384260669350624, Final Batch Loss: 0.012775600887835026\n",
      "Epoch 3169, Loss: 0.032926743384450674, Final Batch Loss: 0.006656245794147253\n",
      "Epoch 3170, Loss: 0.061052409932017326, Final Batch Loss: 0.05567890405654907\n",
      "Epoch 3171, Loss: 0.04130144044756889, Final Batch Loss: 0.02867439016699791\n",
      "Epoch 3172, Loss: 0.05974320787936449, Final Batch Loss: 0.006457374431192875\n",
      "Epoch 3173, Loss: 0.10136816184967756, Final Batch Loss: 0.014776128344237804\n",
      "Epoch 3174, Loss: 0.03625407977961004, Final Batch Loss: 0.0029742137994617224\n",
      "Epoch 3175, Loss: 0.03967847116291523, Final Batch Loss: 0.016770455986261368\n",
      "Epoch 3176, Loss: 0.05201353505253792, Final Batch Loss: 0.02329028770327568\n",
      "Epoch 3177, Loss: 0.13535448163747787, Final Batch Loss: 0.058307796716690063\n",
      "Epoch 3178, Loss: 0.04485609568655491, Final Batch Loss: 0.006592581048607826\n",
      "Epoch 3179, Loss: 0.030157499946653843, Final Batch Loss: 0.00657855998724699\n",
      "Epoch 3180, Loss: 0.048080498818308115, Final Batch Loss: 0.0074185156263411045\n",
      "Epoch 3181, Loss: 0.031824556179344654, Final Batch Loss: 0.011229577474296093\n",
      "Epoch 3182, Loss: 0.032643954968079925, Final Batch Loss: 0.0029291973914951086\n",
      "Epoch 3183, Loss: 0.01634338079020381, Final Batch Loss: 0.007591086905449629\n",
      "Epoch 3184, Loss: 0.05432654218748212, Final Batch Loss: 0.002472237218171358\n",
      "Epoch 3185, Loss: 0.09113401174545288, Final Batch Loss: 0.07768513262271881\n",
      "Epoch 3186, Loss: 0.0778120793402195, Final Batch Loss: 0.06148554012179375\n",
      "Epoch 3187, Loss: 0.011362332850694656, Final Batch Loss: 0.002187664620578289\n",
      "Epoch 3188, Loss: 0.019640835467725992, Final Batch Loss: 0.014420575462281704\n",
      "Epoch 3189, Loss: 0.02981651108711958, Final Batch Loss: 0.02514459565281868\n",
      "Epoch 3190, Loss: 0.04685921361669898, Final Batch Loss: 0.04040810093283653\n",
      "Epoch 3191, Loss: 0.022117014974355698, Final Batch Loss: 0.011654010973870754\n",
      "Epoch 3192, Loss: 0.05666228197515011, Final Batch Loss: 0.023983629420399666\n",
      "Epoch 3193, Loss: 0.040650309761986136, Final Batch Loss: 0.003098232438787818\n",
      "Epoch 3194, Loss: 0.01043595839291811, Final Batch Loss: 0.003500164020806551\n",
      "Epoch 3195, Loss: 0.0172786433249712, Final Batch Loss: 0.0056267231702804565\n",
      "Epoch 3196, Loss: 0.11443218495696783, Final Batch Loss: 0.10625462979078293\n",
      "Epoch 3197, Loss: 0.03167126886546612, Final Batch Loss: 0.008992206305265427\n",
      "Epoch 3198, Loss: 0.017996340757235885, Final Batch Loss: 0.0027716828044503927\n",
      "Epoch 3199, Loss: 0.04552562162280083, Final Batch Loss: 0.03666824847459793\n",
      "Epoch 3200, Loss: 0.06741013238206506, Final Batch Loss: 0.00543541694059968\n",
      "Epoch 3201, Loss: 0.03866888163611293, Final Batch Loss: 0.034529924392700195\n",
      "Epoch 3202, Loss: 0.03387416072655469, Final Batch Loss: 0.001265718718059361\n",
      "Epoch 3203, Loss: 0.0516491886228323, Final Batch Loss: 0.04645387828350067\n",
      "Epoch 3204, Loss: 0.02931127790361643, Final Batch Loss: 0.014247013255953789\n",
      "Epoch 3205, Loss: 0.026331831701099873, Final Batch Loss: 0.018516693264245987\n",
      "Epoch 3206, Loss: 0.012150089722126722, Final Batch Loss: 0.004252555314451456\n",
      "Epoch 3207, Loss: 0.13632667064666748, Final Batch Loss: 0.1161537691950798\n",
      "Epoch 3208, Loss: 0.0686819450929761, Final Batch Loss: 0.060502830892801285\n",
      "Epoch 3209, Loss: 0.016604783944785595, Final Batch Loss: 0.0067806486040353775\n",
      "Epoch 3210, Loss: 0.09882101230323315, Final Batch Loss: 0.08308975398540497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3211, Loss: 0.015192253049463034, Final Batch Loss: 0.005548814777284861\n",
      "Epoch 3212, Loss: 0.029087613336741924, Final Batch Loss: 0.012040502391755581\n",
      "Epoch 3213, Loss: 0.02571036107838154, Final Batch Loss: 0.012101677246391773\n",
      "Epoch 3214, Loss: 0.04074610862880945, Final Batch Loss: 0.03170311450958252\n",
      "Epoch 3215, Loss: 0.04062909726053476, Final Batch Loss: 0.0031492123380303383\n",
      "Epoch 3216, Loss: 0.016244233585894108, Final Batch Loss: 0.004243194125592709\n",
      "Epoch 3217, Loss: 0.07955523673444986, Final Batch Loss: 0.07007461786270142\n",
      "Epoch 3218, Loss: 0.03186454391106963, Final Batch Loss: 0.007566885557025671\n",
      "Epoch 3219, Loss: 0.021132882218807936, Final Batch Loss: 0.013857915997505188\n",
      "Epoch 3220, Loss: 0.1018305066972971, Final Batch Loss: 0.0850890502333641\n",
      "Epoch 3221, Loss: 0.015216889325529337, Final Batch Loss: 0.010877287946641445\n",
      "Epoch 3222, Loss: 0.04314563237130642, Final Batch Loss: 0.03407188132405281\n",
      "Epoch 3223, Loss: 0.008516309317201376, Final Batch Loss: 0.0037658358924090862\n",
      "Epoch 3224, Loss: 0.09098367299884558, Final Batch Loss: 0.07663319259881973\n",
      "Epoch 3225, Loss: 0.18742414563894272, Final Batch Loss: 0.16190819442272186\n",
      "Epoch 3226, Loss: 0.029748194385319948, Final Batch Loss: 0.023896675556898117\n",
      "Epoch 3227, Loss: 0.05388438701629639, Final Batch Loss: 0.021110624074935913\n",
      "Epoch 3228, Loss: 0.030087873805314302, Final Batch Loss: 0.005681928712874651\n",
      "Epoch 3229, Loss: 0.026029273867607117, Final Batch Loss: 0.013987044803798199\n",
      "Epoch 3230, Loss: 0.04417717084288597, Final Batch Loss: 0.02700198069214821\n",
      "Epoch 3231, Loss: 0.0833776630461216, Final Batch Loss: 0.033299677073955536\n",
      "Epoch 3232, Loss: 0.05067585129290819, Final Batch Loss: 0.014832419343292713\n",
      "Epoch 3233, Loss: 0.022627318277955055, Final Batch Loss: 0.018597325310111046\n",
      "Epoch 3234, Loss: 0.03552038036286831, Final Batch Loss: 0.028135184198617935\n",
      "Epoch 3235, Loss: 0.02316312282346189, Final Batch Loss: 0.003492550691589713\n",
      "Epoch 3236, Loss: 0.011049044784158468, Final Batch Loss: 0.006013403180986643\n",
      "Epoch 3237, Loss: 0.14993193745613098, Final Batch Loss: 0.08888817578554153\n",
      "Epoch 3238, Loss: 0.018319771625101566, Final Batch Loss: 0.009181375615298748\n",
      "Epoch 3239, Loss: 0.022836067713797092, Final Batch Loss: 0.01874127797782421\n",
      "Epoch 3240, Loss: 0.03735177963972092, Final Batch Loss: 0.007293703034520149\n",
      "Epoch 3241, Loss: 0.026257139164954424, Final Batch Loss: 0.005469710100442171\n",
      "Epoch 3242, Loss: 0.024568751454353333, Final Batch Loss: 0.0054174549877643585\n",
      "Epoch 3243, Loss: 0.0809217244386673, Final Batch Loss: 0.06786637753248215\n",
      "Epoch 3244, Loss: 0.05932699143886566, Final Batch Loss: 0.019884370267391205\n",
      "Epoch 3245, Loss: 0.04181154351681471, Final Batch Loss: 0.009596354328095913\n",
      "Epoch 3246, Loss: 0.0289401737973094, Final Batch Loss: 0.012460474856197834\n",
      "Epoch 3247, Loss: 0.02867419645190239, Final Batch Loss: 0.00938422605395317\n",
      "Epoch 3248, Loss: 0.15309818647801876, Final Batch Loss: 0.1299472153186798\n",
      "Epoch 3249, Loss: 0.045654546935111284, Final Batch Loss: 0.04012879729270935\n",
      "Epoch 3250, Loss: 0.07409828715026379, Final Batch Loss: 0.05403287708759308\n",
      "Epoch 3251, Loss: 0.01089198375120759, Final Batch Loss: 0.0033061886206269264\n",
      "Epoch 3252, Loss: 0.06728920340538025, Final Batch Loss: 0.0210648812353611\n",
      "Epoch 3253, Loss: 0.012563847820274532, Final Batch Loss: 0.0018874191446229815\n",
      "Epoch 3254, Loss: 0.197121299803257, Final Batch Loss: 0.06756170839071274\n",
      "Epoch 3255, Loss: 0.03859373927116394, Final Batch Loss: 0.011077996343374252\n",
      "Epoch 3256, Loss: 0.06427480652928352, Final Batch Loss: 0.04114718735218048\n",
      "Epoch 3257, Loss: 0.008188265841454268, Final Batch Loss: 0.0019622202962636948\n",
      "Epoch 3258, Loss: 0.02045384468510747, Final Batch Loss: 0.005184511188417673\n",
      "Epoch 3259, Loss: 0.03665940649807453, Final Batch Loss: 0.022838067263364792\n",
      "Epoch 3260, Loss: 0.040656598284840584, Final Batch Loss: 0.019614456221461296\n",
      "Epoch 3261, Loss: 0.017947809770703316, Final Batch Loss: 0.008697832934558392\n",
      "Epoch 3262, Loss: 0.025041770190000534, Final Batch Loss: 0.016453588381409645\n",
      "Epoch 3263, Loss: 0.059489449486136436, Final Batch Loss: 0.038420699536800385\n",
      "Epoch 3264, Loss: 0.060487426817417145, Final Batch Loss: 0.03838316723704338\n",
      "Epoch 3265, Loss: 0.02854632819071412, Final Batch Loss: 0.00546247186139226\n",
      "Epoch 3266, Loss: 0.040410778019577265, Final Batch Loss: 0.03576299175620079\n",
      "Epoch 3267, Loss: 0.024542621336877346, Final Batch Loss: 0.007764323614537716\n",
      "Epoch 3268, Loss: 0.0663460772484541, Final Batch Loss: 0.05835346132516861\n",
      "Epoch 3269, Loss: 0.11335339490324259, Final Batch Loss: 0.10675373673439026\n",
      "Epoch 3270, Loss: 0.02168551180511713, Final Batch Loss: 0.012704731896519661\n",
      "Epoch 3271, Loss: 0.02030616533011198, Final Batch Loss: 0.008089393377304077\n",
      "Epoch 3272, Loss: 0.02120069833472371, Final Batch Loss: 0.005357649642974138\n",
      "Epoch 3273, Loss: 0.03121513221412897, Final Batch Loss: 0.026481064036488533\n",
      "Epoch 3274, Loss: 0.02041917433962226, Final Batch Loss: 0.006130885798484087\n",
      "Epoch 3275, Loss: 0.0394208156503737, Final Batch Loss: 0.0028864205814898014\n",
      "Epoch 3276, Loss: 0.04639196489006281, Final Batch Loss: 0.003154163248836994\n",
      "Epoch 3277, Loss: 0.03704661224037409, Final Batch Loss: 0.005339493043720722\n",
      "Epoch 3278, Loss: 0.023183623794466257, Final Batch Loss: 0.018266042694449425\n",
      "Epoch 3279, Loss: 0.020110821817070246, Final Batch Loss: 0.007743805181235075\n",
      "Epoch 3280, Loss: 0.0431102211587131, Final Batch Loss: 0.005761928390711546\n",
      "Epoch 3281, Loss: 0.038524212315678596, Final Batch Loss: 0.026191499084234238\n",
      "Epoch 3282, Loss: 0.014027064666152, Final Batch Loss: 0.0013288026675581932\n",
      "Epoch 3283, Loss: 0.18686338141560555, Final Batch Loss: 0.1341671496629715\n",
      "Epoch 3284, Loss: 0.07411893410608172, Final Batch Loss: 0.06756608933210373\n",
      "Epoch 3285, Loss: 0.04902652092278004, Final Batch Loss: 0.014158783480525017\n",
      "Epoch 3286, Loss: 0.04387431591749191, Final Batch Loss: 0.01762014627456665\n",
      "Epoch 3287, Loss: 0.0353966997936368, Final Batch Loss: 0.010358585976064205\n",
      "Epoch 3288, Loss: 0.03496838128194213, Final Batch Loss: 0.002898534294217825\n",
      "Epoch 3289, Loss: 0.019117400515824556, Final Batch Loss: 0.006395234260708094\n",
      "Epoch 3290, Loss: 0.04124821536242962, Final Batch Loss: 0.009950948879122734\n",
      "Epoch 3291, Loss: 0.01933663012459874, Final Batch Loss: 0.011932424269616604\n",
      "Epoch 3292, Loss: 0.013432249194011092, Final Batch Loss: 0.010638033039867878\n",
      "Epoch 3293, Loss: 0.07023082114756107, Final Batch Loss: 0.053747180849313736\n",
      "Epoch 3294, Loss: 0.019503403920680285, Final Batch Loss: 0.006901703309267759\n",
      "Epoch 3295, Loss: 0.02486110315658152, Final Batch Loss: 0.0038068389985710382\n",
      "Epoch 3296, Loss: 0.04089565994217992, Final Batch Loss: 0.03326363489031792\n",
      "Epoch 3297, Loss: 0.016636031214147806, Final Batch Loss: 0.007222201209515333\n",
      "Epoch 3298, Loss: 0.05732513405382633, Final Batch Loss: 0.021469080820679665\n",
      "Epoch 3299, Loss: 0.01837026048451662, Final Batch Loss: 0.012984631583094597\n",
      "Epoch 3300, Loss: 0.03016225784085691, Final Batch Loss: 0.002898441394791007\n",
      "Epoch 3301, Loss: 0.022646017372608185, Final Batch Loss: 0.010016966611146927\n",
      "Epoch 3302, Loss: 0.03242653328925371, Final Batch Loss: 0.013176674954593182\n",
      "Epoch 3303, Loss: 0.013176999986171722, Final Batch Loss: 0.007598718162626028\n",
      "Epoch 3304, Loss: 0.038648076355457306, Final Batch Loss: 0.016212666407227516\n",
      "Epoch 3305, Loss: 0.013917892705649137, Final Batch Loss: 0.008377766236662865\n",
      "Epoch 3306, Loss: 0.13896731287240982, Final Batch Loss: 0.07243736833333969\n",
      "Epoch 3307, Loss: 0.01909237541258335, Final Batch Loss: 0.009448007680475712\n",
      "Epoch 3308, Loss: 0.017809192650020123, Final Batch Loss: 0.007871109060943127\n",
      "Epoch 3309, Loss: 0.06596640311181545, Final Batch Loss: 0.06124957650899887\n",
      "Epoch 3310, Loss: 0.023892782628536224, Final Batch Loss: 0.012169686146080494\n",
      "Epoch 3311, Loss: 0.038530037738382816, Final Batch Loss: 0.006579269655048847\n",
      "Epoch 3312, Loss: 0.047059583477675915, Final Batch Loss: 0.01125068124383688\n",
      "Epoch 3313, Loss: 0.014510576613247395, Final Batch Loss: 0.006538762710988522\n",
      "Epoch 3314, Loss: 0.023577026091516018, Final Batch Loss: 0.017481036484241486\n",
      "Epoch 3315, Loss: 0.08237936720252037, Final Batch Loss: 0.03176635131239891\n",
      "Epoch 3316, Loss: 0.06053353566676378, Final Batch Loss: 0.014972549863159657\n",
      "Epoch 3317, Loss: 0.05695059150457382, Final Batch Loss: 0.022590864449739456\n",
      "Epoch 3318, Loss: 0.01657124562188983, Final Batch Loss: 0.005444448906928301\n",
      "Epoch 3319, Loss: 0.01575700333341956, Final Batch Loss: 0.010237797163426876\n",
      "Epoch 3320, Loss: 0.029327180236577988, Final Batch Loss: 0.01476007979363203\n",
      "Epoch 3321, Loss: 0.035376026295125484, Final Batch Loss: 0.009850448928773403\n",
      "Epoch 3322, Loss: 0.03232855303213, Final Batch Loss: 0.006868216674774885\n",
      "Epoch 3323, Loss: 0.05377434939146042, Final Batch Loss: 0.023687265813350677\n",
      "Epoch 3324, Loss: 0.06007675267755985, Final Batch Loss: 0.047683410346508026\n",
      "Epoch 3325, Loss: 0.039744369219988585, Final Batch Loss: 0.0022364850156009197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3326, Loss: 0.11567878909409046, Final Batch Loss: 0.09652412682771683\n",
      "Epoch 3327, Loss: 0.019116713665425777, Final Batch Loss: 0.0069711944088339806\n",
      "Epoch 3328, Loss: 0.04069019854068756, Final Batch Loss: 0.019908810034394264\n",
      "Epoch 3329, Loss: 0.06927125342190266, Final Batch Loss: 0.04251446947455406\n",
      "Epoch 3330, Loss: 0.06951599568128586, Final Batch Loss: 0.03232082352042198\n",
      "Epoch 3331, Loss: 0.036004072055220604, Final Batch Loss: 0.016297906637191772\n",
      "Epoch 3332, Loss: 0.02150962920859456, Final Batch Loss: 0.014791899360716343\n",
      "Epoch 3333, Loss: 0.04973399080336094, Final Batch Loss: 0.007850700989365578\n",
      "Epoch 3334, Loss: 0.018457286525517702, Final Batch Loss: 0.006150758359581232\n",
      "Epoch 3335, Loss: 0.030323147540912032, Final Batch Loss: 0.0022666396107524633\n",
      "Epoch 3336, Loss: 0.04549392079934478, Final Batch Loss: 0.0393088199198246\n",
      "Epoch 3337, Loss: 0.04695613868534565, Final Batch Loss: 0.005087351426482201\n",
      "Epoch 3338, Loss: 0.056501634418964386, Final Batch Loss: 0.035462819039821625\n",
      "Epoch 3339, Loss: 0.014785760547965765, Final Batch Loss: 0.004963719751685858\n",
      "Epoch 3340, Loss: 0.02496883738785982, Final Batch Loss: 0.01942637376487255\n",
      "Epoch 3341, Loss: 0.07157228421419859, Final Batch Loss: 0.06347378343343735\n",
      "Epoch 3342, Loss: 0.044893933460116386, Final Batch Loss: 0.023579398170113564\n",
      "Epoch 3343, Loss: 0.03643146716058254, Final Batch Loss: 0.006689341738820076\n",
      "Epoch 3344, Loss: 0.01917408499866724, Final Batch Loss: 0.006124158389866352\n",
      "Epoch 3345, Loss: 0.07390782609581947, Final Batch Loss: 0.058961138129234314\n",
      "Epoch 3346, Loss: 0.0702427364885807, Final Batch Loss: 0.024371221661567688\n",
      "Epoch 3347, Loss: 0.011558544356375933, Final Batch Loss: 0.00641272310167551\n",
      "Epoch 3348, Loss: 0.013170218095183372, Final Batch Loss: 0.00423426553606987\n",
      "Epoch 3349, Loss: 0.04786903131753206, Final Batch Loss: 0.034768737852573395\n",
      "Epoch 3350, Loss: 0.04098094440996647, Final Batch Loss: 0.021209752187132835\n",
      "Epoch 3351, Loss: 0.03343857452273369, Final Batch Loss: 0.019405566155910492\n",
      "Epoch 3352, Loss: 0.039271701127290726, Final Batch Loss: 0.02114000916481018\n",
      "Epoch 3353, Loss: 0.04240229586139321, Final Batch Loss: 0.03518817573785782\n",
      "Epoch 3354, Loss: 0.04898160137236118, Final Batch Loss: 0.029706686735153198\n",
      "Epoch 3355, Loss: 0.017723691184073687, Final Batch Loss: 0.0057198223657906055\n",
      "Epoch 3356, Loss: 0.09324664156883955, Final Batch Loss: 0.08334548771381378\n",
      "Epoch 3357, Loss: 0.03814340569078922, Final Batch Loss: 0.012835841625928879\n",
      "Epoch 3358, Loss: 0.03644141647964716, Final Batch Loss: 0.00803735014051199\n",
      "Epoch 3359, Loss: 0.018625086173415184, Final Batch Loss: 0.011476973071694374\n",
      "Epoch 3360, Loss: 0.027448881417512894, Final Batch Loss: 0.019432401284575462\n",
      "Epoch 3361, Loss: 0.014635427389293909, Final Batch Loss: 0.005198384169489145\n",
      "Epoch 3362, Loss: 0.09471866115927696, Final Batch Loss: 0.04679396003484726\n",
      "Epoch 3363, Loss: 0.02191428281366825, Final Batch Loss: 0.011202281340956688\n",
      "Epoch 3364, Loss: 0.014929094351828098, Final Batch Loss: 0.010835226625204086\n",
      "Epoch 3365, Loss: 0.019641549792140722, Final Batch Loss: 0.014050236903131008\n",
      "Epoch 3366, Loss: 0.055178272537887096, Final Batch Loss: 0.04517115280032158\n",
      "Epoch 3367, Loss: 0.01321565848775208, Final Batch Loss: 0.009629147127270699\n",
      "Epoch 3368, Loss: 0.01150294387480244, Final Batch Loss: 0.0009497114806436002\n",
      "Epoch 3369, Loss: 0.03061598353087902, Final Batch Loss: 0.008742209523916245\n",
      "Epoch 3370, Loss: 0.012149700429290533, Final Batch Loss: 0.006234484259039164\n",
      "Epoch 3371, Loss: 0.03894074261188507, Final Batch Loss: 0.02742837183177471\n",
      "Epoch 3372, Loss: 0.0163366268388927, Final Batch Loss: 0.004938418511301279\n",
      "Epoch 3373, Loss: 0.018120139371603727, Final Batch Loss: 0.005749293137341738\n",
      "Epoch 3374, Loss: 0.023230193182826042, Final Batch Loss: 0.013966148719191551\n",
      "Epoch 3375, Loss: 0.013383430428802967, Final Batch Loss: 0.0042291684076189995\n",
      "Epoch 3376, Loss: 0.02151623461395502, Final Batch Loss: 0.01259264163672924\n",
      "Epoch 3377, Loss: 0.011332661379128695, Final Batch Loss: 0.004542885348200798\n",
      "Epoch 3378, Loss: 0.01346239261329174, Final Batch Loss: 0.00833817757666111\n",
      "Epoch 3379, Loss: 0.031412260606884956, Final Batch Loss: 0.00267191044986248\n",
      "Epoch 3380, Loss: 0.01292544836178422, Final Batch Loss: 0.004337409045547247\n",
      "Epoch 3381, Loss: 0.030374245950952172, Final Batch Loss: 0.003352539846673608\n",
      "Epoch 3382, Loss: 0.028039013035595417, Final Batch Loss: 0.007250643335282803\n",
      "Epoch 3383, Loss: 0.06094606779515743, Final Batch Loss: 0.04879636690020561\n",
      "Epoch 3384, Loss: 0.07585521414875984, Final Batch Loss: 0.00458173081278801\n",
      "Epoch 3385, Loss: 0.011327863205224276, Final Batch Loss: 0.0057768686674535275\n",
      "Epoch 3386, Loss: 0.016265938989818096, Final Batch Loss: 0.006426595151424408\n",
      "Epoch 3387, Loss: 0.09376737847924232, Final Batch Loss: 0.06114603579044342\n",
      "Epoch 3388, Loss: 0.03244677698239684, Final Batch Loss: 0.005654496606439352\n",
      "Epoch 3389, Loss: 0.03257077373564243, Final Batch Loss: 0.013735765591263771\n",
      "Epoch 3390, Loss: 0.038383349776268005, Final Batch Loss: 0.021488578990101814\n",
      "Epoch 3391, Loss: 0.014562075724825263, Final Batch Loss: 0.010871793143451214\n",
      "Epoch 3392, Loss: 0.05333582405000925, Final Batch Loss: 0.004176021553575993\n",
      "Epoch 3393, Loss: 0.01863042265176773, Final Batch Loss: 0.005919015035033226\n",
      "Epoch 3394, Loss: 0.05333060957491398, Final Batch Loss: 0.018494414165616035\n",
      "Epoch 3395, Loss: 0.023920740000903606, Final Batch Loss: 0.004538205452263355\n",
      "Epoch 3396, Loss: 0.029486840590834618, Final Batch Loss: 0.0140492282807827\n",
      "Epoch 3397, Loss: 0.07591346651315689, Final Batch Loss: 0.05946924537420273\n",
      "Epoch 3398, Loss: 0.017672259942628443, Final Batch Loss: 0.0010197187075391412\n",
      "Epoch 3399, Loss: 0.03157425485551357, Final Batch Loss: 0.009364362806081772\n",
      "Epoch 3400, Loss: 0.017874871380627155, Final Batch Loss: 0.014274140819907188\n",
      "Epoch 3401, Loss: 0.012588800629600883, Final Batch Loss: 0.0032802100758999586\n",
      "Epoch 3402, Loss: 0.014802905265241861, Final Batch Loss: 0.0040662349201738834\n",
      "Epoch 3403, Loss: 0.027912340592592955, Final Batch Loss: 0.005944689270108938\n",
      "Epoch 3404, Loss: 0.033728581853210926, Final Batch Loss: 0.02516643889248371\n",
      "Epoch 3405, Loss: 0.060782747343182564, Final Batch Loss: 0.03930612653493881\n",
      "Epoch 3406, Loss: 0.021256156731396914, Final Batch Loss: 0.004603807348757982\n",
      "Epoch 3407, Loss: 0.05745613994076848, Final Batch Loss: 0.003204577136784792\n",
      "Epoch 3408, Loss: 0.053673102520406246, Final Batch Loss: 0.005855626426637173\n",
      "Epoch 3409, Loss: 0.018680985551327467, Final Batch Loss: 0.011319618672132492\n",
      "Epoch 3410, Loss: 0.016843296121805906, Final Batch Loss: 0.0039709932170808315\n",
      "Epoch 3411, Loss: 0.01121396292001009, Final Batch Loss: 0.007197535131126642\n",
      "Epoch 3412, Loss: 0.0428194273263216, Final Batch Loss: 0.004592416808009148\n",
      "Epoch 3413, Loss: 0.025528379483148456, Final Batch Loss: 0.02327115833759308\n",
      "Epoch 3414, Loss: 0.012372900964692235, Final Batch Loss: 0.00289490376599133\n",
      "Epoch 3415, Loss: 0.010721245780587196, Final Batch Loss: 0.004407871048897505\n",
      "Epoch 3416, Loss: 0.01361773768439889, Final Batch Loss: 0.008770940825343132\n",
      "Epoch 3417, Loss: 0.020831432193517685, Final Batch Loss: 0.003876321017742157\n",
      "Epoch 3418, Loss: 0.01755187101662159, Final Batch Loss: 0.01162716280668974\n",
      "Epoch 3419, Loss: 0.013567694928497076, Final Batch Loss: 0.005466405767947435\n",
      "Epoch 3420, Loss: 0.014337933738715947, Final Batch Loss: 0.0012121658073738217\n",
      "Epoch 3421, Loss: 0.0392294330522418, Final Batch Loss: 0.011786851100623608\n",
      "Epoch 3422, Loss: 0.01649427367374301, Final Batch Loss: 0.010793706402182579\n",
      "Epoch 3423, Loss: 0.008210241794586182, Final Batch Loss: 0.004044517874717712\n",
      "Epoch 3424, Loss: 0.031070680357515812, Final Batch Loss: 0.022975318133831024\n",
      "Epoch 3425, Loss: 0.02237544348463416, Final Batch Loss: 0.005603516008704901\n",
      "Epoch 3426, Loss: 0.06558618694543839, Final Batch Loss: 0.037925444543361664\n",
      "Epoch 3427, Loss: 0.038619598373770714, Final Batch Loss: 0.030694540590047836\n",
      "Epoch 3428, Loss: 0.014847280457615852, Final Batch Loss: 0.006583767011761665\n",
      "Epoch 3429, Loss: 0.017726180609315634, Final Batch Loss: 0.0057786512188613415\n",
      "Epoch 3430, Loss: 0.00598351052030921, Final Batch Loss: 0.00237010745331645\n",
      "Epoch 3431, Loss: 0.0078067530412226915, Final Batch Loss: 0.0028016904834657907\n",
      "Epoch 3432, Loss: 0.015455355402082205, Final Batch Loss: 0.004610568750649691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3433, Loss: 0.025514374021440744, Final Batch Loss: 0.0055929687805473804\n",
      "Epoch 3434, Loss: 0.03254118317272514, Final Batch Loss: 0.001132344244979322\n",
      "Epoch 3435, Loss: 0.031134633347392082, Final Batch Loss: 0.018290720880031586\n",
      "Epoch 3436, Loss: 0.021769374143332243, Final Batch Loss: 0.0036589554511010647\n",
      "Epoch 3437, Loss: 0.04897818900644779, Final Batch Loss: 0.041182924062013626\n",
      "Epoch 3438, Loss: 0.050425101653672755, Final Batch Loss: 0.0007582461694255471\n",
      "Epoch 3439, Loss: 0.045471721328794956, Final Batch Loss: 0.03602643683552742\n",
      "Epoch 3440, Loss: 0.010581081500276923, Final Batch Loss: 0.0037451183889061213\n",
      "Epoch 3441, Loss: 0.04963596165180206, Final Batch Loss: 0.039453309029340744\n",
      "Epoch 3442, Loss: 0.0353283251170069, Final Batch Loss: 0.03187442198395729\n",
      "Epoch 3443, Loss: 0.026053200708702207, Final Batch Loss: 0.0025373634416610003\n",
      "Epoch 3444, Loss: 0.004939579404890537, Final Batch Loss: 0.00135736633092165\n",
      "Epoch 3445, Loss: 0.028888946399092674, Final Batch Loss: 0.012305160984396935\n",
      "Epoch 3446, Loss: 0.08527873083949089, Final Batch Loss: 0.06512580066919327\n",
      "Epoch 3447, Loss: 0.0187995582818985, Final Batch Loss: 0.008825634606182575\n",
      "Epoch 3448, Loss: 0.015987748512998223, Final Batch Loss: 0.0018346284050494432\n",
      "Epoch 3449, Loss: 0.015325882006436586, Final Batch Loss: 0.0074492101557552814\n",
      "Epoch 3450, Loss: 0.01948307454586029, Final Batch Loss: 0.008256865665316582\n",
      "Epoch 3451, Loss: 0.017733489628881216, Final Batch Loss: 0.010793224908411503\n",
      "Epoch 3452, Loss: 0.010795920970849693, Final Batch Loss: 0.0014821969671174884\n",
      "Epoch 3453, Loss: 0.05484439991414547, Final Batch Loss: 0.038022931665182114\n",
      "Epoch 3454, Loss: 0.007958733476698399, Final Batch Loss: 0.0009276880882680416\n",
      "Epoch 3455, Loss: 0.059912748634815216, Final Batch Loss: 0.04019700363278389\n",
      "Epoch 3456, Loss: 0.016882731579244137, Final Batch Loss: 0.009519988670945168\n",
      "Epoch 3457, Loss: 0.037874131463468075, Final Batch Loss: 0.006349730305373669\n",
      "Epoch 3458, Loss: 0.016129031777381897, Final Batch Loss: 0.004177705384790897\n",
      "Epoch 3459, Loss: 0.02336421934887767, Final Batch Loss: 0.0051022241823375225\n",
      "Epoch 3460, Loss: 0.043002469232305884, Final Batch Loss: 0.0029801668133586645\n",
      "Epoch 3461, Loss: 0.0077481132466346025, Final Batch Loss: 0.002034543314948678\n",
      "Epoch 3462, Loss: 0.017524200025945902, Final Batch Loss: 0.0073165581561625\n",
      "Epoch 3463, Loss: 0.027435571188107133, Final Batch Loss: 0.024423476308584213\n",
      "Epoch 3464, Loss: 0.029419087804853916, Final Batch Loss: 0.0019544074311852455\n",
      "Epoch 3465, Loss: 0.011218450963497162, Final Batch Loss: 0.006934897042810917\n",
      "Epoch 3466, Loss: 0.015960456104949117, Final Batch Loss: 0.0031298028770834208\n",
      "Epoch 3467, Loss: 0.022216057870537043, Final Batch Loss: 0.004825175274163485\n",
      "Epoch 3468, Loss: 0.010313929058611393, Final Batch Loss: 0.005671156104654074\n",
      "Epoch 3469, Loss: 0.009708458557724953, Final Batch Loss: 0.006282833404839039\n",
      "Epoch 3470, Loss: 0.025456994771957397, Final Batch Loss: 0.005851047113537788\n",
      "Epoch 3471, Loss: 0.04202571325004101, Final Batch Loss: 0.016305336728692055\n",
      "Epoch 3472, Loss: 0.039700435008853674, Final Batch Loss: 0.005141542758792639\n",
      "Epoch 3473, Loss: 0.11080991476774216, Final Batch Loss: 0.06205311045050621\n",
      "Epoch 3474, Loss: 0.036876726895570755, Final Batch Loss: 0.011350875720381737\n",
      "Epoch 3475, Loss: 0.03626469150185585, Final Batch Loss: 0.003947392106056213\n",
      "Epoch 3476, Loss: 0.05305350571870804, Final Batch Loss: 0.02600196562707424\n",
      "Epoch 3477, Loss: 0.08005278743803501, Final Batch Loss: 0.06055232882499695\n",
      "Epoch 3478, Loss: 0.020337237045168877, Final Batch Loss: 0.005979240871965885\n",
      "Epoch 3479, Loss: 0.02918436098843813, Final Batch Loss: 0.004057017154991627\n",
      "Epoch 3480, Loss: 0.1589914821088314, Final Batch Loss: 0.13333795964717865\n",
      "Epoch 3481, Loss: 0.028216810896992683, Final Batch Loss: 0.01673230156302452\n",
      "Epoch 3482, Loss: 0.012104658875614405, Final Batch Loss: 0.0008981623686850071\n",
      "Epoch 3483, Loss: 0.04575740732252598, Final Batch Loss: 0.026386700570583344\n",
      "Epoch 3484, Loss: 0.08168896660208702, Final Batch Loss: 0.04138907045125961\n",
      "Epoch 3485, Loss: 0.07359492219984531, Final Batch Loss: 0.015487061813473701\n",
      "Epoch 3486, Loss: 0.038740454241633415, Final Batch Loss: 0.027298174798488617\n",
      "Epoch 3487, Loss: 0.08686928730458021, Final Batch Loss: 0.0036635054275393486\n",
      "Epoch 3488, Loss: 0.018925624433904886, Final Batch Loss: 0.003930638078600168\n",
      "Epoch 3489, Loss: 0.017258178675547242, Final Batch Loss: 0.013926415704190731\n",
      "Epoch 3490, Loss: 0.03645892534404993, Final Batch Loss: 0.026519186794757843\n",
      "Epoch 3491, Loss: 0.049878946505486965, Final Batch Loss: 0.012528701685369015\n",
      "Epoch 3492, Loss: 0.05960160307586193, Final Batch Loss: 0.0348113588988781\n",
      "Epoch 3493, Loss: 0.02913943910971284, Final Batch Loss: 0.022943999618291855\n",
      "Epoch 3494, Loss: 0.026823976077139378, Final Batch Loss: 0.007318274118006229\n",
      "Epoch 3495, Loss: 0.019912586081773043, Final Batch Loss: 0.0062804254703223705\n",
      "Epoch 3496, Loss: 0.0357879176735878, Final Batch Loss: 0.01790221408009529\n",
      "Epoch 3497, Loss: 0.013950449414551258, Final Batch Loss: 0.007186582777649164\n",
      "Epoch 3498, Loss: 0.02806443814188242, Final Batch Loss: 0.014319567009806633\n",
      "Epoch 3499, Loss: 0.022543371189385653, Final Batch Loss: 0.00604627700522542\n",
      "Epoch 3500, Loss: 0.04008811339735985, Final Batch Loss: 0.02020794153213501\n",
      "Epoch 3501, Loss: 0.05457872478291392, Final Batch Loss: 0.048433322459459305\n",
      "Epoch 3502, Loss: 0.1085801050066948, Final Batch Loss: 0.06534001976251602\n",
      "Epoch 3503, Loss: 0.024659043177962303, Final Batch Loss: 0.01175649743527174\n",
      "Epoch 3504, Loss: 0.014572530519217253, Final Batch Loss: 0.0034850039519369602\n",
      "Epoch 3505, Loss: 0.04827361926436424, Final Batch Loss: 0.02874944731593132\n",
      "Epoch 3506, Loss: 0.04049230134114623, Final Batch Loss: 0.007753861602395773\n",
      "Epoch 3507, Loss: 0.037788701709359884, Final Batch Loss: 0.005664446856826544\n",
      "Epoch 3508, Loss: 0.05086113605648279, Final Batch Loss: 0.005627603270113468\n",
      "Epoch 3509, Loss: 0.03569862595759332, Final Batch Loss: 0.0029426810797303915\n",
      "Epoch 3510, Loss: 0.04061074834316969, Final Batch Loss: 0.01059711817651987\n",
      "Epoch 3511, Loss: 0.03686968400143087, Final Batch Loss: 0.0028516144957393408\n",
      "Epoch 3512, Loss: 0.02850495371967554, Final Batch Loss: 0.009206770919263363\n",
      "Epoch 3513, Loss: 0.04833230748772621, Final Batch Loss: 0.008641298860311508\n",
      "Epoch 3514, Loss: 0.042645975947380066, Final Batch Loss: 0.023969491943717003\n",
      "Epoch 3515, Loss: 0.035137008875608444, Final Batch Loss: 0.020104095339775085\n",
      "Epoch 3516, Loss: 0.00846095196902752, Final Batch Loss: 0.002176702953875065\n",
      "Epoch 3517, Loss: 0.028916548239067197, Final Batch Loss: 0.0035345342475920916\n",
      "Epoch 3518, Loss: 0.023078685626387596, Final Batch Loss: 0.006831672042608261\n",
      "Epoch 3519, Loss: 0.03595886938273907, Final Batch Loss: 0.020510293543338776\n",
      "Epoch 3520, Loss: 0.033796037547290325, Final Batch Loss: 0.025138836354017258\n",
      "Epoch 3521, Loss: 0.047272609546780586, Final Batch Loss: 0.03316941484808922\n",
      "Epoch 3522, Loss: 0.06080624647438526, Final Batch Loss: 0.04595671221613884\n",
      "Epoch 3523, Loss: 0.01200343482196331, Final Batch Loss: 0.007368721999228001\n",
      "Epoch 3524, Loss: 0.024337378097698092, Final Batch Loss: 0.02157098427414894\n",
      "Epoch 3525, Loss: 0.01774635980837047, Final Batch Loss: 0.014273418113589287\n",
      "Epoch 3526, Loss: 0.011309911613352597, Final Batch Loss: 0.0019136780174449086\n",
      "Epoch 3527, Loss: 0.0780123732984066, Final Batch Loss: 0.051788680255413055\n",
      "Epoch 3528, Loss: 0.04996570944786072, Final Batch Loss: 0.0328841395676136\n",
      "Epoch 3529, Loss: 0.03283195476979017, Final Batch Loss: 0.01975422538816929\n",
      "Epoch 3530, Loss: 0.015667705796658993, Final Batch Loss: 0.0063606733456254005\n",
      "Epoch 3531, Loss: 0.036263550631701946, Final Batch Loss: 0.00642759632319212\n",
      "Epoch 3532, Loss: 0.024690791498869658, Final Batch Loss: 0.004761943127959967\n",
      "Epoch 3533, Loss: 0.041282021440565586, Final Batch Loss: 0.02622726373374462\n",
      "Epoch 3534, Loss: 0.01599126821383834, Final Batch Loss: 0.00931831169873476\n",
      "Epoch 3535, Loss: 0.04036250337958336, Final Batch Loss: 0.03473016992211342\n",
      "Epoch 3536, Loss: 0.02430172823369503, Final Batch Loss: 0.006319275125861168\n",
      "Epoch 3537, Loss: 0.028878232464194298, Final Batch Loss: 0.013751639053225517\n",
      "Epoch 3538, Loss: 0.031488879583776, Final Batch Loss: 0.011125472374260426\n",
      "Epoch 3539, Loss: 0.021167123690247536, Final Batch Loss: 0.007193961180746555\n",
      "Epoch 3540, Loss: 0.016739115118980408, Final Batch Loss: 0.011977208778262138\n",
      "Epoch 3541, Loss: 0.012192059773951769, Final Batch Loss: 0.0031964960508048534\n",
      "Epoch 3542, Loss: 0.013032781658694148, Final Batch Loss: 0.003514819545671344\n",
      "Epoch 3543, Loss: 0.03216648381203413, Final Batch Loss: 0.02736314944922924\n",
      "Epoch 3544, Loss: 0.02243059827014804, Final Batch Loss: 0.006510203238576651\n",
      "Epoch 3545, Loss: 0.010683109052479267, Final Batch Loss: 0.006399374455213547\n",
      "Epoch 3546, Loss: 0.011384146055206656, Final Batch Loss: 0.0028424325864762068\n",
      "Epoch 3547, Loss: 0.019957938231527805, Final Batch Loss: 0.010120434686541557\n",
      "Epoch 3548, Loss: 0.018704927526414394, Final Batch Loss: 0.006381547078490257\n",
      "Epoch 3549, Loss: 0.014380395645275712, Final Batch Loss: 0.002896667690947652\n",
      "Epoch 3550, Loss: 0.008220580639317632, Final Batch Loss: 0.0025558702182024717\n",
      "Epoch 3551, Loss: 0.03015170246362686, Final Batch Loss: 0.00851057842373848\n",
      "Epoch 3552, Loss: 0.015949437394738197, Final Batch Loss: 0.00471876747906208\n",
      "Epoch 3553, Loss: 0.026062031043693423, Final Batch Loss: 0.002462933538481593\n",
      "Epoch 3554, Loss: 0.011159252841025591, Final Batch Loss: 0.004483281634747982\n",
      "Epoch 3555, Loss: 0.05020470917224884, Final Batch Loss: 0.033655114471912384\n",
      "Epoch 3556, Loss: 0.011067095678299665, Final Batch Loss: 0.008845548145473003\n",
      "Epoch 3557, Loss: 0.01771731791086495, Final Batch Loss: 0.00345642794854939\n",
      "Epoch 3558, Loss: 0.012362661771476269, Final Batch Loss: 0.004955783020704985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3559, Loss: 0.07591527327895164, Final Batch Loss: 0.01512455940246582\n",
      "Epoch 3560, Loss: 0.012816125992685556, Final Batch Loss: 0.0055449907667934895\n",
      "Epoch 3561, Loss: 0.01441220659762621, Final Batch Loss: 0.0025355080142617226\n",
      "Epoch 3562, Loss: 0.03195773717015982, Final Batch Loss: 0.012204240076243877\n",
      "Epoch 3563, Loss: 0.06487514078617096, Final Batch Loss: 0.04806377738714218\n",
      "Epoch 3564, Loss: 0.024888871237635612, Final Batch Loss: 0.013549013994634151\n",
      "Epoch 3565, Loss: 0.03460576105862856, Final Batch Loss: 0.01542638149112463\n",
      "Epoch 3566, Loss: 0.136697418987751, Final Batch Loss: 0.10396210849285126\n",
      "Epoch 3567, Loss: 0.03467654762789607, Final Batch Loss: 0.030560551211237907\n",
      "Epoch 3568, Loss: 0.08247754420153797, Final Batch Loss: 0.003618632210418582\n",
      "Epoch 3569, Loss: 0.03370126709342003, Final Batch Loss: 0.009643394500017166\n",
      "Epoch 3570, Loss: 0.038661496713757515, Final Batch Loss: 0.02957114577293396\n",
      "Epoch 3571, Loss: 0.02511426340788603, Final Batch Loss: 0.018931858241558075\n",
      "Epoch 3572, Loss: 0.07189567014575005, Final Batch Loss: 0.04691034182906151\n",
      "Epoch 3573, Loss: 0.13555142655968666, Final Batch Loss: 0.0364951454102993\n",
      "Epoch 3574, Loss: 0.05306197702884674, Final Batch Loss: 0.04155785217881203\n",
      "Epoch 3575, Loss: 0.05907907895743847, Final Batch Loss: 0.022056782618165016\n",
      "Epoch 3576, Loss: 0.1169024333357811, Final Batch Loss: 0.09041694551706314\n",
      "Epoch 3577, Loss: 0.16012994945049286, Final Batch Loss: 0.060063451528549194\n",
      "Epoch 3578, Loss: 0.08264784887433052, Final Batch Loss: 0.03373153880238533\n",
      "Epoch 3579, Loss: 0.15508421510457993, Final Batch Loss: 0.0891503170132637\n",
      "Epoch 3580, Loss: 0.03781994804739952, Final Batch Loss: 0.025247545912861824\n",
      "Epoch 3581, Loss: 0.04358907230198383, Final Batch Loss: 0.019223490729928017\n",
      "Epoch 3582, Loss: 0.033663977868855, Final Batch Loss: 0.009442475624382496\n",
      "Epoch 3583, Loss: 0.12158372811973095, Final Batch Loss: 0.0941704511642456\n",
      "Epoch 3584, Loss: 0.09806600958108902, Final Batch Loss: 0.07232391089200974\n",
      "Epoch 3585, Loss: 0.10064378380775452, Final Batch Loss: 0.0611865371465683\n",
      "Epoch 3586, Loss: 0.0655958391726017, Final Batch Loss: 0.010789617896080017\n",
      "Epoch 3587, Loss: 0.0714526791125536, Final Batch Loss: 0.023278793320059776\n",
      "Epoch 3588, Loss: 0.04817867372184992, Final Batch Loss: 0.01252997387200594\n",
      "Epoch 3589, Loss: 0.08337908145040274, Final Batch Loss: 0.01053324993699789\n",
      "Epoch 3590, Loss: 0.0977763757109642, Final Batch Loss: 0.03879581019282341\n",
      "Epoch 3591, Loss: 0.07272498682141304, Final Batch Loss: 0.030843179672956467\n",
      "Epoch 3592, Loss: 0.05880468338727951, Final Batch Loss: 0.005277354270219803\n",
      "Epoch 3593, Loss: 0.0807243287563324, Final Batch Loss: 0.035905539989471436\n",
      "Epoch 3594, Loss: 0.034586920868605375, Final Batch Loss: 0.007001105230301619\n",
      "Epoch 3595, Loss: 0.03646901063621044, Final Batch Loss: 0.02056974172592163\n",
      "Epoch 3596, Loss: 0.1921520596370101, Final Batch Loss: 0.18078795075416565\n",
      "Epoch 3597, Loss: 0.10512063652276993, Final Batch Loss: 0.035443201661109924\n",
      "Epoch 3598, Loss: 0.0705049829557538, Final Batch Loss: 0.05855406075716019\n",
      "Epoch 3599, Loss: 0.05121626891195774, Final Batch Loss: 0.026986679062247276\n",
      "Epoch 3600, Loss: 0.07107442989945412, Final Batch Loss: 0.034513089805841446\n",
      "Epoch 3601, Loss: 0.030075975693762302, Final Batch Loss: 0.014719919301569462\n",
      "Epoch 3602, Loss: 0.03695320291444659, Final Batch Loss: 0.004626828711479902\n",
      "Epoch 3603, Loss: 0.035273305140435696, Final Batch Loss: 0.024544918909668922\n",
      "Epoch 3604, Loss: 0.06791196577250957, Final Batch Loss: 0.05009956657886505\n",
      "Epoch 3605, Loss: 0.04801817238330841, Final Batch Loss: 0.028222491964697838\n",
      "Epoch 3606, Loss: 0.03567600902169943, Final Batch Loss: 0.022707920521497726\n",
      "Epoch 3607, Loss: 0.06749306619167328, Final Batch Loss: 0.02438703551888466\n",
      "Epoch 3608, Loss: 0.030303364619612694, Final Batch Loss: 0.01145189255475998\n",
      "Epoch 3609, Loss: 0.04260572884231806, Final Batch Loss: 0.008841951377689838\n",
      "Epoch 3610, Loss: 0.039968572556972504, Final Batch Loss: 0.023961789906024933\n",
      "Epoch 3611, Loss: 0.03624577634036541, Final Batch Loss: 0.01839940808713436\n",
      "Epoch 3612, Loss: 0.04241381771862507, Final Batch Loss: 0.012557616457343102\n",
      "Epoch 3613, Loss: 0.046024734154343605, Final Batch Loss: 0.017885955050587654\n",
      "Epoch 3614, Loss: 0.1039845272898674, Final Batch Loss: 0.08209546655416489\n",
      "Epoch 3615, Loss: 0.06547763757407665, Final Batch Loss: 0.01855369843542576\n",
      "Epoch 3616, Loss: 0.11979831010103226, Final Batch Loss: 0.07836776971817017\n",
      "Epoch 3617, Loss: 0.06156463548541069, Final Batch Loss: 0.0455668605864048\n",
      "Epoch 3618, Loss: 0.08440319634974003, Final Batch Loss: 0.06379714608192444\n",
      "Epoch 3619, Loss: 0.14500517398118973, Final Batch Loss: 0.11843373626470566\n",
      "Epoch 3620, Loss: 0.06878982856869698, Final Batch Loss: 0.046808380633592606\n",
      "Epoch 3621, Loss: 0.08663700334727764, Final Batch Loss: 0.02689475379884243\n",
      "Epoch 3622, Loss: 0.05530550889670849, Final Batch Loss: 0.03502555936574936\n",
      "Epoch 3623, Loss: 0.03597670886665583, Final Batch Loss: 0.025050437077879906\n",
      "Epoch 3624, Loss: 0.10739574581384659, Final Batch Loss: 0.07273198664188385\n",
      "Epoch 3625, Loss: 0.05013987235724926, Final Batch Loss: 0.014119679108262062\n",
      "Epoch 3626, Loss: 0.028682002564892173, Final Batch Loss: 0.0028066576924175024\n",
      "Epoch 3627, Loss: 0.04622500576078892, Final Batch Loss: 0.024747708812355995\n",
      "Epoch 3628, Loss: 0.03658165596425533, Final Batch Loss: 0.017115097492933273\n",
      "Epoch 3629, Loss: 0.058999648317694664, Final Batch Loss: 0.023371485993266106\n",
      "Epoch 3630, Loss: 0.06023498438298702, Final Batch Loss: 0.030127551406621933\n",
      "Epoch 3631, Loss: 0.04978097230195999, Final Batch Loss: 0.00518345832824707\n",
      "Epoch 3632, Loss: 0.06915155425667763, Final Batch Loss: 0.04846184328198433\n",
      "Epoch 3633, Loss: 0.01971028745174408, Final Batch Loss: 0.008730893954634666\n",
      "Epoch 3634, Loss: 0.021636292338371277, Final Batch Loss: 0.010953282006084919\n",
      "Epoch 3635, Loss: 0.062248628586530685, Final Batch Loss: 0.01400734856724739\n",
      "Epoch 3636, Loss: 0.1939797569066286, Final Batch Loss: 0.17038123309612274\n",
      "Epoch 3637, Loss: 0.049564432352781296, Final Batch Loss: 0.026608427986502647\n",
      "Epoch 3638, Loss: 0.2677099108695984, Final Batch Loss: 0.18556657433509827\n",
      "Epoch 3639, Loss: 0.10916093364357948, Final Batch Loss: 0.07169856131076813\n",
      "Epoch 3640, Loss: 0.09646811336278915, Final Batch Loss: 0.05904783308506012\n",
      "Epoch 3641, Loss: 0.13741705939173698, Final Batch Loss: 0.04611935093998909\n",
      "Epoch 3642, Loss: 0.12073658220469952, Final Batch Loss: 0.023848144337534904\n",
      "Epoch 3643, Loss: 0.10456562414765358, Final Batch Loss: 0.04113190993666649\n",
      "Epoch 3644, Loss: 0.051674638874828815, Final Batch Loss: 0.013042883016169071\n",
      "Epoch 3645, Loss: 0.1020127646625042, Final Batch Loss: 0.06580695509910583\n",
      "Epoch 3646, Loss: 0.1033747922629118, Final Batch Loss: 0.01669333688914776\n",
      "Epoch 3647, Loss: 0.0777576845139265, Final Batch Loss: 0.01797240786254406\n",
      "Epoch 3648, Loss: 0.08540955185890198, Final Batch Loss: 0.04299268126487732\n",
      "Epoch 3649, Loss: 0.05353498086333275, Final Batch Loss: 0.015872567892074585\n",
      "Epoch 3650, Loss: 0.05492003262042999, Final Batch Loss: 0.016782958060503006\n",
      "Epoch 3651, Loss: 0.11935276538133621, Final Batch Loss: 0.07349548488855362\n",
      "Epoch 3652, Loss: 0.05867706425487995, Final Batch Loss: 0.02260991744697094\n",
      "Epoch 3653, Loss: 0.07770630903542042, Final Batch Loss: 0.019461868330836296\n",
      "Epoch 3654, Loss: 0.04391912464052439, Final Batch Loss: 0.008217238821089268\n",
      "Epoch 3655, Loss: 0.07956921774893999, Final Batch Loss: 0.015144524164497852\n",
      "Epoch 3656, Loss: 0.09162472561001778, Final Batch Loss: 0.04853399097919464\n",
      "Epoch 3657, Loss: 0.0980999693274498, Final Batch Loss: 0.06382644921541214\n",
      "Epoch 3658, Loss: 0.10579308494925499, Final Batch Loss: 0.07595555484294891\n",
      "Epoch 3659, Loss: 0.04093620926141739, Final Batch Loss: 0.019057786092162132\n",
      "Epoch 3660, Loss: 0.0543777272105217, Final Batch Loss: 0.03422117605805397\n",
      "Epoch 3661, Loss: 0.08625137992203236, Final Batch Loss: 0.028480274602770805\n",
      "Epoch 3662, Loss: 0.16936146467924118, Final Batch Loss: 0.10381808876991272\n",
      "Epoch 3663, Loss: 0.06401942670345306, Final Batch Loss: 0.019526474177837372\n",
      "Epoch 3664, Loss: 0.0993242273107171, Final Batch Loss: 0.012679153122007847\n",
      "Epoch 3665, Loss: 0.12097521498799324, Final Batch Loss: 0.0687420591711998\n",
      "Epoch 3666, Loss: 0.07017191872000694, Final Batch Loss: 0.051077019423246384\n",
      "Epoch 3667, Loss: 0.07435283809900284, Final Batch Loss: 0.038333117961883545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3668, Loss: 0.27696001529693604, Final Batch Loss: 0.1875537931919098\n",
      "Epoch 3669, Loss: 0.09605898335576057, Final Batch Loss: 0.04707755893468857\n",
      "Epoch 3670, Loss: 0.07790135033428669, Final Batch Loss: 0.04888998344540596\n",
      "Epoch 3671, Loss: 0.04437885619699955, Final Batch Loss: 0.01863125152885914\n",
      "Epoch 3672, Loss: 0.05635448917746544, Final Batch Loss: 0.034554123878479004\n",
      "Epoch 3673, Loss: 0.042406908236443996, Final Batch Loss: 0.013562197797000408\n",
      "Epoch 3674, Loss: 0.03209238965064287, Final Batch Loss: 0.012126580812036991\n",
      "Epoch 3675, Loss: 0.06110154278576374, Final Batch Loss: 0.033438898622989655\n",
      "Epoch 3676, Loss: 0.05642200820147991, Final Batch Loss: 0.015902506187558174\n",
      "Epoch 3677, Loss: 0.04102944489568472, Final Batch Loss: 0.012823968194425106\n",
      "Epoch 3678, Loss: 0.02684551663696766, Final Batch Loss: 0.012511693872511387\n",
      "Epoch 3679, Loss: 0.05245722457766533, Final Batch Loss: 0.03478023037314415\n",
      "Epoch 3680, Loss: 0.0563632994890213, Final Batch Loss: 0.023277416825294495\n",
      "Epoch 3681, Loss: 0.01766180945560336, Final Batch Loss: 0.0030247303657233715\n",
      "Epoch 3682, Loss: 0.03372857067734003, Final Batch Loss: 0.018769070506095886\n",
      "Epoch 3683, Loss: 0.08092981390655041, Final Batch Loss: 0.06983254104852676\n",
      "Epoch 3684, Loss: 0.05495464242994785, Final Batch Loss: 0.021531058475375175\n",
      "Epoch 3685, Loss: 0.02877053525298834, Final Batch Loss: 0.01707959547638893\n",
      "Epoch 3686, Loss: 0.01603682618588209, Final Batch Loss: 0.008330406621098518\n",
      "Epoch 3687, Loss: 0.04091935884207487, Final Batch Loss: 0.009225904010236263\n",
      "Epoch 3688, Loss: 0.028300070203840733, Final Batch Loss: 0.018535591661930084\n",
      "Epoch 3689, Loss: 0.05086432909592986, Final Batch Loss: 0.043278731405735016\n",
      "Epoch 3690, Loss: 0.0228268732316792, Final Batch Loss: 0.016205232590436935\n",
      "Epoch 3691, Loss: 0.01245088642463088, Final Batch Loss: 0.00432615028694272\n",
      "Epoch 3692, Loss: 0.022956970147788525, Final Batch Loss: 0.0038839830085635185\n",
      "Epoch 3693, Loss: 0.011366544757038355, Final Batch Loss: 0.004439421463757753\n",
      "Epoch 3694, Loss: 0.01838396512903273, Final Batch Loss: 0.0036894262302666903\n",
      "Epoch 3695, Loss: 0.03187514841556549, Final Batch Loss: 0.0066131725907325745\n",
      "Epoch 3696, Loss: 0.01375262951478362, Final Batch Loss: 0.008486221544444561\n",
      "Epoch 3697, Loss: 0.02924218587577343, Final Batch Loss: 0.0072240158915519714\n",
      "Epoch 3698, Loss: 0.04566355049610138, Final Batch Loss: 0.024638939648866653\n",
      "Epoch 3699, Loss: 0.039065699093043804, Final Batch Loss: 0.0068181222304701805\n",
      "Epoch 3700, Loss: 0.0505252368748188, Final Batch Loss: 0.016496669501066208\n",
      "Epoch 3701, Loss: 0.019214774947613478, Final Batch Loss: 0.0027442644350230694\n",
      "Epoch 3702, Loss: 0.02604697458446026, Final Batch Loss: 0.012081150896847248\n",
      "Epoch 3703, Loss: 0.04418717324733734, Final Batch Loss: 0.019295603036880493\n",
      "Epoch 3704, Loss: 0.07147839851677418, Final Batch Loss: 0.06506814062595367\n",
      "Epoch 3705, Loss: 0.022158357314765453, Final Batch Loss: 0.008346273563802242\n",
      "Epoch 3706, Loss: 0.09130459651350975, Final Batch Loss: 0.040943875908851624\n",
      "Epoch 3707, Loss: 0.04490053094923496, Final Batch Loss: 0.0150056853890419\n",
      "Epoch 3708, Loss: 0.06401972472667694, Final Batch Loss: 0.04182941094040871\n",
      "Epoch 3709, Loss: 0.059960342943668365, Final Batch Loss: 0.018471818417310715\n",
      "Epoch 3710, Loss: 0.06801974587142467, Final Batch Loss: 0.023516712710261345\n",
      "Epoch 3711, Loss: 0.03462423104792833, Final Batch Loss: 0.0076556699350476265\n",
      "Epoch 3712, Loss: 0.05811198614537716, Final Batch Loss: 0.03687959164381027\n",
      "Epoch 3713, Loss: 0.03861174825578928, Final Batch Loss: 0.013664492405951023\n",
      "Epoch 3714, Loss: 0.021891603711992502, Final Batch Loss: 0.0062597752548754215\n",
      "Epoch 3715, Loss: 0.045339277014136314, Final Batch Loss: 0.029037483036518097\n",
      "Epoch 3716, Loss: 0.021578014828264713, Final Batch Loss: 0.010419324040412903\n",
      "Epoch 3717, Loss: 0.032764255069196224, Final Batch Loss: 0.017228038981556892\n",
      "Epoch 3718, Loss: 0.03741404879838228, Final Batch Loss: 0.02472926303744316\n",
      "Epoch 3719, Loss: 0.025063447654247284, Final Batch Loss: 0.00606851652264595\n",
      "Epoch 3720, Loss: 0.05300027132034302, Final Batch Loss: 0.031432803720235825\n",
      "Epoch 3721, Loss: 0.0393243283033371, Final Batch Loss: 0.02557300217449665\n",
      "Epoch 3722, Loss: 0.07530881837010384, Final Batch Loss: 0.04272611066699028\n",
      "Epoch 3723, Loss: 0.018302667420357466, Final Batch Loss: 0.0068994429893791676\n",
      "Epoch 3724, Loss: 0.025019198656082153, Final Batch Loss: 0.00989062711596489\n",
      "Epoch 3725, Loss: 0.01920261001214385, Final Batch Loss: 0.01189513597637415\n",
      "Epoch 3726, Loss: 0.07617896050214767, Final Batch Loss: 0.019056707620620728\n",
      "Epoch 3727, Loss: 0.016199657227844, Final Batch Loss: 0.011311139911413193\n",
      "Epoch 3728, Loss: 0.0698430510237813, Final Batch Loss: 0.05464979261159897\n",
      "Epoch 3729, Loss: 0.0655243769288063, Final Batch Loss: 0.03657092526555061\n",
      "Epoch 3730, Loss: 0.014922070316970348, Final Batch Loss: 0.002924680709838867\n",
      "Epoch 3731, Loss: 0.04179719649255276, Final Batch Loss: 0.030098656192421913\n",
      "Epoch 3732, Loss: 0.06426411401480436, Final Batch Loss: 0.04958503320813179\n",
      "Epoch 3733, Loss: 0.022583911195397377, Final Batch Loss: 0.005224613472819328\n",
      "Epoch 3734, Loss: 0.03329575899988413, Final Batch Loss: 0.019622869789600372\n",
      "Epoch 3735, Loss: 0.008004864444956183, Final Batch Loss: 0.0022568644490092993\n",
      "Epoch 3736, Loss: 0.012067029252648354, Final Batch Loss: 0.006943570915609598\n",
      "Epoch 3737, Loss: 0.01302466168999672, Final Batch Loss: 0.0036655375733971596\n",
      "Epoch 3738, Loss: 0.02625326719135046, Final Batch Loss: 0.014867202378809452\n",
      "Epoch 3739, Loss: 0.025026187300682068, Final Batch Loss: 0.01074726041406393\n",
      "Epoch 3740, Loss: 0.05575141962617636, Final Batch Loss: 0.04721113666892052\n",
      "Epoch 3741, Loss: 0.03402524720877409, Final Batch Loss: 0.020451199263334274\n",
      "Epoch 3742, Loss: 0.02608164306730032, Final Batch Loss: 0.014084299094974995\n",
      "Epoch 3743, Loss: 0.016242407727986574, Final Batch Loss: 0.00614685146138072\n",
      "Epoch 3744, Loss: 0.02739928406663239, Final Batch Loss: 0.0030835766810923815\n",
      "Epoch 3745, Loss: 0.06139738857746124, Final Batch Loss: 0.028555691242218018\n",
      "Epoch 3746, Loss: 0.02111706556752324, Final Batch Loss: 0.005516656208783388\n",
      "Epoch 3747, Loss: 0.01676348876208067, Final Batch Loss: 0.008664175868034363\n",
      "Epoch 3748, Loss: 0.0861947052180767, Final Batch Loss: 0.03732917457818985\n",
      "Epoch 3749, Loss: 0.013791844248771667, Final Batch Loss: 0.008822361938655376\n",
      "Epoch 3750, Loss: 0.011023119557648897, Final Batch Loss: 0.006111792754381895\n",
      "Epoch 3751, Loss: 0.008871976286172867, Final Batch Loss: 0.005987927317619324\n",
      "Epoch 3752, Loss: 0.01906999619677663, Final Batch Loss: 0.012368756346404552\n",
      "Epoch 3753, Loss: 0.035913363099098206, Final Batch Loss: 0.006484830752015114\n",
      "Epoch 3754, Loss: 0.043619703501462936, Final Batch Loss: 0.03204638138413429\n",
      "Epoch 3755, Loss: 0.018426864873617887, Final Batch Loss: 0.006735770497471094\n",
      "Epoch 3756, Loss: 0.111569844186306, Final Batch Loss: 0.0698067918419838\n",
      "Epoch 3757, Loss: 0.03907028026878834, Final Batch Loss: 0.01586327888071537\n",
      "Epoch 3758, Loss: 0.015376954339444637, Final Batch Loss: 0.006452685222029686\n",
      "Epoch 3759, Loss: 0.05285524344071746, Final Batch Loss: 0.004742281045764685\n",
      "Epoch 3760, Loss: 0.03650503046810627, Final Batch Loss: 0.014998368918895721\n",
      "Epoch 3761, Loss: 0.03271182719618082, Final Batch Loss: 0.015613664872944355\n",
      "Epoch 3762, Loss: 0.030989001039415598, Final Batch Loss: 0.006836113054305315\n",
      "Epoch 3763, Loss: 0.08186141680926085, Final Batch Loss: 0.06900425255298615\n",
      "Epoch 3764, Loss: 0.012278697919100523, Final Batch Loss: 0.007980073802173138\n",
      "Epoch 3765, Loss: 0.022687735501676798, Final Batch Loss: 0.0048581440933048725\n",
      "Epoch 3766, Loss: 0.020837671356275678, Final Batch Loss: 0.0033599839080125093\n",
      "Epoch 3767, Loss: 0.025260736234486103, Final Batch Loss: 0.008266841061413288\n",
      "Epoch 3768, Loss: 0.057653955183923244, Final Batch Loss: 0.047186754643917084\n",
      "Epoch 3769, Loss: 0.041820285841822624, Final Batch Loss: 0.03770449012517929\n",
      "Epoch 3770, Loss: 0.013857140205800533, Final Batch Loss: 0.005916778929531574\n",
      "Epoch 3771, Loss: 0.0626588985323906, Final Batch Loss: 0.03296263515949249\n",
      "Epoch 3772, Loss: 0.06066776439547539, Final Batch Loss: 0.03570794686675072\n",
      "Epoch 3773, Loss: 0.06898256205022335, Final Batch Loss: 0.0457746647298336\n",
      "Epoch 3774, Loss: 0.020955810323357582, Final Batch Loss: 0.014505483210086823\n",
      "Epoch 3775, Loss: 0.010888854507356882, Final Batch Loss: 0.0069040036760270596\n",
      "Epoch 3776, Loss: 0.08823711797595024, Final Batch Loss: 0.058825962245464325\n",
      "Epoch 3777, Loss: 0.02963820705190301, Final Batch Loss: 0.005207997281104326\n",
      "Epoch 3778, Loss: 0.013517067534849048, Final Batch Loss: 0.00379545777104795\n",
      "Epoch 3779, Loss: 0.03272206615656614, Final Batch Loss: 0.023180324584245682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3780, Loss: 0.02106860396452248, Final Batch Loss: 0.0028240785468369722\n",
      "Epoch 3781, Loss: 0.0481517743319273, Final Batch Loss: 0.009292563423514366\n",
      "Epoch 3782, Loss: 0.03352492908015847, Final Batch Loss: 0.004522175062447786\n",
      "Epoch 3783, Loss: 0.0383286913856864, Final Batch Loss: 0.005854620598256588\n",
      "Epoch 3784, Loss: 0.054724040906876326, Final Batch Loss: 0.00581496162340045\n",
      "Epoch 3785, Loss: 0.013163055293262005, Final Batch Loss: 0.0063974675722420216\n",
      "Epoch 3786, Loss: 0.04928598739206791, Final Batch Loss: 0.010351991280913353\n",
      "Epoch 3787, Loss: 0.03508440777659416, Final Batch Loss: 0.009178387001156807\n",
      "Epoch 3788, Loss: 0.08504707738757133, Final Batch Loss: 0.03793364018201828\n",
      "Epoch 3789, Loss: 0.03764936234802008, Final Batch Loss: 0.01455258671194315\n",
      "Epoch 3790, Loss: 0.032710856292396784, Final Batch Loss: 0.0032446016557514668\n",
      "Epoch 3791, Loss: 0.013901765923947096, Final Batch Loss: 0.006683214567601681\n",
      "Epoch 3792, Loss: 0.009515056619420648, Final Batch Loss: 0.0027137373108416796\n",
      "Epoch 3793, Loss: 0.017565935850143433, Final Batch Loss: 0.010817493312060833\n",
      "Epoch 3794, Loss: 0.03716549929231405, Final Batch Loss: 0.012432933785021305\n",
      "Epoch 3795, Loss: 0.00908562121912837, Final Batch Loss: 0.004594048485159874\n",
      "Epoch 3796, Loss: 0.054511365946382284, Final Batch Loss: 0.006878023501485586\n",
      "Epoch 3797, Loss: 0.05076579097658396, Final Batch Loss: 0.01246876735240221\n",
      "Epoch 3798, Loss: 0.09154349192976952, Final Batch Loss: 0.06269802153110504\n",
      "Epoch 3799, Loss: 0.01975856418721378, Final Batch Loss: 0.003850416047498584\n",
      "Epoch 3800, Loss: 0.017620653845369816, Final Batch Loss: 0.009009438566863537\n",
      "Epoch 3801, Loss: 0.04071096237748861, Final Batch Loss: 0.015519916079938412\n",
      "Epoch 3802, Loss: 0.08500967547297478, Final Batch Loss: 0.07321711629629135\n",
      "Epoch 3803, Loss: 0.016991308890283108, Final Batch Loss: 0.010719585232436657\n",
      "Epoch 3804, Loss: 0.017201381735503674, Final Batch Loss: 0.005967726930975914\n",
      "Epoch 3805, Loss: 0.07934100180864334, Final Batch Loss: 0.055152155458927155\n",
      "Epoch 3806, Loss: 0.04357729526236653, Final Batch Loss: 0.005332012195140123\n",
      "Epoch 3807, Loss: 0.023968982510268688, Final Batch Loss: 0.004396113567054272\n",
      "Epoch 3808, Loss: 0.01710219820961356, Final Batch Loss: 0.010221350938081741\n",
      "Epoch 3809, Loss: 0.040789464488625526, Final Batch Loss: 0.025832049548625946\n",
      "Epoch 3810, Loss: 0.048069908283650875, Final Batch Loss: 0.0394987054169178\n",
      "Epoch 3811, Loss: 0.027280726470053196, Final Batch Loss: 0.007732908241450787\n",
      "Epoch 3812, Loss: 0.029818064533174038, Final Batch Loss: 0.01211173553019762\n",
      "Epoch 3813, Loss: 0.01453045941889286, Final Batch Loss: 0.006617569364607334\n",
      "Epoch 3814, Loss: 0.03081595152616501, Final Batch Loss: 0.0027623996138572693\n",
      "Epoch 3815, Loss: 0.019993907306343317, Final Batch Loss: 0.007153034675866365\n",
      "Epoch 3816, Loss: 0.009460185654461384, Final Batch Loss: 0.00524306483566761\n",
      "Epoch 3817, Loss: 0.026874721981585026, Final Batch Loss: 0.003575320355594158\n",
      "Epoch 3818, Loss: 0.009085002588108182, Final Batch Loss: 0.0020007474813610315\n",
      "Epoch 3819, Loss: 0.02093882765620947, Final Batch Loss: 0.012753662653267384\n",
      "Epoch 3820, Loss: 0.009070550324395299, Final Batch Loss: 0.0024605535436421633\n",
      "Epoch 3821, Loss: 0.03341607470065355, Final Batch Loss: 0.005535277538001537\n",
      "Epoch 3822, Loss: 0.017006940906867385, Final Batch Loss: 0.013956360518932343\n",
      "Epoch 3823, Loss: 0.03156419098377228, Final Batch Loss: 0.02439369447529316\n",
      "Epoch 3824, Loss: 0.01965053752064705, Final Batch Loss: 0.014095209538936615\n",
      "Epoch 3825, Loss: 0.03621789161115885, Final Batch Loss: 0.011188711039721966\n",
      "Epoch 3826, Loss: 0.05050062737427652, Final Batch Loss: 0.0022923981305211782\n",
      "Epoch 3827, Loss: 0.03465437516570091, Final Batch Loss: 0.016300607472658157\n",
      "Epoch 3828, Loss: 0.010396362515166402, Final Batch Loss: 0.0030849825125187635\n",
      "Epoch 3829, Loss: 0.010361402295529842, Final Batch Loss: 0.004573535639792681\n",
      "Epoch 3830, Loss: 0.018359603360295296, Final Batch Loss: 0.0129142627120018\n",
      "Epoch 3831, Loss: 0.009763108566403389, Final Batch Loss: 0.004832717590034008\n",
      "Epoch 3832, Loss: 0.023217104375362396, Final Batch Loss: 0.013824849389493465\n",
      "Epoch 3833, Loss: 0.07051586918532848, Final Batch Loss: 0.04163804650306702\n",
      "Epoch 3834, Loss: 0.004753007087856531, Final Batch Loss: 0.0020514277275651693\n",
      "Epoch 3835, Loss: 0.07218229025602341, Final Batch Loss: 0.06708869338035583\n",
      "Epoch 3836, Loss: 0.04140383563935757, Final Batch Loss: 0.017261063680052757\n",
      "Epoch 3837, Loss: 0.07954613864421844, Final Batch Loss: 0.06388256698846817\n",
      "Epoch 3838, Loss: 0.01820997940376401, Final Batch Loss: 0.011601869016885757\n",
      "Epoch 3839, Loss: 0.03199265943840146, Final Batch Loss: 0.028545934706926346\n",
      "Epoch 3840, Loss: 0.060235834680497646, Final Batch Loss: 0.05625394359230995\n",
      "Epoch 3841, Loss: 0.018582754768431187, Final Batch Loss: 0.009029554203152657\n",
      "Epoch 3842, Loss: 0.05224362132139504, Final Batch Loss: 0.002024376066401601\n",
      "Epoch 3843, Loss: 0.08844091463834047, Final Batch Loss: 0.07326673716306686\n",
      "Epoch 3844, Loss: 0.0679404754191637, Final Batch Loss: 0.05783775448799133\n",
      "Epoch 3845, Loss: 0.07508394867181778, Final Batch Loss: 0.040228553116321564\n",
      "Epoch 3846, Loss: 0.05997133068740368, Final Batch Loss: 0.019046304747462273\n",
      "Epoch 3847, Loss: 0.08612816967070103, Final Batch Loss: 0.06995640695095062\n",
      "Epoch 3848, Loss: 0.02301213168539107, Final Batch Loss: 0.00351241254247725\n",
      "Epoch 3849, Loss: 0.04877573996782303, Final Batch Loss: 0.020586350932717323\n",
      "Epoch 3850, Loss: 0.03492250759154558, Final Batch Loss: 0.002417472191154957\n",
      "Epoch 3851, Loss: 0.12847302807494998, Final Batch Loss: 0.006405725609511137\n",
      "Epoch 3852, Loss: 0.100949477404356, Final Batch Loss: 0.048146288841962814\n",
      "Epoch 3853, Loss: 0.14991814270615578, Final Batch Loss: 0.06125545874238014\n",
      "Epoch 3854, Loss: 0.13826895505189896, Final Batch Loss: 0.06825361400842667\n",
      "Epoch 3855, Loss: 0.016867104917764664, Final Batch Loss: 0.0059357574209570885\n",
      "Epoch 3856, Loss: 0.10100537165999413, Final Batch Loss: 0.05430097132921219\n",
      "Epoch 3857, Loss: 0.07541798427700996, Final Batch Loss: 0.034071601927280426\n",
      "Epoch 3858, Loss: 0.035080826841294765, Final Batch Loss: 0.013661359436810017\n",
      "Epoch 3859, Loss: 0.03998670447617769, Final Batch Loss: 0.011585473082959652\n",
      "Epoch 3860, Loss: 0.06381214037537575, Final Batch Loss: 0.007338270545005798\n",
      "Epoch 3861, Loss: 0.06828528456389904, Final Batch Loss: 0.04848479852080345\n",
      "Epoch 3862, Loss: 0.038967773551121354, Final Batch Loss: 0.0027460979763418436\n",
      "Epoch 3863, Loss: 0.01859463262371719, Final Batch Loss: 0.0035818505566567183\n",
      "Epoch 3864, Loss: 0.04240677785128355, Final Batch Loss: 0.03362184762954712\n",
      "Epoch 3865, Loss: 0.07804085314273834, Final Batch Loss: 0.03688142076134682\n",
      "Epoch 3866, Loss: 0.05780049227178097, Final Batch Loss: 0.049069132655858994\n",
      "Epoch 3867, Loss: 0.016134588047862053, Final Batch Loss: 0.011735294945538044\n",
      "Epoch 3868, Loss: 0.08213412016630173, Final Batch Loss: 0.05895218625664711\n",
      "Epoch 3869, Loss: 0.1401608344167471, Final Batch Loss: 0.019189132377505302\n",
      "Epoch 3870, Loss: 0.022970575839281082, Final Batch Loss: 0.01711764559149742\n",
      "Epoch 3871, Loss: 0.03172717709094286, Final Batch Loss: 0.006830307655036449\n",
      "Epoch 3872, Loss: 0.011211870238184929, Final Batch Loss: 0.00486775254830718\n",
      "Epoch 3873, Loss: 0.024485766887664795, Final Batch Loss: 0.011417536064982414\n",
      "Epoch 3874, Loss: 0.0870058499276638, Final Batch Loss: 0.06494186073541641\n",
      "Epoch 3875, Loss: 0.02481891866773367, Final Batch Loss: 0.009688189253211021\n",
      "Epoch 3876, Loss: 0.05229008197784424, Final Batch Loss: 0.023351410403847694\n",
      "Epoch 3877, Loss: 0.014505298575386405, Final Batch Loss: 0.003255552379414439\n",
      "Epoch 3878, Loss: 0.05883265286684036, Final Batch Loss: 0.035510770976543427\n",
      "Epoch 3879, Loss: 0.027951562777161598, Final Batch Loss: 0.018915290012955666\n",
      "Epoch 3880, Loss: 0.023118846118450165, Final Batch Loss: 0.008428473956882954\n",
      "Epoch 3881, Loss: 0.03944405913352966, Final Batch Loss: 0.004731152206659317\n",
      "Epoch 3882, Loss: 0.05464301537722349, Final Batch Loss: 0.040899328887462616\n",
      "Epoch 3883, Loss: 0.03309097699820995, Final Batch Loss: 0.022872434929013252\n",
      "Epoch 3884, Loss: 0.06617317628115416, Final Batch Loss: 0.014437130652368069\n",
      "Epoch 3885, Loss: 0.04492972604930401, Final Batch Loss: 0.018119648098945618\n",
      "Epoch 3886, Loss: 0.11440638173371553, Final Batch Loss: 0.10696396231651306\n",
      "Epoch 3887, Loss: 0.02498290967196226, Final Batch Loss: 0.011600256897509098\n",
      "Epoch 3888, Loss: 0.03185969218611717, Final Batch Loss: 0.014178065583109856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3889, Loss: 0.022314955480396748, Final Batch Loss: 0.012757377699017525\n",
      "Epoch 3890, Loss: 0.09827107191085815, Final Batch Loss: 0.07397427409887314\n",
      "Epoch 3891, Loss: 0.04868937097489834, Final Batch Loss: 0.030472418293356895\n",
      "Epoch 3892, Loss: 0.10895710811018944, Final Batch Loss: 0.062003765255212784\n",
      "Epoch 3893, Loss: 0.08344702422618866, Final Batch Loss: 0.048485223203897476\n",
      "Epoch 3894, Loss: 0.05759022943675518, Final Batch Loss: 0.03236635774374008\n",
      "Epoch 3895, Loss: 0.04715740121901035, Final Batch Loss: 0.032270558178424835\n",
      "Epoch 3896, Loss: 0.0447192657738924, Final Batch Loss: 0.024634703993797302\n",
      "Epoch 3897, Loss: 0.03316068649291992, Final Batch Loss: 0.016562845557928085\n",
      "Epoch 3898, Loss: 0.052504099905490875, Final Batch Loss: 0.03541100025177002\n",
      "Epoch 3899, Loss: 0.04544123541563749, Final Batch Loss: 0.008689972572028637\n",
      "Epoch 3900, Loss: 0.06059844233095646, Final Batch Loss: 0.02216235361993313\n",
      "Epoch 3901, Loss: 0.05411661509424448, Final Batch Loss: 0.00844059232622385\n",
      "Epoch 3902, Loss: 0.04283503629267216, Final Batch Loss: 0.02004864625632763\n",
      "Epoch 3903, Loss: 0.06812866032123566, Final Batch Loss: 0.036518655717372894\n",
      "Epoch 3904, Loss: 0.029460052959620953, Final Batch Loss: 0.012216842733323574\n",
      "Epoch 3905, Loss: 0.05181241501122713, Final Batch Loss: 0.009995055384933949\n",
      "Epoch 3906, Loss: 0.16092229261994362, Final Batch Loss: 0.14214888215065002\n",
      "Epoch 3907, Loss: 0.030648461543023586, Final Batch Loss: 0.01750556193292141\n",
      "Epoch 3908, Loss: 0.0977755505591631, Final Batch Loss: 0.02732989378273487\n",
      "Epoch 3909, Loss: 0.030215426348149776, Final Batch Loss: 0.008191472850739956\n",
      "Epoch 3910, Loss: 0.02528188470751047, Final Batch Loss: 0.006679044105112553\n",
      "Epoch 3911, Loss: 0.022259636782109737, Final Batch Loss: 0.010424119420349598\n",
      "Epoch 3912, Loss: 0.07315541338175535, Final Batch Loss: 0.008081036619842052\n",
      "Epoch 3913, Loss: 0.08265592716634274, Final Batch Loss: 0.027830922976136208\n",
      "Epoch 3914, Loss: 0.04760785587131977, Final Batch Loss: 0.03296501934528351\n",
      "Epoch 3915, Loss: 0.0682548659387976, Final Batch Loss: 0.06515725702047348\n",
      "Epoch 3916, Loss: 0.032317874021828175, Final Batch Loss: 0.015531155280768871\n",
      "Epoch 3917, Loss: 0.018206019885838032, Final Batch Loss: 0.0064469315111637115\n",
      "Epoch 3918, Loss: 0.08444912359118462, Final Batch Loss: 0.05794037505984306\n",
      "Epoch 3919, Loss: 0.0489934328943491, Final Batch Loss: 0.03547418490052223\n",
      "Epoch 3920, Loss: 0.05342786759138107, Final Batch Loss: 0.02623753622174263\n",
      "Epoch 3921, Loss: 0.08329315297305584, Final Batch Loss: 0.07465401291847229\n",
      "Epoch 3922, Loss: 0.02072658622637391, Final Batch Loss: 0.0065541514195501804\n",
      "Epoch 3923, Loss: 0.04489746177569032, Final Batch Loss: 0.007412875536829233\n",
      "Epoch 3924, Loss: 0.040019407868385315, Final Batch Loss: 0.009107137098908424\n",
      "Epoch 3925, Loss: 0.033488460117951035, Final Batch Loss: 0.0024988821242004633\n",
      "Epoch 3926, Loss: 0.04319821950048208, Final Batch Loss: 0.012733069248497486\n",
      "Epoch 3927, Loss: 0.027876287698745728, Final Batch Loss: 0.005473548546433449\n",
      "Epoch 3928, Loss: 0.03166839852929115, Final Batch Loss: 0.014573425054550171\n",
      "Epoch 3929, Loss: 0.037109946832060814, Final Batch Loss: 0.021491985768079758\n",
      "Epoch 3930, Loss: 0.017239663749933243, Final Batch Loss: 0.005823188461363316\n",
      "Epoch 3931, Loss: 0.03318142518401146, Final Batch Loss: 0.010987160727381706\n",
      "Epoch 3932, Loss: 0.022581925615668297, Final Batch Loss: 0.014714551158249378\n",
      "Epoch 3933, Loss: 0.10608167201280594, Final Batch Loss: 0.06248730048537254\n",
      "Epoch 3934, Loss: 0.04333702474832535, Final Batch Loss: 0.03442997485399246\n",
      "Epoch 3935, Loss: 0.010934103047475219, Final Batch Loss: 0.003870276967063546\n",
      "Epoch 3936, Loss: 0.0726202204823494, Final Batch Loss: 0.06683149188756943\n",
      "Epoch 3937, Loss: 0.04204802634194493, Final Batch Loss: 0.004967280197888613\n",
      "Epoch 3938, Loss: 0.05069526843726635, Final Batch Loss: 0.028484156355261803\n",
      "Epoch 3939, Loss: 0.04512419691309333, Final Batch Loss: 0.0056707835756242275\n",
      "Epoch 3940, Loss: 0.023982574231922626, Final Batch Loss: 0.010131054557859898\n",
      "Epoch 3941, Loss: 0.022481225430965424, Final Batch Loss: 0.011721868999302387\n",
      "Epoch 3942, Loss: 0.025282966904342175, Final Batch Loss: 0.006095300428569317\n",
      "Epoch 3943, Loss: 0.026487052906304598, Final Batch Loss: 0.00581402936950326\n",
      "Epoch 3944, Loss: 0.04944967711344361, Final Batch Loss: 0.043339598923921585\n",
      "Epoch 3945, Loss: 0.021316908299922943, Final Batch Loss: 0.011873447336256504\n",
      "Epoch 3946, Loss: 0.014163156505674124, Final Batch Loss: 0.009021500125527382\n",
      "Epoch 3947, Loss: 0.04412013292312622, Final Batch Loss: 0.03593786060810089\n",
      "Epoch 3948, Loss: 0.03654668014496565, Final Batch Loss: 0.005149378441274166\n",
      "Epoch 3949, Loss: 0.021157792769372463, Final Batch Loss: 0.012063388712704182\n",
      "Epoch 3950, Loss: 0.07667385321110487, Final Batch Loss: 0.06872854381799698\n",
      "Epoch 3951, Loss: 0.08779378794133663, Final Batch Loss: 0.01941024325788021\n",
      "Epoch 3952, Loss: 0.052559392992407084, Final Batch Loss: 0.04928133264183998\n",
      "Epoch 3953, Loss: 0.011030498892068863, Final Batch Loss: 0.004964785184711218\n",
      "Epoch 3954, Loss: 0.012109828181564808, Final Batch Loss: 0.003915128298103809\n",
      "Epoch 3955, Loss: 0.02132920129224658, Final Batch Loss: 0.0038183811120688915\n",
      "Epoch 3956, Loss: 0.027307961136102676, Final Batch Loss: 0.01007782481610775\n",
      "Epoch 3957, Loss: 0.054686304181814194, Final Batch Loss: 0.025877103209495544\n",
      "Epoch 3958, Loss: 0.0477666649967432, Final Batch Loss: 0.028448836877942085\n",
      "Epoch 3959, Loss: 0.014765875414013863, Final Batch Loss: 0.0052218250930309296\n",
      "Epoch 3960, Loss: 0.01637141266837716, Final Batch Loss: 0.01225647795945406\n",
      "Epoch 3961, Loss: 0.04381988197565079, Final Batch Loss: 0.02712698094546795\n",
      "Epoch 3962, Loss: 0.03934718668460846, Final Batch Loss: 0.017677823081612587\n",
      "Epoch 3963, Loss: 0.07316000759601593, Final Batch Loss: 0.03279360383749008\n",
      "Epoch 3964, Loss: 0.05252852477133274, Final Batch Loss: 0.027415474876761436\n",
      "Epoch 3965, Loss: 0.032023743726313114, Final Batch Loss: 0.015470617450773716\n",
      "Epoch 3966, Loss: 0.01656438410282135, Final Batch Loss: 0.008262893185019493\n",
      "Epoch 3967, Loss: 0.020459532737731934, Final Batch Loss: 0.01164309959858656\n",
      "Epoch 3968, Loss: 0.018807807005941868, Final Batch Loss: 0.009856455959379673\n",
      "Epoch 3969, Loss: 0.05320759443566203, Final Batch Loss: 0.0042328122071921825\n",
      "Epoch 3970, Loss: 0.026343563105911016, Final Batch Loss: 0.007740268018096685\n",
      "Epoch 3971, Loss: 0.04630818963050842, Final Batch Loss: 0.007716570049524307\n",
      "Epoch 3972, Loss: 0.020104828290641308, Final Batch Loss: 0.005126400850713253\n",
      "Epoch 3973, Loss: 0.06333563849329948, Final Batch Loss: 0.04415891692042351\n",
      "Epoch 3974, Loss: 0.10093237087130547, Final Batch Loss: 0.08312439173460007\n",
      "Epoch 3975, Loss: 0.054073894396424294, Final Batch Loss: 0.026472244411706924\n",
      "Epoch 3976, Loss: 0.026141992304474115, Final Batch Loss: 0.006328888703137636\n",
      "Epoch 3977, Loss: 0.040464529767632484, Final Batch Loss: 0.014884350821375847\n",
      "Epoch 3978, Loss: 0.03483566548675299, Final Batch Loss: 0.02387078106403351\n",
      "Epoch 3979, Loss: 0.023259039502590895, Final Batch Loss: 0.004284888040274382\n",
      "Epoch 3980, Loss: 0.026588461827486753, Final Batch Loss: 0.020814286544919014\n",
      "Epoch 3981, Loss: 0.08024748228490353, Final Batch Loss: 0.01607341878116131\n",
      "Epoch 3982, Loss: 0.05103417485952377, Final Batch Loss: 0.032565776258707047\n",
      "Epoch 3983, Loss: 0.03502759896218777, Final Batch Loss: 0.01360413059592247\n",
      "Epoch 3984, Loss: 0.0499824327416718, Final Batch Loss: 0.007195014972239733\n",
      "Epoch 3985, Loss: 0.03069267049431801, Final Batch Loss: 0.017499752342700958\n",
      "Epoch 3986, Loss: 0.03214637748897076, Final Batch Loss: 0.025478461757302284\n",
      "Epoch 3987, Loss: 0.03790606930851936, Final Batch Loss: 0.026050252839922905\n",
      "Epoch 3988, Loss: 0.11423635482788086, Final Batch Loss: 0.0836043432354927\n",
      "Epoch 3989, Loss: 0.06103919632732868, Final Batch Loss: 0.03438796103000641\n",
      "Epoch 3990, Loss: 0.01184343034401536, Final Batch Loss: 0.007382028736174107\n",
      "Epoch 3991, Loss: 0.12298828922212124, Final Batch Loss: 0.1076139360666275\n",
      "Epoch 3992, Loss: 0.06483947485685349, Final Batch Loss: 0.040969155728816986\n",
      "Epoch 3993, Loss: 0.02831856533885002, Final Batch Loss: 0.019816339015960693\n",
      "Epoch 3994, Loss: 0.04524525813758373, Final Batch Loss: 0.021661093458533287\n",
      "Epoch 3995, Loss: 0.009972239844501019, Final Batch Loss: 0.0052727703005075455\n",
      "Epoch 3996, Loss: 0.05029247759375721, Final Batch Loss: 0.001899630413390696\n",
      "Epoch 3997, Loss: 0.05306280963122845, Final Batch Loss: 0.002805495634675026\n",
      "Epoch 3998, Loss: 0.018874539993703365, Final Batch Loss: 0.006143971346318722\n",
      "Epoch 3999, Loss: 0.09240680932998657, Final Batch Loss: 0.08276596665382385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4000, Loss: 0.028384407050907612, Final Batch Loss: 0.019540220499038696\n",
      "Epoch 4001, Loss: 0.04135737195611, Final Batch Loss: 0.01225660927593708\n",
      "Epoch 4002, Loss: 0.03670535236597061, Final Batch Loss: 0.02336866222321987\n",
      "Epoch 4003, Loss: 0.14239823818206787, Final Batch Loss: 0.10530807077884674\n",
      "Epoch 4004, Loss: 0.03276125714182854, Final Batch Loss: 0.007164999842643738\n",
      "Epoch 4005, Loss: 0.06651210528798401, Final Batch Loss: 0.0027728427667170763\n",
      "Epoch 4006, Loss: 0.03572110738605261, Final Batch Loss: 0.027297331020236015\n",
      "Epoch 4007, Loss: 0.0535660027526319, Final Batch Loss: 0.007688002195209265\n",
      "Epoch 4008, Loss: 0.1253483397886157, Final Batch Loss: 0.11485332250595093\n",
      "Epoch 4009, Loss: 0.10844578966498375, Final Batch Loss: 0.07368333637714386\n",
      "Epoch 4010, Loss: 0.041688779136165977, Final Batch Loss: 0.0038636194076389074\n",
      "Epoch 4011, Loss: 0.07290238700807095, Final Batch Loss: 0.06752214580774307\n",
      "Epoch 4012, Loss: 0.07320744544267654, Final Batch Loss: 0.03845478221774101\n",
      "Epoch 4013, Loss: 0.09629098325967789, Final Batch Loss: 0.035004664212465286\n",
      "Epoch 4014, Loss: 0.05078611150383949, Final Batch Loss: 0.03452657163143158\n",
      "Epoch 4015, Loss: 0.029060982633382082, Final Batch Loss: 0.004325416404753923\n",
      "Epoch 4016, Loss: 0.06202433444559574, Final Batch Loss: 0.02112547494471073\n",
      "Epoch 4017, Loss: 0.037718985229730606, Final Batch Loss: 0.020846432074904442\n",
      "Epoch 4018, Loss: 0.06468869280070066, Final Batch Loss: 0.012872832827270031\n",
      "Epoch 4019, Loss: 0.10132215172052383, Final Batch Loss: 0.04586492106318474\n",
      "Epoch 4020, Loss: 0.032097685150802135, Final Batch Loss: 0.021793775260448456\n",
      "Epoch 4021, Loss: 0.033725565299391747, Final Batch Loss: 0.007301725447177887\n",
      "Epoch 4022, Loss: 0.040149226784706116, Final Batch Loss: 0.023357197642326355\n",
      "Epoch 4023, Loss: 0.01759046409279108, Final Batch Loss: 0.009597877971827984\n",
      "Epoch 4024, Loss: 0.05185589985921979, Final Batch Loss: 0.0015777540393173695\n",
      "Epoch 4025, Loss: 0.03089295607060194, Final Batch Loss: 0.018598854541778564\n",
      "Epoch 4026, Loss: 0.011471797246485949, Final Batch Loss: 0.005355031229555607\n",
      "Epoch 4027, Loss: 0.07259520515799522, Final Batch Loss: 0.04008721560239792\n",
      "Epoch 4028, Loss: 0.04699943866580725, Final Batch Loss: 0.03363487869501114\n",
      "Epoch 4029, Loss: 0.07480791583657265, Final Batch Loss: 0.06821513175964355\n",
      "Epoch 4030, Loss: 0.06796522345393896, Final Batch Loss: 0.010076004080474377\n",
      "Epoch 4031, Loss: 0.03151935152709484, Final Batch Loss: 0.018818484619259834\n",
      "Epoch 4032, Loss: 0.028621690347790718, Final Batch Loss: 0.00427679717540741\n",
      "Epoch 4033, Loss: 0.12081662937998772, Final Batch Loss: 0.09642153233289719\n",
      "Epoch 4034, Loss: 0.02234310144558549, Final Batch Loss: 0.005679769907146692\n",
      "Epoch 4035, Loss: 0.11427910067141056, Final Batch Loss: 0.09401412308216095\n",
      "Epoch 4036, Loss: 0.04845421947538853, Final Batch Loss: 0.004300208762288094\n",
      "Epoch 4037, Loss: 0.041253429371863604, Final Batch Loss: 0.004913311917334795\n",
      "Epoch 4038, Loss: 0.018004851415753365, Final Batch Loss: 0.001355588436126709\n",
      "Epoch 4039, Loss: 0.018239052034914494, Final Batch Loss: 0.007577937096357346\n",
      "Epoch 4040, Loss: 0.05908223940059543, Final Batch Loss: 0.05304349958896637\n",
      "Epoch 4041, Loss: 0.07827679254114628, Final Batch Loss: 0.030070925131440163\n",
      "Epoch 4042, Loss: 0.019449316430836916, Final Batch Loss: 0.004601570311933756\n",
      "Epoch 4043, Loss: 0.048458574805408716, Final Batch Loss: 0.005828468594700098\n",
      "Epoch 4044, Loss: 0.07290742732584476, Final Batch Loss: 0.05028093606233597\n",
      "Epoch 4045, Loss: 0.009681180119514465, Final Batch Loss: 0.002914206590503454\n",
      "Epoch 4046, Loss: 0.029588268138468266, Final Batch Loss: 0.009591548703610897\n",
      "Epoch 4047, Loss: 0.04073091479949653, Final Batch Loss: 0.0019107300322502851\n",
      "Epoch 4048, Loss: 0.05465577496215701, Final Batch Loss: 0.047401539981365204\n",
      "Epoch 4049, Loss: 0.01501293433830142, Final Batch Loss: 0.0030517051927745342\n",
      "Epoch 4050, Loss: 0.044027271680533886, Final Batch Loss: 0.034932639449834824\n",
      "Epoch 4051, Loss: 0.06902357563376427, Final Batch Loss: 0.03811933100223541\n",
      "Epoch 4052, Loss: 0.045601481571793556, Final Batch Loss: 0.022384392097592354\n",
      "Epoch 4053, Loss: 0.02189435064792633, Final Batch Loss: 0.009796230122447014\n",
      "Epoch 4054, Loss: 0.025285194627940655, Final Batch Loss: 0.009155604057013988\n",
      "Epoch 4055, Loss: 0.02432101033627987, Final Batch Loss: 0.004260895773768425\n",
      "Epoch 4056, Loss: 0.06978555861860514, Final Batch Loss: 0.058008790016174316\n",
      "Epoch 4057, Loss: 0.037361555732786655, Final Batch Loss: 0.02873275987803936\n",
      "Epoch 4058, Loss: 0.039471457712352276, Final Batch Loss: 0.025495804846286774\n",
      "Epoch 4059, Loss: 0.032263041473925114, Final Batch Loss: 0.00941548217087984\n",
      "Epoch 4060, Loss: 0.03161529405042529, Final Batch Loss: 0.005129251163452864\n",
      "Epoch 4061, Loss: 0.029135224875062704, Final Batch Loss: 0.0036085392348468304\n",
      "Epoch 4062, Loss: 0.021762677235528827, Final Batch Loss: 0.0026023618411272764\n",
      "Epoch 4063, Loss: 0.05130167445167899, Final Batch Loss: 0.002836917992681265\n",
      "Epoch 4064, Loss: 0.033810748253017664, Final Batch Loss: 0.00768814655020833\n",
      "Epoch 4065, Loss: 0.03824466420337558, Final Batch Loss: 0.004225059878081083\n",
      "Epoch 4066, Loss: 0.03117022104561329, Final Batch Loss: 0.005583211779594421\n",
      "Epoch 4067, Loss: 0.06470683449879289, Final Batch Loss: 0.057452887296676636\n",
      "Epoch 4068, Loss: 0.05473674274981022, Final Batch Loss: 0.01616261713206768\n",
      "Epoch 4069, Loss: 0.009235837729647756, Final Batch Loss: 0.0037343327421694994\n",
      "Epoch 4070, Loss: 0.010442360769957304, Final Batch Loss: 0.005407603457570076\n",
      "Epoch 4071, Loss: 0.010025838622823358, Final Batch Loss: 0.006681068800389767\n",
      "Epoch 4072, Loss: 0.011990614933893085, Final Batch Loss: 0.0029970805626362562\n",
      "Epoch 4073, Loss: 0.012996370904147625, Final Batch Loss: 0.00640989001840353\n",
      "Epoch 4074, Loss: 0.025670624803751707, Final Batch Loss: 0.006710584741085768\n",
      "Epoch 4075, Loss: 0.02425979496911168, Final Batch Loss: 0.016997113823890686\n",
      "Epoch 4076, Loss: 0.0194682814180851, Final Batch Loss: 0.013210387900471687\n",
      "Epoch 4077, Loss: 0.020311245694756508, Final Batch Loss: 0.011198612861335278\n",
      "Epoch 4078, Loss: 0.056708743795752525, Final Batch Loss: 0.027134545147418976\n",
      "Epoch 4079, Loss: 0.020059225149452686, Final Batch Loss: 0.013682716526091099\n",
      "Epoch 4080, Loss: 0.06650013942271471, Final Batch Loss: 0.0030086757615208626\n",
      "Epoch 4081, Loss: 0.011315423296764493, Final Batch Loss: 0.003903071628883481\n",
      "Epoch 4082, Loss: 0.026998264249414206, Final Batch Loss: 0.006542086135596037\n",
      "Epoch 4083, Loss: 0.027482925914227962, Final Batch Loss: 0.0038668187335133553\n",
      "Epoch 4084, Loss: 0.02135195699520409, Final Batch Loss: 0.0017818280030041933\n",
      "Epoch 4085, Loss: 0.025804846547544003, Final Batch Loss: 0.014022359624505043\n",
      "Epoch 4086, Loss: 0.025713483337312937, Final Batch Loss: 0.00552939111366868\n",
      "Epoch 4087, Loss: 0.021892246790230274, Final Batch Loss: 0.004762542434036732\n",
      "Epoch 4088, Loss: 0.023110709385946393, Final Batch Loss: 0.0029172946233302355\n",
      "Epoch 4089, Loss: 0.05961664207279682, Final Batch Loss: 0.013621555641293526\n",
      "Epoch 4090, Loss: 0.03073228057473898, Final Batch Loss: 0.017956804484128952\n",
      "Epoch 4091, Loss: 0.03576832730323076, Final Batch Loss: 0.013486684300005436\n",
      "Epoch 4092, Loss: 0.03117936197668314, Final Batch Loss: 0.00546096358448267\n",
      "Epoch 4093, Loss: 0.01022111251950264, Final Batch Loss: 0.0037417635321617126\n",
      "Epoch 4094, Loss: 0.06059345789253712, Final Batch Loss: 0.03916815295815468\n",
      "Epoch 4095, Loss: 0.10217786440625787, Final Batch Loss: 0.09536804258823395\n",
      "Epoch 4096, Loss: 0.018367580138146877, Final Batch Loss: 0.005055715329945087\n",
      "Epoch 4097, Loss: 0.023049039766192436, Final Batch Loss: 0.002958599478006363\n",
      "Epoch 4098, Loss: 0.030804263427853584, Final Batch Loss: 0.004005758091807365\n",
      "Epoch 4099, Loss: 0.0343426875770092, Final Batch Loss: 0.009540840983390808\n",
      "Epoch 4100, Loss: 0.054718874394893646, Final Batch Loss: 0.0358867272734642\n",
      "Epoch 4101, Loss: 0.03990265354514122, Final Batch Loss: 0.023547010496258736\n",
      "Epoch 4102, Loss: 0.08106566499918699, Final Batch Loss: 0.06731588393449783\n",
      "Epoch 4103, Loss: 0.10499485768377781, Final Batch Loss: 0.029664868488907814\n",
      "Epoch 4104, Loss: 0.022957975044846535, Final Batch Loss: 0.0036375783383846283\n",
      "Epoch 4105, Loss: 0.09285127185285091, Final Batch Loss: 0.0741555392742157\n",
      "Epoch 4106, Loss: 0.05772790685296059, Final Batch Loss: 0.024498462677001953\n",
      "Epoch 4107, Loss: 0.01726465206593275, Final Batch Loss: 0.00650771614164114\n",
      "Epoch 4108, Loss: 0.023093558847904205, Final Batch Loss: 0.008359908126294613\n",
      "Epoch 4109, Loss: 0.030422529205679893, Final Batch Loss: 0.025017373263835907\n",
      "Epoch 4110, Loss: 0.02432554867118597, Final Batch Loss: 0.009710298851132393\n",
      "Epoch 4111, Loss: 0.062479251995682716, Final Batch Loss: 0.031029904261231422\n",
      "Epoch 4112, Loss: 0.02852032007649541, Final Batch Loss: 0.0070558455772697926\n",
      "Epoch 4113, Loss: 0.04597371630370617, Final Batch Loss: 0.01262134499847889\n",
      "Epoch 4114, Loss: 0.02889365586452186, Final Batch Loss: 0.0034591208677738905\n",
      "Epoch 4115, Loss: 0.051715812645852566, Final Batch Loss: 0.04665236175060272\n",
      "Epoch 4116, Loss: 0.03890461102128029, Final Batch Loss: 0.028451595455408096\n",
      "Epoch 4117, Loss: 0.03404103498905897, Final Batch Loss: 0.01448314730077982\n",
      "Epoch 4118, Loss: 0.034030091017484665, Final Batch Loss: 0.020392199978232384\n",
      "Epoch 4119, Loss: 0.02534204674884677, Final Batch Loss: 0.005289775785058737\n",
      "Epoch 4120, Loss: 0.017437933245673776, Final Batch Loss: 0.0030232437420636415\n",
      "Epoch 4121, Loss: 0.05671933386474848, Final Batch Loss: 0.04497331380844116\n",
      "Epoch 4122, Loss: 0.07135877572000027, Final Batch Loss: 0.017753200605511665\n",
      "Epoch 4123, Loss: 0.05177287315018475, Final Batch Loss: 0.00251052831299603\n",
      "Epoch 4124, Loss: 0.04708331311121583, Final Batch Loss: 0.041978199034929276\n",
      "Epoch 4125, Loss: 0.04145694151520729, Final Batch Loss: 0.004622951149940491\n",
      "Epoch 4126, Loss: 0.013450077269226313, Final Batch Loss: 0.005557126831263304\n",
      "Epoch 4127, Loss: 0.032687225146219134, Final Batch Loss: 0.0037566411774605513\n",
      "Epoch 4128, Loss: 0.011517356615513563, Final Batch Loss: 0.003189003560692072\n",
      "Epoch 4129, Loss: 0.03672975685913116, Final Batch Loss: 0.0014228523941710591\n",
      "Epoch 4130, Loss: 0.008088334929198027, Final Batch Loss: 0.004993441514670849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4131, Loss: 0.07113435491919518, Final Batch Loss: 0.0034683533012866974\n",
      "Epoch 4132, Loss: 0.006632329197600484, Final Batch Loss: 0.0029002272058278322\n",
      "Epoch 4133, Loss: 0.0381702184677124, Final Batch Loss: 0.01756158098578453\n",
      "Epoch 4134, Loss: 0.007648719707503915, Final Batch Loss: 0.0043274168856441975\n",
      "Epoch 4135, Loss: 0.07549344189465046, Final Batch Loss: 0.0654485747218132\n",
      "Epoch 4136, Loss: 0.01662538480013609, Final Batch Loss: 0.004628223367035389\n",
      "Epoch 4137, Loss: 0.009450508281588554, Final Batch Loss: 0.004953374620527029\n",
      "Epoch 4138, Loss: 0.06340724136680365, Final Batch Loss: 0.05207294225692749\n",
      "Epoch 4139, Loss: 0.11346793174743652, Final Batch Loss: 0.06676896661520004\n",
      "Epoch 4140, Loss: 0.12888844683766365, Final Batch Loss: 0.0425763763487339\n",
      "Epoch 4141, Loss: 0.1265440136194229, Final Batch Loss: 0.05336564779281616\n",
      "Epoch 4142, Loss: 0.06611401960253716, Final Batch Loss: 0.031196489930152893\n",
      "Epoch 4143, Loss: 0.1154055967926979, Final Batch Loss: 0.08640313148498535\n",
      "Epoch 4144, Loss: 0.07335255667567253, Final Batch Loss: 0.04016583040356636\n",
      "Epoch 4145, Loss: 0.08244338259100914, Final Batch Loss: 0.03805893659591675\n",
      "Epoch 4146, Loss: 0.06112756207585335, Final Batch Loss: 0.01817401498556137\n",
      "Epoch 4147, Loss: 0.15415157191455364, Final Batch Loss: 0.1316010057926178\n",
      "Epoch 4148, Loss: 0.10620077047497034, Final Batch Loss: 0.0927375927567482\n",
      "Epoch 4149, Loss: 0.07630355097353458, Final Batch Loss: 0.018935048952698708\n",
      "Epoch 4150, Loss: 0.10616183653473854, Final Batch Loss: 0.0708061009645462\n",
      "Epoch 4151, Loss: 0.03800861071795225, Final Batch Loss: 0.014747138135135174\n",
      "Epoch 4152, Loss: 0.06022102199494839, Final Batch Loss: 0.023116404190659523\n",
      "Epoch 4153, Loss: 0.06297550164163113, Final Batch Loss: 0.032167356461286545\n",
      "Epoch 4154, Loss: 0.068137651309371, Final Batch Loss: 0.03764907270669937\n",
      "Epoch 4155, Loss: 0.0819903751835227, Final Batch Loss: 0.008916906081140041\n",
      "Epoch 4156, Loss: 0.054355643689632416, Final Batch Loss: 0.025401057675480843\n",
      "Epoch 4157, Loss: 0.08399796765297651, Final Batch Loss: 0.004682163707911968\n",
      "Epoch 4158, Loss: 0.04686349257826805, Final Batch Loss: 0.02660558745265007\n",
      "Epoch 4159, Loss: 0.08530604466795921, Final Batch Loss: 0.05414004623889923\n",
      "Epoch 4160, Loss: 0.05654003843665123, Final Batch Loss: 0.04227161034941673\n",
      "Epoch 4161, Loss: 0.0741903018206358, Final Batch Loss: 0.025508740916848183\n",
      "Epoch 4162, Loss: 0.06717250868678093, Final Batch Loss: 0.03804091736674309\n",
      "Epoch 4163, Loss: 0.1691835056990385, Final Batch Loss: 0.14785592257976532\n",
      "Epoch 4164, Loss: 0.06006840243935585, Final Batch Loss: 0.028988540172576904\n",
      "Epoch 4165, Loss: 0.11033339519053698, Final Batch Loss: 0.09510273486375809\n",
      "Epoch 4166, Loss: 0.05383295193314552, Final Batch Loss: 0.02061733976006508\n",
      "Epoch 4167, Loss: 0.07243039458990097, Final Batch Loss: 0.049435656517744064\n",
      "Epoch 4168, Loss: 0.0218944507651031, Final Batch Loss: 0.007639498915523291\n",
      "Epoch 4169, Loss: 0.08616800233721733, Final Batch Loss: 0.023195791989564896\n",
      "Epoch 4170, Loss: 0.04889848455786705, Final Batch Loss: 0.015667006373405457\n",
      "Epoch 4171, Loss: 0.09114100970327854, Final Batch Loss: 0.03096468560397625\n",
      "Epoch 4172, Loss: 0.020668575540184975, Final Batch Loss: 0.009526640176773071\n",
      "Epoch 4173, Loss: 0.05217629577964544, Final Batch Loss: 0.010814487002789974\n",
      "Epoch 4174, Loss: 0.05763552291318774, Final Batch Loss: 0.05058320611715317\n",
      "Epoch 4175, Loss: 0.04209325648844242, Final Batch Loss: 0.026745053008198738\n",
      "Epoch 4176, Loss: 0.039477813988924026, Final Batch Loss: 0.01894606649875641\n",
      "Epoch 4177, Loss: 0.043899187818169594, Final Batch Loss: 0.033280473202466965\n",
      "Epoch 4178, Loss: 0.04629008285701275, Final Batch Loss: 0.012285629287362099\n",
      "Epoch 4179, Loss: 0.019571388140320778, Final Batch Loss: 0.004144078120589256\n",
      "Epoch 4180, Loss: 0.03934795223176479, Final Batch Loss: 0.022503703832626343\n",
      "Epoch 4181, Loss: 0.03444527927786112, Final Batch Loss: 0.006509953178465366\n",
      "Epoch 4182, Loss: 0.02570509910583496, Final Batch Loss: 0.007577445358037949\n",
      "Epoch 4183, Loss: 0.07081755250692368, Final Batch Loss: 0.057588208466768265\n",
      "Epoch 4184, Loss: 0.08507532812654972, Final Batch Loss: 0.06623439490795135\n",
      "Epoch 4185, Loss: 0.03482102416455746, Final Batch Loss: 0.01510094664990902\n",
      "Epoch 4186, Loss: 0.05009980872273445, Final Batch Loss: 0.03534683585166931\n",
      "Epoch 4187, Loss: 0.02490119682624936, Final Batch Loss: 0.006530980113893747\n",
      "Epoch 4188, Loss: 0.01770696323364973, Final Batch Loss: 0.007910303771495819\n",
      "Epoch 4189, Loss: 0.05788084678351879, Final Batch Loss: 0.00913502462208271\n",
      "Epoch 4190, Loss: 0.025316540151834488, Final Batch Loss: 0.012919281609356403\n",
      "Epoch 4191, Loss: 0.023227620404213667, Final Batch Loss: 0.016265083104372025\n",
      "Epoch 4192, Loss: 0.06392243131995201, Final Batch Loss: 0.03437857702374458\n",
      "Epoch 4193, Loss: 0.0688388142734766, Final Batch Loss: 0.05968872830271721\n",
      "Epoch 4194, Loss: 0.03435306530445814, Final Batch Loss: 0.004162798635661602\n",
      "Epoch 4195, Loss: 0.03937988821417093, Final Batch Loss: 0.010566300712525845\n",
      "Epoch 4196, Loss: 0.021952898241579533, Final Batch Loss: 0.0035269679501652718\n",
      "Epoch 4197, Loss: 0.04222891363315284, Final Batch Loss: 0.0023294563870877028\n",
      "Epoch 4198, Loss: 0.048314230516552925, Final Batch Loss: 0.02010752633213997\n",
      "Epoch 4199, Loss: 0.029836284928023815, Final Batch Loss: 0.011738761328160763\n",
      "Epoch 4200, Loss: 0.019311730982735753, Final Batch Loss: 0.0028730605263262987\n",
      "Epoch 4201, Loss: 0.07642471790313721, Final Batch Loss: 0.04476231336593628\n",
      "Epoch 4202, Loss: 0.021077292971313, Final Batch Loss: 0.007906110025942326\n",
      "Epoch 4203, Loss: 0.03390211332589388, Final Batch Loss: 0.022495564073324203\n",
      "Epoch 4204, Loss: 0.0714035164564848, Final Batch Loss: 0.0412798710167408\n",
      "Epoch 4205, Loss: 0.03696738928556442, Final Batch Loss: 0.016515513882040977\n",
      "Epoch 4206, Loss: 0.06516282446682453, Final Batch Loss: 0.04692564159631729\n",
      "Epoch 4207, Loss: 0.03301936434581876, Final Batch Loss: 0.0031019714660942554\n",
      "Epoch 4208, Loss: 0.05456344783306122, Final Batch Loss: 0.01568295806646347\n",
      "Epoch 4209, Loss: 0.05132376030087471, Final Batch Loss: 0.0386195033788681\n",
      "Epoch 4210, Loss: 0.03223924245685339, Final Batch Loss: 0.005402081646025181\n",
      "Epoch 4211, Loss: 0.03440435975790024, Final Batch Loss: 0.010712210088968277\n",
      "Epoch 4212, Loss: 0.023635525722056627, Final Batch Loss: 0.00428800517693162\n",
      "Epoch 4213, Loss: 0.03540079575031996, Final Batch Loss: 0.009343146346509457\n",
      "Epoch 4214, Loss: 0.023835692554712296, Final Batch Loss: 0.01498096901923418\n",
      "Epoch 4215, Loss: 0.05170670244842768, Final Batch Loss: 0.013582096435129642\n",
      "Epoch 4216, Loss: 0.061784906312823296, Final Batch Loss: 0.043606072664260864\n",
      "Epoch 4217, Loss: 0.02742510475218296, Final Batch Loss: 0.012870398350059986\n",
      "Epoch 4218, Loss: 0.0828079953789711, Final Batch Loss: 0.0345030277967453\n",
      "Epoch 4219, Loss: 0.026216822676360607, Final Batch Loss: 0.012836660258471966\n",
      "Epoch 4220, Loss: 0.0236011054366827, Final Batch Loss: 0.010642100125551224\n",
      "Epoch 4221, Loss: 0.050333382561802864, Final Batch Loss: 0.037662189453840256\n",
      "Epoch 4222, Loss: 0.028789930045604706, Final Batch Loss: 0.013422457501292229\n",
      "Epoch 4223, Loss: 0.03896377421915531, Final Batch Loss: 0.0239045899361372\n",
      "Epoch 4224, Loss: 0.035482573322951794, Final Batch Loss: 0.009236234240233898\n",
      "Epoch 4225, Loss: 0.03156210668385029, Final Batch Loss: 0.010958775877952576\n",
      "Epoch 4226, Loss: 0.026867867447435856, Final Batch Loss: 0.0064712828025221825\n",
      "Epoch 4227, Loss: 0.030397855676710606, Final Batch Loss: 0.007926556281745434\n",
      "Epoch 4228, Loss: 0.06409645080566406, Final Batch Loss: 0.032809872180223465\n",
      "Epoch 4229, Loss: 0.05070129968225956, Final Batch Loss: 0.042914070188999176\n",
      "Epoch 4230, Loss: 0.04914407804608345, Final Batch Loss: 0.01606585830450058\n",
      "Epoch 4231, Loss: 0.037040894851088524, Final Batch Loss: 0.023211630061268806\n",
      "Epoch 4232, Loss: 0.025104258442297578, Final Batch Loss: 0.002557154977694154\n",
      "Epoch 4233, Loss: 0.059615613892674446, Final Batch Loss: 0.04019530490040779\n",
      "Epoch 4234, Loss: 0.01908488618209958, Final Batch Loss: 0.006481748539954424\n",
      "Epoch 4235, Loss: 0.03344650659710169, Final Batch Loss: 0.009602521546185017\n",
      "Epoch 4236, Loss: 0.01952240872196853, Final Batch Loss: 0.0034827187191694975\n",
      "Epoch 4237, Loss: 0.018267817329615355, Final Batch Loss: 0.006481319200247526\n",
      "Epoch 4238, Loss: 0.05587831698358059, Final Batch Loss: 0.021786140277981758\n",
      "Epoch 4239, Loss: 0.0676601268351078, Final Batch Loss: 0.035789065062999725\n",
      "Epoch 4240, Loss: 0.07856203569099307, Final Batch Loss: 0.006444572936743498\n",
      "Epoch 4241, Loss: 0.07441442832350731, Final Batch Loss: 0.06628554314374924\n",
      "Epoch 4242, Loss: 0.01464343722909689, Final Batch Loss: 0.004385205917060375\n",
      "Epoch 4243, Loss: 0.025220947340130806, Final Batch Loss: 0.017866307869553566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4244, Loss: 0.027854090556502342, Final Batch Loss: 0.009215585887432098\n",
      "Epoch 4245, Loss: 0.03536027669906616, Final Batch Loss: 0.01821869984269142\n",
      "Epoch 4246, Loss: 0.0590477311052382, Final Batch Loss: 0.05216683819890022\n",
      "Epoch 4247, Loss: 0.03456444572657347, Final Batch Loss: 0.008059672079980373\n",
      "Epoch 4248, Loss: 0.05738642066717148, Final Batch Loss: 0.01386900246143341\n",
      "Epoch 4249, Loss: 0.016814021626487374, Final Batch Loss: 0.0037882470060139894\n",
      "Epoch 4250, Loss: 0.05552344210445881, Final Batch Loss: 0.03836445510387421\n",
      "Epoch 4251, Loss: 0.0629178136587143, Final Batch Loss: 0.030442502349615097\n",
      "Epoch 4252, Loss: 0.021166773047298193, Final Batch Loss: 0.007379972841590643\n",
      "Epoch 4253, Loss: 0.03323855437338352, Final Batch Loss: 0.015966180711984634\n",
      "Epoch 4254, Loss: 0.05981129687279463, Final Batch Loss: 0.04421672224998474\n",
      "Epoch 4255, Loss: 0.030563965439796448, Final Batch Loss: 0.014317097142338753\n",
      "Epoch 4256, Loss: 0.02326877787709236, Final Batch Loss: 0.008989818394184113\n",
      "Epoch 4257, Loss: 0.026912523433566093, Final Batch Loss: 0.012065869756042957\n",
      "Epoch 4258, Loss: 0.04676820058375597, Final Batch Loss: 0.0395849347114563\n",
      "Epoch 4259, Loss: 0.03734171576797962, Final Batch Loss: 0.016310960054397583\n",
      "Epoch 4260, Loss: 0.03227006341330707, Final Batch Loss: 0.0022459260653704405\n",
      "Epoch 4261, Loss: 0.07429967075586319, Final Batch Loss: 0.038639239966869354\n",
      "Epoch 4262, Loss: 0.02341477759182453, Final Batch Loss: 0.007433813065290451\n",
      "Epoch 4263, Loss: 0.03525919700041413, Final Batch Loss: 0.02772386558353901\n",
      "Epoch 4264, Loss: 0.0492158979177475, Final Batch Loss: 0.030749300494790077\n",
      "Epoch 4265, Loss: 0.030989903025329113, Final Batch Loss: 0.006523058749735355\n",
      "Epoch 4266, Loss: 0.039903584867715836, Final Batch Loss: 0.03277115523815155\n",
      "Epoch 4267, Loss: 0.03256703121587634, Final Batch Loss: 0.024892648681998253\n",
      "Epoch 4268, Loss: 0.02961822133511305, Final Batch Loss: 0.011995171196758747\n",
      "Epoch 4269, Loss: 0.007400513626635075, Final Batch Loss: 0.00238982867449522\n",
      "Epoch 4270, Loss: 0.007688963087275624, Final Batch Loss: 0.005436022765934467\n",
      "Epoch 4271, Loss: 0.01971981185488403, Final Batch Loss: 0.002678862540051341\n",
      "Epoch 4272, Loss: 0.19648512452840805, Final Batch Loss: 0.15499213337898254\n",
      "Epoch 4273, Loss: 0.01993569836486131, Final Batch Loss: 0.0014314419822767377\n",
      "Epoch 4274, Loss: 0.0475954245775938, Final Batch Loss: 0.028833620250225067\n",
      "Epoch 4275, Loss: 0.045137675013393164, Final Batch Loss: 0.004786094184964895\n",
      "Epoch 4276, Loss: 0.06349330209195614, Final Batch Loss: 0.04845535010099411\n",
      "Epoch 4277, Loss: 0.06044191331602633, Final Batch Loss: 0.057511840015649796\n",
      "Epoch 4278, Loss: 0.10720711573958397, Final Batch Loss: 0.037062499672174454\n",
      "Epoch 4279, Loss: 0.11239071935415268, Final Batch Loss: 0.07695465534925461\n",
      "Epoch 4280, Loss: 0.05886961054056883, Final Batch Loss: 0.003090842626988888\n",
      "Epoch 4281, Loss: 0.06916843261569738, Final Batch Loss: 0.01543158944696188\n",
      "Epoch 4282, Loss: 0.11506326496601105, Final Batch Loss: 0.09616515785455704\n",
      "Epoch 4283, Loss: 0.14569571614265442, Final Batch Loss: 0.08964382112026215\n",
      "Epoch 4284, Loss: 0.2544717490673065, Final Batch Loss: 0.08394119143486023\n",
      "Epoch 4285, Loss: 0.11701510287821293, Final Batch Loss: 0.090413898229599\n",
      "Epoch 4286, Loss: 0.036301310174167156, Final Batch Loss: 0.02365238405764103\n",
      "Epoch 4287, Loss: 0.04354611225426197, Final Batch Loss: 0.016516387462615967\n",
      "Epoch 4288, Loss: 0.13592582195997238, Final Batch Loss: 0.09818068891763687\n",
      "Epoch 4289, Loss: 0.07964262366294861, Final Batch Loss: 0.03759972006082535\n",
      "Epoch 4290, Loss: 0.017767305951565504, Final Batch Loss: 0.0062887356616556644\n",
      "Epoch 4291, Loss: 0.05353814549744129, Final Batch Loss: 0.011147899553179741\n",
      "Epoch 4292, Loss: 0.06457995995879173, Final Batch Loss: 0.012624673545360565\n",
      "Epoch 4293, Loss: 0.04575567692518234, Final Batch Loss: 0.013625010848045349\n",
      "Epoch 4294, Loss: 0.03261593449860811, Final Batch Loss: 0.0055541591718792915\n",
      "Epoch 4295, Loss: 0.06319128349423409, Final Batch Loss: 0.03524071350693703\n",
      "Epoch 4296, Loss: 0.042760225012898445, Final Batch Loss: 0.03219572454690933\n",
      "Epoch 4297, Loss: 0.04146655648946762, Final Batch Loss: 0.02255004085600376\n",
      "Epoch 4298, Loss: 0.04456261172890663, Final Batch Loss: 0.0186174176633358\n",
      "Epoch 4299, Loss: 0.04927696846425533, Final Batch Loss: 0.0233249980956316\n",
      "Epoch 4300, Loss: 0.05051114782691002, Final Batch Loss: 0.016828905791044235\n",
      "Epoch 4301, Loss: 0.0333043048158288, Final Batch Loss: 0.013931862078607082\n",
      "Epoch 4302, Loss: 0.054005216807127, Final Batch Loss: 0.03392474725842476\n",
      "Epoch 4303, Loss: 0.027462443336844444, Final Batch Loss: 0.008120143786072731\n",
      "Epoch 4304, Loss: 0.03530141059309244, Final Batch Loss: 0.027744481340050697\n",
      "Epoch 4305, Loss: 0.041550648398697376, Final Batch Loss: 0.02781037427484989\n",
      "Epoch 4306, Loss: 0.029211421497166157, Final Batch Loss: 0.011793077923357487\n",
      "Epoch 4307, Loss: 0.031278437934815884, Final Batch Loss: 0.011273168958723545\n",
      "Epoch 4308, Loss: 0.02921021357178688, Final Batch Loss: 0.014286795631051064\n",
      "Epoch 4309, Loss: 0.043016672134399414, Final Batch Loss: 0.00471847876906395\n",
      "Epoch 4310, Loss: 0.06674575433135033, Final Batch Loss: 0.04848264157772064\n",
      "Epoch 4311, Loss: 0.055241484893485904, Final Batch Loss: 0.0037992156576365232\n",
      "Epoch 4312, Loss: 0.10298553854227066, Final Batch Loss: 0.06228630617260933\n",
      "Epoch 4313, Loss: 0.02792833372950554, Final Batch Loss: 0.012491496279835701\n",
      "Epoch 4314, Loss: 0.058663330506533384, Final Batch Loss: 0.006271548103541136\n",
      "Epoch 4315, Loss: 0.02504820143803954, Final Batch Loss: 0.007015240844339132\n",
      "Epoch 4316, Loss: 0.03810819052159786, Final Batch Loss: 0.011790979653596878\n",
      "Epoch 4317, Loss: 0.0185054293833673, Final Batch Loss: 0.004729944746941328\n",
      "Epoch 4318, Loss: 0.05160225369036198, Final Batch Loss: 0.02330700121819973\n",
      "Epoch 4319, Loss: 0.041053829714655876, Final Batch Loss: 0.011673375964164734\n",
      "Epoch 4320, Loss: 0.058995017781853676, Final Batch Loss: 0.04957647621631622\n",
      "Epoch 4321, Loss: 0.058403207920491695, Final Batch Loss: 0.013431868515908718\n",
      "Epoch 4322, Loss: 0.03419554093852639, Final Batch Loss: 0.007024273741990328\n",
      "Epoch 4323, Loss: 0.048810435459017754, Final Batch Loss: 0.02560049667954445\n",
      "Epoch 4324, Loss: 0.027932733297348022, Final Batch Loss: 0.00830584205687046\n",
      "Epoch 4325, Loss: 0.030427944380789995, Final Batch Loss: 0.0076142591424286366\n",
      "Epoch 4326, Loss: 0.06234910525381565, Final Batch Loss: 0.035065047442913055\n",
      "Epoch 4327, Loss: 0.05202109087258577, Final Batch Loss: 0.0410991907119751\n",
      "Epoch 4328, Loss: 0.04036671109497547, Final Batch Loss: 0.024149512872099876\n",
      "Epoch 4329, Loss: 0.033414576668292284, Final Batch Loss: 0.02578692138195038\n",
      "Epoch 4330, Loss: 0.08905986975878477, Final Batch Loss: 0.08060072362422943\n",
      "Epoch 4331, Loss: 0.06600484997034073, Final Batch Loss: 0.025098390877246857\n",
      "Epoch 4332, Loss: 0.0394758777692914, Final Batch Loss: 0.02726670354604721\n",
      "Epoch 4333, Loss: 0.06100489944219589, Final Batch Loss: 0.007608789950609207\n",
      "Epoch 4334, Loss: 0.06624470092356205, Final Batch Loss: 0.04162058234214783\n",
      "Epoch 4335, Loss: 0.10458304919302464, Final Batch Loss: 0.08838382363319397\n",
      "Epoch 4336, Loss: 0.053293853998184204, Final Batch Loss: 0.03566616401076317\n",
      "Epoch 4337, Loss: 0.02157063502818346, Final Batch Loss: 0.012020350433886051\n",
      "Epoch 4338, Loss: 0.06091421656310558, Final Batch Loss: 0.017444292083382607\n",
      "Epoch 4339, Loss: 0.04653247818350792, Final Batch Loss: 0.026126042008399963\n",
      "Epoch 4340, Loss: 0.03414198663085699, Final Batch Loss: 0.008576382882893085\n",
      "Epoch 4341, Loss: 0.05210110358893871, Final Batch Loss: 0.016063788905739784\n",
      "Epoch 4342, Loss: 0.031103627756237984, Final Batch Loss: 0.02031262032687664\n",
      "Epoch 4343, Loss: 0.03698668256402016, Final Batch Loss: 0.011084677651524544\n",
      "Epoch 4344, Loss: 0.05928746424615383, Final Batch Loss: 0.01524488814175129\n",
      "Epoch 4345, Loss: 0.034190052188932896, Final Batch Loss: 0.015536856837570667\n",
      "Epoch 4346, Loss: 0.03456577961333096, Final Batch Loss: 0.0024162635672837496\n",
      "Epoch 4347, Loss: 0.025920136831700802, Final Batch Loss: 0.00505776796489954\n",
      "Epoch 4348, Loss: 0.025795592926442623, Final Batch Loss: 0.01591046154499054\n",
      "Epoch 4349, Loss: 0.023997357580810785, Final Batch Loss: 0.004001955036073923\n",
      "Epoch 4350, Loss: 0.012362383073195815, Final Batch Loss: 0.008929123170673847\n",
      "Epoch 4351, Loss: 0.08349043037742376, Final Batch Loss: 0.0780796930193901\n",
      "Epoch 4352, Loss: 0.045474315993487835, Final Batch Loss: 0.011292281560599804\n",
      "Epoch 4353, Loss: 0.037934706546366215, Final Batch Loss: 0.01119388546794653\n",
      "Epoch 4354, Loss: 0.01897655101493001, Final Batch Loss: 0.002127269748598337\n",
      "Epoch 4355, Loss: 0.03424134897068143, Final Batch Loss: 0.007327342871576548\n",
      "Epoch 4356, Loss: 0.10908563435077667, Final Batch Loss: 0.06620197743177414\n",
      "Epoch 4357, Loss: 0.02675933763384819, Final Batch Loss: 0.019725952297449112\n",
      "Epoch 4358, Loss: 0.012741319835186005, Final Batch Loss: 0.0026814723387360573\n",
      "Epoch 4359, Loss: 0.2394750639796257, Final Batch Loss: 0.19425715506076813\n",
      "Epoch 4360, Loss: 0.01923392154276371, Final Batch Loss: 0.005281859077513218\n",
      "Epoch 4361, Loss: 0.18585838936269283, Final Batch Loss: 0.025897866114974022\n",
      "Epoch 4362, Loss: 0.048238047398626804, Final Batch Loss: 0.013810147531330585\n",
      "Epoch 4363, Loss: 0.15618342254310846, Final Batch Loss: 0.14682160317897797\n",
      "Epoch 4364, Loss: 0.031003544107079506, Final Batch Loss: 0.01714337430894375\n",
      "Epoch 4365, Loss: 0.008666125126183033, Final Batch Loss: 0.0039123659953475\n",
      "Epoch 4366, Loss: 0.012856020126491785, Final Batch Loss: 0.004199965391308069\n",
      "Epoch 4367, Loss: 0.03656906634569168, Final Batch Loss: 0.023036450147628784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4368, Loss: 0.013379425974562764, Final Batch Loss: 0.0031760812271386385\n",
      "Epoch 4369, Loss: 0.025423300452530384, Final Batch Loss: 0.008954194374382496\n",
      "Epoch 4370, Loss: 0.11165883298963308, Final Batch Loss: 0.10065928846597672\n",
      "Epoch 4371, Loss: 0.015052986796945333, Final Batch Loss: 0.003756632562726736\n",
      "Epoch 4372, Loss: 0.024266650900244713, Final Batch Loss: 0.010295224376022816\n",
      "Epoch 4373, Loss: 0.06371942022815347, Final Batch Loss: 0.004914405290037394\n",
      "Epoch 4374, Loss: 0.016108558047562838, Final Batch Loss: 0.0068207294680178165\n",
      "Epoch 4375, Loss: 0.030430518090724945, Final Batch Loss: 0.007835622876882553\n",
      "Epoch 4376, Loss: 0.015684685669839382, Final Batch Loss: 0.004208996891975403\n",
      "Epoch 4377, Loss: 0.03787083690986037, Final Batch Loss: 0.03194655105471611\n",
      "Epoch 4378, Loss: 0.015836277976632118, Final Batch Loss: 0.0076310159638524055\n",
      "Epoch 4379, Loss: 0.0641250442713499, Final Batch Loss: 0.04178892821073532\n",
      "Epoch 4380, Loss: 0.04319225624203682, Final Batch Loss: 0.032000832259655\n",
      "Epoch 4381, Loss: 0.02796301245689392, Final Batch Loss: 0.019853154197335243\n",
      "Epoch 4382, Loss: 0.04447169415652752, Final Batch Loss: 0.03476607799530029\n",
      "Epoch 4383, Loss: 0.03629230801016092, Final Batch Loss: 0.022495172917842865\n",
      "Epoch 4384, Loss: 0.03827551007270813, Final Batch Loss: 0.02226829342544079\n",
      "Epoch 4385, Loss: 0.018398030661046505, Final Batch Loss: 0.006539491005241871\n",
      "Epoch 4386, Loss: 0.043588386848568916, Final Batch Loss: 0.019729893654584885\n",
      "Epoch 4387, Loss: 0.01048176409676671, Final Batch Loss: 0.004261956550180912\n",
      "Epoch 4388, Loss: 0.0162065620534122, Final Batch Loss: 0.0025197616778314114\n",
      "Epoch 4389, Loss: 0.016671376884914935, Final Batch Loss: 0.014779357239603996\n",
      "Epoch 4390, Loss: 0.040824076742865145, Final Batch Loss: 0.0012801761040464044\n",
      "Epoch 4391, Loss: 0.015134670305997133, Final Batch Loss: 0.008064905181527138\n",
      "Epoch 4392, Loss: 0.022939317394047976, Final Batch Loss: 0.017578832805156708\n",
      "Epoch 4393, Loss: 0.035893244203180075, Final Batch Loss: 0.005495383869856596\n",
      "Epoch 4394, Loss: 0.04199591604992747, Final Batch Loss: 0.03587302565574646\n",
      "Epoch 4395, Loss: 0.06777471210807562, Final Batch Loss: 0.011570851318538189\n",
      "Epoch 4396, Loss: 0.038133293855935335, Final Batch Loss: 0.033050112426280975\n",
      "Epoch 4397, Loss: 0.0785480048507452, Final Batch Loss: 0.04800745099782944\n",
      "Epoch 4398, Loss: 0.03012586897239089, Final Batch Loss: 0.004025427158921957\n",
      "Epoch 4399, Loss: 0.02220731438137591, Final Batch Loss: 0.018918292596936226\n",
      "Epoch 4400, Loss: 0.009615610353648663, Final Batch Loss: 0.001730695366859436\n",
      "Epoch 4401, Loss: 0.014222637051716447, Final Batch Loss: 0.001542289974167943\n",
      "Epoch 4402, Loss: 0.03575861034914851, Final Batch Loss: 0.03031982108950615\n",
      "Epoch 4403, Loss: 0.04484020243398845, Final Batch Loss: 0.041966795921325684\n",
      "Epoch 4404, Loss: 0.020102863665670156, Final Batch Loss: 0.014856710098683834\n",
      "Epoch 4405, Loss: 0.049638501135632396, Final Batch Loss: 0.0028443920891731977\n",
      "Epoch 4406, Loss: 0.013688626931980252, Final Batch Loss: 0.0037087772507220507\n",
      "Epoch 4407, Loss: 0.03051525540649891, Final Batch Loss: 0.004429973661899567\n",
      "Epoch 4408, Loss: 0.011585277738049626, Final Batch Loss: 0.0033735514152795076\n",
      "Epoch 4409, Loss: 0.030354061163961887, Final Batch Loss: 0.017389900982379913\n",
      "Epoch 4410, Loss: 0.013391114072874188, Final Batch Loss: 0.0019155743066221476\n",
      "Epoch 4411, Loss: 0.008775128051638603, Final Batch Loss: 0.004184702876955271\n",
      "Epoch 4412, Loss: 0.08663784898817539, Final Batch Loss: 0.08221785724163055\n",
      "Epoch 4413, Loss: 0.021321780048310757, Final Batch Loss: 0.011456158943474293\n",
      "Epoch 4414, Loss: 0.020222490653395653, Final Batch Loss: 0.01094286609441042\n",
      "Epoch 4415, Loss: 0.0075001041404902935, Final Batch Loss: 0.002915259450674057\n",
      "Epoch 4416, Loss: 0.014927377691492438, Final Batch Loss: 0.011525167152285576\n",
      "Epoch 4417, Loss: 0.015620893333107233, Final Batch Loss: 0.008545707911252975\n",
      "Epoch 4418, Loss: 0.03428977355360985, Final Batch Loss: 0.010078934952616692\n",
      "Epoch 4419, Loss: 0.015753774903714657, Final Batch Loss: 0.011724714189767838\n",
      "Epoch 4420, Loss: 0.1056660134345293, Final Batch Loss: 0.01723945327103138\n",
      "Epoch 4421, Loss: 0.01356109231710434, Final Batch Loss: 0.007222931366413832\n",
      "Epoch 4422, Loss: 0.017025979701429605, Final Batch Loss: 0.0054379780776798725\n",
      "Epoch 4423, Loss: 0.07396836369298398, Final Batch Loss: 0.003662017872557044\n",
      "Epoch 4424, Loss: 0.0169884548522532, Final Batch Loss: 0.005511709954589605\n",
      "Epoch 4425, Loss: 0.0196870737709105, Final Batch Loss: 0.007369220722466707\n",
      "Epoch 4426, Loss: 0.022151434794068336, Final Batch Loss: 0.003925377503037453\n",
      "Epoch 4427, Loss: 0.009437109110876918, Final Batch Loss: 0.006716704927384853\n",
      "Epoch 4428, Loss: 0.019411953864619136, Final Batch Loss: 0.003511457471176982\n",
      "Epoch 4429, Loss: 0.007419336121529341, Final Batch Loss: 0.0048853131011128426\n",
      "Epoch 4430, Loss: 0.05926254019141197, Final Batch Loss: 0.04339224100112915\n",
      "Epoch 4431, Loss: 0.052252622321248055, Final Batch Loss: 0.03596216440200806\n",
      "Epoch 4432, Loss: 0.03970901295542717, Final Batch Loss: 0.03346894681453705\n",
      "Epoch 4433, Loss: 0.019348337315022945, Final Batch Loss: 0.007568897679448128\n",
      "Epoch 4434, Loss: 0.03367074532434344, Final Batch Loss: 0.004966495092958212\n",
      "Epoch 4435, Loss: 0.03798755956813693, Final Batch Loss: 0.03306843712925911\n",
      "Epoch 4436, Loss: 0.021587274502962828, Final Batch Loss: 0.014551171101629734\n",
      "Epoch 4437, Loss: 0.02261702436953783, Final Batch Loss: 0.012550944462418556\n",
      "Epoch 4438, Loss: 0.10492599382996559, Final Batch Loss: 0.03682238236069679\n",
      "Epoch 4439, Loss: 0.07583778630942106, Final Batch Loss: 0.06682909280061722\n",
      "Epoch 4440, Loss: 0.020143709145486355, Final Batch Loss: 0.013854505494236946\n",
      "Epoch 4441, Loss: 0.04092753119766712, Final Batch Loss: 0.006287014111876488\n",
      "Epoch 4442, Loss: 0.030350765213370323, Final Batch Loss: 0.01578247919678688\n",
      "Epoch 4443, Loss: 0.024382375180721283, Final Batch Loss: 0.009388572536408901\n",
      "Epoch 4444, Loss: 0.02056770119816065, Final Batch Loss: 0.0024954332038760185\n",
      "Epoch 4445, Loss: 0.13434642273932695, Final Batch Loss: 0.12374438345432281\n",
      "Epoch 4446, Loss: 0.02903079893440008, Final Batch Loss: 0.012869690544903278\n",
      "Epoch 4447, Loss: 0.010421715211123228, Final Batch Loss: 0.0016692518256604671\n",
      "Epoch 4448, Loss: 0.0273616531630978, Final Batch Loss: 0.0018342280527576804\n",
      "Epoch 4449, Loss: 0.03953152149915695, Final Batch Loss: 0.011404847726225853\n",
      "Epoch 4450, Loss: 0.05640694219619036, Final Batch Loss: 0.049993254244327545\n",
      "Epoch 4451, Loss: 0.00836771517060697, Final Batch Loss: 0.0015148802194744349\n",
      "Epoch 4452, Loss: 0.004943198058754206, Final Batch Loss: 0.0019980361685156822\n",
      "Epoch 4453, Loss: 0.02661257074214518, Final Batch Loss: 0.00236739800311625\n",
      "Epoch 4454, Loss: 0.020241172751411796, Final Batch Loss: 0.018072335049510002\n",
      "Epoch 4455, Loss: 0.015004646498709917, Final Batch Loss: 0.0054269530810415745\n",
      "Epoch 4456, Loss: 0.01096312003210187, Final Batch Loss: 0.004587903618812561\n",
      "Epoch 4457, Loss: 0.04877132549881935, Final Batch Loss: 0.01866907998919487\n",
      "Epoch 4458, Loss: 0.006530828308314085, Final Batch Loss: 0.0018914476968348026\n",
      "Epoch 4459, Loss: 0.009738369146361947, Final Batch Loss: 0.002863735193386674\n",
      "Epoch 4460, Loss: 0.0287656900472939, Final Batch Loss: 0.0019912556745111942\n",
      "Epoch 4461, Loss: 0.032819942105561495, Final Batch Loss: 0.004629429895430803\n",
      "Epoch 4462, Loss: 0.06427852902561426, Final Batch Loss: 0.05749228224158287\n",
      "Epoch 4463, Loss: 0.01242718892171979, Final Batch Loss: 0.0028537590987980366\n",
      "Epoch 4464, Loss: 0.004367271845694631, Final Batch Loss: 0.0006953186239115894\n",
      "Epoch 4465, Loss: 0.020723792200442404, Final Batch Loss: 0.0008977730176411569\n",
      "Epoch 4466, Loss: 0.02059079660102725, Final Batch Loss: 0.01731809228658676\n",
      "Epoch 4467, Loss: 0.053303811233490705, Final Batch Loss: 0.005865394603461027\n",
      "Epoch 4468, Loss: 0.006429309956729412, Final Batch Loss: 0.002736652735620737\n",
      "Epoch 4469, Loss: 0.01946903974749148, Final Batch Loss: 0.0020144919399172068\n",
      "Epoch 4470, Loss: 0.01075583091005683, Final Batch Loss: 0.006734820082783699\n",
      "Epoch 4471, Loss: 0.016904734075069427, Final Batch Loss: 0.01066172681748867\n",
      "Epoch 4472, Loss: 0.05168907926417887, Final Batch Loss: 0.0022831170354038477\n",
      "Epoch 4473, Loss: 0.012930230470374227, Final Batch Loss: 0.003233954543247819\n",
      "Epoch 4474, Loss: 0.021772713866084814, Final Batch Loss: 0.006604850757867098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4475, Loss: 0.03300483338534832, Final Batch Loss: 0.016572488471865654\n",
      "Epoch 4476, Loss: 0.029120516031980515, Final Batch Loss: 0.004222739487886429\n",
      "Epoch 4477, Loss: 0.016685894690454006, Final Batch Loss: 0.011600488796830177\n",
      "Epoch 4478, Loss: 0.005172166274860501, Final Batch Loss: 0.002522819908335805\n",
      "Epoch 4479, Loss: 0.016148301190696657, Final Batch Loss: 0.0006937443977221847\n",
      "Epoch 4480, Loss: 0.014028037898242474, Final Batch Loss: 0.0016846591606736183\n",
      "Epoch 4481, Loss: 0.026800096267834306, Final Batch Loss: 0.002716858172789216\n",
      "Epoch 4482, Loss: 0.007310642162337899, Final Batch Loss: 0.0033633087296038866\n",
      "Epoch 4483, Loss: 0.019943254068493843, Final Batch Loss: 0.006975429132580757\n",
      "Epoch 4484, Loss: 0.04338900186121464, Final Batch Loss: 0.024808280169963837\n",
      "Epoch 4485, Loss: 0.01813744381070137, Final Batch Loss: 0.00667875912040472\n",
      "Epoch 4486, Loss: 0.018946449854411185, Final Batch Loss: 0.0018784810090437531\n",
      "Epoch 4487, Loss: 0.10010586935095489, Final Batch Loss: 0.09748126566410065\n",
      "Epoch 4488, Loss: 0.01050514541566372, Final Batch Loss: 0.004959322512149811\n",
      "Epoch 4489, Loss: 0.023089612368494272, Final Batch Loss: 0.003226150292903185\n",
      "Epoch 4490, Loss: 0.040725238621234894, Final Batch Loss: 0.015627475455403328\n",
      "Epoch 4491, Loss: 0.006921887630596757, Final Batch Loss: 0.00448499945923686\n",
      "Epoch 4492, Loss: 0.0397973358631134, Final Batch Loss: 0.018584663048386574\n",
      "Epoch 4493, Loss: 0.01084848353639245, Final Batch Loss: 0.007119393907487392\n",
      "Epoch 4494, Loss: 0.03592591593042016, Final Batch Loss: 0.0035319426096975803\n",
      "Epoch 4495, Loss: 0.02054170984774828, Final Batch Loss: 0.004112684167921543\n",
      "Epoch 4496, Loss: 0.0346873146481812, Final Batch Loss: 0.006563282106071711\n",
      "Epoch 4497, Loss: 0.01628417707979679, Final Batch Loss: 0.00907739344984293\n",
      "Epoch 4498, Loss: 0.016334249638020992, Final Batch Loss: 0.004968850873410702\n",
      "Epoch 4499, Loss: 0.02776948641985655, Final Batch Loss: 0.022297780960798264\n",
      "Epoch 4500, Loss: 0.008494176901876926, Final Batch Loss: 0.004855093080550432\n",
      "Epoch 4501, Loss: 0.022943954914808273, Final Batch Loss: 0.003167223185300827\n",
      "Epoch 4502, Loss: 0.009123236872255802, Final Batch Loss: 0.006018300540745258\n",
      "Epoch 4503, Loss: 0.024453736492432654, Final Batch Loss: 0.02272934839129448\n",
      "Epoch 4504, Loss: 0.006591318408027291, Final Batch Loss: 0.0017423008102923632\n",
      "Epoch 4505, Loss: 0.00612757308408618, Final Batch Loss: 0.0044184415601193905\n",
      "Epoch 4506, Loss: 0.00735865137539804, Final Batch Loss: 0.002071024151518941\n",
      "Epoch 4507, Loss: 0.031650666147470474, Final Batch Loss: 0.005092553794384003\n",
      "Epoch 4508, Loss: 0.010600488632917404, Final Batch Loss: 0.006677460856735706\n",
      "Epoch 4509, Loss: 0.07518807239830494, Final Batch Loss: 0.06368174403905869\n",
      "Epoch 4510, Loss: 0.008878347463905811, Final Batch Loss: 0.004899358376860619\n",
      "Epoch 4511, Loss: 0.009508572053164244, Final Batch Loss: 0.001679444219917059\n",
      "Epoch 4512, Loss: 0.023399218916893005, Final Batch Loss: 0.020045392215251923\n",
      "Epoch 4513, Loss: 0.006528029218316078, Final Batch Loss: 0.0038705060724169016\n",
      "Epoch 4514, Loss: 0.004083363455720246, Final Batch Loss: 0.0026186658069491386\n",
      "Epoch 4515, Loss: 0.01611005561426282, Final Batch Loss: 0.007040496449917555\n",
      "Epoch 4516, Loss: 0.013700275681912899, Final Batch Loss: 0.006833173800259829\n",
      "Epoch 4517, Loss: 0.020511274691671133, Final Batch Loss: 0.005728172603994608\n",
      "Epoch 4518, Loss: 0.010153839364647865, Final Batch Loss: 0.0055506471544504166\n",
      "Epoch 4519, Loss: 0.01860528066754341, Final Batch Loss: 0.01241124328225851\n",
      "Epoch 4520, Loss: 0.03496596869081259, Final Batch Loss: 0.014402451924979687\n",
      "Epoch 4521, Loss: 0.024599367752671242, Final Batch Loss: 0.011010977439582348\n",
      "Epoch 4522, Loss: 0.0069830757565796375, Final Batch Loss: 0.003962188493460417\n",
      "Epoch 4523, Loss: 0.05697175860404968, Final Batch Loss: 0.021445024758577347\n",
      "Epoch 4524, Loss: 0.010551065439358354, Final Batch Loss: 0.003812924725934863\n",
      "Epoch 4525, Loss: 0.04836814315058291, Final Batch Loss: 0.003891477594152093\n",
      "Epoch 4526, Loss: 0.02679851232096553, Final Batch Loss: 0.007421731483191252\n",
      "Epoch 4527, Loss: 0.02169174887239933, Final Batch Loss: 0.015302271582186222\n",
      "Epoch 4528, Loss: 0.022921832278370857, Final Batch Loss: 0.007352855056524277\n",
      "Epoch 4529, Loss: 0.03826429462060332, Final Batch Loss: 0.03242599219083786\n",
      "Epoch 4530, Loss: 0.051987115293741226, Final Batch Loss: 0.03504512459039688\n",
      "Epoch 4531, Loss: 0.0760601304937154, Final Batch Loss: 0.07236099988222122\n",
      "Epoch 4532, Loss: 0.0078039346262812614, Final Batch Loss: 0.0021188328973948956\n",
      "Epoch 4533, Loss: 0.012289965990930796, Final Batch Loss: 0.007508136797696352\n",
      "Epoch 4534, Loss: 0.015293898992240429, Final Batch Loss: 0.004786129109561443\n",
      "Epoch 4535, Loss: 0.008950533112511039, Final Batch Loss: 0.002368283225223422\n",
      "Epoch 4536, Loss: 0.007146827876567841, Final Batch Loss: 0.0032992640044540167\n",
      "Epoch 4537, Loss: 0.005432015284895897, Final Batch Loss: 0.0013432465493679047\n",
      "Epoch 4538, Loss: 0.004411407629959285, Final Batch Loss: 0.0017240893794223666\n",
      "Epoch 4539, Loss: 0.036827731877565384, Final Batch Loss: 0.022133905440568924\n",
      "Epoch 4540, Loss: 0.029076722799800336, Final Batch Loss: 0.0014305313816294074\n",
      "Epoch 4541, Loss: 0.036582534201443195, Final Batch Loss: 0.02527322620153427\n",
      "Epoch 4542, Loss: 0.043706003576517105, Final Batch Loss: 0.028425704687833786\n",
      "Epoch 4543, Loss: 0.036799753084778786, Final Batch Loss: 0.027807649224996567\n",
      "Epoch 4544, Loss: 0.037788545712828636, Final Batch Loss: 0.022138049826025963\n",
      "Epoch 4545, Loss: 0.048354821279644966, Final Batch Loss: 0.015990080311894417\n",
      "Epoch 4546, Loss: 0.04135886998847127, Final Batch Loss: 0.005781181622296572\n",
      "Epoch 4547, Loss: 0.060385019518435, Final Batch Loss: 0.0539386160671711\n",
      "Epoch 4548, Loss: 0.09906789055094123, Final Batch Loss: 0.005846822168678045\n",
      "Epoch 4549, Loss: 0.012619514018297195, Final Batch Loss: 0.005151981487870216\n",
      "Epoch 4550, Loss: 0.027980458922684193, Final Batch Loss: 0.010205154307186604\n",
      "Epoch 4551, Loss: 0.008931624237447977, Final Batch Loss: 0.003366239834576845\n",
      "Epoch 4552, Loss: 0.04175040731206536, Final Batch Loss: 0.007013967726379633\n",
      "Epoch 4553, Loss: 0.07241233251988888, Final Batch Loss: 0.009570544585585594\n",
      "Epoch 4554, Loss: 0.03099193947855383, Final Batch Loss: 0.001868325867690146\n",
      "Epoch 4555, Loss: 0.015393396373838186, Final Batch Loss: 0.005193614866584539\n",
      "Epoch 4556, Loss: 0.01364150969311595, Final Batch Loss: 0.006118146702647209\n",
      "Epoch 4557, Loss: 0.10896746069192886, Final Batch Loss: 0.0850449800491333\n",
      "Epoch 4558, Loss: 0.007463939022272825, Final Batch Loss: 0.0022858106531202793\n",
      "Epoch 4559, Loss: 0.03068459313362837, Final Batch Loss: 0.017055803909897804\n",
      "Epoch 4560, Loss: 0.02647254429757595, Final Batch Loss: 0.009843090549111366\n",
      "Epoch 4561, Loss: 0.010597743093967438, Final Batch Loss: 0.004676824901252985\n",
      "Epoch 4562, Loss: 0.03193637542426586, Final Batch Loss: 0.020130235701799393\n",
      "Epoch 4563, Loss: 0.019732437562197447, Final Batch Loss: 0.01662112958729267\n",
      "Epoch 4564, Loss: 0.04845119081437588, Final Batch Loss: 0.020978987216949463\n",
      "Epoch 4565, Loss: 0.021426119841635227, Final Batch Loss: 0.010907544754445553\n",
      "Epoch 4566, Loss: 0.03971501160413027, Final Batch Loss: 0.03456265479326248\n",
      "Epoch 4567, Loss: 0.02167703490704298, Final Batch Loss: 0.003613322041928768\n",
      "Epoch 4568, Loss: 0.006459122058004141, Final Batch Loss: 0.0031939949840307236\n",
      "Epoch 4569, Loss: 0.028112060390412807, Final Batch Loss: 0.020147383213043213\n",
      "Epoch 4570, Loss: 0.01976432907395065, Final Batch Loss: 0.0027065358590334654\n",
      "Epoch 4571, Loss: 0.012446176959201694, Final Batch Loss: 0.0036773632746189833\n",
      "Epoch 4572, Loss: 0.012562063056975603, Final Batch Loss: 0.007092712447047234\n",
      "Epoch 4573, Loss: 0.009506648173555732, Final Batch Loss: 0.006289245560765266\n",
      "Epoch 4574, Loss: 0.034775879234075546, Final Batch Loss: 0.02219569869339466\n",
      "Epoch 4575, Loss: 0.016746139619499445, Final Batch Loss: 0.009675264358520508\n",
      "Epoch 4576, Loss: 0.024056975729763508, Final Batch Loss: 0.010196266695857048\n",
      "Epoch 4577, Loss: 0.03581765480339527, Final Batch Loss: 0.031681522727012634\n",
      "Epoch 4578, Loss: 0.009020806523039937, Final Batch Loss: 0.0025549784768372774\n",
      "Epoch 4579, Loss: 0.07805689610540867, Final Batch Loss: 0.06609822064638138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4580, Loss: 0.021337989252060652, Final Batch Loss: 0.002394552808254957\n",
      "Epoch 4581, Loss: 0.03467795019969344, Final Batch Loss: 0.004335572477430105\n",
      "Epoch 4582, Loss: 0.031234925147145987, Final Batch Loss: 0.0049036904238164425\n",
      "Epoch 4583, Loss: 0.0454500550404191, Final Batch Loss: 0.0393693782389164\n",
      "Epoch 4584, Loss: 0.06421983800828457, Final Batch Loss: 0.05720819532871246\n",
      "Epoch 4585, Loss: 0.035258576506748796, Final Batch Loss: 0.0020017775241285563\n",
      "Epoch 4586, Loss: 0.011124405544251204, Final Batch Loss: 0.005336157511919737\n",
      "Epoch 4587, Loss: 0.01463820319622755, Final Batch Loss: 0.004653365351259708\n",
      "Epoch 4588, Loss: 0.0356032052077353, Final Batch Loss: 0.028658177703619003\n",
      "Epoch 4589, Loss: 0.015005994588136673, Final Batch Loss: 0.012056841515004635\n",
      "Epoch 4590, Loss: 0.011724160984158516, Final Batch Loss: 0.0026096096262335777\n",
      "Epoch 4591, Loss: 0.011243519373238087, Final Batch Loss: 0.007619387935847044\n",
      "Epoch 4592, Loss: 0.06078202649950981, Final Batch Loss: 0.03278106078505516\n",
      "Epoch 4593, Loss: 0.03481763415038586, Final Batch Loss: 0.010925039649009705\n",
      "Epoch 4594, Loss: 0.049688377417624, Final Batch Loss: 0.03874851018190384\n",
      "Epoch 4595, Loss: 0.061045728623867035, Final Batch Loss: 0.04919492453336716\n",
      "Epoch 4596, Loss: 0.037649596109986305, Final Batch Loss: 0.014145968481898308\n",
      "Epoch 4597, Loss: 0.013645634986460209, Final Batch Loss: 0.006645653862506151\n",
      "Epoch 4598, Loss: 0.010462668258696795, Final Batch Loss: 0.0006496631540358067\n",
      "Epoch 4599, Loss: 0.10262544453144073, Final Batch Loss: 0.025411807000637054\n",
      "Epoch 4600, Loss: 0.00954431714490056, Final Batch Loss: 0.0026519293896853924\n",
      "Epoch 4601, Loss: 0.020646448829211295, Final Batch Loss: 0.018951017409563065\n",
      "Epoch 4602, Loss: 0.01610839320346713, Final Batch Loss: 0.0062230234034359455\n",
      "Epoch 4603, Loss: 0.008885435527190566, Final Batch Loss: 0.005483841057866812\n",
      "Epoch 4604, Loss: 0.03774638706818223, Final Batch Loss: 0.005450705531984568\n",
      "Epoch 4605, Loss: 0.051465900149196386, Final Batch Loss: 0.045724090188741684\n",
      "Epoch 4606, Loss: 0.03863957151770592, Final Batch Loss: 0.02030307427048683\n",
      "Epoch 4607, Loss: 0.029254889581352472, Final Batch Loss: 0.004860606510192156\n",
      "Epoch 4608, Loss: 0.008028478361666203, Final Batch Loss: 0.0019788886420428753\n",
      "Epoch 4609, Loss: 0.007934787310659885, Final Batch Loss: 0.00394873833283782\n",
      "Epoch 4610, Loss: 0.009286380838602781, Final Batch Loss: 0.005100840702652931\n",
      "Epoch 4611, Loss: 0.03476663865149021, Final Batch Loss: 0.008157828822731972\n",
      "Epoch 4612, Loss: 0.016395158134400845, Final Batch Loss: 0.005306541919708252\n",
      "Epoch 4613, Loss: 0.008677046978846192, Final Batch Loss: 0.003123957896605134\n",
      "Epoch 4614, Loss: 0.01967498124577105, Final Batch Loss: 0.002848306903615594\n",
      "Epoch 4615, Loss: 0.009000850142911077, Final Batch Loss: 0.003191366558894515\n",
      "Epoch 4616, Loss: 0.016300244897138327, Final Batch Loss: 0.0008687672088854015\n",
      "Epoch 4617, Loss: 0.036184271331876516, Final Batch Loss: 0.03158421069383621\n",
      "Epoch 4618, Loss: 0.02165617886930704, Final Batch Loss: 0.011711522936820984\n",
      "Epoch 4619, Loss: 0.019592097494751215, Final Batch Loss: 0.016716815531253815\n",
      "Epoch 4620, Loss: 0.016783104743808508, Final Batch Loss: 0.0033923652954399586\n",
      "Epoch 4621, Loss: 0.012110010255128145, Final Batch Loss: 0.002949128393083811\n",
      "Epoch 4622, Loss: 0.029240097850561142, Final Batch Loss: 0.019216109067201614\n",
      "Epoch 4623, Loss: 0.026870353147387505, Final Batch Loss: 0.00950796902179718\n",
      "Epoch 4624, Loss: 0.017130885971710086, Final Batch Loss: 0.0034775135572999716\n",
      "Epoch 4625, Loss: 0.036561368964612484, Final Batch Loss: 0.014648632146418095\n",
      "Epoch 4626, Loss: 0.017174821346998215, Final Batch Loss: 0.009162696078419685\n",
      "Epoch 4627, Loss: 0.03431417513638735, Final Batch Loss: 0.009628125466406345\n",
      "Epoch 4628, Loss: 0.09113526390865445, Final Batch Loss: 0.08411797136068344\n",
      "Epoch 4629, Loss: 0.014272575033828616, Final Batch Loss: 0.011227625422179699\n",
      "Epoch 4630, Loss: 0.013054372859187424, Final Batch Loss: 0.0006945395143702626\n",
      "Epoch 4631, Loss: 0.017286220099776983, Final Batch Loss: 0.0018964116461575031\n",
      "Epoch 4632, Loss: 0.02754644677042961, Final Batch Loss: 0.013328716158866882\n",
      "Epoch 4633, Loss: 0.04894969239830971, Final Batch Loss: 0.031847428530454636\n",
      "Epoch 4634, Loss: 0.02771935425698757, Final Batch Loss: 0.007788838818669319\n",
      "Epoch 4635, Loss: 0.048413993790745735, Final Batch Loss: 0.028125828132033348\n",
      "Epoch 4636, Loss: 0.017281055683270097, Final Batch Loss: 0.0036578981671482325\n",
      "Epoch 4637, Loss: 0.03434708388522267, Final Batch Loss: 0.005830653477460146\n",
      "Epoch 4638, Loss: 0.013476588763296604, Final Batch Loss: 0.0034388303756713867\n",
      "Epoch 4639, Loss: 0.037710804492235184, Final Batch Loss: 0.026299884542822838\n",
      "Epoch 4640, Loss: 0.022474149242043495, Final Batch Loss: 0.017706790938973427\n",
      "Epoch 4641, Loss: 0.009899886790663004, Final Batch Loss: 0.004228703677654266\n",
      "Epoch 4642, Loss: 0.00536287110298872, Final Batch Loss: 0.0015179510228335857\n",
      "Epoch 4643, Loss: 0.020903365220874548, Final Batch Loss: 0.0046755908988416195\n",
      "Epoch 4644, Loss: 0.018448943039402366, Final Batch Loss: 0.002919162390753627\n",
      "Epoch 4645, Loss: 0.060133319813758135, Final Batch Loss: 0.0528017096221447\n",
      "Epoch 4646, Loss: 0.008549145655706525, Final Batch Loss: 0.002363314153626561\n",
      "Epoch 4647, Loss: 0.009616043884307146, Final Batch Loss: 0.005324053578078747\n",
      "Epoch 4648, Loss: 0.010425084736198187, Final Batch Loss: 0.004243064671754837\n",
      "Epoch 4649, Loss: 0.020374362356960773, Final Batch Loss: 0.0033118342980742455\n",
      "Epoch 4650, Loss: 0.03740506432950497, Final Batch Loss: 0.018344394862651825\n",
      "Epoch 4651, Loss: 0.03219476109370589, Final Batch Loss: 0.0029536387883126736\n",
      "Epoch 4652, Loss: 0.032822600565850735, Final Batch Loss: 0.015042268671095371\n",
      "Epoch 4653, Loss: 0.012073088437318802, Final Batch Loss: 0.005017385818064213\n",
      "Epoch 4654, Loss: 0.04658790025860071, Final Batch Loss: 0.03987699747085571\n",
      "Epoch 4655, Loss: 0.014382340479642153, Final Batch Loss: 0.005428052041679621\n",
      "Epoch 4656, Loss: 0.011425791075453162, Final Batch Loss: 0.0029125146102160215\n",
      "Epoch 4657, Loss: 0.01358155207708478, Final Batch Loss: 0.0036860411055386066\n",
      "Epoch 4658, Loss: 0.008802753873169422, Final Batch Loss: 0.005281372927129269\n",
      "Epoch 4659, Loss: 0.03212977573275566, Final Batch Loss: 0.018351109698414803\n",
      "Epoch 4660, Loss: 0.017491961363703012, Final Batch Loss: 0.010426064021885395\n",
      "Epoch 4661, Loss: 0.021879046224057674, Final Batch Loss: 0.0014058025553822517\n",
      "Epoch 4662, Loss: 0.013893470633774996, Final Batch Loss: 0.003167607355862856\n",
      "Epoch 4663, Loss: 0.0183235052973032, Final Batch Loss: 0.016129489988088608\n",
      "Epoch 4664, Loss: 0.01775294286198914, Final Batch Loss: 0.0024293793831020594\n",
      "Epoch 4665, Loss: 0.009599768905900419, Final Batch Loss: 0.0010974587639793754\n",
      "Epoch 4666, Loss: 0.028776676394045353, Final Batch Loss: 0.003957911394536495\n",
      "Epoch 4667, Loss: 0.020714452723041177, Final Batch Loss: 0.0019862691406160593\n",
      "Epoch 4668, Loss: 0.011986009543761611, Final Batch Loss: 0.0019595862831920385\n",
      "Epoch 4669, Loss: 0.00782893062569201, Final Batch Loss: 0.005122246686369181\n",
      "Epoch 4670, Loss: 0.012592919170856476, Final Batch Loss: 0.001390557736158371\n",
      "Epoch 4671, Loss: 0.039236622862517834, Final Batch Loss: 0.031078126281499863\n",
      "Epoch 4672, Loss: 0.042995513416826725, Final Batch Loss: 0.035174936056137085\n",
      "Epoch 4673, Loss: 0.008611186873167753, Final Batch Loss: 0.0029526124708354473\n",
      "Epoch 4674, Loss: 0.04640439338982105, Final Batch Loss: 0.019637538120150566\n",
      "Epoch 4675, Loss: 0.012782055186107755, Final Batch Loss: 0.00925049651414156\n",
      "Epoch 4676, Loss: 0.009677949594333768, Final Batch Loss: 0.006327490787953138\n",
      "Epoch 4677, Loss: 0.029616738436743617, Final Batch Loss: 0.001941826893016696\n",
      "Epoch 4678, Loss: 0.008140963036566973, Final Batch Loss: 0.0010771770030260086\n",
      "Epoch 4679, Loss: 0.01706606289371848, Final Batch Loss: 0.005073266569525003\n",
      "Epoch 4680, Loss: 0.014786961022764444, Final Batch Loss: 0.005144441034644842\n",
      "Epoch 4681, Loss: 0.03547062166035175, Final Batch Loss: 0.021567238494753838\n",
      "Epoch 4682, Loss: 0.006231706589460373, Final Batch Loss: 0.003704612608999014\n",
      "Epoch 4683, Loss: 0.05431047733873129, Final Batch Loss: 0.05176124721765518\n",
      "Epoch 4684, Loss: 0.0049079753225669265, Final Batch Loss: 0.0036618553567677736\n",
      "Epoch 4685, Loss: 0.014309866819530725, Final Batch Loss: 0.009223378263413906\n",
      "Epoch 4686, Loss: 0.004322294145822525, Final Batch Loss: 0.002023976296186447\n",
      "Epoch 4687, Loss: 0.023894215235486627, Final Batch Loss: 0.0027829764876514673\n",
      "Epoch 4688, Loss: 0.01631261082366109, Final Batch Loss: 0.009862715378403664\n",
      "Epoch 4689, Loss: 0.01664289738982916, Final Batch Loss: 0.009639274328947067\n",
      "Epoch 4690, Loss: 0.03679345827549696, Final Batch Loss: 0.0040324656292796135\n",
      "Epoch 4691, Loss: 0.00363525771535933, Final Batch Loss: 0.0015461391303688288\n",
      "Epoch 4692, Loss: 0.007850349880754948, Final Batch Loss: 0.0018656258471310139\n",
      "Epoch 4693, Loss: 0.005019195727072656, Final Batch Loss: 0.0010286228498443961\n",
      "Epoch 4694, Loss: 0.010639471234753728, Final Batch Loss: 0.0020566044840961695\n",
      "Epoch 4695, Loss: 0.004440395976416767, Final Batch Loss: 0.0018235916504636407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4696, Loss: 0.04121409170329571, Final Batch Loss: 0.01642524264752865\n",
      "Epoch 4697, Loss: 0.007205870701000094, Final Batch Loss: 0.00326916784979403\n",
      "Epoch 4698, Loss: 0.03555078664794564, Final Batch Loss: 0.03351261094212532\n",
      "Epoch 4699, Loss: 0.005771578289568424, Final Batch Loss: 0.002125235740095377\n",
      "Epoch 4700, Loss: 0.014413512777537107, Final Batch Loss: 0.005226373206824064\n",
      "Epoch 4701, Loss: 0.01929409068543464, Final Batch Loss: 0.017790792509913445\n",
      "Epoch 4702, Loss: 0.01286145020276308, Final Batch Loss: 0.008146189153194427\n",
      "Epoch 4703, Loss: 0.1686791144311428, Final Batch Loss: 0.13276085257530212\n",
      "Epoch 4704, Loss: 0.004346345318481326, Final Batch Loss: 0.0023494393099099398\n",
      "Epoch 4705, Loss: 0.0035076833446510136, Final Batch Loss: 0.0008350068819709122\n",
      "Epoch 4706, Loss: 0.005381783354096115, Final Batch Loss: 0.0018714995821937919\n",
      "Epoch 4707, Loss: 0.016653274651616812, Final Batch Loss: 0.004411100875586271\n",
      "Epoch 4708, Loss: 0.0277512576431036, Final Batch Loss: 0.020327292382717133\n",
      "Epoch 4709, Loss: 0.009091153042390943, Final Batch Loss: 0.0072233728133141994\n",
      "Epoch 4710, Loss: 0.039599010488018394, Final Batch Loss: 0.03608306497335434\n",
      "Epoch 4711, Loss: 0.02824171702377498, Final Batch Loss: 0.0022273908834904432\n",
      "Epoch 4712, Loss: 0.03434615954756737, Final Batch Loss: 0.002697296440601349\n",
      "Epoch 4713, Loss: 0.009678757516667247, Final Batch Loss: 0.0016941723879426718\n",
      "Epoch 4714, Loss: 0.006481972872279584, Final Batch Loss: 0.0012446296168491244\n",
      "Epoch 4715, Loss: 0.006092572817578912, Final Batch Loss: 0.0039994302205741405\n",
      "Epoch 4716, Loss: 0.04354520421475172, Final Batch Loss: 0.0064323944970965385\n",
      "Epoch 4717, Loss: 0.03343694191426039, Final Batch Loss: 0.007375658489763737\n",
      "Epoch 4718, Loss: 0.01611294038593769, Final Batch Loss: 0.010232747532427311\n",
      "Epoch 4719, Loss: 0.04518229886889458, Final Batch Loss: 0.017192112281918526\n",
      "Epoch 4720, Loss: 0.050530880922451615, Final Batch Loss: 0.0032214077655225992\n",
      "Epoch 4721, Loss: 0.07559916377067566, Final Batch Loss: 0.0665668249130249\n",
      "Epoch 4722, Loss: 0.015684492653235793, Final Batch Loss: 0.002136698691174388\n",
      "Epoch 4723, Loss: 0.01457776315510273, Final Batch Loss: 0.012338156811892986\n",
      "Epoch 4724, Loss: 0.01690696703735739, Final Batch Loss: 0.001482343883253634\n",
      "Epoch 4725, Loss: 0.012501880992203951, Final Batch Loss: 0.01041293703019619\n",
      "Epoch 4726, Loss: 0.01379892323166132, Final Batch Loss: 0.0039604827761650085\n",
      "Epoch 4727, Loss: 0.04443180188536644, Final Batch Loss: 0.03086048737168312\n",
      "Epoch 4728, Loss: 0.007699820678681135, Final Batch Loss: 0.004650695249438286\n",
      "Epoch 4729, Loss: 0.014360721688717604, Final Batch Loss: 0.006205834913998842\n",
      "Epoch 4730, Loss: 0.016184624982997775, Final Batch Loss: 0.012380986474454403\n",
      "Epoch 4731, Loss: 0.007756943581625819, Final Batch Loss: 0.0020245660562068224\n",
      "Epoch 4732, Loss: 0.03615417727269232, Final Batch Loss: 0.0024017097894102335\n",
      "Epoch 4733, Loss: 0.03099548607133329, Final Batch Loss: 0.0012518053408712149\n",
      "Epoch 4734, Loss: 0.01094866101630032, Final Batch Loss: 0.007729103788733482\n",
      "Epoch 4735, Loss: 0.07741821371018887, Final Batch Loss: 0.024979742243885994\n",
      "Epoch 4736, Loss: 0.03939956519752741, Final Batch Loss: 0.0038873227313160896\n",
      "Epoch 4737, Loss: 0.06940681207925081, Final Batch Loss: 0.0616116002202034\n",
      "Epoch 4738, Loss: 0.015057547483593225, Final Batch Loss: 0.0019061374478042126\n",
      "Epoch 4739, Loss: 0.04358699731528759, Final Batch Loss: 0.01531372033059597\n",
      "Epoch 4740, Loss: 0.020734240068122745, Final Batch Loss: 0.0031155336182564497\n",
      "Epoch 4741, Loss: 0.09874342079274356, Final Batch Loss: 0.096345916390419\n",
      "Epoch 4742, Loss: 0.03442686330527067, Final Batch Loss: 0.012110390700399876\n",
      "Epoch 4743, Loss: 0.054883874487131834, Final Batch Loss: 0.004200443159788847\n",
      "Epoch 4744, Loss: 0.06883344426751137, Final Batch Loss: 0.016231238842010498\n",
      "Epoch 4745, Loss: 0.15511395037174225, Final Batch Loss: 0.13482138514518738\n",
      "Epoch 4746, Loss: 0.08014609338715672, Final Batch Loss: 0.07417842000722885\n",
      "Epoch 4747, Loss: 0.05472488864324987, Final Batch Loss: 0.0027576254215091467\n",
      "Epoch 4748, Loss: 0.15658066049218178, Final Batch Loss: 0.10422470420598984\n",
      "Epoch 4749, Loss: 0.18463724106550217, Final Batch Loss: 0.11508861929178238\n",
      "Epoch 4750, Loss: 0.1312971767038107, Final Batch Loss: 0.10339006036520004\n",
      "Epoch 4751, Loss: 0.4025343060493469, Final Batch Loss: 0.14352715015411377\n",
      "Epoch 4752, Loss: 0.32693052291870117, Final Batch Loss: 0.17923913896083832\n",
      "Epoch 4753, Loss: 0.249497190117836, Final Batch Loss: 0.08205023407936096\n",
      "Epoch 4754, Loss: 0.23717938363552094, Final Batch Loss: 0.1745050847530365\n",
      "Epoch 4755, Loss: 0.1094885915517807, Final Batch Loss: 0.04854204133152962\n",
      "Epoch 4756, Loss: 0.10834828019142151, Final Batch Loss: 0.07002387195825577\n",
      "Epoch 4757, Loss: 0.11981667578220367, Final Batch Loss: 0.062326349318027496\n",
      "Epoch 4758, Loss: 0.20095711946487427, Final Batch Loss: 0.08259830623865128\n",
      "Epoch 4759, Loss: 0.13295506685972214, Final Batch Loss: 0.05454494059085846\n",
      "Epoch 4760, Loss: 0.12139556929469109, Final Batch Loss: 0.051817093044519424\n",
      "Epoch 4761, Loss: 0.1289244145154953, Final Batch Loss: 0.05774397403001785\n",
      "Epoch 4762, Loss: 0.17651042714715004, Final Batch Loss: 0.02982831373810768\n",
      "Epoch 4763, Loss: 0.1277978979051113, Final Batch Loss: 0.037039753049612045\n",
      "Epoch 4764, Loss: 0.06762252934277058, Final Batch Loss: 0.029864652082324028\n",
      "Epoch 4765, Loss: 0.09355910494923592, Final Batch Loss: 0.032595060765743256\n",
      "Epoch 4766, Loss: 0.08230219408869743, Final Batch Loss: 0.034062664955854416\n",
      "Epoch 4767, Loss: 0.1377171166241169, Final Batch Loss: 0.11178223043680191\n",
      "Epoch 4768, Loss: 0.09740397334098816, Final Batch Loss: 0.0618511363863945\n",
      "Epoch 4769, Loss: 0.07755965739488602, Final Batch Loss: 0.04060853272676468\n",
      "Epoch 4770, Loss: 0.07762028835713863, Final Batch Loss: 0.02530302293598652\n",
      "Epoch 4771, Loss: 0.06385947577655315, Final Batch Loss: 0.037555448710918427\n",
      "Epoch 4772, Loss: 0.05974169634282589, Final Batch Loss: 0.025547729805111885\n",
      "Epoch 4773, Loss: 0.1043936237692833, Final Batch Loss: 0.07907703518867493\n",
      "Epoch 4774, Loss: 0.06463014520704746, Final Batch Loss: 0.04849660396575928\n",
      "Epoch 4775, Loss: 0.07063271291553974, Final Batch Loss: 0.018175730481743813\n",
      "Epoch 4776, Loss: 0.0645072627812624, Final Batch Loss: 0.030886458232998848\n",
      "Epoch 4777, Loss: 0.058961864560842514, Final Batch Loss: 0.031272463500499725\n",
      "Epoch 4778, Loss: 0.09425620175898075, Final Batch Loss: 0.06434115767478943\n",
      "Epoch 4779, Loss: 0.06126382760703564, Final Batch Loss: 0.0356307178735733\n",
      "Epoch 4780, Loss: 0.12827178463339806, Final Batch Loss: 0.07623698562383652\n",
      "Epoch 4781, Loss: 0.06023338623344898, Final Batch Loss: 0.0207477156072855\n",
      "Epoch 4782, Loss: 0.08136080764234066, Final Batch Loss: 0.06203284487128258\n",
      "Epoch 4783, Loss: 0.06104263290762901, Final Batch Loss: 0.034338172525167465\n",
      "Epoch 4784, Loss: 0.07121423445641994, Final Batch Loss: 0.015746036544442177\n",
      "Epoch 4785, Loss: 0.03599280212074518, Final Batch Loss: 0.010144281201064587\n",
      "Epoch 4786, Loss: 0.04002266004681587, Final Batch Loss: 0.015084575861692429\n",
      "Epoch 4787, Loss: 0.04639756120741367, Final Batch Loss: 0.02748483046889305\n",
      "Epoch 4788, Loss: 0.08575775660574436, Final Batch Loss: 0.0551549457013607\n",
      "Epoch 4789, Loss: 0.041799054481089115, Final Batch Loss: 0.012623411603271961\n",
      "Epoch 4790, Loss: 0.13045409694314003, Final Batch Loss: 0.09837371855974197\n",
      "Epoch 4791, Loss: 0.03996631596237421, Final Batch Loss: 0.007845287211239338\n",
      "Epoch 4792, Loss: 0.052165256813168526, Final Batch Loss: 0.021133890375494957\n",
      "Epoch 4793, Loss: 0.1378900296986103, Final Batch Loss: 0.10045463591814041\n",
      "Epoch 4794, Loss: 0.056180477142333984, Final Batch Loss: 0.025550955906510353\n",
      "Epoch 4795, Loss: 0.03230169974267483, Final Batch Loss: 0.004444759339094162\n",
      "Epoch 4796, Loss: 0.03885755501687527, Final Batch Loss: 0.026914330199360847\n",
      "Epoch 4797, Loss: 0.04752839636057615, Final Batch Loss: 0.032484136521816254\n",
      "Epoch 4798, Loss: 0.021511151921004057, Final Batch Loss: 0.005737090017646551\n",
      "Epoch 4799, Loss: 0.029542414005845785, Final Batch Loss: 0.005525690969079733\n",
      "Epoch 4800, Loss: 0.034273456782102585, Final Batch Loss: 0.008780783042311668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4801, Loss: 0.03285809699445963, Final Batch Loss: 0.012259642593562603\n",
      "Epoch 4802, Loss: 0.026746324263513088, Final Batch Loss: 0.009655431844294071\n",
      "Epoch 4803, Loss: 0.02275104634463787, Final Batch Loss: 0.011553510092198849\n",
      "Epoch 4804, Loss: 0.02165837027132511, Final Batch Loss: 0.005447475239634514\n",
      "Epoch 4805, Loss: 0.07520513236522675, Final Batch Loss: 0.008076861500740051\n",
      "Epoch 4806, Loss: 0.05765140801668167, Final Batch Loss: 0.03992074728012085\n",
      "Epoch 4807, Loss: 0.04854793194681406, Final Batch Loss: 0.03515706583857536\n",
      "Epoch 4808, Loss: 0.026325120590627193, Final Batch Loss: 0.01212012767791748\n",
      "Epoch 4809, Loss: 0.04567462485283613, Final Batch Loss: 0.03640466928482056\n",
      "Epoch 4810, Loss: 0.029747571796178818, Final Batch Loss: 0.010508708655834198\n",
      "Epoch 4811, Loss: 0.04854295775294304, Final Batch Loss: 0.010870859026908875\n",
      "Epoch 4812, Loss: 0.01838819310069084, Final Batch Loss: 0.009718786925077438\n",
      "Epoch 4813, Loss: 0.027500759344547987, Final Batch Loss: 0.003558057826012373\n",
      "Epoch 4814, Loss: 0.02044592145830393, Final Batch Loss: 0.009181580506265163\n",
      "Epoch 4815, Loss: 0.03089962899684906, Final Batch Loss: 0.016571389511227608\n",
      "Epoch 4816, Loss: 0.02960801776498556, Final Batch Loss: 0.006610850803554058\n",
      "Epoch 4817, Loss: 0.05073452228680253, Final Batch Loss: 0.043340589851140976\n",
      "Epoch 4818, Loss: 0.03865177230909467, Final Batch Loss: 0.003342099953442812\n",
      "Epoch 4819, Loss: 0.025724012404680252, Final Batch Loss: 0.016874030232429504\n",
      "Epoch 4820, Loss: 0.05828651785850525, Final Batch Loss: 0.005828917026519775\n",
      "Epoch 4821, Loss: 0.026605505496263504, Final Batch Loss: 0.010575845837593079\n",
      "Epoch 4822, Loss: 0.01973265316337347, Final Batch Loss: 0.0075920941308140755\n",
      "Epoch 4823, Loss: 0.04463834501802921, Final Batch Loss: 0.026346782222390175\n",
      "Epoch 4824, Loss: 0.020249318797141314, Final Batch Loss: 0.007107990328222513\n",
      "Epoch 4825, Loss: 0.05892557092010975, Final Batch Loss: 0.026806427165865898\n",
      "Epoch 4826, Loss: 0.022054956760257483, Final Batch Loss: 0.007588514592498541\n",
      "Epoch 4827, Loss: 0.020295136608183384, Final Batch Loss: 0.009815036319196224\n",
      "Epoch 4828, Loss: 0.05609338637441397, Final Batch Loss: 0.008618156425654888\n",
      "Epoch 4829, Loss: 0.01852442044764757, Final Batch Loss: 0.009115011431276798\n",
      "Epoch 4830, Loss: 0.03564164275303483, Final Batch Loss: 0.003696723375469446\n",
      "Epoch 4831, Loss: 0.05964743159711361, Final Batch Loss: 0.024875374510884285\n",
      "Epoch 4832, Loss: 0.09835443925112486, Final Batch Loss: 0.010268817655742168\n",
      "Epoch 4833, Loss: 0.047469548881053925, Final Batch Loss: 0.026497524231672287\n",
      "Epoch 4834, Loss: 0.012556227156892419, Final Batch Loss: 0.002528828801587224\n",
      "Epoch 4835, Loss: 0.027019997127354145, Final Batch Loss: 0.012170953676104546\n",
      "Epoch 4836, Loss: 0.0151492515578866, Final Batch Loss: 0.003665774129331112\n",
      "Epoch 4837, Loss: 0.015532738994807005, Final Batch Loss: 0.006594886537641287\n",
      "Epoch 4838, Loss: 0.02065529301762581, Final Batch Loss: 0.0019603297114372253\n",
      "Epoch 4839, Loss: 0.04791276529431343, Final Batch Loss: 0.002808336168527603\n",
      "Epoch 4840, Loss: 0.021020086482167244, Final Batch Loss: 0.010681995190680027\n",
      "Epoch 4841, Loss: 0.04424245283007622, Final Batch Loss: 0.015951046720147133\n",
      "Epoch 4842, Loss: 0.020526209846138954, Final Batch Loss: 0.012245246209204197\n",
      "Epoch 4843, Loss: 0.018129741307348013, Final Batch Loss: 0.006654713768512011\n",
      "Epoch 4844, Loss: 0.040549661964178085, Final Batch Loss: 0.023161375895142555\n",
      "Epoch 4845, Loss: 0.01639902964234352, Final Batch Loss: 0.007360076531767845\n",
      "Epoch 4846, Loss: 0.010207898914813995, Final Batch Loss: 0.004040546715259552\n",
      "Epoch 4847, Loss: 0.010601583868265152, Final Batch Loss: 0.002549528144299984\n",
      "Epoch 4848, Loss: 0.04240117873996496, Final Batch Loss: 0.03809608891606331\n",
      "Epoch 4849, Loss: 0.026508856564760208, Final Batch Loss: 0.014189805835485458\n",
      "Epoch 4850, Loss: 0.020255330950021744, Final Batch Loss: 0.009009010158479214\n",
      "Epoch 4851, Loss: 0.02436556085012853, Final Batch Loss: 0.020583484321832657\n",
      "Epoch 4852, Loss: 0.030881958547979593, Final Batch Loss: 0.024913404136896133\n",
      "Epoch 4853, Loss: 0.07031881250441074, Final Batch Loss: 0.0241845715790987\n",
      "Epoch 4854, Loss: 0.028055832721292973, Final Batch Loss: 0.018446341156959534\n",
      "Epoch 4855, Loss: 0.03177311643958092, Final Batch Loss: 0.0173280481249094\n",
      "Epoch 4856, Loss: 0.10713717713952065, Final Batch Loss: 0.08484984189271927\n",
      "Epoch 4857, Loss: 0.01393334474414587, Final Batch Loss: 0.004099585115909576\n",
      "Epoch 4858, Loss: 0.016409890726208687, Final Batch Loss: 0.0065363626927137375\n",
      "Epoch 4859, Loss: 0.020264101214706898, Final Batch Loss: 0.006614401936531067\n",
      "Epoch 4860, Loss: 0.0414542481303215, Final Batch Loss: 0.013157442212104797\n",
      "Epoch 4861, Loss: 0.022441650275141, Final Batch Loss: 0.004095992539077997\n",
      "Epoch 4862, Loss: 0.015353139955550432, Final Batch Loss: 0.007224422413855791\n",
      "Epoch 4863, Loss: 0.036902706138789654, Final Batch Loss: 0.013259301893413067\n",
      "Epoch 4864, Loss: 0.04190933518111706, Final Batch Loss: 0.03175230696797371\n",
      "Epoch 4865, Loss: 0.015719831455498934, Final Batch Loss: 0.010401367209851742\n",
      "Epoch 4866, Loss: 0.030000918544828892, Final Batch Loss: 0.023945815861225128\n",
      "Epoch 4867, Loss: 0.03100019134581089, Final Batch Loss: 0.007631853222846985\n",
      "Epoch 4868, Loss: 0.028369204606860876, Final Batch Loss: 0.0206594280898571\n",
      "Epoch 4869, Loss: 0.02324620122089982, Final Batch Loss: 0.005552372429519892\n",
      "Epoch 4870, Loss: 0.017476752400398254, Final Batch Loss: 0.005063910968601704\n",
      "Epoch 4871, Loss: 0.029057549312710762, Final Batch Loss: 0.020373476669192314\n",
      "Epoch 4872, Loss: 0.04794077109545469, Final Batch Loss: 0.03870050236582756\n",
      "Epoch 4873, Loss: 0.019577770493924618, Final Batch Loss: 0.005396201275289059\n",
      "Epoch 4874, Loss: 0.013387053972110152, Final Batch Loss: 0.0015421591233462095\n",
      "Epoch 4875, Loss: 0.011456210282631218, Final Batch Loss: 0.0014439766528084874\n",
      "Epoch 4876, Loss: 0.03503148490563035, Final Batch Loss: 0.030999554321169853\n",
      "Epoch 4877, Loss: 0.09766340162605047, Final Batch Loss: 0.09121204912662506\n",
      "Epoch 4878, Loss: 0.03953456785529852, Final Batch Loss: 0.02570667490363121\n",
      "Epoch 4879, Loss: 0.02287904918193817, Final Batch Loss: 0.012201229110360146\n",
      "Epoch 4880, Loss: 0.022290369728580117, Final Batch Loss: 0.019403649494051933\n",
      "Epoch 4881, Loss: 0.02266550133936107, Final Batch Loss: 0.0024028390180319548\n",
      "Epoch 4882, Loss: 0.062227506190538406, Final Batch Loss: 0.020450085401535034\n",
      "Epoch 4883, Loss: 0.010899038054049015, Final Batch Loss: 0.004446213599294424\n",
      "Epoch 4884, Loss: 0.026421697810292244, Final Batch Loss: 0.01741156354546547\n",
      "Epoch 4885, Loss: 0.011977655347436666, Final Batch Loss: 0.0029495456255972385\n",
      "Epoch 4886, Loss: 0.051980290561914444, Final Batch Loss: 0.034695517271757126\n",
      "Epoch 4887, Loss: 0.011529539246112108, Final Batch Loss: 0.005087637342512608\n",
      "Epoch 4888, Loss: 0.06083505041897297, Final Batch Loss: 0.04720093309879303\n",
      "Epoch 4889, Loss: 0.028743845410645008, Final Batch Loss: 0.011419315822422504\n",
      "Epoch 4890, Loss: 0.046965207904577255, Final Batch Loss: 0.029337724670767784\n",
      "Epoch 4891, Loss: 0.026887787273153663, Final Batch Loss: 0.0030938496347516775\n",
      "Epoch 4892, Loss: 0.02353143086656928, Final Batch Loss: 0.019299933686852455\n",
      "Epoch 4893, Loss: 0.016143081709742546, Final Batch Loss: 0.00666528195142746\n",
      "Epoch 4894, Loss: 0.013375834561884403, Final Batch Loss: 0.0017972160130739212\n",
      "Epoch 4895, Loss: 0.021613786928355694, Final Batch Loss: 0.0027435878291726112\n",
      "Epoch 4896, Loss: 0.017258557491004467, Final Batch Loss: 0.006558151915669441\n",
      "Epoch 4897, Loss: 0.0961306830868125, Final Batch Loss: 0.08408460021018982\n",
      "Epoch 4898, Loss: 0.025365173816680908, Final Batch Loss: 0.011781602166593075\n",
      "Epoch 4899, Loss: 0.08526487741619349, Final Batch Loss: 0.0737723633646965\n",
      "Epoch 4900, Loss: 0.020245459396392107, Final Batch Loss: 0.012493896298110485\n",
      "Epoch 4901, Loss: 0.04433051124215126, Final Batch Loss: 0.03994942456483841\n",
      "Epoch 4902, Loss: 0.06218199245631695, Final Batch Loss: 0.04624456539750099\n",
      "Epoch 4903, Loss: 0.02287025493569672, Final Batch Loss: 0.0030723114032298326\n",
      "Epoch 4904, Loss: 0.06673655332997441, Final Batch Loss: 0.003931683022528887\n",
      "Epoch 4905, Loss: 0.08726124837994576, Final Batch Loss: 0.05000072717666626\n",
      "Epoch 4906, Loss: 0.021257217042148113, Final Batch Loss: 0.004237116314470768\n",
      "Epoch 4907, Loss: 0.046757275238633156, Final Batch Loss: 0.01902826316654682\n",
      "Epoch 4908, Loss: 0.007152231875807047, Final Batch Loss: 0.003344917669892311\n",
      "Epoch 4909, Loss: 0.016269847517833114, Final Batch Loss: 0.002222602954134345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4910, Loss: 0.0198309610132128, Final Batch Loss: 0.0027904140297323465\n",
      "Epoch 4911, Loss: 0.013609740766696632, Final Batch Loss: 0.001139553147368133\n",
      "Epoch 4912, Loss: 0.02482595667243004, Final Batch Loss: 0.007349472492933273\n",
      "Epoch 4913, Loss: 0.08970328979194164, Final Batch Loss: 0.07378701120615005\n",
      "Epoch 4914, Loss: 0.14538953080773354, Final Batch Loss: 0.08846072107553482\n",
      "Epoch 4915, Loss: 0.008954373188316822, Final Batch Loss: 0.0024651847779750824\n",
      "Epoch 4916, Loss: 0.021286738105118275, Final Batch Loss: 0.010812920518219471\n",
      "Epoch 4917, Loss: 0.010158807970583439, Final Batch Loss: 0.005397922825068235\n",
      "Epoch 4918, Loss: 0.011553057003766298, Final Batch Loss: 0.0056616924703121185\n",
      "Epoch 4919, Loss: 0.00980545743368566, Final Batch Loss: 0.0023339081089943647\n",
      "Epoch 4920, Loss: 0.07128095394000411, Final Batch Loss: 0.06656983494758606\n",
      "Epoch 4921, Loss: 0.017098412849009037, Final Batch Loss: 0.005478803999722004\n",
      "Epoch 4922, Loss: 0.0129766627214849, Final Batch Loss: 0.005931845400482416\n",
      "Epoch 4923, Loss: 0.014151908690109849, Final Batch Loss: 0.0020173939410597086\n",
      "Epoch 4924, Loss: 0.0538235642015934, Final Batch Loss: 0.01727808266878128\n",
      "Epoch 4925, Loss: 0.026808071415871382, Final Batch Loss: 0.007399415131658316\n",
      "Epoch 4926, Loss: 0.008427513996139169, Final Batch Loss: 0.0014808850828558207\n",
      "Epoch 4927, Loss: 0.028435993939638138, Final Batch Loss: 0.02259145863354206\n",
      "Epoch 4928, Loss: 0.015182815724983811, Final Batch Loss: 0.011442078277468681\n",
      "Epoch 4929, Loss: 0.06540768966078758, Final Batch Loss: 0.02992820367217064\n",
      "Epoch 4930, Loss: 0.03323018737137318, Final Batch Loss: 0.023495731875300407\n",
      "Epoch 4931, Loss: 0.03457864560186863, Final Batch Loss: 0.014627216383814812\n",
      "Epoch 4932, Loss: 0.011669946834445, Final Batch Loss: 0.0068635959178209305\n",
      "Epoch 4933, Loss: 0.00832158513367176, Final Batch Loss: 0.0020045950077474117\n",
      "Epoch 4934, Loss: 0.030983459670096636, Final Batch Loss: 0.02673695795238018\n",
      "Epoch 4935, Loss: 0.032387091778218746, Final Batch Loss: 0.02688734233379364\n",
      "Epoch 4936, Loss: 0.016635381616652012, Final Batch Loss: 0.011389780789613724\n",
      "Epoch 4937, Loss: 0.042559199035167694, Final Batch Loss: 0.009826749563217163\n",
      "Epoch 4938, Loss: 0.04586430033668876, Final Batch Loss: 0.004307487513870001\n",
      "Epoch 4939, Loss: 0.07867885194718838, Final Batch Loss: 0.07334521412849426\n",
      "Epoch 4940, Loss: 0.01770099252462387, Final Batch Loss: 0.006210534833371639\n",
      "Epoch 4941, Loss: 0.028599608223885298, Final Batch Loss: 0.0058790589682757854\n",
      "Epoch 4942, Loss: 0.024957452435046434, Final Batch Loss: 0.017811201512813568\n",
      "Epoch 4943, Loss: 0.008999589830636978, Final Batch Loss: 0.004365165252238512\n",
      "Epoch 4944, Loss: 0.011275524739176035, Final Batch Loss: 0.00541064515709877\n",
      "Epoch 4945, Loss: 0.012481499928981066, Final Batch Loss: 0.007533669471740723\n",
      "Epoch 4946, Loss: 0.030857373494654894, Final Batch Loss: 0.005989304278045893\n",
      "Epoch 4947, Loss: 0.019267842755652964, Final Batch Loss: 0.0014398606726899743\n",
      "Epoch 4948, Loss: 0.012189004570245743, Final Batch Loss: 0.004873733501881361\n",
      "Epoch 4949, Loss: 0.01985548227094114, Final Batch Loss: 0.0033388116862624884\n",
      "Epoch 4950, Loss: 0.008113577961921692, Final Batch Loss: 0.003993919584900141\n",
      "Epoch 4951, Loss: 0.013869165442883968, Final Batch Loss: 0.0023057078942656517\n",
      "Epoch 4952, Loss: 0.007793949800543487, Final Batch Loss: 0.0018924114992842078\n",
      "Epoch 4953, Loss: 0.030383663019165397, Final Batch Loss: 0.026863763108849525\n",
      "Epoch 4954, Loss: 0.008007604628801346, Final Batch Loss: 0.006351769436150789\n",
      "Epoch 4955, Loss: 0.04717299900949001, Final Batch Loss: 0.04270581528544426\n",
      "Epoch 4956, Loss: 0.020282422425225377, Final Batch Loss: 0.002517183544114232\n",
      "Epoch 4957, Loss: 0.08366325683891773, Final Batch Loss: 0.06918207556009293\n",
      "Epoch 4958, Loss: 0.011430766666308045, Final Batch Loss: 0.009221714921295643\n",
      "Epoch 4959, Loss: 0.005163156311027706, Final Batch Loss: 0.0016596930800005794\n",
      "Epoch 4960, Loss: 0.023020980414003134, Final Batch Loss: 0.015524689108133316\n",
      "Epoch 4961, Loss: 0.01186716789379716, Final Batch Loss: 0.004169379360973835\n",
      "Epoch 4962, Loss: 0.022699065739288926, Final Batch Loss: 0.019983556121587753\n",
      "Epoch 4963, Loss: 0.06372819654643536, Final Batch Loss: 0.03573484718799591\n",
      "Epoch 4964, Loss: 0.01904210075736046, Final Batch Loss: 0.014970016665756702\n",
      "Epoch 4965, Loss: 0.019478059839457273, Final Batch Loss: 0.013014625757932663\n",
      "Epoch 4966, Loss: 0.04967157356441021, Final Batch Loss: 0.018770704045891762\n",
      "Epoch 4967, Loss: 0.012944038026034832, Final Batch Loss: 0.007493709679692984\n",
      "Epoch 4968, Loss: 0.057867856696248055, Final Batch Loss: 0.029899446293711662\n",
      "Epoch 4969, Loss: 0.010846538003534079, Final Batch Loss: 0.006358557380735874\n",
      "Epoch 4970, Loss: 0.002505468321032822, Final Batch Loss: 0.0011749181430786848\n",
      "Epoch 4971, Loss: 0.016649863682687283, Final Batch Loss: 0.00542119424790144\n",
      "Epoch 4972, Loss: 0.022037638758774847, Final Batch Loss: 0.0006567988893948495\n",
      "Epoch 4973, Loss: 0.003022717544808984, Final Batch Loss: 0.0014470953028649092\n",
      "Epoch 4974, Loss: 0.01868875790387392, Final Batch Loss: 0.004111113026738167\n",
      "Epoch 4975, Loss: 0.04237690847367048, Final Batch Loss: 0.008056442253291607\n",
      "Epoch 4976, Loss: 0.01912677939981222, Final Batch Loss: 0.00827326625585556\n",
      "Epoch 4977, Loss: 0.011005708016455173, Final Batch Loss: 0.003492743708193302\n",
      "Epoch 4978, Loss: 0.007981446920894086, Final Batch Loss: 0.0016065997770056129\n",
      "Epoch 4979, Loss: 0.01805800199508667, Final Batch Loss: 0.009528697468340397\n",
      "Epoch 4980, Loss: 0.039019000716507435, Final Batch Loss: 0.010730895213782787\n",
      "Epoch 4981, Loss: 0.01614457741379738, Final Batch Loss: 0.002872285433113575\n",
      "Epoch 4982, Loss: 0.02313283772673458, Final Batch Loss: 0.021836115047335625\n",
      "Epoch 4983, Loss: 0.007581443293020129, Final Batch Loss: 0.004125376231968403\n",
      "Epoch 4984, Loss: 0.013099425937980413, Final Batch Loss: 0.003800526726990938\n",
      "Epoch 4985, Loss: 0.013995732180774212, Final Batch Loss: 0.009674718603491783\n",
      "Epoch 4986, Loss: 0.0323351020924747, Final Batch Loss: 0.00736815994605422\n",
      "Epoch 4987, Loss: 0.013647749088704586, Final Batch Loss: 0.004902408458292484\n",
      "Epoch 4988, Loss: 0.01999306632205844, Final Batch Loss: 0.007276063319295645\n",
      "Epoch 4989, Loss: 0.011140216141939163, Final Batch Loss: 0.008420983329415321\n",
      "Epoch 4990, Loss: 0.012168343062512577, Final Batch Loss: 0.0018236142350360751\n",
      "Epoch 4991, Loss: 0.004820636007934809, Final Batch Loss: 0.0022873368579894304\n",
      "Epoch 4992, Loss: 0.025449315086007118, Final Batch Loss: 0.007845232263207436\n",
      "Epoch 4993, Loss: 0.02457232167944312, Final Batch Loss: 0.004394156392663717\n",
      "Epoch 4994, Loss: 0.010090769501402974, Final Batch Loss: 0.0073411851190030575\n",
      "Epoch 4995, Loss: 0.007002157857641578, Final Batch Loss: 0.00450927997007966\n",
      "Epoch 4996, Loss: 0.007341141812503338, Final Batch Loss: 0.0021543302573263645\n",
      "Epoch 4997, Loss: 0.004481446463614702, Final Batch Loss: 0.0020460195373743773\n",
      "Epoch 4998, Loss: 0.0383476447314024, Final Batch Loss: 0.02268071100115776\n",
      "Epoch 4999, Loss: 0.042097014375030994, Final Batch Loss: 0.006815181113779545\n",
      "Epoch 5000, Loss: 0.02910193521529436, Final Batch Loss: 0.00867814477533102\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33  0  0]\n",
      " [ 2 22  1]\n",
      " [ 0  0 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.94286   1.00000   0.97059        33\n",
      "           1    1.00000   0.88000   0.93617        25\n",
      "           2    0.96875   1.00000   0.98413        31\n",
      "\n",
      "    accuracy                        0.96629        89\n",
      "   macro avg    0.97054   0.96000   0.96363        89\n",
      "weighted avg    0.96793   0.96629   0.96564        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38  0  0]\n",
      " [ 0 21  5]\n",
      " [ 0  0 25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        38\n",
      "           1    1.00000   0.80769   0.89362        26\n",
      "           2    0.83333   1.00000   0.90909        25\n",
      "\n",
      "    accuracy                        0.94382        89\n",
      "   macro avg    0.94444   0.93590   0.93424        89\n",
      "weighted avg    0.95318   0.94382   0.94339        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(usr_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(usr_vectors[0], preds.cpu(), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
