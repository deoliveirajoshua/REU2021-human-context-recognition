{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '125 tBodyGyro-std()-Y',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '138 tBodyGyro-energy()-Y',\n",
    " '165 tBodyGyroJerk-std()-Y',\n",
    " '168 tBodyGyroJerk-mad()-Y',\n",
    " '178 tBodyGyroJerk-energy()-Y',\n",
    " '181 tBodyGyroJerk-iqr()-Y',\n",
    " '425 fBodyGyro-mean()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '431 fBodyGyro-mad()-Y',\n",
    " '441 fBodyGyro-energy()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '478 fBodyGyro-bandsEnergy()-25,32',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '204 tBodyAccMag-max()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '217 tGravityAccMag-max()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '275 fBodyAcc-max()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '506 fBodyAccMag-max()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>42 tGravityAcc-mean()-Y</th>\n",
       "      <th>43 tGravityAcc-mean()-Z</th>\n",
       "      <th>51 tGravityAcc-max()-Y</th>\n",
       "      <th>52 tGravityAcc-max()-Z</th>\n",
       "      <th>54 tGravityAcc-min()-Y</th>\n",
       "      <th>55 tGravityAcc-min()-Z</th>\n",
       "      <th>56 tGravityAcc-sma()</th>\n",
       "      <th>59 tGravityAcc-energy()-Z</th>\n",
       "      <th>125 tBodyGyro-std()-Y</th>\n",
       "      <th>128 tBodyGyro-mad()-Y</th>\n",
       "      <th>...</th>\n",
       "      <th>282 fBodyAcc-energy()-X</th>\n",
       "      <th>303 fBodyAcc-bandsEnergy()-1,8</th>\n",
       "      <th>311 fBodyAcc-bandsEnergy()-1,16</th>\n",
       "      <th>315 fBodyAcc-bandsEnergy()-1,24</th>\n",
       "      <th>504 fBodyAccMag-std()</th>\n",
       "      <th>505 fBodyAccMag-mad()</th>\n",
       "      <th>506 fBodyAccMag-max()</th>\n",
       "      <th>509 fBodyAccMag-energy()</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.140840</td>\n",
       "      <td>0.115375</td>\n",
       "      <td>-0.161265</td>\n",
       "      <td>0.124660</td>\n",
       "      <td>-0.123213</td>\n",
       "      <td>0.056483</td>\n",
       "      <td>-0.375426</td>\n",
       "      <td>-0.975510</td>\n",
       "      <td>-0.976623</td>\n",
       "      <td>-0.976353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999968</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>-0.956134</td>\n",
       "      <td>-0.948870</td>\n",
       "      <td>-0.974321</td>\n",
       "      <td>-0.998285</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.141551</td>\n",
       "      <td>0.109379</td>\n",
       "      <td>-0.161343</td>\n",
       "      <td>0.122586</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.383430</td>\n",
       "      <td>-0.978500</td>\n",
       "      <td>-0.989046</td>\n",
       "      <td>-0.989038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.975866</td>\n",
       "      <td>-0.975777</td>\n",
       "      <td>-0.978226</td>\n",
       "      <td>-0.999472</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.142010</td>\n",
       "      <td>0.101884</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.094566</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.401602</td>\n",
       "      <td>-0.981672</td>\n",
       "      <td>-0.993552</td>\n",
       "      <td>-0.994122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-0.999972</td>\n",
       "      <td>-0.989015</td>\n",
       "      <td>-0.985594</td>\n",
       "      <td>-0.993062</td>\n",
       "      <td>-0.999807</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.143976</td>\n",
       "      <td>0.099850</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.093425</td>\n",
       "      <td>-0.121336</td>\n",
       "      <td>0.095753</td>\n",
       "      <td>-0.400278</td>\n",
       "      <td>-0.982420</td>\n",
       "      <td>-0.992407</td>\n",
       "      <td>-0.993142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999975</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-0.986742</td>\n",
       "      <td>-0.983524</td>\n",
       "      <td>-0.990230</td>\n",
       "      <td>-0.999770</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.148750</td>\n",
       "      <td>0.094486</td>\n",
       "      <td>-0.166786</td>\n",
       "      <td>0.091682</td>\n",
       "      <td>-0.121834</td>\n",
       "      <td>0.094059</td>\n",
       "      <td>-0.400477</td>\n",
       "      <td>-0.984363</td>\n",
       "      <td>-0.992378</td>\n",
       "      <td>-0.992542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.990063</td>\n",
       "      <td>-0.992324</td>\n",
       "      <td>-0.990506</td>\n",
       "      <td>-0.999873</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>-0.222004</td>\n",
       "      <td>-0.039492</td>\n",
       "      <td>-0.214233</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.071977</td>\n",
       "      <td>-0.405132</td>\n",
       "      <td>-0.995193</td>\n",
       "      <td>0.084878</td>\n",
       "      <td>0.065142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674230</td>\n",
       "      <td>-0.684177</td>\n",
       "      <td>-0.666429</td>\n",
       "      <td>-0.668164</td>\n",
       "      <td>-0.232600</td>\n",
       "      <td>-0.007392</td>\n",
       "      <td>-0.401674</td>\n",
       "      <td>-0.584282</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>-0.242054</td>\n",
       "      <td>-0.039863</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.358934</td>\n",
       "      <td>-0.995151</td>\n",
       "      <td>0.098249</td>\n",
       "      <td>0.091791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.705580</td>\n",
       "      <td>-0.726986</td>\n",
       "      <td>-0.704444</td>\n",
       "      <td>-0.705435</td>\n",
       "      <td>-0.275373</td>\n",
       "      <td>-0.172448</td>\n",
       "      <td>-0.410577</td>\n",
       "      <td>-0.632536</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>-0.236950</td>\n",
       "      <td>-0.026805</td>\n",
       "      <td>-0.249134</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.216004</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.377025</td>\n",
       "      <td>-0.995450</td>\n",
       "      <td>0.185902</td>\n",
       "      <td>0.170686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.692379</td>\n",
       "      <td>-0.655263</td>\n",
       "      <td>-0.674515</td>\n",
       "      <td>-0.684729</td>\n",
       "      <td>-0.220288</td>\n",
       "      <td>-0.216074</td>\n",
       "      <td>-0.362904</td>\n",
       "      <td>-0.641170</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>-0.233230</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.244267</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.210542</td>\n",
       "      <td>-0.040009</td>\n",
       "      <td>-0.440050</td>\n",
       "      <td>-0.998824</td>\n",
       "      <td>0.190360</td>\n",
       "      <td>0.178939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693098</td>\n",
       "      <td>-0.643425</td>\n",
       "      <td>-0.677215</td>\n",
       "      <td>-0.685088</td>\n",
       "      <td>-0.234539</td>\n",
       "      <td>-0.220443</td>\n",
       "      <td>-0.397687</td>\n",
       "      <td>-0.663579</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>-0.233292</td>\n",
       "      <td>-0.020954</td>\n",
       "      <td>-0.240956</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>-0.212149</td>\n",
       "      <td>-0.047491</td>\n",
       "      <td>-0.432003</td>\n",
       "      <td>-0.998144</td>\n",
       "      <td>0.022216</td>\n",
       "      <td>-0.073681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.731037</td>\n",
       "      <td>-0.709495</td>\n",
       "      <td>-0.728519</td>\n",
       "      <td>-0.727441</td>\n",
       "      <td>-0.342670</td>\n",
       "      <td>-0.146649</td>\n",
       "      <td>-0.620014</td>\n",
       "      <td>-0.698087</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      42 tGravityAcc-mean()-Y  43 tGravityAcc-mean()-Z  \\\n",
       "0                   -0.140840                 0.115375   \n",
       "1                   -0.141551                 0.109379   \n",
       "2                   -0.142010                 0.101884   \n",
       "3                   -0.143976                 0.099850   \n",
       "4                   -0.148750                 0.094486   \n",
       "...                       ...                      ...   \n",
       "7347                -0.222004                -0.039492   \n",
       "7348                -0.242054                -0.039863   \n",
       "7349                -0.236950                -0.026805   \n",
       "7350                -0.233230                -0.004984   \n",
       "7351                -0.233292                -0.020954   \n",
       "\n",
       "      51 tGravityAcc-max()-Y  52 tGravityAcc-max()-Z  54 tGravityAcc-min()-Y  \\\n",
       "0                  -0.161265                0.124660               -0.123213   \n",
       "1                  -0.161343                0.122586               -0.114893   \n",
       "2                  -0.163711                0.094566               -0.114893   \n",
       "3                  -0.163711                0.093425               -0.121336   \n",
       "4                  -0.166786                0.091682               -0.121834   \n",
       "...                      ...                     ...                     ...   \n",
       "7347               -0.214233               -0.016391               -0.234998   \n",
       "7348               -0.231477               -0.016391               -0.234998   \n",
       "7349               -0.249134                0.024684               -0.216004   \n",
       "7350               -0.244267                0.024684               -0.210542   \n",
       "7351               -0.240956                0.003031               -0.212149   \n",
       "\n",
       "      55 tGravityAcc-min()-Z  56 tGravityAcc-sma()  59 tGravityAcc-energy()-Z  \\\n",
       "0                   0.056483             -0.375426                  -0.975510   \n",
       "1                   0.102764             -0.383430                  -0.978500   \n",
       "2                   0.102764             -0.401602                  -0.981672   \n",
       "3                   0.095753             -0.400278                  -0.982420   \n",
       "4                   0.094059             -0.400477                  -0.984363   \n",
       "...                      ...                   ...                        ...   \n",
       "7347               -0.071977             -0.405132                  -0.995193   \n",
       "7348               -0.068919             -0.358934                  -0.995151   \n",
       "7349               -0.068919             -0.377025                  -0.995450   \n",
       "7350               -0.040009             -0.440050                  -0.998824   \n",
       "7351               -0.047491             -0.432003                  -0.998144   \n",
       "\n",
       "      125 tBodyGyro-std()-Y  128 tBodyGyro-mad()-Y  ...  \\\n",
       "0                 -0.976623              -0.976353  ...   \n",
       "1                 -0.989046              -0.989038  ...   \n",
       "2                 -0.993552              -0.994122  ...   \n",
       "3                 -0.992407              -0.993142  ...   \n",
       "4                 -0.992378              -0.992542  ...   \n",
       "...                     ...                    ...  ...   \n",
       "7347               0.084878               0.065142  ...   \n",
       "7348               0.098249               0.091791  ...   \n",
       "7349               0.185902               0.170686  ...   \n",
       "7350               0.190360               0.178939  ...   \n",
       "7351               0.022216              -0.073681  ...   \n",
       "\n",
       "      282 fBodyAcc-energy()-X  303 fBodyAcc-bandsEnergy()-1,8  \\\n",
       "0                   -0.999968                       -0.999963   \n",
       "1                   -0.999991                       -0.999996   \n",
       "2                   -0.999969                       -0.999989   \n",
       "3                   -0.999975                       -0.999989   \n",
       "4                   -0.999990                       -0.999994   \n",
       "...                       ...                             ...   \n",
       "7347                -0.674230                       -0.684177   \n",
       "7348                -0.705580                       -0.726986   \n",
       "7349                -0.692379                       -0.655263   \n",
       "7350                -0.693098                       -0.643425   \n",
       "7351                -0.731037                       -0.709495   \n",
       "\n",
       "      311 fBodyAcc-bandsEnergy()-1,16  315 fBodyAcc-bandsEnergy()-1,24  \\\n",
       "0                           -0.999969                        -0.999971   \n",
       "1                           -0.999994                        -0.999992   \n",
       "2                           -0.999983                        -0.999972   \n",
       "3                           -0.999986                        -0.999977   \n",
       "4                           -0.999993                        -0.999991   \n",
       "...                               ...                              ...   \n",
       "7347                        -0.666429                        -0.668164   \n",
       "7348                        -0.704444                        -0.705435   \n",
       "7349                        -0.674515                        -0.684729   \n",
       "7350                        -0.677215                        -0.685088   \n",
       "7351                        -0.728519                        -0.727441   \n",
       "\n",
       "      504 fBodyAccMag-std()  505 fBodyAccMag-mad()  506 fBodyAccMag-max()  \\\n",
       "0                 -0.956134              -0.948870              -0.974321   \n",
       "1                 -0.975866              -0.975777              -0.978226   \n",
       "2                 -0.989015              -0.985594              -0.993062   \n",
       "3                 -0.986742              -0.983524              -0.990230   \n",
       "4                 -0.990063              -0.992324              -0.990506   \n",
       "...                     ...                    ...                    ...   \n",
       "7347              -0.232600              -0.007392              -0.401674   \n",
       "7348              -0.275373              -0.172448              -0.410577   \n",
       "7349              -0.220288              -0.216074              -0.362904   \n",
       "7350              -0.234539              -0.220443              -0.397687   \n",
       "7351              -0.342670              -0.146649              -0.620014   \n",
       "\n",
       "      509 fBodyAccMag-energy()  Activity  Subject  \n",
       "0                    -0.998285         5        1  \n",
       "1                    -0.999472         5        1  \n",
       "2                    -0.999807         5        1  \n",
       "3                    -0.999770         5        1  \n",
       "4                    -0.999873         5        1  \n",
       "...                        ...       ...      ...  \n",
       "7347                 -0.584282         2       30  \n",
       "7348                 -0.632536         2       30  \n",
       "7349                 -0.641170         2       30  \n",
       "7350                 -0.663579         2       30  \n",
       "7351                 -0.698087         2       30  \n",
       "\n",
       "[7352 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names = pd.read_csv('../../data/features.txt', delimiter = '\\n', header = None)\n",
    "train_column_names = train_names.values.tolist()\n",
    "train_column_names = [k for row in train_column_names for k in row]\n",
    "\n",
    "train_data = pd.read_csv('../../data/X_train.txt', delim_whitespace = True, header = None)\n",
    "train_data.columns = train_column_names\n",
    "\n",
    "### Single dataframe column\n",
    "y_train = pd.read_csv('../../data/y_train.txt', header = None)\n",
    "y_train.columns = ['Activity']\n",
    "\n",
    "y_train_subject = pd.read_csv('../../data/subject_train.txt', header = None)\n",
    "y_train_subject.columns = ['Subject']\n",
    "\n",
    "X_train_1 = train_data[sub_features]\n",
    "X_train_2 = train_data[act_features]\n",
    "X_train_data = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "\n",
    "X_train_data = pd.concat([X_train_data, y_train, y_train_subject], axis = 1)\n",
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_data[(X_train_data['Subject'].isin([7, 8, 11])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,:-2].values\n",
    "y_train = X_train_data[(X_train_data['Subject'].isin([7, 8, 11])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,-2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y_train)):\n",
    "    if y_train[k] == 1:\n",
    "        y_train[k] = 0\n",
    "    elif y_train[k] == 3:\n",
    "        y_train[k] = 1\n",
    "    else:\n",
    "        y_train[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.15, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 30),\n",
    "            classifier_block(30, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.269522190093994, Final Batch Loss: 1.136056900024414\n",
      "Epoch 2, Loss: 2.2586755752563477, Final Batch Loss: 1.1198252439498901\n",
      "Epoch 3, Loss: 2.2703771591186523, Final Batch Loss: 1.151710033416748\n",
      "Epoch 4, Loss: 2.2465131282806396, Final Batch Loss: 1.1096835136413574\n",
      "Epoch 5, Loss: 2.242921233177185, Final Batch Loss: 1.1094870567321777\n",
      "Epoch 6, Loss: 2.2476062774658203, Final Batch Loss: 1.1269042491912842\n",
      "Epoch 7, Loss: 2.2501087188720703, Final Batch Loss: 1.137291431427002\n",
      "Epoch 8, Loss: 2.233152747154236, Final Batch Loss: 1.1131528615951538\n",
      "Epoch 9, Loss: 2.2159184217453003, Final Batch Loss: 1.087282657623291\n",
      "Epoch 10, Loss: 2.2309353351593018, Final Batch Loss: 1.1230469942092896\n",
      "Epoch 11, Loss: 2.2212501764297485, Final Batch Loss: 1.1111210584640503\n",
      "Epoch 12, Loss: 2.2134796380996704, Final Batch Loss: 1.1092957258224487\n",
      "Epoch 13, Loss: 2.21994948387146, Final Batch Loss: 1.1258931159973145\n",
      "Epoch 14, Loss: 2.207967162132263, Final Batch Loss: 1.1175435781478882\n",
      "Epoch 15, Loss: 2.191683530807495, Final Batch Loss: 1.086463212966919\n",
      "Epoch 16, Loss: 2.1825342178344727, Final Batch Loss: 1.087295651435852\n",
      "Epoch 17, Loss: 2.1749179363250732, Final Batch Loss: 1.0861042737960815\n",
      "Epoch 18, Loss: 2.1749907732009888, Final Batch Loss: 1.0995891094207764\n",
      "Epoch 19, Loss: 2.1476093530654907, Final Batch Loss: 1.0684617757797241\n",
      "Epoch 20, Loss: 2.1384055614471436, Final Batch Loss: 1.0767887830734253\n",
      "Epoch 21, Loss: 2.113435745239258, Final Batch Loss: 1.0443148612976074\n",
      "Epoch 22, Loss: 2.103023886680603, Final Batch Loss: 1.0549979209899902\n",
      "Epoch 23, Loss: 2.076833128929138, Final Batch Loss: 1.0443530082702637\n",
      "Epoch 24, Loss: 2.048389434814453, Final Batch Loss: 1.0187517404556274\n",
      "Epoch 25, Loss: 2.0192527174949646, Final Batch Loss: 0.994583785533905\n",
      "Epoch 26, Loss: 1.9940712451934814, Final Batch Loss: 0.9795076847076416\n",
      "Epoch 27, Loss: 1.9674310684204102, Final Batch Loss: 0.9793926477432251\n",
      "Epoch 28, Loss: 1.9441571831703186, Final Batch Loss: 0.960050642490387\n",
      "Epoch 29, Loss: 1.8867743015289307, Final Batch Loss: 0.9389307498931885\n",
      "Epoch 30, Loss: 1.8660943508148193, Final Batch Loss: 0.9385743141174316\n",
      "Epoch 31, Loss: 1.784893810749054, Final Batch Loss: 0.8822845220565796\n",
      "Epoch 32, Loss: 1.7500895857810974, Final Batch Loss: 0.8583948612213135\n",
      "Epoch 33, Loss: 1.715463399887085, Final Batch Loss: 0.8582701683044434\n",
      "Epoch 34, Loss: 1.6956367492675781, Final Batch Loss: 0.8709258437156677\n",
      "Epoch 35, Loss: 1.6195992231369019, Final Batch Loss: 0.8068528175354004\n",
      "Epoch 36, Loss: 1.580872654914856, Final Batch Loss: 0.7840933799743652\n",
      "Epoch 37, Loss: 1.5199000239372253, Final Batch Loss: 0.7477550506591797\n",
      "Epoch 38, Loss: 1.454221487045288, Final Batch Loss: 0.6778854131698608\n",
      "Epoch 39, Loss: 1.436107337474823, Final Batch Loss: 0.7238864302635193\n",
      "Epoch 40, Loss: 1.395999789237976, Final Batch Loss: 0.7234696745872498\n",
      "Epoch 41, Loss: 1.321124792098999, Final Batch Loss: 0.6466705203056335\n",
      "Epoch 42, Loss: 1.27006334066391, Final Batch Loss: 0.6190412640571594\n",
      "Epoch 43, Loss: 1.210722029209137, Final Batch Loss: 0.5824902057647705\n",
      "Epoch 44, Loss: 1.155773103237152, Final Batch Loss: 0.5649865865707397\n",
      "Epoch 45, Loss: 1.095998227596283, Final Batch Loss: 0.5384016036987305\n",
      "Epoch 46, Loss: 1.05910062789917, Final Batch Loss: 0.5210494995117188\n",
      "Epoch 47, Loss: 0.9897842705249786, Final Batch Loss: 0.5128063559532166\n",
      "Epoch 48, Loss: 0.9164453148841858, Final Batch Loss: 0.4528696835041046\n",
      "Epoch 49, Loss: 0.8376414179801941, Final Batch Loss: 0.38075748085975647\n",
      "Epoch 50, Loss: 0.8499071002006531, Final Batch Loss: 0.4272647500038147\n",
      "Epoch 51, Loss: 0.8278548121452332, Final Batch Loss: 0.3895469605922699\n",
      "Epoch 52, Loss: 0.7413058280944824, Final Batch Loss: 0.3815149664878845\n",
      "Epoch 53, Loss: 0.7085118591785431, Final Batch Loss: 0.3336435556411743\n",
      "Epoch 54, Loss: 0.6423647999763489, Final Batch Loss: 0.288462370634079\n",
      "Epoch 55, Loss: 0.6492983400821686, Final Batch Loss: 0.334038645029068\n",
      "Epoch 56, Loss: 0.5241556316614151, Final Batch Loss: 0.239095076918602\n",
      "Epoch 57, Loss: 0.5657102465629578, Final Batch Loss: 0.2571452856063843\n",
      "Epoch 58, Loss: 0.5247583389282227, Final Batch Loss: 0.27716347575187683\n",
      "Epoch 59, Loss: 0.4950520247220993, Final Batch Loss: 0.23055978119373322\n",
      "Epoch 60, Loss: 0.4722660779953003, Final Batch Loss: 0.22735477983951569\n",
      "Epoch 61, Loss: 0.4701634645462036, Final Batch Loss: 0.22586987912654877\n",
      "Epoch 62, Loss: 0.4637294262647629, Final Batch Loss: 0.2169075608253479\n",
      "Epoch 63, Loss: 0.4786589741706848, Final Batch Loss: 0.24415159225463867\n",
      "Epoch 64, Loss: 0.4491906762123108, Final Batch Loss: 0.2702702283859253\n",
      "Epoch 65, Loss: 0.44288094341754913, Final Batch Loss: 0.23665674030780792\n",
      "Epoch 66, Loss: 0.34786587953567505, Final Batch Loss: 0.13285544514656067\n",
      "Epoch 67, Loss: 0.37346453964710236, Final Batch Loss: 0.14675751328468323\n",
      "Epoch 68, Loss: 0.4347999542951584, Final Batch Loss: 0.23245899379253387\n",
      "Epoch 69, Loss: 0.3691295385360718, Final Batch Loss: 0.20902766287326813\n",
      "Epoch 70, Loss: 0.37795451283454895, Final Batch Loss: 0.20347601175308228\n",
      "Epoch 71, Loss: 0.34860511124134064, Final Batch Loss: 0.1879711151123047\n",
      "Epoch 72, Loss: 0.34478871524333954, Final Batch Loss: 0.15121395885944366\n",
      "Epoch 73, Loss: 0.32649773359298706, Final Batch Loss: 0.1614948809146881\n",
      "Epoch 74, Loss: 0.35037828981876373, Final Batch Loss: 0.18038244545459747\n",
      "Epoch 75, Loss: 0.2660956531763077, Final Batch Loss: 0.1368735134601593\n",
      "Epoch 76, Loss: 0.29172152280807495, Final Batch Loss: 0.1266132891178131\n",
      "Epoch 77, Loss: 0.3596610873937607, Final Batch Loss: 0.2153657227754593\n",
      "Epoch 78, Loss: 0.29029960185289383, Final Batch Loss: 0.12479142099618912\n",
      "Epoch 79, Loss: 0.31945544481277466, Final Batch Loss: 0.12603001296520233\n",
      "Epoch 80, Loss: 0.3050895631313324, Final Batch Loss: 0.11826266348361969\n",
      "Epoch 81, Loss: 0.3011644780635834, Final Batch Loss: 0.15815718472003937\n",
      "Epoch 82, Loss: 0.28557226061820984, Final Batch Loss: 0.15943655371665955\n",
      "Epoch 83, Loss: 0.2264947071671486, Final Batch Loss: 0.11331909894943237\n",
      "Epoch 84, Loss: 0.24363590776920319, Final Batch Loss: 0.10323408246040344\n",
      "Epoch 85, Loss: 0.2726609855890274, Final Batch Loss: 0.14511427283287048\n",
      "Epoch 86, Loss: 0.2745479941368103, Final Batch Loss: 0.16697384417057037\n",
      "Epoch 87, Loss: 0.22703839093446732, Final Batch Loss: 0.1344582736492157\n",
      "Epoch 88, Loss: 0.2612229883670807, Final Batch Loss: 0.14078375697135925\n",
      "Epoch 89, Loss: 0.23533467948436737, Final Batch Loss: 0.11291498690843582\n",
      "Epoch 90, Loss: 0.2458314672112465, Final Batch Loss: 0.13324765861034393\n",
      "Epoch 91, Loss: 0.2882726639509201, Final Batch Loss: 0.16063831746578217\n",
      "Epoch 92, Loss: 0.29201050102710724, Final Batch Loss: 0.19800959527492523\n",
      "Epoch 93, Loss: 0.20292609930038452, Final Batch Loss: 0.07773023843765259\n",
      "Epoch 94, Loss: 0.25114088505506516, Final Batch Loss: 0.11745744198560715\n",
      "Epoch 95, Loss: 0.19828753918409348, Final Batch Loss: 0.094210684299469\n",
      "Epoch 96, Loss: 0.20307523757219315, Final Batch Loss: 0.06625816971063614\n",
      "Epoch 97, Loss: 0.23019835352897644, Final Batch Loss: 0.10393619537353516\n",
      "Epoch 98, Loss: 0.18523746728897095, Final Batch Loss: 0.0808640643954277\n",
      "Epoch 99, Loss: 0.27457889169454575, Final Batch Loss: 0.1717846542596817\n",
      "Epoch 100, Loss: 0.18157348409295082, Final Batch Loss: 0.05194482579827309\n",
      "Epoch 101, Loss: 0.1525663062930107, Final Batch Loss: 0.07532192021608353\n",
      "Epoch 102, Loss: 0.2636876106262207, Final Batch Loss: 0.13737322390079498\n",
      "Epoch 103, Loss: 0.18529554083943367, Final Batch Loss: 0.061157260090112686\n",
      "Epoch 104, Loss: 0.1704738475382328, Final Batch Loss: 0.12176407128572464\n",
      "Epoch 105, Loss: 0.1933230385184288, Final Batch Loss: 0.07331688702106476\n",
      "Epoch 106, Loss: 0.15835711359977722, Final Batch Loss: 0.08896564692258835\n",
      "Epoch 107, Loss: 0.21967357397079468, Final Batch Loss: 0.09608079493045807\n",
      "Epoch 108, Loss: 0.1771501898765564, Final Batch Loss: 0.09307989478111267\n",
      "Epoch 109, Loss: 0.1668870598077774, Final Batch Loss: 0.05980517715215683\n",
      "Epoch 110, Loss: 0.16592593491077423, Final Batch Loss: 0.06931006163358688\n",
      "Epoch 111, Loss: 0.2082548514008522, Final Batch Loss: 0.12252085655927658\n",
      "Epoch 112, Loss: 0.25123025476932526, Final Batch Loss: 0.14755457639694214\n",
      "Epoch 113, Loss: 0.1824716329574585, Final Batch Loss: 0.06927476823329926\n",
      "Epoch 114, Loss: 0.1665542870759964, Final Batch Loss: 0.05753900110721588\n",
      "Epoch 115, Loss: 0.18359915912151337, Final Batch Loss: 0.10781789571046829\n",
      "Epoch 116, Loss: 0.16992276906967163, Final Batch Loss: 0.10664526373147964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117, Loss: 0.17260903865098953, Final Batch Loss: 0.0915452316403389\n",
      "Epoch 118, Loss: 0.1548483520746231, Final Batch Loss: 0.0645831897854805\n",
      "Epoch 119, Loss: 0.12283168360590935, Final Batch Loss: 0.04216822609305382\n",
      "Epoch 120, Loss: 0.17807473614811897, Final Batch Loss: 0.1165938675403595\n",
      "Epoch 121, Loss: 0.1782369464635849, Final Batch Loss: 0.08723612129688263\n",
      "Epoch 122, Loss: 0.16573075950145721, Final Batch Loss: 0.08759687840938568\n",
      "Epoch 123, Loss: 0.1511741206049919, Final Batch Loss: 0.07781092077493668\n",
      "Epoch 124, Loss: 0.16778136044740677, Final Batch Loss: 0.08985642343759537\n",
      "Epoch 125, Loss: 0.12762920558452606, Final Batch Loss: 0.0416887030005455\n",
      "Epoch 126, Loss: 0.1742030680179596, Final Batch Loss: 0.08769014477729797\n",
      "Epoch 127, Loss: 0.13674205541610718, Final Batch Loss: 0.07344036549329758\n",
      "Epoch 128, Loss: 0.11365759372711182, Final Batch Loss: 0.044494472444057465\n",
      "Epoch 129, Loss: 0.16967133432626724, Final Batch Loss: 0.10361829400062561\n",
      "Epoch 130, Loss: 0.13432656228542328, Final Batch Loss: 0.07652571052312851\n",
      "Epoch 131, Loss: 0.13274546340107918, Final Batch Loss: 0.07150759547948837\n",
      "Epoch 132, Loss: 0.17286159470677376, Final Batch Loss: 0.11242705583572388\n",
      "Epoch 133, Loss: 0.120425283908844, Final Batch Loss: 0.09230294078588486\n",
      "Epoch 134, Loss: 0.13204333186149597, Final Batch Loss: 0.05818121135234833\n",
      "Epoch 135, Loss: 0.1373179331421852, Final Batch Loss: 0.06679368019104004\n",
      "Epoch 136, Loss: 0.15407536551356316, Final Batch Loss: 0.09522132575511932\n",
      "Epoch 137, Loss: 0.11729000508785248, Final Batch Loss: 0.04820355772972107\n",
      "Epoch 138, Loss: 0.1478392258286476, Final Batch Loss: 0.11083538830280304\n",
      "Epoch 139, Loss: 0.13167958706617355, Final Batch Loss: 0.07197829335927963\n",
      "Epoch 140, Loss: 0.11619178578257561, Final Batch Loss: 0.03360467031598091\n",
      "Epoch 141, Loss: 0.09763852134346962, Final Batch Loss: 0.04972553625702858\n",
      "Epoch 142, Loss: 0.1061628870666027, Final Batch Loss: 0.05322093889117241\n",
      "Epoch 143, Loss: 0.13445785641670227, Final Batch Loss: 0.06810244172811508\n",
      "Epoch 144, Loss: 0.1095120832324028, Final Batch Loss: 0.06326034665107727\n",
      "Epoch 145, Loss: 0.09068914130330086, Final Batch Loss: 0.03480897098779678\n",
      "Epoch 146, Loss: 0.0788111612200737, Final Batch Loss: 0.014580965042114258\n",
      "Epoch 147, Loss: 0.10163512080907822, Final Batch Loss: 0.04469843581318855\n",
      "Epoch 148, Loss: 0.09201493114233017, Final Batch Loss: 0.060754481703042984\n",
      "Epoch 149, Loss: 0.09913583472371101, Final Batch Loss: 0.042651183903217316\n",
      "Epoch 150, Loss: 0.15082097053527832, Final Batch Loss: 0.08775939047336578\n",
      "Epoch 151, Loss: 0.11814695224165916, Final Batch Loss: 0.042662959545850754\n",
      "Epoch 152, Loss: 0.08734264597296715, Final Batch Loss: 0.04149767756462097\n",
      "Epoch 153, Loss: 0.11476346105337143, Final Batch Loss: 0.06564972549676895\n",
      "Epoch 154, Loss: 0.11287654936313629, Final Batch Loss: 0.06193561106920242\n",
      "Epoch 155, Loss: 0.11339101940393448, Final Batch Loss: 0.06148200482130051\n",
      "Epoch 156, Loss: 0.08639947697520256, Final Batch Loss: 0.036758918315172195\n",
      "Epoch 157, Loss: 0.08613830432295799, Final Batch Loss: 0.03267831355333328\n",
      "Epoch 158, Loss: 0.08054950088262558, Final Batch Loss: 0.04783983528614044\n",
      "Epoch 159, Loss: 0.08236886747181416, Final Batch Loss: 0.02692185528576374\n",
      "Epoch 160, Loss: 0.11042172089219093, Final Batch Loss: 0.06368272751569748\n",
      "Epoch 161, Loss: 0.08730448782444, Final Batch Loss: 0.04415404051542282\n",
      "Epoch 162, Loss: 0.07774194702506065, Final Batch Loss: 0.04432098940014839\n",
      "Epoch 163, Loss: 0.048032961785793304, Final Batch Loss: 0.01757640205323696\n",
      "Epoch 164, Loss: 0.10703689977526665, Final Batch Loss: 0.06802232563495636\n",
      "Epoch 165, Loss: 0.08305661752820015, Final Batch Loss: 0.043441109359264374\n",
      "Epoch 166, Loss: 0.09229850396513939, Final Batch Loss: 0.04706687480211258\n",
      "Epoch 167, Loss: 0.06065590679645538, Final Batch Loss: 0.03742532059550285\n",
      "Epoch 168, Loss: 0.09946266561746597, Final Batch Loss: 0.0657792016863823\n",
      "Epoch 169, Loss: 0.10320959985256195, Final Batch Loss: 0.05382472649216652\n",
      "Epoch 170, Loss: 0.08431416749954224, Final Batch Loss: 0.03639422729611397\n",
      "Epoch 171, Loss: 0.06227153725922108, Final Batch Loss: 0.024216344580054283\n",
      "Epoch 172, Loss: 0.0881846509873867, Final Batch Loss: 0.04724308103322983\n",
      "Epoch 173, Loss: 0.07255101390182972, Final Batch Loss: 0.04131663590669632\n",
      "Epoch 174, Loss: 0.07972558215260506, Final Batch Loss: 0.04583702236413956\n",
      "Epoch 175, Loss: 0.07662251219153404, Final Batch Loss: 0.04722977802157402\n",
      "Epoch 176, Loss: 0.11358696408569813, Final Batch Loss: 0.08244744688272476\n",
      "Epoch 177, Loss: 0.07391129061579704, Final Batch Loss: 0.021595299243927002\n",
      "Epoch 178, Loss: 0.10508569329977036, Final Batch Loss: 0.0478394441306591\n",
      "Epoch 179, Loss: 0.05573236010968685, Final Batch Loss: 0.03327033668756485\n",
      "Epoch 180, Loss: 0.04991757869720459, Final Batch Loss: 0.01657799258828163\n",
      "Epoch 181, Loss: 0.06464712135493755, Final Batch Loss: 0.034435875713825226\n",
      "Epoch 182, Loss: 0.05019623599946499, Final Batch Loss: 0.020796194672584534\n",
      "Epoch 183, Loss: 0.058477455750107765, Final Batch Loss: 0.029813943430781364\n",
      "Epoch 184, Loss: 0.06328713148832321, Final Batch Loss: 0.047574885189533234\n",
      "Epoch 185, Loss: 0.06411775015294552, Final Batch Loss: 0.03312051668763161\n",
      "Epoch 186, Loss: 0.05842125043272972, Final Batch Loss: 0.036296308040618896\n",
      "Epoch 187, Loss: 0.045460483990609646, Final Batch Loss: 0.014262584038078785\n",
      "Epoch 188, Loss: 0.08025387860834599, Final Batch Loss: 0.05069863051176071\n",
      "Epoch 189, Loss: 0.03435786720365286, Final Batch Loss: 0.01038265135139227\n",
      "Epoch 190, Loss: 0.04379558376967907, Final Batch Loss: 0.018781043589115143\n",
      "Epoch 191, Loss: 0.04160210397094488, Final Batch Loss: 0.006784583441913128\n",
      "Epoch 192, Loss: 0.062462927773594856, Final Batch Loss: 0.024387089535593987\n",
      "Epoch 193, Loss: 0.05586924962699413, Final Batch Loss: 0.04001232981681824\n",
      "Epoch 194, Loss: 0.06457411870360374, Final Batch Loss: 0.03335786610841751\n",
      "Epoch 195, Loss: 0.05455717816948891, Final Batch Loss: 0.03508051484823227\n",
      "Epoch 196, Loss: 0.05433139577507973, Final Batch Loss: 0.03140796348452568\n",
      "Epoch 197, Loss: 0.05756949447095394, Final Batch Loss: 0.022483831271529198\n",
      "Epoch 198, Loss: 0.07053886726498604, Final Batch Loss: 0.0449521578848362\n",
      "Epoch 199, Loss: 0.09948114678263664, Final Batch Loss: 0.06532008200883865\n",
      "Epoch 200, Loss: 0.04611576721072197, Final Batch Loss: 0.027002720162272453\n",
      "Epoch 201, Loss: 0.050287483260035515, Final Batch Loss: 0.015767069533467293\n",
      "Epoch 202, Loss: 0.08301397785544395, Final Batch Loss: 0.045722898095846176\n",
      "Epoch 203, Loss: 0.07579579949378967, Final Batch Loss: 0.041676901280879974\n",
      "Epoch 204, Loss: 0.0801907517015934, Final Batch Loss: 0.04585085064172745\n",
      "Epoch 205, Loss: 0.04239152930676937, Final Batch Loss: 0.02356158383190632\n",
      "Epoch 206, Loss: 0.03549861162900925, Final Batch Loss: 0.013346714898943901\n",
      "Epoch 207, Loss: 0.038804362528026104, Final Batch Loss: 0.012741458602249622\n",
      "Epoch 208, Loss: 0.03934155311435461, Final Batch Loss: 0.02511020191013813\n",
      "Epoch 209, Loss: 0.04909892566502094, Final Batch Loss: 0.024121500551700592\n",
      "Epoch 210, Loss: 0.053796106949448586, Final Batch Loss: 0.015923330560326576\n",
      "Epoch 211, Loss: 0.07363311201334, Final Batch Loss: 0.0377579890191555\n",
      "Epoch 212, Loss: 0.06427632831037045, Final Batch Loss: 0.02496815286576748\n",
      "Epoch 213, Loss: 0.051604487001895905, Final Batch Loss: 0.021903671324253082\n",
      "Epoch 214, Loss: 0.04322285018861294, Final Batch Loss: 0.02130267024040222\n",
      "Epoch 215, Loss: 0.0704740546643734, Final Batch Loss: 0.03648873418569565\n",
      "Epoch 216, Loss: 0.05770916864275932, Final Batch Loss: 0.03735587000846863\n",
      "Epoch 217, Loss: 0.020749405957758427, Final Batch Loss: 0.013711865060031414\n",
      "Epoch 218, Loss: 0.04595647379755974, Final Batch Loss: 0.019670207053422928\n",
      "Epoch 219, Loss: 0.04488527774810791, Final Batch Loss: 0.017498748376965523\n",
      "Epoch 220, Loss: 0.06455492600798607, Final Batch Loss: 0.04201378673315048\n",
      "Epoch 221, Loss: 0.035641844384372234, Final Batch Loss: 0.0201179888099432\n",
      "Epoch 222, Loss: 0.04369282443076372, Final Batch Loss: 0.028437821194529533\n",
      "Epoch 223, Loss: 0.0326703917235136, Final Batch Loss: 0.021005580201745033\n",
      "Epoch 224, Loss: 0.02298566233366728, Final Batch Loss: 0.009908669628202915\n",
      "Epoch 225, Loss: 0.06823088973760605, Final Batch Loss: 0.02853306755423546\n",
      "Epoch 226, Loss: 0.03254042472690344, Final Batch Loss: 0.019818367436528206\n",
      "Epoch 227, Loss: 0.05516311153769493, Final Batch Loss: 0.024510350078344345\n",
      "Epoch 228, Loss: 0.03975696209818125, Final Batch Loss: 0.010228347964584827\n",
      "Epoch 229, Loss: 0.03108987119048834, Final Batch Loss: 0.01678435504436493\n",
      "Epoch 230, Loss: 0.05879993923008442, Final Batch Loss: 0.03562941774725914\n",
      "Epoch 231, Loss: 0.061547776684165, Final Batch Loss: 0.0169632937759161\n",
      "Epoch 232, Loss: 0.04062246158719063, Final Batch Loss: 0.02371598593890667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233, Loss: 0.023288271855562925, Final Batch Loss: 0.007461007218807936\n",
      "Epoch 234, Loss: 0.0677361786365509, Final Batch Loss: 0.020926672965288162\n",
      "Epoch 235, Loss: 0.025989677757024765, Final Batch Loss: 0.009935593232512474\n",
      "Epoch 236, Loss: 0.05177652835845947, Final Batch Loss: 0.02663150615990162\n",
      "Epoch 237, Loss: 0.04636740544810891, Final Batch Loss: 0.006474489811807871\n",
      "Epoch 238, Loss: 0.03199324570596218, Final Batch Loss: 0.020150858908891678\n",
      "Epoch 239, Loss: 0.013600301463156939, Final Batch Loss: 0.0042688013054430485\n",
      "Epoch 240, Loss: 0.03538802918046713, Final Batch Loss: 0.009748865850269794\n",
      "Epoch 241, Loss: 0.03874584101140499, Final Batch Loss: 0.02624177746474743\n",
      "Epoch 242, Loss: 0.024739284068346024, Final Batch Loss: 0.012539632618427277\n",
      "Epoch 243, Loss: 0.022109882906079292, Final Batch Loss: 0.00971377082169056\n",
      "Epoch 244, Loss: 0.026896526105701923, Final Batch Loss: 0.014491138979792595\n",
      "Epoch 245, Loss: 0.020316563546657562, Final Batch Loss: 0.010701299645006657\n",
      "Epoch 246, Loss: 0.06492814235389233, Final Batch Loss: 0.04522614926099777\n",
      "Epoch 247, Loss: 0.08210822567343712, Final Batch Loss: 0.07037685811519623\n",
      "Epoch 248, Loss: 0.016450032824650407, Final Batch Loss: 0.0034933167044073343\n",
      "Epoch 249, Loss: 0.033166942186653614, Final Batch Loss: 0.017968466505408287\n",
      "Epoch 250, Loss: 0.04191309888847172, Final Batch Loss: 0.0023696899879723787\n",
      "Epoch 251, Loss: 0.037325665820389986, Final Batch Loss: 0.0030104820616543293\n",
      "Epoch 252, Loss: 0.048279669135808945, Final Batch Loss: 0.03858202323317528\n",
      "Epoch 253, Loss: 0.029029515106230974, Final Batch Loss: 0.004240280482918024\n",
      "Epoch 254, Loss: 0.037231871858239174, Final Batch Loss: 0.019935453310608864\n",
      "Epoch 255, Loss: 0.025429083965718746, Final Batch Loss: 0.01213141530752182\n",
      "Epoch 256, Loss: 0.017534830141812563, Final Batch Loss: 0.005938644986599684\n",
      "Epoch 257, Loss: 0.031582724303007126, Final Batch Loss: 0.0073830075562000275\n",
      "Epoch 258, Loss: 0.05083860643208027, Final Batch Loss: 0.02419767715036869\n",
      "Epoch 259, Loss: 0.021169072948396206, Final Batch Loss: 0.009957002475857735\n",
      "Epoch 260, Loss: 0.036637148819863796, Final Batch Loss: 0.010234360583126545\n",
      "Epoch 261, Loss: 0.05156971514225006, Final Batch Loss: 0.036118555814027786\n",
      "Epoch 262, Loss: 0.031091813929378986, Final Batch Loss: 0.017780473455786705\n",
      "Epoch 263, Loss: 0.022709458600729704, Final Batch Loss: 0.015558917075395584\n",
      "Epoch 264, Loss: 0.03270117659121752, Final Batch Loss: 0.009775652550160885\n",
      "Epoch 265, Loss: 0.029509278014302254, Final Batch Loss: 0.012860294431447983\n",
      "Epoch 266, Loss: 0.026533949188888073, Final Batch Loss: 0.009549823589622974\n",
      "Epoch 267, Loss: 0.042789435014128685, Final Batch Loss: 0.016157614067196846\n",
      "Epoch 268, Loss: 0.027132284827530384, Final Batch Loss: 0.0090259974822402\n",
      "Epoch 269, Loss: 0.04933793656527996, Final Batch Loss: 0.03693908825516701\n",
      "Epoch 270, Loss: 0.03332995343953371, Final Batch Loss: 0.01398675236850977\n",
      "Epoch 271, Loss: 0.02006139326840639, Final Batch Loss: 0.008283274248242378\n",
      "Epoch 272, Loss: 0.03749080002307892, Final Batch Loss: 0.029475737363100052\n",
      "Epoch 273, Loss: 0.07492158748209476, Final Batch Loss: 0.05495170131325722\n",
      "Epoch 274, Loss: 0.031354570761322975, Final Batch Loss: 0.016037698835134506\n",
      "Epoch 275, Loss: 0.022995383013039827, Final Batch Loss: 0.00461294362321496\n",
      "Epoch 276, Loss: 0.018042873591184616, Final Batch Loss: 0.006242940202355385\n",
      "Epoch 277, Loss: 0.041624682024121284, Final Batch Loss: 0.014637606218457222\n",
      "Epoch 278, Loss: 0.03182665631175041, Final Batch Loss: 0.02106454037129879\n",
      "Epoch 279, Loss: 0.015248441603034735, Final Batch Loss: 0.005505954381078482\n",
      "Epoch 280, Loss: 0.04787508212029934, Final Batch Loss: 0.02316662110388279\n",
      "Epoch 281, Loss: 0.0251086987555027, Final Batch Loss: 0.012138302437961102\n",
      "Epoch 282, Loss: 0.018628501798957586, Final Batch Loss: 0.0077157155610620975\n",
      "Epoch 283, Loss: 0.02021745778620243, Final Batch Loss: 0.00992504321038723\n",
      "Epoch 284, Loss: 0.044522788375616074, Final Batch Loss: 0.019391588866710663\n",
      "Epoch 285, Loss: 0.008974005002528429, Final Batch Loss: 0.00393797317519784\n",
      "Epoch 286, Loss: 0.028659219853579998, Final Batch Loss: 0.018200553953647614\n",
      "Epoch 287, Loss: 0.05954471789300442, Final Batch Loss: 0.031217940151691437\n",
      "Epoch 288, Loss: 0.020087329670786858, Final Batch Loss: 0.011396000161767006\n",
      "Epoch 289, Loss: 0.017885610926896334, Final Batch Loss: 0.004994145128875971\n",
      "Epoch 290, Loss: 0.028654263354837894, Final Batch Loss: 0.01159654650837183\n",
      "Epoch 291, Loss: 0.013273169752210379, Final Batch Loss: 0.004933524411171675\n",
      "Epoch 292, Loss: 0.028058873023837805, Final Batch Loss: 0.004108877386897802\n",
      "Epoch 293, Loss: 0.01862493483349681, Final Batch Loss: 0.0038693812675774097\n",
      "Epoch 294, Loss: 0.03010046947747469, Final Batch Loss: 0.010011767037212849\n",
      "Epoch 295, Loss: 0.015249752206727862, Final Batch Loss: 0.003297781338915229\n",
      "Epoch 296, Loss: 0.0180756370536983, Final Batch Loss: 0.006365578155964613\n",
      "Epoch 297, Loss: 0.018299059942364693, Final Batch Loss: 0.0018832571804523468\n",
      "Epoch 298, Loss: 0.008702019229531288, Final Batch Loss: 0.0038318089209496975\n",
      "Epoch 299, Loss: 0.027941839303821325, Final Batch Loss: 0.005682218354195356\n",
      "Epoch 300, Loss: 0.045651750639081, Final Batch Loss: 0.02325725182890892\n",
      "Epoch 301, Loss: 0.0343560129404068, Final Batch Loss: 0.010502684861421585\n",
      "Epoch 302, Loss: 0.016118239611387253, Final Batch Loss: 0.011922270059585571\n",
      "Epoch 303, Loss: 0.02843612525612116, Final Batch Loss: 0.01387816946953535\n",
      "Epoch 304, Loss: 0.1208760254085064, Final Batch Loss: 0.07490413635969162\n",
      "Epoch 305, Loss: 0.03320080600678921, Final Batch Loss: 0.01846173033118248\n",
      "Epoch 306, Loss: 0.01574090402573347, Final Batch Loss: 0.009013624861836433\n",
      "Epoch 307, Loss: 0.021376057527959347, Final Batch Loss: 0.010016116313636303\n",
      "Epoch 308, Loss: 0.015554094454273582, Final Batch Loss: 0.002897250233218074\n",
      "Epoch 309, Loss: 0.03581884503364563, Final Batch Loss: 0.025955799967050552\n",
      "Epoch 310, Loss: 0.014768414897844195, Final Batch Loss: 0.0029035701882094145\n",
      "Epoch 311, Loss: 0.06341811083257198, Final Batch Loss: 0.013868877664208412\n",
      "Epoch 312, Loss: 0.01955330651253462, Final Batch Loss: 0.00636599026620388\n",
      "Epoch 313, Loss: 0.011887823697179556, Final Batch Loss: 0.006844891235232353\n",
      "Epoch 314, Loss: 0.025743454229086637, Final Batch Loss: 0.018450189381837845\n",
      "Epoch 315, Loss: 0.021345566026866436, Final Batch Loss: 0.005979576148092747\n",
      "Epoch 316, Loss: 0.030199989210814238, Final Batch Loss: 0.007744023110717535\n",
      "Epoch 317, Loss: 0.029374289326369762, Final Batch Loss: 0.007910472340881824\n",
      "Epoch 318, Loss: 0.021034675650298595, Final Batch Loss: 0.009894920513033867\n",
      "Epoch 319, Loss: 0.01671503158286214, Final Batch Loss: 0.0022724061273038387\n",
      "Epoch 320, Loss: 0.042135538533329964, Final Batch Loss: 0.03363771364092827\n",
      "Epoch 321, Loss: 0.012538121081888676, Final Batch Loss: 0.004701620899140835\n",
      "Epoch 322, Loss: 0.040717728435993195, Final Batch Loss: 0.021632498130202293\n",
      "Epoch 323, Loss: 0.014108279719948769, Final Batch Loss: 0.002998020499944687\n",
      "Epoch 324, Loss: 0.02238330338150263, Final Batch Loss: 0.009104691445827484\n",
      "Epoch 325, Loss: 0.019580508582293987, Final Batch Loss: 0.016031257808208466\n",
      "Epoch 326, Loss: 0.02371722087264061, Final Batch Loss: 0.015318406745791435\n",
      "Epoch 327, Loss: 0.015965084545314312, Final Batch Loss: 0.01179225742816925\n",
      "Epoch 328, Loss: 0.044917880557477474, Final Batch Loss: 0.011356293223798275\n",
      "Epoch 329, Loss: 0.050105830654501915, Final Batch Loss: 0.037533748894929886\n",
      "Epoch 330, Loss: 0.016213782597333193, Final Batch Loss: 0.004366906825453043\n",
      "Epoch 331, Loss: 0.01100970059633255, Final Batch Loss: 0.004805046133697033\n",
      "Epoch 332, Loss: 0.01534743804950267, Final Batch Loss: 0.000977249932475388\n",
      "Epoch 333, Loss: 0.014679845422506332, Final Batch Loss: 0.00233566015958786\n",
      "Epoch 334, Loss: 0.0221273151692003, Final Batch Loss: 0.0032908262219280005\n",
      "Epoch 335, Loss: 0.014776092022657394, Final Batch Loss: 0.00753907160833478\n",
      "Epoch 336, Loss: 0.008072775788605213, Final Batch Loss: 0.004687210079282522\n",
      "Epoch 337, Loss: 0.022057298570871353, Final Batch Loss: 0.01704264059662819\n",
      "Epoch 338, Loss: 0.028302442282438278, Final Batch Loss: 0.009347902610898018\n",
      "Epoch 339, Loss: 0.048510560765862465, Final Batch Loss: 0.009845668449997902\n",
      "Epoch 340, Loss: 0.019886326044797897, Final Batch Loss: 0.010685553774237633\n",
      "Epoch 341, Loss: 0.022025765385478735, Final Batch Loss: 0.007232638541609049\n",
      "Epoch 342, Loss: 0.02121701557189226, Final Batch Loss: 0.004923001863062382\n",
      "Epoch 343, Loss: 0.009130356134846807, Final Batch Loss: 0.0027950184885412455\n",
      "Epoch 344, Loss: 0.011935950955376029, Final Batch Loss: 0.009342149831354618\n",
      "Epoch 345, Loss: 0.022430118639022112, Final Batch Loss: 0.006158426869660616\n",
      "Epoch 346, Loss: 0.02533651515841484, Final Batch Loss: 0.017980331555008888\n",
      "Epoch 347, Loss: 0.03481533844023943, Final Batch Loss: 0.027104225009679794\n",
      "Epoch 348, Loss: 0.01275433273985982, Final Batch Loss: 0.0065845949575304985\n",
      "Epoch 349, Loss: 0.029339903965592384, Final Batch Loss: 0.020174136385321617\n",
      "Epoch 350, Loss: 0.016313290689140558, Final Batch Loss: 0.010335301980376244\n",
      "Epoch 351, Loss: 0.019753092899918556, Final Batch Loss: 0.013479656539857388\n",
      "Epoch 352, Loss: 0.020778929349035025, Final Batch Loss: 0.0032048127613961697\n",
      "Epoch 353, Loss: 0.028174922335892916, Final Batch Loss: 0.02108209952712059\n",
      "Epoch 354, Loss: 0.015539183281362057, Final Batch Loss: 0.0031204791739583015\n",
      "Epoch 355, Loss: 0.034284320659935474, Final Batch Loss: 0.012170909903943539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356, Loss: 0.020117991138249636, Final Batch Loss: 0.005880130920559168\n",
      "Epoch 357, Loss: 0.02122434601187706, Final Batch Loss: 0.010101264342665672\n",
      "Epoch 358, Loss: 0.008045877795666456, Final Batch Loss: 0.004076138138771057\n",
      "Epoch 359, Loss: 0.014229545835405588, Final Batch Loss: 0.006660807877779007\n",
      "Epoch 360, Loss: 0.019832012243568897, Final Batch Loss: 0.005914708599448204\n",
      "Epoch 361, Loss: 0.014599462039768696, Final Batch Loss: 0.007982156239449978\n",
      "Epoch 362, Loss: 0.016762531828135252, Final Batch Loss: 0.009371016174554825\n",
      "Epoch 363, Loss: 0.027204247191548347, Final Batch Loss: 0.008006962016224861\n",
      "Epoch 364, Loss: 0.021851921454072, Final Batch Loss: 0.01210856530815363\n",
      "Epoch 365, Loss: 0.007363150827586651, Final Batch Loss: 0.0014961794950067997\n",
      "Epoch 366, Loss: 0.019608677364885807, Final Batch Loss: 0.009260621853172779\n",
      "Epoch 367, Loss: 0.016608477802947164, Final Batch Loss: 0.012901762500405312\n",
      "Epoch 368, Loss: 0.009431857615709305, Final Batch Loss: 0.004261791240423918\n",
      "Epoch 369, Loss: 0.032541988883167505, Final Batch Loss: 0.0023078271187841892\n",
      "Epoch 370, Loss: 0.048568269703537226, Final Batch Loss: 0.043169621378183365\n",
      "Epoch 371, Loss: 0.009454127168282866, Final Batch Loss: 0.00690188305452466\n",
      "Epoch 372, Loss: 0.018652469851076603, Final Batch Loss: 0.01168784499168396\n",
      "Epoch 373, Loss: 0.014202896738424897, Final Batch Loss: 0.0027800353709608316\n",
      "Epoch 374, Loss: 0.021673589013516903, Final Batch Loss: 0.005180935375392437\n",
      "Epoch 375, Loss: 0.04538428224623203, Final Batch Loss: 0.009916285052895546\n",
      "Epoch 376, Loss: 0.015086766332387924, Final Batch Loss: 0.009475239552557468\n",
      "Epoch 377, Loss: 0.007291624671779573, Final Batch Loss: 0.0017579722916707397\n",
      "Epoch 378, Loss: 0.027213886380195618, Final Batch Loss: 0.0102592334151268\n",
      "Epoch 379, Loss: 0.011984047945588827, Final Batch Loss: 0.0026408364064991474\n",
      "Epoch 380, Loss: 0.020572937093675137, Final Batch Loss: 0.010498050600290298\n",
      "Epoch 381, Loss: 0.030530447140336037, Final Batch Loss: 0.013087432831525803\n",
      "Epoch 382, Loss: 0.02620000671595335, Final Batch Loss: 0.0072884755209088326\n",
      "Epoch 383, Loss: 0.017533570528030396, Final Batch Loss: 0.005122970789670944\n",
      "Epoch 384, Loss: 0.013691355474293232, Final Batch Loss: 0.004368648864328861\n",
      "Epoch 385, Loss: 0.008009119192138314, Final Batch Loss: 0.0038255939725786448\n",
      "Epoch 386, Loss: 0.02307890960946679, Final Batch Loss: 0.015666479244828224\n",
      "Epoch 387, Loss: 0.009205973939970136, Final Batch Loss: 0.002525139367207885\n",
      "Epoch 388, Loss: 0.026425152085721493, Final Batch Loss: 0.016818875446915627\n",
      "Epoch 389, Loss: 0.011434025131165981, Final Batch Loss: 0.004239242058247328\n",
      "Epoch 390, Loss: 0.005899726413190365, Final Batch Loss: 0.0033256711903959513\n",
      "Epoch 391, Loss: 0.013493956299498677, Final Batch Loss: 0.0033545310143381357\n",
      "Epoch 392, Loss: 0.016361108981072903, Final Batch Loss: 0.004944515414535999\n",
      "Epoch 393, Loss: 0.021653173491358757, Final Batch Loss: 0.011641176417469978\n",
      "Epoch 394, Loss: 0.008544478449039161, Final Batch Loss: 0.0014171976363286376\n",
      "Epoch 395, Loss: 0.01690561743453145, Final Batch Loss: 0.005582290235906839\n",
      "Epoch 396, Loss: 0.003977420390583575, Final Batch Loss: 0.002055695978924632\n",
      "Epoch 397, Loss: 0.037119623040780425, Final Batch Loss: 0.0339772030711174\n",
      "Epoch 398, Loss: 0.053282337612472475, Final Batch Loss: 0.05133409798145294\n",
      "Epoch 399, Loss: 0.029207357205450535, Final Batch Loss: 0.009316747076809406\n",
      "Epoch 400, Loss: 0.027567106299102306, Final Batch Loss: 0.02268262952566147\n",
      "Epoch 401, Loss: 0.022366186836734414, Final Batch Loss: 0.003197986865416169\n",
      "Epoch 402, Loss: 0.00810308288782835, Final Batch Loss: 0.003872559405863285\n",
      "Epoch 403, Loss: 0.01873642299324274, Final Batch Loss: 0.00587763637304306\n",
      "Epoch 404, Loss: 0.022223645821213722, Final Batch Loss: 0.014504692517220974\n",
      "Epoch 405, Loss: 0.011400683550164104, Final Batch Loss: 0.008531552739441395\n",
      "Epoch 406, Loss: 0.022897126153111458, Final Batch Loss: 0.0097462497651577\n",
      "Epoch 407, Loss: 0.016659962944686413, Final Batch Loss: 0.010037040337920189\n",
      "Epoch 408, Loss: 0.006496803718619049, Final Batch Loss: 0.0012651298893615603\n",
      "Epoch 409, Loss: 0.009669605875387788, Final Batch Loss: 0.006163197569549084\n",
      "Epoch 410, Loss: 0.026285138446837664, Final Batch Loss: 0.005829243455082178\n",
      "Epoch 411, Loss: 0.014487175270915031, Final Batch Loss: 0.002121127210557461\n",
      "Epoch 412, Loss: 0.04659603349864483, Final Batch Loss: 0.020340189337730408\n",
      "Epoch 413, Loss: 0.016063084825873375, Final Batch Loss: 0.009221036918461323\n",
      "Epoch 414, Loss: 0.006090653710998595, Final Batch Loss: 0.0018645917298272252\n",
      "Epoch 415, Loss: 0.005942497286014259, Final Batch Loss: 0.001887864782474935\n",
      "Epoch 416, Loss: 0.009933691006153822, Final Batch Loss: 0.005848074331879616\n",
      "Epoch 417, Loss: 0.018609683495014906, Final Batch Loss: 0.0021467632614076138\n",
      "Epoch 418, Loss: 0.0068037305027246475, Final Batch Loss: 0.0035658751148730516\n",
      "Epoch 419, Loss: 0.006393061019480228, Final Batch Loss: 0.003406178206205368\n",
      "Epoch 420, Loss: 0.03136975783854723, Final Batch Loss: 0.01769097149372101\n",
      "Epoch 421, Loss: 0.02258530491963029, Final Batch Loss: 0.004380813334137201\n",
      "Epoch 422, Loss: 0.00904987845569849, Final Batch Loss: 0.0033099092543125153\n",
      "Epoch 423, Loss: 0.018225123640149832, Final Batch Loss: 0.004486622754484415\n",
      "Epoch 424, Loss: 0.00772774952929467, Final Batch Loss: 0.0013678389368578792\n",
      "Epoch 425, Loss: 0.013246287358924747, Final Batch Loss: 0.0027622112538665533\n",
      "Epoch 426, Loss: 0.04902969649992883, Final Batch Loss: 0.047175414860248566\n",
      "Epoch 427, Loss: 0.01285658311098814, Final Batch Loss: 0.005624019540846348\n",
      "Epoch 428, Loss: 0.012375612976029515, Final Batch Loss: 0.003318914445117116\n",
      "Epoch 429, Loss: 0.012546631041914225, Final Batch Loss: 0.008354529738426208\n",
      "Epoch 430, Loss: 0.01862654834985733, Final Batch Loss: 0.010685375891625881\n",
      "Epoch 431, Loss: 0.004338683269452304, Final Batch Loss: 0.0008786674006842077\n",
      "Epoch 432, Loss: 0.028142370283603668, Final Batch Loss: 0.012154117226600647\n",
      "Epoch 433, Loss: 0.01950154174119234, Final Batch Loss: 0.005354192107915878\n",
      "Epoch 434, Loss: 0.014154203585349023, Final Batch Loss: 0.0015012020012363791\n",
      "Epoch 435, Loss: 0.009827201720327139, Final Batch Loss: 0.0019849534146487713\n",
      "Epoch 436, Loss: 0.015016242396086454, Final Batch Loss: 0.0010833828710019588\n",
      "Epoch 437, Loss: 0.010712012415751815, Final Batch Loss: 0.007387514226138592\n",
      "Epoch 438, Loss: 0.01545471721328795, Final Batch Loss: 0.011637692339718342\n",
      "Epoch 439, Loss: 0.004469675448490307, Final Batch Loss: 0.00038195119122974575\n",
      "Epoch 440, Loss: 0.017640074249356985, Final Batch Loss: 0.011642624624073505\n",
      "Epoch 441, Loss: 0.008415469317696989, Final Batch Loss: 0.001776643912307918\n",
      "Epoch 442, Loss: 0.01567933289334178, Final Batch Loss: 0.0051341610960662365\n",
      "Epoch 443, Loss: 0.013949028449133039, Final Batch Loss: 0.0010841602925211191\n",
      "Epoch 444, Loss: 0.01091952295973897, Final Batch Loss: 0.0032216557301580906\n",
      "Epoch 445, Loss: 0.008807062171399593, Final Batch Loss: 0.001504626590758562\n",
      "Epoch 446, Loss: 0.013003328815102577, Final Batch Loss: 0.009741170331835747\n",
      "Epoch 447, Loss: 0.005370068596675992, Final Batch Loss: 0.002053156029433012\n",
      "Epoch 448, Loss: 0.005588281666859984, Final Batch Loss: 0.0034718732349574566\n",
      "Epoch 449, Loss: 0.01044727221596986, Final Batch Loss: 0.009425238706171513\n",
      "Epoch 450, Loss: 0.006201788550242782, Final Batch Loss: 0.004344624932855368\n",
      "Epoch 451, Loss: 0.017598274163901806, Final Batch Loss: 0.006473453715443611\n",
      "Epoch 452, Loss: 0.02504472469445318, Final Batch Loss: 0.023289769887924194\n",
      "Epoch 453, Loss: 0.005326956510543823, Final Batch Loss: 0.0032998810056596994\n",
      "Epoch 454, Loss: 0.007479859981685877, Final Batch Loss: 0.002239022869616747\n",
      "Epoch 455, Loss: 0.022895802278071642, Final Batch Loss: 0.01568090170621872\n",
      "Epoch 456, Loss: 0.02117971470579505, Final Batch Loss: 0.014661028981208801\n",
      "Epoch 457, Loss: 0.019232236314564943, Final Batch Loss: 0.01378466933965683\n",
      "Epoch 458, Loss: 0.0040310207405127585, Final Batch Loss: 0.0005286513478495181\n",
      "Epoch 459, Loss: 0.008335768012329936, Final Batch Loss: 0.0063726166263222694\n",
      "Epoch 460, Loss: 0.022409940604120493, Final Batch Loss: 0.007642758544534445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 461, Loss: 0.0037408642238005996, Final Batch Loss: 0.0026361949276179075\n",
      "Epoch 462, Loss: 0.00495286425575614, Final Batch Loss: 0.002533061197027564\n",
      "Epoch 463, Loss: 0.003113779763225466, Final Batch Loss: 0.0005915435613133013\n",
      "Epoch 464, Loss: 0.037800247548148036, Final Batch Loss: 0.0026177081745117903\n",
      "Epoch 465, Loss: 0.007996707456186414, Final Batch Loss: 0.004301914479583502\n",
      "Epoch 466, Loss: 0.01825262000784278, Final Batch Loss: 0.012459203600883484\n",
      "Epoch 467, Loss: 0.011660736985504627, Final Batch Loss: 0.009339706040918827\n",
      "Epoch 468, Loss: 0.010697151999920607, Final Batch Loss: 0.000520873349159956\n",
      "Epoch 469, Loss: 0.008292607148177922, Final Batch Loss: 0.0017693500267341733\n",
      "Epoch 470, Loss: 0.010951736010611057, Final Batch Loss: 0.004378385376185179\n",
      "Epoch 471, Loss: 0.003393750172108412, Final Batch Loss: 0.001453691627830267\n",
      "Epoch 472, Loss: 0.008698929334059358, Final Batch Loss: 0.0034540665801614523\n",
      "Epoch 473, Loss: 0.026902904151938856, Final Batch Loss: 0.0006921825697645545\n",
      "Epoch 474, Loss: 0.009552901145070791, Final Batch Loss: 0.0026257019490003586\n",
      "Epoch 475, Loss: 0.023369334870949388, Final Batch Loss: 0.02164512127637863\n",
      "Epoch 476, Loss: 0.003189019509591162, Final Batch Loss: 0.0016723473090678453\n",
      "Epoch 477, Loss: 0.02075782243628055, Final Batch Loss: 0.01911645196378231\n",
      "Epoch 478, Loss: 0.011911430861800909, Final Batch Loss: 0.005267597269266844\n",
      "Epoch 479, Loss: 0.005482129869051278, Final Batch Loss: 0.003606952028349042\n",
      "Epoch 480, Loss: 0.019380075857043266, Final Batch Loss: 0.010155987925827503\n",
      "Epoch 481, Loss: 0.0032711634412407875, Final Batch Loss: 0.0009341707918792963\n",
      "Epoch 482, Loss: 0.003970793331973255, Final Batch Loss: 0.0008534170920029283\n",
      "Epoch 483, Loss: 0.03880411013960838, Final Batch Loss: 0.014651309698820114\n",
      "Epoch 484, Loss: 0.02022721664980054, Final Batch Loss: 0.005419382359832525\n",
      "Epoch 485, Loss: 0.004583002766594291, Final Batch Loss: 0.002130611799657345\n",
      "Epoch 486, Loss: 0.00980464491294697, Final Batch Loss: 0.0006966724176891148\n",
      "Epoch 487, Loss: 0.009927481529302895, Final Batch Loss: 0.0010044194059446454\n",
      "Epoch 488, Loss: 0.004814326879568398, Final Batch Loss: 0.0007260098354890943\n",
      "Epoch 489, Loss: 0.00925422040745616, Final Batch Loss: 0.0069492412731051445\n",
      "Epoch 490, Loss: 0.004554204526357353, Final Batch Loss: 0.0013694720109924674\n",
      "Epoch 491, Loss: 0.007597413146868348, Final Batch Loss: 0.0020423869136720896\n",
      "Epoch 492, Loss: 0.00948359607718885, Final Batch Loss: 0.007054448127746582\n",
      "Epoch 493, Loss: 0.010024518589489162, Final Batch Loss: 0.008267661556601524\n",
      "Epoch 494, Loss: 0.015581783838570118, Final Batch Loss: 0.011066385544836521\n",
      "Epoch 495, Loss: 0.03242772538214922, Final Batch Loss: 0.02698660083115101\n",
      "Epoch 496, Loss: 0.003497950790915638, Final Batch Loss: 0.0025768449995666742\n",
      "Epoch 497, Loss: 0.01082965126261115, Final Batch Loss: 0.005948763340711594\n",
      "Epoch 498, Loss: 0.004405811661854386, Final Batch Loss: 0.0029716151766479015\n",
      "Epoch 499, Loss: 0.024457654682919383, Final Batch Loss: 0.0014266862999647856\n",
      "Epoch 500, Loss: 0.002938726102001965, Final Batch Loss: 0.0011471675243228674\n",
      "Epoch 501, Loss: 0.0031973401200957596, Final Batch Loss: 0.0009438747656531632\n",
      "Epoch 502, Loss: 0.005566114094108343, Final Batch Loss: 0.003945094533264637\n",
      "Epoch 503, Loss: 0.011441276874393225, Final Batch Loss: 0.006601857021450996\n",
      "Epoch 504, Loss: 0.007918829564005136, Final Batch Loss: 0.005411026068031788\n",
      "Epoch 505, Loss: 0.002915479359216988, Final Batch Loss: 0.0015686822589486837\n",
      "Epoch 506, Loss: 0.012687090085819364, Final Batch Loss: 0.0009775247890502214\n",
      "Epoch 507, Loss: 0.012147492729127407, Final Batch Loss: 0.010297022759914398\n",
      "Epoch 508, Loss: 0.02374460850842297, Final Batch Loss: 0.003698786022141576\n",
      "Epoch 509, Loss: 0.009437927277758718, Final Batch Loss: 0.002304638037458062\n",
      "Epoch 510, Loss: 0.0051031766925007105, Final Batch Loss: 0.001428511692211032\n",
      "Epoch 511, Loss: 0.004228775738738477, Final Batch Loss: 0.0017669774824753404\n",
      "Epoch 512, Loss: 0.014363923401106149, Final Batch Loss: 0.000905324995983392\n",
      "Epoch 513, Loss: 0.002387814922258258, Final Batch Loss: 0.0005637709982693195\n",
      "Epoch 514, Loss: 0.007636234280653298, Final Batch Loss: 0.0007752162637189031\n",
      "Epoch 515, Loss: 0.0037072787526994944, Final Batch Loss: 0.00231732870452106\n",
      "Epoch 516, Loss: 0.004788502585142851, Final Batch Loss: 0.0019215482752770185\n",
      "Epoch 517, Loss: 0.027330878539942205, Final Batch Loss: 0.025656871497631073\n",
      "Epoch 518, Loss: 0.006100617116317153, Final Batch Loss: 0.002118288306519389\n",
      "Epoch 519, Loss: 0.008029076707316563, Final Batch Loss: 0.0003283517144154757\n",
      "Epoch 520, Loss: 0.017078511649742723, Final Batch Loss: 0.014466251246631145\n",
      "Epoch 521, Loss: 0.004142471123486757, Final Batch Loss: 0.0014420500956475735\n",
      "Epoch 522, Loss: 0.004804390948265791, Final Batch Loss: 0.002843062160536647\n",
      "Epoch 523, Loss: 0.0033313335152342916, Final Batch Loss: 0.0014085271395742893\n",
      "Epoch 524, Loss: 0.018152316100895405, Final Batch Loss: 0.0158991739153862\n",
      "Epoch 525, Loss: 0.005899406387470663, Final Batch Loss: 0.0011337640462443233\n",
      "Epoch 526, Loss: 0.0035418972838670015, Final Batch Loss: 0.001005988335236907\n",
      "Epoch 527, Loss: 0.004231131286360323, Final Batch Loss: 0.001380341942422092\n",
      "Epoch 528, Loss: 0.0018207665416412055, Final Batch Loss: 0.0006094694253988564\n",
      "Epoch 529, Loss: 0.0033740681828930974, Final Batch Loss: 0.0015673417365178466\n",
      "Epoch 530, Loss: 0.007528051966801286, Final Batch Loss: 0.0018437143880873919\n",
      "Epoch 531, Loss: 0.0046186307445168495, Final Batch Loss: 0.001361469505354762\n",
      "Epoch 532, Loss: 0.013035616837441921, Final Batch Loss: 0.006660062354058027\n",
      "Epoch 533, Loss: 0.0046141521306708455, Final Batch Loss: 0.00034032680559903383\n",
      "Epoch 534, Loss: 0.0037727326271124184, Final Batch Loss: 0.0006717548822052777\n",
      "Epoch 535, Loss: 0.004231555270962417, Final Batch Loss: 0.002739987801760435\n",
      "Epoch 536, Loss: 0.0021883674198761582, Final Batch Loss: 0.0016361214220523834\n",
      "Epoch 537, Loss: 0.009042407153174281, Final Batch Loss: 0.0022233787458389997\n",
      "Epoch 538, Loss: 0.03336882754229009, Final Batch Loss: 0.03082169219851494\n",
      "Epoch 539, Loss: 0.029836513567715883, Final Batch Loss: 0.027291759848594666\n",
      "Epoch 540, Loss: 0.013400997151620686, Final Batch Loss: 0.011836047284305096\n",
      "Epoch 541, Loss: 0.004434840055182576, Final Batch Loss: 0.003971581347286701\n",
      "Epoch 542, Loss: 0.021886577480472624, Final Batch Loss: 0.020031845197081566\n",
      "Epoch 543, Loss: 0.00999796180985868, Final Batch Loss: 0.006519515998661518\n",
      "Epoch 544, Loss: 0.005815040552988648, Final Batch Loss: 0.004244503565132618\n",
      "Epoch 545, Loss: 0.006849776022136211, Final Batch Loss: 0.0036891296040266752\n",
      "Epoch 546, Loss: 0.002890106523409486, Final Batch Loss: 0.0023587606847286224\n",
      "Epoch 547, Loss: 0.0026391400024294853, Final Batch Loss: 0.0013053014408797026\n",
      "Epoch 548, Loss: 0.013360929675400257, Final Batch Loss: 0.008225989528000355\n",
      "Epoch 549, Loss: 0.002353018498979509, Final Batch Loss: 0.0010772626847028732\n",
      "Epoch 550, Loss: 0.028074761969037354, Final Batch Loss: 0.0012611189158633351\n",
      "Epoch 551, Loss: 0.011425759177654982, Final Batch Loss: 0.002386759500950575\n",
      "Epoch 552, Loss: 0.010201840661466122, Final Batch Loss: 0.0014828592538833618\n",
      "Epoch 553, Loss: 0.005500659346580505, Final Batch Loss: 0.002575539518147707\n",
      "Epoch 554, Loss: 0.031077802530489862, Final Batch Loss: 0.029283344745635986\n",
      "Epoch 555, Loss: 0.0025926517555490136, Final Batch Loss: 0.0010726174805313349\n",
      "Epoch 556, Loss: 0.014050445490283892, Final Batch Loss: 0.00025069338153116405\n",
      "Epoch 557, Loss: 0.0018898460839409381, Final Batch Loss: 0.00011125396122224629\n",
      "Epoch 558, Loss: 0.004176619462668896, Final Batch Loss: 0.0031069277320057154\n",
      "Epoch 559, Loss: 0.004666814114898443, Final Batch Loss: 0.002788977697491646\n",
      "Epoch 560, Loss: 0.002200881775934249, Final Batch Loss: 0.00062749587232247\n",
      "Epoch 561, Loss: 0.005182427121326327, Final Batch Loss: 0.0034431545063853264\n",
      "Epoch 562, Loss: 0.008447229978628457, Final Batch Loss: 0.0017976780654862523\n",
      "Epoch 563, Loss: 0.02442324161529541, Final Batch Loss: 0.014560758136212826\n",
      "Epoch 564, Loss: 0.006850892677903175, Final Batch Loss: 0.0018297950737178326\n",
      "Epoch 565, Loss: 0.002691053436137736, Final Batch Loss: 0.0007133075268939137\n",
      "Epoch 566, Loss: 0.011328394059091806, Final Batch Loss: 0.008690432645380497\n",
      "Epoch 567, Loss: 0.005738313542678952, Final Batch Loss: 0.002989349886775017\n",
      "Epoch 568, Loss: 0.006410007597878575, Final Batch Loss: 0.003867760067805648\n",
      "Epoch 569, Loss: 0.01545752413221635, Final Batch Loss: 0.00037168353446759284\n",
      "Epoch 570, Loss: 0.011523295368533581, Final Batch Loss: 0.0005407083663158119\n",
      "Epoch 571, Loss: 0.01137031870894134, Final Batch Loss: 0.00975794717669487\n",
      "Epoch 572, Loss: 0.0019869659445248544, Final Batch Loss: 0.0005881981342099607\n",
      "Epoch 573, Loss: 0.030748303048312664, Final Batch Loss: 0.025605568662285805\n",
      "Epoch 574, Loss: 0.00679976143874228, Final Batch Loss: 0.00501035712659359\n",
      "Epoch 575, Loss: 0.007926338585093617, Final Batch Loss: 0.003287212224677205\n",
      "Epoch 576, Loss: 0.011007943423464894, Final Batch Loss: 0.0022071118000894785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 577, Loss: 0.01380067243007943, Final Batch Loss: 0.0009552270057611167\n",
      "Epoch 578, Loss: 0.02411240991204977, Final Batch Loss: 0.007743620313704014\n",
      "Epoch 579, Loss: 0.0032997028320096433, Final Batch Loss: 0.0009246274712495506\n",
      "Epoch 580, Loss: 0.007648643106222153, Final Batch Loss: 0.005625919438898563\n",
      "Epoch 581, Loss: 0.021889722454943694, Final Batch Loss: 0.00021270338038448244\n",
      "Epoch 582, Loss: 0.00279952771961689, Final Batch Loss: 0.0013740886934101582\n",
      "Epoch 583, Loss: 0.028526077512651682, Final Batch Loss: 0.023407677188515663\n",
      "Epoch 584, Loss: 0.0026468904688954353, Final Batch Loss: 0.0013037798926234245\n",
      "Epoch 585, Loss: 0.0031700354302302003, Final Batch Loss: 0.0015350288012996316\n",
      "Epoch 586, Loss: 0.040185679914429784, Final Batch Loss: 0.002219313057139516\n",
      "Epoch 587, Loss: 0.007575983414426446, Final Batch Loss: 0.005341575480997562\n",
      "Epoch 588, Loss: 0.002849429816706106, Final Batch Loss: 0.00038279147702269256\n",
      "Epoch 589, Loss: 0.010574287036433816, Final Batch Loss: 0.0010250175837427378\n",
      "Epoch 590, Loss: 0.0067686522379517555, Final Batch Loss: 0.0015120063908398151\n",
      "Epoch 591, Loss: 0.004526306060142815, Final Batch Loss: 0.0011515672085806727\n",
      "Epoch 592, Loss: 0.011168481432832778, Final Batch Loss: 0.0007428197422996163\n",
      "Epoch 593, Loss: 0.004971061833202839, Final Batch Loss: 0.00396220525726676\n",
      "Epoch 594, Loss: 0.006159271113574505, Final Batch Loss: 0.0021168538369238377\n",
      "Epoch 595, Loss: 0.01891920797061175, Final Batch Loss: 0.01830463856458664\n",
      "Epoch 596, Loss: 0.00404842896386981, Final Batch Loss: 0.0009254501201212406\n",
      "Epoch 597, Loss: 0.00300028536003083, Final Batch Loss: 0.0010039607295766473\n",
      "Epoch 598, Loss: 0.004119447316043079, Final Batch Loss: 0.0022259382531046867\n",
      "Epoch 599, Loss: 0.005741128930822015, Final Batch Loss: 0.004637239035218954\n",
      "Epoch 600, Loss: 0.015816330444067717, Final Batch Loss: 0.010384418070316315\n",
      "Epoch 601, Loss: 0.032312734983861446, Final Batch Loss: 0.014018765650689602\n",
      "Epoch 602, Loss: 0.0068093056906946, Final Batch Loss: 0.00022754521341994405\n",
      "Epoch 603, Loss: 0.0055188334081321955, Final Batch Loss: 0.0007569270674139261\n",
      "Epoch 604, Loss: 0.002236287371488288, Final Batch Loss: 0.0004339975130278617\n",
      "Epoch 605, Loss: 0.0034980339696630836, Final Batch Loss: 0.0006491910899057984\n",
      "Epoch 606, Loss: 0.014305172022432089, Final Batch Loss: 0.005383276846259832\n",
      "Epoch 607, Loss: 0.003080688591580838, Final Batch Loss: 0.0007665950688533485\n",
      "Epoch 608, Loss: 0.003678370558191091, Final Batch Loss: 0.0027369086164981127\n",
      "Epoch 609, Loss: 0.03775868285447359, Final Batch Loss: 0.008971615694463253\n",
      "Epoch 610, Loss: 0.005910186795517802, Final Batch Loss: 0.001589419087395072\n",
      "Epoch 611, Loss: 0.012231658911332488, Final Batch Loss: 0.0011154056992381811\n",
      "Epoch 612, Loss: 0.00700632412917912, Final Batch Loss: 0.004399174824357033\n",
      "Epoch 613, Loss: 0.004908818751573563, Final Batch Loss: 0.0028168545104563236\n",
      "Epoch 614, Loss: 0.003163148183375597, Final Batch Loss: 0.0005768374539911747\n",
      "Epoch 615, Loss: 0.00446426949929446, Final Batch Loss: 0.002710911212489009\n",
      "Epoch 616, Loss: 0.0024369831662625074, Final Batch Loss: 0.0012131796684116125\n",
      "Epoch 617, Loss: 0.01675289496779442, Final Batch Loss: 0.010285904631018639\n",
      "Epoch 618, Loss: 0.009536376222968102, Final Batch Loss: 0.005602906458079815\n",
      "Epoch 619, Loss: 0.034701408352702856, Final Batch Loss: 0.02999468892812729\n",
      "Epoch 620, Loss: 0.004107038956135511, Final Batch Loss: 0.001858005067333579\n",
      "Epoch 621, Loss: 0.013468045508489013, Final Batch Loss: 0.0026084284763783216\n",
      "Epoch 622, Loss: 0.005960844224318862, Final Batch Loss: 0.002670732093974948\n",
      "Epoch 623, Loss: 0.006203097058460116, Final Batch Loss: 0.0022321848664432764\n",
      "Epoch 624, Loss: 0.002492578874807805, Final Batch Loss: 0.0018007629550993443\n",
      "Epoch 625, Loss: 0.008235471555963159, Final Batch Loss: 0.004630703944712877\n",
      "Epoch 626, Loss: 0.0033749539870768785, Final Batch Loss: 0.0009712229948490858\n",
      "Epoch 627, Loss: 0.008360314182937145, Final Batch Loss: 0.004090640693902969\n",
      "Epoch 628, Loss: 0.013581240753410384, Final Batch Loss: 0.00044978337245993316\n",
      "Epoch 629, Loss: 0.002075204043649137, Final Batch Loss: 0.0013392239343374968\n",
      "Epoch 630, Loss: 0.0035412543220445514, Final Batch Loss: 0.0006822090363129973\n",
      "Epoch 631, Loss: 0.005947847152128816, Final Batch Loss: 0.004624461755156517\n",
      "Epoch 632, Loss: 0.0057061053812503815, Final Batch Loss: 0.003197991754859686\n",
      "Epoch 633, Loss: 0.008463146223220974, Final Batch Loss: 0.007789139170199633\n",
      "Epoch 634, Loss: 0.0027233153814449906, Final Batch Loss: 0.0015221100766211748\n",
      "Epoch 635, Loss: 0.006333366502076387, Final Batch Loss: 0.0012462446466088295\n",
      "Epoch 636, Loss: 0.0036796506610699, Final Batch Loss: 0.0005850706365890801\n",
      "Epoch 637, Loss: 0.0010029856784967706, Final Batch Loss: 0.00019756918482016772\n",
      "Epoch 638, Loss: 0.012799745367374271, Final Batch Loss: 0.012118929997086525\n",
      "Epoch 639, Loss: 0.02375507995020598, Final Batch Loss: 0.0010599110973998904\n",
      "Epoch 640, Loss: 0.011738765984773636, Final Batch Loss: 0.002091069705784321\n",
      "Epoch 641, Loss: 0.002007623203098774, Final Batch Loss: 0.0010181214893236756\n",
      "Epoch 642, Loss: 0.006424316903576255, Final Batch Loss: 0.0018201775383204222\n",
      "Epoch 643, Loss: 0.0028216461651027203, Final Batch Loss: 0.0014217504067346454\n",
      "Epoch 644, Loss: 0.0030999339651316404, Final Batch Loss: 0.0016059745103120804\n",
      "Epoch 645, Loss: 0.0022839935263618827, Final Batch Loss: 0.0005225640488788486\n",
      "Epoch 646, Loss: 0.00573875242844224, Final Batch Loss: 0.0036123055033385754\n",
      "Epoch 647, Loss: 0.004144168924540281, Final Batch Loss: 0.00196225312538445\n",
      "Epoch 648, Loss: 0.0070305775152519345, Final Batch Loss: 0.0018145159119740129\n",
      "Epoch 649, Loss: 0.002931928844191134, Final Batch Loss: 0.0011586867040023208\n",
      "Epoch 650, Loss: 0.0037435097619891167, Final Batch Loss: 0.00218006270006299\n",
      "Epoch 651, Loss: 0.0037002259050495923, Final Batch Loss: 0.003119082422927022\n",
      "Epoch 652, Loss: 0.01580090099014342, Final Batch Loss: 0.002805279800668359\n",
      "Epoch 653, Loss: 0.0066307254892308265, Final Batch Loss: 0.006377335637807846\n",
      "Epoch 654, Loss: 0.0035627323668450117, Final Batch Loss: 0.002065008971840143\n",
      "Epoch 655, Loss: 0.004355013486929238, Final Batch Loss: 0.0032279163133352995\n",
      "Epoch 656, Loss: 0.008364909095689654, Final Batch Loss: 0.007511454168707132\n",
      "Epoch 657, Loss: 0.004717107804026455, Final Batch Loss: 0.0009496362763457\n",
      "Epoch 658, Loss: 0.009022664278745651, Final Batch Loss: 0.0044325594790279865\n",
      "Epoch 659, Loss: 0.003344109805766493, Final Batch Loss: 0.0008269085665233433\n",
      "Epoch 660, Loss: 0.005693369574146345, Final Batch Loss: 0.005375743843615055\n",
      "Epoch 661, Loss: 0.0014292526175267994, Final Batch Loss: 0.0004525703261606395\n",
      "Epoch 662, Loss: 0.026561797596514225, Final Batch Loss: 0.02000156231224537\n",
      "Epoch 663, Loss: 0.011189524317160249, Final Batch Loss: 0.008544466458261013\n",
      "Epoch 664, Loss: 0.006181496370118111, Final Batch Loss: 0.0005382832023315132\n",
      "Epoch 665, Loss: 0.003338997717946768, Final Batch Loss: 0.002541557652875781\n",
      "Epoch 666, Loss: 0.004485347133595496, Final Batch Loss: 0.0009372197673656046\n",
      "Epoch 667, Loss: 0.0030754614272154868, Final Batch Loss: 0.0024147711228579283\n",
      "Epoch 668, Loss: 0.0023504532873630524, Final Batch Loss: 0.001298495102673769\n",
      "Epoch 669, Loss: 0.004732172470539808, Final Batch Loss: 0.003626482794061303\n",
      "Epoch 670, Loss: 0.003279076947364956, Final Batch Loss: 0.0023726511280983686\n",
      "Epoch 671, Loss: 0.00562735740095377, Final Batch Loss: 0.0025796941481530666\n",
      "Epoch 672, Loss: 0.011362407240085304, Final Batch Loss: 0.010753465816378593\n",
      "Epoch 673, Loss: 0.0016224958817474544, Final Batch Loss: 0.0009888529311865568\n",
      "Epoch 674, Loss: 0.004183459212072194, Final Batch Loss: 0.0022403826005756855\n",
      "Epoch 675, Loss: 0.0072026061825454235, Final Batch Loss: 0.005732306744903326\n",
      "Epoch 676, Loss: 0.023348175454884768, Final Batch Loss: 0.018464192748069763\n",
      "Epoch 677, Loss: 0.005064414668595418, Final Batch Loss: 0.0003560845216270536\n",
      "Epoch 678, Loss: 0.0026539061218500137, Final Batch Loss: 0.001034989720210433\n",
      "Epoch 679, Loss: 0.0023765914083924145, Final Batch Loss: 0.00020181862055324018\n",
      "Epoch 680, Loss: 0.0019026848021894693, Final Batch Loss: 0.0006019691936671734\n",
      "Epoch 681, Loss: 0.0574599439278245, Final Batch Loss: 0.04947185888886452\n",
      "Epoch 682, Loss: 0.004586901632137597, Final Batch Loss: 0.0032017703633755445\n",
      "Epoch 683, Loss: 0.0008788714185357094, Final Batch Loss: 0.000367659202311188\n",
      "Epoch 684, Loss: 0.03279405419016257, Final Batch Loss: 0.0007789205410517752\n",
      "Epoch 685, Loss: 0.003768497728742659, Final Batch Loss: 0.0016515598399564624\n",
      "Epoch 686, Loss: 0.0017756917077349499, Final Batch Loss: 0.0015713738976046443\n",
      "Epoch 687, Loss: 0.006205755169503391, Final Batch Loss: 0.004561244510114193\n",
      "Epoch 688, Loss: 0.001601318537723273, Final Batch Loss: 0.0006889585056342185\n",
      "Epoch 689, Loss: 0.01803968334570527, Final Batch Loss: 0.0011314214207231998\n",
      "Epoch 690, Loss: 0.002090263878926635, Final Batch Loss: 0.0012210996355861425\n",
      "Epoch 691, Loss: 0.0018222565995529294, Final Batch Loss: 0.0003063655458390713\n",
      "Epoch 692, Loss: 0.006447137100622058, Final Batch Loss: 0.004597796592861414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 693, Loss: 0.002525517367757857, Final Batch Loss: 0.001001492259092629\n",
      "Epoch 694, Loss: 0.009951046609785408, Final Batch Loss: 0.009083529934287071\n",
      "Epoch 695, Loss: 0.0013823346816934645, Final Batch Loss: 0.0003158175968565047\n",
      "Epoch 696, Loss: 0.008460738463327289, Final Batch Loss: 0.002503457246348262\n",
      "Epoch 697, Loss: 0.006868063355796039, Final Batch Loss: 0.0018958681030198932\n",
      "Epoch 698, Loss: 0.001729640702251345, Final Batch Loss: 0.0012470316141843796\n",
      "Epoch 699, Loss: 0.012090669479221106, Final Batch Loss: 0.005683360155671835\n",
      "Epoch 700, Loss: 0.0017219929432030767, Final Batch Loss: 0.00024722781381569803\n",
      "Epoch 701, Loss: 0.008686409681104124, Final Batch Loss: 0.007697829511016607\n",
      "Epoch 702, Loss: 0.0030590182868763804, Final Batch Loss: 0.0007171932375058532\n",
      "Epoch 703, Loss: 0.006352659955155104, Final Batch Loss: 0.000599006365519017\n",
      "Epoch 704, Loss: 0.005707160220481455, Final Batch Loss: 0.0038824875373393297\n",
      "Epoch 705, Loss: 0.003906302736140788, Final Batch Loss: 0.0024059778079390526\n",
      "Epoch 706, Loss: 0.0021422840654850006, Final Batch Loss: 0.0007677425164729357\n",
      "Epoch 707, Loss: 0.00913069723173976, Final Batch Loss: 0.0028525404632091522\n",
      "Epoch 708, Loss: 0.0019705298909684643, Final Batch Loss: 0.00013047757965978235\n",
      "Epoch 709, Loss: 0.004461945034563541, Final Batch Loss: 0.003648411948233843\n",
      "Epoch 710, Loss: 0.004591204604366794, Final Batch Loss: 0.00030224063084460795\n",
      "Epoch 711, Loss: 0.004810811718925834, Final Batch Loss: 0.002782039577141404\n",
      "Epoch 712, Loss: 0.003614163550082594, Final Batch Loss: 0.0009743369300849736\n",
      "Epoch 713, Loss: 0.029028998804278672, Final Batch Loss: 0.028326859697699547\n",
      "Epoch 714, Loss: 0.007697651046328247, Final Batch Loss: 0.001709902542643249\n",
      "Epoch 715, Loss: 0.008601499488577247, Final Batch Loss: 0.0013604976702481508\n",
      "Epoch 716, Loss: 0.0015780855028424412, Final Batch Loss: 0.00014191647642292082\n",
      "Epoch 717, Loss: 0.002293484518304467, Final Batch Loss: 0.0012692518066614866\n",
      "Epoch 718, Loss: 0.006642987369559705, Final Batch Loss: 0.0052612763829529285\n",
      "Epoch 719, Loss: 0.0027479263371787965, Final Batch Loss: 0.0004189947503618896\n",
      "Epoch 720, Loss: 0.013790724682621658, Final Batch Loss: 0.0006766159785911441\n",
      "Epoch 721, Loss: 0.0028264144202694297, Final Batch Loss: 0.0016643324634060264\n",
      "Epoch 722, Loss: 0.0019946350366808474, Final Batch Loss: 0.0008453576010651886\n",
      "Epoch 723, Loss: 0.005548886489123106, Final Batch Loss: 0.001191744115203619\n",
      "Epoch 724, Loss: 0.0050352523976471275, Final Batch Loss: 0.0003139330947306007\n",
      "Epoch 725, Loss: 0.007824648986570537, Final Batch Loss: 0.0005334228044375777\n",
      "Epoch 726, Loss: 0.004204899712931365, Final Batch Loss: 0.0005391218583099544\n",
      "Epoch 727, Loss: 0.0030928667983971536, Final Batch Loss: 0.002394261071458459\n",
      "Epoch 728, Loss: 0.006468045990914106, Final Batch Loss: 0.002273558173328638\n",
      "Epoch 729, Loss: 0.005644574528560042, Final Batch Loss: 0.00303628365509212\n",
      "Epoch 730, Loss: 0.003745917580090463, Final Batch Loss: 0.0016689234180375934\n",
      "Epoch 731, Loss: 0.007385904958937317, Final Batch Loss: 0.007068844512104988\n",
      "Epoch 732, Loss: 0.0010917996987700462, Final Batch Loss: 0.0006720792734995484\n",
      "Epoch 733, Loss: 0.018552826019003987, Final Batch Loss: 0.0020124197471886873\n",
      "Epoch 734, Loss: 0.0028151198057457805, Final Batch Loss: 0.0012228903360664845\n",
      "Epoch 735, Loss: 0.0011985984165221453, Final Batch Loss: 0.0005774946184828877\n",
      "Epoch 736, Loss: 0.0035105752758681774, Final Batch Loss: 0.0010399785824120045\n",
      "Epoch 737, Loss: 0.011848770780488849, Final Batch Loss: 0.0034881995525211096\n",
      "Epoch 738, Loss: 0.009158756118267775, Final Batch Loss: 0.005954104475677013\n",
      "Epoch 739, Loss: 0.011711368570104241, Final Batch Loss: 0.010514257475733757\n",
      "Epoch 740, Loss: 0.002697307034395635, Final Batch Loss: 0.001546690589748323\n",
      "Epoch 741, Loss: 0.0021443015430122614, Final Batch Loss: 0.0012452766532078385\n",
      "Epoch 742, Loss: 0.0013393237022683024, Final Batch Loss: 0.0004871282144449651\n",
      "Epoch 743, Loss: 0.017236488114576787, Final Batch Loss: 0.0004373753326945007\n",
      "Epoch 744, Loss: 0.0014671707904199138, Final Batch Loss: 0.001245575724169612\n",
      "Epoch 745, Loss: 0.0008362373628187925, Final Batch Loss: 0.000513985229190439\n",
      "Epoch 746, Loss: 0.009422111790627241, Final Batch Loss: 0.007690786849707365\n",
      "Epoch 747, Loss: 0.0010169229644816369, Final Batch Loss: 0.0002880254469346255\n",
      "Epoch 748, Loss: 0.0018856451788451523, Final Batch Loss: 0.0014974025543779135\n",
      "Epoch 749, Loss: 0.001337364810751751, Final Batch Loss: 0.0004818341985810548\n",
      "Epoch 750, Loss: 0.0011429096339270473, Final Batch Loss: 0.0002966892789117992\n",
      "Epoch 751, Loss: 0.0033285487443208694, Final Batch Loss: 0.0014195824041962624\n",
      "Epoch 752, Loss: 0.002746670041233301, Final Batch Loss: 0.0012503835605457425\n",
      "Epoch 753, Loss: 0.00927235088602174, Final Batch Loss: 0.00908881239593029\n",
      "Epoch 754, Loss: 0.0031282170093618333, Final Batch Loss: 0.0005195123958401382\n",
      "Epoch 755, Loss: 0.0018153215642087162, Final Batch Loss: 0.0013008484384045005\n",
      "Epoch 756, Loss: 0.0005339256604202092, Final Batch Loss: 0.0003348820027895272\n",
      "Epoch 757, Loss: 0.0015451497456524521, Final Batch Loss: 0.00040152916335500777\n",
      "Epoch 758, Loss: 0.0006014603713992983, Final Batch Loss: 0.0002763352822512388\n",
      "Epoch 759, Loss: 0.0015884048189036548, Final Batch Loss: 0.0005369755090214312\n",
      "Epoch 760, Loss: 0.008193047542590648, Final Batch Loss: 0.007478892337530851\n",
      "Epoch 761, Loss: 0.0005551209760596976, Final Batch Loss: 0.00013693726214114577\n",
      "Epoch 762, Loss: 0.012187016196548939, Final Batch Loss: 0.006522841285914183\n",
      "Epoch 763, Loss: 0.004860054832533933, Final Batch Loss: 0.00024244481755886227\n",
      "Epoch 764, Loss: 0.008767364779487252, Final Batch Loss: 0.0017211318481713533\n",
      "Epoch 765, Loss: 0.0009155041916528717, Final Batch Loss: 0.00015424583398271352\n",
      "Epoch 766, Loss: 0.0031625059637008235, Final Batch Loss: 0.00020596470858436078\n",
      "Epoch 767, Loss: 0.01300155691569671, Final Batch Loss: 0.012312530539929867\n",
      "Epoch 768, Loss: 0.015537896018940955, Final Batch Loss: 0.0004990294692106545\n",
      "Epoch 769, Loss: 0.01966631697723642, Final Batch Loss: 0.0007924596429802477\n",
      "Epoch 770, Loss: 0.015040673315525055, Final Batch Loss: 0.01081439945846796\n",
      "Epoch 771, Loss: 0.0029472839669324458, Final Batch Loss: 0.002581164939329028\n",
      "Epoch 772, Loss: 0.002603866480058059, Final Batch Loss: 0.0004838382301386446\n",
      "Epoch 773, Loss: 0.009232549753505737, Final Batch Loss: 0.008721524849534035\n",
      "Epoch 774, Loss: 0.011460353620350361, Final Batch Loss: 0.0010020555928349495\n",
      "Epoch 775, Loss: 0.016046475619077682, Final Batch Loss: 0.012886020354926586\n",
      "Epoch 776, Loss: 0.01629766629775986, Final Batch Loss: 0.0008393041207455099\n",
      "Epoch 777, Loss: 0.0035443187225610018, Final Batch Loss: 0.002702143741771579\n",
      "Epoch 778, Loss: 0.004058055288624018, Final Batch Loss: 0.0009199277847073972\n",
      "Epoch 779, Loss: 0.001123066176660359, Final Batch Loss: 0.0005502530257217586\n",
      "Epoch 780, Loss: 0.0024561324971728027, Final Batch Loss: 0.0018663753289729357\n",
      "Epoch 781, Loss: 0.0027817118098028004, Final Batch Loss: 0.0009249260765500367\n",
      "Epoch 782, Loss: 0.01343513437313959, Final Batch Loss: 0.0006559516186825931\n",
      "Epoch 783, Loss: 0.0014317490858957171, Final Batch Loss: 0.0006710010347887874\n",
      "Epoch 784, Loss: 0.004671839764341712, Final Batch Loss: 0.003978854976594448\n",
      "Epoch 785, Loss: 0.0004182677948847413, Final Batch Loss: 0.00010998384095728397\n",
      "Epoch 786, Loss: 0.001627161167562008, Final Batch Loss: 0.00029895512852817774\n",
      "Epoch 787, Loss: 0.007422447786666453, Final Batch Loss: 0.0064399586990475655\n",
      "Epoch 788, Loss: 0.0018770349852275103, Final Batch Loss: 0.0001849218679126352\n",
      "Epoch 789, Loss: 0.0013996362686157227, Final Batch Loss: 0.0006098811281844974\n",
      "Epoch 790, Loss: 0.0011542864958755672, Final Batch Loss: 0.0002714437432587147\n",
      "Epoch 791, Loss: 0.03154858632478863, Final Batch Loss: 0.001149707124568522\n",
      "Epoch 792, Loss: 0.0008300403860630468, Final Batch Loss: 0.00013769221550319344\n",
      "Epoch 793, Loss: 0.003402146801818162, Final Batch Loss: 0.0030270067509263754\n",
      "Epoch 794, Loss: 0.0017233658581972122, Final Batch Loss: 0.0013716684188693762\n",
      "Epoch 795, Loss: 0.011280567850917578, Final Batch Loss: 0.005824001040309668\n",
      "Epoch 796, Loss: 0.001969898192328401, Final Batch Loss: 0.0017534714424982667\n",
      "Epoch 797, Loss: 0.0012268194986972958, Final Batch Loss: 0.0004600835090968758\n",
      "Epoch 798, Loss: 0.002628372749313712, Final Batch Loss: 0.002170829800888896\n",
      "Epoch 799, Loss: 0.004515748005360365, Final Batch Loss: 0.0021619871258735657\n",
      "Epoch 800, Loss: 0.005195138277485967, Final Batch Loss: 0.003051215782761574\n",
      "Epoch 801, Loss: 0.015281387371942401, Final Batch Loss: 0.003851921996101737\n",
      "Epoch 802, Loss: 0.005672021332429722, Final Batch Loss: 0.005206543020904064\n",
      "Epoch 803, Loss: 0.009901592653477564, Final Batch Loss: 0.009538616985082626\n",
      "Epoch 804, Loss: 0.03964158892631531, Final Batch Loss: 0.037449467927217484\n",
      "Epoch 805, Loss: 0.020469767856411636, Final Batch Loss: 0.019461916759610176\n",
      "Epoch 806, Loss: 0.0008572012011427432, Final Batch Loss: 0.00028069576364941895\n",
      "Epoch 807, Loss: 0.0051841086824424565, Final Batch Loss: 0.0005195460398681462\n",
      "Epoch 808, Loss: 0.007891687157098204, Final Batch Loss: 0.0072191013023257256\n",
      "Epoch 809, Loss: 0.001782141043804586, Final Batch Loss: 0.0008108209003694355\n",
      "Epoch 810, Loss: 0.002035179699305445, Final Batch Loss: 0.0005497376550920308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 811, Loss: 0.006041752872988582, Final Batch Loss: 0.0034461794421076775\n",
      "Epoch 812, Loss: 0.003229630645364523, Final Batch Loss: 0.0020019011572003365\n",
      "Epoch 813, Loss: 0.0028965158853679895, Final Batch Loss: 0.00101316103246063\n",
      "Epoch 814, Loss: 0.03615243046078831, Final Batch Loss: 0.0354851558804512\n",
      "Epoch 815, Loss: 0.0064671068685129285, Final Batch Loss: 0.000971107860095799\n",
      "Epoch 816, Loss: 0.0010466118801559787, Final Batch Loss: 6.021496301400475e-05\n",
      "Epoch 817, Loss: 0.0032763450872153044, Final Batch Loss: 0.0015037835109978914\n",
      "Epoch 818, Loss: 0.002636049292050302, Final Batch Loss: 0.0021260089706629515\n",
      "Epoch 819, Loss: 0.0048946723400149494, Final Batch Loss: 0.00036546113551594317\n",
      "Epoch 820, Loss: 0.006246071076020598, Final Batch Loss: 0.0007290088105946779\n",
      "Epoch 821, Loss: 0.00164440119988285, Final Batch Loss: 0.00019549365970306098\n",
      "Epoch 822, Loss: 0.012064222799381241, Final Batch Loss: 0.0004409054236020893\n",
      "Epoch 823, Loss: 0.0022312792134471238, Final Batch Loss: 0.0008911281474865973\n",
      "Epoch 824, Loss: 0.013281808962346986, Final Batch Loss: 0.01303535420447588\n",
      "Epoch 825, Loss: 0.006732453126460314, Final Batch Loss: 0.0033806527499109507\n",
      "Epoch 826, Loss: 0.0008148195629473776, Final Batch Loss: 0.0003164295048918575\n",
      "Epoch 827, Loss: 0.00138730340404436, Final Batch Loss: 0.0007781042950227857\n",
      "Epoch 828, Loss: 0.0030643314821645617, Final Batch Loss: 0.0023727549705654383\n",
      "Epoch 829, Loss: 0.0033766363631002605, Final Batch Loss: 0.000555139675270766\n",
      "Epoch 830, Loss: 0.0025960589991882443, Final Batch Loss: 0.001152500626631081\n",
      "Epoch 831, Loss: 0.0024587768130004406, Final Batch Loss: 0.001154335681349039\n",
      "Epoch 832, Loss: 0.004154523951001465, Final Batch Loss: 0.0018029302591457963\n",
      "Epoch 833, Loss: 0.014064278802834451, Final Batch Loss: 0.0009019965073093772\n",
      "Epoch 834, Loss: 0.004452876979485154, Final Batch Loss: 0.0011567077599465847\n",
      "Epoch 835, Loss: 0.005823603365570307, Final Batch Loss: 0.0006410004571080208\n",
      "Epoch 836, Loss: 0.017941958969458938, Final Batch Loss: 0.001293267821893096\n",
      "Epoch 837, Loss: 0.004110758236492984, Final Batch Loss: 5.8468940551392734e-05\n",
      "Epoch 838, Loss: 0.0060653595719486475, Final Batch Loss: 0.002345654647797346\n",
      "Epoch 839, Loss: 0.004676634562201798, Final Batch Loss: 0.003206823952496052\n",
      "Epoch 840, Loss: 0.0024413117789663374, Final Batch Loss: 0.0006709714070893824\n",
      "Epoch 841, Loss: 0.003852643771097064, Final Batch Loss: 0.001548820175230503\n",
      "Epoch 842, Loss: 0.00870083854533732, Final Batch Loss: 0.005353277083486319\n",
      "Epoch 843, Loss: 0.0023755526344757527, Final Batch Loss: 0.0019181922543793917\n",
      "Epoch 844, Loss: 0.0011717727757059038, Final Batch Loss: 0.0005958823021501303\n",
      "Epoch 845, Loss: 0.002227756180218421, Final Batch Loss: 0.00012425192107912153\n",
      "Epoch 846, Loss: 0.010881489142775536, Final Batch Loss: 0.009188013151288033\n",
      "Epoch 847, Loss: 0.00304709339980036, Final Batch Loss: 0.0009174061706289649\n",
      "Epoch 848, Loss: 0.0018908670754171908, Final Batch Loss: 0.0008026327122934163\n",
      "Epoch 849, Loss: 0.014954522252082825, Final Batch Loss: 0.01195946428924799\n",
      "Epoch 850, Loss: 0.012792075634934008, Final Batch Loss: 0.01130696851760149\n",
      "Epoch 851, Loss: 0.0015222851652652025, Final Batch Loss: 0.000677751493640244\n",
      "Epoch 852, Loss: 0.0006571458143298514, Final Batch Loss: 9.272731404053047e-05\n",
      "Epoch 853, Loss: 0.012737756012938917, Final Batch Loss: 0.0006787193706259131\n",
      "Epoch 854, Loss: 0.0011629721848294139, Final Batch Loss: 0.00046599673805758357\n",
      "Epoch 855, Loss: 0.002692048001335934, Final Batch Loss: 0.002320402767509222\n",
      "Epoch 856, Loss: 0.0033008817117661238, Final Batch Loss: 0.002629075897857547\n",
      "Epoch 857, Loss: 0.0043195473263040185, Final Batch Loss: 0.0013366491766646504\n",
      "Epoch 858, Loss: 0.0043981996132060885, Final Batch Loss: 0.0009061376331374049\n",
      "Epoch 859, Loss: 0.0025649950257502496, Final Batch Loss: 0.0016603122930973768\n",
      "Epoch 860, Loss: 0.004394029034301639, Final Batch Loss: 0.00041932915337383747\n",
      "Epoch 861, Loss: 0.028020579979056492, Final Batch Loss: 0.000355633586877957\n",
      "Epoch 862, Loss: 0.0036617208388634026, Final Batch Loss: 0.003332120133563876\n",
      "Epoch 863, Loss: 0.0053790716920048, Final Batch Loss: 0.0028109403792768717\n",
      "Epoch 864, Loss: 0.0022701684501953423, Final Batch Loss: 0.0006819114205427468\n",
      "Epoch 865, Loss: 0.00979500135872513, Final Batch Loss: 0.00928847398608923\n",
      "Epoch 866, Loss: 0.0017156540998257697, Final Batch Loss: 0.0013134687906131148\n",
      "Epoch 867, Loss: 0.0006582320638699457, Final Batch Loss: 0.00019359045836608857\n",
      "Epoch 868, Loss: 0.008429630775935948, Final Batch Loss: 0.007066026795655489\n",
      "Epoch 869, Loss: 0.002217474451754242, Final Batch Loss: 0.001490571303293109\n",
      "Epoch 870, Loss: 0.004413913935422897, Final Batch Loss: 0.003848077729344368\n",
      "Epoch 871, Loss: 0.00041001800855156034, Final Batch Loss: 0.0002072974166367203\n",
      "Epoch 872, Loss: 0.0018543727055657655, Final Batch Loss: 0.0015438161790370941\n",
      "Epoch 873, Loss: 0.002942866209195927, Final Batch Loss: 0.0027977507561445236\n",
      "Epoch 874, Loss: 0.0012849592603743076, Final Batch Loss: 0.0003770001349039376\n",
      "Epoch 875, Loss: 0.013668007261003368, Final Batch Loss: 0.00016428348317276686\n",
      "Epoch 876, Loss: 0.0024961510207504034, Final Batch Loss: 0.001750083756633103\n",
      "Epoch 877, Loss: 0.0008835915068630129, Final Batch Loss: 0.00011480579269118607\n",
      "Epoch 878, Loss: 0.0127408925909549, Final Batch Loss: 0.011989781633019447\n",
      "Epoch 879, Loss: 0.0020964301365893334, Final Batch Loss: 0.001802576007321477\n",
      "Epoch 880, Loss: 0.0004552487953333184, Final Batch Loss: 0.00026742886984720826\n",
      "Epoch 881, Loss: 0.0013099315983708948, Final Batch Loss: 5.450038588605821e-05\n",
      "Epoch 882, Loss: 0.002321998996194452, Final Batch Loss: 0.0006895684055052698\n",
      "Epoch 883, Loss: 0.0018376490916125476, Final Batch Loss: 0.0011219611624255776\n",
      "Epoch 884, Loss: 0.0011399838549550623, Final Batch Loss: 0.00019250731565989554\n",
      "Epoch 885, Loss: 0.007999831344932318, Final Batch Loss: 0.0012901178561151028\n",
      "Epoch 886, Loss: 0.03798964305315167, Final Batch Loss: 6.551726255565882e-05\n",
      "Epoch 887, Loss: 0.00460351919173263, Final Batch Loss: 0.004318906459957361\n",
      "Epoch 888, Loss: 0.010084717680001631, Final Batch Loss: 0.00048013139166869223\n",
      "Epoch 889, Loss: 0.005167728289961815, Final Batch Loss: 0.0009859022684395313\n",
      "Epoch 890, Loss: 0.001748569804476574, Final Batch Loss: 0.0013944869861006737\n",
      "Epoch 891, Loss: 0.0023675140109844506, Final Batch Loss: 0.0016986904665827751\n",
      "Epoch 892, Loss: 0.0007540407823398709, Final Batch Loss: 0.0004494745808187872\n",
      "Epoch 893, Loss: 0.0002097407341352664, Final Batch Loss: 6.044784822734073e-05\n",
      "Epoch 894, Loss: 0.0014385756512638181, Final Batch Loss: 0.0001644717704039067\n",
      "Epoch 895, Loss: 0.011119359522126615, Final Batch Loss: 0.0010384641354903579\n",
      "Epoch 896, Loss: 0.007079837378114462, Final Batch Loss: 0.0022548926062881947\n",
      "Epoch 897, Loss: 0.0005114149826113135, Final Batch Loss: 0.0002860461827367544\n",
      "Epoch 898, Loss: 0.008266237331554294, Final Batch Loss: 0.006766103208065033\n",
      "Epoch 899, Loss: 0.004675684962421656, Final Batch Loss: 0.0024686791002750397\n",
      "Epoch 900, Loss: 0.0022237447556108236, Final Batch Loss: 0.0018065356416627765\n",
      "Epoch 901, Loss: 0.0004325337868067436, Final Batch Loss: 5.423794937087223e-05\n",
      "Epoch 902, Loss: 0.00841268408112228, Final Batch Loss: 0.00666106166318059\n",
      "Epoch 903, Loss: 0.0012356627266854048, Final Batch Loss: 0.0007512838928960264\n",
      "Epoch 904, Loss: 0.007930081221275032, Final Batch Loss: 0.0012352968333289027\n",
      "Epoch 905, Loss: 0.001421344408299774, Final Batch Loss: 0.00010694417869672179\n",
      "Epoch 906, Loss: 0.0005693198982044123, Final Batch Loss: 0.00044783353223465383\n",
      "Epoch 907, Loss: 0.0017056244250852615, Final Batch Loss: 0.0012673443416133523\n",
      "Epoch 908, Loss: 0.0004474576999200508, Final Batch Loss: 9.317767398897558e-05\n",
      "Epoch 909, Loss: 0.012324783951044083, Final Batch Loss: 0.007500678766518831\n",
      "Epoch 910, Loss: 0.0013781797606498003, Final Batch Loss: 0.0003419076092541218\n",
      "Epoch 911, Loss: 0.011809791903942823, Final Batch Loss: 0.008409935981035233\n",
      "Epoch 912, Loss: 0.001349255267996341, Final Batch Loss: 0.000712830456905067\n",
      "Epoch 913, Loss: 0.01738313934765756, Final Batch Loss: 0.00044647022150456905\n",
      "Epoch 914, Loss: 0.0015416088281199336, Final Batch Loss: 0.0005291410489007831\n",
      "Epoch 915, Loss: 0.0031423956097569317, Final Batch Loss: 0.0003339691029395908\n",
      "Epoch 916, Loss: 0.0010661126871127635, Final Batch Loss: 0.0002611488162074238\n",
      "Epoch 917, Loss: 0.0017973803915083408, Final Batch Loss: 0.0007280319696292281\n",
      "Epoch 918, Loss: 0.0006826944299973547, Final Batch Loss: 0.0001386836520396173\n",
      "Epoch 919, Loss: 0.009036823292262852, Final Batch Loss: 0.008071542717516422\n",
      "Epoch 920, Loss: 0.0010893159196712077, Final Batch Loss: 0.0007714114617556334\n",
      "Epoch 921, Loss: 0.002240237721707672, Final Batch Loss: 0.0008470223401673138\n",
      "Epoch 922, Loss: 0.002287725394126028, Final Batch Loss: 0.0013645708095282316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 923, Loss: 0.0013102886732667685, Final Batch Loss: 7.115339394658804e-05\n",
      "Epoch 924, Loss: 0.001151619479060173, Final Batch Loss: 0.0008156818221323192\n",
      "Epoch 925, Loss: 0.0044297854183241725, Final Batch Loss: 0.002835699124261737\n",
      "Epoch 926, Loss: 0.011071577318944037, Final Batch Loss: 0.00994071364402771\n",
      "Epoch 927, Loss: 0.0027960831066593528, Final Batch Loss: 0.0014123977161943913\n",
      "Epoch 928, Loss: 0.0014613632229156792, Final Batch Loss: 0.0005462908884510398\n",
      "Epoch 929, Loss: 0.0043268087320029736, Final Batch Loss: 0.0030101987067610025\n",
      "Epoch 930, Loss: 0.0012379988329485059, Final Batch Loss: 0.00015599897596985102\n",
      "Epoch 931, Loss: 0.0006267517601372674, Final Batch Loss: 0.00021439553529489785\n",
      "Epoch 932, Loss: 0.0010858243040274829, Final Batch Loss: 0.00027943364693783224\n",
      "Epoch 933, Loss: 0.004776711226440966, Final Batch Loss: 0.003890572115778923\n",
      "Epoch 934, Loss: 0.002151213731849566, Final Batch Loss: 0.00045747790136374533\n",
      "Epoch 935, Loss: 0.001127959112636745, Final Batch Loss: 0.0009394125663675368\n",
      "Epoch 936, Loss: 0.001049820304615423, Final Batch Loss: 0.0002005700080189854\n",
      "Epoch 937, Loss: 0.0003080470341956243, Final Batch Loss: 9.295968629885465e-05\n",
      "Epoch 938, Loss: 0.009330990695161745, Final Batch Loss: 0.009262735024094582\n",
      "Epoch 939, Loss: 0.03443583915941417, Final Batch Loss: 0.03329963982105255\n",
      "Epoch 940, Loss: 0.007243457832373679, Final Batch Loss: 0.0012141038896515965\n",
      "Epoch 941, Loss: 0.001335551671218127, Final Batch Loss: 0.0003699763328768313\n",
      "Epoch 942, Loss: 0.0018660351634025574, Final Batch Loss: 0.0005309452535584569\n",
      "Epoch 943, Loss: 0.0016469160618726164, Final Batch Loss: 0.00028358763665892184\n",
      "Epoch 944, Loss: 0.003489387090667151, Final Batch Loss: 0.00014199140423443168\n",
      "Epoch 945, Loss: 0.0023697298020124435, Final Batch Loss: 0.0010654402431100607\n",
      "Epoch 946, Loss: 0.03170377900823951, Final Batch Loss: 0.03089502453804016\n",
      "Epoch 947, Loss: 0.0015210050041787326, Final Batch Loss: 0.0007505741668865085\n",
      "Epoch 948, Loss: 0.028449186240322888, Final Batch Loss: 0.027006078511476517\n",
      "Epoch 949, Loss: 0.017333950265310705, Final Batch Loss: 0.0003932336112484336\n",
      "Epoch 950, Loss: 0.014581759460270405, Final Batch Loss: 0.0021277498453855515\n",
      "Epoch 951, Loss: 0.004041794803924859, Final Batch Loss: 0.0030327881686389446\n",
      "Epoch 952, Loss: 0.0049856630503199995, Final Batch Loss: 0.004416265524923801\n",
      "Epoch 953, Loss: 0.0010620073735481128, Final Batch Loss: 7.286235631909221e-05\n",
      "Epoch 954, Loss: 0.0035615620436146855, Final Batch Loss: 0.00032437441404908895\n",
      "Epoch 955, Loss: 0.004172566637862474, Final Batch Loss: 0.0005703040515072644\n",
      "Epoch 956, Loss: 0.006751715671271086, Final Batch Loss: 0.0005994746461510658\n",
      "Epoch 957, Loss: 0.0007690446509514004, Final Batch Loss: 0.0004311315715312958\n",
      "Epoch 958, Loss: 0.0005356290785130113, Final Batch Loss: 0.0003363582072779536\n",
      "Epoch 959, Loss: 0.008271732018329203, Final Batch Loss: 0.007525341585278511\n",
      "Epoch 960, Loss: 0.002743493125308305, Final Batch Loss: 0.0018890585051849484\n",
      "Epoch 961, Loss: 0.009052240988239646, Final Batch Loss: 0.003153950674459338\n",
      "Epoch 962, Loss: 0.0015184968942776322, Final Batch Loss: 0.0007347801001742482\n",
      "Epoch 963, Loss: 0.007595719362143427, Final Batch Loss: 0.006970617454499006\n",
      "Epoch 964, Loss: 0.004283878064597957, Final Batch Loss: 0.00011875764175783843\n",
      "Epoch 965, Loss: 0.0016846949001774192, Final Batch Loss: 0.0007896722527220845\n",
      "Epoch 966, Loss: 0.004287855583243072, Final Batch Loss: 0.0006076152203604579\n",
      "Epoch 967, Loss: 0.008646333124488592, Final Batch Loss: 0.007550301030278206\n",
      "Epoch 968, Loss: 0.0008189252694137394, Final Batch Loss: 0.0004577318031806499\n",
      "Epoch 969, Loss: 0.0007813011252437718, Final Batch Loss: 0.00011621160228969529\n",
      "Epoch 970, Loss: 0.0007070474384818226, Final Batch Loss: 0.00019527276162989438\n",
      "Epoch 971, Loss: 0.0013247556489659473, Final Batch Loss: 8.353269367944449e-05\n",
      "Epoch 972, Loss: 0.0006026436894899234, Final Batch Loss: 0.00023596662504132837\n",
      "Epoch 973, Loss: 0.0007145819836296141, Final Batch Loss: 0.000335043907398358\n",
      "Epoch 974, Loss: 0.0007509814604418352, Final Batch Loss: 0.0001278661220567301\n",
      "Epoch 975, Loss: 0.001320340670645237, Final Batch Loss: 0.0008404566324315965\n",
      "Epoch 976, Loss: 0.0020088640521862544, Final Batch Loss: 0.00010250564810121432\n",
      "Epoch 977, Loss: 0.0018700164509937167, Final Batch Loss: 0.0010962722590193152\n",
      "Epoch 978, Loss: 0.013018681842368096, Final Batch Loss: 0.0007176214712671936\n",
      "Epoch 979, Loss: 0.003875104244798422, Final Batch Loss: 0.00026387511752545834\n",
      "Epoch 980, Loss: 0.0008050764008658007, Final Batch Loss: 0.00016740262799430639\n",
      "Epoch 981, Loss: 0.0009273219839087687, Final Batch Loss: 6.712404865538701e-05\n",
      "Epoch 982, Loss: 0.005772205593530089, Final Batch Loss: 0.005479005165398121\n",
      "Epoch 983, Loss: 0.04070689284708351, Final Batch Loss: 0.040435854345560074\n",
      "Epoch 984, Loss: 0.003621632233262062, Final Batch Loss: 0.0020874664187431335\n",
      "Epoch 985, Loss: 0.010409027338027954, Final Batch Loss: 0.010022473521530628\n",
      "Epoch 986, Loss: 0.0015988360100891441, Final Batch Loss: 0.00044092079042457044\n",
      "Epoch 987, Loss: 0.001725960333715193, Final Batch Loss: 0.00020674247934948653\n",
      "Epoch 988, Loss: 0.0012798318057321012, Final Batch Loss: 0.00040769862243905663\n",
      "Epoch 989, Loss: 0.015735337510704994, Final Batch Loss: 0.0019759275019168854\n",
      "Epoch 990, Loss: 0.015437184600159526, Final Batch Loss: 0.01319284550845623\n",
      "Epoch 991, Loss: 0.012151552480645478, Final Batch Loss: 0.011305442079901695\n",
      "Epoch 992, Loss: 0.0019519462948665023, Final Batch Loss: 0.0011520362459123135\n",
      "Epoch 993, Loss: 0.001679535795119591, Final Batch Loss: 0.0001496107579441741\n",
      "Epoch 994, Loss: 0.022635606466792524, Final Batch Loss: 0.02244582772254944\n",
      "Epoch 995, Loss: 0.005598340532742441, Final Batch Loss: 0.005557173863053322\n",
      "Epoch 996, Loss: 0.02349142450839281, Final Batch Loss: 0.020855173468589783\n",
      "Epoch 997, Loss: 0.029701681691221893, Final Batch Loss: 0.02891905978322029\n",
      "Epoch 998, Loss: 0.0017353431903757155, Final Batch Loss: 0.0013213551137596369\n",
      "Epoch 999, Loss: 0.0063121730636339635, Final Batch Loss: 0.005951276049017906\n",
      "Epoch 1000, Loss: 0.002574439044110477, Final Batch Loss: 0.0011417670175433159\n",
      "Epoch 1001, Loss: 0.000408640771638602, Final Batch Loss: 7.402969640679657e-05\n",
      "Epoch 1002, Loss: 0.007480034022592008, Final Batch Loss: 0.001159254345111549\n",
      "Epoch 1003, Loss: 0.0073127353098243475, Final Batch Loss: 0.0006726135034114122\n",
      "Epoch 1004, Loss: 0.0016531444271095097, Final Batch Loss: 0.0009851012146100402\n",
      "Epoch 1005, Loss: 0.003852959256619215, Final Batch Loss: 0.002051194431260228\n",
      "Epoch 1006, Loss: 0.0008262465707957745, Final Batch Loss: 0.0002778851776383817\n",
      "Epoch 1007, Loss: 0.0007375613058684394, Final Batch Loss: 0.00021578562154900283\n",
      "Epoch 1008, Loss: 0.000951617636019364, Final Batch Loss: 0.00030043520382605493\n",
      "Epoch 1009, Loss: 0.002098355966154486, Final Batch Loss: 0.0012759576784446836\n",
      "Epoch 1010, Loss: 0.00421068693685811, Final Batch Loss: 0.00022105050447862595\n",
      "Epoch 1011, Loss: 0.002082293212879449, Final Batch Loss: 0.001174312550574541\n",
      "Epoch 1012, Loss: 0.00028947788814548403, Final Batch Loss: 0.00014073734928388149\n",
      "Epoch 1013, Loss: 0.01580324536189437, Final Batch Loss: 0.0004703463055193424\n",
      "Epoch 1014, Loss: 0.0011789847048930824, Final Batch Loss: 0.0009844382293522358\n",
      "Epoch 1015, Loss: 0.0034228250151500106, Final Batch Loss: 0.00026723567862063646\n",
      "Epoch 1016, Loss: 0.0016336705593857914, Final Batch Loss: 0.0011701899347826838\n",
      "Epoch 1017, Loss: 0.0020956782464054413, Final Batch Loss: 8.519751281710342e-05\n",
      "Epoch 1018, Loss: 0.0028704916912829503, Final Batch Loss: 0.00011412052845116705\n",
      "Epoch 1019, Loss: 0.0025411503738723695, Final Batch Loss: 0.0001608470338396728\n",
      "Epoch 1020, Loss: 0.0012199101620353758, Final Batch Loss: 0.0005574845708906651\n",
      "Epoch 1021, Loss: 0.00022566244297195226, Final Batch Loss: 0.00014484488929156214\n",
      "Epoch 1022, Loss: 0.0008716629818081856, Final Batch Loss: 0.0004977539065293968\n",
      "Epoch 1023, Loss: 0.01741907838732004, Final Batch Loss: 0.016841460019350052\n",
      "Epoch 1024, Loss: 0.002609204384498298, Final Batch Loss: 0.001532294088974595\n",
      "Epoch 1025, Loss: 0.0009613892179913819, Final Batch Loss: 0.0005668964004144073\n",
      "Epoch 1026, Loss: 0.00047965734847821295, Final Batch Loss: 7.763752364553511e-05\n",
      "Epoch 1027, Loss: 0.0009075237612705678, Final Batch Loss: 0.00039326815749518573\n",
      "Epoch 1028, Loss: 0.003888402832672, Final Batch Loss: 0.0001555026974529028\n",
      "Epoch 1029, Loss: 0.0010466199601069093, Final Batch Loss: 0.0004542212118394673\n",
      "Epoch 1030, Loss: 0.020386508549563587, Final Batch Loss: 0.0012118228478357196\n",
      "Epoch 1031, Loss: 0.001232622831594199, Final Batch Loss: 0.0010118000209331512\n",
      "Epoch 1032, Loss: 0.0018297089845873415, Final Batch Loss: 0.0015069195069372654\n",
      "Epoch 1033, Loss: 0.0014809853746555746, Final Batch Loss: 0.0013044847873970866\n",
      "Epoch 1034, Loss: 0.001502805098425597, Final Batch Loss: 5.2749470341950655e-05\n",
      "Epoch 1035, Loss: 0.03543977648951113, Final Batch Loss: 0.03233560174703598\n",
      "Epoch 1036, Loss: 0.0008960727282101288, Final Batch Loss: 0.00023858460190240294\n",
      "Epoch 1037, Loss: 0.0015374805079773068, Final Batch Loss: 0.0005195687990635633\n",
      "Epoch 1038, Loss: 0.008747784508159384, Final Batch Loss: 0.008445329032838345\n",
      "Epoch 1039, Loss: 0.002699787262827158, Final Batch Loss: 0.0014594733947888017\n",
      "Epoch 1040, Loss: 0.015655445167794824, Final Batch Loss: 0.015068812295794487\n",
      "Epoch 1041, Loss: 0.0038612603675574064, Final Batch Loss: 0.0013753771781921387\n",
      "Epoch 1042, Loss: 0.0026006498374044895, Final Batch Loss: 0.001579438685439527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1043, Loss: 0.0010314291284885257, Final Batch Loss: 0.0004268170159775764\n",
      "Epoch 1044, Loss: 0.005957671906799078, Final Batch Loss: 0.0007058745250105858\n",
      "Epoch 1045, Loss: 0.000321719198836945, Final Batch Loss: 0.00014543169527314603\n",
      "Epoch 1046, Loss: 0.0012788406456820667, Final Batch Loss: 0.0006653765449300408\n",
      "Epoch 1047, Loss: 0.0013362276222323999, Final Batch Loss: 0.0001752574316924438\n",
      "Epoch 1048, Loss: 0.011534264544025064, Final Batch Loss: 0.010072080418467522\n",
      "Epoch 1049, Loss: 0.006552795181050897, Final Batch Loss: 0.0021773611661046743\n",
      "Epoch 1050, Loss: 0.00477404217235744, Final Batch Loss: 0.001159856328740716\n",
      "Epoch 1051, Loss: 0.0028907773084938526, Final Batch Loss: 0.0014088209718465805\n",
      "Epoch 1052, Loss: 0.00044951702875550836, Final Batch Loss: 0.00027068512281402946\n",
      "Epoch 1053, Loss: 0.0024477327679051086, Final Batch Loss: 0.00015944083861541003\n",
      "Epoch 1054, Loss: 0.0014995791716501117, Final Batch Loss: 0.0006061869789846241\n",
      "Epoch 1055, Loss: 0.00463264505378902, Final Batch Loss: 0.0014067655429244041\n",
      "Epoch 1056, Loss: 0.0008868471486493945, Final Batch Loss: 0.00021730043226853013\n",
      "Epoch 1057, Loss: 0.0023898050712887198, Final Batch Loss: 0.0004052574804518372\n",
      "Epoch 1058, Loss: 0.004262105037923902, Final Batch Loss: 0.0006799927796237171\n",
      "Epoch 1059, Loss: 0.002862318971892819, Final Batch Loss: 0.0024020527489483356\n",
      "Epoch 1060, Loss: 0.002838492568116635, Final Batch Loss: 0.0008386109839193523\n",
      "Epoch 1061, Loss: 0.00040737671952228993, Final Batch Loss: 0.00021468856721185148\n",
      "Epoch 1062, Loss: 0.0012665065296459943, Final Batch Loss: 0.0008405917906202376\n",
      "Epoch 1063, Loss: 0.002447330334689468, Final Batch Loss: 0.0018769340822473168\n",
      "Epoch 1064, Loss: 0.016363854287192225, Final Batch Loss: 0.012503069825470448\n",
      "Epoch 1065, Loss: 0.0028736586100421846, Final Batch Loss: 0.002186712808907032\n",
      "Epoch 1066, Loss: 0.0041409789700992405, Final Batch Loss: 0.0037721337284892797\n",
      "Epoch 1067, Loss: 0.011723593983333558, Final Batch Loss: 0.011349198408424854\n",
      "Epoch 1068, Loss: 0.007139456341974437, Final Batch Loss: 0.006322209723293781\n",
      "Epoch 1069, Loss: 0.001427470317139523, Final Batch Loss: 4.431543129612692e-05\n",
      "Epoch 1070, Loss: 0.0008965175657067448, Final Batch Loss: 0.00011629893560893834\n",
      "Epoch 1071, Loss: 0.0011107616010122001, Final Batch Loss: 0.0005393116152845323\n",
      "Epoch 1072, Loss: 0.002346509718336165, Final Batch Loss: 0.001774090458638966\n",
      "Epoch 1073, Loss: 0.012805154081434011, Final Batch Loss: 0.007979469373822212\n",
      "Epoch 1074, Loss: 0.012843700093071675, Final Batch Loss: 5.0106053095078096e-05\n",
      "Epoch 1075, Loss: 0.0011551144998520613, Final Batch Loss: 0.00033935921965166926\n",
      "Epoch 1076, Loss: 0.002386512467637658, Final Batch Loss: 0.001522662932984531\n",
      "Epoch 1077, Loss: 0.002930599031969905, Final Batch Loss: 0.001279927440918982\n",
      "Epoch 1078, Loss: 0.0016665143193677068, Final Batch Loss: 0.00013549625873565674\n",
      "Epoch 1079, Loss: 0.0016300560091622174, Final Batch Loss: 0.0008659221930429339\n",
      "Epoch 1080, Loss: 0.000586972018936649, Final Batch Loss: 0.00028309080516919494\n",
      "Epoch 1081, Loss: 0.00038665234751533717, Final Batch Loss: 0.00015154309221543372\n",
      "Epoch 1082, Loss: 0.002173806249629706, Final Batch Loss: 0.001375876134261489\n",
      "Epoch 1083, Loss: 0.002964394341688603, Final Batch Loss: 0.002579743042588234\n",
      "Epoch 1084, Loss: 0.0010826156358234584, Final Batch Loss: 0.00033811700996011496\n",
      "Epoch 1085, Loss: 0.014410460367798805, Final Batch Loss: 0.006003214977681637\n",
      "Epoch 1086, Loss: 0.0006377444951795042, Final Batch Loss: 0.00022610279847867787\n",
      "Epoch 1087, Loss: 0.005202320346143097, Final Batch Loss: 0.0042496491223573685\n",
      "Epoch 1088, Loss: 0.0032856342586455867, Final Batch Loss: 0.0001880297641037032\n",
      "Epoch 1089, Loss: 0.004852569953072816, Final Batch Loss: 0.0005320541677065194\n",
      "Epoch 1090, Loss: 0.00288480322342366, Final Batch Loss: 0.0008843349060043693\n",
      "Epoch 1091, Loss: 0.00044496033660834655, Final Batch Loss: 0.00010522032243898138\n",
      "Epoch 1092, Loss: 0.0008458466327283531, Final Batch Loss: 0.0004919412895105779\n",
      "Epoch 1093, Loss: 0.0021962300525046885, Final Batch Loss: 0.0007859923061914742\n",
      "Epoch 1094, Loss: 0.0007388780650217086, Final Batch Loss: 0.0002689770481083542\n",
      "Epoch 1095, Loss: 0.0014194778050296009, Final Batch Loss: 0.0005016734357923269\n",
      "Epoch 1096, Loss: 0.001362671988317743, Final Batch Loss: 0.00025359485880471766\n",
      "Epoch 1097, Loss: 0.0007604472775710747, Final Batch Loss: 0.0005224047927185893\n",
      "Epoch 1098, Loss: 0.0025942908105207607, Final Batch Loss: 0.00021836352243553847\n",
      "Epoch 1099, Loss: 0.0013270391646074131, Final Batch Loss: 0.001139820902608335\n",
      "Epoch 1100, Loss: 0.0007933700835565105, Final Batch Loss: 7.38263624953106e-05\n",
      "Epoch 1101, Loss: 0.0029842971853213385, Final Batch Loss: 0.0001781193568604067\n",
      "Epoch 1102, Loss: 0.0005986627656966448, Final Batch Loss: 0.00039295453461818397\n",
      "Epoch 1103, Loss: 0.0010292387451045215, Final Batch Loss: 0.0002017614315263927\n",
      "Epoch 1104, Loss: 0.002065160486381501, Final Batch Loss: 0.0002480469993315637\n",
      "Epoch 1105, Loss: 0.001990553573705256, Final Batch Loss: 0.0014059122186154127\n",
      "Epoch 1106, Loss: 0.0038555155624635518, Final Batch Loss: 0.0007013516151346266\n",
      "Epoch 1107, Loss: 0.0008118108089547604, Final Batch Loss: 0.0002634208358358592\n",
      "Epoch 1108, Loss: 0.0009093241533264518, Final Batch Loss: 0.00033093965612351894\n",
      "Epoch 1109, Loss: 0.007558914483524859, Final Batch Loss: 0.006521725561469793\n",
      "Epoch 1110, Loss: 0.0034434820991009474, Final Batch Loss: 0.0005214419215917587\n",
      "Epoch 1111, Loss: 0.0007061982396407984, Final Batch Loss: 0.0006304291891865432\n",
      "Epoch 1112, Loss: 0.0027881901842192747, Final Batch Loss: 7.003141945460811e-05\n",
      "Epoch 1113, Loss: 0.0023154253140091896, Final Batch Loss: 0.0010247654281556606\n",
      "Epoch 1114, Loss: 0.0016132837772602215, Final Batch Loss: 9.634556772653013e-05\n",
      "Epoch 1115, Loss: 0.0008370692667085677, Final Batch Loss: 0.0006327519076876342\n",
      "Epoch 1116, Loss: 0.004240270354785025, Final Batch Loss: 0.003177872858941555\n",
      "Epoch 1117, Loss: 0.003358715563081205, Final Batch Loss: 0.0009993320563808084\n",
      "Epoch 1118, Loss: 0.0009254144097212702, Final Batch Loss: 0.00034313698415644467\n",
      "Epoch 1119, Loss: 0.0012453822419047356, Final Batch Loss: 0.0007773817633278668\n",
      "Epoch 1120, Loss: 0.002403392398264259, Final Batch Loss: 0.0018841163255274296\n",
      "Epoch 1121, Loss: 0.0003510035603540018, Final Batch Loss: 4.057619662489742e-05\n",
      "Epoch 1122, Loss: 0.0015531489916611463, Final Batch Loss: 0.00014428133727051318\n",
      "Epoch 1123, Loss: 0.005905795638682321, Final Batch Loss: 0.005421180743724108\n",
      "Epoch 1124, Loss: 0.002582374436315149, Final Batch Loss: 0.0019072620198130608\n",
      "Epoch 1125, Loss: 0.0004821040201932192, Final Batch Loss: 0.00010271251085214317\n",
      "Epoch 1126, Loss: 0.00406436209595995, Final Batch Loss: 6.976171425776556e-05\n",
      "Epoch 1127, Loss: 0.0008191580127459019, Final Batch Loss: 0.00043607738916762173\n",
      "Epoch 1128, Loss: 0.0014431708841584623, Final Batch Loss: 0.00041150260949507356\n",
      "Epoch 1129, Loss: 0.001386766140058171, Final Batch Loss: 6.696808122796938e-05\n",
      "Epoch 1130, Loss: 0.006349341128952801, Final Batch Loss: 0.0010121000232174993\n",
      "Epoch 1131, Loss: 0.013957837538328022, Final Batch Loss: 0.00020841037621721625\n",
      "Epoch 1132, Loss: 0.0019515474559739232, Final Batch Loss: 0.0004648243775591254\n",
      "Epoch 1133, Loss: 0.010271965322317556, Final Batch Loss: 0.009978481568396091\n",
      "Epoch 1134, Loss: 0.007803318090736866, Final Batch Loss: 0.0021762014366686344\n",
      "Epoch 1135, Loss: 0.0014050935569684952, Final Batch Loss: 0.00020627208868972957\n",
      "Epoch 1136, Loss: 0.0012385010777506977, Final Batch Loss: 0.0002538521366659552\n",
      "Epoch 1137, Loss: 0.002014105732087046, Final Batch Loss: 0.0008275230065919459\n",
      "Epoch 1138, Loss: 0.0020591102074831724, Final Batch Loss: 0.0017721120966598392\n",
      "Epoch 1139, Loss: 0.0012006082688458264, Final Batch Loss: 0.0003080798778682947\n",
      "Epoch 1140, Loss: 0.001146737631643191, Final Batch Loss: 0.0004527312412392348\n",
      "Epoch 1141, Loss: 0.0018919426365755498, Final Batch Loss: 0.0012854632223024964\n",
      "Epoch 1142, Loss: 0.0007136829517548904, Final Batch Loss: 0.0004975540214218199\n",
      "Epoch 1143, Loss: 0.005521980579942465, Final Batch Loss: 0.002443748526275158\n",
      "Epoch 1144, Loss: 0.0052235411130823195, Final Batch Loss: 0.0002690386609174311\n",
      "Epoch 1145, Loss: 0.0015120822936296463, Final Batch Loss: 0.0004033521981909871\n",
      "Epoch 1146, Loss: 0.0037129608390387148, Final Batch Loss: 0.00013261180720292032\n",
      "Epoch 1147, Loss: 0.0008552797080483288, Final Batch Loss: 0.00026402450748719275\n",
      "Epoch 1148, Loss: 0.0011288346722722054, Final Batch Loss: 0.0005137320840731263\n",
      "Epoch 1149, Loss: 0.003402422269573435, Final Batch Loss: 0.00016550309373997152\n",
      "Epoch 1150, Loss: 0.004342018801253289, Final Batch Loss: 0.003541801357641816\n",
      "Epoch 1151, Loss: 0.003604854289733339, Final Batch Loss: 0.00358264846727252\n",
      "Epoch 1152, Loss: 0.0036657873424701393, Final Batch Loss: 0.00041667529148980975\n",
      "Epoch 1153, Loss: 0.00044201550190337, Final Batch Loss: 2.6464840630069375e-05\n",
      "Epoch 1154, Loss: 0.0011769720003940165, Final Batch Loss: 0.0008787960978224874\n",
      "Epoch 1155, Loss: 0.0027402848354540765, Final Batch Loss: 0.0022106070537120104\n",
      "Epoch 1156, Loss: 0.0002505537704564631, Final Batch Loss: 8.555912063457072e-05\n",
      "Epoch 1157, Loss: 0.0038688137792632915, Final Batch Loss: 3.2345451472792774e-05\n",
      "Epoch 1158, Loss: 0.00395734328776598, Final Batch Loss: 0.001183094223961234\n",
      "Epoch 1159, Loss: 0.0009468470816500485, Final Batch Loss: 0.0006098068552091718\n",
      "Epoch 1160, Loss: 0.0007039180491119623, Final Batch Loss: 0.00027616810984909534\n",
      "Epoch 1161, Loss: 0.003744931484106928, Final Batch Loss: 0.0005098081310279667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1162, Loss: 0.003206400142516941, Final Batch Loss: 0.0003513791016303003\n",
      "Epoch 1163, Loss: 0.0011648627114482224, Final Batch Loss: 0.0002523578586988151\n",
      "Epoch 1164, Loss: 0.0006430043486034265, Final Batch Loss: 1.4427210771827959e-05\n",
      "Epoch 1165, Loss: 0.0008530200575478375, Final Batch Loss: 0.0005634425906464458\n",
      "Epoch 1166, Loss: 0.0013837850419804454, Final Batch Loss: 0.001081028487533331\n",
      "Epoch 1167, Loss: 0.01249292471766239, Final Batch Loss: 4.692727088695392e-05\n",
      "Epoch 1168, Loss: 0.00038818090251879767, Final Batch Loss: 0.00010767658386612311\n",
      "Epoch 1169, Loss: 0.0034342832514084876, Final Batch Loss: 0.002536121755838394\n",
      "Epoch 1170, Loss: 0.0038859757769387215, Final Batch Loss: 0.00039647609810344875\n",
      "Epoch 1171, Loss: 0.0007950973813422024, Final Batch Loss: 0.0003449179348535836\n",
      "Epoch 1172, Loss: 0.0005984845338389277, Final Batch Loss: 0.0001690261415205896\n",
      "Epoch 1173, Loss: 0.002034507575444877, Final Batch Loss: 0.00139099161606282\n",
      "Epoch 1174, Loss: 0.0027426753658801317, Final Batch Loss: 0.0010904240189120173\n",
      "Epoch 1175, Loss: 0.015850095078349113, Final Batch Loss: 0.00814454909414053\n",
      "Epoch 1176, Loss: 0.0007595181596116163, Final Batch Loss: 4.118422657484189e-05\n",
      "Epoch 1177, Loss: 0.0017830684955697507, Final Batch Loss: 0.0016226519364863634\n",
      "Epoch 1178, Loss: 0.0006661814040853642, Final Batch Loss: 0.000581373751629144\n",
      "Epoch 1179, Loss: 0.015470122583792545, Final Batch Loss: 0.015307845547795296\n",
      "Epoch 1180, Loss: 0.0010000304610002786, Final Batch Loss: 0.0005473861237987876\n",
      "Epoch 1181, Loss: 0.0004176437796559185, Final Batch Loss: 0.00021902173466514796\n",
      "Epoch 1182, Loss: 0.003637838146460126, Final Batch Loss: 2.915711775131058e-05\n",
      "Epoch 1183, Loss: 0.001282325083593605, Final Batch Loss: 5.224319102126174e-05\n",
      "Epoch 1184, Loss: 0.0005998823035042733, Final Batch Loss: 0.00011163638555444777\n",
      "Epoch 1185, Loss: 0.0010243002616334707, Final Batch Loss: 0.0008492081542499363\n",
      "Epoch 1186, Loss: 0.00033007117599481717, Final Batch Loss: 0.00025894102873280644\n",
      "Epoch 1187, Loss: 0.005067985621280968, Final Batch Loss: 0.004000912886112928\n",
      "Epoch 1188, Loss: 0.0008138069533742964, Final Batch Loss: 0.0006941190222278237\n",
      "Epoch 1189, Loss: 0.0006176288152346388, Final Batch Loss: 0.00048796861665323377\n",
      "Epoch 1190, Loss: 0.001623345393454656, Final Batch Loss: 0.0003163200744893402\n",
      "Epoch 1191, Loss: 0.021980157795042032, Final Batch Loss: 2.0091163605684415e-05\n",
      "Epoch 1192, Loss: 0.0056539322540629655, Final Batch Loss: 0.0001729340583551675\n",
      "Epoch 1193, Loss: 0.01817175274481997, Final Batch Loss: 0.017532989382743835\n",
      "Epoch 1194, Loss: 0.002929880043666344, Final Batch Loss: 7.581849786220118e-05\n",
      "Epoch 1195, Loss: 0.0012704228283837438, Final Batch Loss: 0.00019648601301014423\n",
      "Epoch 1196, Loss: 0.005767335882410407, Final Batch Loss: 0.002563739661127329\n",
      "Epoch 1197, Loss: 0.004076062061358243, Final Batch Loss: 0.0008781320066191256\n",
      "Epoch 1198, Loss: 0.0031245529753505252, Final Batch Loss: 1.871558924904093e-05\n",
      "Epoch 1199, Loss: 0.019387134758289903, Final Batch Loss: 0.0005066538578830659\n",
      "Epoch 1200, Loss: 0.022947484627366066, Final Batch Loss: 0.007040603086352348\n",
      "Epoch 1201, Loss: 0.0008700575563125312, Final Batch Loss: 0.0004003247304353863\n",
      "Epoch 1202, Loss: 0.001391250261804089, Final Batch Loss: 0.0009828440379351377\n",
      "Epoch 1203, Loss: 0.0003614751185523346, Final Batch Loss: 0.0001835899893194437\n",
      "Epoch 1204, Loss: 0.00041113293809758034, Final Batch Loss: 2.3219856302603148e-05\n",
      "Epoch 1205, Loss: 0.001485619373852387, Final Batch Loss: 0.00034146002144552767\n",
      "Epoch 1206, Loss: 0.001964907249202952, Final Batch Loss: 0.0016083494992926717\n",
      "Epoch 1207, Loss: 0.004451686370885, Final Batch Loss: 0.004087349399924278\n",
      "Epoch 1208, Loss: 0.0020875060581602156, Final Batch Loss: 0.001479544211179018\n",
      "Epoch 1209, Loss: 0.0016293981461785734, Final Batch Loss: 0.0005367191624827683\n",
      "Epoch 1210, Loss: 0.011670425767078996, Final Batch Loss: 0.0022073027212172747\n",
      "Epoch 1211, Loss: 0.0006563496135640889, Final Batch Loss: 0.0003470526135060936\n",
      "Epoch 1212, Loss: 0.001081450202036649, Final Batch Loss: 0.0007431306294165552\n",
      "Epoch 1213, Loss: 0.001889868697617203, Final Batch Loss: 0.001043636817485094\n",
      "Epoch 1214, Loss: 0.00022789359354646876, Final Batch Loss: 0.00010358870349591598\n",
      "Epoch 1215, Loss: 0.00035737102007260546, Final Batch Loss: 0.0001109495569835417\n",
      "Epoch 1216, Loss: 0.0015130112878978252, Final Batch Loss: 0.0005991319776512682\n",
      "Epoch 1217, Loss: 0.004490703680858132, Final Batch Loss: 2.105474595737178e-05\n",
      "Epoch 1218, Loss: 0.0018006294849328697, Final Batch Loss: 0.0006983013008721173\n",
      "Epoch 1219, Loss: 0.00036963203456252813, Final Batch Loss: 0.00017475565255153924\n",
      "Epoch 1220, Loss: 0.000843600690132007, Final Batch Loss: 0.0002785716496873647\n",
      "Epoch 1221, Loss: 0.0012685840483754873, Final Batch Loss: 0.000497782020829618\n",
      "Epoch 1222, Loss: 0.00067294375912752, Final Batch Loss: 0.0001266086910618469\n",
      "Epoch 1223, Loss: 0.0016737312253098935, Final Batch Loss: 0.00037843346945010126\n",
      "Epoch 1224, Loss: 0.001044007614837028, Final Batch Loss: 0.00020799537014681846\n",
      "Epoch 1225, Loss: 0.00047349095984827727, Final Batch Loss: 9.181709901895374e-05\n",
      "Epoch 1226, Loss: 0.011116954032331705, Final Batch Loss: 0.0082943644374609\n",
      "Epoch 1227, Loss: 0.008243679534643888, Final Batch Loss: 0.0044179498217999935\n",
      "Epoch 1228, Loss: 0.000769600854255259, Final Batch Loss: 0.00026195839745923877\n",
      "Epoch 1229, Loss: 0.00025913826539181173, Final Batch Loss: 6.241504161152989e-05\n",
      "Epoch 1230, Loss: 0.004342748026829213, Final Batch Loss: 0.0008712233393453062\n",
      "Epoch 1231, Loss: 0.0011638797877822071, Final Batch Loss: 0.0010121488012373447\n",
      "Epoch 1232, Loss: 0.0008831385057419538, Final Batch Loss: 0.0005041942349635065\n",
      "Epoch 1233, Loss: 0.0002556203107815236, Final Batch Loss: 7.522488886024803e-05\n",
      "Epoch 1234, Loss: 0.00014613215171266347, Final Batch Loss: 7.249257032526657e-05\n",
      "Epoch 1235, Loss: 0.0006987038941588253, Final Batch Loss: 0.0005594739341177046\n",
      "Epoch 1236, Loss: 0.003409550048672827, Final Batch Loss: 3.586103048291989e-05\n",
      "Epoch 1237, Loss: 0.0006857598491478711, Final Batch Loss: 0.00010715614189393818\n",
      "Epoch 1238, Loss: 0.0014938680760678835, Final Batch Loss: 0.0014069940662011504\n",
      "Epoch 1239, Loss: 0.0008953546930570155, Final Batch Loss: 0.00027558705187402666\n",
      "Epoch 1240, Loss: 0.0049281805695500225, Final Batch Loss: 0.00025712008937262\n",
      "Epoch 1241, Loss: 0.0006087773654144257, Final Batch Loss: 0.00019798794528469443\n",
      "Epoch 1242, Loss: 0.0011354266898706555, Final Batch Loss: 0.0005740728811360896\n",
      "Epoch 1243, Loss: 0.008615714374172967, Final Batch Loss: 8.270784019259736e-05\n",
      "Epoch 1244, Loss: 0.002203004725743085, Final Batch Loss: 0.0018262394005432725\n",
      "Epoch 1245, Loss: 0.0009718290348246228, Final Batch Loss: 5.5226653785211965e-05\n",
      "Epoch 1246, Loss: 0.005781192681752145, Final Batch Loss: 0.005006037186831236\n",
      "Epoch 1247, Loss: 0.007008997956290841, Final Batch Loss: 0.0016221709083765745\n",
      "Epoch 1248, Loss: 0.014650813536718488, Final Batch Loss: 0.0011167603079229593\n",
      "Epoch 1249, Loss: 0.003039915405679494, Final Batch Loss: 0.00016147253336384892\n",
      "Epoch 1250, Loss: 0.0017783677903935313, Final Batch Loss: 0.0009971028193831444\n",
      "Epoch 1251, Loss: 0.0009510490781394765, Final Batch Loss: 0.00024047026818152517\n",
      "Epoch 1252, Loss: 0.0014593463274650276, Final Batch Loss: 0.0005666047800332308\n",
      "Epoch 1253, Loss: 0.0065780105360317975, Final Batch Loss: 0.006199182011187077\n",
      "Epoch 1254, Loss: 0.002670191206561867, Final Batch Loss: 8.302040077978745e-05\n",
      "Epoch 1255, Loss: 0.0020619057504518423, Final Batch Loss: 5.439337473944761e-05\n",
      "Epoch 1256, Loss: 0.0001442079956177622, Final Batch Loss: 6.836595275672153e-05\n",
      "Epoch 1257, Loss: 0.02168096673267428, Final Batch Loss: 0.000234526363783516\n",
      "Epoch 1258, Loss: 0.01414255491545191, Final Batch Loss: 7.415535947075114e-05\n",
      "Epoch 1259, Loss: 0.0007847069573472254, Final Batch Loss: 4.072044248459861e-05\n",
      "Epoch 1260, Loss: 0.003152421413687989, Final Batch Loss: 0.00016972303274087608\n",
      "Epoch 1261, Loss: 0.0015104436315596104, Final Batch Loss: 0.00031919905450195074\n",
      "Epoch 1262, Loss: 0.0018428406037855893, Final Batch Loss: 0.0003480807936284691\n",
      "Epoch 1263, Loss: 0.0005409243458416313, Final Batch Loss: 0.00023274478735402226\n",
      "Epoch 1264, Loss: 0.0008551217106287368, Final Batch Loss: 0.000757651578169316\n",
      "Epoch 1265, Loss: 0.0004126054482185282, Final Batch Loss: 8.743778016651049e-05\n",
      "Epoch 1266, Loss: 0.0005742449138779193, Final Batch Loss: 7.490775897167623e-05\n",
      "Epoch 1267, Loss: 0.0007662519055884331, Final Batch Loss: 4.483383963815868e-05\n",
      "Epoch 1268, Loss: 0.0007752232777420431, Final Batch Loss: 0.0004025921516586095\n",
      "Epoch 1269, Loss: 0.0014606571930926293, Final Batch Loss: 0.00033471055212430656\n",
      "Epoch 1270, Loss: 0.0005717943713534623, Final Batch Loss: 0.00022911862470209599\n",
      "Epoch 1271, Loss: 0.0007158852240536362, Final Batch Loss: 0.0005392019520513713\n",
      "Epoch 1272, Loss: 0.009345869766548276, Final Batch Loss: 0.007118786685168743\n",
      "Epoch 1273, Loss: 0.0009540704195387661, Final Batch Loss: 0.0005460079410113394\n",
      "Epoch 1274, Loss: 0.000605815788730979, Final Batch Loss: 0.0003954959975089878\n",
      "Epoch 1275, Loss: 0.005655358370859176, Final Batch Loss: 0.0006513272528536618\n",
      "Epoch 1276, Loss: 0.0007767127244733274, Final Batch Loss: 0.000501284608617425\n",
      "Epoch 1277, Loss: 0.0008351075521204621, Final Batch Loss: 0.00020687220967374742\n",
      "Epoch 1278, Loss: 0.0035693842510227114, Final Batch Loss: 0.0034995826426893473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1279, Loss: 0.000555511811398901, Final Batch Loss: 0.00017814467719290406\n",
      "Epoch 1280, Loss: 0.0004945068358210847, Final Batch Loss: 0.00038336843135766685\n",
      "Epoch 1281, Loss: 0.0034582104854052886, Final Batch Loss: 0.0002112486254191026\n",
      "Epoch 1282, Loss: 0.00105134042314603, Final Batch Loss: 5.719082764699124e-05\n",
      "Epoch 1283, Loss: 0.0003591090498957783, Final Batch Loss: 0.00012711049930658191\n",
      "Epoch 1284, Loss: 0.0019261679844930768, Final Batch Loss: 0.001784212770871818\n",
      "Epoch 1285, Loss: 0.0006895821570651606, Final Batch Loss: 0.00016698626859579235\n",
      "Epoch 1286, Loss: 0.0016102403533295728, Final Batch Loss: 0.00010043980000773445\n",
      "Epoch 1287, Loss: 0.00035097212821710855, Final Batch Loss: 6.520542956423014e-05\n",
      "Epoch 1288, Loss: 0.0015461363218491897, Final Batch Loss: 0.00018815450312104076\n",
      "Epoch 1289, Loss: 0.001919218513648957, Final Batch Loss: 0.0007438320317305624\n",
      "Epoch 1290, Loss: 0.00527514040004462, Final Batch Loss: 0.00016540696378797293\n",
      "Epoch 1291, Loss: 0.0009926522325258702, Final Batch Loss: 0.0005982922157272696\n",
      "Epoch 1292, Loss: 0.0019056725432164967, Final Batch Loss: 0.0008365795365534723\n",
      "Epoch 1293, Loss: 0.05035635163949337, Final Batch Loss: 0.05014210194349289\n",
      "Epoch 1294, Loss: 0.005287537307594903, Final Batch Loss: 0.00018881536379922181\n",
      "Epoch 1295, Loss: 0.0017268424126086757, Final Batch Loss: 7.064726378303021e-05\n",
      "Epoch 1296, Loss: 0.0008492987544741482, Final Batch Loss: 0.0004151703615207225\n",
      "Epoch 1297, Loss: 0.0011941330594709143, Final Batch Loss: 0.0009707135031931102\n",
      "Epoch 1298, Loss: 0.0009280422236770391, Final Batch Loss: 0.0004957623896189034\n",
      "Epoch 1299, Loss: 0.0019547229749150574, Final Batch Loss: 0.0008260957547463477\n",
      "Epoch 1300, Loss: 0.0002620982122607529, Final Batch Loss: 9.596283780410886e-05\n",
      "Epoch 1301, Loss: 0.005381164199206978, Final Batch Loss: 0.004902405198663473\n",
      "Epoch 1302, Loss: 0.0016924912633839995, Final Batch Loss: 0.0012577709276229143\n",
      "Epoch 1303, Loss: 0.002048504233243875, Final Batch Loss: 0.00023628333292435855\n",
      "Epoch 1304, Loss: 0.0010840249597094953, Final Batch Loss: 0.0008075784426182508\n",
      "Epoch 1305, Loss: 0.0008426489366684109, Final Batch Loss: 0.00024248790577985346\n",
      "Epoch 1306, Loss: 0.002988546126289293, Final Batch Loss: 0.00019730461644940078\n",
      "Epoch 1307, Loss: 0.0023889411095296964, Final Batch Loss: 0.00016119306383188814\n",
      "Epoch 1308, Loss: 0.00036900229497405235, Final Batch Loss: 1.5027218978502788e-05\n",
      "Epoch 1309, Loss: 0.0027463560218166094, Final Batch Loss: 3.66769490938168e-05\n",
      "Epoch 1310, Loss: 0.000854045560117811, Final Batch Loss: 0.0002946959575638175\n",
      "Epoch 1311, Loss: 0.0003558300668373704, Final Batch Loss: 0.0002092213835567236\n",
      "Epoch 1312, Loss: 0.0011876699045387795, Final Batch Loss: 2.2721802451997064e-05\n",
      "Epoch 1313, Loss: 0.0008056176302488893, Final Batch Loss: 0.0003870102809742093\n",
      "Epoch 1314, Loss: 0.0012924837064929307, Final Batch Loss: 0.0007743706810288131\n",
      "Epoch 1315, Loss: 0.016272643173579127, Final Batch Loss: 0.0008279397734440863\n",
      "Epoch 1316, Loss: 0.010474575567059219, Final Batch Loss: 0.00047500140499323606\n",
      "Epoch 1317, Loss: 0.0061965707573108375, Final Batch Loss: 0.005947127938270569\n",
      "Epoch 1318, Loss: 0.005848058266565204, Final Batch Loss: 0.00547093665227294\n",
      "Epoch 1319, Loss: 0.0030751109297852963, Final Batch Loss: 0.0029717085417360067\n",
      "Epoch 1320, Loss: 0.003934732754714787, Final Batch Loss: 0.000939248944632709\n",
      "Epoch 1321, Loss: 0.0010036727398983203, Final Batch Loss: 5.946921737631783e-05\n",
      "Epoch 1322, Loss: 0.000918496196391061, Final Batch Loss: 0.00030206856899894774\n",
      "Epoch 1323, Loss: 0.0006695053743897006, Final Batch Loss: 0.0001163371343864128\n",
      "Epoch 1324, Loss: 0.0013614725030492991, Final Batch Loss: 7.08236766513437e-05\n",
      "Epoch 1325, Loss: 0.035359373287064955, Final Batch Loss: 0.00033105348120443523\n",
      "Epoch 1326, Loss: 0.003995386534370482, Final Batch Loss: 0.0027397077064961195\n",
      "Epoch 1327, Loss: 0.0005283047503326088, Final Batch Loss: 0.0003637576592154801\n",
      "Epoch 1328, Loss: 0.0029090649040881544, Final Batch Loss: 0.00025418555014766753\n",
      "Epoch 1329, Loss: 0.00034623308602022007, Final Batch Loss: 5.622363096335903e-05\n",
      "Epoch 1330, Loss: 0.0008381245424970984, Final Batch Loss: 0.0005281392368488014\n",
      "Epoch 1331, Loss: 0.0004033550576423295, Final Batch Loss: 0.00011323768558213487\n",
      "Epoch 1332, Loss: 0.002827373507898301, Final Batch Loss: 0.0004909580457024276\n",
      "Epoch 1333, Loss: 0.0007440302288159728, Final Batch Loss: 0.0005119611159898341\n",
      "Epoch 1334, Loss: 0.0026206612237729132, Final Batch Loss: 0.0006978397141210735\n",
      "Epoch 1335, Loss: 0.0019362292077858, Final Batch Loss: 0.0017626185435801744\n",
      "Epoch 1336, Loss: 0.0009466250776313245, Final Batch Loss: 0.0003207475529052317\n",
      "Epoch 1337, Loss: 0.002090088033583015, Final Batch Loss: 0.00032444874523207545\n",
      "Epoch 1338, Loss: 0.014611739805332036, Final Batch Loss: 2.4171686163754202e-05\n",
      "Epoch 1339, Loss: 0.0011299497273284942, Final Batch Loss: 0.0010299026034772396\n",
      "Epoch 1340, Loss: 0.005816360382596031, Final Batch Loss: 0.005509526003152132\n",
      "Epoch 1341, Loss: 0.0007619069947395474, Final Batch Loss: 0.00023419645731337368\n",
      "Epoch 1342, Loss: 0.004143562022363767, Final Batch Loss: 0.00021571977413259447\n",
      "Epoch 1343, Loss: 0.0007055673195281997, Final Batch Loss: 0.00013682620192412287\n",
      "Epoch 1344, Loss: 0.00017745906370691955, Final Batch Loss: 8.20062923594378e-05\n",
      "Epoch 1345, Loss: 0.000731273896235507, Final Batch Loss: 3.091803955612704e-05\n",
      "Epoch 1346, Loss: 0.0007868795801186934, Final Batch Loss: 0.00012374216748867184\n",
      "Epoch 1347, Loss: 0.0037859680596739054, Final Batch Loss: 0.0005875930655747652\n",
      "Epoch 1348, Loss: 0.0005513561118277721, Final Batch Loss: 0.00010162672697333619\n",
      "Epoch 1349, Loss: 0.00012992708070669323, Final Batch Loss: 6.646715337410569e-05\n",
      "Epoch 1350, Loss: 0.00013297457735461649, Final Batch Loss: 2.9648987037944607e-05\n",
      "Epoch 1351, Loss: 0.000843140049255453, Final Batch Loss: 0.00023280455206986517\n",
      "Epoch 1352, Loss: 0.002282821988046635, Final Batch Loss: 0.002223376650363207\n",
      "Epoch 1353, Loss: 0.00040487041405867785, Final Batch Loss: 0.00018016653484664857\n",
      "Epoch 1354, Loss: 0.00130884010468435, Final Batch Loss: 2.125637729477603e-05\n",
      "Epoch 1355, Loss: 0.000378515716874972, Final Batch Loss: 0.00018800684483721852\n",
      "Epoch 1356, Loss: 0.0015161335468292236, Final Batch Loss: 0.000722955446690321\n",
      "Epoch 1357, Loss: 0.000942583050346002, Final Batch Loss: 0.0003126182418782264\n",
      "Epoch 1358, Loss: 0.0012718149228021502, Final Batch Loss: 0.00023509608581662178\n",
      "Epoch 1359, Loss: 0.0005564465973293409, Final Batch Loss: 0.00045087485341355205\n",
      "Epoch 1360, Loss: 0.0008029061427805573, Final Batch Loss: 0.00016789205255918205\n",
      "Epoch 1361, Loss: 0.00034988656261703, Final Batch Loss: 8.962998253991827e-05\n",
      "Epoch 1362, Loss: 0.0009139495668932796, Final Batch Loss: 0.0004916999605484307\n",
      "Epoch 1363, Loss: 0.0002690599467314314, Final Batch Loss: 5.906013757339679e-05\n",
      "Epoch 1364, Loss: 0.0006957654186408035, Final Batch Loss: 5.982052971376106e-05\n",
      "Epoch 1365, Loss: 0.0010811361426021904, Final Batch Loss: 0.0008847204735502601\n",
      "Epoch 1366, Loss: 0.0005697820452041924, Final Batch Loss: 0.0003179524792358279\n",
      "Epoch 1367, Loss: 0.016818858915939927, Final Batch Loss: 0.01573330909013748\n",
      "Epoch 1368, Loss: 0.0005941050039837137, Final Batch Loss: 0.00018874519446399063\n",
      "Epoch 1369, Loss: 0.000539980799658224, Final Batch Loss: 0.00028592333546839654\n",
      "Epoch 1370, Loss: 0.0005011818393541034, Final Batch Loss: 2.6988152967533097e-05\n",
      "Epoch 1371, Loss: 0.008914878708310425, Final Batch Loss: 0.008300898596644402\n",
      "Epoch 1372, Loss: 0.0031495453440584242, Final Batch Loss: 0.00017563678557053208\n",
      "Epoch 1373, Loss: 0.00290666485670954, Final Batch Loss: 0.0026160941924899817\n",
      "Epoch 1374, Loss: 0.000857185514178127, Final Batch Loss: 0.0006809662445448339\n",
      "Epoch 1375, Loss: 0.000750431208871305, Final Batch Loss: 0.00022771977819502354\n",
      "Epoch 1376, Loss: 0.0006716724601574242, Final Batch Loss: 0.00036799805820919573\n",
      "Epoch 1377, Loss: 0.0031048412201926112, Final Batch Loss: 0.0013520827051252127\n",
      "Epoch 1378, Loss: 0.0003595276066334918, Final Batch Loss: 0.00012089665688108653\n",
      "Epoch 1379, Loss: 0.0012791657936759293, Final Batch Loss: 0.0002849491429515183\n",
      "Epoch 1380, Loss: 0.0006403374682122376, Final Batch Loss: 0.0006109451642259955\n",
      "Epoch 1381, Loss: 0.0034125282836612314, Final Batch Loss: 0.0003544602950569242\n",
      "Epoch 1382, Loss: 0.0041263464372605085, Final Batch Loss: 0.000593546312302351\n",
      "Epoch 1383, Loss: 0.0012115523422835395, Final Batch Loss: 0.0010855658911168575\n",
      "Epoch 1384, Loss: 0.0028185783594381064, Final Batch Loss: 0.002460252260789275\n",
      "Epoch 1385, Loss: 0.00030433978099608794, Final Batch Loss: 7.301009463844821e-05\n",
      "Epoch 1386, Loss: 0.0005137915104569402, Final Batch Loss: 0.0004759282455779612\n",
      "Epoch 1387, Loss: 0.0011823929380625486, Final Batch Loss: 0.0004862736095674336\n",
      "Epoch 1388, Loss: 0.003005588165251538, Final Batch Loss: 0.00032279218430630863\n",
      "Epoch 1389, Loss: 0.00033207711749128066, Final Batch Loss: 0.00029367380193434656\n",
      "Epoch 1390, Loss: 0.00023724182392470539, Final Batch Loss: 6.329049938358366e-05\n",
      "Epoch 1391, Loss: 0.0005669882229994982, Final Batch Loss: 0.0002681547193787992\n",
      "Epoch 1392, Loss: 0.003157167840981856, Final Batch Loss: 0.0002695686707738787\n",
      "Epoch 1393, Loss: 0.0006030701406416483, Final Batch Loss: 6.979652243899181e-05\n",
      "Epoch 1394, Loss: 0.002844972725142725, Final Batch Loss: 0.002766229212284088\n",
      "Epoch 1395, Loss: 0.00032126419682754204, Final Batch Loss: 0.00023923696426209062\n",
      "Epoch 1396, Loss: 0.011309019871987402, Final Batch Loss: 0.011185826733708382\n",
      "Epoch 1397, Loss: 0.0006402783874364104, Final Batch Loss: 3.063451367779635e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1398, Loss: 0.0008041643595788628, Final Batch Loss: 0.00015093435649760067\n",
      "Epoch 1399, Loss: 0.0007373270345851779, Final Batch Loss: 0.0005274356808513403\n",
      "Epoch 1400, Loss: 0.00019694393358804518, Final Batch Loss: 8.882693691703025e-06\n",
      "Epoch 1401, Loss: 0.0023409808636642992, Final Batch Loss: 0.0020485445857048035\n",
      "Epoch 1402, Loss: 0.0007677191169932485, Final Batch Loss: 0.00020402262452989817\n",
      "Epoch 1403, Loss: 0.001982217887416482, Final Batch Loss: 0.0013556379126384854\n",
      "Epoch 1404, Loss: 0.0010097312915604562, Final Batch Loss: 0.0003629799757618457\n",
      "Epoch 1405, Loss: 0.0002629170339787379, Final Batch Loss: 8.466889266856015e-05\n",
      "Epoch 1406, Loss: 0.0004866773379035294, Final Batch Loss: 0.00015331953181885183\n",
      "Epoch 1407, Loss: 0.000530667050043121, Final Batch Loss: 8.932049968279898e-05\n",
      "Epoch 1408, Loss: 0.013603188621345907, Final Batch Loss: 0.013026895001530647\n",
      "Epoch 1409, Loss: 0.000665257015498355, Final Batch Loss: 0.00014549176557920873\n",
      "Epoch 1410, Loss: 0.00016222341218963265, Final Batch Loss: 1.5930301742628217e-05\n",
      "Epoch 1411, Loss: 0.00454034295398742, Final Batch Loss: 0.0042732032015919685\n",
      "Epoch 1412, Loss: 0.000595251825870946, Final Batch Loss: 4.5036053052172065e-05\n",
      "Epoch 1413, Loss: 0.0013354350230656564, Final Batch Loss: 0.00020347238751128316\n",
      "Epoch 1414, Loss: 0.0007757597777526826, Final Batch Loss: 0.0003807713801506907\n",
      "Epoch 1415, Loss: 0.00027587324439082295, Final Batch Loss: 0.00011178806016687304\n",
      "Epoch 1416, Loss: 0.00361819751560688, Final Batch Loss: 0.0012305493000894785\n",
      "Epoch 1417, Loss: 0.00022462907509179786, Final Batch Loss: 0.00016795787087175995\n",
      "Epoch 1418, Loss: 0.00047949143481673673, Final Batch Loss: 8.135609823511913e-05\n",
      "Epoch 1419, Loss: 0.004099268408026546, Final Batch Loss: 0.0006232063169591129\n",
      "Epoch 1420, Loss: 0.0063647551942267455, Final Batch Loss: 0.006254177540540695\n",
      "Epoch 1421, Loss: 0.0011417050700401887, Final Batch Loss: 0.0001614902721485123\n",
      "Epoch 1422, Loss: 0.002210265985922888, Final Batch Loss: 0.00017931408365257084\n",
      "Epoch 1423, Loss: 0.00469468193477951, Final Batch Loss: 0.00445882324129343\n",
      "Epoch 1424, Loss: 0.000665889325318858, Final Batch Loss: 0.0003985911316704005\n",
      "Epoch 1425, Loss: 0.008154538663802668, Final Batch Loss: 0.008002730086445808\n",
      "Epoch 1426, Loss: 0.0002493774954928085, Final Batch Loss: 0.00015738600632175803\n",
      "Epoch 1427, Loss: 0.007698241766775027, Final Batch Loss: 0.0002746052632573992\n",
      "Epoch 1428, Loss: 0.0006884487083880231, Final Batch Loss: 0.0005643078475259244\n",
      "Epoch 1429, Loss: 0.01092459425854031, Final Batch Loss: 0.010810027830302715\n",
      "Epoch 1430, Loss: 0.00041431066711083986, Final Batch Loss: 0.0003689609875436872\n",
      "Epoch 1431, Loss: 0.0063378514314536005, Final Batch Loss: 0.005875148810446262\n",
      "Epoch 1432, Loss: 0.0036292114527896047, Final Batch Loss: 0.0004051405703648925\n",
      "Epoch 1433, Loss: 5.323732602846576e-05, Final Batch Loss: 3.802008359343745e-05\n",
      "Epoch 1434, Loss: 0.004820237780222669, Final Batch Loss: 8.906135917641222e-05\n",
      "Epoch 1435, Loss: 0.00016231906920438632, Final Batch Loss: 6.209268030943349e-05\n",
      "Epoch 1436, Loss: 0.011411686602514237, Final Batch Loss: 5.773938028141856e-05\n",
      "Epoch 1437, Loss: 0.00012967495422344655, Final Batch Loss: 4.0534097934141755e-05\n",
      "Epoch 1438, Loss: 0.0008591137593612075, Final Batch Loss: 0.0003696428029797971\n",
      "Epoch 1439, Loss: 0.0007487498041882645, Final Batch Loss: 4.996083953301422e-05\n",
      "Epoch 1440, Loss: 0.000605364388320595, Final Batch Loss: 0.00033273446024395525\n",
      "Epoch 1441, Loss: 0.0021593530691461638, Final Batch Loss: 0.0019586661364883184\n",
      "Epoch 1442, Loss: 0.0003687225907924585, Final Batch Loss: 9.549763490213081e-05\n",
      "Epoch 1443, Loss: 0.002918022350058891, Final Batch Loss: 0.0028532850556075573\n",
      "Epoch 1444, Loss: 0.0018403033900540322, Final Batch Loss: 0.001717928214929998\n",
      "Epoch 1445, Loss: 0.0035337887943569513, Final Batch Loss: 5.323044661054155e-06\n",
      "Epoch 1446, Loss: 0.0001621915853320388, Final Batch Loss: 2.3606100512552075e-05\n",
      "Epoch 1447, Loss: 0.0006129675020929426, Final Batch Loss: 8.137818076647818e-05\n",
      "Epoch 1448, Loss: 0.0007793492586642969, Final Batch Loss: 0.0007316377013921738\n",
      "Epoch 1449, Loss: 0.00023725970095256343, Final Batch Loss: 0.00011519741383381188\n",
      "Epoch 1450, Loss: 0.001635290333069861, Final Batch Loss: 0.0015568885719403625\n",
      "Epoch 1451, Loss: 0.0004327848473621998, Final Batch Loss: 0.000405679689720273\n",
      "Epoch 1452, Loss: 0.000870624186063651, Final Batch Loss: 3.502073377603665e-05\n",
      "Epoch 1453, Loss: 0.0006216651891008951, Final Batch Loss: 0.0005705863004550338\n",
      "Epoch 1454, Loss: 0.016855477588251233, Final Batch Loss: 0.01598852314054966\n",
      "Epoch 1455, Loss: 0.002253251339425333, Final Batch Loss: 0.0021280571818351746\n",
      "Epoch 1456, Loss: 0.0005499621911440045, Final Batch Loss: 0.00020299135940149426\n",
      "Epoch 1457, Loss: 0.0006279051012825221, Final Batch Loss: 0.00020499774836935103\n",
      "Epoch 1458, Loss: 0.0019180498202331364, Final Batch Loss: 0.0007726678741164505\n",
      "Epoch 1459, Loss: 0.0010088340350193903, Final Batch Loss: 0.0009450984071008861\n",
      "Epoch 1460, Loss: 0.008851720718666911, Final Batch Loss: 0.008376029320061207\n",
      "Epoch 1461, Loss: 0.006117162323789671, Final Batch Loss: 0.0002599926956463605\n",
      "Epoch 1462, Loss: 0.003243133003707044, Final Batch Loss: 6.19234488112852e-05\n",
      "Epoch 1463, Loss: 0.00470505871635396, Final Batch Loss: 0.00015224826347548515\n",
      "Epoch 1464, Loss: 0.0023175093811005354, Final Batch Loss: 0.002077185083180666\n",
      "Epoch 1465, Loss: 0.00025438049942749785, Final Batch Loss: 1.5228736629069317e-05\n",
      "Epoch 1466, Loss: 0.008015737985260785, Final Batch Loss: 0.006653855554759502\n",
      "Epoch 1467, Loss: 0.0005953048530500382, Final Batch Loss: 9.469533688388765e-05\n",
      "Epoch 1468, Loss: 0.00036743635428138077, Final Batch Loss: 0.00013427673547994345\n",
      "Epoch 1469, Loss: 0.008006231568288058, Final Batch Loss: 0.0008169093052856624\n",
      "Epoch 1470, Loss: 0.00010533121167100035, Final Batch Loss: 3.501664104987867e-05\n",
      "Epoch 1471, Loss: 0.0021867109462618828, Final Batch Loss: 0.0017970119370147586\n",
      "Epoch 1472, Loss: 0.00048254333250952186, Final Batch Loss: 1.5224960407067556e-05\n",
      "Epoch 1473, Loss: 0.00022212013209355064, Final Batch Loss: 8.885621355148032e-06\n",
      "Epoch 1474, Loss: 0.0006554620049428195, Final Batch Loss: 0.0003567617095541209\n",
      "Epoch 1475, Loss: 0.02747665881179273, Final Batch Loss: 0.027056748047471046\n",
      "Epoch 1476, Loss: 0.00044398407044354826, Final Batch Loss: 8.642517786938697e-05\n",
      "Epoch 1477, Loss: 0.003902481807017466, Final Batch Loss: 4.432646892382763e-05\n",
      "Epoch 1478, Loss: 0.000760896218707785, Final Batch Loss: 0.0004114189650863409\n",
      "Epoch 1479, Loss: 0.0006073695840314031, Final Batch Loss: 0.000372799055185169\n",
      "Epoch 1480, Loss: 0.0006661776715191081, Final Batch Loss: 0.00022710308257956058\n",
      "Epoch 1481, Loss: 0.0009207988332491368, Final Batch Loss: 0.0002535194798838347\n",
      "Epoch 1482, Loss: 0.005976276472210884, Final Batch Loss: 0.005163287278264761\n",
      "Epoch 1483, Loss: 0.0008586646144976839, Final Batch Loss: 0.00024362657859455794\n",
      "Epoch 1484, Loss: 0.006759438547305763, Final Batch Loss: 0.006021806504577398\n",
      "Epoch 1485, Loss: 0.00023528798192273825, Final Batch Loss: 9.833999502006918e-05\n",
      "Epoch 1486, Loss: 0.019875017926096916, Final Batch Loss: 0.015878692269325256\n",
      "Epoch 1487, Loss: 0.0006175017188070342, Final Batch Loss: 0.00047037596232257783\n",
      "Epoch 1488, Loss: 0.0006036797058186494, Final Batch Loss: 0.00011186257324879989\n",
      "Epoch 1489, Loss: 0.0009148145036306232, Final Batch Loss: 0.0005695797153748572\n",
      "Epoch 1490, Loss: 0.05567266186699271, Final Batch Loss: 0.05479678884148598\n",
      "Epoch 1491, Loss: 0.0022633219487033784, Final Batch Loss: 0.0016312655061483383\n",
      "Epoch 1492, Loss: 0.0005898220115341246, Final Batch Loss: 0.0003945610369555652\n",
      "Epoch 1493, Loss: 0.0035822745267068967, Final Batch Loss: 0.0002062816492980346\n",
      "Epoch 1494, Loss: 0.0010631980330799706, Final Batch Loss: 0.0009655402973294258\n",
      "Epoch 1495, Loss: 0.001049328831868479, Final Batch Loss: 0.0010227180318906903\n",
      "Epoch 1496, Loss: 0.00038288790528895333, Final Batch Loss: 2.122877776855603e-05\n",
      "Epoch 1497, Loss: 0.006879443186335266, Final Batch Loss: 0.0064457315020263195\n",
      "Epoch 1498, Loss: 0.001341475814115256, Final Batch Loss: 0.0007026730454526842\n",
      "Epoch 1499, Loss: 0.0002579411884653382, Final Batch Loss: 0.00021422270219773054\n",
      "Epoch 1500, Loss: 0.0022004932980053127, Final Batch Loss: 0.0014605990145355463\n",
      "Epoch 1501, Loss: 0.017781950387870893, Final Batch Loss: 3.0824769055470824e-05\n",
      "Epoch 1502, Loss: 0.00042336585465818644, Final Batch Loss: 0.00010409479727968574\n",
      "Epoch 1503, Loss: 0.0015688168932683766, Final Batch Loss: 0.0011658602161332965\n",
      "Epoch 1504, Loss: 0.009706663491670042, Final Batch Loss: 0.009514441713690758\n",
      "Epoch 1505, Loss: 0.0011032954353140667, Final Batch Loss: 0.0009489355143159628\n",
      "Epoch 1506, Loss: 0.0032234965183306485, Final Batch Loss: 0.0003766115114558488\n",
      "Epoch 1507, Loss: 0.0007070930441841483, Final Batch Loss: 0.0004864675283897668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1508, Loss: 0.002139009942766279, Final Batch Loss: 0.0007344910991378129\n",
      "Epoch 1509, Loss: 0.0004843487113248557, Final Batch Loss: 0.0003907501231878996\n",
      "Epoch 1510, Loss: 0.0010793896799441427, Final Batch Loss: 0.00043493465636856854\n",
      "Epoch 1511, Loss: 0.0003322569973533973, Final Batch Loss: 6.966495129745454e-05\n",
      "Epoch 1512, Loss: 0.0021828346070833504, Final Batch Loss: 0.0016992234159260988\n",
      "Epoch 1513, Loss: 0.005173310579266399, Final Batch Loss: 0.00014463945990428329\n",
      "Epoch 1514, Loss: 8.933725985116325e-05, Final Batch Loss: 3.067545549129136e-05\n",
      "Epoch 1515, Loss: 0.000599130435148254, Final Batch Loss: 0.00038460129871964455\n",
      "Epoch 1516, Loss: 0.0011206028866581619, Final Batch Loss: 0.0001138396910391748\n",
      "Epoch 1517, Loss: 0.001990112941712141, Final Batch Loss: 0.00015002547297626734\n",
      "Epoch 1518, Loss: 0.00036624257336370647, Final Batch Loss: 3.259317600168288e-05\n",
      "Epoch 1519, Loss: 0.00021515051048481837, Final Batch Loss: 0.00011717270535882562\n",
      "Epoch 1520, Loss: 0.0030483836089842953, Final Batch Loss: 2.1885127353016287e-05\n",
      "Epoch 1521, Loss: 0.0010622253903420642, Final Batch Loss: 0.00012900926230940968\n",
      "Epoch 1522, Loss: 0.0002164338748116279, Final Batch Loss: 1.999089181481395e-05\n",
      "Epoch 1523, Loss: 0.0007851736736483872, Final Batch Loss: 0.00015179038746282458\n",
      "Epoch 1524, Loss: 0.0005949058540863916, Final Batch Loss: 0.0001344565098406747\n",
      "Epoch 1525, Loss: 0.0020481121900957078, Final Batch Loss: 0.00010531998123042285\n",
      "Epoch 1526, Loss: 0.0036456692760111764, Final Batch Loss: 6.355631921906024e-05\n",
      "Epoch 1527, Loss: 0.0006397959950845689, Final Batch Loss: 0.0004700572753790766\n",
      "Epoch 1528, Loss: 0.0017614816315472126, Final Batch Loss: 0.0007077752379700541\n",
      "Epoch 1529, Loss: 0.004763253789860755, Final Batch Loss: 0.0008696197182871401\n",
      "Epoch 1530, Loss: 0.0005608411993307527, Final Batch Loss: 1.1515596270328388e-05\n",
      "Epoch 1531, Loss: 0.007364139310084283, Final Batch Loss: 0.007043544203042984\n",
      "Epoch 1532, Loss: 0.0005992109363432974, Final Batch Loss: 0.00034226448042318225\n",
      "Epoch 1533, Loss: 0.0009032440138980746, Final Batch Loss: 0.00027761555975303054\n",
      "Epoch 1534, Loss: 0.000683746678987518, Final Batch Loss: 3.989445394836366e-05\n",
      "Epoch 1535, Loss: 0.0004342157917562872, Final Batch Loss: 0.0002506925375200808\n",
      "Epoch 1536, Loss: 0.0006930713425390422, Final Batch Loss: 0.0003677566710393876\n",
      "Epoch 1537, Loss: 0.0006102524566813372, Final Batch Loss: 8.001157402759418e-05\n",
      "Epoch 1538, Loss: 0.004874162870692089, Final Batch Loss: 0.004548041615635157\n",
      "Epoch 1539, Loss: 0.0006251101731322706, Final Batch Loss: 0.00039153319085016847\n",
      "Epoch 1540, Loss: 0.001551377306896029, Final Batch Loss: 3.693224789458327e-05\n",
      "Epoch 1541, Loss: 0.00021460939387907274, Final Batch Loss: 3.80561723432038e-05\n",
      "Epoch 1542, Loss: 0.0005661890609189868, Final Batch Loss: 0.00029103015549480915\n",
      "Epoch 1543, Loss: 0.0032120424366439693, Final Batch Loss: 0.00012171995331300423\n",
      "Epoch 1544, Loss: 0.0004952939270879142, Final Batch Loss: 0.00038577691884711385\n",
      "Epoch 1545, Loss: 0.0005999603599775583, Final Batch Loss: 0.0002447267179377377\n",
      "Epoch 1546, Loss: 0.0003741326436283998, Final Batch Loss: 0.00011242264736210927\n",
      "Epoch 1547, Loss: 0.0020374504410938243, Final Batch Loss: 1.2335137398622464e-05\n",
      "Epoch 1548, Loss: 0.0004638076206902042, Final Batch Loss: 7.618217205163091e-05\n",
      "Epoch 1549, Loss: 0.0021413526774267666, Final Batch Loss: 0.0020504253916442394\n",
      "Epoch 1550, Loss: 0.001153371442342177, Final Batch Loss: 0.0007382042240351439\n",
      "Epoch 1551, Loss: 0.000825422554044053, Final Batch Loss: 0.00044411755516193807\n",
      "Epoch 1552, Loss: 0.002829540677339537, Final Batch Loss: 2.96299513138365e-05\n",
      "Epoch 1553, Loss: 0.0008957693789852783, Final Batch Loss: 0.0008293826249428093\n",
      "Epoch 1554, Loss: 0.00019653747585834935, Final Batch Loss: 8.110816270345822e-05\n",
      "Epoch 1555, Loss: 0.0006082671170588583, Final Batch Loss: 0.00025478628231212497\n",
      "Epoch 1556, Loss: 0.0004917484329780564, Final Batch Loss: 7.999579247552902e-05\n",
      "Epoch 1557, Loss: 0.005574686947511509, Final Batch Loss: 0.00020661254529841244\n",
      "Epoch 1558, Loss: 0.0007846202061045915, Final Batch Loss: 0.0005067293532192707\n",
      "Epoch 1559, Loss: 0.0005027606530347839, Final Batch Loss: 0.00011601454752963036\n",
      "Epoch 1560, Loss: 0.002174405351979658, Final Batch Loss: 0.0001317395071964711\n",
      "Epoch 1561, Loss: 0.0006575890583917499, Final Batch Loss: 0.00023584443260915577\n",
      "Epoch 1562, Loss: 0.005150376004166901, Final Batch Loss: 0.00468098558485508\n",
      "Epoch 1563, Loss: 0.0007347827922785655, Final Batch Loss: 0.00012292103201616555\n",
      "Epoch 1564, Loss: 0.0001681503163126763, Final Batch Loss: 5.22682057635393e-05\n",
      "Epoch 1565, Loss: 0.0003894431720254943, Final Batch Loss: 0.0002493002393748611\n",
      "Epoch 1566, Loss: 0.0005524620646610856, Final Batch Loss: 0.00034364155726507306\n",
      "Epoch 1567, Loss: 0.0006415719399228692, Final Batch Loss: 0.00034500518813729286\n",
      "Epoch 1568, Loss: 0.0004138128424528986, Final Batch Loss: 0.00034365334431640804\n",
      "Epoch 1569, Loss: 0.0012212180881761014, Final Batch Loss: 0.0001704809837974608\n",
      "Epoch 1570, Loss: 0.00023463441903004423, Final Batch Loss: 4.19129355577752e-06\n",
      "Epoch 1571, Loss: 0.0004913368647976313, Final Batch Loss: 0.0004369583912193775\n",
      "Epoch 1572, Loss: 0.00035797274176729843, Final Batch Loss: 0.00011393594468245283\n",
      "Epoch 1573, Loss: 0.0005229699454503134, Final Batch Loss: 0.00024156559084076434\n",
      "Epoch 1574, Loss: 0.00036125600308878347, Final Batch Loss: 6.279261288000271e-05\n",
      "Epoch 1575, Loss: 0.00042954697710229084, Final Batch Loss: 0.000352104107150808\n",
      "Epoch 1576, Loss: 0.0015783735434524715, Final Batch Loss: 0.000601969484705478\n",
      "Epoch 1577, Loss: 0.00024465466412948444, Final Batch Loss: 0.00018312575411982834\n",
      "Epoch 1578, Loss: 0.0004930649829475442, Final Batch Loss: 0.0004681068821810186\n",
      "Epoch 1579, Loss: 0.0039012509332678746, Final Batch Loss: 5.8173940487904474e-05\n",
      "Epoch 1580, Loss: 6.273278449953068e-05, Final Batch Loss: 3.565984661690891e-05\n",
      "Epoch 1581, Loss: 0.008387075962673407, Final Batch Loss: 0.008302346803247929\n",
      "Epoch 1582, Loss: 0.0009608200052753091, Final Batch Loss: 0.0006201117066666484\n",
      "Epoch 1583, Loss: 0.0011077509843744338, Final Batch Loss: 0.0005615521804429591\n",
      "Epoch 1584, Loss: 0.004724254074972123, Final Batch Loss: 0.003949557896703482\n",
      "Epoch 1585, Loss: 0.009056221548235044, Final Batch Loss: 0.0087595134973526\n",
      "Epoch 1586, Loss: 0.0006478921786765568, Final Batch Loss: 0.00011563760199351236\n",
      "Epoch 1587, Loss: 0.0005667234836437274, Final Batch Loss: 0.0005269226967357099\n",
      "Epoch 1588, Loss: 7.506547990487888e-05, Final Batch Loss: 3.6921646824339405e-05\n",
      "Epoch 1589, Loss: 0.00017381089855916798, Final Batch Loss: 8.461762627121061e-05\n",
      "Epoch 1590, Loss: 0.00120291426719632, Final Batch Loss: 0.00017176113033201545\n",
      "Epoch 1591, Loss: 0.0006234045140445232, Final Batch Loss: 0.0002823812246788293\n",
      "Epoch 1592, Loss: 0.0006060579762561247, Final Batch Loss: 0.00017988916079048067\n",
      "Epoch 1593, Loss: 0.0051949379267171025, Final Batch Loss: 0.004942627623677254\n",
      "Epoch 1594, Loss: 0.0010834080712811556, Final Batch Loss: 0.0010384715860709548\n",
      "Epoch 1595, Loss: 0.004298230865970254, Final Batch Loss: 0.0016380972228944302\n",
      "Epoch 1596, Loss: 0.0008817230118438601, Final Batch Loss: 0.0006696807686239481\n",
      "Epoch 1597, Loss: 0.00027514099929248914, Final Batch Loss: 0.00011214731057407334\n",
      "Epoch 1598, Loss: 0.00012523722034529783, Final Batch Loss: 7.101451774360612e-05\n",
      "Epoch 1599, Loss: 0.00027855254666064866, Final Batch Loss: 2.2212701878743246e-05\n",
      "Epoch 1600, Loss: 0.003931194405595306, Final Batch Loss: 0.003863502526655793\n",
      "Epoch 1601, Loss: 0.0002389949804637581, Final Batch Loss: 6.66546548018232e-05\n",
      "Epoch 1602, Loss: 0.0026579454133752733, Final Batch Loss: 0.0024706816766411066\n",
      "Epoch 1603, Loss: 0.0014455532364081591, Final Batch Loss: 0.0011632171226665378\n",
      "Epoch 1604, Loss: 0.0004885228627244942, Final Batch Loss: 0.00045555169344879687\n",
      "Epoch 1605, Loss: 0.03433741777553223, Final Batch Loss: 0.033908188343048096\n",
      "Epoch 1606, Loss: 0.0006763604396837763, Final Batch Loss: 0.0005797945195809007\n",
      "Epoch 1607, Loss: 0.0024973312247311696, Final Batch Loss: 0.00010078538616653532\n",
      "Epoch 1608, Loss: 0.0011225485359318554, Final Batch Loss: 0.0004832744598388672\n",
      "Epoch 1609, Loss: 0.004879053769400343, Final Batch Loss: 0.0045354231260716915\n",
      "Epoch 1610, Loss: 0.01785525059676729, Final Batch Loss: 0.017693964764475822\n",
      "Epoch 1611, Loss: 0.00022547621665580664, Final Batch Loss: 0.00020892337488476187\n",
      "Epoch 1612, Loss: 0.00011796195758506656, Final Batch Loss: 6.921430031070486e-05\n",
      "Epoch 1613, Loss: 0.0035166541929356754, Final Batch Loss: 0.0004970852169208229\n",
      "Epoch 1614, Loss: 0.0009261104787583463, Final Batch Loss: 0.00011266109504504129\n",
      "Epoch 1615, Loss: 0.0001352465087620658, Final Batch Loss: 1.193299704027595e-05\n",
      "Epoch 1616, Loss: 5.4421843287855154e-05, Final Batch Loss: 5.8760683714353945e-06\n",
      "Epoch 1617, Loss: 0.0003428658892516978, Final Batch Loss: 0.0002538459957577288\n",
      "Epoch 1618, Loss: 0.0005432060279417783, Final Batch Loss: 0.00015642732614651322\n",
      "Epoch 1619, Loss: 0.00046658907376695424, Final Batch Loss: 6.0851642047055066e-05\n",
      "Epoch 1620, Loss: 0.00020171924552414566, Final Batch Loss: 0.00013298286648932844\n",
      "Epoch 1621, Loss: 0.00023496727226302028, Final Batch Loss: 3.325483703520149e-05\n",
      "Epoch 1622, Loss: 0.0006663579697487876, Final Batch Loss: 0.0005118344561196864\n",
      "Epoch 1623, Loss: 0.0004528425124590285, Final Batch Loss: 0.0003325222642160952\n",
      "Epoch 1624, Loss: 0.0008109300106298178, Final Batch Loss: 0.00014028875739313662\n",
      "Epoch 1625, Loss: 0.001554751994262915, Final Batch Loss: 0.00011857167555717751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1626, Loss: 0.0008060286636464298, Final Batch Loss: 0.0006450543878600001\n",
      "Epoch 1627, Loss: 0.0003999633918283507, Final Batch Loss: 0.0002700486220419407\n",
      "Epoch 1628, Loss: 0.0011665919155348092, Final Batch Loss: 0.00037747874739579856\n",
      "Epoch 1629, Loss: 0.0009174992846965324, Final Batch Loss: 5.059233444626443e-05\n",
      "Epoch 1630, Loss: 0.00014585308235837147, Final Batch Loss: 6.345603469526395e-05\n",
      "Epoch 1631, Loss: 0.004380415892228484, Final Batch Loss: 0.000510835088789463\n",
      "Epoch 1632, Loss: 0.00014111453492660075, Final Batch Loss: 4.843500937568024e-05\n",
      "Epoch 1633, Loss: 0.00036085047759115696, Final Batch Loss: 0.00014972558710724115\n",
      "Epoch 1634, Loss: 0.00018048569108941592, Final Batch Loss: 0.0001280692231375724\n",
      "Epoch 1635, Loss: 0.00039404200651915744, Final Batch Loss: 0.0001144706693594344\n",
      "Epoch 1636, Loss: 0.001843390564317815, Final Batch Loss: 0.00018363007984589785\n",
      "Epoch 1637, Loss: 0.0015886023757047951, Final Batch Loss: 0.0009542793268337846\n",
      "Epoch 1638, Loss: 0.001068425626726821, Final Batch Loss: 0.000886305293533951\n",
      "Epoch 1639, Loss: 0.00032893074967432767, Final Batch Loss: 6.546250369865447e-05\n",
      "Epoch 1640, Loss: 0.00034594754106365144, Final Batch Loss: 0.00022533068840857595\n",
      "Epoch 1641, Loss: 0.0007828511588741094, Final Batch Loss: 0.000443624856416136\n",
      "Epoch 1642, Loss: 0.0005528333858819678, Final Batch Loss: 0.00032452738378196955\n",
      "Epoch 1643, Loss: 0.0005551423419092316, Final Batch Loss: 3.490299059194513e-05\n",
      "Epoch 1644, Loss: 5.319306001183577e-05, Final Batch Loss: 1.9964085367973894e-05\n",
      "Epoch 1645, Loss: 0.00032014142198022455, Final Batch Loss: 4.1364997741766274e-05\n",
      "Epoch 1646, Loss: 0.012139996280893683, Final Batch Loss: 0.009587526321411133\n",
      "Epoch 1647, Loss: 0.022577068186365068, Final Batch Loss: 0.0018564913189038634\n",
      "Epoch 1648, Loss: 0.0032594173317193054, Final Batch Loss: 4.209760663798079e-05\n",
      "Epoch 1649, Loss: 0.00044742786121787503, Final Batch Loss: 0.00039740221109241247\n",
      "Epoch 1650, Loss: 0.009066138503840193, Final Batch Loss: 7.754014222882688e-05\n",
      "Epoch 1651, Loss: 0.003210892202332616, Final Batch Loss: 0.0028795020189136267\n",
      "Epoch 1652, Loss: 0.000779008842073381, Final Batch Loss: 0.00047893120790831745\n",
      "Epoch 1653, Loss: 0.0010360956366639584, Final Batch Loss: 0.0004313419631216675\n",
      "Epoch 1654, Loss: 0.00011858788275276311, Final Batch Loss: 1.3755674444837496e-05\n",
      "Epoch 1655, Loss: 0.010751793161034584, Final Batch Loss: 0.008692755363881588\n",
      "Epoch 1656, Loss: 0.0007414046267513186, Final Batch Loss: 0.0004363862390164286\n",
      "Epoch 1657, Loss: 0.0006199045456014574, Final Batch Loss: 0.000251384568400681\n",
      "Epoch 1658, Loss: 0.0014779928897041827, Final Batch Loss: 0.0011052214540541172\n",
      "Epoch 1659, Loss: 0.0009026670595631003, Final Batch Loss: 0.00042064004810526967\n",
      "Epoch 1660, Loss: 0.002548223012126982, Final Batch Loss: 0.0011959751136600971\n",
      "Epoch 1661, Loss: 0.0001563628829899244, Final Batch Loss: 8.029677701415494e-05\n",
      "Epoch 1662, Loss: 0.0003370304621057585, Final Batch Loss: 0.00019718795374501497\n",
      "Epoch 1663, Loss: 0.0012410622730385512, Final Batch Loss: 0.0008821769151836634\n",
      "Epoch 1664, Loss: 0.00030604839776060544, Final Batch Loss: 1.1160092981299385e-05\n",
      "Epoch 1665, Loss: 0.0005346314392227214, Final Batch Loss: 0.0004978584474883974\n",
      "Epoch 1666, Loss: 0.00048256609443342313, Final Batch Loss: 0.0004095867625437677\n",
      "Epoch 1667, Loss: 0.00032677443232387304, Final Batch Loss: 0.0001668520417297259\n",
      "Epoch 1668, Loss: 0.005991400917991996, Final Batch Loss: 0.003973888233304024\n",
      "Epoch 1669, Loss: 0.0024982895047287457, Final Batch Loss: 6.26248584012501e-05\n",
      "Epoch 1670, Loss: 0.0008791196014499292, Final Batch Loss: 8.770851127337664e-05\n",
      "Epoch 1671, Loss: 0.004399196415761253, Final Batch Loss: 0.004339753184467554\n",
      "Epoch 1672, Loss: 0.0006786531885154545, Final Batch Loss: 0.00042660743929445744\n",
      "Epoch 1673, Loss: 0.00034178923669969663, Final Batch Loss: 4.6006338379811496e-05\n",
      "Epoch 1674, Loss: 0.0004039258092234377, Final Batch Loss: 3.73222901544068e-05\n",
      "Epoch 1675, Loss: 0.0015002588042989373, Final Batch Loss: 0.0005882531986571848\n",
      "Epoch 1676, Loss: 0.010395788063760847, Final Batch Loss: 0.00012316316133365035\n",
      "Epoch 1677, Loss: 0.0013951001892564818, Final Batch Loss: 1.910682476591319e-05\n",
      "Epoch 1678, Loss: 0.013515734550310299, Final Batch Loss: 0.013252461329102516\n",
      "Epoch 1679, Loss: 0.0018811270128935575, Final Batch Loss: 0.0013516690814867616\n",
      "Epoch 1680, Loss: 0.001174368371721357, Final Batch Loss: 0.000524313363712281\n",
      "Epoch 1681, Loss: 0.00011237784929107875, Final Batch Loss: 1.805660576792434e-05\n",
      "Epoch 1682, Loss: 0.004086657732841559, Final Batch Loss: 0.003932940308004618\n",
      "Epoch 1683, Loss: 0.0001668070472078398, Final Batch Loss: 0.00012799573596566916\n",
      "Epoch 1684, Loss: 0.00017389699905834277, Final Batch Loss: 5.17908165420522e-06\n",
      "Epoch 1685, Loss: 0.0003037418136955239, Final Batch Loss: 2.0561863493639976e-05\n",
      "Epoch 1686, Loss: 0.0012706434645224363, Final Batch Loss: 0.0002147046907339245\n",
      "Epoch 1687, Loss: 0.00025403279141755775, Final Batch Loss: 8.141136640915647e-05\n",
      "Epoch 1688, Loss: 0.011693396605551243, Final Batch Loss: 0.005547088570892811\n",
      "Epoch 1689, Loss: 0.0010230469051748514, Final Batch Loss: 3.746023867279291e-05\n",
      "Epoch 1690, Loss: 0.0007613330089952797, Final Batch Loss: 0.0002149138890672475\n",
      "Epoch 1691, Loss: 0.00019062691080762306, Final Batch Loss: 8.304393304570112e-06\n",
      "Epoch 1692, Loss: 0.00027452840004116297, Final Batch Loss: 8.906706352718174e-05\n",
      "Epoch 1693, Loss: 0.0015445368480868638, Final Batch Loss: 0.0014252392575144768\n",
      "Epoch 1694, Loss: 0.007717539789155126, Final Batch Loss: 0.005494582001119852\n",
      "Epoch 1695, Loss: 0.001246906875167042, Final Batch Loss: 0.0008537403191439807\n",
      "Epoch 1696, Loss: 0.00027514500106917694, Final Batch Loss: 0.00010290102363796905\n",
      "Epoch 1697, Loss: 0.00726402280270122, Final Batch Loss: 0.006869219243526459\n",
      "Epoch 1698, Loss: 0.0012649311684072018, Final Batch Loss: 0.0008979524718597531\n",
      "Epoch 1699, Loss: 0.0007549828151240945, Final Batch Loss: 0.0006631918950006366\n",
      "Epoch 1700, Loss: 0.0015238128253258765, Final Batch Loss: 0.0014576829271391034\n",
      "Epoch 1701, Loss: 0.0030150161765050143, Final Batch Loss: 0.0003189725975971669\n",
      "Epoch 1702, Loss: 0.000425373378675431, Final Batch Loss: 0.0001572481996845454\n",
      "Epoch 1703, Loss: 0.015840359279536642, Final Batch Loss: 0.0156482495367527\n",
      "Epoch 1704, Loss: 0.001450499810744077, Final Batch Loss: 0.0004980105441063643\n",
      "Epoch 1705, Loss: 0.0006487195496447384, Final Batch Loss: 0.00038598760147579014\n",
      "Epoch 1706, Loss: 0.00021300510707078502, Final Batch Loss: 0.00015010929200798273\n",
      "Epoch 1707, Loss: 9.863960440270603e-05, Final Batch Loss: 4.6048382500885054e-05\n",
      "Epoch 1708, Loss: 0.0007190844153228682, Final Batch Loss: 5.5583612265763804e-05\n",
      "Epoch 1709, Loss: 5.644877819577232e-05, Final Batch Loss: 1.3008397218072787e-05\n",
      "Epoch 1710, Loss: 0.0026051341264974326, Final Batch Loss: 0.00014339431072585285\n",
      "Epoch 1711, Loss: 0.00024077223861240782, Final Batch Loss: 5.375066029955633e-05\n",
      "Epoch 1712, Loss: 0.001684656017459929, Final Batch Loss: 0.0010739436838775873\n",
      "Epoch 1713, Loss: 0.003295881231679232, Final Batch Loss: 1.6838102965266444e-05\n",
      "Epoch 1714, Loss: 0.0010920064960373566, Final Batch Loss: 0.0009500224259682\n",
      "Epoch 1715, Loss: 0.0027745291881728917, Final Batch Loss: 7.414285209961236e-05\n",
      "Epoch 1716, Loss: 0.0005267220258247107, Final Batch Loss: 0.0001489566348027438\n",
      "Epoch 1717, Loss: 0.0008238652371801436, Final Batch Loss: 0.000445438054157421\n",
      "Epoch 1718, Loss: 5.082631923869485e-05, Final Batch Loss: 9.133012099482585e-06\n",
      "Epoch 1719, Loss: 0.0005438591724669095, Final Batch Loss: 3.859199568978511e-05\n",
      "Epoch 1720, Loss: 0.00025617667415644974, Final Batch Loss: 4.094293399248272e-05\n",
      "Epoch 1721, Loss: 0.0002113681475748308, Final Batch Loss: 0.00013782190217170864\n",
      "Epoch 1722, Loss: 0.0006909652784088394, Final Batch Loss: 2.2150348740979098e-05\n",
      "Epoch 1723, Loss: 8.906222683435772e-05, Final Batch Loss: 1.4675535567221232e-05\n",
      "Epoch 1724, Loss: 0.03687023330712691, Final Batch Loss: 0.036812566220760345\n",
      "Epoch 1725, Loss: 0.0072504503186792135, Final Batch Loss: 0.004109728615731001\n",
      "Epoch 1726, Loss: 0.0015210678975563496, Final Batch Loss: 0.001393387676216662\n",
      "Epoch 1727, Loss: 0.00421184953302145, Final Batch Loss: 0.0006011477671563625\n",
      "Epoch 1728, Loss: 0.00016282058641081676, Final Batch Loss: 2.760662027867511e-05\n",
      "Epoch 1729, Loss: 0.0018771296308841556, Final Batch Loss: 0.0017113641370087862\n",
      "Epoch 1730, Loss: 0.00016943863010965288, Final Batch Loss: 2.2416439605876803e-05\n",
      "Epoch 1731, Loss: 0.0009490187949268147, Final Batch Loss: 4.6832821681164205e-05\n",
      "Epoch 1732, Loss: 0.00042012085032183677, Final Batch Loss: 0.00027265746030025184\n",
      "Epoch 1733, Loss: 0.019711523531441344, Final Batch Loss: 0.0196837168186903\n",
      "Epoch 1734, Loss: 0.00021061486040707678, Final Batch Loss: 0.00010867776290979236\n",
      "Epoch 1735, Loss: 0.0015906153712421656, Final Batch Loss: 0.00045542512089014053\n",
      "Epoch 1736, Loss: 0.0005640085873892531, Final Batch Loss: 0.00037616907502524555\n",
      "Epoch 1737, Loss: 0.00021605177607852966, Final Batch Loss: 8.356699254363775e-05\n",
      "Epoch 1738, Loss: 0.0006851915932202246, Final Batch Loss: 3.310711690573953e-05\n",
      "Epoch 1739, Loss: 0.0022317447001114488, Final Batch Loss: 0.0011065049329772592\n",
      "Epoch 1740, Loss: 0.0004658930847654119, Final Batch Loss: 0.00019456159498076886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1741, Loss: 0.008585342671722174, Final Batch Loss: 0.004876741208136082\n",
      "Epoch 1742, Loss: 0.0017125167651101947, Final Batch Loss: 0.0012687845155596733\n",
      "Epoch 1743, Loss: 0.0011649112639133818, Final Batch Loss: 0.001105504808947444\n",
      "Epoch 1744, Loss: 0.004407302942126989, Final Batch Loss: 0.002458525588735938\n",
      "Epoch 1745, Loss: 0.002855628961697221, Final Batch Loss: 0.002572959754616022\n",
      "Epoch 1746, Loss: 0.0023244798139785416, Final Batch Loss: 3.883260797010735e-05\n",
      "Epoch 1747, Loss: 0.0008642754328320734, Final Batch Loss: 3.764841676456854e-05\n",
      "Epoch 1748, Loss: 0.00011940791955566965, Final Batch Loss: 3.4210457670269534e-05\n",
      "Epoch 1749, Loss: 0.00043991862185066566, Final Batch Loss: 8.884304406819865e-05\n",
      "Epoch 1750, Loss: 0.00022644736964139156, Final Batch Loss: 0.00017837448103819042\n",
      "Epoch 1751, Loss: 0.00015524121408816427, Final Batch Loss: 8.005218114703894e-05\n",
      "Epoch 1752, Loss: 0.00023489506293117302, Final Batch Loss: 2.044643224508036e-06\n",
      "Epoch 1753, Loss: 0.000827194657176733, Final Batch Loss: 0.00056676403619349\n",
      "Epoch 1754, Loss: 0.00018086638010572642, Final Batch Loss: 6.19697239017114e-05\n",
      "Epoch 1755, Loss: 0.00020558390679070726, Final Batch Loss: 8.010237797861919e-05\n",
      "Epoch 1756, Loss: 0.00073239479388576, Final Batch Loss: 0.00010064539674203843\n",
      "Epoch 1757, Loss: 0.024487516566296108, Final Batch Loss: 0.0002406413696007803\n",
      "Epoch 1758, Loss: 0.0011955220688832924, Final Batch Loss: 0.00014952947094570845\n",
      "Epoch 1759, Loss: 7.079923034325475e-05, Final Batch Loss: 6.113156268838793e-05\n",
      "Epoch 1760, Loss: 0.004444220641744323, Final Batch Loss: 0.00011267334048170596\n",
      "Epoch 1761, Loss: 0.0010382557229604572, Final Batch Loss: 0.00018442029249854386\n",
      "Epoch 1762, Loss: 0.0010613517952151597, Final Batch Loss: 0.0007207049638964236\n",
      "Epoch 1763, Loss: 0.0004993644542992115, Final Batch Loss: 0.00012947406503371894\n",
      "Epoch 1764, Loss: 0.0027805797290056944, Final Batch Loss: 0.0004988177679479122\n",
      "Epoch 1765, Loss: 0.00018889981947722845, Final Batch Loss: 1.6748566849855706e-05\n",
      "Epoch 1766, Loss: 0.002051925603154814, Final Batch Loss: 2.185007542720996e-05\n",
      "Epoch 1767, Loss: 0.0025511056592222303, Final Batch Loss: 0.0003662715607788414\n",
      "Epoch 1768, Loss: 0.0003702356989379041, Final Batch Loss: 0.00027149985544383526\n",
      "Epoch 1769, Loss: 0.0047458159970119596, Final Batch Loss: 0.001171923358924687\n",
      "Epoch 1770, Loss: 0.0007043437799438834, Final Batch Loss: 0.0004137687792535871\n",
      "Epoch 1771, Loss: 0.005074535612948239, Final Batch Loss: 0.0047393194399774075\n",
      "Epoch 1772, Loss: 0.0011047684238292277, Final Batch Loss: 0.0007778513827361166\n",
      "Epoch 1773, Loss: 0.0001481820763729047, Final Batch Loss: 0.00011078031820943579\n",
      "Epoch 1774, Loss: 0.011156769845911185, Final Batch Loss: 9.727109500090592e-06\n",
      "Epoch 1775, Loss: 0.0002626979876367841, Final Batch Loss: 0.0002018857776420191\n",
      "Epoch 1776, Loss: 0.00046172567817848176, Final Batch Loss: 0.00010301834845449775\n",
      "Epoch 1777, Loss: 0.0005290147237246856, Final Batch Loss: 0.00040141690988093615\n",
      "Epoch 1778, Loss: 0.0006411354406736791, Final Batch Loss: 0.00019187305588275194\n",
      "Epoch 1779, Loss: 0.00041104789124801755, Final Batch Loss: 0.00022755638929083943\n",
      "Epoch 1780, Loss: 0.0014081133176659932, Final Batch Loss: 2.3535487343906425e-05\n",
      "Epoch 1781, Loss: 0.00020014073379570618, Final Batch Loss: 5.17037624376826e-05\n",
      "Epoch 1782, Loss: 0.0006906963171786629, Final Batch Loss: 7.471135904779658e-05\n",
      "Epoch 1783, Loss: 0.0008921703483792953, Final Batch Loss: 3.729294257936999e-05\n",
      "Epoch 1784, Loss: 0.00014328956240206026, Final Batch Loss: 8.572384103899822e-05\n",
      "Epoch 1785, Loss: 0.0003828552580671385, Final Batch Loss: 0.00019130174769088626\n",
      "Epoch 1786, Loss: 0.00022889633328304626, Final Batch Loss: 3.068434671149589e-05\n",
      "Epoch 1787, Loss: 0.0002406708154012449, Final Batch Loss: 0.00016835835413075984\n",
      "Epoch 1788, Loss: 0.0023421923178830184, Final Batch Loss: 4.105884727323428e-05\n",
      "Epoch 1789, Loss: 0.0005823711398988962, Final Batch Loss: 0.0001617568777874112\n",
      "Epoch 1790, Loss: 0.0029713273979723454, Final Batch Loss: 0.0015143777709454298\n",
      "Epoch 1791, Loss: 0.00011490141969261458, Final Batch Loss: 9.846632565313485e-06\n",
      "Epoch 1792, Loss: 0.00015104831527423812, Final Batch Loss: 1.2048013559251558e-05\n",
      "Epoch 1793, Loss: 0.0002589611540315673, Final Batch Loss: 8.895696373656392e-05\n",
      "Epoch 1794, Loss: 0.0007441292764269747, Final Batch Loss: 6.204934470588341e-05\n",
      "Epoch 1795, Loss: 0.003907193546183407, Final Batch Loss: 0.002063552848994732\n",
      "Epoch 1796, Loss: 0.0004584784765029326, Final Batch Loss: 0.0003321800904814154\n",
      "Epoch 1797, Loss: 0.000781192589784041, Final Batch Loss: 0.0007100060465745628\n",
      "Epoch 1798, Loss: 0.0009474086291447747, Final Batch Loss: 0.0008933377685025334\n",
      "Epoch 1799, Loss: 0.00010361075419496046, Final Batch Loss: 3.268895852670539e-06\n",
      "Epoch 1800, Loss: 0.002146595623344183, Final Batch Loss: 0.0016020649345591664\n",
      "Epoch 1801, Loss: 0.00018481702863937244, Final Batch Loss: 7.99126282799989e-05\n",
      "Epoch 1802, Loss: 0.001983685084269382, Final Batch Loss: 6.480749289039522e-05\n",
      "Epoch 1803, Loss: 0.005514448625035584, Final Batch Loss: 0.0001686700852587819\n",
      "Epoch 1804, Loss: 7.739141665297211e-05, Final Batch Loss: 4.453273959370563e-06\n",
      "Epoch 1805, Loss: 0.0005534870142582804, Final Batch Loss: 0.00013975982437841594\n",
      "Epoch 1806, Loss: 0.00026566878386802273, Final Batch Loss: 1.230879297509091e-05\n",
      "Epoch 1807, Loss: 0.002648797204528819, Final Batch Loss: 2.898354250646662e-05\n",
      "Epoch 1808, Loss: 0.00012794604299415369, Final Batch Loss: 2.8112104700994678e-05\n",
      "Epoch 1809, Loss: 0.0020493767797233886, Final Batch Loss: 8.78033370099729e-06\n",
      "Epoch 1810, Loss: 0.0013170752790756524, Final Batch Loss: 0.0011297276942059398\n",
      "Epoch 1811, Loss: 0.03028184916911414, Final Batch Loss: 0.03024270012974739\n",
      "Epoch 1812, Loss: 0.00023811624851077795, Final Batch Loss: 0.0002052397176157683\n",
      "Epoch 1813, Loss: 0.0033440222032368183, Final Batch Loss: 0.0020276024006307125\n",
      "Epoch 1814, Loss: 0.0020300281394156627, Final Batch Loss: 0.00011175811960129067\n",
      "Epoch 1815, Loss: 0.0006883048590680119, Final Batch Loss: 3.4210705052828416e-05\n",
      "Epoch 1816, Loss: 0.0018029904094873928, Final Batch Loss: 5.886828148504719e-05\n",
      "Epoch 1817, Loss: 0.0005180938969715498, Final Batch Loss: 8.617297135060653e-05\n",
      "Epoch 1818, Loss: 0.00080917174636852, Final Batch Loss: 0.0005871274042874575\n",
      "Epoch 1819, Loss: 0.00045056286398903467, Final Batch Loss: 2.0291194232413545e-05\n",
      "Epoch 1820, Loss: 0.001137590006692335, Final Batch Loss: 0.0008931431220844388\n",
      "Epoch 1821, Loss: 0.0032407281396444887, Final Batch Loss: 0.0002653590345289558\n",
      "Epoch 1822, Loss: 0.000615616287177545, Final Batch Loss: 1.7885833585751243e-05\n",
      "Epoch 1823, Loss: 0.00021194278997427318, Final Batch Loss: 2.33783448493341e-05\n",
      "Epoch 1824, Loss: 0.0014093415811657906, Final Batch Loss: 0.0011019401717931032\n",
      "Epoch 1825, Loss: 0.0015419768169522285, Final Batch Loss: 0.0012426498578861356\n",
      "Epoch 1826, Loss: 0.0012356840998108964, Final Batch Loss: 4.787738362210803e-05\n",
      "Epoch 1827, Loss: 0.0002123536032740958, Final Batch Loss: 0.0002003170520765707\n",
      "Epoch 1828, Loss: 0.00030237846567615634, Final Batch Loss: 1.4928139535186347e-05\n",
      "Epoch 1829, Loss: 0.0007545602675236296, Final Batch Loss: 2.6876496121985838e-05\n",
      "Epoch 1830, Loss: 0.0009762236441019922, Final Batch Loss: 0.0009108830709010363\n",
      "Epoch 1831, Loss: 0.0005616352973447647, Final Batch Loss: 3.442645174800418e-05\n",
      "Epoch 1832, Loss: 0.00022606795391766354, Final Batch Loss: 0.00015683456149417907\n",
      "Epoch 1833, Loss: 0.010153073671972379, Final Batch Loss: 0.0003996573796030134\n",
      "Epoch 1834, Loss: 0.0014055431820452213, Final Batch Loss: 0.0004054189193993807\n",
      "Epoch 1835, Loss: 0.0002348062553210184, Final Batch Loss: 5.589610373135656e-05\n",
      "Epoch 1836, Loss: 0.00014088757416175213, Final Batch Loss: 1.7664036931819282e-05\n",
      "Epoch 1837, Loss: 0.0006231825245777145, Final Batch Loss: 0.00040456204442307353\n",
      "Epoch 1838, Loss: 0.000501897549838759, Final Batch Loss: 0.00041492944001220167\n",
      "Epoch 1839, Loss: 0.0005137028056196868, Final Batch Loss: 0.0002339506463613361\n",
      "Epoch 1840, Loss: 0.007612587538460502, Final Batch Loss: 0.00756109319627285\n",
      "Epoch 1841, Loss: 0.0007635288638994098, Final Batch Loss: 0.00036119422293268144\n",
      "Epoch 1842, Loss: 0.00012230258005274663, Final Batch Loss: 9.250551329387235e-07\n",
      "Epoch 1843, Loss: 0.0046971834963187575, Final Batch Loss: 0.0012102954788133502\n",
      "Epoch 1844, Loss: 0.0015585101227770792, Final Batch Loss: 2.8509997719083913e-05\n",
      "Epoch 1845, Loss: 0.008202645360142924, Final Batch Loss: 4.5701293856836855e-05\n",
      "Epoch 1846, Loss: 0.0005787041955045424, Final Batch Loss: 4.185034049442038e-05\n",
      "Epoch 1847, Loss: 0.0002248376331408508, Final Batch Loss: 0.00016064477676991373\n",
      "Epoch 1848, Loss: 9.415116437594406e-05, Final Batch Loss: 6.25100001343526e-05\n",
      "Epoch 1849, Loss: 0.00036023216762259835, Final Batch Loss: 1.0008720892074052e-05\n",
      "Epoch 1850, Loss: 0.002149751322576776, Final Batch Loss: 0.0001811053662095219\n",
      "Epoch 1851, Loss: 7.495816680602729e-05, Final Batch Loss: 5.7071170886047184e-05\n",
      "Epoch 1852, Loss: 0.0008556703687645495, Final Batch Loss: 0.000619886617641896\n",
      "Epoch 1853, Loss: 0.0002242707669211086, Final Batch Loss: 0.0002152022352674976\n",
      "Epoch 1854, Loss: 0.00018527513748267666, Final Batch Loss: 6.863484304631129e-05\n",
      "Epoch 1855, Loss: 0.000368553344742395, Final Batch Loss: 0.00019262402202002704\n",
      "Epoch 1856, Loss: 0.0015670044595026411, Final Batch Loss: 6.74108523526229e-05\n",
      "Epoch 1857, Loss: 0.0006370489281835034, Final Batch Loss: 3.4645156119950116e-05\n",
      "Epoch 1858, Loss: 0.0009398761176271364, Final Batch Loss: 0.0009000738500617445\n",
      "Epoch 1859, Loss: 0.0006777013477403671, Final Batch Loss: 0.0004640772531274706\n",
      "Epoch 1860, Loss: 0.0019826837560685817, Final Batch Loss: 0.0019470141269266605\n",
      "Epoch 1861, Loss: 0.00023926945686980616, Final Batch Loss: 1.8893069864134304e-05\n",
      "Epoch 1862, Loss: 0.00011320398868974735, Final Batch Loss: 1.6049870055212523e-06\n",
      "Epoch 1863, Loss: 5.545512067328673e-05, Final Batch Loss: 2.078067154798191e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1864, Loss: 0.0012630588025785983, Final Batch Loss: 0.0006972621195018291\n",
      "Epoch 1865, Loss: 0.0008325208618771285, Final Batch Loss: 0.0005732338759116828\n",
      "Epoch 1866, Loss: 7.829510423107422e-05, Final Batch Loss: 7.443713457178092e-06\n",
      "Epoch 1867, Loss: 0.026536586694419384, Final Batch Loss: 0.025617746636271477\n",
      "Epoch 1868, Loss: 0.0004523365350905806, Final Batch Loss: 0.00017527531599625945\n",
      "Epoch 1869, Loss: 9.706474884296767e-05, Final Batch Loss: 5.6287932238774374e-05\n",
      "Epoch 1870, Loss: 0.006927505717612803, Final Batch Loss: 0.005256375763565302\n",
      "Epoch 1871, Loss: 0.0013025791995460168, Final Batch Loss: 0.00024265401589218527\n",
      "Epoch 1872, Loss: 0.0001373830164084211, Final Batch Loss: 3.6607445508707315e-05\n",
      "Epoch 1873, Loss: 9.413913358002901e-05, Final Batch Loss: 5.9589907323243096e-05\n",
      "Epoch 1874, Loss: 0.0003935870245186379, Final Batch Loss: 0.000372146547306329\n",
      "Epoch 1875, Loss: 0.0005965500022284687, Final Batch Loss: 0.00027980309096165\n",
      "Epoch 1876, Loss: 0.0007850612309994176, Final Batch Loss: 0.0001455738820368424\n",
      "Epoch 1877, Loss: 0.005589827545918524, Final Batch Loss: 0.004583956208080053\n",
      "Epoch 1878, Loss: 0.00016396423234255053, Final Batch Loss: 0.00010882761853281409\n",
      "Epoch 1879, Loss: 4.729538886749651e-05, Final Batch Loss: 2.124281309079379e-05\n",
      "Epoch 1880, Loss: 0.00012834155495511368, Final Batch Loss: 9.011222573462874e-06\n",
      "Epoch 1881, Loss: 0.002557000465458259, Final Batch Loss: 0.0003102306218352169\n",
      "Epoch 1882, Loss: 3.62246946679079e-05, Final Batch Loss: 2.3130654881242663e-05\n",
      "Epoch 1883, Loss: 9.69226130109746e-05, Final Batch Loss: 1.6856796719366685e-05\n",
      "Epoch 1884, Loss: 0.00030232907374738716, Final Batch Loss: 3.139502587146126e-05\n",
      "Epoch 1885, Loss: 0.00021641261628246866, Final Batch Loss: 5.2616825996665284e-05\n",
      "Epoch 1886, Loss: 0.00040148530206352007, Final Batch Loss: 1.950454134203028e-05\n",
      "Epoch 1887, Loss: 0.003144078578770859, Final Batch Loss: 4.54691871709656e-05\n",
      "Epoch 1888, Loss: 0.0008519226830685511, Final Batch Loss: 8.61231965245679e-05\n",
      "Epoch 1889, Loss: 0.0002199190294049913, Final Batch Loss: 5.497024176293053e-06\n",
      "Epoch 1890, Loss: 0.0008939415511122206, Final Batch Loss: 2.0942528863088228e-05\n",
      "Epoch 1891, Loss: 0.00018237459880765527, Final Batch Loss: 0.00014006686978973448\n",
      "Epoch 1892, Loss: 0.0003086974174948409, Final Batch Loss: 0.00014100794214755297\n",
      "Epoch 1893, Loss: 0.003826564527116716, Final Batch Loss: 0.001742238993756473\n",
      "Epoch 1894, Loss: 0.012575475499033928, Final Batch Loss: 0.004771411418914795\n",
      "Epoch 1895, Loss: 0.00010518572707951535, Final Batch Loss: 7.999982335604727e-05\n",
      "Epoch 1896, Loss: 0.00018093494145432487, Final Batch Loss: 7.089344580890611e-05\n",
      "Epoch 1897, Loss: 0.000264982991211582, Final Batch Loss: 6.682608363917097e-05\n",
      "Epoch 1898, Loss: 0.00011509106116136536, Final Batch Loss: 1.838918251451105e-05\n",
      "Epoch 1899, Loss: 0.0046272308100014925, Final Batch Loss: 0.0023737377487123013\n",
      "Epoch 1900, Loss: 0.0007882928039180115, Final Batch Loss: 0.00015460136637557298\n",
      "Epoch 1901, Loss: 0.0011475414721644484, Final Batch Loss: 7.063955854391679e-05\n",
      "Epoch 1902, Loss: 0.0002075736083497759, Final Batch Loss: 0.00015766752767376602\n",
      "Epoch 1903, Loss: 0.0006462491128331749, Final Batch Loss: 2.6383740987512283e-05\n",
      "Epoch 1904, Loss: 0.002609772462164983, Final Batch Loss: 0.0024133040569722652\n",
      "Epoch 1905, Loss: 0.006248124875128269, Final Batch Loss: 0.00017234869301319122\n",
      "Epoch 1906, Loss: 0.0007448543547070585, Final Batch Loss: 0.0006288583390414715\n",
      "Epoch 1907, Loss: 0.002169174893424497, Final Batch Loss: 1.6285392121062614e-05\n",
      "Epoch 1908, Loss: 0.007826436354662292, Final Batch Loss: 0.007640086580067873\n",
      "Epoch 1909, Loss: 0.002578055326011963, Final Batch Loss: 0.002404462778940797\n",
      "Epoch 1910, Loss: 0.00040019174048211426, Final Batch Loss: 0.00033739866921678185\n",
      "Epoch 1911, Loss: 0.00014130730778560974, Final Batch Loss: 1.5614805306540802e-05\n",
      "Epoch 1912, Loss: 0.00014604148600483313, Final Batch Loss: 1.682046422502026e-05\n",
      "Epoch 1913, Loss: 0.0005299066115185269, Final Batch Loss: 6.012342964822892e-06\n",
      "Epoch 1914, Loss: 0.0005010275344830006, Final Batch Loss: 0.00025475837173871696\n",
      "Epoch 1915, Loss: 0.00016720635539968498, Final Batch Loss: 2.2487514797830954e-05\n",
      "Epoch 1916, Loss: 0.0027595328429015353, Final Batch Loss: 0.00024304453108925372\n",
      "Epoch 1917, Loss: 0.003956086788093671, Final Batch Loss: 0.003532187780365348\n",
      "Epoch 1918, Loss: 0.0015193567960523069, Final Batch Loss: 0.00014723901404067874\n",
      "Epoch 1919, Loss: 0.0008641983986308333, Final Batch Loss: 1.6824949852889404e-05\n",
      "Epoch 1920, Loss: 0.0017147397265944164, Final Batch Loss: 1.5423993318108842e-05\n",
      "Epoch 1921, Loss: 0.0009356152877444401, Final Batch Loss: 0.000865528651047498\n",
      "Epoch 1922, Loss: 0.0012653967714868486, Final Batch Loss: 0.0004983086255379021\n",
      "Epoch 1923, Loss: 0.0004284766473574564, Final Batch Loss: 0.00020985526498407125\n",
      "Epoch 1924, Loss: 0.0004714683454949409, Final Batch Loss: 6.710339221172035e-05\n",
      "Epoch 1925, Loss: 0.0004718504242191557, Final Batch Loss: 0.0004592546902131289\n",
      "Epoch 1926, Loss: 0.00029357745370361954, Final Batch Loss: 0.00021149266103748232\n",
      "Epoch 1927, Loss: 0.0001574654561409261, Final Batch Loss: 5.160922955838032e-05\n",
      "Epoch 1928, Loss: 0.0002923154252130189, Final Batch Loss: 4.05761329602683e-06\n",
      "Epoch 1929, Loss: 0.00021645851666107774, Final Batch Loss: 0.000130725689814426\n",
      "Epoch 1930, Loss: 0.00042478290561120957, Final Batch Loss: 6.127917731646448e-05\n",
      "Epoch 1931, Loss: 5.4742791689932346e-05, Final Batch Loss: 2.5449577151448466e-05\n",
      "Epoch 1932, Loss: 9.507949653198011e-05, Final Batch Loss: 2.5859331799438223e-05\n",
      "Epoch 1933, Loss: 5.74435191538214e-05, Final Batch Loss: 3.375809001227026e-06\n",
      "Epoch 1934, Loss: 0.0019324908216731274, Final Batch Loss: 1.0248827493342105e-05\n",
      "Epoch 1935, Loss: 0.0010563300602370873, Final Batch Loss: 0.0008907497394829988\n",
      "Epoch 1936, Loss: 0.004058140671986621, Final Batch Loss: 4.250031634001061e-05\n",
      "Epoch 1937, Loss: 0.0009458796121180058, Final Batch Loss: 0.0007709448109380901\n",
      "Epoch 1938, Loss: 0.0005339839444786776, Final Batch Loss: 3.626740726758726e-05\n",
      "Epoch 1939, Loss: 0.0002321974952792516, Final Batch Loss: 2.451637374178972e-05\n",
      "Epoch 1940, Loss: 0.00041260205762227997, Final Batch Loss: 0.00010477768228156492\n",
      "Epoch 1941, Loss: 0.00041437053005211055, Final Batch Loss: 0.0003401287831366062\n",
      "Epoch 1942, Loss: 0.000295358884613961, Final Batch Loss: 7.499224739149213e-05\n",
      "Epoch 1943, Loss: 0.00033203072962351143, Final Batch Loss: 0.00018200579506810755\n",
      "Epoch 1944, Loss: 0.00027923163725063205, Final Batch Loss: 7.85180163802579e-05\n",
      "Epoch 1945, Loss: 0.00014978300168877468, Final Batch Loss: 2.8065980586688966e-05\n",
      "Epoch 1946, Loss: 0.0007459335538442247, Final Batch Loss: 0.0006344615248963237\n",
      "Epoch 1947, Loss: 0.0002134633541572839, Final Batch Loss: 9.438676352147013e-05\n",
      "Epoch 1948, Loss: 0.0001294125304411864, Final Batch Loss: 3.394923624000512e-06\n",
      "Epoch 1949, Loss: 0.0004660358317778446, Final Batch Loss: 0.00010549239959800616\n",
      "Epoch 1950, Loss: 0.0023739776224829257, Final Batch Loss: 0.0022636582143604755\n",
      "Epoch 1951, Loss: 0.00014147558613331057, Final Batch Loss: 3.8490190490847453e-05\n",
      "Epoch 1952, Loss: 6.942807158338837e-05, Final Batch Loss: 4.463832738110796e-06\n",
      "Epoch 1953, Loss: 0.00042015223880298436, Final Batch Loss: 8.767176768742502e-05\n",
      "Epoch 1954, Loss: 0.00010260641647619195, Final Batch Loss: 4.9784834118327126e-05\n",
      "Epoch 1955, Loss: 0.0006307578478299547, Final Batch Loss: 1.5450135833816603e-05\n",
      "Epoch 1956, Loss: 0.00012013129526167177, Final Batch Loss: 4.063775486429222e-05\n",
      "Epoch 1957, Loss: 0.0007554428302682936, Final Batch Loss: 0.0006505030323751271\n",
      "Epoch 1958, Loss: 8.086947127594613e-05, Final Batch Loss: 4.0480983443558216e-05\n",
      "Epoch 1959, Loss: 0.0003038859490516188, Final Batch Loss: 7.342509434238309e-06\n",
      "Epoch 1960, Loss: 0.00016006388977984898, Final Batch Loss: 0.00011425912816775963\n",
      "Epoch 1961, Loss: 0.00015403913130285218, Final Batch Loss: 8.468722808174789e-05\n",
      "Epoch 1962, Loss: 0.00010982165986206383, Final Batch Loss: 3.2875155739020556e-05\n",
      "Epoch 1963, Loss: 0.00013695455800188938, Final Batch Loss: 1.4571030078514013e-05\n",
      "Epoch 1964, Loss: 0.0004698023776654736, Final Batch Loss: 7.333023859246168e-06\n",
      "Epoch 1965, Loss: 0.00011451493264758028, Final Batch Loss: 5.7644334447104484e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1966, Loss: 0.00016447616508230567, Final Batch Loss: 6.597572064492851e-05\n",
      "Epoch 1967, Loss: 0.0026701741035140003, Final Batch Loss: 5.3354187912191264e-06\n",
      "Epoch 1968, Loss: 0.002457808965118602, Final Batch Loss: 0.00024663799558766186\n",
      "Epoch 1969, Loss: 6.943012886040378e-05, Final Batch Loss: 1.7553267753100954e-05\n",
      "Epoch 1970, Loss: 0.00037776945828227326, Final Batch Loss: 0.0001119566077250056\n",
      "Epoch 1971, Loss: 0.00028686687437584624, Final Batch Loss: 0.00016727215552236885\n",
      "Epoch 1972, Loss: 0.0009043527243193239, Final Batch Loss: 0.00017052129260264337\n",
      "Epoch 1973, Loss: 9.668226630310528e-05, Final Batch Loss: 1.3172200851840898e-05\n",
      "Epoch 1974, Loss: 0.0015717183850938454, Final Batch Loss: 0.00135460973251611\n",
      "Epoch 1975, Loss: 0.00034872455944423564, Final Batch Loss: 0.00031720768311060965\n",
      "Epoch 1976, Loss: 0.00042103930900339037, Final Batch Loss: 0.00017901039973367006\n",
      "Epoch 1977, Loss: 0.0005245498541626148, Final Batch Loss: 6.230727740330622e-05\n",
      "Epoch 1978, Loss: 6.637802107434254e-05, Final Batch Loss: 1.559423799335491e-05\n",
      "Epoch 1979, Loss: 0.00032742280745878816, Final Batch Loss: 0.00018443417502567172\n",
      "Epoch 1980, Loss: 0.0002222023977083154, Final Batch Loss: 0.0001711770601104945\n",
      "Epoch 1981, Loss: 0.00022578217613045126, Final Batch Loss: 5.414977204054594e-05\n",
      "Epoch 1982, Loss: 8.912966040952597e-05, Final Batch Loss: 1.0179335731663741e-05\n",
      "Epoch 1983, Loss: 0.0004074155440321192, Final Batch Loss: 7.367397483903915e-05\n",
      "Epoch 1984, Loss: 0.002535535655624699, Final Batch Loss: 0.0024273982271552086\n",
      "Epoch 1985, Loss: 0.001403483056492405, Final Batch Loss: 0.001390867866575718\n",
      "Epoch 1986, Loss: 0.021241654991172254, Final Batch Loss: 0.020142968744039536\n",
      "Epoch 1987, Loss: 0.0032545416133871186, Final Batch Loss: 0.0032421115320175886\n",
      "Epoch 1988, Loss: 0.0007696038110225345, Final Batch Loss: 1.2517138202383649e-05\n",
      "Epoch 1989, Loss: 0.00024952221610874403, Final Batch Loss: 1.728593088046182e-05\n",
      "Epoch 1990, Loss: 6.860676694486756e-05, Final Batch Loss: 1.8544518752605654e-05\n",
      "Epoch 1991, Loss: 0.0009842374820436817, Final Batch Loss: 4.257140608387999e-05\n",
      "Epoch 1992, Loss: 5.938033837082912e-05, Final Batch Loss: 5.385908025345998e-06\n",
      "Epoch 1993, Loss: 0.006416877595256665, Final Batch Loss: 2.959776065836195e-05\n",
      "Epoch 1994, Loss: 0.0013537362901843153, Final Batch Loss: 7.720980647718534e-05\n",
      "Epoch 1995, Loss: 0.0025676818768261, Final Batch Loss: 0.00020846740517299622\n",
      "Epoch 1996, Loss: 3.157425635436084e-05, Final Batch Loss: 7.797349098837003e-06\n",
      "Epoch 1997, Loss: 7.850596739444882e-05, Final Batch Loss: 5.953418803983368e-05\n",
      "Epoch 1998, Loss: 3.4940052501042373e-05, Final Batch Loss: 1.6627993318252265e-05\n",
      "Epoch 1999, Loss: 0.00035254439353593625, Final Batch Loss: 0.00030548812355846167\n",
      "Epoch 2000, Loss: 0.0014284367061918601, Final Batch Loss: 7.236025703605264e-05\n",
      "Epoch 2001, Loss: 0.00010023272079706658, Final Batch Loss: 8.258635352831334e-05\n",
      "Epoch 2002, Loss: 0.0011368989362381399, Final Batch Loss: 0.0006443753954954445\n",
      "Epoch 2003, Loss: 7.404145071632229e-05, Final Batch Loss: 3.559475590009242e-05\n",
      "Epoch 2004, Loss: 0.0010143590916413814, Final Batch Loss: 0.0003954718995373696\n",
      "Epoch 2005, Loss: 0.001078844943549484, Final Batch Loss: 0.000698861142154783\n",
      "Epoch 2006, Loss: 0.00023537501692771912, Final Batch Loss: 0.00010780787852127105\n",
      "Epoch 2007, Loss: 0.0007715412200468563, Final Batch Loss: 2.2276788058661623e-06\n",
      "Epoch 2008, Loss: 7.872562855482101e-05, Final Batch Loss: 1.5533019904978573e-05\n",
      "Epoch 2009, Loss: 0.00013843717988493154, Final Batch Loss: 0.000124719284940511\n",
      "Epoch 2010, Loss: 0.0005148124182596803, Final Batch Loss: 0.00035924967960454524\n",
      "Epoch 2011, Loss: 2.547177609812934e-05, Final Batch Loss: 2.1851838027941994e-05\n",
      "Epoch 2012, Loss: 0.00015636661828466458, Final Batch Loss: 1.5087035535543691e-05\n",
      "Epoch 2013, Loss: 0.00010233755892841145, Final Batch Loss: 4.8314865125576034e-05\n",
      "Epoch 2014, Loss: 0.0009205561364069581, Final Batch Loss: 6.783689605072141e-05\n",
      "Epoch 2015, Loss: 0.00023664868422201835, Final Batch Loss: 3.888574065058492e-05\n",
      "Epoch 2016, Loss: 0.0007641561824129894, Final Batch Loss: 0.0006432337686419487\n",
      "Epoch 2017, Loss: 0.00016380640954594128, Final Batch Loss: 0.0001122492176364176\n",
      "Epoch 2018, Loss: 0.000349945155903697, Final Batch Loss: 4.338563303463161e-05\n",
      "Epoch 2019, Loss: 0.0014211577781679807, Final Batch Loss: 0.001397511688992381\n",
      "Epoch 2020, Loss: 0.0007392229235847481, Final Batch Loss: 0.0006683513638563454\n",
      "Epoch 2021, Loss: 0.0007551902999693993, Final Batch Loss: 5.722427886212245e-06\n",
      "Epoch 2022, Loss: 0.00027574355772230774, Final Batch Loss: 0.00020139693515375257\n",
      "Epoch 2023, Loss: 0.0005840668018208817, Final Batch Loss: 0.0004306311602704227\n",
      "Epoch 2024, Loss: 0.002146384811567259, Final Batch Loss: 1.3668455721926875e-05\n",
      "Epoch 2025, Loss: 0.0021923203312326223, Final Batch Loss: 3.098699380643666e-05\n",
      "Epoch 2026, Loss: 0.0021149468375369906, Final Batch Loss: 0.0005306490929797292\n",
      "Epoch 2027, Loss: 0.006692800554446876, Final Batch Loss: 0.0007857157615944743\n",
      "Epoch 2028, Loss: 0.00032815797021612525, Final Batch Loss: 0.0002382988022873178\n",
      "Epoch 2029, Loss: 0.00023485492329200497, Final Batch Loss: 1.2006616998405661e-05\n",
      "Epoch 2030, Loss: 0.00024771348398644477, Final Batch Loss: 0.00019297061953693628\n",
      "Epoch 2031, Loss: 0.0002990601205965504, Final Batch Loss: 0.00018912408268079162\n",
      "Epoch 2032, Loss: 0.0026162519825447816, Final Batch Loss: 0.002587800845503807\n",
      "Epoch 2033, Loss: 0.0001751328544514763, Final Batch Loss: 1.2979306802662904e-06\n",
      "Epoch 2034, Loss: 0.00014310202459455468, Final Batch Loss: 0.00010676013334887102\n",
      "Epoch 2035, Loss: 0.00043905798247578787, Final Batch Loss: 9.127962584898341e-06\n",
      "Epoch 2036, Loss: 0.0025638466759119183, Final Batch Loss: 6.026439950801432e-05\n",
      "Epoch 2037, Loss: 0.0005808792047901079, Final Batch Loss: 0.0003564132784958929\n",
      "Epoch 2038, Loss: 0.00013940798089606687, Final Batch Loss: 6.125742220319808e-05\n",
      "Epoch 2039, Loss: 0.0024624209127068752, Final Batch Loss: 2.879609564843122e-05\n",
      "Epoch 2040, Loss: 0.00017016766287270002, Final Batch Loss: 3.2749940146459267e-05\n",
      "Epoch 2041, Loss: 0.0048957250546664, Final Batch Loss: 0.0030169631354510784\n",
      "Epoch 2042, Loss: 0.0010097330923599657, Final Batch Loss: 3.611042848206125e-05\n",
      "Epoch 2043, Loss: 0.004381433478556573, Final Batch Loss: 0.003905304241925478\n",
      "Epoch 2044, Loss: 0.0007342906610574573, Final Batch Loss: 0.00037351009086705744\n",
      "Epoch 2045, Loss: 0.0022472687987828976, Final Batch Loss: 1.0920454769802745e-05\n",
      "Epoch 2046, Loss: 0.00012319522465986665, Final Batch Loss: 1.0606096111587249e-05\n",
      "Epoch 2047, Loss: 0.0011493797719595022, Final Batch Loss: 0.0010968411806970835\n",
      "Epoch 2048, Loss: 0.0001394272840116173, Final Batch Loss: 3.1740564736537635e-05\n",
      "Epoch 2049, Loss: 0.00037752193748019636, Final Batch Loss: 3.215594915673137e-05\n",
      "Epoch 2050, Loss: 0.00048471194895682856, Final Batch Loss: 1.3464705261867493e-05\n",
      "Epoch 2051, Loss: 0.0008862466984282946, Final Batch Loss: 2.5889856260619126e-05\n",
      "Epoch 2052, Loss: 0.0015200240886770189, Final Batch Loss: 0.0007813145639374852\n",
      "Epoch 2053, Loss: 0.0004449898551683873, Final Batch Loss: 5.069229518994689e-05\n",
      "Epoch 2054, Loss: 0.0009114383574342355, Final Batch Loss: 0.0007467038813047111\n",
      "Epoch 2055, Loss: 0.0031623786489944905, Final Batch Loss: 0.0003421413421165198\n",
      "Epoch 2056, Loss: 6.0192572163941804e-05, Final Batch Loss: 1.2184450497443322e-05\n",
      "Epoch 2057, Loss: 2.4692300030437764e-05, Final Batch Loss: 1.381480433337856e-05\n",
      "Epoch 2058, Loss: 0.0001797100849216804, Final Batch Loss: 5.175803380552679e-05\n",
      "Epoch 2059, Loss: 0.002963834538604715, Final Batch Loss: 1.6518033589818515e-05\n",
      "Epoch 2060, Loss: 7.812249407379568e-05, Final Batch Loss: 1.0623831485645496e-06\n",
      "Epoch 2061, Loss: 8.504510515194852e-05, Final Batch Loss: 1.7016502170008607e-05\n",
      "Epoch 2062, Loss: 0.0002940222475444898, Final Batch Loss: 6.138825847301632e-05\n",
      "Epoch 2063, Loss: 0.0003248161337978672, Final Batch Loss: 4.1127361328108236e-05\n",
      "Epoch 2064, Loss: 0.0022741214133930043, Final Batch Loss: 1.0158190889342222e-05\n",
      "Epoch 2065, Loss: 0.0002866477952920832, Final Batch Loss: 0.00016905942175071687\n",
      "Epoch 2066, Loss: 0.00022314928719424643, Final Batch Loss: 0.0001758578437147662\n",
      "Epoch 2067, Loss: 0.0002551329198468011, Final Batch Loss: 1.4425499102799222e-05\n",
      "Epoch 2068, Loss: 0.0005053407076047733, Final Batch Loss: 0.00035912575549446046\n",
      "Epoch 2069, Loss: 0.00011373162124073133, Final Batch Loss: 7.624000863870606e-05\n",
      "Epoch 2070, Loss: 0.0004966281412634999, Final Batch Loss: 0.0003225146501790732\n",
      "Epoch 2071, Loss: 0.0003833460996247595, Final Batch Loss: 1.8860786440200172e-05\n",
      "Epoch 2072, Loss: 0.0006969535606913269, Final Batch Loss: 0.00037285167491063476\n",
      "Epoch 2073, Loss: 0.003206037014024332, Final Batch Loss: 0.0002830135927069932\n",
      "Epoch 2074, Loss: 0.0006372008065227419, Final Batch Loss: 0.00016838809824548662\n",
      "Epoch 2075, Loss: 0.0011373005750101584, Final Batch Loss: 4.489271759666735e-06\n",
      "Epoch 2076, Loss: 0.0001834116701502353, Final Batch Loss: 0.00013786449562758207\n",
      "Epoch 2077, Loss: 0.00022757204715162516, Final Batch Loss: 0.00017878548533190042\n",
      "Epoch 2078, Loss: 0.0374365272000432, Final Batch Loss: 0.0037516364827752113\n",
      "Epoch 2079, Loss: 0.0006997484997555148, Final Batch Loss: 7.75353328208439e-06\n",
      "Epoch 2080, Loss: 4.81226288684411e-05, Final Batch Loss: 3.108193413936533e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2081, Loss: 0.0013090023021504749, Final Batch Loss: 0.001261841505765915\n",
      "Epoch 2082, Loss: 0.0036544044196489267, Final Batch Loss: 0.0035869756247848272\n",
      "Epoch 2083, Loss: 0.00027455675444798544, Final Batch Loss: 8.060842083068565e-05\n",
      "Epoch 2084, Loss: 0.00011653932961053215, Final Batch Loss: 3.076989742112346e-05\n",
      "Epoch 2085, Loss: 0.00045766731636831537, Final Batch Loss: 9.609291009837762e-05\n",
      "Epoch 2086, Loss: 0.0003154018822897342, Final Batch Loss: 1.1321190868329722e-05\n",
      "Epoch 2087, Loss: 0.000584475328651024, Final Batch Loss: 0.0005600908771157265\n",
      "Epoch 2088, Loss: 0.0018788583688547078, Final Batch Loss: 5.027104180044262e-06\n",
      "Epoch 2089, Loss: 0.0003539926838129759, Final Batch Loss: 3.273983020335436e-05\n",
      "Epoch 2090, Loss: 0.00010493894478713628, Final Batch Loss: 2.4732920792303048e-05\n",
      "Epoch 2091, Loss: 0.0005078486283309758, Final Batch Loss: 3.482369356788695e-05\n",
      "Epoch 2092, Loss: 0.0006901109300088137, Final Batch Loss: 0.0004911391297355294\n",
      "Epoch 2093, Loss: 0.0004844434588449076, Final Batch Loss: 0.00030418610549531877\n",
      "Epoch 2094, Loss: 0.003583111858461052, Final Batch Loss: 0.0006816452951170504\n",
      "Epoch 2095, Loss: 8.87203586898977e-05, Final Batch Loss: 1.637368586671073e-05\n",
      "Epoch 2096, Loss: 0.00045518761908169836, Final Batch Loss: 0.0004121868114452809\n",
      "Epoch 2097, Loss: 0.0002138053660019068, Final Batch Loss: 1.9518656699801795e-05\n",
      "Epoch 2098, Loss: 0.00045547616900876164, Final Batch Loss: 0.0003093387058470398\n",
      "Epoch 2099, Loss: 0.0005157351770321839, Final Batch Loss: 4.4727632484864444e-05\n",
      "Epoch 2100, Loss: 0.00024110646700137295, Final Batch Loss: 0.00020045829296577722\n",
      "Epoch 2101, Loss: 0.0003219627178623341, Final Batch Loss: 0.00025584030663594604\n",
      "Epoch 2102, Loss: 6.383814434229862e-05, Final Batch Loss: 4.674951560446061e-05\n",
      "Epoch 2103, Loss: 5.8188457842334174e-05, Final Batch Loss: 2.5571376681909896e-05\n",
      "Epoch 2104, Loss: 0.00033913416700670496, Final Batch Loss: 0.00028135653701610863\n",
      "Epoch 2105, Loss: 0.00027688151749316603, Final Batch Loss: 0.0002649742236826569\n",
      "Epoch 2106, Loss: 0.0022601931414101273, Final Batch Loss: 0.0020686467178165913\n",
      "Epoch 2107, Loss: 0.0023288878583116457, Final Batch Loss: 0.00011376714974176139\n",
      "Epoch 2108, Loss: 0.0012119991588406265, Final Batch Loss: 0.00043778150575235486\n",
      "Epoch 2109, Loss: 0.0005325239326339215, Final Batch Loss: 0.00019590120064094663\n",
      "Epoch 2110, Loss: 0.002238262110040523, Final Batch Loss: 8.10382334748283e-05\n",
      "Epoch 2111, Loss: 0.0004360971652204171, Final Batch Loss: 0.00029816656024195254\n",
      "Epoch 2112, Loss: 0.0012777866613760125, Final Batch Loss: 0.0012635583989322186\n",
      "Epoch 2113, Loss: 0.00013834753190167248, Final Batch Loss: 9.883294114843011e-05\n",
      "Epoch 2114, Loss: 5.315913676895434e-05, Final Batch Loss: 1.4739275684405584e-05\n",
      "Epoch 2115, Loss: 0.0001681685789662879, Final Batch Loss: 0.0001404490030836314\n",
      "Epoch 2116, Loss: 0.0008883158152457327, Final Batch Loss: 0.0006286618881858885\n",
      "Epoch 2117, Loss: 0.0024802882689982653, Final Batch Loss: 0.000656273914501071\n",
      "Epoch 2118, Loss: 0.00016957266780082136, Final Batch Loss: 0.0001064711032086052\n",
      "Epoch 2119, Loss: 8.928787065087818e-05, Final Batch Loss: 1.2458625860745087e-05\n",
      "Epoch 2120, Loss: 0.000132394543470582, Final Batch Loss: 5.698483073501848e-05\n",
      "Epoch 2121, Loss: 0.0012482469855967793, Final Batch Loss: 1.279206026083557e-05\n",
      "Epoch 2122, Loss: 5.061905540060252e-06, Final Batch Loss: 9.288678484153934e-07\n",
      "Epoch 2123, Loss: 0.0020484436050765, Final Batch Loss: 1.385643031426298e-06\n",
      "Epoch 2124, Loss: 0.00029236880982352886, Final Batch Loss: 2.9965676731080748e-05\n",
      "Epoch 2125, Loss: 0.0003887489656335674, Final Batch Loss: 0.00035084737464785576\n",
      "Epoch 2126, Loss: 0.0002246223061774799, Final Batch Loss: 2.006452177738538e-06\n",
      "Epoch 2127, Loss: 0.00118433250236194, Final Batch Loss: 4.844825070904335e-06\n",
      "Epoch 2128, Loss: 0.00017261448192584794, Final Batch Loss: 0.00016682766727171838\n",
      "Epoch 2129, Loss: 3.7172503652982414e-05, Final Batch Loss: 1.3055863746558316e-05\n",
      "Epoch 2130, Loss: 0.0022559434619324747, Final Batch Loss: 2.023796332650818e-05\n",
      "Epoch 2131, Loss: 0.007206559415408265, Final Batch Loss: 5.4955030464043375e-06\n",
      "Epoch 2132, Loss: 0.00011252971353314933, Final Batch Loss: 0.00010694416414480656\n",
      "Epoch 2133, Loss: 0.0008299452601931989, Final Batch Loss: 0.0006263944087550044\n",
      "Epoch 2134, Loss: 0.0031451395188923925, Final Batch Loss: 0.0028259216342121363\n",
      "Epoch 2135, Loss: 0.004674219253502088, Final Batch Loss: 7.746933988528326e-06\n",
      "Epoch 2136, Loss: 4.363248660865793e-05, Final Batch Loss: 9.44126782087551e-07\n",
      "Epoch 2137, Loss: 6.8872108386131e-05, Final Batch Loss: 2.0245734049240127e-05\n",
      "Epoch 2138, Loss: 0.00047495733542746166, Final Batch Loss: 0.00046535232104361057\n",
      "Epoch 2139, Loss: 6.179383672133554e-05, Final Batch Loss: 3.4069631510647014e-05\n",
      "Epoch 2140, Loss: 0.0008586318726884201, Final Batch Loss: 0.0006546982331201434\n",
      "Epoch 2141, Loss: 0.0027164662606082857, Final Batch Loss: 0.0008912496850825846\n",
      "Epoch 2142, Loss: 0.0016245651204371825, Final Batch Loss: 0.0001613971689948812\n",
      "Epoch 2143, Loss: 0.0005998800970701268, Final Batch Loss: 2.154530920961406e-05\n",
      "Epoch 2144, Loss: 0.0030294069147203118, Final Batch Loss: 0.0002650075184646994\n",
      "Epoch 2145, Loss: 0.034847180562792346, Final Batch Loss: 0.03475343436002731\n",
      "Epoch 2146, Loss: 0.0010993040227731399, Final Batch Loss: 6.3551883613399696e-06\n",
      "Epoch 2147, Loss: 5.494096149050165e-05, Final Batch Loss: 8.148197593982331e-06\n",
      "Epoch 2148, Loss: 4.967537518041354e-05, Final Batch Loss: 1.2807400935344049e-06\n",
      "Epoch 2149, Loss: 0.0006919852703504148, Final Batch Loss: 6.198383744049352e-06\n",
      "Epoch 2150, Loss: 0.0005661725299432874, Final Batch Loss: 7.654010551050305e-05\n",
      "Epoch 2151, Loss: 0.015990889984095702, Final Batch Loss: 1.1778789485106245e-05\n",
      "Epoch 2152, Loss: 6.480003662545641e-06, Final Batch Loss: 1.608801426300488e-06\n",
      "Epoch 2153, Loss: 5.269941198093875e-05, Final Batch Loss: 2.8828401354985544e-06\n",
      "Epoch 2154, Loss: 0.00010506296166568063, Final Batch Loss: 3.263564212829806e-05\n",
      "Epoch 2155, Loss: 0.0009484107285970822, Final Batch Loss: 0.0007283684681169689\n",
      "Epoch 2156, Loss: 0.000471594808914233, Final Batch Loss: 6.051653326721862e-05\n",
      "Epoch 2157, Loss: 0.001825800465667271, Final Batch Loss: 0.001795907854102552\n",
      "Epoch 2158, Loss: 7.777205973980017e-05, Final Batch Loss: 4.281365545466542e-05\n",
      "Epoch 2159, Loss: 6.657613084826153e-05, Final Batch Loss: 4.018584149889648e-05\n",
      "Epoch 2160, Loss: 0.006275312916841358, Final Batch Loss: 0.0060410285368561745\n",
      "Epoch 2161, Loss: 0.0037369232159107924, Final Batch Loss: 0.002934799063950777\n",
      "Epoch 2162, Loss: 0.00010979226863128133, Final Batch Loss: 8.034355414565653e-05\n",
      "Epoch 2163, Loss: 0.0002876463404390961, Final Batch Loss: 7.357799040619284e-05\n",
      "Epoch 2164, Loss: 0.0022296243041637354, Final Batch Loss: 0.00011255812569288537\n",
      "Epoch 2165, Loss: 9.224612040270586e-05, Final Batch Loss: 3.0245895686675794e-05\n",
      "Epoch 2166, Loss: 7.857067248551175e-05, Final Batch Loss: 3.9730206481181085e-05\n",
      "Epoch 2167, Loss: 0.002301581782376161, Final Batch Loss: 5.7220804592361674e-05\n",
      "Epoch 2168, Loss: 0.0018466610345058143, Final Batch Loss: 0.001055971602909267\n",
      "Epoch 2169, Loss: 0.003798192243266385, Final Batch Loss: 0.0036943103186786175\n",
      "Epoch 2170, Loss: 0.0032153219890460605, Final Batch Loss: 2.4795948775135912e-05\n",
      "Epoch 2171, Loss: 0.0057015422789845616, Final Batch Loss: 0.0002396678610239178\n",
      "Epoch 2172, Loss: 0.0016441789921373129, Final Batch Loss: 0.0009161007474176586\n",
      "Epoch 2173, Loss: 0.00584412319585681, Final Batch Loss: 0.004457505419850349\n",
      "Epoch 2174, Loss: 0.000588399067055434, Final Batch Loss: 0.0004370701208245009\n",
      "Epoch 2175, Loss: 0.002208320123827434, Final Batch Loss: 9.044471880770288e-06\n",
      "Epoch 2176, Loss: 0.005997977394144982, Final Batch Loss: 0.0007622169214300811\n",
      "Epoch 2177, Loss: 0.0009176497151202057, Final Batch Loss: 1.8011549400398508e-05\n",
      "Epoch 2178, Loss: 0.00018666835603653453, Final Batch Loss: 0.00015276808699127287\n",
      "Epoch 2179, Loss: 3.947790082747815e-05, Final Batch Loss: 7.380264833045658e-06\n",
      "Epoch 2180, Loss: 0.0002790300713968463, Final Batch Loss: 7.543285755673423e-05\n",
      "Epoch 2181, Loss: 0.0004240812413627282, Final Batch Loss: 0.00012234335008542985\n",
      "Epoch 2182, Loss: 0.00023340772168012336, Final Batch Loss: 0.00016286561731249094\n",
      "Epoch 2183, Loss: 0.003925170000002254, Final Batch Loss: 0.003896568436175585\n",
      "Epoch 2184, Loss: 0.0033470899797976017, Final Batch Loss: 0.0009589581750333309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2185, Loss: 0.000355334508640226, Final Batch Loss: 8.1375110312365e-06\n",
      "Epoch 2186, Loss: 0.0007080141804181039, Final Batch Loss: 0.00013371685054153204\n",
      "Epoch 2187, Loss: 0.0003381305298262305, Final Batch Loss: 4.825571977562504e-07\n",
      "Epoch 2188, Loss: 0.001861203447333537, Final Batch Loss: 0.00021460953576024622\n",
      "Epoch 2189, Loss: 0.0003280731070844922, Final Batch Loss: 0.00027585940551944077\n",
      "Epoch 2190, Loss: 5.830870759382378e-05, Final Batch Loss: 3.192192525602877e-05\n",
      "Epoch 2191, Loss: 2.996600596816279e-05, Final Batch Loss: 1.281646837014705e-05\n",
      "Epoch 2192, Loss: 0.0019948139438383805, Final Batch Loss: 4.026258920930559e-06\n",
      "Epoch 2193, Loss: 0.002830491546774283, Final Batch Loss: 0.0024209944531321526\n",
      "Epoch 2194, Loss: 0.0009250986040569842, Final Batch Loss: 0.0006658363272435963\n",
      "Epoch 2195, Loss: 0.004441408844286343, Final Batch Loss: 3.400811328901909e-05\n",
      "Epoch 2196, Loss: 0.0021908358758082613, Final Batch Loss: 3.181920328643173e-05\n",
      "Epoch 2197, Loss: 0.0002229535639344249, Final Batch Loss: 0.0001807361259125173\n",
      "Epoch 2198, Loss: 8.542287469026633e-05, Final Batch Loss: 4.060054197907448e-05\n",
      "Epoch 2199, Loss: 0.0020966127049177885, Final Batch Loss: 0.001532271271571517\n",
      "Epoch 2200, Loss: 0.00023661841260036454, Final Batch Loss: 6.25242610112764e-05\n",
      "Epoch 2201, Loss: 0.0014148245463729836, Final Batch Loss: 0.0001001016134978272\n",
      "Epoch 2202, Loss: 6.442698213504627e-05, Final Batch Loss: 3.408854900044389e-05\n",
      "Epoch 2203, Loss: 0.0002558409819357621, Final Batch Loss: 0.0002514109655749053\n",
      "Epoch 2204, Loss: 0.001431185573892435, Final Batch Loss: 3.393081351532601e-05\n",
      "Epoch 2205, Loss: 0.0007290724170161411, Final Batch Loss: 0.0006174057489261031\n",
      "Epoch 2206, Loss: 0.00011718834502971731, Final Batch Loss: 3.105753057752736e-05\n",
      "Epoch 2207, Loss: 0.0011979223054368049, Final Batch Loss: 0.0008281089249067008\n",
      "Epoch 2208, Loss: 0.0002516853273846209, Final Batch Loss: 0.00013525440590456128\n",
      "Epoch 2209, Loss: 6.090387796575669e-05, Final Batch Loss: 3.631264917203225e-05\n",
      "Epoch 2210, Loss: 2.5223069769708673e-05, Final Batch Loss: 7.314447884709807e-06\n",
      "Epoch 2211, Loss: 0.00029101116524543613, Final Batch Loss: 5.2164949011057615e-05\n",
      "Epoch 2212, Loss: 0.00046566159289795905, Final Batch Loss: 0.0002534658997319639\n",
      "Epoch 2213, Loss: 0.0016015978580981027, Final Batch Loss: 6.846134056104347e-06\n",
      "Epoch 2214, Loss: 0.002004724090511445, Final Batch Loss: 6.531886901939288e-05\n",
      "Epoch 2215, Loss: 0.0037315153981580806, Final Batch Loss: 0.003725344082340598\n",
      "Epoch 2216, Loss: 0.0018477817247912753, Final Batch Loss: 5.294442598824389e-05\n",
      "Epoch 2217, Loss: 0.00015130124302231707, Final Batch Loss: 0.00011708535021170974\n",
      "Epoch 2218, Loss: 0.0017453881882829592, Final Batch Loss: 1.583473931532353e-05\n",
      "Epoch 2219, Loss: 8.646668175060768e-05, Final Batch Loss: 7.584533159388229e-05\n",
      "Epoch 2220, Loss: 0.00021597763043246232, Final Batch Loss: 4.5951510401209816e-05\n",
      "Epoch 2221, Loss: 0.0007506226158966456, Final Batch Loss: 2.4002713416848565e-06\n",
      "Epoch 2222, Loss: 8.578091001254506e-05, Final Batch Loss: 6.605406088056043e-05\n",
      "Epoch 2223, Loss: 0.0001825567233026959, Final Batch Loss: 5.931476334808394e-05\n",
      "Epoch 2224, Loss: 0.00011132121289847419, Final Batch Loss: 9.250063158106059e-06\n",
      "Epoch 2225, Loss: 0.0009590229483364965, Final Batch Loss: 5.446246177598368e-06\n",
      "Epoch 2226, Loss: 0.0005890420143259689, Final Batch Loss: 5.831725138705224e-05\n",
      "Epoch 2227, Loss: 4.031317257613409e-05, Final Batch Loss: 2.5444571292609908e-05\n",
      "Epoch 2228, Loss: 0.0018638194596860558, Final Batch Loss: 0.0017400092910975218\n",
      "Epoch 2229, Loss: 7.653385182493366e-05, Final Batch Loss: 5.906690421397798e-05\n",
      "Epoch 2230, Loss: 0.0011693461710819975, Final Batch Loss: 0.0011153618106618524\n",
      "Epoch 2231, Loss: 0.000671239809889812, Final Batch Loss: 0.0006495288107544184\n",
      "Epoch 2232, Loss: 9.819004117161967e-05, Final Batch Loss: 8.186005288735032e-05\n",
      "Epoch 2233, Loss: 0.00018193486175732687, Final Batch Loss: 0.00010886827658396214\n",
      "Epoch 2234, Loss: 5.526318636839278e-05, Final Batch Loss: 3.75620620616246e-05\n",
      "Epoch 2235, Loss: 6.648894282079709e-05, Final Batch Loss: 3.4375605082459515e-06\n",
      "Epoch 2236, Loss: 0.0004119735094718635, Final Batch Loss: 4.467906546778977e-05\n",
      "Epoch 2237, Loss: 6.32742030575173e-05, Final Batch Loss: 1.6655130821163766e-05\n",
      "Epoch 2238, Loss: 0.00015699543473601807, Final Batch Loss: 0.00013948163541499525\n",
      "Epoch 2239, Loss: 0.00020945411870343378, Final Batch Loss: 0.00019552570302039385\n",
      "Epoch 2240, Loss: 0.0002468812162987888, Final Batch Loss: 0.00019967241678386927\n",
      "Epoch 2241, Loss: 0.0006123666462372057, Final Batch Loss: 0.0004973695031367242\n",
      "Epoch 2242, Loss: 0.00016062324903032277, Final Batch Loss: 0.0001383831404382363\n",
      "Epoch 2243, Loss: 0.000902216968825087, Final Batch Loss: 0.0001789690286386758\n",
      "Epoch 2244, Loss: 0.004244216746883467, Final Batch Loss: 0.00024421329726465046\n",
      "Epoch 2245, Loss: 0.00021488908168976195, Final Batch Loss: 0.00017375794413965195\n",
      "Epoch 2246, Loss: 9.68905478657689e-05, Final Batch Loss: 8.039151725824922e-05\n",
      "Epoch 2247, Loss: 0.005564789011259563, Final Batch Loss: 0.005357763264328241\n",
      "Epoch 2248, Loss: 0.00032498594373464584, Final Batch Loss: 0.00016609561862424016\n",
      "Epoch 2249, Loss: 0.0002445896971039474, Final Batch Loss: 7.644302968401462e-05\n",
      "Epoch 2250, Loss: 9.083919735530799e-05, Final Batch Loss: 3.223017984055332e-06\n",
      "Epoch 2251, Loss: 0.00037376336695160717, Final Batch Loss: 0.00017038617806974798\n",
      "Epoch 2252, Loss: 0.00014960089538362809, Final Batch Loss: 4.193355198367499e-05\n",
      "Epoch 2253, Loss: 7.623530109412968e-05, Final Batch Loss: 7.01075405231677e-05\n",
      "Epoch 2254, Loss: 1.358425163289212e-05, Final Batch Loss: 1.8453107486493536e-06\n",
      "Epoch 2255, Loss: 8.72094922215183e-05, Final Batch Loss: 2.8570455015142215e-06\n",
      "Epoch 2256, Loss: 1.0093471018990385e-05, Final Batch Loss: 3.5664668303070357e-06\n",
      "Epoch 2257, Loss: 0.0013004495413042605, Final Batch Loss: 0.0012468683999031782\n",
      "Epoch 2258, Loss: 0.0001395679530560301, Final Batch Loss: 2.3926652374939295e-06\n",
      "Epoch 2259, Loss: 0.0002277170044635568, Final Batch Loss: 3.711369799930253e-06\n",
      "Epoch 2260, Loss: 0.003353084743139334, Final Batch Loss: 0.0032406256068497896\n",
      "Epoch 2261, Loss: 2.8200533961353358e-05, Final Batch Loss: 1.3323827261046972e-05\n",
      "Epoch 2262, Loss: 3.438697058300022e-05, Final Batch Loss: 1.4309816833701916e-05\n",
      "Epoch 2263, Loss: 0.0065758647106122226, Final Batch Loss: 0.00633652787655592\n",
      "Epoch 2264, Loss: 0.00017336210839857813, Final Batch Loss: 1.309937761106994e-05\n",
      "Epoch 2265, Loss: 5.647253601637203e-05, Final Batch Loss: 8.590703146182932e-06\n",
      "Epoch 2266, Loss: 4.2407712953718146e-05, Final Batch Loss: 4.178583822067594e-06\n",
      "Epoch 2267, Loss: 0.00015449078455276322, Final Batch Loss: 0.00012835772940889\n",
      "Epoch 2268, Loss: 0.0013387488870648667, Final Batch Loss: 0.0011304138461127877\n",
      "Epoch 2269, Loss: 0.0006381833591149189, Final Batch Loss: 0.0005386245320551097\n",
      "Epoch 2270, Loss: 0.00015814072867215145, Final Batch Loss: 0.0001403999631293118\n",
      "Epoch 2271, Loss: 0.00016125037382153096, Final Batch Loss: 8.31584202387603e-06\n",
      "Epoch 2272, Loss: 6.872179437777959e-05, Final Batch Loss: 3.602271681302227e-05\n",
      "Epoch 2273, Loss: 0.00016387833056796808, Final Batch Loss: 1.8586872101877816e-05\n",
      "Epoch 2274, Loss: 0.0005265970867185388, Final Batch Loss: 0.0004833939019590616\n",
      "Epoch 2275, Loss: 0.004911876039841445, Final Batch Loss: 2.01307593670208e-05\n",
      "Epoch 2276, Loss: 0.00013025614998696255, Final Batch Loss: 0.00012509942462202162\n",
      "Epoch 2277, Loss: 8.807618542050477e-05, Final Batch Loss: 6.534277054015547e-05\n",
      "Epoch 2278, Loss: 4.2519354337855475e-05, Final Batch Loss: 3.1374115678772796e-06\n",
      "Epoch 2279, Loss: 7.489803829230368e-05, Final Batch Loss: 2.439574382151477e-05\n",
      "Epoch 2280, Loss: 0.00013718961054109968, Final Batch Loss: 9.883748134598136e-05\n",
      "Epoch 2281, Loss: 0.0008704492647666484, Final Batch Loss: 0.0008094105287455022\n",
      "Epoch 2282, Loss: 8.010173041839153e-05, Final Batch Loss: 2.5788795028347522e-05\n",
      "Epoch 2283, Loss: 0.00024546094209654257, Final Batch Loss: 0.00022870389511808753\n",
      "Epoch 2284, Loss: 4.431893330547609e-06, Final Batch Loss: 1.5239093045238405e-06\n",
      "Epoch 2285, Loss: 0.0002506593838234039, Final Batch Loss: 1.7956728015633416e-06\n",
      "Epoch 2286, Loss: 0.0001483118066971656, Final Batch Loss: 9.798933024285361e-05\n",
      "Epoch 2287, Loss: 0.0031012434337753803, Final Batch Loss: 0.002911777002736926\n",
      "Epoch 2288, Loss: 0.0003046710035050637, Final Batch Loss: 9.739508641359862e-06\n",
      "Epoch 2289, Loss: 0.0016004098035864445, Final Batch Loss: 2.909513796112151e-06\n",
      "Epoch 2290, Loss: 9.30278383748373e-05, Final Batch Loss: 6.40398429823108e-05\n",
      "Epoch 2291, Loss: 0.00044006214739056304, Final Batch Loss: 7.513157470384613e-05\n",
      "Epoch 2292, Loss: 0.0002837077481672168, Final Batch Loss: 0.000231466387049295\n",
      "Epoch 2293, Loss: 0.0038193785585463047, Final Batch Loss: 0.0013824792113155127\n",
      "Epoch 2294, Loss: 0.0006819365880801342, Final Batch Loss: 0.0005858209333382547\n",
      "Epoch 2295, Loss: 0.002426723251119256, Final Batch Loss: 0.002393127651885152\n",
      "Epoch 2296, Loss: 0.0010613192274604444, Final Batch Loss: 1.0232610065941117e-06\n",
      "Epoch 2297, Loss: 0.0020499295933404937, Final Batch Loss: 7.955114415381104e-05\n",
      "Epoch 2298, Loss: 0.0017229900461188663, Final Batch Loss: 0.0017197886481881142\n",
      "Epoch 2299, Loss: 0.00021064387692604214, Final Batch Loss: 0.000142743912874721\n",
      "Epoch 2300, Loss: 0.0002189548622482107, Final Batch Loss: 0.00020883152319584042\n",
      "Epoch 2301, Loss: 0.0019871304102707654, Final Batch Loss: 0.0002672883274499327\n",
      "Epoch 2302, Loss: 0.000377387463231571, Final Batch Loss: 0.0002472184714861214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2303, Loss: 0.00040161498327506706, Final Batch Loss: 0.00036871570046059787\n",
      "Epoch 2304, Loss: 4.085456021130085e-05, Final Batch Loss: 2.9925769922556356e-05\n",
      "Epoch 2305, Loss: 0.00021243329683784395, Final Batch Loss: 2.9253977118059993e-05\n",
      "Epoch 2306, Loss: 0.00069304826320149, Final Batch Loss: 0.00019661299302242696\n",
      "Epoch 2307, Loss: 0.0010897301945078652, Final Batch Loss: 2.995134491357021e-05\n",
      "Epoch 2308, Loss: 3.353553620399907e-05, Final Batch Loss: 1.5809189790161327e-05\n",
      "Epoch 2309, Loss: 0.006345435937646471, Final Batch Loss: 0.0063418070785701275\n",
      "Epoch 2310, Loss: 0.00048528963088756427, Final Batch Loss: 0.0003978179593104869\n",
      "Epoch 2311, Loss: 0.0018946067120850785, Final Batch Loss: 2.706408668018412e-05\n",
      "Epoch 2312, Loss: 0.0008947606984293088, Final Batch Loss: 0.0007995445048436522\n",
      "Epoch 2313, Loss: 0.001604363031219691, Final Batch Loss: 0.0014023184776306152\n",
      "Epoch 2314, Loss: 1.0973657708746032e-05, Final Batch Loss: 2.8580318485182943e-06\n",
      "Epoch 2315, Loss: 4.262234506313689e-05, Final Batch Loss: 1.9050528862862848e-05\n",
      "Epoch 2316, Loss: 0.001836481664213352, Final Batch Loss: 1.1062293197028339e-05\n",
      "Epoch 2317, Loss: 0.000151066058606375, Final Batch Loss: 7.947506674099714e-05\n",
      "Epoch 2318, Loss: 0.00041980073365266435, Final Batch Loss: 0.000388662883779034\n",
      "Epoch 2319, Loss: 8.495461224811152e-05, Final Batch Loss: 3.3071199140977114e-05\n",
      "Epoch 2320, Loss: 0.0009466617193538696, Final Batch Loss: 6.519394810311496e-05\n",
      "Epoch 2321, Loss: 0.0006245713921089191, Final Batch Loss: 5.262629201752134e-05\n",
      "Epoch 2322, Loss: 2.4386449467783677e-05, Final Batch Loss: 8.048853032960324e-07\n",
      "Epoch 2323, Loss: 0.001509042211182532, Final Batch Loss: 1.1813697710749693e-05\n",
      "Epoch 2324, Loss: 8.460563185508363e-05, Final Batch Loss: 4.625574729288928e-05\n",
      "Epoch 2325, Loss: 0.0005027849792895722, Final Batch Loss: 0.0004971069283783436\n",
      "Epoch 2326, Loss: 0.00038760614188504405, Final Batch Loss: 0.00035457260673865676\n",
      "Epoch 2327, Loss: 0.00120511170825921, Final Batch Loss: 0.0007381325121968985\n",
      "Epoch 2328, Loss: 0.00010574299903964857, Final Batch Loss: 1.154934670921648e-05\n",
      "Epoch 2329, Loss: 0.001759845981723629, Final Batch Loss: 0.00018161021580453962\n",
      "Epoch 2330, Loss: 0.003470796058536507, Final Batch Loss: 0.003229390364140272\n",
      "Epoch 2331, Loss: 0.00016914596017159056, Final Batch Loss: 0.00015837408136576414\n",
      "Epoch 2332, Loss: 0.0008283569986815564, Final Batch Loss: 3.864824975607917e-05\n",
      "Epoch 2333, Loss: 0.00010175289207836613, Final Batch Loss: 5.3254672820912674e-05\n",
      "Epoch 2334, Loss: 2.8040802135365084e-05, Final Batch Loss: 4.293169695301913e-06\n",
      "Epoch 2335, Loss: 9.442454393138178e-05, Final Batch Loss: 4.599253225023858e-05\n",
      "Epoch 2336, Loss: 9.27865803532768e-05, Final Batch Loss: 6.159911572467536e-05\n",
      "Epoch 2337, Loss: 0.0012512820103438571, Final Batch Loss: 2.350781869608909e-05\n",
      "Epoch 2338, Loss: 0.0004276550062058959, Final Batch Loss: 0.00038689709617756307\n",
      "Epoch 2339, Loss: 2.2516873741551535e-05, Final Batch Loss: 2.989633230754407e-06\n",
      "Epoch 2340, Loss: 2.8404491331457393e-05, Final Batch Loss: 4.2690667214628775e-06\n",
      "Epoch 2341, Loss: 0.0002299815341757494, Final Batch Loss: 0.00021851214114576578\n",
      "Epoch 2342, Loss: 0.0020514469943009317, Final Batch Loss: 2.524809679016471e-05\n",
      "Epoch 2343, Loss: 0.0014275753637775779, Final Batch Loss: 0.0013822460314258933\n",
      "Epoch 2344, Loss: 0.0019094109102297807, Final Batch Loss: 4.855779479839839e-06\n",
      "Epoch 2345, Loss: 9.485578516432724e-06, Final Batch Loss: 2.422310672045569e-07\n",
      "Epoch 2346, Loss: 0.0012969667004654184, Final Batch Loss: 7.157518120948225e-05\n",
      "Epoch 2347, Loss: 5.4722291679354385e-05, Final Batch Loss: 3.857286719721742e-05\n",
      "Epoch 2348, Loss: 2.766181842162041e-05, Final Batch Loss: 1.732617056404706e-05\n",
      "Epoch 2349, Loss: 0.0015023838823253755, Final Batch Loss: 3.635874963947572e-05\n",
      "Epoch 2350, Loss: 0.00016440282252006, Final Batch Loss: 7.453169928339776e-06\n",
      "Epoch 2351, Loss: 0.0028047056985087693, Final Batch Loss: 0.00035990943433716893\n",
      "Epoch 2352, Loss: 4.8984200475388207e-05, Final Batch Loss: 3.369787737028673e-05\n",
      "Epoch 2353, Loss: 0.00021193426891841227, Final Batch Loss: 1.4191945410857443e-05\n",
      "Epoch 2354, Loss: 0.0021165099533391185, Final Batch Loss: 6.11033829045482e-05\n",
      "Epoch 2355, Loss: 0.00015143846394494176, Final Batch Loss: 0.00011523740249685943\n",
      "Epoch 2356, Loss: 3.593849714889075e-05, Final Batch Loss: 5.108696768729715e-06\n",
      "Epoch 2357, Loss: 0.0007011715005091901, Final Batch Loss: 3.519033953125472e-07\n",
      "Epoch 2358, Loss: 0.0011609214125201106, Final Batch Loss: 3.910623490810394e-06\n",
      "Epoch 2359, Loss: 0.0014469984416791704, Final Batch Loss: 0.0014288801467046142\n",
      "Epoch 2360, Loss: 6.898967740198714e-06, Final Batch Loss: 5.237794084678171e-06\n",
      "Epoch 2361, Loss: 4.952506174049631e-06, Final Batch Loss: 1.8300441979590687e-06\n",
      "Epoch 2362, Loss: 0.00017751270570443012, Final Batch Loss: 3.3580963645363227e-05\n",
      "Epoch 2363, Loss: 0.0006054534605937079, Final Batch Loss: 0.00011437515786383301\n",
      "Epoch 2364, Loss: 0.000366838645277312, Final Batch Loss: 2.231401958852075e-05\n",
      "Epoch 2365, Loss: 0.0004966784181306139, Final Batch Loss: 5.812149902340025e-05\n",
      "Epoch 2366, Loss: 0.00014447277681028936, Final Batch Loss: 0.00012044938193866983\n",
      "Epoch 2367, Loss: 7.921098404040094e-05, Final Batch Loss: 2.576886436145287e-05\n",
      "Epoch 2368, Loss: 0.0004875655795331113, Final Batch Loss: 6.626551476074383e-05\n",
      "Epoch 2369, Loss: 3.591882159525994e-05, Final Batch Loss: 2.6884195904131047e-05\n",
      "Epoch 2370, Loss: 0.00016725836940167937, Final Batch Loss: 0.00013800282613374293\n",
      "Epoch 2371, Loss: 8.095848170341924e-05, Final Batch Loss: 7.316325354622677e-05\n",
      "Epoch 2372, Loss: 0.003489527980036655, Final Batch Loss: 7.352920420089504e-06\n",
      "Epoch 2373, Loss: 0.0049989480903605, Final Batch Loss: 0.0049353111535310745\n",
      "Epoch 2374, Loss: 0.00020657067398133222, Final Batch Loss: 2.6401738068670966e-05\n",
      "Epoch 2375, Loss: 0.00029937816384517646, Final Batch Loss: 5.960284852335462e-07\n",
      "Epoch 2376, Loss: 0.0014173528834362514, Final Batch Loss: 1.948636054294184e-05\n",
      "Epoch 2377, Loss: 9.752634150572703e-05, Final Batch Loss: 5.731434157496551e-06\n",
      "Epoch 2378, Loss: 0.00030994761027614004, Final Batch Loss: 4.89229478262132e-07\n",
      "Epoch 2379, Loss: 0.00372756426804699, Final Batch Loss: 0.003248224500566721\n",
      "Epoch 2380, Loss: 0.08392018429003656, Final Batch Loss: 0.08036866784095764\n",
      "Epoch 2381, Loss: 0.0009824771216244699, Final Batch Loss: 1.5314683423639508e-06\n",
      "Epoch 2382, Loss: 0.0007760561275063083, Final Batch Loss: 0.000585494446568191\n",
      "Epoch 2383, Loss: 0.003683476650621742, Final Batch Loss: 0.0003454309771768749\n",
      "Epoch 2384, Loss: 0.018674665479920805, Final Batch Loss: 0.0003234496107324958\n",
      "Epoch 2385, Loss: 0.00014358837506733835, Final Batch Loss: 0.00011855305638164282\n",
      "Epoch 2386, Loss: 0.00038322362161125056, Final Batch Loss: 1.7925642168847844e-05\n",
      "Epoch 2387, Loss: 0.00020353173204057384, Final Batch Loss: 0.0001837497839005664\n",
      "Epoch 2388, Loss: 0.00023868658536230214, Final Batch Loss: 5.0252045184606686e-05\n",
      "Epoch 2389, Loss: 0.03900160345801851, Final Batch Loss: 0.038967669010162354\n",
      "Epoch 2390, Loss: 0.00026560259902908, Final Batch Loss: 5.3707572078565136e-06\n",
      "Epoch 2391, Loss: 0.0003204742733942112, Final Batch Loss: 2.3408711058436893e-05\n",
      "Epoch 2392, Loss: 0.0001687540534476284, Final Batch Loss: 0.00014993677905295044\n",
      "Epoch 2393, Loss: 0.053957849042490125, Final Batch Loss: 0.053089845925569534\n",
      "Epoch 2394, Loss: 0.0006602052744710818, Final Batch Loss: 3.7911420804448426e-05\n",
      "Epoch 2395, Loss: 0.0033176842662214767, Final Batch Loss: 0.003292436245828867\n",
      "Epoch 2396, Loss: 0.0017726090081850998, Final Batch Loss: 0.001700776512734592\n",
      "Epoch 2397, Loss: 1.911207345983712e-05, Final Batch Loss: 1.1881941645697225e-05\n",
      "Epoch 2398, Loss: 0.00047817757877055556, Final Batch Loss: 0.0003261473320890218\n",
      "Epoch 2399, Loss: 0.00016140226944116876, Final Batch Loss: 2.3985594452824444e-05\n",
      "Epoch 2400, Loss: 0.0005566818749684899, Final Batch Loss: 6.704869974782923e-06\n",
      "Epoch 2401, Loss: 0.0009539821185171604, Final Batch Loss: 0.0004962180973961949\n",
      "Epoch 2402, Loss: 0.00511553518299479, Final Batch Loss: 5.1440278184600174e-05\n",
      "Epoch 2403, Loss: 0.00011619678571150871, Final Batch Loss: 0.00011043813719879836\n",
      "Epoch 2404, Loss: 0.0007875403389334679, Final Batch Loss: 0.0003838377306237817\n",
      "Epoch 2405, Loss: 6.539887544931844e-05, Final Batch Loss: 4.694414747064002e-05\n",
      "Epoch 2406, Loss: 0.0017159137642011046, Final Batch Loss: 0.0004448569379746914\n",
      "Epoch 2407, Loss: 0.0002815745974658057, Final Batch Loss: 0.0001275620306842029\n",
      "Epoch 2408, Loss: 0.0030866526740283007, Final Batch Loss: 0.003067574929445982\n",
      "Epoch 2409, Loss: 0.0006248691279324703, Final Batch Loss: 0.0005601469310931861\n",
      "Epoch 2410, Loss: 0.0005886750659556128, Final Batch Loss: 3.6540244764182717e-05\n",
      "Epoch 2411, Loss: 5.82923021283932e-05, Final Batch Loss: 3.747352457139641e-05\n",
      "Epoch 2412, Loss: 0.0002805223557516001, Final Batch Loss: 7.983292016433552e-05\n",
      "Epoch 2413, Loss: 0.0017076913645723835, Final Batch Loss: 0.0015859442064538598\n",
      "Epoch 2414, Loss: 6.266132913879119e-05, Final Batch Loss: 2.4728888092795387e-05\n",
      "Epoch 2415, Loss: 0.0005191011291572067, Final Batch Loss: 7.299443950614659e-06\n",
      "Epoch 2416, Loss: 0.0004108242428628728, Final Batch Loss: 8.301269554067403e-05\n",
      "Epoch 2417, Loss: 0.000282044849882368, Final Batch Loss: 0.0002381556696491316\n",
      "Epoch 2418, Loss: 0.0029053271218799637, Final Batch Loss: 0.002893265103921294\n",
      "Epoch 2419, Loss: 0.0007467708201147616, Final Batch Loss: 0.0001544274273328483\n",
      "Epoch 2420, Loss: 0.00012754600902553648, Final Batch Loss: 3.1983603548724204e-05\n",
      "Epoch 2421, Loss: 4.609026200341759e-05, Final Batch Loss: 5.127417352923658e-06\n",
      "Epoch 2422, Loss: 0.0005186363705433905, Final Batch Loss: 0.0003361739800311625\n",
      "Epoch 2423, Loss: 2.2002632704243297e-05, Final Batch Loss: 1.4687235307064839e-05\n",
      "Epoch 2424, Loss: 0.000629262309303158, Final Batch Loss: 0.0006059208535589278\n",
      "Epoch 2425, Loss: 0.0006336346559692174, Final Batch Loss: 0.00020012972527183592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2426, Loss: 0.0004187712329439819, Final Batch Loss: 0.0001865108060883358\n",
      "Epoch 2427, Loss: 0.0010105848487000912, Final Batch Loss: 8.750046254135668e-05\n",
      "Epoch 2428, Loss: 0.001886207661300432, Final Batch Loss: 0.00011348845873726532\n",
      "Epoch 2429, Loss: 0.0006252190960367443, Final Batch Loss: 0.0005969451740384102\n",
      "Epoch 2430, Loss: 0.0001941774899023585, Final Batch Loss: 9.070375381270424e-05\n",
      "Epoch 2431, Loss: 0.0017585494788363576, Final Batch Loss: 0.0014387881383299828\n",
      "Epoch 2432, Loss: 0.0017702748300507665, Final Batch Loss: 0.00027520046569406986\n",
      "Epoch 2433, Loss: 0.0023113796050893143, Final Batch Loss: 4.00745338993147e-05\n",
      "Epoch 2434, Loss: 5.849932949786307e-05, Final Batch Loss: 1.0394343007646967e-05\n",
      "Epoch 2435, Loss: 0.00031726472661830485, Final Batch Loss: 0.00018396455561742187\n",
      "Epoch 2436, Loss: 0.0006066878704586998, Final Batch Loss: 9.013213275466114e-05\n",
      "Epoch 2437, Loss: 0.0002503342111594975, Final Batch Loss: 0.00013414263958111405\n",
      "Epoch 2438, Loss: 0.0018779727251967415, Final Batch Loss: 0.0001688049960648641\n",
      "Epoch 2439, Loss: 3.2557588838244556e-05, Final Batch Loss: 6.5312265178363305e-06\n",
      "Epoch 2440, Loss: 0.0002587330491223838, Final Batch Loss: 3.792314601014368e-05\n",
      "Epoch 2441, Loss: 0.00033307391277048737, Final Batch Loss: 0.00012501917080953717\n",
      "Epoch 2442, Loss: 0.000164275654242374, Final Batch Loss: 9.186349780065939e-05\n",
      "Epoch 2443, Loss: 0.0026259844889864326, Final Batch Loss: 0.0020754330325871706\n",
      "Epoch 2444, Loss: 0.0023043575702104135, Final Batch Loss: 6.680936166958418e-06\n",
      "Epoch 2445, Loss: 0.0017161168702841678, Final Batch Loss: 7.222251497296384e-06\n",
      "Epoch 2446, Loss: 0.0003978887034463696, Final Batch Loss: 0.00032292958348989487\n",
      "Epoch 2447, Loss: 9.7474639005668e-05, Final Batch Loss: 8.635089761810377e-05\n",
      "Epoch 2448, Loss: 0.00021048849794169655, Final Batch Loss: 1.120736760640284e-05\n",
      "Epoch 2449, Loss: 7.300595098058693e-05, Final Batch Loss: 1.7530110199004412e-05\n",
      "Epoch 2450, Loss: 0.0019058743346249685, Final Batch Loss: 0.0001575333153596148\n",
      "Epoch 2451, Loss: 0.0008553912193747237, Final Batch Loss: 0.00017741510237101465\n",
      "Epoch 2452, Loss: 0.00320453808444654, Final Batch Loss: 6.352614491333952e-06\n",
      "Epoch 2453, Loss: 0.00014413333701668307, Final Batch Loss: 7.890971755841747e-05\n",
      "Epoch 2454, Loss: 0.00010904588998528197, Final Batch Loss: 5.401322778197937e-05\n",
      "Epoch 2455, Loss: 0.003299298230558634, Final Batch Loss: 0.002711034379899502\n",
      "Epoch 2456, Loss: 0.009882168844342232, Final Batch Loss: 0.008612051606178284\n",
      "Epoch 2457, Loss: 0.001344990991128725, Final Batch Loss: 2.3718183001619764e-05\n",
      "Epoch 2458, Loss: 0.0005843180697411299, Final Batch Loss: 0.00038164816214703023\n",
      "Epoch 2459, Loss: 0.0001237166507053189, Final Batch Loss: 1.1555050150491297e-05\n",
      "Epoch 2460, Loss: 5.1435205023153685e-05, Final Batch Loss: 2.2897718736203387e-05\n",
      "Epoch 2461, Loss: 0.00012482700662985735, Final Batch Loss: 3.351067107359995e-06\n",
      "Epoch 2462, Loss: 6.415835741790943e-05, Final Batch Loss: 4.023245855933055e-05\n",
      "Epoch 2463, Loss: 0.002680040262930561, Final Batch Loss: 0.0026074708439409733\n",
      "Epoch 2464, Loss: 0.00031504595244769007, Final Batch Loss: 0.00017664315237198025\n",
      "Epoch 2465, Loss: 0.00041335773858008906, Final Batch Loss: 0.0003947727382183075\n",
      "Epoch 2466, Loss: 0.0026495555648580194, Final Batch Loss: 0.0011402489617466927\n",
      "Epoch 2467, Loss: 0.007231407216750085, Final Batch Loss: 0.007099462207406759\n",
      "Epoch 2468, Loss: 5.526502900465857e-05, Final Batch Loss: 6.48665263724979e-06\n",
      "Epoch 2469, Loss: 0.003582195637136465, Final Batch Loss: 0.003548012813553214\n",
      "Epoch 2470, Loss: 0.0018864197236325708, Final Batch Loss: 1.1372151675459463e-05\n",
      "Epoch 2471, Loss: 0.0019134990325255785, Final Batch Loss: 4.177756272838451e-05\n",
      "Epoch 2472, Loss: 0.007693331630434841, Final Batch Loss: 0.0007457350729964674\n",
      "Epoch 2473, Loss: 0.0001764989210641943, Final Batch Loss: 0.00011088443716289476\n",
      "Epoch 2474, Loss: 6.938369733688887e-05, Final Batch Loss: 2.207590478064958e-05\n",
      "Epoch 2475, Loss: 0.0003894608234986663, Final Batch Loss: 0.000324148015351966\n",
      "Epoch 2476, Loss: 0.00011709083264577202, Final Batch Loss: 2.4944780307123438e-05\n",
      "Epoch 2477, Loss: 5.51648934106197e-05, Final Batch Loss: 3.013379455296672e-06\n",
      "Epoch 2478, Loss: 0.002734947018325329, Final Batch Loss: 0.001680293120443821\n",
      "Epoch 2479, Loss: 3.9486561036028434e-05, Final Batch Loss: 3.100217872997746e-05\n",
      "Epoch 2480, Loss: 8.403713582083583e-05, Final Batch Loss: 3.533692506607622e-05\n",
      "Epoch 2481, Loss: 8.823588632367318e-05, Final Batch Loss: 1.4657488463853952e-05\n",
      "Epoch 2482, Loss: 0.00020669043442467228, Final Batch Loss: 0.00010334128455724567\n",
      "Epoch 2483, Loss: 0.00017117838069680147, Final Batch Loss: 4.0344424633076414e-05\n",
      "Epoch 2484, Loss: 0.0011257018923060969, Final Batch Loss: 7.598155934829265e-05\n",
      "Epoch 2485, Loss: 0.0032402114884462208, Final Batch Loss: 7.560671656392515e-05\n",
      "Epoch 2486, Loss: 0.011579953599721193, Final Batch Loss: 0.0001681172288954258\n",
      "Epoch 2487, Loss: 0.0008045056165428832, Final Batch Loss: 2.301881613675505e-05\n",
      "Epoch 2488, Loss: 0.00017530556442579837, Final Batch Loss: 0.0001681284629739821\n",
      "Epoch 2489, Loss: 0.00010880401532631367, Final Batch Loss: 3.075143467867747e-05\n",
      "Epoch 2490, Loss: 0.00021323780674720183, Final Batch Loss: 1.195880031445995e-05\n",
      "Epoch 2491, Loss: 0.0036147396313026547, Final Batch Loss: 0.00011435069609433413\n",
      "Epoch 2492, Loss: 2.2223062842385843e-05, Final Batch Loss: 8.957940735854208e-06\n",
      "Epoch 2493, Loss: 0.00011773609003284946, Final Batch Loss: 9.925571794155985e-05\n",
      "Epoch 2494, Loss: 0.00036927561450283974, Final Batch Loss: 0.0001474693708587438\n",
      "Epoch 2495, Loss: 3.0807132134214044e-05, Final Batch Loss: 1.864003570517525e-05\n",
      "Epoch 2496, Loss: 0.00010766316336230375, Final Batch Loss: 2.0665447664214298e-05\n",
      "Epoch 2497, Loss: 1.6353408682334702e-05, Final Batch Loss: 7.5180323619861156e-06\n",
      "Epoch 2498, Loss: 4.888122384727467e-05, Final Batch Loss: 2.702744495763909e-05\n",
      "Epoch 2499, Loss: 0.006277889886405319, Final Batch Loss: 0.006038137245923281\n",
      "Epoch 2500, Loss: 0.0016960027805907885, Final Batch Loss: 1.0931393262580968e-05\n",
      "Epoch 2501, Loss: 0.00017322814164799638, Final Batch Loss: 0.0001222813007188961\n",
      "Epoch 2502, Loss: 0.0005069759281468578, Final Batch Loss: 2.3195847461465746e-05\n",
      "Epoch 2503, Loss: 2.297303672094131e-05, Final Batch Loss: 2.082769242406357e-06\n",
      "Epoch 2504, Loss: 0.0001312688873440493, Final Batch Loss: 2.7921039873035625e-05\n",
      "Epoch 2505, Loss: 6.352727177727502e-05, Final Batch Loss: 4.7247969632735476e-05\n",
      "Epoch 2506, Loss: 0.001288943002691667, Final Batch Loss: 6.6810853240895085e-06\n",
      "Epoch 2507, Loss: 0.0006145730458229082, Final Batch Loss: 8.207834980566986e-06\n",
      "Epoch 2508, Loss: 0.00015859319319133647, Final Batch Loss: 5.753861114499159e-05\n",
      "Epoch 2509, Loss: 0.0004473236149351578, Final Batch Loss: 0.00041555010830052197\n",
      "Epoch 2510, Loss: 0.00016767904890002683, Final Batch Loss: 9.311589383287355e-05\n",
      "Epoch 2511, Loss: 0.00010971803840220673, Final Batch Loss: 1.2077764949935954e-05\n",
      "Epoch 2512, Loss: 0.00017876614583656192, Final Batch Loss: 3.85095045203343e-05\n",
      "Epoch 2513, Loss: 0.0008362365188077092, Final Batch Loss: 0.00010249239858239889\n",
      "Epoch 2514, Loss: 0.0033378239604644477, Final Batch Loss: 0.0002597905113361776\n",
      "Epoch 2515, Loss: 0.0002151415501430165, Final Batch Loss: 3.336686859256588e-05\n",
      "Epoch 2516, Loss: 0.00018771108625514898, Final Batch Loss: 0.00016068300465121865\n",
      "Epoch 2517, Loss: 2.873817493309616e-05, Final Batch Loss: 6.692974693578435e-06\n",
      "Epoch 2518, Loss: 0.00247442681575194, Final Batch Loss: 0.0007691913633607328\n",
      "Epoch 2519, Loss: 0.0021183909939281875, Final Batch Loss: 0.002101379679515958\n",
      "Epoch 2520, Loss: 0.0015100079817784717, Final Batch Loss: 2.0715966456918977e-05\n",
      "Epoch 2521, Loss: 0.00024651311923662433, Final Batch Loss: 1.5001548490545247e-05\n",
      "Epoch 2522, Loss: 0.00016103005327749997, Final Batch Loss: 2.0578780095092952e-05\n",
      "Epoch 2523, Loss: 0.0004497944755712524, Final Batch Loss: 4.213130159769207e-05\n",
      "Epoch 2524, Loss: 0.00018959870794788003, Final Batch Loss: 0.00014964838919695467\n",
      "Epoch 2525, Loss: 7.101520168362185e-05, Final Batch Loss: 2.944217703770846e-05\n",
      "Epoch 2526, Loss: 0.0004316206759540364, Final Batch Loss: 0.00023602960573043674\n",
      "Epoch 2527, Loss: 0.00010426959306641947, Final Batch Loss: 2.1236692191450857e-05\n",
      "Epoch 2528, Loss: 0.0002912122799898498, Final Batch Loss: 3.1982890504878014e-05\n",
      "Epoch 2529, Loss: 0.0005654736123688053, Final Batch Loss: 2.8908700187457725e-05\n",
      "Epoch 2530, Loss: 0.00013203352955315495, Final Batch Loss: 1.1546036148502026e-05\n",
      "Epoch 2531, Loss: 5.4063001698523294e-05, Final Batch Loss: 1.3009767826588359e-05\n",
      "Epoch 2532, Loss: 0.0016380030519940192, Final Batch Loss: 2.6166762836510316e-06\n",
      "Epoch 2533, Loss: 0.00011474500115582487, Final Batch Loss: 8.249843631347176e-06\n",
      "Epoch 2534, Loss: 5.337075890565757e-05, Final Batch Loss: 3.1745406886329874e-05\n",
      "Epoch 2535, Loss: 0.0024198898463509977, Final Batch Loss: 0.002121784258633852\n",
      "Epoch 2536, Loss: 3.687544449348934e-05, Final Batch Loss: 1.0088506314787082e-05\n",
      "Epoch 2537, Loss: 1.7478882341492863e-05, Final Batch Loss: 1.686989321569854e-06\n",
      "Epoch 2538, Loss: 5.141973787203824e-05, Final Batch Loss: 8.230014714172285e-07\n",
      "Epoch 2539, Loss: 0.052060641570278676, Final Batch Loss: 0.05202190950512886\n",
      "Epoch 2540, Loss: 7.499868297600187e-05, Final Batch Loss: 3.985202783951536e-05\n",
      "Epoch 2541, Loss: 0.00012036116186209256, Final Batch Loss: 3.1896861401037313e-06\n",
      "Epoch 2542, Loss: 0.00032281912353937514, Final Batch Loss: 5.6299340940313414e-05\n",
      "Epoch 2543, Loss: 8.548194455215707e-05, Final Batch Loss: 6.946105713723227e-05\n",
      "Epoch 2544, Loss: 0.00026617856201482937, Final Batch Loss: 0.00014526501763612032\n",
      "Epoch 2545, Loss: 0.0006503304175566882, Final Batch Loss: 0.0005231497925706208\n",
      "Epoch 2546, Loss: 0.002331522264285013, Final Batch Loss: 0.002289114985615015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2547, Loss: 0.0017631275586609263, Final Batch Loss: 1.794255877030082e-05\n",
      "Epoch 2548, Loss: 0.03218124964769231, Final Batch Loss: 3.1524985388386995e-05\n",
      "Epoch 2549, Loss: 5.554015569941839e-05, Final Batch Loss: 1.2694868019025307e-05\n",
      "Epoch 2550, Loss: 0.0004041369538754225, Final Batch Loss: 0.00023800648341421038\n",
      "Epoch 2551, Loss: 8.318731124745682e-05, Final Batch Loss: 3.6880017432849854e-05\n",
      "Epoch 2552, Loss: 0.0010452165806782432, Final Batch Loss: 3.485894558252767e-05\n",
      "Epoch 2553, Loss: 0.0004426101440913044, Final Batch Loss: 9.13941694307141e-05\n",
      "Epoch 2554, Loss: 0.000716334514436312, Final Batch Loss: 0.0005728815449401736\n",
      "Epoch 2555, Loss: 0.00010719058627728373, Final Batch Loss: 3.397458931431174e-05\n",
      "Epoch 2556, Loss: 0.0028755726971212425, Final Batch Loss: 9.533877346257214e-06\n",
      "Epoch 2557, Loss: 0.0004761836025863886, Final Batch Loss: 0.0002699886681511998\n",
      "Epoch 2558, Loss: 0.00012925233750138432, Final Batch Loss: 6.14563177805394e-05\n",
      "Epoch 2559, Loss: 0.011187608424734208, Final Batch Loss: 2.00700724235503e-05\n",
      "Epoch 2560, Loss: 0.005547857814235613, Final Batch Loss: 0.00029327344964258373\n",
      "Epoch 2561, Loss: 0.0007508451999456156, Final Batch Loss: 5.0093007303075865e-05\n",
      "Epoch 2562, Loss: 0.0009413614970981143, Final Batch Loss: 0.0008714995929040015\n",
      "Epoch 2563, Loss: 0.0013690376158592699, Final Batch Loss: 1.2950708878634032e-06\n",
      "Epoch 2564, Loss: 0.0003347276433487423, Final Batch Loss: 8.25942333904095e-05\n",
      "Epoch 2565, Loss: 0.00010579010267974809, Final Batch Loss: 1.9912105926778167e-05\n",
      "Epoch 2566, Loss: 3.6754669054062106e-05, Final Batch Loss: 3.352533531142399e-05\n",
      "Epoch 2567, Loss: 0.000999725997189671, Final Batch Loss: 8.59252850204939e-07\n",
      "Epoch 2568, Loss: 0.002793402425595559, Final Batch Loss: 0.0026200725696980953\n",
      "Epoch 2569, Loss: 0.000889287618747403, Final Batch Loss: 3.4178349324065493e-06\n",
      "Epoch 2570, Loss: 0.0006184012454468757, Final Batch Loss: 0.00010335326078347862\n",
      "Epoch 2571, Loss: 0.00014707598893437535, Final Batch Loss: 8.234193956013769e-05\n",
      "Epoch 2572, Loss: 0.00045049159234622493, Final Batch Loss: 0.0003686770214699209\n",
      "Epoch 2573, Loss: 0.00019576379781938158, Final Batch Loss: 1.6429588868049905e-05\n",
      "Epoch 2574, Loss: 0.002452195272780955, Final Batch Loss: 0.0021549176890403032\n",
      "Epoch 2575, Loss: 0.0004977085191057995, Final Batch Loss: 0.0003067035286221653\n",
      "Epoch 2576, Loss: 5.763433455285849e-05, Final Batch Loss: 6.614824997086544e-06\n",
      "Epoch 2577, Loss: 0.0005531595670618117, Final Batch Loss: 0.0003948098747059703\n",
      "Epoch 2578, Loss: 0.0006969161258894019, Final Batch Loss: 6.387178291333839e-05\n",
      "Epoch 2579, Loss: 2.7236804271524306e-05, Final Batch Loss: 8.349515155714471e-06\n",
      "Epoch 2580, Loss: 4.5732098442385904e-05, Final Batch Loss: 3.692201789817773e-05\n",
      "Epoch 2581, Loss: 4.2822110572160454e-05, Final Batch Loss: 3.885942714987323e-05\n",
      "Epoch 2582, Loss: 5.3866588132223114e-05, Final Batch Loss: 1.2731114111375064e-05\n",
      "Epoch 2583, Loss: 0.0009071269014384598, Final Batch Loss: 0.0008946668822318316\n",
      "Epoch 2584, Loss: 0.0004810574755538255, Final Batch Loss: 0.00018357846420258284\n",
      "Epoch 2585, Loss: 6.746785720679327e-05, Final Batch Loss: 4.965445896232268e-06\n",
      "Epoch 2586, Loss: 0.00025061852647922933, Final Batch Loss: 0.00010837800800800323\n",
      "Epoch 2587, Loss: 0.00010454055700392928, Final Batch Loss: 9.018105629365891e-05\n",
      "Epoch 2588, Loss: 0.001577168339963464, Final Batch Loss: 3.6100252600590466e-06\n",
      "Epoch 2589, Loss: 3.0294226235128008e-05, Final Batch Loss: 2.2139585780678317e-05\n",
      "Epoch 2590, Loss: 5.295495702739572e-05, Final Batch Loss: 4.031894786749035e-05\n",
      "Epoch 2591, Loss: 0.0007256865937961265, Final Batch Loss: 1.688003249000758e-05\n",
      "Epoch 2592, Loss: 2.8462448426580522e-05, Final Batch Loss: 7.825980901543517e-06\n",
      "Epoch 2593, Loss: 2.0949751160515007e-05, Final Batch Loss: 5.423821676231455e-06\n",
      "Epoch 2594, Loss: 5.295459232002031e-05, Final Batch Loss: 2.7484182282933034e-05\n",
      "Epoch 2595, Loss: 1.0576615068202955e-05, Final Batch Loss: 1.5315620203182334e-06\n",
      "Epoch 2596, Loss: 0.00035399528860580176, Final Batch Loss: 8.881710527930409e-05\n",
      "Epoch 2597, Loss: 0.002582917455583811, Final Batch Loss: 0.0011950331972911954\n",
      "Epoch 2598, Loss: 0.00033694539160933346, Final Batch Loss: 0.00024920457508414984\n",
      "Epoch 2599, Loss: 5.855727522430243e-05, Final Batch Loss: 8.039675776672084e-06\n",
      "Epoch 2600, Loss: 5.4767398978583515e-05, Final Batch Loss: 2.3964614229043946e-05\n",
      "Epoch 2601, Loss: 0.00024902236418711254, Final Batch Loss: 0.00023821304785087705\n",
      "Epoch 2602, Loss: 3.736680810106918e-05, Final Batch Loss: 3.051949533983134e-05\n",
      "Epoch 2603, Loss: 8.180655777323409e-05, Final Batch Loss: 6.701802249153843e-06\n",
      "Epoch 2604, Loss: 0.002123364494764246, Final Batch Loss: 7.594867201987654e-05\n",
      "Epoch 2605, Loss: 0.000472942934720777, Final Batch Loss: 0.00024884066078811884\n",
      "Epoch 2606, Loss: 0.00016453157149953768, Final Batch Loss: 0.00011926313891308382\n",
      "Epoch 2607, Loss: 0.008962866941146785, Final Batch Loss: 0.008919671177864075\n",
      "Epoch 2608, Loss: 3.115164327027742e-05, Final Batch Loss: 7.736936822766438e-06\n",
      "Epoch 2609, Loss: 0.0001521249214420095, Final Batch Loss: 8.29578420962207e-05\n",
      "Epoch 2610, Loss: 0.0028854440643044654, Final Batch Loss: 0.002844817005097866\n",
      "Epoch 2611, Loss: 9.601026204109075e-05, Final Batch Loss: 5.375025921239285e-06\n",
      "Epoch 2612, Loss: 9.755380415299442e-05, Final Batch Loss: 9.308516382589005e-06\n",
      "Epoch 2613, Loss: 0.0003157069440931082, Final Batch Loss: 0.00018397603707853705\n",
      "Epoch 2614, Loss: 0.0029455022340698633, Final Batch Loss: 6.650054274359718e-06\n",
      "Epoch 2615, Loss: 8.700970283825882e-05, Final Batch Loss: 1.6521731595275924e-05\n",
      "Epoch 2616, Loss: 0.00019827939468086697, Final Batch Loss: 3.613978697103448e-05\n",
      "Epoch 2617, Loss: 5.042711018177215e-05, Final Batch Loss: 3.1769133784109727e-05\n",
      "Epoch 2618, Loss: 5.351804770725721e-05, Final Batch Loss: 1.96642190530838e-06\n",
      "Epoch 2619, Loss: 0.003942843934055418, Final Batch Loss: 0.0038509811274707317\n",
      "Epoch 2620, Loss: 0.003158427498419769, Final Batch Loss: 7.24812998669222e-05\n",
      "Epoch 2621, Loss: 0.00025334369274787605, Final Batch Loss: 0.00012631605204660445\n",
      "Epoch 2622, Loss: 0.002754976521828212, Final Batch Loss: 0.002587663708254695\n",
      "Epoch 2623, Loss: 0.002663161256350577, Final Batch Loss: 0.00047351152170449495\n",
      "Epoch 2624, Loss: 0.003138379892334342, Final Batch Loss: 0.0017545620212331414\n",
      "Epoch 2625, Loss: 0.0003218713645765092, Final Batch Loss: 4.0757582610240206e-05\n",
      "Epoch 2626, Loss: 0.001060057438394324, Final Batch Loss: 1.1434382258812548e-06\n",
      "Epoch 2627, Loss: 6.839563366156654e-05, Final Batch Loss: 4.78040101370425e-06\n",
      "Epoch 2628, Loss: 0.0001598413091414841, Final Batch Loss: 0.0001450244162697345\n",
      "Epoch 2629, Loss: 0.000666422929498367, Final Batch Loss: 0.00020818291523028165\n",
      "Epoch 2630, Loss: 0.00038545659299416, Final Batch Loss: 0.0003624579985626042\n",
      "Epoch 2631, Loss: 0.002645772590767592, Final Batch Loss: 0.0007825052016414702\n",
      "Epoch 2632, Loss: 0.000613368127233116, Final Batch Loss: 5.0157028454123065e-05\n",
      "Epoch 2633, Loss: 1.3739187579631107e-05, Final Batch Loss: 7.327570074266987e-06\n",
      "Epoch 2634, Loss: 0.00039493499616582994, Final Batch Loss: 7.26993721400504e-06\n",
      "Epoch 2635, Loss: 0.0012600028931046836, Final Batch Loss: 7.857550372136757e-05\n",
      "Epoch 2636, Loss: 0.00012554821933008498, Final Batch Loss: 0.00011053431808250025\n",
      "Epoch 2637, Loss: 0.0012691468098182668, Final Batch Loss: 3.716219680427457e-06\n",
      "Epoch 2638, Loss: 0.001395692306687124, Final Batch Loss: 0.00023876568593550473\n",
      "Epoch 2639, Loss: 0.00014621262380387634, Final Batch Loss: 7.227212336147204e-05\n",
      "Epoch 2640, Loss: 0.0004483717029017953, Final Batch Loss: 3.805152175573312e-07\n",
      "Epoch 2641, Loss: 0.0012959968589711934, Final Batch Loss: 0.0011967170285061002\n",
      "Epoch 2642, Loss: 6.478982868429739e-05, Final Batch Loss: 4.3928677769145e-05\n",
      "Epoch 2643, Loss: 0.00109459699888248, Final Batch Loss: 0.0009576908778399229\n",
      "Epoch 2644, Loss: 7.790695485709875e-05, Final Batch Loss: 2.5192300654452993e-06\n",
      "Epoch 2645, Loss: 0.00011023092883988284, Final Batch Loss: 3.2299667509505525e-05\n",
      "Epoch 2646, Loss: 0.00042390013186377473, Final Batch Loss: 4.5907905587228015e-05\n",
      "Epoch 2647, Loss: 1.1571356253625709e-05, Final Batch Loss: 8.500317562720738e-06\n",
      "Epoch 2648, Loss: 0.0012640876429941272, Final Batch Loss: 1.9302262444398366e-05\n",
      "Epoch 2649, Loss: 9.65556728260708e-05, Final Batch Loss: 1.5382365745608695e-06\n",
      "Epoch 2650, Loss: 0.00010075699719891418, Final Batch Loss: 2.4769115043454804e-05\n",
      "Epoch 2651, Loss: 0.0005257156153675169, Final Batch Loss: 0.00037199672078713775\n",
      "Epoch 2652, Loss: 8.669057297083782e-05, Final Batch Loss: 7.564554834971204e-05\n",
      "Epoch 2653, Loss: 0.0031841978197917342, Final Batch Loss: 0.0016645734431222081\n",
      "Epoch 2654, Loss: 0.0023361987696262076, Final Batch Loss: 0.002258210675790906\n",
      "Epoch 2655, Loss: 2.984398179251002e-05, Final Batch Loss: 1.4481610378425103e-05\n",
      "Epoch 2656, Loss: 0.00013754374595009722, Final Batch Loss: 0.00012938941654283553\n",
      "Epoch 2657, Loss: 2.89096105916542e-05, Final Batch Loss: 1.0238441063847858e-05\n",
      "Epoch 2658, Loss: 3.351629675307777e-05, Final Batch Loss: 4.026125679956749e-06\n",
      "Epoch 2659, Loss: 0.00010812914842972532, Final Batch Loss: 2.520717680454254e-05\n",
      "Epoch 2660, Loss: 1.1421910585340811e-05, Final Batch Loss: 5.068080554337939e-06\n",
      "Epoch 2661, Loss: 0.00023863973910920322, Final Batch Loss: 0.00019768231140915304\n",
      "Epoch 2662, Loss: 0.00126135515893111, Final Batch Loss: 1.0970317816827446e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2663, Loss: 0.0047458160552196205, Final Batch Loss: 0.004444616846740246\n",
      "Epoch 2664, Loss: 5.99573631916428e-05, Final Batch Loss: 1.0805671990965493e-05\n",
      "Epoch 2665, Loss: 0.00020437718194443733, Final Batch Loss: 0.00018072662351187319\n",
      "Epoch 2666, Loss: 0.003304025922261644, Final Batch Loss: 0.0032161371782422066\n",
      "Epoch 2667, Loss: 1.9093566379524418e-05, Final Batch Loss: 2.034992803601199e-06\n",
      "Epoch 2668, Loss: 3.148103678540792e-05, Final Batch Loss: 3.4631357266334817e-06\n",
      "Epoch 2669, Loss: 5.68911191294319e-05, Final Batch Loss: 4.4942345994058996e-05\n",
      "Epoch 2670, Loss: 0.0003558647422323702, Final Batch Loss: 0.00034795686951838434\n",
      "Epoch 2671, Loss: 0.020292673103540437, Final Batch Loss: 4.997088763047941e-05\n",
      "Epoch 2672, Loss: 0.0030942321608335988, Final Batch Loss: 1.0728689403549652e-06\n",
      "Epoch 2673, Loss: 0.002795157764921896, Final Batch Loss: 1.782416075002402e-05\n",
      "Epoch 2674, Loss: 0.0007215936784632504, Final Batch Loss: 6.634293822571635e-05\n",
      "Epoch 2675, Loss: 4.042582531837979e-05, Final Batch Loss: 6.462124474637676e-06\n",
      "Epoch 2676, Loss: 2.2484236069431063e-05, Final Batch Loss: 9.964359378500376e-06\n",
      "Epoch 2677, Loss: 0.00012211780085635837, Final Batch Loss: 9.779744141269475e-05\n",
      "Epoch 2678, Loss: 4.337170139478985e-06, Final Batch Loss: 3.0621390578744467e-06\n",
      "Epoch 2679, Loss: 0.02233113767579198, Final Batch Loss: 0.000793148297816515\n",
      "Epoch 2680, Loss: 0.0016071083059046032, Final Batch Loss: 1.1539435718077584e-07\n",
      "Epoch 2681, Loss: 0.0008996078140626196, Final Batch Loss: 3.4152853913838044e-05\n",
      "Epoch 2682, Loss: 0.0004209153412375599, Final Batch Loss: 0.0003233846800867468\n",
      "Epoch 2683, Loss: 0.0008905692961889144, Final Batch Loss: 5.753711320721777e-06\n",
      "Epoch 2684, Loss: 0.00012447272092686035, Final Batch Loss: 8.500408148393035e-05\n",
      "Epoch 2685, Loss: 2.9178520890127402e-05, Final Batch Loss: 1.5388788597192615e-05\n",
      "Epoch 2686, Loss: 0.00042303431746404385, Final Batch Loss: 1.73375792655861e-06\n",
      "Epoch 2687, Loss: 6.149872024252545e-05, Final Batch Loss: 4.053293014294468e-05\n",
      "Epoch 2688, Loss: 0.0002838165164575912, Final Batch Loss: 6.63308528601192e-05\n",
      "Epoch 2689, Loss: 0.0003413181957512279, Final Batch Loss: 1.150151092588203e-05\n",
      "Epoch 2690, Loss: 6.529924212372862e-05, Final Batch Loss: 2.4061275325948372e-05\n",
      "Epoch 2691, Loss: 2.7192902507522376e-05, Final Batch Loss: 2.255677645734977e-05\n",
      "Epoch 2692, Loss: 9.310226187153603e-05, Final Batch Loss: 4.5719530135102104e-06\n",
      "Epoch 2693, Loss: 0.002649515085067833, Final Batch Loss: 0.0026274279225617647\n",
      "Epoch 2694, Loss: 0.00015371683548437431, Final Batch Loss: 6.512887921417132e-05\n",
      "Epoch 2695, Loss: 0.020887557462629047, Final Batch Loss: 0.020870227366685867\n",
      "Epoch 2696, Loss: 0.00012781156328856014, Final Batch Loss: 8.139948477037251e-05\n",
      "Epoch 2697, Loss: 0.0009173071666737087, Final Batch Loss: 6.047881470294669e-05\n",
      "Epoch 2698, Loss: 5.185177542443853e-05, Final Batch Loss: 4.432464265846647e-05\n",
      "Epoch 2699, Loss: 0.0009752653877512785, Final Batch Loss: 9.368568498757668e-06\n",
      "Epoch 2700, Loss: 0.0023628720082342625, Final Batch Loss: 0.0005084517179057002\n",
      "Epoch 2701, Loss: 0.0010498159972485155, Final Batch Loss: 0.00012407088070176542\n",
      "Epoch 2702, Loss: 0.003405981697142124, Final Batch Loss: 0.0016034860163927078\n",
      "Epoch 2703, Loss: 0.021357296323913033, Final Batch Loss: 8.307686584885232e-06\n",
      "Epoch 2704, Loss: 0.0018578746366983978, Final Batch Loss: 2.889202551159542e-05\n",
      "Epoch 2705, Loss: 0.0001399502252752427, Final Batch Loss: 3.249296059948392e-05\n",
      "Epoch 2706, Loss: 0.0002939958358183503, Final Batch Loss: 0.0001715557009447366\n",
      "Epoch 2707, Loss: 0.002909621427534148, Final Batch Loss: 0.002512255683541298\n",
      "Epoch 2708, Loss: 4.173208799329586e-05, Final Batch Loss: 3.508540612529032e-05\n",
      "Epoch 2709, Loss: 0.000547840947547229, Final Batch Loss: 3.154778460157104e-05\n",
      "Epoch 2710, Loss: 0.000902611169294687, Final Batch Loss: 0.0008785229292698205\n",
      "Epoch 2711, Loss: 0.0017903905609273352, Final Batch Loss: 9.743122063810006e-05\n",
      "Epoch 2712, Loss: 0.0007588322623632848, Final Batch Loss: 0.00016611919272691011\n",
      "Epoch 2713, Loss: 3.8724099795217626e-05, Final Batch Loss: 8.085427907644771e-06\n",
      "Epoch 2714, Loss: 9.54540264501702e-05, Final Batch Loss: 2.6589204935589805e-05\n",
      "Epoch 2715, Loss: 9.16891913220752e-05, Final Batch Loss: 3.396480678929947e-05\n",
      "Epoch 2716, Loss: 0.0014387972478289157, Final Batch Loss: 0.0003443633031565696\n",
      "Epoch 2717, Loss: 0.003439928686930216, Final Batch Loss: 0.0034225760027766228\n",
      "Epoch 2718, Loss: 0.00015280484512913972, Final Batch Loss: 1.8963823094964027e-05\n",
      "Epoch 2719, Loss: 0.004176683956757188, Final Batch Loss: 0.003109302604570985\n",
      "Epoch 2720, Loss: 0.0014598203524656128, Final Batch Loss: 6.024054528097622e-05\n",
      "Epoch 2721, Loss: 0.002269772463478148, Final Batch Loss: 0.00023753161076456308\n",
      "Epoch 2722, Loss: 6.938759906915948e-05, Final Batch Loss: 8.100090781226754e-06\n",
      "Epoch 2723, Loss: 0.002664272702531889, Final Batch Loss: 0.0022507335525006056\n",
      "Epoch 2724, Loss: 1.9124045593343908e-05, Final Batch Loss: 1.5690626241848804e-05\n",
      "Epoch 2725, Loss: 9.745030365593266e-05, Final Batch Loss: 8.23406080598943e-05\n",
      "Epoch 2726, Loss: 0.0009792307391762733, Final Batch Loss: 0.0005774948513135314\n",
      "Epoch 2727, Loss: 0.0001746735792949039, Final Batch Loss: 0.00017214803665410727\n",
      "Epoch 2728, Loss: 0.00013650712571688928, Final Batch Loss: 4.461510616238229e-05\n",
      "Epoch 2729, Loss: 0.00011017025462933816, Final Batch Loss: 3.782361090998165e-05\n",
      "Epoch 2730, Loss: 2.6479213147467817e-05, Final Batch Loss: 1.3503783975465922e-06\n",
      "Epoch 2731, Loss: 4.039512987219496e-05, Final Batch Loss: 8.812089618004393e-06\n",
      "Epoch 2732, Loss: 0.01544428904844608, Final Batch Loss: 6.867659521958558e-06\n",
      "Epoch 2733, Loss: 0.026238681537506636, Final Batch Loss: 0.02615625411272049\n",
      "Epoch 2734, Loss: 3.4399459764244966e-05, Final Batch Loss: 1.9368038920219988e-05\n",
      "Epoch 2735, Loss: 0.00023410355424857698, Final Batch Loss: 0.0001855546433944255\n",
      "Epoch 2736, Loss: 7.178185251177638e-05, Final Batch Loss: 6.285610197664937e-06\n",
      "Epoch 2737, Loss: 0.0025599528412385553, Final Batch Loss: 4.866796643909765e-06\n",
      "Epoch 2738, Loss: 8.983128986983502e-05, Final Batch Loss: 9.364846391690662e-07\n",
      "Epoch 2739, Loss: 0.0001077847155102063, Final Batch Loss: 8.217942377086729e-05\n",
      "Epoch 2740, Loss: 5.254299912849092e-05, Final Batch Loss: 4.808004814549349e-05\n",
      "Epoch 2741, Loss: 0.0002348428834011429, Final Batch Loss: 4.863076355832163e-06\n",
      "Epoch 2742, Loss: 0.0005409765944932587, Final Batch Loss: 3.073964762734249e-05\n",
      "Epoch 2743, Loss: 0.00014057768566999584, Final Batch Loss: 6.675759505014867e-05\n",
      "Epoch 2744, Loss: 0.001721724052913487, Final Batch Loss: 0.0010440031765028834\n",
      "Epoch 2745, Loss: 0.0001226883632625686, Final Batch Loss: 2.5958341211662628e-05\n",
      "Epoch 2746, Loss: 0.0001775725631887326, Final Batch Loss: 2.1560839741141535e-05\n",
      "Epoch 2747, Loss: 0.04494251297728624, Final Batch Loss: 0.0447511300444603\n",
      "Epoch 2748, Loss: 0.0012430387432686985, Final Batch Loss: 0.00021557888248935342\n",
      "Epoch 2749, Loss: 0.000211316131753847, Final Batch Loss: 6.316778308246285e-05\n",
      "Epoch 2750, Loss: 0.0010759506330941804, Final Batch Loss: 4.413381248014048e-05\n",
      "Epoch 2751, Loss: 0.00012247766426298767, Final Batch Loss: 6.319237581919879e-05\n",
      "Epoch 2752, Loss: 0.00036992532113799825, Final Batch Loss: 0.00026596072711981833\n",
      "Epoch 2753, Loss: 0.00044526664714794606, Final Batch Loss: 8.520889969076961e-05\n",
      "Epoch 2754, Loss: 9.668337133916793e-05, Final Batch Loss: 1.4767235370527487e-05\n",
      "Epoch 2755, Loss: 0.0004603850429703016, Final Batch Loss: 4.120789890293963e-05\n",
      "Epoch 2756, Loss: 0.000277757178992033, Final Batch Loss: 0.0001582647382747382\n",
      "Epoch 2757, Loss: 0.0002637738361954689, Final Batch Loss: 8.320641063619405e-05\n",
      "Epoch 2758, Loss: 0.0012399900042510126, Final Batch Loss: 0.0012233250308781862\n",
      "Epoch 2759, Loss: 5.1057597374892794e-05, Final Batch Loss: 2.226010474259965e-05\n",
      "Epoch 2760, Loss: 0.0007826498076610733, Final Batch Loss: 0.000737076043151319\n",
      "Epoch 2761, Loss: 0.00022554783754458185, Final Batch Loss: 2.5363644454046153e-05\n",
      "Epoch 2762, Loss: 0.0002933366486104205, Final Batch Loss: 0.00011805034591816366\n",
      "Epoch 2763, Loss: 9.067951032193378e-05, Final Batch Loss: 4.5346299884840846e-05\n",
      "Epoch 2764, Loss: 0.00025389571965206414, Final Batch Loss: 8.891682955436409e-05\n",
      "Epoch 2765, Loss: 0.00019283476285636425, Final Batch Loss: 2.3423999664373696e-05\n",
      "Epoch 2766, Loss: 0.00017255971033591777, Final Batch Loss: 0.00010012667189585045\n",
      "Epoch 2767, Loss: 9.002716615214013e-05, Final Batch Loss: 5.6894754379754886e-05\n",
      "Epoch 2768, Loss: 0.00016348255303455517, Final Batch Loss: 7.664112490601838e-05\n",
      "Epoch 2769, Loss: 0.0005832815077155828, Final Batch Loss: 0.0003890656225848943\n",
      "Epoch 2770, Loss: 0.0027873374347109348, Final Batch Loss: 0.000341014500008896\n",
      "Epoch 2771, Loss: 0.0007305902690859511, Final Batch Loss: 0.0005740256747230887\n",
      "Epoch 2772, Loss: 0.0002860161766875535, Final Batch Loss: 0.0002087629836751148\n",
      "Epoch 2773, Loss: 0.00023678112484049052, Final Batch Loss: 6.691835005767643e-05\n",
      "Epoch 2774, Loss: 7.17112015991006e-05, Final Batch Loss: 4.114244075026363e-05\n",
      "Epoch 2775, Loss: 0.001648707071581157, Final Batch Loss: 5.9483445511432365e-05\n",
      "Epoch 2776, Loss: 0.00022639805501967203, Final Batch Loss: 1.5041861843201332e-05\n",
      "Epoch 2777, Loss: 0.0012170840036560548, Final Batch Loss: 2.741673779382836e-05\n",
      "Epoch 2778, Loss: 3.775669870265119e-05, Final Batch Loss: 2.6472673653188394e-06\n",
      "Epoch 2779, Loss: 0.00043942568299826235, Final Batch Loss: 1.4261036994867027e-05\n",
      "Epoch 2780, Loss: 0.0009141790287685581, Final Batch Loss: 7.279066630871966e-05\n",
      "Epoch 2781, Loss: 6.164845945022535e-05, Final Batch Loss: 2.916823905252386e-05\n",
      "Epoch 2782, Loss: 4.654017266148003e-05, Final Batch Loss: 1.0776800081657711e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2783, Loss: 0.0006443207748816349, Final Batch Loss: 0.00010364448098698631\n",
      "Epoch 2784, Loss: 0.0005652441031998023, Final Batch Loss: 0.00013454655709210783\n",
      "Epoch 2785, Loss: 0.0008846871642163023, Final Batch Loss: 0.0008659952436573803\n",
      "Epoch 2786, Loss: 7.926166654215194e-05, Final Batch Loss: 5.04144663864281e-05\n",
      "Epoch 2787, Loss: 0.002403934356152604, Final Batch Loss: 1.4569247468898539e-05\n",
      "Epoch 2788, Loss: 0.001348053073797928, Final Batch Loss: 4.025261205242714e-06\n",
      "Epoch 2789, Loss: 7.393439227598719e-05, Final Batch Loss: 3.499555532471277e-05\n",
      "Epoch 2790, Loss: 5.9996944401063956e-05, Final Batch Loss: 4.56178022432141e-05\n",
      "Epoch 2791, Loss: 0.0015332850398408482, Final Batch Loss: 1.4587794794351794e-05\n",
      "Epoch 2792, Loss: 0.0001302432137890719, Final Batch Loss: 4.534102481557056e-05\n",
      "Epoch 2793, Loss: 0.00015755293134134263, Final Batch Loss: 8.11596546554938e-05\n",
      "Epoch 2794, Loss: 0.00018707993149291724, Final Batch Loss: 4.846676893066615e-05\n",
      "Epoch 2795, Loss: 6.267673416004982e-05, Final Batch Loss: 1.631600571272429e-05\n",
      "Epoch 2796, Loss: 0.001364513692806213, Final Batch Loss: 4.640707174985437e-06\n",
      "Epoch 2797, Loss: 7.321571320062503e-05, Final Batch Loss: 3.919150185538456e-05\n",
      "Epoch 2798, Loss: 0.0010236058969894657, Final Batch Loss: 1.6809639419079758e-05\n",
      "Epoch 2799, Loss: 0.0010426805365568725, Final Batch Loss: 9.553228665026836e-06\n",
      "Epoch 2800, Loss: 0.00206308094857377, Final Batch Loss: 0.002042291918769479\n",
      "Epoch 2801, Loss: 0.0009122362571361009, Final Batch Loss: 2.244781717308797e-05\n",
      "Epoch 2802, Loss: 0.00014094501193540054, Final Batch Loss: 7.561196525784908e-06\n",
      "Epoch 2803, Loss: 0.00022708793130732374, Final Batch Loss: 7.178049600042868e-06\n",
      "Epoch 2804, Loss: 0.0026516991811149637, Final Batch Loss: 1.3931016837887e-05\n",
      "Epoch 2805, Loss: 0.000359975325409323, Final Batch Loss: 0.00015827667084522545\n",
      "Epoch 2806, Loss: 5.960188354947604e-05, Final Batch Loss: 3.199726779712364e-05\n",
      "Epoch 2807, Loss: 0.0026905679114861414, Final Batch Loss: 0.00021802289120387286\n",
      "Epoch 2808, Loss: 0.00040081496990751475, Final Batch Loss: 6.10890710959211e-05\n",
      "Epoch 2809, Loss: 6.139470497146249e-05, Final Batch Loss: 9.617619070922956e-06\n",
      "Epoch 2810, Loss: 5.102433715364896e-05, Final Batch Loss: 3.135660517727956e-05\n",
      "Epoch 2811, Loss: 0.0003061570678255521, Final Batch Loss: 0.00011154663661727682\n",
      "Epoch 2812, Loss: 0.00011698585694830399, Final Batch Loss: 1.9511089703883044e-05\n",
      "Epoch 2813, Loss: 0.0004636199046217371, Final Batch Loss: 0.00044569704914465547\n",
      "Epoch 2814, Loss: 0.000997620591078885, Final Batch Loss: 0.00016865880752447993\n",
      "Epoch 2815, Loss: 4.4339751184452325e-05, Final Batch Loss: 9.189236152451485e-06\n",
      "Epoch 2816, Loss: 0.0037098330180924677, Final Batch Loss: 2.9724292289756704e-06\n",
      "Epoch 2817, Loss: 0.0005981953727314249, Final Batch Loss: 0.0004387133230920881\n",
      "Epoch 2818, Loss: 7.927060187284951e-05, Final Batch Loss: 6.790393399569439e-06\n",
      "Epoch 2819, Loss: 0.00027808047889266163, Final Batch Loss: 0.0002455818757880479\n",
      "Epoch 2820, Loss: 0.00016307350233546458, Final Batch Loss: 0.00011012043250957504\n",
      "Epoch 2821, Loss: 0.00011636686213023495, Final Batch Loss: 1.6470423361170106e-05\n",
      "Epoch 2822, Loss: 0.0010520656069274992, Final Batch Loss: 0.0006670557777397335\n",
      "Epoch 2823, Loss: 0.000382489016828913, Final Batch Loss: 5.605209935310995e-06\n",
      "Epoch 2824, Loss: 0.0012176962100056699, Final Batch Loss: 2.19885023398092e-05\n",
      "Epoch 2825, Loss: 0.0012654026177187916, Final Batch Loss: 5.98131118749734e-05\n",
      "Epoch 2826, Loss: 0.030939920572564006, Final Batch Loss: 0.0298843402415514\n",
      "Epoch 2827, Loss: 0.0028492064002421102, Final Batch Loss: 0.0028355903923511505\n",
      "Epoch 2828, Loss: 7.22096719982801e-05, Final Batch Loss: 4.9622456572251394e-05\n",
      "Epoch 2829, Loss: 0.0030954478970670607, Final Batch Loss: 0.00306123960763216\n",
      "Epoch 2830, Loss: 0.000521683363331249, Final Batch Loss: 3.4177846828242764e-05\n",
      "Epoch 2831, Loss: 0.04641386213188525, Final Batch Loss: 0.00012251453881617635\n",
      "Epoch 2832, Loss: 0.0023789848492015153, Final Batch Loss: 0.0021570411045104265\n",
      "Epoch 2833, Loss: 0.0018265300514030969, Final Batch Loss: 9.9398512247717e-06\n",
      "Epoch 2834, Loss: 0.0003971871265093796, Final Batch Loss: 4.150112363277003e-05\n",
      "Epoch 2835, Loss: 3.235519966438005e-05, Final Batch Loss: 1.1157628705404932e-06\n",
      "Epoch 2836, Loss: 0.00014589136117137969, Final Batch Loss: 9.803599095903337e-05\n",
      "Epoch 2837, Loss: 0.00035075159576081205, Final Batch Loss: 2.2133261154522188e-05\n",
      "Epoch 2838, Loss: 6.208924241946079e-05, Final Batch Loss: 2.2916785383131355e-05\n",
      "Epoch 2839, Loss: 9.795234382181661e-05, Final Batch Loss: 1.4135262063064147e-05\n",
      "Epoch 2840, Loss: 5.44410777365556e-05, Final Batch Loss: 3.3488373446743935e-05\n",
      "Epoch 2841, Loss: 0.00829756649909541, Final Batch Loss: 0.007711510173976421\n",
      "Epoch 2842, Loss: 0.00014016859040566487, Final Batch Loss: 0.0001304729375988245\n",
      "Epoch 2843, Loss: 0.0002369358771829866, Final Batch Loss: 0.00011632007226580754\n",
      "Epoch 2844, Loss: 7.479906707885675e-05, Final Batch Loss: 5.866937863174826e-05\n",
      "Epoch 2845, Loss: 0.007805024855770171, Final Batch Loss: 0.007108010817319155\n",
      "Epoch 2846, Loss: 4.718739364761859e-05, Final Batch Loss: 1.6845904610818252e-05\n",
      "Epoch 2847, Loss: 0.0042716316602309234, Final Batch Loss: 7.832429400878027e-05\n",
      "Epoch 2848, Loss: 0.00041134819184662774, Final Batch Loss: 0.00012130672257626429\n",
      "Epoch 2849, Loss: 0.0003957632616220508, Final Batch Loss: 5.593055175268091e-05\n",
      "Epoch 2850, Loss: 0.008564504983951338, Final Batch Loss: 0.008498115465044975\n",
      "Epoch 2851, Loss: 7.434815233864356e-05, Final Batch Loss: 5.307487299432978e-05\n",
      "Epoch 2852, Loss: 0.0018141576902053203, Final Batch Loss: 0.0017994625959545374\n",
      "Epoch 2853, Loss: 0.0070891463255975395, Final Batch Loss: 0.006967258173972368\n",
      "Epoch 2854, Loss: 3.083918636548333e-05, Final Batch Loss: 2.1779860617243685e-05\n",
      "Epoch 2855, Loss: 0.012888250348623842, Final Batch Loss: 0.00017786904936656356\n",
      "Epoch 2856, Loss: 0.00010576842396403663, Final Batch Loss: 6.534219573950395e-05\n",
      "Epoch 2857, Loss: 9.066001803148538e-05, Final Batch Loss: 3.407596886972897e-05\n",
      "Epoch 2858, Loss: 0.011668688253848813, Final Batch Loss: 0.00012444295862223953\n",
      "Epoch 2859, Loss: 0.012194070965051651, Final Batch Loss: 0.008610359393060207\n",
      "Epoch 2860, Loss: 0.00013479537574312417, Final Batch Loss: 0.00012599141336977482\n",
      "Epoch 2861, Loss: 0.0008190796852431959, Final Batch Loss: 0.000798882741946727\n",
      "Epoch 2862, Loss: 0.000264060843619518, Final Batch Loss: 0.00020659476285800338\n",
      "Epoch 2863, Loss: 0.0005818700301460922, Final Batch Loss: 0.00017884225235320628\n",
      "Epoch 2864, Loss: 0.00011475932296889368, Final Batch Loss: 2.992939880641643e-05\n",
      "Epoch 2865, Loss: 0.0075442544621182606, Final Batch Loss: 0.00010752496018540114\n",
      "Epoch 2866, Loss: 0.0005779432103736326, Final Batch Loss: 0.0003755167708732188\n",
      "Epoch 2867, Loss: 0.0009060531010618433, Final Batch Loss: 0.0007999370573088527\n",
      "Epoch 2868, Loss: 0.002106177358655259, Final Batch Loss: 0.00022532392176799476\n",
      "Epoch 2869, Loss: 0.0003452740602369886, Final Batch Loss: 0.00030348484870046377\n",
      "Epoch 2870, Loss: 0.00043662285315804183, Final Batch Loss: 0.0003914920671377331\n",
      "Epoch 2871, Loss: 0.00010012147140514571, Final Batch Loss: 2.9954835554235615e-05\n",
      "Epoch 2872, Loss: 6.059403131075669e-05, Final Batch Loss: 3.135625593131408e-05\n",
      "Epoch 2873, Loss: 0.04548162204946493, Final Batch Loss: 6.9288703343772795e-06\n",
      "Epoch 2874, Loss: 0.0001355992990283994, Final Batch Loss: 2.6727639124146663e-05\n",
      "Epoch 2875, Loss: 1.758607686497271e-05, Final Batch Loss: 7.671561434108298e-06\n",
      "Epoch 2876, Loss: 0.0003827457912848331, Final Batch Loss: 0.00010263027070323005\n",
      "Epoch 2877, Loss: 0.00012927189891343005, Final Batch Loss: 4.3782023567473516e-05\n",
      "Epoch 2878, Loss: 0.0005525767610379262, Final Batch Loss: 2.4221457351814024e-05\n",
      "Epoch 2879, Loss: 0.0002034525605267845, Final Batch Loss: 0.00017191244114656\n",
      "Epoch 2880, Loss: 0.004356204008217901, Final Batch Loss: 0.00048090534983202815\n",
      "Epoch 2881, Loss: 0.00010898618711507879, Final Batch Loss: 6.723518890794367e-05\n",
      "Epoch 2882, Loss: 7.61175788284163e-05, Final Batch Loss: 1.1462793736427557e-05\n",
      "Epoch 2883, Loss: 0.0018531303248892073, Final Batch Loss: 3.164201189065352e-06\n",
      "Epoch 2884, Loss: 0.0006085486093070358, Final Batch Loss: 0.0003013642563018948\n",
      "Epoch 2885, Loss: 0.001572161399963079, Final Batch Loss: 0.001546576269902289\n",
      "Epoch 2886, Loss: 3.527672197378706e-05, Final Batch Loss: 1.6194391719182022e-05\n",
      "Epoch 2887, Loss: 0.00013519548883778043, Final Batch Loss: 2.811135709634982e-05\n",
      "Epoch 2888, Loss: 0.0002913647040259093, Final Batch Loss: 0.0001883666409412399\n",
      "Epoch 2889, Loss: 0.0017254534759558737, Final Batch Loss: 5.194864934310317e-05\n",
      "Epoch 2890, Loss: 0.0009140632864728104, Final Batch Loss: 0.0008725296938791871\n",
      "Epoch 2891, Loss: 0.00013027335808146745, Final Batch Loss: 1.0017873137257993e-05\n",
      "Epoch 2892, Loss: 0.00058091375103686, Final Batch Loss: 0.0001794274867279455\n",
      "Epoch 2893, Loss: 9.305435241913074e-05, Final Batch Loss: 3.0496507861244027e-06\n",
      "Epoch 2894, Loss: 0.0002874831402550626, Final Batch Loss: 6.793401098548202e-06\n",
      "Epoch 2895, Loss: 0.00014995305537013337, Final Batch Loss: 3.411957004573196e-05\n",
      "Epoch 2896, Loss: 0.0003678774755826453, Final Batch Loss: 1.4362181900651194e-05\n",
      "Epoch 2897, Loss: 5.2914930165570695e-05, Final Batch Loss: 3.9169528463389724e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2898, Loss: 9.60401685006218e-05, Final Batch Loss: 1.6281164789688773e-05\n",
      "Epoch 2899, Loss: 0.00016573964899180282, Final Batch Loss: 3.786742354350281e-06\n",
      "Epoch 2900, Loss: 0.00034401638913550414, Final Batch Loss: 0.00029993674252182245\n",
      "Epoch 2901, Loss: 0.0005271113477647305, Final Batch Loss: 0.0001403277856297791\n",
      "Epoch 2902, Loss: 8.720650112081785e-05, Final Batch Loss: 2.745953133853618e-05\n",
      "Epoch 2903, Loss: 4.243141029292019e-05, Final Batch Loss: 1.3715857676288579e-05\n",
      "Epoch 2904, Loss: 0.0002082625578623265, Final Batch Loss: 0.0001605999277671799\n",
      "Epoch 2905, Loss: 0.0006955722346901894, Final Batch Loss: 0.0005252158152870834\n",
      "Epoch 2906, Loss: 0.00011172593985975254, Final Batch Loss: 2.4552997274440713e-05\n",
      "Epoch 2907, Loss: 0.0006496845962828957, Final Batch Loss: 0.0006036140839569271\n",
      "Epoch 2908, Loss: 0.0006048323702998459, Final Batch Loss: 6.400409620255232e-05\n",
      "Epoch 2909, Loss: 0.0003234647447243333, Final Batch Loss: 0.00018919716239906847\n",
      "Epoch 2910, Loss: 9.739708184497431e-05, Final Batch Loss: 5.793134914711118e-05\n",
      "Epoch 2911, Loss: 3.353426291141659e-05, Final Batch Loss: 1.7875368939712644e-05\n",
      "Epoch 2912, Loss: 0.001221255588461645, Final Batch Loss: 1.962932583410293e-05\n",
      "Epoch 2913, Loss: 0.00011931941844522953, Final Batch Loss: 8.839664951665327e-05\n",
      "Epoch 2914, Loss: 0.0016177054785657674, Final Batch Loss: 0.0012710982700809836\n",
      "Epoch 2915, Loss: 0.0002613487213238841, Final Batch Loss: 0.00024010347260627896\n",
      "Epoch 2916, Loss: 6.131500776973553e-05, Final Batch Loss: 4.3183106754440814e-05\n",
      "Epoch 2917, Loss: 0.0002954699593828991, Final Batch Loss: 0.00022776523837819695\n",
      "Epoch 2918, Loss: 7.60225091198663e-05, Final Batch Loss: 3.481597332211095e-06\n",
      "Epoch 2919, Loss: 0.0026083801149070496, Final Batch Loss: 1.0445781299495138e-05\n",
      "Epoch 2920, Loss: 0.0031329818593803793, Final Batch Loss: 0.003068768186494708\n",
      "Epoch 2921, Loss: 0.00025197181957992143, Final Batch Loss: 4.796741905011004e-06\n",
      "Epoch 2922, Loss: 0.0034381262958049774, Final Batch Loss: 0.0027463636361062527\n",
      "Epoch 2923, Loss: 0.00019543765756679932, Final Batch Loss: 1.0671437848941423e-06\n",
      "Epoch 2924, Loss: 0.005052746302681044, Final Batch Loss: 8.190938387997448e-05\n",
      "Epoch 2925, Loss: 0.00040667527355253696, Final Batch Loss: 1.552779576741159e-05\n",
      "Epoch 2926, Loss: 0.00015111023458302952, Final Batch Loss: 3.152899807901122e-05\n",
      "Epoch 2927, Loss: 0.000292271317448467, Final Batch Loss: 8.898033411242068e-05\n",
      "Epoch 2928, Loss: 0.0003118638924206607, Final Batch Loss: 0.00026427212287671864\n",
      "Epoch 2929, Loss: 0.0016880808834685013, Final Batch Loss: 0.00014012718747835606\n",
      "Epoch 2930, Loss: 6.00625789957121e-05, Final Batch Loss: 4.751567394123413e-05\n",
      "Epoch 2931, Loss: 0.0015025484826765023, Final Batch Loss: 1.7669772205408663e-05\n",
      "Epoch 2932, Loss: 0.0006926275127625559, Final Batch Loss: 4.056952093378641e-05\n",
      "Epoch 2933, Loss: 0.0033769228029996157, Final Batch Loss: 0.002167576691135764\n",
      "Epoch 2934, Loss: 0.00032721130173740676, Final Batch Loss: 8.06771913630655e-06\n",
      "Epoch 2935, Loss: 7.40902942197863e-05, Final Batch Loss: 2.2764390450902283e-05\n",
      "Epoch 2936, Loss: 4.3374668166507035e-05, Final Batch Loss: 9.570343536324799e-06\n",
      "Epoch 2937, Loss: 5.398162238634541e-05, Final Batch Loss: 5.616753242065897e-06\n",
      "Epoch 2938, Loss: 0.0001402888428856386, Final Batch Loss: 0.00011657447612378746\n",
      "Epoch 2939, Loss: 0.0025706329179229215, Final Batch Loss: 0.00020055340428370982\n",
      "Epoch 2940, Loss: 0.00017550975280755665, Final Batch Loss: 0.00015445190365426242\n",
      "Epoch 2941, Loss: 7.665453631489072e-05, Final Batch Loss: 2.940117883554194e-05\n",
      "Epoch 2942, Loss: 0.002639937010826543, Final Batch Loss: 0.0025111541617661715\n",
      "Epoch 2943, Loss: 2.2857867406855803e-05, Final Batch Loss: 1.8894455934059806e-05\n",
      "Epoch 2944, Loss: 0.0013870659149688436, Final Batch Loss: 1.8996592189068906e-05\n",
      "Epoch 2945, Loss: 0.0001558829003442952, Final Batch Loss: 3.7048498597869184e-06\n",
      "Epoch 2946, Loss: 0.006236444989554002, Final Batch Loss: 0.00621896842494607\n",
      "Epoch 2947, Loss: 0.00010031930378318066, Final Batch Loss: 1.372323549730936e-05\n",
      "Epoch 2948, Loss: 5.282012170937378e-05, Final Batch Loss: 3.316964648547582e-05\n",
      "Epoch 2949, Loss: 0.0001471589130233042, Final Batch Loss: 8.397437341045588e-05\n",
      "Epoch 2950, Loss: 0.000440936564700678, Final Batch Loss: 0.0003385106974747032\n",
      "Epoch 2951, Loss: 0.000261225237409235, Final Batch Loss: 2.489753569534514e-05\n",
      "Epoch 2952, Loss: 9.990511534851976e-05, Final Batch Loss: 2.2501608327729627e-05\n",
      "Epoch 2953, Loss: 0.0005713235277653439, Final Batch Loss: 0.0005457638762891293\n",
      "Epoch 2954, Loss: 0.0274937100475654, Final Batch Loss: 0.026866119354963303\n",
      "Epoch 2955, Loss: 0.002294676113706373, Final Batch Loss: 0.0022843938786536455\n",
      "Epoch 2956, Loss: 0.00010620591274346225, Final Batch Loss: 9.191398567054421e-05\n",
      "Epoch 2957, Loss: 0.00015962640463840216, Final Batch Loss: 5.1418137445580214e-05\n",
      "Epoch 2958, Loss: 0.00476003024232341, Final Batch Loss: 4.269653436494991e-05\n",
      "Epoch 2959, Loss: 0.0010466336279932875, Final Batch Loss: 3.193125667166896e-05\n",
      "Epoch 2960, Loss: 0.00019970816083514364, Final Batch Loss: 4.424718099471647e-06\n",
      "Epoch 2961, Loss: 0.0001580303069204092, Final Batch Loss: 0.00012207131658215076\n",
      "Epoch 2962, Loss: 8.432729873675271e-05, Final Batch Loss: 4.97014616485103e-06\n",
      "Epoch 2963, Loss: 0.0006126604639575817, Final Batch Loss: 0.0004964001709595323\n",
      "Epoch 2964, Loss: 0.0016441523912362754, Final Batch Loss: 0.0009387229802086949\n",
      "Epoch 2965, Loss: 0.0002884168607124593, Final Batch Loss: 0.00026262030587531626\n",
      "Epoch 2966, Loss: 0.0002057626988971606, Final Batch Loss: 0.0001292181696044281\n",
      "Epoch 2967, Loss: 0.0037786593202326912, Final Batch Loss: 0.0037661632522940636\n",
      "Epoch 2968, Loss: 0.0007381861651083454, Final Batch Loss: 0.000587773509323597\n",
      "Epoch 2969, Loss: 0.00013295332610141486, Final Batch Loss: 5.2945404604543e-05\n",
      "Epoch 2970, Loss: 0.00019730343774426728, Final Batch Loss: 0.00013297666737344116\n",
      "Epoch 2971, Loss: 2.960070651170099e-05, Final Batch Loss: 1.0815908353833947e-05\n",
      "Epoch 2972, Loss: 0.001556327595608309, Final Batch Loss: 0.001353490399196744\n",
      "Epoch 2973, Loss: 5.007596337236464e-05, Final Batch Loss: 4.5127391786081716e-05\n",
      "Epoch 2974, Loss: 0.000957467156695202, Final Batch Loss: 0.000916391727514565\n",
      "Epoch 2975, Loss: 2.17799715755973e-05, Final Batch Loss: 1.3081984434393235e-05\n",
      "Epoch 2976, Loss: 8.108041220111772e-05, Final Batch Loss: 4.4537307985592633e-05\n",
      "Epoch 2977, Loss: 0.00030394612622330897, Final Batch Loss: 3.887846105499193e-06\n",
      "Epoch 2978, Loss: 0.00015947099745972082, Final Batch Loss: 9.925027552526444e-05\n",
      "Epoch 2979, Loss: 0.0005054296002526826, Final Batch Loss: 9.202872206515167e-07\n",
      "Epoch 2980, Loss: 0.00214682839850866, Final Batch Loss: 1.0471735549799632e-05\n",
      "Epoch 2981, Loss: 7.449180338880979e-05, Final Batch Loss: 1.3289030903251842e-05\n",
      "Epoch 2982, Loss: 0.00019537425396265462, Final Batch Loss: 0.00016558692732360214\n",
      "Epoch 2983, Loss: 1.4895159893058008e-05, Final Batch Loss: 2.16662419916247e-06\n",
      "Epoch 2984, Loss: 2.1370601075432205e-05, Final Batch Loss: 9.72728571468906e-07\n",
      "Epoch 2985, Loss: 0.0002401247329544276, Final Batch Loss: 0.00020686154311988503\n",
      "Epoch 2986, Loss: 0.00032489628210896626, Final Batch Loss: 8.85976551217027e-05\n",
      "Epoch 2987, Loss: 0.00019223239905841183, Final Batch Loss: 2.804884388751816e-05\n",
      "Epoch 2988, Loss: 3.913270938937785e-05, Final Batch Loss: 9.54358165472513e-06\n",
      "Epoch 2989, Loss: 0.00010049386423816031, Final Batch Loss: 7.705496045673499e-07\n",
      "Epoch 2990, Loss: 0.0003108546807197854, Final Batch Loss: 0.0002465839497745037\n",
      "Epoch 2991, Loss: 0.002215645621618023, Final Batch Loss: 3.428978016017936e-05\n",
      "Epoch 2992, Loss: 0.00017638304780120961, Final Batch Loss: 0.00012427757610566914\n",
      "Epoch 2993, Loss: 0.0004089597950951429, Final Batch Loss: 0.0003947704390157014\n",
      "Epoch 2994, Loss: 0.0012263212283869507, Final Batch Loss: 1.0496254617464729e-05\n",
      "Epoch 2995, Loss: 1.793646970327245e-05, Final Batch Loss: 1.4581717550754547e-05\n",
      "Epoch 2996, Loss: 0.00032588583781034686, Final Batch Loss: 2.9872058803448454e-05\n",
      "Epoch 2997, Loss: 0.00020999304075530745, Final Batch Loss: 4.2342986716903397e-07\n",
      "Epoch 2998, Loss: 3.8638409023405984e-05, Final Batch Loss: 1.446701935492456e-05\n",
      "Epoch 2999, Loss: 0.0029792254626954673, Final Batch Loss: 1.64280481840251e-05\n",
      "Epoch 3000, Loss: 0.0002181152522098273, Final Batch Loss: 3.920112794730812e-05\n",
      "Epoch 3001, Loss: 3.2025673590396764e-05, Final Batch Loss: 3.4033969313895795e-06\n",
      "Epoch 3002, Loss: 6.059193947294261e-05, Final Batch Loss: 3.7628069549100474e-05\n",
      "Epoch 3003, Loss: 7.324715261347592e-05, Final Batch Loss: 1.903375959955156e-05\n",
      "Epoch 3004, Loss: 0.0003341277697472833, Final Batch Loss: 8.965748565969989e-05\n",
      "Epoch 3005, Loss: 0.0007443454232998192, Final Batch Loss: 0.0001476265606470406\n",
      "Epoch 3006, Loss: 2.6494316443859134e-05, Final Batch Loss: 1.4468777408183087e-05\n",
      "Epoch 3007, Loss: 0.00035431537889962783, Final Batch Loss: 1.1442832146713044e-05\n",
      "Epoch 3008, Loss: 0.0013179198649595492, Final Batch Loss: 1.2721218809019774e-05\n",
      "Epoch 3009, Loss: 4.8729577542871994e-05, Final Batch Loss: 1.1653766023300705e-06\n",
      "Epoch 3010, Loss: 5.4807622291264124e-05, Final Batch Loss: 1.6527092157048173e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3011, Loss: 0.003880777945596492, Final Batch Loss: 0.0038479226641356945\n",
      "Epoch 3012, Loss: 7.998255387065001e-05, Final Batch Loss: 1.6767746274126694e-05\n",
      "Epoch 3013, Loss: 0.0001129100000980543, Final Batch Loss: 1.833855094446335e-05\n",
      "Epoch 3014, Loss: 7.723038106632885e-05, Final Batch Loss: 6.206316902535036e-05\n",
      "Epoch 3015, Loss: 4.541067028185353e-05, Final Batch Loss: 1.561333738209214e-05\n",
      "Epoch 3016, Loss: 0.0003556109149940312, Final Batch Loss: 0.00023014257021714002\n",
      "Epoch 3017, Loss: 0.00015110103288407117, Final Batch Loss: 1.6458931213492178e-06\n",
      "Epoch 3018, Loss: 2.3355591110885143e-05, Final Batch Loss: 9.645259524404537e-06\n",
      "Epoch 3019, Loss: 4.7555618948535994e-05, Final Batch Loss: 3.307166844024323e-05\n",
      "Epoch 3020, Loss: 0.00028067914354323875, Final Batch Loss: 0.00027600934845395386\n",
      "Epoch 3021, Loss: 0.00018810128767654533, Final Batch Loss: 9.05034630704904e-06\n",
      "Epoch 3022, Loss: 6.231825682334602e-05, Final Batch Loss: 3.531188485794701e-05\n",
      "Epoch 3023, Loss: 9.971341205528006e-05, Final Batch Loss: 6.072553514968604e-05\n",
      "Epoch 3024, Loss: 0.002823162044478522, Final Batch Loss: 1.4079886568652e-05\n",
      "Epoch 3025, Loss: 0.0002569885728007648, Final Batch Loss: 3.195299723302014e-05\n",
      "Epoch 3026, Loss: 0.00287507098801143, Final Batch Loss: 1.6645497453282587e-05\n",
      "Epoch 3027, Loss: 0.0029760333345620893, Final Batch Loss: 2.0856001356150955e-05\n",
      "Epoch 3028, Loss: 0.0013169996600481682, Final Batch Loss: 0.0011949639301747084\n",
      "Epoch 3029, Loss: 0.000663176983835001, Final Batch Loss: 9.439933819521684e-06\n",
      "Epoch 3030, Loss: 0.03446399548374757, Final Batch Loss: 1.5766707292641513e-05\n",
      "Epoch 3031, Loss: 0.00023922645277707488, Final Batch Loss: 0.0002344851236557588\n",
      "Epoch 3032, Loss: 0.00010590628517093137, Final Batch Loss: 6.697531352983788e-05\n",
      "Epoch 3033, Loss: 0.000498117609822657, Final Batch Loss: 8.87196438270621e-05\n",
      "Epoch 3034, Loss: 0.00010588390432531014, Final Batch Loss: 8.09484554338269e-05\n",
      "Epoch 3035, Loss: 0.0003959977129852632, Final Batch Loss: 0.00038598396349698305\n",
      "Epoch 3036, Loss: 0.0025925510344677605, Final Batch Loss: 8.511168562108651e-05\n",
      "Epoch 3037, Loss: 0.0001193554921883333, Final Batch Loss: 3.8409702938224655e-06\n",
      "Epoch 3038, Loss: 0.0003046249257749878, Final Batch Loss: 0.00028025583014823496\n",
      "Epoch 3039, Loss: 0.001651271537411958, Final Batch Loss: 0.001602645730599761\n",
      "Epoch 3040, Loss: 0.002107198190060444, Final Batch Loss: 3.798872057814151e-05\n",
      "Epoch 3041, Loss: 5.379082676881808e-05, Final Batch Loss: 5.91477100897464e-06\n",
      "Epoch 3042, Loss: 0.00272345743724145, Final Batch Loss: 0.002541282447054982\n",
      "Epoch 3043, Loss: 0.0001582403274369426, Final Batch Loss: 0.00010268556798109785\n",
      "Epoch 3044, Loss: 2.859845153579954e-05, Final Batch Loss: 1.4397204722627066e-05\n",
      "Epoch 3045, Loss: 9.961933028534986e-05, Final Batch Loss: 4.6215376642066985e-05\n",
      "Epoch 3046, Loss: 0.00022475338482763618, Final Batch Loss: 4.846496449317783e-05\n",
      "Epoch 3047, Loss: 0.001562458313856041, Final Batch Loss: 0.0015312109608203173\n",
      "Epoch 3048, Loss: 0.00584828935097903, Final Batch Loss: 3.490166272968054e-05\n",
      "Epoch 3049, Loss: 0.00017828457930590957, Final Batch Loss: 9.140918700722978e-05\n",
      "Epoch 3050, Loss: 0.0013582121810031822, Final Batch Loss: 9.04614535102155e-06\n",
      "Epoch 3051, Loss: 0.00023929041708470322, Final Batch Loss: 0.00020487607980612665\n",
      "Epoch 3052, Loss: 0.0015159489412326366, Final Batch Loss: 0.0001399701286572963\n",
      "Epoch 3053, Loss: 0.00023255142605194123, Final Batch Loss: 1.2370034710329492e-05\n",
      "Epoch 3054, Loss: 0.0003622098683990771, Final Batch Loss: 2.240101821371354e-06\n",
      "Epoch 3055, Loss: 0.0007040250930003822, Final Batch Loss: 0.00010431103873997927\n",
      "Epoch 3056, Loss: 5.8154169892077334e-05, Final Batch Loss: 2.5627918148529716e-05\n",
      "Epoch 3057, Loss: 0.0012004361451545265, Final Batch Loss: 5.2897838031640276e-05\n",
      "Epoch 3058, Loss: 0.0013620683384942822, Final Batch Loss: 0.0012507776264101267\n",
      "Epoch 3059, Loss: 5.971603422949556e-05, Final Batch Loss: 2.829382174240891e-05\n",
      "Epoch 3060, Loss: 0.00022238447854761034, Final Batch Loss: 9.180545748677105e-05\n",
      "Epoch 3061, Loss: 5.372444684326183e-05, Final Batch Loss: 1.7340864360448904e-05\n",
      "Epoch 3062, Loss: 0.00014307096716947854, Final Batch Loss: 7.40979885449633e-05\n",
      "Epoch 3063, Loss: 0.002114883202011697, Final Batch Loss: 0.00012929043441545218\n",
      "Epoch 3064, Loss: 0.000628956375294365, Final Batch Loss: 0.00019425562641117722\n",
      "Epoch 3065, Loss: 0.00013033990398980677, Final Batch Loss: 6.497044523712248e-05\n",
      "Epoch 3066, Loss: 0.000741849115001969, Final Batch Loss: 0.0005866840365342796\n",
      "Epoch 3067, Loss: 0.0026705545315053314, Final Batch Loss: 0.002601795829832554\n",
      "Epoch 3068, Loss: 0.00032922134414548054, Final Batch Loss: 0.0002135436370735988\n",
      "Epoch 3069, Loss: 0.0013062122197879944, Final Batch Loss: 0.001290563028305769\n",
      "Epoch 3070, Loss: 0.0052567508164429455, Final Batch Loss: 6.0305092119961046e-06\n",
      "Epoch 3071, Loss: 7.206414238680736e-05, Final Batch Loss: 5.419244644144783e-06\n",
      "Epoch 3072, Loss: 7.790053314238321e-05, Final Batch Loss: 2.445603058731649e-05\n",
      "Epoch 3073, Loss: 0.00012280921509955078, Final Batch Loss: 7.829129026504233e-05\n",
      "Epoch 3074, Loss: 0.003338726455694996, Final Batch Loss: 0.0001720539148664102\n",
      "Epoch 3075, Loss: 0.00015688733401475474, Final Batch Loss: 4.175746289547533e-05\n",
      "Epoch 3076, Loss: 0.00016287953985738568, Final Batch Loss: 3.0617182346759364e-05\n",
      "Epoch 3077, Loss: 0.00037254879589454504, Final Batch Loss: 8.072970558714587e-06\n",
      "Epoch 3078, Loss: 0.0015645745443180203, Final Batch Loss: 0.0006730949389748275\n",
      "Epoch 3079, Loss: 7.329490836127661e-05, Final Batch Loss: 3.122820271528326e-05\n",
      "Epoch 3080, Loss: 0.0003798063116846606, Final Batch Loss: 0.00010824923811014742\n",
      "Epoch 3081, Loss: 0.00034694946953095496, Final Batch Loss: 2.3333996068686247e-05\n",
      "Epoch 3082, Loss: 0.0001646789623919176, Final Batch Loss: 0.00013718697300646454\n",
      "Epoch 3083, Loss: 0.002970108878798783, Final Batch Loss: 0.0017069840105250478\n",
      "Epoch 3084, Loss: 4.013530383417674e-05, Final Batch Loss: 3.4454399155947613e-06\n",
      "Epoch 3085, Loss: 0.0003974063729401678, Final Batch Loss: 0.00027270373539067805\n",
      "Epoch 3086, Loss: 0.00013183147893869318, Final Batch Loss: 4.9469334044260904e-05\n",
      "Epoch 3087, Loss: 0.001105450723116519, Final Batch Loss: 0.0010860413312911987\n",
      "Epoch 3088, Loss: 0.0003383603470865637, Final Batch Loss: 3.580361953936517e-05\n",
      "Epoch 3089, Loss: 0.00011104068471468054, Final Batch Loss: 1.551107197883539e-05\n",
      "Epoch 3090, Loss: 6.423211846140475e-05, Final Batch Loss: 1.7775975038603065e-06\n",
      "Epoch 3091, Loss: 0.0006208050435816403, Final Batch Loss: 0.000564051850233227\n",
      "Epoch 3092, Loss: 0.00235061163402861, Final Batch Loss: 0.0023083114065229893\n",
      "Epoch 3093, Loss: 0.00011660221025522333, Final Batch Loss: 6.185413440107368e-06\n",
      "Epoch 3094, Loss: 0.007334925068789744, Final Batch Loss: 3.0203091228031553e-05\n",
      "Epoch 3095, Loss: 0.0002448161176289432, Final Batch Loss: 0.00016494678857270628\n",
      "Epoch 3096, Loss: 0.00021099472360219806, Final Batch Loss: 6.751732144039124e-05\n",
      "Epoch 3097, Loss: 0.00017370241198477743, Final Batch Loss: 0.00016995097394101322\n",
      "Epoch 3098, Loss: 4.733628156827763e-05, Final Batch Loss: 2.3167083782027476e-05\n",
      "Epoch 3099, Loss: 0.004091133254405577, Final Batch Loss: 0.003994479309767485\n",
      "Epoch 3100, Loss: 8.283065108116716e-05, Final Batch Loss: 5.0911632570205256e-05\n",
      "Epoch 3101, Loss: 3.199740172021848e-05, Final Batch Loss: 2.5651345367805334e-06\n",
      "Epoch 3102, Loss: 0.00035787975411949446, Final Batch Loss: 0.0003459573199506849\n",
      "Epoch 3103, Loss: 0.00015905003965599462, Final Batch Loss: 4.3971798731945455e-05\n",
      "Epoch 3104, Loss: 6.0427062408052734e-05, Final Batch Loss: 2.3087211502570426e-06\n",
      "Epoch 3105, Loss: 8.398806494369637e-05, Final Batch Loss: 3.933562766178511e-06\n",
      "Epoch 3106, Loss: 3.160491223752615e-05, Final Batch Loss: 2.701764060475398e-05\n",
      "Epoch 3107, Loss: 0.0003681849611893995, Final Batch Loss: 8.294473445857875e-06\n",
      "Epoch 3108, Loss: 6.436473631765693e-05, Final Batch Loss: 3.747652590391226e-05\n",
      "Epoch 3109, Loss: 0.0004983363760402426, Final Batch Loss: 0.00024386080622207373\n",
      "Epoch 3110, Loss: 0.0030319865472847596, Final Batch Loss: 0.0028487821109592915\n",
      "Epoch 3111, Loss: 5.946732926531695e-05, Final Batch Loss: 9.288265573559329e-06\n",
      "Epoch 3112, Loss: 0.0005940394767094404, Final Batch Loss: 0.0003346065932419151\n",
      "Epoch 3113, Loss: 9.668081838754006e-05, Final Batch Loss: 4.906464891973883e-05\n",
      "Epoch 3114, Loss: 0.0033593917833059095, Final Batch Loss: 0.003283444093540311\n",
      "Epoch 3115, Loss: 9.355484507977962e-05, Final Batch Loss: 6.190181011334062e-05\n",
      "Epoch 3116, Loss: 1.507878050688305e-05, Final Batch Loss: 5.213357781030936e-06\n",
      "Epoch 3117, Loss: 0.00438631814904511, Final Batch Loss: 0.0032327098306268454\n",
      "Epoch 3118, Loss: 0.0005407675707829185, Final Batch Loss: 0.0004785894707310945\n",
      "Epoch 3119, Loss: 0.0001577961784278159, Final Batch Loss: 0.00014679630112368613\n",
      "Epoch 3120, Loss: 0.0004977322823833674, Final Batch Loss: 0.00011522386921569705\n",
      "Epoch 3121, Loss: 3.7230222687867354e-05, Final Batch Loss: 3.0525250167556806e-06\n",
      "Epoch 3122, Loss: 0.000984607537247939, Final Batch Loss: 5.160706859896891e-05\n",
      "Epoch 3123, Loss: 2.7199273972655647e-05, Final Batch Loss: 1.9908658941858448e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3124, Loss: 0.0001657409454765002, Final Batch Loss: 3.077396058870363e-06\n",
      "Epoch 3125, Loss: 0.034300630673442356, Final Batch Loss: 6.502255473606056e-06\n",
      "Epoch 3126, Loss: 0.00011846194684039801, Final Batch Loss: 3.9509686757810414e-05\n",
      "Epoch 3127, Loss: 3.9218088204506785e-05, Final Batch Loss: 2.2658714442513883e-06\n",
      "Epoch 3128, Loss: 5.204426634008996e-05, Final Batch Loss: 8.681396138854325e-06\n",
      "Epoch 3129, Loss: 4.2989027861040086e-05, Final Batch Loss: 3.227520937798545e-05\n",
      "Epoch 3130, Loss: 0.00019713510118890554, Final Batch Loss: 1.9964732928201556e-05\n",
      "Epoch 3131, Loss: 5.7647951507533435e-05, Final Batch Loss: 4.3891654058825225e-05\n",
      "Epoch 3132, Loss: 0.0002731631939241197, Final Batch Loss: 0.00023592394427396357\n",
      "Epoch 3133, Loss: 0.0007766855269437656, Final Batch Loss: 0.00020168481569271535\n",
      "Epoch 3134, Loss: 0.00018470551913196687, Final Batch Loss: 0.00016463230713270605\n",
      "Epoch 3135, Loss: 0.005018341355025768, Final Batch Loss: 0.004147502593696117\n",
      "Epoch 3136, Loss: 2.3384121050185058e-05, Final Batch Loss: 5.252538358035963e-06\n",
      "Epoch 3137, Loss: 0.00035799300894723274, Final Batch Loss: 2.8938437026226893e-05\n",
      "Epoch 3138, Loss: 2.303324708918808e-05, Final Batch Loss: 1.2944046829943545e-05\n",
      "Epoch 3139, Loss: 3.58246143150609e-05, Final Batch Loss: 7.672220817767084e-06\n",
      "Epoch 3140, Loss: 0.00010484224594620173, Final Batch Loss: 3.3205474210262764e-06\n",
      "Epoch 3141, Loss: 0.0020149454330748995, Final Batch Loss: 7.72013754612999e-06\n",
      "Epoch 3142, Loss: 4.593235871652723e-05, Final Batch Loss: 1.98063435163931e-06\n",
      "Epoch 3143, Loss: 0.002415113799543178, Final Batch Loss: 1.0015392945206258e-05\n",
      "Epoch 3144, Loss: 0.0002005431852012407, Final Batch Loss: 0.0001539685035822913\n",
      "Epoch 3145, Loss: 0.00019836029241560027, Final Batch Loss: 0.00017382463556714356\n",
      "Epoch 3146, Loss: 0.00018823775462806225, Final Batch Loss: 8.236651046900079e-05\n",
      "Epoch 3147, Loss: 0.0011150204518344253, Final Batch Loss: 0.0006308723241090775\n",
      "Epoch 3148, Loss: 6.532474981213454e-05, Final Batch Loss: 2.537766886234749e-05\n",
      "Epoch 3149, Loss: 0.00012805386904801708, Final Batch Loss: 2.7128253350383602e-05\n",
      "Epoch 3150, Loss: 0.00014036565153219271, Final Batch Loss: 1.5638275726814754e-05\n",
      "Epoch 3151, Loss: 3.045356788788922e-05, Final Batch Loss: 1.4688341252622195e-05\n",
      "Epoch 3152, Loss: 0.004441147571469628, Final Batch Loss: 3.6255401028029155e-06\n",
      "Epoch 3153, Loss: 0.0006227018639037851, Final Batch Loss: 0.0006144649814814329\n",
      "Epoch 3154, Loss: 3.1665980714024045e-05, Final Batch Loss: 2.4203378416132182e-05\n",
      "Epoch 3155, Loss: 0.0027101004070573254, Final Batch Loss: 0.0027006978634744883\n",
      "Epoch 3156, Loss: 6.881714580231346e-05, Final Batch Loss: 4.925496250507422e-05\n",
      "Epoch 3157, Loss: 6.879646389279515e-05, Final Batch Loss: 3.1287887395592406e-05\n",
      "Epoch 3158, Loss: 0.0013086123908578884, Final Batch Loss: 0.0012770453467965126\n",
      "Epoch 3159, Loss: 0.0033033155068551423, Final Batch Loss: 2.0063265765202232e-05\n",
      "Epoch 3160, Loss: 0.0004530214282567613, Final Batch Loss: 0.00036015771911479533\n",
      "Epoch 3161, Loss: 0.00019643497580545954, Final Batch Loss: 5.287737803882919e-05\n",
      "Epoch 3162, Loss: 0.0012610824805960874, Final Batch Loss: 1.4829568499408197e-05\n",
      "Epoch 3163, Loss: 0.00013328116801858414, Final Batch Loss: 0.00011226634524064139\n",
      "Epoch 3164, Loss: 3.0510181431964156e-05, Final Batch Loss: 1.1500953860377194e-06\n",
      "Epoch 3165, Loss: 0.00013473250260176428, Final Batch Loss: 0.0001336448622168973\n",
      "Epoch 3166, Loss: 0.0001516822085250169, Final Batch Loss: 8.78908540471457e-05\n",
      "Epoch 3167, Loss: 3.2956160794128664e-05, Final Batch Loss: 2.2744216039427556e-05\n",
      "Epoch 3168, Loss: 0.00036137741335551254, Final Batch Loss: 5.169356518308632e-05\n",
      "Epoch 3169, Loss: 0.0004722213197965175, Final Batch Loss: 0.0004546615236904472\n",
      "Epoch 3170, Loss: 0.00018862012802856043, Final Batch Loss: 6.945597851881757e-05\n",
      "Epoch 3171, Loss: 0.0002038699749391526, Final Batch Loss: 0.00014168523193802685\n",
      "Epoch 3172, Loss: 0.0031335692011680294, Final Batch Loss: 0.003132015699520707\n",
      "Epoch 3173, Loss: 0.0007555220581707545, Final Batch Loss: 0.0007296334952116013\n",
      "Epoch 3174, Loss: 8.08827935543377e-05, Final Batch Loss: 5.081415656604804e-05\n",
      "Epoch 3175, Loss: 0.00014407747403311078, Final Batch Loss: 2.63486090261722e-05\n",
      "Epoch 3176, Loss: 0.00016881708870641887, Final Batch Loss: 3.608431143220514e-05\n",
      "Epoch 3177, Loss: 0.0004756706525768095, Final Batch Loss: 2.019781732087722e-06\n",
      "Epoch 3178, Loss: 0.00015703413919254672, Final Batch Loss: 1.5018957128631882e-05\n",
      "Epoch 3179, Loss: 3.771476468727997e-05, Final Batch Loss: 5.674322096638207e-07\n",
      "Epoch 3180, Loss: 7.008567627053708e-05, Final Batch Loss: 3.633033702499233e-05\n",
      "Epoch 3181, Loss: 0.0005187061360629741, Final Batch Loss: 0.0004992272006347775\n",
      "Epoch 3182, Loss: 4.5119192691345233e-05, Final Batch Loss: 8.2783271864173e-06\n",
      "Epoch 3183, Loss: 0.0020465460256673396, Final Batch Loss: 1.9730126950889826e-05\n",
      "Epoch 3184, Loss: 0.000254253413004335, Final Batch Loss: 9.339871030533686e-05\n",
      "Epoch 3185, Loss: 3.360277332831174e-05, Final Batch Loss: 1.6296520698233508e-05\n",
      "Epoch 3186, Loss: 0.0003620169227360748, Final Batch Loss: 7.526852277806029e-05\n",
      "Epoch 3187, Loss: 0.00011108890248578973, Final Batch Loss: 6.501715688500553e-05\n",
      "Epoch 3188, Loss: 0.0012367289600661024, Final Batch Loss: 0.0002044939756160602\n",
      "Epoch 3189, Loss: 8.25843808343052e-05, Final Batch Loss: 7.282748265424743e-05\n",
      "Epoch 3190, Loss: 0.0004265060488251038, Final Batch Loss: 0.0003867734340019524\n",
      "Epoch 3191, Loss: 8.65168163954877e-05, Final Batch Loss: 1.4400117152035818e-06\n",
      "Epoch 3192, Loss: 0.0017696598661132157, Final Batch Loss: 4.5631604734808207e-05\n",
      "Epoch 3193, Loss: 1.8717790226219222e-05, Final Batch Loss: 1.0195652066613548e-05\n",
      "Epoch 3194, Loss: 0.029764858656562865, Final Batch Loss: 0.029591107740998268\n",
      "Epoch 3195, Loss: 0.0002774780077743344, Final Batch Loss: 0.00016325923206750304\n",
      "Epoch 3196, Loss: 0.00014774276496609673, Final Batch Loss: 8.281414193334058e-05\n",
      "Epoch 3197, Loss: 0.0032419605558970943, Final Batch Loss: 0.0032264087349176407\n",
      "Epoch 3198, Loss: 0.00037579295167233795, Final Batch Loss: 0.00014011400344315916\n",
      "Epoch 3199, Loss: 0.06399534619413316, Final Batch Loss: 0.06293751299381256\n",
      "Epoch 3200, Loss: 0.00047657776303822175, Final Batch Loss: 2.8047281375620514e-05\n",
      "Epoch 3201, Loss: 9.067199425771832e-05, Final Batch Loss: 4.8171397793339565e-05\n",
      "Epoch 3202, Loss: 0.0008931791653594701, Final Batch Loss: 1.0821690011653118e-05\n",
      "Epoch 3203, Loss: 0.002272933672657018, Final Batch Loss: 0.0022699865512549877\n",
      "Epoch 3204, Loss: 0.004397478507598862, Final Batch Loss: 0.004200638271868229\n",
      "Epoch 3205, Loss: 6.779753675800748e-05, Final Batch Loss: 4.1028215491678566e-05\n",
      "Epoch 3206, Loss: 0.000301603417028673, Final Batch Loss: 0.00019844333291985095\n",
      "Epoch 3207, Loss: 0.01740959016024135, Final Batch Loss: 0.00015163150965236127\n",
      "Epoch 3208, Loss: 0.0003182786895195022, Final Batch Loss: 0.00013215921353548765\n",
      "Epoch 3209, Loss: 0.00012279555539862486, Final Batch Loss: 7.402476512652356e-06\n",
      "Epoch 3210, Loss: 0.0006234154461708385, Final Batch Loss: 2.1653937437804416e-05\n",
      "Epoch 3211, Loss: 0.010754985400126316, Final Batch Loss: 0.0001756647980073467\n",
      "Epoch 3212, Loss: 0.00014126096220934414, Final Batch Loss: 5.712505753763253e-06\n",
      "Epoch 3213, Loss: 0.00025194378395099193, Final Batch Loss: 0.00018819743127096444\n",
      "Epoch 3214, Loss: 0.002315410397386586, Final Batch Loss: 1.0217757335340139e-05\n",
      "Epoch 3215, Loss: 0.0009472686215303838, Final Batch Loss: 0.0005893978523090482\n",
      "Epoch 3216, Loss: 5.000561759516131e-05, Final Batch Loss: 1.5677424016757868e-05\n",
      "Epoch 3217, Loss: 0.002356632314331364, Final Batch Loss: 0.0023351870477199554\n",
      "Epoch 3218, Loss: 0.0001869683856057236, Final Batch Loss: 2.042990854533855e-05\n",
      "Epoch 3219, Loss: 1.8937670574814547e-05, Final Batch Loss: 9.86853501672158e-06\n",
      "Epoch 3220, Loss: 0.000642293605778832, Final Batch Loss: 6.041461165295914e-05\n",
      "Epoch 3221, Loss: 9.781072367331944e-05, Final Batch Loss: 6.516814028145745e-05\n",
      "Epoch 3222, Loss: 0.00010075594309455482, Final Batch Loss: 1.3162268260202836e-05\n",
      "Epoch 3223, Loss: 6.538575325976126e-05, Final Batch Loss: 4.710524808615446e-05\n",
      "Epoch 3224, Loss: 0.001428877527359873, Final Batch Loss: 0.00084607646567747\n",
      "Epoch 3225, Loss: 0.00017030315211741254, Final Batch Loss: 8.767028339207172e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3226, Loss: 5.676448927260935e-05, Final Batch Loss: 1.477783007430844e-05\n",
      "Epoch 3227, Loss: 0.0009657519549364224, Final Batch Loss: 7.76345405029133e-05\n",
      "Epoch 3228, Loss: 0.0001862938588601537, Final Batch Loss: 0.00010718650446506217\n",
      "Epoch 3229, Loss: 0.002067324829113204, Final Batch Loss: 3.567699604900554e-05\n",
      "Epoch 3230, Loss: 0.00013763563765678555, Final Batch Loss: 9.335422510048375e-05\n",
      "Epoch 3231, Loss: 0.00047076748160179704, Final Batch Loss: 0.00013914440933149308\n",
      "Epoch 3232, Loss: 0.00025135061878245324, Final Batch Loss: 9.537528967484832e-06\n",
      "Epoch 3233, Loss: 0.00021751455642515793, Final Batch Loss: 2.880398096749559e-05\n",
      "Epoch 3234, Loss: 0.0004368209956737701, Final Batch Loss: 0.00041447250987403095\n",
      "Epoch 3235, Loss: 0.00014883790572639555, Final Batch Loss: 1.442334905732423e-05\n",
      "Epoch 3236, Loss: 0.00030847591551719233, Final Batch Loss: 0.00018664055096451193\n",
      "Epoch 3237, Loss: 0.00015869025810388848, Final Batch Loss: 7.897179602878168e-05\n",
      "Epoch 3238, Loss: 0.0023643142958462704, Final Batch Loss: 4.928642374579795e-05\n",
      "Epoch 3239, Loss: 0.0004778772668032616, Final Batch Loss: 1.4838838069408666e-06\n",
      "Epoch 3240, Loss: 0.015130588551983237, Final Batch Loss: 0.0030637483578175306\n",
      "Epoch 3241, Loss: 0.016220618039369583, Final Batch Loss: 0.014232445508241653\n",
      "Epoch 3242, Loss: 0.0031636306739528663, Final Batch Loss: 0.0030997295398265123\n",
      "Epoch 3243, Loss: 0.00012956174032296985, Final Batch Loss: 2.1806663426104933e-05\n",
      "Epoch 3244, Loss: 0.0015394687679872732, Final Batch Loss: 7.796569661877584e-06\n",
      "Epoch 3245, Loss: 0.0002261601694044657, Final Batch Loss: 0.0001382047776132822\n",
      "Epoch 3246, Loss: 0.00019301396241644397, Final Batch Loss: 4.8962530854623765e-05\n",
      "Epoch 3247, Loss: 0.0022338689595926553, Final Batch Loss: 0.00039719397318549454\n",
      "Epoch 3248, Loss: 0.00013124988981871866, Final Batch Loss: 8.999671990750358e-05\n",
      "Epoch 3249, Loss: 0.005207873931794893, Final Batch Loss: 0.005156365223228931\n",
      "Epoch 3250, Loss: 0.00015632142094545998, Final Batch Loss: 4.671716669690795e-05\n",
      "Epoch 3251, Loss: 0.00030457277898676693, Final Batch Loss: 0.00021938662393949926\n",
      "Epoch 3252, Loss: 0.003498969686916098, Final Batch Loss: 0.00013701090938411653\n",
      "Epoch 3253, Loss: 9.551862240186892e-05, Final Batch Loss: 1.876557871582918e-05\n",
      "Epoch 3254, Loss: 0.00016475917072966695, Final Batch Loss: 0.00010276566172251478\n",
      "Epoch 3255, Loss: 0.0003597966133384034, Final Batch Loss: 0.00015972342225722969\n",
      "Epoch 3256, Loss: 0.00012994417193112895, Final Batch Loss: 4.734063986688852e-05\n",
      "Epoch 3257, Loss: 0.0012570373037306126, Final Batch Loss: 0.0012073568068444729\n",
      "Epoch 3258, Loss: 0.0005238419762463309, Final Batch Loss: 6.004403257975355e-05\n",
      "Epoch 3259, Loss: 0.0002563441084930673, Final Batch Loss: 8.947185415308923e-05\n",
      "Epoch 3260, Loss: 0.00036574131809175014, Final Batch Loss: 0.000261190056335181\n",
      "Epoch 3261, Loss: 0.00013382959878072143, Final Batch Loss: 6.198428309289739e-05\n",
      "Epoch 3262, Loss: 0.0001098900283977855, Final Batch Loss: 2.681734986254014e-05\n",
      "Epoch 3263, Loss: 0.0005494805191119667, Final Batch Loss: 0.0005237740115262568\n",
      "Epoch 3264, Loss: 9.406047684024088e-05, Final Batch Loss: 3.4469594538677484e-05\n",
      "Epoch 3265, Loss: 0.00042121453225263394, Final Batch Loss: 0.000403742422349751\n",
      "Epoch 3266, Loss: 0.00010217666567768902, Final Batch Loss: 4.375540083856322e-05\n",
      "Epoch 3267, Loss: 0.0006194001180119812, Final Batch Loss: 0.00044642359716817737\n",
      "Epoch 3268, Loss: 0.0005792891661258182, Final Batch Loss: 2.5224004275514744e-05\n",
      "Epoch 3269, Loss: 0.0007854240830056369, Final Batch Loss: 0.0006658160709775984\n",
      "Epoch 3270, Loss: 0.00021470881620189175, Final Batch Loss: 5.754955054726452e-06\n",
      "Epoch 3271, Loss: 0.0014492952523141867, Final Batch Loss: 2.9409469789243303e-05\n",
      "Epoch 3272, Loss: 0.0002475960682204459, Final Batch Loss: 0.0001911386934807524\n",
      "Epoch 3273, Loss: 0.00015894249008852057, Final Batch Loss: 4.0895432903198525e-05\n",
      "Epoch 3274, Loss: 0.0005350230785552412, Final Batch Loss: 0.00046363944420590997\n",
      "Epoch 3275, Loss: 8.880910263542319e-05, Final Batch Loss: 6.439281605707947e-06\n",
      "Epoch 3276, Loss: 0.00017435429617762566, Final Batch Loss: 8.619028812972829e-05\n",
      "Epoch 3277, Loss: 0.0031677978113293648, Final Batch Loss: 0.0007966542616486549\n",
      "Epoch 3278, Loss: 0.0003612883301684633, Final Batch Loss: 0.00028117213514633477\n",
      "Epoch 3279, Loss: 8.817355410428718e-05, Final Batch Loss: 6.406594911823049e-05\n",
      "Epoch 3280, Loss: 0.0010124192340299487, Final Batch Loss: 0.00024872616631910205\n",
      "Epoch 3281, Loss: 0.0002693495771382004, Final Batch Loss: 0.00010738537821453065\n",
      "Epoch 3282, Loss: 0.0003501150022202637, Final Batch Loss: 0.0003044769400730729\n",
      "Epoch 3283, Loss: 0.00035902504168916494, Final Batch Loss: 0.00028895746800117195\n",
      "Epoch 3284, Loss: 0.0001628127029107418, Final Batch Loss: 2.295762169524096e-05\n",
      "Epoch 3285, Loss: 0.00019031267947866581, Final Batch Loss: 1.3117456546751782e-05\n",
      "Epoch 3286, Loss: 0.0007539251746493392, Final Batch Loss: 0.00010613572521833703\n",
      "Epoch 3287, Loss: 9.525932000542525e-05, Final Batch Loss: 1.9799810615950264e-05\n",
      "Epoch 3288, Loss: 0.0004413573169586016, Final Batch Loss: 1.5696276022936217e-05\n",
      "Epoch 3289, Loss: 0.00010182734513364267, Final Batch Loss: 8.843286923365667e-05\n",
      "Epoch 3290, Loss: 0.00014922101672709687, Final Batch Loss: 1.3114421562931966e-05\n",
      "Epoch 3291, Loss: 0.0002675961222848855, Final Batch Loss: 0.0002556902763899416\n",
      "Epoch 3292, Loss: 3.3947642805287614e-05, Final Batch Loss: 1.2412847354426049e-05\n",
      "Epoch 3293, Loss: 0.0002605947956908494, Final Batch Loss: 0.00014046643627807498\n",
      "Epoch 3294, Loss: 0.0003810486086877063, Final Batch Loss: 0.0001226549647981301\n",
      "Epoch 3295, Loss: 0.00011140694050482125, Final Batch Loss: 6.28228235655115e-06\n",
      "Epoch 3296, Loss: 0.01877745822275756, Final Batch Loss: 0.018728775903582573\n",
      "Epoch 3297, Loss: 0.0055316499801847385, Final Batch Loss: 0.005505764856934547\n",
      "Epoch 3298, Loss: 0.00011025571802747436, Final Batch Loss: 1.8203081708634272e-05\n",
      "Epoch 3299, Loss: 0.004416935880726669, Final Batch Loss: 0.004333883058279753\n",
      "Epoch 3300, Loss: 0.00015874026712481282, Final Batch Loss: 0.00015435522072948515\n",
      "Epoch 3301, Loss: 0.00046995384036563337, Final Batch Loss: 0.00029563865973614156\n",
      "Epoch 3302, Loss: 0.00020304911595303565, Final Batch Loss: 6.914061668794602e-05\n",
      "Epoch 3303, Loss: 3.3701172469591256e-05, Final Batch Loss: 1.1797544175351504e-05\n",
      "Epoch 3304, Loss: 0.00045133475214242935, Final Batch Loss: 0.00011075864313170314\n",
      "Epoch 3305, Loss: 0.0020018585710204206, Final Batch Loss: 0.00010509069397812709\n",
      "Epoch 3306, Loss: 0.001572270562974154, Final Batch Loss: 1.824394530558493e-05\n",
      "Epoch 3307, Loss: 0.0017987065475608688, Final Batch Loss: 0.001763159059919417\n",
      "Epoch 3308, Loss: 0.00211695809775847, Final Batch Loss: 4.431786874192767e-05\n",
      "Epoch 3309, Loss: 0.00010702175131882541, Final Batch Loss: 4.2451978515600786e-05\n",
      "Epoch 3310, Loss: 0.0010352092576795258, Final Batch Loss: 5.4692944104317576e-05\n",
      "Epoch 3311, Loss: 0.007716340012848377, Final Batch Loss: 0.005538221448659897\n",
      "Epoch 3312, Loss: 0.004553425562335178, Final Batch Loss: 0.0003357026434969157\n",
      "Epoch 3313, Loss: 8.743404396227561e-05, Final Batch Loss: 1.4746208762517199e-05\n",
      "Epoch 3314, Loss: 4.0319961044588126e-05, Final Batch Loss: 1.4307379387901165e-05\n",
      "Epoch 3315, Loss: 0.0001705940949250362, Final Batch Loss: 8.872840226104017e-06\n",
      "Epoch 3316, Loss: 0.00010937501792795956, Final Batch Loss: 5.2664508984889835e-05\n",
      "Epoch 3317, Loss: 0.0012011419621558161, Final Batch Loss: 5.3428684623213485e-06\n",
      "Epoch 3318, Loss: 0.0003775894612090269, Final Batch Loss: 1.1310359013805282e-06\n",
      "Epoch 3319, Loss: 0.00026168939825765847, Final Batch Loss: 1.9854999209201196e-06\n",
      "Epoch 3320, Loss: 0.00011464480121503584, Final Batch Loss: 3.878136703860946e-05\n",
      "Epoch 3321, Loss: 5.830019972563605e-05, Final Batch Loss: 5.577126557909651e-06\n",
      "Epoch 3322, Loss: 1.596467973286053e-05, Final Batch Loss: 5.668995981977787e-06\n",
      "Epoch 3323, Loss: 0.00018169785471400246, Final Batch Loss: 0.0001455782330594957\n",
      "Epoch 3324, Loss: 9.053211761056446e-05, Final Batch Loss: 3.184554952895269e-05\n",
      "Epoch 3325, Loss: 7.586667095438315e-05, Final Batch Loss: 9.784552048586193e-07\n",
      "Epoch 3326, Loss: 9.126009899773635e-05, Final Batch Loss: 3.853173620882444e-05\n",
      "Epoch 3327, Loss: 0.00011933797759411391, Final Batch Loss: 7.967841156641953e-06\n",
      "Epoch 3328, Loss: 4.1138086999126244e-05, Final Batch Loss: 2.978639349748846e-05\n",
      "Epoch 3329, Loss: 3.82454145437805e-05, Final Batch Loss: 1.728447932691779e-05\n",
      "Epoch 3330, Loss: 0.0014109587064012885, Final Batch Loss: 1.2102420441806316e-05\n",
      "Epoch 3331, Loss: 0.0002643146417540265, Final Batch Loss: 1.2823931683669798e-05\n",
      "Epoch 3332, Loss: 0.00033461421844549477, Final Batch Loss: 0.0002119233540724963\n",
      "Epoch 3333, Loss: 0.00011949111285503022, Final Batch Loss: 3.0928244086680934e-05\n",
      "Epoch 3334, Loss: 9.489568219578359e-05, Final Batch Loss: 2.20288220589282e-05\n",
      "Epoch 3335, Loss: 0.00015262458327924833, Final Batch Loss: 0.00010593944898573682\n",
      "Epoch 3336, Loss: 3.0466506359516643e-05, Final Batch Loss: 1.5404461009893566e-05\n",
      "Epoch 3337, Loss: 0.002161863720175461, Final Batch Loss: 1.6211060938076116e-05\n",
      "Epoch 3338, Loss: 0.0021915181350777857, Final Batch Loss: 0.0021205306984484196\n",
      "Epoch 3339, Loss: 0.00016294909073621966, Final Batch Loss: 0.0001243323931703344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3340, Loss: 7.909613850642927e-05, Final Batch Loss: 3.901924719684757e-05\n",
      "Epoch 3341, Loss: 0.0013131441678524425, Final Batch Loss: 6.235264208953595e-06\n",
      "Epoch 3342, Loss: 0.0001222012251673732, Final Batch Loss: 8.564404561184347e-05\n",
      "Epoch 3343, Loss: 0.0016474755002491293, Final Batch Loss: 1.3439193025988061e-05\n",
      "Epoch 3344, Loss: 5.9390122260083444e-05, Final Batch Loss: 8.746284947847016e-06\n",
      "Epoch 3345, Loss: 0.00012835620145779103, Final Batch Loss: 6.392032810254022e-05\n",
      "Epoch 3346, Loss: 4.9160796606884105e-05, Final Batch Loss: 7.252237537613837e-06\n",
      "Epoch 3347, Loss: 0.0006562906200997531, Final Batch Loss: 0.00040109301335178316\n",
      "Epoch 3348, Loss: 2.4854625735315494e-05, Final Batch Loss: 1.1759691915358417e-05\n",
      "Epoch 3349, Loss: 0.0003769544309761841, Final Batch Loss: 0.0003466936177574098\n",
      "Epoch 3350, Loss: 0.000143645862408448, Final Batch Loss: 7.500864012399688e-05\n",
      "Epoch 3351, Loss: 0.001672804376539716, Final Batch Loss: 0.0016578540671616793\n",
      "Epoch 3352, Loss: 5.2202130973455496e-05, Final Batch Loss: 1.1030317182303406e-05\n",
      "Epoch 3353, Loss: 0.00011407451711420435, Final Batch Loss: 9.750325261848047e-05\n",
      "Epoch 3354, Loss: 0.0007251173810800537, Final Batch Loss: 0.0001236026146216318\n",
      "Epoch 3355, Loss: 0.0018338714598939987, Final Batch Loss: 0.0018135152058675885\n",
      "Epoch 3356, Loss: 0.017582809457962867, Final Batch Loss: 5.234954733168706e-05\n",
      "Epoch 3357, Loss: 0.00010748333590981929, Final Batch Loss: 1.6965510667432682e-06\n",
      "Epoch 3358, Loss: 0.000277987310255412, Final Batch Loss: 0.00016939983470365405\n",
      "Epoch 3359, Loss: 2.5793434360821266e-05, Final Batch Loss: 3.6953251765226014e-06\n",
      "Epoch 3360, Loss: 0.0005514502445294056, Final Batch Loss: 0.0004936429904773831\n",
      "Epoch 3361, Loss: 0.0003360865221111453, Final Batch Loss: 8.893925951269921e-06\n",
      "Epoch 3362, Loss: 0.00014819963325862773, Final Batch Loss: 4.236668246448971e-05\n",
      "Epoch 3363, Loss: 6.821304305049125e-05, Final Batch Loss: 2.5155144612654112e-05\n",
      "Epoch 3364, Loss: 0.00011211293303858838, Final Batch Loss: 7.0707187660445925e-06\n",
      "Epoch 3365, Loss: 9.389301703777164e-05, Final Batch Loss: 3.991655830759555e-05\n",
      "Epoch 3366, Loss: 0.0020673865801654756, Final Batch Loss: 0.001954353181645274\n",
      "Epoch 3367, Loss: 0.0001235488998645451, Final Batch Loss: 3.3714586606947705e-05\n",
      "Epoch 3368, Loss: 0.0004647882128665515, Final Batch Loss: 1.7127717910625506e-06\n",
      "Epoch 3369, Loss: 0.0020130913130742556, Final Batch Loss: 5.071366558695445e-06\n",
      "Epoch 3370, Loss: 6.165576269268058e-05, Final Batch Loss: 1.4474178897216916e-05\n",
      "Epoch 3371, Loss: 0.002421659499304951, Final Batch Loss: 2.509410296624992e-05\n",
      "Epoch 3372, Loss: 0.0003594884183257818, Final Batch Loss: 0.00024187396047636867\n",
      "Epoch 3373, Loss: 0.001189709255413618, Final Batch Loss: 3.432944504311308e-05\n",
      "Epoch 3374, Loss: 0.00020953104422005708, Final Batch Loss: 4.724857262772275e-06\n",
      "Epoch 3375, Loss: 0.0001488666148361517, Final Batch Loss: 0.00012286906712688506\n",
      "Epoch 3376, Loss: 0.022686517448164523, Final Batch Loss: 0.02073574997484684\n",
      "Epoch 3377, Loss: 1.6334148540408933e-05, Final Batch Loss: 1.7623435724090086e-06\n",
      "Epoch 3378, Loss: 3.338150872878032e-05, Final Batch Loss: 2.3666500055696815e-05\n",
      "Epoch 3379, Loss: 4.516023545875214e-05, Final Batch Loss: 6.0081838455516845e-06\n",
      "Epoch 3380, Loss: 0.03949840530549409, Final Batch Loss: 1.2622920621652156e-05\n",
      "Epoch 3381, Loss: 0.001364155901057984, Final Batch Loss: 7.800948083058756e-07\n",
      "Epoch 3382, Loss: 6.382439505614457e-05, Final Batch Loss: 1.815679297578754e-06\n",
      "Epoch 3383, Loss: 0.00028719672445731703, Final Batch Loss: 1.4914267012500204e-05\n",
      "Epoch 3384, Loss: 4.2677386772993486e-05, Final Batch Loss: 9.381200470670592e-06\n",
      "Epoch 3385, Loss: 0.00010635320904839318, Final Batch Loss: 1.674976920185145e-05\n",
      "Epoch 3386, Loss: 0.00016795052852103254, Final Batch Loss: 1.2579773283505347e-05\n",
      "Epoch 3387, Loss: 0.0070408632745966315, Final Batch Loss: 0.0019423709018155932\n",
      "Epoch 3388, Loss: 3.579218946470064e-05, Final Batch Loss: 3.90969262298313e-06\n",
      "Epoch 3389, Loss: 0.0002785304459393956, Final Batch Loss: 0.00020529735775198787\n",
      "Epoch 3390, Loss: 0.0005982139991829172, Final Batch Loss: 0.00042712167487479746\n",
      "Epoch 3391, Loss: 0.0034022176296275575, Final Batch Loss: 5.694396168109961e-05\n",
      "Epoch 3392, Loss: 0.00016280915951938368, Final Batch Loss: 2.4464261514367536e-05\n",
      "Epoch 3393, Loss: 0.0009988074889406562, Final Batch Loss: 0.00034645776031538844\n",
      "Epoch 3394, Loss: 8.23458976810798e-05, Final Batch Loss: 1.6997095372062176e-05\n",
      "Epoch 3395, Loss: 6.476496128016151e-05, Final Batch Loss: 2.134405804099515e-05\n",
      "Epoch 3396, Loss: 0.0004264103772584349, Final Batch Loss: 0.00031680462416261435\n",
      "Epoch 3397, Loss: 0.0011445361778896768, Final Batch Loss: 0.0011069803731516004\n",
      "Epoch 3398, Loss: 0.00102710126520833, Final Batch Loss: 8.474944479530677e-05\n",
      "Epoch 3399, Loss: 0.00013334421146282693, Final Batch Loss: 0.00012123369378969073\n",
      "Epoch 3400, Loss: 5.9182859331485815e-05, Final Batch Loss: 5.20668072567787e-06\n",
      "Epoch 3401, Loss: 0.0006926838068466168, Final Batch Loss: 0.0006848087068647146\n",
      "Epoch 3402, Loss: 0.0001363641677016858, Final Batch Loss: 0.00011965855082962662\n",
      "Epoch 3403, Loss: 0.00028227817529113963, Final Batch Loss: 7.572715549031273e-05\n",
      "Epoch 3404, Loss: 0.001529919776658062, Final Batch Loss: 3.939096495741978e-05\n",
      "Epoch 3405, Loss: 4.9384195563106914e-05, Final Batch Loss: 1.9939591311413096e-06\n",
      "Epoch 3406, Loss: 0.0002730255509959534, Final Batch Loss: 0.000174068525666371\n",
      "Epoch 3407, Loss: 5.06160176882986e-05, Final Batch Loss: 2.4717792257433757e-05\n",
      "Epoch 3408, Loss: 0.00038033671808079816, Final Batch Loss: 1.0853695130208507e-05\n",
      "Epoch 3409, Loss: 0.0002743940121945343, Final Batch Loss: 8.892252481018659e-06\n",
      "Epoch 3410, Loss: 0.0004938205165672116, Final Batch Loss: 0.00043352984357625246\n",
      "Epoch 3411, Loss: 4.702349872331979e-05, Final Batch Loss: 1.009931679618603e-06\n",
      "Epoch 3412, Loss: 0.0001780382081051357, Final Batch Loss: 0.00010319475404685363\n",
      "Epoch 3413, Loss: 6.659578320977744e-05, Final Batch Loss: 2.998877789650578e-05\n",
      "Epoch 3414, Loss: 0.0068536057115125, Final Batch Loss: 2.044262146227993e-05\n",
      "Epoch 3415, Loss: 0.0010854111751541495, Final Batch Loss: 0.0009818091057240963\n",
      "Epoch 3416, Loss: 0.00020191303337924182, Final Batch Loss: 4.323005850892514e-05\n",
      "Epoch 3417, Loss: 0.00043834394091391005, Final Batch Loss: 4.298400381230749e-05\n",
      "Epoch 3418, Loss: 0.00017752831627149135, Final Batch Loss: 7.398197340080515e-05\n",
      "Epoch 3419, Loss: 6.672490417258814e-05, Final Batch Loss: 3.6023313441546634e-05\n",
      "Epoch 3420, Loss: 4.853306836594129e-05, Final Batch Loss: 1.429186977475183e-05\n",
      "Epoch 3421, Loss: 0.004046232905238867, Final Batch Loss: 0.0036299678031355143\n",
      "Epoch 3422, Loss: 0.0009746399955474772, Final Batch Loss: 4.465049278223887e-05\n",
      "Epoch 3423, Loss: 0.00016578592112637125, Final Batch Loss: 4.1085306293098256e-05\n",
      "Epoch 3424, Loss: 0.0003507662004267331, Final Batch Loss: 2.9997838282724842e-05\n",
      "Epoch 3425, Loss: 6.666282661171863e-05, Final Batch Loss: 3.3128899303846993e-06\n",
      "Epoch 3426, Loss: 0.0002949930712929927, Final Batch Loss: 0.00026080181123688817\n",
      "Epoch 3427, Loss: 5.56132108613383e-05, Final Batch Loss: 3.3027368772309273e-05\n",
      "Epoch 3428, Loss: 0.0002743989789451007, Final Batch Loss: 0.0002325348323211074\n",
      "Epoch 3429, Loss: 0.00010437069795443676, Final Batch Loss: 4.9704216507961974e-05\n",
      "Epoch 3430, Loss: 6.324468995444477e-05, Final Batch Loss: 3.279210432083346e-05\n",
      "Epoch 3431, Loss: 0.0029256525139089717, Final Batch Loss: 0.0029241687152534723\n",
      "Epoch 3432, Loss: 0.0035422961900621885, Final Batch Loss: 2.4066141122602858e-05\n",
      "Epoch 3433, Loss: 1.880931722553214e-05, Final Batch Loss: 7.878007636463735e-06\n",
      "Epoch 3434, Loss: 2.7020357265428174e-05, Final Batch Loss: 1.061724924511509e-05\n",
      "Epoch 3435, Loss: 0.002356741882977076, Final Batch Loss: 0.002154883462935686\n",
      "Epoch 3436, Loss: 0.00012737846554955468, Final Batch Loss: 9.192226571030915e-06\n",
      "Epoch 3437, Loss: 0.00015216551400953904, Final Batch Loss: 8.833435276756063e-05\n",
      "Epoch 3438, Loss: 0.0001119294174714014, Final Batch Loss: 7.462127541657537e-05\n",
      "Epoch 3439, Loss: 0.00026547730158199556, Final Batch Loss: 0.0002086745953420177\n",
      "Epoch 3440, Loss: 1.2013959462819912e-05, Final Batch Loss: 1.0394934406576795e-06\n",
      "Epoch 3441, Loss: 0.00026085042918566614, Final Batch Loss: 5.3166018915362656e-05\n",
      "Epoch 3442, Loss: 0.000266512734015123, Final Batch Loss: 2.876444523280952e-05\n",
      "Epoch 3443, Loss: 0.0007279779001692077, Final Batch Loss: 9.771441909833811e-06\n",
      "Epoch 3444, Loss: 4.182036286692892e-05, Final Batch Loss: 9.851312370301457e-07\n",
      "Epoch 3445, Loss: 9.518779188510962e-05, Final Batch Loss: 5.3420139010995626e-05\n",
      "Epoch 3446, Loss: 0.00016745108769100625, Final Batch Loss: 2.103878250636626e-05\n",
      "Epoch 3447, Loss: 0.000934367133595515, Final Batch Loss: 6.493856926681474e-05\n",
      "Epoch 3448, Loss: 2.5709558940434363e-05, Final Batch Loss: 3.861648110614624e-06\n",
      "Epoch 3449, Loss: 0.0011551772422535578, Final Batch Loss: 0.001135733793489635\n",
      "Epoch 3450, Loss: 0.0007698105764575303, Final Batch Loss: 0.0006542431656271219\n",
      "Epoch 3451, Loss: 0.0036502843713606126, Final Batch Loss: 8.032190635276493e-06\n",
      "Epoch 3452, Loss: 5.659506769006839e-05, Final Batch Loss: 1.1708702913892921e-05\n",
      "Epoch 3453, Loss: 0.0022351668994815554, Final Batch Loss: 0.002193235559388995\n",
      "Epoch 3454, Loss: 7.719963377894601e-06, Final Batch Loss: 1.4981578715378419e-06\n",
      "Epoch 3455, Loss: 0.00020057475012436043, Final Batch Loss: 0.0001753769174683839\n",
      "Epoch 3456, Loss: 0.00011889717643498443, Final Batch Loss: 7.988684956217185e-06\n",
      "Epoch 3457, Loss: 0.00023158588737715036, Final Batch Loss: 7.761451706755906e-05\n",
      "Epoch 3458, Loss: 3.1473358831135556e-05, Final Batch Loss: 1.9528126358636655e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3459, Loss: 0.00018098931468557566, Final Batch Loss: 5.939314723946154e-05\n",
      "Epoch 3460, Loss: 0.00010947006012429483, Final Batch Loss: 3.266983185312711e-05\n",
      "Epoch 3461, Loss: 4.280239500076277e-05, Final Batch Loss: 1.0039372682513203e-05\n",
      "Epoch 3462, Loss: 5.550925880015711e-05, Final Batch Loss: 6.561465397680877e-06\n",
      "Epoch 3463, Loss: 0.00021338603119147592, Final Batch Loss: 2.3230154511111323e-06\n",
      "Epoch 3464, Loss: 0.00022020816686563194, Final Batch Loss: 0.0001425734517397359\n",
      "Epoch 3465, Loss: 0.00024366029538214207, Final Batch Loss: 0.0001846810628194362\n",
      "Epoch 3466, Loss: 0.0028737429765897105, Final Batch Loss: 6.166310413391329e-06\n",
      "Epoch 3467, Loss: 4.556526801025029e-05, Final Batch Loss: 3.2188800105359405e-05\n",
      "Epoch 3468, Loss: 0.00023744023974359152, Final Batch Loss: 3.8781877265137155e-06\n",
      "Epoch 3469, Loss: 0.00020394049897731747, Final Batch Loss: 1.120458728109952e-05\n",
      "Epoch 3470, Loss: 9.119249443756416e-05, Final Batch Loss: 4.57221940450836e-05\n",
      "Epoch 3471, Loss: 1.1555902347026858e-05, Final Batch Loss: 4.194819211988943e-06\n",
      "Epoch 3472, Loss: 0.0011885948251801892, Final Batch Loss: 1.4134194316284265e-05\n",
      "Epoch 3473, Loss: 0.0002853758933270001, Final Batch Loss: 0.00027987200883217156\n",
      "Epoch 3474, Loss: 0.005142146046637208, Final Batch Loss: 0.005115620791912079\n",
      "Epoch 3475, Loss: 2.3591290755575756e-05, Final Batch Loss: 1.801386497390922e-05\n",
      "Epoch 3476, Loss: 0.0003722654084867827, Final Batch Loss: 3.477676045804401e-06\n",
      "Epoch 3477, Loss: 5.84541485295631e-05, Final Batch Loss: 2.424449849058874e-05\n",
      "Epoch 3478, Loss: 0.000203307589799806, Final Batch Loss: 0.00019426486687734723\n",
      "Epoch 3479, Loss: 0.000387039573979564, Final Batch Loss: 5.2150426199659705e-06\n",
      "Epoch 3480, Loss: 0.00015722354874014854, Final Batch Loss: 3.8398058677557856e-05\n",
      "Epoch 3481, Loss: 4.764599179907236e-05, Final Batch Loss: 1.4493745766230859e-05\n",
      "Epoch 3482, Loss: 0.00029634021484525874, Final Batch Loss: 0.00024634154397062957\n",
      "Epoch 3483, Loss: 1.0669837365639978e-05, Final Batch Loss: 3.0552939733752282e-06\n",
      "Epoch 3484, Loss: 8.920381151256151e-05, Final Batch Loss: 3.4123055229429156e-05\n",
      "Epoch 3485, Loss: 0.0012899857538286597, Final Batch Loss: 9.666502592153847e-05\n",
      "Epoch 3486, Loss: 5.8675838090493926e-05, Final Batch Loss: 1.8423945675749565e-06\n",
      "Epoch 3487, Loss: 6.845358984719496e-05, Final Batch Loss: 2.3447386411135085e-05\n",
      "Epoch 3488, Loss: 0.0026526446781645063, Final Batch Loss: 1.6756388504290953e-05\n",
      "Epoch 3489, Loss: 1.3228674788479111e-05, Final Batch Loss: 9.718025467009284e-06\n",
      "Epoch 3490, Loss: 3.349952203279827e-05, Final Batch Loss: 2.9505661586881615e-05\n",
      "Epoch 3491, Loss: 0.00022082624127506278, Final Batch Loss: 0.0001784536289051175\n",
      "Epoch 3492, Loss: 4.04198920023191e-05, Final Batch Loss: 2.5165620627376484e-06\n",
      "Epoch 3493, Loss: 0.00026994775544153526, Final Batch Loss: 4.448484833119437e-05\n",
      "Epoch 3494, Loss: 6.967105014155095e-05, Final Batch Loss: 6.772715278202668e-05\n",
      "Epoch 3495, Loss: 0.00012245275502209552, Final Batch Loss: 3.2105879654409364e-05\n",
      "Epoch 3496, Loss: 0.00011611763511609752, Final Batch Loss: 1.3832572221872397e-05\n",
      "Epoch 3497, Loss: 2.2961249669606332e-05, Final Batch Loss: 8.067090675467625e-06\n",
      "Epoch 3498, Loss: 2.448607574478956e-05, Final Batch Loss: 7.775041922286619e-06\n",
      "Epoch 3499, Loss: 0.0001606230445077017, Final Batch Loss: 1.1691819281622884e-06\n",
      "Epoch 3500, Loss: 9.399688315170351e-05, Final Batch Loss: 3.000031938427128e-06\n",
      "Epoch 3501, Loss: 7.066446050885133e-05, Final Batch Loss: 4.1661045543150976e-05\n",
      "Epoch 3502, Loss: 0.00040131493005901575, Final Batch Loss: 1.311834785155952e-05\n",
      "Epoch 3503, Loss: 3.82951748179039e-05, Final Batch Loss: 2.190291888837237e-05\n",
      "Epoch 3504, Loss: 0.0007098196647348232, Final Batch Loss: 7.552443094027694e-06\n",
      "Epoch 3505, Loss: 5.075232365925331e-05, Final Batch Loss: 2.4440407287329435e-05\n",
      "Epoch 3506, Loss: 0.0006394742849806789, Final Batch Loss: 0.0006077587604522705\n",
      "Epoch 3507, Loss: 0.0013690219070667808, Final Batch Loss: 2.126516392308986e-06\n",
      "Epoch 3508, Loss: 7.625892430951353e-05, Final Batch Loss: 1.1931178960367106e-05\n",
      "Epoch 3509, Loss: 0.00011718763198587112, Final Batch Loss: 4.3336327507859096e-05\n",
      "Epoch 3510, Loss: 0.0008714497998880688, Final Batch Loss: 0.0008595852996222675\n",
      "Epoch 3511, Loss: 0.0007329480422413326, Final Batch Loss: 0.0007250700728036463\n",
      "Epoch 3512, Loss: 0.00037580043863272294, Final Batch Loss: 0.0002730115666054189\n",
      "Epoch 3513, Loss: 0.0002566017083154293, Final Batch Loss: 2.105109342664946e-05\n",
      "Epoch 3514, Loss: 3.42088505931315e-05, Final Batch Loss: 2.8560312784975395e-05\n",
      "Epoch 3515, Loss: 0.00011261120744165964, Final Batch Loss: 6.499126902781427e-05\n",
      "Epoch 3516, Loss: 5.123665505379904e-05, Final Batch Loss: 3.882839155266993e-05\n",
      "Epoch 3517, Loss: 8.753266320127295e-05, Final Batch Loss: 7.581769023090601e-05\n",
      "Epoch 3518, Loss: 0.0002684951246010314, Final Batch Loss: 7.3713376878004055e-06\n",
      "Epoch 3519, Loss: 9.533652337267995e-05, Final Batch Loss: 4.09251224482432e-05\n",
      "Epoch 3520, Loss: 0.001987443549296586, Final Batch Loss: 1.214794974657707e-05\n",
      "Epoch 3521, Loss: 9.754773373060743e-06, Final Batch Loss: 6.731947905791458e-06\n",
      "Epoch 3522, Loss: 0.0008523527249053586, Final Batch Loss: 0.0008090450428426266\n",
      "Epoch 3523, Loss: 0.0007548191028945439, Final Batch Loss: 0.0007490687421523035\n",
      "Epoch 3524, Loss: 0.00018177372840000317, Final Batch Loss: 9.154861618299037e-05\n",
      "Epoch 3525, Loss: 0.0012751897284033475, Final Batch Loss: 1.0827598089235835e-05\n",
      "Epoch 3526, Loss: 7.716138475188927e-05, Final Batch Loss: 9.5745758699195e-07\n",
      "Epoch 3527, Loss: 8.951556810643524e-05, Final Batch Loss: 2.4131906684488058e-05\n",
      "Epoch 3528, Loss: 0.00020408177078934386, Final Batch Loss: 0.00011897031799890101\n",
      "Epoch 3529, Loss: 1.6826467117425636e-05, Final Batch Loss: 1.498187202741974e-06\n",
      "Epoch 3530, Loss: 0.00030160703317960724, Final Batch Loss: 3.481713793007657e-05\n",
      "Epoch 3531, Loss: 5.83342643949436e-05, Final Batch Loss: 3.951650796807371e-05\n",
      "Epoch 3532, Loss: 0.0002629002265166491, Final Batch Loss: 0.00022029835963621736\n",
      "Epoch 3533, Loss: 4.2771211155923083e-05, Final Batch Loss: 1.3026910892222077e-06\n",
      "Epoch 3534, Loss: 0.00015537054150627228, Final Batch Loss: 0.00014644813199993223\n",
      "Epoch 3535, Loss: 1.8734369177764165e-05, Final Batch Loss: 1.7051067970896838e-06\n",
      "Epoch 3536, Loss: 7.733197435300099e-05, Final Batch Loss: 9.466185474593658e-06\n",
      "Epoch 3537, Loss: 0.00010735505475167884, Final Batch Loss: 8.737700227356981e-06\n",
      "Epoch 3538, Loss: 0.0002515575943107251, Final Batch Loss: 0.0002192172541981563\n",
      "Epoch 3539, Loss: 1.128472399614111e-05, Final Batch Loss: 7.920438292785548e-06\n",
      "Epoch 3540, Loss: 0.000602953412453644, Final Batch Loss: 2.936190867330879e-05\n",
      "Epoch 3541, Loss: 0.001404706395987887, Final Batch Loss: 8.287642413051799e-05\n",
      "Epoch 3542, Loss: 0.0016603143376414664, Final Batch Loss: 0.00010283088340656832\n",
      "Epoch 3543, Loss: 3.165946964145405e-05, Final Batch Loss: 1.8362037735641934e-05\n",
      "Epoch 3544, Loss: 4.336709207564127e-05, Final Batch Loss: 1.1373142115189694e-05\n",
      "Epoch 3545, Loss: 4.4693513700622134e-05, Final Batch Loss: 2.990381653944496e-05\n",
      "Epoch 3546, Loss: 0.002185452550293121, Final Batch Loss: 5.894859896216076e-06\n",
      "Epoch 3547, Loss: 4.967203381056606e-06, Final Batch Loss: 1.5105796364878188e-06\n",
      "Epoch 3548, Loss: 0.007020920140803355, Final Batch Loss: 2.9495899980247486e-06\n",
      "Epoch 3549, Loss: 0.0027972435191259137, Final Batch Loss: 0.0027922436129301786\n",
      "Epoch 3550, Loss: 3.515330627124058e-05, Final Batch Loss: 2.2001688193995506e-05\n",
      "Epoch 3551, Loss: 0.00010130856026080437, Final Batch Loss: 1.1648906365735456e-05\n",
      "Epoch 3552, Loss: 0.0012929692638863344, Final Batch Loss: 1.2918771972181275e-05\n",
      "Epoch 3553, Loss: 0.0005020065364078619, Final Batch Loss: 0.0003825184248853475\n",
      "Epoch 3554, Loss: 0.0003826098509307485, Final Batch Loss: 0.0003503009211272001\n",
      "Epoch 3555, Loss: 9.651444270275533e-05, Final Batch Loss: 5.8634082961361855e-05\n",
      "Epoch 3556, Loss: 0.0003011493181475089, Final Batch Loss: 2.1647365429089405e-06\n",
      "Epoch 3557, Loss: 7.074532913975418e-05, Final Batch Loss: 1.8636066670296714e-05\n",
      "Epoch 3558, Loss: 5.4747873946325853e-05, Final Batch Loss: 1.792154580471106e-05\n",
      "Epoch 3559, Loss: 0.00017335436587018194, Final Batch Loss: 1.0960099643853027e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3560, Loss: 1.802611950552091e-05, Final Batch Loss: 9.356511327496264e-06\n",
      "Epoch 3561, Loss: 2.1577797724603442e-05, Final Batch Loss: 1.7403177480446175e-05\n",
      "Epoch 3562, Loss: 9.997118127103022e-05, Final Batch Loss: 1.1338890999468276e-06\n",
      "Epoch 3563, Loss: 0.00023321692970057484, Final Batch Loss: 2.247599149995949e-05\n",
      "Epoch 3564, Loss: 0.00012107983548048651, Final Batch Loss: 0.00010959379869746044\n",
      "Epoch 3565, Loss: 0.0019819205481326208, Final Batch Loss: 7.443407957907766e-05\n",
      "Epoch 3566, Loss: 0.00036986550549045205, Final Batch Loss: 0.0002988622582051903\n",
      "Epoch 3567, Loss: 0.00024555152049288154, Final Batch Loss: 0.00010798014409374446\n",
      "Epoch 3568, Loss: 9.904354374157265e-05, Final Batch Loss: 2.5577704946044832e-05\n",
      "Epoch 3569, Loss: 0.00013172831313568167, Final Batch Loss: 8.77973870956339e-05\n",
      "Epoch 3570, Loss: 0.0007144273713493021, Final Batch Loss: 0.0007105700788088143\n",
      "Epoch 3571, Loss: 0.00036796790300286375, Final Batch Loss: 0.00034030276583507657\n",
      "Epoch 3572, Loss: 0.00031556661997456104, Final Batch Loss: 7.654530054423958e-05\n",
      "Epoch 3573, Loss: 0.002510517690097913, Final Batch Loss: 0.0022649080492556095\n",
      "Epoch 3574, Loss: 0.0003996695304522291, Final Batch Loss: 0.00014043789997231215\n",
      "Epoch 3575, Loss: 0.00011501512562972493, Final Batch Loss: 3.1863102776696905e-05\n",
      "Epoch 3576, Loss: 0.001634378462767927, Final Batch Loss: 0.001591192907653749\n",
      "Epoch 3577, Loss: 0.004535437299637124, Final Batch Loss: 0.00037590760621242225\n",
      "Epoch 3578, Loss: 6.238864261831623e-05, Final Batch Loss: 2.462924203427974e-05\n",
      "Epoch 3579, Loss: 0.0011646427847153973, Final Batch Loss: 0.0011350468266755342\n",
      "Epoch 3580, Loss: 0.001497364822853342, Final Batch Loss: 2.9092059321556007e-06\n",
      "Epoch 3581, Loss: 1.5207134282491097e-05, Final Batch Loss: 6.294246190918784e-08\n",
      "Epoch 3582, Loss: 0.003436333527588431, Final Batch Loss: 0.0034330349881201982\n",
      "Epoch 3583, Loss: 6.454440267589234e-06, Final Batch Loss: 5.950861350356718e-07\n",
      "Epoch 3584, Loss: 3.0370189051609486e-05, Final Batch Loss: 2.014070560107939e-06\n",
      "Epoch 3585, Loss: 3.188780101481825e-05, Final Batch Loss: 1.5790699762874283e-05\n",
      "Epoch 3586, Loss: 4.9461157232144615e-06, Final Batch Loss: 1.419965428794967e-06\n",
      "Epoch 3587, Loss: 0.00043194289810344344, Final Batch Loss: 0.00042012074845843017\n",
      "Epoch 3588, Loss: 0.003860330209136009, Final Batch Loss: 0.00286807375960052\n",
      "Epoch 3589, Loss: 4.571434647004935e-05, Final Batch Loss: 6.25242637397605e-06\n",
      "Epoch 3590, Loss: 0.00025495119371043984, Final Batch Loss: 1.4524857760989107e-05\n",
      "Epoch 3591, Loss: 1.1147835039082565e-05, Final Batch Loss: 3.125897137579159e-06\n",
      "Epoch 3592, Loss: 1.4133270269667264e-05, Final Batch Loss: 6.548598321387544e-06\n",
      "Epoch 3593, Loss: 0.005996978348775883, Final Batch Loss: 2.1020388885517605e-05\n",
      "Epoch 3594, Loss: 0.00023388978684124595, Final Batch Loss: 2.6386808258394012e-06\n",
      "Epoch 3595, Loss: 5.87519925829838e-05, Final Batch Loss: 5.580400465987623e-05\n",
      "Epoch 3596, Loss: 2.867169041564921e-05, Final Batch Loss: 1.0073675184685271e-05\n",
      "Epoch 3597, Loss: 5.270611109153833e-05, Final Batch Loss: 1.8548833395470865e-05\n",
      "Epoch 3598, Loss: 0.0002398852666374296, Final Batch Loss: 0.0001558136282255873\n",
      "Epoch 3599, Loss: 0.00018123777181244805, Final Batch Loss: 5.1358051678107586e-06\n",
      "Epoch 3600, Loss: 6.900762684836081e-05, Final Batch Loss: 1.5258120811267872e-06\n",
      "Epoch 3601, Loss: 0.0002926892921095714, Final Batch Loss: 8.949657785706222e-05\n",
      "Epoch 3602, Loss: 0.0010891654528677464, Final Batch Loss: 3.6890851333737373e-06\n",
      "Epoch 3603, Loss: 8.159874141711043e-06, Final Batch Loss: 5.575548584602075e-06\n",
      "Epoch 3604, Loss: 0.0017982550998567604, Final Batch Loss: 0.0017476833891123533\n",
      "Epoch 3605, Loss: 0.00029085928690619767, Final Batch Loss: 0.00023622038133908063\n",
      "Epoch 3606, Loss: 6.656910272795358e-06, Final Batch Loss: 1.1110071227449225e-06\n",
      "Epoch 3607, Loss: 0.00023590726777911186, Final Batch Loss: 5.836995842400938e-05\n",
      "Epoch 3608, Loss: 1.1235878446314018e-05, Final Batch Loss: 6.689729161735158e-06\n",
      "Epoch 3609, Loss: 0.002115848887115135, Final Batch Loss: 1.611206062079873e-05\n",
      "Epoch 3610, Loss: 7.4752381351572694e-06, Final Batch Loss: 3.850239863822935e-06\n",
      "Epoch 3611, Loss: 0.0014949578926461982, Final Batch Loss: 0.0014842328382655978\n",
      "Epoch 3612, Loss: 5.3428751925821416e-05, Final Batch Loss: 2.506899727450218e-05\n",
      "Epoch 3613, Loss: 0.0018324812699574977, Final Batch Loss: 0.000423236662754789\n",
      "Epoch 3614, Loss: 0.00035453875045732275, Final Batch Loss: 1.091908984562906e-06\n",
      "Epoch 3615, Loss: 2.588188090157928e-05, Final Batch Loss: 1.2674378012889065e-05\n",
      "Epoch 3616, Loss: 1.8726532289292663e-05, Final Batch Loss: 1.1384890967747197e-05\n",
      "Epoch 3617, Loss: 9.66033803706523e-05, Final Batch Loss: 9.60335455602035e-07\n",
      "Epoch 3618, Loss: 4.6978941099951044e-05, Final Batch Loss: 3.097572334809229e-05\n",
      "Epoch 3619, Loss: 0.00014459092199103907, Final Batch Loss: 0.00010959985957015306\n",
      "Epoch 3620, Loss: 0.00011357980110915378, Final Batch Loss: 7.945982360979542e-05\n",
      "Epoch 3621, Loss: 5.6034781664493494e-05, Final Batch Loss: 2.3177790353656746e-05\n",
      "Epoch 3622, Loss: 2.998162199219223e-05, Final Batch Loss: 7.79674701334443e-06\n",
      "Epoch 3623, Loss: 1.7687808735900035e-05, Final Batch Loss: 1.623969728825614e-05\n",
      "Epoch 3624, Loss: 4.538005077847629e-05, Final Batch Loss: 6.353604021569481e-06\n",
      "Epoch 3625, Loss: 5.1073051281491644e-05, Final Batch Loss: 2.305912630617968e-06\n",
      "Epoch 3626, Loss: 0.003776728210937108, Final Batch Loss: 9.059793910637381e-07\n",
      "Epoch 3627, Loss: 0.000933463412366109, Final Batch Loss: 1.9141316442983225e-05\n",
      "Epoch 3628, Loss: 4.081655424670316e-05, Final Batch Loss: 2.7825301003758796e-05\n",
      "Epoch 3629, Loss: 3.2686906024537166e-05, Final Batch Loss: 2.1684402327082353e-06\n",
      "Epoch 3630, Loss: 0.00014302805539045949, Final Batch Loss: 2.8664320780080743e-05\n",
      "Epoch 3631, Loss: 0.00012577710367622785, Final Batch Loss: 3.2908330467762426e-05\n",
      "Epoch 3632, Loss: 0.00022231788898352534, Final Batch Loss: 0.00017968447355087847\n",
      "Epoch 3633, Loss: 0.0003096113981655435, Final Batch Loss: 1.1739506362573593e-06\n",
      "Epoch 3634, Loss: 2.7491794753586873e-05, Final Batch Loss: 1.136063838202972e-05\n",
      "Epoch 3635, Loss: 8.445288131042616e-06, Final Batch Loss: 8.478077688778285e-07\n",
      "Epoch 3636, Loss: 3.4891790619440144e-05, Final Batch Loss: 4.61956869912683e-06\n",
      "Epoch 3637, Loss: 0.0002516344754326383, Final Batch Loss: 8.630665320197295e-07\n",
      "Epoch 3638, Loss: 0.000861484368215315, Final Batch Loss: 0.00013784899783786386\n",
      "Epoch 3639, Loss: 0.0003891399537678808, Final Batch Loss: 4.5712513383477926e-05\n",
      "Epoch 3640, Loss: 0.00019165132835041732, Final Batch Loss: 9.782671259017661e-05\n",
      "Epoch 3641, Loss: 0.0003031504311366007, Final Batch Loss: 0.00021533429389819503\n",
      "Epoch 3642, Loss: 3.0485216484521516e-05, Final Batch Loss: 1.5149787941481918e-05\n",
      "Epoch 3643, Loss: 0.00011297771197860129, Final Batch Loss: 3.803465733653866e-05\n",
      "Epoch 3644, Loss: 3.292270321253454e-05, Final Batch Loss: 2.1981091776979156e-05\n",
      "Epoch 3645, Loss: 0.007004777813563123, Final Batch Loss: 0.0003760051040444523\n",
      "Epoch 3646, Loss: 0.0002188797348026128, Final Batch Loss: 2.004509497055551e-06\n",
      "Epoch 3647, Loss: 0.00015612001152476296, Final Batch Loss: 0.0001411669800290838\n",
      "Epoch 3648, Loss: 0.003009057433075668, Final Batch Loss: 7.085657784955401e-07\n",
      "Epoch 3649, Loss: 6.492701913884957e-05, Final Batch Loss: 5.393344054027693e-06\n",
      "Epoch 3650, Loss: 0.0016858323360793293, Final Batch Loss: 0.0007095831097103655\n",
      "Epoch 3651, Loss: 7.954486466132948e-05, Final Batch Loss: 7.804477354511619e-05\n",
      "Epoch 3652, Loss: 6.813970321672969e-05, Final Batch Loss: 4.4780106691177934e-05\n",
      "Epoch 3653, Loss: 0.0023529029167548288, Final Batch Loss: 8.406601409660652e-06\n",
      "Epoch 3654, Loss: 0.00116250358405523, Final Batch Loss: 0.00048026334843598306\n",
      "Epoch 3655, Loss: 0.0002486700286681298, Final Batch Loss: 3.809135887422599e-05\n",
      "Epoch 3656, Loss: 4.329896728449967e-05, Final Batch Loss: 1.7648844732320867e-05\n",
      "Epoch 3657, Loss: 0.00042379959631944075, Final Batch Loss: 8.397014607908204e-05\n",
      "Epoch 3658, Loss: 0.0012647113253478892, Final Batch Loss: 3.472384560154751e-05\n",
      "Epoch 3659, Loss: 8.162431549862958e-05, Final Batch Loss: 1.552180401631631e-05\n",
      "Epoch 3660, Loss: 0.0002557484549470246, Final Batch Loss: 3.060507879126817e-05\n",
      "Epoch 3661, Loss: 9.761443902789324e-05, Final Batch Loss: 2.5737851956364466e-06\n",
      "Epoch 3662, Loss: 6.766862134099938e-05, Final Batch Loss: 3.422123336349614e-05\n",
      "Epoch 3663, Loss: 0.00026858658384298906, Final Batch Loss: 0.0002533013466745615\n",
      "Epoch 3664, Loss: 0.003036492249520961, Final Batch Loss: 0.00010695725359255448\n",
      "Epoch 3665, Loss: 0.00026690618869906757, Final Batch Loss: 1.8211600036011077e-05\n",
      "Epoch 3666, Loss: 6.488525968961767e-05, Final Batch Loss: 4.646598881663522e-06\n",
      "Epoch 3667, Loss: 0.0002279167511005653, Final Batch Loss: 9.08576294023078e-06\n",
      "Epoch 3668, Loss: 6.273711005633231e-05, Final Batch Loss: 5.611445885733701e-06\n",
      "Epoch 3669, Loss: 4.342227202869253e-05, Final Batch Loss: 2.3154034352046438e-06\n",
      "Epoch 3670, Loss: 5.388878162193578e-05, Final Batch Loss: 3.64286606782116e-05\n",
      "Epoch 3671, Loss: 1.05793312741298e-05, Final Batch Loss: 7.810651368345134e-06\n",
      "Epoch 3672, Loss: 4.459054980543442e-05, Final Batch Loss: 8.96436904440634e-06\n",
      "Epoch 3673, Loss: 0.0019706315215444192, Final Batch Loss: 7.94993102317676e-05\n",
      "Epoch 3674, Loss: 3.478166945569683e-05, Final Batch Loss: 1.6674573998898268e-05\n",
      "Epoch 3675, Loss: 5.368666825233959e-05, Final Batch Loss: 2.1025898604420945e-05\n",
      "Epoch 3676, Loss: 0.00015763741612317972, Final Batch Loss: 5.2558771130861714e-05\n",
      "Epoch 3677, Loss: 0.00024259510973934084, Final Batch Loss: 0.0001291974331252277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3678, Loss: 0.00022849045387829392, Final Batch Loss: 1.570638119119394e-06\n",
      "Epoch 3679, Loss: 0.0002553407975938171, Final Batch Loss: 7.965895929373801e-05\n",
      "Epoch 3680, Loss: 0.0002594268007669598, Final Batch Loss: 0.00019962646183557808\n",
      "Epoch 3681, Loss: 1.1122237538074842e-05, Final Batch Loss: 2.256188508908963e-06\n",
      "Epoch 3682, Loss: 0.0002648746700515403, Final Batch Loss: 1.8843962834580452e-06\n",
      "Epoch 3683, Loss: 0.00023361797684628982, Final Batch Loss: 1.0689169357647188e-05\n",
      "Epoch 3684, Loss: 0.00016855395551829133, Final Batch Loss: 8.961253115558065e-06\n",
      "Epoch 3685, Loss: 1.0274516171193682e-05, Final Batch Loss: 3.3687069844745565e-06\n",
      "Epoch 3686, Loss: 6.88600030116504e-05, Final Batch Loss: 5.300081102177501e-05\n",
      "Epoch 3687, Loss: 5.140965686223353e-05, Final Batch Loss: 4.5997057895874605e-05\n",
      "Epoch 3688, Loss: 4.275167475498165e-05, Final Batch Loss: 3.681151065393351e-05\n",
      "Epoch 3689, Loss: 6.518836744362488e-05, Final Batch Loss: 3.239623401896097e-05\n",
      "Epoch 3690, Loss: 0.00045386450801743194, Final Batch Loss: 4.070784052601084e-05\n",
      "Epoch 3691, Loss: 0.0014664914251625305, Final Batch Loss: 2.186529127357062e-05\n",
      "Epoch 3692, Loss: 1.4741487575520296e-05, Final Batch Loss: 2.85040914604906e-06\n",
      "Epoch 3693, Loss: 0.000390752552448248, Final Batch Loss: 1.489541227783775e-05\n",
      "Epoch 3694, Loss: 2.717361178383726e-05, Final Batch Loss: 2.52961071964819e-05\n",
      "Epoch 3695, Loss: 2.536439205869101e-05, Final Batch Loss: 5.59742511541117e-06\n",
      "Epoch 3696, Loss: 0.00019036101730307564, Final Batch Loss: 6.459805445047095e-05\n",
      "Epoch 3697, Loss: 4.74732878501527e-05, Final Batch Loss: 1.193340722238645e-05\n",
      "Epoch 3698, Loss: 7.677199391764589e-05, Final Batch Loss: 5.249456444289535e-05\n",
      "Epoch 3699, Loss: 0.00010319905686628772, Final Batch Loss: 3.707590622070711e-06\n",
      "Epoch 3700, Loss: 8.595632971264422e-05, Final Batch Loss: 6.326824222924188e-05\n",
      "Epoch 3701, Loss: 0.00015042977611301467, Final Batch Loss: 6.754416244802997e-05\n",
      "Epoch 3702, Loss: 2.0351701550680446e-05, Final Batch Loss: 1.6287981452478562e-06\n",
      "Epoch 3703, Loss: 9.777062359717092e-06, Final Batch Loss: 7.331523647735594e-06\n",
      "Epoch 3704, Loss: 2.7683089683705475e-05, Final Batch Loss: 1.3114333341945894e-05\n",
      "Epoch 3705, Loss: 6.548048270360596e-05, Final Batch Loss: 1.476262809774198e-06\n",
      "Epoch 3706, Loss: 0.0001228041510330513, Final Batch Loss: 5.194337427383289e-05\n",
      "Epoch 3707, Loss: 0.00020916831272188574, Final Batch Loss: 0.00011570849892450497\n",
      "Epoch 3708, Loss: 0.00015645908752048854, Final Batch Loss: 0.0001377912994939834\n",
      "Epoch 3709, Loss: 0.0001633651918382384, Final Batch Loss: 9.964087803382427e-05\n",
      "Epoch 3710, Loss: 9.342197154182941e-05, Final Batch Loss: 5.04147210449446e-05\n",
      "Epoch 3711, Loss: 1.586299958944437e-05, Final Batch Loss: 2.73404248218867e-06\n",
      "Epoch 3712, Loss: 0.0002783959134831093, Final Batch Loss: 0.00023289243108592927\n",
      "Epoch 3713, Loss: 0.00029061648274364416, Final Batch Loss: 6.691358066746034e-06\n",
      "Epoch 3714, Loss: 1.728572624415392e-05, Final Batch Loss: 7.672661013202742e-06\n",
      "Epoch 3715, Loss: 0.0015840949290577555, Final Batch Loss: 9.832237992668524e-07\n",
      "Epoch 3716, Loss: 6.418705561372917e-05, Final Batch Loss: 1.8148117305827327e-05\n",
      "Epoch 3717, Loss: 2.4245330052963254e-05, Final Batch Loss: 3.6715965734401834e-07\n",
      "Epoch 3718, Loss: 9.702269016997889e-05, Final Batch Loss: 3.392632061149925e-05\n",
      "Epoch 3719, Loss: 9.689481203167816e-05, Final Batch Loss: 1.4047077456780244e-06\n",
      "Epoch 3720, Loss: 9.119573223870248e-05, Final Batch Loss: 8.10136625659652e-05\n",
      "Epoch 3721, Loss: 4.65812222500972e-05, Final Batch Loss: 8.287347554869484e-07\n",
      "Epoch 3722, Loss: 0.0001266108884010464, Final Batch Loss: 7.421048212563619e-05\n",
      "Epoch 3723, Loss: 0.0013824030452269653, Final Batch Loss: 3.28905161950388e-06\n",
      "Epoch 3724, Loss: 0.0013475722844304983, Final Batch Loss: 0.0013292526127770543\n",
      "Epoch 3725, Loss: 0.00016331480856024427, Final Batch Loss: 6.436722287617158e-06\n",
      "Epoch 3726, Loss: 3.314666662390664e-05, Final Batch Loss: 1.6545249081900693e-06\n",
      "Epoch 3727, Loss: 8.721166113900836e-05, Final Batch Loss: 2.161923021049006e-06\n",
      "Epoch 3728, Loss: 0.00024127631513692904, Final Batch Loss: 0.00021978562290314585\n",
      "Epoch 3729, Loss: 1.2828784292651108e-05, Final Batch Loss: 3.82415692001814e-07\n",
      "Epoch 3730, Loss: 0.0001864190726337256, Final Batch Loss: 0.00015917551354505122\n",
      "Epoch 3731, Loss: 2.602141921670409e-05, Final Batch Loss: 1.3734513231611345e-05\n",
      "Epoch 3732, Loss: 0.00044885361603519414, Final Batch Loss: 0.00042822971590794623\n",
      "Epoch 3733, Loss: 6.610732862100122e-05, Final Batch Loss: 7.3444030022074e-06\n",
      "Epoch 3734, Loss: 4.22246284870198e-05, Final Batch Loss: 2.8866397769888863e-06\n",
      "Epoch 3735, Loss: 8.586361036577728e-05, Final Batch Loss: 5.712185156880878e-05\n",
      "Epoch 3736, Loss: 0.00028360836654428567, Final Batch Loss: 0.0002824258990585804\n",
      "Epoch 3737, Loss: 1.4425662584471866e-05, Final Batch Loss: 1.2940561191499e-06\n",
      "Epoch 3738, Loss: 2.3376762328553014e-05, Final Batch Loss: 1.3489678167388774e-05\n",
      "Epoch 3739, Loss: 0.0012116351672943892, Final Batch Loss: 0.001210925169289112\n",
      "Epoch 3740, Loss: 4.611542522070522e-05, Final Batch Loss: 8.182344117813045e-07\n",
      "Epoch 3741, Loss: 0.00019302637520013377, Final Batch Loss: 0.00017128277977462858\n",
      "Epoch 3742, Loss: 1.526172309240792e-05, Final Batch Loss: 8.674905075167771e-06\n",
      "Epoch 3743, Loss: 0.00031924872018862516, Final Batch Loss: 3.727797593455762e-05\n",
      "Epoch 3744, Loss: 0.0003291424417284361, Final Batch Loss: 1.5134336308619822e-06\n",
      "Epoch 3745, Loss: 6.280580055317841e-05, Final Batch Loss: 2.226906144642271e-05\n",
      "Epoch 3746, Loss: 0.0002004888014255357, Final Batch Loss: 1.4686557392451505e-07\n",
      "Epoch 3747, Loss: 0.00010874832514673471, Final Batch Loss: 9.568336827214807e-05\n",
      "Epoch 3748, Loss: 0.0003067653378820978, Final Batch Loss: 0.00018945441115647554\n",
      "Epoch 3749, Loss: 1.977147516640798e-05, Final Batch Loss: 3.566700286228297e-07\n",
      "Epoch 3750, Loss: 0.0015321625229489655, Final Batch Loss: 9.536576044411049e-07\n",
      "Epoch 3751, Loss: 0.0024334245827049017, Final Batch Loss: 0.001658278051763773\n",
      "Epoch 3752, Loss: 2.179132798119099e-05, Final Batch Loss: 5.120906735101016e-06\n",
      "Epoch 3753, Loss: 5.3915855460218154e-05, Final Batch Loss: 2.549031523813028e-05\n",
      "Epoch 3754, Loss: 9.937705726770218e-06, Final Batch Loss: 5.115849944559159e-06\n",
      "Epoch 3755, Loss: 1.9452039396128384e-05, Final Batch Loss: 4.5486735871236306e-06\n",
      "Epoch 3756, Loss: 7.043036407594627e-05, Final Batch Loss: 2.314435050720931e-06\n",
      "Epoch 3757, Loss: 0.0018186187007813714, Final Batch Loss: 0.00176721578463912\n",
      "Epoch 3758, Loss: 0.00026618506672093645, Final Batch Loss: 0.00019713726942427456\n",
      "Epoch 3759, Loss: 0.0034877273651545693, Final Batch Loss: 3.985122475569369e-06\n",
      "Epoch 3760, Loss: 5.085921293357387e-05, Final Batch Loss: 1.229773261002265e-05\n",
      "Epoch 3761, Loss: 0.00019292771480650117, Final Batch Loss: 2.4318592295458075e-07\n",
      "Epoch 3762, Loss: 0.00043804460437968373, Final Batch Loss: 7.923220982775092e-05\n",
      "Epoch 3763, Loss: 1.921054615650064e-05, Final Batch Loss: 1.666016828494321e-06\n",
      "Epoch 3764, Loss: 0.0023664114414714277, Final Batch Loss: 0.0015534718986600637\n",
      "Epoch 3765, Loss: 9.164015591522912e-05, Final Batch Loss: 1.1186430128873326e-06\n",
      "Epoch 3766, Loss: 2.1609102986985818e-05, Final Batch Loss: 8.460098797513638e-06\n",
      "Epoch 3767, Loss: 0.0006020948894729372, Final Batch Loss: 0.0005602130549959838\n",
      "Epoch 3768, Loss: 0.0009609726037069777, Final Batch Loss: 0.0009580717887729406\n",
      "Epoch 3769, Loss: 4.543767090581241e-06, Final Batch Loss: 2.3524858079326805e-06\n",
      "Epoch 3770, Loss: 6.785393634345382e-05, Final Batch Loss: 2.533479710109532e-05\n",
      "Epoch 3771, Loss: 0.0006001482670399128, Final Batch Loss: 0.0005808487185277045\n",
      "Epoch 3772, Loss: 0.0002456721558701247, Final Batch Loss: 9.307955042459071e-05\n",
      "Epoch 3773, Loss: 7.290668395398825e-05, Final Batch Loss: 2.8427627967175795e-06\n",
      "Epoch 3774, Loss: 2.565242184005001e-05, Final Batch Loss: 2.9658812650268374e-07\n",
      "Epoch 3775, Loss: 0.000818465143083813, Final Batch Loss: 0.0008153290837071836\n",
      "Epoch 3776, Loss: 3.148004361719359e-05, Final Batch Loss: 1.365420212096069e-05\n",
      "Epoch 3777, Loss: 8.160689139913302e-05, Final Batch Loss: 2.4786697395029478e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3778, Loss: 1.452197750495543e-05, Final Batch Loss: 8.392136123802629e-07\n",
      "Epoch 3779, Loss: 0.0033801872214098694, Final Batch Loss: 0.0033644852228462696\n",
      "Epoch 3780, Loss: 0.00022707764719598345, Final Batch Loss: 3.6102005651628133e-06\n",
      "Epoch 3781, Loss: 0.00015313000767491758, Final Batch Loss: 7.03557234373875e-05\n",
      "Epoch 3782, Loss: 0.001421247154212324, Final Batch Loss: 0.0014080890687182546\n",
      "Epoch 3783, Loss: 0.0001455736135085317, Final Batch Loss: 2.325942432435113e-06\n",
      "Epoch 3784, Loss: 5.685520932274812e-06, Final Batch Loss: 1.6068873947006068e-06\n",
      "Epoch 3785, Loss: 1.6879997929208912e-05, Final Batch Loss: 5.837027856614441e-06\n",
      "Epoch 3786, Loss: 0.0024349860614165664, Final Batch Loss: 0.0008709152461960912\n",
      "Epoch 3787, Loss: 2.25548947128118e-05, Final Batch Loss: 6.768471394025255e-06\n",
      "Epoch 3788, Loss: 2.8912125344504602e-05, Final Batch Loss: 2.2638825612375513e-05\n",
      "Epoch 3789, Loss: 2.7026728275814094e-05, Final Batch Loss: 1.9744340534089133e-05\n",
      "Epoch 3790, Loss: 9.582219036019524e-06, Final Batch Loss: 2.632805490065948e-06\n",
      "Epoch 3791, Loss: 0.005046534584835172, Final Batch Loss: 0.0035359638277441263\n",
      "Epoch 3792, Loss: 0.0004250109996064566, Final Batch Loss: 0.00039645476499572396\n",
      "Epoch 3793, Loss: 0.0011241811080253683, Final Batch Loss: 0.0010860332986339927\n",
      "Epoch 3794, Loss: 7.917602374618582e-06, Final Batch Loss: 1.1634450629571802e-06\n",
      "Epoch 3795, Loss: 2.1487851881829556e-05, Final Batch Loss: 1.175092620542273e-05\n",
      "Epoch 3796, Loss: 7.489375548175303e-06, Final Batch Loss: 1.4590123100788333e-06\n",
      "Epoch 3797, Loss: 0.00024523685715394095, Final Batch Loss: 0.00022010794782545418\n",
      "Epoch 3798, Loss: 0.0017309164268226596, Final Batch Loss: 0.0017107476014643908\n",
      "Epoch 3799, Loss: 5.6457351888639096e-05, Final Batch Loss: 4.5108288304618327e-07\n",
      "Epoch 3800, Loss: 2.2379182155418675e-05, Final Batch Loss: 7.710706086072605e-06\n",
      "Epoch 3801, Loss: 8.45822269184282e-05, Final Batch Loss: 6.771968037355691e-05\n",
      "Epoch 3802, Loss: 4.651858580473345e-05, Final Batch Loss: 3.455817568465136e-05\n",
      "Epoch 3803, Loss: 3.65693083494989e-05, Final Batch Loss: 3.427152842050418e-05\n",
      "Epoch 3804, Loss: 0.0003492501491564326, Final Batch Loss: 7.242778519866988e-05\n",
      "Epoch 3805, Loss: 2.405584200459998e-05, Final Batch Loss: 8.652103133499622e-06\n",
      "Epoch 3806, Loss: 0.0006593964901639993, Final Batch Loss: 0.0006572737474925816\n",
      "Epoch 3807, Loss: 4.701666512119118e-05, Final Batch Loss: 2.6374078515800647e-05\n",
      "Epoch 3808, Loss: 8.922284760615184e-05, Final Batch Loss: 2.9372895937740395e-07\n",
      "Epoch 3809, Loss: 9.588324473952525e-06, Final Batch Loss: 1.816674057408818e-06\n",
      "Epoch 3810, Loss: 0.0024985763898257574, Final Batch Loss: 1.912908828671789e-06\n",
      "Epoch 3811, Loss: 0.0002380542500759475, Final Batch Loss: 0.00012884616444353014\n",
      "Epoch 3812, Loss: 0.0016936120844093239, Final Batch Loss: 0.0016899765469133854\n",
      "Epoch 3813, Loss: 0.00010179321907344274, Final Batch Loss: 5.92575415794272e-05\n",
      "Epoch 3814, Loss: 5.627002610708587e-05, Final Batch Loss: 2.887301343434956e-05\n",
      "Epoch 3815, Loss: 1.569028108860948e-05, Final Batch Loss: 8.458769116259646e-07\n",
      "Epoch 3816, Loss: 6.874260461131598e-05, Final Batch Loss: 3.709766076553933e-07\n",
      "Epoch 3817, Loss: 6.594861815756303e-06, Final Batch Loss: 5.459552994580008e-06\n",
      "Epoch 3818, Loss: 0.00019951990179833956, Final Batch Loss: 3.524682324496098e-05\n",
      "Epoch 3819, Loss: 0.0013444531505228952, Final Batch Loss: 0.00012875530228484422\n",
      "Epoch 3820, Loss: 2.2767469090467785e-05, Final Batch Loss: 1.6288466213154607e-05\n",
      "Epoch 3821, Loss: 5.570956773226499e-06, Final Batch Loss: 2.453620027154102e-06\n",
      "Epoch 3822, Loss: 5.4598538554273546e-05, Final Batch Loss: 2.3552067432319745e-05\n",
      "Epoch 3823, Loss: 1.3359948809466005e-05, Final Batch Loss: 2.9182325533838593e-07\n",
      "Epoch 3824, Loss: 4.334503955760738e-06, Final Batch Loss: 7.18093360774219e-07\n",
      "Epoch 3825, Loss: 7.858164053686778e-05, Final Batch Loss: 3.2994753382808995e-06\n",
      "Epoch 3826, Loss: 0.00018072338571073487, Final Batch Loss: 5.314468580763787e-06\n",
      "Epoch 3827, Loss: 2.2556936528417282e-05, Final Batch Loss: 2.0136698367423378e-05\n",
      "Epoch 3828, Loss: 3.1472875434701564e-06, Final Batch Loss: 2.272349775012117e-06\n",
      "Epoch 3829, Loss: 0.00022098075078247348, Final Batch Loss: 7.823568921594415e-06\n",
      "Epoch 3830, Loss: 0.005545616593735758, Final Batch Loss: 1.6052254068199545e-05\n",
      "Epoch 3831, Loss: 2.090873181259667e-06, Final Batch Loss: 1.241642053173564e-06\n",
      "Epoch 3832, Loss: 0.00042983698187981645, Final Batch Loss: 1.5629990457455278e-06\n",
      "Epoch 3833, Loss: 0.0002627793119245325, Final Batch Loss: 0.00025991094298660755\n",
      "Epoch 3834, Loss: 0.004542732975096442, Final Batch Loss: 0.004467136692255735\n",
      "Epoch 3835, Loss: 0.00017147299081443634, Final Batch Loss: 0.00016881345072761178\n",
      "Epoch 3836, Loss: 2.4194768229790498e-05, Final Batch Loss: 1.3212104931881186e-05\n",
      "Epoch 3837, Loss: 4.4562981429407955e-06, Final Batch Loss: 1.1529622270245454e-06\n",
      "Epoch 3838, Loss: 0.0001798293633328285, Final Batch Loss: 3.1203653634293005e-05\n",
      "Epoch 3839, Loss: 0.0005447593139251694, Final Batch Loss: 0.00023421617515850812\n",
      "Epoch 3840, Loss: 0.0003809114194268659, Final Batch Loss: 2.679797148630314e-07\n",
      "Epoch 3841, Loss: 0.0006706799031235278, Final Batch Loss: 0.0006525437929667532\n",
      "Epoch 3842, Loss: 0.0015209210359898861, Final Batch Loss: 6.81928577250801e-06\n",
      "Epoch 3843, Loss: 4.9748759465728654e-05, Final Batch Loss: 2.20278479901026e-06\n",
      "Epoch 3844, Loss: 0.0001286086280742893, Final Batch Loss: 0.00011601288133533671\n",
      "Epoch 3845, Loss: 0.00011368850573489908, Final Batch Loss: 2.6192372388322838e-05\n",
      "Epoch 3846, Loss: 0.022101608890807256, Final Batch Loss: 0.0004524978285189718\n",
      "Epoch 3847, Loss: 0.0006528940139105543, Final Batch Loss: 0.0006182450451888144\n",
      "Epoch 3848, Loss: 8.734406719668186e-06, Final Batch Loss: 3.757465947273886e-07\n",
      "Epoch 3849, Loss: 0.017446006531827152, Final Batch Loss: 0.0009781596018001437\n",
      "Epoch 3850, Loss: 2.084939069391112e-05, Final Batch Loss: 5.7535494306648616e-06\n",
      "Epoch 3851, Loss: 1.8085142073687166e-05, Final Batch Loss: 8.161191544786561e-06\n",
      "Epoch 3852, Loss: 6.927127969902358e-06, Final Batch Loss: 2.746562586253276e-07\n",
      "Epoch 3853, Loss: 6.29190617473796e-05, Final Batch Loss: 1.7306549125351012e-05\n",
      "Epoch 3854, Loss: 0.0009686463163234293, Final Batch Loss: 0.0004795795539394021\n",
      "Epoch 3855, Loss: 0.01881935293022252, Final Batch Loss: 4.001280103693716e-06\n",
      "Epoch 3856, Loss: 9.956193423477089e-05, Final Batch Loss: 1.8576541833681404e-06\n",
      "Epoch 3857, Loss: 4.5364977268036455e-06, Final Batch Loss: 9.946327281795675e-07\n",
      "Epoch 3858, Loss: 2.2892688775755232e-05, Final Batch Loss: 1.6521289580850862e-05\n",
      "Epoch 3859, Loss: 0.00884100023836254, Final Batch Loss: 0.008837328292429447\n",
      "Epoch 3860, Loss: 4.291650293453131e-05, Final Batch Loss: 3.910065788659267e-05\n",
      "Epoch 3861, Loss: 3.160123378620483e-05, Final Batch Loss: 1.1485390132293105e-05\n",
      "Epoch 3862, Loss: 3.7918274756520987e-05, Final Batch Loss: 1.3572705938713625e-05\n",
      "Epoch 3863, Loss: 0.0002543810857673634, Final Batch Loss: 7.638752208549704e-07\n",
      "Epoch 3864, Loss: 2.575592134235194e-05, Final Batch Loss: 2.0849254724453203e-05\n",
      "Epoch 3865, Loss: 0.002857877562291833, Final Batch Loss: 2.963623501273105e-06\n",
      "Epoch 3866, Loss: 3.942870239370677e-05, Final Batch Loss: 1.846249460868421e-06\n",
      "Epoch 3867, Loss: 0.00042107456152962186, Final Batch Loss: 7.724671036157815e-07\n",
      "Epoch 3868, Loss: 1.792830198610318e-05, Final Batch Loss: 1.121224613598315e-05\n",
      "Epoch 3869, Loss: 2.9306963369890582e-05, Final Batch Loss: 2.570996730355546e-05\n",
      "Epoch 3870, Loss: 0.0006557883577897883, Final Batch Loss: 0.0006531733670271933\n",
      "Epoch 3871, Loss: 0.00010063394211101695, Final Batch Loss: 6.124244009697577e-06\n",
      "Epoch 3872, Loss: 0.0001133946424261012, Final Batch Loss: 3.223393605367164e-07\n",
      "Epoch 3873, Loss: 1.3258447324915323e-05, Final Batch Loss: 4.961396371072624e-06\n",
      "Epoch 3874, Loss: 2.943076742667472e-05, Final Batch Loss: 1.102992882806575e-05\n",
      "Epoch 3875, Loss: 0.00041683643212309107, Final Batch Loss: 6.903366738697514e-05\n",
      "Epoch 3876, Loss: 0.00012952075803696061, Final Batch Loss: 7.145975814637495e-06\n",
      "Epoch 3877, Loss: 0.0009604084507373045, Final Batch Loss: 6.418241355277132e-06\n",
      "Epoch 3878, Loss: 3.137701355626632e-05, Final Batch Loss: 2.873236189770978e-05\n",
      "Epoch 3879, Loss: 3.91376477182348e-05, Final Batch Loss: 2.8168531116534723e-06\n",
      "Epoch 3880, Loss: 6.289854854912846e-05, Final Batch Loss: 5.9068410337204114e-05\n",
      "Epoch 3881, Loss: 0.0020786075183423236, Final Batch Loss: 0.001978803426027298\n",
      "Epoch 3882, Loss: 0.00016729960043448955, Final Batch Loss: 0.00011810078285634518\n",
      "Epoch 3883, Loss: 0.0001481882864027284, Final Batch Loss: 8.178185817087069e-05\n",
      "Epoch 3884, Loss: 0.00014426295638259035, Final Batch Loss: 1.2811780834454112e-05\n",
      "Epoch 3885, Loss: 1.0249846809529117e-05, Final Batch Loss: 7.5739549174613785e-06\n",
      "Epoch 3886, Loss: 0.00010122945968760177, Final Batch Loss: 3.622563963290304e-05\n",
      "Epoch 3887, Loss: 0.00018023032862402033, Final Batch Loss: 0.00016074332233984023\n",
      "Epoch 3888, Loss: 1.1742578863049857e-05, Final Batch Loss: 1.1417855603212956e-05\n",
      "Epoch 3889, Loss: 9.336932635051198e-06, Final Batch Loss: 6.300615041254787e-06\n",
      "Epoch 3890, Loss: 0.010579121289737259, Final Batch Loss: 3.1757164720147557e-07\n",
      "Epoch 3891, Loss: 1.0424579159007408e-05, Final Batch Loss: 2.9275242923176847e-06\n",
      "Epoch 3892, Loss: 3.712562465807423e-05, Final Batch Loss: 1.0447092790855095e-05\n",
      "Epoch 3893, Loss: 5.224128835834563e-05, Final Batch Loss: 6.736729119438678e-06\n",
      "Epoch 3894, Loss: 1.2082960438419832e-05, Final Batch Loss: 1.0051576282421593e-06\n",
      "Epoch 3895, Loss: 2.844126538548153e-05, Final Batch Loss: 3.8025718822609633e-06\n",
      "Epoch 3896, Loss: 2.8402691896189936e-05, Final Batch Loss: 1.3336268239072524e-05\n",
      "Epoch 3897, Loss: 2.714586844376754e-05, Final Batch Loss: 9.286435670219362e-06\n",
      "Epoch 3898, Loss: 0.0031338391454482917, Final Batch Loss: 0.0031213010661303997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3899, Loss: 2.9544077506216126e-05, Final Batch Loss: 2.577528675828944e-06\n",
      "Epoch 3900, Loss: 0.00011179191824339796, Final Batch Loss: 0.00010389611270511523\n",
      "Epoch 3901, Loss: 3.115244498985703e-05, Final Batch Loss: 2.9509325031540357e-05\n",
      "Epoch 3902, Loss: 0.0001225167670781957, Final Batch Loss: 0.00011171952792210504\n",
      "Epoch 3903, Loss: 6.730917357344879e-05, Final Batch Loss: 8.594269274908584e-06\n",
      "Epoch 3904, Loss: 3.218411484340322e-05, Final Batch Loss: 2.4616168957436457e-05\n",
      "Epoch 3905, Loss: 7.02467641531257e-05, Final Batch Loss: 4.12063418480102e-05\n",
      "Epoch 3906, Loss: 0.0010978868922393303, Final Batch Loss: 0.001064880401827395\n",
      "Epoch 3907, Loss: 4.5831762690795586e-05, Final Batch Loss: 2.2908745449967682e-05\n",
      "Epoch 3908, Loss: 0.00016811658497317694, Final Batch Loss: 1.0900221241172403e-06\n",
      "Epoch 3909, Loss: 0.0003049040406040149, Final Batch Loss: 0.00028068534447811544\n",
      "Epoch 3910, Loss: 0.0019384514016564935, Final Batch Loss: 0.00033919906127266586\n",
      "Epoch 3911, Loss: 3.536149142746581e-05, Final Batch Loss: 3.330475010443479e-05\n",
      "Epoch 3912, Loss: 0.0005781103735671422, Final Batch Loss: 7.34324089535221e-07\n",
      "Epoch 3913, Loss: 1.5995742188579243e-05, Final Batch Loss: 4.3010416561628517e-07\n",
      "Epoch 3914, Loss: 1.2241010608704528e-05, Final Batch Loss: 3.3834317036962602e-06\n",
      "Epoch 3915, Loss: 0.0003295647195500351, Final Batch Loss: 0.000327285029925406\n",
      "Epoch 3916, Loss: 0.00012311560749367345, Final Batch Loss: 1.9917280951631255e-05\n",
      "Epoch 3917, Loss: 7.404079588013701e-05, Final Batch Loss: 3.1821575248613954e-05\n",
      "Epoch 3918, Loss: 6.0429050790844485e-05, Final Batch Loss: 1.8960206944029778e-05\n",
      "Epoch 3919, Loss: 6.575932275154628e-05, Final Batch Loss: 5.116264219395816e-05\n",
      "Epoch 3920, Loss: 3.3377448175997415e-05, Final Batch Loss: 3.277330688433722e-05\n",
      "Epoch 3921, Loss: 0.0005025014252169058, Final Batch Loss: 9.150536789093167e-05\n",
      "Epoch 3922, Loss: 0.00024132539738275227, Final Batch Loss: 3.398716671654256e-06\n",
      "Epoch 3923, Loss: 8.06019093033683e-05, Final Batch Loss: 2.577610302978428e-06\n",
      "Epoch 3924, Loss: 7.32428834453458e-05, Final Batch Loss: 2.4975224732770585e-05\n",
      "Epoch 3925, Loss: 2.0777487975465192e-05, Final Batch Loss: 1.2750475661960081e-06\n",
      "Epoch 3926, Loss: 6.811330240452662e-05, Final Batch Loss: 2.153420791728422e-05\n",
      "Epoch 3927, Loss: 1.5075160263222642e-05, Final Batch Loss: 1.0913068763329647e-05\n",
      "Epoch 3928, Loss: 0.0045339932112256065, Final Batch Loss: 0.004516485147178173\n",
      "Epoch 3929, Loss: 8.802752563497052e-05, Final Batch Loss: 5.377070920076221e-06\n",
      "Epoch 3930, Loss: 0.0015444890491380647, Final Batch Loss: 5.335303740139352e-06\n",
      "Epoch 3931, Loss: 0.000913199401111342, Final Batch Loss: 8.688140951562673e-05\n",
      "Epoch 3932, Loss: 2.2719751086697215e-05, Final Batch Loss: 1.57399736053776e-05\n",
      "Epoch 3933, Loss: 4.6513973302353406e-05, Final Batch Loss: 4.346874266047962e-05\n",
      "Epoch 3934, Loss: 0.00011673067638184875, Final Batch Loss: 2.877505903597921e-05\n",
      "Epoch 3935, Loss: 0.00029859172354917973, Final Batch Loss: 0.00021653865405824035\n",
      "Epoch 3936, Loss: 9.0546760475263e-05, Final Batch Loss: 7.127368007786572e-05\n",
      "Epoch 3937, Loss: 2.729152129177237e-05, Final Batch Loss: 1.85341286851326e-05\n",
      "Epoch 3938, Loss: 1.26107852338464e-05, Final Batch Loss: 4.459025149117224e-06\n",
      "Epoch 3939, Loss: 0.0005868673737268182, Final Batch Loss: 1.955025936695165e-07\n",
      "Epoch 3940, Loss: 0.0003126449978481105, Final Batch Loss: 0.0003078354347962886\n",
      "Epoch 3941, Loss: 2.0981206830583687e-05, Final Batch Loss: 1.967094067367725e-05\n",
      "Epoch 3942, Loss: 0.0010019901386613128, Final Batch Loss: 6.647027248618542e-07\n",
      "Epoch 3943, Loss: 0.000316757352265995, Final Batch Loss: 0.00022631419415120035\n",
      "Epoch 3944, Loss: 1.1191610155947274e-05, Final Batch Loss: 5.527327630261425e-06\n",
      "Epoch 3945, Loss: 1.543709413454053e-05, Final Batch Loss: 3.109704721282469e-06\n",
      "Epoch 3946, Loss: 3.174888388457475e-05, Final Batch Loss: 1.1562750842131209e-05\n",
      "Epoch 3947, Loss: 4.624152643373236e-05, Final Batch Loss: 2.8468333766795695e-05\n",
      "Epoch 3948, Loss: 5.5151087281046784e-05, Final Batch Loss: 5.2428138587856665e-05\n",
      "Epoch 3949, Loss: 4.870771226705983e-05, Final Batch Loss: 7.695245585637167e-06\n",
      "Epoch 3950, Loss: 0.00045340682845562696, Final Batch Loss: 2.467533340677619e-05\n",
      "Epoch 3951, Loss: 1.2157373703303165e-05, Final Batch Loss: 2.7005305582861183e-06\n",
      "Epoch 3952, Loss: 3.415601872802654e-05, Final Batch Loss: 1.409505557603552e-06\n",
      "Epoch 3953, Loss: 0.0005201847729949804, Final Batch Loss: 4.078398433193797e-06\n",
      "Epoch 3954, Loss: 5.637678987113759e-05, Final Batch Loss: 1.2046239135088399e-05\n",
      "Epoch 3955, Loss: 2.4994697014335543e-05, Final Batch Loss: 1.468002301407978e-05\n",
      "Epoch 3956, Loss: 7.016413672999988e-05, Final Batch Loss: 6.008087325426459e-07\n",
      "Epoch 3957, Loss: 4.976429590897169e-05, Final Batch Loss: 1.3185899661039002e-05\n",
      "Epoch 3958, Loss: 2.297011769769597e-05, Final Batch Loss: 2.0072176994290203e-05\n",
      "Epoch 3959, Loss: 9.561159095028415e-05, Final Batch Loss: 4.1350122046424076e-05\n",
      "Epoch 3960, Loss: 0.00012229930234752828, Final Batch Loss: 1.0446056876389775e-05\n",
      "Epoch 3961, Loss: 2.9558731966972118e-05, Final Batch Loss: 4.9654149734124076e-06\n",
      "Epoch 3962, Loss: 7.426319825754035e-05, Final Batch Loss: 2.079788282571826e-05\n",
      "Epoch 3963, Loss: 0.0002274252019560663, Final Batch Loss: 0.00020139232219662517\n",
      "Epoch 3964, Loss: 3.1717058845970314e-05, Final Batch Loss: 4.354754310043063e-06\n",
      "Epoch 3965, Loss: 9.483577969149337e-06, Final Batch Loss: 3.7752927255496616e-06\n",
      "Epoch 3966, Loss: 0.0006581435774251077, Final Batch Loss: 1.4304279147836496e-06\n",
      "Epoch 3967, Loss: 2.0783128775292425e-05, Final Batch Loss: 1.736596232149168e-06\n",
      "Epoch 3968, Loss: 4.360435559647158e-05, Final Batch Loss: 2.4749011572566815e-05\n",
      "Epoch 3969, Loss: 9.525127097731456e-05, Final Batch Loss: 3.463531538727693e-05\n",
      "Epoch 3970, Loss: 5.605866863334086e-05, Final Batch Loss: 3.102069968008436e-05\n",
      "Epoch 3971, Loss: 2.3259472072822973e-06, Final Batch Loss: 1.8443477074470138e-06\n",
      "Epoch 3972, Loss: 0.000876518854056485, Final Batch Loss: 0.0007348563522100449\n",
      "Epoch 3973, Loss: 5.7758669754548464e-05, Final Batch Loss: 6.56825886835577e-06\n",
      "Epoch 3974, Loss: 2.7789962132374058e-05, Final Batch Loss: 4.773232376464875e-06\n",
      "Epoch 3975, Loss: 0.001661453970882576, Final Batch Loss: 0.0016330727376043797\n",
      "Epoch 3976, Loss: 0.0002729326763528661, Final Batch Loss: 2.5004367216752144e-06\n",
      "Epoch 3977, Loss: 1.254664982752729e-05, Final Batch Loss: 1.1558262258404284e-06\n",
      "Epoch 3978, Loss: 7.751264274702407e-05, Final Batch Loss: 8.655184501549229e-06\n",
      "Epoch 3979, Loss: 0.003288718142812286, Final Batch Loss: 0.00328120868653059\n",
      "Epoch 3980, Loss: 0.00013798776876683405, Final Batch Loss: 1.9873298242600868e-06\n",
      "Epoch 3981, Loss: 1.9235400031902827e-05, Final Batch Loss: 1.3961561307951342e-05\n",
      "Epoch 3982, Loss: 4.3324339117134514e-05, Final Batch Loss: 1.2559418109958642e-06\n",
      "Epoch 3983, Loss: 0.00020665588090196252, Final Batch Loss: 0.00012596546730492264\n",
      "Epoch 3984, Loss: 4.834206811210606e-05, Final Batch Loss: 1.6450334442197345e-05\n",
      "Epoch 3985, Loss: 2.0398342257976765e-05, Final Batch Loss: 1.89579095604131e-05\n",
      "Epoch 3986, Loss: 0.00014389964417205192, Final Batch Loss: 2.6795230951393023e-05\n",
      "Epoch 3987, Loss: 9.173895523417741e-05, Final Batch Loss: 5.614652036456391e-05\n",
      "Epoch 3988, Loss: 0.0004191417820038623, Final Batch Loss: 0.0004040322091896087\n",
      "Epoch 3989, Loss: 5.321309896544335e-05, Final Batch Loss: 5.35005767687835e-07\n",
      "Epoch 3990, Loss: 0.00024321767614310374, Final Batch Loss: 5.931512532697525e-06\n",
      "Epoch 3991, Loss: 0.00012533300468930975, Final Batch Loss: 8.153379894793034e-05\n",
      "Epoch 3992, Loss: 1.3825217138219159e-05, Final Batch Loss: 1.1424817785155028e-06\n",
      "Epoch 3993, Loss: 9.435978995497862e-06, Final Batch Loss: 1.3732881143369013e-07\n",
      "Epoch 3994, Loss: 5.8733766309160274e-05, Final Batch Loss: 4.9267719077761285e-06\n",
      "Epoch 3995, Loss: 3.880273879985907e-06, Final Batch Loss: 1.833824853747501e-06\n",
      "Epoch 3996, Loss: 0.00012120711562602082, Final Batch Loss: 1.044726468535373e-05\n",
      "Epoch 3997, Loss: 0.000743228622013703, Final Batch Loss: 0.0001349461090285331\n",
      "Epoch 3998, Loss: 0.0020906280651615816, Final Batch Loss: 9.952850632544141e-06\n",
      "Epoch 3999, Loss: 4.943802468915237e-05, Final Batch Loss: 4.879383050138131e-05\n",
      "Epoch 4000, Loss: 3.231494191879847e-05, Final Batch Loss: 1.306529071598561e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4001, Loss: 5.8761827403941425e-05, Final Batch Loss: 5.185931877349503e-05\n",
      "Epoch 4002, Loss: 3.7723183595517185e-05, Final Batch Loss: 2.696679803193547e-05\n",
      "Epoch 4003, Loss: 2.4539939886381035e-05, Final Batch Loss: 3.1239990221365588e-06\n",
      "Epoch 4004, Loss: 0.0002493909851182252, Final Batch Loss: 1.4515942893922329e-05\n",
      "Epoch 4005, Loss: 5.1240926040918566e-05, Final Batch Loss: 1.7289685274590738e-05\n",
      "Epoch 4006, Loss: 0.0005623942433885531, Final Batch Loss: 7.144497430999763e-06\n",
      "Epoch 4007, Loss: 5.55347906328052e-06, Final Batch Loss: 4.863732527837783e-08\n",
      "Epoch 4008, Loss: 0.00011191874644111977, Final Batch Loss: 1.5258690666541952e-07\n",
      "Epoch 4009, Loss: 0.0001959117987553327, Final Batch Loss: 1.792742068573716e-06\n",
      "Epoch 4010, Loss: 2.8703681053343644e-05, Final Batch Loss: 1.4209679477517057e-07\n",
      "Epoch 4011, Loss: 0.0001987213554457412, Final Batch Loss: 0.0001885920064523816\n",
      "Epoch 4012, Loss: 1.6740377304813592e-05, Final Batch Loss: 1.1744569746952038e-05\n",
      "Epoch 4013, Loss: 0.0006777008929930162, Final Batch Loss: 0.0006423545419238508\n",
      "Epoch 4014, Loss: 3.4254904221597826e-05, Final Batch Loss: 3.200358696631156e-05\n",
      "Epoch 4015, Loss: 1.3200830608184333e-05, Final Batch Loss: 2.6355744466854958e-06\n",
      "Epoch 4016, Loss: 6.822961040597875e-06, Final Batch Loss: 8.172896741598379e-07\n",
      "Epoch 4017, Loss: 0.0001490748836658895, Final Batch Loss: 0.00012541093747131526\n",
      "Epoch 4018, Loss: 0.0012431963159542647, Final Batch Loss: 8.53289839142235e-06\n",
      "Epoch 4019, Loss: 1.567967137816595e-05, Final Batch Loss: 1.1746775271603838e-05\n",
      "Epoch 4020, Loss: 1.624837841518456e-05, Final Batch Loss: 9.654285349824931e-06\n",
      "Epoch 4021, Loss: 8.084948331088526e-05, Final Batch Loss: 7.045223173918203e-05\n",
      "Epoch 4022, Loss: 2.4387452640439733e-05, Final Batch Loss: 2.079855903502903e-06\n",
      "Epoch 4023, Loss: 0.0012867444145854279, Final Batch Loss: 9.41259543196793e-07\n",
      "Epoch 4024, Loss: 0.00011069654192397138, Final Batch Loss: 9.54914212343283e-05\n",
      "Epoch 4025, Loss: 7.837946213840041e-06, Final Batch Loss: 4.876511411566753e-06\n",
      "Epoch 4026, Loss: 4.0401961086899973e-05, Final Batch Loss: 2.976840187329799e-05\n",
      "Epoch 4027, Loss: 1.5026273558760295e-05, Final Batch Loss: 8.733935828786343e-06\n",
      "Epoch 4028, Loss: 0.00011310558988952835, Final Batch Loss: 0.00011242324399063364\n",
      "Epoch 4029, Loss: 0.0002458539129293058, Final Batch Loss: 9.88137981039472e-06\n",
      "Epoch 4030, Loss: 5.586374390986748e-05, Final Batch Loss: 4.7890709538478404e-05\n",
      "Epoch 4031, Loss: 7.30233648482681e-06, Final Batch Loss: 5.4151842050487176e-06\n",
      "Epoch 4032, Loss: 5.2621996928792214e-05, Final Batch Loss: 5.340299594536191e-06\n",
      "Epoch 4033, Loss: 0.00013624302033576896, Final Batch Loss: 0.00013556401245296001\n",
      "Epoch 4034, Loss: 3.80212844675043e-05, Final Batch Loss: 8.687860599820851e-07\n",
      "Epoch 4035, Loss: 0.0012581773007696029, Final Batch Loss: 5.179326035431586e-05\n",
      "Epoch 4036, Loss: 0.00039397126147378003, Final Batch Loss: 0.00039104229654185474\n",
      "Epoch 4037, Loss: 1.4571091014659032e-05, Final Batch Loss: 5.476006663229782e-06\n",
      "Epoch 4038, Loss: 0.0001646096570766531, Final Batch Loss: 0.00014664317131973803\n",
      "Epoch 4039, Loss: 6.870399784020265e-05, Final Batch Loss: 7.33823662812938e-06\n",
      "Epoch 4040, Loss: 0.0007173680755840905, Final Batch Loss: 5.763704848504858e-06\n",
      "Epoch 4041, Loss: 4.9492902405745554e-05, Final Batch Loss: 4.885252928943373e-05\n",
      "Epoch 4042, Loss: 9.051109009305947e-05, Final Batch Loss: 6.645765824941918e-05\n",
      "Epoch 4043, Loss: 0.0005628937351502827, Final Batch Loss: 0.0005477277445606887\n",
      "Epoch 4044, Loss: 0.00030517205050273333, Final Batch Loss: 2.3041147869662382e-05\n",
      "Epoch 4045, Loss: 1.8026787302005687e-05, Final Batch Loss: 8.611571047367761e-07\n",
      "Epoch 4046, Loss: 3.8550336967091425e-05, Final Batch Loss: 6.818661404395243e-07\n",
      "Epoch 4047, Loss: 5.696111111319624e-05, Final Batch Loss: 2.8550421120598912e-05\n",
      "Epoch 4048, Loss: 2.5789258927488845e-05, Final Batch Loss: 6.809150931985641e-07\n",
      "Epoch 4049, Loss: 1.566166156408144e-05, Final Batch Loss: 4.588546289596707e-06\n",
      "Epoch 4050, Loss: 3.3556256767042214e-05, Final Batch Loss: 4.230320428177947e-06\n",
      "Epoch 4051, Loss: 2.0769261027453467e-05, Final Batch Loss: 8.694860298419371e-06\n",
      "Epoch 4052, Loss: 2.4888303869374795e-05, Final Batch Loss: 4.463550340005895e-06\n",
      "Epoch 4053, Loss: 0.00018521152469475055, Final Batch Loss: 0.00017672804824542254\n",
      "Epoch 4054, Loss: 6.564632030858775e-06, Final Batch Loss: 2.9530310712289065e-06\n",
      "Epoch 4055, Loss: 0.00018081423877447378, Final Batch Loss: 1.7999815099756233e-05\n",
      "Epoch 4056, Loss: 0.00011332381700412952, Final Batch Loss: 0.00011113291111541912\n",
      "Epoch 4057, Loss: 5.741027189287706e-05, Final Batch Loss: 3.2442017072753515e-06\n",
      "Epoch 4058, Loss: 6.490060513897333e-05, Final Batch Loss: 1.8402855857857503e-05\n",
      "Epoch 4059, Loss: 1.2431613868102431e-05, Final Batch Loss: 4.351837560534477e-06\n",
      "Epoch 4060, Loss: 0.002248479695936112, Final Batch Loss: 2.2563058337254915e-06\n",
      "Epoch 4061, Loss: 0.0002366903459005698, Final Batch Loss: 3.809177997027291e-06\n",
      "Epoch 4062, Loss: 1.0594587365631014e-05, Final Batch Loss: 1.1205347618670203e-06\n",
      "Epoch 4063, Loss: 2.3759926079947036e-05, Final Batch Loss: 6.8131166699458845e-06\n",
      "Epoch 4064, Loss: 4.829011504625669e-05, Final Batch Loss: 3.3327945857308805e-05\n",
      "Epoch 4065, Loss: 0.00035974886850453913, Final Batch Loss: 0.00023235793923959136\n",
      "Epoch 4066, Loss: 0.0003629706880019512, Final Batch Loss: 0.00030272878939285874\n",
      "Epoch 4067, Loss: 4.491057666200504e-06, Final Batch Loss: 1.1043283620892907e-06\n",
      "Epoch 4068, Loss: 0.003181360094458796, Final Batch Loss: 5.2422183216549456e-05\n",
      "Epoch 4069, Loss: 0.001298188403865197, Final Batch Loss: 2.5081416765715403e-07\n",
      "Epoch 4070, Loss: 2.8569481401063967e-05, Final Batch Loss: 1.5756171706016175e-05\n",
      "Epoch 4071, Loss: 4.5841315113648307e-05, Final Batch Loss: 1.06806601252174e-06\n",
      "Epoch 4072, Loss: 8.08976955113394e-06, Final Batch Loss: 7.183363777585328e-06\n",
      "Epoch 4073, Loss: 6.802479219913948e-06, Final Batch Loss: 4.908131813863292e-06\n",
      "Epoch 4074, Loss: 0.00039049207225616556, Final Batch Loss: 2.817170570779126e-05\n",
      "Epoch 4075, Loss: 5.440898166853003e-05, Final Batch Loss: 2.236008003819734e-05\n",
      "Epoch 4076, Loss: 1.1493963143038854e-05, Final Batch Loss: 1.1067675586673431e-05\n",
      "Epoch 4077, Loss: 0.00037000361044192687, Final Batch Loss: 1.4686520444229245e-07\n",
      "Epoch 4078, Loss: 8.920114419197489e-05, Final Batch Loss: 2.250409352200222e-06\n",
      "Epoch 4079, Loss: 4.8277457608492114e-05, Final Batch Loss: 2.5610446755308658e-05\n",
      "Epoch 4080, Loss: 0.0002452575135976076, Final Batch Loss: 9.901385055854917e-06\n",
      "Epoch 4081, Loss: 0.0019810260127997026, Final Batch Loss: 0.0018003875156864524\n",
      "Epoch 4082, Loss: 0.0009212349332301528, Final Batch Loss: 0.0009060913580469787\n",
      "Epoch 4083, Loss: 1.2068969454048784e-05, Final Batch Loss: 1.0484125596121885e-05\n",
      "Epoch 4084, Loss: 2.8134083436270885e-06, Final Batch Loss: 3.0231370828914805e-07\n",
      "Epoch 4085, Loss: 1.657228449403192e-05, Final Batch Loss: 7.281200396391796e-06\n",
      "Epoch 4086, Loss: 0.0016517947305487723, Final Batch Loss: 0.0016511648427695036\n",
      "Epoch 4087, Loss: 2.645851782290265e-05, Final Batch Loss: 1.84888322110055e-05\n",
      "Epoch 4088, Loss: 0.0002780480836008792, Final Batch Loss: 0.0002645434869918972\n",
      "Epoch 4089, Loss: 0.0007226215820992365, Final Batch Loss: 0.0005708393873646855\n",
      "Epoch 4090, Loss: 1.5023281207504624e-05, Final Batch Loss: 1.3568036592914723e-05\n",
      "Epoch 4091, Loss: 0.006187930153600973, Final Batch Loss: 2.5643128083174815e-06\n",
      "Epoch 4092, Loss: 0.00010212804926368335, Final Batch Loss: 0.00010130985174328089\n",
      "Epoch 4093, Loss: 6.879222283373565e-06, Final Batch Loss: 2.126675013869317e-07\n",
      "Epoch 4094, Loss: 5.376856208272329e-06, Final Batch Loss: 1.9836254239180562e-07\n",
      "Epoch 4095, Loss: 1.529670259969862e-05, Final Batch Loss: 1.0718671319409623e-06\n",
      "Epoch 4096, Loss: 0.002637654833961278, Final Batch Loss: 0.00039529899368062615\n",
      "Epoch 4097, Loss: 0.00010548796853981912, Final Batch Loss: 9.755448991199955e-05\n",
      "Epoch 4098, Loss: 4.857423959947482e-05, Final Batch Loss: 1.0146479780814843e-06\n",
      "Epoch 4099, Loss: 5.39960583409993e-05, Final Batch Loss: 2.7366502763470635e-05\n",
      "Epoch 4100, Loss: 4.4659277591563296e-06, Final Batch Loss: 1.8586354144645156e-06\n",
      "Epoch 4101, Loss: 1.6343862625944894e-05, Final Batch Loss: 8.914749741961714e-06\n",
      "Epoch 4102, Loss: 0.000517288802910798, Final Batch Loss: 3.2043109854384966e-07\n",
      "Epoch 4103, Loss: 4.910952281989012e-05, Final Batch Loss: 1.3884667851016275e-06\n",
      "Epoch 4104, Loss: 2.379001580266049e-05, Final Batch Loss: 1.2652420082304161e-05\n",
      "Epoch 4105, Loss: 0.06408868060680106, Final Batch Loss: 0.06339065730571747\n",
      "Epoch 4106, Loss: 1.1005359283444704e-05, Final Batch Loss: 8.489744686812628e-06\n",
      "Epoch 4107, Loss: 0.000812452019772536, Final Batch Loss: 1.7890367871586932e-06\n",
      "Epoch 4108, Loss: 0.00028108261903980747, Final Batch Loss: 0.0002751218562480062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4109, Loss: 2.21362674892589e-05, Final Batch Loss: 5.3912003750156146e-06\n",
      "Epoch 4110, Loss: 0.0011729884372471133, Final Batch Loss: 0.0011535644298419356\n",
      "Epoch 4111, Loss: 1.6501326626894297e-05, Final Batch Loss: 1.4876813111186493e-05\n",
      "Epoch 4112, Loss: 8.110762792057358e-05, Final Batch Loss: 1.647328826948069e-05\n",
      "Epoch 4113, Loss: 0.02399872016394511, Final Batch Loss: 0.00018928718054667115\n",
      "Epoch 4114, Loss: 8.934859215514734e-05, Final Batch Loss: 2.9863342206226662e-05\n",
      "Epoch 4115, Loss: 0.0042916333477478474, Final Batch Loss: 0.00022447502124123275\n",
      "Epoch 4116, Loss: 1.392789772580727e-05, Final Batch Loss: 2.281953584315488e-06\n",
      "Epoch 4117, Loss: 4.830492707696976e-05, Final Batch Loss: 3.330702384118922e-05\n",
      "Epoch 4118, Loss: 0.00013925587336416356, Final Batch Loss: 4.217587775201537e-05\n",
      "Epoch 4119, Loss: 0.0007063234806992114, Final Batch Loss: 0.0006803982541896403\n",
      "Epoch 4120, Loss: 0.0017715007852530107, Final Batch Loss: 9.065934864338487e-05\n",
      "Epoch 4121, Loss: 0.0022139679877000162, Final Batch Loss: 0.002183920470997691\n",
      "Epoch 4122, Loss: 2.1892915071930474e-05, Final Batch Loss: 9.27910775772034e-07\n",
      "Epoch 4123, Loss: 0.00019359338966751238, Final Batch Loss: 9.490750926488545e-06\n",
      "Epoch 4124, Loss: 8.76802751008654e-05, Final Batch Loss: 1.3814556950819679e-05\n",
      "Epoch 4125, Loss: 1.829084339988185e-05, Final Batch Loss: 1.1526703019626439e-05\n",
      "Epoch 4126, Loss: 0.0017297080485150218, Final Batch Loss: 0.0016693526413291693\n",
      "Epoch 4127, Loss: 0.00013188043658374227, Final Batch Loss: 2.5451968213019427e-06\n",
      "Epoch 4128, Loss: 3.118491804343648e-05, Final Batch Loss: 1.098975189961493e-05\n",
      "Epoch 4129, Loss: 0.00028873477094748523, Final Batch Loss: 0.00026499282103031874\n",
      "Epoch 4130, Loss: 0.002339302223845152, Final Batch Loss: 3.997458770754747e-05\n",
      "Epoch 4131, Loss: 9.315365150541766e-05, Final Batch Loss: 5.181685082789045e-06\n",
      "Epoch 4132, Loss: 0.0004531287995632738, Final Batch Loss: 4.635547520592809e-05\n",
      "Epoch 4133, Loss: 2.1084059881104622e-05, Final Batch Loss: 7.1326367105939426e-06\n",
      "Epoch 4134, Loss: 0.0007529675976911676, Final Batch Loss: 0.0007408087840303779\n",
      "Epoch 4135, Loss: 0.00010037765969173051, Final Batch Loss: 8.916515798773617e-05\n",
      "Epoch 4136, Loss: 0.00039122214548115153, Final Batch Loss: 2.7396819859859534e-05\n",
      "Epoch 4137, Loss: 0.0006911342206876725, Final Batch Loss: 0.00043917790753766894\n",
      "Epoch 4138, Loss: 0.00036892026400892064, Final Batch Loss: 0.00011221586464671418\n",
      "Epoch 4139, Loss: 0.000960265093453927, Final Batch Loss: 2.3018259525997564e-05\n",
      "Epoch 4140, Loss: 2.9167928460083203e-05, Final Batch Loss: 4.054256805829937e-06\n",
      "Epoch 4141, Loss: 0.02034823872963898, Final Batch Loss: 7.178352097980678e-05\n",
      "Epoch 4142, Loss: 3.4640779631445184e-05, Final Batch Loss: 1.1369273124728352e-05\n",
      "Epoch 4143, Loss: 1.5911859009065665e-05, Final Batch Loss: 8.288900971820112e-06\n",
      "Epoch 4144, Loss: 3.384922308669047e-06, Final Batch Loss: 2.564310534580727e-06\n",
      "Epoch 4145, Loss: 6.459326641561347e-06, Final Batch Loss: 2.075116981359315e-06\n",
      "Epoch 4146, Loss: 1.2953065834153676e-05, Final Batch Loss: 6.18859485257417e-06\n",
      "Epoch 4147, Loss: 1.9996659375465242e-05, Final Batch Loss: 6.83339794704807e-06\n",
      "Epoch 4148, Loss: 3.056030436709989e-05, Final Batch Loss: 5.047224476584233e-06\n",
      "Epoch 4149, Loss: 0.002171239745166531, Final Batch Loss: 3.589246716728667e-06\n",
      "Epoch 4150, Loss: 0.00012786080333171412, Final Batch Loss: 8.352657459909096e-05\n",
      "Epoch 4151, Loss: 0.0026792662124535127, Final Batch Loss: 4.039788564114133e-06\n",
      "Epoch 4152, Loss: 0.0006199597910381272, Final Batch Loss: 1.1886127140314784e-05\n",
      "Epoch 4153, Loss: 1.7398718227923382e-05, Final Batch Loss: 4.682606231654063e-06\n",
      "Epoch 4154, Loss: 1.0409182323201094e-05, Final Batch Loss: 4.854701273870887e-06\n",
      "Epoch 4155, Loss: 5.36391189598362e-06, Final Batch Loss: 4.223835276206955e-06\n",
      "Epoch 4156, Loss: 3.2885327527765185e-06, Final Batch Loss: 1.628798599995207e-06\n",
      "Epoch 4157, Loss: 9.686682096798904e-05, Final Batch Loss: 4.292732774047181e-05\n",
      "Epoch 4158, Loss: 5.090616397751546e-06, Final Batch Loss: 4.919909770251252e-06\n",
      "Epoch 4159, Loss: 0.0008445157782261958, Final Batch Loss: 1.2166832675575279e-05\n",
      "Epoch 4160, Loss: 1.584163373991032e-05, Final Batch Loss: 4.270866611477686e-06\n",
      "Epoch 4161, Loss: 6.8015669057786e-05, Final Batch Loss: 1.2973984667041805e-05\n",
      "Epoch 4162, Loss: 0.0004401652672640921, Final Batch Loss: 0.00044002317008562386\n",
      "Epoch 4163, Loss: 0.00030349319331435254, Final Batch Loss: 1.5144810276979115e-05\n",
      "Epoch 4164, Loss: 6.212162952579092e-05, Final Batch Loss: 3.237011333112605e-05\n",
      "Epoch 4165, Loss: 4.8850760805407845e-06, Final Batch Loss: 9.632090325339959e-08\n",
      "Epoch 4166, Loss: 0.0001370109430354205, Final Batch Loss: 6.127976121206302e-06\n",
      "Epoch 4167, Loss: 0.0003706187053467147, Final Batch Loss: 8.875125058693811e-05\n",
      "Epoch 4168, Loss: 0.001246328510418948, Final Batch Loss: 2.1552953910486394e-07\n",
      "Epoch 4169, Loss: 0.00020627648700610735, Final Batch Loss: 3.1175357435131446e-05\n",
      "Epoch 4170, Loss: 2.3502168005506974e-05, Final Batch Loss: 4.739621545013506e-06\n",
      "Epoch 4171, Loss: 0.0013134347952927783, Final Batch Loss: 0.0013106443220749497\n",
      "Epoch 4172, Loss: 0.00024665214186825324, Final Batch Loss: 0.00023552040511276573\n",
      "Epoch 4173, Loss: 1.0351290256949142e-05, Final Batch Loss: 2.899141691159457e-07\n",
      "Epoch 4174, Loss: 4.082253701653826e-05, Final Batch Loss: 3.892486711265519e-05\n",
      "Epoch 4175, Loss: 3.28412299950287e-05, Final Batch Loss: 3.0507244446198456e-05\n",
      "Epoch 4176, Loss: 9.971835243050009e-05, Final Batch Loss: 9.89525651675649e-05\n",
      "Epoch 4177, Loss: 1.8703865407587728e-06, Final Batch Loss: 7.820119662937941e-08\n",
      "Epoch 4178, Loss: 0.0003342276398825561, Final Batch Loss: 0.0003329569299239665\n",
      "Epoch 4179, Loss: 0.0003300300199953199, Final Batch Loss: 5.264479568722891e-06\n",
      "Epoch 4180, Loss: 5.173369163458119e-05, Final Batch Loss: 2.116990344802616e-06\n",
      "Epoch 4181, Loss: 0.0016415774070992484, Final Batch Loss: 0.0016380979213863611\n",
      "Epoch 4182, Loss: 0.00026508127120905556, Final Batch Loss: 5.7108296459773555e-05\n",
      "Epoch 4183, Loss: 0.00012711381896224339, Final Batch Loss: 9.890899673337117e-05\n",
      "Epoch 4184, Loss: 0.0007147907745093107, Final Batch Loss: 9.048072388395667e-05\n",
      "Epoch 4185, Loss: 6.6035443069267785e-06, Final Batch Loss: 3.321409622003557e-06\n",
      "Epoch 4186, Loss: 1.944955718613528e-05, Final Batch Loss: 3.4808934401553415e-07\n",
      "Epoch 4187, Loss: 2.532596909077256e-05, Final Batch Loss: 1.8277853087056428e-05\n",
      "Epoch 4188, Loss: 1.500624719596999e-05, Final Batch Loss: 2.6035129963020154e-07\n",
      "Epoch 4189, Loss: 9.653023198552546e-06, Final Batch Loss: 1.4733552688994678e-06\n",
      "Epoch 4190, Loss: 3.0956836553741596e-05, Final Batch Loss: 3.452275905146962e-07\n",
      "Epoch 4191, Loss: 0.0007647051966159779, Final Batch Loss: 4.33398190580192e-06\n",
      "Epoch 4192, Loss: 0.0014083385356116196, Final Batch Loss: 0.0014059990644454956\n",
      "Epoch 4193, Loss: 0.001077643275493756, Final Batch Loss: 5.103871808387339e-05\n",
      "Epoch 4194, Loss: 0.001208274547025212, Final Batch Loss: 0.001197740319184959\n",
      "Epoch 4195, Loss: 6.265344427447417e-05, Final Batch Loss: 5.855520430486649e-05\n",
      "Epoch 4196, Loss: 2.039526270891656e-05, Final Batch Loss: 7.028434083622415e-07\n",
      "Epoch 4197, Loss: 9.328349005954806e-05, Final Batch Loss: 2.2106311007519253e-05\n",
      "Epoch 4198, Loss: 1.341776936669703e-06, Final Batch Loss: 4.100760691017058e-07\n",
      "Epoch 4199, Loss: 0.0006567722302861512, Final Batch Loss: 0.00042649052920751274\n",
      "Epoch 4200, Loss: 8.012845938765167e-06, Final Batch Loss: 3.5953169685853936e-07\n",
      "Epoch 4201, Loss: 3.0418864980674698e-05, Final Batch Loss: 2.4527523692086106e-06\n",
      "Epoch 4202, Loss: 6.267940239013114e-05, Final Batch Loss: 1.306488911723136e-06\n",
      "Epoch 4203, Loss: 0.00012117886615214957, Final Batch Loss: 4.968572966390639e-07\n",
      "Epoch 4204, Loss: 1.7696293298286037e-05, Final Batch Loss: 1.743546818033792e-05\n",
      "Epoch 4205, Loss: 0.0005780641303516632, Final Batch Loss: 2.2888063710979623e-07\n",
      "Epoch 4206, Loss: 1.8657881923900277e-06, Final Batch Loss: 1.1357677749401773e-06\n",
      "Epoch 4207, Loss: 0.0021668687058991054, Final Batch Loss: 1.701205655990634e-05\n",
      "Epoch 4208, Loss: 2.1984004888508935e-05, Final Batch Loss: 4.251617610862013e-06\n",
      "Epoch 4209, Loss: 4.9229830523245255e-06, Final Batch Loss: 4.75752176498645e-06\n",
      "Epoch 4210, Loss: 0.005052951382310766, Final Batch Loss: 6.456243113461824e-07\n",
      "Epoch 4211, Loss: 0.0007983759878698038, Final Batch Loss: 7.552329407189973e-06\n",
      "Epoch 4212, Loss: 4.704229922936065e-05, Final Batch Loss: 9.050253538589459e-06\n",
      "Epoch 4213, Loss: 0.0009023537022585515, Final Batch Loss: 4.019155312562361e-06\n",
      "Epoch 4214, Loss: 2.7117805984744336e-05, Final Batch Loss: 1.831820009101648e-05\n",
      "Epoch 4215, Loss: 3.4837789485209214e-05, Final Batch Loss: 7.62912009122374e-07\n",
      "Epoch 4216, Loss: 0.0010309684003004804, Final Batch Loss: 5.498762766364962e-05\n",
      "Epoch 4217, Loss: 3.662836888906895e-06, Final Batch Loss: 9.736918400449213e-07\n",
      "Epoch 4218, Loss: 0.0001776765471959152, Final Batch Loss: 5.817324790768907e-07\n",
      "Epoch 4219, Loss: 0.00023111260816222057, Final Batch Loss: 0.00016528615378774703\n",
      "Epoch 4220, Loss: 4.015653416900022e-06, Final Batch Loss: 6.103449550209916e-07\n",
      "Epoch 4221, Loss: 0.00010342311725253239, Final Batch Loss: 4.226642340654507e-05\n",
      "Epoch 4222, Loss: 0.00013238046722108265, Final Batch Loss: 1.2351446457614657e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4223, Loss: 3.209853230146109e-05, Final Batch Loss: 1.2749746929330286e-06\n",
      "Epoch 4224, Loss: 7.256169510583277e-06, Final Batch Loss: 4.47220691057737e-06\n",
      "Epoch 4225, Loss: 2.426684022793779e-05, Final Batch Loss: 1.2457137927412987e-05\n",
      "Epoch 4226, Loss: 0.0010568211691861507, Final Batch Loss: 0.00103274779394269\n",
      "Epoch 4227, Loss: 0.0005812511695921785, Final Batch Loss: 3.156634420520277e-07\n",
      "Epoch 4228, Loss: 5.977716512006737e-06, Final Batch Loss: 9.517446528661822e-07\n",
      "Epoch 4229, Loss: 0.009559837868437171, Final Batch Loss: 0.007464026100933552\n",
      "Epoch 4230, Loss: 0.0007671002686038264, Final Batch Loss: 3.4062695704051293e-06\n",
      "Epoch 4231, Loss: 0.0008465950395475375, Final Batch Loss: 0.0008317375322803855\n",
      "Epoch 4232, Loss: 3.0111170133295673e-05, Final Batch Loss: 7.419418466270145e-07\n",
      "Epoch 4233, Loss: 0.00020378018234623596, Final Batch Loss: 8.524705481249839e-05\n",
      "Epoch 4234, Loss: 1.111713682178106e-05, Final Batch Loss: 1.0902084795816336e-05\n",
      "Epoch 4235, Loss: 9.055284317582846e-05, Final Batch Loss: 4.472866567084566e-05\n",
      "Epoch 4236, Loss: 0.0004582395044110399, Final Batch Loss: 3.347371659856435e-07\n",
      "Epoch 4237, Loss: 0.00013157346620573662, Final Batch Loss: 8.7607535533607e-05\n",
      "Epoch 4238, Loss: 4.4589711251319386e-05, Final Batch Loss: 1.6477926692459732e-05\n",
      "Epoch 4239, Loss: 3.565228962543188e-05, Final Batch Loss: 2.0632462110370398e-05\n",
      "Epoch 4240, Loss: 6.54333678085095e-06, Final Batch Loss: 1.4543028328262153e-06\n",
      "Epoch 4241, Loss: 9.520877370050584e-06, Final Batch Loss: 7.756242666800972e-06\n",
      "Epoch 4242, Loss: 7.3362070907023735e-06, Final Batch Loss: 5.346046236809343e-06\n",
      "Epoch 4243, Loss: 1.0657548273229622e-05, Final Batch Loss: 3.222191708118771e-06\n",
      "Epoch 4244, Loss: 3.5581693396125047e-06, Final Batch Loss: 5.645682108479377e-07\n",
      "Epoch 4245, Loss: 1.575064584358188e-05, Final Batch Loss: 1.3915836461819708e-05\n",
      "Epoch 4246, Loss: 1.1597112688832567e-05, Final Batch Loss: 5.845870418852428e-07\n",
      "Epoch 4247, Loss: 1.4957752512145817e-06, Final Batch Loss: 1.1910791499758488e-06\n",
      "Epoch 4248, Loss: 0.0001126690651744866, Final Batch Loss: 0.00010984302207361907\n",
      "Epoch 4249, Loss: 5.086093733552843e-05, Final Batch Loss: 4.255857857060619e-05\n",
      "Epoch 4250, Loss: 4.078739584656432e-05, Final Batch Loss: 2.2266363885137253e-05\n",
      "Epoch 4251, Loss: 1.431812961527612e-05, Final Batch Loss: 1.0515632311580703e-05\n",
      "Epoch 4252, Loss: 4.902668160866597e-05, Final Batch Loss: 4.27494705945719e-05\n",
      "Epoch 4253, Loss: 8.826448765830719e-05, Final Batch Loss: 7.07719163983711e-06\n",
      "Epoch 4254, Loss: 5.8240029829903506e-05, Final Batch Loss: 3.6221190384821966e-05\n",
      "Epoch 4255, Loss: 4.483978045755066e-06, Final Batch Loss: 1.109104687202489e-06\n",
      "Epoch 4256, Loss: 1.607881858944893e-05, Final Batch Loss: 4.239504960423801e-06\n",
      "Epoch 4257, Loss: 1.4529803365803673e-05, Final Batch Loss: 2.1628245576721383e-06\n",
      "Epoch 4258, Loss: 0.0012513995498011354, Final Batch Loss: 1.3608114386443049e-06\n",
      "Epoch 4259, Loss: 2.3297198822547216e-05, Final Batch Loss: 1.4204275430529378e-05\n",
      "Epoch 4260, Loss: 0.0014838424322078936, Final Batch Loss: 0.001386917196214199\n",
      "Epoch 4261, Loss: 2.3590298951603472e-05, Final Batch Loss: 2.4459423002554104e-06\n",
      "Epoch 4262, Loss: 4.901332928852753e-06, Final Batch Loss: 1.2874583887878543e-07\n",
      "Epoch 4263, Loss: 1.0959139672195306e-05, Final Batch Loss: 3.820943220489426e-06\n",
      "Epoch 4264, Loss: 0.0008494940891523584, Final Batch Loss: 0.0008465878781862557\n",
      "Epoch 4265, Loss: 0.00013530771002479014, Final Batch Loss: 3.4220579436805565e-06\n",
      "Epoch 4266, Loss: 2.0737830368489085e-05, Final Batch Loss: 3.252004034948186e-07\n",
      "Epoch 4267, Loss: 0.0006764989709608926, Final Batch Loss: 2.8827241749240784e-06\n",
      "Epoch 4268, Loss: 0.00027497126575326547, Final Batch Loss: 0.0001653522631386295\n",
      "Epoch 4269, Loss: 4.3097324123664293e-05, Final Batch Loss: 8.679327038407791e-06\n",
      "Epoch 4270, Loss: 0.00011673505468934309, Final Batch Loss: 9.513360419077799e-05\n",
      "Epoch 4271, Loss: 0.001156581931596179, Final Batch Loss: 0.0011564570013433695\n",
      "Epoch 4272, Loss: 4.2806638248293893e-05, Final Batch Loss: 8.687861736689229e-07\n",
      "Epoch 4273, Loss: 6.5906353938771645e-06, Final Batch Loss: 1.3885062344343169e-06\n",
      "Epoch 4274, Loss: 1.2213526474624814e-05, Final Batch Loss: 1.0518718909224845e-06\n",
      "Epoch 4275, Loss: 4.767917857861903e-06, Final Batch Loss: 6.313199492069543e-07\n",
      "Epoch 4276, Loss: 2.2099367015471216e-05, Final Batch Loss: 1.0688411748560611e-05\n",
      "Epoch 4277, Loss: 5.031539586752842e-06, Final Batch Loss: 4.766897291119676e-06\n",
      "Epoch 4278, Loss: 7.475609709217679e-05, Final Batch Loss: 1.559143311169464e-05\n",
      "Epoch 4279, Loss: 8.485547459713416e-05, Final Batch Loss: 7.322157216549385e-06\n",
      "Epoch 4280, Loss: 0.00011493748206703458, Final Batch Loss: 2.8338932679616846e-05\n",
      "Epoch 4281, Loss: 0.0006390413759049807, Final Batch Loss: 6.694603484902473e-07\n",
      "Epoch 4282, Loss: 1.2326421028774348e-05, Final Batch Loss: 1.4104291494732024e-06\n",
      "Epoch 4283, Loss: 3.140735043416498e-05, Final Batch Loss: 8.095498742477503e-06\n",
      "Epoch 4284, Loss: 1.393684598838263e-06, Final Batch Loss: 1.4591186925372313e-07\n",
      "Epoch 4285, Loss: 1.0036199000751367e-05, Final Batch Loss: 1.5887640074652154e-06\n",
      "Epoch 4286, Loss: 0.00020828024389629718, Final Batch Loss: 2.0157289327471517e-05\n",
      "Epoch 4287, Loss: 4.116716013413679e-05, Final Batch Loss: 4.6252466745499987e-07\n",
      "Epoch 4288, Loss: 2.2113425984571222e-05, Final Batch Loss: 1.2154006981290877e-05\n",
      "Epoch 4289, Loss: 1.068678409410495e-05, Final Batch Loss: 1.266454432879982e-06\n",
      "Epoch 4290, Loss: 1.0094267508975463e-05, Final Batch Loss: 7.571626156277489e-06\n",
      "Epoch 4291, Loss: 2.449523299219436e-05, Final Batch Loss: 4.842258476855932e-06\n",
      "Epoch 4292, Loss: 3.784295068953725e-05, Final Batch Loss: 7.31448665192147e-07\n",
      "Epoch 4293, Loss: 1.2712078387266956e-05, Final Batch Loss: 1.0159965313505381e-05\n",
      "Epoch 4294, Loss: 1.0355326821809285e-05, Final Batch Loss: 1.7451623079978162e-06\n",
      "Epoch 4295, Loss: 1.4466589064454638e-05, Final Batch Loss: 2.0789856591818534e-07\n",
      "Epoch 4296, Loss: 3.949412166548427e-05, Final Batch Loss: 2.3448013962479308e-05\n",
      "Epoch 4297, Loss: 0.00011839090211651637, Final Batch Loss: 4.078528490936151e-06\n",
      "Epoch 4298, Loss: 0.0001243479382537771, Final Batch Loss: 9.79438700596802e-05\n",
      "Epoch 4299, Loss: 4.396741701384599e-05, Final Batch Loss: 1.5067073491081828e-06\n",
      "Epoch 4300, Loss: 9.960736406355863e-06, Final Batch Loss: 8.660496860102285e-06\n",
      "Epoch 4301, Loss: 0.0007024190570028566, Final Batch Loss: 4.100797568185044e-08\n",
      "Epoch 4302, Loss: 0.007933104330732021, Final Batch Loss: 9.668424172559753e-05\n",
      "Epoch 4303, Loss: 2.945217170235992e-05, Final Batch Loss: 3.2305936201737495e-06\n",
      "Epoch 4304, Loss: 7.34167369955685e-05, Final Batch Loss: 5.693211278412491e-05\n",
      "Epoch 4305, Loss: 7.17728469226131e-05, Final Batch Loss: 8.096465080598136e-07\n",
      "Epoch 4306, Loss: 2.320098474228871e-05, Final Batch Loss: 3.980684141424717e-06\n",
      "Epoch 4307, Loss: 0.00014184586871124338, Final Batch Loss: 1.7732583728502505e-05\n",
      "Epoch 4308, Loss: 0.00030746215816179756, Final Batch Loss: 0.00027920660795643926\n",
      "Epoch 4309, Loss: 0.0001217125536641106, Final Batch Loss: 4.182986594969407e-05\n",
      "Epoch 4310, Loss: 1.7761317621989292e-05, Final Batch Loss: 1.457837424823083e-05\n",
      "Epoch 4311, Loss: 2.76854489200673e-06, Final Batch Loss: 5.817405579477963e-08\n",
      "Epoch 4312, Loss: 2.9480831869932445e-05, Final Batch Loss: 5.350079277377517e-07\n",
      "Epoch 4313, Loss: 4.926471092403517e-06, Final Batch Loss: 4.305175025365315e-06\n",
      "Epoch 4314, Loss: 9.666845789979561e-05, Final Batch Loss: 6.0259312704147305e-06\n",
      "Epoch 4315, Loss: 0.00010707765963502425, Final Batch Loss: 3.023122587819671e-07\n",
      "Epoch 4316, Loss: 3.6717231552074736e-05, Final Batch Loss: 4.4917672425981436e-07\n",
      "Epoch 4317, Loss: 3.0584003880562705e-05, Final Batch Loss: 1.4305068418707378e-07\n",
      "Epoch 4318, Loss: 0.0009324046222900506, Final Batch Loss: 7.42546035326086e-06\n",
      "Epoch 4319, Loss: 3.64892457582755e-05, Final Batch Loss: 3.510742317303084e-06\n",
      "Epoch 4320, Loss: 7.433388702793309e-05, Final Batch Loss: 7.27567239664495e-05\n",
      "Epoch 4321, Loss: 0.0001392644044244662, Final Batch Loss: 8.996630640467629e-05\n",
      "Epoch 4322, Loss: 0.0016642731770843966, Final Batch Loss: 2.3218726710183546e-06\n",
      "Epoch 4323, Loss: 1.1392619398975512e-05, Final Batch Loss: 2.175997451558942e-06\n",
      "Epoch 4324, Loss: 3.266244584665401e-05, Final Batch Loss: 2.2999320208327845e-05\n",
      "Epoch 4325, Loss: 4.2626582498428434e-05, Final Batch Loss: 1.2493102019561775e-07\n",
      "Epoch 4326, Loss: 1.6977553968899883e-05, Final Batch Loss: 1.2442240404197946e-05\n",
      "Epoch 4327, Loss: 4.077480070918682e-06, Final Batch Loss: 1.9653095932881115e-06\n",
      "Epoch 4328, Loss: 0.0030540952905013796, Final Batch Loss: 0.0030540218576788902\n",
      "Epoch 4329, Loss: 9.795325240702368e-06, Final Batch Loss: 7.456171715602977e-06\n",
      "Epoch 4330, Loss: 0.00023130943463911535, Final Batch Loss: 2.6414099920657463e-06\n",
      "Epoch 4331, Loss: 4.090497390762948e-05, Final Batch Loss: 9.059881023176786e-08\n",
      "Epoch 4332, Loss: 7.613242388515573e-06, Final Batch Loss: 4.1579599496799347e-07\n",
      "Epoch 4333, Loss: 5.263819002720993e-05, Final Batch Loss: 3.6639266909332946e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4334, Loss: 3.2275276176108036e-06, Final Batch Loss: 4.2915321074588064e-08\n",
      "Epoch 4335, Loss: 8.15544831311854e-06, Final Batch Loss: 6.668241894658422e-06\n",
      "Epoch 4336, Loss: 3.7768481433886336e-05, Final Batch Loss: 3.237276177969761e-05\n",
      "Epoch 4337, Loss: 0.00019355061931491946, Final Batch Loss: 0.0001887783728307113\n",
      "Epoch 4338, Loss: 2.6145169442770566e-06, Final Batch Loss: 1.831045040034951e-07\n",
      "Epoch 4339, Loss: 0.0004288392108264816, Final Batch Loss: 7.457590527337743e-07\n",
      "Epoch 4340, Loss: 2.0542231595754856e-05, Final Batch Loss: 1.776082717697136e-05\n",
      "Epoch 4341, Loss: 4.893106734016328e-06, Final Batch Loss: 2.365088676015148e-07\n",
      "Epoch 4342, Loss: 0.0004657021568164055, Final Batch Loss: 3.050554823857965e-06\n",
      "Epoch 4343, Loss: 5.887910629098769e-05, Final Batch Loss: 9.713507097330876e-06\n",
      "Epoch 4344, Loss: 3.280866241084368e-05, Final Batch Loss: 8.544610068383918e-07\n",
      "Epoch 4345, Loss: 1.7927351109392475e-05, Final Batch Loss: 1.4060152352612931e-05\n",
      "Epoch 4346, Loss: 6.866869171062717e-06, Final Batch Loss: 2.077894805552205e-06\n",
      "Epoch 4347, Loss: 3.140991191230569e-05, Final Batch Loss: 2.946829908978543e-07\n",
      "Epoch 4348, Loss: 1.620978036953602e-05, Final Batch Loss: 7.941079275042284e-06\n",
      "Epoch 4349, Loss: 5.720537728848285e-06, Final Batch Loss: 2.087523625959875e-06\n",
      "Epoch 4350, Loss: 0.0008762587126511789, Final Batch Loss: 0.000873805140145123\n",
      "Epoch 4351, Loss: 4.41682441305602e-05, Final Batch Loss: 2.9377835744526237e-05\n",
      "Epoch 4352, Loss: 1.2273236222881678e-05, Final Batch Loss: 7.161933694987965e-07\n",
      "Epoch 4353, Loss: 0.00020008869626053638, Final Batch Loss: 2.57488977695175e-07\n",
      "Epoch 4354, Loss: 4.491821371743754e-06, Final Batch Loss: 1.6117049028707697e-07\n",
      "Epoch 4355, Loss: 1.1810496687303385e-06, Final Batch Loss: 3.051735859571636e-07\n",
      "Epoch 4356, Loss: 5.0806956096494105e-05, Final Batch Loss: 1.397203504893696e-05\n",
      "Epoch 4357, Loss: 4.282887812223635e-05, Final Batch Loss: 3.8468111597467214e-05\n",
      "Epoch 4358, Loss: 1.7934489108029084e-05, Final Batch Loss: 7.276460678440344e-07\n",
      "Epoch 4359, Loss: 3.9162296161521226e-05, Final Batch Loss: 3.487541835056618e-05\n",
      "Epoch 4360, Loss: 3.4927401770801225e-06, Final Batch Loss: 4.625218821274757e-07\n",
      "Epoch 4361, Loss: 4.255434942024294e-05, Final Batch Loss: 1.0191668479819782e-05\n",
      "Epoch 4362, Loss: 0.0003117792568900768, Final Batch Loss: 2.6234104097966338e-06\n",
      "Epoch 4363, Loss: 0.0006170791673412168, Final Batch Loss: 2.2304227513814112e-06\n",
      "Epoch 4364, Loss: 0.000955237599555403, Final Batch Loss: 0.0003839475102722645\n",
      "Epoch 4365, Loss: 6.4133259911614005e-06, Final Batch Loss: 4.353673830337357e-06\n",
      "Epoch 4366, Loss: 3.459479137291055e-05, Final Batch Loss: 3.371841739863157e-05\n",
      "Epoch 4367, Loss: 5.7874522099155e-05, Final Batch Loss: 4.915231329505332e-05\n",
      "Epoch 4368, Loss: 0.0009683184001119116, Final Batch Loss: 1.4018979754837346e-07\n",
      "Epoch 4369, Loss: 1.2848890179384398e-05, Final Batch Loss: 1.2577571396832354e-05\n",
      "Epoch 4370, Loss: 9.12887378490268e-06, Final Batch Loss: 8.453684131382033e-06\n",
      "Epoch 4371, Loss: 0.00010694144657463767, Final Batch Loss: 6.417128315661103e-05\n",
      "Epoch 4372, Loss: 4.33440504821192e-06, Final Batch Loss: 1.440879486835911e-06\n",
      "Epoch 4373, Loss: 8.822210929793073e-06, Final Batch Loss: 2.685113031475339e-06\n",
      "Epoch 4374, Loss: 9.2785436891063e-05, Final Batch Loss: 3.129610149699147e-06\n",
      "Epoch 4375, Loss: 0.0001699673875918961, Final Batch Loss: 0.00016777386190369725\n",
      "Epoch 4376, Loss: 7.236484293571266e-06, Final Batch Loss: 5.653467269439716e-06\n",
      "Epoch 4377, Loss: 0.0027761634264606982, Final Batch Loss: 0.0023833001032471657\n",
      "Epoch 4378, Loss: 9.59052727012022e-06, Final Batch Loss: 7.721954716544133e-06\n",
      "Epoch 4379, Loss: 0.002045938788796775, Final Batch Loss: 0.0020380972418934107\n",
      "Epoch 4380, Loss: 2.009790051715754e-06, Final Batch Loss: 1.6488286291860277e-06\n",
      "Epoch 4381, Loss: 7.991553161446063e-07, Final Batch Loss: 3.414101286125515e-07\n",
      "Epoch 4382, Loss: 4.993355832993984e-05, Final Batch Loss: 4.7956218622857705e-05\n",
      "Epoch 4383, Loss: 5.635720481222961e-05, Final Batch Loss: 1.9844246708089486e-06\n",
      "Epoch 4384, Loss: 6.126081389190574e-05, Final Batch Loss: 1.5258775576398875e-08\n",
      "Epoch 4385, Loss: 7.394552157435896e-05, Final Batch Loss: 5.435940053644117e-08\n",
      "Epoch 4386, Loss: 0.00061841681599617, Final Batch Loss: 0.00041289691580459476\n",
      "Epoch 4387, Loss: 1.1572466753762e-06, Final Batch Loss: 1.1024105788237648e-06\n",
      "Epoch 4388, Loss: 2.687463188522088e-05, Final Batch Loss: 2.8922115689056227e-06\n",
      "Epoch 4389, Loss: 0.0023144229041633935, Final Batch Loss: 2.6512017825552903e-07\n",
      "Epoch 4390, Loss: 2.4983729360883444e-06, Final Batch Loss: 3.404589676847536e-07\n",
      "Epoch 4391, Loss: 3.9506133020950074e-05, Final Batch Loss: 3.8818550819996744e-05\n",
      "Epoch 4392, Loss: 8.73754163421836e-06, Final Batch Loss: 7.784376975905616e-06\n",
      "Epoch 4393, Loss: 0.0007559273044535075, Final Batch Loss: 0.0007554094772785902\n",
      "Epoch 4394, Loss: 0.0006618342913498054, Final Batch Loss: 1.3265732377476525e-05\n",
      "Epoch 4395, Loss: 4.75991987514135e-06, Final Batch Loss: 2.5509200440865243e-06\n",
      "Epoch 4396, Loss: 0.0002995085316968016, Final Batch Loss: 4.6062015712777793e-07\n",
      "Epoch 4397, Loss: 0.0002498312824172899, Final Batch Loss: 9.479526488576084e-05\n",
      "Epoch 4398, Loss: 2.4158766365189877e-06, Final Batch Loss: 1.5926293883694598e-07\n",
      "Epoch 4399, Loss: 3.277026848991227e-06, Final Batch Loss: 1.6582957869104575e-06\n",
      "Epoch 4400, Loss: 0.00087392506247852, Final Batch Loss: 0.00014476595970336348\n",
      "Epoch 4401, Loss: 7.015049902747705e-06, Final Batch Loss: 2.51766721248714e-07\n",
      "Epoch 4402, Loss: 0.0006251865838748927, Final Batch Loss: 0.0006187394028529525\n",
      "Epoch 4403, Loss: 1.1127871857752325e-05, Final Batch Loss: 9.088157639780547e-07\n",
      "Epoch 4404, Loss: 5.348430008211835e-06, Final Batch Loss: 2.1076037626244215e-07\n",
      "Epoch 4405, Loss: 0.00010299505447619595, Final Batch Loss: 8.651366806589067e-05\n",
      "Epoch 4406, Loss: 7.219546841952251e-05, Final Batch Loss: 6.095873686717823e-05\n",
      "Epoch 4407, Loss: 0.00022125503954661951, Final Batch Loss: 2.765653839276183e-08\n",
      "Epoch 4408, Loss: 6.9714947130705696e-06, Final Batch Loss: 1.0976327757816762e-06\n",
      "Epoch 4409, Loss: 0.002977180563902948, Final Batch Loss: 0.002965590450912714\n",
      "Epoch 4410, Loss: 8.223060503098623e-05, Final Batch Loss: 5.722030493870989e-08\n",
      "Epoch 4411, Loss: 0.0003136588396728257, Final Batch Loss: 1.2788417507181293e-06\n",
      "Epoch 4412, Loss: 2.2505052683641225e-05, Final Batch Loss: 1.974086529799024e-07\n",
      "Epoch 4413, Loss: 1.3193694030633196e-06, Final Batch Loss: 4.3677414396370295e-07\n",
      "Epoch 4414, Loss: 2.911294397023312e-05, Final Batch Loss: 1.0108889370030738e-07\n",
      "Epoch 4415, Loss: 3.6850885294370528e-06, Final Batch Loss: 9.297827432419581e-07\n",
      "Epoch 4416, Loss: 4.392795244712033e-05, Final Batch Loss: 3.6318648199085146e-05\n",
      "Epoch 4417, Loss: 0.00016317448898917064, Final Batch Loss: 0.00014771234418731183\n",
      "Epoch 4418, Loss: 0.00014252367753897488, Final Batch Loss: 0.00014194863615557551\n",
      "Epoch 4419, Loss: 7.003523637649778e-05, Final Batch Loss: 6.779625982744619e-05\n",
      "Epoch 4420, Loss: 6.646745305260993e-06, Final Batch Loss: 4.127779902773909e-06\n",
      "Epoch 4421, Loss: 3.254324838053435e-06, Final Batch Loss: 1.0909550383075839e-06\n",
      "Epoch 4422, Loss: 8.201849119870985e-06, Final Batch Loss: 6.389607420942411e-08\n",
      "Epoch 4423, Loss: 0.00012329894343565684, Final Batch Loss: 0.00011394740431569517\n",
      "Epoch 4424, Loss: 3.9167784507299075e-05, Final Batch Loss: 3.271326204412617e-05\n",
      "Epoch 4425, Loss: 2.8345772307147854e-06, Final Batch Loss: 1.6440006902485038e-06\n",
      "Epoch 4426, Loss: 0.014045575233694763, Final Batch Loss: 0.01404204498976469\n",
      "Epoch 4427, Loss: 5.0224466576764826e-06, Final Batch Loss: 2.8150745947641553e-06\n",
      "Epoch 4428, Loss: 0.00020453255046959384, Final Batch Loss: 0.000202177616301924\n",
      "Epoch 4429, Loss: 1.5000849657553772e-05, Final Batch Loss: 1.3238022802397609e-05\n",
      "Epoch 4430, Loss: 1.2860048173024552e-05, Final Batch Loss: 6.110430149419699e-06\n",
      "Epoch 4431, Loss: 0.00015598548270645551, Final Batch Loss: 0.00013038571341894567\n",
      "Epoch 4432, Loss: 9.026348197949119e-05, Final Batch Loss: 7.117709901649505e-05\n",
      "Epoch 4433, Loss: 0.08320045525852038, Final Batch Loss: 0.08318620920181274\n",
      "Epoch 4434, Loss: 5.601671773547423e-06, Final Batch Loss: 3.352545490997727e-06\n",
      "Epoch 4435, Loss: 7.311762419703882e-05, Final Batch Loss: 2.2104171875980683e-05\n",
      "Epoch 4436, Loss: 0.0001593853157828562, Final Batch Loss: 1.1934440408367664e-05\n",
      "Epoch 4437, Loss: 0.00028026983909512637, Final Batch Loss: 0.0002723459911067039\n",
      "Epoch 4438, Loss: 0.028157880256912904, Final Batch Loss: 0.02812795899808407\n",
      "Epoch 4439, Loss: 5.996461823087884e-06, Final Batch Loss: 1.3389089872362092e-06\n",
      "Epoch 4440, Loss: 2.1213336367509328e-06, Final Batch Loss: 7.476699011021992e-07\n",
      "Epoch 4441, Loss: 0.002694343736038718, Final Batch Loss: 0.0026846921537071466\n",
      "Epoch 4442, Loss: 0.0011803365009654954, Final Batch Loss: 0.0011744993971660733\n",
      "Epoch 4443, Loss: 0.0038224939208930664, Final Batch Loss: 0.0038211860228329897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4444, Loss: 0.028976867761230096, Final Batch Loss: 0.00039480518898926675\n",
      "Epoch 4445, Loss: 0.003388166767095413, Final Batch Loss: 0.0033880032133311033\n",
      "Epoch 4446, Loss: 3.2402533918229892e-06, Final Batch Loss: 2.9760874440398766e-06\n",
      "Epoch 4447, Loss: 0.0020202226005494595, Final Batch Loss: 0.0020060627721250057\n",
      "Epoch 4448, Loss: 5.4074339459475596e-06, Final Batch Loss: 2.77505614576512e-06\n",
      "Epoch 4449, Loss: 0.0003416757417653571, Final Batch Loss: 0.00033327695564366877\n",
      "Epoch 4450, Loss: 2.881211639760295e-05, Final Batch Loss: 9.41258895181818e-06\n",
      "Epoch 4451, Loss: 8.759356717291666e-06, Final Batch Loss: 5.121151502862631e-07\n",
      "Epoch 4452, Loss: 1.163305807949655e-05, Final Batch Loss: 1.7642047396293492e-06\n",
      "Epoch 4453, Loss: 6.352704440359958e-05, Final Batch Loss: 1.908744525280781e-05\n",
      "Epoch 4454, Loss: 2.7757045188536722e-05, Final Batch Loss: 4.978064112037828e-07\n",
      "Epoch 4455, Loss: 0.009920247888658196, Final Batch Loss: 0.009842241182923317\n",
      "Epoch 4456, Loss: 0.002026828587986529, Final Batch Loss: 0.0006244531832635403\n",
      "Epoch 4457, Loss: 3.7288044950400945e-05, Final Batch Loss: 1.5040393009257969e-05\n",
      "Epoch 4458, Loss: 0.017322766338565998, Final Batch Loss: 4.012812951259548e-06\n",
      "Epoch 4459, Loss: 0.0008074333309195936, Final Batch Loss: 0.00037820273428224027\n",
      "Epoch 4460, Loss: 3.328256389067974e-05, Final Batch Loss: 1.770525886968244e-05\n",
      "Epoch 4461, Loss: 9.629749183659442e-05, Final Batch Loss: 4.277774860383943e-05\n",
      "Epoch 4462, Loss: 0.00013656281953444704, Final Batch Loss: 7.19901654520072e-05\n",
      "Epoch 4463, Loss: 8.198984539831145e-05, Final Batch Loss: 1.575372493789473e-06\n",
      "Epoch 4464, Loss: 0.0020528350569293252, Final Batch Loss: 1.1447452379798051e-05\n",
      "Epoch 4465, Loss: 0.00043304233145136095, Final Batch Loss: 2.6355326099292142e-06\n",
      "Epoch 4466, Loss: 0.00011843200081784744, Final Batch Loss: 8.463635822408833e-06\n",
      "Epoch 4467, Loss: 0.00011834468705274048, Final Batch Loss: 6.990298970777076e-07\n",
      "Epoch 4468, Loss: 4.507526099928327e-06, Final Batch Loss: 2.2601976468195062e-07\n",
      "Epoch 4469, Loss: 2.9206064482423244e-05, Final Batch Loss: 2.427900835755281e-05\n",
      "Epoch 4470, Loss: 2.455067971141034e-06, Final Batch Loss: 2.8991601652705867e-07\n",
      "Epoch 4471, Loss: 0.025545553883603134, Final Batch Loss: 0.025541014969348907\n",
      "Epoch 4472, Loss: 0.006551470054546371, Final Batch Loss: 0.0001482664665672928\n",
      "Epoch 4473, Loss: 4.3688007281161845e-05, Final Batch Loss: 1.6902842617128044e-05\n",
      "Epoch 4474, Loss: 7.564657062175684e-05, Final Batch Loss: 9.663544915383682e-06\n",
      "Epoch 4475, Loss: 0.0006037172552169068, Final Batch Loss: 0.0005776275065727532\n",
      "Epoch 4476, Loss: 0.0027736428619391518, Final Batch Loss: 0.0027446893509477377\n",
      "Epoch 4477, Loss: 0.000507510030274716, Final Batch Loss: 3.939199359592749e-06\n",
      "Epoch 4478, Loss: 0.0004005257796961814, Final Batch Loss: 0.0002687767846509814\n",
      "Epoch 4479, Loss: 0.021170379540308204, Final Batch Loss: 1.0795837624755222e-05\n",
      "Epoch 4480, Loss: 4.0527988858229946e-05, Final Batch Loss: 8.747282663534861e-06\n",
      "Epoch 4481, Loss: 0.00020870209846179932, Final Batch Loss: 8.697077282704413e-05\n",
      "Epoch 4482, Loss: 1.7181189832626842e-05, Final Batch Loss: 2.080819285765756e-06\n",
      "Epoch 4483, Loss: 0.00034331990900682285, Final Batch Loss: 0.0002238821325590834\n",
      "Epoch 4484, Loss: 2.1853767975699157e-05, Final Batch Loss: 1.3035761185165029e-05\n",
      "Epoch 4485, Loss: 1.585660766068031e-05, Final Batch Loss: 1.3837520782544743e-06\n",
      "Epoch 4486, Loss: 5.985441566735972e-05, Final Batch Loss: 2.1926216504652984e-05\n",
      "Epoch 4487, Loss: 8.185194928955752e-05, Final Batch Loss: 2.0280409444239922e-05\n",
      "Epoch 4488, Loss: 0.0003125884932160261, Final Batch Loss: 9.095175300899427e-06\n",
      "Epoch 4489, Loss: 0.00010968192509608343, Final Batch Loss: 9.933549881679937e-05\n",
      "Epoch 4490, Loss: 0.0015322258941523614, Final Batch Loss: 0.0015186590608209372\n",
      "Epoch 4491, Loss: 0.0005059190953033976, Final Batch Loss: 6.0234997363295406e-05\n",
      "Epoch 4492, Loss: 1.3278587630338734e-05, Final Batch Loss: 8.34448201203486e-07\n",
      "Epoch 4493, Loss: 0.00010027915050159208, Final Batch Loss: 4.751473170472309e-05\n",
      "Epoch 4494, Loss: 9.778964158613235e-05, Final Batch Loss: 7.494039891753346e-05\n",
      "Epoch 4495, Loss: 9.960178158507915e-05, Final Batch Loss: 9.741173016664106e-06\n",
      "Epoch 4496, Loss: 0.00021050785289844498, Final Batch Loss: 3.2215008104685694e-05\n",
      "Epoch 4497, Loss: 8.8749347924022e-05, Final Batch Loss: 4.086738408659585e-05\n",
      "Epoch 4498, Loss: 0.0001379083150823135, Final Batch Loss: 0.00011819788778666407\n",
      "Epoch 4499, Loss: 3.559984361345414e-05, Final Batch Loss: 2.4984601623145863e-05\n",
      "Epoch 4500, Loss: 6.738703223163611e-05, Final Batch Loss: 2.722526460274821e-06\n",
      "Epoch 4501, Loss: 0.003681383946968708, Final Batch Loss: 0.003585608908906579\n",
      "Epoch 4502, Loss: 5.597063409368275e-05, Final Batch Loss: 5.037487062509172e-05\n",
      "Epoch 4503, Loss: 7.684923878059635e-05, Final Batch Loss: 1.8432980368743301e-06\n",
      "Epoch 4504, Loss: 1.712706557555066e-05, Final Batch Loss: 2.180970795961912e-06\n",
      "Epoch 4505, Loss: 2.6989167054125573e-05, Final Batch Loss: 8.253736268670764e-06\n",
      "Epoch 4506, Loss: 5.378559376367775e-05, Final Batch Loss: 5.145594332134351e-05\n",
      "Epoch 4507, Loss: 0.004469676485314267, Final Batch Loss: 0.004440633114427328\n",
      "Epoch 4508, Loss: 2.5435740099055693e-05, Final Batch Loss: 1.243278256879421e-05\n",
      "Epoch 4509, Loss: 0.002369929032283835, Final Batch Loss: 3.177106555085629e-05\n",
      "Epoch 4510, Loss: 5.216517240569374e-05, Final Batch Loss: 1.9005652802661643e-06\n",
      "Epoch 4511, Loss: 3.880475014739204e-05, Final Batch Loss: 1.9622331819846295e-05\n",
      "Epoch 4512, Loss: 0.00010105237379320897, Final Batch Loss: 6.812582432758063e-05\n",
      "Epoch 4513, Loss: 0.0008489879737680894, Final Batch Loss: 3.5484745239955373e-06\n",
      "Epoch 4514, Loss: 0.0004015183640149189, Final Batch Loss: 0.0003766002773772925\n",
      "Epoch 4515, Loss: 0.009608369204215705, Final Batch Loss: 0.0005289408145472407\n",
      "Epoch 4516, Loss: 4.999918928660918e-05, Final Batch Loss: 3.264511178713292e-05\n",
      "Epoch 4517, Loss: 0.00021251188536552945, Final Batch Loss: 4.78233505418757e-06\n",
      "Epoch 4518, Loss: 8.173976129910443e-05, Final Batch Loss: 3.874412868754007e-06\n",
      "Epoch 4519, Loss: 2.0344554741313914e-05, Final Batch Loss: 4.416792307893047e-06\n",
      "Epoch 4520, Loss: 6.211061918293126e-05, Final Batch Loss: 2.9317317967070267e-05\n",
      "Epoch 4521, Loss: 0.00010687943495213403, Final Batch Loss: 4.9148561629408505e-06\n",
      "Epoch 4522, Loss: 0.0004003203193860827, Final Batch Loss: 1.9480428818496875e-05\n",
      "Epoch 4523, Loss: 0.0173724008454883, Final Batch Loss: 0.017357874661684036\n",
      "Epoch 4524, Loss: 1.3604057599536645e-05, Final Batch Loss: 2.002712022886044e-07\n",
      "Epoch 4525, Loss: 0.00027884199835170875, Final Batch Loss: 0.0002757032634690404\n",
      "Epoch 4526, Loss: 0.00031015966669656336, Final Batch Loss: 0.0003047606151085347\n",
      "Epoch 4527, Loss: 0.00026456459454493597, Final Batch Loss: 0.00017497705994173884\n",
      "Epoch 4528, Loss: 0.00012375496135064168, Final Batch Loss: 4.043179615109693e-06\n",
      "Epoch 4529, Loss: 8.364264249394182e-05, Final Batch Loss: 6.197588663781062e-05\n",
      "Epoch 4530, Loss: 4.9543640557203616e-05, Final Batch Loss: 1.1386626965759206e-06\n",
      "Epoch 4531, Loss: 0.0020216781485942192, Final Batch Loss: 0.0019693016074597836\n",
      "Epoch 4532, Loss: 0.00021211936109466478, Final Batch Loss: 2.695795410545543e-05\n",
      "Epoch 4533, Loss: 0.0005243561936367769, Final Batch Loss: 5.3042418585391715e-05\n",
      "Epoch 4534, Loss: 0.00048020060057751834, Final Batch Loss: 0.0003515370190143585\n",
      "Epoch 4535, Loss: 1.2691722076851875e-05, Final Batch Loss: 5.678267825715011e-06\n",
      "Epoch 4536, Loss: 3.1938091524352785e-05, Final Batch Loss: 1.8329934391658753e-05\n",
      "Epoch 4537, Loss: 4.4083543798478786e-05, Final Batch Loss: 2.9277698558871634e-05\n",
      "Epoch 4538, Loss: 0.004012743675048114, Final Batch Loss: 0.003991888836026192\n",
      "Epoch 4539, Loss: 2.4814489279378904e-05, Final Batch Loss: 1.0785820450109895e-06\n",
      "Epoch 4540, Loss: 2.312570904905442e-05, Final Batch Loss: 1.2325047464400996e-05\n",
      "Epoch 4541, Loss: 0.00010292699880665168, Final Batch Loss: 9.742245310917497e-05\n",
      "Epoch 4542, Loss: 0.0002802386234179721, Final Batch Loss: 1.2251833140908275e-05\n",
      "Epoch 4543, Loss: 0.0008657019861857407, Final Batch Loss: 1.928017445607111e-05\n",
      "Epoch 4544, Loss: 8.799960050964728e-05, Final Batch Loss: 3.48339272022713e-05\n",
      "Epoch 4545, Loss: 0.00010841868015631917, Final Batch Loss: 5.582245194091229e-06\n",
      "Epoch 4546, Loss: 4.426684654390556e-06, Final Batch Loss: 1.241626478076796e-06\n",
      "Epoch 4547, Loss: 0.00014493540038529318, Final Batch Loss: 0.00012962057371623814\n",
      "Epoch 4548, Loss: 0.00012118408631067723, Final Batch Loss: 1.0948679118882865e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4549, Loss: 8.727684871701058e-06, Final Batch Loss: 5.415552095655585e-06\n",
      "Epoch 4550, Loss: 0.0001517417113063857, Final Batch Loss: 3.95432289224118e-06\n",
      "Epoch 4551, Loss: 9.381125892105047e-05, Final Batch Loss: 1.2478159987949766e-05\n",
      "Epoch 4552, Loss: 0.0005315701055224054, Final Batch Loss: 0.0004098304780200124\n",
      "Epoch 4553, Loss: 5.675585543940542e-05, Final Batch Loss: 4.185043144389056e-05\n",
      "Epoch 4554, Loss: 0.0001842627207224723, Final Batch Loss: 0.00016056210733950138\n",
      "Epoch 4555, Loss: 0.00040876849300275353, Final Batch Loss: 9.641363476475817e-07\n",
      "Epoch 4556, Loss: 8.555945532862097e-05, Final Batch Loss: 7.917135371826589e-05\n",
      "Epoch 4557, Loss: 2.4763825422269292e-05, Final Batch Loss: 5.176891136216e-06\n",
      "Epoch 4558, Loss: 9.505240768703516e-06, Final Batch Loss: 3.737019824257004e-06\n",
      "Epoch 4559, Loss: 0.002095213641950977, Final Batch Loss: 2.446097096253652e-05\n",
      "Epoch 4560, Loss: 0.0030987225964054232, Final Batch Loss: 1.726025038806256e-05\n",
      "Epoch 4561, Loss: 0.000100126850156812, Final Batch Loss: 5.887205043109134e-05\n",
      "Epoch 4562, Loss: 5.793083300886792e-05, Final Batch Loss: 5.5565462389495224e-05\n",
      "Epoch 4563, Loss: 0.00014864408421999542, Final Batch Loss: 0.00013593262701760978\n",
      "Epoch 4564, Loss: 0.0003627145579230273, Final Batch Loss: 5.01535578223411e-06\n",
      "Epoch 4565, Loss: 0.0020122561218158808, Final Batch Loss: 0.001974807819351554\n",
      "Epoch 4566, Loss: 9.11394199647475e-05, Final Batch Loss: 7.760962034808472e-05\n",
      "Epoch 4567, Loss: 8.414318472205196e-05, Final Batch Loss: 4.340758096077479e-06\n",
      "Epoch 4568, Loss: 0.00044037645966454875, Final Batch Loss: 0.00042215822031721473\n",
      "Epoch 4569, Loss: 0.00026539213286014274, Final Batch Loss: 0.00010723550076363608\n",
      "Epoch 4570, Loss: 2.529548783058999e-05, Final Batch Loss: 9.696726010588463e-06\n",
      "Epoch 4571, Loss: 0.0011754812985600438, Final Batch Loss: 0.001164305955171585\n",
      "Epoch 4572, Loss: 0.000203613610665343, Final Batch Loss: 3.824574832833605e-06\n",
      "Epoch 4573, Loss: 4.6763608224864583e-05, Final Batch Loss: 8.647354661661666e-06\n",
      "Epoch 4574, Loss: 0.00011071212429669686, Final Batch Loss: 4.93874576932285e-05\n",
      "Epoch 4575, Loss: 2.0287931079110422e-05, Final Batch Loss: 1.643120526750863e-06\n",
      "Epoch 4576, Loss: 0.0021509647194761783, Final Batch Loss: 0.0002511079946998507\n",
      "Epoch 4577, Loss: 0.002447934079782499, Final Batch Loss: 2.156201617253828e-06\n",
      "Epoch 4578, Loss: 1.3203870366851334e-05, Final Batch Loss: 5.30566740053473e-06\n",
      "Epoch 4579, Loss: 2.6235125005769078e-05, Final Batch Loss: 1.14215199573664e-05\n",
      "Epoch 4580, Loss: 0.0001207732166221831, Final Batch Loss: 2.2184580302564427e-05\n",
      "Epoch 4581, Loss: 0.00032289770945226337, Final Batch Loss: 0.00032129179453477263\n",
      "Epoch 4582, Loss: 5.749473302785191e-06, Final Batch Loss: 5.836375294165919e-07\n",
      "Epoch 4583, Loss: 2.3903930696178577e-05, Final Batch Loss: 2.0322122509242035e-05\n",
      "Epoch 4584, Loss: 1.999724736378994e-05, Final Batch Loss: 1.0749281500466168e-05\n",
      "Epoch 4585, Loss: 0.00010025899246102199, Final Batch Loss: 8.51219447213225e-05\n",
      "Epoch 4586, Loss: 0.00015560229257971514, Final Batch Loss: 1.6208099623327143e-05\n",
      "Epoch 4587, Loss: 8.074419747572392e-05, Final Batch Loss: 5.904379577259533e-05\n",
      "Epoch 4588, Loss: 1.725070842439891e-05, Final Batch Loss: 6.508006208605366e-06\n",
      "Epoch 4589, Loss: 0.00028885542997159064, Final Batch Loss: 0.0001364661002298817\n",
      "Epoch 4590, Loss: 0.00013138238182364148, Final Batch Loss: 5.241927738097729e-06\n",
      "Epoch 4591, Loss: 0.0012390857991704252, Final Batch Loss: 5.2219602366676554e-05\n",
      "Epoch 4592, Loss: 3.5870863030140754e-05, Final Batch Loss: 2.3371121642412618e-05\n",
      "Epoch 4593, Loss: 2.6377820631751092e-05, Final Batch Loss: 4.97757400808041e-06\n",
      "Epoch 4594, Loss: 2.464728277118411e-05, Final Batch Loss: 1.0603884220472537e-05\n",
      "Epoch 4595, Loss: 0.009447777298191795, Final Batch Loss: 0.00941504817456007\n",
      "Epoch 4596, Loss: 1.9571124539652374e-05, Final Batch Loss: 1.5398129107779823e-05\n",
      "Epoch 4597, Loss: 1.2356197657936718e-05, Final Batch Loss: 2.2496133169624954e-06\n",
      "Epoch 4598, Loss: 0.0004555110936053097, Final Batch Loss: 0.0003317074733786285\n",
      "Epoch 4599, Loss: 0.0003079054573618123, Final Batch Loss: 9.14557517717185e-07\n",
      "Epoch 4600, Loss: 0.0003105742121078947, Final Batch Loss: 5.958155725238612e-06\n",
      "Epoch 4601, Loss: 0.0001528677312307991, Final Batch Loss: 0.00014810041466262192\n",
      "Epoch 4602, Loss: 0.0005738659574490157, Final Batch Loss: 0.0005622016033157706\n",
      "Epoch 4603, Loss: 3.746217862499179e-05, Final Batch Loss: 5.820443220727611e-06\n",
      "Epoch 4604, Loss: 6.331822442007251e-05, Final Batch Loss: 3.157156243105419e-05\n",
      "Epoch 4605, Loss: 6.586734161828645e-05, Final Batch Loss: 1.0693467629607767e-05\n",
      "Epoch 4606, Loss: 0.0005661658506141976, Final Batch Loss: 0.00043842956074513495\n",
      "Epoch 4607, Loss: 5.702543012375827e-05, Final Batch Loss: 5.0523885875009e-05\n",
      "Epoch 4608, Loss: 0.0003771874798985664, Final Batch Loss: 0.00034264582791365683\n",
      "Epoch 4609, Loss: 1.2624099781533005e-05, Final Batch Loss: 8.121165592456236e-06\n",
      "Epoch 4610, Loss: 0.0002083293438772671, Final Batch Loss: 7.839174213586375e-05\n",
      "Epoch 4611, Loss: 0.00012134632197557949, Final Batch Loss: 9.793998469831422e-05\n",
      "Epoch 4612, Loss: 0.00011495146827655844, Final Batch Loss: 5.8039655414177105e-05\n",
      "Epoch 4613, Loss: 0.00013420838695310522, Final Batch Loss: 9.380690244142897e-06\n",
      "Epoch 4614, Loss: 0.0009928772706189193, Final Batch Loss: 0.0009744884446263313\n",
      "Epoch 4615, Loss: 1.7468846635892987e-05, Final Batch Loss: 4.674608135246672e-06\n",
      "Epoch 4616, Loss: 5.3472960587441776e-05, Final Batch Loss: 7.038015041871404e-07\n",
      "Epoch 4617, Loss: 4.9066355131799355e-05, Final Batch Loss: 3.559987817425281e-05\n",
      "Epoch 4618, Loss: 6.12111487043876e-05, Final Batch Loss: 2.233414988950244e-06\n",
      "Epoch 4619, Loss: 0.00016325959222740494, Final Batch Loss: 0.000111644811113365\n",
      "Epoch 4620, Loss: 1.746060138430039e-05, Final Batch Loss: 2.240056574009941e-06\n",
      "Epoch 4621, Loss: 5.788367161585484e-05, Final Batch Loss: 6.348205715767108e-06\n",
      "Epoch 4622, Loss: 4.879815696767764e-05, Final Batch Loss: 1.0028711585619021e-05\n",
      "Epoch 4623, Loss: 4.467055441637058e-05, Final Batch Loss: 2.948317887785379e-05\n",
      "Epoch 4624, Loss: 0.0004499842252698727, Final Batch Loss: 0.00037733447970822453\n",
      "Epoch 4625, Loss: 0.0001107618054447812, Final Batch Loss: 2.105659405060578e-06\n",
      "Epoch 4626, Loss: 3.6076433389098383e-05, Final Batch Loss: 7.86431337473914e-06\n",
      "Epoch 4627, Loss: 0.000557892180950148, Final Batch Loss: 4.923302185488865e-06\n",
      "Epoch 4628, Loss: 1.839387232394074e-05, Final Batch Loss: 1.084456562239211e-05\n",
      "Epoch 4629, Loss: 0.00021264239694573916, Final Batch Loss: 0.00017954548820853233\n",
      "Epoch 4630, Loss: 0.0001904242435557535, Final Batch Loss: 2.171150663343724e-05\n",
      "Epoch 4631, Loss: 7.949494738568319e-05, Final Batch Loss: 7.302334415726364e-05\n",
      "Epoch 4632, Loss: 3.0407481062866282e-05, Final Batch Loss: 1.2518758921942208e-05\n",
      "Epoch 4633, Loss: 2.851764224942599e-05, Final Batch Loss: 3.735141262950492e-06\n",
      "Epoch 4634, Loss: 0.0003989146644016728, Final Batch Loss: 0.00026051068562082946\n",
      "Epoch 4635, Loss: 6.91822096996475e-05, Final Batch Loss: 5.2805909945163876e-05\n",
      "Epoch 4636, Loss: 1.9542119389370782e-05, Final Batch Loss: 7.346151051024208e-06\n",
      "Epoch 4637, Loss: 9.189973388856743e-05, Final Batch Loss: 7.648175596841611e-06\n",
      "Epoch 4638, Loss: 1.0101455700350925e-05, Final Batch Loss: 5.39662050869083e-06\n",
      "Epoch 4639, Loss: 5.35548508651118e-05, Final Batch Loss: 1.5753987554489868e-06\n",
      "Epoch 4640, Loss: 0.0001256377427125699, Final Batch Loss: 6.551504156959709e-06\n",
      "Epoch 4641, Loss: 5.411698657553643e-05, Final Batch Loss: 9.486946510151029e-06\n",
      "Epoch 4642, Loss: 0.0007912319269962609, Final Batch Loss: 0.00014332548016682267\n",
      "Epoch 4643, Loss: 1.3989227682031924e-05, Final Batch Loss: 6.04713795837597e-06\n",
      "Epoch 4644, Loss: 0.00021000354939815224, Final Batch Loss: 0.00020919248345308006\n",
      "Epoch 4645, Loss: 0.0001974976130441064, Final Batch Loss: 0.00019082377548329532\n",
      "Epoch 4646, Loss: 0.0019172967467966373, Final Batch Loss: 0.0019081317586824298\n",
      "Epoch 4647, Loss: 0.00019676574083860032, Final Batch Loss: 5.2599087212001905e-05\n",
      "Epoch 4648, Loss: 2.2304896447167266e-05, Final Batch Loss: 1.6803913240437396e-05\n",
      "Epoch 4649, Loss: 8.211518036205234e-06, Final Batch Loss: 3.299688273727952e-07\n",
      "Epoch 4650, Loss: 5.3325821340877155e-06, Final Batch Loss: 9.126461577579903e-07\n",
      "Epoch 4651, Loss: 5.2767291890631896e-05, Final Batch Loss: 8.418343895755243e-06\n",
      "Epoch 4652, Loss: 0.007585485804384007, Final Batch Loss: 0.007584735751152039\n",
      "Epoch 4653, Loss: 6.368814865709282e-05, Final Batch Loss: 5.892515036975965e-05\n",
      "Epoch 4654, Loss: 0.004020833942831814, Final Batch Loss: 0.004014812875539064\n",
      "Epoch 4655, Loss: 8.407073983107693e-05, Final Batch Loss: 2.7638197934720665e-05\n",
      "Epoch 4656, Loss: 2.8631387976929545e-05, Final Batch Loss: 1.609042374184355e-05\n",
      "Epoch 4657, Loss: 4.6764659941800346e-05, Final Batch Loss: 5.636169362333021e-07\n",
      "Epoch 4658, Loss: 7.422839917126112e-05, Final Batch Loss: 8.40997017803602e-06\n",
      "Epoch 4659, Loss: 0.0017575434594618855, Final Batch Loss: 0.0017482824623584747\n",
      "Epoch 4660, Loss: 0.00011114181961602299, Final Batch Loss: 1.517253531346796e-05\n",
      "Epoch 4661, Loss: 0.000626239059783984, Final Batch Loss: 2.470799518050626e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4662, Loss: 2.4056111669779057e-05, Final Batch Loss: 2.0205125110805966e-05\n",
      "Epoch 4663, Loss: 1.930387844595316e-05, Final Batch Loss: 5.130739850756072e-07\n",
      "Epoch 4664, Loss: 0.00014851232572254958, Final Batch Loss: 0.0001440323976567015\n",
      "Epoch 4665, Loss: 0.0005525199462681485, Final Batch Loss: 3.989809101767605e-06\n",
      "Epoch 4666, Loss: 9.544590091081773e-05, Final Batch Loss: 6.151147999844397e-07\n",
      "Epoch 4667, Loss: 4.945646105625201e-05, Final Batch Loss: 3.379262489033863e-05\n",
      "Epoch 4668, Loss: 1.8439534301251115e-05, Final Batch Loss: 9.765357162905275e-07\n",
      "Epoch 4669, Loss: 3.00894103020255e-05, Final Batch Loss: 2.535323437768966e-05\n",
      "Epoch 4670, Loss: 0.0010394406963314395, Final Batch Loss: 9.654158930061385e-06\n",
      "Epoch 4671, Loss: 5.289461000757001e-06, Final Batch Loss: 1.0232741942672874e-06\n",
      "Epoch 4672, Loss: 5.382467861636542e-05, Final Batch Loss: 2.0528867025859654e-05\n",
      "Epoch 4673, Loss: 0.00021724498128605774, Final Batch Loss: 1.222217451868346e-05\n",
      "Epoch 4674, Loss: 1.5576388705085265e-05, Final Batch Loss: 4.5847978071833495e-06\n",
      "Epoch 4675, Loss: 3.3985424124693964e-05, Final Batch Loss: 1.2276624147489201e-05\n",
      "Epoch 4676, Loss: 0.0017684819940768648, Final Batch Loss: 2.4687808036105707e-05\n",
      "Epoch 4677, Loss: 5.459778549266048e-06, Final Batch Loss: 4.169960902800085e-06\n",
      "Epoch 4678, Loss: 7.748351390546304e-05, Final Batch Loss: 7.276387623278424e-05\n",
      "Epoch 4679, Loss: 4.913701332043274e-05, Final Batch Loss: 4.266253745299764e-05\n",
      "Epoch 4680, Loss: 1.3637986626235943e-05, Final Batch Loss: 1.4542810049533728e-06\n",
      "Epoch 4681, Loss: 0.00011595632668104372, Final Batch Loss: 7.580057626910275e-06\n",
      "Epoch 4682, Loss: 2.0011834294564323e-05, Final Batch Loss: 6.8992953856650274e-06\n",
      "Epoch 4683, Loss: 0.010109278882737271, Final Batch Loss: 0.00022626719146501273\n",
      "Epoch 4684, Loss: 0.0011127120233993537, Final Batch Loss: 1.0681114304134098e-07\n",
      "Epoch 4685, Loss: 0.0004699244398125302, Final Batch Loss: 3.2490295325260377e-06\n",
      "Epoch 4686, Loss: 0.00013933315163683346, Final Batch Loss: 1.9454851951650198e-07\n",
      "Epoch 4687, Loss: 0.000538315727681038, Final Batch Loss: 2.7541000235942192e-05\n",
      "Epoch 4688, Loss: 0.00018258230556966737, Final Batch Loss: 0.00011950056068599224\n",
      "Epoch 4689, Loss: 0.001679095599683933, Final Batch Loss: 2.6138193788938224e-05\n",
      "Epoch 4690, Loss: 0.00018374092451267643, Final Batch Loss: 1.1194165381311905e-05\n",
      "Epoch 4691, Loss: 1.0346004728489788e-05, Final Batch Loss: 3.3991464079008438e-06\n",
      "Epoch 4692, Loss: 0.0007065810605126899, Final Batch Loss: 0.0006930905510671437\n",
      "Epoch 4693, Loss: 7.86944542596757e-06, Final Batch Loss: 4.507027824729448e-06\n",
      "Epoch 4694, Loss: 0.000545578548553749, Final Batch Loss: 8.995708412840031e-06\n",
      "Epoch 4695, Loss: 0.0009400150593705803, Final Batch Loss: 8.048810400396178e-07\n",
      "Epoch 4696, Loss: 2.5322360670543276e-05, Final Batch Loss: 7.223416105262004e-06\n",
      "Epoch 4697, Loss: 2.7921682658416103e-05, Final Batch Loss: 2.5512823413009755e-05\n",
      "Epoch 4698, Loss: 7.5173879849899095e-06, Final Batch Loss: 6.1961532082932536e-06\n",
      "Epoch 4699, Loss: 0.00011677154179778881, Final Batch Loss: 6.415974348783493e-05\n",
      "Epoch 4700, Loss: 8.971655688583269e-05, Final Batch Loss: 8.553299267077819e-05\n",
      "Epoch 4701, Loss: 2.4945572931756033e-05, Final Batch Loss: 2.2405851268558763e-05\n",
      "Epoch 4702, Loss: 6.839326147201064e-06, Final Batch Loss: 2.565371914897696e-07\n",
      "Epoch 4703, Loss: 4.435513801581692e-05, Final Batch Loss: 1.678924854786601e-05\n",
      "Epoch 4704, Loss: 4.016862760636286e-06, Final Batch Loss: 1.9836335241052439e-07\n",
      "Epoch 4705, Loss: 5.001311592423008e-06, Final Batch Loss: 1.1253007414779859e-06\n",
      "Epoch 4706, Loss: 0.00011081942466262262, Final Batch Loss: 3.953608029405586e-06\n",
      "Epoch 4707, Loss: 0.004829620493183029, Final Batch Loss: 0.004804861731827259\n",
      "Epoch 4708, Loss: 3.346520315972157e-05, Final Batch Loss: 9.788971510715783e-06\n",
      "Epoch 4709, Loss: 0.006380453472957015, Final Batch Loss: 0.00021354970522224903\n",
      "Epoch 4710, Loss: 0.00010113403641298646, Final Batch Loss: 3.2329353416571394e-07\n",
      "Epoch 4711, Loss: 1.221168645315629e-05, Final Batch Loss: 2.7060852971771965e-06\n",
      "Epoch 4712, Loss: 0.005051193333201809, Final Batch Loss: 2.7070327632827684e-05\n",
      "Epoch 4713, Loss: 0.0002599020444904454, Final Batch Loss: 6.979321915423498e-05\n",
      "Epoch 4714, Loss: 7.61973246881098e-05, Final Batch Loss: 7.049460691632703e-05\n",
      "Epoch 4715, Loss: 7.925312019096964e-06, Final Batch Loss: 4.6443230417025916e-07\n",
      "Epoch 4716, Loss: 1.9634000523183204e-05, Final Batch Loss: 1.5610729633408482e-06\n",
      "Epoch 4717, Loss: 2.840405591086892e-05, Final Batch Loss: 2.6854424504563212e-05\n",
      "Epoch 4718, Loss: 2.3988643533812137e-06, Final Batch Loss: 1.1128984169772593e-06\n",
      "Epoch 4719, Loss: 0.0008334210431542033, Final Batch Loss: 2.5462921371399716e-07\n",
      "Epoch 4720, Loss: 3.141783076898719e-05, Final Batch Loss: 2.9749084205832332e-05\n",
      "Epoch 4721, Loss: 9.982761184801348e-05, Final Batch Loss: 5.472351404023357e-05\n",
      "Epoch 4722, Loss: 3.765630651741958e-06, Final Batch Loss: 2.989375161632779e-06\n",
      "Epoch 4723, Loss: 1.5644951588456024e-05, Final Batch Loss: 4.262857942194387e-07\n",
      "Epoch 4724, Loss: 4.98915881053108e-06, Final Batch Loss: 1.1538860462678713e-06\n",
      "Epoch 4725, Loss: 6.87321445411726e-05, Final Batch Loss: 6.72984606353566e-05\n",
      "Epoch 4726, Loss: 2.063624771153627e-05, Final Batch Loss: 5.140194048181002e-07\n",
      "Epoch 4727, Loss: 0.0001323861957871486, Final Batch Loss: 6.093774800319807e-07\n",
      "Epoch 4728, Loss: 3.105398172920104e-05, Final Batch Loss: 3.7055051507195458e-06\n",
      "Epoch 4729, Loss: 9.301636237069033e-05, Final Batch Loss: 6.735563511028886e-05\n",
      "Epoch 4730, Loss: 0.0007968687087895887, Final Batch Loss: 5.273715260045719e-07\n",
      "Epoch 4731, Loss: 3.533842755132355e-05, Final Batch Loss: 2.97146980301477e-05\n",
      "Epoch 4732, Loss: 0.0008661670372021035, Final Batch Loss: 1.3297679288371e-05\n",
      "Epoch 4733, Loss: 0.00013995417475598515, Final Batch Loss: 4.692973107012222e-06\n",
      "Epoch 4734, Loss: 2.2062084212848276e-06, Final Batch Loss: 6.818488031967718e-07\n",
      "Epoch 4735, Loss: 2.2000365333951777e-06, Final Batch Loss: 1.5496560763494927e-06\n",
      "Epoch 4736, Loss: 0.0006104754502302967, Final Batch Loss: 0.0005406058626249433\n",
      "Epoch 4737, Loss: 0.00019014706094822031, Final Batch Loss: 9.794098332349677e-07\n",
      "Epoch 4738, Loss: 1.0029532859334722e-05, Final Batch Loss: 6.959422080399236e-06\n",
      "Epoch 4739, Loss: 0.0004840701362240907, Final Batch Loss: 4.997195333089621e-07\n",
      "Epoch 4740, Loss: 8.408315125052468e-06, Final Batch Loss: 6.208499598869821e-06\n",
      "Epoch 4741, Loss: 3.3076791623898316e-05, Final Batch Loss: 2.257815867778845e-05\n",
      "Epoch 4742, Loss: 7.170100161602022e-06, Final Batch Loss: 2.4755240701779258e-06\n",
      "Epoch 4743, Loss: 7.284658158823731e-05, Final Batch Loss: 2.5538242880429607e-06\n",
      "Epoch 4744, Loss: 9.095748623622057e-06, Final Batch Loss: 1.4103846979196533e-06\n",
      "Epoch 4745, Loss: 1.608324296853425e-06, Final Batch Loss: 1.2493093493048946e-07\n",
      "Epoch 4746, Loss: 7.693285442655906e-05, Final Batch Loss: 4.014205114799552e-05\n",
      "Epoch 4747, Loss: 4.303615810385963e-06, Final Batch Loss: 6.837746013843571e-07\n",
      "Epoch 4748, Loss: 3.0271483410615474e-05, Final Batch Loss: 2.4894507077988237e-05\n",
      "Epoch 4749, Loss: 2.7501983481670322e-06, Final Batch Loss: 2.7370316502128844e-07\n",
      "Epoch 4750, Loss: 2.282108971485286e-05, Final Batch Loss: 2.2429153432312887e-06\n",
      "Epoch 4751, Loss: 6.662530040557613e-06, Final Batch Loss: 3.1439988106285455e-06\n",
      "Epoch 4752, Loss: 9.822887022892246e-06, Final Batch Loss: 7.264100531756412e-06\n",
      "Epoch 4753, Loss: 0.013357942278901191, Final Batch Loss: 0.013357055373489857\n",
      "Epoch 4754, Loss: 4.309219946208032e-06, Final Batch Loss: 4.959071588928055e-07\n",
      "Epoch 4755, Loss: 0.00015513683683821, Final Batch Loss: 0.00013473103172145784\n",
      "Epoch 4756, Loss: 3.809249847108731e-05, Final Batch Loss: 3.0083243473200127e-05\n",
      "Epoch 4757, Loss: 7.048279803711921e-05, Final Batch Loss: 5.5337110097752884e-05\n",
      "Epoch 4758, Loss: 0.00015847688700887375, Final Batch Loss: 0.00010476904571987689\n",
      "Epoch 4759, Loss: 5.6516782933613285e-05, Final Batch Loss: 3.382770228199661e-05\n",
      "Epoch 4760, Loss: 3.3943595553864725e-05, Final Batch Loss: 2.3109516405384056e-05\n",
      "Epoch 4761, Loss: 0.00010336848026781809, Final Batch Loss: 5.6285116443177685e-06\n",
      "Epoch 4762, Loss: 6.019337524776347e-05, Final Batch Loss: 1.8546637875260785e-05\n",
      "Epoch 4763, Loss: 1.8685469967749668e-05, Final Batch Loss: 1.4410129551833961e-05\n",
      "Epoch 4764, Loss: 0.0020025251633342123, Final Batch Loss: 0.0019803589675575495\n",
      "Epoch 4765, Loss: 0.0013840098199580098, Final Batch Loss: 2.9360971893765964e-05\n",
      "Epoch 4766, Loss: 4.598019950208254e-05, Final Batch Loss: 1.7717629816615954e-05\n",
      "Epoch 4767, Loss: 0.00013818693150824402, Final Batch Loss: 6.5527947299415246e-06\n",
      "Epoch 4768, Loss: 3.3955902836169116e-05, Final Batch Loss: 1.2460806829039939e-05\n",
      "Epoch 4769, Loss: 0.0008263409745268291, Final Batch Loss: 9.779809261090122e-06\n",
      "Epoch 4770, Loss: 0.0002172854365198873, Final Batch Loss: 5.5023694585543126e-05\n",
      "Epoch 4771, Loss: 0.00017544029287819285, Final Batch Loss: 1.3131853847880848e-05\n",
      "Epoch 4772, Loss: 0.00041759826126508415, Final Batch Loss: 0.00025128063862212\n",
      "Epoch 4773, Loss: 0.0004974652765667997, Final Batch Loss: 9.026889892993495e-05\n",
      "Epoch 4774, Loss: 4.3832040319102816e-05, Final Batch Loss: 7.988213837961666e-06\n",
      "Epoch 4775, Loss: 8.957134195952676e-05, Final Batch Loss: 4.57488204119727e-05\n",
      "Epoch 4776, Loss: 0.0006466568011092022, Final Batch Loss: 0.0005247010267339647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4777, Loss: 0.0008743286307435483, Final Batch Loss: 0.0008130682981573045\n",
      "Epoch 4778, Loss: 0.00015108625757420668, Final Batch Loss: 0.00013717295951209962\n",
      "Epoch 4779, Loss: 1.5613631148880813e-05, Final Batch Loss: 1.0581305105006322e-05\n",
      "Epoch 4780, Loss: 0.0024853052964317612, Final Batch Loss: 5.781114305136725e-05\n",
      "Epoch 4781, Loss: 4.477531365409959e-05, Final Batch Loss: 4.018407707917504e-06\n",
      "Epoch 4782, Loss: 0.0001620589655999538, Final Batch Loss: 6.313248945843952e-07\n",
      "Epoch 4783, Loss: 0.00011892607778918318, Final Batch Loss: 9.841509154284722e-07\n",
      "Epoch 4784, Loss: 0.000706846418324858, Final Batch Loss: 0.00010089704301208258\n",
      "Epoch 4785, Loss: 0.00040798444047140947, Final Batch Loss: 3.542565764291794e-06\n",
      "Epoch 4786, Loss: 0.0003053264999834937, Final Batch Loss: 6.946172106836457e-06\n",
      "Epoch 4787, Loss: 0.00031204740662360564, Final Batch Loss: 9.404531738255173e-06\n",
      "Epoch 4788, Loss: 1.221527008965495e-05, Final Batch Loss: 6.400622623914387e-06\n",
      "Epoch 4789, Loss: 0.00033951208024518564, Final Batch Loss: 7.3435730882920325e-06\n",
      "Epoch 4790, Loss: 5.190839260649227e-06, Final Batch Loss: 1.0366212563894805e-06\n",
      "Epoch 4791, Loss: 0.000773356397075986, Final Batch Loss: 8.174493814294692e-06\n",
      "Epoch 4792, Loss: 0.0002467217273078859, Final Batch Loss: 0.00018390353943686932\n",
      "Epoch 4793, Loss: 4.8502173285669414e-05, Final Batch Loss: 7.468308012903435e-06\n",
      "Epoch 4794, Loss: 3.653975454653846e-05, Final Batch Loss: 2.9624043236253783e-05\n",
      "Epoch 4795, Loss: 1.557863032530804e-05, Final Batch Loss: 6.904539873175963e-07\n",
      "Epoch 4796, Loss: 8.085999161266955e-05, Final Batch Loss: 6.94365517119877e-05\n",
      "Epoch 4797, Loss: 0.00019398502490730607, Final Batch Loss: 0.00018676347099244595\n",
      "Epoch 4798, Loss: 0.00015041112783364952, Final Batch Loss: 5.7913901400752366e-05\n",
      "Epoch 4799, Loss: 8.603688911534846e-06, Final Batch Loss: 4.9242003115068655e-06\n",
      "Epoch 4800, Loss: 1.498490587437118e-05, Final Batch Loss: 2.0245690848241793e-06\n",
      "Epoch 4801, Loss: 1.5079983768373495e-05, Final Batch Loss: 8.386759873246774e-06\n",
      "Epoch 4802, Loss: 0.00010596074207569472, Final Batch Loss: 1.8057882698485628e-05\n",
      "Epoch 4803, Loss: 2.8946175007149577e-05, Final Batch Loss: 1.4543202269123867e-06\n",
      "Epoch 4804, Loss: 0.00010107021444127895, Final Batch Loss: 5.9507950936676934e-05\n",
      "Epoch 4805, Loss: 0.00010610416939016432, Final Batch Loss: 9.335832146462053e-06\n",
      "Epoch 4806, Loss: 0.00018670468853088096, Final Batch Loss: 4.939757491229102e-05\n",
      "Epoch 4807, Loss: 0.0009747588374011684, Final Batch Loss: 4.424849248607643e-05\n",
      "Epoch 4808, Loss: 0.003920669900253415, Final Batch Loss: 0.0011497016530483961\n",
      "Epoch 4809, Loss: 7.453844591509551e-05, Final Batch Loss: 3.2332878618035465e-05\n",
      "Epoch 4810, Loss: 8.723341352379066e-05, Final Batch Loss: 6.418126758944709e-07\n",
      "Epoch 4811, Loss: 2.4141250833054073e-05, Final Batch Loss: 8.749604603508487e-06\n",
      "Epoch 4812, Loss: 7.563593862869311e-05, Final Batch Loss: 6.838353874627501e-05\n",
      "Epoch 4813, Loss: 2.9519806162170426e-05, Final Batch Loss: 2.832394056895282e-05\n",
      "Epoch 4814, Loss: 1.7571807347849244e-05, Final Batch Loss: 6.828020104876487e-06\n",
      "Epoch 4815, Loss: 0.001350617705611512, Final Batch Loss: 0.0010794473346322775\n",
      "Epoch 4816, Loss: 4.4192502173245884e-05, Final Batch Loss: 2.268588650622405e-05\n",
      "Epoch 4817, Loss: 3.2577779165876564e-05, Final Batch Loss: 1.1158880624861922e-05\n",
      "Epoch 4818, Loss: 1.2120133305870695e-05, Final Batch Loss: 7.513584478147095e-06\n",
      "Epoch 4819, Loss: 2.617399786686292e-05, Final Batch Loss: 1.318637077929452e-05\n",
      "Epoch 4820, Loss: 3.476934148238797e-05, Final Batch Loss: 3.330647814436816e-05\n",
      "Epoch 4821, Loss: 0.0003926427671103738, Final Batch Loss: 6.577191379619762e-05\n",
      "Epoch 4822, Loss: 0.0003947435398004018, Final Batch Loss: 6.17310797679238e-05\n",
      "Epoch 4823, Loss: 6.003309499647003e-05, Final Batch Loss: 1.4666857168776914e-06\n",
      "Epoch 4824, Loss: 1.303107569583517e-05, Final Batch Loss: 1.062276351149194e-05\n",
      "Epoch 4825, Loss: 5.640161361952778e-05, Final Batch Loss: 2.397063326498028e-05\n",
      "Epoch 4826, Loss: 0.0006683779120066902, Final Batch Loss: 0.0006401868304237723\n",
      "Epoch 4827, Loss: 0.00010027498319686856, Final Batch Loss: 8.732980495551601e-05\n",
      "Epoch 4828, Loss: 0.00018208650362794288, Final Batch Loss: 0.00015223091759253293\n",
      "Epoch 4829, Loss: 0.00016353892351617105, Final Batch Loss: 0.00015971744142007083\n",
      "Epoch 4830, Loss: 3.600870059017325e-05, Final Batch Loss: 1.0857381312234793e-05\n",
      "Epoch 4831, Loss: 1.6456286857646774e-05, Final Batch Loss: 9.155053248832701e-07\n",
      "Epoch 4832, Loss: 4.357077500571904e-06, Final Batch Loss: 1.8318975207876065e-06\n",
      "Epoch 4833, Loss: 7.922379154479131e-06, Final Batch Loss: 2.1809746613143943e-06\n",
      "Epoch 4834, Loss: 2.2287626961770002e-05, Final Batch Loss: 2.2162648747325875e-06\n",
      "Epoch 4835, Loss: 1.4581952882508631e-05, Final Batch Loss: 4.98768486068002e-07\n",
      "Epoch 4836, Loss: 0.0009911662200465798, Final Batch Loss: 0.0008478001691401005\n",
      "Epoch 4837, Loss: 0.00016287389053104562, Final Batch Loss: 0.00015525576600339264\n",
      "Epoch 4838, Loss: 9.351208518637577e-06, Final Batch Loss: 7.119838301150594e-06\n",
      "Epoch 4839, Loss: 0.0002579605929895479, Final Batch Loss: 4.709450422524242e-06\n",
      "Epoch 4840, Loss: 4.947217348671984e-05, Final Batch Loss: 4.3624899262795225e-05\n",
      "Epoch 4841, Loss: 0.001230068612130708, Final Batch Loss: 0.0012089801020920277\n",
      "Epoch 4842, Loss: 5.3176800975052174e-05, Final Batch Loss: 4.1238919948227704e-05\n",
      "Epoch 4843, Loss: 0.001204272237373516, Final Batch Loss: 0.00029299085144884884\n",
      "Epoch 4844, Loss: 0.00010216011378361145, Final Batch Loss: 9.403245348948985e-05\n",
      "Epoch 4845, Loss: 0.0001161033142125234, Final Batch Loss: 5.7948738685809076e-05\n",
      "Epoch 4846, Loss: 0.0001537557673145784, Final Batch Loss: 0.00014175237447489053\n",
      "Epoch 4847, Loss: 1.0526217579354125e-05, Final Batch Loss: 1.436201841897855e-06\n",
      "Epoch 4848, Loss: 6.868308128105127e-05, Final Batch Loss: 1.947234068211401e-06\n",
      "Epoch 4849, Loss: 0.00013589138438874215, Final Batch Loss: 2.705285851334338e-06\n",
      "Epoch 4850, Loss: 5.8358673413749784e-05, Final Batch Loss: 1.7248603398911655e-05\n",
      "Epoch 4851, Loss: 0.00034210699959658086, Final Batch Loss: 0.00011133043153677136\n",
      "Epoch 4852, Loss: 0.00014203524187905714, Final Batch Loss: 0.00013957831833977252\n",
      "Epoch 4853, Loss: 0.004318193066865206, Final Batch Loss: 0.0041764406487345695\n",
      "Epoch 4854, Loss: 7.314031063287985e-05, Final Batch Loss: 6.540766480611637e-05\n",
      "Epoch 4855, Loss: 6.6975210302189225e-06, Final Batch Loss: 2.6489180982025573e-06\n",
      "Epoch 4856, Loss: 3.6149555398878874e-05, Final Batch Loss: 3.611047304730164e-06\n",
      "Epoch 4857, Loss: 6.152101832412882e-05, Final Batch Loss: 5.401040652941447e-06\n",
      "Epoch 4858, Loss: 9.556140003041946e-05, Final Batch Loss: 4.167128736298764e-06\n",
      "Epoch 4859, Loss: 2.1650224198310752e-05, Final Batch Loss: 2.136122247975436e-06\n",
      "Epoch 4860, Loss: 3.663474490167573e-05, Final Batch Loss: 8.985616659629159e-06\n",
      "Epoch 4861, Loss: 0.002257991021451744, Final Batch Loss: 0.00225260853767395\n",
      "Epoch 4862, Loss: 8.927474618758424e-05, Final Batch Loss: 8.653500844957307e-05\n",
      "Epoch 4863, Loss: 1.0792590728669893e-05, Final Batch Loss: 2.687091182451695e-06\n",
      "Epoch 4864, Loss: 1.98807792912703e-05, Final Batch Loss: 3.542672857292928e-06\n",
      "Epoch 4865, Loss: 0.00018511511734686792, Final Batch Loss: 0.00011749560508178547\n",
      "Epoch 4866, Loss: 2.4842704988259356e-05, Final Batch Loss: 1.2226687431393657e-05\n",
      "Epoch 4867, Loss: 0.001028035330818966, Final Batch Loss: 0.0004242628056090325\n",
      "Epoch 4868, Loss: 2.3921051706565777e-05, Final Batch Loss: 1.82967687578639e-05\n",
      "Epoch 4869, Loss: 6.147468002382084e-05, Final Batch Loss: 1.4762567843717989e-06\n",
      "Epoch 4870, Loss: 4.4016248921252554e-05, Final Batch Loss: 3.863224628730677e-05\n",
      "Epoch 4871, Loss: 1.1753377975765034e-05, Final Batch Loss: 9.545811735733878e-06\n",
      "Epoch 4872, Loss: 1.235468562299502e-05, Final Batch Loss: 7.988255674717948e-06\n",
      "Epoch 4873, Loss: 2.6129874868274783e-06, Final Batch Loss: 1.2712062016362324e-06\n",
      "Epoch 4874, Loss: 4.6259301825557486e-05, Final Batch Loss: 1.2740749752992997e-06\n",
      "Epoch 4875, Loss: 3.8128802657411143e-06, Final Batch Loss: 7.972536764100369e-07\n",
      "Epoch 4876, Loss: 3.146055314573459e-05, Final Batch Loss: 1.738373248372227e-05\n",
      "Epoch 4877, Loss: 9.439787027076818e-05, Final Batch Loss: 5.597182462224737e-05\n",
      "Epoch 4878, Loss: 7.744583672320005e-05, Final Batch Loss: 3.953957275371067e-06\n",
      "Epoch 4879, Loss: 5.464726655191043e-06, Final Batch Loss: 2.7836356366606196e-06\n",
      "Epoch 4880, Loss: 2.0440887880113223e-06, Final Batch Loss: 2.3460167142275168e-07\n",
      "Epoch 4881, Loss: 0.0001223311701323837, Final Batch Loss: 0.0001075013424269855\n",
      "Epoch 4882, Loss: 0.00019000462498297566, Final Batch Loss: 0.00018406403250992298\n",
      "Epoch 4883, Loss: 8.948439131017949e-06, Final Batch Loss: 7.666736564715393e-06\n",
      "Epoch 4884, Loss: 0.007043050427455455, Final Batch Loss: 0.006440320983529091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4885, Loss: 2.155166021111654e-05, Final Batch Loss: 8.522487405571155e-06\n",
      "Epoch 4886, Loss: 7.110809929145034e-05, Final Batch Loss: 1.0431589544168673e-05\n",
      "Epoch 4887, Loss: 0.00022001636170898564, Final Batch Loss: 0.00018307461868971586\n",
      "Epoch 4888, Loss: 0.00036111194640398026, Final Batch Loss: 9.067787323147058e-05\n",
      "Epoch 4889, Loss: 0.00017042532022060186, Final Batch Loss: 1.5191446891549276e-06\n",
      "Epoch 4890, Loss: 0.0001556301831442397, Final Batch Loss: 5.099503687233664e-05\n",
      "Epoch 4891, Loss: 0.00044970590170123614, Final Batch Loss: 0.00044183668796904385\n",
      "Epoch 4892, Loss: 2.7114209842693526e-05, Final Batch Loss: 2.648765621415805e-05\n",
      "Epoch 4893, Loss: 1.825522917897615e-05, Final Batch Loss: 3.2479126730322605e-06\n",
      "Epoch 4894, Loss: 0.0012165332655058592, Final Batch Loss: 1.089952183974674e-05\n",
      "Epoch 4895, Loss: 4.774645049110404e-06, Final Batch Loss: 1.9311398773425026e-06\n",
      "Epoch 4896, Loss: 5.6019818657659926e-05, Final Batch Loss: 2.1640711565851234e-05\n",
      "Epoch 4897, Loss: 1.2192741451144684e-05, Final Batch Loss: 7.64710785006173e-06\n",
      "Epoch 4898, Loss: 2.7035976927436423e-05, Final Batch Loss: 3.0198525564628653e-06\n",
      "Epoch 4899, Loss: 2.3706701540504582e-05, Final Batch Loss: 9.903193131322041e-06\n",
      "Epoch 4900, Loss: 2.5441649995627813e-05, Final Batch Loss: 6.038266292307526e-06\n",
      "Epoch 4901, Loss: 6.880124601593707e-06, Final Batch Loss: 4.253028691891814e-06\n",
      "Epoch 4902, Loss: 7.933771712487214e-06, Final Batch Loss: 4.8537231123191305e-06\n",
      "Epoch 4903, Loss: 5.11991745497653e-05, Final Batch Loss: 3.002019866471528e-06\n",
      "Epoch 4904, Loss: 0.0002984917900903383, Final Batch Loss: 0.00028268041205592453\n",
      "Epoch 4905, Loss: 2.0522489421637147e-05, Final Batch Loss: 1.8952383470605128e-05\n",
      "Epoch 4906, Loss: 2.712454261200037e-05, Final Batch Loss: 2.1322084649000317e-06\n",
      "Epoch 4907, Loss: 0.00015906060434645042, Final Batch Loss: 8.44400201458484e-05\n",
      "Epoch 4908, Loss: 1.308939499722328e-05, Final Batch Loss: 4.933804120810237e-06\n",
      "Epoch 4909, Loss: 5.235222397459438e-05, Final Batch Loss: 6.034612852090504e-06\n",
      "Epoch 4910, Loss: 2.709982663873234e-05, Final Batch Loss: 2.1629017282975838e-05\n",
      "Epoch 4911, Loss: 0.01169862234746688, Final Batch Loss: 0.011672347784042358\n",
      "Epoch 4912, Loss: 8.786545697603287e-05, Final Batch Loss: 8.726799569558352e-05\n",
      "Epoch 4913, Loss: 2.4648030830576317e-05, Final Batch Loss: 1.9437444279901683e-05\n",
      "Epoch 4914, Loss: 6.679563227862673e-06, Final Batch Loss: 2.7942445512962877e-07\n",
      "Epoch 4915, Loss: 0.0001537430962343933, Final Batch Loss: 0.0001492096489528194\n",
      "Epoch 4916, Loss: 3.20740448955803e-06, Final Batch Loss: 2.861011410004721e-07\n",
      "Epoch 4917, Loss: 0.00026997663371730596, Final Batch Loss: 5.875853821635246e-05\n",
      "Epoch 4918, Loss: 1.906819761643419e-06, Final Batch Loss: 1.036628873407608e-06\n",
      "Epoch 4919, Loss: 4.590072649079957e-06, Final Batch Loss: 2.3811448954802472e-06\n",
      "Epoch 4920, Loss: 4.671289957514091e-05, Final Batch Loss: 4.424253347679041e-05\n",
      "Epoch 4921, Loss: 0.0006493501840907356, Final Batch Loss: 1.296993161759019e-07\n",
      "Epoch 4922, Loss: 4.510637455723554e-05, Final Batch Loss: 4.493328378885053e-05\n",
      "Epoch 4923, Loss: 1.227370671585959e-05, Final Batch Loss: 1.3436667813948588e-06\n",
      "Epoch 4924, Loss: 3.178898259648122e-05, Final Batch Loss: 6.124524588813074e-06\n",
      "Epoch 4925, Loss: 3.3544952202646527e-06, Final Batch Loss: 9.260063507099403e-07\n",
      "Epoch 4926, Loss: 0.0002973940790980123, Final Batch Loss: 3.9286962419282645e-05\n",
      "Epoch 4927, Loss: 0.00018211774022347527, Final Batch Loss: 0.00017741724150255322\n",
      "Epoch 4928, Loss: 0.0006064339504519012, Final Batch Loss: 0.0005907282466068864\n",
      "Epoch 4929, Loss: 2.831721644724894e-06, Final Batch Loss: 1.8776664774122764e-06\n",
      "Epoch 4930, Loss: 0.00026146084564970806, Final Batch Loss: 1.5668752894271165e-05\n",
      "Epoch 4931, Loss: 3.3410219657525886e-06, Final Batch Loss: 2.0054997094121063e-06\n",
      "Epoch 4932, Loss: 1.4766444564884296e-05, Final Batch Loss: 7.496370471926639e-06\n",
      "Epoch 4933, Loss: 3.7084837231304846e-05, Final Batch Loss: 1.7184263469971484e-06\n",
      "Epoch 4934, Loss: 0.005110606085509062, Final Batch Loss: 0.0015689788851886988\n",
      "Epoch 4935, Loss: 0.00010270559596392559, Final Batch Loss: 9.776855586096644e-05\n",
      "Epoch 4936, Loss: 5.637778372147295e-06, Final Batch Loss: 3.791116569118458e-06\n",
      "Epoch 4937, Loss: 1.1028703994497846e-06, Final Batch Loss: 1.831048876965724e-07\n",
      "Epoch 4938, Loss: 0.0001461563260818366, Final Batch Loss: 2.174229666707106e-05\n",
      "Epoch 4939, Loss: 5.856652251168271e-06, Final Batch Loss: 1.171048779724515e-06\n",
      "Epoch 4940, Loss: 0.0003554064498985099, Final Batch Loss: 1.9768378933804343e-06\n",
      "Epoch 4941, Loss: 6.17102800788416e-05, Final Batch Loss: 7.368913884420181e-06\n",
      "Epoch 4942, Loss: 2.4968946490844246e-05, Final Batch Loss: 5.8584091675584204e-06\n",
      "Epoch 4943, Loss: 2.9051919909761637e-06, Final Batch Loss: 1.9215078737033764e-06\n",
      "Epoch 4944, Loss: 1.3069817441646592e-06, Final Batch Loss: 8.754481655159907e-07\n",
      "Epoch 4945, Loss: 3.5206223401473835e-05, Final Batch Loss: 2.6987556339008734e-05\n",
      "Epoch 4946, Loss: 0.00010914478116319515, Final Batch Loss: 7.899215415818617e-05\n",
      "Epoch 4947, Loss: 2.426364483198995e-05, Final Batch Loss: 1.1119460623376654e-06\n",
      "Epoch 4948, Loss: 2.300367248153634e-05, Final Batch Loss: 2.4604503323644167e-07\n",
      "Epoch 4949, Loss: 0.00010732824648584938, Final Batch Loss: 9.46752043091692e-05\n",
      "Epoch 4950, Loss: 3.8458016206277534e-05, Final Batch Loss: 8.975923265097663e-06\n",
      "Epoch 4951, Loss: 3.314306786705856e-05, Final Batch Loss: 2.863542704290012e-06\n",
      "Epoch 4952, Loss: 1.3349733649192785e-05, Final Batch Loss: 1.3083966905469424e-06\n",
      "Epoch 4953, Loss: 6.218354656084557e-06, Final Batch Loss: 2.1370485683291918e-06\n",
      "Epoch 4954, Loss: 0.00018198533052782295, Final Batch Loss: 3.612115506257396e-06\n",
      "Epoch 4955, Loss: 3.1729517786516226e-05, Final Batch Loss: 1.4781596746615833e-06\n",
      "Epoch 4956, Loss: 0.0001707958424503886, Final Batch Loss: 0.0001687672920525074\n",
      "Epoch 4957, Loss: 2.3995530682441313e-05, Final Batch Loss: 8.7203197836061e-06\n",
      "Epoch 4958, Loss: 9.016171952680452e-05, Final Batch Loss: 1.1272231859038584e-06\n",
      "Epoch 4959, Loss: 5.382252837193846e-06, Final Batch Loss: 1.6880001396657462e-07\n",
      "Epoch 4960, Loss: 0.014197392544019749, Final Batch Loss: 2.805298436214798e-06\n",
      "Epoch 4961, Loss: 4.440238308234257e-05, Final Batch Loss: 4.059657294419594e-05\n",
      "Epoch 4962, Loss: 0.004657148455521565, Final Batch Loss: 0.0046554324217140675\n",
      "Epoch 4963, Loss: 0.002290163108341403, Final Batch Loss: 0.002288381801918149\n",
      "Epoch 4964, Loss: 5.781544132332783e-06, Final Batch Loss: 2.2151127723191166e-06\n",
      "Epoch 4965, Loss: 1.2719308671194085e-05, Final Batch Loss: 3.900447893556702e-07\n",
      "Epoch 4966, Loss: 6.49389386353505e-06, Final Batch Loss: 4.0435253367832047e-07\n",
      "Epoch 4967, Loss: 0.00015635863178431464, Final Batch Loss: 1.7613544969208306e-06\n",
      "Epoch 4968, Loss: 9.936612627825525e-06, Final Batch Loss: 1.8642850818650913e-06\n",
      "Epoch 4969, Loss: 9.435176616534591e-05, Final Batch Loss: 1.554952177684754e-05\n",
      "Epoch 4970, Loss: 0.011396288507967256, Final Batch Loss: 3.186018147971481e-05\n",
      "Epoch 4971, Loss: 0.0005472167067637201, Final Batch Loss: 0.000509495148435235\n",
      "Epoch 4972, Loss: 7.039078718662495e-05, Final Batch Loss: 6.085037057346199e-06\n",
      "Epoch 4973, Loss: 1.1878676332344185e-05, Final Batch Loss: 1.0265166565659456e-05\n",
      "Epoch 4974, Loss: 9.025309464050224e-05, Final Batch Loss: 8.45671966089867e-05\n",
      "Epoch 4975, Loss: 2.7143541046825703e-05, Final Batch Loss: 2.5188624931615777e-05\n",
      "Epoch 4976, Loss: 2.141673803635058e-05, Final Batch Loss: 1.667211290623527e-05\n",
      "Epoch 4977, Loss: 6.861539304736652e-06, Final Batch Loss: 2.8779943477275083e-06\n",
      "Epoch 4978, Loss: 0.0001014816571114352, Final Batch Loss: 1.9633216652437113e-05\n",
      "Epoch 4979, Loss: 0.00014727784650858666, Final Batch Loss: 0.00014402533997781575\n",
      "Epoch 4980, Loss: 0.00016525759929209016, Final Batch Loss: 1.3062392099527642e-05\n",
      "Epoch 4981, Loss: 5.154556674824562e-05, Final Batch Loss: 3.697287684190087e-05\n",
      "Epoch 4982, Loss: 0.000343859346685349, Final Batch Loss: 0.0003379521076567471\n",
      "Epoch 4983, Loss: 1.5460833765246207e-05, Final Batch Loss: 8.717556738702115e-06\n",
      "Epoch 4984, Loss: 7.327963612624444e-05, Final Batch Loss: 4.679369885707274e-05\n",
      "Epoch 4985, Loss: 0.00036091899892198853, Final Batch Loss: 0.0003177229082211852\n",
      "Epoch 4986, Loss: 3.376763402229699e-06, Final Batch Loss: 2.109379011017154e-06\n",
      "Epoch 4987, Loss: 1.3769489214610076e-05, Final Batch Loss: 5.831903308717301e-06\n",
      "Epoch 4988, Loss: 5.821708805342496e-05, Final Batch Loss: 1.167272102975403e-06\n",
      "Epoch 4989, Loss: 3.4701506592682563e-06, Final Batch Loss: 1.8500608121030382e-06\n",
      "Epoch 4990, Loss: 0.0016881975766409596, Final Batch Loss: 0.0016866603400558233\n",
      "Epoch 4991, Loss: 0.0007567331458204762, Final Batch Loss: 2.3460320619506092e-07\n",
      "Epoch 4992, Loss: 0.0005757446128882293, Final Batch Loss: 5.406975560617866e-06\n",
      "Epoch 4993, Loss: 5.830369445902761e-05, Final Batch Loss: 4.106064443476498e-05\n",
      "Epoch 4994, Loss: 0.00014596003737210594, Final Batch Loss: 3.681109603803634e-07\n",
      "Epoch 4995, Loss: 0.00011514617199281929, Final Batch Loss: 9.283593499276321e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4996, Loss: 0.00014871082566969562, Final Batch Loss: 1.9918270481866784e-05\n",
      "Epoch 4997, Loss: 8.376452751690522e-05, Final Batch Loss: 3.594824011088349e-05\n",
      "Epoch 4998, Loss: 6.197944730956806e-05, Final Batch Loss: 6.630528332607355e-06\n",
      "Epoch 4999, Loss: 0.0016824562626425177, Final Batch Loss: 0.0004810401296708733\n",
      "Epoch 5000, Loss: 9.259586872190084e-05, Final Batch Loss: 2.708423778585711e-07\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  0  0]\n",
      " [ 0 17  0]\n",
      " [ 0  0 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000        28\n",
      "           1      1.000     1.000     1.000        17\n",
      "           2      1.000     1.000     1.000        22\n",
      "\n",
      "    accuracy                          1.000        67\n",
      "   macro avg      1.000     1.000     1.000        67\n",
      "weighted avg      1.000     1.000     1.000        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../../saved_models/UCI 3 Label Classifier Group 2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
