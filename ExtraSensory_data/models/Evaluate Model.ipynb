{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3628270f",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42bec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a387f2",
   "metadata": {},
   "source": [
    "# Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d769d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation(df):\n",
    "    col_to_avg = list(df.columns) #Start with keeping all the columns as columns to use an average interpolation on\n",
    "    for k in range(len(list(df.columns))):\n",
    "        if list(df.columns)[k].startswith(('discrete', 'label')): #Remove label and discrete columns from col_to_avg\n",
    "            col_to_avg.remove(list(df.columns)[k])\n",
    "    \n",
    "    df_with_avg = df[col_to_avg].fillna(df[col_to_avg].mean()) #Interpolate nan columns for all continuous-valued columns with average\n",
    "    \n",
    "    col_to_zero = list(df.columns)\n",
    "    for k in range(len(list(df.columns))):\n",
    "        if not list(df.columns)[k].startswith(('discrete', 'label')): #Remove all columns except label and discrete\n",
    "            col_to_zero.remove(list(df.columns)[k])\n",
    "    \n",
    "    df_with_zero = df[col_to_zero].fillna(0) #Interpolate nan values for label and discrete columns with 0\n",
    "    \n",
    "    return pd.concat([df_with_avg, df_with_zero], axis = 1)\n",
    "\n",
    "\n",
    "data = pd.read_csv('../aggregated_data/aggregated_data.csv')\n",
    "\n",
    "X = data.iloc[:,1:27]\n",
    "y = data[['label:SITTING']]\n",
    "\n",
    "#Get training data\n",
    "X_sit = X[y['label:SITTING'] == 1]\n",
    "X_sit = interpolation(X_sit)\n",
    "X_sit = X_sit.values\n",
    "\n",
    "X_not_sit  = X[y['label:SITTING'] == 0]\n",
    "X_not_sit = interpolation(X_not_sit)\n",
    "X_not_sit = X_not_sit.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0451b0b7",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc75f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = 10000\n",
    "\n",
    "test_sample = 2000\n",
    "\n",
    "#Sample from real sitting data\n",
    "index_choice = np.random.choice(len(X_sit), int(train_sample/2), replace=False)\n",
    "X_sit_sample = X_sit[index_choice]\n",
    "y_sit_sample = np.ones(int(train_sample/2))\n",
    "\n",
    "#Sample from real non sitting data\n",
    "index_choice = np.random.choice(len(X_not_sit), int(train_sample/2), replace=False)\n",
    "X_not_sit_sample = X_not_sit[index_choice]\n",
    "y_not_sit_sample = np.zeros(int(train_sample/2))\n",
    "\n",
    "# Get testing data\n",
    "index_choice = np.random.choice(len(X_sit), test_sample, replace=False)\n",
    "X_test = X_sit[index_choice]\n",
    "y_test = np.ones(test_sample)\n",
    "\n",
    "#Concatenate to make train set\n",
    "X_train = np.concatenate((X_sit_sample, X_not_sit_sample), axis = 0)\n",
    "y_train = np.concatenate((y_sit_sample, y_not_sit_sample), axis = 0)\n",
    "\n",
    "#Shuffle in unison\n",
    "shuffler = np.random.permutation(len(X_train))\n",
    "X_train = X_train[shuffler]\n",
    "y_train = y_train[shuffler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e2b28cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_performance(y_pred, y_test):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for k in range(len(y_pred)):\n",
    "        #True positive\n",
    "        if y_test[k] == 1 and y_pred[k] == 1:\n",
    "            tp += 1\n",
    "        #False Negative\n",
    "        elif y_test[k] == 1 and y_pred[k] == 0:\n",
    "            fn += 1\n",
    "        #True Negative\n",
    "        elif y_test[k] == 0 and y_pred[k] == 0:\n",
    "            tn += 1\n",
    "        elif y_test[k] == 0 and y_pred[k] == 1:\n",
    "            fp += 1\n",
    "        else:\n",
    "            print(\"Error\")\n",
    "            exit()\n",
    "            \n",
    "    acc = (tp + tn)/(tp + tn + fp + fn)\n",
    "\n",
    "    if tp + fp == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "\n",
    "    if tp + fn == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = tp / (tp + fn)\n",
    "    \n",
    "    f1 = 2*(precision * recall / (precision + recall + 0.001))\n",
    "    \n",
    "    print(f'Precision: {precision:.3f} Recall: {recall:.3f} F-1 Score: {f1:.3f}')\n",
    "    \n",
    "    return acc, f1\n",
    "\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = 26, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 40),\n",
    "            generator_block(40, 28),\n",
    "            nn.Linear(28, feature_dim)\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b193dd8",
   "metadata": {},
   "source": [
    "# Train on Real, Evaluate on Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11afce4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.000 Recall: 1.000 F-1 Score: 1.000\n",
      "\n",
      "Train on Real, Evaluate on Real\n",
      "Accuracy: 1.00000 | F1: 0.99950\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(penalty = 'l2', C = 0.8)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "#print(y_pred, y_test)\n",
    "accuracy, f1 = classifier_performance(y_pred, y_test)\n",
    "print(f\"\\nTrain on Real, Evaluate on Real\\nAccuracy: {accuracy:.5f} | F1: {f1:.5f}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a62f9",
   "metadata": {},
   "source": [
    "# Train on Real + Fake, Evaluate on Fake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d22e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.000 Recall: 0.000 F-1 Score: 0.000\n",
      "\n",
      "Train on Real + Fake, Evaluate on Real\n",
      "Accuracy: 0.00000 | F1: 0.00000\n"
     ]
    }
   ],
   "source": [
    "#Load in generator\n",
    "z_dim = 100\n",
    "Gen = Generator(z_dim)\n",
    "Gen.load_state_dict(torch.load('../saved_models/gan'))\n",
    "\n",
    "latent_vectors = torch.randn(int(train_sample/2), 100)\n",
    "fake_features = Gen(latent_vectors).detach().numpy()\n",
    "y_label_sitting = np.ones(int(train_sample/2))\n",
    "                          \n",
    "X_train = np.concatenate((fake_features, X_not_sit_sample), axis = 0)\n",
    "y_train = np.concatenate((y_label_sitting, y_not_sit_sample), axis = 0)\n",
    "\n",
    "#Shuffle in unison\n",
    "shuffler = np.random.permutation(len(X_train))\n",
    "X_train = X_train[shuffler]\n",
    "y_train = y_train[shuffler]                       \n",
    "\n",
    "                          \n",
    "classifier = LogisticRegression(penalty = 'l2', C = 0.7)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy, f1 = classifier_performance(y_pred, y_test)\n",
    "\n",
    "print(f\"\\nTrain on Real + Fake, Evaluate on Real\\nAccuracy: {accuracy:.5f} | F1: {f1:.5f}\")                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5de16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
