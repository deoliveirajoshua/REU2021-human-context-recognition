{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>raw_acc:magnitude_stats:mean</th>\n",
       "      <th>raw_acc:magnitude_stats:std</th>\n",
       "      <th>raw_acc:magnitude_stats:moment3</th>\n",
       "      <th>raw_acc:magnitude_stats:moment4</th>\n",
       "      <th>raw_acc:magnitude_stats:percentile25</th>\n",
       "      <th>raw_acc:magnitude_stats:percentile50</th>\n",
       "      <th>raw_acc:magnitude_stats:percentile75</th>\n",
       "      <th>raw_acc:magnitude_stats:value_entropy</th>\n",
       "      <th>raw_acc:magnitude_stats:time_entropy</th>\n",
       "      <th>...</th>\n",
       "      <th>label:STAIRS_-_GOING_DOWN</th>\n",
       "      <th>label:ELEVATOR</th>\n",
       "      <th>label:OR_standing</th>\n",
       "      <th>label:AT_SCHOOL</th>\n",
       "      <th>label:PHONE_IN_HAND</th>\n",
       "      <th>label:PHONE_IN_BAG</th>\n",
       "      <th>label:PHONE_ON_TABLE</th>\n",
       "      <th>label:WITH_CO-WORKERS</th>\n",
       "      <th>label:WITH_FRIENDS</th>\n",
       "      <th>label_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1449601597</td>\n",
       "      <td>1.000371</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>-0.016173</td>\n",
       "      <td>0.027860</td>\n",
       "      <td>0.998221</td>\n",
       "      <td>1.000739</td>\n",
       "      <td>1.003265</td>\n",
       "      <td>0.891038</td>\n",
       "      <td>6.684582</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1449601657</td>\n",
       "      <td>1.000243</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>-0.002713</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>0.998463</td>\n",
       "      <td>1.000373</td>\n",
       "      <td>1.002088</td>\n",
       "      <td>1.647929</td>\n",
       "      <td>6.684605</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1449601717</td>\n",
       "      <td>1.000811</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>-0.001922</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.999653</td>\n",
       "      <td>1.000928</td>\n",
       "      <td>1.002032</td>\n",
       "      <td>1.960286</td>\n",
       "      <td>6.684610</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1449601777</td>\n",
       "      <td>1.001245</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>-0.002895</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>0.999188</td>\n",
       "      <td>1.001425</td>\n",
       "      <td>1.003500</td>\n",
       "      <td>1.614524</td>\n",
       "      <td>6.684601</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1449601855</td>\n",
       "      <td>1.001354</td>\n",
       "      <td>0.065186</td>\n",
       "      <td>-0.096520</td>\n",
       "      <td>0.165298</td>\n",
       "      <td>1.000807</td>\n",
       "      <td>1.002259</td>\n",
       "      <td>1.003631</td>\n",
       "      <td>0.837790</td>\n",
       "      <td>6.682252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp  raw_acc:magnitude_stats:mean  raw_acc:magnitude_stats:std  \\\n",
       "0  1449601597                      1.000371                     0.007671   \n",
       "1  1449601657                      1.000243                     0.003782   \n",
       "2  1449601717                      1.000811                     0.002082   \n",
       "3  1449601777                      1.001245                     0.004715   \n",
       "4  1449601855                      1.001354                     0.065186   \n",
       "\n",
       "   raw_acc:magnitude_stats:moment3  raw_acc:magnitude_stats:moment4  \\\n",
       "0                        -0.016173                         0.027860   \n",
       "1                        -0.002713                         0.007046   \n",
       "2                        -0.001922                         0.003575   \n",
       "3                        -0.002895                         0.008881   \n",
       "4                        -0.096520                         0.165298   \n",
       "\n",
       "   raw_acc:magnitude_stats:percentile25  raw_acc:magnitude_stats:percentile50  \\\n",
       "0                              0.998221                              1.000739   \n",
       "1                              0.998463                              1.000373   \n",
       "2                              0.999653                              1.000928   \n",
       "3                              0.999188                              1.001425   \n",
       "4                              1.000807                              1.002259   \n",
       "\n",
       "   raw_acc:magnitude_stats:percentile75  \\\n",
       "0                              1.003265   \n",
       "1                              1.002088   \n",
       "2                              1.002032   \n",
       "3                              1.003500   \n",
       "4                              1.003631   \n",
       "\n",
       "   raw_acc:magnitude_stats:value_entropy  \\\n",
       "0                               0.891038   \n",
       "1                               1.647929   \n",
       "2                               1.960286   \n",
       "3                               1.614524   \n",
       "4                               0.837790   \n",
       "\n",
       "   raw_acc:magnitude_stats:time_entropy  ...  label:STAIRS_-_GOING_DOWN  \\\n",
       "0                              6.684582  ...                        NaN   \n",
       "1                              6.684605  ...                        NaN   \n",
       "2                              6.684610  ...                        NaN   \n",
       "3                              6.684601  ...                        NaN   \n",
       "4                              6.682252  ...                        0.0   \n",
       "\n",
       "   label:ELEVATOR  label:OR_standing  label:AT_SCHOOL  label:PHONE_IN_HAND  \\\n",
       "0             NaN                NaN              NaN                  NaN   \n",
       "1             NaN                NaN              NaN                  NaN   \n",
       "2             NaN                NaN              NaN                  NaN   \n",
       "3             NaN                NaN              NaN                  NaN   \n",
       "4             NaN                0.0              1.0                  NaN   \n",
       "\n",
       "   label:PHONE_IN_BAG  label:PHONE_ON_TABLE  label:WITH_CO-WORKERS  \\\n",
       "0                 NaN                   NaN                    NaN   \n",
       "1                 NaN                   NaN                    NaN   \n",
       "2                 NaN                   NaN                    NaN   \n",
       "3                 NaN                   NaN                    NaN   \n",
       "4                 NaN                   NaN                    NaN   \n",
       "\n",
       "   label:WITH_FRIENDS  label_source  \n",
       "0                 NaN            -1  \n",
       "1                 NaN            -1  \n",
       "2                 NaN            -1  \n",
       "3                 NaN            -1  \n",
       "4                 0.0             2  \n",
       "\n",
       "[5 rows x 278 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Change the data file directory below appropriately\n",
    "data = pd.read_csv('../raw_data/0A986513-7828-4D53-AA1F-E02D6DF9561B.features_labels.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolating acceleration columns with average values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation(df):\n",
    "    col_to_avg = list(df.columns) #Start with keeping all the columns as columns to use an average interpolation on\n",
    "    for k in range(len(list(df.columns))):\n",
    "        if list(df.columns)[k].startswith(('discrete', 'label')): #Remove label and discrete columns from col_to_avg\n",
    "            col_to_avg.remove(list(df.columns)[k])\n",
    "    \n",
    "    df_with_avg = df[col_to_avg].fillna(df[col_to_avg].mean()) #Interpolate nan columns for all continuous-valued columns with average\n",
    "    \n",
    "    col_to_zero = list(df.columns)\n",
    "    for k in range(len(list(df.columns))):\n",
    "        if not list(df.columns)[k].startswith(('discrete', 'label')): #Remove all columns except label and discrete\n",
    "            col_to_zero.remove(list(df.columns)[k])\n",
    "    \n",
    "    df_with_zero = df[col_to_zero].fillna(0) #Interpolate nan values for label and discrete columns with 0\n",
    "    \n",
    "    return pd.concat([df_with_avg, df_with_zero], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data and loading it into a PyTorch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2253 2253\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:,1:27]\n",
    "y = data[['label:SITTING']]\n",
    "\n",
    "X = X[y['label:SITTING'] == 1]\n",
    "y = y[y['label:SITTING'] == 1]\n",
    "\n",
    "X = interpolation(X).values\n",
    "y = interpolation(y).values\n",
    "\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = 26, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, int(hidden_dim/2)),\n",
    "            generator_block(int(hidden_dim/2), int(hidden_dim/4)),\n",
    "            generator_block(int(hidden_dim/4), 30),\n",
    "            generator_block(30, feature_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def discriminator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, feature_dim = 26, hidden_dim = 16):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            discriminator_block(feature_dim, hidden_dim),\n",
    "            discriminator_block(hidden_dim, int(hidden_dim/2)),\n",
    "            discriminator_block(int(hidden_dim/2), int(hidden_dim/4)),\n",
    "            nn.Linear(int(hidden_dim/4), 1),\n",
    "            nn.Sigmoid()                    \n",
    "        )\n",
    "    def forward(self, feature_vector):\n",
    "        return self.disc(feature_vector)\n",
    "\n",
    "def get_disc_loss(gen, disc, criterion, real_features, batch_size, z_dim):\n",
    "    latent_vectors = get_noise(batch_size, z_dim)\n",
    "    fake_features = gen(latent_vectors)\n",
    "    pred_fake = disc(fake_features.detach())\n",
    "    \n",
    "    ground_truth = torch.zeros_like(pred_fake)\n",
    "    loss_fake = criterion(pred_fake, ground_truth)\n",
    "    \n",
    "    pred_real = disc(real_features)\n",
    "    ground_truth = torch.ones_like(pred_real)\n",
    "    loss_real = criterion(pred_real, ground_truth)\n",
    "    \n",
    "    disc_loss = (loss_fake + loss_real) / 2\n",
    "    return disc_loss\n",
    "\n",
    "def get_gen_loss(gen, disc, criterion, batch_size, z_dim):\n",
    "    latent_vectors = get_noise(batch_size, z_dim)\n",
    "    fake_features = gen(latent_vectors)\n",
    "    pred = disc(fake_features)\n",
    "    gen_loss = criterion(pred, torch.ones_like(pred))\n",
    "    return gen_loss\n",
    "\n",
    "def visualize_gen_batch(gen, b_size, epochs = -1):\n",
    "    #print(str(b_size))\n",
    "    latent_vectors = get_noise(b_size, z_dim)\n",
    "    #print(latent_vectors.shape)\n",
    "    fake_features = gen(latent_vectors)\n",
    "    #print(fake_features.shape)\n",
    "    \n",
    "    w_img = fake_features\n",
    "    wmin = torch.min(w_img)\n",
    "    wmax = torch.max(w_img)\n",
    "    w_img = w_img.cpu()\n",
    "    w_img = w_img.detach().numpy()\n",
    "    c = plt.imshow(w_img, cmap ='Reds', vmin = wmin , vmax = wmax,\n",
    "                        interpolation ='nearest', origin ='upper')\n",
    "    plt.colorbar(c)\n",
    "    plt.title('Generated Batch at Epoch ' + str(epochs), fontweight =\"bold\")\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_real_batch(features):\n",
    "    w_img = features\n",
    "    wmin = torch.min(w_img)\n",
    "    wmax = torch.max(w_img)\n",
    "    w_img = w_img.cpu()\n",
    "    w_img = w_img.detach().numpy()\n",
    "    c = plt.imshow(w_img, cmap ='Reds', vmin = wmin , vmax = wmax,\n",
    "                        interpolation ='nearest', origin ='upper')\n",
    "    plt.colorbar(c)\n",
    "    plt.title('Real Batch of Data', fontweight =\"bold\")\n",
    "    plt.show()\n",
    "    \n",
    "def performance_stats(gen, disc, b_size, batch = None):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if batch is None:\n",
    "            latent_vectors = get_noise(b_size, z_dim)\n",
    "            fake_features = gen(latent_vectors)\n",
    "            y_hat = torch.round(disc(fake_features))\n",
    "            y_label = [0] * b_size\n",
    "            y_label = torch.Tensor(y_label)\n",
    "        else:\n",
    "            latent_vectors = get_noise(int(b_size/2), z_dim)\n",
    "            fake_features = gen(latent_vectors)\n",
    "            y_hat = torch.round(disc(fake_features))\n",
    "            y_label = [0] * int(b_size/2)\n",
    "            \n",
    "            real_y_hat = torch.round(disc(batch[:int(b_size/2)]))\n",
    "            for i in range(0, int(b_size/2)):\n",
    "                y_label.append(1)\n",
    "            y_hat = torch.cat((y_hat, real_y_hat), dim = 0)\n",
    "            \n",
    "            #print(y_hat)\n",
    "            #print(y_label)\n",
    "         \n",
    "        \n",
    "        for k in range(len(y_hat)):\n",
    "            #True positive\n",
    "            if y_label[k] == 1 and y_hat[k] == 1:\n",
    "                tp += 1\n",
    "            #False Negative\n",
    "            elif y_label[k] == 1 and y_hat[k] == 0:\n",
    "                fn += 1\n",
    "            #True Negative\n",
    "            elif y_label[k] == 0 and y_hat[k] == 0:\n",
    "                tn += 1\n",
    "            elif y_label[k] == 0 and y_hat[k] == 1:\n",
    "                fp += 1\n",
    "            \n",
    "        class_acc = (tp + tn)/(tp + tn + fp + fn)\n",
    "        \n",
    "        if tp + fp == 0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = tp / (tp + fp)\n",
    "            \n",
    "        if tp + fn == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = tp / (tp + fn)\n",
    "            \n",
    "        if fp + tn == 0:\n",
    "            fpR = 0\n",
    "        else: \n",
    "            fpR = fp / (fp + tn)\n",
    "\n",
    "        #print(f'Classification Accuracy: {class_acc:.2f}')\n",
    "        #print(f'Precision: {precision:.2f}') #What percentage of a model's positive predictions were actually positive\n",
    "        #print(f'Recall: {recall:.2f}') #What percent of the true positives were identified\n",
    "        #print(f'F-1 Score: {2*(precision * recall / (precision + recall + 0.001)):.2f}')\n",
    "        return class_acc, precision, recall, fpR, 2*(precision * recall / (precision + recall + 0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Hyperparameters (Always Run Again Before Starting Training Loop) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function for model\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Digit Precision for printouts\n",
    "dig = 3\n",
    "\n",
    "# Max epochs to run\n",
    "n_epochs = 3000\n",
    "\n",
    "# Number of dimensions of latent vector\n",
    "z_dim = 100\n",
    "\n",
    "# Batch Size\n",
    "batch_size = 200\n",
    "\n",
    "# Learning Rates for Generator (Gen) and Discriminator (Disc)\n",
    "gen_lr =  0.0001\n",
    "disc_lr = 0.0001\n",
    "\n",
    "# Constant epochs approach to train Discriminator, Generator\n",
    "constant_train_flag = False # Set to true to train based on constant # of epochs per machine \n",
    "                           # Set to false to train dynamically based on machine performance\n",
    "disc_epochs = 5            #Number of consecutive epochs to train discriminator before epoch threshold\n",
    "gen_epochs = 2             #Number of consecutive epochs to train generator before epoch threshold\n",
    "epoch_threshold = 50       #Epoch number to change training epoch ratio\n",
    "disc_epochs_change = 1     #New number of consecutive epochs to train discriminator\n",
    "gen_epochs_change = 50     #New number of consecutive epochs to train generator\n",
    "rel_epochs = 0             # Epochs passed since last switch (always set to 0)\n",
    "\n",
    "\n",
    "# Dynamic number of epochs to train Discriminator, Generator\n",
    "static_threshold = 5   #Epoch number to change from static ratio to dynamic\n",
    "static_disc_epochs = 3  #Number of consecutive epochs to train discriminator before epoch threshold\n",
    "static_gen_epochs = 2   #Number of consecutive epochs to train generator before epoch threshold\n",
    "pull_threshold = 0.75   #Accuracy threshold for switching machine training when the generator is no longer competitive\n",
    "push_threshold = 0.50   #Accuracy threshold for switching machine training when the discriminator is no longer competitive\n",
    "\n",
    "# Which machine to train (0 for Generator, 1 for Discriminator) !!!(do not change unless for good reason)!!!\n",
    "GENERATOR = 0\n",
    "DISCRIMINATOR = 1\n",
    "to_train = DISCRIMINATOR\n",
    "train_string = \"DISC\"\n",
    "\n",
    "# Show model performance per batch (will always show summary for each epoch)\n",
    "print_batches = False\n",
    "\n",
    "# Moving corpus data into a pyTorch format !!!(do not change unless for good reason)!!!\n",
    "train_features = torch.tensor(X)\n",
    "train_labels = torch.tensor(y)\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "# Initializiing the Machines !!!(do not change unless for good reason)!!!\n",
    "disc = Discriminator()\n",
    "gen = Generator(z_dim)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr = disc_lr)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr = gen_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3000] Training: DISC | Loss D: 0.708, Loss G: 0.843 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [2/3000] Training: DISC | Loss D: 0.705, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [3/3000] Training: DISC | Loss D: 0.706, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [4/3000] Training: GEN | Loss D: 0.706, Loss G: 0.842 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [5/3000] Training: GEN | Loss D: 0.705, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [6/3000] Training: GEN | Loss D: 0.708, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [7/3000] Training: GEN | Loss D: 0.704, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [8/3000] Training: GEN | Loss D: 0.702, Loss G: 0.842 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [9/3000] Training: GEN | Loss D: 0.706, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [10/3000] Training: GEN | Loss D: 0.708, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [11/3000] Training: GEN | Loss D: 0.707, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [12/3000] Training: GEN | Loss D: 0.706, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [13/3000] Training: GEN | Loss D: 0.707, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [14/3000] Training: GEN | Loss D: 0.707, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [15/3000] Training: GEN | Loss D: 0.704, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [16/3000] Training: GEN | Loss D: 0.707, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [17/3000] Training: GEN | Loss D: 0.706, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [18/3000] Training: GEN | Loss D: 0.704, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [19/3000] Training: GEN | Loss D: 0.703, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [20/3000] Training: GEN | Loss D: 0.706, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [21/3000] Training: GEN | Loss D: 0.706, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [22/3000] Training: GEN | Loss D: 0.707, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [23/3000] Training: GEN | Loss D: 0.704, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [24/3000] Training: GEN | Loss D: 0.706, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [25/3000] Training: GEN | Loss D: 0.708, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [26/3000] Training: GEN | Loss D: 0.706, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [27/3000] Training: GEN | Loss D: 0.706, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [28/3000] Training: GEN | Loss D: 0.703, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [29/3000] Training: GEN | Loss D: 0.706, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [30/3000] Training: GEN | Loss D: 0.705, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [31/3000] Training: GEN | Loss D: 0.708, Loss G: 0.842 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [32/3000] Training: GEN | Loss D: 0.707, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [33/3000] Training: GEN | Loss D: 0.705, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [34/3000] Training: GEN | Loss D: 0.706, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [35/3000] Training: GEN | Loss D: 0.707, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [36/3000] Training: GEN | Loss D: 0.708, Loss G: 0.842 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [37/3000] Training: GEN | Loss D: 0.705, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [38/3000] Training: GEN | Loss D: 0.707, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [39/3000] Training: GEN | Loss D: 0.707, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [40/3000] Training: GEN | Loss D: 0.704, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [41/3000] Training: GEN | Loss D: 0.705, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [42/3000] Training: GEN | Loss D: 0.708, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [43/3000] Training: GEN | Loss D: 0.703, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [44/3000] Training: GEN | Loss D: 0.704, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [45/3000] Training: GEN | Loss D: 0.705, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [46/3000] Training: GEN | Loss D: 0.705, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [47/3000] Training: GEN | Loss D: 0.707, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [48/3000] Training: GEN | Loss D: 0.710, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [49/3000] Training: GEN | Loss D: 0.703, Loss G: 0.842 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [50/3000] Training: GEN | Loss D: 0.705, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [51/3000] Training: GEN | Loss D: 0.706, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [52/3000] Training: GEN | Loss D: 0.705, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [53/3000] Training: GEN | Loss D: 0.707, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [54/3000] Training: GEN | Loss D: 0.707, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [55/3000] Training: GEN | Loss D: 0.707, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [56/3000] Training: GEN | Loss D: 0.706, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [57/3000] Training: GEN | Loss D: 0.706, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [58/3000] Training: GEN | Loss D: 0.706, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [59/3000] Training: GEN | Loss D: 0.708, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [60/3000] Training: GEN | Loss D: 0.708, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [61/3000] Training: GEN | Loss D: 0.705, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [62/3000] Training: GEN | Loss D: 0.707, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [63/3000] Training: GEN | Loss D: 0.706, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [64/3000] Training: GEN | Loss D: 0.706, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [65/3000] Training: GEN | Loss D: 0.705, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [66/3000] Training: GEN | Loss D: 0.706, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [67/3000] Training: GEN | Loss D: 0.709, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/3000] Training: GEN | Loss D: 0.708, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [69/3000] Training: GEN | Loss D: 0.705, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [70/3000] Training: GEN | Loss D: 0.705, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [71/3000] Training: GEN | Loss D: 0.707, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [72/3000] Training: GEN | Loss D: 0.706, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [73/3000] Training: GEN | Loss D: 0.707, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [74/3000] Training: GEN | Loss D: 0.705, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [75/3000] Training: GEN | Loss D: 0.705, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [76/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [77/3000] Training: GEN | Loss D: 0.705, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [78/3000] Training: GEN | Loss D: 0.707, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [79/3000] Training: GEN | Loss D: 0.705, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [80/3000] Training: GEN | Loss D: 0.707, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [81/3000] Training: GEN | Loss D: 0.706, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [82/3000] Training: GEN | Loss D: 0.708, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [83/3000] Training: GEN | Loss D: 0.705, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [84/3000] Training: GEN | Loss D: 0.706, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [85/3000] Training: GEN | Loss D: 0.708, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [86/3000] Training: GEN | Loss D: 0.704, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [87/3000] Training: GEN | Loss D: 0.707, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [88/3000] Training: GEN | Loss D: 0.709, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [89/3000] Training: GEN | Loss D: 0.705, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [90/3000] Training: GEN | Loss D: 0.708, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [91/3000] Training: GEN | Loss D: 0.704, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [92/3000] Training: GEN | Loss D: 0.706, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [93/3000] Training: GEN | Loss D: 0.707, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [94/3000] Training: GEN | Loss D: 0.705, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [95/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [96/3000] Training: GEN | Loss D: 0.708, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [97/3000] Training: GEN | Loss D: 0.711, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [98/3000] Training: GEN | Loss D: 0.707, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [99/3000] Training: GEN | Loss D: 0.705, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [100/3000] Training: GEN | Loss D: 0.707, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [101/3000] Training: GEN | Loss D: 0.707, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [102/3000] Training: GEN | Loss D: 0.710, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [103/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [104/3000] Training: GEN | Loss D: 0.704, Loss G: 0.841 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [105/3000] Training: GEN | Loss D: 0.704, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [106/3000] Training: GEN | Loss D: 0.709, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [107/3000] Training: GEN | Loss D: 0.704, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [108/3000] Training: GEN | Loss D: 0.707, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [109/3000] Training: GEN | Loss D: 0.704, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [110/3000] Training: GEN | Loss D: 0.708, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [111/3000] Training: GEN | Loss D: 0.704, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [112/3000] Training: GEN | Loss D: 0.706, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [113/3000] Training: GEN | Loss D: 0.703, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [114/3000] Training: GEN | Loss D: 0.705, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [115/3000] Training: GEN | Loss D: 0.709, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [116/3000] Training: GEN | Loss D: 0.704, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [117/3000] Training: GEN | Loss D: 0.706, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [118/3000] Training: GEN | Loss D: 0.707, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [119/3000] Training: GEN | Loss D: 0.709, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [120/3000] Training: GEN | Loss D: 0.710, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [121/3000] Training: GEN | Loss D: 0.709, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [122/3000] Training: GEN | Loss D: 0.705, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [123/3000] Training: GEN | Loss D: 0.705, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [124/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [125/3000] Training: GEN | Loss D: 0.709, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [126/3000] Training: GEN | Loss D: 0.708, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [127/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [128/3000] Training: GEN | Loss D: 0.707, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [129/3000] Training: GEN | Loss D: 0.705, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [130/3000] Training: GEN | Loss D: 0.705, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [131/3000] Training: GEN | Loss D: 0.708, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [132/3000] Training: GEN | Loss D: 0.704, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [133/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [134/3000] Training: GEN | Loss D: 0.708, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [135/3000] Training: GEN | Loss D: 0.708, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [136/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [137/3000] Training: GEN | Loss D: 0.707, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [138/3000] Training: GEN | Loss D: 0.705, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [139/3000] Training: GEN | Loss D: 0.708, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [140/3000] Training: GEN | Loss D: 0.704, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [141/3000] Training: GEN | Loss D: 0.705, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [142/3000] Training: GEN | Loss D: 0.708, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [143/3000] Training: GEN | Loss D: 0.705, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [144/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [145/3000] Training: GEN | Loss D: 0.705, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [146/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [147/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [148/3000] Training: GEN | Loss D: 0.710, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [149/3000] Training: GEN | Loss D: 0.708, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [150/3000] Training: GEN | Loss D: 0.708, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [151/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [152/3000] Training: GEN | Loss D: 0.709, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [153/3000] Training: GEN | Loss D: 0.708, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [154/3000] Training: GEN | Loss D: 0.707, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [155/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [156/3000] Training: GEN | Loss D: 0.708, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [157/3000] Training: GEN | Loss D: 0.708, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [158/3000] Training: GEN | Loss D: 0.706, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [159/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [160/3000] Training: GEN | Loss D: 0.709, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [161/3000] Training: GEN | Loss D: 0.707, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [162/3000] Training: GEN | Loss D: 0.709, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [163/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [164/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [165/3000] Training: GEN | Loss D: 0.707, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [166/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [167/3000] Training: GEN | Loss D: 0.708, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [168/3000] Training: GEN | Loss D: 0.708, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [169/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [170/3000] Training: GEN | Loss D: 0.707, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [171/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [172/3000] Training: GEN | Loss D: 0.706, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [173/3000] Training: GEN | Loss D: 0.709, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [174/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [175/3000] Training: GEN | Loss D: 0.705, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [176/3000] Training: GEN | Loss D: 0.709, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [177/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [178/3000] Training: GEN | Loss D: 0.708, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [179/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [180/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [181/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [182/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [183/3000] Training: GEN | Loss D: 0.707, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [184/3000] Training: GEN | Loss D: 0.706, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [185/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [186/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [187/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [188/3000] Training: GEN | Loss D: 0.708, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [189/3000] Training: GEN | Loss D: 0.707, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [190/3000] Training: GEN | Loss D: 0.710, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [191/3000] Training: GEN | Loss D: 0.708, Loss G: 0.840 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [192/3000] Training: GEN | Loss D: 0.708, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [193/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [194/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [195/3000] Training: GEN | Loss D: 0.705, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [196/3000] Training: GEN | Loss D: 0.706, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [197/3000] Training: GEN | Loss D: 0.708, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [198/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [199/3000] Training: GEN | Loss D: 0.709, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/3000] Training: GEN | Loss D: 0.705, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [201/3000] Training: GEN | Loss D: 0.704, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [202/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [203/3000] Training: GEN | Loss D: 0.706, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [204/3000] Training: GEN | Loss D: 0.708, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [205/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [206/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [207/3000] Training: GEN | Loss D: 0.707, Loss G: 0.839 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [208/3000] Training: GEN | Loss D: 0.707, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [209/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [210/3000] Training: GEN | Loss D: 0.706, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [211/3000] Training: GEN | Loss D: 0.708, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [212/3000] Training: GEN | Loss D: 0.706, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [213/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [214/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [215/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [216/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.660 | fpR: 0.000 P: 1.000 | R: 0.019 | F1: 0.037\n",
      "Epoch [217/3000] Training: GEN | Loss D: 0.706, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [218/3000] Training: GEN | Loss D: 0.708, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [219/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [220/3000] Training: GEN | Loss D: 0.705, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [221/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [222/3000] Training: GEN | Loss D: 0.707, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [223/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.660 | fpR: 0.000 P: 1.000 | R: 0.019 | F1: 0.037\n",
      "Epoch [224/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [225/3000] Training: GEN | Loss D: 0.707, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [226/3000] Training: GEN | Loss D: 0.710, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [227/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [228/3000] Training: GEN | Loss D: 0.705, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [229/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [230/3000] Training: GEN | Loss D: 0.709, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [231/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [232/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [233/3000] Training: GEN | Loss D: 0.707, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [234/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [235/3000] Training: GEN | Loss D: 0.708, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [236/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [237/3000] Training: GEN | Loss D: 0.704, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [238/3000] Training: GEN | Loss D: 0.711, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [239/3000] Training: GEN | Loss D: 0.705, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [240/3000] Training: GEN | Loss D: 0.707, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [241/3000] Training: GEN | Loss D: 0.705, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [242/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [243/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [244/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [245/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [246/3000] Training: GEN | Loss D: 0.705, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [247/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [248/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [249/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [250/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [251/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [252/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [253/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [254/3000] Training: GEN | Loss D: 0.708, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [255/3000] Training: GEN | Loss D: 0.709, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [256/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [257/3000] Training: GEN | Loss D: 0.705, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [258/3000] Training: GEN | Loss D: 0.705, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [259/3000] Training: GEN | Loss D: 0.709, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [260/3000] Training: GEN | Loss D: 0.711, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [261/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [262/3000] Training: GEN | Loss D: 0.709, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [263/3000] Training: GEN | Loss D: 0.706, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [264/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [265/3000] Training: GEN | Loss D: 0.711, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [266/3000] Training: GEN | Loss D: 0.707, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [267/3000] Training: GEN | Loss D: 0.703, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [268/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [269/3000] Training: GEN | Loss D: 0.710, Loss G: 0.838 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [270/3000] Training: GEN | Loss D: 0.707, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [271/3000] Training: GEN | Loss D: 0.705, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [272/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [273/3000] Training: GEN | Loss D: 0.706, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [274/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [275/3000] Training: GEN | Loss D: 0.710, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [276/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [277/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [278/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [279/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [280/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [281/3000] Training: GEN | Loss D: 0.711, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [282/3000] Training: GEN | Loss D: 0.711, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [283/3000] Training: GEN | Loss D: 0.706, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [284/3000] Training: GEN | Loss D: 0.710, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [285/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [286/3000] Training: GEN | Loss D: 0.705, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [287/3000] Training: GEN | Loss D: 0.707, Loss G: 0.832 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [288/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [289/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [290/3000] Training: GEN | Loss D: 0.708, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [291/3000] Training: GEN | Loss D: 0.706, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [292/3000] Training: GEN | Loss D: 0.706, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [293/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [294/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [295/3000] Training: GEN | Loss D: 0.706, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [296/3000] Training: GEN | Loss D: 0.708, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [297/3000] Training: GEN | Loss D: 0.706, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [298/3000] Training: GEN | Loss D: 0.710, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [299/3000] Training: GEN | Loss D: 0.707, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [300/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [301/3000] Training: GEN | Loss D: 0.708, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [302/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [303/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [304/3000] Training: GEN | Loss D: 0.707, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [305/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [306/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [307/3000] Training: GEN | Loss D: 0.705, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [308/3000] Training: GEN | Loss D: 0.710, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [309/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [310/3000] Training: GEN | Loss D: 0.704, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [311/3000] Training: GEN | Loss D: 0.707, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [312/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [313/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [314/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [315/3000] Training: GEN | Loss D: 0.708, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [316/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [317/3000] Training: GEN | Loss D: 0.710, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [318/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [319/3000] Training: GEN | Loss D: 0.708, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [320/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [321/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [322/3000] Training: GEN | Loss D: 0.708, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [323/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [324/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [325/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [326/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [327/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [328/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [329/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [330/3000] Training: GEN | Loss D: 0.706, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [331/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [332/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [333/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [334/3000] Training: GEN | Loss D: 0.709, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [335/3000] Training: GEN | Loss D: 0.711, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [336/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [337/3000] Training: GEN | Loss D: 0.712, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [338/3000] Training: GEN | Loss D: 0.709, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [339/3000] Training: GEN | Loss D: 0.710, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [340/3000] Training: GEN | Loss D: 0.706, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [341/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [342/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [343/3000] Training: GEN | Loss D: 0.705, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [344/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [345/3000] Training: GEN | Loss D: 0.710, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [346/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [347/3000] Training: GEN | Loss D: 0.708, Loss G: 0.832 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [348/3000] Training: GEN | Loss D: 0.712, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [349/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [350/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [351/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [352/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [353/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [354/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [355/3000] Training: GEN | Loss D: 0.708, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [356/3000] Training: GEN | Loss D: 0.706, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [357/3000] Training: GEN | Loss D: 0.708, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [358/3000] Training: GEN | Loss D: 0.710, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [359/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [360/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [361/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [362/3000] Training: GEN | Loss D: 0.707, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [363/3000] Training: GEN | Loss D: 0.707, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [364/3000] Training: GEN | Loss D: 0.708, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [365/3000] Training: GEN | Loss D: 0.710, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [366/3000] Training: GEN | Loss D: 0.705, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [367/3000] Training: GEN | Loss D: 0.707, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [368/3000] Training: GEN | Loss D: 0.706, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [369/3000] Training: GEN | Loss D: 0.710, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [370/3000] Training: GEN | Loss D: 0.710, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [371/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [372/3000] Training: GEN | Loss D: 0.707, Loss G: 0.832 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [373/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [374/3000] Training: GEN | Loss D: 0.712, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [375/3000] Training: GEN | Loss D: 0.709, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [376/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [377/3000] Training: GEN | Loss D: 0.707, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [378/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [379/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [380/3000] Training: GEN | Loss D: 0.707, Loss G: 0.832 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [381/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [382/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [383/3000] Training: GEN | Loss D: 0.707, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [384/3000] Training: GEN | Loss D: 0.708, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [385/3000] Training: GEN | Loss D: 0.710, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [386/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [387/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [388/3000] Training: GEN | Loss D: 0.710, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [389/3000] Training: GEN | Loss D: 0.711, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [390/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [391/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [392/3000] Training: GEN | Loss D: 0.707, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [393/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [394/3000] Training: GEN | Loss D: 0.710, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [395/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [396/3000] Training: GEN | Loss D: 0.710, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [397/3000] Training: GEN | Loss D: 0.707, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [398/3000] Training: GEN | Loss D: 0.710, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [399/3000] Training: GEN | Loss D: 0.708, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [400/3000] Training: GEN | Loss D: 0.708, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [401/3000] Training: GEN | Loss D: 0.707, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [402/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [403/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [404/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [405/3000] Training: GEN | Loss D: 0.709, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [406/3000] Training: GEN | Loss D: 0.704, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [407/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [408/3000] Training: GEN | Loss D: 0.709, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [409/3000] Training: GEN | Loss D: 0.706, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [410/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [411/3000] Training: GEN | Loss D: 0.707, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [412/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [413/3000] Training: GEN | Loss D: 0.707, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [414/3000] Training: GEN | Loss D: 0.707, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [415/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [416/3000] Training: GEN | Loss D: 0.710, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [417/3000] Training: GEN | Loss D: 0.710, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [418/3000] Training: GEN | Loss D: 0.708, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [419/3000] Training: GEN | Loss D: 0.710, Loss G: 0.832 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [420/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [421/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [422/3000] Training: GEN | Loss D: 0.708, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [423/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [424/3000] Training: GEN | Loss D: 0.708, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [425/3000] Training: GEN | Loss D: 0.709, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [426/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [427/3000] Training: GEN | Loss D: 0.711, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [428/3000] Training: GEN | Loss D: 0.708, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [429/3000] Training: GEN | Loss D: 0.707, Loss G: 0.832 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [430/3000] Training: GEN | Loss D: 0.704, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [431/3000] Training: GEN | Loss D: 0.709, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [432/3000] Training: GEN | Loss D: 0.709, Loss G: 0.832 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [433/3000] Training: GEN | Loss D: 0.710, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [434/3000] Training: GEN | Loss D: 0.706, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [435/3000] Training: GEN | Loss D: 0.707, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [436/3000] Training: GEN | Loss D: 0.707, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [437/3000] Training: GEN | Loss D: 0.708, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [438/3000] Training: GEN | Loss D: 0.707, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [439/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [440/3000] Training: GEN | Loss D: 0.710, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [441/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [442/3000] Training: GEN | Loss D: 0.711, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [443/3000] Training: GEN | Loss D: 0.709, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [444/3000] Training: GEN | Loss D: 0.707, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [445/3000] Training: GEN | Loss D: 0.709, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [446/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [447/3000] Training: GEN | Loss D: 0.705, Loss G: 0.832 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [448/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [449/3000] Training: GEN | Loss D: 0.707, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [450/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [451/3000] Training: GEN | Loss D: 0.706, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [452/3000] Training: GEN | Loss D: 0.710, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [453/3000] Training: GEN | Loss D: 0.707, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [454/3000] Training: GEN | Loss D: 0.707, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [455/3000] Training: GEN | Loss D: 0.708, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [456/3000] Training: GEN | Loss D: 0.709, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [457/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [458/3000] Training: GEN | Loss D: 0.708, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [459/3000] Training: GEN | Loss D: 0.710, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [460/3000] Training: GEN | Loss D: 0.710, Loss G: 0.835 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [461/3000] Training: GEN | Loss D: 0.709, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [462/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [463/3000] Training: GEN | Loss D: 0.709, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [464/3000] Training: GEN | Loss D: 0.711, Loss G: 0.837 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [465/3000] Training: GEN | Loss D: 0.708, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [466/3000] Training: GEN | Loss D: 0.705, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [467/3000] Training: GEN | Loss D: 0.710, Loss G: 0.833 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [468/3000] Training: GEN | Loss D: 0.709, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [469/3000] Training: GEN | Loss D: 0.708, Loss G: 0.836 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [470/3000] Training: GEN | Loss D: 0.710, Loss G: 0.834 | Accuracy: 0.654 | fpR: 0.000 P: 0.000 | R: 0.000 | F1: 0.000\n",
      "Epoch [471/3000] Training: GEN "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-81bb4468a4bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mopt_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mgen_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_gen_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mgen_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[0mopt_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperformance_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreal_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "last_real_features = []\n",
    "\n",
    "for epoch in range(n_epochs):  \n",
    "    if constant_train_flag:\n",
    "        if to_train == DISCRIMINATOR and rel_epochs >= disc_epochs:\n",
    "            rel_epochs = 0\n",
    "            to_train = GENERATOR\n",
    "            train_string = \"GEN\"\n",
    "\n",
    "        elif to_train == GENERATOR and rel_epochs >= gen_epochs:\n",
    "            rel_epochs = 0\n",
    "            to_train = DISCRIMINATOR\n",
    "            train_string = \"DISC\"\n",
    "        \n",
    "        # Change epoch ratio after intial 'leveling out'\n",
    "        if epoch == epoch_threshold:\n",
    "            rel_epochs = 0\n",
    "            to_train = GENERATOR\n",
    "            train_string = \"GENERATOR\"\n",
    "\n",
    "            old_ratio = gen_epochs / disc_epochs\n",
    "            gen_epochs = gen_epochs_change\n",
    "            disc_epochs = disc_epochs_change\n",
    "            new_ratio = gen_epochs / disc_epochs\n",
    "            print(f'\\n\\nTraining ratio of G/D switched from {old_ratio:.{dig}f} to {new_ratio:.{dig}f}\\n\\n')\n",
    "    else:\n",
    "        if epoch < static_threshold:\n",
    "            if to_train == DISCRIMINATOR and rel_epochs >= static_disc_epochs:\n",
    "                rel_epochs = 0\n",
    "                to_train = GENERATOR\n",
    "                train_string = \"GEN\"\n",
    "\n",
    "            elif to_train == GENERATOR and rel_epochs >= static_gen_epochs:\n",
    "                rel_epochs = 0\n",
    "                to_train = DISCRIMINATOR\n",
    "                train_string = \"DISC\"\n",
    "        \n",
    "        else:\n",
    "            if to_train == DISCRIMINATOR and acc >= pull_threshold:\n",
    "                to_train = GENERATOR\n",
    "                train_string = \"GEN\"\n",
    "            if to_train == GENERATOR and acc <= push_threshold:\n",
    "                to_train = DISCRIMINATOR\n",
    "                train_string = \"DISC\"\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{n_epochs}] Training: {train_string} ', end ='')\n",
    "    cc, P, R, fpR, F1 = 0, 0, 0, 0, 0\n",
    "    for batch_idx, (real_features, _) in enumerate(train_loader):\n",
    "        #batch_size = len(real_features)\n",
    "    \n",
    "        if print_batches:\n",
    "                print(f'\\n\\tBatch [{batch_idx + 1} / {len(train_loader)}] |', end ='')\n",
    "    \n",
    "        if to_train == DISCRIMINATOR:\n",
    "            ### Training Discriminator\n",
    "            #visualize_real_batch(real_features.float())\n",
    "            opt_disc.zero_grad()\n",
    "            disc_loss = get_disc_loss(gen, disc, criterion, real_features.float(), batch_size, z_dim)\n",
    "            disc_loss.backward(retain_graph = True)\n",
    "            opt_disc.step()\n",
    "            acc, P, R, fpR, F1 = performance_stats(gen, disc, batch_size, batch = real_features.float())\n",
    "            if print_batches:\n",
    "                print(f'Loss D: {disc_loss.item():.digf}, Loss G: {get_gen_loss(gen, disc, criterion, batch_size, z_dim):.{dig}f} | Accuracy: {acc:.{dig}f} | fpR: {fpR:.{dig}f} P: {P:.{dig}f} | R: {R:.{dig}f} | F1: {F1:.{dig}f}')\n",
    "        else:\n",
    "            ### Training Generator\n",
    "            \n",
    "            opt_gen.zero_grad()\n",
    "            gen_loss = get_gen_loss(gen, disc, criterion, batch_size, z_dim)\n",
    "            gen_loss.backward()\n",
    "            opt_gen.step()\n",
    "            acc, P, R, fpR, F1 = performance_stats(gen, disc, batch_size, batch = real_features.float())\n",
    "            if print_batches:\n",
    "                print(f'Loss D: {get_disc_loss(gen, disc, criterion, real_features.float(), batch_size, z_dim):.{dig}f}, Loss G: {gen_loss.item():.{dig}f} | Accuracy: {acc:.{dig}f} | fpR: {fpR:.{dig}f} P: {P:.{dig}f} | R: {R:.{dig}f} | F1: {F1:.{dig}f}')\n",
    "        \n",
    "    if not print_batches:\n",
    "        if to_train == DISCRIMINATOR:\n",
    "            print(f'| Loss D: {disc_loss.item():.{dig}f}, Loss G: {get_gen_loss(gen, disc, criterion, batch_size, z_dim):.{dig}f} | Accuracy: {acc:.{dig}f} | fpR: {fpR:.{dig}f} P: {P:.{dig}f} | R: {R:.{dig}f} | F1: {F1:.{dig}f}')\n",
    "        else:\n",
    "            print(f'| Loss D: {get_disc_loss(gen, disc, criterion, real_features.float(), batch_size, z_dim):.{dig}f}, Loss G: {gen_loss.item():.{dig}f} | Accuracy: {acc:.{dig}f} | fpR: {fpR:.{dig}f} P: {P:.{dig}f} | R: {R:.{dig}f} | F1: {F1:.{dig}f}')\n",
    "    rel_epochs += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Generation Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
